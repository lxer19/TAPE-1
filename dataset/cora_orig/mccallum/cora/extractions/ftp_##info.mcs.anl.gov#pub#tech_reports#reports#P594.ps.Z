URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P594.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts96.htm
Root-URL: http://www.mcs.anl.gov
Email: fD.Abramson,R.Sosicg@cit.gu.edu.au  foster@mcs.anl.gov  jon@dstc.edu.au  andrew@qpsf.edu.au  n.white@ctpm.uq.edu.au  
Title: The Nimrod Computational Workbench: A Case Study in Desktop Metacomputing  
Author: David Abramsony Ian Fosterz Jon Giddyx Andrew Lewis# Rok Sosicy Robert Sutherst$ Neil White$ 
Address: Australia  Argonne, IL 60439 U.S.A.  Australia  Australia  Australia  
Affiliation: ySchool of Computing and Information Technology Griffith University Brisbane, Qld. 4111  zMathematics and Computer Science Division Argonne National Laboratory  xCo-operative Research Centre for Distributed Systems Technology Level 7, Gehrmann Laboratories University of Queensland St. Lucia, Qld.  Queensland Parallel Supercomputing Facility Griffith University Brisbane, Qld. 4111  $Co-operative Research Centre for Tropical Pest Management Level 5, Gehrmann Laboratories, University of Queensland St. Lucia, Qld.  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D. Abramson, R. Sosic, J. Giddy, and M. </author> <title> Cope. The laboratory bench: Distributed computing for parametised simulations. </title> <booktitle> In 1994 Parallel Computing and Transputers Conference, </booktitle> <pages> pages 17-27, </pages> <address> Wollongong, Australia, </address> <year> 1994. </year>
Reference-contexts: We conclude by indicating how Nimrod can be modified to meet these challenges. 2 The Nimrod Problem-Solving Environment Nimrod automates the creation and management of large parametric experiments <ref> [1, 2] </ref>. It allows a user to run a single application under a wide range of input conditions and then to aggregate the results of these different runs for interpretation.
Reference: [2] <author> D. Abramson, R. Sosic, J. Giddy, and B. Hall. Nimrod: </author> <title> A tool for performing parametised simulations using distributed workstations. </title> <booktitle> In Proc. of the 4th IEEE Symposium on High Performance Distributed Computing, </booktitle> <month> 8 </month> <year> 1995. </year>
Reference-contexts: We conclude by indicating how Nimrod can be modified to meet these challenges. 2 The Nimrod Problem-Solving Environment Nimrod automates the creation and management of large parametric experiments <ref> [1, 2] </ref>. It allows a user to run a single application under a wide range of input conditions and then to aggregate the results of these different runs for interpretation.
Reference: [3] <author> C. Catlett and L. </author> <title> Smarr. Metacomputing. </title> <journal> CACM, </journal> <volume> 35(6) </volume> <pages> 44-52, </pages> <year> 1992. </year>
Reference-contexts: This logical computer can be used to access unique resources not accessible at a particular site or to assemble aggregate computational resources superior to that offered by a single site <ref> [3] </ref>. In principle, metacomputing can both increase accessibility to supercomputing capabilities and provide more cost-effective computing than do conventional high-performance systems. Experiments such as the I-WAY/GII Testbed [4] have demonstrated serious applications on wide-area networks. However, concerns remain regarding the viability of the approach. Two questions appear particularly troublesome.
Reference: [4] <author> T. DeFanti, I. Foster, M. Papka, R. Stevens, and T. Kuhfuss. </author> <title> Overview of the I-WAY: Wide area visual supercomputing. </title> <booktitle> Intl J. Supercomputer Applications, </booktitle> <year> 1996. </year> <note> in press. 15 </note>
Reference-contexts: In principle, metacomputing can both increase accessibility to supercomputing capabilities and provide more cost-effective computing than do conventional high-performance systems. Experiments such as the I-WAY/GII Testbed <ref> [4] </ref> have demonstrated serious applications on wide-area networks. However, concerns remain regarding the viability of the approach. Two questions appear particularly troublesome. <p> The I-WAY was designed to support a rather different class of applications to Nimrod: for the most part, tightly coupled applications with demanding network quality of service requirements. Hence, it is interesting to understand how I-WAY and Nimrod requirements correspond and differ. 4.1 The I-WAY Experiment The I-WAY project <ref> [4] </ref> was conceived in early 1995 with the goal of providing a large-scale testbed in which innovative high-performance and geographically distributed applications could be deployed. The testbed comprised an ATM network connecting supercomputers, mass storage systems, and advanced visualization devices at 17 different sites 11 within North America.
Reference: [5] <author> M. Eldred, D. Outka, C. Fulcher, and W. Bohnhoff. </author> <title> Optimization of complex mechanics simulations with object-oriented software design. </title> <booktitle> In Proceedings of the 36th AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference, </booktitle> <pages> pages 2406-2415, </pages> <address> New Orleans, LA, </address> <month> 4 </month> <year> 1995. </year>
Reference-contexts: In effect, Nimrod transforms file-based programs into interactive "meta-applications" that invoke user programs much as we might call subroutines. 3 Nimrod can be compared with optimization systems designed to locate local or global minima of user-supplied functions across parameter spaces <ref> [5] </ref>. It is distinguished from these systems by the fact that it does not require changes to user code.
Reference: [6] <author> F. Ferstl. </author> <title> CODINE Technical Overview. </title> <type> Technical report, </type> <institution> Genias, </institution> <month> 4 </month> <year> 1993. </year>
Reference-contexts: These efforts build on experience with systems such as PVM [19] that hide machine-specific details. The LSF network operating system [22] also attempts to provide the illusion of a large processor address space. Job management systems such as LoadLeveler [11], NQS, Codine <ref> [6] </ref>, and others [12] map jobs placed in a work queue to physically distributed processors. 2 While low-level system services are important, they are not in themselves a sufficient solution to the problems of metacomputing applications and usability.
Reference: [7] <author> E. A. Fitzpatrick and H. A. Nix. </author> <title> A model for simulating soil water regime in alternating fallow-crop systems. </title> <journal> Agricultural Meteorology, </journal> <volume> 6 </volume> <pages> 303-319, </pages> <year> 1969. </year>
Reference-contexts: Herd composition data for Australia, obtained from the Australian Bureau of Resource Economics, are used to derive weighted average herd characteristics and stocking rates. A soil dryness index is derived from meteorological data by using a single-layer soil water model based on <ref> [7] </ref>. Each simulation uses long-term average climate data and is run to equilibrium (ten years) after an initialization. The model is written in Fortran 77 and uses the NCSA netCDF/HDF data file format [16] to handle climate surface data and simulation output.
Reference: [8] <author> I. Foster, J. Geisler, C. Kesselman, and S. Tuecke. </author> <title> Multimethod communication for high-performance metacomputing applications. </title> <type> Preprint, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1996. </year>
Reference-contexts: In addition, applications and tools may need to be able to determine network properties such as topology and delivered QoS, so that they can adapt algorithms and protocols to maximize performance <ref> [8] </ref>. Previous work on wide area scheduling has not really addressed these issues, and it might appear that the coarse-grained tasks typically scheduled by such systems would not be overly sensitive to these factors.
Reference: [9] <author> I. Foster, J. Geisler, W. Nickless, W. Smith, and S. Tuecke. </author> <title> Software infrastructure for the I-WAY high-performance distributed computing experiment. </title> <booktitle> In Proc. of the 5th IEEE Symposium on High Performance Distributed Computing. IEEE, </booktitle> <year> 1996. </year>
Reference-contexts: Two questions appear particularly troublesome. Is there in practice a large base of applications able to exploit geographically distributed resources connected by networks with high latencies and low bisection bandwidth? Will programmers master the complexities inherent in computing in geographically distributed, heterogeneous, internetworked environments? The I-WAY <ref> [9] </ref>, Legion [10], and Globe [21] projects are addressing the usability issue by developing system services intended to provide the illusion of a single virtual machine. These efforts build on experience with systems such as PVM [19] that hide machine-specific details. <p> It was deployed at the Supercomputing conference (SC'95) in San Diego in December 1995 and used by over 60 application groups for experiments in high-performance computing, collaborative design, and the coupling of remote supercomputers and databases into local environments. A management and application programming environment, called I-Soft <ref> [9] </ref>, provided uniform authentication, resource reservation, process creation, and communication functions across I-WAY resources. The I-WAY was successful in demonstrating that large-scale, high-performance meta-computing is feasible and useful. Just as important, it provided the first application-oriented testbed in which to identify the critical issues affecting future progress in this area. <p> Local schedulers performed site-dependent actions in response to requests from the central scheduler to allocate resources, create processes, and deallocate resources <ref> [9] </ref>. Nimrod does not currently use local machine schedulers. In the TICK1 experiment, we disabled the native schedulers (which in most cases was LSF) and required users to start Nimrod execution servers directly. In effect, we negotiated access to remote resources manually|via e-mail or telephone.
Reference: [10] <author> A. Grimshaw, W. Wulf, J. French, A. Weaver, and P. Reynolds, Jr. Legion: </author> <title> The next logical step toward a nationwide virtual computer. </title> <type> Technical Report CS-94-21, </type> <institution> Department of Computer Science, University of Virginia, </institution> <year> 1994. </year>
Reference-contexts: Two questions appear particularly troublesome. Is there in practice a large base of applications able to exploit geographically distributed resources connected by networks with high latencies and low bisection bandwidth? Will programmers master the complexities inherent in computing in geographically distributed, heterogeneous, internetworked environments? The I-WAY [9], Legion <ref> [10] </ref>, and Globe [21] projects are addressing the usability issue by developing system services intended to provide the illusion of a single virtual machine. These efforts build on experience with systems such as PVM [19] that hide machine-specific details.
Reference: [11] <institution> IBM. IBM LoadLeveler: </institution> <note> User's Guide. </note> <institution> International Business Machines Corporation, </institution> <month> 3 </month> <year> 1993. </year>
Reference-contexts: These efforts build on experience with systems such as PVM [19] that hide machine-specific details. The LSF network operating system [22] also attempts to provide the illusion of a large processor address space. Job management systems such as LoadLeveler <ref> [11] </ref>, NQS, Codine [6], and others [12] map jobs placed in a work queue to physically distributed processors. 2 While low-level system services are important, they are not in themselves a sufficient solution to the problems of metacomputing applications and usability.
Reference: [12] <author> J. Kaplan and M. Nelson. </author> <title> A comparison of queuing, cluster and distributed computing systems. </title> <type> Technical Report 109025, </type> <institution> NASA, Langley Research Centre, Hampton, Virginia, </institution> <month> 23681-0001, 10 </month> <year> 1993. </year>
Reference-contexts: These efforts build on experience with systems such as PVM [19] that hide machine-specific details. The LSF network operating system [22] also attempts to provide the illusion of a large processor address space. Job management systems such as LoadLeveler [11], NQS, Codine [6], and others <ref> [12] </ref> map jobs placed in a work queue to physically distributed processors. 2 While low-level system services are important, they are not in themselves a sufficient solution to the problems of metacomputing applications and usability.
Reference: [13] <author> A. Lewis, D. Abramson, R. Sosic, and J. Giddy. </author> <title> Tool-based parameterisation : An application perspective. </title> <booktitle> In Computational Techniques and Applications Conference, </booktitle> <address> Melbourne, Australia, </address> <month> 7 </month> <year> 1995. </year>
Reference-contexts: Nimrod was originally developed to provide seamless access to a homogeneous collection of workstations located on a single local area network. In this environment, Nimrod has proved extremely effective in application studies involving users with a wide range of parallel programming skills <ref> [13] </ref>. In this article, we describe extensions to Nimrod that support its use in a metacomputing environment. These extensions include support for multiple architectures, including parallel supercomputers; new job startup mechanisms and file transfer mechanisms, suitable for wide area network; and alternative authentication mechanisms for job creation at multiple sites.
Reference: [14] <author> G. F. Maywald, M. J. Dallwitz, and R. W. Sutherst. </author> <title> A systems approach to cattle tick control. </title> <booktitle> In Proceedings of the 4th Biennial Conference of the Simulation Society of Australia, </booktitle> <pages> pages 131-139, </pages> <year> 1980. </year>
Reference-contexts: Enormous savings are to be made by optimizing the application of control measures and utilization of resistant strains. Optimal control techniques also can help to reduce chemical resistance within tick populations and to minimize residual pesticide levels. Our experiment uses TICK1 <ref> [20, 14] </ref>, a simulation code developed to study cattle tick ecology. TICK1 is a climate-driven, process-based, discrete time step (weekly) model of the population dynamics of cattle ticks. It incorporates models of various ecological and physiological tick development processes, including on-host survival, competition between ticks, and avoidance behavior in cattle.
Reference: [15] <author> Linda Mui and Eric Pearce. </author> <title> X Window System Administrator's Guide. </title> <publisher> O'Reilly and Associates, Inc, </publisher> <address> Sebastopol, California, </address> <year> 1992. </year>
Reference-contexts: Execution servers are then run under the id of the user. A magic token is used to ensure that servers accept only authorized requests, in a similar way to X windows (XAuth <ref> [15] </ref>). The current Nimrod approach works reasonably well across a wide range of platforms. Because it does not require any privileges not already granted to a normal user, it does not result in any major security difficulties. Its most significant disadvantage is the need for a prior trust relationship.
Reference: [16] <author> NCSA. </author> <title> The HDF reference manual version 3.3. </title> <type> Technical report, </type> <institution> National Center for Supercomputing Applications., </institution> <month> 2 </month> <year> 1994. </year>
Reference-contexts: Each simulation uses long-term average climate data and is run to equilibrium (ten years) after an initialization. The model is written in Fortran 77 and uses the NCSA netCDF/HDF data file format <ref> [16] </ref> to handle climate surface data and simulation output. A 50 km grid is used across Australia (2785 locations). Simulation inputs are obtained from a commercial geographical information system; these comprise climatic (rainfall, maximum and minimum temperature and evaporation), herd composition, stocking rate, and management strategy data.
Reference: [17] <author> R. Sosic. </author> <title> Design and implementation of Dynascope, a directing platform for compiled programs. </title> <journal> Computing Systems, </journal> <volume> 8(2) </volume> <pages> 107-134, </pages> <month> Spring </month> <year> 1995. </year>
Reference-contexts: This feature is useful for long-running jobs because it allows the user to determine the exact progress of the run, for example by monitoring the time step or computed error values within an equation solver. Variables are accessed with the Dynascope library <ref> [18, 17] </ref>, which provides a convenient method for extracting data from remotely executing programs. The final phase of an experiment is data aggregation and display. This functionality is supported by a user-specified experiment completion script that can invoke external data filters and visualization tools.
Reference: [18] <author> R. Sosic. </author> <title> A procedural interface for program directing. </title> <journal> Software-Practice and Experience, </journal> <volume> 25(7) </volume> <pages> 767-787, </pages> <month> July </month> <year> 1995. </year> <month> 16 </month>
Reference-contexts: This feature is useful for long-running jobs because it allows the user to determine the exact progress of the run, for example by monitoring the time step or computed error values within an equation solver. Variables are accessed with the Dynascope library <ref> [18, 17] </ref>, which provides a convenient method for extracting data from remotely executing programs. The final phase of an experiment is data aggregation and display. This functionality is supported by a user-specified experiment completion script that can invoke external data filters and visualization tools.
Reference: [19] <author> V. Sunderam, A. Geist, J. Dongarra, and Mancheck. </author> <title> The PVM concurrent computing system: Evolution, experiences and trends. </title> <journal> Parallel Computing, </journal> <volume> 20(4) </volume> <pages> 531-546, </pages> <month> 3 </month> <year> 1994. </year>
Reference-contexts: These efforts build on experience with systems such as PVM <ref> [19] </ref> that hide machine-specific details. The LSF network operating system [22] also attempts to provide the illusion of a large processor address space.
Reference: [20] <author> R. W. Sutherst and M. J. Dallwitz. </author> <title> Progress in the development of a population model for the cattle tick boophilus microplus. </title> <booktitle> In Proceedings of the 4th International Congress of Acarology, </booktitle> <pages> pages 557-563, </pages> <year> 1974. </year>
Reference-contexts: Enormous savings are to be made by optimizing the application of control measures and utilization of resistant strains. Optimal control techniques also can help to reduce chemical resistance within tick populations and to minimize residual pesticide levels. Our experiment uses TICK1 <ref> [20, 14] </ref>, a simulation code developed to study cattle tick ecology. TICK1 is a climate-driven, process-based, discrete time step (weekly) model of the population dynamics of cattle ticks. It incorporates models of various ecological and physiological tick development processes, including on-host survival, competition between ticks, and avoidance behavior in cattle.
Reference: [21] <author> M. van Steen, P. Homburg, L. van Doorn, A. Tanenbaum, and W. de Jonge. </author> <title> Towards object-based wide area distributed systems. </title> <booktitle> In Proc. of the International Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 224-227, </pages> <year> 1995. </year>
Reference-contexts: Is there in practice a large base of applications able to exploit geographically distributed resources connected by networks with high latencies and low bisection bandwidth? Will programmers master the complexities inherent in computing in geographically distributed, heterogeneous, internetworked environments? The I-WAY [9], Legion [10], and Globe <ref> [21] </ref> projects are addressing the usability issue by developing system services intended to provide the illusion of a single virtual machine. These efforts build on experience with systems such as PVM [19] that hide machine-specific details.
Reference: [22] <author> S. Zhou, J. Wang, X Zheng, and P Deliale. </author> <title> Utopia: A load sharing facility for large, heterogeneous distributed systems. </title> <type> Technical Report CSRI-257, </type> <institution> Computer Systems Research Institute, University of Toronto, Toronto, Canada, M5S 1A1, </institution> <year> 1992. </year> <month> 17 </month>
Reference-contexts: These efforts build on experience with systems such as PVM [19] that hide machine-specific details. The LSF network operating system <ref> [22] </ref> also attempts to provide the illusion of a large processor address space.
References-found: 22

