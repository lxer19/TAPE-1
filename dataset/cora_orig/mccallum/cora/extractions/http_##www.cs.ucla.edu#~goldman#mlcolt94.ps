URL: http://www.cs.ucla.edu/~goldman/mlcolt94.ps
Refering-URL: http://www.cs.ucla.edu/~goldman/papers.html
Root-URL: http://www.cs.ucla.edu
Email: t.ross@ieee.org  
Title: Pattern Theoretic Feature Extraction and Constructive Induction  
Author: T. D. Ross M. J. Noviskey M. L. Axtell D. A. Gadd J. A. Goldman 
Address: WL/AART-2 WPAFB, OH  5200 Springfield Pk Dayton, OH  
Affiliation: Wright Lab  Wright Lab  Veda Inc.  Wright Lab  Wright Lab  
Abstract: This paper offers a perspective on features and pattern finding in general. This perspective is based on a robust complexity measure called Decomposed Function Car-dinality. A function decomposition algorithm for minimizing this complexity measure and finding the associated features is outlined. Results from experiments with this algorithm are also summarized.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Yaser S. Abu-Mostafa, </author> <title> editor. Complexity in Information Theory. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: One approach to this challenge is called pattern theory [13] 2 , where we think of robust complexity determination as the problem of finding a pattern. Pattern theory uses Decomposed Function Cardinality (DFC), proposed by Y. S. Abu-Mostafa as a general measure of complexity <ref> [1, p.128] </ref>. DFC is based on the cardinality of a function. After all, a function is a set of ordered pairs and, as with any set, has a definite property in its number of elements or cardi-nality.
Reference: [2] <author> Robert L. Ashenhurst. </author> <title> The decomposition of switching functions. </title> <booktitle> In Proceedings of the International Symposium on the Theory of Switching, </booktitle> <month> April </month> <year> 1957. </year>
Reference-contexts: L. Ashenhurst <ref> [2] </ref> and others. The basic approach used by AFD is best conveyed by a simple example. Suppose we want to decompose the function in Table 1. This same table is shown in Table 2, except we partition the variables into row and column variables to get a two-dimension table.
Reference: [3] <author> A. R. Barron and R. L. Barron. </author> <title> Statistical learning networks: A unifying view. </title> <booktitle> In 1988 Symposium on the Interface: Statistics and Computing Science, </booktitle> <pages> page 12, </pages> <year> 1988. </year>
Reference-contexts: This extrapolation requires both samples and "inductive bias." Bias towards low complexity, as in Occam's Razor, is particularly important. There is a strong theoretical basis for Occam-based learning, see for example <ref> [3, 4] </ref>. Kolmogorov complexity was developed specifically for induction (reference [7]); however, finding it is not tractable.
Reference: [4] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. </author> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <pages> pages 377-380, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: This extrapolation requires both samples and "inductive bias." Bias towards low complexity, as in Occam's Razor, is particularly important. There is a strong theoretical basis for Occam-based learning, see for example <ref> [3, 4] </ref>. Kolmogorov complexity was developed specifically for induction (reference [7]); however, finding it is not tractable.
Reference: [5] <author> Ulf Grenander. </author> <title> Lectures in Pattern Theory: Pattern Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1978. </year> <note> Applied Mathematical Sciences Vol. 24. </note>
Reference-contexts: DFC is especially robust in the sense that it reflects patterns of many different kinds. Its robustness is supported by its relationship to more conventional 1 Trademark of AbTech Corp. 2 This "pattern theory" is not directly related to that developed by Ulf Grenander <ref> [5] </ref> which addresses a different problem. measures of complexity, including circuit size com-plexity, time complexity, and decision tree or diagram size. If a problem has low complexity by any of these measures then it will also have low DFC [13, Chapter 4].
Reference: [6] <author> Jack S. N. Jean, Kefu Xue, and Shailendra Goel. </author> <title> Pattern theory for character recognition. </title> <booktitle> In Proceedings of ICNN, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: The results on these small, but non-trivial, functions have consistently pointed to a promising ability to find many different kinds of patterns. Work is continuing on methods for improving the runtime of these methods, notably the extensions made by Jean et. al. in <ref> [6] </ref> for a 96 variable multi-valued problem. 5 SUMMARY The problem of feature extraction generalizes to one of pattern finding. Pattern finding can be formalized as minimizing a robust measure of complexity, such as DFC.
Reference: [7] <author> Ming Li and Paul M. B. Vitanyi. </author> <title> Inductive reasoning and kolmogorov complexity. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 44 </volume> <pages> 343-384, </pages> <year> 1992. </year>
Reference-contexts: This extrapolation requires both samples and "inductive bias." Bias towards low complexity, as in Occam's Razor, is particularly important. There is a strong theoretical basis for Occam-based learning, see for example [3, 4]. Kolmogorov complexity was developed specifically for induction (reference <ref> [7] </ref>); however, finding it is not tractable. There have been some tractable measures of complexity used in actual implementations of Occam-based learning, such as the Abductory Inference Mechanism (AIM 1 ) [8] which uses polynomial networks and C4.5 [9] which uses decision trees.
Reference: [8] <author> Gerald J. Montgomery and Keith C. Drake. </author> <title> Ab-ductive networks. </title> <booktitle> In SPIE Applications of Neural Networks Conference, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: Kolmogorov complexity was developed specifically for induction (reference [7]); however, finding it is not tractable. There have been some tractable measures of complexity used in actual implementations of Occam-based learning, such as the Abductory Inference Mechanism (AIM 1 ) <ref> [8] </ref> which uses polynomial networks and C4.5 [9] which uses decision trees.
Reference: [9] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, Cali-fornia, </address> <year> 1993. </year>
Reference-contexts: Kolmogorov complexity was developed specifically for induction (reference [7]); however, finding it is not tractable. There have been some tractable measures of complexity used in actual implementations of Occam-based learning, such as the Abductory Inference Mechanism (AIM 1 ) [8] which uses polynomial networks and C4.5 <ref> [9] </ref> which uses decision trees.
Reference: [10] <author> Timothy D. Ross. </author> <title> Elementary Theorems in Pattern Theory. </title> <type> PhD thesis, </type> <institution> Air Force Institute of Technology, </institution> <year> 1988. </year>
Reference-contexts: In another sense it reduces the dimensionality from the four original input variables to the three inputs to F . That is, it concentrates the "information." The component function is a useful feature if it concentrates the information <ref> [10, pp.64-66] </ref>.
Reference: [11] <author> Timothy D. Ross, Mark L. Axtell, Michael J. Noviskey, and David A. Gadd. </author> <title> Pattern theory paradigm for system design. </title> <booktitle> In 36th Midwest Symposium on Circuits and Systems, </booktitle> <year> 1993. </year>
Reference-contexts: non-optimal coloring algorithms show promise for this problem; however, reducing the computational complexity of function decomposition, while preserving its desirable characteristics, remains a significant problem. 4 SUMMARY OF DFC MEASUREMENTS AND APPLICATIONS A number of experiments have been conducted to assess the generality of DFC across different problem domains (see <ref> [11] </ref>).
Reference: [12] <author> Timothy D. Ross, Jeffrey A. Goldman, David A. Gadd, Michael J. Noviskey, and Mark L. Axtell. </author> <title> On the decomposition of real-valued functions. </title> <booktitle> In Third International Workshop on Post-Binary ULSI Systems in affiliation with the Twenty-Fourth International Symposium on Multiple-Valued Logic, </booktitle> <year> 1994. </year>
Reference-contexts: Our work has concentrated on functions with binary inputs, but the concept is easily extended to functions on any finite set [13] and is being formulated for continuous functions <ref> [12] </ref>. 3 FUNCTION DECOMPOSITION AS A FEATURE EXTRACTOR DFC can be found (or approximated) by using a decomposition program (referred to as AFD) derived from the work of R. L. Ashenhurst [2] and others. The basic approach used by AFD is best conveyed by a simple example.
Reference: [13] <author> Timothy D. Ross, Michael J. Noviskey, Timothy N. Taylor, and David A. Gadd. </author> <title> Pattern theory: An engineering paradigm for algorithm design. </title> <type> Final Technical Report WL-TR-91-1060, </type> <institution> Wright Laboratory, USAF, </institution> <address> WL/AART, WPAFB, OH 45433-6543, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: The challenge is to develop robust and tractable measures of complexity. One approach to this challenge is called pattern theory <ref> [13] </ref> 2 , where we think of robust complexity determination as the problem of finding a pattern. Pattern theory uses Decomposed Function Cardinality (DFC), proposed by Y. S. Abu-Mostafa as a general measure of complexity [1, p.128]. DFC is based on the cardinality of a function. <p> If a problem has low complexity by any of these measures then it will also have low DFC <ref> [13, Chapter 4] </ref>. <p> If a problem has low complexity by any of these measures then it will also have low DFC [13, Chapter 4]. Our work has concentrated on functions with binary inputs, but the concept is easily extended to functions on any finite set <ref> [13] </ref> and is being formulated for continuous functions [12]. 3 FUNCTION DECOMPOSITION AS A FEATURE EXTRACTOR DFC can be found (or approximated) by using a decomposition program (referred to as AFD) derived from the work of R. L. Ashenhurst [2] and others.
References-found: 13

