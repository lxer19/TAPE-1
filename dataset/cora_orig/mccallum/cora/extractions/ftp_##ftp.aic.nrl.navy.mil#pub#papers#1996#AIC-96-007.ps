URL: ftp://ftp.aic.nrl.navy.mil/pub/papers/1996/AIC-96-007.ps
Refering-URL: http://www.aic.nrl.navy.mil/~schultz/papers.html
Root-URL: 
Title: Continuous Localization Using Evidence Grids  
Author: Alan C. Schultz and William Adams 
Address: Washington, DC 20375-5337, U.S.A.  
Affiliation: Navy Center for Applied Research in Artificial Intelligence Naval Research Laboratory  
Abstract: Evidence grids provide a uniform representation for fusing temporally and spatially distinct sensor readings. However, the use of evidence grids requires that the robot be localized within its environment. Odome-try errors typically accumulate over time, making localization estimates degrade, and introducing significant errors into evidence grids as they are built. We have addressed this problem by developing a method for "continuous localization", in which the robot corrects its localization estimates incrementally and on the fly. Assuming the mobile robot has a map of its environment represented as an evidence grid, localization is achieved by building a series of "local perception grids" based on localized sensor readings and the current odometry, and then registering the local and global grids. The registration produces an offset which is used to correct the odometry. Results are given on the effectiveness of this method, and quantify the improvement of continuous localization over dead reckoning. We also compare different techniques for matching evidence grids and for searching registration offsets. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bauer, R., </author> <title> "Active manoeuvres for supporting the localisation process of an autonomous mobile robot," </title> <booktitle> Robotics and Autonomous Systems 16: </booktitle> <publisher> Elsevier, </publisher> <pages> pp 39-46, </pages> <year> 1995. </year>
Reference-contexts: Using specific landmarks often requires the robot to perform special maneuvers in order to locate or recognize these landmarks <ref> [1] </ref>. In our work, such maneuvers are unnecessary.
Reference: [2] <author> Chenavier, F. and Crowley, J., </author> <title> "Position estimation for a mobile robot using vision and odom-etry," </title> <booktitle> proc. IEEE Int. Conf. on Robotics and Automation, Nice, France: IEEE, </booktitle> <pages> pp 2588-2592, </pages> <year> 1992. </year>
Reference-contexts: Many localization techniques rely on structures in the environment that can serve as landmarks, for example, vertical structures such as door posts and poles <ref> [2] </ref>, large planes [5], or other geometric beacons [6]. Using specific landmarks often requires the robot to perform special maneuvers in order to locate or recognize these landmarks [1]. In our work, such maneuvers are unnecessary.
Reference: [3] <author> Elfes, A. E., </author> <title> "Multi-source spatial data fusion using bayesian reasoning," </title> <booktitle> Data Fusion in Robotics and Machine Intelligence, </booktitle> <editor> (eds. M. A. Abidi and R. C. Gonzalez), </editor> <publisher> Academic Press, </publisher> <pages> pp 137-163, </pages> <year> 1992. </year>
Reference-contexts: A wide variety of representations and sensors have been used, but in most cases, the data has come from a single sensor type, such as stereo optic vision. In this work, an evidence grid representation has been used <ref> [3, 8, 9] </ref>. Evidence grids provide a uniform representation for fusing temporally and spatially distinct sensor readings. All robot sensors can contribute to the task of localization, and the system is robust in the face of sensor failures and noise in individual sensor readings. <p> After each sensor reading, all relevant cells are updated using the new evidence from the sensor. Several techniques have been used to update the evidence in the evidence grid representation including Bayesian techniques <ref> [8, 3] </ref>, and Dempster-Shafer techniques [9]. In the work reported here, Bayesian updating is used. Although evidence grids may represent a three-dimensional space, our initial results examine a single horizontal layer of the evidence grid that is located at the height of the sensors.
Reference: [4] <author> Graves, K., Adams, W., and Schultz, A., </author> <title> "Continuous Localization in Changing Environments," </title> <booktitle> proc. of the IEEE Int. Symp. on Computational Intelligence in Robotics and Automation, IEEE, </booktitle> <address> Monterey, CA, </address> <month> July, </month> <year> 1997. </year>
Reference-contexts: Initial results indicate that the long-term map can be adaptive to changing environments, and still allow CL to work well <ref> [4] </ref>. A second problem occurs when there is a sudden large change in the robot's odometry, such as a hard collision that allows the wheels to slip.
Reference: [5] <author> Horn, J. and Schmidt, M., </author> <title> "Continuous localization of a mobile robot based on 3D-laser-range-data, predicted sensor images, </title> <booktitle> and dead-reckoning," Robotics and Autonomous Systems 14: </booktitle> <publisher> Elsevier, </publisher> <pages> pp 99-118, </pages> <year> 1995. </year>
Reference-contexts: Many localization techniques rely on structures in the environment that can serve as landmarks, for example, vertical structures such as door posts and poles [2], large planes <ref> [5] </ref>, or other geometric beacons [6]. Using specific landmarks often requires the robot to perform special maneuvers in order to locate or recognize these landmarks [1]. In our work, such maneuvers are unnecessary.
Reference: [6] <author> Leonard, J., Durrant-Whyte, H., and Cox, I., </author> <title> "Dynamic map building for an Autonomous Mobile Robot," </title> <journal> The International Journal of Robotics Research 11: IEEE, </journal> <pages> pp 286-298 ,1992. </pages>
Reference-contexts: Many localization techniques rely on structures in the environment that can serve as landmarks, for example, vertical structures such as door posts and poles [2], large planes [5], or other geometric beacons <ref> [6] </ref>. Using specific landmarks often requires the robot to perform special maneuvers in order to locate or recognize these landmarks [1]. In our work, such maneuvers are unnecessary.
Reference: [7] <author> Lu, F., and Milios, E., </author> <title> "Robot pose estimation in unknown environments by matching 2-D Range scans," </title> <booktitle> proc. IEEE Computer Vision and Pattern Recognition, </booktitle> <address> Seattle: </address> <publisher> IEEE, </publisher> <pages> pp 935-938, </pages> <year> 1994. </year>
Reference-contexts: In that study, evidence grids are created for each specific "place" along the robots path. When the robot revisited a specific place, it created a new evidence grid to match against the evidence grid for that location to correct its position. An alternate search method by Lu <ref> [7] </ref> looks promising although it is intended for free-form scans without the use of evidence grids, and the effect of using it on functions compared the artificially rasterized data of evidence grids is an open question.
Reference: [8] <author> Moravec, H. P., </author> <title> "Sensor fusion in evidence grids for mobile robots," </title> <journal> AI Magazine, </journal> <pages> pp 61-74, </pages> <year> 1988. </year>
Reference-contexts: A wide variety of representations and sensors have been used, but in most cases, the data has come from a single sensor type, such as stereo optic vision. In this work, an evidence grid representation has been used <ref> [3, 8, 9] </ref>. Evidence grids provide a uniform representation for fusing temporally and spatially distinct sensor readings. All robot sensors can contribute to the task of localization, and the system is robust in the face of sensor failures and noise in individual sensor readings. <p> After each sensor reading, all relevant cells are updated using the new evidence from the sensor. Several techniques have been used to update the evidence in the evidence grid representation including Bayesian techniques <ref> [8, 3] </ref>, and Dempster-Shafer techniques [9]. In the work reported here, Bayesian updating is used. Although evidence grids may represent a three-dimensional space, our initial results examine a single horizontal layer of the evidence grid that is located at the height of the sensors. <p> Since the sonars are more likely to detect an object near its axis, cells closer to the sensor's axis receive larger adjustments than cells far from the axis. More information on the sonar sensor model is available in <ref> [8] </ref>. The sensor model for the structured light range finder provides strong evidence at the cell where the range datum lies, but makes no adjustment to any intermediate cells.
Reference: [9] <author> Hughes, K., and Murphy, </author> <title> R.R., "Ultrasonic Robot Localization using Dempster-Shafer Theory", </title> <booktitle> SPIE Stochastic Methods in Signal Processing, Image Processing, and Computer Vision, invited session on Applications for Vision and Robotics, </booktitle> <address> San Diego, CA, </address> <month> July 19-24, </month> <year> 1992. </year>
Reference-contexts: A wide variety of representations and sensors have been used, but in most cases, the data has come from a single sensor type, such as stereo optic vision. In this work, an evidence grid representation has been used <ref> [3, 8, 9] </ref>. Evidence grids provide a uniform representation for fusing temporally and spatially distinct sensor readings. All robot sensors can contribute to the task of localization, and the system is robust in the face of sensor failures and noise in individual sensor readings. <p> After each sensor reading, all relevant cells are updated using the new evidence from the sensor. Several techniques have been used to update the evidence in the evidence grid representation including Bayesian techniques [8, 3], and Dempster-Shafer techniques <ref> [9] </ref>. In the work reported here, Bayesian updating is used. Although evidence grids may represent a three-dimensional space, our initial results examine a single horizontal layer of the evidence grid that is located at the height of the sensors. <p> We believe that the CL method will be robust to the underlying grid representation. We will demonstrate the CL method using a Dempster-Shafer version of evidence grids <ref> [9] </ref>. Continuing work also includes the integration of CL with frontier-based exploration [12] in order to map the room while remaining localized, eliminating the a priori map requirement and providing an accurate, learned long-term map.
Reference: [10] <author> Schiele, B., Crowley, J., </author> <title> "A comparison of position estimation techniques using occupancy grids," </title> <booktitle> Robotics and Autonomous Systems 12: </booktitle> <publisher> Elsevier, </publisher> <pages> pp 163-171, </pages> <year> 1994. </year>
Reference-contexts: In an approach similar to that presented here, Schiele and Crowley <ref> [10] </ref> compared grid matching to other localization methods that included detecting and matching edge segments in the evidence grids. Their work did not give quantitative results on matching evidence grids, nor did it examine various methods for matching or searching for poses.
Reference: [11] <author> Yamauchi, B., </author> <title> "Mobile robot localization in dynamic environments using dead reckoning and evidence grids," </title> <booktitle> proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> New York, NY: </address> <publisher> IEEE, </publisher> <pages> pp 1401-1406, </pages> <year> 1996. </year>
Reference-contexts: Interpolation's smoothing of the search space appears unnecessary when used with the center-of-mass search, which performs its own smoothing during the averaging process inherent to it. Since interpolation incurs additional computational cost without providing any additional benefit, the CP combination was selected for future work. 6 Related work In <ref> [11] </ref>, Yamauchi uses evidence grids to perform occasional localization by matching evidence grids. In that study, evidence grids are created for each specific "place" along the robots path.
Reference: [12] <author> Yamauchi, B., Schultz, A., and Adams, W., </author> <title> "Mobile Robot Exploration and Map-Building with Continuous Localization," </title> <booktitle> proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> Leuven, Belgium: </address> <publisher> IEEE, </publisher> <year> 1998. </year>
Reference-contexts: We also compare different techniques for matching evidence grids and for searching for registration offsets. In Section 2, we briefly describe our representation for long-term and short-term perception maps, and 1 Current work is examining how to simultaneously learn maps while using them to stay localized <ref> [12] </ref>. describe how these maps may be registered. In Sec--tion 3, the method for CL is described. The robotic platform used in our experiments is presented in Section 4. We give the results of several experiments that demonstrate the technique's ability in Section 5. <p> We believe that the CL method will be robust to the underlying grid representation. We will demonstrate the CL method using a Dempster-Shafer version of evidence grids [9]. Continuing work also includes the integration of CL with frontier-based exploration <ref> [12] </ref> in order to map the room while remaining localized, eliminating the a priori map requirement and providing an accurate, learned long-term map. Initial results indicate that accurate maps of the room can be simultaneously learned and used for continuous localization.
References-found: 12

