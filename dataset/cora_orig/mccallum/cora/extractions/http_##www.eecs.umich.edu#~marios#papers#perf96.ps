URL: http://www.eecs.umich.edu/~marios/papers/perf96.ps
Refering-URL: http://www.eecs.umich.edu/~marios/pubs.html
Root-URL: http://www.cs.umich.edu
Email: mss@watson.ibm.com  fwang-fang,papaefthymiou-mariosg@cs.yale.edu  
Title: Stochastic Analysis of Gang Scheduling in Parallel and Distributed Systems  
Author: Mark S. Squillante a Fang Wang b and Marios Papaefthymiou b 
Address: Yorktown Heights, NY 10598, USA  New Haven, CT 06520, USA  
Affiliation: a IBM Thomas J. Watson Research Center,  b Computer Science Department, Yale University,  
Abstract: Gang scheduling is an approach for resource allocation in parallel and distributed systems that combines time-sharing with space-sharing to ensure a short response time for interactive tasks and high overall system throughput. In this paper, we present queueing theoretic models for a particular gang scheduling system under a workload representative of large-scale engineering and scientific computing environments. We derive a detailed mathematical analysis of these models, from which we obtain closed-form expressions for different performance measures of interest. Our model and analysis is then used to analyze several fundamental performance tradeoffs associated with gang scheduling. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: Stability The irreducibility of the Markov process fX p (t) ; t 0g can be verified for any specific instance of our model by determining whether the first P=g p + 2 levels of the state space (the boundary plus the first level of the repeating portion) are strongly connected <ref> [1] </ref>.
Reference: [2] <author> S. Asmussen, O. Nerman, and M. Olsson. </author> <title> Fitting phase type distributions via the EM algorithm. </title> <type> Technical Report 1994:23, </type> <institution> Department of Mathematics, Chalmers University of Technology, </institution> <month> May </month> <year> 1994. </year>
Reference: [3] <author> S.-H. Chiang, R. K. Mansharamani, and M. K. Vernon. </author> <title> Use of application characteristics and limited preemption for run-to-completion parallel processor scheduling policies. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 33-44, </pages> <month> May </month> <year> 1994. </year>
Reference: [4] <author> V. D. Cung et al. </author> <title> Concurrent data structures and load balancing strategies for parallel branch-and-bound/A* algorithms. </title> <booktitle> In The Third DIMACS International Algorithm Implementation Challenge on Parallel Algorithms, </booktitle> <month> October </month> <year> 1994. </year> <month> 27 </month>
Reference: [5] <author> E. de Souza e Silva, H. R. Gail, and R. R. Muntz. </author> <title> Polling systems with server timeouts and their application to token passing networks. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 3(5) </volume> <pages> 560-575, </pages> <month> October </month> <year> 1995. </year>
Reference: [6] <author> K. Dussa, B. Carlson, L. Dowdy, and K.-H. Park. </author> <title> Dynamic partitioning in transputer environments. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 203-213, </pages> <year> 1990. </year>
Reference: [7] <author> M. J. Faddy. </author> <title> Fitting structured phase-type distributions. </title> <type> Technical report, </type> <institution> Department of Mathematics, University of Queensland, Australia, </institution> <month> April </month> <year> 1994. </year> <title> To appear, Applied Stochastic Models and Data Analysis. </title>
Reference: [8] <author> D. G. Feitelson and B. Nitzberg. </author> <title> Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/860. In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 337-360. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference: [9] <author> D. G. Feitelson and L. Rudolph. </author> <title> Distributed hierarchical control for parallel processing. </title> <booktitle> Computer, </booktitle> <pages> pages 65-77, </pages> <month> May </month> <year> 1990. </year>
Reference: [10] <author> D. G. Feitelson and L. Rudolph. </author> <title> Mapping and scheduling in a shared parallel environment using distributed hierarchical control. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <volume> volume I, </volume> <pages> pages 1-8, </pages> <month> August </month> <year> 1990. </year>
Reference: [11] <author> D. G. Feitelson and L. Rudolph. </author> <title> Gang scheduling performance benefits for fine-grain synchronization. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16(4) </volume> <pages> 306-318, </pages> <month> December </month> <year> 1992. </year>
Reference: [12] <author> H. Franke, P. Pattnaik, and L. Rudolph. </author> <title> Gang scheduling for highly efficient distributed multiprocessor systems. </title> <type> Technical report, </type> <institution> IBM Research Division, </institution> <month> March </month> <year> 1996. </year> <note> To appear, Proceedings of Frontiers'96. </note>
Reference: [13] <author> F. R. Gantmacher. </author> <title> The Theory of Matrices. </title> <publisher> Chelsea, </publisher> <year> 1959. </year>
Reference-contexts: Since the non-diagonal elements of a generator matrix are non-negative and the diagonal element of each row is the negative sum of the non-diagonal elements on that row <ref> [13] </ref>, we have Se + S = 0.
Reference: [14] <author> D. Ghosal, G. Serazzi, and S. K. Tripathi. </author> <title> The processor working set and its use in scheduling multiprocessor systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17 </volume> <pages> 443-453, </pages> <month> May </month> <year> 1991. </year>
Reference: [15] <author> A. Gupta, A. Tucker, and S. Urushibara. </author> <title> The impact of operating system scheduling policies and synchronization methods on the performance of parallel applications. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 120-132, </pages> <month> May </month> <year> 1991. </year>
Reference: [16] <author> S. G. Hotovy. </author> <title> Workload evolution on the Cornell Theory Center IBM SP2. </title> <booktitle> In Proceedings of the 2nd Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 15-22, </pages> <month> April </month> <year> 1996. </year>
Reference: [17] <author> S. G. Hotovy, D. J. Schneider, and T. O'Donnell. </author> <title> Analysis of the early workload on the Cornell Theory Center IBM SP2. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 272-273, </pages> <month> May </month> <year> 1996. </year> <month> 28 </month>
Reference: [18] <author> N. Islam, A. Prodromidis, and M. S. Squillante. </author> <title> Dynamic partitioning in different distributed-memory environments. </title> <booktitle> In Proceedings of the 2nd Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 155-170, </pages> <month> April </month> <year> 1996. </year>
Reference: [19] <author> N. Islam, A. Prodromidis, M. S. Squillante, A. S. Gopal, and L. L. Fong. </author> <title> Extensible resource management for cluster computing. </title> <type> Technical report, </type> <institution> IBM Research Division, </institution> <month> May </month> <year> 1996. </year>
Reference: [20] <author> L. Kleinrock. </author> <title> Queueing Systems Volume I: Theory. </title> <publisher> John Wiley and Sons, </publisher> <year> 1975. </year>
Reference-contexts: Multiple job arrivals, multiple job departures, and both an arrival and a departure within a small time interval t are all assumed to occur with probability of order o (t) <ref> [20] </ref>.
Reference: [21] <author> L. Kleinrock. </author> <title> Queueing Systems Volume II: Computer Applications. </title> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference-contexts: This, possibly coupled with multi-level feedback queues [44], has proven to be a reasonable approximation of shortest-job-first in sequential systems, which is known to minimize mean response time for these environments <ref> [21] </ref>. In parallel environments, however, there are situations in which jobs may not need all of the available resources in the system. It has been argued, for example, that performance does not increase as the number of processors dedicated to a job increases beyond a certain limit [4,22].
Reference: [22] <author> A. Krishnamurthy et al. </author> <title> Connected components on distributed memory machines. </title> <booktitle> In The Third DIMACS International Algorithm Implementation Challenge on Parallel Algorithms, </booktitle> <month> October </month> <year> 1994. </year>
Reference: [23] <author> A. Lang. </author> <title> Parameter estimation for phase-type distributions, part I: Fundamentals and existing methods. </title> <type> Technical Report 159, </type> <institution> Department of Statistics, Oregon State University, </institution> <year> 1994. </year>
Reference: [24] <author> A. Lang and J. L. Arthur. </author> <title> Parameter estimation for phase-type distributions, part II: Computational evaluation. </title> <type> Technical Report 160, </type> <institution> Department of Statistics, Oregon State University, </institution> <month> August </month> <year> 1994. </year>
Reference: [25] <author> S. T. Leutenegger and M. K. Vernon. </author> <title> The performance of multiprogrammed multiprocessor scheduling policies. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 226-236, </pages> <month> May </month> <year> 1990. </year>
Reference: [26] <author> J. D. C. Little. </author> <title> A proof of the queuing formula L = W . Operations Research, </title> <booktitle> 9 </booktitle> <pages> 383-387, </pages> <year> 1961. </year>
Reference-contexts: p +k e: Using (14) and the condition sp (R p ) &lt; 1, we can rewrite this equation in closed form as N p = k=1 (p) (p) 1 (p) 2 The expected response time for class p, denoted by T p , can be calculated using Little's result <ref> [26] </ref> and (27).
Reference: [27] <author> C. McCann, R. Vaswani, and J. Zahorjan. </author> <title> A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(2) </volume> <pages> 146-178, </pages> <month> May </month> <year> 1993. </year>
Reference: [28] <author> V. K. Naik, S. K. Setia, and M. S. Squillante. </author> <title> Performance analysis of job scheduling policies in parallel supercomputing environments. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 824-833, </pages> <month> November </month> <year> 1993. </year>
Reference: [29] <author> V. K. Naik, S. K. Setia, and M. S. Squillante. </author> <title> Scheduling of large scientific applications on distributed memory multiprocessor systems. </title> <booktitle> In Proceedings Sixth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 913-922, </pages> <month> March </month> <year> 1993. </year>
Reference: [30] <author> V. K. Naik, S. K. Setia, and M. S. Squillante. </author> <title> Processor allocation in multiprogrammed, distributed-memory parallel computer systems. </title> <type> Technical Report RC 20239, </type> <institution> IBM Research Division, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: The job arrival rates are chosen to satisfy 0 + 1 : 2 : 3 = 100 : 10 : 1 as in <ref> [30] </ref>, where we use 1 = (7=8) 0 . This is representative of the workloads exhibited in large-scale engineering and scientific computing environments, where the majority of jobs arriving to the system are small jobs, but most processor cycles are consumed by fewer long running applications [8,16,17].
Reference: [31] <author> R. D. Nelson and M. S. Squillante. </author> <title> The MAtrix-Geometric qUeueing model Solution package (MAGUS) user manual. </title> <type> Technical Report RC, </type> <institution> IBM Research Division, </institution> <month> June </month> <year> 1994. </year> <month> 29 </month>
Reference: [32] <author> M. F. Neuts. </author> <title> Matrix-Geometric Solutions in Stochastic Models: An Algorithmic Approach. </title> <publisher> The Johns Hopkins University Press, </publisher> <year> 1981. </year>
Reference-contexts: Multiple job arrivals, multiple job departures, and both an arrival and a departure within a small time interval t are all assumed to occur with probability of order o (t) [20]. Under our parameter distribution assumptions defined in Section 2.3, this will lead to a quasi-birth-death process <ref> [32] </ref>, although our mathematical analysis in Section 3 is easily extended to handle batch arrivals and/or departures as long as the batch sizes are bounded. 5 2.2 Gang Scheduling Policy We consider a particular gang scheduling strategy proposed in the research literature that uses a distributed hierarchical control structure where the <p> Our mathematical analysis also exploits the form of the convolution of two phase-type distributions. In particular, the following basic theorem for the convolution of two phase-type distributions can be easily established <ref> [32] </ref>. <p> In this section we present a mathematical analysis of the model that is based in part on decomposition and leads to an exact solution of matrix-geometric form <ref> [32] </ref>. We first develop our general approach and derive an analysis of the model under certain heavy-traffic assumptions. We then derive an analysis for the non-heavy-traffic regime, as well as some approximations that simplify the numerical computations. <p> We refer to levels 0 through P=g p as the boundary. Given the form in equation (13) for the generator matrix of this Markov process, the components of its invariant probability vector (p) can be obtained exactly via matrix-geometric techniques <ref> [32] </ref>. In particular, the probability vector for the repeating portion can be solved as P=g p +n = P=g p R n where R p is the minimal non-negative matrix that satisfies R 2 (p) (p) (p) having spectral radius (i.e., maximum eigenvalue) sp (R p ) &lt; 1. <p> In general, the matrix R p is solved numerically using the iteration <ref> [32] </ref> R p (0) = 0 (p) p (n)A 2 A 1 ; n 0; (18) where iterations stop when jR p (n+1)R p (n)j is less than some tolerance. The solution of equations (16) and (17) then can be obtained in an efficient manner via standard numerical methods. <p> probability of each such path and the probability of each class queue length vector can be obtained from the first passage times (and other measures) of the quasi-birth-death processes fX 0 p (t) ; t 0g, fX p (t) ; t 0g and f f X p;n ; n 0g <ref> [32] </ref>, together with the invariant probability vectors (p) , 0 p &lt; L. We then use a fixed-point iteration to solve the Markov process as follows. The distributions F p () are obtained from the conditional distributions constructed above using the L model solutions. <p> The generators A (p) for our parallel system model will be irreducible provided that the phase-type distributions A p , B p , C p and G p have irreducible representations, 0 p &lt; L. Since we can always obtain an irreducible representation of a phase-type distribution <ref> [32] </ref>, the stability conditions for our model are given by equation (26). 3.4 Performance Measures The components of the invariant probability vectors (p) , 0 p &lt; L, com pletely characterize the behavior of the system, and we can directly obtain performance measures of interest for each job class from these
Reference: [33] <author> J. K. Ousterhout. </author> <title> Scheduling techniques for concurrent systems. </title> <booktitle> In Proceedings of the Third International Conference on Distributed Computing Systems, </booktitle> <pages> pages 22-30, </pages> <month> October </month> <year> 1982. </year>
Reference: [34] <author> V. G. Peris, M. S. Squillante, and V. K. Naik. </author> <title> Analysis of the impact of memory in distributed parallel processing systems. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 5-18, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: This issue was first studied in <ref> [34] </ref> where it was shown that when such paging activity occurs, for large multigrid-based applications, the resulting memory overhead dominates the execution time of the job, and therefore the number of processors allocated to each job must be greater than this critical point for the job to prevent significant degradation in
Reference: [35] <author> S. M. Ross. </author> <title> Stochastic Processes. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: We also use the technique of uniformization to construct a particular discrete-time version of the original Markov process <ref> [35] </ref>. Consider the generator matrix Q (p) [q (p) i;j ] for the original Markov process fX p (t) ; t 0g, and define q (p) max maxfq (p) i;i g. Note that q (p) i;i is the total instantaneous rate of leaving state i.
Reference: [36] <author> E. Rosti, E. Smirni, L. W. Dowdy, G. Serazzi, and B. M. Carlson. </author> <title> Robust partitioning policies of multiprocessor systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 141-165, </pages> <year> 1994. </year>
Reference: [37] <author> R. Schassberger. </author> <title> Insensitivity of steady-state distributions of generalized semi-Markov processes, part I. </title> <journal> The Annals of Probability, </journal> <volume> 5(1) </volume> <pages> 87-99, </pages> <year> 1977. </year>
Reference: [38] <author> R. Schassberger. </author> <title> Insensitivity of steady-state distributions of generalized semi-Markov processes, part II. </title> <journal> The Annals of Probability, </journal> <volume> 6(1) </volume> <pages> 85-93, </pages> <year> 1978. </year>
Reference: [39] <author> R. Schassberger. </author> <title> Insensitivity of steady-state distributions of generalized semi-Markov process with speeds. </title> <booktitle> Advances in Applied Probability, </booktitle> <volume> 10 </volume> <pages> 836-851, </pages> <year> 1978. </year>
Reference: [40] <author> S. K. Setia. </author> <title> The interaction between memory allocation and adaptive partitioning in message-passing multicomputers. In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 146-164. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: The same conclusion was reached for a different workload in a subsequent study <ref> [40] </ref>.
Reference: [41] <author> S. K. Setia and S. K. Tripathi. </author> <title> A comparative analysis of static processor partitioning policies for parallel computers. </title> <booktitle> In Proceedings of the International Workshop on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS), </booktitle> <pages> pages 283-286, </pages> <month> January </month> <year> 1993. </year>
Reference: [42] <author> K. C. Sevcik. </author> <title> Characterizations of parallelism in applications and their use in scheduling. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 171-180, </pages> <month> May </month> <year> 1989. </year>
Reference: [43] <author> K. C. Sevcik. </author> <title> Application scheduling and processor allocation in multiprogrammed parallel processing systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 107-140, </pages> <year> 1994. </year>
Reference: [44] <author> A. Silberschatz and P. B. Galvin. </author> <title> Operating System Concepts. </title> <publisher> Addison-Wesley, </publisher> <address> Fourth edition, </address> <year> 1994. </year>
Reference-contexts: Time-sharing therefore ensures that all jobs will gain access to the system resources within a relatively short period of time, and it is particularly suitable for tasks with small processing requirements. This, possibly coupled with multi-level feedback queues <ref> [44] </ref>, has proven to be a reasonable approximation of shortest-job-first in sequential systems, which is known to minimize mean response time for these environments [21]. In parallel environments, however, there are situations in which jobs may not need all of the available resources in the system.
Reference: [45] <author> M. S. Squillante. </author> <title> MAGIC: A computer performance modeling tool based on matrix-geometric techniques. </title> <booktitle> In Proceedings of the Fifth International Conference on Modelling Techniques and Tools for Computer Performance Evaluation, </booktitle> <pages> pages 411-425, </pages> <month> February </month> <year> 1991. </year> <month> 30 </month>
Reference: [46] <author> M. S. Squillante. </author> <title> On the benefits and limitations of dynamic partitioning in parallel computer systems. In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 219-238. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference: [47] <author> M. S. Squillante, F. Wang, and M. Papaefthymiou. </author> <title> An analysis of gang scheduling for multiprogrammed parallel computing environments. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 89-98, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: We derive a detailed mathematical analysis of the models, from which we obtain closed-form expressions for different performance measures of this parallel system. The models and analysis presented herein significantly extend our previous, preliminary analysis of gang scheduling <ref> [47] </ref>. This modeling framework is then used to analyze various gang scheduling performance tradeoffs as a function of different system variables, including the workload, the quantum length, the context switching overhead and the system load.
Reference: [48] <author> M. S. Squillante, F. Wang, and M. Papaefthymiou. </author> <title> Stochastic analysis of gang scheduling in parallel and distributed systems. </title> <type> Technical report, </type> <institution> IBM Research Division, </institution> <month> March </month> <year> 1996. </year>
Reference-contexts: In what follows we present a small portion of these results which illustrate some of our findings and are a representative sample of some of the key trends observed. We refer the interested reader to <ref> [48] </ref> for additional results, including consideration of the quanta lengths that minimize convex objective functions of the per-class mean response times for a given timeplexing cycle length, as well as the effects of variance. 4.1 Mean Response Time Comparison We first consider the per-class mean response times of our base case
Reference: [49] <author> H. Takagi. </author> <title> Queueing Analysis A Foundation of Performance Evaluation, volume 1: Vacation and Priority Systems, Part 1. </title> <publisher> North Holland, </publisher> <year> 1991. </year>
Reference: [50] <author> A. Tucker and A. Gupta. </author> <title> Process control and scheduling issues for multiprogrammed shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 159-166, </pages> <month> December </month> <year> 1989. </year>
Reference: [51] <author> J. Walrand. </author> <title> An Introduction to Queueing Networks. </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference: [52] <author> F. Wang, H. Franke, M. Papaefthymiou, P. Pattnaik, L. Rudolph, and M. S. Squillante. </author> <title> A gang scheduling design for multiprogrammed parallel computing environments. </title> <booktitle> In Proceedings of the 2nd Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 67-75, </pages> <month> April </month> <year> 1996. </year>
Reference: [53] <author> J. Zahorjan and C. McCann. </author> <title> Processor scheduling in shared memory multiprocessors. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 214-225, </pages> <month> May </month> <year> 1990. </year> <month> 31 </month>
References-found: 53

