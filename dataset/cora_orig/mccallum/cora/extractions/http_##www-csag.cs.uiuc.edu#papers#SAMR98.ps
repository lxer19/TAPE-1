URL: http://www-csag.cs.uiuc.edu/papers/SAMR98.ps
Refering-URL: http://www-csag.cs.uiuc.edu/papers/index.html
Root-URL: http://www.cs.uiuc.edu
Title: High-Level Parallel Programming of An Adaptive Mesh Application Using the Illinois Concert System  
Author: Bishwaroop Ganguly and Andrew Chien 
Web: ganguly,achien@red-herring.cs.uiuc.edu  
Address: Urbana, Illinois 61801  
Affiliation: Department of Computer Science University of Illinois  
Abstract: We have used the Illinois Concert C++ system (which supports dynamic, object-based parallelism) to parallelize a flexible adaptive mesh refinement code for the Cosmology NSF Grand Challenge. Out goal is to enable programmers of large-scale numerical applications to build complex applications with irregular structure using a high-level interface. The key elements are an aggressive optimizing compiler and runtime system support that harnesses the performance of the SGI-Cray Origin 2000 shared memory architecture. We have developed a configurable runtime system and a flexible Structured Adaptive Mesh Refinement (SAMR) application that runs with good performance. We describe the programming of SAMR using the Illinois Concert System, which is a concurrent object-oriented parallel programming interface, documenting the modest parallelization effort. We obtain good performance of up to 24.4 speedup on 32 processors of the Origin 2000. We also present results addressing the effect of virtual machine configuration and parallel grain size on performance. Our study characterizes the SAMR application and how our programming system design assists in parallelizing dynamic codes using high-level programming.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Gul Agha. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The Illinois Concert System is a programming environment that harnesses the benefits of COOP, with a goal of high performance. It consists of the ICC++ language [12], Concert compiler [4, 15, 3] and the Concert runtime system [9]. Concert supports fine-grained, concurrent object-oriented programming on Actors <ref> [1] </ref>. Computation is expressed as method invocations on objects or collections of objects. Concurrent method invocations operate against state stored in dynamically created thread data structures.
Reference: 2. <author> Greg L. Bryan. </author> <title> The Numerical Simulation of X-ray Clusters. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: Our runtime system allows programs to utilize varying degrees of shared memory support. To demonstrate our technology, we have parallelized a large-scale SAMR application, a numerical simulation method being used for the NSF Cosmology Grand Challenge <ref> [2] </ref>. SAMR is a technique for simulating a discrete model of space. It works by solving hyperbolic partial differential equations numerically through a series of discrete timesteps. SAMR methods recognize that a large portion of this modeling area is often empty and/or constant throughout the simulation. <p> SAMR uses a dynamic hierarchy of meshes, only creating high-resolution meshes where heuristics deem that they are needed. This approach saves computation while still providing high resolution modeling. SAMR has been successfully applied to a number of important problems <ref> [2] </ref>, and is gaining acceptance in the realm of scientific computation. Programming SAMR is more complex than single or multi-grid simulations, and this has prevented it from becoming more widely used. <p> It has been used in a number of cosmology experiments <ref> [2] </ref>. It is written in C++ and uses Fortran 77 kernels to perform the compute-intensive interpolation and partial differential equation solves. 3.1 Code Structure The code is structured as a series of phases. Each phase is either an inter-mesh communication phase or is mesh independent. <p> All experiments were run on the NCSA Origin 2000, on configurations of up to 32 processors with 12Gb of total physical memory running IRIX version 6.4. The input data set for our experiments is a two-dimensional ShockTube simulation <ref> [2] </ref>. This test case can be run either adaptively, or as a non-adaptive, single-mesh simulation. Size of the input data set is roughly governed by the size of the top-level mesh in the hierarchy, which is specified as a program parameter.
Reference: 3. <author> Andrew Chien, Julian Dolby, Bishwaroop Ganguly, Vijay Karamcheti, and Xingbin Zhang. </author> <title> Supporting high level programming with high performance: The Illinois Concert system. </title> <booktitle> In Proceedings of the Second International Workshop on High-level Parallel Programming Models and Supportive Environments, </booktitle> <pages> pages 15-24, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Therefore, the parallelism across meshes is dynamic, and is not analyzable during compilation or even initialization of the program. SAMR's dynamic parallelism must be exploited during the run of the program, making parallelization of the method a challenge. The Illinois Concert System <ref> [3] </ref> and ICC++ language [13, 12] together form a parallel programming environment geared towards tackling dynamically parallel codes. This system provides a variety of support for dynamic parallelism and distributed parallel data structures a global namespace, efficient fine-grained threads, orthogonal data distribution, and high performance runtime primitives. <p> The Illinois Concert System is a programming environment that harnesses the benefits of COOP, with a goal of high performance. It consists of the ICC++ language [12], Concert compiler <ref> [4, 15, 3] </ref> and the Concert runtime system [9]. Concert supports fine-grained, concurrent object-oriented programming on Actors [1]. Computation is expressed as method invocations on objects or collections of objects. Concurrent method invocations operate against state stored in dynamically created thread data structures. <p> Implicit dynamic thread creation frees programmers from explicit thread and synchronization management. Object-level concurrency control maintains sequential consistency of the object state in the global names-pace, freeing the programmer from managing explicit locking. The Concert system implementation <ref> [3, 4, 15, 12, 8] </ref> is a state-of-the-art implementation of a COOP programming model. A full discussion of the Concert runtime system can be found in [8]. The Concert compiler [12] implements a number of aggressive, inter-procedural optimizations that achieve high performance for sequential object-oriented codes.
Reference: 4. <author> Julian Dolby. </author> <title> Automatic inline allocation of objects. </title> <booktitle> In Proceedings of the 1997 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 7-17, </pages> <address> Las Vegas, Nevada, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: The Illinois Concert System is a programming environment that harnesses the benefits of COOP, with a goal of high performance. It consists of the ICC++ language [12], Concert compiler <ref> [4, 15, 3] </ref> and the Concert runtime system [9]. Concert supports fine-grained, concurrent object-oriented programming on Actors [1]. Computation is expressed as method invocations on objects or collections of objects. Concurrent method invocations operate against state stored in dynamically created thread data structures. <p> Implicit dynamic thread creation frees programmers from explicit thread and synchronization management. Object-level concurrency control maintains sequential consistency of the object state in the global names-pace, freeing the programmer from managing explicit locking. The Concert system implementation <ref> [3, 4, 15, 12, 8] </ref> is a state-of-the-art implementation of a COOP programming model. A full discussion of the Concert runtime system can be found in [8]. The Concert compiler [12] implements a number of aggressive, inter-procedural optimizations that achieve high performance for sequential object-oriented codes.
Reference: 5. <author> High Performance Fortran Forum. </author> <title> High performance Fortran language specification version 1.0. </title> <type> Technical Report CRPC-TR92225, </type> <institution> Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: This is not a good match for the SAMR method, which creates an entirely new hierarchy of possibly hundreds of new grids at every iteration. Compiler-based approaches such as HPF <ref> [5] </ref> need compile-time knowledge to load balance such an application, and are usually unable to glean such information through analysis. We have also explored the use of thread-based shared memory to parallelize the code.
Reference: 6. <author> Bishwaroop Ganguly. </author> <title> Concurrent object-oriented programming on large-scaled shared memory: A structured adaptive mesh refinement method in icc++. </title> <type> Master's thesis, </type> <institution> The University of Illinois at Urbana-Champaign, Urbana, Illinois, </institution> <month> December </month> <year> 1997. </year>
Reference-contexts: Size of the input data set is roughly governed by the size of the top-level mesh in the hierarchy, which is specified as a program parameter. For a complete description of test cases and a full set of results, see <ref> [6] </ref>. We benchmarked the ICC++ code against the C++ compiled using the SGI CC compiler with full (-O3) optimization and found the ICC++ code with parallel annotations to be no more than 15% slower. These results validate par-allelization of the code. <p> This last result tells us that we have ample parallelism for up to 32 processors, even for the largest tile size shown here. Our experiments show that speedup of the tile-to-tile communication phases are the poorest, and tend to limit overall parallel efficiency. See <ref> [6] </ref> for more details. We do achieve high overall performance, with a high percentage of feasible speedup.
Reference: 7. <author> William D. Henshaw. </author> <title> A Primer for Writing PDE Solvers with Overture. </title> <institution> La-ur-96-3894, Los Alamos National Laboratory, </institution> <address> Los Alamos, NM, </address> <month> December </month> <year> 1997. </year>
Reference-contexts: This factor would presumably be higher if less efficient messaging primitives were used. 6 Related Work 6.1 Overture The Overture project <ref> [7] </ref> at Los Alamos National Laboratory is also a framework for writing parallel SAMR methods. It is built atop the A++/P++ [11] parallel array class library. Overture is a library of C++ classes designed to represent grids and grid functions.
Reference: 8. <author> Vijay Karamcheti. </author> <title> Run-Time Techniques for Dynamic Multithreaded Computations. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, Urbana, Illinois, </institution> <year> 1998. </year>
Reference-contexts: Implicit dynamic thread creation frees programmers from explicit thread and synchronization management. Object-level concurrency control maintains sequential consistency of the object state in the global names-pace, freeing the programmer from managing explicit locking. The Concert system implementation <ref> [3, 4, 15, 12, 8] </ref> is a state-of-the-art implementation of a COOP programming model. A full discussion of the Concert runtime system can be found in [8]. The Concert compiler [12] implements a number of aggressive, inter-procedural optimizations that achieve high performance for sequential object-oriented codes. <p> The Concert system implementation [3, 4, 15, 12, 8] is a state-of-the-art implementation of a COOP programming model. A full discussion of the Concert runtime system can be found in <ref> [8] </ref>. The Concert compiler [12] implements a number of aggressive, inter-procedural optimizations that achieve high performance for sequential object-oriented codes. An implementation of Fast Messages [8] is used for low-overhead communication between address spaces. 2.2 SAMR Methods Adaptive mesh methods are a class of finite difference method that provide high modeling <p> A full discussion of the Concert runtime system can be found in <ref> [8] </ref>. The Concert compiler [12] implements a number of aggressive, inter-procedural optimizations that achieve high performance for sequential object-oriented codes. An implementation of Fast Messages [8] is used for low-overhead communication between address spaces. 2.2 SAMR Methods Adaptive mesh methods are a class of finite difference method that provide high modeling resolution and computational efficiency by generating a hierarchy of grids, comprised of a series of levels. <p> The Concert runtime logically distributes the underlying memory into address spaces over which a programs objects are distributed for concurrent execution. The address spaces contain each contain heavyweight threads (e.g. Unix processes) to execute lightweight logical Concert threads. A full description of the system can be found in <ref> [8] </ref>. We have developed a configurable version of this system for the shared memory architecture. 4.2 Runtime Configuration Fig. 1. Runtime Configurations 7 The Concert runtime implementation on the shared memory SGI-Cray Origin 2000 machine is architected to take advantage of the hardware shared memory support.
Reference: 9. <author> Vijay Karamcheti, John Plevyak, and Andrew A. Chien. </author> <title> Runtime mechanisms for efficient dynamic multithreading. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37(1) </volume> <pages> 21-40, </pages> <year> 1996. </year> <note> Available from http://www-csag.cs.uiuc.edu/papers/ rtperf.ps. 13 </note>
Reference-contexts: The Illinois Concert System is a programming environment that harnesses the benefits of COOP, with a goal of high performance. It consists of the ICC++ language [12], Concert compiler [4, 15, 3] and the Concert runtime system <ref> [9] </ref>. Concert supports fine-grained, concurrent object-oriented programming on Actors [1]. Computation is expressed as method invocations on objects or collections of objects. Concurrent method invocations operate against state stored in dynamically created thread data structures.
Reference: 10. <author> S.R. Kohn and S.B. Baden. </author> <title> Irregular coarse-grain data parallelism under lparx. </title> <journal> Scientific Programming, </journal> <volume> 5(3), </volume> <month> Fall </month> <year> 1996. </year>
Reference-contexts: These classes can be instantiated to form a SAMR implementation with a rich set of operations for dealing with different hierarchy topologies and boundary conditions. As Overture is a domain-specific framework, it is restricted to grid-based simulations. 6.2 LPARX The LPARX <ref> [10] </ref> parallel system is designed to address the problem of block irregular mesh methods and the problems they present. The system is designed to parallelize methods such as SAMR efficiently, using a collaboration of user and runtime support.
Reference: 11. <author> R. Parsons and D. Quinlan. </author> <title> A++/P++ array classes for architecture independent finite difference computations. </title> <booktitle> In Proceedings of the Second Annual Object-Oriented Numerics Conference, </booktitle> <pages> pages 408-418, </pages> <address> Sunriver, Oregon, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: This factor would presumably be higher if less efficient messaging primitives were used. 6 Related Work 6.1 Overture The Overture project [7] at Los Alamos National Laboratory is also a framework for writing parallel SAMR methods. It is built atop the A++/P++ <ref> [11] </ref> parallel array class library. Overture is a library of C++ classes designed to represent grids and grid functions. These classes can be instantiated to form a SAMR implementation with a rich set of operations for dealing with different hierarchy topologies and boundary conditions.
Reference: 12. <author> John Plevyak. </author> <title> Optimization of Object-Oriented and Concurrent Programs. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, Urbana, Illinois, </institution> <year> 1996. </year>
Reference-contexts: Therefore, the parallelism across meshes is dynamic, and is not analyzable during compilation or even initialization of the program. SAMR's dynamic parallelism must be exploited during the run of the program, making parallelization of the method a challenge. The Illinois Concert System [3] and ICC++ language <ref> [13, 12] </ref> together form a parallel programming environment geared towards tackling dynamically parallel codes. This system provides a variety of support for dynamic parallelism and distributed parallel data structures a global namespace, efficient fine-grained threads, orthogonal data distribution, and high performance runtime primitives. <p> The Illinois Concert System is a programming environment that harnesses the benefits of COOP, with a goal of high performance. It consists of the ICC++ language <ref> [12] </ref>, Concert compiler [4, 15, 3] and the Concert runtime system [9]. Concert supports fine-grained, concurrent object-oriented programming on Actors [1]. Computation is expressed as method invocations on objects or collections of objects. Concurrent method invocations operate against state stored in dynamically created thread data structures. <p> Implicit dynamic thread creation frees programmers from explicit thread and synchronization management. Object-level concurrency control maintains sequential consistency of the object state in the global names-pace, freeing the programmer from managing explicit locking. The Concert system implementation <ref> [3, 4, 15, 12, 8] </ref> is a state-of-the-art implementation of a COOP programming model. A full discussion of the Concert runtime system can be found in [8]. The Concert compiler [12] implements a number of aggressive, inter-procedural optimizations that achieve high performance for sequential object-oriented codes. <p> The Concert system implementation [3, 4, 15, 12, 8] is a state-of-the-art implementation of a COOP programming model. A full discussion of the Concert runtime system can be found in [8]. The Concert compiler <ref> [12] </ref> implements a number of aggressive, inter-procedural optimizations that achieve high performance for sequential object-oriented codes.
Reference: 13. <author> John Plevyak, Xingbin Zhang, and Andrew A. Chien. </author> <title> Obtaining sequential efficiency in concurrent object-oriented programs. </title> <booktitle> In Proceedings of the ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 311-321, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Therefore, the parallelism across meshes is dynamic, and is not analyzable during compilation or even initialization of the program. SAMR's dynamic parallelism must be exploited during the run of the program, making parallelization of the method a challenge. The Illinois Concert System [3] and ICC++ language <ref> [13, 12] </ref> together form a parallel programming environment geared towards tackling dynamically parallel codes. This system provides a variety of support for dynamic parallelism and distributed parallel data structures a global namespace, efficient fine-grained threads, orthogonal data distribution, and high performance runtime primitives.
Reference: 14. <author> Silicon Graphics, Inc., </author> <title> Mountain View, CA. Origin Servers: Technical Overview of the Origin Family, </title> <note> 1996. http://www.sgi.com/Products/hardware/servers/ technology/overview.html. </note>
Reference-contexts: Our performance results show that a modest parallel grain size of 50x50 tiled meshes is best to provide ample parallelism, and minimize overhead of concurrent execution. We achieve up to 24.4 times speedup on a 32 processor Origin 2000 <ref> [14] </ref> using maximum shared memory support for communication, which is 93% of maximum feasible speedup for our application. In addition, we achieve 11.7 times speedup on 16 processors for our application by relying heavily on our high-performance messaging support and simple additional techniques.
Reference: 15. <author> Xingbin Zhang and Andrew A. Chien. </author> <title> Dynamic pointer alignment: Tiling and communication optimizations for parallel pointer-based computations. </title> <booktitle> In Proceedings of ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 37-47, </pages> <address> Las Vegas, Nevada, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: The Illinois Concert System is a programming environment that harnesses the benefits of COOP, with a goal of high performance. It consists of the ICC++ language [12], Concert compiler <ref> [4, 15, 3] </ref> and the Concert runtime system [9]. Concert supports fine-grained, concurrent object-oriented programming on Actors [1]. Computation is expressed as method invocations on objects or collections of objects. Concurrent method invocations operate against state stored in dynamically created thread data structures. <p> Implicit dynamic thread creation frees programmers from explicit thread and synchronization management. Object-level concurrency control maintains sequential consistency of the object state in the global names-pace, freeing the programmer from managing explicit locking. The Concert system implementation <ref> [3, 4, 15, 12, 8] </ref> is a state-of-the-art implementation of a COOP programming model. A full discussion of the Concert runtime system can be found in [8]. The Concert compiler [12] implements a number of aggressive, inter-procedural optimizations that achieve high performance for sequential object-oriented codes.
References-found: 15

