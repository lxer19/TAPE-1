URL: ftp://ftp.huji.ac.il/users/yish/learning.strategies.extended.abstract.ps
Refering-URL: http://www.cs.huji.ac.il/~yish/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: yish@cs.huji.ac.il, clag@cs.huji.ac.il, jeff@cs.huji.ac.il  
Title: Learn Your Opponent's Strategy (in Polynomial Time)! (An extended abstract)  
Author: Yishay Mor Claudia V. Goldman Jeffrey S. Rosenschein ph: ---- 
Keyword: Distributed Artificial Intelligence, Learning, repeated games, automata  
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Computer Science Department Hebrew University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Aumann and A. Brandenburger. </author> <title> Epistemic conditions for Nash equilibrium. </title> <type> Working Paper 91-042, </type> <institution> Harvard Business School, </institution> <year> 1991. </year>
Reference-contexts: Standard notions of equilibria in game theory involve a set of players holding strategies, such that no player can gain by deviating from his current strategy while the others' strategies stay fixed. This idea implicitly assumes some degree of knowledge about the players' strategies <ref> [1] </ref>. An obvious question is how this knowledge came to be. One possible answer is to have the players negotiate over their strategies.
Reference: [2] <author> L. Fortnow and D. Whang. </author> <title> Optimality and domination in repeated games with bounded players. </title> <type> Technical report, </type> <institution> Department of Computer Science University of Chicago, Chicago, </institution> <year> 1994. </year>
Reference-contexts: This line of work is, in a sense, contrapositional to other common measures of complexity. Papadimitriou [6] has shown that as the bound on the number of states of the automaton becomes more restrictive, the problem of designing the optimal automaton becomes harder. Fortnow and Whang <ref> [2] </ref> were the first to assume total ignorance of the opponent's automaton. <p> For any &lt; ff; fi &gt;, we construct an automaton that *-supports &lt; ff; fi &gt; as follows: * Build a consensus cycle, C imp that implements &lt; ff; fi &gt; as in Theorem 1. * Build the punishing chain, C pun that is based on the automaton presented in <ref> [2] </ref>. The idea is to choose a random binary string of Cs and Ds and to construct the punishing chain so that B can escape from it only by following this string. It was shown in [2] that C pun cannot be learnt in polynomial time. <p> Build the punishing chain, C pun that is based on the automaton presented in <ref> [2] </ref>. The idea is to choose a random binary string of Cs and Ds and to construct the punishing chain so that B can escape from it only by following this string. It was shown in [2] that C pun cannot be learnt in polynomial time.
Reference: [3] <author> Ehud Kalai. </author> <title> Bounded rationality and strategic complexity in repeated games. </title> <editor> In T. Ichi-ishi, A. Neyman, and Y. Tauman, editors, </editor> <booktitle> Game Theory and Aplications, </booktitle> <pages> pages 131-157. </pages> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1990. </year>
Reference-contexts: An extensive survey of the relevant literature appears in <ref> [3] </ref>. The basic concept underlying this trend is that the players are rational, but are constrained to submit automata of limited size as their agents in the game. The number of states in the automata is accepted as a measure of their complexity.
Reference: [4] <author> Michael J. Kearns and Umesh V. Vazirani. </author> <title> An Introduction to Computational Learning Theory. </title> <publisher> MIT press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1994. </year>
Reference-contexts: We assume A restricts herself to strategies realizable by Deterministic Finite State Automata (DFS) because DFS strategies have been accepted widely as a model of bounded rationality, and because learning the structure of an automaton has been shown to be a very hard problem <ref> [4] </ref>. This paper investigates the learning process in two-person, non-zero-sum repeated games. We focus, as an example, on the repeated game of The Prisoner's Dilemma.
Reference: [5] <author> A. Neyman. </author> <title> Bounded complexity justifies cooperation in finitely repeated prisoner's dilemma. </title> <journal> Economic Letters, </journal> <pages> pages 227-229, </pages> <year> 1985. </year>
Reference-contexts: However, most, if not all, of our results can easily be generalized to a wider class of two-person non-zero-sum games. 1.1 Related Work Finite automata players were suggested as a model of bounded rationality, and as a means of resolving the prisoner's dilemma paradox, by Rubinstein [7] and by Neyman <ref> [5] </ref>. An extensive survey of the relevant literature appears in [3]. The basic concept underlying this trend is that the players are rational, but are constrained to submit automata of limited size as their agents in the game.
Reference: [6] <author> Christos H. Papadimitriou. </author> <title> On players with a bounded ,number of states. </title> <journal> Games and Economic Behavior, </journal> <volume> 4 </volume> <pages> 122-131, </pages> <year> 1992. </year>
Reference-contexts: The number of states in the automata is accepted as a measure of their complexity. This line of work is, in a sense, contrapositional to other common measures of complexity. Papadimitriou <ref> [6] </ref> has shown that as the bound on the number of states of the automaton becomes more restrictive, the problem of designing the optimal automaton becomes harder. Fortnow and Whang [2] were the first to assume total ignorance of the opponent's automaton.
Reference: [7] <author> A. Rubinstein. </author> <title> Finite automata play the repeated prisoner's dilemma. </title> <type> ST/ICERD Discussion Paper 85/109, </type> <institution> London School of Economics, </institution> <year> 1985. </year> <month> 7 </month>
Reference-contexts: However, most, if not all, of our results can easily be generalized to a wider class of two-person non-zero-sum games. 1.1 Related Work Finite automata players were suggested as a model of bounded rationality, and as a means of resolving the prisoner's dilemma paradox, by Rubinstein <ref> [7] </ref> and by Neyman [5]. An extensive survey of the relevant literature appears in [3]. The basic concept underlying this trend is that the players are rational, but are constrained to submit automata of limited size as their agents in the game.
References-found: 7

