URL: ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/VysGroKro93b.ps.gz
Refering-URL: http://www.fwi.uva.nl/research/neuro/publications/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The optimal number of learning samples and hidden units in function approximation with a feedforward network  
Author: Vytautas Vysniauskas Frans C.A. Groen, Ben J.A. Krose 
Keyword: Feedforward networks, function approximation, continuous mapping, learning from examples, generalization, hidden units.  
Address: Kruislaan 403, 1098 SJ Amsterdam The Netherlands  
Affiliation: University of Amsterdam Faculty of Computer Science and Mathematics  
Pubnum: Technical Report CS-93-15  
Email: e-mail: groen@fwi.uva.nl, krose@fwi.uva.nl  
Date: 1993, November 9  
Abstract: This paper presents a methodology to estimate the optimal number of learning samples and the number of hidden units needed to obtain a desired accuracy of a function approximation by a feedforward network. The representation error and the generalization error, components of the total approximation error are analyzed and the approximation accuracy of a feedforward network is investigated as a function of the number of hidden units and the number of learning samples. Based on the asymptotical behavior of the approximation error, an asymptotical model of the error function (AMEF) is introduced of which the parameters can be determined experimentally. An alternative model of the error function, which include theoretical results about general bounds of approximation, is also analyzed. In combination with knowledge about the computational complexity of the learning rule an optimal learning set size and number of hidden units can be found resulting in a minimum computation time for a given desired precision of the approximation. This approach was applied to optimize the learning of the camera-robot mapping of a visually guided robot arm and a complex logarithm function approximation. 
Abstract-found: 1
Intro-found: 1
Reference: [Baba 1989] <author> Baba, N. </author> <title> "A New Approach for Finding the Global Minimum of Error Function of Neural Networks", Neural Networks, </title> <type> Vol.2, </type> <year> 1989, </year> <month> pp.367-373. </month>
Reference-contexts: The deterministic methods have a possibility to be trapped into a local minimum, giving a suboptimal solution, but, alternatively, the stochastic optimization technique (for example, a random optimization method <ref> [Baba 1989] </ref> or simulated annealing procedure [Kirkpatrick 1983]), which ensures theoretically the convergence to the global minimum, tends to be very slow.
Reference: [Barron 1991a] <author> Barron, </author> <title> A.,R. "Approximation and estimation bounds for artificial neural networks", </title> <booktitle> Proceedings of the Fourth Annual Workshop on Computational Learning Theory, </booktitle> <year> 1991, </year> <pages> pp 243-249. </pages>
Reference-contexts: In fact, these methods are very closely related in essence, besides that link between the information-theoretic and SM approach can be established [Levin 1990]. An important contribution about the approximation capabilities of feedforward networks was made by Barron <ref> [Barron 1991a] </ref> who pointed out that for some classes of smooth functions the mean integrated squared error between the estimated network and the target function is bounded by O (1=h) + O (h=N )logN where h is number of hidden units, N is the number of training examples. <p> An asymptotic model of the error function (AMEF) and an alternative model based on the result of <ref> [Barron 1991a] </ref> are analyzed in section 4. 2 Section 5 presents two experiments to test the obtained solution and to estimate these parameters in order to optimize a function approximation. <p> In this case the representation error is expressed as a finite sum of the inverse powers over h. Extended Barron's formula An alternative model can be derived from the work of Barron <ref> [Barron 1991a] </ref>. An upper bound is given for the approximation error of a feedforward network, derived in a distribution-free, worst case analysis. <p> We used a general asymptotical model of the error function (AMEF) and the extension of Barron's formula (EBF) which includes theoretical results about the approximation bounds of feedforward networks <ref> [Barron 1991a] </ref>. Estimates of the accuracy as a function of learning set size and network size or guidelines about the needed number of hidden units and learning samples for a specified accuracy are of great importance when feedforward neural networks are applied in adaptive systems.
Reference: [Barron 1991b] <author> Barron, </author> <title> A.,R. "Complexity Regularization with Application to Neural Networks", Nonparametric Functional Estimation and Related Topics, </title> <publisher> Roussas G.,editor, Kluwer Academic Publishers, </publisher> <year> 1991, </year> <month> pp.561-576. </month>
Reference-contexts: This result was discovered introducing a complexity regularization criterion <ref> [Barron 1991b] </ref> which defines the best tradeoff between approximation error and the complexity of models estimated from information-theoretic considerations. This bound is a real upper bound, which can deviate considerably from the real error curve, since the result was obtained in a distribution-free, worst case analysis.
Reference: [Baum 1989] <author> Baum, E.,B., Haussler, D. </author> <title> "What Size Net Gives Valid Generalization?", </title> <booktitle> Neural Computation 1,1989, </booktitle> <pages> pp. 151-160. </pages>
Reference-contexts: A theoretical description of learning in neural networks predicts a generalization error inversely proportional to some power of the number of learning samples. The most common approaches are probably almost correct (PAC) learning <ref> [Baum 1989] </ref>,[Hausler 1989] and statistical mechanical (SM) framework [Seung 1992]. Alternative approaches also exist based on Bayesian paradigm [Lansen 1989], Vapnik's method of structural risk minimization [Vapnik 1982], or information-theoretic model estimation techniques such as minimum description length criterion [Rissanen 1986]. <p> In the case of neural networks, the VC dimension is closely related to the number of weights in the architecture. In <ref> [Baum 1989] </ref> classification performance of feedforward networks of linear threshold functions was analyzed, the results suggested that the appropriate number of learning samples is approximately the number of weights times the inverse of the accuracy parameter. 3 The approach In this section an approach is presented to find the number of
Reference: [Chen 1991] <author> Chen, A.,M., Hecht-Nielsen, R. </author> <title> "On the Geometry of Feedforward Neural Network Weight Spaces", </title> <booktitle> Proc. Second IEE International Conference On Neural Networks, </booktitle> <pages> 1-4, </pages> <publisher> IEE Press, </publisher> <address> London, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: We assume that the possibility of a neural network to be trapped into a local minimum is relatively small, otherwise a stochastic procedure of the global optimization must be used. The feedforward neural network has multiple solutions due to the weights permutations and sign flips - equioutput transformations <ref> [Chen 1991] </ref>, and, as a consequence, the space of parameters w 2 W is divided into many identical cones. The feedforward network with h hidden units arranged into a single hidden layer has h!2 h multiple solutions providing the high possibility to get near the optimal solution.
Reference: [Cybenko 1989] <author> Cybenko, G. </author> <title> "Approximation by Superpositions of a Sigmoidal Function", </title> <journal> Math. Control Signals Systems, </journal> <volume> 2, </volume> <year> 1989, </year> <pages> pp. 303-314. </pages>
Reference-contexts: Are multilayer feedforward networks in fact capable of universal approximation? Actually, the answer is given by the rigorous prove ([Hornik 1989], [Funahashi 1989], <ref> [Cybenko 1989] </ref>), that standard multilayer feedforward networks with at least one hidden layer of computational units whose output functions are sigmoidal functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any degree of accuracy, provided sufficiently many hidden units are available.
Reference: [Funahashi 1989] <author> Funahashi, K. </author> <title> "On the Approximate Realization of Continuous Mappings by Neural Networks", Neural Networks, </title> <type> vol.2, </type> <year> 1989, </year> <pages> pp. 183-192. </pages>
Reference-contexts: 1 Introduction In the last several years many researchers have explored the ability of multilayer feedforward networks to approximate general mappings from one finite dimensional space to another. Are multilayer feedforward networks in fact capable of universal approximation? Actually, the answer is given by the rigorous prove ([Hornik 1989], <ref> [Funahashi 1989] </ref>, [Cybenko 1989]), that standard multilayer feedforward networks with at least one hidden layer of computational units whose output functions are sigmoidal functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any degree of accuracy, provided sufficiently many hidden units are available.
Reference: [Hornik 1989] <author> Hornik, K., Stinchcombe, M., White, H. </author> <title> "Multilayer Feedforward Networks are Universal Approximators", Neural Networks, </title> <type> vol.2, </type> <year> 1989, </year> <month> pp.359-366. </month>
Reference-contexts: It was shown by Hornik et.al. <ref> [Hornik 1989] </ref> that there exists the solution ~w = argmin w R the function f approximation for a given architecture of the feedforward network. Such a solution we define as the best approximation 1 . <p> According to the main result in <ref> [Hornik 1989] </ref>, any continuous function can be arbitrarily closely approximated by a network provided a sufficient number of the hidden units. <p> (h) (25) * The representation error can be reduced arbitrary by increasing the number of hidden units " a (N; 1) = " g (N; 1) (26) * Given an infinitive large learning set and arbitrary large network the approximation error converges to zero as was proved by Hornik et.al. <ref> [Hornik 1989] </ref> lim " a (1; h) = 0: (27) Note, that in the strict sense the situation must be treated as a double limit, and specific growth rates for the network size must be provided with increasing the learning set size to avoid the dangers of both overfitting (overlearning) and
Reference: [Hausler 1989] <author> Hausler, D. </author> <title> "Generalizing the PAC Model: Sample Size Bounds From Metric Dimension-based Uniform Convergence Results", </title> <booktitle> Proceedings ot the 30th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <month> pp.40-45. </month>
Reference: [Kirkpatrick 1983] <author> Kirkpatrick, S., Gelatt, C.,D., Vecchi, M. </author> <title> "Optimization by Simulated Annealing", </title> <booktitle> Science vol.220,1983,pp. </booktitle> <pages> 621-680. </pages>
Reference-contexts: The deterministic methods have a possibility to be trapped into a local minimum, giving a suboptimal solution, but, alternatively, the stochastic optimization technique (for example, a random optimization method [Baba 1989] or simulated annealing procedure <ref> [Kirkpatrick 1983] </ref>), which ensures theoretically the convergence to the global minimum, tends to be very slow.
Reference: [Krose 1990] <author> Krose, B.,J.,A., van der Korst, M.,J., Groen, F.,C.,A. </author> <title> "Learning strategies for a vision based neural controller for a robot arm", </title> <booktitle> in IEEE International Workshop on Intelligent Motor Control, </booktitle> <address> O.Kaynak, ed.,Istambul, 20-22 Aug.,1990, pp.199-203. </address>
Reference-contexts: Learning procedure As usual, a feedforward network is learned in a supervised way, which means that is has to be provided with learning samples to describe the input-output relationship. Instead of a direct generation of samples (because the relationship is unknown), the input-adjustment method <ref> [Krose 1990] </ref>, an indirect learning procedure can be used. The idea is as follows. Given the input x (t), the network generates output y (t) resulting in the new position x (t + 1).
Reference: [Lansen 1989] <author> Lansen, A., Ekeberg, O. </author> <title> "A one layer feedback, artificial network with a Bayesian learning rule", </title> <journal> Int. J. Neural Systems, </journal> <note> 1989, vol.1, pp.77-87. </note>
Reference-contexts: The most common approaches are probably almost correct (PAC) learning [Baum 1989],[Hausler 1989] and statistical mechanical (SM) framework [Seung 1992]. Alternative approaches also exist based on Bayesian paradigm <ref> [Lansen 1989] </ref>, Vapnik's method of structural risk minimization [Vapnik 1982], or information-theoretic model estimation techniques such as minimum description length criterion [Rissanen 1986]. In fact, these methods are very closely related in essence, besides that link between the information-theoretic and SM approach can be established [Levin 1990].
Reference: [Levin 1990] <author> Levin, E., Thishby, N., Solla, S.,A. </author> <title> "A Statistical Approach to Learning and Generalization in Layered Neural Networks",Proceedings of IEEE, </title> <address> vol.78, </address> <year> 1990, </year> <month> pp.1568-1574. </month>
Reference-contexts: In fact, these methods are very closely related in essence, besides that link between the information-theoretic and SM approach can be established <ref> [Levin 1990] </ref>.
Reference: [Nowlan 1992] <author> Nowlan, S.,J., Hinton, E. </author> <title> "Simplifying Neural Networks by Soft Weight-Sharing", </title> <booktitle> Neural Computation, </booktitle> <year> 1992, </year> <month> pp.473-493. </month>
Reference-contexts: The simplest example of the regularizer can be weight decay term (such as jwj 2 ) which penalizes large weights. In <ref> [Nowlan 1992] </ref> a very sophisticated approach of the regularizer is investigated, when the weights values are modeled as a mixture of multiple gaussians with tunable parameters at the same time as the network learns.
Reference: [Powell 1977] <author> Powell, M.,J.,D. </author> <title> "Restart procedures for the conjugate gradient method", </title> <journal> Mathematical Programming, </journal> <volume> 12, </volume> <year> 1977, </year> <month> pp.241-254. </month>
Reference-contexts: The original version of BP explores simple gradient descent update rule (with user-defined learning step) to adjust iteratively the weights. We preferred to use conjugate gradient method (CG) with Powell's procedure of restarts <ref> [Powell 1977] </ref> as a tool for the network weights adjusting. It seems a good compromise between the computational complexity and the convergence, since this method requires only O (q) of a computation and the performance is close to the second order methods with the complexity O (q 2 ).
Reference: [Rissanen 1986] <author> Rissanen, J. </author> <title> "Stochastic complexity and modeling", </title> <journal> The Annals of Statistics, </journal> <volume> vol.14, </volume> <year> 1986, </year> <month> pp.1080-1100. </month>
Reference-contexts: The most common approaches are probably almost correct (PAC) learning [Baum 1989],[Hausler 1989] and statistical mechanical (SM) framework [Seung 1992]. Alternative approaches also exist based on Bayesian paradigm [Lansen 1989], Vapnik's method of structural risk minimization [Vapnik 1982], or information-theoretic model estimation techniques such as minimum description length criterion <ref> [Rissanen 1986] </ref>. In fact, these methods are very closely related in essence, besides that link between the information-theoretic and SM approach can be established [Levin 1990].
Reference: [Rumelhart 1986] <author> Rumelhart, D.,E., Hinton, G.,E., Williams, </author> <title> R.,J. "Learning representation by back-propagating errors", </title> <journal> Nature, </journal> <volume> 323, </volume> <year> 1986, </year> <pages> pp. 533-536. </pages>
Reference-contexts: In order to minimize the learning set redundancy and to increase the possibility to generalize well, learning samples were distributed uniformly in 5-dimensional input space. The most popular algorithm of the feed-forward network learning is backward error propagation, or back-propagation (BP) method, originally introduced by Rumelhart,Hinton and Williams <ref> [Rumelhart 1986] </ref>. In essence, BP is very efficient method to compute the elements of the gradient of a least squares function, and we used this method as well to compute the gradient of the criterion function (7).
Reference: [Seung 1992] <author> Seung, H.,S., Sompolinsky, H., Tishby, N. </author> <title> "Statistical mechanics of learning from examples", Physical Review A, </title> <booktitle> 1992, vol.45, no.8, </booktitle> <pages> pp. 6056-6091. </pages> <publisher> [Smagt 1991] van der Smagt, </publisher> <pages> P.,P. </pages> <note> "Control of the UvA OSCAR-6 robot", Report # Uva-sma-4-9104-1,April 23, </note> <year> 1991; </year> <month> August 30, </month> <year> 1991. </year>
Reference-contexts: A theoretical description of learning in neural networks predicts a generalization error inversely proportional to some power of the number of learning samples. The most common approaches are probably almost correct (PAC) learning [Baum 1989],[Hausler 1989] and statistical mechanical (SM) framework <ref> [Seung 1992] </ref>. Alternative approaches also exist based on Bayesian paradigm [Lansen 1989], Vapnik's method of structural risk minimization [Vapnik 1982], or information-theoretic model estimation techniques such as minimum description length criterion [Rissanen 1986].
Reference: [Vapnik 1971] <author> Vapnik, V.,N.,Chervonenkis, A.,YA. </author> <title> "On the uniform convergence of relative frequencies of events to their probabilities", </title> <journal> Theory of Probability and its Applications, </journal> <volume> vol XVI, </volume> <pages> no.2, </pages> <year> 1971, </year> <month> pp.264-280. </month>
Reference-contexts: (w o jZ N ) differs significantly from " g be very small P r [ sup jE g (w o jZ N ) " g j &gt; *] ffi (N ); (22) lim ffi (N ) = 0: (23) The problem was solved in principle by Vapnik and Chervonenkis <ref> [Vapnik 1971] </ref> by introducing the concept of Vapnik-Chervonenkis (V C) dimension, a measure how fast the convergence is achieved (likelihood of generalization).
Reference: [Vapnik 1982] <author> Vapnik, V. </author> <title> "Estimation of dependences based on empirical data", </title> <address> Springel-Verlag, New York, </address> <year> 1982. </year>
Reference-contexts: The most common approaches are probably almost correct (PAC) learning [Baum 1989],[Hausler 1989] and statistical mechanical (SM) framework [Seung 1992]. Alternative approaches also exist based on Bayesian paradigm [Lansen 1989], Vapnik's method of structural risk minimization <ref> [Vapnik 1982] </ref>, or information-theoretic model estimation techniques such as minimum description length criterion [Rissanen 1986]. In fact, these methods are very closely related in essence, besides that link between the information-theoretic and SM approach can be established [Levin 1990].
Reference: [White 1989] <author> White, H. </author> <title> "Learning in Artificial Neural Networks: A Statistical Perspective", </title> <booktitle> Neural Computuation, vol.1, </booktitle> <year> 1989, </year> <month> pp.425-464. </month>
Reference-contexts: The notation Q (Z N ; w fl jZ N ) means "the measure Q computed along the set Z N with respect to the solution w fl evaluated from the set Z N ". There is no evidence, however, that criterion (7) ensures minimal squared error <ref> [White 1989] </ref> over the whole input space X.
Reference: [White 1990] <author> White, H. </author> <title> "Connectionist Nonparametric Regression: Multilayer Feedforward Networks Can Learn Arbitrary Mappings", Neural Networks, </title> <type> vol.3, </type> <year> 1990, </year> <month> pp.525-549. </month>
Reference-contexts: h) = 0: (27) Note, that in the strict sense the situation must be treated as a double limit, and specific growth rates for the network size must be provided with increasing the learning set size to avoid the dangers of both overfitting (overlearning) and underfitting the learning set (see <ref> [White 1990] </ref> for more details).
References-found: 22

