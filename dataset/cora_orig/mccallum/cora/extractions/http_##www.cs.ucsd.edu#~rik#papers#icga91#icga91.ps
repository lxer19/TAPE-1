URL: http://www.cs.ucsd.edu/~rik/papers/icga91/icga91.ps
Refering-URL: http://www.cs.ucsd.edu/~rik/bibliography3_5.html
Root-URL: http://www.cs.ucsd.edu
Email: whart@cs.ucsd.edu  rik@cs.ucsd.edu  
Title: Optimizing an Arbitrary Function is Hard for the Genetic Algorithm  
Author: William E. Hart Richard K. Belew R. K. Belew, L. B. Booker (ed.). 
Note: In Proc. Fourth Intl. Conf. on Genetic Algorithms.  Morgan Kaufmann, San Mateo, CA. 1991. pp. 190-195.  
Address: La Jolla, CA 92093  
Affiliation: Cognitive Computer Science Research Group Computer Science and Engineering (C-014) University of California San Diego  
Abstract: The Genetic Algorithm (GA) is generally portrayed as a search procedure which can optimize pseudo-boolean functions based on a limited sample of the function's values. There have been many attempts to analyze the computational behavior of the GA. For the most part, these attempts have tacitly assumed that the algorithmic parameters of the GA (e.g. population size, choice of genetic operators, etc.) can be isolated from the characteristics of the class of functions being optimized. In the following, we demonstrate why this assumption is inappropriate. We consider the class, F, of all deterministic pseudo-boolean functions whose values range over the integers. We then consider the Genetic Algorithm as a combinatorial optimization problem over f0; 1g l and demonstrate that the computational problem it attempts to solve is NP-hard relative to this class of functions. Using standard performance measures, we also give evidence that the Genetic Algorithm will not be able to efficiently approximate this optimization problem. These results imply that there does not exist a fixed set of algorithmic parameters which enable the GA to optimize an arbitrary function in F. We conclude that theoretical and experimental analyses of the GA which do not specify the class of functions being optimized can make few claims regarding the efficiency of the genetic algorithm for an arbitrary fitness function. When analyzing the computational complexity of the Genetic Algorithm, classes (or distributions) of functions should be analyzed relative to the algorithmic parameters chosen for the GA. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Lenore Blum. </author> <title> Lectures on a theory of computation and complexity over the reals (or an arbitrary ring). </title> <editor> In Erica Jen, editor, </editor> <booktitle> 1989 Lectures in Complex Systems, </booktitle> <pages> pages 1-48. </pages> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: This is clearly undesirable, though for the moment it will have to suffice. Only recently have models been proposed in automata theory which can appropriately consider computation over real numbers (see for example <ref> [1] </ref>). Another important assumption is that we consider only deterministic functions. There is no particular reason our analysis should exclude the probabilistic case, though we expect it would require different proof techniques from those presented here.
Reference: [2] <author> Yves Crama. </author> <title> Recognition problems for special classes of polynomials in 0-1 variables. </title> <journal> Mathematical Programming, </journal> <volume> 44 </volume> <pages> 139-155, </pages> <year> 1989. </year>
Reference: [3] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability A guide to the theory of NP-completeness. W.H. </title> <publisher> Freeman and Co., </publisher> <year> 1979. </year>
Reference-contexts: If, however, the fitness of the population is not dependent on the size of the population itself, the set of binary strings of length l may suffice. 1 The reader is referred to <ref> [3] </ref> for an excellent discussion of the complexity differences between P and N P , and to [4] for an exposition of probabilistic computation. 3 The meaning of a `most fit' population within this search space is some-what ambiguous. <p> B l 2) an encoding of a TM M f , which defines a function f : B l ! Z 3 Complexity Results In order to determine the complexity of DGA-MAX , we need to define a version of this problem as a formal language (using the format of <ref> [3] </ref>). Definition 2 DGA-MAX INSTANCE: a string encoding integers l, and , and a Turing machine M f which computes a function f : B l ! Z in polynomial time. <p> Even so, there exists an algorithm which can produce a tour through the cities which is at most twice the value of the optimal tour.<ref> [3] </ref> 6 Before continuing, we introduce some notation (from [3]). Let Opt (I) refer to the value of the optimal value for instance I, and let A (I) refer to the value that algorithm A returns for instance I (we assume that A is an efficient algorithm). <p> We take the following definitions from <ref> [3] </ref>. Let the ratio R A (I) = Opt (I)=A (I).
Reference: [4] <author> John Gill. </author> <title> Computational complexity of probabilistic turing machines. </title> <journal> SIAM Journal of Computation, </journal> <volume> 6(4) </volume> <pages> 675-695, </pages> <year> 1977. </year>
Reference-contexts: If, however, the fitness of the population is not dependent on the size of the population itself, the set of binary strings of length l may suffice. 1 The reader is referred to [3] for an excellent discussion of the complexity differences between P and N P , and to <ref> [4] </ref> for an exposition of probabilistic computation. 3 The meaning of a `most fit' population within this search space is some-what ambiguous. Simulations of the GA are typically halted at the researcher's discretion and not at some well defined convergence criterion. Often several measures of the population's fitness are provided.
Reference: [5] <author> D.E. Goldberg. </author> <title> Genetic algorithms and walsh functions: Part I, a gentle introduction. </title> <journal> Complex Systems, </journal> <volume> 3 </volume> <pages> 129-152, </pages> <year> 1989. </year>
Reference: [6] <author> D.E. Goldberg. </author> <title> Genetic algorithms and walsh functions: Part II, deception and its analysis. </title> <journal> Complex Systems, </journal> <volume> 3 </volume> <pages> 153-171, </pages> <year> 1989. </year>
Reference: [7] <author> D.E Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley Publishing Co., Inc., </publisher> <year> 1989. </year>
Reference-contexts: In other words, a TM M is efficient if the language it accepts is in P . A formal definition of the Genetic Algorithm is not necessary for the following presentation. We refer the interested reader to <ref> [7] </ref> for an excellent presentation of the GA and its applications. 2 Statement of the Problem To analyze the computational complexity of the Genetic Algorithm, we need to formalize the task which it accomplishes.
Reference: [8] <author> D.E. Goldberg and C.L. </author> <title> Bridges. An analysis of a reordering operator on a GA-hard problem. </title> <journal> Biological Cybernetics, </journal> <volume> 62 </volume> <pages> 397-405, </pages> <year> 1990. </year>
Reference-contexts: For example, while genetic operators like bitwise reordering may help the GA to optimize functions which it would otherwise find deceptive <ref> [8] </ref>, there will necessarily exist other functions which this modified GA will not be able to efficiently optimize.
Reference: [9] <author> P.L. Hammer, P. Hansen, and B. Simeone. </author> <title> Roof duality, complementation and persistency in quadratic 0-1 optimization. </title> <journal> Mathematical Programming, </journal> <volume> 28 </volume> <pages> 121-155, </pages> <year> 1984. </year>
Reference: [10] <author> Pierre Hansen and Bruno Simeone. </author> <title> Unimodular functions. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 14 </volume> <pages> 269-281, </pages> <year> 1986. </year>
Reference: [11] <author> J.H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <year> 1976. </year>
Reference-contexts: 1 Introduction The Genetic Algorithm [11,7] is a method of stochastic optimization which has attracted significant attention in recent years. There have been many attempts to analyze the computational behavior of the GA, with Holland's schema theorem <ref> [11] </ref> central to much of this analysis. Using it, we can justify how and why certain bit patterns (schemata) will be propagated from one generation to the next. This can be used to analyze the effectiveness of different genetic operators (see for example [15]).
Reference: [12] <author> John E. Hopcroft and Jeffrey D. Ullman. </author> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison-Wesley Pub. Co., </publisher> <year> 1979. </year>
Reference-contexts: Before proceeding, we introduce some notation and definitions. We let B = f0; 1g and let B l refer to binary strings of length l. We assume that the reader is familiar with formal language theory; we generally follow the notational conventions of <ref> [12] </ref>. Particularly notice that the expressions surrounded by h i's refer to encodings used when defining formal languages; for an integer k, hki would refer to its encoding.
Reference: [13] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization Algorithms and Complexity. </title> <publisher> Prentice Hall, Inc., </publisher> <year> 1982. </year> <month> 11 </month>
Reference-contexts: Having defined the search space for the Genetic Algorithm as well as the fitness criteria it uses for a population, we can now formalize the problem which the Genetic Algorithm attempts to solve as a combinatorial optimization problem, DGA-MAX (following the format of <ref> [13] </ref>). 4 Definition 1 DGA-MAX The Genetic Algorithm combinatorial maximization problem which (1) uses a deterministic fitness function f and (2) assigns the fitness of the maximally fit individual in a population to the fitness of the population itself. <p> Given a TM which solves the optimization version, we can clearly solve the formal language version. However, it is unknown whether the opposite is true (see <ref> [13] </ref> for further details). Thus, the optimization version is at least as difficult as the formal language version of DGA-MAX . We now demonstrate that the formal language version of DGA-MAX is very difficult to solve. To do this, we use the following definition (recall that SAT is NP-complete).
Reference: [14] <author> Alex Rinnooy Kan. </author> <title> Probabilistic analysis of algorithms. </title> <journal> Annals of Discrete Mathematics, </journal> <volume> 31 </volume> <pages> 365-384, </pages> <year> 1987. </year>
Reference: [15] <author> Gilbert Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9, </pages> <year> 1989. </year>
Reference-contexts: Using it, we can justify how and why certain bit patterns (schemata) will be propagated from one generation to the next. This can be used to analyze the effectiveness of different genetic operators (see for example <ref> [15] </ref>). Related analysis with Walsh functions has also proven very rewarding.
References-found: 15

