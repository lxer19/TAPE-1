URL: ftp://ftp.eecs.umich.edu/groups/gasm/distprolog.ps
Refering-URL: http://www.eecs.umich.edu/gasm/papers.html
Root-URL: http://www.cs.umich.edu
Email: lurdes@dia.ucm.es)  
Title: Correctness proof of a Distributed Implementation of Prolog by means of Abstract State Machines.  
Author: Lourdes Araujo 
Address: Madrid 28040, Spain  
Affiliation: (Dpto. Informatica Automatica (Fac. Matematicas) Universidad Complutense de Madrid  
Abstract: This work provides both a specification and a proof of correctness for the system PDP (Prolog Distributed Processor) which make use of Abstract State Machines (ASMs). PDP is a recomputation-based model for parallel execution of Prolog on distributed memory. The system exploits OR parallelism, Independent AND parallelism as well as the combination of both. The verification process starts from the SLD trees, which define the execution of a Prolog program, and going through the parallel model, it arrives to the abstract machine designed for PDP, an extension of the WAM (Warren Abstract Machine), the most common sequential implementation of Prolog. The first step of this process consists in defining parallel SLD subtrees, which are a kind of partition of the SLD tree for programs whose clauses are annotated with parallelism. In a subsequent step the parallel execution approach of PDP is modeled by means of an OR TASK ASM. In this ASM each task is associated with the execution of a parallel SLD subtree. The execution of the parallel SLD subtree corresponding to each task is modeled by a NODE submachine which is an extension of the one proposed by Borger and Rosenzweig to verify the sequential execution of Prolog. Accordingly, the verification leans on the results of this work in order to avoid the verification of the common points with the sequential execution. The new elements of the execution due to parallelism exploitation are modeled at successive steps of the verification process, finally leading to the extended WAM which implements PDP. The PDP verification proves correctness for this particular system but it can readily be adapted to prove it in other related parallel systems exploiting AND, OR or both kinds of parallelism. 
Abstract-found: 1
Intro-found: 1
Reference: [Ali90] <author> Ali, K. A. M., Karlsson, R.: </author> <title> "The Muse Approach to Or-Parallel Prolog"; Int. </title> <journal> Journal of Parallel Programming 19, </journal> <volume> 2 (1990), </volume> <pages> 129-162. </pages>
Reference-contexts: In the same way the verification of the OR parallel exploitation by recomputation may be easily adapted to systems which use a different method for the exploitation of OR parallelism, such as the copying in MUSE <ref> [Ali90] </ref>. <p> Likewise, verification of other OR parallel systems can make profit out of the first steps of the verification of PDP, since they share the relation between OR parallel computations and the SLD tree. Furthermore, OR parallel systems using independent working environments, such as MUSE <ref> [Ali90] </ref>, can be verified in a way similar to PDP, by simply replacing the recomputation rule by a copying rule, since copying is the mechanism used in this system to reconstruct a working environment.
Reference: [Apt90] <editor> Apt, C.: </editor> <booktitle> "Logic Programming"; Handbook of Theoretical Computer Science (J. </booktitle> <editor> van Leeuwen ed.), </editor> <publisher> Elsevier (1990). </publisher>
Reference: [Ara93] <author> Araujo, L. Ruz, J.J.: </author> <title> "OR-Parallel Execution of Prolog on a Transputer-based System"; Transputers and Occam Research: New Directions. </title> <publisher> IOS Press (1993), </publisher> <pages> 167-181. </pages>
Reference-contexts: Thus, the results of the execution of each goal are collected in the parent processor (the one finding the parallel call). OR parallelism is exploited by following a recomputation approach <ref> [Ara93] </ref>; a processor environment is reconstructed by recomputing the initial goal without backtracking (see Figure 1), following the socalled success path, i.e. the sequence of clauses which have succeeded, obtained from the parent processor (the one finding the parallel clause).
Reference: [Ara94] <author> Araujo, L., Ruz, J.J.: </author> <title> "PDP: Prolog Distributed Processor for Independent AND=OR Parallel Execution of Prolog"; Proc. </title> <booktitle> Int. Conf. of Logic Programming, </booktitle> <publisher> MIT Press (1994), </publisher> <pages> 142-156. </pages>
Reference-contexts: This extension is focused on the representation and unification of terms, where the type of the constraints has to be considered. The aim of this work is to use ASMs to provide a specification and a proof of correctness for the system PDP (Prolog Distributed Processor) <ref> [Ara94, Ara97] </ref>. To achieve this we again take WAM's proof of correctness for granted. <p> Finally, after outlining how the model is completed in section 11, conclusions are drawn in section 12. 2 Overview of PDP PDP <ref> [Ara94, Ara97] </ref> is a multisequential system supporting both independent-AND and OR parallelism, as well as its combination. Parallelism is supposed to be annotated in the source program. <p> Processor 1 Processor 2 OR left of P1 to arrive at this point, while processor 2 has only computed the shorter path (success path) until P2, which is annotated to be executed in parallel. This path to P2 is provided by processor 1. OR under AND parallelism <ref> [Ara94] </ref> is designed to create, in an automatic and decentralized way, an independent computation for each solution. <p> Prolog programs 575Araujo L.: Correctness Proof of a Distributed Implementation of Prolog ... are compiled to PDP instructions. These consist of WAM instructions along with instructions to manage each kind of parallelism. A complete description of the PDP data structures and instructions can be found in <ref> [Ara94, Ara97] </ref>. The detailed refinement steps arriving to the PDP architecture are not included in this work but can be found elsewhere [Ara96]. 3 Parallel SLD subtrees From now on this work will deal with logic programs annotated with parallelism.
Reference: [Ara96] <author> Araujo, L.: </author> <title> "Correctness proof of a Parallel Implementation of Prolog by means of Evolving Algebras"; Technical Report DIA 21-96, </title> <institution> Dpto. Inform'atica y Au-tom'atica, Universidad Complutense de Madrid, </institution> <year> (1996). </year>
Reference-contexts: A complete description of the PDP data structures and instructions can be found in [Ara94, Ara97]. The detailed refinement steps arriving to the PDP architecture are not included in this work but can be found elsewhere <ref> [Ara96] </ref>. 3 Parallel SLD subtrees From now on this work will deal with logic programs annotated with parallelism. These annotations may be added to clauses (OR parallelism) or to goals (AND parallelism). <p> A new universe PENDING GOAL is introduced to model the new actions. The Select rule reflects the change. 594 Araujo L.: Correctness Proof of a Distributed Implementation of Prolog ... For the sake of brevity we do not include here the new rules, but they can be found in <ref> [Ara96] </ref>. Now, it is necessary to introduce mechanisms to deal with the pending AND and OR tasks. Let us assume that the scheduler function is able to detect the change in the state of the workers and to check the goal stack and pending alternative list. <p> A task with the possibility of creating new tasks does it when the its input function adopts the appropriate request value. A new rule <ref> [Ara96] </ref> is introduced to model the system behavior when com state becomes input. It is necessary to model the behavior of an AND task, which now in case of failure has to explicitly communicate this result to its parent task. <p> Backtracking has also to take into account that if a goal to be reexecuted belongs to a parallel call and has been solved by an AND task, the new solution has to be requested to this task, and thus a new backtracking rule appears (this can be found in <ref> [Ara96] </ref>). In case there is no idle processor in the system, a mechanism is needed by means of which the pending tasks are developed by the current task itself. In the case of the OR tasks, the pending alternatives are taken automatically in the backtracking process. <p> The task model of this section turns out to be correct and complete wrt that of 6 as it is shown in <ref> [Ara96] </ref>. 8 Introducing Stacks in the Tasks In a way similar to the step from Trees to Stack in [Bor95a], the path of active nodes in a task may be viewed as a stack, if cands list are represented elsewhere. <p> of the list. (CP E LI ST ; cpe; bcpe; +; ; val) The elements of the NODE ASM are recovered as follows node (currtask) = F (b (currtask)) success path (currtask) = F (bsp) cpel (currtask) = F (bcpe) These changes are reflected in a new set of rules <ref> [Ara96] </ref>. As it is stated in [Bor95a], the "stacks" maintain the node tree structure corresponding to a task: they are not discarded when they are "popped" on backtracking, but they are still there and may be used when needed. <p> Old Call mode will retain its role. A new 0-ary function (`cutpoint register') ct 2 ST AT E is introduced. It will, in call mode, store b's old value in order to find it in Enter mode. (See <ref> [Bor95a, Ara96] </ref> for details). 9 Predicates structure: OR parallelism The code for the extended WAM which corresponds to OR parallelism exploitation appears when the disjunctive structure of Prolog predicates is considered. As in [Bor95a], a predicate is represented as a sequence of instructions to manage choicepoints. <p> The same remarks of [Bor95a] in the corresponding stage of abstraction allow to establish that the model of 9 is correct and complete wrt that of 8 (see <ref> [Ara96] </ref> for details). 10 Clause structure: AND parallelism The PDP extension to the WAM for the exploitation of AND parallelism appears when the compilation of clause structure into WAM is analyzed. <p> And in both cases, the process has to distinguish whether the goal has pending alternatives. All these facts are controlled by introducing objects as markers in the stack. This in turn leads to introduce new instructions and to modify the backtracking process (see <ref> [Ara96] </ref> for details). <p> The state component of the proof map F proposed in [Bor95a] at this level is extended here (see <ref> [Ara96] </ref> for details) yielding correctness and completeness of the model of 10.1 wrt that of 10. 11 Completing the model The next step in the process is to take into account the representation of terms and substitutions. This leads to introduce new universes that are submachines of DATAAREA.
Reference: [Ara97] <author> Araujo, L., Ruz, J.J.: </author> <title> "A Parallel Prolog System for Distributed Memory"; The Journal of Logic Programming, </title> <type> 33, </type> <month> 1 </month> <year> (1997), </year> <pages> 49-79. </pages>
Reference-contexts: This extension is focused on the representation and unification of terms, where the type of the constraints has to be considered. The aim of this work is to use ASMs to provide a specification and a proof of correctness for the system PDP (Prolog Distributed Processor) <ref> [Ara94, Ara97] </ref>. To achieve this we again take WAM's proof of correctness for granted. <p> Finally, after outlining how the model is completed in section 11, conclusions are drawn in section 12. 2 Overview of PDP PDP <ref> [Ara94, Ara97] </ref> is a multisequential system supporting both independent-AND and OR parallelism, as well as its combination. Parallelism is supposed to be annotated in the source program. <p> The results of the implementation of this model <ref> [Ara97] </ref> have proved that OR parallelism exploitation provides a linear speedup for high granularity programs. For some programs presenting both kinds of parallelism PDP achieves a greater speedup than the product of the speedups achieved by exploiting each kind of parallelism separately. <p> Prolog programs 575Araujo L.: Correctness Proof of a Distributed Implementation of Prolog ... are compiled to PDP instructions. These consist of WAM instructions along with instructions to manage each kind of parallelism. A complete description of the PDP data structures and instructions can be found in <ref> [Ara94, Ara97] </ref>. The detailed refinement steps arriving to the PDP architecture are not included in this work but can be found elsewhere [Ara96]. 3 Parallel SLD subtrees From now on this work will deal with logic programs annotated with parallelism.
Reference: [Bei96] <author> Beierle, C., Borger, E.: </author> <title> "Specification and correctness proof of a WAM extension with abstract type constraints"; Formal Aspects of Computing, </title> <type> 8, </type> <month> 4 </month> <year> (1996), </year> <pages> 428-462. </pages> <editor> 601Araujo L.: </editor> <title> Correctness Proof of a Distributed Implementation of Prolog </title> ... 
Reference-contexts: Then, using WAM correctness as an starting point, some extensions of Prolog have been specified or verified; e.g. Beierle and Borger <ref> [Bei96] </ref> have provided a specification and correctness proof of a Prolog extended with abstract type constraints. This extension is focused on the representation and unification of terms, where the type of the constraints has to be considered.
Reference: [Bor93] <author> Borger, E., Riccobene, E.: </author> <title> "A Formal Specification of Parlog"; Semantics of Programming Languages and Model Theory (M. </title> <editor> Droste, Y. Gurevich, Eds.), </editor> <publisher> Gordon and Breach (1993), </publisher> <pages> 1-42. </pages>
Reference-contexts: Some of them make a detailed description of a language or a system architecture: the operational semantics of Occam is described in [Gur89, Bor94a]; the semantics of the concurrent logic programming language Parlog has been represented by an ASM <ref> [Bor93] </ref>; the architecture of the Parallel Virtual Machine (PVM), a software system to manage a heterogeneous set of computers as a distributed memory system, has been defined to provide a correct understanding of the system at the C-interface level [Bor94c].
Reference: [Bor94a] <author> Borger, E.,Durdanovic, I., Rosenzweig, D.: </author> <title> "Occam: Specification and Compiler Correctness" (E.-R. </title> <editor> Olderog, Ed.), </editor> <booktitle> Proc. PROCOMET'94 (IFIP Working Conference on Programming Concepts, Methods and Calculi), North-Holland (1994), </booktitle> <pages> 489-508. </pages>
Reference-contexts: Many programming languages and systems have also been specified or verified by using ASMs. Some of them make a detailed description of a language or a system architecture: the operational semantics of Occam is described in <ref> [Gur89, Bor94a] </ref>; the semantics of the concurrent logic programming language Parlog has been represented by an ASM [Bor93]; the architecture of the Parallel Virtual Machine (PVM), a software system to manage a heterogeneous set of computers as a distributed memory system, has been defined to provide a correct understanding of the
Reference: [Bor94b] <author> Borger, E., Lopez-Fraguas, F.J., Rodriguez-Artalejo, M.: </author> <title> "A model for mathematical analysis of functional logic programs and their implementations"; Proc. </title> <booktitle> World Computer Congress, North-Holland (1994), </booktitle> <pages> 410-415. </pages>
Reference-contexts: another system: Borger and Mazzanti [Bor97] present a correctness proof for pipelining with respect to the sequential model in RISC architectures; Borger and Dur-danovic present a proof of correctness of transputer code with respect to Occam [Bor96]; a graph narrowing machine is derived from the functional logic programming language BABEL <ref> [Bor94b] </ref>; using the technique of successive refinements, Borger and Rosenzweig [Bor95a] reconstructed the Warren Abstract Machine (WAM) [Warr83] (a virtual machine model which underlies most of the current Prolog implementations) from a Prolog specification ASM.
Reference: [Bor94c] <author> Borger, E., Glasser, U.: </author> <title> "A formal Specification of the PVM Architecture"; Proc. </title> <booktitle> IFIP 13th World Computer Congress, Volume I, </booktitle> <publisher> Elsevier, </publisher> <year> (1994), </year> <pages> 402-409. </pages>
Reference-contexts: concurrent logic programming language Parlog has been represented by an ASM [Bor93]; the architecture of the Parallel Virtual Machine (PVM), a software system to manage a heterogeneous set of computers as a distributed memory system, has been defined to provide a correct understanding of the system at the C-interface level <ref> [Bor94c] </ref>.
Reference: [Bor95a] <author> Borger, E., Rosenzweig, D.: </author> <title> "The WAM Definition and compiler correctness"; Logic Programming: Formal methods and Practical Applications. </title> <editor> Beierle, C., y Plumer, L. eds. </editor> <booktitle> North-Holland Series in Computer Science and Artificial Intelligence (1995), </booktitle> <pages> 21-90. </pages>
Reference-contexts: for pipelining with respect to the sequential model in RISC architectures; Borger and Dur-danovic present a proof of correctness of transputer code with respect to Occam [Bor96]; a graph narrowing machine is derived from the functional logic programming language BABEL [Bor94b]; using the technique of successive refinements, Borger and Rosenzweig <ref> [Bor95a] </ref> reconstructed the Warren Abstract Machine (WAM) [Warr83] (a virtual machine model which underlies most of the current Prolog implementations) from a Prolog specification ASM. Then, using WAM correctness as an starting point, some extensions of Prolog have been specified or verified; e.g. <p> The aim of this work is to use ASMs to provide a specification and a proof of correctness for the system PDP (Prolog Distributed Processor) [Ara94, Ara97]. To achieve this we again take WAM's proof of correctness for granted. The proof given by Borger and Rosenzweig <ref> [Bor95a] </ref> to verify the WAM consists of a number of refinement steps leading from an ASM, (A; R), closer to the Prolog model, to an ASM, (B; S), closer to the execution system. <p> The idea is to define a universe OR TASK whose elements correspond to a depth-first, left to right execution of a parallel SLD subtree. The Prolog tree representation proposed in <ref> [Bor95a] </ref>, extended to deal with parallelism, has been adopted as a submachine which models the execution of the goals inside each task. The computation inside each OR task is modeled by a NODE submachine, an adaptation of the one proposed by Borger and Rosenzweig [Bor95a] for the whole SLD tree: (N <p> The Prolog tree representation proposed in <ref> [Bor95a] </ref>, extended to deal with parallelism, has been adopted as a submachine which models the execution of the goals inside each task. The computation inside each OR task is modeled by a NODE submachine, an adaptation of the one proposed by Borger and Rosenzweig [Bor95a] for the whole SLD tree: (N ODE; root; currnode; f ather) with the function f node : OR T ASK ! N ODE The function f node provides the currnode of the task. In order to make the paper selfcontained, the ASM proposed as initial level in [Bor95a] is outlined <p> and Rosenzweig <ref> [Bor95a] </ref> for the whole SLD tree: (N ODE; root; currnode; f ather) with the function f node : OR T ASK ! N ODE The function f node provides the currnode of the task. In order to make the paper selfcontained, the ASM proposed as initial level in [Bor95a] is outlined here. For a complete explanation of the rules of the node machine see the work by Borger and Rosenzweig [Bor95a]. Let us call act (activator) the selected literal of a node n. <p> In order to make the paper selfcontained, the ASM proposed as initial level in <ref> [Bor95a] </ref> is outlined here. For a complete explanation of the rules of the node machine see the work by Borger and Rosenzweig [Bor95a]. Let us call act (activator) the selected literal of a node n. For n they are created as many sons as unlabeled alternatives there are to solve act. Each son has associated a candidate clause of the program. <p> The mentioned switching modes are represented by a distinguished element mode 2 fCall; Selectg. Now, in order to complete the description of this level we have to complete the signature and to define the transition rules. We assume the universes of Prolog literals, goals, terms and clauses of <ref> [Bor95a] </ref>: LI T; GOAL = LI T fl ; T ERM; CLAU SE The computation state of a node is associated by functions on universe NODE. The representation of the cut (!) operator at this level follows the one of [Bor95a]. <p> the universes of Prolog literals, goals, terms and clauses of <ref> [Bor95a] </ref>: LI T; GOAL = LI T fl ; T ERM; CLAU SE The computation state of a node is associated by functions on universe NODE. The representation of the cut (!) operator at this level follows the one of [Bor95a]. The goals waiting for execution in a state are not represented linearly, but as subsequences in which clause bodies are decorated with cutpoints to which they are to return in case of backtracking. <p> It is also assumed a substitution concatenating function ffi. As in <ref> [Bor95a] </ref>, the renaming of variables is represented by the function: rename : T ERM fi N ! T ERM which renames the variables of the term with the given index. The current renaming index is given by the 0-ary function vi. <p> The current renaming index is given by the 0-ary function vi. Furthermore, we will use all the usual list operations adopting standard notation. hd and bdy are also used to select head and body of clauses, respectively. As in <ref> [Bor95a] </ref>, it is still used an abstract universe CODE of clause occurrences, with the functions cll (n) being the candidate clause occurrence of a candidate son n of a computation state, and clause (p) being the clause pointed to by p. <p> The parameter currnode is usually abbreviated in the rules (f ather f ather (currnode), cands cands (currnode), s s (currnode) and decglseq decglseq (currnode). The query success rule is modified with respect to the one in <ref> [Bor95a] </ref> in order to view Prolog as returning all solutions. This rule triggers backtracking if all done then backtrack where all done represents decglseq = [ ]. <p> Rules call, selection and query success of the NODE machine by Borger and Rosenzweig <ref> [Bor95a] </ref> have to be modified to introduce the new data representation. <p> For instance, the success path of T 3 indicates that when solving the goal a the first clause in the procedure has to be chosen, and the same for the goal b. The process for the remaining tasks follows the same scheme. The node classification proposed in <ref> [Bor95a] </ref> can be applied to the nodes of a task. <p> Lemma 4.1 Given a pure Prolog program and a query, every visited node of a task corresponds to a node of the parallel SLD subtree with the same success path and the same substitution as the visited node. Proof Borger and Rosenzweig <ref> [Bor95a] </ref> have proved that given a pure Prolog program and a query, every visited node of the Prolog tree corresponds to a node of the SLD-tree with the same substitution. It has been showed by induction over the time of the first visit (number of rule executions preceding). <p> It has been showed by induction over the time of the first visit (number of rule executions preceding). Induction step follows from the Select rule together with the definition of SLD-tree and candidate clause. Since the Select rule of <ref> [Bor95a] </ref> has been maintained in the task tree representation and since theorem 3.1 establishes a one-to-one correspondence between the branches in the SLD tree and those of the parallel subtrees, the same result is fulfilled. <p> Lemma 4.2 Given a pure Prolog program and a query, every abandoned node of a task corresponds to a failure node of the parallel SLD subtree with the same success path as the abandoned node. Proof Borger and Rosenzweig <ref> [Bor95a] </ref> have proved that given a pure Prolog program and a query, every abandoned node of the Prolog tree corresponds to a failed node of the SLD-tree. It has been showed by induction over the abandonment time. Because of theorem 3.1 this result is extended to parallel SLD subtrees. <p> The task model of this section turns out to be correct and complete wrt that of 6 as it is shown in [Ara96]. 8 Introducing Stacks in the Tasks In a way similar to the step from Trees to Stack in <ref> [Bor95a] </ref>, the path of active nodes in a task may be viewed as a stack, if cands list are represented elsewhere. <p> CODEAREA clause : CODEAREA ! CLAU SE + fnilg procdef : LI T fi P ROGRAM ! CODEAREA 595Araujo L.: Correctness Proof of a Distributed Implementation of Prolog ... procdef now yields an element of CODEAREA, i.e. a pointer, instead of a list; the old list can easily be reconstructed <ref> [Bor95a] </ref>. The information contained in currnode is separated from other active nodes, by recording the former in 0-ary functions. <p> (for backtracking). b 2 ST AT E b : ST AT E ! ST AT E replacing the previous NODE submachine (N ODE; root; currnode; f ather) by the statetree ASM (ST AT E; bottom; b; b) More formally, it will be the mapping F proposed by Borger and Rosenzweig <ref> [Bor95a] </ref> the one which maps stack elements to task nodes as: (decglseq; s; cll; b; bottom; vi) ! (node; root; vi)) where the node decorations in the task are recovered from the registers and the decorations of the stack elements as follows: decglseq (currnode) = decglseq s (currnode) = s cands <p> cands (F (n)) = mk cands (F (n), cll) father (F (n)) = F (b (n)) F (bottom) = root where: mk cands (Node, Cll) if clause (Cll) = nil then [ ] else [hN ode; Cllijmk cands (N ode; Cll + +)] This F is the one adopted in <ref> [Bor95a] </ref> when the state ASM is introduced, but adding the new data structures corresponding to the success path and to the cpe list. Assuming the representation of data proposed in [Bor95a] (DAT AAREA; +; ; val); where +; : DAT AAREA ! DAT AAREA val : DAT AAREA ! P O <p> then [ ] else [hN ode; Cllijmk cands (N ode; Cll + +)] This F is the one adopted in <ref> [Bor95a] </ref> when the state ASM is introduced, but adding the new data structures corresponding to the success path and to the cpe list. Assuming the representation of data proposed in [Bor95a] (DAT AAREA; +; ; val); where +; : DAT AAREA ! DAT AAREA val : DAT AAREA ! P O + M EM ORY 596 Araujo L.: Correctness Proof of a Distributed Implementation of Prolog ... where P O (for Prolog Objects) is a universe supplied with functions type : <p> As it is stated in <ref> [Bor95a] </ref>, the "stacks" maintain the node tree structure corresponding to a task: they are not discarded when they are "popped" on backtracking, but they are still there and may be used when needed. <p> Assuming F on rules as homonymy, the commutativity of the rule executions is obtained with F , giving Prop 8.1 The stack model of 8 is correct and complete wrt sets of Prolog nodes. 8.1 Optimization in the creation of choicepoints In the analysis of <ref> [Bor95a] </ref>, an optimization is introduced at this point of the construction of the stacks. The aim of this optimization is not to create a choice point if the selected unifying clause fails. <p> Old Call mode will retain its role. A new 0-ary function (`cutpoint register') ct 2 ST AT E is introduced. It will, in call mode, store b's old value in order to find it in Enter mode. (See <ref> [Bor95a, Ara96] </ref> for details). 9 Predicates structure: OR parallelism The code for the extended WAM which corresponds to OR parallelism exploitation appears when the disjunctive structure of Prolog predicates is considered. As in [Bor95a], a predicate is represented as a sequence of instructions to manage choicepoints. <p> As in <ref> [Bor95a] </ref>, a predicate is represented as a sequence of instructions to manage choicepoints. This leads to slightly modify the signature. cll and clause are replaced with p (for `program pointer') and code, assuming a special location start. <p> I N ST R = f try me else (N ); retry me else (N ); trust me (N ); try (N ); retry (N ); trust (N ) try par (N ); retry par (N )jN 2 CODEAREAg The INSTR universe has been enlarged with respect the one of <ref> [Bor95a] </ref> at this point with the parallel instructions. Besides, it will be more enlarged in the sequel, as more WAM and specific PDP instructions are introduced. <p> The same remarks of <ref> [Bor95a] </ref> in the corresponding stage of abstraction allow to establish that the model of 9 is correct and complete wrt that of 8 (see [Ara96] for details). 10 Clause structure: AND parallelism The PDP extension to the WAM for the exploitation of AND parallelism appears when the compilation of clause structure <p> Following the Borger and Rosenzweig analysis, this section deals only with simplified clause structure (using only instructions for environments and parallel call ((de )allocation, unification and calling). Thus, terms and substitutions are considered independently and the analysis of <ref> [Bor95a] </ref> is adopted directly for them. Viewing decglseq as a stack, the previous model may be seen as a stack of stacks, which contains common structures. <p> In general, when a clause is considered a new environment is allocated, containing the data necessary to 598 Araujo L.: Correctness Proof of a Distributed Implementation of Prolog ... continue the computation once the goals of the body are solved. Following the scheme of <ref> [Bor95a] </ref>, it is defined a universe EN V with functions cg : EN V ! GOAL cutpt : EN V ! ST AT E ce : EN V ! EN V where cg is the continuation goal, and ce links the environment stack (for continuation environment). <p> common bottom ST ACK ST AT E; EN V; P CE; markers : ST ACK ! ST ACK bottom 2 ST AT E " EN V " P CE " markers The proof map to the model of the previous section will be defined by extending the proof map of <ref> [Bor95a] </ref> at this abstraction level, turning out that the current model is correct and complete wrt to that of 9. 599Araujo L.: Correctness Proof of a Distributed Implementation of Prolog ... 10.1 Compilation of clause structure As in [Bor95a], a function to produce code for a clause is assumed. <p> the previous section will be defined by extending the proof map of <ref> [Bor95a] </ref> at this abstraction level, turning out that the current model is correct and complete wrt to that of 9. 599Araujo L.: Correctness Proof of a Distributed Implementation of Prolog ... 10.1 Compilation of clause structure As in [Bor95a], a function to produce code for a clause is assumed. <p> The state component of the proof map F proposed in <ref> [Bor95a] </ref> at this level is extended here (see [Ara96] for details) yielding correctness and completeness of the model of 10.1 wrt that of 10. 11 Completing the model The next step in the process is to take into account the representation of terms and substitutions. <p> This leads to introduce new universes that are submachines of DATAAREA. These new universes lead to the appearance of the Heap and the Trail, as well as the putting and getting instructions. Since the remaining refinement steps consist in the direct application of the transformation of <ref> [Bor95a] </ref> to the PDP model, I refer to this work for those steps. 12 Conclusions This work provides a specification and proof of correctness for the system PDP (Prolog Distributed Processor), as well as for the abstract machine designed for it, by means of ASMs. <p> Completeness is restricted to the special case in which each branch of the SLD tree corresponds to a different parallel SLD subtree. The execution of the parallel SLD subtree corresponding to each task is modeled by a NODE submachine which extends the one proposed by Borger and Rosenzweig <ref> [Bor95a] </ref> to model the sequential execution of Prolog. In this way the result of this work allows to avoid the verification of common points. Several of the following steps reproduce the scheme developed in [Bor95a], though introducing at each level the objects required to manage parallelism. 600 Araujo L.: Correctness Proof <p> task is modeled by a NODE submachine which extends the one proposed by Borger and Rosenzweig <ref> [Bor95a] </ref> to model the sequential execution of Prolog. In this way the result of this work allows to avoid the verification of common points. Several of the following steps reproduce the scheme developed in [Bor95a], though introducing at each level the objects required to manage parallelism. 600 Araujo L.: Correctness Proof of a Distributed Implementation of Prolog ...
Reference: [Bor95b] <author> Borger, E., Salomone, R.: </author> <title> "CLAM specification for provably correct compilation of CLP(R) programs"; Specification and Validation Methods (Borger, </title> <editor> E. eds.), </editor> <publisher> Oxford Univ. Press (1995), </publisher> <pages> 97-130. </pages>
Reference: [Bor96] <author> Borger, E., Durdanovic, I.: </author> <title> "Correctness of Compiling Occam to Transputer Code"; The Computer Journal, </title> <type> 39, </type> <month> 1 </month> <year> (1996), </year> <pages> 52-92. </pages>
Reference-contexts: provide a proof of correctness with respect to the specification of a language or another system: Borger and Mazzanti [Bor97] present a correctness proof for pipelining with respect to the sequential model in RISC architectures; Borger and Dur-danovic present a proof of correctness of transputer code with respect to Occam <ref> [Bor96] </ref>; a graph narrowing machine is derived from the functional logic programming language BABEL [Bor94b]; using the technique of successive refinements, Borger and Rosenzweig [Bor95a] reconstructed the Warren Abstract Machine (WAM) [Warr83] (a virtual machine model which underlies most of the current Prolog implementations) from a Prolog specification ASM.
Reference: [Bor97] <author> Boerger, E., Mazzanti, S.: </author> <title> "A Practical Method for Rigorously Controllable Hardware Design"; (Bowen, </title> <editor> J.P., Hinchey, M.G., Till, D., Eds.), ZUM'97: </editor> <title> The Z Formal Specification Notation, </title> <publisher> Springer LNCS 1212 (1997), </publisher> <pages> 151-187. </pages>
Reference-contexts: In some cases ASMs have been used not only to specify the system but also to provide a proof of correctness with respect to the specification of a language or another system: Borger and Mazzanti <ref> [Bor97] </ref> present a correctness proof for pipelining with respect to the sequential model in RISC architectures; Borger and Dur-danovic present a proof of correctness of transputer code with respect to Occam [Bor96]; a graph narrowing machine is derived from the functional logic programming language BABEL [Bor94b]; using the technique of successive
Reference: [Gup93] <author> Gupta, G., Hermenegildo, M., Costa, </author> <title> V.S.: "And-Or parallel Prolog: A recomputation based approach"; New Generation Computing, </title> <type> 11, </type> <month> 3 </month> <year> (1993), </year> <pages> 297-322. </pages>
Reference-contexts: Finally, systems which combine both kinds of parallelism, such as ACE <ref> [Gup93] </ref>, can also take advantage of a number of steps in the verification of PDP. Acknowledgement I would like to thank the anonymous referees for making many useful comments and suggestions which have helped to improve the paper.
Reference: [Gur88] <author> Gurevich, Y.: </author> <title> "Logic and the challenge of computer science"; Currents trains in theoretical computer science, </title> <editor> (Borger, E. eds.), </editor> <publisher> Computer Science Press (1988), </publisher> <pages> 1-57. </pages>
Reference: [Gur89] <author> Gurevich, Y., Moss, </author> <title> L.S.: "Algebraic Operational Semantics and Occam"; CSL'89, </title> <booktitle> Lecture Notes in Computer Science 440, </booktitle> <publisher> Springer-Verlag (1990), </publisher> <pages> 176-192. </pages>
Reference-contexts: Many programming languages and systems have also been specified or verified by using ASMs. Some of them make a detailed description of a language or a system architecture: the operational semantics of Occam is described in <ref> [Gur89, Bor94a] </ref>; the semantics of the concurrent logic programming language Parlog has been represented by an ASM [Bor93]; the architecture of the Parallel Virtual Machine (PVM), a software system to manage a heterogeneous set of computers as a distributed memory system, has been defined to provide a correct understanding of the
Reference: [Gur91] <author> Gurevich, Y.: </author> <title> "Evolving Algebras. </title> <booktitle> A tutorial introduction"; Bulletin of the European Association for Theoretical Computer Science, </booktitle> <volume> 43, </volume> <year> (1991). </year>
Reference-contexts: 1 Introduction Abstract State machines (ASMs) (or Gurevich ASMs) are a useful tool to express and verify algorithms in a precise way. Originally, the idea was to provide operational semantics for programs and programming languages by improving Turing's thesis <ref> [Gur91] </ref> |according to which every algorithm can be simulated by an appropriate Turing machine. Translating a given algorithm into a Tur-ing machine may, however, be very tedious because every step of the algorithm may require a long sequence of steps of the Turing machine. <p> Thus, each level is represented by means of an ASM consisting of a pair (A; R), where A is a set of domains with partial functions, and R is a finite system of transition rules <ref> [Gur91] </ref>. ASMs also provide a powerful and simple mechanism for information hiding and definition of the precise interface by means of external functions. Any function g not appearing in any update of the transition rules R is called external for R and for the ASM corresponding to R.
Reference: [Her86] <author> Hermenegildo, M.: </author> <title> "An abstract Machine Based Execution Model for Computer Architecture Design and Efficient Implementation of Logic Program in Parallel"; PhD thesis, </title> <type> U. </type> <institution> of Texas at Austin (1986). </institution>
Reference-contexts: The PDP verification not only provides correctness results for this particular system but it can be readily adapted to other related parallel systems. In this way, since the PDP approach to exploit AND parallelism is an extension for distributed memory systems of the RAP model <ref> [Her86] </ref>, the verification of this model is also obtained as a particular case. In the same way the verification of the OR parallel exploitation by recomputation may be easily adapted to systems which use a different method for the exploitation of OR parallelism, such as the copying in MUSE [Ali90]. <p> Independent AND parallelism is exploited by following a fork-join approach, which is an extension for distributed memory systems of the one followed in the RAP model <ref> [Her86] </ref>. Each goal in a parallel call, set of independent goals annotated to be executed in parallel, is executed in a different processor, if available. Thus, the results of the execution of each goal are collected in the parent processor (the one finding the parallel call). <p> This process leads to the WAM extension which underlies the architecture of PDP. Communication and scheduling are modeled as external functions. The scheme we have followed to verify PDP can also be applied to other parallel systems. Thus, the RAP model <ref> [Her86] </ref>, whose extension for distributed memory systems, has been adopted to exploit AND parallelism in PDP, can be verified as a particular case of PDP when OR parallelism does not appear.
Reference: [Warr83] <author> Warren, D.H.D.: </author> <title> "An Abstract Prolog Instruction Set"; Tech. Note 309, SRI International (1983). 602 Araujo L.: Correctness Proof of a Distributed Implementation of Prolog </title> ... 
Reference-contexts: model in RISC architectures; Borger and Dur-danovic present a proof of correctness of transputer code with respect to Occam [Bor96]; a graph narrowing machine is derived from the functional logic programming language BABEL [Bor94b]; using the technique of successive refinements, Borger and Rosenzweig [Bor95a] reconstructed the Warren Abstract Machine (WAM) <ref> [Warr83] </ref> (a virtual machine model which underlies most of the current Prolog implementations) from a Prolog specification ASM. Then, using WAM correctness as an starting point, some extensions of Prolog have been specified or verified; e.g. <p> Each worker operates on its own private memory and interprocessor communication is performed only by the passing of messages. A worker executes a task of any type until it is finished, then executes a new one, and so on. Every worker implements an extension of the WAM <ref> [Warr83] </ref> consisting in the addition of new data structures and instructions related to parallelism. The success stack and the success pointer (SP) have been added to record the success path. Other data structures have been introduced with the purpose of synchronizing the execution of a parallel call.
References-found: 21

