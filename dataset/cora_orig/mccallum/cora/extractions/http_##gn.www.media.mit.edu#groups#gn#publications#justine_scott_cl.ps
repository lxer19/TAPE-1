URL: http://gn.www.media.mit.edu/groups/gn/publications/justine_scott_cl.ps
Refering-URL: http://gn.www.media.mit.edu/groups/gn/publications.html
Root-URL: http://www.media.mit.edu
Title: Embodied Natural Language Generation: A Framework for the Generation of Speech and Gesture  
Author: Justine Cassell Scott Prevost 
Affiliation: The MIT Media Laboratory  
Abstract: While the extant literature on natural language generation deals primarily with the production of written language, we present a framework for generating embodied, spoken language with context-appropriate intonation contours and manual gestures. We show how information structure models discourse context and serves as a representational link between intonational and gestural phenomena. This framework also accounts for the complementarity of semantic features across communicative modalities, so that gesture and speech need not always convey redundant information. Finally, we show how this framework fits into a computational architecture involving separate content planning and sentence planning phases. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alibali, M. W., L. Flevares, and S. Goldin-Meadow. </author> <year> 1994. </year> <title> Going beyond what children say to assess their knowledge. </title> <type> Manuscript, </type> <institution> Department of Psychology, University of Chicago. </institution>
Reference: <author> Bolinger, Dwight. </author> <year> 1972. </year> <title> Accent is predictable (if you're a mind reader). </title> <booktitle> Language, </booktitle> <volume> 48 </volume> <pages> 633-644. </pages> <booktitle> 41 Computational Linguistics Volume , Number Bolinger, Dwight. </booktitle> <year> 1983. </year> <title> Intonation and gesture. </title> <journal> American Speech, </journal> <volume> 58(2) </volume> <pages> 156-174. </pages>
Reference-contexts: Fortunately, when we arrived at the BEACH, the weather turned BEAUTIFUL. Given the semantic nature of intonational patterns and the obvious contextual effects, predicting the distribution of pitch accents for a given utterance is indeed difficult. In broad terms, <ref> (Bolinger, 1972) </ref> defined the problem as semantic highlighting, whereby lexical items are stressed based on their contextual interest, or roughly speaking, how much they contribute to the hearer's model of the conversation.
Reference: <author> Bolinger, Dwight. </author> <year> 1989. </year> <title> Intonation and Its Uses. </title> <publisher> Stanford University Press. </publisher>
Reference: <author> Bolt, Richard A. </author> <year> 1980. </year> <title> Put that there: Voice and gesture at the graphics interface. </title> <journal> Computer Graphics, </journal> <volume> 14(3) </volume> <pages> 262-270. </pages>
Reference: <author> Bolt, Richard A. </author> <year> 1987. </year> <title> The integrated multi-Modal interface. </title> <journal> Transactions of the Institute of Electronics, Information and Communication Engineers, J79-D(11):2017-2025. </journal>
Reference: <author> Cassell, Justine and David McNeill. </author> <year> 1991. </year> <title> Gesture and the poetics of prose. </title> <journal> Poetics Today, </journal> <volume> 12(3) </volume> <pages> 375-404. </pages>
Reference-contexts: Most discussed in the literature is the fact that gesture can represent the point of view of the speaker when this is not necessarily conveyed by speech <ref> (Cassell and McNeill, 1991) </ref>.
Reference: <editor> Cassell, Justine, David McNeill, and K. E. McCullough. in press. Speech-gesture mismatches: </editor> <title> Evidence for one underlying representation of linguistic and non-linguistic information. </title> <journal> Cognition. </journal>
Reference: <author> Cassell, Justine, Catherine Pelachaud, Norman Badler, Mark Steedman, Brett Achorn, Tripp Becket, Brett Douville, Scott Prevost, and Matthew Stone. </author> <year> 1994. </year> <title> Animated conversation: Rule-based generation of facial expression, gesture and spoken intonation for multiple conversational agents. </title> <booktitle> Computer Graphics (SIGGRAPH Proceedings). </booktitle>
Reference-contexts: the beginning of an utterance, and the hands fall at the end of the utterance along with the final intonational marking.(Kendon, 1972) * Second, the most effortful part of the gesture (the "stroke") co-occurs with the pitch accent, or most effortful part of enunciation. * Third, as we hypothesized in <ref> (Cassell et al., 1994) </ref>, one is most likely to find gestures co-occuring with the rhematic part of speech, just as we find particular intonational tunes co-occuring with the rhematic part of speech. <p> So, we need a discourse framework that allows us to flag the conditions under which information receives "overmarking" (i.e. expression by two modalities). In previous work <ref> (Cassell et al., 1994) </ref> we claimed that one is most likely to find gestures co-occuring with the rhematic part of speech, just as we find particular intonational tunes co-occuring with the rhematic part of speech. <p> That is, whether information is conveyed in gesture is determined by the retrievability of the information 27 Computational Linguistics Volume , Number "No, he just runs." conveyed, and the contrast set of discourse entities. The idea is fundamentally the same as that proposed in <ref> (Cassell et al., 1994) </ref>: gestures overmark, or add redundancy, in those contexts where information is least predictable or least easy to retrieve. We add, however, the insight that gestures are sometimes found with non-rhematic material, and that focus plays a role in determining redundancy. <p> The division of utterances into theme and rheme at the content planning stage of generation also dictates the alignment of gestures. In our previous work <ref> (Cassell et al., 1994) </ref>, gestures were placed to co-occur with the rhematic material. Based on our more recent research, described in the previous section, we now believe that some gestures may occur with thematic material in contrastive contexts. <p> As described above, path gestures are commonly found as non-redundant gestures in English, as path is not commonly conveyed in the verb. The first two iconic gestures are shown in Figure 8. This implementation differs from our prior work <ref> (Cassell et al., 1994) </ref> in the following way. In our previous dialogue generation, intonation was determined on the basis of a variant of the previous mention strategy rather the more robust contrastive stress model presented here and in Prevost (1996a).
Reference: <author> Cassell, Justine and Scott Prevost. </author> <year> 1996. </year> <title> Distribution of semantic features across speech and gesture by humans and machines. </title> <booktitle> In Proceedings of the Workshop on the Integration of Gesture in Language and Speech, </booktitle> <address> Wilmington, DE. </address>
Reference-contexts: This temporal phase information is correlated with function <ref> (Cassell and Prevost, 1996) </ref>. Iconics and metaphorics are the gestures which carry meaning by way of handshape as well as trajectory. It is the second phase which carries this semantic information. <p> In fact, such a correlation between physical information and gesture type can enable automatic machine recognition of gesture type, and potentially bootstrap the interpretation of the information conveyed by gesture in interactive systems <ref> (Wilson, Bobick, and Cassell, 1996) </ref>. As far as the culturally specific nature of gesture is concerned, emblems do vary widely among different language communities. The four gesture types described, however, have appeared in narrations in a very wide variety of languages.
Reference: <author> Cassell, Justine, Matthew Stone, Brett Douville, Scott Prevost, Brett Achorn, Mark Steedman, Norm Badler, and Catherine Pelachaud. </author> <year> 1994. </year> <title> Modeling the interaction between speech and gesture. </title> <booktitle> In Proceedings of the Sixteenth Conference of the Cognitive Science Society, </booktitle> <address> Atlanta. </address>
Reference-contexts: the beginning of an utterance, and the hands fall at the end of the utterance along with the final intonational marking.(Kendon, 1972) * Second, the most effortful part of the gesture (the "stroke") co-occurs with the pitch accent, or most effortful part of enunciation. * Third, as we hypothesized in <ref> (Cassell et al., 1994) </ref>, one is most likely to find gestures co-occuring with the rhematic part of speech, just as we find particular intonational tunes co-occuring with the rhematic part of speech. <p> So, we need a discourse framework that allows us to flag the conditions under which information receives "overmarking" (i.e. expression by two modalities). In previous work <ref> (Cassell et al., 1994) </ref> we claimed that one is most likely to find gestures co-occuring with the rhematic part of speech, just as we find particular intonational tunes co-occuring with the rhematic part of speech. <p> That is, whether information is conveyed in gesture is determined by the retrievability of the information 27 Computational Linguistics Volume , Number "No, he just runs." conveyed, and the contrast set of discourse entities. The idea is fundamentally the same as that proposed in <ref> (Cassell et al., 1994) </ref>: gestures overmark, or add redundancy, in those contexts where information is least predictable or least easy to retrieve. We add, however, the insight that gestures are sometimes found with non-rhematic material, and that focus plays a role in determining redundancy. <p> The division of utterances into theme and rheme at the content planning stage of generation also dictates the alignment of gestures. In our previous work <ref> (Cassell et al., 1994) </ref>, gestures were placed to co-occur with the rhematic material. Based on our more recent research, described in the previous section, we now believe that some gestures may occur with thematic material in contrastive contexts. <p> As described above, path gestures are commonly found as non-redundant gestures in English, as path is not commonly conveyed in the verb. The first two iconic gestures are shown in Figure 8. This implementation differs from our prior work <ref> (Cassell et al., 1994) </ref> in the following way. In our previous dialogue generation, intonation was determined on the basis of a variant of the previous mention strategy rather the more robust contrastive stress model presented here and in Prevost (1996a).
Reference: <author> Church, R. B. and S. Goldin-Meadow. </author> <year> 1986. </year> <title> The mismatch between gesture and speech as an index of transitional knowledge. </title> <journal> Cognition, </journal> <volume> 23 </volume> <pages> 43-71. </pages>
Reference-contexts: Gestures have also been shown to identify underlying reasoning processes that the speaker did not or could not articulate <ref> (Church and Goldin-Meadow, 1986) </ref>.
Reference: <author> Cohen, A. A. </author> <year> 1977. </year> <title> The communicative functions of hand illustrators. </title> <journal> Journal of Communication, </journal> <volume> 27(4) </volume> <pages> 54-63. </pages>
Reference: <author> Cohen, A. A. and R. P. Harrison. </author> <year> 1973. </year> <title> Intentionality in the use of hand illustrators in face-to-face communication situations. </title> <journal> Journal of Personality and Social Psychology, </journal> <volume> 28 </volume> <pages> 276-279. </pages>
Reference: <author> Dale, Robert and Nicholas Haddock. </author> <year> 1991. </year> <title> Content determination in the generation of referring expressions. </title> <journal> Computational Intelligence, </journal> <volume> 7(4) </volume> <pages> 252-265. </pages>
Reference-contexts: Since referring expressions are generally taken to be in the domain of the sentence planner <ref> (Dale and Haddock, 1991) </ref>, the present approach resolves issues of contrastive focus assignment at the sentence processing stage as well.
Reference: <author> Efron, D. </author> <year> 1941. </year> <title> Gesture and Environment. </title> <publisher> King's Crown Press, </publisher> <address> New York. </address>
Reference: <author> Ekman, P. and W. Friesen. </author> <year> 1969. </year> <title> The repertoire of nonverbal behavioral categories-origins, usages and coding. </title> <journal> Semiotica, </journal> <volume> 1 </volume> <pages> 49-98. </pages>
Reference: <author> Elhadad, Michael, Kathleen McKeown, and Jacques Robin. </author> <year> 1996. </year> <title> Floating constraints in lexical choice. </title> <note> Computational Linguistics. To appear. </note>
Reference-contexts: and speech do not convey the same content, how is content distributed across the modalities? Once the issue of redundancy has been dealt with, how do we represent the distribution of content? We believe that these questions are similar to those addressed by research on lexical choice in text generation <ref> (Elhadad, McKeown, and Robin, 1996) </ref>: in the same way as we must choose between "he hightailed it out of the room" and "he left the room," we must choose between generating the phrase "he drove down the road" and "he went down the road" paired with a driving gesture. 28 Cassell
Reference: <author> Engdahl, Elisabet and Enric Vallduv. </author> <year> 1994. </year> <title> Information packaging and grammar architecture: A constraint-based approach. </title> <editor> In E. Engdahl, editor, </editor> <title> Integrating Information Structure into Constraint-Based and Categorial Approaches (DYANA-2 Report R.1.3.B). </title> <address> CLLI, Amsterdam. </address>
Reference: <author> Goldin-Meadow, S., D. Wein, and C. Chang. </author> <year> 1992. </year> <title> Assessing knowledge through gesture: Using children's hands to read their minds. </title> <journal> Cognition and Instruction, </journal> <volume> 9(3) </volume> <pages> 201-219. </pages>
Reference: <author> Grosz, Barbara J. and Candace L. Sidner. </author> <year> 1986. </year> <title> Attentions, intentions and the structure of discourse. </title> <journal> Computational Linguistics, </journal> <volume> 12 </volume> <pages> 175-204. </pages>
Reference: <author> Hajicova, Eva and Petr Sgall. </author> <year> 1987. </year> <title> The ordering principle. </title> <journal> Journal of Pragmatics, </journal> <volume> 11 </volume> <pages> 435-454. </pages>
Reference: <author> Hajicova, Eva and Petr Sgall. </author> <year> 1988. </year> <title> Topic and focus of a sentence and the patterning of a text. In Janos Petofi, editor, Text and Discourse Constitution. </title> <publisher> De Gruyter, </publisher> <address> Berlin. </address>
Reference: <author> Halliday, Michael. </author> <year> 1967. </year> <title> Intonation and Grammar in British English. Mouton, The Hague. </title>
Reference: <author> Halliday, Michael. </author> <year> 1970. </year> <title> Language structure and language function. </title> <editor> In John Lyons, editor, </editor> <booktitle> New Horizons in Linguistics. </booktitle> <publisher> Penguin, </publisher> <pages> pages 140-165. </pages>
Reference: <author> Heim, Irene. </author> <year> 1983. </year> <title> File change semantics and the familiarity theory of definiteness. </title>
Reference: <editor> In Rainer Bauerle, Christoph Schwarze, and Arnim von Stechow, editors, </editor> <title> Meaning, Use and Interpretation of Language. </title> <publisher> W. de Gruyter, Berlin, </publisher> <pages> pages 164-189. </pages>
Reference: <author> Herzog, G. and P. Waxinski. </author> <year> 1994. </year> <title> VIsual TRAnslator: Linking perceptions and natural language descriptions. </title> <journal> Artificial Intelligence Review, </journal> <volume> 8 </volume> <pages> 175-187. </pages>
Reference-contexts: In the case of gesture, the decision about what kinds of content to represent in gesture has to do with what is perceptually salient in the scene being described <ref> (Herzog and Waxinski, 1994) </ref>, and with the language being spoken.
Reference: <author> Hirschberg, Julia. </author> <year> 1990. </year> <title> Accent and discourse context: Assigning pitch accent in synthetic speech. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 952-957. </pages> <booktitle> 42 Cassell and Prevost Embodied Natural Language Generation Hirschberg, Julia and Janet Pierrehumbert. </booktitle> <year> 1986. </year> <title> The intonational structuring of discourse. </title> <booktitle> In Proceedings of the 24th Annual Meeting of the Association for Computational Linguistics. </booktitle>
Reference-contexts: Hirschberg and Pierrehumbert (1986) showed how intonational features relate to attentional and intentional structures of discourse and how the choice of intonational contour can affect discourse interpretation <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. This research provides a compositional account of the meaning of intonational tunes based on the meanings of the intonational phenomena which comprise those tunes. 1.1.1 Intonational Components. <p> The H* accent, perhaps the most commonly used, has often been noted to correspond to items that are "new" to the discourse|i.e. items that have not been previously mentioned or made salient by implication <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. More generally, H* accents seem to mark the instantiation of the variable in the open proposition conveyed by the rest of the utterance (Prince, 1986), and to update the hearer's beliefs accordingly (Pierrehumbert and Hirschberg, 1990). <p> the discourse|i.e. items that have not been previously mentioned or made salient by implication <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. More generally, H* accents seem to mark the instantiation of the variable in the open proposition conveyed by the rest of the utterance (Prince, 1986), and to update the hearer's beliefs accordingly (Pierrehumbert and Hirschberg, 1990). This use of H* is illustrated in (1) below. 1 (1) Q: What about the beans? Who ate them? A: FRED H* L ate the BEANS. L+H* L-H% L+H* accents are commonly associated with the notion of contrast. <p> 1 In this example and throughout the remainder of this paper, items in capital letters bear some type of pitch accent. 8 Cassell and Prevost Embodied Natural Language Generation the variable in the open proposition conveyed by the rest of the utterance, and allows hearers to update their beliefs accordingly <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. Just as pitch accents have been associated with certain meanings or interpretive strategies, phrasal tones and boundaries are also amenable to such analysis. <p> beliefs accordingly <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. Just as pitch accents have been associated with certain meanings or interpretive strategies, phrasal tones and boundaries are also amenable to such analysis. The phrasal tones have been taken "to indicate the presence or absence of an interpretive as well as a phonological boundary" (Pierrehumbert and Hirschberg, 1990). Specifically we consider the L- phrasal tone to have the effect of delimiting segments that are to be interpreted separately. For example, in (1), the L- seems to mark the distinction between the core contribution of the utterance (i.e. Fred) and the established background.
Reference: <author> Hoffman, Beryl. </author> <year> 1995. </year> <title> The Computational Analysis of the Syntax and Interpretation of `Free' Word Order in Turkish. </title> <type> Ph.D. thesis, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia. </address>
Reference: <author> Hovy, Eduard. </author> <year> 1993. </year> <title> Automated discourse generation using discourse structure relations. </title> <journal> Artificial Intelligence, </journal> <volume> 63 </volume> <pages> 341-385. </pages>
Reference-contexts: Schema-based systems (McKeown, 1985), which have been widely used for this task with impressive results, form the basis for our content generator. Rhetorical structure theory (RST) approaches (Mann and Thompson, 1986), which organize texts by identifying rhetorical relations between clause-level propositions from a knowledge base, have also been developed <ref> (Hovy, 1993) </ref> and are particularly well-suited to handling theme and rheme level constituents. The present framework for organizing the content of a spoken monologue is a hybrid of the schema and RST approaches. The implementation produces descriptions of objects and events from a knowledge base.
Reference: <author> Jackendoff, Ray. </author> <year> 1972. </year> <title> Semantic Interpretation in Generative Grammar. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: L+H* L-H% L+H* accents are commonly associated with the notion of contrast. While H* accents are so strongly associated with (instantiated) variables in open propositions, L+H* accents seem particularly useful for marking contrast in the fully instantiated background part of the open proposition, as noted by <ref> (Jackendoff, 1972) </ref> and others, and demonstrated in (1). While it may be convenient in some cases to simply correlate H* accents with "new" information and L+H* accents with contrastive information, the situation is somewhat more complex.
Reference: <author> Kendon, A. </author> <year> 1972. </year> <title> Some relationships between body motion and speech. </title> <editor> In A. W. Siegman and B. Pope, editors, </editor> <title> Studies in Dyadic Communication. </title> <publisher> Pergamon Press, </publisher> <address> New York. </address>
Reference-contexts: In many cases, different modalities serve to reinforce one another, as when intonation contours serve to mark the most important word in an utterance, or when a speaker aligns the most effortful part of gestures with intonational prominences <ref> (Kendon, 1972) </ref>. In other cases, semantic and pragmatic attributes of the message are distributed across the modalities such that the full communicative intentions of the speaker are interpreted by combining linguistic and para-linguistic information.
Reference: <author> Kendon, A. </author> <year> 1980. </year> <title> Gesticulation and speech: Two aspects of the process. </title> <editor> In M. R. </editor> <title> Key, editor, The Relation Between Verbal and Nonverbal Communication. </title> <publisher> Mouton. </publisher>
Reference: <author> Kendon, A. </author> <year> 1993. </year> <title> Gestures as illocutionary and discourse structure markers in southern italian conversation. </title> <booktitle> In Proceedings of the Linguistic Society of America Symposium on Gesture in Context of Talk. </booktitle>
Reference-contexts: Examples of emblems in American culture are the thumb-and-index-finger ring gesture that signals `okay' or the `thumbs up' gesture. Many more of these "emblems" appear to exist in French and Italian culture than in America <ref> (Kendon, 1993) </ref>, but in few cultures do these gestures appear to constitute more than 10% of the gestures produced by speakers.
Reference: <author> Kuno, Susumo. </author> <year> 1976. </year> <title> Subject, theme and speaker's empathy: A reexamination of relativization phenomena. </title> <editor> In Charles Li, editor, </editor> <title> Subject and Topic. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <pages> pages 417-444. </pages>
Reference: <author> Lyons, John. </author> <year> 1977. </year> <title> Semantics, Volume II. </title> <publisher> Cambridge University Press. </publisher>
Reference: <author> Mann, W. and S. Thompson. </author> <year> 1986. </year> <title> Rhetorical structure theory: Description and construction of text structures. </title> <editor> In G. Kempen, editor, </editor> <booktitle> Natural Language Generation: New Results in Artificial Intelligence, Psychology and Linguistics. </booktitle> <publisher> Kluwer Academic Publishers, Boston, </publisher> <pages> pages 279-300. </pages>
Reference-contexts: Schema-based systems (McKeown, 1985), which have been widely used for this task with impressive results, form the basis for our content generator. Rhetorical structure theory (RST) approaches <ref> (Mann and Thompson, 1986) </ref>, which organize texts by identifying rhetorical relations between clause-level propositions from a knowledge base, have also been developed (Hovy, 1993) and are particularly well-suited to handling theme and rheme level constituents.
Reference: <author> McKeown, Kathleen, Karen Kukich, and James Shaw. </author> <year> 1994. </year> <title> Practical issues in automatic documentation generation. </title> <booktitle> In Proceedings of the Fourth ACL Conference on Applied Natural Language Processing, </booktitle> <pages> pages 7-14, </pages> <institution> Stuttgart. Association for Computational Linguistics. </institution>
Reference: <author> McKeown, Kathleen R. </author> <year> 1985. </year> <title> Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference-contexts: Schema-based systems <ref> (McKeown, 1985) </ref>, which have been widely used for this task with impressive results, form the basis for our content generator.
Reference: <author> McNeill, David. </author> <year> 1992. </year> <title> Hand and Mind: What Gestures Reveal about Thought. </title> <publisher> University of Chicago Press, Chicago. </publisher>
Reference-contexts: We suspect that hand gestures must be integral to the speech event when we examine their temporal relationship to other communicative phenomena. Hand gestures co-occur with their semantically parallel linguistic units, although in cases of hesitations, pauses or syntactically complex speech, it is the gesture which appears first <ref> (McNeill, 1992) </ref>. At the most local level, individual gestures and words are synchronized in time so that the stroke (most energetic part of the gesture) occurs either with or just before the intonationally most prominent syllable of the accompanying speech segment (Kendon, 1980; McNeill, 1992). <p> Speakers may say "left" and mean "right," but they will probably point towards the right. Listeners may correct speakers' errors, on the basis of the speaker's gestures <ref> (McNeill, 1992) </ref>. Gestures also play a role in structuring how information is packaged in a discourse. Gestures are found most often in co-occurence with the core idea of an utterance (Cassell et al., 1994; McNeill and Duncan, 1996).
Reference: <author> McNeill, David and Starkey Duncan. </author> <year> 1996. </year> <title> Language as gesture (gesture as language). </title> <booktitle> In Proceedings of the Workshop on the Integration of Gesture in Language and Speech, </booktitle> <address> Wilmington, DE. </address>
Reference-contexts: This effect can also be seen from a comparison of gesture and motion verbs in English and Spanish <ref> (McNeill and Duncan, 1996) </ref>. In English, where there are a number of manner-of-motion verbs available (e.g. run, hike, lope, jog, zip, etc.) the feature of manner in gesture seems only to appear in rhematic contexts (what McNeill refers to as "the core idea").
Reference: <author> Meteer, Marie. </author> <year> 1991. </year> <title> Bridging the generation gap between text planning and linguistic realization. </title> <journal> Computational Intelligence, </journal> <volume> 7(4) </volume> <pages> 296-304. </pages>
Reference: <author> Monaghan, Alex. </author> <year> 1991. </year> <title> Intonation in a Text-to-Speech Conversion System. </title> <type> Ph.D. thesis, </type> <institution> University of Edinburgh. </institution>
Reference: <author> Pelachaud, Catherine and Scott Prevost. </author> <year> 1995. </year> <title> Talking heads: Physical, linguistic and cognitive issues in facial animation. </title> <booktitle> Course Notes for Computer Graphics International '95. </booktitle>
Reference: <author> Pierrehumbert, Janet. </author> <year> 1980. </year> <title> The Phonology and Phonetics of English Intonation. </title> <type> Ph.D. thesis, </type> <institution> Massachusetts Institute of Technology. Distributed by Indiana University Linguistics Club, Bloomington, </institution> <note> IN. </note>
Reference: <author> Pierrehumbert, Janet and Julia Hirschberg. </author> <year> 1990. </year> <title> The meaning of intonational contours in the interpretation of discourse. </title> <editor> In Philip Cohen, Jerry Morgan, and Martha Pollock, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <pages> pages 271-312. </pages>
Reference-contexts: Hirschberg and Pierrehumbert (1986) showed how intonational features relate to attentional and intentional structures of discourse and how the choice of intonational contour can affect discourse interpretation <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. This research provides a compositional account of the meaning of intonational tunes based on the meanings of the intonational phenomena which comprise those tunes. 1.1.1 Intonational Components. <p> The H* accent, perhaps the most commonly used, has often been noted to correspond to items that are "new" to the discourse|i.e. items that have not been previously mentioned or made salient by implication <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. More generally, H* accents seem to mark the instantiation of the variable in the open proposition conveyed by the rest of the utterance (Prince, 1986), and to update the hearer's beliefs accordingly (Pierrehumbert and Hirschberg, 1990). <p> the discourse|i.e. items that have not been previously mentioned or made salient by implication <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. More generally, H* accents seem to mark the instantiation of the variable in the open proposition conveyed by the rest of the utterance (Prince, 1986), and to update the hearer's beliefs accordingly (Pierrehumbert and Hirschberg, 1990). This use of H* is illustrated in (1) below. 1 (1) Q: What about the beans? Who ate them? A: FRED H* L ate the BEANS. L+H* L-H% L+H* accents are commonly associated with the notion of contrast. <p> 1 In this example and throughout the remainder of this paper, items in capital letters bear some type of pitch accent. 8 Cassell and Prevost Embodied Natural Language Generation the variable in the open proposition conveyed by the rest of the utterance, and allows hearers to update their beliefs accordingly <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. Just as pitch accents have been associated with certain meanings or interpretive strategies, phrasal tones and boundaries are also amenable to such analysis. <p> beliefs accordingly <ref> (Pierrehumbert and Hirschberg, 1990) </ref>. Just as pitch accents have been associated with certain meanings or interpretive strategies, phrasal tones and boundaries are also amenable to such analysis. The phrasal tones have been taken "to indicate the presence or absence of an interpretive as well as a phonological boundary" (Pierrehumbert and Hirschberg, 1990). Specifically we consider the L- phrasal tone to have the effect of delimiting segments that are to be interpreted separately. For example, in (1), the L- seems to mark the distinction between the core contribution of the utterance (i.e. Fred) and the established background.
Reference: <author> Prevost, Scott. </author> <year> 1996a. </year> <title> An information structural approach to monologue generation. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 294-301, </pages> <address> Santa Cruz. </address>
Reference: <author> Prevost, Scott. </author> <year> 1996b. </year> <title> Modeling contrast in the generation and synthesis of spoken language. </title> <booktitle> In Proceedings of ICSLP '96: the Fourth International Conference on Spoken Language Processing. </booktitle>
Reference: <author> Prevost, Scott and Mark Steedman. </author> <year> 1993. </year> <title> Generating contextually appropriate intonation. </title> <booktitle> In Proceedings of the 6th Conference of the European Chapter of the Association for Computational Linguistics, </booktitle> <pages> pages 332-340, </pages> <address> Utrecht. </address>
Reference: <author> Prevost, Scott and Mark Steedman. </author> <year> 1994. </year> <title> Specifying intonation from context for speech synthesis. </title> <journal> Speech Communication, </journal> <volume> 15 </volume> <pages> 139-153. </pages>
Reference: <author> Prince, Ellen F. </author> <year> 1986. </year> <title> On the syntactic marking of the presupposed open proposition. </title> <journal> Journal of the Chicago Linguistic Society, </journal> <pages> pages 208-222. </pages> <note> 43 Computational Linguistics Volume , Number Quek, </note> <author> F. </author> <year> 1994. </year> <title> Toward a vision-based hand gesture interface. </title> <booktitle> In Proceedings of the Virtual Reality System Technology Conference, </booktitle> <pages> pages 17-29, </pages> <address> Singapore. </address>
Reference-contexts: More generally, H* accents seem to mark the instantiation of the variable in the open proposition conveyed by the rest of the utterance <ref> (Prince, 1986) </ref>, and to update the hearer's beliefs accordingly (Pierrehumbert and Hirschberg, 1990). This use of H* is illustrated in (1) below. 1 (1) Q: What about the beans? Who ate them? A: FRED H* L ate the BEANS.
Reference: <author> Rambow, Owen and Tanya Korelsky. </author> <year> 1992. </year> <title> Applied text generation. </title> <booktitle> In Proceedings of the Third Conference on Applied Natural Language Processing (ANLP-1992), </booktitle> <pages> pages 40-47. </pages>
Reference: <author> Reinhart, Tanya. </author> <year> 1981. </year> <title> Pragmatics and linguistics: an analysis of sentence topic. </title> <journal> Philosophica, </journal> <volume> 27 </volume> <pages> 53-94. </pages>
Reference: <author> Reiter, Ehud and Robert Dale. </author> <year> 1992. </year> <title> A fast algorithm for the generation of referring expressions. </title> <booktitle> In COLING 92: Proceedings of the 14th International Conference on Computational Linguistics, </booktitle> <pages> pages 232-238. </pages>
Reference: <author> Reiter, Ehud and Chris Mellish. </author> <year> 1992. </year> <title> Using classification to generate text. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 265-272. </pages>
Reference: <author> Rime, B. </author> <year> 1982. </year> <title> The elimination of visible behavior from social interactions: Effects of verbal, nonverbal and interpersonal variables. </title> <journal> European Journal of Social Psychology, </journal> <volume> 12 </volume> <pages> 113-129. </pages>
Reference-contexts: Does gesture play an communicative role for the participants during a speech event? We know that gestures are still produced in situations where there is no listener, or the listener cannot see the speaker's hands <ref> (Rime, 1982) </ref>, although more gestures may be produced when an addressee is present (Cohen, 1977; Cohen and Harrison, 1973). Thus it appears that gestures must serve some function for the speaker, independent of any communicative intent.
Reference: <author> Rochemont, Michael. </author> <year> 1986. </year> <title> Focus in Generative Grammar. </title> <publisher> John Benjamins, </publisher> <address> Philadelphia. </address>
Reference: <author> Rogers, W. T. </author> <year> 1978. </year> <title> The contribution of kinesic illustrators toward the comprehension of verbal behaviors within utterances. </title> <journal> Human Communication Research, </journal> <volume> 5 </volume> <pages> 54-62. </pages>
Reference-contexts: But it has been shown that when speech is ambiguous (Thompson and Massaro, 1986) or in a speech situation with some noise <ref> (Rogers, 1978) </ref>, listeners do rely on gestural cues (and, the higher the noise-to-signal ratio, the more facilitation by gesture).
Reference: <author> Short, J., E. Williams, and B. Christie. </author> <year> 1976. </year> <title> The Social Psychology of Telecommunications. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Silverman, K., M. Beckman, J. Pitrelli, M. Ostendorf, C. Wightman, P. Price, J. Pierrehumbert, and J. Hirschberg. </author> <year> 1992. </year> <title> ToBI: A standard for labeling english prosody. </title> <booktitle> In Proceedings of the 1992 International Conference on Spoken Language Processing (ICSLP), </booktitle> <volume> volume 2, </volume> <pages> pages 867-870, </pages> <address> Banff. </address>
Reference-contexts: Since that time, Pierrehumbert's intonational transcription system has been modified and supplanted by a common standard called ToBI (Tones and Boundary Indices), which retains much of Pierrehumbert's original classification scheme <ref> (Silverman et al., 1992) </ref>. The tonal layer of the ToBI system, consists of five pitch accents (H*, L*, L*+H, L+H* and H+!H*), two phrasal tones (L- and H-) and two final boundary tones (L% and H%).
Reference: <author> Steedman, Mark. </author> <year> 1991a. </year> <title> Structure and intonation. </title> <booktitle> Language, </booktitle> <pages> pages 260-296. </pages>
Reference: <author> Steedman, Mark. </author> <year> 1991b. </year> <title> Surface structure, intonation and meaning in spoken language. </title> <editor> In M. Bates and R. Weischedel, editors, </editor> <booktitle> Challenges in Natural Language Processing. </booktitle> <publisher> Cambridge University Press. </publisher>
Reference: <author> Thompson, L. A. and D. W. Massaro. </author> <year> 1986. </year> <title> Evaluation and integration of speech and pointing gestures during referential understanding. </title> <journal> Journal of Experimental Child Psychology, </journal> <volume> 42 </volume> <pages> 144-168. </pages> <address> Thorisson, Kristinn. </address> <year> 1996. </year> <title> Communicative Humanoids: A Computational Model of Psychosocial Dialogue Skills. </title> <type> Ph.D. thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA. Thorisson, Kristinn and Justine Cassell. </address> <year> 1996. </year> <title> Why put an agent in a body: the importance of communicative feedback in human-humanoid dialogue. </title> <booktitle> In Lifelike Computer Characters '96, </booktitle> <address> Snowbird, Utah. </address>
Reference-contexts: But it has been shown that when speech is ambiguous <ref> (Thompson and Massaro, 1986) </ref> or in a speech situation with some noise (Rogers, 1978), listeners do rely on gestural cues (and, the higher the noise-to-signal ratio, the more facilitation by gesture). <p> Schema-based systems (McKeown, 1985), which have been widely used for this task with impressive results, form the basis for our content generator. Rhetorical structure theory (RST) approaches <ref> (Mann and Thompson, 1986) </ref>, which organize texts by identifying rhetorical relations between clause-level propositions from a knowledge base, have also been developed (Hovy, 1993) and are particularly well-suited to handling theme and rheme level constituents.
Reference: <author> Vallduv, Enric. </author> <year> 1990. </year> <title> The Informational Component. </title> <type> Ph.D. thesis, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia. </address>
Reference-contexts: Thus, sentences conveying the same propositional content in different contexts need not share the same information structure. In simpler terms, information structure refers to how the semantic content of an utterance is packaged, and amounts to instructions for updating the information models of the discourse participants <ref> (Vallduv, 1990) </ref>. The realization of information structure in a sentence, however, differs from language to language. In English, for example, intonation carries much of the burden of information structure, while languages with freer word order, such as Catalan (Vallduv, 1990) and Turkish (Hoff-man, 1995) convey information structure syntactically. <p> amounts to instructions for updating the information models of the discourse participants <ref> (Vallduv, 1990) </ref>. The realization of information structure in a sentence, however, differs from language to language. In English, for example, intonation carries much of the burden of information structure, while languages with freer word order, such as Catalan (Vallduv, 1990) and Turkish (Hoff-man, 1995) convey information structure syntactically.
Reference: <author> Vilkuna, Maria. </author> <year> 1989. </year> <title> Free Word Order in Finnish: Its Syntax and Discourse Functions. </title> <address> Suomalaisen Kirjallisuuden Seura, Helsinki. </address>
Reference: <author> Ward, Gregory and Julia Hirschberg. </author> <year> 1985. </year> <title> Implicating uncertainty: the pragmatics of fall-rise intonation. </title> <booktitle> Language, </booktitle> <pages> pages 747-776. </pages>
Reference: <author> Williams, E. </author> <year> 1977. </year> <title> Experimental comparisons of face-to-face and mediated communication: A review. </title> <journal> Psychological Bulletin, </journal> <volume> 84 </volume> <pages> 963-976. </pages>
Reference: <author> Wilson, A., A. Bobick, and J. Cassell. </author> <year> 1996. </year> <title> Recovering the temporal structure of natural gesture. </title> <booktitle> Submitted to the Second International Conference on Automatic Face and Gesture Recognition. </booktitle> <pages> 44 </pages>
Reference-contexts: In fact, such a correlation between physical information and gesture type can enable automatic machine recognition of gesture type, and potentially bootstrap the interpretation of the information conveyed by gesture in interactive systems <ref> (Wilson, Bobick, and Cassell, 1996) </ref>. As far as the culturally specific nature of gesture is concerned, emblems do vary widely among different language communities. The four gesture types described, however, have appeared in narrations in a very wide variety of languages.
References-found: 68

