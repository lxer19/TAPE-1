URL: ftp://ftp.cs.indiana.edu/pub/gasser/gala.ps
Refering-URL: http://www.cs.indiana.edu/ai/Gasser/Morphophon/home.html
Root-URL: http://www.cs.indiana.edu
Title: Relating Comprehension and Production in the Acquisition of Morphology  
Author: Michael Gasser 
Affiliation: Indiana University  
Abstract: Most theories of language processing and acquisition make the assumption that perception and comprehension are related to production, but few have anything say about how. This paper describes a performance-oriented connectionist model of the acquisition of morphology in which production builds on representations which develop during the learning of word recognition. Using artificial language stimuli embodying simple suffixation, prefixation, and template rules, I demonstrate that the model generalizes to novel combinations of roots and inflections for both word recognition and production. I argue that the capacity of connectionist networks to develop intermediate distributed representations which not only enable the solving of the task at hand but also facilitate another task offers a plausible account of how comprehension and production come to share phonological knowledge as words are learned. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Browman, C. & Goldstein, L. </author> <year> (1986). </year> <title> Towards an articulatory phonology. </title> <journal> Phonology Yearbook, </journal> <volume> 3, </volume> <pages> 219-252. </pages>
Reference-contexts: Thus the three forms for the root bx were baxa, bixi , and buxu. "Auditory" inputs consisted of sequences of segments, each containing values for seven gross acoustic features. "Articulatory" output also consisted of sequences of segments, but these were based loosely on the gestures of Articulatory Phonology <ref> (Browman & Goldstein, 1986) </ref>. Thus, while these inputs and outputs were far from authentic, they were quite unlike each other in character. With 24 roots and three inflections, there were always 72 possible words.
Reference: <author> Elbers, L. </author> <year> (1995). </year> <title> Production as a source of input for analysis: evidence from the developmental course of a word-blend. </title> <journal> Journal of Child Language, </journal> <volume> 22, </volume> <pages> 47-71. </pages>
Reference-contexts: shown in previous work (Gasser, 1994a) to be capable of learning morphological rules of the following types: suffixation, prefixation, 2 There is a further possibility for the learning of morphology, namely, that analysis into constituent morphemes takes place as the child listens to her own production of a memorized word <ref> (Elbers, 1995) </ref>. While this complicates the picture presented here somewhat, it is still in agreement with the basic account of how receptive and productive learning are related. infixation, mutation, template, and deletion. 3 The network consists of separate, though connected, modules for receptive (perception and comprehension) and productive performance.
Reference: <author> Elman, J. </author> <year> (1990). </year> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14, </volume> <pages> 179-211. </pages>
Reference-contexts: Further the receptive component consists of separate modules responsible for recognition of the root and for the grammatical morphemes in a word (Gasser, 1994b). Each module in the network is a form of simple recurrent network <ref> (Elman, 1990) </ref>, a feedforward network augmented with some recurrent (feedback) connections. The overall architecture of the model is shown in Figure 3. Boxes represent clusters of connectionist units, and arrows represent complete connectivity between clusters. There are recurrent connections on the hidden-layer (IPR) units.
Reference: <author> Gasser, M. </author> <year> (1994a). </year> <title> Acquiring receptive morphology: a connectionist model. </title> <booktitle> Annual Meeting of the Association for Computational Linguistics, </booktitle> <volume> 32, </volume> <pages> 279-286. </pages>
Reference-contexts: A Model: MCNAM The Modular Connectionist Network for the Acquisition of Morphology (MCNAM) is a relatively simple architecture which has been shown in previous work <ref> (Gasser, 1994a) </ref> to be capable of learning morphological rules of the following types: suffixation, prefixation, 2 There is a further possibility for the learning of morphology, namely, that analysis into constituent morphemes takes place as the child listens to her own production of a memorized word (Elbers, 1995).
Reference: <author> Gasser, M. </author> <year> (1994b). </year> <title> Modularity in a connectionist model of morphology acquisition. </title> <booktitle> Proceedings of the International Conference on Computational Linguistics, </booktitle> <volume> 15, </volume> <pages> 214-220. </pages>
Reference-contexts: Further the receptive component consists of separate modules responsible for recognition of the root and for the grammatical morphemes in a word <ref> (Gasser, 1994b) </ref>. Each module in the network is a form of simple recurrent network (Elman, 1990), a feedforward network augmented with some recurrent (feedback) connections. The overall architecture of the model is shown in Figure 3. Boxes represent clusters of connectionist units, and arrows represent complete connectivity between clusters.
Reference: <author> Harris, M., Yeeles, C., Chasin, J., & Oakley, Y. </author> <year> (1995). </year> <title> Symmetries and asymmetries in early lexical comprehension and production. </title> <journal> Journal of Child Language, </journal> <volume> 22, </volume> <pages> 1-18. </pages>
Reference: <author> Quine, W. V. O. </author> <year> (1960). </year> <title> Word and Object. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The evidence the child receives is far from perfect | words are not always isolable in the input stream, and the precise set of semantic features singled out by the word is never actually indicated <ref> (Quine, 1960) </ref> | but in a sense the child is "taught" to understand words. For word recognition there is a target. The same cannot be said for word production. Children who produce an utterance with some communicative intent have no target to guide them.
Reference: <author> Snow, C. E. </author> <year> (1977). </year> <title> Mothers' speech research: from input to interaction. In Snow, </title> <editor> C. E. & Ferguson, C. (Eds.), </editor> <title> Talking to Children: </title> <booktitle> Language Input and Acquisition, </booktitle> <pages> pp. 31-49. </pages> <publisher> Cambridge University Press, </publisher> <address> Cambridgem MA. </address>
Reference-contexts: This task can be viewed as an example of supervised learning: under at least some circumstances, the child has access to a "teacher" to provide the correct response. That is, because language addressed to children tends to refer to the here-and-now <ref> (Snow, 1977) </ref>, the referent of the word is available in the context and often pointed to in one way or another.
Reference: <author> Sutton, R. S. (Ed.). </author> <year> (1992). </year> <title> Reinforcement Learning. </title> <publisher> Kluwer Academic, </publisher> <address> Boston. </address>
Reference-contexts: How, then, can production be learned at all? The only real possibility is through reinforcement , rather than strictly supervised, learning <ref> (Sutton, 1992) </ref>. When the learner is right and is told so, reinforcement learning is identical to supervised learning: the learner should do the same thing under the same circumstances the next time.
References-found: 9

