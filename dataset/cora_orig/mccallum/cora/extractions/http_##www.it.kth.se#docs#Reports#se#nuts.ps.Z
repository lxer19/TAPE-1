URL: http://www.it.kth.se/docs/Reports/se/nuts.ps.Z
Refering-URL: http://www.it.kth.se/docs/Reports/se/
Root-URL: http://www.it.kth.se
Email: E-mail: -tyugu, vlad, mattin-@it.kth.se  
Phone: Voice: +46 8 752 1371 Fax: +46 8 751 1793  
Title: NUTS: a Distributed Object-Oriented Platform with High-Level Communication Functions  
Author: Enn Tyugu, Vladimir Vlassov and Mattin Addibpour 
Note: Contact person: Prof. Enn Tyugu, Teleinformatics, KTH Electrum 240, S-164 40 KISTA (Stockholm)  
Address: 204, S-164 40 Kista, Sweden  
Affiliation: Department of Teleinformatics, Royal Institute of Technology, Electrum  
Abstract: An extensible object-oriented platform NUTS for distributed computing is described which is based on an object-oriented programming environment NUT, is built on top of the Parallel Virtual Machine (PVM), and hides all low-level features of the latter. The language of NUTS is a concurrent object-oriented programming language with coarse-grained parallelism and distributed shared memory communication model implemented on a distributed memory architecture. It differs from other languages of concurrent programming in the following: concurrent processes are represented by packages which are semantically richer entities than objects, inter-process communication is performed in terms of classes, objects, scripts and packages, using the EDA communication model; processes can be arranged into structured collections: grids which enable one to program data-parallel computations on a high level; sequential segments of programs can be synthesized automatically from specifications represented as classes using the program synthesis features of NUT. Examples of usage of generic parallel computing control structures PARDIF and PARARR are given. 
Abstract-found: 1
Intro-found: 0
Reference: [1] <author> M. Addibpour, </author> <title> Control Structures for Parallel Computing in NUT. </title> <institution> MSc thesis TRITA - IT-R 95:18, CSLab, Dept. of Teleinformatics, Royal Institute of Technology (KTH), Stockholm, </institution> <year> 1995. </year>
Reference-contexts: The intention is to construct and run parallel branches of computations automatically, using a set of predefined control structures. These control structures are implemented in the form of classes in NUT. Once preprogrammed, the control structures are expected to constitute a domain-specific parallel programming toolkit <ref> [1] </ref>. 4.1 Control Structures for Parallel Programming Using NUTS The task of developing parallel programs consists of a number of sub-tasks: parallel algorithm design, problem partitioning, mapping, communication and synchronization management and resource management.
Reference: [2] <author> H. Ahmed, L-E Thorelli, and V. Vlassov, mEDA: </author> <title> A Parallel Programming Environment, </title> <booktitle> in Proceedings of the Euromicro95 Conference on Design of Hardware/ Software Systems, </booktitle> <address> Como, Italy, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: A formal description and software implementation of the EDA model can be found in <ref> [2, 8, 12] </ref>. 3.4.1 The EDA Communication Operations EDA is a model of object-oriented multithreaded computation. An EDA object contains local and shared variables and a thread of control. All shared variables form a space of shared memory which is accessible from each object. <p> The EDA model [8] recognizes three types of shared variables: x, i and s, each with special synchronization requirements. Semantics of typed shared variables of EDA was extended and expressed in terms of special shared memory operations carried out on untyped shared variables <ref> [2, 13] </ref>. This modification was done in order to make the EDA model more convenient and exible. The modified EDA model specifies eight kinds of shared memory operations: 17 x-fetch is a blocking extract operation.
Reference: [3] <author> J.C. Browne, S. I. Hyder, J. Dongarra, K. Moore, and P. </author> <title> Newton, Visual Programming and Debugging for Parallel Computing, </title> <type> Technical Report TR94-229, </type> <institution> Dept. of Computer Sciences, Univ. of Texas at Austin, </institution> <year> 1994. </year>
Reference-contexts: HeNCE (Heterogeneous Network Computing Environment) and CODE 2.0, are visual programming environments each of which is based on visual parallel programming language using directed graphs as a natural mechanism for presentation of the behav-iour of parallel programs <ref> [3] </ref>. Nodes of a graph denote conventional Fortran or C subroutines and arcs represent data and control dependencies. The NUTS system also contains visual programming tools which are a part of the NUT environment.
Reference: [4] <author> K.M. Chandy and S Taylor, </author> <title> An Introduction to Parallel Programming. </title> <publisher> Jones and Bartlett 34 Publishers, </publisher> <address> Boston, </address> <year> 1992, </year> <pages> pp. 103-122. </pages>
Reference-contexts: After each iteration, all workers send the results to the root through the par_out component. To demonstrate a usage of the PARDIF structure, we have implemented a two-dimensional Laplace equation solver with Dirichlet boundary conditions, using the simultaneous displacement method of Jacobi <ref> [4, 7] </ref>. This problem called the Dirichlet problem is formulated as: (EQ 1) To solve this equation, the surface F is partitioned into an n by n grid whose elements represent the initial state of F. The value of F at the surface boundaries is a known constant.
Reference: [5] <author> J.E. Devaney, R. Lipman, M. Lo, W.M. Mitchell, M. Edwards, and C.W. Clark, </author> <title> The Parallel Application Development Environment (PADE). A Users Manual. </title> <institution> National Institute of Standards and Technology, </institution> <year> 1995. </year>
Reference-contexts: The PADE package has graphical user interface and it allows the user to develop a parallel application which consists of a number of components located on the file systems of different computes with different operating systems <ref> [5] </ref>. HeNCE (Heterogeneous Network Computing Environment) and CODE 2.0, are visual programming environments each of which is based on visual parallel programming language using directed graphs as a natural mechanism for presentation of the behav-iour of parallel programs [3].
Reference: [6] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam, PVM3: </author> <title> Parallel Virtual Machine. A Users Guide and Tutorial for Networked Parallel Computing. </title> <publisher> The MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The last aspect is a distinguished feature of the NUT programming environment enabling users easily to implement declarative problem-oriented languages. Developing the NUTS system, we have used two existing software tools: an object-oriented programming environment NUT [9, 11] and the Parallel Virtual Machine, PVM <ref> [6] </ref>. The NUT system will be briey described in section 2. Here we give some hints about the PVM. The Parallel Virtual Machine, PVM, is a widely used integrated framework for heterogeneous computing.
Reference: [7] <author> R.H. Perrot, </author> <title> Parallel Programming. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> G.B., </address> <year> 1987, </year> <pages> pp. 150-153. </pages>
Reference-contexts: Process A: dest := [tid_b]; buf := sh_buf; rnut_sstore (dest, 1, buf, 5); rnut_sstore (dest, 1, buf, -1.3 ); rnut_sstore (dest, 1, buf, Hello World); rnut_sstore (dest, 1, buf, <ref> [7, 3.1415] </ref>); rnut_sstore (dest, 1, buf, [radio, -ga, -ga]); Process B: x := new array of any; me:= rnut_mytid (); 23 x [i]:= rnut_xfetch (me, sh_buf); od; value of the local object x which consumes a stream of values from the process A. 4.0 Programming Experience with NUTS The exibility of <p> After each iteration, all workers send the results to the root through the par_out component. To demonstrate a usage of the PARDIF structure, we have implemented a two-dimensional Laplace equation solver with Dirichlet boundary conditions, using the simultaneous displacement method of Jacobi <ref> [4, 7] </ref>. This problem called the Dirichlet problem is formulated as: (EQ 1) To solve this equation, the surface F is partitioned into an n by n grid whose elements represent the initial state of F. The value of F at the surface boundaries is a known constant.
Reference: [8] <author> L.-E. Thorelli, </author> <title> The EDA Multiprocessing Model. </title> <type> Technical Report TRITA-IT-R 94:28, </type> <institution> CSLab, Dept. of Teleinformatics, Royal Institute of Technology (KTH), Stockholm, </institution> <year> 1994. </year>
Reference-contexts: Passing scrips and classes is not used for process synchronization, rather it allows to distribute and control computation in collaborative NUT processes. Synchronization and communication mechanism of NUTS is based on object passing according to the EDA multiprocessing model <ref> [8] </ref>. The NUTS library librnut is implemented on top of PVM library libpvm which provides low level inter-process communication based on explicit message passing. 3.1 Process Control The distributed NUTS program is structured as a number of collaborative NUT processes running on PVM. <p> A formal description and software implementation of the EDA model can be found in <ref> [2, 8, 12] </ref>. 3.4.1 The EDA Communication Operations EDA is a model of object-oriented multithreaded computation. An EDA object contains local and shared variables and a thread of control. All shared variables form a space of shared memory which is accessible from each object. <p> An EDA object can store local data into shared memory and fetch a value of a shared variable into its local memory. A shared variable may be in one of two states: full (containing data) or empty. The EDA model <ref> [8] </ref> recognizes three types of shared variables: x, i and s, each with special synchronization requirements. Semantics of typed shared variables of EDA was extended and expressed in terms of special shared memory operations carried out on untyped shared variables [2, 13].
Reference: [9] <author> E. Tyugu, </author> <title> Using classes as specifications for automatic construction of programs in the NUT system, </title> <journal> Journal of Automated Software Engineering, </journal> <volume> vol. 1, </volume> <pages> pp. 315 - 334, </pages> <year> 1994. </year>
Reference-contexts: Segments of programs can be synthesized automatically from specifications repre sented as classes. The last aspect is a distinguished feature of the NUT programming environment enabling users easily to implement declarative problem-oriented languages. Developing the NUTS system, we have used two existing software tools: an object-oriented programming environment NUT <ref> [9, 11] </ref> and the Parallel Virtual Machine, PVM [6]. The NUT system will be briey described in section 2. Here we give some hints about the PVM. The Parallel Virtual Machine, PVM, is a widely used integrated framework for heterogeneous computing. <p> Solvability of a task is defined with respect to a specification, i.e. a theory obtained from a class. The SSP has a sound logical explanation in terms of intuitionistic propositional logic and simple types, as well as in terms of higher-order constraint networks <ref> [9, 10] </ref>. Due to the simplicity of the logical language of SSP, its performance is quite satisfactory which can be seen from the Table 1. A program synthesis task may appear in several forms.
Reference: [10] <author> E. Tyugu and T. Uustalu, </author> <title> Higher-order functional constraint networks, Constraint programming. NATO ASI Series F: </title> <journal> Computer and System Sciences, </journal> <volume> vol. 131, </volume> <pages> pp. 116 - 139, </pages> <year> 1994. </year>
Reference-contexts: Solvability of a task is defined with respect to a specification, i.e. a theory obtained from a class. The SSP has a sound logical explanation in terms of intuitionistic propositional logic and simple types, as well as in terms of higher-order constraint networks <ref> [9, 10] </ref>. Due to the simplicity of the logical language of SSP, its performance is quite satisfactory which can be seen from the Table 1. A program synthesis task may appear in several forms.
Reference: [11] <author> T. Uustalu, U. Kopra, V. Kotkas, M. Matskin, and E Tyugu, </author> <title> The NUT Language Report. </title> <type> Technical Report TRITA-IT-R 94:14, </type> <institution> CSLab, Dept. of Teleinformatics, Royal Institute of Technology (KTH), Stockholm, </institution> <year> 1994. </year>
Reference-contexts: Segments of programs can be synthesized automatically from specifications repre sented as classes. The last aspect is a distinguished feature of the NUT programming environment enabling users easily to implement declarative problem-oriented languages. Developing the NUTS system, we have used two existing software tools: an object-oriented programming environment NUT <ref> [9, 11] </ref> and the Parallel Virtual Machine, PVM [6]. The NUT system will be briey described in section 2. Here we give some hints about the PVM. The Parallel Virtual Machine, PVM, is a widely used integrated framework for heterogeneous computing. <p> NUT language has features of an object-oriented language with multiple inheritance, parametric polymorphism and a exible mechanism for message passing <ref> [11] </ref>. The NUT system has good interoperability with programs written in C and, in general, with other software components running under Unix. Each software package used in NUT is represented by an object of a specific class designed for this package.
Reference: [12] <author> V. Vlassov, H. Ahmed, and L-E Thorelli, mEDA2: </author> <title> An Extension of PVM, </title> <booktitle> in Proceedings of the 3rd International Conference on Parallel Computing Technologies, </booktitle> <address> St.-Petersburg, Russia, </address> <month> September </month> <year> 1995. </year> <pages> pp. 288-293. </pages>
Reference-contexts: A formal description and software implementation of the EDA model can be found in <ref> [2, 8, 12] </ref>. 3.4.1 The EDA Communication Operations EDA is a model of object-oriented multithreaded computation. An EDA object contains local and shared variables and a thread of control. All shared variables form a space of shared memory which is accessible from each object.
Reference: [13] <author> V. Vlassov, E. Tyugu, and M. Addibpour, </author> <title> Distributed programming toolkit for NUT. </title> <type> Technical Report TRITA-IT-R 94:34, </type> <institution> CSLab, Dept. of Teleinformatics, Royal Institute of Technology (KTH), Stockholm, </institution> <year> 1994. </year>
Reference-contexts: The EDA model [8] recognizes three types of shared variables: x, i and s, each with special synchronization requirements. Semantics of typed shared variables of EDA was extended and expressed in terms of special shared memory operations carried out on untyped shared variables <ref> [2, 13] </ref>. This modification was done in order to make the EDA model more convenient and exible. The modified EDA model specifies eight kinds of shared memory operations: 17 x-fetch is a blocking extract operation.

References-found: 13

