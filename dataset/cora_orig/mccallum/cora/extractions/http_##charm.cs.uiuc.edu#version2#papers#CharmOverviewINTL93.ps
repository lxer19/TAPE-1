URL: http://charm.cs.uiuc.edu/version2/papers/CharmOverviewINTL93.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/CharmOverviewINTL93.html
Root-URL: http://www.cs.uiuc.edu
Email: email kale@cs.uiuc.edu  Email: kale@cs.uiuc.edu  
Phone: Phone (217) 244-0094,  
Title: Parallel Programming with CHARM: An Overview  
Author: L. V. Kale 
Affiliation: Department of Computer Science, University of Illinois, Urbana-Champaign.  
Abstract: This Paper describes the research centered on the Charm Parallel Programming System. Charm is a portable parallel programming system under development at the University of Illinois for the past six years. The system enhances latency tolerance via message driven execution, supports dynamic load balancing for medium grain tasks, and provides innovative language features such as specifically shared variables and "branch office" processes. The paper describes the philosophy behind the system, and elaborates on its features and their motivation. Completed and ongoing related projects are summarized, including: Dagger, a textual notation and a corresponding visual language for simplifying expression of split-phase communication that is necessary in message driven execution; A subset of the High Performance Fortran that demonstrates superior latency tolerance; Performance feedback and debugging tools that exploit the specificity of information available to the runtime system to give the user a highly refined and usable feedback; strategies for parallel execution of speculatively parallel computations; and a summary of preliminary applications.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Agha. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: The system provides FIFO, LIFO, and priority-based scheduling strategies, with unbounded levels of priorities. Similarly, it provides a variety of dynamic load balancing strategies developed over the years. 3 Enhancing Expressiveness The language defined so far might not appear novel. The reader might compare the chares to actors <ref> [1] </ref>, processes, monitors, concurrent objects [4, 27, 3], etc. with each of which it shares some similarities and differences. Even at this level, Charm probably was one of the first such systems implemented in portable manner [11] with support for dynamic load balancing.
Reference: [2] <author> Arvind, R. S. Nikhil, and K. K. Pingali. I-structures: </author> <title> Data structures for parallel computing. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 598-632, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: They are also related to the I-structures <ref> [2] </ref> of the data flow languages. 3. The accumulator. The accumulator is a shared data structure with a commutative and associative operator. The users are free to define their own data structures and operators as long as they satisfy this requirement.
Reference: [3] <author> K. Mani Chandy and Carl Kesselman. </author> <title> Compositional C++: Compositional parallel programming. </title> <type> Technical Report Caltech-CS-TR-92-13, </type> <institution> Department of Computer Science, California Institute of Tech nology, </institution> <year> 1992. </year>
Reference-contexts: Similarly, it provides a variety of dynamic load balancing strategies developed over the years. 3 Enhancing Expressiveness The language defined so far might not appear novel. The reader might compare the chares to actors [1], processes, monitors, concurrent objects <ref> [4, 27, 3] </ref>, etc. with each of which it shares some similarities and differences. Even at this level, Charm probably was one of the first such systems implemented in portable manner [11] with support for dynamic load balancing.
Reference: [4] <author> A. Chien. </author> <title> Concurrent Aggregates. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Similarly, it provides a variety of dynamic load balancing strategies developed over the years. 3 Enhancing Expressiveness The language defined so far might not appear novel. The reader might compare the chares to actors [1], processes, monitors, concurrent objects <ref> [4, 27, 3] </ref>, etc. with each of which it shares some similarities and differences. Even at this level, Charm probably was one of the first such systems implemented in portable manner [11] with support for dynamic load balancing.
Reference: [5] <author> David Culler, Richard Karpa, David Patterson, Abhijit Sahay, Abhijit Sahat, Klaus Erik Schauser, Eunice Santos, Ramesh Subramonian, and Thorsten von Eicken. </author> <title> Logp: Towards a realistic model of parallel computation. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming PPOPP, </booktitle> <address> San Diego, California, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: By tracing individual computation blocks in a Dagger program and using the dependence information in the dag graph solves this problem. A simulator embodying these ideas has been implemented [8]. The architecture models supported by the simulator appears to subsume the LogP model proposed recently in <ref> [5] </ref>. 7 Supporting Parallel Programming In contrast to SPMD programs running on vendor supplied software, the Charm runtime system has much more specific, application level, information about the events in the parallel computation.
Reference: [6] <author> A. Gursoy, L.V. Kale, and S.P. Vanka. </author> <title> Unsteady fluid flow calculations using a machine independent parallel programming environment. </title> <editor> In R. B. Pelz, A. Ecer, and J. Hauser, editors, </editor> <booktitle> Parallel Computational Fluid Dynamics '92, </booktitle> <pages> pages 175-185. </pages> <publisher> North-Holland, </publisher> <year> 1993. </year>
Reference-contexts: Several CFD algorithms are being implemented to study the effectiveness of message driven execution for them <ref> [6] </ref>. A molecular dynamics program named EGO, originally written in OCCAM, was recently ported to Charm. A novel comparison based sorting algorithm|which can be used for floating-point numbers, strings, as well as integers has been implemented.
Reference: [7] <author> Attila Gursoy and L.V. Kale. Dagger: </author> <title> Combining the benefits of synchronous and asynchronous communication styles. </title> <type> Technical Report 93-3, </type> <institution> Parallel Programming Laboratory, Department of Computer Science, University of Illinois, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: This sometimes leads to bugs due to a message processing sequence that is different than those anticipated by the user program. We have developed a notation called Dagger <ref> [7] </ref>, and an associated graphical program editor that helps programmers deal with this complexity. Consider the graph shown in Figure 7. The rectangles in this graph represent subcomputations and circles represent messages. Note that all the subcomputations are part of a single process executing on a single processor.
Reference: [8] <author> Attila Gursoy and L.V.Kale. </author> <title> Simulating message driven programs. </title> <type> Technical Report 93-9, </type> <institution> Parallel Programming Laboratory, Department of Computer Science, University of Illinois, </institution> <month> Jul </month> <year> 1993. </year>
Reference-contexts: As the traces were obtained with respect to a specific sequence, faithful simulation becomes difficult. By tracing individual computation blocks in a Dagger program and using the dependence information in the dag graph solves this problem. A simulator embodying these ideas has been implemented <ref> [8] </ref>. The architecture models supported by the simulator appears to subsume the LogP model proposed recently in [5]. 7 Supporting Parallel Programming In contrast to SPMD programs running on vendor supplied software, the Charm runtime system has much more specific, application level, information about the events in the parallel computation.
Reference: [9] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler support for machine independent parallel programming in Fortran-D. </title> <publisher> Elsevier Science Publishers B.V., </publisher> <year> 1992. </year>
Reference-contexts: DP-Charm [21] is a data-parallel language being developed on top of Charm. The language implements a subset of the official HPF (High Performance Fortran) language. It is an array oriented language, in which the programmer specifies the distribution of each array explicitly, as in Fortran-D <ref> [9] </ref>. It supports data parallel loops, and primitives for shifts, reductions, and other array operations. The compiler for this language takes a user program and translates it into a intermediate language of smaller primitives.
Reference: [10] <author> L. V. Kale. </author> <title> A tree representation for parallel problem solving. </title> <booktitle> In Proceedings of AAAI, </booktitle> <pages> pages 677-681, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: As DP-Charm generates Charm modules, they can be easily linked with other Charm modules. Thus one can compose programs with highly regular, data parallel, components with irregular components requiring dynamic load balancing, etc. A parallel implementation of Prolog <ref> [14, 10, 22] </ref> was one of the earliest projects carried out on top of Charm. In fact, it is a progenitor of Charm|Charm originated when the runtime system for the Parallel Prolog was separated and independently developed in 1986.
Reference: [11] <author> L. V. Kale. </author> <title> The Chare kernel parallel programming language and system. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <volume> volume II, </volume> <pages> pages 17-25, </pages> <address> St. Charles, IL, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: However, even such a drastic measure does not eliminate all sources of unwanted interactions. A more thorough and clean approach to compositionality and modularity is needed. The Charm parallel programming system <ref> [11, 24, 13] </ref> has been developed as a response to these concerns, at University of Illinois at Urbana Champaign over the past several years (1986-1993). <p> The reader might compare the chares to actors [1], processes, monitors, concurrent objects [4, 27, 3], etc. with each of which it shares some similarities and differences. Even at this level, Charm probably was one of the first such systems implemented in portable manner <ref> [11] </ref> with support for dynamic load balancing. However, our significant point of departure comes with the features we describe next: Information sharing abstractions and branch office chares. 3.1 Specifically Shared Variables The language described so far allows dynamically created processes to send messages to each other.
Reference: [12] <author> L. V. Kale and V. Saletore. </author> <title> Parallel state-space search for a first solution. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 19 </volume> <pages> 251-293, </pages> <year> 1990. </year>
Reference-contexts: The objective of our research here was therefore to achieve consistent (i.e. from run to run) speedups that increase monotonically with the number of processors. We developed a series of prioritization strategies <ref> [12, 16] </ref> for different application domains that help achieve this objective. We also developed prioritized load balancing schemes [23, 26] to support this. The priorities required for the these applications need to be unbounded.
Reference: [13] <author> L. V. Kale and W. Shu. </author> <title> The Chare Kernel language for parallel programming: A perspective. </title> <type> Technical Report UIUCDCS-R-88-1451, </type> <institution> Department of Computer Science, University of Illinois, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: However, even such a drastic measure does not eliminate all sources of unwanted interactions. A more thorough and clean approach to compositionality and modularity is needed. The Charm parallel programming system <ref> [11, 24, 13] </ref> has been developed as a response to these concerns, at University of Illinois at Urbana Champaign over the past several years (1986-1993).
Reference: [14] <author> L.V. Kale. </author> <title> The REDUCE OR process model for parallel execution of logic programs. </title> <journal> Journal of Logic Programming, </journal> <volume> 11(1) </volume> <pages> 55-84, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: As DP-Charm generates Charm modules, they can be easily linked with other Charm modules. Thus one can compose programs with highly regular, data parallel, components with irregular components requiring dynamic load balancing, etc. A parallel implementation of Prolog <ref> [14, 10, 22] </ref> was one of the earliest projects carried out on top of Charm. In fact, it is a progenitor of Charm|Charm originated when the runtime system for the Parallel Prolog was separated and independently developed in 1986.
Reference: [15] <author> L.V. Kale. </author> <title> A tutorial introduction to Charm. </title> <type> Technical Report 92-6, </type> <institution> Parallel Programming Laboratory, Department of Computer Science, University of Illinois, </institution> <year> 1992. </year>
Reference-contexts: This last advantage is similar to that of coroutines and threads in that it allows one to separate independent threads of control in the program without sacrificing the interleaved execution of such threads. A more thorough description of branch office chares can be found elsewhere <ref> [15] </ref>. Here we will give a simple example. Consider the program of Figure 1. Suppose we now also want to record each solution obtained by the calculate function.
Reference: [16] <author> L.V. Kale. </author> <title> Prioritization in parallel symbolic computing. </title> <editor> In T. Ito and R. Halstead, editors, </editor> <booktitle> To Appear in Lecture Notes in Comp. Science, </booktitle> <pages> pages 146-181. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <month> 19 </month>
Reference-contexts: The objective of our research here was therefore to achieve consistent (i.e. from run to run) speedups that increase monotonically with the number of processors. We developed a series of prioritization strategies <ref> [12, 16] </ref> for different application domains that help achieve this objective. We also developed prioritized load balancing schemes [23, 26] to support this. The priorities required for the these applications need to be unbounded. <p> The problems in these different application domains, although they share the common difficulty of speculatively parallel computations, are very distinct and need different solution strategies. However a common theme in all the solutions the use of priorities. The full extent of such efforts is described in <ref> [16] </ref>.
Reference: [17] <author> L.V. Kale and Sanjeev Krishnan. </author> <title> Charm++ : A portable concurrent object oriented sys-tem based on C++. </title> <booktitle> In To appear in the Proceedings of the Conference on Object Oriented Programming Systems, Languages and Applications, </booktitle> <month> September </month> <year> 1993, </year> <month> March </month> <year> 1993. </year> <note> (Also: Technical Report UIUCDCS-R-93-1796, </note> <month> March </month> <year> 1993, </year> <institution> University of Illinois, Urbana, IL. </institution>
Reference: [18] <author> L.V. Kale and Sanjeev Krishnan. </author> <title> A comparison based parallel sorting algorithm. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: A research group led by Prof. P. Banerjee at University of Illinois used Charm to implement several VLSI-CAD algorithms with excellent results. As an example, the performance results obtained using Charm for a parallel sorting algorithm are shown in Tables 2, 3, 4 and 5. <ref> [18, 25] </ref>. The key set for all tables consists of integers obtained by averaging 4 sets of random integers. Table 2: Parallel Sort Basic Timings on the CM5.
Reference: [19] <author> L.V. Kale and A.B. Sinha. </author> <title> Projections: A scalable performance tool, </title> <month> April </month> <year> 1993. </year> <title> Parallel Systems Fair, </title> <booktitle> International Parallel Processing Symposium. </booktitle>
Reference-contexts: We have only begun to explore these possibilities. A preliminary performance feedback tool called Projections <ref> [19] </ref> has been developed. The only specificity exploited in this tool is the category of a message. It distinguishes messages for creation of new chares, for existing chares, and for branch office chares.
Reference: [20] <author> L.V. Kale and Amitabh Sinha. </author> <title> Information sharing mechanisms in parallel programs. </title> <type> Technical Report 93-4, </type> <institution> Parallel Programming Laboratory, Department of Computer Science, University of Illinois, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Instead, we believe that processes should be allowed to exchange information via multiple alternative information sharing modes. The task then is to identify commonly used modes, to define abstractions for them, and then to implement them, possibly differently, on different parallel machines <ref> [20] </ref>. The conceptual model of a Charm computation, with chares that send messages to each other, create new instances, and share information via specifically shared variables is shown in Figure 2. Charm supports the following abstractions in addition to messages. 1. Read only variables. <p> to find the data corresponding to a given key, for example, deposits a request to send this data to a named chare chare id at a named entry point entry point, as shown below. find (table name, key, chare id, entry point); Distributed tables subsume the functionality of tuple spaces <ref> [20] </ref>, but are nonblocking. They are also related to the I-structures [2] of the data flow languages. 3. The accumulator. The accumulator is a shared data structure with a commutative and associative operator.
Reference: [21] <author> Edward Kornkven and Laxmikant Kale. </author> <title> Dynamic adaptive scheduling in an implementation of a data parallel language. </title> <type> Technical Report 92-10, </type> <institution> Parallel Programming Laboratory, Department of Computer Science, University of Illinois, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: One can write direct applications using Charm, but one can also develop other higher level languages and specialized packages on top of Charm. Two such projects, one ongoing and one older, carried out at the Parallel Programming Laboratory are described below. DP-Charm <ref> [21] </ref> is a data-parallel language being developed on top of Charm. The language implements a subset of the official HPF (High Performance Fortran) language. It is an array oriented language, in which the programmer specifies the distribution of each array explicitly, as in Fortran-D [9].
Reference: [22] <author> B. Ramkumar and L.V. Kale. </author> <title> Machine independent AND and OR parallel execution of logic programs: Part I and II. </title> <note> To appear in IEEE Transactions on Parallel and Distributed Systems, </note> <year> 1991. </year>
Reference-contexts: As DP-Charm generates Charm modules, they can be easily linked with other Charm modules. Thus one can compose programs with highly regular, data parallel, components with irregular components requiring dynamic load balancing, etc. A parallel implementation of Prolog <ref> [14, 10, 22] </ref> was one of the earliest projects carried out on top of Charm. In fact, it is a progenitor of Charm|Charm originated when the runtime system for the Parallel Prolog was separated and independently developed in 1986.
Reference: [23] <author> V. Saletore. </author> <title> Machine Independent Parallel Execution of Speculative Computations. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Illinois, </institution> <year> 1990. </year>
Reference-contexts: We developed a series of prioritization strategies [12, 16] for different application domains that help achieve this objective. We also developed prioritized load balancing schemes <ref> [23, 26] </ref> to support this. The priorities required for the these applications need to be unbounded. For example, the state space search is prioritized by attaching a bit vector priority to every node of the search tree.
Reference: [24] <author> W. W. Shu and L. V. Kale. </author> <title> Chare Kernel a runtime support system for parallel computations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 11 </volume> <pages> 198-211, </pages> <year> 1990. </year>
Reference-contexts: However, even such a drastic measure does not eliminate all sources of unwanted interactions. A more thorough and clean approach to compositionality and modularity is needed. The Charm parallel programming system <ref> [11, 24, 13] </ref> has been developed as a response to these concerns, at University of Illinois at Urbana Champaign over the past several years (1986-1993).
Reference: [25] <author> Amitabh Sinha and L.V. Kale. </author> <title> A load balancing strategy for prioritized execution of tasks. In Workshop on Dynamic Object Placement and Load Balancing, in co-operation with ECOOP's 92, </title> <address> Utrecht, The Netherlands, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: The system allows dynamic creation of work, and supports it with a suite of user-selectable dynamic load balancing strategies. It allows associating priorities with messages and tasks, supported by prioritized scheduling and load balancing strategies <ref> [25] </ref>. Finally, it supports a sophisticated module system that allows one to reuse modules (even separately compiled ones) effectively without loss of efficiency. This paper provides an overview of Charm, and related research projects. We begin by summarizing the core language supported by Charm. <p> A research group led by Prof. P. Banerjee at University of Illinois used Charm to implement several VLSI-CAD algorithms with excellent results. As an example, the performance results obtained using Charm for a parallel sorting algorithm are shown in Tables 2, 3, 4 and 5. <ref> [18, 25] </ref>. The key set for all tables consists of integers obtained by averaging 4 sets of random integers. Table 2: Parallel Sort Basic Timings on the CM5.
Reference: [26] <author> Amitabh Sinha and L.V. Kale. </author> <title> A load balancing strategy for prioritized execution of tasks. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <address> New Port Beach, CA., </address> <month> April </month> <year> 1993. </year>
Reference-contexts: We developed a series of prioritization strategies [12, 16] for different application domains that help achieve this objective. We also developed prioritized load balancing schemes <ref> [23, 26] </ref> to support this. The priorities required for the these applications need to be unbounded. For example, the state space search is prioritized by attaching a bit vector priority to every node of the search tree.
Reference: [27] <author> A. Yonezawa. </author> <title> ABCL: An Object Oriented Concurrent System. </title> <publisher> MIT Press, </publisher> <year> 1990. </year> <month> 20 </month>
Reference-contexts: Similarly, it provides a variety of dynamic load balancing strategies developed over the years. 3 Enhancing Expressiveness The language defined so far might not appear novel. The reader might compare the chares to actors [1], processes, monitors, concurrent objects <ref> [4, 27, 3] </ref>, etc. with each of which it shares some similarities and differences. Even at this level, Charm probably was one of the first such systems implemented in portable manner [11] with support for dynamic load balancing.
References-found: 27

