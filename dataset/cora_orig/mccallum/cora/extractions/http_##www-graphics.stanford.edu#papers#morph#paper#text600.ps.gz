URL: http://www-graphics.stanford.edu/papers/morph/paper/text600.ps.gz
Refering-URL: http://www-graphics.stanford.edu/papers/morph/
Root-URL: http://www.cs.stanford.edu
Title: Feature-Based Volume Metamorphosis  
Author: Apostolos Lerios, Chase D. Garfinkle, Marc Levoy 
Keyword: CR Categories: I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. Additional Keywords: Volume morphing, warping, rendering; sculpting; shape interpolation, transformation, blending; computer animation.  
Affiliation: Computer Science Department Stanford University  
Abstract: Image metamorphosis, or image morphing, is a popular technique for creating a smooth transition between two images. For synthetic images, transforming and rendering the underlying three-dimensional (3D) models has a number of advantages over morphing between two pre-rendered images. In this paper we consider 3D metamorphosis applied to volume-based representations of objects. We discuss the issues which arise in volume morphing and present a method for creating morphs. Our morphing method has two components: first a warping of the two input volumes, then a blending of the resulting warped volumes. The warping component, an extension of Beier and Neely's image warping technique to 3D, is feature-based and allows fine user control, thus ensuring realistic looking intermediate objects. In addition, our warping method is amenable to an efficient approximation which gives a 50 times speedup and is computable to arbitrary accuracy. Also, our technique corrects the ghosting problem present in Beier and Neely's technique. The second component of the morphing process, blending, is also under user control; this guarantees smooth transitions in the renderings. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Beier and S. Neely. </author> <title> Pacific Data Images. </title> <type> Personal communication. </type>
Reference-contexts: This optimization has been applied to 2D morphing systems, as well; by using common texture-mapping hardware 5 We always use an error tolerance of a single voxel width and an initial subdivision of 15 3 cells. to warp the images, 2D morphs can be generated at interac-tive rates <ref> [1] </ref>. 5.2 Octree Subdivision V usually contains large "empty" regions, that is, regions which are completely transparent. The warp will map these parts of V into empty regions of V 0 .
Reference: [2] <author> T. Beier and S. Neely. </author> <title> Feature-based image metamorphosis. </title> <journal> In Computer Graphics, </journal> <volume> vol 26(2), </volume> <pages> pp 35-42, </pages> <address> New York, NY, </address> <month> July </month> <year> 1992. </year> <note> Proceedings of SIGGRAPH '92. </note>
Reference-contexts: 1 Introduction 1.1 Image Morphing versus 3D Morphing Image morphing, the construction of an image sequence depicting a gradual transition between two images, has been extensively investigated [21] <ref> [2] </ref> [6] [16]. <p> Each representation requires different morphing algorithms. This dichotomy parallels the separation of 2D morphing techniques into those that operate on raster images [21] <ref> [2] </ref> [6], and those that assume vector-based image representations [16]. We believe that volume-based descriptions are more appropriate for 3D morphing for the following reasons: * The quality and applicability of geometric 3D morphing techniques [12] is highly dependent on the models' geometric primitives and their topological properties. <p> Blending: S 0 and T 0 are combined into one volume, the morph. Our blending technique provides the user with sufficient control to create a smooth morph. 1.4 Prior Work Prior work on feature-based 2D morphing <ref> [2] </ref> will be discussed in section 3. Prior work in volume morphing comprises [9], [8], and [5]. These approaches can be summarized in terms of our warping/blending framework. [5] and [8] have both presented warping techniques. [5] examined the theory of extending selected 2D warping techniques into 3D. <p> However, regular grids provide a cumbersome interface in 2D; in 3D they would likely become unmanageable. Also, prohibitively many scattered points are needed to adequately specify a 3D warp. Our solution is a feature-based approach extending the work of <ref> [2] </ref> into the 3D domain. The next two sections will introduce our feature-based 3D warping and discuss the UI to feature specification. 3.1 Feature-Based 3D Warping using Fields The purpose of a feature element is to identify a feature of an object. <p> For example, a box magnet defines the path of points within and near the box; points further from the box are influenced less as their distance increases. The reader familiar with the 2D technique of <ref> [2] </ref> will notice two differences between our 3D elements and a direct extention of 2D feature lines into 3D; in fact, these are the only differences as far as the warping algorithm is concerned. result of squeezing a circle using two feature lines placed on opposite sides of the circle. <p> Second, our feature elements encode the 3D extent of a 3D feature via the scaling factors s x , s y , and s z ; by contrast, feature lines in <ref> [2] </ref> capture only the 1D extent of a 2D feature, in the direction of each feature line. These scaling factors introduce additional degrees of freedom for each feature element. In the majority of situations, these extra degrees have a minor effect on the warp and may thus be ignored. <p> These scaling factors introduce additional degrees of freedom for each feature element. In the majority of situations, these extra degrees have a minor effect on the warp and may thus be ignored. However, under extreme warps, they permit the user to solve the ghosting problem, documented in <ref> [2] </ref> and illustrated in figure 2. For instance, in part (b) of this example, the ellipsoid is replicated because each feature line requires that an unscaled ellipsoid appear by its side: the feature lines in [2] cannot specify any stretching in the perpendicular direction. <p> However, under extreme warps, they permit the user to solve the ghosting problem, documented in <ref> [2] </ref> and illustrated in figure 2. For instance, in part (b) of this example, the ellipsoid is replicated because each feature line requires that an unscaled ellipsoid appear by its side: the feature lines in [2] cannot specify any stretching in the perpendicular direction. However, in a 2D analogue of our technique, the user would use the lines' scaling factors to stretch the ellipsoid. First, the user would encode the ellipsoid's width in the scaling factors of the original feature lines. <p> In fact, using our technique, a single feature line suffices to turn the ellipsoid into a circle. Element Pairs As in the 2D morphing system of <ref> [2] </ref>, the animator identifies two corresponding features in S and T , by defining a pair of elements (e s ; e t ). These features should be transformed to one another during the morph. <p> point c + p x s x x + p y s y y + p z s z z. 2 Collections of Element Pairs In extending the warping algorithm of the previous paragraph to multiple element pairs, we adhere to the intuitive mental model of magnetic sculpting used in <ref> [2] </ref>. Each pair of elements defines a field that extends throughout the volume. A collection of element pairs defines a collection of fields, all of which influence each point in the volume. <p> This definition is identical to [21]. Segments: The element is treated as a line segment centered at the origin c, aligned with the local x-axis and having length s x ; d is the distance of p 0 from this line segment. This definition is identical to <ref> [2] </ref>. Rectangles: Rectangles have the same center and x extent as segments, but also extend into a second dimension, having width s y along the local y-axis. d is zero if p 0 is on the rectangle, otherwise it is the distance of p 0 from the rectangle. <p> In the first step, our feature-based warping algorithm allows fine user control, and thus ensures realistic morphs. In addition, our warping method is amenable to an efficient, adaptive approximation which gives a 50 times speedup. Also, our technique corrects the ghost-ing problem of <ref> [2] </ref>.
Reference: [3] <author> B. P. Bergeron. </author> <title> Morphing as a means of generating variation in visual medical teaching materials. </title> <journal> Computers in Biology and Medicine, </journal> <volume> 24(1) </volume> <pages> 11-18, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: Blending: Blending can be improved by allowing local definition of the blending rate, associating an interpolation schedule with each feature element. Morphing's primary application has been in the entertainment industry. However, it can also be used as a general visualization tool for illustration and teaching purposes <ref> [3] </ref>; for example, our orangutan to human morph could be used as a means of visualizing Darwinian evolution. Finally, our feature-based warping technique can be used in modeling and sculpting.
Reference: [4] <author> B. Cabral, N. Cam, and J. Foran. </author> <title> Accelerated volume rendering and tomographic reconstruction using texture mapping hardware. </title> <editor> In A. Kaufman and W. Krueger, editors, </editor> <booktitle> Proceedings of the 1994 Symposium on Volume Visualization, </booktitle> <pages> pp 91-98, </pages> <address> New York, NY, </address> <month> Oct. </month> <year> 1994. </year> <journal> ACM SIGGRAPH and IEEE Computer Society. </journal>
Reference-contexts: However, a variety of element types maintains best the intuitive conceptual analogy to magnetic sculpting. 3.2 User Interface The UI to the warping algorithm has to depict the source and target volumes, in conjunction with the feature elements. Hardware-assisted volume rendering <ref> [4] </ref> makes possible a UI solely based on direct visualization of the volumes, with the embedded elements interactively scan-converted. Using a low-end rendering pipeline, however, the UI has to resort to geometric representations of the models embedded in the volumes.
Reference: [5] <author> M. Chen, M. W. Jones, and P. Townsend. </author> <title> Methods for volume metamorphosis. To appear in Image Processing for Broadcast and Video Production, </title> <editor> Y. Paker and S. Wilbur editors, </editor> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1995. </year>
Reference-contexts: Our blending technique provides the user with sufficient control to create a smooth morph. 1.4 Prior Work Prior work on feature-based 2D morphing [2] will be discussed in section 3. Prior work in volume morphing comprises [9], [8], and <ref> [5] </ref>. These approaches can be summarized in terms of our warping/blending framework. [5] and [8] have both presented warping techniques. [5] examined the theory of extending selected 2D warping techniques into 3D. <p> Prior work in volume morphing comprises [9], [8], and <ref> [5] </ref>. These approaches can be summarized in terms of our warping/blending framework. [5] and [8] have both presented warping techniques. [5] examined the theory of extending selected 2D warping techniques into 3D. <p> Prior work in volume morphing comprises [9], [8], and <ref> [5] </ref>. These approaches can be summarized in terms of our warping/blending framework. [5] and [8] have both presented warping techniques. [5] examined the theory of extending selected 2D warping techniques into 3D.
Reference: [6] <author> M. Covell and M. Withgott. </author> <title> Spanning the gap between motion estimation and morphing. </title> <booktitle> In Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> vol 5, </volume> <pages> pp 213-216, </pages> <address> New York, NY, 1994. </address> <publisher> IEEE. </publisher>
Reference-contexts: 1 Introduction 1.1 Image Morphing versus 3D Morphing Image morphing, the construction of an image sequence depicting a gradual transition between two images, has been extensively investigated [21] [2] <ref> [6] </ref> [16]. <p> Each representation requires different morphing algorithms. This dichotomy parallels the separation of 2D morphing techniques into those that operate on raster images [21] [2] <ref> [6] </ref>, and those that assume vector-based image representations [16]. We believe that volume-based descriptions are more appropriate for 3D morphing for the following reasons: * The quality and applicability of geometric 3D morphing techniques [12] is highly dependent on the models' geometric primitives and their topological properties. <p> More complex, but more expressive feature elements [11] may also be designed. User Interface: We envision improving our UI by adding computer-assisted feature identification: the computer suggesting features by landmark data extraction [18], 3D edge identification, or, as in 2D morphing, by motion estimation <ref> [6] </ref>. Also, we are considering giving the user more flexible control over the movement of feature elements during the morph, i.e. the rule by which interpolated elements are constructed, perhaps by key framed or spline-path motion.
Reference: [7] <author> T. A. Galyean and J. F. Hughes. </author> <title> Sculpting: An interactive volumetric modeling technique. </title> <journal> In Computer Graphics, </journal> <volume> vol 25(4), </volume> <pages> pp 267-274, </pages> <address> New York, NY, </address> <month> July </month> <year> 1991. </year> <note> Proceedings of SIGGRAPH '91. </note>
Reference-contexts: Scan converted geometric models: A geometric model can be voxelized [10], preferably with antialiasing [20], generating a volume-based representation of the model. Figures 6 (a), 6 (b), 7 (a), and 7 (b) show examples of scan-converted volumes. Interactive sculpting: Interactive modeling, or sculpting [19] <ref> [7] </ref>, can generate volume data directly. Procedural definition: Hypertexture volumes [15] can be defined procedurally by functions over 3D space. 3 Warping The first step in the volume morphing pipeline is warping the source and target volumes S and T .
Reference: [8] <author> T. He, S. Wang, and A. Kaufman. </author> <title> Wavelet-based volume morphing. </title> <editor> In D. Bergeron and A. Kaufman, editors, </editor> <booktitle> Proceedings of Visualization '94, </booktitle> <pages> pp 85-91, </pages> <address> Los Alamitos, CA, </address> <month> Oct. </month> <year> 1994. </year> <journal> IEEE Computer Society and ACM SIGGRAPH. </journal>
Reference-contexts: Our blending technique provides the user with sufficient control to create a smooth morph. 1.4 Prior Work Prior work on feature-based 2D morphing [2] will be discussed in section 3. Prior work in volume morphing comprises [9], <ref> [8] </ref>, and [5]. These approaches can be summarized in terms of our warping/blending framework. [5] and [8] have both presented warping techniques. [5] examined the theory of extending selected 2D warping techniques into 3D. A UI was not presented, however, and only morphs of simple objects were shown. [8] presents an <p> Prior work in volume morphing comprises [9], <ref> [8] </ref>, and [5]. These approaches can be summarized in terms of our warping/blending framework. [5] and [8] have both presented warping techniques. [5] examined the theory of extending selected 2D warping techniques into 3D. A UI was not presented, however, and only morphs of simple objects were shown. [8] presents an algorithm which attempts to automatically identify correspondences between the volumes, without the aid of user input. <p> comprises [9], <ref> [8] </ref>, and [5]. These approaches can be summarized in terms of our warping/blending framework. [5] and [8] have both presented warping techniques. [5] examined the theory of extending selected 2D warping techniques into 3D. A UI was not presented, however, and only morphs of simple objects were shown. [8] presents an algorithm which attempts to automatically identify correspondences between the volumes, without the aid of user input. [9] and [8] have suggested using a frequency or wavelet representation of the volumes to perform the blending, allowing different interpolation schedules across subbands. <p> A UI was not presented, however, and only morphs of simple objects were shown. <ref> [8] </ref> presents an algorithm which attempts to automatically identify correspondences between the volumes, without the aid of user input. [9] and [8] have suggested using a frequency or wavelet representation of the volumes to perform the blending, allowing different interpolation schedules across subbands. In addition, they have observed that isosurfaces of the morphs may move abruptly, or even completely disappear and reappear as the morph progresses, destroying its continuity.
Reference: [9] <author> J. F. Hughes. </author> <title> Scheduled Fourier volume morphing. </title> <journal> In Computer Graphics, </journal> <volume> vol 26(2), </volume> <pages> pp 43-46, </pages> <address> New York, NY, </address> <month> July </month> <year> 1992. </year> <note> Proceedings of SIGGRAPH '92. </note>
Reference-contexts: Blending: S 0 and T 0 are combined into one volume, the morph. Our blending technique provides the user with sufficient control to create a smooth morph. 1.4 Prior Work Prior work on feature-based 2D morphing [2] will be discussed in section 3. Prior work in volume morphing comprises <ref> [9] </ref>, [8], and [5]. These approaches can be summarized in terms of our warping/blending framework. [5] and [8] have both presented warping techniques. [5] examined the theory of extending selected 2D warping techniques into 3D. <p> A UI was not presented, however, and only morphs of simple objects were shown. [8] presents an algorithm which attempts to automatically identify correspondences between the volumes, without the aid of user input. <ref> [9] </ref> and [8] have suggested using a frequency or wavelet representation of the volumes to perform the blending, allowing different interpolation schedules across subbands. In addition, they have observed that isosurfaces of the morphs may move abruptly, or even completely disappear and reappear as the morph progresses, destroying its continuity.
Reference: [10] <author> A. Kaufman, D. Cohen, and R. </author> <title> Yagel. </title> <journal> Volume graphics. Computer, </journal> <volume> 26(7) </volume> <pages> 51-64, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Scanned volumes: Some scanning technologies, such as Computerized Tomography (CT) or Magnetic Resonance Imaging (MRI) generate volume data. Figures 5 (a) and 5 (c) show CT scans of a human and an orangutan head, respectively. Scan converted geometric models: A geometric model can be voxelized <ref> [10] </ref>, preferably with antialiasing [20], generating a volume-based representation of the model. Figures 6 (a), 6 (b), 7 (a), and 7 (b) show examples of scan-converted volumes. Interactive sculpting: Interactive modeling, or sculpting [19] [7], can generate volume data directly.
Reference: [11] <author> A. Kaul and J. Rossignac. </author> <title> Solid-interpolating deformations: Construction and animation of PIPs. </title> <editor> In F. H. Post and W. Barth, editors, </editor> <volume> Eurographics '91, </volume> <pages> pp 493-505, </pages> <address> Amsterdam, The Nether-lands, </address> <month> Sept. </month> <year> 1991. </year> <title> Eurographics Association, </title> <publisher> North-Holland. </publisher>
Reference-contexts: More complex, but more expressive feature elements <ref> [11] </ref> may also be designed. User Interface: We envision improving our UI by adding computer-assisted feature identification: the computer suggesting features by landmark data extraction [18], 3D edge identification, or, as in 2D morphing, by motion estimation [6].
Reference: [12] <author> J. R. Kent, W. E. Carlson, and R. E. Parent. </author> <title> Shape transformation for polyhedral objects. </title> <journal> In Computer Graphics, </journal> <volume> vol 26(2), </volume> <pages> pp 47-54, </pages> <address> New York, NY, </address> <month> July </month> <year> 1992. </year> <note> Proceedings of SIGGRAPH '92. </note>
Reference-contexts: We believe that volume-based descriptions are more appropriate for 3D morphing for the following reasons: * The quality and applicability of geometric 3D morphing techniques <ref> [12] </ref> is highly dependent on the models' geometric primitives and their topological properties.
Reference: [13] <author> P. Litwinowicz. </author> <title> Efficient techniques for interactive texture placement. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pp 119-122, </pages> <address> New York, NY, </address> <month> July </month> <year> 1994. </year> <booktitle> Conference Proceedings of SIGGRAPH '94. </booktitle>
Reference-contexts: This group of algorithms includes free-form deformations [17], as well as semi-automatic medical data alignment [18]. As stated in section 1.3, user control over the warps is crucial in designing good morphs. Point-to-point mapping methods [21], in the form of either regular lattices or scattered points <ref> [13] </ref>, have worked in 2D. However, regular grids provide a cumbersome interface in 2D; in 3D they would likely become unmanageable. Also, prohibitively many scattered points are needed to adequately specify a 3D warp. Our solution is a feature-based approach extending the work of [2] into the 3D domain. <p> The dotted rectangles mark image buffer borders. We have implemented two optimizations which greatly accelerate the computation of the warped volume V 0 , where we henceforth use V to denote either S or T . First, we approximate the spatially non-linear warping function with a piecewise linear warp <ref> [13] </ref>. Second, we introduce an octree subdivision over V. 5.1 Piecewise Linear Approximation The 2D form of this optimization, shown in figure 4, illustrates its key steps within the familiar framework of image warping.
Reference: [14] <author> W. E. Lorensen and H. E. Cline. </author> <title> Marching cubes: A high resolution 3-D surface construction algorithm. </title> <journal> In Computer Graphics, </journal> <volume> vol 21(4), </volume> <pages> pp 163-169, </pages> <address> New York, NY, </address> <month> July </month> <year> 1987. </year> <note> Proceedings of SIGGRAPH '87. </note>
Reference-contexts: Using a low-end rendering pipeline, however, the UI has to resort to geometric representations of the models embedded in the volumes. These geometric representations can be obtained in either of two ways: * Pre-existing volumes are visualized by isosurface extraction via marching cubes <ref> [14] </ref>. Several different iso-surfaces can be extracted to visualize all prominent features of the volume, a volume rendering guiding the extraction process. * For volumes that were obtained by scan converting ge ometric models, the original model can be used.
Reference: [15] <author> K. Perlin and E. M. Hoffert. </author> <title> Hypertexture. </title> <journal> In Computer Graphics, </journal> <volume> vol 23(3), </volume> <pages> pp 253-262, </pages> <address> New York, NY, </address> <month> July </month> <year> 1989. </year> <note> Proceedings of SIGGRAPH '89. </note>
Reference-contexts: Figures 6 (a), 6 (b), 7 (a), and 7 (b) show examples of scan-converted volumes. Interactive sculpting: Interactive modeling, or sculpting [19] [7], can generate volume data directly. Procedural definition: Hypertexture volumes <ref> [15] </ref> can be defined procedurally by functions over 3D space. 3 Warping The first step in the volume morphing pipeline is warping the source and target volumes S and T . Volume warping has been the subject of several investigations in computer graphics, computer vision, and medicine.
Reference: [16] <author> T. W. Sedeberg, P. Gao, G. Wang, and H. </author> <title> Mu. 2-D shape blending: An intrinsic solution to the vertex path problem. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pp 15-18, </pages> <address> New York, NY, </address> <month> Aug. </month> <year> 1993. </year> <booktitle> Conference Proceedings of SIGGRAPH '93. </booktitle>
Reference-contexts: 1 Introduction 1.1 Image Morphing versus 3D Morphing Image morphing, the construction of an image sequence depicting a gradual transition between two images, has been extensively investigated [21] [2] [6] <ref> [16] </ref>. <p> Each representation requires different morphing algorithms. This dichotomy parallels the separation of 2D morphing techniques into those that operate on raster images [21] [2] [6], and those that assume vector-based image representations <ref> [16] </ref>. We believe that volume-based descriptions are more appropriate for 3D morphing for the following reasons: * The quality and applicability of geometric 3D morphing techniques [12] is highly dependent on the models' geometric primitives and their topological properties.
Reference: [17] <author> T. W. Sederberg and S. R. Parry. </author> <title> Free-form deformations of solid geometric models. </title> <journal> In Computer Graphics, </journal> <volume> vol 20(4), </volume> <pages> pp 151-160, </pages> <address> New York, NY, </address> <month> Aug. </month> <year> 1986. </year> <note> Proceedings of SIGGRAPH '86. </note>
Reference-contexts: The rest of the volume is then warped by interpolating the warping function. This group of algorithms includes free-form deformations <ref> [17] </ref>, as well as semi-automatic medical data alignment [18]. As stated in section 1.3, user control over the warps is crucial in designing good morphs. Point-to-point mapping methods [21], in the form of either regular lattices or scattered points [13], have worked in 2D.
Reference: [18] <author> P. A. van den Elsen, E.-J. D. Pol, and M. A. Viergever. </author> <title> Medical image matching | a review with classification. </title> <journal> IEEE Engineering in Medicine and Biology Magazine, </journal> <volume> 12(1) </volume> <pages> 26-39, </pages> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: Warping techniques can be coarsely classified into two groups: (i) Techniques that allow only minimal user control, consisting of at most a few scalar parameters. These algorithms automatically determine similarities between two volumes, and then seek the warp which transforms the first volume to the second one <ref> [18] </ref>. (ii) Techniques in which user control consists of manually specifying the warp for a collection of points in the volume. The rest of the volume is then warped by interpolating the warping function. This group of algorithms includes free-form deformations [17], as well as semi-automatic medical data alignment [18]. <p> one <ref> [18] </ref>. (ii) Techniques in which user control consists of manually specifying the warp for a collection of points in the volume. The rest of the volume is then warped by interpolating the warping function. This group of algorithms includes free-form deformations [17], as well as semi-automatic medical data alignment [18]. As stated in section 1.3, user control over the warps is crucial in designing good morphs. Point-to-point mapping methods [21], in the form of either regular lattices or scattered points [13], have worked in 2D. <p> More complex, but more expressive feature elements [11] may also be designed. User Interface: We envision improving our UI by adding computer-assisted feature identification: the computer suggesting features by landmark data extraction <ref> [18] </ref>, 3D edge identification, or, as in 2D morphing, by motion estimation [6]. Also, we are considering giving the user more flexible control over the movement of feature elements during the morph, i.e. the rule by which interpolated elements are constructed, perhaps by key framed or spline-path motion.
Reference: [19] <author> S. W. Wang and A. Kaufman. </author> <title> Volume sculpting. </title> <booktitle> In Proceedings of 1995 Symposium on Interactive 3D Graphics, </booktitle> <pages> pp 151-156, 214, </pages> <address> New York, NY, </address> <month> Apr. </month> <year> 1995. </year> <note> ACM SIGGRAPH. </note>
Reference-contexts: Scan converted geometric models: A geometric model can be voxelized [10], preferably with antialiasing [20], generating a volume-based representation of the model. Figures 6 (a), 6 (b), 7 (a), and 7 (b) show examples of scan-converted volumes. Interactive sculpting: Interactive modeling, or sculpting <ref> [19] </ref> [7], can generate volume data directly. Procedural definition: Hypertexture volumes [15] can be defined procedurally by functions over 3D space. 3 Warping The first step in the volume morphing pipeline is warping the source and target volumes S and T .
Reference: [20] <author> S. W. Wang and A. E. Kaufman. </author> <title> Volume sampled voxelization of geometric primitives. </title> <editor> In G. M. Nielson and D. Bergeron, editors, </editor> <booktitle> Proceedings of Visualization '93, </booktitle> <pages> pp 78-84, </pages> <address> Los Alamitos, CA, </address> <month> Oct. </month> <year> 1993. </year> <journal> IEEE Computer Society and ACM SIGGRAPH. </journal>
Reference-contexts: Scanned volumes: Some scanning technologies, such as Computerized Tomography (CT) or Magnetic Resonance Imaging (MRI) generate volume data. Figures 5 (a) and 5 (c) show CT scans of a human and an orangutan head, respectively. Scan converted geometric models: A geometric model can be voxelized [10], preferably with antialiasing <ref> [20] </ref>, generating a volume-based representation of the model. Figures 6 (a), 6 (b), 7 (a), and 7 (b) show examples of scan-converted volumes. Interactive sculpting: Interactive modeling, or sculpting [19] [7], can generate volume data directly.
Reference: [21] <author> G. Wolberg. </author> <title> Digital Image Warping. </title> <publisher> IEEE Computer Society P., Los Alamitos, </publisher> <address> CA, </address> <year> 1990. </year>
Reference-contexts: 1 Introduction 1.1 Image Morphing versus 3D Morphing Image morphing, the construction of an image sequence depicting a gradual transition between two images, has been extensively investigated <ref> [21] </ref> [2] [6] [16]. <p> Each representation requires different morphing algorithms. This dichotomy parallels the separation of 2D morphing techniques into those that operate on raster images <ref> [21] </ref> [2] [6], and those that assume vector-based image representations [16]. We believe that volume-based descriptions are more appropriate for 3D morphing for the following reasons: * The quality and applicability of geometric 3D morphing techniques [12] is highly dependent on the models' geometric primitives and their topological properties. <p> The rest of the volume is then warped by interpolating the warping function. This group of algorithms includes free-form deformations [17], as well as semi-automatic medical data alignment [18]. As stated in section 1.3, user control over the warps is crucial in designing good morphs. Point-to-point mapping methods <ref> [21] </ref>, in the form of either regular lattices or scattered points [13], have worked in 2D. However, regular grids provide a cumbersome interface in 2D; in 3D they would likely become unmanageable. Also, prohibitively many scattered points are needed to adequately specify a 3D warp. <p> This definition is identical to <ref> [21] </ref>. Segments: The element is treated as a line segment centered at the origin c, aligned with the local x-axis and having length s x ; d is the distance of p 0 from this line segment. This definition is identical to [2].
References-found: 21

