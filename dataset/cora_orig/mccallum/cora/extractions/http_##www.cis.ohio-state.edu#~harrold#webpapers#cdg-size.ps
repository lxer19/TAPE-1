URL: http://www.cis.ohio-state.edu/~harrold/webpapers/cdg-size.ps
Refering-URL: http://www.cis.ohio-state.edu/~harrold/allpapers.html
Root-URL: 
Email: harrold@cis.ohio-state.edu jjones@cis.ohio-state.edu grother@cs.orst.edu  
Title: Empirical Studies of Control Dependence Graph Size for C Programs  
Author: Mary Jean Harrold James A. Jones Gregg Rothermel 
Address: 307A Dearborn Hall Columbus, OH 43210 Columbus, OH 43210 Corvallis, OR 97331  
Affiliation: Computer and Information Science Computer and Information Science Computer Science Ohio State University Ohio State University Oregon State University 395 Dreese Lab 395 Dreese Lab  
Abstract: Many tools and techniques for performing software engineering tasks require control dependence information, represented in the form of control dependence graphs. Worst-case analysis of these graphs has shown that their size may be quadratic in the number of statements in the procedure that they represent. Despite this result, two empirical studies suggest that in practice, the relationship between control dependence graph size and program size is linear. These studies, however, were performed on a relatively small number of Fortran procedures, all of which were derived from numerical methods programs. To further investigate control dependence size, we implemented tools for constructing the two most popular types of control dependence graphs, and ran our tools on over 3000 C functions extracted from a wide range of source programs. Our results support the earlier conclusions about control dependence graph size, and also suggest that the difference in size between the two types of control dependence graph is insignificant.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Agrawal, R. DeMillo, and E. Spafford. </author> <title> Dynamic slicing in the presence of unconstrained pointers. </title> <booktitle> In Proceedings of the Symposium on Testing, Analysis and Verification, </booktitle> <pages> pages 60-73, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications [2, 4, 5, 10, 15, 16], integrating different versions of programs [13], and performing static and dynamic slicing <ref> [1, 3] </ref> all use such information. To represent control dependence information, these techniques typically use control dependence graphs. Attempts to scale these techniques to handle large programs are constrained by the memory and disk space required to construct and store the control dependence graphs for these programs.
Reference: [2] <author> H. Agrawal, J. Horgan, E. Krauser, and S. </author> <title> London. Incremental regression testing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1993, </booktitle> <pages> pages 348-357, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Many software engineering techniques and tools rely on control-dependence information. Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications <ref> [2, 4, 5, 10, 15, 16] </ref>, integrating different versions of programs [13], and performing static and dynamic slicing [1, 3] all use such information. To represent control dependence information, these techniques typically use control dependence graphs.
Reference: [3] <author> H. Agrawal and J. R. Horgan. </author> <title> Dynamic program slicing. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 246-56, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications [2, 4, 5, 10, 15, 16], integrating different versions of programs [13], and performing static and dynamic slicing <ref> [1, 3] </ref> all use such information. To represent control dependence information, these techniques typically use control dependence graphs. Attempts to scale these techniques to handle large programs are constrained by the memory and disk space required to construct and store the control dependence graphs for these programs.
Reference: [4] <author> S. Bates and S. Horwitz. </author> <title> Incremental program testing using program dependence graphs. </title> <booktitle> In Proceedings of the 20th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 384-396, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Many software engineering techniques and tools rely on control-dependence information. Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications <ref> [2, 4, 5, 10, 15, 16] </ref>, integrating different versions of programs [13], and performing static and dynamic slicing [1, 3] all use such information. To represent control dependence information, these techniques typically use control dependence graphs.
Reference: [5] <author> D. Binkley. </author> <title> Using semantic differencing to reduce the cost of regression testing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1992, </booktitle> <pages> pages 41-50, </pages> <month> November </month> <year> 1992. </year> <title> 5 executable statements, and the vertical axis represents the sizes of control-dependence graph with region nodes. executable statements, and the vertical axis represents sizes of control-dependence graph without region nodes. </title> <type> 6 </type>
Reference-contexts: 1 Introduction Many software engineering techniques and tools rely on control-dependence information. Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications <ref> [2, 4, 5, 10, 15, 16] </ref>, integrating different versions of programs [13], and performing static and dynamic slicing [1, 3] all use such information. To represent control dependence information, these techniques typically use control dependence graphs.
Reference: [6] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K . Zadeck. </author> <title> An efficient method of computing static single assignment form. </title> <booktitle> In POPL89, </booktitle> <pages> pages 25-35, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: To represent control dependence information, these techniques typically use control dependence graphs. Attempts to scale these techniques to handle large programs are constrained by the memory and disk space required to construct and store the control dependence graphs for these programs. A worst-case analysis by Cytron et al. <ref> [6] </ref> shows that the size of the control-dependence graph for a procedure P can be quadratic in the size of the control-flow graph for P , and hence, quadratic in the number of statements in P .
Reference: [7] <author> R. Cytron, J Ferrante, and V. Sarkar. </author> <title> Compact representations for control dependence. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 337-351, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: However, in a study using the 61 Fortran routines in Eispack [17] (a set of matrix Eigensystem routines), Cytron et al. found that, in practice, the relationship between control-dependence graph size and program size is linear. A larger study by Cytron, Ferrante, and Sarkar <ref> [7] </ref> on over 400 Fortran procedures from several popular numerical analysis programs also showed a linear relationship between the size of the control-dependence graph and the number of program statements.
Reference: [8] <author> E. Duesterwald, R. Gupta, and M. L. Soffa. </author> <title> Rigorous data flow testing through output influences. </title> <booktitle> In Second Irvine Software Symposium , pages 131-145, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Many software engineering techniques and tools rely on control-dependence information. Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches <ref> [8] </ref>, generating reduced test sets for programs [11], determining the retesting required after program modifications [2, 4, 5, 10, 15, 16], integrating different versions of programs [13], and performing static and dynamic slicing [1, 3] all use such information.
Reference: [9] <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Control dependence is defined in terms of control-flow graphs and the postdominance relation <ref> [9] </ref>. <p> A control-dependence graph contains several types of nodes. Statement nodes, shown as ellipses, represent simple statements. Predicate nodes, depicted as squares, correspond to statements from which two edges may originate. Node numbers labeling statement and predicate nodes correspond to statement numbers in the program. Ferrante, Ottenstein, and Warren <ref> [9] </ref> give a method for inserting region nodes that summarize nodes with identical control dependencies. The control-dependence graph for Sums with region nodes inserted is shown in the lower right of Figure 1. Region nodes, shown as circles in the figure, group nodes that share the same control dependencies. <p> Aristotle processes C source code, and computes various types of information for use in code-based analysis tools. One of these code-based analysis tools uses a function's control-flow graph to construct a control-dependence graph with region nodes for the function, following the algorithm given in <ref> [9] </ref>. We also implemented a tool that takes a control-dependence graph with region nodes as input, and creates the corresponding control-dependence graph without region nodes. 1 This definition of postdominance does not include the initial node on the path; thus, a node never postdominates itself. 3 Number of Avg.
Reference: [10] <author> R. Gupta, M. J. Harrold, and M. L. Soffa. </author> <title> An approach to regression testing using slicing. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1992, </booktitle> <pages> pages 299-308, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Many software engineering techniques and tools rely on control-dependence information. Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications <ref> [2, 4, 5, 10, 15, 16] </ref>, integrating different versions of programs [13], and performing static and dynamic slicing [1, 3] all use such information. To represent control dependence information, these techniques typically use control dependence graphs.
Reference: [11] <author> R. Gupta and M. L. Soffa. </author> <title> Employing static information in the generation of test cases. </title> <journal> Journal of Software Testing, Verification and Reliability, </journal> <volume> 3(1) </volume> <pages> 29-48, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Many software engineering techniques and tools rely on control-dependence information. Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs <ref> [11] </ref>, determining the retesting required after program modifications [2, 4, 5, 10, 15, 16], integrating different versions of programs [13], and performing static and dynamic slicing [1, 3] all use such information. To represent control dependence information, these techniques typically use control dependence graphs.
Reference: [12] <author> M. J. Harrold, L. Larsen, J. Lloyd, D. Nedved, M. Page, G. Rothermel, M. Singh, and M. Smith. Aristotle: </author> <title> A system for the development of program-analysis-based tools. </title> <booktitle> In Proceedings of the 33rd Annual Southeast Conference, </booktitle> <pages> pages 110-119, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Evaluation of the hypothesis required tools for constructing control dependence graphs, and a sample population of C functions. To construct control dependence graphs, and gather data about those graphs and about our subjects, we used the Aristotle analysis system <ref> [12] </ref>. Aristotle processes C source code, and computes various types of information for use in code-based analysis tools. One of these code-based analysis tools uses a function's control-flow graph to construct a control-dependence graph with region nodes for the function, following the algorithm given in [9].
Reference: [13] <author> S. Horwitz, J. Prins, and T. Reps. </author> <title> Integrating non-interfering versions of programs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(3) </volume> <pages> 345-387, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications [2, 4, 5, 10, 15, 16], integrating different versions of programs <ref> [13] </ref>, and performing static and dynamic slicing [1, 3] all use such information. To represent control dependence information, these techniques typically use control dependence graphs.
Reference: [14] <author> B. Korel. </author> <title> The program dependence graph in static program testing. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 103-108, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: 1 Introduction Many software engineering techniques and tools rely on control-dependence information. Techniques for selecting test data and determining test set adequacy <ref> [14] </ref>, extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications [2, 4, 5, 10, 15, 16], integrating different versions of programs [13], and performing static and dynamic slicing [1, 3] all use such information.
Reference: [15] <author> G. Rothermel and M. J. Harrold. </author> <title> A safe, efficient algorithm for regression test selection. </title> <booktitle> In Proceedings of the Conference on Software Maintenance - 1993, </booktitle> <pages> pages 358-367, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Many software engineering techniques and tools rely on control-dependence information. Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications <ref> [2, 4, 5, 10, 15, 16] </ref>, integrating different versions of programs [13], and performing static and dynamic slicing [1, 3] all use such information. To represent control dependence information, these techniques typically use control dependence graphs.
Reference: [16] <author> G. Rothermel and M. J. Harrold. </author> <title> Selecting tests and identifying test coverage requirements for modified software. </title> <booktitle> In Proceedings of the 1994 International Symposium on Software Testing and Analysis, </booktitle> <pages> pages 169-184, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Many software engineering techniques and tools rely on control-dependence information. Techniques for selecting test data and determining test set adequacy [14], extending data-flow testing approaches [8], generating reduced test sets for programs [11], determining the retesting required after program modifications <ref> [2, 4, 5, 10, 15, 16] </ref>, integrating different versions of programs [13], and performing static and dynamic slicing [1, 3] all use such information. To represent control dependence information, these techniques typically use control dependence graphs.
Reference: [17] <author> B. T. Smith, J. M. Boyle, J. J. Dongarra, B. S. Garbow, Y. Ikebe, V. C. Klema, and C. B. Moler. </author> <title> Matrix Eigensystem Routines - Eispack Guide. </title> <publisher> Springer-Verlag, </publisher> <year> 1976. </year>
Reference-contexts: However, in a study using the 61 Fortran routines in Eispack <ref> [17] </ref> (a set of matrix Eigensystem routines), Cytron et al. found that, in practice, the relationship between control-dependence graph size and program size is linear.
Reference: [18] <author> J. M. Smith. </author> <title> MCC: A modular and extensible C compiler. </title> <type> Master's thesis, </type> <institution> Clemson University, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: the maintenance, modification, and regeneration of programs. miscellaneous summarizes a number of small C programs, such as euclid.c, that have been used as subjects in studies of testing techniques. player is one module of the Internet game Empire, that we have used in studies of regression test selection techniques. mcc <ref> [18] </ref> is an experimental C compiler written to facilitate evaluation of machine dependent code optimizations. tcsh is version 6.04 of a Unix C shell. xvcg is version 1.30 of a compiler graph visualizer. Given the foregoing tools and C functions, we conducted two studies.
References-found: 18

