URL: ftp://ftp.cs.toronto.edu/pub/cogrob/sensing.ps.Z
Refering-URL: 
Root-URL: 
Email: hector@cs.toronto.edu  
Title: conditional plan What is planning in the presence of sensing? Scherl) and to Fahiem Bacchus,
Author: Hector J. Levesque ning Fangzhen Lin, Daniel Marcu, Ray Reiter, and Richard 
Address: Toronto, ON, M5S 3H5 Canada  
Affiliation: University of Toronto Cognitive Robotics group  Department of Computer Science University of Toronto  
Note: sensing action not  Copyright c 1996 American Association for Artificial Intelligence. All rights reserved. Thanks to the members of the  (Yves Lesperance,  5. This research was made possible by financial support from the Information Technology Research Center, the Institute for Robotics and Intelligent Systems, and the Natural Science and Engineering Research Council. They also had to pick up the asinine AAAI fee for extra pages. However, see [10]  Consider the following motivating example:  
Pubnum: no sensing).  
Abstract: The Airport Example Despite the existence of programs that are able to generate so-called conditional plans, there has yet to emerge a clear and general specification of what it is these programs are looking for: what exactly is a plan in this setting, and when is it correct? In this paper, we develop and motivate a specification within the situation calculus of conditional and iterative plans over domains that include binary sensing actions. The account is built on an existing theory of action which includes a solution to the frame problem, and an extension to it that handles sensing actions and the effect they have on the knowledge of a robot. Plans are taken to be programs in a new simple robot program language, and the planning task is to find a program that would be known by the robot at the outset to lead to a final situation where the goal is satisfied. This specification is used to analyze the correctness of a small example plan, as well as variants that have redundant or missing sensing actions. We also investigate whether the proposed robot program language is powerful enough to serve for any intuitively achievable goal. Much of high-level symbolic AI research has been concerned with planning: specifying the behaviour of intelligent agents by providing goals to be achieved or maintained. In the simplest case, the output of a planner is a sequence of actions to be performed by the agent. However, a number of researchers are investigating the topic of (see for example, [3, 9, 14, 17]) where the output, for one reason or another, is not expected to be a fixed sequence of actions, but a more general specification involving conditionals and iteration. In this paper, we will be concerned with conditional planning problems where what action to perform next in a plan may depend on the result of an earlier . The local airport has only two boarding gates, Gate A and Gate B. Every plane will be parked at one of the two gates. In the initial state, you are at home. From home, it is possible to go to the airport, and from there you can go directly to either gate. At the airport, it is also possible to check the departures screen, to find out what gate a flight will be using. Once at a gate, the only thing to do is to board the plane that is parked there. The goal is to be on the plane for Flight 123. There clearly is no sequence of actions that can be shown to achieve the desired goal: which gate to go to depends on the (runtime) result of checking the departure screen. Surprisingly, despite the existence of planners that are able to solve simple problems like this, there has yet to emerge a clear specification of what it is that these planners are looking for: what is a plan in this setting, and when is it correct? In this paper, we will propose a new definition, show some examples of plans that meet (and fail to meet) the specification, and argue for the utility of this specification independent of plan generation. What we will do in this paper is propose a new planning procedure. In many cases, existing procedures like the one presented in [3] will be adequate, given various representational restrictions. Moreover, our specification goes beyond what can be handled by existing planning procedures, including problems like the following: We begin with a supply of eggs, some of which may be bad, but at least 3 of which are good. We have a bowl and a saucer, which can be emptied at any time. It is possible to break a new egg into the saucer, if it is empty, or into the bowl. By smelling a container, it is possible to tell if it contains a bad egg. Also, the contents of the saucer can be transferred to the bowl. The goal is to get 3 good eggs and no bad ones into the bowl. While it is far from clear how to automatically generate a plan to solve a problem like this, our account, at least, will make clear what a solution ought to be. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Bacchus, J. Halpern, and H. Levesque. </author> <title> Reasoning about noisy sensors in the situation calculus. </title> <booktitle> In , pp. </booktitle> <pages> 1933-1940, </pages> <address> Montreal, August 1995. </address> <publisher> Morgan Kaufmann Publishing. </publisher>
Reference: [2] <author> E. Davis. </author> <title> Knowledge preconditions for plans. </title> <type> Technical Report 637, </type> <institution> Computer Science Department, </institution> <address> New York University, </address> <year> 1993. </year>
Reference: [3] <author> O. Etzioni, S. Hanks, D. Weld, D. Draper, N. Lesh, and M. Williamson. </author> <title> An approach to planning with incomplete information. </title> <booktitle> In , pp. </booktitle> <pages> 115-125, </pages> <address> Cambridge, MA, 1992. </address> <publisher> Morgan Kaufmann Publishing. </publisher>
Reference: [4] <author> O. Etzioni and S. Hanks. </author> <type> Personal comm., </type> <year> 1995. </year>
Reference: [5] <author> Cordell C. Green. </author> <title> Theorem proving by resolution as a basis for question-answering systems. </title> <booktitle> In , pp. </booktitle> <pages> 183-205. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1969. </year>
Reference-contexts: Of course, our specification does provide us with a planning procedure (of sorts): ( ) [ ( ) ( )] return We can also think of the as being returned by answer extraction <ref> [5] </ref> from an attempt to prove the following: = ( ) [ ( ) ( )] Either way, the procedure would be problematic: we are searching blindly through the space of all possible robot programs, and for each one, the constraint to check involves using the fluent explicitly as well as
Reference: [6] <author> F. Lin and R. Reiter. </author> <title> How to progress a database II: The STRIPS connection. </title> <booktitle> In , pp. </booktitle> <pages> 2001-2007, </pages> <address> Montreal, </address> <month> Aug. </month> <pages> 20-25, </pages> <year> 1995. </year>
Reference: [7] <author> H. J. Levesque, R. Reiter, Y. Lesperance, F. Lin, and R. Scherl. GOLOG: </author> <title> A logic programming language for dynamic domains. </title> <note> To appear in the , 1996. </note>
Reference-contexts: Indeed, our criticism of earlier accounts was precisely that they were overly tied up with specific planning procedures. In our own work in Cognitive Robotics, we take a slightly different approach. Instead of planning tasks, we focus on the execution of high-level programs written in the GOLOG programming language <ref> [7] </ref>. GOLOG programs look like ordinary block-structured imperative programs except that they are nondeterministic, and they use the primitive actions and fluents of a user-supplied domain theory.
Reference: [8] <author> Hector J. Levesque. </author> <title> The execution of high-level robot programs with sensing actions: theory and implementation. </title> <note> In preparation, </note> <year> 1996. </year>
Reference-contexts: This is obviously a special case of planning. Furthermore, when contains sensing actions, an argument analogous to the one presented here suggests that instead of , the GOLOG processor would need to find a robot program <ref> [8] </ref>. With or without sensing, considerable searching may be required to do this type of processing.
Reference: [9] <author> K. Krebsbach, D. Olawsky, and M. Gini. </author> <title> An empirical study of sensing and defaulting in planning. </title> <booktitle> In , pp. </booktitle> <pages> 136-144, </pages> <address> San Mateo CA, </address> <year> 1992. </year>
Reference: [10] <author> Z. Manna and R. Waldinger. </author> <title> How to clear a block: A theory of plans. </title> , <booktitle> 3 </booktitle> <pages> 343-377, </pages> <year> 1987. </year>
Reference: [11] <author> D. McAllester and D. Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In , pp. </booktitle> <pages> 634-639, </pages> <address> Menlo Park, CA, </address> <month> July </month> <year> 1991. </year>
Reference: [12] <author> J. McCarthy and P. J. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <booktitle> In , pp. </booktitle> <pages> 463-502. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1969. </year>
Reference: [13] <author> R. C. Moore. </author> <title> A formal theory of knowledge and action. </title> <editor> In J. R. Hobbs and R. C. Moore, </editor> <booktitle> editors, </booktitle> , <pages> pp. 319-358. </pages> <publisher> Ablex Publishing, </publisher> <address> Norwood, NJ, </address> <year> 1985. </year>
Reference-contexts: For example, to execute ( ( ( )) ) we can unwind the loop and execute ( ( ( ( ( )) ))) Note that we should not try to define axiomatically using axioms like these (as in <ref> [13] </ref>, for example) since they are first-order, and not strong enough to characterize loop termination.
Reference: [14] <author> M. Peot and D. Smith. </author> <title> Conditional nonlinear planning. </title> <booktitle> In , pp. </booktitle> <pages> 189-197, </pages> <address> San Mateo CA, </address> <year> 1992. </year>
Reference: [15] <author> R. Reiter. </author> <title> The frame problem in the situation calculus: A simple solution (sometimes) and a completeness result for goal regression. In Vladimir Lifschitz, </title> <booktitle> editor, </booktitle> , <pages> pp. 359-380. </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1991. </year>
Reference: [16] <author> R. Scherl and H. Levesque. </author> <title> The frame problem and knowledge-producing actions. </title> <booktitle> In , pp. </booktitle> <pages> 689-695, </pages> <address> Washington, DC, July 1993. </address> <publisher> AAAI Press/The MIT Press. </publisher>
Reference: [17] <author> M. Schoppers. </author> <title> Building plans to monitor and exploit open-loop and closed-loop dynamics. </title> <booktitle> In , pp. </booktitle> <pages> 204-213, </pages> <address> San Mateo CA, </address> <year> 1992. </year>
References-found: 17

