URL: ftp://cse.ogi.edu/pub/tech-reports/1997/97-TH-002.ps.gz
Refering-URL: ftp://cse.ogi.edu/pub/tech-reports/README.html
Root-URL: http://www.cse.ogi.edu
Title: Rapid Speaker Adaptation for Neural Network Speech Recognizers  
Author: Daniel Clark Burnett B.S., Harvey 
Degree: A dissertation submitted to the faculty of the Oregon Graduate Institute of Science and Technology in partial fulfillment of the requirements for the degree Doctor of Philosophy in Computer Science and Engineering  
Date: 1990  April 1997  
Address: College,  
Affiliation: Mudd  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Abrash, V., Franco, H., Cohen, M., Morgan, N., and Konig, Y. </author> <title> Connectionist gender adaptation in a hybrid neural network / hidden Markov model speech recognition system. </title> <booktitle> In Proceedings of the 1992 International Conference on Spoken Language Processing, </booktitle> <address> Banff, Alberta, Canada, </address> <month> Oct. 12-16 </month> <year> (1992), </year> <journal> vol. </journal> <volume> 2, </volume> <pages> pp. 911-914. </pages>
Reference: [2] <author> Andreou, A., Kamm, T., and Cohen, J. </author> <title> Experiments in vocal tract normalization. </title> <booktitle> In Proceedings of the CAIP Workshop: Frontiers in Speech Recognition II (CAIP, </booktitle> <address> P.O. Box 1390, </address> <institution> CoRE Building, Rutgers University, </institution> <address> Piscataway, NJ 08855, </address> <year> 1994), </year> <institution> Center for Computer Aids for Industrial Productivity. </institution>
Reference: [3] <author> Bellegarda, J. R., de Souza, P. V., N adas, A. J., Nahamoo, D., Picheny, M. A., and Bahl, L. R. </author> <title> Robust speaker adaptation using a piecewise linear acoustic mapping. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> San Francisco, </address> <month> Mar. 23-26 </month> <year> (1992), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 445-448. </pages>
Reference: [4] <author> Bladon, R. A. W., Henton, C. G., and Pickering, J. B. </author> <title> Towards an auditory theory of speaker normalization. Language & Communication 4, </title> <booktitle> 1 (1984), </booktitle> <pages> 59-69. </pages>
Reference-contexts: One factor that varies among speakers, especially between adult males, adult females, and children, is the length of the individual's vocal tract. One effect of the difference in vocal tract lengths can be seen in the speech spectra of vowels. Bladon, et al. <ref> [4] </ref> compared average spectra, for the vowel /"/, for male and female speakers of Northern British English and noticed that when presented on the Bark scale, the spectra differed, on average, only in their location on the Bark frequency axis.
Reference: [5] <author> Bourlard, H., and Morgan, N. </author> <title> Connectionist Speech Recognition|A Hybrid Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference: [6] <author> Bourlard, H., Morgan, N., and Renals, S. </author> <title> Neural nets and hidden Markov models: Review and generalizations. Speech Communication 11, </title> <journal> Nos. </journal> <note> 2 and 3 (June 1992), 237-246. </note>
Reference: [7] <author> Brent, R. P. </author> <title> Algorithms for Minimization without Derivatives. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1973. </year>
Reference-contexts: For the task at hand this is critically important, since a "function evaluation" corresponds to a complete recognizer pass over the adaptation utterance, including signal processing, feature generation, probability estimation, and Viterbi search to produce the function value. For information on the actual heuristics used in Brent's algorithm, see <ref> [7, Chapter 5] </ref>. We have illustrated the search procedure on a simplified example in Figure 6.9. Notice in this particular example that only parabolic interpolation is used to set the next evaluation point.
Reference: [8] <author> Chen, L. </author> <title> A global optimization algorithm for neural network training. </title> <booktitle> In Proceedings of the 1993 International Joint Conference on Neural Networks, </booktitle> <address> Nagoya, Japan, Oct. 25-29 (Oct. </address> <booktitle> 1993), </booktitle> <volume> vol. 1, </volume> <pages> pp. 443-446. 101 102 </pages>
Reference: [9] <author> Cole, R. A., Noel, M., Lander, T., and Durham, T. </author> <title> New telephone speech corpora at CSLU. </title> <booktitle> In Proceedings of the 4 th European Conference on Speech Communication and Technology, </booktitle> <address> Madrid, </address> <month> Sep. 18-21 (Sept. </month> <year> 1995), </year> <title> vol. </title> <booktitle> 1, European Speech Communication Association, </booktitle> <pages> pp. 821-824. </pages>
Reference-contexts: Sections 6.4 and 5.3). Wherever possible, we have included references to more complete descriptions of the datasets. 4.1 The OGI 30000 Numbers corpus Release 1.0 of the OGI 30000 Numbers corpus <ref> [9] </ref> is a telephone speech database consisting of 15000 number-string utterances. The utterances were taken from birthdates, phone numbers, zip codes, and street addresses collected in various OGI CSLU data collections. All calls have been transcribed at the word level (without time alignment) according to the conventions in [33].
Reference: [10] <author> Cole, R. A., Stern, R. M., Phillips, M. S., Brill, S. M., Pilant, A. P., and Specker, P. </author> <title> Feature-based speaker-independent recognition of isolated English letters. </title> <booktitle> In Proceedings of the 1983 IEEE International Conference on Acoustics, Speech, and Signal Processing (1983), </booktitle> <pages> pp. 731-734. </pages>
Reference-contexts: Woodland [36, 37] have also addressed the no-examples problem, as have Digalakis, et al. [13] and Zavaliagkos, et al.[61, 62] Earlier work in this area has been done by Stern and Lasry.[55] Having experimented with both supervised and unsupervised MAP adjustment of the means of feature vectors in CMU's FEATURE <ref> [10] </ref> system, they claim to be the first researchers to have "include [d] statistical correlations across decision classes in a speaker adaptation procedure explicitly." There has recently been substantial research on ways to combine various adaptation methods.
Reference: [11] <author> Cox, S. </author> <title> Predictive speaker adaptation in speech recognition. </title> <booktitle> Computer Speech and Language 9, 1 (1995), </booktitle> <pages> 1-17. </pages>
Reference-contexts: A more general theoretical expansion of this work can be found in [19]. Recently a number of researchers have focused on the problem of lacking or insufficient examples for all models. Cox <ref> [11] </ref>, for example, models each sound class as a linear regression on a set of different sound classes. Ohkura, et al. have introduced Vector Field Smoothing [45], a popular technique in Japan, to accomplish the same task.
Reference: [12] <author> Digalakis, V., and Neumeyer, L. </author> <title> Speaker adaptation using combined transformation and Bayesian methods. </title> <booktitle> In Proceedings of the 1995 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Detroit, Michigan, </address> <month> May 9-12 </month> <year> (1995), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 680-683. </pages>
Reference-contexts: statistical approaches can be categorized into 20 either Maximum Likelihood feature transformation approaches or Bayesian adaptation approaches, where the former require little adaptation data but cannot adequately use more and the latter require more data but asymptotically approach speaker-dependent performance with increases in the data set size, Digalakis and Neumeyer <ref> [12, 44] </ref> present a method of combining the two families to create an adaptation approach with both short-term and asymptotically good performance. Earlier work by Zhao [63, 64] also focused on a similar combination of methods.
Reference: [13] <author> Digalakis, V., Rtischev, D., and Neumeyer, L. </author> <title> Fast speaker adaptation using constrained estimation of Gaussian mixtures. </title> <journal> IEEE Transactions on Speech and Audio Processing 3, </journal> <month> 5 (Sept. </month> <year> 1995), </year> <pages> 357-366. </pages>
Reference-contexts: Kosaka, et al. [32] have combined this method with two simpler methods to improve performance when given small amounts of adaptation data. Leggetter and Woodland [36, 37] have also addressed the no-examples problem, as have Digalakis, et al. <ref> [13] </ref> and Zavaliagkos, et al.[61, 62] Earlier work in this area has been done by Stern and Lasry.[55] Having experimented with both supervised and unsupervised MAP adjustment of the means of feature vectors in CMU's FEATURE [10] system, they claim to be the first researchers to have "include [d] statistical correlations
Reference: [14] <author> Eide, E., and Gish, H. </author> <title> A parametric approach to vocal tract length normalization. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Atlanta, Georgia, </address> <month> May 7-10 </month> <year> (1996), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 346-349. </pages>
Reference-contexts: Recently, several papers have reported on experiments with various scalings of the frequency axis. Both Eide and Gish <ref> [14] </ref> and Lee and Rose [35] have proposed extensions to the work of Andreou, et al.[2] This work has also been extended by Kamm, et al.[27], who experimented with linearly scaling the frequency axis for speakers from the Switchboard corpus.
Reference: [15] <author> Fourcin, A., Ainsworth, W., Fant, G., Fujimura, O., Fujisaki, H., Hess, W., Holmes, J., Itakura, F., Schroeder, M., and Struebe, H. </author> <title> Speech processing by man and machine: Group report. In Recognition of Complex Acoustic Signals, </title> <editor> T. H. Bullock, Ed., </editor> <volume> no. </volume> <booktitle> 5 in Life Sciences Research Report. </booktitle> <publisher> Abakon Verlag, </publisher> <year> 1977, </year> <pages> pp. 307-351. </pages>
Reference-contexts: This analysis consists of a Hamming-windowed FFT, a warping of the power spectrum to the Bark scale, critical-band masking, equal-loudness pre-emphasis, intensity-loudness conversion, and finally LPC cepstral modelling. The original Hz-to-Bark transformation (an analytic approximation from Schroeder <ref> [15, p. 324] </ref>) and its inverse were (f ) = 6 ln f r 600 + 1 (6.1) f () = 600sinh (=6) (6.2) A plot of this transformation is shown in Figure 6.4.
Reference: [16] <author> Fukuzawa, K., Komori, Y., Sawai, H., and Sugiyama, M. </author> <title> A segment-based speaker adaptation neural network applied to continuous speech recognition. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> San Francisco, </address> <month> Mar. 23-26 </month> <year> (1992), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 433-436. </pages>
Reference: [17] <author> Furui, S. </author> <title> A training procedure for isolated word recognition systems. </title> <booktitle> IEEE Transactions on Acoustics, Speech, and Signal Processing 28 (1980), </booktitle> <pages> 129-136. </pages>
Reference: [18] <author> G. David Forney, J. </author> <title> The Viterbi algorithm. </title> <booktitle> Proceedings of the IEEE 61, </booktitle> <month> 3 (Mar. </month> <year> 1973), </year> <pages> 268-277. 103 </pages>
Reference: [19] <author> Gauvain, J.-L., and Lee, C.-H. </author> <title> Maximum a Posteriori estimation for multivariate gaussian mixture observations of markov chains. </title> <journal> IEEE Transactions on Speech and Audio Processing 2, </journal> <volume> 2 (1994), </volume> <pages> 291-298. </pages>
Reference-contexts: Also, the theoretical development of this technique requires that one have adaptation examples for each speech unit in order to adapt all of the models, which may be practically impossible for certain adaptation tasks. A more general theoretical expansion of this work can be found in <ref> [19] </ref>. Recently a number of researchers have focused on the problem of lacking or insufficient examples for all models. Cox [11], for example, models each sound class as a linear regression on a set of different sound classes.
Reference: [20] <author> Gong, Y., Siohan, O., and Haton, J.-P. </author> <title> Minimization of speech alignment error by iterative transformation for speaker adaptation. </title> <booktitle> In Proceedings of the 1992 International Conference on Spoken Language Processing, </booktitle> <address> Banff, Alberta, Canada, </address> <month> Oct. 12-16 </month> <year> (1992), </year> <pages> pp. 377-380. </pages>
Reference: [21] <author> H. Bourlard, e. </author> <title> Wernicke esprit project 6487: </title> <type> 1993-1994 progress report. </type> <institution> Obtained from author at the International Computer Science Institute, Berkeley, </institution> <address> CA. </address>
Reference-contexts: Data/model transformation Speech recognition researchers have examined connectionist feature-space transformations for neural network-based systems. Frequently, this approach allows the feature-space transform to be directly included into the architecture, training, and/or use of the existing network model. Two such methods can be found in the European ESPRIT project <ref> [21, pp. 38-46] </ref> and work by Watrous.[57] In the ESPRIT project, researchers examined adding a speaker-dependent linear transformation layer to either the input or the output of the network.
Reference: [22] <author> Hermansky, H. </author> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> Journal of the Acoustical Society of America 87, </journal> <month> 4 (Apr. </month> <year> 1990), </year> <pages> 1738-1752. </pages>
Reference-contexts: Wegmann, et al.[58] investigated an approach to vocal tract normalization based on an explicit voiced speech model. Their piecewise-linear mapping produced a 12% reduction in error rates on a Switchboard task. 6.2.2 Implementation Within our system, the Bark offset parameter is implemented through a modification of the standard PLP <ref> [22] </ref> analysis. This analysis consists of a Hamming-windowed FFT, a warping of the power spectrum to the Bark scale, critical-band masking, equal-loudness pre-emphasis, intensity-loudness conversion, and finally LPC cepstral modelling.
Reference: [23] <author> Hermansky, H., Morgan, N., Bayya, A., and Kohn, P. </author> <title> Compensation for the effect of the communication channel in auditory-like analysis of speech (RASTA-PLP). </title> <booktitle> In Proceedings of the 2 nd European Conference on Speech Communication and Technology, Genova (1991), European Speech Communication Association, </booktitle> <pages> pp. 1367-1370. </pages>
Reference: [24] <author> Huang, X. </author> <title> Speaker normalization for speech recognition. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> San Francisco, </address> <month> Mar. 23-26 </month> <year> (1992), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 465-468. </pages>
Reference: [25] <author> II, J. B. H., and Waibel, A. H. </author> <title> The Meta-Pi network: Building distributed knowledge representations for robust pattern recognition. </title> <type> Tech. Rep. </type> <institution> CMU-CS-89-166, School of Computer Science, Carnegie Mellon University, </institution> <month> Aug. </month> <year> 1989. </year>
Reference: [26] <author> II, J. B. H., and Waibel, A. H. </author> <title> The META-PI network: Connectionist rapid adaptation for high-performance multi-speaker phoneme recognition. </title> <booktitle> In Proceedings of the 1990 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Albuquerque, New Mexico (Apr. </address> <year> 1990), </year> <pages> pp. 165-169. </pages>
Reference: [27] <author> Kamm, T., Andreou, A. G., and Cohen, J. </author> <title> Vocal tract normalization in speech recognition: Compensating for systematic speaker variability. </title> <booktitle> In Proceedings of the 15 th Annual Speech Research Symposium (Johns Hopkins University, </booktitle> <month> June </month> <year> 1995), </year> <pages> pp. 175-178. </pages>
Reference: [28] <author> Knohl, L., and Rinscheid, A. </author> <title> Speaker normalization and adaptation based on feature-map projection. </title> <booktitle> In Proceedings of the 3 rd European Conference on Speech Communication and Technology, </booktitle> <address> Berlin (1993), </address> <pages> pp. 367-370. 104 </pages>
Reference: [29] <author> Kobayashi, T., Uchiyama, Y., Osada, J., and Shirai, K. </author> <title> Speaker adaptive phoneme recognition based on feature mapping from spectral domain to probabilistic domain. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> San Francisco, </address> <month> Mar. 23-26 </month> <year> (1992), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 457-460. </pages>
Reference: [30] <author> Konig, Y., and Morgan, N. </author> <title> Supervised and unsupervised clustering of the speaker space for connectionist speech recognition. </title> <booktitle> In Proceedings of the 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Minneapolis, Min-nesota, </address> <month> Apr. 27-30 </month> <year> (1993), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 545-548. </pages>
Reference: [31] <author> Kosaka, T., and Sagayama, S. </author> <title> Tree-structured speaker clustering for fast speaker adaptation. </title> <booktitle> In Proceedings of the 1994 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Adelaide, Australia, </address> <month> Apr. 19-22 </month> <year> (1994), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 245-248. </pages>
Reference: [32] <author> Kosaka, T., Willems, E., Takami, J.-I., and Sagayama, S. </author> <title> A dynamic approach to speaker adaptation of hidden Markov networks for speech recognition. </title> <booktitle> In Proceedings of the 3 rd European Conference on Speech Communication and Technology, </booktitle> <address> Berlin (1993), </address> <pages> pp. 363-366. </pages>
Reference-contexts: VFS not only estimates mappings for which there are no data; it also includes a smoothing step to adjust all mappings based on the surrounding (in model space) mappings, relying more heavily on mappings for which more examples exist. Kosaka, et al. <ref> [32] </ref> have combined this method with two simpler methods to improve performance when given small amounts of adaptation data.
Reference: [33] <author> Lander, T. </author> <title> The CSLU labeling guide. </title> <type> Tech. Rep. </type> <institution> CSLU-014-96, Center for Spoken Language Understanding, Oregon Graduate Institute, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: The utterances were taken from birthdates, phone numbers, zip codes, and street addresses collected in various OGI CSLU data collections. All calls have been transcribed at the word level (without time alignment) according to the conventions in <ref> [33] </ref>. From this corpus we selected all speakers for whom we had both an address and zipcode that consisted only of (possibly) connected digits, i.e. we only allowed sequences containing the words "oh", "zero", "one", "two", "three", "four", "five", "six", "seven", "eight", and "nine". <p> A sample call list is shown in Appendix A. Native speakers were given one number to call and non-native speakers another. The collection protocol (list of prompts) is also given in Appendix A. 4.4.2 Transcription The calls have all been labelled at the word level using the conventions in <ref> [33] </ref>. 26 following information: email address, native/non-native speaker of American English, and optionally mailing address, age range, and gender. Table 4.2: Words collected in Huh? corpus.
Reference: [34] <author> Lee, C. H., Lin, C. H., and Juang, B. H. </author> <title> A study on speaker adaptation of the parameters of continuous density hidden Markov models. </title> <booktitle> IEEE Transactions on Signal Processing 39 (1991), </booktitle> <pages> 806-814. </pages>
Reference-contexts: introduction of our method. 19 3.1.3 Model Transformation Approaches HMM Model transformation approaches, both for HMM- and neural network-based systems, have enjoyed recent popularity, due in large part to a 1991 paper by Lee, Lin, and Juang <ref> [34] </ref> presenting a Bayesian procedure for adapting continuous-density hidden Markov model parameters to the speech of a new speaker. This widely-cited paper demonstrates how to adjust model means in a way that optimally integrates new speech data with the existing speaker-independent models.
Reference: [35] <author> Lee, L., and Rose, R. C. </author> <title> Speaker normalization using efficient frequency warping procedures. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Atlanta, Georgia, </address> <month> May 7-10 </month> <year> (1996), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 353-356. </pages>
Reference-contexts: Recently, several papers have reported on experiments with various scalings of the frequency axis. Both Eide and Gish [14] and Lee and Rose <ref> [35] </ref> have proposed extensions to the work of Andreou, et al.[2] This work has also been extended by Kamm, et al.[27], who experimented with linearly scaling the frequency axis for speakers from the Switchboard corpus. <p> Their error rates, also on Switchboard, 67 showed an 8-10% drop for several different dataset sizes and conditions. Lee and Rose <ref> [35] </ref> proposed HMM-based procedures for estimating an appropriate scaling factor and described a simple implementation of the frequency warping using a direct modification of the filters in their front-end. Experiments on a telephone-based connected digit recognition task demonstrated a noticeable reduction in error rate.
Reference: [36] <author> Leggetter, C. J., and Woodland, P. C. </author> <title> Speaker adaptation of continuous density HMMs using linear regression. </title> <booktitle> In Proceedings of the 1994 International Conference on Spoken Language Processing, </booktitle> <address> Yokohama, Japan, </address> <month> Sep. 18-22 </month> <year> (1994), </year> <journal> vol. </journal> <volume> 2, </volume> <pages> pp. 451-454. </pages>
Reference-contexts: Kosaka, et al. [32] have combined this method with two simpler methods to improve performance when given small amounts of adaptation data. Leggetter and Woodland <ref> [36, 37] </ref> have also addressed the no-examples problem, as have Digalakis, et al. [13] and Zavaliagkos, et al.[61, 62] Earlier work in this area has been done by Stern and Lasry.[55] Having experimented with both supervised and unsupervised MAP adjustment of the means of feature vectors in CMU's FEATURE [10] system,
Reference: [37] <author> Leggetter, C. J., and Woodland, P. C. </author> <title> Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models. </title> <booktitle> Computer Speech and Language 9, </booktitle> <month> 2 (Apr. </month> <year> 1995), </year> <pages> 171-185. 105 </pages>
Reference-contexts: Kosaka, et al. [32] have combined this method with two simpler methods to improve performance when given small amounts of adaptation data. Leggetter and Woodland <ref> [36, 37] </ref> have also addressed the no-examples problem, as have Digalakis, et al. [13] and Zavaliagkos, et al.[61, 62] Earlier work in this area has been done by Stern and Lasry.[55] Having experimented with both supervised and unsupervised MAP adjustment of the means of feature vectors in CMU's FEATURE [10] system,
Reference: [38] <author> Leonard, R. G. </author> <title> A database for speaker-independent digit recognition. </title> <booktitle> In Proceedings of the 1984 IEEE International Conference on Acoustics, Speech, and Signal Processing (1984), </booktitle> <volume> vol. 3, </volume> <editor> p. </editor> <publisher> 42.11. </publisher>
Reference-contexts: dataset = 8 &gt; &gt; &gt; &gt; : training if call number mod 5 = 0,1, or 2 development if call number mod 5 = 3 test otherwise This resulted in 1147 training speakers, 406 development speakers, and 376 test speakers. 23 24 4.2 The TIDIGITS corpus The TIDIGITS corpus <ref> [38] </ref> consists of studio-quality connected-digit utterances read by men, women, boys, and girls. Each speaker (adult or child) read 22 single-digit utterances and 11 each of 2-, 3-, 4-, 5-, and 7-digit utterances, for a total of 77 utterances per speaker.
Reference: [39] <author> Lippmann, R. P. </author> <title> An introduction to computing with neural nets. </title> <journal> IEEE SSSP Magazine (Apr. </journal> <year> 1987), </year> <pages> 4-22. </pages>
Reference: [40] <author> Ljolje, A. </author> <title> Speaker clustering for improved speech recognition. </title> <booktitle> In Proceedings of the 3 rd European Conference on Speech Communication and Technology, </booktitle> <address> Berlin (1993), </address> <pages> pp. 631-634. </pages>
Reference: [41] <author> Matsukoto, H., and Inoue, H. </author> <title> A piecewise linear spectral mapping for supervised speaker adaptation. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> San Francisco, </address> <month> Mar. 23-26 </month> <year> (1992), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 449-452. </pages>
Reference: [42] <author> Morgan, N., and Hermansky, H. </author> <title> RASTA extensions: Robustness to additive and convolutional noise. </title> <booktitle> In Proceedings of the Workshop on Speech Processing in Adverse Environments, </booktitle> <address> Cannes, France (Nov. </address> <year> 1992). </year> <institution> Obtained from Hermansky at the Oregon Graduate Institute, </institution> <address> P.O. Box 91000, Portland, OR 97291. </address>
Reference-contexts: The technique is applicable to any task for which there is a single value that must be set appropriately for a speaker, phone line, etc. using only a small amount of speech. As an example, one such parameter 97 would be the J in J-RASTA. J-RASTA <ref> [42] </ref> is a modification of the RASTA algorithm designed to overcome the latter's difficulties in handling additive noise. It turns out that the optimal J factor for any utterance is dependent upon the level of noise in the utterance. In the paper decribing this algorithm [42], the authors explicitly estimated the <p> J-RASTA <ref> [42] </ref> is a modification of the RASTA algorithm designed to overcome the latter's difficulties in handling additive noise. It turns out that the optimal J factor for any utterance is dependent upon the level of noise in the utterance. In the paper decribing this algorithm [42], the authors explicitly estimated the noise in the signal and set the value of J accordingly. Instead, using our approach one would directly find the value that optimizes the overall recognizer score. This reduces the risk of errors that might otherwise have been introduced by the noise estimation algorithm.
Reference: [43] <author> Neuberg, E. P. </author> <title> Frequency-axis warping to improve automatic word recognition. </title> <booktitle> In Proceedings of the 1980 IEEE International Conference on Acoustics, Speech, and Signal Processing (1980), </booktitle> <pages> pp. 166-168. </pages>
Reference-contexts: In a vowel identification task using steady-state portions of the vowels, normalization resulted in a 26% reduction in the identification error rate. Neuberg <ref> [43] </ref> examined several different transformations to the frequency scale. In an experiment on two speakers, he observed that piecewise-linear transformations of the first, second, and third formant regions of the frequency axis resulted in an improved correlation between vowel nuclei spectra from the two speakers.
Reference: [44] <author> Neumeyer, L., Sankar, A., and Digalakis, V. </author> <title> A comparative study of speaker adaptation techniques. </title> <booktitle> In Proceedings of the 4 th European Conference on Speech Communication and Technology, </booktitle> <address> Madrid, </address> <month> Sep. 18-21 </month> <year> (1995), </year> <pages> pp. 1127-1130. </pages>
Reference-contexts: statistical approaches can be categorized into 20 either Maximum Likelihood feature transformation approaches or Bayesian adaptation approaches, where the former require little adaptation data but cannot adequately use more and the latter require more data but asymptotically approach speaker-dependent performance with increases in the data set size, Digalakis and Neumeyer <ref> [12, 44] </ref> present a method of combining the two families to create an adaptation approach with both short-term and asymptotically good performance. Earlier work by Zhao [63, 64] also focused on a similar combination of methods.
Reference: [45] <author> Ohkura, K., Sugiyama, M., and Sagayama, S. </author> <title> Speaker adaptation based on transfer vector field smoothing with continuous mixture density HMMs. </title> <booktitle> In Proceedings of the 1992 International Conference on Spoken Language Processing, </booktitle> <address> Banff, Alberta, Canada, </address> <month> Oct. 12-16 </month> <year> (1992), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 369-372. </pages>
Reference-contexts: Recently a number of researchers have focused on the problem of lacking or insufficient examples for all models. Cox [11], for example, models each sound class as a linear regression on a set of different sound classes. Ohkura, et al. have introduced Vector Field Smoothing <ref> [45] </ref>, a popular technique in Japan, to accomplish the same task. VFS not only estimates mappings for which there are no data; it also includes a smoothing step to adjust all mappings based on the surrounding (in model space) mappings, relying more heavily on mappings for which more examples exist.
Reference: [46] <author> Pallett, D., Fiscus, J., and Garofolo, J. </author> <title> DARPA resource management benchmark test results June 1990. </title> <booktitle> In DARPA Speech and Language Workshop. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 298-305. </pages>
Reference-contexts: Although the linear transformation might not perform as well as a nonlinear transformation, the former can be directly integrated into the existing nonlinear weights, thereby eliminating the need for any extra computation when using the new speaker-dependent system. On the Resource Management (RM) Task <ref> [46] </ref>, the linear output network reduced the word error rate on the Speaker Dependent (SD) speakers by 6% using 100 adaptation sentences. The linear input network reduced the word error rate by about 22%.
Reference: [47] <author> Pedreira, C. E., and Roehl, N. M. </author> <title> On adaptively trained neural networks. </title> <booktitle> In Proceedings of the 1993 International Joint Conference on Neural Networks, </booktitle> <address> Nagoya, Japan, Oct. 25-29 (Oct. </address> <booktitle> 1993), </booktitle> <volume> vol. 1, </volume> <pages> pp. 565-568. 106 </pages>
Reference-contexts: The problem of learning new patterns without losing the old has been directly addressed in the neural network community under the term "catastrophic forgetting". A recent paper by Robins [50] discussed this problem in detail and presented several solutions. Pedreira and Roehl <ref> [47] </ref> also discussed this problem.
Reference: [48] <author> Pitrelli, J. F., Fong, C., Wong, S. H., Spitz, J. R., and Leung, H. C. </author> <title> Phonebook: A phonetically-rich isolated-word telephone-speech database. </title> <booktitle> In Proceedings of the 1995 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Detroit, Michigan, </address> <month> May 9-12 </month> <year> (1995), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 101-104. </pages>
Reference-contexts: The numbers of speakers in the training and test sets are shown in Table 4.1. Table 4.1: Number of speakers in the TIDIGITS dataset. Number of speakers Dataset Man Woman Girl Boy Train 55 57 26 25 Test 56 57 25 25 4.3 The PhoneBook corpus The PhoneBook corpus <ref> [48] </ref> consists of both read speech and spontaneous speech utterances spoken over the telephone. Our experiments used only the read speech portion. In this portion, each speaker was given a list of either 75 or 76 isolated words to read.
Reference: [49] <author> Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P. </author> <title> Numerical Recipes in C: The Art of Scientific Computing, second ed. </title> <publisher> Cambridge University Press, </publisher> <year> 1994. </year>
Reference-contexts: This insight led us to select an optimization method that would take advantage of our knowledge of the general shape of the function. We selected Brent's algorithm <ref> [49, section 10.2] </ref>, a cross between the golden section search and inverse parabolic interpolation, to perform the optimization.
Reference: [50] <author> Robins, A. </author> <title> Catastrophic forgetting, </title> <booktitle> rehearsal and pseudorehearsal. Connection Science 7, 1 (1995), </booktitle> <pages> 123-146. </pages>
Reference-contexts: The problem of learning new patterns without losing the old has been directly addressed in the neural network community under the term "catastrophic forgetting". A recent paper by Robins <ref> [50] </ref> discussed this problem in detail and presented several solutions. Pedreira and Roehl [47] also discussed this problem. <p> Most of the HMM methods perform adjustments to the parameters, e.g. means and/or variances, of the probability density functions of the subword models. Without changing the architecture of our network, we do not have the option of changing such parameters. Unlike the "catastrophic forgetting" research <ref> [50] </ref>, we are not attempting to learn totally new information. Rather, we are attempting to slightly alter some of the information that has been learned without affecting other patterns.
Reference: [51] <author> Rumelhart, D., Hinton, H., and Williams, R. </author> <title> Learning internal representations by error propagation. In Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </title> <editor> D. Rumelhart and J. McClelland, Eds., </editor> <volume> vol. </volume> <editor> I. </editor> <publisher> The MIT Press, </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference: [52] <author> Scharf, B. </author> <title> Critical bands. In Foundations of Modern Auditory Theory, </title> <editor> J. V. Tobias, Ed., </editor> <volume> vol. </volume> <editor> I. </editor> <publisher> Academic Press, </publisher> <year> 1970, </year> <note> ch. 5. </note>
Reference-contexts: Note that although the end mapping is similar, this new frequency scale is constructed differently from the mel scale, a pitch-scaling based function. For a discussion of the critical bands and their importance in human auditory theory, see <ref> [52] </ref>. One factor that varies among speakers, especially between adult males, adult females, and children, is the length of the individual's vocal tract. One effect of the difference in vocal tract lengths can be seen in the speech spectra of vowels.
Reference: [53] <author> Schmidbauer, O., and Tebelskis, J. </author> <title> An LVQ based reference model for speaker-adaptive speech recognition. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> San Francisco, </address> <month> Mar. 23-26 </month> <year> (1992), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 441-444. </pages>
Reference: [54] <author> Simpson, P. K. </author> <booktitle> Artificial Neural Systems. </booktitle> <publisher> Pergamon Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference: [55] <author> Stern, R. M., and Lasry, M. J. </author> <title> Dynamic speaker adaptation for feature-based isolated word recognition. </title> <booktitle> IEEE Transactions on Acoustics, Speech, and Signal Processing 35, </booktitle> <month> 6 (June </month> <year> 1987), </year> <pages> 751-763. </pages>
Reference: [56] <author> Wakita, H. </author> <title> Normalization of vowels by vocal-tract length and its application to vowel identification. </title> <booktitle> IEEE Transactions on Acoustics, Speech, and Signal Processing 25, </booktitle> <month> 2 (Apr. </month> <year> 1977), </year> <pages> 183-192. </pages>
Reference-contexts: In 1977, Wakita <ref> [56] </ref> presented a method of vowel formant frequency normalization which used explicit estimates of the speaker's vocal-tract length and area functions obtained from the acoustic waveform. In a vowel identification task using steady-state portions of the vowels, normalization resulted in a 26% reduction in the identification error rate.
Reference: [57] <author> Watrous, R. L. </author> <title> Speaker normalization and adaptation using second-order connectionist networks. </title> <journal> IEEE Transactions on Neural Networks 4, </journal> <month> 1 (Jan. </month> <year> 1993), </year> <pages> 21-30. </pages>
Reference: [58] <author> Wegmann, S., McAllaster, D., Orloff, J., and Peskin, B. </author> <title> Speaker normalization on conversational telephone speech. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Atlanta, Georgia, </address> <month> May 7-10 </month> <year> (1996), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 339-341. 107 </pages>
Reference: [59] <author> Witbrock, M., and Haffner, P. </author> <title> Rapid connectionist speaker adaptation. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> San Francisco, </address> <month> Mar. 23-26 </month> <year> (1992), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 453-456. </pages>
Reference: [60] <author> Zavaliagkos, G. </author> <title> Maximum A Posteriori Adaptation Techniques for Speech Recognition. </title> <type> PhD thesis, </type> <institution> Northeastern University, Boston, Massachusetts, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Earlier work by Zhao [63, 64] also focused on a similar combination of methods. For a more detailed discussion of this topic, George Zavaliagkos' doctoral dissertation <ref> [60] </ref> contains an excellent review of recent HMM speaker adaptation techniques. Neural Network The model-based adaptation/retraining methods for neural network-based systems can be broken down into data/model transformations, new architectures, and new techniques. Data/model transformation Speech recognition researchers have examined connectionist feature-space transformations for neural network-based systems.
Reference: [61] <author> Zavaliagkos, G., Schwartz, R., and Makhoul, J. </author> <title> Batch, incremental and instantaneous adaptation techniques for speech recognition. </title> <booktitle> In Proceedings of the 1995 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Detroit, Michigan, </address> <month> May 9-12 </month> <year> (1995), </year> <journal> vol. </journal> <volume> 1, </volume> <pages> pp. 676-679. </pages>
Reference: [62] <author> Zavaliagkos, G., Schwartz, R., McDonough, J., and Makhoul, J. </author> <title> Adaptation algorithms for large scale HMM recognizers. </title> <booktitle> In Proceedings of the 4 th European Conference on Speech Communication and Technology, </booktitle> <address> Madrid, </address> <month> Sep. 18-21 </month> <year> (1995), </year> <pages> pp. 1131-1134. </pages>
Reference: [63] <author> Zhao, Y. </author> <title> Self-learning speaker adaptation based on spectral variation source decomposition. </title> <booktitle> In Proceedings of the 3 rd European Conference on Speech Communication and Technology, </booktitle> <address> Berlin (1993), </address> <pages> pp. 359-362. </pages>
Reference-contexts: Earlier work by Zhao <ref> [63, 64] </ref> also focused on a similar combination of methods. For a more detailed discussion of this topic, George Zavaliagkos' doctoral dissertation [60] contains an excellent review of recent HMM speaker adaptation techniques.
Reference: [64] <author> Zhao, Y. </author> <title> An acoustic-phonetic-based speaker adaptation technique for improving speaker-independent continuous speech recognition. </title> <journal> IEEE Transactions on Speech and Audio Processing 2, </journal> <month> 3 (July </month> <year> 1994), </year> <pages> 380-394. </pages>
Reference-contexts: Earlier work by Zhao <ref> [63, 64] </ref> also focused on a similar combination of methods. For a more detailed discussion of this topic, George Zavaliagkos' doctoral dissertation [60] contains an excellent review of recent HMM speaker adaptation techniques.
Reference: [65] <author> Zwicker, E. </author> <title> Subdivision of the audible frequency range into critical bands (frequenz-gruppen). </title> <journal> Journal of the Acoustical Society of America 33, </journal> <volume> 2 (1961), </volume> <pages> 248. </pages>
References-found: 65

