URL: http://www.cs.uni-bonn.de/~jw/publikationen/BNCOD97_short_version.ps.gz
Refering-URL: http://www.cs.uni-bonn.de/~oleg/
Root-URL: http://cs.uni-bonn.de
Email: foleg,tb,abc,cully,jwg@cs.uni-bonn.de  rottmann@hbz-nrw.de  
Phone: 2  
Title: Maintaining Library Catalogues with an RDBMS: A Performance Study  
Author: O. Balownew T. Bode A.B. Cremers J. Kalinski J.E. Wolff H. Rottmann 
Address: Romerstr. 164, 53117 Bonn, Germany  Landes NW (HBZ), Classen-Kappelmann-Str. 24, 50931 Koln, Germany  
Affiliation: 1 Institute of Computer Science III, University of Bonn,  Hochschulbibliothekszentrum des  
Abstract: Our study [1] is the result of a cooperation with the University Library Center of the State of North-Rhine Westfalia (HBZ). The HBZ catalogue is a collection of data about (amongst others) documents, persons, keyword sequences and the relationships between them. As many of the HBZ data is data about well-structured entities, it is natural to ask whether a relational DBMS performs sufficiently powerful to meet the requirements of the HBZ with respect to retrieval and update operations. The following tests are based on real catalogue data (comprising about 7.5 mio. document titles) and on librarians' real queries and updates. While part of the user transactions can be expressed by standard SQL queries and updates, special support is needed for keyword search. The first test series took place at the SEQUENT test center in Munich. 1 Different loads with up to 50 new transactions per second have been generated (average load in the actual system: 5 transactions/second). In several hardware configurations standard SQL queries and updates could be answered in less than one second. These positive results are implications of the librarians' ability to specify their interests in a very concise way such that more than 99% of all SQL queries have less than 50 hits. We then tested in how far ORACLE's TextServer3 supports the HBZ application in respect to keyword search. In TextServer3 word occurrence information is represented by bitvectors and stored in database tables in a compressed format. Our measurements show that this tool fails to meet the HBZ performance requirements: In a realization with so-called hitlist tables as well as in an API-based solution the first evaluation step (bitvector processing) already takes 3-5 seconds. The promising performance of the DBMS server motivated us to dispense with bitlist encodings and to compare different realizations of keyword 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> O. Balownew, T. Bode, A.B. Cremers, J. Kalinski, J.E. Wolff, and H. Rottmann. </author> <title> Maintaing Library Catalogues with an RDBMS | A Performance Study |. Technical Report IAI-TR-96-13, </title> <institution> University of Bonn, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: 1 Institute of Computer Science III, University of Bonn, Romerstr. 164, 53117 Bonn, Germany foleg,tb,abc,cully,jwg@cs.uni-bonn.de 2 Hochschulbibliothekszentrum des Landes NW (HBZ), Classen-Kappelmann-Str. 24, 50931 Koln, Germany rottmann@hbz-nrw.de Abstract. Our study <ref> [1] </ref> is the result of a cooperation with the University Library Center of the State of North-Rhine Westfalia (HBZ). The HBZ catalogue is a collection of data about (amongst others) documents, persons, keyword sequences and the relationships between them.
Reference: 2. <author> H. Kaufmann and H.-J. Schek. </author> <title> Text search using database systems revisited | some experiments |. In C.A. </title> <editor> Goble and J.A. Keane, editors, </editor> <booktitle> Proc. of the 13th British National Conf. on Databases, </booktitle> <pages> pages 204-225. </pages> <publisher> Springer, LNCS 940, </publisher> <year> 1995. </year> <title> 2 Using ORACLE 7.3.2 on a SUN SPARCstation 10 with Solaris 2.5 at our institute. </title>
Reference-contexts: Performance of evaluation strategies As an alternative optimization Kaufmann and Schek <ref> [2] </ref> propose to ignore frequent words in the INTERSECT-step (see curve RI ). But in the HBZ application a quarter of the intermediate results will then be incorrect (i.e. too large) requiring expensive post-processing in order to detect the "false drops".
References-found: 2

