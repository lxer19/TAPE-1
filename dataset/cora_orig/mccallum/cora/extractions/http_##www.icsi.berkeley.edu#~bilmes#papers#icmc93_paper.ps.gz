URL: http://www.icsi.berkeley.edu/~bilmes/papers/icmc93_paper.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/~bilmes/papers/
Root-URL: http://www.icsi.berkeley.edu
Email: &lt;bilmes@amt.mit.edu&gt;  
Title: Techniques to Foster Drum Machine Expressivity  
Author: Jeff A. Bilmes 
Address: Cambridge, MA 02139  
Affiliation: Perceptual Computing Group MIT Media Laboratory Massachusetts Institute of Technology  
Abstract: Electronic drum machines need algorithms to help them produce "expressive-sounding" rhythmic phrases. In [Bilmes, 1992], I claim that three perceptually separate elements characterize percussive rhythm: metric content, tempo variation, and deviations (formerly called event-shifts). Herein, I demonstrate that algorithms based on this model may considerably facilitate reproduction of expressive rhythm. I describe one such algorithm which extracts the separate elements from a percussive performance. The performance is then resynthesized with varying degrees of tempo variation and deviations. Without the deviations, the performance sounds mechanical. With them it sounds rich and alive. Consequently, I claim that we should begin a concentrated study on the separate elements characterizing percussive rhythm, particularly deviations. To this effect, development has be gun on a graphical drum machine program with which deviations may be explored.
Abstract-found: 1
Intro-found: 1
Reference: [Bilmes, 1992] <author> Jeff A. Bilmes. </author> <title> A Model for Musical Rhythm. </title> <booktitle> Proceedings of the ICMC, </booktitle> <address> San Jose CA, </address> <year> 1992. </year>
Reference-contexts: In <ref> [Bilmes, 1992] </ref>, I introduce a new model of rhythmic expressivity. Specifically, I state that beat-based rhythm can be characterized by three components: metric structure, tempo variation, and deviations (formerly called event-shift models). <p> That is, any performance variation not accounted for by tempo variation because of its high frequency must be owing to "deviations." The following algorithm was developed with this assumption in mind. 3 Timing Extraction Algo rithm In <ref> [Bilmes, 1992] </ref>, I point out the necessity of an algorithm that extracts deviations from a performance. Presented herein is one that extracts the quantized score, the tempo variation, and the deviations. The input to the algorithm is a list of attack times. <p> Therein may also be found a new drum attack detection algorithm, an automatic drum stroke classifier, and the design of a deviation learning algorithm 9 . In this paper, I have introduced the concept of tatum, have utilized the separate elements defined in <ref> [Bilmes, 1992] </ref> for rhythmic analysis, and have demonstrated the importance of deviations for representing expressivity in percussive musical phrases. Deviations play a vital role in rhythm. They should be analyzed, comprehended, and utilized.
Reference: [Bilmes, 1993] <author> Jeff A. Bilmes. </author> <title> Timing is of the Essence: Perceptual and Computational Techniques for Representing, Learning, and Reproducing Expressive Timing in Percussive Rhythm. </title> <type> Masters Thesis 1993, </type> <institution> Mas-sachusetts Institute of Technology, MIT Media Laboratory, </institution> <address> Cambridge MA, </address> <month> 02139. </month>
Reference-contexts: Timing data was obtained from the following performance instruments: the quinto (high), the segundo (middle), and the tumbao (low) drum. A new attack detection algorithm, using only high frequency energy to determine the attack, is defined in <ref> [Bilmes, 1993] </ref> and was used here. The reference instrument was the guagua, a thick bamboo cylinder, about 4" diameter, hit with two sticks. An approximation to the reference instrument pattern may be seen in Figure 2. What follows are the results of the segundo only. <p> Clearly, this confirms that structure does exist in the deviations. The performance was resynthesized 7 by triggering select samples of the original performance. I developed an automatic note classification algorithm to obtain the drum stroke types which completed the score <ref> [Bilmes, 1993] </ref>. The various resynthesis examples follow: 1. Direct by triggering the samples at the ap propriate time. 2. Quantized using a constant tempo equal to the overall average. 3. Quantized using b [n] as the tempo 4. <p> During playback, deviations, toggles, and pattern durations may all be adjusted. xited is thus a novel drum machine user interface. A similar such interface could be used by music sequencers, or eventually, by commercial drum machines. In <ref> [Bilmes, 1993] </ref>, an algorithm is defined that creates a mapping between quantized musical patterns and sets of deviations. This algorithm will be eventually incorporated into xited. xited provides the ability to experiment with deviations and to determine the best sounding de viations for a drum pattern. <p> Indeed, some very interesting rhythmic effects may be attained with xited by varying deviations and pattern durations. 6 Conclusion This paper is a summary of two and one-half chapters from <ref> [Bilmes, 1993] </ref>. Therein may also be found a new drum attack detection algorithm, an automatic drum stroke classifier, and the design of a deviation learning algorithm 9 .
Reference: [Desain and Honing, 1992] <author> Peter Desain and Henk-jan Honing. </author> <title> Music, Mind and Machine: Studies in Computer Music, Music Cognition, </title> <booktitle> and Artificial Intelligence. </booktitle> <publisher> Thesis Publishers, </publisher> <address> Amsterdam 1992. </address>
Reference-contexts: Unsuitable for percussive music however, previous representations of expressive timing ([Clines, 1977], [Jaffe, 1985], [Schloss, 1985], [Repp, 1990], [Wessel et al., 1991], [Anderson and Kuivila, 1991], [Anderson and Bilmes, 1991], and <ref> [Desain and Honing, 1992] </ref>) can all (with the exception of [Desain and Honing, 1992]) be reduced to tempo variation. In [Bilmes, 1992], I introduce a new model of rhythmic expressivity. <p> Unsuitable for percussive music however, previous representations of expressive timing ([Clines, 1977], [Jaffe, 1985], [Schloss, 1985], [Repp, 1990], [Wessel et al., 1991], [Anderson and Kuivila, 1991], [Anderson and Bilmes, 1991], and <ref> [Desain and Honing, 1992] </ref>) can all (with the exception of [Desain and Honing, 1992]) be reduced to tempo variation. In [Bilmes, 1992], I introduce a new model of rhythmic expressivity. Specifically, I state that beat-based rhythm can be characterized by three components: metric structure, tempo variation, and deviations (formerly called event-shift models).
Reference: [Schloss, 1985] <author> W. Andrew Schloss. </author> <title> On the Automatic Transcription of Percussive Music - From Acoustic Signal to High-Level Analysis. </title> <type> Ph.D. Thesis, </type> <institution> CCRMA, Stanford University, Stanford CA, </institution> <month> 94305. </month>
Reference-contexts: Percussive music is a case in point, as anyone who has truly enjoyed traditional music from Africa, India, or Central or South America knows. Unsuitable for percussive music however, previous representations of expressive timing ([Clines, 1977], [Jaffe, 1985], <ref> [Schloss, 1985] </ref>, [Repp, 1990], [Wessel et al., 1991], [Anderson and Kuivila, 1991], [Anderson and Bilmes, 1991], and [Desain and Honing, 1992]) can all (with the exception of [Desain and Honing, 1992]) be reduced to tempo variation. In [Bilmes, 1992], I introduce a new model of rhythmic expressivity.
Reference: [Clines, 1977] <author> Manfred Clines. Sentics, </author> <title> The Touch of Emotion. </title> <publisher> Doubleday Anchor, </publisher> <address> New York 1987. </address>
Reference: [Press et al., 1992] <author> W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery. </author> <title> Numerical Recipes in C, Second Edition. </title> <publisher> Cam-bridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: outcome. 5 ffi [0] = 1; ffi [n 6= 0] = 0 To filter out high frequency variation, we convolve again, and compute d [n] = d 0 [n] fl h [n]; where h [n] is either an FIR low-pass filter with a desired stop-band, or a Savitzky-Golay smoothing filter <ref> [Press et al., 1992] </ref>. This step removes high frequency variation in d 0 [n]. Thus, the array d [n] is our estimate of the duration of the n th tatum. <p> In this form it is hard to see any structure. Although the deviation array is essentially an unevenly sampled signal, spectral analysis is still possible. The Lomb normalized peri odogram <ref> [Press et al., 1992] </ref> is a magnitude spectral analysis technique specifically designed for unevenly sampled signals. It is commonly applied to astrophysical data where regular sampling is not possible.
Reference: [Marr, 1982] <author> David Marr. </author> <title> Vision. W.H. </title> <publisher> Freeman and Company, </publisher> <address> San Francisco 1982 </address>
Reference-contexts: Perceiving the tatum implies that the listener or performer is judging and anticipating musical events with respect to a high frequency pulse. It is a natural perception, perhaps similar to the illusory contour in the well known picture on the front cover of Marr's book <ref> [Marr, 1982] </ref>. The tatum is not always explicitly stated in a piece of music. How, then, is it implied? The tatum is the lowest level of the metric musical hierarchy. Often, it is defined by the smallest time interval between successive notes in a rhythmic phrase.
Reference: [Jaffe, 1985] <author> David Jaffe. </author> <title> Ensemble Timing in Computer Music. </title> <journal> Computer Music Journal, </journal> <volume> 9(4): pp.38-48, </volume> <year> 1985. </year>
Reference-contexts: Percussive music is a case in point, as anyone who has truly enjoyed traditional music from Africa, India, or Central or South America knows. Unsuitable for percussive music however, previous representations of expressive timing ([Clines, 1977], <ref> [Jaffe, 1985] </ref>, [Schloss, 1985], [Repp, 1990], [Wessel et al., 1991], [Anderson and Kuivila, 1991], [Anderson and Bilmes, 1991], and [Desain and Honing, 1992]) can all (with the exception of [Desain and Honing, 1992]) be reduced to tempo variation. In [Bilmes, 1992], I introduce a new model of rhythmic expressivity.
Reference: [Anderson and Kuivila, 1991] <author> David P. Anderson and Ron Kuivila. </author> <title> Formula: A Programming Language for Expressive Computer Music. </title> <journal> IEEE Computer, </journal> <volume> 24(7): pp.12-21, </volume> <year> 1991. </year>
Reference-contexts: Percussive music is a case in point, as anyone who has truly enjoyed traditional music from Africa, India, or Central or South America knows. Unsuitable for percussive music however, previous representations of expressive timing ([Clines, 1977], [Jaffe, 1985], [Schloss, 1985], [Repp, 1990], [Wessel et al., 1991], <ref> [Anderson and Kuivila, 1991] </ref>, [Anderson and Bilmes, 1991], and [Desain and Honing, 1992]) can all (with the exception of [Desain and Honing, 1992]) be reduced to tempo variation. In [Bilmes, 1992], I introduce a new model of rhythmic expressivity.
Reference: [Anderson and Bilmes, 1991] <author> David P. Anderson and Jeff Bilmes. </author> <title> Concurrent Real-Time Music in C++. </title> <booktitle> USENIX C++ Conference Proceedings, </booktitle> <address> Washington, D.C. </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Unsuitable for percussive music however, previous representations of expressive timing ([Clines, 1977], [Jaffe, 1985], [Schloss, 1985], [Repp, 1990], [Wessel et al., 1991], [Anderson and Kuivila, 1991], <ref> [Anderson and Bilmes, 1991] </ref>, and [Desain and Honing, 1992]) can all (with the exception of [Desain and Honing, 1992]) be reduced to tempo variation. In [Bilmes, 1992], I introduce a new model of rhythmic expressivity.
Reference: [Anderson and Bilmes, 1992] <author> David P. Anderson and Jeff Bilmes. </author> <title> MOOD: A Concurrent C++-Based Music Language. </title> <booktitle> Proceedings of the ICMC, </booktitle> <address> pp.440-441 San Jose CA. </address> <year> 1992. </year>
Reference: [Repp, 1990] <author> Bruno H. Repp. </author> <title> Patterns of Expressive Timing in Performances of a Beethoven Minuet by Nineteen Famous Pianists. </title> <journal> J. Acoust. Soc. Am. </journal> <volume> 88, </volume> <pages> pp. 622-641. </pages>
Reference-contexts: Percussive music is a case in point, as anyone who has truly enjoyed traditional music from Africa, India, or Central or South America knows. Unsuitable for percussive music however, previous representations of expressive timing ([Clines, 1977], [Jaffe, 1985], [Schloss, 1985], <ref> [Repp, 1990] </ref>, [Wessel et al., 1991], [Anderson and Kuivila, 1991], [Anderson and Bilmes, 1991], and [Desain and Honing, 1992]) can all (with the exception of [Desain and Honing, 1992]) be reduced to tempo variation. In [Bilmes, 1992], I introduce a new model of rhythmic expressivity.
Reference: [Wessel et al., 1991] <author> David Wessel, David Bris-tow, and Zack Settel. </author> <title> Control of Phrasing and Articulation in Synthesis. </title> <booktitle> Proceedings of the ICMC, </booktitle> <address> Urbana, Illinois 1987. </address>
Reference-contexts: Percussive music is a case in point, as anyone who has truly enjoyed traditional music from Africa, India, or Central or South America knows. Unsuitable for percussive music however, previous representations of expressive timing ([Clines, 1977], [Jaffe, 1985], [Schloss, 1985], [Repp, 1990], <ref> [Wessel et al., 1991] </ref>, [Anderson and Kuivila, 1991], [Anderson and Bilmes, 1991], and [Desain and Honing, 1992]) can all (with the exception of [Desain and Honing, 1992]) be reduced to tempo variation. In [Bilmes, 1992], I introduce a new model of rhythmic expressivity.
References-found: 13

