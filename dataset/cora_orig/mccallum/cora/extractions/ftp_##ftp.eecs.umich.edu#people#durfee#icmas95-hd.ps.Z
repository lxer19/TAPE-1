URL: ftp://ftp.eecs.umich.edu/people/durfee/icmas95-hd.ps.Z
Refering-URL: http://ai.eecs.umich.edu/people/durfee/vita.html
Root-URL: http://www.cs.umich.edu
Email: marcush@engin.umich.edu durfee@engin.umich.edu  
Title: Deciding When to Commit To Action During Observation-based Coordination  
Author: Marcus J. Huber and Edmund H. Durfee 
Web: http://ai.eecs.umich.edu/people  
Address: Michigan  
Affiliation: Distributed Intelligent Agents Group (DIAG) The University of  
Abstract: We have developed a multiagent scheme which utilizes plan recognition as its primary means of acquiring the information necessary to coordinate the activities of agents. Preliminary research has demonstrated that the plan recognition system developed makes coordination of multiple agents possible. An important issue that arises when observation is the primary means of information acquisition is the introduction of uncertainty into the coordination process. We have explored the issue of early versus late commitment to the uncertain information thus gained and the resulting tradeoff between time and effort as the commitment level is changed. Our results show that while in some situations it is worthwhile delaying commitment until uncertainty is reduced, in other situations it is important to act even when uncertainty is high. The long-term goal of the research is to develop the notion of coordination through observation, where agents utilize plan recognition to acquire coordination information. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Charniak, E., and Goldman, R. </author> <year> 1991. </year> <title> A probabilistic model of plan recognition. </title> <booktitle> In Proceedings Ninth National Conference on Artificial Intelligence, </booktitle> <pages> 160-165. </pages> <address> Anaheim, CA: </address> <booktitle> American Association for Artificial Intelligence. </booktitle>
Reference-contexts: Another alternative, and the approach that we have taken, is for the agents to infer the plans of each other by observing the actions or behaviors of the other agents <ref> (Charniak & Goldman 1991) </ref>, rather than either actively communicating plans, goals, and intentions, or inferring these through knowledge of what others con sider relevant or desirable.
Reference: <author> Cohen, P. R., and Perrault, C. R. </author> <year> 1979. </year> <title> Elements of a plan-based theory of speech acts. </title> <booktitle> Cognitive Science 3(3) </booktitle> <pages> 177-212. </pages>
Reference: <author> Conry, S. E.; Meyer, R. A.; and Lesser, V. R. </author> <year> 1988. </year> <title> Multistage negotiation in distributed planning. </title>
Reference: <editor> In Bond, A. H., and Gasser, L., eds., </editor> <booktitle> Readings in Distributed Artificial Intelligence. </booktitle> <publisher> Morgan Kaufman. </publisher> <pages> 367-384. </pages>
Reference: <author> Durfee, E. H., and Montgomery, T. A. </author> <year> 1990. </year> <title> A hierarchical protocol for coordinating multiagent behaviors. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 86-93. </pages>
Reference-contexts: We then describe our plan recognition system and the integration of the plan recognition system into agents performing navigation tasks in the environment. The environment in which our agents act is a discrete time, two-dimensional, simulated grid world. This environment was created using MICE <ref> (Montgomery & Durfee 1990) </ref>, a testbed designed explicitly for experimentation with multiple agent coordination techniques. The agents in this environment were limited to the primitive actions of motion (movement north, south, east, or west) or no motion.
Reference: <author> Durfee, E. H.; Lesser, V. R.; and Corkill, D. D. </author> <year> 1987. </year> <title> Coherent cooperation among communicating problem solvers. </title> <journal> IEEE Transactions on Computers C-36(11):1275-1291. </journal> <note> (Also published in Readings in Distributed Artificial Intelligence, </note> <editor> Alan H. Bond and Les Gasser, editors, </editor> <address> pages 268-284, </address> <publisher> Morgan Kauf-mann, 1988.). </publisher>
Reference: <author> Genesereth, M.; Ginsberg, M.; and Rosenschein, J. </author> <year> 1984. </year> <title> Cooperation without communications. </title> <type> Technical Report 84-36, </type> <institution> Stanford Heuristic Programming Project, Computer Science Department, Stan-ford University, Stanford, California 94305. </institution> <note> (Also published in Readings in Distributed Artificial Intelligence, </note> <editor> Alan H. Bond and Les Gasser, editors, </editor> <address> pages 220-226, </address> <publisher> Morgan Kaufmann, 1988.). </publisher>
Reference-contexts: In addition, traditional DAI techniques rely on strong assumptions of common communication language, communication protocol, and plan and goal representation (Cohen & Perrault 1979; Durfee & Montgomery 1990). Communication-poor coordination techniques do exist, including social conventions (Shoham & Tennen-holtz 1992), focal points (Kraus & Rosenschein 1991), decision-theoretic <ref> (Genesereth, Ginsberg, & Rosen-schein 1984) </ref>, and game-theoretic recursive modeling (Gmytrasiewicz, Durfee, & Wehe 1991). In general, these techniques emphasize implicitly or explicitly in-fering others' actions based on established norms for behavior or on beliefs about the preferences or interests of others.
Reference: <author> Gmytrasiewicz, P. J.; Durfee, E. H.; and Wehe, D. K. </author> <year> 1991. </year> <title> A decision-theoretic approach to coordinating multiagent interactions. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: Communication-poor coordination techniques do exist, including social conventions (Shoham & Tennen-holtz 1992), focal points (Kraus & Rosenschein 1991), decision-theoretic (Genesereth, Ginsberg, & Rosen-schein 1984), and game-theoretic recursive modeling <ref> (Gmytrasiewicz, Durfee, & Wehe 1991) </ref>. In general, these techniques emphasize implicitly or explicitly in-fering others' actions based on established norms for behavior or on beliefs about the preferences or interests of others. Thus, social conventions constrain behavior to make others predictable, but can be over-constraining in variable environments.
Reference: <author> Huber, M. J., and Durfee, E. H. </author> <year> 1993. </year> <title> Observational uncertainty in plan recognition among interacting robots. </title> <booktitle> In Working Notes: Workshop on Dynamically Interacting Robots, </booktitle> <pages> 68-75. </pages>
Reference-contexts: The various agents, then, may be heterogeneous, having different representations of models and plans, perceptual capabilities, communication means, etc. We recognize, however, that there are costs associated with the plan recognition process. These costs include the introduction of uncertainty due to imperfect observation and inferencing <ref> (Huber & Durfee 1993) </ref>, additional computation time and effort to perform plan and goal inferencing, and the relative difficulty (compared to direct communication methods) of recognizing and incorporating new goals and behaviors into the models of other agents (Huber, Durfee, & Well-man 1994). <p> the current position of the agent is set to a probability of 1.0, since the observing agent can tell where the other agent is at all times and sensors are assumed to be perfect in this implementation. 1 The Destination node's 1 Further experiments, motivated by experiments with actual robots <ref> (Huber & Durfee 1993) </ref>, where uncertainty (a) grid-world plan recognition environment. states are initially equiprobable, as the observing agent starts without any bias toward which goal the bounding agent will be heading toward.
Reference: <author> Huber, M. J.; Durfee, E. H.; and Wellman, M. P. </author> <year> 1994. </year> <title> The automated mapping of plans for plan recognition. </title> <booktitle> In Proceedings of the 1994 Distributed AI Workshop, </booktitle> <pages> 137-152. </pages>
Reference-contexts: costs include the introduction of uncertainty due to imperfect observation and inferencing (Huber & Durfee 1993), additional computation time and effort to perform plan and goal inferencing, and the relative difficulty (compared to direct communication methods) of recognizing and incorporating new goals and behaviors into the models of other agents <ref> (Huber, Durfee, & Well-man 1994) </ref>. Cooperating agents will need to weigh the costs and risks associated with explicit communication against the costs associated with plan recognition. If explicit communication is relatively inexpensive and risk free it is probably advantageous for the agent to utilize it.
Reference: <author> Kraus, S., and Rosenschein, J. S. </author> <year> 1991. </year> <title> The role of representation in interaction: Discovering focal points among alternative solutions. </title> <editor> In Demazeau, Y., and Muller, J.-P., eds., </editor> <booktitle> Decentralized AI. </booktitle> <publisher> North Holland. </publisher>
Reference-contexts: In addition, traditional DAI techniques rely on strong assumptions of common communication language, communication protocol, and plan and goal representation (Cohen & Perrault 1979; Durfee & Montgomery 1990). Communication-poor coordination techniques do exist, including social conventions (Shoham & Tennen-holtz 1992), focal points <ref> (Kraus & Rosenschein 1991) </ref>, decision-theoretic (Genesereth, Ginsberg, & Rosen-schein 1984), and game-theoretic recursive modeling (Gmytrasiewicz, Durfee, & Wehe 1991). In general, these techniques emphasize implicitly or explicitly in-fering others' actions based on established norms for behavior or on beliefs about the preferences or interests of others.
Reference: <author> Montgomery, T. A., and Durfee, E. H. </author> <year> 1990. </year> <title> MICE users guide. </title> <type> Technical Report CSE-TR-64-90, </type> <institution> Computer Science and Engineering Division, EE and CS Department, University of Michigan, </institution> <address> Ann Arbor, MI 48109. </address> <note> (Revised 1992). </note>
Reference-contexts: We then describe our plan recognition system and the integration of the plan recognition system into agents performing navigation tasks in the environment. The environment in which our agents act is a discrete time, two-dimensional, simulated grid world. This environment was created using MICE <ref> (Montgomery & Durfee 1990) </ref>, a testbed designed explicitly for experimentation with multiple agent coordination techniques. The agents in this environment were limited to the primitive actions of motion (movement north, south, east, or west) or no motion.
Reference: <author> Shoham, Y., and Tennenholtz, M. </author> <year> 1992. </year> <title> On the synthesis of useful social laws for artificial agents societies (preliminary report). </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: In addition, traditional DAI techniques rely on strong assumptions of common communication language, communication protocol, and plan and goal representation (Cohen & Perrault 1979; Durfee & Montgomery 1990). Communication-poor coordination techniques do exist, including social conventions <ref> (Shoham & Tennen-holtz 1992) </ref>, focal points (Kraus & Rosenschein 1991), decision-theoretic (Genesereth, Ginsberg, & Rosen-schein 1984), and game-theoretic recursive modeling (Gmytrasiewicz, Durfee, & Wehe 1991).
Reference: <author> Srinivas, S., and Breese, J. </author> <year> 1990. </year> <title> Ideal: A software package for analysis of influence diagrams. </title> <booktitle> In Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> 212-219. </pages>
Reference-contexts: Goal Inference The overwatching agent's primary objective was to accurately infer the goal (the final destination) of the bounding agent. To do this, each overwatching agent employed a belief network implemented using the IDEAL system <ref> (Srinivas & Breese 1990) </ref>. The IDEAL system consists of a collection of LISP functions that permit the construction and maintenance of belief networks, the accumulation of observations, and the subsequent propagation of the beliefs throughout the network in order to perform plan inferencing.
References-found: 14

