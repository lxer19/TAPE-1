URL: http://cs.nyu.edu/cs/faculty/weinshal/papers/dual.ps.gz
Refering-URL: http://cs.nyu.edu/cs/faculty/weinshal/papers.html
Root-URL: http://www.cs.nyu.edu
Title: Dual Computation of Projective Shape and Camera Positions from Multiple Images  
Author: STEFAN CARLSSON DAPHNA WEINSHALL 
Keyword: projective shape, reconstruction, positioning, epipolar geometry, duality, multiple views  
Address: S 100 44 Stockholm, Sweden  91904 Jerusalem, Israel  
Affiliation: Dept. of Numerical Analysis and Computing Science, Royal Institute of Technology  Institute of Computer Science, The Hebrew University of Jerusalem  
Note: International Journal of Computer Vision,  c 1998 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  What are the positions of the cameras relative to the points?  
Email: Email: stefanc@nada.kth.se  Email: daphna@cs.huji.ac.il  
Date: 27(3), 1-16 (1998)  Received June 10, 1996. Revised March 3, 1997.  
Abstract: Given multiple image data from a set of points in 3-D, there are two fundamental questions that can be addressed: In this paper we show that, for projective views and with structure and position defined projectively, these problems are dual because they can be solved using constraint equations where space points and camera positions occur in a reciprocal way. More specifically, by using canonical projective reference frames for all points in space and images, the imaging of point sets in space by multiple cameras can be captured by constraint relations involving three different kinds of parameters only, which are the coordinates of :(1) space points, (2) camera positions (3) image points. The duality implies that the problem of computing camera positions from p points in q views can be solved with the same algorithm as the problem of directly reconstructing q + 4 points in p 4 views. This unifies different approaches to projective reconstruction: methods based on external calibration and direct methods exploiting constraints that exist between shape and image invariants. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S.Carlsson, </author> <title> The Double Algebra: An Effective Tool for Computing Invariants in Computer Vision "Applications of Invariance in Computer Vision" Springer LNCS 825 pp. </title> <month> 145 - 164 </month> <year> (1994) </year>
Reference-contexts: Projective reconstruction is then achieved using the epipolar information in various alternative ways: projective shape from projection matrices [7], [22], cross-ratios [10], or more direct methods expressing 3-D invariants directly in terms of the fundamental matrix <ref> [1] </ref>, [5]. Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], [13], [19], [26], [34]. <p> This is done by making the substitutions defined in (40)-(41). We can use these equations to find camera positions. If we choose the coordinates of the center of camera a to be at <ref> [1; 1; 1; 1] </ref>, then 0 ; 0 ; 0 ; ! 0 give the center of camera b (inverse), 00 ; 00 ; 00 ; ! 00 give the center of camera c (inverse), and 000 ; 000 ; 000 ; ! 000 give the center of camera d (inverse), <p> This is done by substituting (42)-(43), for 8 points P 1 ; : : : ; P 8 observed in the image of camera a. If we choose the coordinates of the 5th space point to be at <ref> [1; 1; 1; 1] </ref>, then 0 ; 0 ; 0 ; ! 0 give the coordinates of point 6, 00 ; 00 ; 00 ; ! 00 give the coordinates of point 7, and 000 ; 000 ; 000 ; ! 000 give the coordinates of point 8 in the basis
Reference: 2. <author> S. </author> <title> Carlsson View Variation and Linear Invariants in 2-D and 3-D Tech. </title> <type> rep. </type> <institution> Royal Institute of Technology, ISRN KTH/NA/P-95/22-SE, </institution> <month> Dec. </month> <year> 1995 </year>
Reference-contexts: Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry [17], [29], [31]. Especially in the case of constrained scenes, direct methods are powerful <ref> [2] </ref> , [23], [30], [38] in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points [6], [21], [38].
Reference: 3. <author> S. Carlsson. </author> <title> Duality of reconstruction and positioning from projective views. </title> <booktitle> In IEEE Workshop on Representations of Visual Scenes, </booktitle> <address> Cambridge, Mass, </address> <year> 1995. </year>
Reference-contexts: The duality between positioning and reconstruction was first reported in the 1995 Workshop on Representations of Visual Scenes: The basic algebraic relations, and the geometrical interpretation in terms of duality between the position of the camera's center of projection and the position of a point in 3D, was described in <ref> [3] </ref>. The basic algebraic duality, which formally exists for any representation of the basis points, was also described in [37]; in [37] we described the new space-image relations that are obtained using the duality observation, and obtained a low rank factorization of the 7 points shape tensor (cf. [28]).
Reference: 4. <author> H.H. Chen and T.S. Huang, </author> <title> Matching 3-D line segments with applications to multiple-object motion estimation, </title> <address> T-PAMI 12, </address> <year> 1990, </year> <pages> 1002-1008. </pages>
Reference-contexts: The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. The case of multiple camera constraints has also been investigated for the case of reconstruction from lines for calibrated cameras <ref> [4] </ref>, [32] and for un-calibrated cameras [12]. Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry [17], [29], [31].
Reference: 5. <author> G. Csurka and O.D. </author> <title> Faugeras Computing three-dimensional projective invariants from a pair of images using the Grassmann-Cayley algebra Tech. </title> <type> report INRIA-Sophia Antipolis Nov. </type> <year> 1994 </year>
Reference-contexts: Projective reconstruction is then achieved using the epipolar information in various alternative ways: projective shape from projection matrices [7], [22], cross-ratios [10], or more direct methods expressing 3-D invariants directly in terms of the fundamental matrix [1], <ref> [5] </ref>. Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], [13], [19], [26], [34].
Reference: 6. <author> S. Demey, A. Ziserman and P. Beardley, </author> <title> Affine and projective structure from motion, </title> <booktitle> Proc. </booktitle> <address> BMVC-92, </address> <year> (1992) </year>
Reference-contexts: Especially in the case of constrained scenes, direct methods are powerful [2] , [23], [30], [38] in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points <ref> [6] </ref>, [21], [38]. The direct methods for reconstruction exploit constraints existing between projective coordinates of coordinates of space points and their image coordinates, not involving camera geometry. Direct methods in unconstrained scenes, but assuming weak perspective projection, were described in [33], [35], [36].
Reference: 7. <author> O.D. Faugeras, </author> <title> What can be seen in three dimensions with an un calibrated stereo rig?, </title> <booktitle> Proc. 2:nd ECCV, </booktitle> <pages> pp. 563-578. </pages> <year> (1992) </year>
Reference-contexts: This matrix can be used to constrain image coordinates of points in two images of the same scene. Projective reconstruction is then achieved using the epipolar information in various alternative ways: projective shape from projection matrices <ref> [7] </ref>, [22], cross-ratios [10], or more direct methods expressing 3-D invariants directly in terms of the fundamental matrix [1], [5].
Reference: 8. <author> O.D. Faugeras, Q.T. Luong, and S.J. Maybank, </author> <title> Camera self- calibration: Theory and experiments, </title> <booktitle> Proc. 2:nd ECCV, </booktitle> <pages> pp. 321-334. </pages> <year> (1992) </year>
Reference-contexts: Camera positioning, or external calibration, in the perspective projection case is based on the determination of the epipolar geometry which for two cameras is captured by the fundamental ma 2 Carlsson and Weinshall trix <ref> [8] </ref>. This matrix can be used to constrain image coordinates of points in two images of the same scene. <p> Given multiple views of a set of points, reconstruction can be achieved by determining the projection matrices M i and the 3-D point positions P i . In the general un-calibrated camera case, these can only be determined up to an arbitrary linear transformation <ref> [8] </ref>, [11]. Given that P 1 ; P 2 : : : P n is a reconstruction, it follows that (P 0 2 : : : P 0 where T is an arbitrary 4 fi 4 matrix, is an equally valid reconstruction given the observed image data.
Reference: 9. <author> O.D. Faugeras, and B. </author> <title> Mourrain Algebraic and geometric properties of point correspondences between N images, </title> <booktitle> Proc 5:th ICCV, </booktitle> <pages> 951-956, </pages> <note> (1995) 16 Carlsson and Weinshall </note>
Reference-contexts: Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention <ref> [9] </ref>, [12], [13], [19], [26], [34]. The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. <p> X 1 Y 1 Z 1 W 1 1 C C C A (36) Since both rectangular matrices have rank 3 all their 4 fi 4 minors must vanish, giving us constraints among up to four cameras and image mea surements, or up to four space points and image measurements <ref> [9] </ref>. These constraints are bi tri-or quadri-linear in the projective image coordinates. They are related to the multiple image epipolar constraints previously derived and discussed in [9],[13], [25], [34]. <p> Space-point and camera-point relations: The tri-linear constraints for external calibration described in [12], [25] are obtained from (45), and the quadrilinear constraints described in <ref> [9] </ref>, [26], [34] are obtained from the corresponding quadrilinear system. This is done by making the substitutions defined in (40)-(41). We can use these equations to find camera positions. <p> This is the essence of the analysis described in, e.g., <ref> [9] </ref>, [12], [13], [19], [26], [34]. On the other hand, substituting (54) into (36) would significantly change the essence of the following derivations. Now the G-matrix and the multi-linear shape tensors depend on the shape and the camera they now depend on the orientation of the image via matrix Q.
Reference: 10. <author> P. </author> <title> Gros , How to use the cross ratio to compute invariants from two images "Applications of Invariance in Computer Vision" Springer LNCS 825 pp. </title> <month> 107 - 126 </month> <year> (1994) </year>
Reference-contexts: This matrix can be used to constrain image coordinates of points in two images of the same scene. Projective reconstruction is then achieved using the epipolar information in various alternative ways: projective shape from projection matrices [7], [22], cross-ratios <ref> [10] </ref>, or more direct methods expressing 3-D invariants directly in terms of the fundamental matrix [1], [5]. Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], [13], [19], [26], [34].
Reference: 11. <author> R. Hartley, R. Gupta, and T. Chang, </author> <title> Stereo from uncalibrated cameras,Proc. </title> <booktitle> CVPR, </booktitle> <pages> 761-764. </pages> <year> (1992) </year>
Reference-contexts: Given multiple views of a set of points, reconstruction can be achieved by determining the projection matrices M i and the 3-D point positions P i . In the general un-calibrated camera case, these can only be determined up to an arbitrary linear transformation [8], <ref> [11] </ref>. Given that P 1 ; P 2 : : : P n is a reconstruction, it follows that (P 0 2 : : : P 0 where T is an arbitrary 4 fi 4 matrix, is an equally valid reconstruction given the observed image data.
Reference: 12. <author> R.I. </author> <title> Hartley Lines and Points in Three Views An Integrated Approach IUWS (1994) </title>
Reference-contexts: Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], <ref> [12] </ref>, [13], [19], [26], [34]. The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. <p> The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. The case of multiple camera constraints has also been investigated for the case of reconstruction from lines for calibrated cameras [4], [32] and for un-calibrated cameras <ref> [12] </ref>. Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry [17], [29], [31]. Especially in the case of constrained scenes, direct methods are powerful [2] , [23], [30], [38] in the sense that fewer points are needed for reconstruction. <p> Space-point and camera-point relations: The tri-linear constraints for external calibration described in <ref> [12] </ref>, [25] are obtained from (45), and the quadrilinear constraints described in [9], [26], [34] are obtained from the corresponding quadrilinear system. This is done by making the substitutions defined in (40)-(41). We can use these equations to find camera positions. <p> This is the essence of the analysis described in, e.g., [9], <ref> [12] </ref>, [13], [19], [26], [34]. On the other hand, substituting (54) into (36) would significantly change the essence of the following derivations. Now the G-matrix and the multi-linear shape tensors depend on the shape and the camera they now depend on the orientation of the image via matrix Q.
Reference: 13. <author> A. </author> <title> Heyden Reconstruction from image sequences by means of relative depths. </title> <booktitle> Proc 5:th ICCV, </booktitle> <volume> 1058 - 1063, </volume> <year> (1995) </year>
Reference-contexts: Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], <ref> [13] </ref>, [19], [26], [34]. The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. <p> We will see that the method proposed corresponds to the computation of a fundamental matrix and tensors in a canonical image coordinate system, similar to that presented in <ref> [13] </ref>. In distinction to the work in [13], however, we use a projective canonical frame which permits us to write all constraint equations in dual form. In the positioning case, this canonical F-matrix is parameterized by camera positions only. <p> We will see that the method proposed corresponds to the computation of a fundamental matrix and tensors in a canonical image coordinate system, similar to that presented in <ref> [13] </ref>. In distinction to the work in [13], however, we use a projective canonical frame which permits us to write all constraint equations in dual form. In the positioning case, this canonical F-matrix is parameterized by camera positions only. <p> The choice of the basis for the projective image coordinates ensures that the fundamental matrix is determined completely by the camera positions and no other imaging parameters. The structure of this F -matrix is similar to the one derived in <ref> [13] </ref> where a similar but not identical canonical framework is used. It can be readily shown that the determinant (f 2 f 1 )(f 5 f 3 )(f 6 f 4 )+ (16) The rank of the F-matrix is therefore 2. 4.2. <p> This is the essence of the analysis described in, e.g., [9], [12], <ref> [13] </ref>, [19], [26], [34]. On the other hand, substituting (54) into (36) would significantly change the essence of the following derivations. Now the G-matrix and the multi-linear shape tensors depend on the shape and the camera they now depend on the orientation of the image via matrix Q.
Reference: 14. <author> A. </author> <title> Heyden Reconstruction from multiple images using kinetic depths. </title> <type> Tech. Report. </type> <institution> Dep. of Mathematics, Lund University, </institution> <month> April </month> <year> 1995 </year>
Reference-contexts: This algorithm could equally well be applied to the projective reconstruction problem with the same number of points and views, as discussed in Section 6. A systematic description of direct reconstruction algorithms has been presented in <ref> [14] </ref>. Table 1 gives a summary of the dual algorithms, and how they can be obtained from the above analysis: The fact that the problems of projective reconstruction and camera positioning have this dual structure poses challenging problems for compu-tationally efficient algorithms.
Reference: 15. <author> M. Irani and P. Anandan. </author> <title> Parallax geometry of pairs of points for 3D scence analysis Proc. </title> <booktitle> 4:th ECCV Vol. </booktitle> <volume> I, </volume> <pages> 17-30. </pages> <year> (1996) </year>
Reference-contexts: Recently a dual epipolar structure, where the dual epipole is defined by the shape geometry instead of camera geometry, was described in <ref> [15] </ref>. Dual Computation of Projective Shape and Camera Positions 3 2.
Reference: 16. <author> J. J. Koenderink and A. J. van Doorn, </author> <title> Affine Structure from Motion, </title> <journal> J. Optic. Soc. Am. A, </journal> <volume> No. 2, </volume> <year> 1991, </year> <pages> pp. 377-385. </pages>
Reference-contexts: For parallel projection, position and structure can be determined up to an arbitrary affine transformation <ref> [16] </ref>, and for perspective projection cameras, position and structure can be determined up to an arbitrary linear transformation in P 3 [8],[11]. In the perspective projection case we therefore use the terms projective reconstruction and projective shape for the computation of 3-D shape when we are dealing with un-calibrated cameras.
Reference: 17. <institution> Long Quan Invariants of 6 points from 3 uncalibrated images, </institution> <note> Proc. 3:rd ECCV, pp. Vol. II 459 - 470 (1994) </note>
Reference-contexts: The case of multiple camera constraints has also been investigated for the case of reconstruction from lines for calibrated cameras [4], [32] and for un-calibrated cameras [12]. Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry <ref> [17] </ref>, [29], [31]. Especially in the case of constrained scenes, direct methods are powerful [2] , [23], [30], [38] in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points [6], [21], [38]. <p> These equations are exactly those treated and solved in <ref> [17] </ref> for the structure computation case. 5.4. Computing projective coordinates from the F- and G- matrices The parameters ; ; ; ! give ratios of homogeneous projective coordinates for either camera positions or space points.
Reference: 18. <author> H.C. Longuet-Higgins and K. </author> <title> Prazdny,"The interpretation of a moving retinal image", </title> <journal> Proc. Roy. Soc. Lond. </journal> <volume> B-208, </volume> <pages> pp. 385-397, </pages> <year> 1980 </year>
Reference-contexts: Similarly, the algorithms for direct computation of projective structure can be used to obtain relative camera positions. This is illustrated in Fig. 3. Fig. 4 illustrates this for various published algorithms. As was discussed in Section 5, the linear 8-points algorithm for computing the F -matrix <ref> [18] </ref> can be used for direct computation of projective structure for 6 points in 4 images. Likewise, as pointed out in [25], there is a linear algorithm for camera geometry for 7 points in 3 views.
Reference: 19. <author> Luong, Q.-T. and Vieville, T. </author> <title> Canonic representations for the geometries of multiple projective views", </title> <booktitle> Proc. 3:rd ECCV (1994) </booktitle>
Reference-contexts: Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], [13], <ref> [19] </ref>, [26], [34]. The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. The case of multiple camera constraints has also been investigated for the case of reconstruction from lines for calibrated cameras [4], [32] and for un-calibrated cameras [12]. <p> This is the essence of the analysis described in, e.g., [9], [12], [13], <ref> [19] </ref>, [26], [34]. On the other hand, substituting (54) into (36) would significantly change the essence of the following derivations. Now the G-matrix and the multi-linear shape tensors depend on the shape and the camera they now depend on the orientation of the image via matrix Q.
Reference: 20. <author> S.J. Maybank, </author> <title> The projective geometry of ambiguous surfaces, </title> <journal> Proc. Royal Soc. A 322: </journal> <volume> 1- 47, </volume> <year> (1990) </year>
Reference-contexts: Constraints on scene structure and constraints on camera geometry can be used to reduce the number of unknowns to be solved for and should be exploited in similar ways. The existence of ambiguous configurations of points <ref> [20] </ref> should have a dual counterpart in ambiguous camera configurations. Dual Computation of Projective Shape and Camera Positions 15 Table 1.
Reference: 21. <author> R. Mohr, </author> <title> Projective Geometry and Computer Vision, </title> <booktitle> Handbook of Pattern Recognition and Computer Vision, </booktitle> <year> (1992) </year>
Reference-contexts: Especially in the case of constrained scenes, direct methods are powerful [2] , [23], [30], [38] in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points [6], <ref> [21] </ref>, [38]. The direct methods for reconstruction exploit constraints existing between projective coordinates of coordinates of space points and their image coordinates, not involving camera geometry. Direct methods in unconstrained scenes, but assuming weak perspective projection, were described in [33], [35], [36].
Reference: 22. <author> R.Mohr, L. Quan, F. </author> <title> Veillon , Relative 3D Reconstruction using Multiple Uncalibrated Images International Journal of Robotics Research No. </title> <booktitle> 6, Decem-ber 1995, </booktitle> <pages> pp. 619-632 </pages>
Reference-contexts: This matrix can be used to constrain image coordinates of points in two images of the same scene. Projective reconstruction is then achieved using the epipolar information in various alternative ways: projective shape from projection matrices [7], <ref> [22] </ref>, cross-ratios [10], or more direct methods expressing 3-D invariants directly in terms of the fundamental matrix [1], [5]. Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], [13], [19], [26], [34].
Reference: 23. <author> C.A. Rothwell, D.A. Forsyth, A.P. Zisserman, J.L. </author> <title> Mundy Extracting Projective Structure from Single Perspective Views of 3-D Point Sets Proc. </title> <booktitle> of 4:th ICCV, </booktitle> <pages> pp. 573-582. </pages> <year> (1993) </year>
Reference-contexts: Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry [17], [29], [31]. Especially in the case of constrained scenes, direct methods are powerful [2] , <ref> [23] </ref>, [30], [38] in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points [6], [21], [38].
Reference: 24. <author> A. Shashua, </author> <title> Projective depth: A Geometric Invariant for 3-D Reconstruction From Two Perspective/Orthographic Views and for Visual recognition, </title> <booktitle> Proc 4:th ICCV, </booktitle> <pages> pp. 583-590. </pages> <year> (1993) </year>
Reference: 25. <author> A. Shashua, </author> <title> Trilinearity in visual recognition by alignment, </title> <booktitle> Proc. 3:rd ECCV A, </booktitle> <pages> 479-484. </pages> <year> (1994) </year>
Reference-contexts: Projective reconstruction is then achieved using the epipolar information in various alternative ways: projective shape from projection matrices [7], [22], cross-ratios [10], or more direct methods expressing 3-D invariants directly in terms of the fundamental matrix [1], [5]. Recently, initiated by the work in <ref> [25] </ref>, [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], [13], [19], [26], [34]. The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. <p> These constraints are bi tri-or quadri-linear in the projective image coordinates. They are related to the multiple image epipolar constraints previously derived and discussed in [9],[13], <ref> [25] </ref>, [34]. <p> Space-point and camera-point relations: The tri-linear constraints for external calibration described in [12], <ref> [25] </ref> are obtained from (45), and the quadrilinear constraints described in [9], [26], [34] are obtained from the corresponding quadrilinear system. This is done by making the substitutions defined in (40)-(41). We can use these equations to find camera positions. <p> Fig. 4 illustrates this for various published algorithms. As was discussed in Section 5, the linear 8-points algorithm for computing the F -matrix [18] can be used for direct computation of projective structure for 6 points in 4 images. Likewise, as pointed out in <ref> [25] </ref>, there is a linear algorithm for camera geometry for 7 points in 3 views. This algorithm could equally well be applied to the projective reconstruction problem with the same number of points and views, as discussed in Section 6.
Reference: 26. <author> A. Shashua and M. </author> <title> Werman Trilinearity of Three Perspective Views and its Associated Tensor, </title> <booktitle> Proc 5:th ICCV, </booktitle> <volume> 920 - 925, </volume> <year> (1995) </year>
Reference-contexts: Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], [13], [19], <ref> [26] </ref>, [34]. The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. The case of multiple camera constraints has also been investigated for the case of reconstruction from lines for calibrated cameras [4], [32] and for un-calibrated cameras [12]. <p> Space-point and camera-point relations: The tri-linear constraints for external calibration described in [12], [25] are obtained from (45), and the quadrilinear constraints described in [9], <ref> [26] </ref>, [34] are obtained from the corresponding quadrilinear system. This is done by making the substitutions defined in (40)-(41). We can use these equations to find camera positions. <p> This is the essence of the analysis described in, e.g., [9], [12], [13], [19], <ref> [26] </ref>, [34]. On the other hand, substituting (54) into (36) would significantly change the essence of the following derivations. Now the G-matrix and the multi-linear shape tensors depend on the shape and the camera they now depend on the orientation of the image via matrix Q.
Reference: 27. <author> A. Shashua. </author> <title> Algebraic functions for recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(8) </volume> <pages> 779-789, </pages> <year> 1995. </year>
Reference-contexts: Projective reconstruction is then achieved using the epipolar information in various alternative ways: projective shape from projection matrices [7], [22], cross-ratios [10], or more direct methods expressing 3-D invariants directly in terms of the fundamental matrix [1], [5]. Recently, initiated by the work in [25], <ref> [27] </ref>, the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], [13], [19], [26], [34]. The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images.
Reference: 28. <author> A. Shashua and S. </author> <title> Avidan The rank4 constraint in multiple view geometry, </title> <booktitle> Proc. 4:th ECCV, </booktitle> <pages> pp. 196 - 206, </pages> <month> April, </month> <year> 1996, </year>
Reference-contexts: The basic algebraic duality, which formally exists for any representation of the basis points, was also described in [37]; in [37] we described the new space-image relations that are obtained using the duality observation, and obtained a low rank factorization of the 7 points shape tensor (cf. <ref> [28] </ref>). Recently a dual epipolar structure, where the dual epipole is defined by the shape geometry instead of camera geometry, was described in [15]. Dual Computation of Projective Shape and Camera Positions 3 2.
Reference: 29. <author> G. Sparr, </author> <booktitle> Proc. 1:st ESPRIT-DARPA workshop on Invariants in Computer Vision, </booktitle> <address> Reykjavik, </address> <year> (1991) </year>
Reference-contexts: The case of multiple camera constraints has also been investigated for the case of reconstruction from lines for calibrated cameras [4], [32] and for un-calibrated cameras [12]. Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry [17], <ref> [29] </ref>, [31]. Especially in the case of constrained scenes, direct methods are powerful [2] , [23], [30], [38] in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points [6], [21], [38].
Reference: 30. <author> G. Sparr, </author> <title> Depth Computations from Polyhedral Images, </title> <journal> Image and Vision Computing, </journal> <volume> vol. 10, no. 10, </volume> <pages> pp. 683-688. </pages> <year> (1992) </year>
Reference-contexts: Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry [17], [29], [31]. Especially in the case of constrained scenes, direct methods are powerful [2] , [23], <ref> [30] </ref>, [38] in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points [6], [21], [38].
Reference: 31. <author> G. Sparr, </author> <title> A common framework for kinetic depth, reconstruction and motion for deformable objects, </title> <booktitle> Proc. ECCV B, </booktitle> <pages> 471-482. </pages> <year> (1994) </year>
Reference-contexts: The case of multiple camera constraints has also been investigated for the case of reconstruction from lines for calibrated cameras [4], [32] and for un-calibrated cameras [12]. Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry [17], [29], <ref> [31] </ref>. Especially in the case of constrained scenes, direct methods are powerful [2] , [23], [30], [38] in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points [6], [21], [38].
Reference: 32. <author> M.E. Spetsakis and J.(Y.) Aloimonos, </author> <title> Structure from motion using line correspondences, </title> <journal> International Journal of Computer Vision 4, </journal> <year> 1990, </year> <pages> 171-183. </pages>
Reference-contexts: The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. The case of multiple camera constraints has also been investigated for the case of reconstruction from lines for calibrated cameras [4], <ref> [32] </ref> and for un-calibrated cameras [12]. Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry [17], [29], [31].
Reference: 33. <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: The direct methods for reconstruction exploit constraints existing between projective coordinates of coordinates of space points and their image coordinates, not involving camera geometry. Direct methods in unconstrained scenes, but assuming weak perspective projection, were described in <ref> [33] </ref>, [35], [36]. The existence of basically two alternative methods for achieving projective reconstruction naturally poses the question whether there is a relation between them. In this paper we will demonstrate that this is indeed the case.
Reference: 34. <author> B. </author> <booktitle> Triggs Matching Constraints and the Joint Image Proc 5:th ICCV, </booktitle> <volume> 338 - 343, </volume> <year> (1995) </year>
Reference-contexts: Recently, initiated by the work in [25], [27], the generalization of the epipolar constraints to the case of multiple un-calibrated cameras has received widespread attention [9], [12], [13], [19], [26], <ref> [34] </ref>. The bilinear image constraints in the case of two images are then generalized to multi linear constraints between multiple images. The case of multiple camera constraints has also been investigated for the case of reconstruction from lines for calibrated cameras [4], [32] and for un-calibrated cameras [12]. <p> These constraints are bi tri-or quadri-linear in the projective image coordinates. They are related to the multiple image epipolar constraints previously derived and discussed in [9],[13], [25], <ref> [34] </ref>. <p> Space-point and camera-point relations: The tri-linear constraints for external calibration described in [12], [25] are obtained from (45), and the quadrilinear constraints described in [9], [26], <ref> [34] </ref> are obtained from the corresponding quadrilinear system. This is done by making the substitutions defined in (40)-(41). We can use these equations to find camera positions. <p> This is the essence of the analysis described in, e.g., [9], [12], [13], [19], [26], <ref> [34] </ref>. On the other hand, substituting (54) into (36) would significantly change the essence of the following derivations. Now the G-matrix and the multi-linear shape tensors depend on the shape and the camera they now depend on the orientation of the image via matrix Q.
Reference: 35. <author> D. Weinshall. </author> <title> Model-based invariants for 3D vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 10(1) </volume> <pages> 27-42, </pages> <year> 1993. </year>
Reference-contexts: The direct methods for reconstruction exploit constraints existing between projective coordinates of coordinates of space points and their image coordinates, not involving camera geometry. Direct methods in unconstrained scenes, but assuming weak perspective projection, were described in [33], <ref> [35] </ref>, [36]. The existence of basically two alternative methods for achieving projective reconstruction naturally poses the question whether there is a relation between them. In this paper we will demonstrate that this is indeed the case.
Reference: 36. <author> D. Weinshall and C. Tomasi. </author> <title> Linear and incremental acquisition of invariant shape models from image sequences. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(5) </volume> <pages> 512-517, </pages> <year> 1995. </year>
Reference-contexts: The direct methods for reconstruction exploit constraints existing between projective coordinates of coordinates of space points and their image coordinates, not involving camera geometry. Direct methods in unconstrained scenes, but assuming weak perspective projection, were described in [33], [35], <ref> [36] </ref>. The existence of basically two alternative methods for achieving projective reconstruction naturally poses the question whether there is a relation between them. In this paper we will demonstrate that this is indeed the case.
Reference: 37. <author> D. Weinshall, M. Werman, and A. Shashua. </author> <title> Shape tensors for efficient and learnable indexing. </title> <booktitle> In Proceedings of the IEEE Workshop on Representations of Visual Scenes, </booktitle> <address> Cambridge, Mass, </address> <year> 1995. </year>
Reference-contexts: The basic algebraic duality, which formally exists for any representation of the basis points, was also described in <ref> [37] </ref>; in [37] we described the new space-image relations that are obtained using the duality observation, and obtained a low rank factorization of the 7 points shape tensor (cf. [28]). <p> The basic algebraic duality, which formally exists for any representation of the basis points, was also described in <ref> [37] </ref>; in [37] we described the new space-image relations that are obtained using the duality observation, and obtained a low rank factorization of the 7 points shape tensor (cf. [28]).
Reference: 38. <author> A. Zisserman, </author> <title> A Case Against Epipolar Geometry, </title> <booktitle> "Applications of Invariance in Computer Vision" Springer LNCS 825 pp. </booktitle> <month> 69 - 88 </month> <year> (1994) </year>
Reference-contexts: Interestingly, there are alternative direct ways for projective reconstruction, not relying on the computation of epipolar geometry [17], [29], [31]. Especially in the case of constrained scenes, direct methods are powerful [2] , [23], [30], <ref> [38] </ref> in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points [6], [21], [38]. <p> Especially in the case of constrained scenes, direct methods are powerful [2] , [23], [30], <ref> [38] </ref> in the sense that fewer points are needed for reconstruction. Constraining the scene also makes possible the computation of epipolar geometry with fewer points [6], [21], [38]. The direct methods for reconstruction exploit constraints existing between projective coordinates of coordinates of space points and their image coordinates, not involving camera geometry. Direct methods in unconstrained scenes, but assuming weak perspective projection, were described in [33], [35], [36].
References-found: 38

