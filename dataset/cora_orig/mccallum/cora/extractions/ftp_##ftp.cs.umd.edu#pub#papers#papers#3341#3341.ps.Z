URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3341/3341.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: ON THE GEOMETRY OF VISUAL CORRESPONDENCE  
Author: Cornelia Fermuller Yiannis Aloimonos and 
Address: College Park, MD 20742-3275  S-100 44 Stockholm, Sweden  
Affiliation: Computer Vision Laboratory Center for Automation Research University of Maryland  Computational Vision and Active Perception Laboratory Royal Institute of Technology  
Date: July 1994  
Pubnum: CAR-TR-732  DACA76-92-C-0009 IRI-90-57934  
Abstract: Image displacement fields|optical flow fields, stereo disparity fields, normal flow fields|due to rigid motion possess a global geometric structure which is independent of the scene in view. Motion vectors of certain lengths and directions are constrained to lie on the imaging surface at particular loci whose location and form depends solely on the 3D motion parameters. If optical flow fields or stereo disparity fields are considered, then equal vectors are shown to lie on conic sections. Similarly, for normal motion fields, equal vectors lie within regions whose boundaries also constitute conics. By studying various properties of these curves and regions and their relationships, a characterization of the structure of rigid motion fields is given. The goal of this paper is to introduce a concept underlying the global structure of image displacement fields. This concept gives rise to various constraints that could form the basis of algorithms for the recovery of visual information from multiple views. The support of the Advanced Research Projects Agency (ARPA Order No. 8459) and the U.S. Army Topographic Engineering Center under Contract DACA76-92-C-0009, the National Science Foundation under Grant IRI-90-57934, and the Office of Naval Research under Contract N00014-93-1-0257, is gratefully acknowledged, as is the help of Sandy German in preparing this paper. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.Y. Aloimonos. </author> <title> Purposive and qualitative active vision. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 816-828, </pages> <year> 1990. </year> <month> 35 </month>
Reference-contexts: is in the direction of the translational motion component (see Figure 15). the motion vectors are in the direction of their translational motion components. 4 Normal motion constraints The vector field which represents the components of the motion field perpendicular to edges is referred to as the normal motion field <ref> [1, 34] </ref>. It is uniquely defined by local image measurements and can be derived without confronting the aperture problem. Although a normal motion field seems to contain less information than the exact motion field, the motion involved is still manifested in it.
Reference: [2] <author> Y. Aloimonos, </author> <title> editor. Active Perception. </title> <booktitle> Advances in Computer Vision. </booktitle> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1993. </year>
Reference: [3] <author> P. Anandan and R. Weiss. </author> <title> Introducing a smoothness constraint in a matching approach for the computation of optical flow fields. </title> <booktitle> In Proc. 3rd Workshop on Computer Vision: Representation and Control, </booktitle> <pages> pages 186-194, </pages> <year> 1985. </year>
Reference-contexts: First, a description that relates local measurements in multiple views is developed; local descriptors include stereo disparity measurements, motion disparity measurements, motion fields, partial disparity fields such as those along the x- or y-axes, or normal motion fields (the projections of motion fields along the gradient direction) <ref> [3, 16, 18, 19, 28] </ref>. Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry [11, 17, 20, 21, 23, 26, 29, 31].
Reference: [4] <author> R. </author> <title> Bajcsy. Active perception. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 76 </volume> <pages> 996-1005, </pages> <year> 1988. </year>
Reference: [5] <author> G. Baratoff. </author> <title> Disparity Space under Binocular Fixation. </title> <type> Technical Report, </type> <institution> Center for Automation Research, University of Maryland, College Park, MD, </institution> <note> to appear. </note>
Reference: [6] <author> F. Bergholm. </author> <title> Motion from flow along contours: A note on robustness and ambiguous cases. </title> <journal> International Journal of Computer Vision, </journal> <volume> 3 </volume> <pages> 395-415, </pages> <year> 1988. </year>
Reference: [7] <author> K. Daniilidis. </author> <title> On the error sensitivity in the recovery of object descriptions. </title> <type> PhD thesis, </type> <institution> Department of Informatics, University of Karlsruhe, Germany, </institution> <year> 1992, </year> <note> in German. </note>
Reference: [8] <author> K. Daniilidis and H. Nagel. </author> <title> Analytical results on error sensitivity of motion estimation from two views. </title> <journal> Image and Vision Computing, </journal> <volume> 8 </volume> <pages> 297-303, </pages> <year> 1990. </year>
Reference: [9] <author> O. Faugeras. </author> <title> Three Dimensional Computer Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference: [10] <author> O. Faugeras, F. Lustman, and G. Toscani. </author> <title> Motion and structure from motion from point and line matches. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 25-34, </pages> <year> 1987. </year>
Reference: [11] <author> O. Faugeras and S. Maybank. </author> <title> Motion from point matches: Multiplicity of solutions. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 225-246, </pages> <year> 1990. </year>
Reference-contexts: Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry <ref> [11, 17, 20, 21, 23, 26, 29, 31] </ref>. This paper deals with the case where the transformation between the views is described by a rigid motion.
Reference: [12] <editor> C. Fermuller. Navigational preliminaries. In Y. Aloimonos, editor, </editor> <title> Active Perception, </title> <booktitle> Advances in Computer Vision. </booktitle> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1993. </year>
Reference-contexts: Instead of considering vectors of the same value, we examine various classes of vector-valued functions. In particular, we investigate the coaxis- and copoint vectors, which we described in an earlier paper <ref> [12] </ref>. 24 (a) (b) (e) (f) field are the boundaries of the two normal motion areas corresponding to the vectors of length zero in direction n 1 and n 2 . (b) The black and gray squares denote locations where in the normal motion field of (a) vectors of length zero <p> The normal motion regions can be obtained by localizing their boundaries. In particular, the normal motion vectors of length zero are bounded by curves which can be described by only three parameters. Thus a simple search technique in a three-dimensional space, such as in <ref> [12, 13] </ref>, could be employed to find the 3D motion parameters. The iso-normal motion areas, however, also allow to obtain bounds on the solutions for the motion parameters in very simple ways.
Reference: [13] <author> C. Fermuller and Y. Aloimonos. </author> <title> The role of fixation in visual motion analysis. </title> <journal> International Journal of Computer Vision: </journal> <note> Special issue on Active Vision, </note> <editor> M. Swain (Ed.), </editor> <volume> 11 </volume> <pages> 165-186, </pages> <year> 1993. </year>
Reference-contexts: The normal motion regions can be obtained by localizing their boundaries. In particular, the normal motion vectors of length zero are bounded by curves which can be described by only three parameters. Thus a simple search technique in a three-dimensional space, such as in <ref> [12, 13] </ref>, could be employed to find the 3D motion parameters. The iso-normal motion areas, however, also allow to obtain bounds on the solutions for the motion parameters in very simple ways.
Reference: [14] <author> J. G-arding, J. Porrill, J. Mayhew, and J.P. </author> <title> Frisby. Binocular Stereopsis, Vertical Disparity and Relief Transformations. </title> <type> Technical Report TRITA-NA-P9334, </type> <institution> CVAP, Royal Institute of Technology, Stockholm, Sweden, </institution> <year> 1993. </year> <month> 36 </month>
Reference-contexts: Indeed, the problems of stereo, 3D motion estimation, calibration, obstacle detection, pose estimation for recognition, etc. can be regarded as special instances of the general recovery problem <ref> [6-10, 14, 20, 24, 25, 30, 32, 33] </ref>. Approaches to various aspects of this problem that have appeared in the literature seek a solution in two computational steps.
Reference: [15] <author> H. v. Helmholtz. Handbuch der Physiologischen Optik. Leopold Voss, </author> <month> 1896. </month>
Reference-contexts: The endpoints of these segments are the FOE and the points R ku . 3.4 Fixating stereo The image displacement field due to binocular disparity measurements obtained by a stereo system fixating at a point deserves some separate discussion. This configuration has often been studied in the psychophysical literature <ref> [15] </ref>. In particular, a concept has been investigated that can be regarded as a special case of the iso-motion contours: The locus of points in space that yield zero disparity, the so-called horopter .
Reference: [16] <author> E. Hildreth. </author> <title> Computations underlying the measurement of visual motion. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 309-354, </pages> <year> 1984. </year>
Reference-contexts: First, a description that relates local measurements in multiple views is developed; local descriptors include stereo disparity measurements, motion disparity measurements, motion fields, partial disparity fields such as those along the x- or y-axes, or normal motion fields (the projections of motion fields along the gradient direction) <ref> [3, 16, 18, 19, 28] </ref>. Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry [11, 17, 20, 21, 23, 26, 29, 31].
Reference: [17] <author> B. Horn. </author> <title> Relative orientation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 59-78, </pages> <year> 1990. </year>
Reference-contexts: Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry <ref> [11, 17, 20, 21, 23, 26, 29, 31] </ref>. This paper deals with the case where the transformation between the views is described by a rigid motion.
Reference: [18] <author> B. Horn and B. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: First, a description that relates local measurements in multiple views is developed; local descriptors include stereo disparity measurements, motion disparity measurements, motion fields, partial disparity fields such as those along the x- or y-axes, or normal motion fields (the projections of motion fields along the gradient direction) <ref> [3, 16, 18, 19, 28] </ref>. Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry [11, 17, 20, 21, 23, 26, 29, 31].
Reference: [19] <author> J. Koenderink. </author> <title> Optic flow. </title> <journal> Vision Research, </journal> <volume> 26 </volume> <pages> 161-180, </pages> <year> 1986. </year>
Reference-contexts: First, a description that relates local measurements in multiple views is developed; local descriptors include stereo disparity measurements, motion disparity measurements, motion fields, partial disparity fields such as those along the x- or y-axes, or normal motion fields (the projections of motion fields along the gradient direction) <ref> [3, 16, 18, 19, 28] </ref>. Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry [11, 17, 20, 21, 23, 26, 29, 31].
Reference: [20] <author> J. Koenderink and A. van Doorn. </author> <title> Affine structure from motion. </title> <journal> Journal of the Optical Society of America, </journal> <volume> 8 </volume> <pages> 377-385, </pages> <year> 1991. </year>
Reference-contexts: Indeed, the problems of stereo, 3D motion estimation, calibration, obstacle detection, pose estimation for recognition, etc. can be regarded as special instances of the general recovery problem <ref> [6-10, 14, 20, 24, 25, 30, 32, 33] </ref>. Approaches to various aspects of this problem that have appeared in the literature seek a solution in two computational steps. <p> Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry <ref> [11, 17, 20, 21, 23, 26, 29, 31] </ref>. This paper deals with the case where the transformation between the views is described by a rigid motion.
Reference: [21] <author> Y. Liu and T. Huang. </author> <title> Estimation of rigid body motion using straight line correspondences. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 43 </volume> <pages> 37-52, </pages> <year> 1988. </year>
Reference-contexts: Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry <ref> [11, 17, 20, 21, 23, 26, 29, 31] </ref>. This paper deals with the case where the transformation between the views is described by a rigid motion.
Reference: [22] <author> H.C. Longuet-Higgins and K. Prazdny. </author> <title> The interpretation of a moving retinal image. </title> <journal> Proceedings of the Royal Society, London B, </journal> <volume> 208 </volume> <pages> 385-397, </pages> <year> 1980. </year>
Reference-contexts: If we introduce new coordinates for the direction of translation (x 0 ; y 0 ) = ( Uf W ; V f W ), we obtain the well-known equations <ref> [22] </ref> u = u trans + u rot = = (x 0 + x) Z xy fi ( f v = v trans + v rot = = (y 0 + y) Z y 2 + f ) fi f The projection of a 3D vector u = (u; v; w)
Reference: [23] <author> S. Maybank. </author> <title> Theory of Reconstruction from Image Motion. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1993. </year>
Reference-contexts: Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry <ref> [11, 17, 20, 21, 23, 26, 29, 31] </ref>. This paper deals with the case where the transformation between the views is described by a rigid motion.
Reference: [24] <author> N. Navab, O. Faugeras, and T. Vieville. </author> <title> The critical sets of lines for camera displacement estimation: A mixed Euclidian-projective and constructive approach. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 713-723, </pages> <year> 1993. </year>
Reference-contexts: Indeed, the problems of stereo, 3D motion estimation, calibration, obstacle detection, pose estimation for recognition, etc. can be regarded as special instances of the general recovery problem <ref> [6-10, 14, 20, 24, 25, 30, 32, 33] </ref>. Approaches to various aspects of this problem that have appeared in the literature seek a solution in two computational steps.
Reference: [25] <author> R. Nelson and J. Aloimonos. </author> <title> Finding motion parameters from spherical flow fields (or the advantage of having eyes in the back of your head). </title> <journal> Biological Cybernetics, </journal> <volume> 58 </volume> <pages> 261-273, </pages> <year> 1988. </year>
Reference-contexts: Indeed, the problems of stereo, 3D motion estimation, calibration, obstacle detection, pose estimation for recognition, etc. can be regarded as special instances of the general recovery problem <ref> [6-10, 14, 20, 24, 25, 30, 32, 33] </ref>. Approaches to various aspects of this problem that have appeared in the literature seek a solution in two computational steps.
Reference: [26] <author> K. Prazdny. </author> <title> Egomotion and relative depth map from optical flow. </title> <journal> Biological Cybernetics, </journal> <volume> 36 </volume> <pages> 87-102, </pages> <year> 1980. </year>
Reference-contexts: Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry <ref> [11, 17, 20, 21, 23, 26, 29, 31] </ref>. This paper deals with the case where the transformation between the views is described by a rigid motion.
Reference: [27] <author> S. Selby, </author> <title> editor. Standard Mathematical Tables. </title> <publisher> Chemical Rubber Co., </publisher> <address> Cleveland, Ohio, </address> <year> 1972. </year>
Reference-contexts: The axes of the conics are all parallel to each other with slopes m and 1 m , where m is the positive of the two values <ref> [27] </ref> (fiy 0 ffx 0 ) (ff 2 + fi 2 )(x 2 0 ) : The nature of the iso-motion contours depends on the values of the translation and rotation. <p> Their axes are parallel to the medians, and the center of their axes is <ref> [27] </ref> (x c ; y c ) = ( fix 0 v 1 f ): The zero motion contour, which is the projection of the horopter on the image plane, is defined as yfi ( f 17 which is the equation of two lines, one being the x-axis, the other a
Reference: [28] <author> D. Shulman and J.-Y. Herve. </author> <title> Regularization of discontinuous flow fields. </title> <booktitle> In Proc. IEEE Workshop on Visual Motion, </booktitle> <pages> pages 81-86, </pages> <year> 1989. </year>
Reference-contexts: First, a description that relates local measurements in multiple views is developed; local descriptors include stereo disparity measurements, motion disparity measurements, motion fields, partial disparity fields such as those along the x- or y-axes, or normal motion fields (the projections of motion fields along the gradient direction) <ref> [3, 16, 18, 19, 28] </ref>. Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry [11, 17, 20, 21, 23, 26, 29, 31].
Reference: [29] <author> M. Spetsakis and J. Aloimonos. </author> <title> Optimal computing of structure from motion using point correspondence. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 449-453, </pages> <year> 1988. </year> <month> 37 </month>
Reference-contexts: Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry <ref> [11, 17, 20, 21, 23, 26, 29, 31] </ref>. This paper deals with the case where the transformation between the views is described by a rigid motion.
Reference: [30] <author> M. Tistarelli and G. </author> <title> Sandini. Dynamic aspects in active vision. CVGIP: Image Understanding: Special Issue on Purposive, Qualitative, Active Vision, </title> <editor> Y. Aloimonos (Ed.), </editor> <volume> 56 </volume> <pages> 108-129, </pages> <year> 1992. </year>
Reference-contexts: Indeed, the problems of stereo, 3D motion estimation, calibration, obstacle detection, pose estimation for recognition, etc. can be regarded as special instances of the general recovery problem <ref> [6-10, 14, 20, 24, 25, 30, 32, 33] </ref>. Approaches to various aspects of this problem that have appeared in the literature seek a solution in two computational steps.
Reference: [31] <author> R. Tsai and T. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects with curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 13-27, </pages> <year> 1984. </year>
Reference-contexts: Second, knowledge of the model of the geometric transformation between the multiple views provides constraints on the local descriptors; these constraints are used to relate image measurements to the 3D scene and viewing geometry <ref> [11, 17, 20, 21, 23, 26, 29, 31] </ref>. This paper deals with the case where the transformation between the views is described by a rigid motion.
Reference: [32] <author> S. Ullman. </author> <title> The interpretation of structure from motion. </title> <journal> Proceedings of the Royal Society, London, </journal> <volume> B 203 </volume> <pages> 405-426, </pages> <year> 1979. </year>
Reference-contexts: Indeed, the problems of stereo, 3D motion estimation, calibration, obstacle detection, pose estimation for recognition, etc. can be regarded as special instances of the general recovery problem <ref> [6-10, 14, 20, 24, 25, 30, 32, 33] </ref>. Approaches to various aspects of this problem that have appeared in the literature seek a solution in two computational steps.
Reference: [33] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combination of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 992-1006, </pages> <year> 1991. </year>
Reference-contexts: Indeed, the problems of stereo, 3D motion estimation, calibration, obstacle detection, pose estimation for recognition, etc. can be regarded as special instances of the general recovery problem <ref> [6-10, 14, 20, 24, 25, 30, 32, 33] </ref>. Approaches to various aspects of this problem that have appeared in the literature seek a solution in two computational steps.
Reference: [34] <author> A. Verri and T. Poggio. </author> <title> Motion field and optical flow: Qualitative properties. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11 </volume> <pages> 490-498, </pages> <year> 1989. </year> <month> 38 </month>
Reference-contexts: is in the direction of the translational motion component (see Figure 15). the motion vectors are in the direction of their translational motion components. 4 Normal motion constraints The vector field which represents the components of the motion field perpendicular to edges is referred to as the normal motion field <ref> [1, 34] </ref>. It is uniquely defined by local image measurements and can be derived without confronting the aperture problem. Although a normal motion field seems to contain less information than the exact motion field, the motion involved is still manifested in it.
References-found: 34

