URL: http://ranger.uta.edu/~piotr/papers/RMM-Comm.ps
Refering-URL: http://www-cse.uta.edu/~piotr/www/piotr.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: piotr@cse.uta.edu, durfee@engin.umich.edu  
Title: Rational Interactions in Multiagent Environments: Communication  
Author: Piotr J. Gmytrasiewicz and Edmund H. Durfee flfl 
Note: 0 This research was supported, in part, by the Department of Energy under contract DG-FG-86NE37969, by the National Science Foundation under grant IRI-9015423, by the PYI award IRI-9158473, and by ONR grant N00014-95-1-0775.  
Date: August 26, 1997  
Address: TX 76013  Ann Arbor, Michigan 48109  
Affiliation: Computer Science and Engineering University of Texas at Arlington,  flfl Department of Electrical Engineering and Computer Science University of Michigan,  
Abstract: We address the issue of rational communicative behavior among autonomous intelligent agents that have to make decisions as to what, to whom, and how to communicate. We treat communicative actions as aimed at increasing the efficiency of interaction among agents. We postulate that a rational speaker design a speech act so as to maximally increase the benefit obtained as the result of the interaction. We quantify the gain in the quality of interaction as the expected utility, and we present a framework that allows an agent to compute the expected utility of various communicative actions. Our framework uses the Recursive Modeling Method as the representation of the agent's state of knowledge, including the agent's preferences, abilities and beliefs about the world, as well as the beliefs the agent has about the other agents, the beliefs it has about the other agents' beliefs, and so on. A decision-theoretic pragmatics of a communicative act can be then defined as the transformation it induces on the agent's state of knowledge about its decision-making situation. This transformation leads to a change in the quality of the interaction, expressed in terms of the benefit to the agent. We analyze decision-theoretic pragmatics of a number of important communicative acts, and investigate their expected utility using examples. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. L. Austin. </author> <title> How to do Things with Words. </title> <publisher> Clarendon Press, </publisher> <year> 1962. </year>
Reference-contexts: The need for considering the nestedness of the agents' beliefs for communication has been widely recognized in the related literature before <ref> [1, 2, 3, 5, 10, 19, 24, 27, 28] </ref>; clearly, without a model of the other agents' state of beliefs it would be impossible to properly assess the impact of the communicative act. <p> We give examples of these in the following sections. It may be useful to classify communicative acts into types. Some of the types we consider have close correspondents in the speech act theory <ref> [1, 33] </ref>, and in various kinds of performatives considered in KQML [18]. 3 Modeling Communicative Acts Our modeling acts update the hearer's and the speaker's model of the multiagent world. The close correspondents of these type of communicative acts in speech act theory are the inform, assert and tell acts. <p> 4 2 2 0 4 0 5 3 3 5 3 3 The projected structure, on the right in Figure 2, can be easily solved, showing that R 1 would be sure that R 2 would observe from point P2, taking action a 2 2 : p R 2 = <ref> [0; 1; 0] </ref>. The best alternative for R 1 now is to make an observation from P1, but the expected payoff has increased to 5. <p> a 1 3 a 1 2 2 2 2 a 1 1 a 1 3 2 2 1 2 3 2 a 2 2 1 a 1 a 1 a 3 a 1 a 1 a 1 a 1 2 a 3 R 1 R 2 R 2 R 1 <ref> [ 0, 1 ] </ref> [ 0, 1, 0] [ 0.5, 0.5] [ 1/3, 1/3, 1/3 ] 5 3 3 0 4 0 2 4 0 2 4 0 0 0 2 0 4 2 2 p = 0.1 p = 0.9 1 5 1 2 4 0 The expected utilities of <p> 1 2 2 2 2 a 1 1 a 1 3 2 2 1 2 3 2 a 2 2 1 a 1 a 1 a 3 a 1 a 1 a 1 a 1 2 a 3 R 1 R 2 R 2 R 1 [ 0, 1 ] <ref> [ 0, 1, 0] </ref> [ 0.5, 0.5] [ 1/3, 1/3, 1/3 ] 5 3 3 0 4 0 2 4 0 2 4 0 0 0 2 0 4 2 2 p = 0.1 p = 0.9 1 5 1 2 4 0 The expected utilities of R 1 's alternatives <p> R 1 ;R 2 c &lt; 1=6 then the intentional probability R 1 would think R 2 ascribes to R 1 would be p R 1 ;R 2 c = 1=6 then p R 1 ;R 2 c &gt; 1=6, we have p R 1 ;R 2 R 1 = <ref> [1; 0; 0] </ref>. <p> The projected structure of M 6 , on the right in Figure 8, can be easily solved and results in R 1 's anticipating that R 2 will observe from P2: p R 1 ; R 2 = <ref> [0; 1; 0] </ref>, which makes a 1 1 R 1 's best option with the expected utility of 5. <p> Based on this R 1 conjectures that R 2 's behavior is described by the intentional probability distribution of <ref> [0, 0, 1] </ref>, meaning that R 2 will sit still. In turn, now R 1 expects utilities of 1 for a 1 2 , and 0 for a 1 3 .
Reference: [2] <author> Afzal Ballim and Yoric Wilks. </author> <title> Artificial Believers. </title> <publisher> Earlbaum Associates, Inc., </publisher> <year> 1991. </year>
Reference-contexts: The need for considering the nestedness of the agents' beliefs for communication has been widely recognized in the related literature before <ref> [1, 2, 3, 5, 10, 19, 24, 27, 28] </ref>; clearly, without a model of the other agents' state of beliefs it would be impossible to properly assess the impact of the communicative act.
Reference: [3] <author> Herbert H. Clark. </author> <title> Arenas of Language Use. </title> <publisher> The University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1992. </year>
Reference-contexts: The need for considering the nestedness of the agents' beliefs for communication has been widely recognized in the related literature before <ref> [1, 2, 3, 5, 10, 19, 24, 27, 28] </ref>; clearly, without a model of the other agents' state of beliefs it would be impossible to properly assess the impact of the communicative act. <p> evaluating the alternative communicative acts in this way, the agent can select and send the highest utility message|the message that causes the greatest gain in the expected utility of the agent's action. 2 DT pragmatics of a communicative act differs in a subtle way from its pragmatic meaning, usually defined <ref> [3, 10, 28] </ref> as the change of the state of knowledge brought about by the act. Imagine two agents engaged together in assembling a bicycle from parts scattered about a garage.
Reference: [4] <author> P. R. Cohen and H. J. Levesque. </author> <title> Persistence , intention and commitment. </title> <editor> In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: This leads to the nesting of models represented explicitly by our framework. Uncertainty-based decision-theoretic frameworks for HCI have been used by Jameson and associates in [14, 15]. In an earlier work, Cohen and Levesque provide a logical formalization of the concepts of intention and commitment <ref> [4] </ref>, and apply it to issues of communication [5]. In this formalization, the concept of rationality takes a prominent place but, as the authors remark ([4], page 40), it is not the formalization that the agents should actually use as a guide to their action.
Reference: [5] <author> P. R. Cohen and H. J. Levesque. </author> <title> Rational interaction as the basis for communication. </title> <editor> In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The need for considering the nestedness of the agents' beliefs for communication has been widely recognized in the related literature before <ref> [1, 2, 3, 5, 10, 19, 24, 27, 28] </ref>; clearly, without a model of the other agents' state of beliefs it would be impossible to properly assess the impact of the communicative act. <p> Uncertainty-based decision-theoretic frameworks for HCI have been used by Jameson and associates in [14, 15]. In an earlier work, Cohen and Levesque provide a logical formalization of the concepts of intention and commitment [4], and apply it to issues of communication <ref> [5] </ref>. In this formalization, the concept of rationality takes a prominent place but, as the authors remark ([4], page 40), it is not the formalization that the agents should actually use as a guide to their action. Rather, it is an attempt to formally describe a rational agent's behavior.
Reference: [6] <author> V. P. Crawford and J. Sobel. </author> <title> Strategic information transmission. </title> <journal> Econometrica, </journal> <volume> 50(6) </volume> <pages> 1431-1452, </pages> <year> 1982. </year>
Reference-contexts: While work on communication in negotiation is reported in [17, 34, 35]. Communication among rational agents has also been of interest for the researchers in game theory, usually viewed a part of pre-game "cheap talk" <ref> [6] </ref>, or as threat games [20] (see also discussion in [8] and references therein). These approaches, however, concentrate on the influence of pre-play communication on equilibria of the resulting game.
Reference: [7] <author> Gerhard Fischer. </author> <title> The imortance of models in making complex systems comprehensible. </title> <editor> In M. J. Tauber and D. Ackerman, editors, </editor> <title> Mental Models and Human-Computer Interaction. </title> <publisher> North Holland, </publisher> <year> 1991. </year>
Reference-contexts: Our ongoing research is delving into meta-level issues, so as to eventually capture such reasoning about imperatives. 17 10 Related Work The issue of modeling agents for the purpose of communication has received considerable attention in the field of human-computer interaction [30]. Fischer <ref> [7] </ref>, for example, stresses the importance of a system's model of the user and the user's model of the system during man-machine communication. This leads to the nesting of models represented explicitly by our framework. Uncertainty-based decision-theoretic frameworks for HCI have been used by Jameson and associates in [14, 15].
Reference: [8] <author> Drew Fudenberg and Jean Tirole. </author> <title> Game Theory. </title> <publisher> MIT Press, </publisher> <year> 1991. </year> <month> 20 </month>
Reference-contexts: While work on communication in negotiation is reported in [17, 34, 35]. Communication among rational agents has also been of interest for the researchers in game theory, usually viewed a part of pre-game "cheap talk" [6], or as threat games [20] (see also discussion in <ref> [8] </ref> and references therein). These approaches, however, concentrate on the influence of pre-play communication on equilibria of the resulting game.
Reference: [9] <author> Piotr J. Gmytrasiewicz and Edmund H. Durfee. </author> <title> Toward a theory of honesty and trust among communicating autonomous agents. Group Decision and Negotiation, </title> <booktitle> 2 </booktitle> <pages> 237-258, </pages> <year> 1993. </year>
Reference-contexts: Definition 5: Intentional communicative acts contain information about the intentional probabilities p (R i ;ff);R j defined in the companion paper. For the purpose of the present discussion we assume that the truthfulness of these messages is guaranteed (see <ref> [9] </ref> for cases involving lying). Thus, a hearer can use this message to predict exactly what the speaker will do.
Reference: [10] <author> H. P. Grice. </author> <title> Meaning. </title> <journal> Philosophical Review, </journal> <volume> (LXVI):377-388, </volume> <year> 1957. </year>
Reference-contexts: The need for considering the nestedness of the agents' beliefs for communication has been widely recognized in the related literature before <ref> [1, 2, 3, 5, 10, 19, 24, 27, 28] </ref>; clearly, without a model of the other agents' state of beliefs it would be impossible to properly assess the impact of the communicative act. <p> evaluating the alternative communicative acts in this way, the agent can select and send the highest utility message|the message that causes the greatest gain in the expected utility of the agent's action. 2 DT pragmatics of a communicative act differs in a subtle way from its pragmatic meaning, usually defined <ref> [3, 10, 28] </ref> as the change of the state of knowledge brought about by the act. Imagine two agents engaged together in assembling a bicycle from parts scattered about a garage.
Reference: [11] <author> B. J. Grosz and C. Sidner. </author> <title> Plans for discourse. </title> <editor> In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: In the similar vein is the work of Grosz and Sidner <ref> [11] </ref>, Pollack [26], and Meyden [31]. While our research builds on the above work to a large extent, it contributes the crucial notion of decision-theoretic rationality as a normative paradigm in communicative behavior, thus enabling to determine what communicative behavior should be executed in a situation at hand.
Reference: [12] <author> Joseph Y. Halpern and Yoram Moses. </author> <title> A guide to the modal logics of knowledge and belief. </title> <type> Technical Report 74007, </type> <institution> IBM Corporation, Almaden Research Center, </institution> <year> 1990. </year>
Reference-contexts: The semantics of propositional attitude statements have received much attention in the AI literature <ref> [12, 16] </ref>. Here, we would like to illustrate how the utility of statements of this kind can be computed within the framework we propose, given some straightforward postulates of what they intend to convey.
Reference: [13] <author> R. A. Howard. </author> <title> Information value theory. </title> <journal> IEEE Transactions on Systems Science and Cybernetics, </journal> <volume> 2 </volume> <pages> 22-26, </pages> <year> 1966. </year>
Reference-contexts: A qualitative approach, more closely related to ours and including dishonesty, has been presented by Myerson in [19]. In a similar vein, Parikh [22] used game-theoretic insights for disambiguation. Other relevant work includes value of information approaches by Horvitz and associates [25], building on earlier work by Howard <ref> [13] </ref>. Horvitz's approach is related in that the decision-making situation of the agent includes uncertainty, and is represented as an influence diagram.
Reference: [14] <author> Anthony Jameson. </author> <title> But what will the listener think? belief ascription and image maintenance in dialog. </title> <editor> In A. Kobsa and W. Wahlster, editors, </editor> <title> User Models in Dialog Systems. </title> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Fischer [7], for example, stresses the importance of a system's model of the user and the user's model of the system during man-machine communication. This leads to the nesting of models represented explicitly by our framework. Uncertainty-based decision-theoretic frameworks for HCI have been used by Jameson and associates in <ref> [14, 15] </ref>. In an earlier work, Cohen and Levesque provide a logical formalization of the concepts of intention and commitment [4], and apply it to issues of communication [5].
Reference: [15] <author> Anthony Jameson, Ralph Shaefer, Joep Simons, and Thomas Weis. </author> <title> Adaptive provision of evaluation-oriented information: Tasks and techniques. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1886-1893, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Fischer [7], for example, stresses the importance of a system's model of the user and the user's model of the system during man-machine communication. This leads to the nesting of models represented explicitly by our framework. Uncertainty-based decision-theoretic frameworks for HCI have been used by Jameson and associates in <ref> [14, 15] </ref>. In an earlier work, Cohen and Levesque provide a logical formalization of the concepts of intention and commitment [4], and apply it to issues of communication [5].
Reference: [16] <author> Kurt Konolige. </author> <title> A Deduction Model of Belief. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: The semantics of propositional attitude statements have received much attention in the AI literature <ref> [12, 16] </ref>. Here, we would like to illustrate how the utility of statements of this kind can be computed within the framework we propose, given some straightforward postulates of what they intend to convey.
Reference: [17] <author> Sarit Kraus and Jonathan Wilkenfeld. </author> <title> The function of time in cooperative negotiations. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Other work in AI include efforts on semantics of KQML [18, 29], which is closely related to earlier work of Cohen and Levesque, but it does not include the notion of value central to our approach. While work on communication in negotiation is reported in <ref> [17, 34, 35] </ref>. Communication among rational agents has also been of interest for the researchers in game theory, usually viewed a part of pre-game "cheap talk" [6], or as threat games [20] (see also discussion in [8] and references therein).
Reference: [18] <author> Y. Labrou and T. Finin. </author> <title> A semantics approach for KQML a general purpose communication language for software agents. </title> <booktitle> In Proceedings of the Third International Conference on Information and Knowledge Management, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Proof: Using Definition 3, we have U p M fR i g (Y ) = U p fR i g (X) for any trivial message M , since the utilities are calculated based on the prior and projected structures which are identical. 4 See <ref> [18, 29] </ref> for KQML effort, for example. 4 Cost = 1 Cost = 2 Cost = 2 Cost = 1 worth 2 P1, observation P2, observation worth 4 Trees R R 2 1 The theorem then follows directly from Definition 2. <p> We give examples of these in the following sections. It may be useful to classify communicative acts into types. Some of the types we consider have close correspondents in the speech act theory [1, 33], and in various kinds of performatives considered in KQML <ref> [18] </ref>. 3 Modeling Communicative Acts Our modeling acts update the hearer's and the speaker's model of the multiagent world. The close correspondents of these type of communicative acts in speech act theory are the inform, assert and tell acts. <p> Other work in AI include efforts on semantics of KQML <ref> [18, 29] </ref>, which is closely related to earlier work of Cohen and Levesque, but it does not include the notion of value central to our approach. While work on communication in negotiation is reported in [17, 34, 35].
Reference: [19] <author> Roger B. Myerson. </author> <title> Incentive constraints and optimal communication systems. </title> <booktitle> In Proceedings of the Second Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 179-193, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: The need for considering the nestedness of the agents' beliefs for communication has been widely recognized in the related literature before <ref> [1, 2, 3, 5, 10, 19, 24, 27, 28] </ref>; clearly, without a model of the other agents' state of beliefs it would be impossible to properly assess the impact of the communicative act. <p> A qualitative approach, more closely related to ours and including dishonesty, has been presented by Myerson in <ref> [19] </ref>. In a similar vein, Parikh [22] used game-theoretic insights for disambiguation. Other relevant work includes value of information approaches by Horvitz and associates [25], building on earlier work by Howard [13].
Reference: [20] <author> Roger B. Myerson. </author> <title> Game Theory: Analysis of Conflict. </title> <publisher> Harvard University Press, </publisher> <year> 1991. </year>
Reference-contexts: While work on communication in negotiation is reported in [17, 34, 35]. Communication among rational agents has also been of interest for the researchers in game theory, usually viewed a part of pre-game "cheap talk" [6], or as threat games <ref> [20] </ref> (see also discussion in [8] and references therein). These approaches, however, concentrate on the influence of pre-play communication on equilibria of the resulting game.
Reference: [21] <author> Sanguk Noh and Piotr J. Gmytrasiewicz. </author> <title> Decision-theoretic communication in coordinated anti-air defense. </title> <note> In In preparation, </note> <year> 1997. </year>
Reference-contexts: In our current work we undertook a more exhaustive testing of this correlation using the experimental environments described in the companion paper. The results and further discussion are forthcoming in <ref> [21] </ref>. In our future work we will investigate techniques that can be used to compile the first-principle method of deciding on the proper speech act. This gives rise, naturally, to the establishment of protocols.
Reference: [22] <author> Prashant Parikh. </author> <title> A game-theoretic account of implicature. </title> <booktitle> In Proceedings of the Conference on Theoretical Aspects of Reasoning about Knowladge, </booktitle> <pages> pages 85-93. </pages> <publisher> Morgan Kauf-man, </publisher> <month> August </month> <year> 1992. </year> <month> 21 </month>
Reference-contexts: A qualitative approach, more closely related to ours and including dishonesty, has been presented by Myerson in [19]. In a similar vein, Parikh <ref> [22] </ref> used game-theoretic insights for disambiguation. Other relevant work includes value of information approaches by Horvitz and associates [25], building on earlier work by Howard [13]. Horvitz's approach is related in that the decision-making situation of the agent includes uncertainty, and is represented as an influence diagram.
Reference: [23] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Infer--ence. </title> <publisher> Morgan Kaufman, </publisher> <year> 1988. </year>
Reference-contexts: This act also 1 Since our formalism is probabilistic, it naturally handles cases when the meaning of a message is itself uncertain. 2 The notion of the utility of a message we use here differs from the notion of the value of information considered in decision theory <ref> [23, 27] </ref>. The latter expresses the value of information to its recipient. We, on the other hand, consider the value of a message to its sender, since, of course, it is the sender that makes the decision of if, and what, to communicate. <p> Asking the question thus has a utility of 0:3. Let us note that the value of asking the question computed above coincides with the expected value of information obtained as a result, which is the usual notion of information value <ref> [23, 27] </ref>, as we would expect. We can summarize the analysis above in the following: Observation 2: The communicative acts corresponding to questions are acts declaring ignorance on the part of the speaker.
Reference: [24] <author> C. R. Perrault. </author> <title> An application of default logic to speech act theory. </title> <editor> In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The need for considering the nestedness of the agents' beliefs for communication has been widely recognized in the related literature before <ref> [1, 2, 3, 5, 10, 19, 24, 27, 28] </ref>; clearly, without a model of the other agents' state of beliefs it would be impossible to properly assess the impact of the communicative act. <p> example, the fact that a rational agent will not attempt to achieve goals that it believes are already true (in either action or communication) is just a manifestation of the expected utility of such attempts to a rational agent being zero. 8 Cohen and Levesque, as well as Perrault in <ref> [24] </ref>, also analyze the nestedness of beliefs so important in issues of communication, but rely on a notion of common belief, the justifiability of which, as with common knowledge, we find problematic (see the discussion in our companion paper).
Reference: [25] <author> Kim L. Poh and Eric J. Horvitz. </author> <title> A graph-theoretic analysis of information value. </title> <booktitle> In Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence (UAI-96), </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: A qualitative approach, more closely related to ours and including dishonesty, has been presented by Myerson in [19]. In a similar vein, Parikh [22] used game-theoretic insights for disambiguation. Other relevant work includes value of information approaches by Horvitz and associates <ref> [25] </ref>, building on earlier work by Howard [13]. Horvitz's approach is related in that the decision-making situation of the agent includes uncertainty, and is represented as an influence diagram.
Reference: [26] <author> Martha Pollack. </author> <title> Plans as complex mental attitudes. </title> <editor> In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: In the similar vein is the work of Grosz and Sidner [11], Pollack <ref> [26] </ref>, and Meyden [31]. While our research builds on the above work to a large extent, it contributes the crucial notion of decision-theoretic rationality as a normative paradigm in communicative behavior, thus enabling to determine what communicative behavior should be executed in a situation at hand.
Reference: [27] <author> S. Russell and P. Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <year> 1994. </year>
Reference-contexts: The need for considering the nestedness of the agents' beliefs for communication has been widely recognized in the related literature before <ref> [1, 2, 3, 5, 10, 19, 24, 27, 28] </ref>; clearly, without a model of the other agents' state of beliefs it would be impossible to properly assess the impact of the communicative act. <p> This act also 1 Since our formalism is probabilistic, it naturally handles cases when the meaning of a message is itself uncertain. 2 The notion of the utility of a message we use here differs from the notion of the value of information considered in decision theory <ref> [23, 27] </ref>. The latter expresses the value of information to its recipient. We, on the other hand, consider the value of a message to its sender, since, of course, it is the sender that makes the decision of if, and what, to communicate. <p> Further, some non-trivial messages may have expected utilities that are zero or even negative, in stark contrast to the usual decision-theoretic notion of the value of information which is never negative <ref> [27] </ref>. We give examples of these in the following sections. It may be useful to classify communicative acts into types. <p> This illustrates the point mentioned before: There is no guarantee that the communicative acts considered will have nonnegative expected utilities. This is in contrast to the theory of information value <ref> [27] </ref>. <p> Asking the question thus has a utility of 0:3. Let us note that the value of asking the question computed above coincides with the expected value of information obtained as a result, which is the usual notion of information value <ref> [23, 27] </ref>, as we would expect. We can summarize the analysis above in the following: Observation 2: The communicative acts corresponding to questions are acts declaring ignorance on the part of the speaker.
Reference: [28] <author> Stephen Schiffer. </author> <title> Meaning. </title> <publisher> Clarendon Press, </publisher> <year> 1972. </year>
Reference-contexts: The need for considering the nestedness of the agents' beliefs for communication has been widely recognized in the related literature before <ref> [1, 2, 3, 5, 10, 19, 24, 27, 28] </ref>; clearly, without a model of the other agents' state of beliefs it would be impossible to properly assess the impact of the communicative act. <p> evaluating the alternative communicative acts in this way, the agent can select and send the highest utility message|the message that causes the greatest gain in the expected utility of the agent's action. 2 DT pragmatics of a communicative act differs in a subtle way from its pragmatic meaning, usually defined <ref> [3, 10, 28] </ref> as the change of the state of knowledge brought about by the act. Imagine two agents engaged together in assembling a bicycle from parts scattered about a garage.
Reference: [29] <author> Ira A. Smith and Philip R. Cohen. </author> <title> Toward a semantics for an agent communications language based on speech acts. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 24-31, </pages> <address> Portland, OR, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: Proof: Using Definition 3, we have U p M fR i g (Y ) = U p fR i g (X) for any trivial message M , since the utilities are calculated based on the prior and projected structures which are identical. 4 See <ref> [18, 29] </ref> for KQML effort, for example. 4 Cost = 1 Cost = 2 Cost = 2 Cost = 1 worth 2 P1, observation P2, observation worth 4 Trees R R 2 1 The theorem then follows directly from Definition 2. <p> Other work in AI include efforts on semantics of KQML <ref> [18, 29] </ref>, which is closely related to earlier work of Cohen and Levesque, but it does not include the notion of value central to our approach. While work on communication in negotiation is reported in [17, 34, 35].
Reference: [30] <author> M. J. Tauber and D. Ackerman. </author> <title> Mental Models and Human-Computer Interaction 2. </title> <publisher> North Holland, </publisher> <year> 1991. </year>
Reference-contexts: Our ongoing research is delving into meta-level issues, so as to eventually capture such reasoning about imperatives. 17 10 Related Work The issue of modeling agents for the purpose of communication has received considerable attention in the field of human-computer interaction <ref> [30] </ref>. Fischer [7], for example, stresses the importance of a system's model of the user and the user's model of the system during man-machine communication. This leads to the nesting of models represented explicitly by our framework.
Reference: [31] <author> Ron van der Meyden. </author> <title> Mutual belief revision (preliminary report). </title> <booktitle> In Proceedings of the International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 595-606, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: In the similar vein is the work of Grosz and Sidner [11], Pollack [26], and Meyden <ref> [31] </ref>. While our research builds on the above work to a large extent, it contributes the crucial notion of decision-theoretic rationality as a normative paradigm in communicative behavior, thus enabling to determine what communicative behavior should be executed in a situation at hand.
Reference: [32] <author> Michael P. Wellman. </author> <title> The preferential semantics for goals. </title> <booktitle> In AAAI91, </booktitle> <pages> pages 698-703, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Horvitz's approach is related in that the decision-making situation of the agent includes uncertainty, and is represented as an influence diagram. These diagrams contain agent's alternative actions, utility, and states that influence utility, 8 See <ref> [32] </ref> for arguments showing how the notion of utility generalizes the notion of a goal. 18 which are the elements represented by the payoff matrices that we use.
Reference: [33] <author> Terry Winograd and Fernando Flores. </author> <title> Understanding Computers and Cognition: A New Foundation for Design. </title> <publisher> Ablex Publishing, </publisher> <year> 1986. </year>
Reference-contexts: We give examples of these in the following sections. It may be useful to classify communicative acts into types. Some of the types we consider have close correspondents in the speech act theory <ref> [1, 33] </ref>, and in various kinds of performatives considered in KQML [18]. 3 Modeling Communicative Acts Our modeling acts update the hearer's and the speaker's model of the multiagent world. The close correspondents of these type of communicative acts in speech act theory are the inform, assert and tell acts.
Reference: [34] <author> Gilad Zlotkin and Jeffrey S. Rosenschein. </author> <title> Negotiation and task sharing among autonomous agents in cooperative domains. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 912-917, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Other work in AI include efforts on semantics of KQML [18, 29], which is closely related to earlier work of Cohen and Levesque, but it does not include the notion of value central to our approach. While work on communication in negotiation is reported in <ref> [17, 34, 35] </ref>. Communication among rational agents has also been of interest for the researchers in game theory, usually viewed a part of pre-game "cheap talk" [6], or as threat games [20] (see also discussion in [8] and references therein).
Reference: [35] <author> Gilad Zlotkin and Jeffrey S. Rosenschein. </author> <title> Negotiation and conflict resolution in noncooperative domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 100-105, </pages> <month> July </month> <year> 1990. </year> <month> 22 </month>
Reference-contexts: Other work in AI include efforts on semantics of KQML [18, 29], which is closely related to earlier work of Cohen and Levesque, but it does not include the notion of value central to our approach. While work on communication in negotiation is reported in <ref> [17, 34, 35] </ref>. Communication among rational agents has also been of interest for the researchers in game theory, usually viewed a part of pre-game "cheap talk" [6], or as threat games [20] (see also discussion in [8] and references therein).
References-found: 35

