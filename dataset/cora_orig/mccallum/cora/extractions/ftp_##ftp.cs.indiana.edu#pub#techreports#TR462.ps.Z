URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR462.ps.Z
Refering-URL: http://www.cs.indiana.edu/ftp/techreports/index.html
Root-URL: http://www.cs.indiana.edu
Title: INTROSPECTIVE LEARNING FOR CASE-BASED PLANNING  
Author: by Susan Fox 
Degree: Submitted to the faculty of the Graduate School in partial fulfillment of the requirements for the degree Doctor of Philosophy in the  
Date: October, 1995  
Affiliation: Department of Computer Science, Indiana University  
Abstract-found: 0
Intro-found: 1
Reference: <author> Agre, P. & Chapman, D. </author> <year> (1987). </year> <title> Pengi: an implementation of a theory of activity. </title> <booktitle> In Proceedings of the Sixth Annual National Conference on Artificial Intelligence Seattle, </booktitle> <address> WA. </address> <publisher> AAAI. </publisher>
Reference-contexts: Firby's RAPs incorporate both high-level and low-level actions. Other approaches to reactive planning focus on increasingly low-level actions and an even closer link between observations and actions. The Pengi system plays the video game Pengo <ref> (Agre & Chapman, 1987) </ref>. At each moment, Pengi selects a routine, an action to perform, based on the current situation. Local objects are labeled according to their function from Pengi's perspective (i.e., the-bee-that-is-chasing-me) and re-labeled in the next moment.
Reference: <author> Alterman, R. </author> <year> (1986). </year> <title> An adaptive planner. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 65-69 Philadelphia, PA. </address> <publisher> AAAI. </publisher>
Reference-contexts: ROBBIE alters its indexing, but uses an analysis of its reasoning process to detect a broader class of failures: its introspective reasoning allows it to detect a bad retrieval even when its case adaptor can repair the problems to produce a successful solution. Other case-based planners include PLEXUS <ref> (Alterman, 1986) </ref> which applies cases describing routine, everyday plans for traveling by public transportation. PLEXUS is concerned with the integration of planning and action, as ROBBIE is, and performs adaptation of retrieved routine plans as an execution task.
Reference: <author> Arcos, J. & Plaza, E. </author> <year> (1993). </year> <title> A reflective architecture for integrated memory-based learning and reasoning. </title> <editor> In Wess, S., Altoff, K., & Richter, M. (Eds.), </editor> <booktitle> Topics in Case-Based Reasoning. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Kaiserslautern, Germany. </address>
Reference: <author> Bain, W. </author> <year> (1986). </year> <title> Case-based Reasoning: A Computer Model of Subjective Assessment. </title> <type> Ph.D. thesis, </type> <institution> Yale University. Computer Science Department Technical Report 470. </institution>
Reference: <author> Barletta, R. & Mark, W. </author> <year> (1988). </year> <title> Explanation-based indexing of cases. </title> <editor> In Kolodner, J. (Ed.), </editor> <booktitle> Proceedings of a Workshop on Case-Based Reasoning, </booktitle> <pages> pp. </pages> <address> 50-60 Palo Alto. </address> <publisher> DARPA, Morgan Kaufmann, Inc. </publisher>
Reference-contexts: Explanations are often used to determine the relevance of features when assigning indices to new cases. CABER provides plans for recovering from machine failures of a milling machine to a human user <ref> (Barletta & Mark, 1988) </ref>. New repair plans are stored by deriving the important indices from explanations based on knowledge of the machine. in question. Leake & Owens (1986) determine the acceptability of a case for explaining an anomaly by characterizing the anomaly and the goals of its explanation.
Reference: <author> Bhatta, S. & Goel, A. </author> <year> (1993). </year> <title> Model-based learning of structural indices to design cases. </title> <booktitle> In Proceedings of the IJCAI-93 Workshop on Reuse of Design Chambery, </booktitle> <address> France. </address> <note> IJCAI. 244 BIBLIOGRAPHY 245 Birnbaum, </note> <author> L., Collins, G., Brand, M., Freed, M., Krulwich, B., & Pryor, L. </author> <year> (1991). </year> <title> A model-based approach to the construction of adaptive case-based planning systems. In Bareiss, </title> <editor> R. (Ed.), </editor> <booktitle> Proceedings of the Case-Based Reasoning Workshop, </booktitle> <pages> pp. </pages> <address> 215-224 San Mateo. </address> <publisher> DARPA, Morgan Kaufmann, Inc. </publisher>
Reference-contexts: IDEAL investigates index learning in the domain of device design by using a model of the structure and function of a device to determine the important structural features of a given device description, for indexing that description as a case <ref> (Bhatta & Goel, 1993) </ref>. In CADET, Sycara & Navinchandra (1989) alter the indices used to retrieve cases for designing new devices by applying operators which elaborate the important features describing the new desired device.
Reference: <author> Birnbaum, L., Collins, G., Freed, M., & Krulwich, B. </author> <year> (1990). </year> <title> Model-based diagnosis of planning failures. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 318-323 Boston, MA. </address> <publisher> AAAI. </publisher>
Reference-contexts: Failures are explained by searching the declarative model for other possible failures causally related to the detected one. The possibility of applying this approach for improving case-based reasoning systems was first proposed by Birnbaum et al. (1991), based on their earlier work involving self-debugging, chaining-based planners <ref> (Birnbaum et al., 1990) </ref>. Our approach to model-based introspective reasoning achieves all the goals described above. Detected failures drive the introspective learning task; without an Model-based Introspective Reasoning 117 expectation failure the introspective component takes no action.
Reference: <author> Brooks, R. </author> <year> (1987). </year> <title> Intelligence without representation. </title> <booktitle> In Proceedings of the Workshop on the Foundations of Artificial Intelligence Cambridge, </booktitle> <address> MA. </address> <publisher> MIT. </publisher>
Reference-contexts: ROBBIE, by contrast, assumes explicit deliberative planning, in combination with a representational approach to reactive planning. At the extreme end of the reactive planning spectrum, and perhaps unwillingly classified as such, is Brooks' subsumption architecture <ref> (Brooks, 1987) </ref>. The "planning" aspect is nearly missing completely; Brooks ties sensor input and action together without an explicit representation of input or action intervening. The choice between actions is mediated between different hardwired processes performing different functions which map from input to action.
Reference: <author> Burke, R. </author> <year> (1993). </year> <title> Retrieval strategies for tutorial stories. </title> <editor> In Leake, D. (Ed.), </editor> <booktitle> Proceedings of the AAAI-93 Workshop on Case-Based Reasoning, </booktitle> <pages> pp. </pages> <address> 118-124 Wash-ington, DC. </address> <publisher> AAAI. AAAI Press technical report WS-93-01. </publisher>
Reference: <author> Chandrasekaran, B. </author> <year> (1994). </year> <title> Functional representation and causal processes. </title> <editor> In Yovits, M. (Ed.), </editor> <booktitle> Advances in Computers. </booktitle> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Chi, M. & Glaser, R. </author> <year> (1980). </year> <title> The measurement of expertise: a development of knowledge and skill as a basis for assessing achievement. </title> <editor> In Baker, E. & Quellmalz, E. (Eds.), </editor> <title> Educational testing and evaluation: Design, analysis and policy. </title> <publisher> Sage Publications, </publisher> <address> Beverly Hill, CA. </address>
Reference: <author> Cohen, P. & Howe, A. </author> <year> (1988). </year> <title> How evaluation guides ai research. </title> <journal> The AI Magazine, </journal> <volume> 9 (4), </volume> <pages> 35-43. </pages>
Reference-contexts: This has led to a call for systematic evaluations of artificial intelligence systems (e.g., <ref> (Cohen & Howe, 1988) </ref>). Our previous chapters have discussed the in principle benefits of introspective learning. This chapter presents empirical tests of our system. To our knowledge, 156 Experimental Results 157 these are the first empirical tests of any system using introspective reasoning to learn from reasoning failures.
Reference: <author> Collins, G., Birnbaum, L., Krulwich, B., & Freed, M. </author> <year> (1993). </year> <title> The role of self-models in learning to plan. In Foundations of Knowledge Acquisition: </title> <booktitle> Machine Learning, </booktitle> <pages> pp. 83-116. </pages> <publisher> Kluwer Academic Publishers. BIBLIOGRAPHY 246 Cottrell, </publisher> <editor> G. W. & Tsung, F.-S. </editor> <year> (1989). </year> <title> Learning simple arithmetic procedures. </title> <booktitle> In Proceedings of the Eleventh Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. </pages> <address> 58-65 Hillsdale, NJ. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Cox, M. </author> <year> (1994). </year> <title> Machines that forget: learning from retrieval failure of mis-indexed explanations. </title> <booktitle> In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 225-230. </pages> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Meta-AQUA performs failure-driven introspective learning in a case-based manner, by retrieving and applying cases which describe reasoning events instead of domain events <ref> (Ram & Cox, 1994) </ref>. Meta-AQUA is a story understanding system that applies explanation pattern cases (XPs) to explain anomalies (expectation failures) discovered in the story it is given. When Meta-AQUA fails to understand a story fragment it expects to understand, it applies "Introspective Meta-XPs" (IMXPs) to correct its reasoning process. <p> Different IMXPs refer to different Background 42 classes of reasoning failures, such as "Novel situation," "Incorrect background knowledge," or "Impasse during memory retrieval," <ref> (Cox, 1994) </ref>. Cox (1995) describes a taxonomy of different reasoning events and failures from which IMXPs might be derived. Meta-AQUA focuses on the use of Meta-XPs to explain and learn from reasoning failures.
Reference: <author> Cox, M. </author> <year> (1995). </year> <title> Representing mental events (or the lack thereof). </title> <booktitle> In Proceedings of the 1995 AAAI Spring Symposium on Representing Mental States and Mechanisms. </booktitle>
Reference-contexts: Recently, there has been a surge of interest in systems which have explicit Background 37 knowledge about reasoning methods, and which can use that knowledge to diagnose and repair their own reasoning methods, or understand the reasoning of others <ref> (Cox & Freed, 1995) </ref>. The introspective reasoning framework we have designed performs diagnosis and repair of its own reasoning, but its approach to the representational needs for modeling reasoning appears useful for these other introspective tasks as well.
Reference: <author> Cox, M. </author> & <title> Freed, </title> <editor> M. (Eds.). </editor> <booktitle> (1995). Proceedings of the 1995 AAAI Spring Symposium on Representing Mental States and Mechanisms, </booktitle> <address> Stanford, CA. </address> <publisher> AAAI. </publisher>
Reference-contexts: Recently, there has been a surge of interest in systems which have explicit Background 37 knowledge about reasoning methods, and which can use that knowledge to diagnose and repair their own reasoning methods, or understand the reasoning of others <ref> (Cox & Freed, 1995) </ref>. The introspective reasoning framework we have designed performs diagnosis and repair of its own reasoning, but its approach to the representational needs for modeling reasoning appears useful for these other introspective tasks as well.
Reference: <author> DeJong, G. & Mooney, R. </author> <year> (1986). </year> <title> Explanation-based learning: an alternative view. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 145-176. </pages>
Reference: <author> Downs, J. & Reichgelt, H. </author> <year> (1991). </year> <title> Integrating classical and reactive planning within an architecture for autonomous agents. </title> <booktitle> In European Workshop on Planning, </booktitle> <pages> pp. 13-26. </pages>
Reference: <author> Efron, B. & Tibshirani, R. </author> <year> (1993). </year> <title> An Introduction to the Boostrap. </title> <publisher> Chapman & Hall. </publisher>
Reference-contexts: We performed instead a variation of the t-test which makes no assumptions about the distribution of success rates in our samples. We applied a statistical method called boot-strapping <ref> (Efron & Tibshirani, 1993) </ref> to produce a "population" of mean differences to which to compare the observed mean difference of a sequence.
Reference: <author> Elman, J. L. </author> <year> (1991). </year> <title> Incremental learning, or the importance of starting small. </title> <booktitle> Annual Conference of the Cognitive Science Society, </booktitle> <volume> 13, </volume> <pages> 443-448. </pages>
Reference: <author> Evett, M. </author> <year> (1994). </year> <title> PARKA: A System for Massively Parallel Knowledge Representation. </title> <type> Ph.D. thesis, </type> <institution> University of Maryland. </institution> <note> BIBLIOGRAPHY 247 Firby, </note> <author> J., Kahn, R., Prokopowicz, P., & Swain, M. </author> <year> (1995). </year> <title> An architecture for vision and action. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 72-79. </pages> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference: <author> Firby, R. J. </author> <year> (1989). </year> <title> Adaptive Execution in Complex Dynamic Worlds. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Computer Science Department. </institution> <type> Technical Report 672. </type>
Reference-contexts: Its reactive component is based on the Reactive Action Packages (RAP) model of Firby <ref> (Firby, 1989) </ref>. <p> Additional objects in the world such as cars and features such as time constraints on ROBBIE's performance could also be added using the same basic simulator mechanisms. 3.4 The planner ROBBIE's planner combines a typical case-based planner (Hammond, 1989) with a reactive planning execution module <ref> (Firby, 1989) </ref>. Figure 3.9 outlines the planner's process. The case-based planner takes a description of its current situation (the current starting and goal locations), builds an index describing the situation, and ROBBIE and Its Domain 59 retrieves old plans with similar indices for already-known routes on the current map.
Reference: <author> Flavell, J. </author> <year> (1985). </year> <title> Cognitive Development. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference: <author> Flavell, J., Friedrichs, A., & Hoyt, J. </author> <year> (1970). </year> <title> Develpmental changes in memorization processes. </title> <journal> Cognitive Psychology, </journal> <volume> 1, </volume> <pages> 324-340. </pages>
Reference: <author> Fowler, N., Cross, S., & Owens, C. </author> <year> (1995). </year> <title> The ARPA-Rome knowledge-based planning initiative. </title> <journal> IEEE Expert, </journal> <volume> 10 (1), </volume> <pages> 4-9. </pages>
Reference-contexts: correct index describing its salient features. 2.1.1 Planning in the context of CBR Case-based reasoning has been applied to the tasks of explanation, understanding, diagnosis, tutoring, and many others, but case-based planning has been a popular task, perhaps because of the immediate crucial importance of planning for practical applications (e.g., <ref> (Fowler, Cross, & Owens, 1995) </ref>). Where a case for an understanding system might describe a scene or set of events, a case-based planner's case is likely to be a set of instructions for achieving some goal.
Reference: <author> Fox, S. & Leake, D. </author> <year> (1994). </year> <title> Using introspective reasoning to guide index refinement in case-based reasoning. </title> <booktitle> In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. </pages> <address> 324-329 Atlanta, GA. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Fox, S. & Leake, D. </author> <year> (1995a). </year> <title> An introspective reasoning method for index refinement. </title> <booktitle> In Proceedings of 14th international Joint Conference on Artificial Intelligence. IJCAI. </booktitle>
Reference: <author> Fox, S. & Leake, D. </author> <year> (1995b). </year> <title> Learning to refine indexing by introspective reasoning. </title> <booktitle> In Proceedings of the First International Conference on Case-Based Reasoning Sesimbra, </booktitle> <address> Portugal. </address> <note> BIBLIOGRAPHY 248 Fox, </note> <author> S. & Leake, D. </author> <year> (1995c). </year> <title> Modeling case-based planning for repairing reasoning failures. </title> <booktitle> In Proceedings of the 1995 AAAI Spring Symposium on Representing Mental States and Mechanisms Stanford, </booktitle> <address> CA. </address> <publisher> AAAI. </publisher>
Reference: <author> Freed, M. & Collins, G. </author> <year> (1994a). </year> <title> Adapting routines to improve task coordination. </title> <booktitle> In Proceedings of the 1994 Conference on AI Planning Systems, </booktitle> <pages> pp. 255-259. </pages>
Reference-contexts: Their approach was also implemented in CASTLE, a system which introspectively learned strategies for playing chess (Collins et al., 1993; Krul-wich et al., 1992). A variation was applied to Firby's reactive planning domain (RAPTER, <ref> (Freed & Collins, 1994a) </ref>, see below). Their proposal for applying the approach to case-based reasoning, however, was never investigated. ROBBIE's model, while based on the proposal of Birnbaum et al., deviates from their proposed model in a number of ways.
Reference: <author> Freed, M. & Collins, G. </author> <year> (1994b). </year> <title> Learning to prevent task interactions. </title> <editor> In desJardins, M. & Ram, A. (Eds.), </editor> <booktitle> Proceedings of the 1994 AAAI Spring Symposium on Goal-driven Learning, </booktitle> <pages> pp. 28-35. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: as ROBBIE includes are used to describe a reasoning trace from which the introspective reasoner extracts information about the actual reasoning of the planner. 2.4.2 RAPTER The RAPTER system developed by Freed applies an introspective model of ideal reasoning behavior to a Firby-like reactive planner in Firby's deliver-truck domain, Truckworld <ref> (Freed & Collins, 1994b) </ref>. The model is similar to ROBBIE's and the Background 39 CASTLE model mentioned above, in that it is a set of assertions about the expected reasoning behavior of the system.
Reference: <author> Gat, E. </author> <year> (1992). </year> <title> Integrating planning and reacting in a heterogeneous asynchronous architecture for controlling real-worl mobile robots. </title> <booktitle> In Proceedings, Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 809-815. </pages>
Reference: <author> Gentner, D. </author> <year> (1988). </year> <title> Metaphor as structure mapping: the relational shift. Child Development, </title> <booktitle> 59, </booktitle> <pages> 47-59. </pages>
Reference: <author> Goel, A., Ali, K., & de Silva Garza, A. G. </author> <year> (1994). </year> <title> Computational tradeoffs in experience-based reasoning. </title> <booktitle> In Proceedings of the AAAI-94 workshop on Case-Based Reasoning, </booktitle> <pages> pp. </pages> <address> 55-61 Seattle, WA. </address>
Reference-contexts: ROUTER combines case-based plan creation with a more traditional model-based approach. Background 31 Unlike ROBBIE, it is not concerned with execution of plans or dynamic changes to the world which may suddenly invalidate an previously perfect plan. ROUTER has also been combined with an introspective reasoning component, Autognostic, <ref> (Stroulia & Goel, 1994) </ref> as we will describe in Section 2.4. ROBBIE differs from all these case-based planners in its focus on incorporating introspective reasoning into the system to detect and repair failures due to faulty reasoning. <p> ROBBIE monitors not only the outcomes of the planning process, but the reasoning process itself to discover failures. Background 40 2.4.3 Autognostic Autognostic incorporates a different form of model for representing reasoning processes <ref> (Stroulia & Goel, 1994) </ref>. Instead of a model that contains explicit expectations about the underlying reasoning process, Autognostic represents the underlying reasoning process as a computational process. <p> To strongly support failure detection, we needed to develop a representation of desired performance. Autognostic has been used to model the performance of two different underlying Background 41 systems: ROUTER <ref> (Goel, Ali, & de Silva Garza, 1994) </ref> which applies both case-based planning and rule-based planning to construct route plans for traversing a college campus, and Kritik2 (Stroulia & Goel, 1992) which performs device design and diagnosis.
Reference: <author> Goel, A., Callantine, T., Shankar, M., & Chandrasekaran, B. </author> <year> (1991). </year> <title> Representation, organization, and use of topographic models of physical spaces for route planning. </title> <booktitle> In Proceedings of the Seventh IEEE Conference on AI Applications, </booktitle> <pages> pp. 308-314. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: ROBBIE uses a more traditional adaptation process to form a high-level plan, then uses reactive execution to complete the adaptation in interaction with the external world. ROUTER is another case-based route planner, which creates routes for navigating a college campus <ref> (Goel, Callantine, Shankar, & Chandrasekaran, 1991) </ref>. ROUTER combines case-based plan creation with a more traditional model-based approach. Background 31 Unlike ROBBIE, it is not concerned with execution of plans or dynamic changes to the world which may suddenly invalidate an previously perfect plan.
Reference: <author> Goel, A. & Chandrasekaran, B. </author> <year> (1989). </year> <title> Use of device models in adaptation of design cases. </title> <editor> In Hammond, K. (Ed.), </editor> <booktitle> Proceedings of the Case-Based Reasoning Workshop, </booktitle> <pages> pp. </pages> <address> 100-109 San Mateo. </address> <publisher> DARPA, Morgan Kaufmann, Inc. </publisher> <address> BIBLIOGRAPHY 249 Gruber, T. </address> <year> (1989). </year> <title> Automated knowledge acquisition for strategic knowledge. </title> <journal> Machine Learning, </journal> <volume> 4, </volume> <pages> 293-336. </pages>
Reference: <author> Hammond, C. </author> <year> (1989). </year> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <publisher> Academic Press, </publisher> <address> San Diego. </address>
Reference-contexts: Additional objects in the world such as cars and features such as time constraints on ROBBIE's performance could also be added using the same basic simulator mechanisms. 3.4 The planner ROBBIE's planner combines a typical case-based planner <ref> (Hammond, 1989) </ref> with a reactive planning execution module (Firby, 1989). Figure 3.9 outlines the planner's process. <p> Case retrieval: Once a goal has been created, ROBBIE must generate a route plan that describes a path from its starting location to the goal location. The plan is created by a case-based planner structurally similar to the planning system CHEF <ref> (Hammond, 1989) </ref> 2 . The case-based planner takes the goal (the new desired location and current situation) and builds an index which describes the situation in terms of 2 Previous case-based route planners are discussed in Chapter 2.
Reference: <author> Hennessey, D. & Hinkle, D. </author> <year> (1991). </year> <title> Initial results from clavier: a case-based autoclave loading assistant. In Bareiss, </title> <editor> R. (Ed.), </editor> <booktitle> Proceedings of the Case-Based Reasoning Workshop, </booktitle> <pages> pp. </pages> <address> 225-232 San Mateo. </address> <publisher> DARPA, Morgan Kaufmann, Inc. </publisher>
Reference-contexts: Kitano et al. (1992) implement in SQUAD a system to assist a human user in diagnosing and correcting software problems, without automatic adaptation. CLAVIER proposes layouts for baking high-technology parts in an autoclave, but adaptation of old solutions is left to a human user <ref> (Hennessey & Hinkle, 1991) </ref>. Case applications Given that a case-based plan is to be executed interactively, there are two aspects of the reactive planning process that pose obstacles to scaling up. <p> The CLAVIER system assists a user in positioning pieces to be baked in an autoclave; it provides the user with a set of the most similar, unadapted cases in its memory <ref> (Hennessey & Hinkle, 1991) </ref>. CASCADE contains cases describing VMS operating system failures and provides the closest matching alternatives to the user in the face of a new problem (Simoudis, 1992).
Reference: <author> Hinrichs, T. </author> <year> (1992). </year> <title> Problem Solving in Open Worlds: A Case Study in Design. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Ibrahim, M. </author> <year> (1992). </year> <title> Reflection in object-oriented programming. </title> <journal> International Journal on Artificial Intelligence Tools, </journal> <volume> 1 (1), </volume> <pages> 117-136. </pages>
Reference: <author> Kitano, H., Shibata, A., Shimazu, H., Kajihara, J., & Sato, A. </author> <year> (1992). </year> <title> Building large-scale and corporate-wide case-based systems: integration of organizational and machine executable algorithms. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 843-849 San Jose, CA. </address> <publisher> AAAI. </publisher>
Reference: <editor> Kodratoff, Y. & Michalski, R. (Eds.). </editor> <booktitle> (1990). Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. 3. </volume> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kolodner, J. </author> <year> (1984). </year> <title> Retrieval and Organizational Strategies in Conceptual Memory. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Kolodner, J. </author> <year> (1988). </year> <title> Retrieving events from a case memory: a parallel implementation. </title> <editor> In Kolodner, J. (Ed.), </editor> <booktitle> Proceedings of a Workshop on Case-Based Reasoning, </booktitle> <pages> pp. </pages> <address> 233-249 Palo Alto. </address> <publisher> DARPA, Morgan Kaufmann, Inc. BIBLIOGRAPHY 250 Kolodner, </publisher> <editor> J. </editor> <year> (1993a). </year> <title> Case-Based Reasoning, </title> <journal> chap. </journal> <volume> 8, </volume> <pages> pp. 289-320. </pages> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Kolodner, J. </author> <year> (1993b). </year> <title> Case-Based Reasoning. </title> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Koton, P. </author> <year> (1989). </year> <title> Smartplan: a case-based resource allocation and scheduling system. </title>
Reference: <editor> In Hammond, K. (Ed.), </editor> <booktitle> Proceedings of the Case-Based Reasoning Workshop, </booktitle> <pages> pp. </pages> <address> 290-294 San Mateo. </address> <publisher> DARPA, Morgan Kaufmann, Inc. </publisher>
Reference: <author> Kreutzer, M., Leonard, M., & Flavell, J. </author> <year> (1975). </year> <title> An interview study of children's knowledge about memory. </title> <booktitle> Monographs of the Society for Research in Child Development, </booktitle> <volume> 40. (1, Serial No. </volume> <pages> 159). </pages>
Reference: <author> Krulwich, B., Birnbaum, L., & Collins, G. </author> <year> (1992). </year> <title> Learning several lessons from one experience. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. </pages> <address> 242-247 Bloomington, </address> <publisher> IN. Cognitive Science Society. </publisher>
Reference: <author> Leake, D. </author> <year> (1992). </year> <title> Evaluating Explanations: A Content Theory. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Leake, D. </author> <year> (1995). </year> <title> Combining rules and cases to learn case adaptation. </title> <booktitle> In Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society Pitts-burgh, </booktitle> <address> PA. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Determining what changes to make during adaptation remains an open question, although learning when to apply a given adaptation strategy, or even learning new strategies, could help to limit the adaptation effort when the case being adapted is highly complex <ref> (Leake, 1995) </ref>. In general, as the case library for a case-based reasoner grows in size, the need for extensive adaptation decreases: a case selected will be more similar than when few cases are available.
Reference: <author> Leake, D. & Owens, C. </author> <year> (1986). </year> <title> Organizing memory for explanation. </title> <booktitle> In Proceedings of the Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. </pages> <address> 710-715 Amherst, MA. </address> <publisher> Cognitive Science Society. </publisher>
Reference: <author> Lehnert, W. </author> <year> (1978). </year> <title> The Process of Question Answering. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address> <note> BIBLIOGRAPHY 251 Machine Learning (1989) Machine Learning, 4 (3/4). Special issue on knowledge acquisition. </note>
Reference: <author> McDermott, D. </author> <year> (1981). </year> <title> Artificial intelligence meets natural stupidity. </title> <editor> In Haugeland, J. (Ed.), </editor> <title> Mind Design. </title> <publisher> MIT Press, Bradford Books, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: This approach may include a detailed analysis of the system's methods and its most important features. It raises the question, however, of the breadth of the system's good performance: the suspicion may lurk that the examples studied are the only examples for which the system works properly <ref> (McDermott, 1981) </ref>, or that this performance is not typical over the long term (Minton, 1990). This has led to a call for systematic evaluations of artificial intelligence systems (e.g., (Cohen & Howe, 1988)). Our previous chapters have discussed the in principle benefits of introspective learning.
Reference: <author> Meeden, L. </author> <year> (1994). </year> <title> Towards Planning: Incremental Investigations into Adaptive Robot Control. </title> <type> Ph.D. thesis, </type> <institution> Indiana University, Computer Science Department. </institution>
Reference: <editor> Michalski, R., Carbonell, J., & Mitchell, T. (Eds.). </editor> <booktitle> (1983). Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. 1. </volume> <publisher> Morgan Kaufmann. </publisher>
Reference: <editor> Michalski, R., Carbonell, J., & Mitchell, T. (Eds.). </editor> <booktitle> (1986). Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. 2. </volume> <publisher> Morgan Kaufmann. </publisher>
Reference: <editor> Michalski, R. & Tecuci, G. (Eds.). </editor> <booktitle> (1994). Machine Learning: A multistrategy approach, </booktitle> <volume> Vol. 4. </volume> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Minton, S. </author> <year> (1990). </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 42, </volume> <pages> 363-391. </pages>
Reference-contexts: It raises the question, however, of the breadth of the system's good performance: the suspicion may lurk that the examples studied are the only examples for which the system works properly (McDermott, 1981), or that this performance is not typical over the long term <ref> (Minton, 1990) </ref>. This has led to a call for systematic evaluations of artificial intelligence systems (e.g., (Cohen & Howe, 1988)). Our previous chapters have discussed the in principle benefits of introspective learning. This chapter presents empirical tests of our system.
Reference: <author> Mitchell, T., Keller, R., & Kedar-Cabelli, S. </author> <year> (1986). </year> <title> Explanation-based generalization: a unifying view. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 47-80. </pages>
Reference: <author> Nourbakhsh, I., Powers, R., & Birchfield, S. </author> <year> (1995). </year> <title> Dervish: an office-navigating robot. </title> <journal> AI Magazine, </journal> <volume> 16 (2), </volume> <pages> 53-60. </pages>
Reference: <author> Oehlmann, R., Edwards, P., & Sleeman, D. </author> <year> (1995). </year> <title> Introspection planning: representing metacognitive experience. </title> <booktitle> In Proceedings of the 1995 AAAI Spring Symposium on Representing Mental States and Mechanisms. BIBLIOGRAPHY 252 Ram, A. </booktitle> <year> (1989). </year> <title> Question-driven understanding: An integrated theory of story understanding, memory and learning. </title> <type> Ph.D. thesis, </type> <institution> Yale University, New Haven, CT. Computer Science Department Technical Report 710. </institution>
Reference-contexts: Unlike ROBBIE, it cannot detect suboptimal reasoning performance unless later information reveals the sub-optimality explicitly. 2.4.5 IULIAN IULIAN is another system which integrates introspective reasoning with its overall case-based task. IULIAN's task is discovery learning, to describe and explain problems presented it by forming theories or by performing experiments <ref> (Oehlmann, Edwards, & Sleeman, 1995) </ref>. Its case memory contains previously solved problems, plans for creating experiments by adapting existing ones, and plans for forming theories through posing questions and recursively applying its methods to answer them.
Reference: <author> Ram, A. </author> <year> (1993). </year> <title> Indexing, elaboration and refinement: incremental learning of explanatory cases. </title> <journal> Machine Learning, </journal> <volume> 10 (3), </volume> <pages> 201-248. </pages>
Reference-contexts: Leake & Owens (1986) determine the acceptability of a case for explaining an anomaly by characterizing the anomaly and the goals of its explanation. In AQUA, new cases are similarly indexed by explanation-based generalization of the "stereotypical" features of situations, and the objects and characters in them <ref> (Ram, 1993) </ref>. However, less attention has been devoted to the central questions addressed by ROBBIE: when and how to alter the indexing criteria based on an existing case in memory. Some approaches alter indices in response to external feedback.
Reference: <author> Ram, A. & Cox, M. </author> <year> (1994). </year> <title> Introspective reasoning using meta-explanations for multistrategy learning. </title> <editor> In Michalski, R. & Tecuci, G. (Eds.), </editor> <booktitle> Machine Learning: </booktitle>
Reference-contexts: Meta-AQUA performs failure-driven introspective learning in a case-based manner, by retrieving and applying cases which describe reasoning events instead of domain events <ref> (Ram & Cox, 1994) </ref>. Meta-AQUA is a story understanding system that applies explanation pattern cases (XPs) to explain anomalies (expectation failures) discovered in the story it is given. When Meta-AQUA fails to understand a story fragment it expects to understand, it applies "Introspective Meta-XPs" (IMXPs) to correct its reasoning process.
References-found: 63

