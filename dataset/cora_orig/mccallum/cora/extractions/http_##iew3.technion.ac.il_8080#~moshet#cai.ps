URL: http://iew3.technion.ac.il:8080/~moshet/cai.ps
Refering-URL: http://iew3.technion.ac.il:8080/~moshet/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Artificial Social Systems  
Author: Yoram Moses Moshe Tennenholtz 
Keyword: Social Laws, Multi-Agent Systems, Off-Line Design  
Address: Rehovot, 76100 Israel Haifa 32000, Israel  
Affiliation: Department of Applied Math and CS Faculty of Industrial Engineering and Management The Weizmann Institute of Science Technion Israel Institute of Technology  
Abstract: An artificial social system is a set of restrictions on agents' behaviors in a multi-agent environment. Its role is to allow agents to coexist in a shared environment and pursue their respective goals in the presence of other agents. This paper argues that artificial social systems exist in practically every multi-agent system, and play a major role in the performance and effectiveness of the agents. We propose artificial social systems as an explicit and formal object of study, and investigate several basic issues that arise in their design. fl This work was supported in part by the US-Israel Binational Foundation. The work of the first author was supported by an Alon Fellowship, and by a Helen and Marcus Kimmelman Career Development Chair. The second author was supported in part by an Eshkol Fellowship of the Israeli Ministry of Science and Technology, and later by the Air Force Office of Scientific Research. Part of the research was carried out while the second author was in the department of Applied Mathematics and CS in the Weizmann Institute, and part while he was in the CS department at Stanford University. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> James Allen, James Hendler, and Austin Tate, editors. </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year>
Reference-contexts: Given a set of n agents, a set S of possible physical strategies, a set G soc of socially acceptable goals, and for each g 2 G soc a payoff function u g : S n ! <ref> [0; 1] </ref>, find a set S S of "socially acceptable" strategies such that for all g 2 G soc there exists s 2 S such that u g (s; ) * for all 2 S n1 . <p> This is the type of context in which high-level planning is normally studied <ref> [1] </ref>. In many cases, the set of basic tasks is rather small, while the class of behaviors that the agents can generate using them is rich and complex. We call the implementations of 9 these tasks primitive routines. <p> Thus, the same goal (getting to the airport) can be attained via routes yielding different utilities. Formally, utilities are added to a social system hS; fLegal i g in ; G soc ; W soc i by adding a function u a;g : W g ! <ref> [0; 1] </ref> for every agent a and goal g 2 G soc .
Reference: [2] <author> S. Berthet, Y. Demazeau, and O. Boissier. </author> <title> Knowling Each Other Better. </title> <booktitle> In Decentralized AI 2, </booktitle> <pages> pages 23-42, </pages> <year> 1992. </year>
Reference-contexts: In sufficiently complex situations, however, some communication and explicit coordination between the agents is inevitable, and in others it may be desirable. Indeed, a central concern in distributed and decentralized AI is the design of communication and interaction protocols <ref> [2, 14] </ref>. Our framework applies equally well to such situations. For agents in a multi-agent setting to communicate, they need to have a common language, specific protocols for interaction, and conventions for when and how these are used. <p> A comprehensive social system must therefore also contain a component that describes how conflicts are to be handled once they occur. The work on negotiations [18], deals [30], consensus [27], interaction protocols (e.g., <ref> [2] </ref>), as well as many other forms of conflict resolution can be viewed as handling this very delicate and complex aspect of the design of a social system. 4 Logical Reasoning about Social Systems The previous sections introduced and investigated basic issues in artificial social systems and their design. <p> In spite of the generality of our work, we wish to emphasize that our work in no way diminishs the crucial importance of mechanisms for interaction and communication among agents, nor the significance of the study of effective representations for agents. Some of the work developed in LIFIA <ref> [2, 9] </ref> provides considerable progress in these complementary directions. The discussion of various ways of modeling agents is of significant importance to the coordination between agents. Further study of artificial social systems may need to take various representation levels into account while addressing the construction of useful social laws. <p> Indeed, our discussion on high-level social laws is in the spirit of the discussion on bridging the gap between intentional and reactive agents in [9]. Moreover, as we explained in Section 3.3, elaborated communication and negotiation mechanisms (as discussed in <ref> [2] </ref>) may serve as essential components of a social law. Our work does not take into account the incentives agents have for cooperation.
Reference: [3] <editor> A. H. Bond and L. Gasser. </editor> <booktitle> Readings in Distributed Artificial Intelligence. </booktitle> <publisher> Ablex Publishing Corporation, </publisher> <year> 1988. </year>
Reference-contexts: Tradeoffs involved in the design of multi-agent systems that this approach uncovers are presented, and a methodology for design based on this approach is offered. Various issues of concern to the distributed/decentralized AI communities (DAI/DzAI) <ref> [3, 7, 8] </ref> are shown to fit naturally into the artificial social systems framework. Finally, we present semantics and a formal logical syntax in which reasoning about such systems can be carried out. <p> The design of such environments is generally a very difficult problem. We can consider the fundamental problem of the field of distributed/decentralized artificial intelligence (DAI/DzAI) <ref> [3, 7, 5] </ref> to be how to design artificial agents and environments for them to operate in. For such a design to be good, it should allow the agents to fruitfully 10 coexist and effectively function to obtain particular goals of interest.
Reference: [4] <author> C. Castelfranchi. </author> <title> Social Power: A Point Missed in Multi-Agent, </title> <editor> DAI and HCI. In Y. Demazeau and J.P. Muller, editors, </editor> <booktitle> Decentralized AI, </booktitle> <pages> pages 49-62. </pages> <address> North-Holland/Elsevier, </address> <year> 1990. </year>
Reference-contexts: Moreover, as we explained in Section 3.3, elaborated communication and negotiation mechanisms (as discussed in [2]) may serve as essential components of a social law. Our work does not take into account the incentives agents have for cooperation. Some of the work in CNR <ref> [6, 4] </ref> has been concerned with issues such as defining goal adoption as a basic form of cooperation, and with the effect of social power on cooperation among agents.
Reference: [5] <author> C. Castelfranchi and E. Werner. </author> <title> Artificial Social Systems. From Reactive to Intentional Agents, </title> <year> 1992. </year>
Reference-contexts: The design of such environments is generally a very difficult problem. We can consider the fundamental problem of the field of distributed/decentralized artificial intelligence (DAI/DzAI) <ref> [3, 7, 5] </ref> to be how to design artificial agents and environments for them to operate in. For such a design to be good, it should allow the agents to fruitfully 10 coexist and effectively function to obtain particular goals of interest.
Reference: [6] <author> R. Conte, M. Miceli, and C. Castelfranchi. </author> <title> Limites and Levels of Cooperation: Disentangling Various Types of Prosocial Interaction. </title> <editor> In Y. Demazeau and J.P. Muller, editors, </editor> <booktitle> Decentralized AI 2, </booktitle> <pages> pages 147-157. </pages> <address> North-Holland/Elsevier, </address> <year> 1991. </year>
Reference-contexts: Moreover, as we explained in Section 3.3, elaborated communication and negotiation mechanisms (as discussed in [2]) may serve as essential components of a social law. Our work does not take into account the incentives agents have for cooperation. Some of the work in CNR <ref> [6, 4] </ref> has been concerned with issues such as defining goal adoption as a basic form of cooperation, and with the effect of social power on cooperation among agents.
Reference: [7] <editor> Y. Demazeau and J.P. Muller. </editor> <booktitle> Decentralized AI. </booktitle> <address> North Holland/Elsevier, </address> <year> 1990. </year> <month> 26 </month>
Reference-contexts: Tradeoffs involved in the design of multi-agent systems that this approach uncovers are presented, and a methodology for design based on this approach is offered. Various issues of concern to the distributed/decentralized AI communities (DAI/DzAI) <ref> [3, 7, 8] </ref> are shown to fit naturally into the artificial social systems framework. Finally, we present semantics and a formal logical syntax in which reasoning about such systems can be carried out. <p> The design of such environments is generally a very difficult problem. We can consider the fundamental problem of the field of distributed/decentralized artificial intelligence (DAI/DzAI) <ref> [3, 7, 5] </ref> to be how to design artificial agents and environments for them to operate in. For such a design to be good, it should allow the agents to fruitfully 10 coexist and effectively function to obtain particular goals of interest.
Reference: [8] <editor> Y. Demazeau and J.P. Muller. </editor> <booktitle> Decentralized AI 2. </booktitle> <address> North Holland/Elsevier, </address> <year> 1991. </year>
Reference-contexts: Tradeoffs involved in the design of multi-agent systems that this approach uncovers are presented, and a methodology for design based on this approach is offered. Various issues of concern to the distributed/decentralized AI communities (DAI/DzAI) <ref> [3, 7, 8] </ref> are shown to fit naturally into the artificial social systems framework. Finally, we present semantics and a formal logical syntax in which reasoning about such systems can be carried out.
Reference: [9] <author> Y. Demazeau and J.P. Muller. </author> <title> From Reactive to Intentional Agents. </title> <editor> In Y. Demazeau and J.P. Muller, editors, </editor> <booktitle> Decentralized AI 2, </booktitle> <pages> pages 3-10. </pages> <address> North-Holland/Elsevier, </address> <year> 1991. </year>
Reference-contexts: In spite of the generality of our work, we wish to emphasize that our work in no way diminishs the crucial importance of mechanisms for interaction and communication among agents, nor the significance of the study of effective representations for agents. Some of the work developed in LIFIA <ref> [2, 9] </ref> provides considerable progress in these complementary directions. The discussion of various ways of modeling agents is of significant importance to the coordination between agents. Further study of artificial social systems may need to take various representation levels into account while addressing the construction of useful social laws. <p> Further study of artificial social systems may need to take various representation levels into account while addressing the construction of useful social laws. Indeed, our discussion on high-level social laws is in the spirit of the discussion on bridging the gap between intentional and reactive agents in <ref> [9] </ref>. Moreover, as we explained in Section 3.3, elaborated communication and negotiation mechanisms (as discussed in [2]) may serve as essential components of a social law. Our work does not take into account the incentives agents have for cooperation.
Reference: [10] <author> J. Doyle and M.P. Wellman. </author> <title> Impediments to Universal Preference-Based Default Theories. </title> <booktitle> In Proceedings of the 1st conference on principles of knowledge representation and reasoning, </booktitle> <year> 1989. </year>
Reference-contexts: Society metaphors have been proposed before in the AI literature, albeit in somewhat different contexts. Minsky uses a society metaphor in his work on the society of mind [22]. 19 The notion of social choice is an important element in e.g. the work of Jon Doyle <ref> [10] </ref>. Finally, social metaphors appear also in the works of Fox, Kornfeld and Hewitt, Malone, and Simon ([12], [17], [20], [36]) concerning organization theory. We treat the notion of an artificial social system in a relatively narrow sense, and with a particular point of view in mind.
Reference: [11] <author> Edmund H. Durfee, Victor R. Lesser, and Daniel D. Corkill. </author> <title> Coherent Cooperation Among Communicating Problem Solvers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36 </volume> <pages> 1275-1291, </pages> <year> 1987. </year>
Reference-contexts: This includes work in the areas of organization theory (see [20],[12],[20]), team theory ([21]), and DAI (see for example <ref> [11] </ref>). The related work in these areas of research is especially concerned with the design of agents' roles and communication structures that enable cooperative achievement of a common goal.
Reference: [12] <author> M. S. Fox. </author> <title> An organizational view of distributed systems. </title> <journal> IEEE Trans. Sys., Man., Cyber., </journal> <volume> 11 </volume> <pages> 70-80, </pages> <year> 1981. </year>
Reference: [13] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability A Guide to the Theory of NP-completeness. W.H. </title> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference-contexts: We now prove that the problem is NP-hard by a reduction from 3-SAT <ref> [13] </ref>. Assume we are given an instance of 3-SAT, and let k be the number of clauses in . We assume that the dependent automata has two identical agents.
Reference: [14] <author> G. Gaspar. </author> <title> Communication and Belief Changes in a Society of Agents: Towards a Formal Model of an Automanous Agent. </title> <editor> In Y. Demazeau and J.P. Muller, editors, </editor> <booktitle> Decentralized AI 2, </booktitle> <pages> pages 245-255. </pages> <address> North-Holland/Elsevier, </address> <year> 1991. </year>
Reference-contexts: In sufficiently complex situations, however, some communication and explicit coordination between the agents is inevitable, and in others it may be desirable. Indeed, a central concern in distributed and decentralized AI is the design of communication and interaction protocols <ref> [2, 14] </ref>. Our framework applies equally well to such situations. For agents in a multi-agent setting to communicate, they need to have a common language, specific protocols for interaction, and conventions for when and how these are used.
Reference: [15] <author> M. P. Georgeff. </author> <title> Communication and Interaction in Multi-Agent Planning. </title> <booktitle> In Proc. of AAAI-83, </booktitle> <pages> pages 125-129, </pages> <year> 1983. </year>
Reference-contexts: Much work has been devoted to an explicit and formal study of the centralized approach and of the on-line resolution of conflicts (e.g., [19], <ref> [15] </ref>, [37], [30],[18]). Our work is the first to discuss explicitly and formally the computational mechanism that applies for non-centralized intermediate solutions.
Reference: [16] <author> J. Halpern and Y. Moses. </author> <title> Knowledge and common knowledge in a distributed environment. </title> <type> Technical Report RJ 4421, </type> <institution> IBM, </institution> <year> 1984. </year>
Reference-contexts: Roughly speaking, we are thinking of these along the lines of the situated automata literature [31], and the related work on knowledge in distributed systems <ref> [16] </ref>. The K i relations are intended to capture the agents' knowledge. The possible external inputs I are intended to capture messages an agent may receive from outside the system.
Reference: [17] <author> W. A. Kornfeld and C. E. Hewitt. </author> <title> The scientific community metaphor. </title> <journal> IEEE Trans. Sys., Man., Cyber., </journal> <volume> 11 </volume> <pages> 24-33, </pages> <year> 1981. </year>
Reference-contexts: Minsky uses a society metaphor in his work on the society of mind [22]. 19 The notion of social choice is an important element in e.g. the work of Jon Doyle [10]. Finally, social metaphors appear also in the works of Fox, Kornfeld and Hewitt, Malone, and Simon ([12], <ref> [17] </ref>, [20], [36]) concerning organization theory. We treat the notion of an artificial social system in a relatively narrow sense, and with a particular point of view in mind.
Reference: [18] <author> S. Kraus and J. Wilkenfeld. </author> <title> The Function of Time in Cooperative Negotiations. </title> <booktitle> In Proc. of AAAI-91, </booktitle> <pages> pages 179-184, </pages> <year> 1991. </year>
Reference-contexts: A comprehensive social system must therefore also contain a component that describes how conflicts are to be handled once they occur. The work on negotiations <ref> [18] </ref>, deals [30], consensus [27], interaction protocols (e.g., [2]), as well as many other forms of conflict resolution can be viewed as handling this very delicate and complex aspect of the design of a social system. 4 Logical Reasoning about Social Systems The previous sections introduced and investigated basic issues in
Reference: [19] <author> Amy. L. Lansky. </author> <title> Localized Event-Based Reasoning for Multiagent Domains. </title> <type> Technical Report 423, </type> <institution> SRI International, </institution> <year> 1988. </year>
Reference-contexts: Much work has been devoted to an explicit and formal study of the centralized approach and of the on-line resolution of conflicts (e.g., <ref> [19] </ref>, [15], [37], [30],[18]). Our work is the first to discuss explicitly and formally the computational mechanism that applies for non-centralized intermediate solutions.
Reference: [20] <author> T. W. Malone. </author> <title> Modeling Coordination in Organizations and Markets. </title> <journal> Management Science, </journal> <volume> 33(10) </volume> <pages> 1317-1332, </pages> <year> 1987. </year>
Reference-contexts: Finally, social metaphors appear also in the works of Fox, Kornfeld and Hewitt, Malone, and Simon ([12], [17], <ref> [20] </ref>, [36]) concerning organization theory. We treat the notion of an artificial social system in a relatively narrow sense, and with a particular point of view in mind.
Reference: [21] <author> Jacob Marschak and Roy Radner. </author> <title> Economic Theory of Teams. </title> <publisher> Yale University Press, </publisher> <year> 1972. </year>
Reference: [22] <author> M. Minsky. </author> <title> The Society of Mind. </title> <publisher> Simon and Schuster, </publisher> <year> 1986. </year>
Reference-contexts: For further discussion of this connection, see [35]. Society metaphors have been proposed before in the AI literature, albeit in somewhat different contexts. Minsky uses a society metaphor in his work on the society of mind <ref> [22] </ref>. 19 The notion of social choice is an important element in e.g. the work of Jon Doyle [10]. Finally, social metaphors appear also in the works of Fox, Kornfeld and Hewitt, Malone, and Simon ([12], [17], [20], [36]) concerning organization theory.
Reference: [23] <author> Y. Moses and Y. Shoham. </author> <title> Belief as Defeasible Knowledge. </title> <booktitle> In Proc. 11th International Joint Conference on Artificial Intelligence, </booktitle> <year> 1989. </year> <month> 27 </month>
Reference-contexts: The definition of the social belief operator B s i in clause (k) is an instance of "belief as defeasible knowledge", as defined in <ref> [23] </ref>. While B s i is a notion of belief, in that B s i ' may hold when ' does not, the definition of B s i in clause (k) gives us a rigorous semantic handle on when facts are believed, and when they are not.
Reference: [24] <author> Y. Moses and M. Tennenholtz. </author> <title> Artificial Social Systems Part I: Basic Principles. </title> <type> Technical Report CS90-12, </type> <institution> Weizmann Institute, </institution> <year> 1990. </year>
Reference-contexts: Our purpose in this work is to initiate the study of artificial social systems as an explicit and formal paradigm for design. This paper presents the notion of artificial social systems. It is based on the original manuscripts that presented this notion <ref> [24, 25, 38] </ref>. We describe how artificial social systems suggest an approach to the design of multi-agent systems. Tradeoffs involved in the design of multi-agent systems that this approach uncovers are presented, and a methodology for design based on this approach is offered. <p> Namely, we present a general logical framework for reasoning about social systems. This will enable to supply a general semantics for artificial social systems, and will enable formal logical reasoning about the elements of social systems. 4.1 The semantics of Artificial Social Systems As argued in <ref> [24] </ref>, providing a clear semantics for artificial social systems is a necessary step in their design. In particular, it will enable formal logical reasoning about social systems. In this section we gradually construct a model for an artificial social system.
Reference: [25] <author> Y. Moses and M. Tennenholtz. </author> <title> On Computational Aspects of Artificial Social Systems. </title> <booktitle> In the Proceedings of the Eleventh Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 267-283, </pages> <year> 1992. </year>
Reference-contexts: Our purpose in this work is to initiate the study of artificial social systems as an explicit and formal paradigm for design. This paper presents the notion of artificial social systems. It is based on the original manuscripts that presented this notion <ref> [24, 25, 38] </ref>. We describe how artificial social systems suggest an approach to the design of multi-agent systems. Tradeoffs involved in the design of multi-agent systems that this approach uncovers are presented, and a methodology for design based on this approach is offered.
Reference: [26] <author> C.H. Papadimitriou and J. Tsitsiklis. </author> <title> On the Complexity of Designing Distributed Protocols. </title> <journal> Information and Control, </journal> <volume> 53(3) </volume> <pages> 211-218, </pages> <year> 1982. </year>
Reference-contexts: The agents' actions and plans are ultimately performed on-line in the multi-agent system. Namely, an agent only two agents with only one goal, where the agents may have different local states, coincide with the computational problem discussed in <ref> [26] </ref>. 4 Details can be found in the Appendix. 8 must ultimately plan a course of action and carry it out with rather stringent constraints on the time, resources, and information available.
Reference: [27] <author> M. Pease, R. Shostak, and L. Lamport. </author> <title> Reaching agreement in the presence of faults. </title> <journal> Journal of the ACM, </journal> <volume> 27(2) </volume> <pages> 228-234, </pages> <year> 1980. </year>
Reference-contexts: A comprehensive social system must therefore also contain a component that describes how conflicts are to be handled once they occur. The work on negotiations [18], deals [30], consensus <ref> [27] </ref>, interaction protocols (e.g., [2]), as well as many other forms of conflict resolution can be viewed as handling this very delicate and complex aspect of the design of a social system. 4 Logical Reasoning about Social Systems The previous sections introduced and investigated basic issues in artificial social systems and
Reference: [28] <author> A. Pnueli and R. Rosner. </author> <title> Distributed Reactive Systems are Hard to Synthesize. </title> <booktitle> In Proc. 31th IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1990. </year>
Reference: [29] <author> P.G. Ramadge and W.M. Wonham. </author> <title> The Control of Discrete Event Systems. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77(1) </volume> <pages> 81-98, </pages> <month> January </month> <year> 1989. </year>
Reference: [30] <author> J. S. Rosenschein and M. R. Genesereth. </author> <title> Deals Among Rational Agents. </title> <booktitle> In Proc. 9th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 91-99, </pages> <year> 1985. </year>
Reference-contexts: A comprehensive social system must therefore also contain a component that describes how conflicts are to be handled once they occur. The work on negotiations [18], deals <ref> [30] </ref>, consensus [27], interaction protocols (e.g., [2]), as well as many other forms of conflict resolution can be viewed as handling this very delicate and complex aspect of the design of a social system. 4 Logical Reasoning about Social Systems The previous sections introduced and investigated basic issues in artificial social
Reference: [31] <author> S. J. Rosenschein. </author> <title> Formal Theories of Knowledge in AI and Robotics. </title> <journal> New Generation Computing, </journal> <volume> 3(3) </volume> <pages> 345-357, </pages> <year> 1985. </year>
Reference-contexts: The structure of the set W of possible worlds, and of the possible worlds themselves will be vitally important in any implementation of a multi-agent system. Roughly speaking, we are thinking of these along the lines of the situated automata literature <ref> [31] </ref>, and the related work on knowledge in distributed systems [16]. The K i relations are intended to capture the agents' knowledge. The possible external inputs I are intended to capture messages an agent may receive from outside the system.
Reference: [32] <author> Y. Shoham and M. Tennenholtz. </author> <title> Emergent Conventions in Multi-Agent Systems: initial experimental results and observations. </title> <booktitle> In Proc. of the 3rd International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 225-231, </pages> <year> 1992. </year>
Reference-contexts: In addition, that work discusses the conditions under which the problem of algorithmically synthesizing a social law becomes tractable. This work has been extended to non-homogeneous dynamic social structures in [39]. In a complementary work (see <ref> [32] </ref>) Shoham and Tennenholtz considered the interesting case of conventions and laws that are not determined off-line before the initiation of activity, but rather emerge during the on-line activity of the system. Their research concentrates on understanding how different agent behaviors and system characteristics affect the efficiency of convention evolution.
Reference: [33] <author> Y. Shoham and M. Tennenholtz. </author> <title> On the Synthesis of Useful Social Laws for Artificial Agent Societies. </title> <booktitle> In Proc. of AAAI-92, </booktitle> <pages> pages 276-281, </pages> <year> 1992. </year>
Reference-contexts: Finally, we present semantics and a formal logical syntax in which reasoning about such systems can be carried out. This work has been followed by a number of papers that use and extend the notion of artificial social systems (e.g., <ref> [34, 33, 39] </ref>). This paper is organized as follows. In the next section we introduce the idea of artificial social systems in the framework of a simple but widely applicable model. In Section 3 we discuss a number of essential aspects in the design of a social system. <p> This is an example of how appropriate off-line design of social laws guarantees very effective on-line behavior. In <ref> [33] </ref> the authors present a novel model that defines multi-agent systems while referring explicitly to the notion of social law. In the framework of this model they investigate the automatic synthesis of useful social laws and give precise conditions under which the problem becomes tractable.
Reference: [34] <author> Y. Shoham and M. Tennenholtz. </author> <title> On Traffic Laws for Mobile Robots. </title> <booktitle> Proc. of the 1st Conference on AI planning systems (AIPS-92), </booktitle> <year> 1992. </year>
Reference-contexts: Finally, we present semantics and a formal logical syntax in which reasoning about such systems can be carried out. This work has been followed by a number of papers that use and extend the notion of artificial social systems (e.g., <ref> [34, 33, 39] </ref>). This paper is organized as follows. In the next section we introduce the idea of artificial social systems in the framework of a simple but widely applicable model. In Section 3 we discuss a number of essential aspects in the design of a social system. <p> Extending work on Artificial Social Systems to include a treatment of cooperation incentives is one of the most challenging directions for future work. A particular case study of the design of a social law is presented in <ref> [34] </ref>. There, the authors investigate traffic laws for mobile robots that operate on an n by n grid.
Reference: [35] <author> Y. Shoham and M. Tennenholtz. </author> <title> Social Laws for Artificial Agent Societies: Off-line Design. </title> <journal> Artificial Inteligence, </journal> <volume> 73, </volume> <year> 1995. </year>
Reference-contexts: This two-stage process can be used as a methodology for the design of discrete event systems as well. For further discussion of this connection, see <ref> [35] </ref>. Society metaphors have been proposed before in the AI literature, albeit in somewhat different contexts. Minsky uses a society metaphor in his work on the society of mind [22]. 19 The notion of social choice is an important element in e.g. the work of Jon Doyle [10].
Reference: [36] <author> Herbert. A. Simon. </author> <booktitle> The Sciences of the Artificial. </booktitle> <publisher> The MIT Press, </publisher> <year> 1981. </year>
Reference-contexts: Finally, social metaphors appear also in the works of Fox, Kornfeld and Hewitt, Malone, and Simon ([12], [17], [20], <ref> [36] </ref>) concerning organization theory. We treat the notion of an artificial social system in a relatively narrow sense, and with a particular point of view in mind.
Reference: [37] <author> C.J. Stuart. </author> <title> An Implementation of a Multi-Agent Plan Synchronizer. </title> <booktitle> In Proc. 9th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1031-1033, </pages> <year> 1985. </year>
Reference-contexts: Much work has been devoted to an explicit and formal study of the centralized approach and of the on-line resolution of conflicts (e.g., [19], [15], <ref> [37] </ref>, [30],[18]). Our work is the first to discuss explicitly and formally the computational mechanism that applies for non-centralized intermediate solutions.
Reference: [38] <author> M. Tennenholtz. </author> <title> Efficient Representation and Reasoning in Multi-Agent Systems. </title> <type> PhD thesis, </type> <institution> Weizmann Institute, Israel, </institution> <year> 1991. </year>
Reference-contexts: Our purpose in this work is to initiate the study of artificial social systems as an explicit and formal paradigm for design. This paper presents the notion of artificial social systems. It is based on the original manuscripts that presented this notion <ref> [24, 25, 38] </ref>. We describe how artificial social systems suggest an approach to the design of multi-agent systems. Tradeoffs involved in the design of multi-agent systems that this approach uncovers are presented, and a methodology for design based on this approach is offered.
Reference: [39] <author> M. Tennenholtz. </author> <title> On Computational Social Laws for Dynamic Non-Homogeneous Social Structurs. </title> <note> To appear in JETAI, 1994. 28 </note>
Reference-contexts: Finally, we present semantics and a formal logical syntax in which reasoning about such systems can be carried out. This work has been followed by a number of papers that use and extend the notion of artificial social systems (e.g., <ref> [34, 33, 39] </ref>). This paper is organized as follows. In the next section we introduce the idea of artificial social systems in the framework of a simple but widely applicable model. In Section 3 we discuss a number of essential aspects in the design of a social system. <p> In addition, that work discusses the conditions under which the problem of algorithmically synthesizing a social law becomes tractable. This work has been extended to non-homogeneous dynamic social structures in <ref> [39] </ref>. In a complementary work (see [32]) Shoham and Tennenholtz considered the interesting case of conventions and laws that are not determined off-line before the initiation of activity, but rather emerge during the on-line activity of the system.
Reference: [40] <author> E. O. Wilson. </author> <title> The insect societies. </title> <publisher> Harvard University Press, </publisher> <year> 1971. </year> <month> 29 </month>
Reference-contexts: In human societies, for example, the social system consists of the legal system, together with various conventions regarding how people behave. Societies of animals, too, have conventions of behavior that constitute their social system <ref> [40] </ref>. We can also view conventions and restrictions employed in artificial multi-agent systems as constituting a social system. Our thesis, however, is that artificial social systems should be treated explicitly as a major component of the design of multi-agent systems.
References-found: 40

