URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-91-1017/CS-TR-91-1017.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-91-1017/
Root-URL: http://www.cs.wisc.edu
Email: fmt,naughtong@cs.wisc.edu  
Title: A Stochastic Approach for Clustering in Object Bases  
Author: Manolis M. Tsangaris and Jeffrey F. Naughton 
Date: October 22, 1991  
Affiliation: Department of Computer Sciences University of Wisconsin-Madison  
Pubnum: Technical Report 1017-1991  
Abstract: Object clustering has long been recognized as important to the performance of object bases, but in most work to date, it is not clear exactly what is being optimized or how optimal are the solutions obtained. We give a rigorous treatment of a fundamental problem in clustering: given an object base and a probabilistic description of the expected access patterns, what is an optimal object clustering, and how can this optimal clustering be found or approximated? We present a system model for the clustering problem and discuss two models for access patterns in the system. For the first, exact optimal clustering strategies can be found; for the second, we show that the problem is NP-complete, but that it is an instance of a well-studied graph partitioning problem. We propose a new clustering algorithm based upon Kernighan's heuristic graph partitioning algorithm, and present an experimental comparison of this new clustering algorithm with several previously proposed clustering algorithms. fl This work was supported by an NSF grant number IRI-8909795, TOPAZ DCR 8521228, and partially by a NATO fellowship. y A shorter version of this paper will appear in SIGMOD 1991. 
Abstract-found: 1
Intro-found: 1
Reference: [All78] <author> Arnold O. Allen. </author> <title> Probability, Statistics, and Queueing Theory, with Computer Science Applications. </title> <publisher> Academic Press, </publisher> <year> 1978. </year>
Reference-contexts: In other words, all their (local) request streams follow the same statistical model. Then, the statistical characteristics of the combined request stream depend a lot on the queueing policy used (FIFO, Priority based, etc.) and on the load of the system <ref> [All78] </ref>. The heavier the load of the system, the more random the global request stream is. Then, in moderately to highly loaded multi-client system the global request stream loses its serial characteristics, and can be described adequately by an IID model.
Reference: [Bar84] <author> Earl R. Barnes. </author> <title> Partitioning the nodes of a graph. </title> <booktitle> In Proceedings of the Fifth Quadrennial International Conference on the Theory of Graphs with special emphasis on Algorithms for Computer Science Applications, </booktitle> <pages> pages 57-72, </pages> <address> Kalamazoo,Michigan, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: J is the upper limit for the partition W SS sought. Although the problem is NP-complete, there are some good heuristic algorithms to find close-to-optimal solutions fast. Notably, Kernighan's partitioning [KL70] is a good O (n 2:4 ) heuristic algorithm. <ref> [Bar84] </ref> and [BVJ84] propose asymptotically faster but more complicated algorithms. Since edge costs cannot be arbitrary (they come from the vertex stationary and edge transition probabilities), it is possible that special purpose partitioning algorithms can be used.
Reference: [BD90] <author> Veronique Benzaken and Claude Delobel. </author> <title> Enhancing performance in a persistent object store: Clustering strategies in O 2 . Technical Report 50-90, </title> <type> Altair, </type> <month> August </month> <year> 1990. </year>
Reference-contexts: Dynamic methods (Cactis [HK89], ObServer [HZ87]) gather statistics about reference patterns, and try to find a "good" clustering based upon these statistics, while still other techniques (O 2 <ref> [BD90] </ref>, WDFS in LOOM [Sta84]) can best be thought of as a hybrid of the syntactic and dynamic methods. The clustering criteria used in each of these types of methods are heuristics whose effect on the performance of the system is not known with any certainty.
Reference: [BVJ84] <author> Earl R. Barnes, A. Vannelli, and J.Q.Walker. </author> <title> A new procedure for partitioning the nodes of a graph. </title> <type> Technical Report RC 10561, </type> <institution> IBM Thomas J. Watson Research Center, </institution> <month> June </month> <year> 1984. </year>
Reference-contexts: J is the upper limit for the partition W SS sought. Although the problem is NP-complete, there are some good heuristic algorithms to find close-to-optimal solutions fast. Notably, Kernighan's partitioning [KL70] is a good O (n 2:4 ) heuristic algorithm. [Bar84] and <ref> [BVJ84] </ref> propose asymptotically faster but more complicated algorithms. Since edge costs cannot be arbitrary (they come from the vertex stationary and edge transition probabilities), it is possible that special purpose partitioning algorithms can be used.
Reference: [CAC + 84] <author> W. P. Cockshot, M. P. Atkinson, K. J. Chisholm, P. J. Bailey, and R. Morrison. </author> <title> Persistent object managment system. </title> <journal> Software Practice and Experience, </journal> <year> 1984. </year>
Reference-contexts: Previous work on object clustering can be divided into several categories. Methods that use programmer hints (E and EXODUS [RC88], Semantic Clustering [SS90]) rely on the skill of the programmer and the programmer's understanding of the problem. Syntactic methods (PS-Algol <ref> [CAC + 84] </ref>, LOOM-Smalltalk [Sta84]) determine a clustering strategy based solely upon the static structure of the object base.
Reference: [Cat88] <author> R. G. G. Cattell. </author> <title> Object oriented performance measurement. </title> <booktitle> In Proceedings of the 2nd International Workshop on OODBMS, </booktitle> <pages> pages 364-367, </pages> <address> FRG, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: Since the field of object oriented databases is very young and only a few operational systems exist, we decided to use object references from a benchmark program instead of actual system traces. We chose the Sun Engineering Benchmark <ref> [Cat88] </ref> because it is widely known, and it provides a common point of reference for other studies as well [DFMV90].
Reference: [Den68] <author> P. J. Denning. </author> <title> The working set model of program behavior. </title> <journal> Comm. ACM, </journal> <volume> 11(5) </volume> <pages> 323-333, </pages> <month> May </month> <year> 1968. </year>
Reference-contexts: A parametrized metric for locality is the working set size (W SS (M )) <ref> [Den68] </ref>.
Reference: [DFMV90] <author> David J. DeWitt, Philippe Futtersack, David Maier, and Fernando Velez. </author> <title> A study of three alternative workstation server architectures for object oriented database systems. </title> <type> Technical Report 936, </type> <institution> University of Wisconsin, Computer Sciences Dept., </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: We chose the Sun Engineering Benchmark [Cat88] because it is widely known, and it provides a common point of reference for other studies as well <ref> [DFMV90] </ref>. Although it is an artificial example of an object store client, and does not have much of an object oriented flavor (it is written in C), it still produces 14 some interesting styles of object access patterns.
Reference: [DK90] <author> Pamela Drew and Roger King. </author> <title> The performance and utility of the CACTIS implementation algorithms. </title> <booktitle> In Proceedings of the 16-th VLDB Conference, </booktitle> <pages> pages 135-147, </pages> <address> Brisbane, Australia, </address> <year> 1990. </year>
Reference-contexts: SOG.WDFS has linear cost O (N ). OG.BFS, OG.DFS and SOG.WDFS have been proposed in [Sta84] for clustering Smalltalk objects. Finally, the SOG.CACTIS is based upon the clustering algorithm proposed in [HK89]. Quoting from <ref> [DK90] </ref>, Clustering starts by placing the most frequently referenced object in the database in an empty block. The system then considers all relationships that go from an object inside the block to an object outside of the block.
Reference: [GJ79] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability. </title> <publisher> W.H.Freeman and Company, </publisher> <year> 1979. </year>
Reference-contexts: It is interesting to observe that clustering scheme C 2 = f [si]; [mp]; [le]g minimizes the W SS K (2) for the example of Figure 1. The weighted graph partitioning problem has been studied previously. According to <ref> [GJ79] </ref>, deciding if there is a partition with cost J, is an NP-complete problem.
Reference: [GS73] <author> David D. Grossman and Harvey F. Silverman. </author> <title> Placement of records on a secondary storage device to minimize access time. </title> <journal> JACM, </journal> <volume> 20(3) </volume> <pages> 429-438, </pages> <month> July </month> <year> 1973. </year>
Reference-contexts: n+1 ) = c (jf n f n+1 j) (2) Additionally, some monotonicity restrictions to the function c (n) exist, so that the longer the head travels the greater the cost is: c (0) c (n) c (m); 0 n m The optimal clustering can still be found (see [YW73], <ref> [GS73] </ref> and [Won83]). The partition component of the optimal mapping remains the same as before (probability ranking), but the permutation is not the identity any more.
Reference: [HK89] <author> Scott E. Hudson and Roger King. Cactis: </author> <title> A self-adaptive, concurrent implementation of an object-oriented database management system. </title> <journal> ACM Transactions on Data Base Systems, </journal> <volume> 14(3) </volume> <pages> 291-321, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Syntactic methods (PS-Algol [CAC + 84], LOOM-Smalltalk [Sta84]) determine a clustering strategy based solely upon the static structure of the object base. Dynamic methods (Cactis <ref> [HK89] </ref>, ObServer [HZ87]) gather statistics about reference patterns, and try to find a "good" clustering based upon these statistics, while still other techniques (O 2 [BD90], WDFS in LOOM [Sta84]) can best be thought of as a hybrid of the syntactic and dynamic methods. <p> SOG.WDFS has linear cost O (N ). OG.BFS, OG.DFS and SOG.WDFS have been proposed in [Sta84] for clustering Smalltalk objects. Finally, the SOG.CACTIS is based upon the clustering algorithm proposed in <ref> [HK89] </ref>. Quoting from [DK90], Clustering starts by placing the most frequently referenced object in the database in an empty block. The system then considers all relationships that go from an object inside the block to an object outside of the block.
Reference: [HZ87] <author> M. F. Hornick and S. B. Zdonick. </author> <title> A shared, segmented memory system for an object-oriented database. </title> <journal> ACM Transactions on Office Information Systems, </journal> <volume> 5(1), </volume> <year> 1987. </year> <month> 30 </month>
Reference-contexts: Syntactic methods (PS-Algol [CAC + 84], LOOM-Smalltalk [Sta84]) determine a clustering strategy based solely upon the static structure of the object base. Dynamic methods (Cactis [HK89], ObServer <ref> [HZ87] </ref>) gather statistics about reference patterns, and try to find a "good" clustering based upon these statistics, while still other techniques (O 2 [BD90], WDFS in LOOM [Sta84]) can best be thought of as a hybrid of the syntactic and dynamic methods.
Reference: [KL70] <author> B.W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> Bell System Technical Journal, </journal> <volume> 49(2) </volume> <pages> 291-307, </pages> <month> February </month> <year> 1970. </year>
Reference-contexts: J is the upper limit for the partition W SS sought. Although the problem is NP-complete, there are some good heuristic algorithms to find close-to-optimal solutions fast. Notably, Kernighan's partitioning <ref> [KL70] </ref> is a good O (n 2:4 ) heuristic algorithm. [Bar84] and [BVJ84] propose asymptotically faster but more complicated algorithms. Since edge costs cannot be arbitrary (they come from the vertex stationary and edge transition probabilities), it is possible that special purpose partitioning algorithms can be used.
Reference: [OS90] <author> E. Omiecinski and P. Scheurmann. </author> <title> Parallel algorithm for record clustering. </title> <journal> ACM Transactions on Data Base Systems, </journal> <month> December </month> <year> 1990. </year>
Reference-contexts: Additionally, we found that some non-backtracking heuristic algorithms with O (N log N ) complexity work well, and they appear to approximate SMC.KERN in terms of performance. Moreover, such partitioning algorithms can be efficiently implemented on parallel architectures (as in <ref> [OS90] </ref>). Finally, we think that performance improvements of SMC.KERN were substantial even on the TRAVERSAL and DIVING workloads where there exist higher order access dependencies 15 and conflicting access patterns between the forward and backward traversals.
Reference: [PS82] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice-Hall Inc, </publisher> <year> 1982. </year>
Reference: [RC88] <author> E. Richardson and M. J. Carey. </author> <title> Persistence in the E language: Issues and implementation. </title> <type> Technical Report 791, </type> <institution> University of Wisconsin-Madison, CS Department, </institution> <month> March </month> <year> 1988. </year>
Reference-contexts: However, the fundamental question of what a "good clustering strategy" means underlies all these other questions, hence is worthy of study in its own right. Previous work on object clustering can be divided into several categories. Methods that use programmer hints (E and EXODUS <ref> [RC88] </ref>, Semantic Clustering [SS90]) rely on the skill of the programmer and the programmer's understanding of the problem. Syntactic methods (PS-Algol [CAC + 84], LOOM-Smalltalk [Sta84]) determine a clustering strategy based solely upon the static structure of the object base. <p> This algorithm attempts to minimize the number of clusters "probable" DFS traversals will see. Edge heat information can be supplied by the compiler based on static usage information (like in Semantic Clustering [SS90]), or as user hints (like in E <ref> [RC88] </ref>). SOG.WDFS has linear cost O (N ). OG.BFS, OG.DFS and SOG.WDFS have been proposed in [Sta84] for clustering Smalltalk objects. Finally, the SOG.CACTIS is based upon the clustering algorithm proposed in [HK89].
Reference: [SS90] <author> Karen Shannon and Richard Snodgrass. </author> <title> Semantic clustering. </title> <booktitle> In Proceedings of the 4-th Int'l Workshop in Persistent Object Systems, </booktitle> <pages> pages 361-374, </pages> <address> Martha's Vineyard, MA, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: However, the fundamental question of what a "good clustering strategy" means underlies all these other questions, hence is worthy of study in its own right. Previous work on object clustering can be divided into several categories. Methods that use programmer hints (E and EXODUS [RC88], Semantic Clustering <ref> [SS90] </ref>) rely on the skill of the programmer and the programmer's understanding of the problem. Syntactic methods (PS-Algol [CAC + 84], LOOM-Smalltalk [Sta84]) determine a clustering strategy based solely upon the static structure of the object base. <p> This algorithm attempts to minimize the number of clusters "probable" DFS traversals will see. Edge heat information can be supplied by the compiler based on static usage information (like in Semantic Clustering <ref> [SS90] </ref>), or as user hints (like in E [RC88]). SOG.WDFS has linear cost O (N ). OG.BFS, OG.DFS and SOG.WDFS have been proposed in [Sta84] for clustering Smalltalk objects. Finally, the SOG.CACTIS is based upon the clustering algorithm proposed in [HK89].
Reference: [Sta84] <author> James W. Stamos. </author> <title> Static grouping of small objects to enhance performance of a paged virtual memory. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(2) </volume> <pages> 155-180, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: Previous work on object clustering can be divided into several categories. Methods that use programmer hints (E and EXODUS [RC88], Semantic Clustering [SS90]) rely on the skill of the programmer and the programmer's understanding of the problem. Syntactic methods (PS-Algol [CAC + 84], LOOM-Smalltalk <ref> [Sta84] </ref>) determine a clustering strategy based solely upon the static structure of the object base. Dynamic methods (Cactis [HK89], ObServer [HZ87]) gather statistics about reference patterns, and try to find a "good" clustering based upon these statistics, while still other techniques (O 2 [BD90], WDFS in LOOM [Sta84]) can best be <p> + 84], LOOM-Smalltalk <ref> [Sta84] </ref>) determine a clustering strategy based solely upon the static structure of the object base. Dynamic methods (Cactis [HK89], ObServer [HZ87]) gather statistics about reference patterns, and try to find a "good" clustering based upon these statistics, while still other techniques (O 2 [BD90], WDFS in LOOM [Sta84]) can best be thought of as a hybrid of the syntactic and dynamic methods. The clustering criteria used in each of these types of methods are heuristics whose effect on the performance of the system is not known with any certainty. <p> Edge heat information can be supplied by the compiler based on static usage information (like in Semantic Clustering [SS90]), or as user hints (like in E [RC88]). SOG.WDFS has linear cost O (N ). OG.BFS, OG.DFS and SOG.WDFS have been proposed in <ref> [Sta84] </ref> for clustering Smalltalk objects. Finally, the SOG.CACTIS is based upon the clustering algorithm proposed in [HK89]. Quoting from [DK90], Clustering starts by placing the most frequently referenced object in the database in an empty block.
Reference: [TN90] <author> Manolis M. Tsangaris and Jeffrey F. Naughton. Amnesia: </author> <title> a stochastic access model for object stores. </title> <type> Unpublished Manuscript, </type> <institution> University of Wisconsin-Madison, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: Since edge costs cannot be arbitrary (they come from the vertex stationary and edge transition probabilities), it is possible that special purpose partitioning algorithms can be used. In fact we are planning to investigate some special purpose algorithms in the future. 6 We have shown in <ref> [TN90] </ref> that minimizing W SS for M &gt; 2 is a hypergraph partitioning problem. 13 b: LOOKUP c: TRAVERSAL d: DIVING random permutation normal distribution uniform distribution uniform distribution a: Node connections range Forward pointers Backward pointers ii-1 i+1 j 4 Experimental Results In this section we give some results from <p> Much important work remains. Some of the assumptions that we have made need to be further examined. For example, the modeling of client requests remains open, and alternative models (both stochastic and syntactic) should be investigated <ref> [TN90] </ref>. Answers to questions such as: "how well does the SMC model approximate real-world POB application reference patterns" must await experience with running systems; using the foundation laid by the work presented here, we will be able to make use of these answers as they become available.
Reference: [VC90] <author> Paul Vongsathorn and Scott D. Carson. </author> <title> A system for adaptive disk rearrangement. </title> <journal> Software Practice and Experience, </journal> <volume> 20(3) </volume> <pages> 225-242, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: In this arrangement, the hottest frames are placed in the middle of the disk. The two next to the hottest frame are placed adjacent to it and the process is repeated until all the frames have been assigned. An adaptive system described in <ref> [VC90] </ref>, uses the above method to dynamically permute disk blocks, so that the average observed access time is minimized. During an observation period, disk block accesses due to the Unix filesystem are measured, and an IID model is estimated from counting the accesses.
Reference: [Won83] <author> C.K. Wong. </author> <title> Algorithmic Studies in Mass Storage Systems. </title> <publisher> Computer Science Press, </publisher> <year> 1983. </year>
Reference-contexts: = c (jf n f n+1 j) (2) Additionally, some monotonicity restrictions to the function c (n) exist, so that the longer the head travels the greater the cost is: c (0) c (n) c (m); 0 n m The optimal clustering can still be found (see [YW73], [GS73] and <ref> [Won83] </ref>). The partition component of the optimal mapping remains the same as before (probability ranking), but the permutation is not the identity any more.
Reference: [YW73] <author> P.C. Yue and C.K. Wong. </author> <title> On the optimality of the probability ranking scheme in storage applications. </title> <journal> JACM, </journal> <volume> 20(4) </volume> <pages> 624-633, </pages> <month> October </month> <year> 1973. </year> <month> 31 </month>
Reference-contexts: by virtue of the law of large numbers and assuming ergodicity 3 of the x n 's, it converges to the expected value of the random variable Q: T = lim T n = E (Q (x n1 ; x n )) A similar cost formula has been proposed elsewhere <ref> [YW73] </ref>. The definition of T is general enough to approximate many real world situations like disk accesses. <p> Because of buffering, there is no cost if the same object is requested again. The optimal clustering scheme in the above case due to <ref> [YW73] </ref>, is known as the probability ranking scheme. <p> f n+1 ) = c (jf n f n+1 j) (2) Additionally, some monotonicity restrictions to the function c (n) exist, so that the longer the head travels the greater the cost is: c (0) c (n) c (m); 0 n m The optimal clustering can still be found (see <ref> [YW73] </ref>, [GS73] and [Won83]). The partition component of the optimal mapping remains the same as before (probability ranking), but the permutation is not the identity any more. <p> R (M ) t of M consecutive frame requests starting 10 Client Cache Client 2 Client 1 Client Cache Client Cache Server queue Server x (n) 1 2 x (n) K x (n) y (n) 1 2 y (n) K y (n) Client k at time t (also used in <ref> [YW73] </ref>). That is: take these M frame requests, eliminate duplicates, and compute the cardinality of the resulting set. Note that the larger the cardinality, the fewer the duplicates, hence the lower the locality. <p> It can be shown that K is minimized for every value of M when each frame f contains objects placed using the probability ranking (see Appendix B.1). This agrees with results in <ref> [YW73] </ref>, where a different methodology was used. 3.6 W SS of the SMC Model A partitioned Markov state space, appears at the limit like a Markov process (see Appendix A.1).
References-found: 23

