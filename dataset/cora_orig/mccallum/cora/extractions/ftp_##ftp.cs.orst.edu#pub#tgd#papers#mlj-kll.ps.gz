URL: ftp://ftp.cs.orst.edu/pub/tgd/papers/mlj-kll.ps.gz
Refering-URL: http://www.cs.orst.edu/~tgd/cv/pubs.html
Root-URL: 
Email: dietterich%oregon-state@csnet-relay  
Title: Learning at the Knowledge Level  
Author: Thomas G. Dietterich 
Keyword: Running head: Knowledge Level Learning  
Address: Corvallis, OR 97331  
Affiliation: Department of Computer Science Oregon State University  
Abstract-found: 0
Intro-found: 1
Reference: <author> Angluin, D., & Smith, C. H. </author> <year> (1982). </year> <title> A survey of inductive inference: </title> <note> theory and methods (Technical Report 250). </note> <institution> New Haven, CT: Yale University, Department of Computer Science. </institution>
Reference-contexts: Further study of the foundations of probability may provide some other ways of applying probabilistic methods to the problem of characterizing rational behavior. Theoretical work in inductive inference has developed some more limited models of ideal learning behavior <ref> (see Angluin & Smith, 1982 for an excellent review) </ref>. Gold (1967) proposed the criterion of identification in the limit. This criterion states that given enough training instances, the learning system should eventually converge on the correct theory (i.e., concept, language, etc.).
Reference: <author> Araya, A. </author> <year> (1984). </year> <title> Learning problem classes by means of experimentation and generalization. </title> <booktitle> In Proceedings of AAAI-84. </booktitle> <address> Los Altos: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 11-15. </pages>
Reference: <author> Bennett, J. S., & Dietterich, T. G. </author> <year> (1986). </year> <title> The test incorporation hypothesis and the weak methods (Technical report 86-30-4). </title> <institution> Corvallis, OR: Oregon State University, Department of Computer Science. </institution>
Reference: <author> Buchanan, B. G., & Mitchell, T. M. </author> <year> (1978). </year> <title> Model-directed learning of production rules. </title> <editor> In D. </editor> <publisher> A. </publisher>
Reference: <editor> Waterman & F. Hayes-Roth (Eds.), </editor> <booktitle> Pattern-directed Inference Systems. </booktitle> <address> New York: </address> <publisher> Academic Press, </publisher> <pages> 297-312. </pages> <note> 21 Chase, </note> <author> W., & Simon, H. A. </author> <title> (1973) Perception in chess. </title> <journal> Cognitive Psychology, </journal> <volume> 4, </volume> <pages> 55-81. </pages>
Reference: <author> Dietterich, T. G. </author> <year> (1984). </year> <title> Constraint propagation techniques for theory-driven data interpretation (Technical Report STAN-CS-84-1030). </title> <institution> Stanford, CA: Stanford University, Department of Computer Science. </institution>
Reference-contexts: Systems that can intelligently select their own training instances or construct fruitful experiments show promise of being much more effective learning systems <ref> (e.g., Dietterich, 1984) </ref>.
Reference: <author> Dietterich, T. G., London, R. L., Clarkson, K., & Dromey, G. </author> <year> (1982). </year> <note> Learning and inductive infer-ence (Technical Report STAN-CS-82-913). </note> <institution> Stanford, CA: Stanford University, Department of Computer Science. </institution> <note> Appears as Chapter XIV in Cohen, </note> <editor> P. R., & Feigenbaum, E. A., </editor> <booktitle> The Handbook of Artificial Intelligence, </booktitle> <volume> Vol. III, </volume> <pages> 323-512, </pages> <address> Los Altos, CA: </address> <publisher> William Kaufmann. </publisher>
Reference-contexts: This definition was always intended to include both SLL and KLL. The feeling was that performance could be "improved" either by improving the efficiency with which existing knowledge was used or by acquiring new knowledge <ref> (see, for example, Dietterich, et al., 1982) </ref>. However, Simon termed his definition "only partially satisfactory," and other researchers (e.g., Scott, 1983) have criticized it for excluding important kinds of learning. In particular, the improved performance definition requires that there exist some performance task by which the improvement can be measured.
Reference: <author> Dietterich, T. G., & Michalski, R. S. </author> <year> (1981). </year> <title> Inductive learning of structural descriptions: Evaluation criteria and comparative review of selected methods. </title> <journal> Artificial Intelligence, </journal> <volume> 16, </volume> <pages> 257-294. </pages>
Reference: <author> Ellman, T. </author> <year> (1985). </year> <title> Generalizing logic circuit designs by analyzing proofs of correctness. </title> <booktitle> In Proceedings of IJCAI-85. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher>
Reference: <author> Fikes, R. E., Hart, P. E., & Nilsson, N. J. </author> <year> (1972). </year> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3, </volume> <pages> 251-288. </pages>
Reference: <author> Flann, N. S., & Dietterich, T. G. </author> <year> (1985). </year> <title> Exploiting functional vocabularies to learn structural descriptions. </title> <booktitle> In Proceedings of the Third International Workshop on Machine Learning. </booktitle> <address> New Brunswick, NJ: </address> <institution> Rutgers University, Department of Computer Science. </institution> <month> 41-43. </month>
Reference: <author> Flann, N. S., & Dietterich, T. G. </author> <year> (1986). </year> <title> Selecting appropriate representations for learning from examples (Technical Report 86-30-5). </title> <institution> Corvallis, OR: Oregon State University, Department of Computer Science. </institution>
Reference: <author> Genesereth, M. R. </author> <year> (1980). </year> <title> Models and metaphors. </title> <booktitle> In Proceedings of AAAI-80, </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 208-211. </pages>
Reference-contexts: Several different avenues of research are currently being pursued. One line of research focuses on studying the computational properties of various architectures and exploiting their constraints to provide biases <ref> (Genesereth, 1980) </ref>. This is the approach of the connectionist learning theorists (e.g., Hinton, Sejnowski & Ackley, 1984) and also of the SOAR group (Rosenbloom, et al., 1985).
Reference: <author> Gold, E. </author> <year> (1967). </year> <title> Language identification in the limit. </title> <journal> Information and Control, </journal> <volume> 16, </volume> <pages> 447-474. </pages>
Reference: <author> Gosling, J. </author> <year> (1983). </year> <title> Algebraic constraints. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Green, C., Luckham, D., Balzer, R., Cheatham, T., & Rich, C. </author> <year> (1983). </year> <note> Report on a knowledge-based software assistant (Techical report KES.U.83.2). </note> <institution> Palo Alto, CA: Kestrel Institute. </institution>
Reference-contexts: In other words, SLL is correctness-preserving program improvement. Hence, a theory of SLL will be a theory of methods for transforming inefficient programs into efficient ones. The prospects for developing such a theory are excellent. Research in automatic programming <ref> (e.g., Green, et al., 1983) </ref> has catalogued a large variety of correctness-preserving program transformation techniques. The remainder of this section sketches one approach to unifying all of these techniques based on the notion of "test incorporation." Further details are presented in Bennett & Dietterich (1986).
Reference: <author> Greiner, R., & Genesereth, M. R. </author> <year> (1983). </year> <title> What's New? A semantic definition of novelty. </title> <booktitle> In Proceedings of IJCAI-83. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 450-454. </pages>
Reference: <author> Grosof, B. </author> <year> (1984). </year> <type> Personal communication. </type>
Reference-contexts: This would not be a knowledge level description, however. 11 possessed by the learning program. The act of applying the circumscription operation is precisely the act of making an unjustified inductive leap. There is one special case in which the bias conjecture is wrong <ref> (Grosof, 1984) </ref>. The case involves the bias to prefer only concepts that can be represented in a restricted language. If there are only finitely many such concepts, then it is possible to represent the set of all possible concepts as a giant disjunction.
Reference: <author> Halpern, J. Y., & Moses, Y. </author> <year> (1985). </year> <title> A guide to the modal logics of knowledge and belief: preliminary draft. </title> <booktitle> In Proceedings of IJCAI-85. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 480-490. </pages>
Reference: <author> Hayes-Roth, F., & McDermott, J. </author> <year> (1978). </year> <title> An interference matching technique for inducing ab-stractions. </title> <journal> CACM, </journal> <volume> 26, </volume> <pages> 401-410. </pages>
Reference: <author> Hintikka, J. </author> <year> (1962). </year> <title> Knowledge and Belief. </title> <publisher> Cornell University Press. </publisher>
Reference: <author> Hinton, G. E., Sejnowski, T. J., & Ackley, D. H. </author> <year> (1984). </year> <title> Boltzmann Machines: Constraint satis-faction networks that learn (Technical Report CMU-CS-84-119). </title> <institution> Pittsburgh, PA: CarnegieMellon University, Department of Computer Science. </institution> <note> 22 Keller, </note> <author> R. M. </author> <year> (1983). </year> <title> Learning by re-expressing concepts for efficient recognition. </title> <booktitle> In Proceedings of AAAI-83. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 182-186. </pages>
Reference-contexts: Several different avenues of research are currently being pursued. One line of research focuses on studying the computational properties of various architectures and exploiting their constraints to provide biases (Genesereth, 1980). This is the approach of the connectionist learning theorists <ref> (e.g., Hinton, Sejnowski & Ackley, 1984) </ref> and also of the SOAR group (Rosenbloom, et al., 1985). The problem with this approach, of course, is that the space of interesting architectures is very large, and any particular set of architectural constraints appears arbitrary.
Reference: <author> Kibler, D., & Porter, B. </author> <year> (1983). </year> <title> Episodic learning. </title> <booktitle> In Proceedings of AAAI-83. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 191-196. </pages>
Reference: <author> Langley, P. </author> <year> (1983). </year> <title> Learning effective search heuristics. </title> <booktitle> In Proceedings of IJCAI-83. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 419-421. </pages>
Reference: <author> Lenat, D. B., & Brown, J. S. </author> <year> (1984). </year> <title> Why AM and EURISKO appear to work. </title> <journal> Artificial Intelligence, </journal> <volume> 23, </volume> <pages> 269-294. </pages>
Reference-contexts: After all, it operates by generating random facts and then believing them if they are consistent. Yet, HL does not require any input from the environment. Hence, HL demonstrates that input is not required for NKLL. HL is an imaginary system, yet the AM system <ref> (Lenat & Brown, 1984) </ref> shares many of its properties. AM receives no input from its environment, but it constructs (by a process of heuristically- guided mutation and combination) a large system of mathematical concepts.
Reference: <author> Lindsay, R. K., Buchanan, B. G., Feigenbaum, E. A., & Lederberg, J. </author> <year> (1980). </year> <title> Applications of artificial intelligence for organic chemistry: The DENDRAL project. </title> <address> New York: McGrawHill. </address>
Reference-contexts: This incorporation will speed up the problem solver substantially. Indeed, if we apply this same incorporation recursively to each subproblem, we arrive at the selection sort algorithm. In AI, similar methods have been employed in the design of expert problem solving systems. Consider, for example, the Dendral system <ref> (Lindsay, et al., 1980) </ref>. The goal of Dendral is to find the molecular structure of an unknown molecule by analyzing the mass spectrum for that molecule. If we were to solve this problem by direct generate-and-test, we might proceed as follows.
Reference: <author> McCarthy, J. </author> <year> (1958). </year> <title> Programs with common sense. </title> <booktitle> In Proceedings of the Symposium on the Mechanization of Thought Processes, </booktitle> <institution> National Physical Laboratory I:77-84. </institution> <note> (Reprinted in M. </note>
Reference-contexts: In every game that he plays, he will play perfectly. He knows the outcome of every possible game. Few computations are as infeasible! One way of summarizing the notion of an ideal rational agent is to imagine providing McCarthy's Advice Taker program <ref> (McCarthy, 1958) </ref> with infinite resources of time and space. We would give this system some starting knowledge and goals, and it would choose actions based on the principle of rationality.
Reference: <author> L. Minsky (Ed.). </author> <year> (1968). </year> <booktitle> Semantic Information Processing. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <pages> 403-409.) </pages> <editor> Mahadevan, S. </editor> <year> (1985). </year> <title> Verification-based learning: a generalization strategy for inferring problemreduction methods. </title> <booktitle> In Proceedings of IJCAI-85. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 616-623. </pages>
Reference: <author> McCarthy, J. </author> <year> (1980). </year> <title> Circumscription|a form of non-monotonic reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13, </volume> <pages> 27-39. </pages>
Reference-contexts: We do not have a proof of this conjecture, but the evidence is mounting that it is correct. One further piece of evidence concerns the bias to prefer maximally specific descriptions. This is equivalent to McCarthy's circumscription operation <ref> (McCarthy, 1980, 1984) </ref>. Circumscription can be viewed in two ways. First, it can be viewed as an operator that is applied to a set of sentences (e.g., training instances) in order to derive additional axioms.
Reference: <author> McCarthy, J. </author> <year> (1986). </year> <title> Applications of circumscription to formalizing common sense knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 28, </volume> <pages> 89-116. </pages>
Reference: <author> Michalski, R. S. </author> <year> (1969). </year> <title> On the quasi-minimal solution of the general covering problem. </title> <booktitle> Proceedings of the Fifth International Federation on Automatic Control, </booktitle> <pages> 27 109-129. </pages>
Reference-contexts: See <ref> (Michalski, 1969) </ref> for a complete description. 9 is chosen as the first seed.
Reference: <author> Michalski, R. S., & Chilausky, R. L. </author> <year> (1980). </year> <title> Learning by being told and learning from examples: An experimental comparison of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. </title> <journal> International Journal of Policy Analysis and Information Systems, </journal> <volume> 4, </volume> <pages> 125-161. </pages>
Reference-contexts: Consequently, AQ11 can infer that all big or red things are pretty. 3 This tactic works for this particular example, but what about some other cases? AQ11 has been successfully applied in a wide variety of domains. One of its most famous applications <ref> (Michalski & Chilausky, 1980) </ref> involved inferring general rules for diagnosis of soybean diseases from specific examples. From 290 training instances of diseased soybean plants, AQ11 inferred a set of rules for diagnosing 15 different soybean diseases.
Reference: <author> Michalski, R. S., & Larson, J. B. </author> <year> (1978). </year> <title> Selection of most representative training examples and incremental generation of VL1 hypotheses: The underlying methodology and the description of programs ESEL and AQ11 (Technical Report 867). </title> <institution> Urbana, IL: University of Illinois, Department of Computer Science. </institution>
Reference-contexts: The combined body of knowledge may be larger than either part taken alone because of new conclusions that can be drawn. 3.3 AQ11 and ID3 AQ11 <ref> (Michalski & Larson, 1978) </ref> and ID3 (Quinlan, 1983) are two very successful inductive learning programs that develop general decision rules from specific examples. <p> For full logical languages, this bias results in the program selecting the disjunction of the negations of all of the negative training instances. By restricting the language to exclude negation, this bias can be made more powerful <ref> (e.g., Michalski & Larson, 1978) </ref>. * Maximally specific descriptions: Prefer concept descriptions that are as specific as possible (i.e., possess the fewest models). For full logical languages, as we have seen above, this amounts to simply listing the disjunction of the training instances. <p> However, many programs apply this bias in combination with a restricted language or a conjunctive bias (e.g., Hayes <br>- Roth & McDermott, 1978; Vere, 1975; Dietterich & Michalski, 1981). * Least disjunction: Prefer concept descriptions (expressed in disjunctive normal form) having the fewest number of disjuncts <ref> (e.g., Michalski & Larson, 1978) </ref>. * One disjunct per lesson: Prefer concept descriptions in which exactly one disjunct was introduced in each lesson. This bias presupposes that the training instances have been partitioned into a sequence of lessons (VanLehn, 1983).
Reference: <author> Mitchell, T. M. </author> <year> (1978). </year> <title> Version spaces: an approach to concept learning (Technical report STANCS-78-711). </title> <institution> Stanford, CA: Stanford University, Department of Computer Science. </institution>
Reference-contexts: Given the three training instances above, A q starts by considering only DNF rules. This is an inductive leap because it assumes that some such rule exists. It might be the case that it is 3 The version space algorithm <ref> (Mitchell, 1978, 1982) </ref> provides an efficient mechanism for performing this kind of calculation, but over larger sets of possible hypotheses. 8 impossible to determine whether an object is P retty given only its color, size, and shape.
Reference: <author> Mitchell, T. M. </author> <year> (1980). </year> <title> The need for biases in learning generalizations (Technical Report CBMTR-117). </title> <address> New Brunswick, NJ: </address> <institution> Rutgers University, Department of Computer Science. </institution>
Reference: <author> Mitchell, T. M. </author> <year> (1982). </year> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18, </volume> <pages> 202-226. </pages>
Reference-contexts: Good instances are instances that led to a solution. Bad instances are instances in which applying a given operator did not lead to a solution. In LEX, the version space algorithm <ref> (Mitchell, 1982) </ref> is applied 5 to discover general heuristics describing the good instances. In LEX2, an analytic technique is applied to deductively infer the exact situations under which a given operator should be applied.
Reference: <author> Mitchell, T. M. </author> <title> (1983) Learning and problem solving, </title> <booktitle> Proceedings of IJCAI-83. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 1139-1151. </pages> <note> 23 Mitchell, </note> <author> T. M., Utgoff, P. E., & Banerji, R. </author> <year> (1983). </year> <title> Learning by experimentation: acquiring and refining problem-solving heuristics. </title> <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M., (Eds.), </editor> <booktitle> Machine Learning. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 163-190. </pages>
Reference: <author> Mooney, R. & DeJong, G. </author> <year> (1985). </year> <title> Learning schemata for natural language processing. </title> <booktitle> In Proceedings of IJCAI-85. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 681-687. </pages>
Reference: <author> Mostow, D. J. </author> <year> (1983). </year> <title> Machine transformation of advice into a heuristic search procedure. </title> <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M., (Eds.) </editor> <booktitle> Machine Learning. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 367-404. </pages>
Reference: <author> Newell, A. </author> <year> (1981). </year> <title> The knowledge level. </title> <journal> AI Magazine, </journal> <volume> 2, </volume> <pages> 1-20. </pages>
Reference: <author> Newell, A., & Simon, H. A. </author> <year> (1976). </year> <title> Computer science as empirical inquiry: symbols and search. </title> <journal> (The 1976 ACM Turing Lecture.) CACM, </journal> <volume> 19, </volume> <pages> 113-126. </pages>
Reference-contexts: There is a minor error with this particular formulation. Any system of logic, such as that employed in the Advice Taker, makes use of some specific vocabulary of predicates and functions to represent its knowledge. These are symbol level entities <ref> (Newell & Simon, 1976) </ref>, and hence, they too are ignored at the knowledge level. To circumvent this problem, we can take a model-theoretic approach. In model theory, any set of logical sentences is taken as being a shorthand for a set of models (or interpretations). <p> Let us consider, for a moment, how programs such as AQ11 actually make these inductive leaps. To do this, we must leave the knowledge level and descend into the symbol level|the level of symbol structures <ref> (Newell & Simon, 1976) </ref>. AQ11 employs the A q algorithm. Given a set of positive and negative training instances, A q attempts to find the maximally general description of those training instances that is in disjunctive normal form (DNF) with fewest disjuncts.
Reference: <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In R. S. Michalski, T. M. Mitchell, & J. Carbonell (Eds.), </editor> <booktitle> Machine Learning. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 463-482. </pages>
Reference-contexts: The combined body of knowledge may be larger than either part taken alone because of new conclusions that can be drawn. 3.3 AQ11 and ID3 AQ11 (Michalski & Larson, 1978) and ID3 <ref> (Quinlan, 1983) </ref> are two very successful inductive learning programs that develop general decision rules from specific examples.
Reference: <author> Rosenbloom, P. S., Laird, J. E., Newell, A., Golding, A., & Unruh, A. </author> <year> (1985). </year> <booktitle> Current research on learning in SOAR. In Proceedings of the Third International Machine Learning Workshop. </booktitle> <address> New Brunswick, NJ: </address> <institution> Rutgers University, Department of Computer Science. </institution>
Reference-contexts: One line of research focuses on studying the computational properties of various architectures and exploiting their constraints to provide biases (Genesereth, 1980). This is the approach of the connectionist learning theorists (e.g., Hinton, Sejnowski & Ackley, 1984) and also of the SOAR group <ref> (Rosenbloom, et al., 1985) </ref>. The problem with this approach, of course, is that the space of interesting architectures is very large, and any particular set of architectural constraints appears arbitrary. A second line of research, exemplified by Utgoff (1984), is to explore techniques for incremental recovery from overly strong biases.
Reference: <author> Russell, S. </author> <year> (1985). </year> <note> The compleat guide to MRS (Technical Report KSL-85-12). </note> <institution> Stanford, CA: Stanford University, Department of Computer Science. </institution>
Reference-contexts: The knowledge level is a kind of specification for LEX's ideal behavior, and that specification has not changed. In summary, LEX provides an example of a learning system whose learning behavior is not visible|and hence, not describable|at the knowledge level. 3.2 MRS Genesereth's MRS system <ref> (Russell, 1985) </ref> is a deductive database system in which facts (and rules) can be stored and queried using a restricted form of first order predicate calculus.
Reference: <author> Samuel, A. L. </author> <year> (1959). </year> <title> Some studies of machine learning using the game of checkers. </title> <journal> IBM J. Research and Development, </journal> <volume> 3, </volume> <pages> 220-229. </pages>
Reference: <author> Scott, P. D. </author> <year> (1983). </year> <title> Learning: the construction of a posteriori knowledge structures. </title> <booktitle> In Proceedings of AAAI-83. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 359-363. </pages>
Reference-contexts: The feeling was that performance could be "improved" either by improving the efficiency with which existing knowledge was used or by acquiring new knowledge (see, for example, Dietterich, et al., 1982). However, Simon termed his definition "only partially satisfactory," and other researchers <ref> (e.g., Scott, 1983) </ref> have criticized it for excluding important kinds of learning. In particular, the improved performance definition requires that there exist some performance task by which the improvement can be measured. Learning in the absence of a specific performance task is not true learning according to this definition.
Reference: <author> Simon, H. A. </author> <year> (1983). </year> <title> Why should machines learn? In R. </title> <editor> S. Michalski, T. M. Mitchell, </editor> & <publisher> J. </publisher>
Reference-contexts: For many years there has been some controversy about how `learning' should best be defined. The majority of workers in machine learning subscribed to the following "improved performance" definition <ref> (Simon, 1983) </ref>: Learning denotes changes in the system that are adaptive in the sense that they enable the system to do the same task or tasks drawn from the same population more efficiently and more effectively the next time. This definition was always intended to include both SLL and KLL.
Reference: <editor> Carbonell (Eds.), </editor> <booktitle> Machine Learning. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 25-38. </pages>
Reference: <author> Stallman, R. M., & Sussman, G. J. </author> <year> (1977). </year> <title> Forward reasoning and dependency-directed backtrack-ing in a system for computer-aided circuit analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 9, </volume> <pages> 135-196. </pages>
Reference-contexts: Another example of run-time incorporation is the technique of constraint propagation employed 18 in EL <ref> (Stallman & Sussman, 1977) </ref> and similar systems (e.g., Sussman & Steele, 1980; Gosling, 1983; Dietterich, 1984). In these systems, the task is to label the nodes of a network with values that satisfy a set of constraints (which reside on the arcs of the network).
Reference: <author> Sussman, G. J., & Steele, G. L., Jr. </author> <year> (1980). </year> <title> CONSTRAINTS-A language for expressing almost hierarchical descriptions. </title> <journal> Artificial Intelligence, </journal> <volume> 14, </volume> <pages> 1-39. </pages>
Reference: <author> Tappel, S. </author> <year> (1980). </year> <title> Some algorithm design methods. </title> <booktitle> In Proceedings of AAAI-80. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 64-67. </pages>
Reference: <author> Utgoff, P. E. </author> <year> (1984). </year> <title> Shift of bias for inductive concept learning. </title> <type> Doctoral Dissertation, </type> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ. </address>
Reference: <author> Utgoff, P. E., & Mitchell, T. M. </author> <year> (1982). </year> <title> Acquisition of appropriate bias for inductive concept learning. </title> <booktitle> In Proceedings of AAAI-82. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 414-417. </pages>
Reference: <author> VanLehn, K. </author> <year> (1983). </year> <title> Felicity conditions for human skill acquisition: Validating an AI-based theory (Technical Report CIS-21). </title> <address> Palo Alto, CA: </address> <institution> Xerox Palo Alto Research Center. </institution> <note> 24 Vere, </note> <author> S. A. </author> <year> (1975). </year> <title> Induction of concepts in the predicate calculus. </title> <booktitle> In Proceedings of IJCAI-75. </booktitle> <address> Los Altos: </address> <publisher> Morgan-Kaufmann. </publisher> <pages> 281-287. 25 </pages>
Reference-contexts: This bias presupposes that the training instances have been partitioned into a sequence of lessons <ref> (VanLehn, 1983) </ref>. In order to successfully predict the behavior of learning programs at the knowledge level, we need to find a way to capture each of these biases in logic.
References-found: 54

