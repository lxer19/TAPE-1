URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS95-19.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Efficient Non-parametric Estimation of Probability Density Functions  
Author: Omer Egecioglu and Ashok Srinivasan 
Keyword: Key words: Probability density, non-parametric estimation, convergence, kernel method, efficient algorithm.  
Note: AMS Subject Classifications: 65U05, 62G05, 62G07, 65D15, 65Y20.  
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: Accurate and fast estimation of probability density functions is crucial for satisfactory computational performance in many scientific problems. When the type of density is known a priori, then the problem becomes statistical estimation of parameters from the observed values. In the non-parametric case, usual estimators make use of kernel functions. If X j ; j = 1; 2; : : : ; n is a sequence of i.i.d. random variables with estimated probability density function f n , in the kernel method the computation of the values f n (X 1 ); f n (X 2 ); : : : ; f n (X n ) requires O(n 2 ) operations, since each kernel needs to be evaluated at every X j . We propose a sequence of special weight functions for the non-parametric estimation of f which requires almost linear time: if m is a slowly growing function that increases without bound with n, our method requires only O(m 2 n) arithmetic operations. We derive conditions for convergence under a number of metrics, which turn out to be similar to those required for the convergence of kernel based methods. We also discuss experiments on different distributions and compare the efficiency and the accuracy of our computations with kernel based estimators for various values of n and m. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bhattacharya P.K. </author> <title> Estimation of a probability density function and its derivatives, </title> <journal> Sankhya Ser. </journal> <note> A, 29 (1967) pp. 373-382. </note>
Reference-contexts: It converges if and only if m 2r+1 ( log n n ) ! 0 as n ! 0. This ends the proof of (17). To complete the proof of the theorem, we need to prove (18). The trick we use is a generalization of an identity of <ref> [1] </ref>: If ; 2 C r (IR) have uniformly continuous r-th derivatives then it can be shown that (r) (x u) (u) = (x u) (r) (u) du s=0 where the superscripts refer to derivatives with respect to x.
Reference: [2] <author> Bickel P.J. and M. </author> <title> Rosenblatt On some global measures of the deviations of density function estimates, </title> <journal> Annals of Statistics, </journal> <note> 1 (1973) pp. 1071-1095. </note>
Reference-contexts: Furthermore in some applications, for example in problems involving directional data, the samples lie on the unit circle S 1 , or along the surface of the unit sphere S 2 . Various methods have been proposed for non-parametric density estimation in mathematical statistics, such as the kernel <ref> [17, 2, 25] </ref> and the orthogonal series methods [19, 9]. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH. <p> We give an example of a sum of fi distributions in Figure (6). The distribution was taken to be 0:35 fi (6; 2) + 0:65 fi (2; 6) and generated by the rejection-acceptance method [12]. The fi function was scaled to take values in <ref> [0; 2] </ref>. Compared with a unimodal distribution, more samples are required to get reasonable results. We can modify our estimator if we know the density function to be symmetric by considering the estimator c m (x) = cos 2m (x)=A m , where A m is a normalization factor.
Reference: [3] <author> Chentsov N.N. </author> <title> Estimation of unknown probability density based on observations, </title> <journal> Dokl. Akad. Nauk SSSR, </journal> <note> 147 (1962) pp. 45-48 (in Russian). </note>
Reference-contexts: Early contributors to the theory of non-parametric estimation include N.V. Smirnov [21], M. Rosenblatt [18], E. Parzen [17], and N.N. Chentsov <ref> [3] </ref>. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in relatively recent books by B.W. Silverman [23], and E.A. Nadaraya [16]. Results of the experimental comparison of some widely used methods appear in [7, 24].
Reference: [4] <author> Duda R.O. and P.E. </author> <title> Hart Pattern classification and scene analysis, </title> <publisher> John Wiley and sons, Inc., </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: One of the drawbacks of the kernel method is the computational cost involved. Even though it is possible to reduce the cost using a series expansion of the kernel <ref> [4] </ref>, this approach is problematic for narrow window widths. We propose a cosine based weight function estimator c m (x) for non-parametric density estimation which is similar to the kernel estimator, but has the ease of evaluation of a series expansion.
Reference: [5] <author> Gradshteyn I.S. </author> <title> and I.M. Ryzhik Table of Integrals Series, and Products, </title> <publisher> Academic Press, Inc., </publisher> <address> Orlando, </address> <year> 1980, </year> <note> p. 374. </note>
Reference-contexts: As examples, the functions c m (x) and c m (x 4 ) for m = 32 are shown on S 1 in Figure (1) (a), and on the interval [; ] in Figure (1) (b). Making use of a table of integrals such as Gradshteyn/Ryzhik <ref> [5] </ref> and by using Stirling's formula, it can be shown that A m = 2 2m1 2m ! 2 m We wish to find sufficient conditions under which the sequence of estimators f n converges to f in the Mean Integrated Square Error (MISE) sense.
Reference: [6] <author> Hernquist L. and Katz N. TREESPH: </author> <title> A unification of SPH with the hierarchical tree method, Astrophys. </title> <journal> J. </journal> <volume> suppl., </volume> <pages> 70 (1989) pp. 419-446. </pages>
Reference-contexts: In time, points that were initially close by can move apart, leading to mesh distortion and numerical difficulties. Problems with mesh distortion can be eliminated to a certain extent by the use of Smoothed Particle Hydrodynamics (SPH) techniques <ref> [15, 6, 13] </ref>. SPH treats the points being tracked as samples coming from an unknown probability distribution. These calculations often require the computation of the values of not only the unknown density, but its gradient as well.
Reference: [7] <author> Hwang J. </author> <title> Non-parametric multivariate density estimation: A comparative study, </title> <journal> IEEE Trans. </journal> <note> Signal Processing, 42 (1994) pp. 2795-2810. </note>
Reference-contexts: Rosenblatt [18], E. Parzen [17], and N.N. Chentsov [3]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in relatively recent books by B.W. Silverman [23], and E.A. Nadaraya [16]. Results of the experimental comparison of some widely used methods appear in <ref> [7, 24] </ref>. Along with applications in discriminant analysis and cluster analysis, an important application of non-parametric density estimation is in computational fluid mechanics. When the flow calculations 1 are performed in a Lagrangian framework, a set of points in space are evolved through time using the governing equations.
Reference: [8] <author> Jones M.C. and Lotwick H.W. </author> <title> A remark on Algorithm AS 176. Kernel density estimation using the fast Fourier transform , Appl. </title> <journal> Statist., </journal> <note> 33 (1984) pp. 120-122. </note>
Reference: [9] <author> Kronmal R. and Tarter M. </author> <title> The estimation of probability densities and cumulatives by Fourier series methods, </title> <journal> American Statist. Association J., (1968) pp. </journal> <pages> 925-952. </pages>
Reference-contexts: Various methods have been proposed for non-parametric density estimation in mathematical statistics, such as the kernel [17, 2, 25] and the orthogonal series methods <ref> [19, 9] </ref>. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH.
Reference: [10] <author> Knuth D.E. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> Vol. 2, </volume> <booktitle> Seminumerical Algorithms, </booktitle> <publisher> Addison-Wesley, </publisher> <address> Menlo Park, CA, </address> <year> 1968. </year> <pages> pp. 41-52. </pages>
Reference: [11] <author> Markushevich A.I. </author> <title> Theory of Functions of a Complex Variable, </title> <publisher> Chelsea Publishing Company, </publisher> <address> New York, </address> <booktitle> 1985, </booktitle> <volume> Vol 2. </volume> <pages> pp. 26-34. </pages>
Reference: [12] <editor> Lavenberg S.S. </editor> <publisher> Computer Performance Modeling Handbook , Academic Press Inc., </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: As with most estimators, the estimation of bimodal distributions is more difficult. We give an example of a sum of fi distributions in Figure (6). The distribution was taken to be 0:35 fi (6; 2) + 0:65 fi (2; 6) and generated by the rejection-acceptance method <ref> [12] </ref>. The fi function was scaled to take values in [0; 2]. Compared with a unimodal distribution, more samples are required to get reasonable results.
Reference: [13] <author> Monaghan J.J. and Lattanzio J.C. </author> <title> A refined particle method for astrophysical problems, </title> <type> Astron. </type> <institution> Astrophys. </institution> <note> 149 (1985) pp. 135-143. </note>
Reference-contexts: In time, points that were initially close by can move apart, leading to mesh distortion and numerical difficulties. Problems with mesh distortion can be eliminated to a certain extent by the use of Smoothed Particle Hydrodynamics (SPH) techniques <ref> [15, 6, 13] </ref>. SPH treats the points being tracked as samples coming from an unknown probability distribution. These calculations often require the computation of the values of not only the unknown density, but its gradient as well. <p> Comparisons were also made with the following kernel estimator <ref> [13] </ref>: K (x) = &gt; &lt; 1 1 0 otherwise where A is the normalization constant.
Reference: [14] <author> Loeve M. </author> <title> Probability Theory, </title> <address> D. </address> <publisher> Van Nostrand Co. Inc., </publisher> <address> Princeton, NJ, </address> <year> 1963. </year> <month> 22 </month>
Reference-contexts: Main conclusions are presented in section (9). The elements of the probability theory we make use of can be found in Loeve's book <ref> [14] </ref>. 2 Convergence of MISE on S 1 Let C 1 [; ] denote continuously differentiable functions on [; ].
Reference: [15] <author> Monaghan J.J. </author> <title> Smoothed particle hydrodynamics, </title> <type> Annu. Rev. </type> <institution> Astron. Astrophys. </institution> <note> 30 (1992) pp. 543-574. </note>
Reference-contexts: In time, points that were initially close by can move apart, leading to mesh distortion and numerical difficulties. Problems with mesh distortion can be eliminated to a certain extent by the use of Smoothed Particle Hydrodynamics (SPH) techniques <ref> [15, 6, 13] </ref>. SPH treats the points being tracked as samples coming from an unknown probability distribution. These calculations often require the computation of the values of not only the unknown density, but its gradient as well.
Reference: [16] <author> Nadaraya E.A. </author> <title> Non-parametric Estimation of Probability Densities and Regression Curves, Mathematics and Applications (Soviet Series)1, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1989. </year>
Reference-contexts: Early contributors to the theory of non-parametric estimation include N.V. Smirnov [21], M. Rosenblatt [18], E. Parzen [17], and N.N. Chentsov [3]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in relatively recent books by B.W. Silverman [23], and E.A. Nadaraya <ref> [16] </ref>. Results of the experimental comparison of some widely used methods appear in [7, 24]. Along with applications in discriminant analysis and cluster analysis, an important application of non-parametric density estimation is in computational fluid mechanics.
Reference: [17] <author> Parzen E. </author> <title> On estimation of a probability density function and mode, </title> <journal> Ann. Math. Statist., </journal> <note> 33 (1962) pp. 1065-1076. </note>
Reference-contexts: This is in contrast to parametric estimation in which the density is assumed come to from a given family, and the parameters are then estimated by various statistical methods. Early contributors to the theory of non-parametric estimation include N.V. Smirnov [21], M. Rosenblatt [18], E. Parzen <ref> [17] </ref>, and N.N. Chentsov [3]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in relatively recent books by B.W. Silverman [23], and E.A. Nadaraya [16]. Results of the experimental comparison of some widely used methods appear in [7, 24]. <p> Furthermore in some applications, for example in problems involving directional data, the samples lie on the unit circle S 1 , or along the surface of the unit sphere S 2 . Various methods have been proposed for non-parametric density estimation in mathematical statistics, such as the kernel <ref> [17, 2, 25] </ref> and the orthogonal series methods [19, 9]. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH.
Reference: [18] <author> Rosenblatt M. </author> <title> Remarks on some non-parametric estimates of a density function, </title> <journal> Ann. Math. Statist., </journal> <note> 27 (1956) pp. 832-837. </note>
Reference-contexts: This is in contrast to parametric estimation in which the density is assumed come to from a given family, and the parameters are then estimated by various statistical methods. Early contributors to the theory of non-parametric estimation include N.V. Smirnov [21], M. Rosenblatt <ref> [18] </ref>, E. Parzen [17], and N.N. Chentsov [3]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in relatively recent books by B.W. Silverman [23], and E.A. Nadaraya [16]. Results of the experimental comparison of some widely used methods appear in [7, 24].
Reference: [19] <author> Schwartz S.C. </author> <title> Estimation of probability density by an orthogonal series, </title> <journal> Ann. Math. Statist., </journal> <note> 38 (1967) pp. 1261-1265. </note>
Reference-contexts: Various methods have been proposed for non-parametric density estimation in mathematical statistics, such as the kernel [17, 2, 25] and the orthogonal series methods <ref> [19, 9] </ref>. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH.
Reference: [20] <author> Silverman B.W. </author> <title> Kernel density estimation using the fast Fourier transform, </title> <journal> Appl. Statist., </journal> <note> 31 (1982) pp. 93-99. </note>
Reference-contexts: Lemma 1 Suppose f 2 C 1 [; ] and let f n (x) be as given in (1). Then Ef n (x) ! f (x) as m ! 1 uniformly, independently of n. Proof Ef n (x) = as shown in Silverman <ref> [20] </ref>, and Whittle [26]. By a change of variable Z c m (x s)f (s)ds = x Z x+ c m (y)f (x + y)dy (5) since c m (y) = c m (y).
Reference: [21] <institution> Smirnov M.V On the approximation of probability densities of random variables, Scholarly Notes of Moscow State Polytechnical Institute, </institution> <note> 16 (1951) pp. 69-96 (in Russian). </note>
Reference-contexts: This is in contrast to parametric estimation in which the density is assumed come to from a given family, and the parameters are then estimated by various statistical methods. Early contributors to the theory of non-parametric estimation include N.V. Smirnov <ref> [21] </ref>, M. Rosenblatt [18], E. Parzen [17], and N.N. Chentsov [3]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in relatively recent books by B.W. Silverman [23], and E.A. Nadaraya [16].
Reference: [22] <author> Smith G. D. </author> <title> Numerical solution of partial differential equations : finite difference methods, </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1978. </year>
Reference: [23] <author> Silverman B.W. </author> <title> Density Estimation for Statistics and Data Analysis, </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: Early contributors to the theory of non-parametric estimation include N.V. Smirnov [21], M. Rosenblatt [18], E. Parzen [17], and N.N. Chentsov [3]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in relatively recent books by B.W. Silverman <ref> [23] </ref>, and E.A. Nadaraya [16]. Results of the experimental comparison of some widely used methods appear in [7, 24]. Along with applications in discriminant analysis and cluster analysis, an important application of non-parametric density estimation is in computational fluid mechanics.
Reference: [24] <author> Vio R., Fasano G., Lazzarin M., and Lessi O. </author> <title> Probability density estimation in astronomy, </title> <type> Astron. </type> <institution> Astrophys., </institution> <note> 289 (1994) pp. 640-648. </note>
Reference-contexts: Rosenblatt [18], E. Parzen [17], and N.N. Chentsov [3]. Extensive descriptions of various approaches to non-parametric estimation along with a comprehensive bibliography can be found in relatively recent books by B.W. Silverman [23], and E.A. Nadaraya [16]. Results of the experimental comparison of some widely used methods appear in <ref> [7, 24] </ref>. Along with applications in discriminant analysis and cluster analysis, an important application of non-parametric density estimation is in computational fluid mechanics. When the flow calculations 1 are performed in a Lagrangian framework, a set of points in space are evolved through time using the governing equations.
Reference: [25] <author> Watson G.S. </author> <title> and Leadbetter M.R. On the estimation of the probability density, I, </title> <journal> Ann. Math. Statist., </journal> <note> 34 (1963) pp. 480-491. </note>
Reference-contexts: Furthermore in some applications, for example in problems involving directional data, the samples lie on the unit circle S 1 , or along the surface of the unit sphere S 2 . Various methods have been proposed for non-parametric density estimation in mathematical statistics, such as the kernel <ref> [17, 2, 25] </ref> and the orthogonal series methods [19, 9]. The kernel method has been extensively studied, and it is probably the most popular scheme in applications such as SPH.
Reference: [26] <author> Whittle P. </author> <title> On the smoothing of probability density functions, </title> <journal> J. Roy. Statist. Soc. B, </journal> <note> 20 (1958) pp. 334-343. </note>
Reference-contexts: Lemma 1 Suppose f 2 C 1 [; ] and let f n (x) be as given in (1). Then Ef n (x) ! f (x) as m ! 1 uniformly, independently of n. Proof Ef n (x) = as shown in Silverman [20], and Whittle <ref> [26] </ref>. By a change of variable Z c m (x s)f (s)ds = x Z x+ c m (y)f (x + y)dy (5) since c m (y) = c m (y). <p> Then var f n (x) ! 0 uniformly as n ! 1 provided m ! 1 as n ! 1, and m = o (n 2 ). Proof var f n (x) = n 1 Z c m (x s)f (s)ds as shown in Whittle <ref> [26] </ref>. As a consequence of lemma (1) Z c m (x s)f (s)ds ! f (x) ; as m ! 1 uniformly. It follows that 1 Z c m (x s)f (s)ds ! 0 as n ! 0 since f is bounded. <p> ! 1, and m = o (n 2 ), then MISE = Z E (f n (x) f (x)) 2 dx ! 0 Proof Z E (f n (x) f (x)) 2 dx = (Ef n (x) f (x)) 2 dx + var f n (x)dx as shown in Whittle <ref> [26] </ref>. From lemma (1) and lemma (2), each of the integrals approaches 0. Hence the MISE converges to 0. 2 5 3 Almost Sure Convergence on IR Let X j ; j = 1; 2; : : : be a sequence of i.i.d. random variables (observations) with values in IR. <p> First we show that sup jf n (x) Ef n (x)j ! 0 a.s.; (11) and then sup jEf n (x) f (x)j ! 0 : (12) For the proof of (11), we use the integral expression for the expectation from Whittle <ref> [26] </ref> and integration by parts to get sup jf n (x) Ef n (x)j = sup j c m (x u)dF n (u) c m (x u)dF (u)j x2IR jF n (u) F (u)jjdc m (x u)j sup u2IR p where the last inequality uses the fact that the function c
References-found: 26

