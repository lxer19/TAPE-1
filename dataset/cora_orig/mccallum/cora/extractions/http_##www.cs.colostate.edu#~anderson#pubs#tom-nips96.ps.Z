URL: http://www.cs.colostate.edu/~anderson/pubs/tom-nips96.ps.Z
Refering-URL: http://www.cs.colostate.edu/~anderson/pubs/pubs.html
Root-URL: 
Email: tlt@VNET.IBM.COM  anderson@cs.colostate.edu  
Title: Traffic Light Control Using SARSA with Three State Representations  Category: Control, Navigation, and Planning: reinforcement learning.  
Author: Thomas L. Thorpe Charles W. Anderson 
Note: No part of this work has been submitted or appeared in other scientific conferences.  
Address: PO Box 1900 Boulder, CO 80301-9191  Fort Collins, CO 80523  
Affiliation: IBM Corporation  Department of Computer Science Colorado State University  
Abstract: SARSA is applied to a simulated traffic light control problem and compared with a fixed-duration strategy and a simple, rule-based strategy. The performance of SARSA with three different representations of the current state of traffic is analyzed. SARSA is shown to be superior to the best, fixed-duration light timing and close to optimal for the simulation used in this article.
Abstract-found: 1
Intro-found: 1
Reference: <author> Chin, D.C., Smith, R.H., Spall, </author> <title> J.C. (1995) A system-wide approach to adaptive traffic control. </title> <booktitle> In Proceedings of 3rd Symposium on Research & Development, </booktitle> <institution> Johns Hopkins University, </institution> <month> November, </month> <year> 1995. </year> <note> Abstract available at http://www.jhuapl.edu/symposium/3rd RandD/Traffic.htm. </note>
Reference-contexts: Vehicles can also be rerouted remotely to reduce congestion. A neural network has been used as a traffic light controller in a simulator based on nine actual intersections in Manhattan, New York <ref> (Chin, 1995) </ref>. The neural net used simultaneous perturbation stochastic approximation and was able to reduce the vehicle wait time by 10% relative to the existing control strategy. Current traffic controllers in wide use are very primitive and require frequent manual adjustments to keep traffic flowing smoothly.
Reference: <author> Crites, Robert H., Barto Andrew G. </author> <title> (1996) Improving elevator performance using reinforcement learning. </title> <booktitle> In Advances in Neural Information Processing Systems 8, </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The main difference is that data packets can continue to flow at varying rates, but are not required to physically stop as automobiles must do to avoid collisions. The traffic control problem is similar to elevator dispatching <ref> (Crites and Barto, 1996) </ref>. The arrival of vehicles at an intersection and the direction of travel are stochastic in nature. The elevator controller could be modified for the traffic control problem to see how well it performs.
Reference: <author> Garnaas, Steve, </author> <month> May 10, </month> <year> 1996, </year> <title> Denver Post, "120th is giving commuters the green light", p 1B and "Caught in Traffic, Timing the thing for Colorado's signal supervisor", p 2B. </title>
Reference-contexts: 1 INTRODUCTION A variety of traffic control strategies are being studied in real traffic networks and in simulation. The Denver Regional Council of Governments works with the Col-orado Department of Transportation and citizens to identify and modify problem intersections <ref> (Garnaas, 1996) </ref>. Computers are used to monitor the traffic flows for critical intersections through the Denver region. The computers have the capability to change traffic light timing remotely but are only used to collect data for traffic analysis.
Reference: <author> Olsson, G. </author> <title> (1996) Fewer traffic jams thanks to computers. </title> <note> At http://www.stockholm.se/bm/projects/vagtrafik-en.html. </note>
Reference-contexts: Recently a major traffic artery was re-timed from 90 seconds in the heavy traffic flow direction to 100 seconds. This resulted in an 87% reduction in times stopped at lights. Stockholm, Sweden, uses remote television cameras to monitor high traffic flow areas <ref> (Olsson, 1996) </ref>. The traffic conditions are directly observed and speed limits and traffic light timing can be slowly adjusted remotely. Vehicles can also be rerouted remotely to reduce congestion.
Reference: <author> Singh, S.P. and Sutton, </author> <title> R.S. (to appear) Reinforcement learning with replacing eligibility traces. </title> <booktitle> Machine Learning. </booktitle>
Reference: <author> Sutton, </author> <title> R.S. (1996) Generalization in reinforcement learning: Successful examples using sparse coarse coding. </title> <booktitle> In Advances in Neural Information Processing Systems 8, </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The greatest volume strategy sets to green the traffic lights in the east-west or north-south lanes depending on which direction contains the most vehicles. The lights in the other direction are set to red. 3 TRAFFIC LIGHT CONTROL WITH SARSA We applied the SARSA <ref> (Sutton, 1996) </ref> algorithm to the traffic light control problem using replace traces (Singh and Sutton, 1996) and a zero probability of taking non-greedy actions. The traffic controller is trained using experience at a single intersection with 4 lanes of traffic leading into it. <p> The lights in the other direction are set to red. 3 TRAFFIC LIGHT CONTROL WITH SARSA We applied the SARSA (Sutton, 1996) algorithm to the traffic light control problem using replace traces <ref> (Singh and Sutton, 1996) </ref> and a zero probability of taking non-greedy actions. The traffic controller is trained using experience at a single intersection with 4 lanes of traffic leading into it. A lane, relative to an intersection, is the block-long (440 foot) stretch of road approaching the intersection.
Reference: <author> Thorpe, T. </author> <title> (1996) A physically-realistic simulation of vehicle traffic flow. </title> <type> Technical Report 96-118, </type> <institution> Department of Computer Science, Colorado State University. </institution>
Reference-contexts: In this article, we show that reinforcement learning with complete knowledge of vehicle locations approaches the best traffic light performance that can possibly be achieved for the limited traffic simulation we used <ref> (Thorpe, 1996) </ref>. In Section 2, we describe the traffic simulation and several conventional traffic light controllers. Our application of SARSA to the traffic light control problem is described in Section 3. <p> Our application of SARSA to the traffic light control problem is described in Section 3. Our results are summarized in Section 4, and Section 5 presents our conclusions and describes on-going work. 2 TRAFFIC SIMULATOR AND CONTROL STRATEGIES Our simulator <ref> (Thorpe, 1996) </ref> uses one-second, discrete time steps for the traffic light controller agent and the simulation of vehicle movement. Vehicle movement is simulated with realistic velocity and acceleration limits and is constrained by minimum following distances.
References-found: 7

