URL: http://www.csc.calpoly.edu/~tpederse/acl96-tr.ps.gz
Refering-URL: http://www.csc.calpoly.edu/~tpederse/pubs.html
Root-URL: http://www.csc.calpoly.edu
Email: fpedersen,kayaalp,rbruceg@seas.smu.edu  
Title: Significant Lexical Relationships  
Author: Ted Pedersen Mehmet Kayaalp Rebecca Bruce 
Date: February 26, 1996  
Address: Dallas, TX 75275  
Affiliation: Department of Computer Science Engineering Southern Methodist University  
Abstract: We describe a test that can be used to accurately assess the significance of a population model from a data sample using freely available software. We apply this test to the study of lexical relationships and demonstrate that the results obtained using this test are both theoretically more reliable and different from the results obtained using previous approaches. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Badsberg. </author> <title> An Environment for Graphical Models. </title> <type> PhD thesis, </type> <institution> Aal-borg University, </institution> <year> 1995. </year>
Reference-contexts: In this paper, we describe a test that can be used to accurately assess the significance of a population model from a data sample. This test, referred to as an "exact conditional test," can be performed using a freely available software package called CoCo <ref> [1] </ref>. We apply the exact conditional test to the study of lexical relationships in naturally occurring text and compare the results obtained to those obtained using other significance tests. The steps involved in formulating a significance test are: 1. <p> An alternative to using an approximation to the distribution of a goodness of fit statistic is to define its exact distribution either by enumerating all elements of that distribution or by sampling from that distribution using a Monte Carlo sampling scheme [12]. The freely available software package called CoCo <ref> [1] </ref> uses such a procedure to formulate the exact conditional distribution of G 2 . This is the distribution of G 2 values that would be observed for comparable data samples randomly generated from the model being tested. <p> This test, referred to as an "exact conditional test," can be performed using a freely available software package called CoCo <ref> [1] </ref>. We have applied the exact conditional test to the study of lexical relationships and demonstrated that the results obtained using this test are both theoretically more reliable and different from the results obtained using previous approaches. 11
Reference: [2] <author> E. Brill. </author> <title> A simple rule-based part of speech tagger. </title> <booktitle> In Proceedings of the Third Conference on Applied Computational Linguistics, </booktitle> <address> Trento, Italy, </address> <year> 1992. </year>
Reference-contexts: Such empirical studies have provided valuable insights into the nature of language (e.g., [7] [6]) and have resulted in the development of several natural language processing systems (e.g., [4] [5] <ref> [2] </ref> [3]). In this paper we discuss the use of significance testing to infer the characteristics of an entire population of text from a randomly selected sample of that text. Empirical studies of language implicitly or explicitly define a probabilistic model for the characteristic being studied.
Reference: [3] <author> E. Brill. </author> <title> Transformation-based error-driven parsing. </title> <booktitle> In Proceedings of the 3th International Workshop on Parser Technologies, </booktitle> <address> Tilburg, The Netherlands, </address> <year> 1993. </year>
Reference-contexts: Such empirical studies have provided valuable insights into the nature of language (e.g., [7] [6]) and have resulted in the development of several natural language processing systems (e.g., [4] [5] [2] <ref> [3] </ref>). In this paper we discuss the use of significance testing to infer the characteristics of an entire population of text from a randomly selected sample of that text. Empirical studies of language implicitly or explicitly define a probabilistic model for the characteristic being studied.
Reference: [4] <author> P. Brown, J. Cocke, S. Della Pietra, V. Della Pietra, F. Jelinek, J. Laf-ferty, R. Mercer, and P. Roossin. </author> <title> A statistical approach to machine translation. </title> <journal> Computational Linguistics, </journal> <volume> 16(2) </volume> <pages> 79-85, </pages> <year> 1990. </year>
Reference-contexts: Such empirical studies have provided valuable insights into the nature of language (e.g., [7] [6]) and have resulted in the development of several natural language processing systems (e.g., <ref> [4] </ref> [5] [2] [3]). In this paper we discuss the use of significance testing to infer the characteristics of an entire population of text from a randomly selected sample of that text. Empirical studies of language implicitly or explicitly define a probabilistic model for the characteristic being studied.
Reference: [5] <author> P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer. </author> <title> Word sense disambiguation using statistical methods. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <volume> volume 1, </volume> <pages> pages 264-304, </pages> <address> Berkeley, California, </address> <year> 1991. </year>
Reference-contexts: Such empirical studies have provided valuable insights into the nature of language (e.g., [7] [6]) and have resulted in the development of several natural language processing systems (e.g., [4] <ref> [5] </ref> [2] [3]). In this paper we discuss the use of significance testing to infer the characteristics of an entire population of text from a randomly selected sample of that text. Empirical studies of language implicitly or explicitly define a probabilistic model for the characteristic being studied.
Reference: [6] <author> K. Church, W. Gale, P. Hanks, and D. Hindle. </author> <title> Using statistics in lexical analysis. </title> <editor> In U. Zernik, editor, </editor> <title> Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Statistical Natural Language Processing (NLP) seeks to make general claims about human language from an empirical study of examples of human speech or text. Such empirical studies have provided valuable insights into the nature of language (e.g., [7] <ref> [6] </ref>) and have resulted in the development of several natural language processing systems (e.g., [4] [5] [2] [3]). In this paper we discuss the use of significance testing to infer the characteristics of an entire population of text from a randomly selected sample of that text. <p> Failure to meet these conditions can mean that the actual distributions of these goodness of fit statistics are far from the 2 approximation. In that case, significance values assigned based on the 2 approximation can be incorrect. 4.2 The t-statistic According to <ref> [6] </ref>, lexical association can be evaluated using the t-statistic to compare the observed sample frequency of a bigram to the expected sample frequency under the model for independence: t f (I)f (J) f (I; J ) n 11 m 11 n 11 The bigram difference test can be evaluated using a <p> The example used in <ref> [6] </ref>, "strong support" versus "powerful support", is formulated using the t-statistic as follows: t f (powerf ul support) f (strong support) q f (powerf ul support) + f (strong support) = p (8) In the t-test, significance is assigned to the t-statistic using the t-distribution, which is equal to the standard
Reference: [7] <author> K. Church and P. Hanks. </author> <title> Word association norms, mutual information and lexicography. </title> <booktitle> In Proceedings of the the 28th Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 76-83, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Statistical Natural Language Processing (NLP) seeks to make general claims about human language from an empirical study of examples of human speech or text. Such empirical studies have provided valuable insights into the nature of language (e.g., <ref> [7] </ref> [6]) and have resulted in the development of several natural language processing systems (e.g., [4] [5] [2] [3]). In this paper we discuss the use of significance testing to infer the characteristics of an entire population of text from a randomly selected sample of that text.
Reference: [8] <author> N. Cressie and T. </author> <title> Read. Multinomial goodness-of-fit tests. </title> <journal> Journal of the Royal Statistics Society Series B, </journal> <volume> 46 </volume> <pages> 440-464, </pages> <year> 1984. </year>
Reference-contexts: All of these statistics have known distributional properties when the null hypothesis is true and certain other conditions hold; they therefore can be used in significance testing. 4.1 The Power Divergence Family The power divergence family of goodness of fit statistics was introduced in <ref> [8] </ref>. A number of well known goodness of fit statistics belong to this family including X 2 and G 2 . These statistics measure the divergence of observed (n ij ) and expected (m ij ) sample counts, where m ij is calculated assuming that the null hypothesis is correct.
Reference: [9] <author> T. Dunning. </author> <title> Accurate methods for the statistics of surprise and coincidence. </title> <journal> Computational Linguistics, </journal> <volume> 19(1) </volume> <pages> 61-74, </pages> <year> 1993. </year>
Reference-contexts: In general, the findings of <ref> [9] </ref> were confirmed; based on a comparison to the exact conditional test, the 2 approximation to the distribution of G 2 was found to be more reliable than the t-test and the 2 approximation to the distribution of Pearson's X 2 . 6.2 Difference in Context A 928,000 word subset of <p> When the difference between n 11 and n 21 is exactly one, the distinction between "&lt;word&gt; came" and "&lt;word&gt; went" is as small as possible. Also note that the significance assigned by the t-test and the 2 approximation to X 2 are identical. This result confirms the findings of <ref> [9] </ref> regarding the inappropriateness of normal assumptions. 6.2.2 extended bigram difference test This experiment compared "&lt;word&gt; came" and "&lt;word&gt; went" where "&lt;word&gt;" now has as possible values any of the spelling forms that immediately precede either "came" or "went".
Reference: [10] <author> M. Marcus, B. Santorini, and M. A. Marcinkiewicz. </author> <title> Building a large annotated corpus of English: The Penn Treebank. </title> <journal> Computational Linguistics, </journal> <volume> 19(2) </volume> <pages> 313-330, </pages> <year> 1993. </year> <month> 12 </month>
Reference-contexts: This follows from the distributional tendencies of individual words and bigrams as described in Zipf's Law [13]. For example, in a 132,755 word subset of the ACL/DCI Wall Street Journal corpus <ref> [10] </ref> there are 14,319 distinct words and 73,779 distinct bigrams. Of the distinct words, 48% of them occur only once and 80% of them occur 5 times or less. Of the distinct bigrams, 81% occur once and 97% of them occur 5 times or less.
Reference: [11] <author> T. Read and N. Cressie. </author> <title> Goodness-of-fit Statistics for Discrete Multi--variate Data. </title> <publisher> Springer-Verlag Inc., </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: More precisely, X 2 and G 2 are approximately 2 distributed when the following conditions regarding the data sample hold <ref> [11] </ref>: 1. the sample size is large, 2. the number of cells in the contingency table representation of the data is fixed and small relative to the sample size, and 3. the expected count (under the hypothetical population model) for each cell is large.
Reference: [12] <author> B. D. Ripley. </author> <title> Stochastic Simulation. </title> <publisher> John Wiley, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: An alternative to using an approximation to the distribution of a goodness of fit statistic is to define its exact distribution either by enumerating all elements of that distribution or by sampling from that distribution using a Monte Carlo sampling scheme <ref> [12] </ref>. The freely available software package called CoCo [1] uses such a procedure to formulate the exact conditional distribution of G 2 . This is the distribution of G 2 values that would be observed for comparable data samples randomly generated from the model being tested.
Reference: [13] <author> G. Zipf. </author> <title> The Psycho-Biology of Language. </title> <publisher> Houghton Mi*in Company, </publisher> <address> Boston, MA, </address> <year> 1935. </year> <month> 13 </month>
Reference-contexts: This follows from the distributional tendencies of individual words and bigrams as described in Zipf's Law <ref> [13] </ref>. For example, in a 132,755 word subset of the ACL/DCI Wall Street Journal corpus [10] there are 14,319 distinct words and 73,779 distinct bigrams. Of the distinct words, 48% of them occur only once and 80% of them occur 5 times or less.
References-found: 13

