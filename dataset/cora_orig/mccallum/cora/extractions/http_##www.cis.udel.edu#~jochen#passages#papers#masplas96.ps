URL: http://www.cis.udel.edu/~jochen/passages/papers/masplas96.ps
Refering-URL: http://www.cis.udel.edu/~jochen/passages/pubs.htm
Root-URL: http://www.cis.udel.edu
Email: ffenwick,pollockg@cis.udel.edu  
Phone: (302) 831-1953  
Title: Identifying Tuple Usage Patterns in an Optimizing Linda Compiler  
Author: James B. Fenwick Jr. Lori L. Pollock 
Date: April 27, 1996  
Note: Proceedings of MASPLAS'96 The Mid-Atlantic Workshop on Programming Languages and Systems  
Address: 19716  New Paltz  
Affiliation: High Performance Computing Software Laboratory Department of Computer and Information Sciences University of Delaware Newark, DE  SUNY at  
Abstract: The associative tuplespace access and uncoupled communication of Linda parallel programs are the key to the power and flexibility of Linda, but also lie at the heart of the compiler and run-time system implementation challenges. This paper provides concrete steps towards advanced compile-time analysis and optimization of the uncoupled communication of Linda programs. In particular, as part of an optimizing Linda compiler, we have developed and implemented a data flow framework which statically estimates the count of tuples at run-time for each of the tuplespace partitions. This information is crucial in identifying tuple usage patterns which form the basis for compile-time optimization of Linda's uncoupled communication. We have also designed algorithms for the identification of shared variable tuples and a class of synchronization tuples. Our empirical findings show that over 28% of tuplespace partitions in a suite of real application programs never contain more than one tuple. These results indicate that there is plenty of opportunity for compile-time optimization of communication of Linda programs, and a global static analysis of Linda parallel programs can indeed provide this information to the optimizer, and thus programmers do not have to rely strictly on run-time and peephole optimizations for achieving good performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Ahmed, Nicholas Carriero, and David Gelern-ter. </author> <title> The linda program builder. </title> <booktitle> In Advances in Languages and Compilers for Parallel Processing, </booktitle> <pages> pages 71-87. </pages> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Our static analysis could be of use in this situation in terms of jumpstarting a dynamic optimization and also by informing the run-time system of a known change later. The Linda program builder (LPB) <ref> [1] </ref> is an emacs-driven Linda programming tool. The LPB pro vides templates for the more common programming paradigms such as master-worker. It also supports the specification of particular distributed data structures such as shared variables and queues. <p> The LPB pro vides templates for the more common programming paradigms such as master-worker. It also supports the specification of particular distributed data structures such as shared variables and queues. This is important information that can be exploited by an optimizing compiler to increase efficiency. However the paper <ref> [1] </ref> fails to detail how the tool and/or database ensure that the programmer does not violate any conditions of these "higher-level" structures, for example by (accidentally) enclosing the out of a shared variable tuple in a loop. <p> In Figure 2, the partition for the "head" tuples acts as the shared variable tuples. Detection of a stream structure crucially depends upon the identification of the shared variable tuple (s). Ahmed, Carriero, and Gelernter <ref> [1] </ref> found empirically that an optimization of a shared variable tuple resulted in a factor of 2 speedup in access to the tuple by eliminating half of the messages required. <p> A second contribution is the development of algorithms that identify shared variable tuples and a class of synchronization tuples. Identification of tuple usage patterns in a Linda program is a key to optimizing the program's uncoupled communication. Ahmed, Car riero, and Gelernter <ref> [1] </ref> empirically found a factor of 2 speedup is possible for shared variable tuple access if optimized. A final contribution is the implementation of our data flow analysis framework and an empirical study of application Linda programs.
Reference: [2] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ull-man. </author> <booktitle> Compilers Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley Publishing Co., </publisher> <year> 1986. </year>
Reference-contexts: consists of a set of values to be propagated throughout the graphical program representation (i.e., a lattice), a set of transfer functions to be applied at each node of the graph, and a binary meet operation to be applied at join points (i.e., points in the graphs where paths converge) <ref> [2] </ref>. Our data flow framework for tuple counting is similar to the framework presented by Hederman [16] for statically estimating reference counts for garbage collection.
Reference: [3] <author> Mauricio Arango and Donald Berndt. Tsnet: </author> <title> A linda implementation for networks of unix-based computers. </title> <type> Technical Report YALEU/DCS/TR-739, </type> <institution> Yale University, Department of Computer Science, </institution> <month> September </month> <year> 1989. </year>
Reference-contexts: Linda has been implemented on massively parallel processors as well as distributed-memory hypercubes, networks of workstations, and shared-memory machines, and has been combined with a number of base languages including C, Fortran, and Lisp <ref> [10, 21, 5, 3, 6] </ref>. Moreover, Deshpande and Schultz [11] demonstrated that Linda programs can be efficient on distributed-memory machines.
Reference: [4] <author> Henri E. Bal. </author> <title> A comparative study of five parallel programming languages. </title> <booktitle> In Distributed Open Systems, </booktitle> <pages> pages 134-151. </pages> <publisher> IEEE, </publisher> <year> 1994. </year>
Reference-contexts: For example, one of the more important contributions of Linda is the introduction of distributed data structures <ref> [4] </ref>. A distributed queue, or stream, is simply an ordered sequence of tuples, and may come in a variety of flavors distinguished by the number of processes removing from and adding to the stream [8].
Reference: [5] <author> Robert D. Bjornson. </author> <title> Linda on Distributed Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Linda has been implemented on massively parallel processors as well as distributed-memory hypercubes, networks of workstations, and shared-memory machines, and has been combined with a number of base languages including C, Fortran, and Lisp <ref> [10, 21, 5, 3, 6] </ref>. Moreover, Deshpande and Schultz [11] demonstrated that Linda programs can be efficient on distributed-memory machines. <p> However, it is also these properties of associative access and uncoupled communication that cause inefficiencies. Compile-time analysis has been developed to structure tuplespace which significantly reduces the associative search cost [10], and run-time strategies have been developed to counteract inefficiencies due to the uncoupling property <ref> [5] </ref>. Carriero and Gelernter discuss potential compile-time analysis to reduce the impact of uncoupled communication [7]. We base our work on the observations presented by them. Specifically, we present global analysis methods for detecting common, yet possibly inefficient, Linda usage patterns at compile-time. <p> They lay a foundation for this analysis by describing several views of Linda programs. However, they provide only an abstract program representation and no algorithms to perform these kinds of analyses. Our paper provides concrete steps towards realizing some of these optimizations that they suggest. Bjornson <ref> [5] </ref> performs some limited compile-time analysis. A peephole pattern recognizer looks for an in (tuple)-out (tuple) combination on the same tuple and replaces it with code to update the tuple in place in tuplespace. <p> However, just as the shared variable tuple is a necessary component of multi-partition distributed data structures like streams, the basic synchronization tuple is also an integral part of multi-partition synchronization data structures. The efficient distributed-memory barrier synchronization of <ref> [5] </ref> is an example. Thus, identifying the basic synchronization has the additional benefit of allowing even more analysis with potentially greater payoff.
Reference: [6] <author> Nicholas Carriero, Eric Freeman, and David Gel-ernter. </author> <title> Adaptive parallelism on multiprocessors: Preliminary experience with piranha on the cm-5. </title> <type> Technical Report YALEU/DCS/TR-969, </type> <institution> Yale University, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Linda has been implemented on massively parallel processors as well as distributed-memory hypercubes, networks of workstations, and shared-memory machines, and has been combined with a number of base languages including C, Fortran, and Lisp <ref> [10, 21, 5, 3, 6] </ref>. Moreover, Deshpande and Schultz [11] demonstrated that Linda programs can be efficient on distributed-memory machines.

Reference: [8] <author> Nicholas Carriero and David Gelernter. </author> <title> How to Write Parallel Programs, A First Course. </title> <publisher> The MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: We describe our implementation and experimental results in section 5. We finish with conclusions and future directions in section 6. 2 Linda Linda is a coordination language consisting of a small number of primitives which are added into existing sequential languages <ref> [13, 8] </ref>. These operations perform the communication and synchronization necessary for parallel programming. Communication between processes is achieved through tuples in an associative, global memory known as tuplespace. The tuples in tuplespace are manipulated by the Linda operations: out, eval, in, rd, inp, rdp. <p> A distributed queue, or stream, is simply an ordered sequence of tuples, and may come in a variety of flavors distinguished by the number of processes removing from and adding to the stream <ref> [8] </ref>. Proper detection of a stream allows a transformation to eliminate a source of inefficiency, concurrent access to a single tuple. A stream is a single data structure, but involves the cooperative use of more than one tuplespace partition as demonstrated in Figure 2.
Reference: [9] <author> Nicholas Carriero and David Gelernter. </author> <title> Learning from our successes. </title> <editor> In Janusz S. Kowalik and Lucio Grandinetti, editors, </editor> <booktitle> Software for Parallel Computation, volume 106 of NATO ASI Series F: Computer and Systems Sciences, </booktitle> <pages> pages 37-45. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: In support, there are a number of Linda production codes to perform tasks as diverse as image ray-tracing to medical monitoring to pricing financial instruments <ref> [9] </ref>. However, very little has been done to statically optimize Linda's communication beyond peephole optimizations and sophisticated partitioning methods for its logically, shared memory.
Reference: [10] <author> Nicholas John Carriero, Jr. </author> <title> Implementation of Tuple Space Machines. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> December </month> <year> 1987. </year>
Reference-contexts: Linda has been implemented on massively parallel processors as well as distributed-memory hypercubes, networks of workstations, and shared-memory machines, and has been combined with a number of base languages including C, Fortran, and Lisp <ref> [10, 21, 5, 3, 6] </ref>. Moreover, Deshpande and Schultz [11] demonstrated that Linda programs can be efficient on distributed-memory machines. <p> Also, the logically, shared memory of tuplespace is content addressable or associative. However, it is also these properties of associative access and uncoupled communication that cause inefficiencies. Compile-time analysis has been developed to structure tuplespace which significantly reduces the associative search cost <ref> [10] </ref>, and run-time strategies have been developed to counteract inefficiencies due to the uncoupling property [5]. Carriero and Gelernter discuss potential compile-time analysis to reduce the impact of uncoupled communication [7]. We base our work on the observations presented by them. <p> operations create templates. 2 In response to the high cost of process creation, many Linda implementations only create processes for the function valued fields of an eval. 6.2 3 Current Strategies for Effi- cient Execution The earliest work on making Linda efficient was directed at the associative matching of tuplespace <ref> [10] </ref>. The implementation of tuplespace must store tuples and search for a matching tuple when presented with a template. If no matching tuple is found, the template is stored and satisfied when a matching tuple finally enters tuplespace.
Reference: [11] <author> Ashish Deshpande and Martin Schultz. </author> <title> Efficient parallel programming with linda. </title> <booktitle> In Supercomputing '92 Proceedings, </booktitle> <pages> pages 238-244, </pages> <address> Min-neapolis, Minnesota, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Linda has been implemented on massively parallel processors as well as distributed-memory hypercubes, networks of workstations, and shared-memory machines, and has been combined with a number of base languages including C, Fortran, and Lisp [10, 21, 5, 3, 6]. Moreover, Deshpande and Schultz <ref> [11] </ref> demonstrated that Linda programs can be efficient on distributed-memory machines. We believe that Linda's simplicity, explicit parallelism, and integration with existing languages makes it an attractive choice for scientists of non-computer science disciplines who wish to increase performance of codes through parallelism.
Reference: [12] <author> James B. Fenwick Jr. and Lori L. Pollock. </author> <title> Implementing an optimizing linda compiler using suif. </title> <type> Technical report, </type> <institution> University of Delaware, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: The SUIF system consists of a core library, support libraries, and a variety of passes. Here, we give a brief overview of our optimizing Linda compiler and its analyses; details can be found in <ref> [12] </ref>. We have developed a new SUIF compiler pass that builds an interprocedural control flow graph (ICFG) [20] for each process, resulting in a forest of ICFGs. Processes are easily identified because Linda's function parallelism is explicit.
Reference: [13] <author> David Gelernter. </author> <title> Generative communication in linda. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(1) </volume> <pages> 80-112, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: Linda is based upon the unique generative communication model <ref> [13] </ref> called tuplespace. Two dis 1 Linda is a registered trademark of Scientific Computing Associates, Inc., of New Haven, Conn. 6.1 tinguishing characteristics of tuplespace give rise to its power and flexibility. Communication uncoupling refers to the tuple producer's lack of concern for the consumer (s) of the tuple. <p> We describe our implementation and experimental results in section 5. We finish with conclusions and future directions in section 6. 2 Linda Linda is a coordination language consisting of a small number of primitives which are added into existing sequential languages <ref> [13, 8] </ref>. These operations perform the communication and synchronization necessary for parallel programming. Communication between processes is achieved through tuples in an associative, global memory known as tuplespace. The tuples in tuplespace are manipulated by the Linda operations: out, eval, in, rd, inp, rdp.
Reference: [14] <author> Milind Girkar and Constantine D. Poly-chronopoulos. </author> <title> The hierarchical task graph as a universal intermediate representation. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 22(5) </volume> <pages> 519-551, </pages> <year> 1994. </year>
Reference-contexts: Functional, task, or DAG parallelism is the parallelism that can be exploited among different operations in a program by using data and control dependences [22] targeting a parallelism that is more coarsely grained than loop-level parallelism. Other research <ref> [22, 14] </ref> may be applied by a Linda compiler to extract these finer grained parallelisms present in individual, explicitly specified Linda processes.
Reference: [15] <author> Stanford SUIF Compiler Group. </author> <title> The SUIF Par-allelizing Compiler Guide. </title> <institution> Stanford University, </institution> <year> 1994. </year> <note> Version 1.0. </note>
Reference-contexts: The algorithm for detecting synchronization tuple usage patterns is very similar to the shared variable usage detection algorithm, and thus not included in this paper. 5 Implementation and Experi mentation 5.1 Experimental Framework Our optimizing Linda compiler is built upon the SUIF compiler project <ref> [15] </ref> developed by Stanford University researchers and utilized by many academic and 6.7 industry groups. SUIF is a compiler research vehicle that is based on a well-documented infrastructure. A common, multi-leveled intermediate representation of programs is the foundation for a set of extendable, independent compilation passes.
Reference: [16] <author> Lucy Hederman. </author> <title> Compile time garbage collection using reference count analysis. </title> <type> Master's thesis, </type> <institution> Rice University, </institution> <month> August </month> <year> 1988. </year> <note> Technical Report COMP TR88-75. </note>
Reference-contexts: Our data flow framework for tuple counting is similar to the framework presented by Hederman <ref> [16] </ref> for statically estimating reference counts for garbage collection. Let C = f1; 0; 1; 1g be the bounded set of potential tuple count values that a process can have on a particular partition at any given time.
Reference: [17] <editor> N.D. Jones and S.S. Muchnick. </editor> <title> A flexible approach to interprocedural data flow analysis and programs with recursive data structures. </title> <booktitle> In Conference Recordof the Ninth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 66-74, </pages> <month> January </month> <year> 1982. </year>
Reference-contexts: For example, an unrealizable path in Figure 4 is M1,M2,M3,S1,S2,S3,M6,M7. Jones and Muchnick explain a general solution to this problem as an encoding of the run-time stack <ref> [17] </ref>. Our implementation also uses an encoding of the run-time stack to deal with unrealizable paths. We perform the tuplespace partitioning as Linda operations are encountered during the ICFG construction. Each such operation is annotated with its tuplespace partition identification.
Reference: [18] <author> J.B. Kam and J.D. Ullman. </author> <title> Global flow analysis and iterative algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 23 </volume> <pages> 153-171, </pages> <year> 1976. </year>
Reference-contexts: a worst case complexity of O (n 2 ), where n is the number of nodes in the ICFG forest, and for the important class of programs with reducible flowgraphs this complexity becomes O (n fl (d + 2)) where d is the maximum cycle nesting depth of the program <ref> [18] </ref>. 5.2 Experimental Results We have run our compiler on a selection of Linda programs with encouraging results. The programs have been classified into two groups: synthetic and applications.
Reference: [19] <author> G. A. Kildall. </author> <title> Global expression optimization during compilation. </title> <booktitle> In Proceedings of the ACM Principles of Programming Languages, </booktitle> <pages> pages 194-206, </pages> <month> October </month> <year> 1973. </year>
Reference-contexts: a t [p] = a t1 [p] 1 f eval : a t [p] = a t1 [p] 1 f in : a t [p] = a t1 [p] 1 f otherwise : a t [p] = a t1 [p] These transfer functions are distributive, and thus Kildall's iterative algorithm <ref> [19] </ref> computes the MOP solution for this problem. Note that this intra-process analysis is only considering the resultant, passive tuple of the eval. We now extend the framework to accommodate the explicit parallelism of Linda.
Reference: [20] <author> William Landi and Barbara G. Ryder. </author> <title> A safe approximation algorithm for interprocedu-ral pointer aliasing. </title> <booktitle> In Proceedings of the SIG 6.10 PLAN '92 Conference on Programming Lan--guage Design and Implementation, </booktitle> <pages> pages 235-248. </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Here, we give a brief overview of our optimizing Linda compiler and its analyses; details can be found in [12]. We have developed a new SUIF compiler pass that builds an interprocedural control flow graph (ICFG) <ref> [20] </ref> for each process, resulting in a forest of ICFGs. Processes are easily identified because Linda's function parallelism is explicit. The ICFG was selected as our program representation because it is a simple and straightforward interprocedural extension of the much utilized CFG. <p> The return node is similarly made to have a single predecessor, the sink node of the called procedure. Figure 4 shows an ICFG for a simple program. An important consideration of using an interprocedural representation such as the ICFG for analysis is the existence of unrealizable paths <ref> [20] </ref>. An unrealizable path in the ICFG results from the fact that all call sites to a procedure are connected to a single entry node for the procedure; similarly, the return node of the procedure is linked back to each call site.
Reference: [21] <author> Jerrold Sol Leichter. </author> <title> Shared Tuple Memories, Shared Memories, Buses and LAN's - Linda Implementations Across the Spectrum of Connectivity. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: Linda has been implemented on massively parallel processors as well as distributed-memory hypercubes, networks of workstations, and shared-memory machines, and has been combined with a number of base languages including C, Fortran, and Lisp <ref> [10, 21, 5, 3, 6] </ref>. Moreover, Deshpande and Schultz [11] demonstrated that Linda programs can be efficient on distributed-memory machines.
Reference: [22] <author> Santosh S. Pande, Dharma P. Agrawal, and Jon Mauney. </author> <title> Compiling functional parallelism on distributed-memory systems. </title> <booktitle> IEEE Parallel & Distributed Technology, </booktitle> <pages> pages 64-76, </pages> <month> Spring </month> <year> 1994. </year>
Reference-contexts: This is how the programmer explicitly creates parallelism. This style of explicit parallelism should be differentiated from other types of parallelism. Functional, task, or DAG parallelism is the parallelism that can be exploited among different operations in a program by using data and control dependences <ref> [22] </ref> targeting a parallelism that is more coarsely grained than loop-level parallelism. Other research [22, 14] may be applied by a Linda compiler to extract these finer grained parallelisms present in individual, explicitly specified Linda processes. <p> Functional, task, or DAG parallelism is the parallelism that can be exploited among different operations in a program by using data and control dependences [22] targeting a parallelism that is more coarsely grained than loop-level parallelism. Other research <ref> [22, 14] </ref> may be applied by a Linda compiler to extract these finer grained parallelisms present in individual, explicitly specified Linda processes.
Reference: [23] <author> Madalene Spezialetti and Rajiv Gupta. </author> <title> Exploiting program semantics for efficient instrumentation of distributed event recognitions. </title> <booktitle> In Proceedings of the 13th Symposium on Reliable Distributed Systems, </booktitle> <year> 1994. </year> <month> 6.11 </month>
Reference-contexts: We are planning to investigate the application of techniques from the distributed monitoring domain <ref> [23] </ref> to assist in the detection of dependences between tuplespace partitions such as exhibited in the ping pong program described above. We also plan to investigate and develop algorithms for the identification of other tuple usage patterns especially messages and streams, and continue to build our optimizing Linda compiler.
References-found: 22

