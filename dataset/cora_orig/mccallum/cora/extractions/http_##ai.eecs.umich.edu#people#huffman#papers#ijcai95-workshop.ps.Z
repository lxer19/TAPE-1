URL: http://ai.eecs.umich.edu/people/huffman/papers/ijcai95-workshop.ps.Z
Refering-URL: http://ai.eecs.umich.edu/people/huffman/hufpubs.html
Root-URL: http://www.eecs.umich.edu
Email: huffman@tc.pw.com  
Title: Learning information extraction patterns from examples  
Author: Scott B. Huffman Price Waterhouse 
Date: February 22, 1995  
Address: 68 Willow Road Menlo Park, CA 94025  
Affiliation: Technology Centre  
Abstract: A growing population of users want to extract a growing variety of information from on-line texts. Unfortunately, current information extraction systems typically require experts to hand-build dictionaries of extraction patterns for each new type of information to be extracted. This paper presents a system that can learn dictionaries of extraction patterns directly from user-provided examples of texts and events to be extracted from them. The system, called LIEP, learns patterns that recognize relationships between key constituents based on local syntax. Sets of patterns learned by LIEP for a sample extraction task perform nearly at the level of a hand-built dictionary of patterns. 
Abstract-found: 1
Intro-found: 1
Reference: [Brill, 1994] <author> E. Brill. </author> <title> Some advances in transformation-based part of speech tagging. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pages 722-7. </pages> <year> 1994. </year>
Reference-contexts: The grammars used for identifying noun and verb groups are loosely based on those used by FASTUS [Hobbs et al., 1992]. 1 We are currently using Eric Brill's part-of-speech tagger <ref> [Brill, 1994] </ref>. 3 n_was_named_t_by_c: noun-group (PNG,head (isa (person-name))), noun-group (TNG,head (isa (title))), noun-group (CNG,head (isa (company-name))), verb-group (VG,type (passive),head (named or elected or appointed)), preposition (PREP,head (of or at or by)), subject (PNG,VG), object (VG,TNG), post_nominal_prep (TNG,PREP), prep_object (PREP,CNG) ==&gt; management_appointment (M,person (PNG),title (TNG),company (CNG)).
Reference: [Chinchor and Sundheim, 1993] <author> N. Chinchor and B. Sundheim. </author> <title> MUC-5 evaluation metrics. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5). </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: For LIEP pattern1, this is: LIEP_pattern1 (NON-GENERALIZABLE-PORTION): noun-group (PNG,head (isa (person-name))), noun-group (TNG,head (isa (title))), noun-group (CNG,head (isa (company-name))), verb-group (VG), preposition (PREP), subject (PNG,VG), 2 The F-measure <ref> [Chinchor and Sundheim, 1993] </ref> balances the recall and precision per formance of the pattern being tested. For our tests we used fi = 1:0. 9 object (VG,TNG), post_verbal_post_object_prep (VG,PREP), prep_object (PREP,CNG) ==&gt; matches_positive_example (person (PNG),title (TNG),company (CNG)).
Reference: [Hall, 1988] <author> R. J. Hall. </author> <title> Learning by failing to explain. </title> <journal> Machine Learning, </journal> <volume> 3(1) </volume> <pages> 45-77, </pages> <year> 1988. </year>
Reference-contexts: The theory is incomplete in that it cannot form an explanation (a covering set of syntactic relationships) for some examples, because the set of syntactic relationships is insufficient. A number of methods have been proposed for inductively extending domain theories to cover previously unexplainable examples (e.g., <ref> [VanLehn, 1987; Hall, 1988; Pazzani, 1991] </ref>; many others). One area of future work on LIEP is in applying such methods to inductively extend the system's vocabulary of syntactic relationships when faced with extraction examples it cannot cover.
Reference: [Hobbs et al., 1992] <author> J. R. Hobbs, D. E. Appelt, J. S. Bear, D. J. Israel, and W. Mabry Tyson. FASTUS: </author> <title> A system for extracting information from natural-language text. </title> <type> Technical Report No. 519, </type> <institution> SRI International, </institution> <month> November </month> <year> 1992. </year> <month> 14 </month>
Reference-contexts: ODIE processes an input text using a fairly typical set of phases for such systems (as described, e.g., by Hobbs [1993]). It is perhaps closest in design to SRI's FASTUS <ref> [Hobbs et al., 1992] </ref> and UMass's CIRCUS [Lehnert et al., 1993]. Given an input text, ODIE first tokenizes the text and breaks it into sentences. <p> The grammars used for identifying noun and verb groups are loosely based on those used by FASTUS <ref> [Hobbs et al., 1992] </ref>. 1 We are currently using Eric Brill's part-of-speech tagger [Brill, 1994]. 3 n_was_named_t_by_c: noun-group (PNG,head (isa (person-name))), noun-group (TNG,head (isa (title))), noun-group (CNG,head (isa (company-name))), verb-group (VG,type (passive),head (named or elected or appointed)), preposition (PREP,head (of or at or by)), subject (PNG,VG), object (VG,TNG), post_nominal_prep (TNG,PREP), prep_object
Reference: [Hobbs, 1993] <author> J. R. Hobbs. </author> <title> The generic information extraction system. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5). </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: [Lehnert et al., 1993] <author> W. Lehnert, J. McCarthy, S. Soderland, E. Riloff, C. Cardie, J. Peterson, F. Feng, C. Dolan, and S. Goldman. UMass/Hughes: </author> <title> Description of the CIRCUS system used for MUC-5. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5). </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: ODIE processes an input text using a fairly typical set of phases for such systems (as described, e.g., by Hobbs [1993]). It is perhaps closest in design to SRI's FASTUS [Hobbs et al., 1992] and UMass's CIRCUS <ref> [Lehnert et al., 1993] </ref>. Given an input text, ODIE first tokenizes the text and breaks it into sentences. For each sentence, ODIE first checks whether the sentence contains any of a set of keywords that indicate the possibility that the sentence expresses an event of interest.
Reference: [Miller, 1990] <author> George Miller. </author> <title> Five papers on WordNet. </title> <journal> International Journal of Lexicography, </journal> <volume> 3 </volume> <pages> 235-312, </pages> <year> 1990. </year>
Reference-contexts: Since for open-class items, what LIEP is learning is essentially a set of synonyms, a more aggressive learning strategy would be to use a synonym dictionary like WordNet <ref> [Miller, 1990] </ref> to propose possible synonyms to the user when a new pattern is first learned. This would reduce the number of training examples needed by the system.
Reference: [Mitchell et al., 1986] <author> T. M. Mitchell, R. M. Keller, and S. T. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <year> 1986. </year>
Reference-contexts: AutoSlog does not try to recognize relationships between multiple constituents, as LIEP does; rather, it builds smaller patterns that recognize instances of single role-fillers. Later stages of CIRCUS then combine these instances into larger events. One way to view LIEP's learning of new extraction patterns is as explanation-based learning <ref> [Mitchell et al., 1986] </ref> with an overgeneral and incomplete domain theory. LIEP's "domain theory" is its knowledge about plausible syntactic relationships. LIEP uses this theory to explain the positive examples it is given.
Reference: [MUC, 1992] <editor> Proceedings of the Fourth Message Understanding Conference (MUC-4). </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Although significant progress has been made on information extraction systems in recent years (for instance through the MUC conferences <ref> [MUC, 1992; MUC, 1993] </ref>), coding the knowledge these systems need to extract new kinds of information and events is an arduous and time-consuming process [Riloff, 1993].
Reference: [MUC, 1993] <editor> Proceedings of the Fifth Message Understanding Conference (MUC-5). </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Although significant progress has been made on information extraction systems in recent years (for instance through the MUC conferences <ref> [MUC, 1992; MUC, 1993] </ref>), coding the knowledge these systems need to extract new kinds of information and events is an arduous and time-consuming process [Riloff, 1993].
Reference: [Pazzani, 1991] <author> M. Pazzani. </author> <title> Learning to predict and explain: An integration of similarity-based, theory driven, and explanation-based learning. </title> <journal> Journal of the Learning Sciences, </journal> <volume> 1(2) </volume> <pages> 153-199, </pages> <year> 1991. </year>
Reference-contexts: The theory is incomplete in that it cannot form an explanation (a covering set of syntactic relationships) for some examples, because the set of syntactic relationships is insufficient. A number of methods have been proposed for inductively extending domain theories to cover previously unexplainable examples (e.g., <ref> [VanLehn, 1987; Hall, 1988; Pazzani, 1991] </ref>; many others). One area of future work on LIEP is in applying such methods to inductively extend the system's vocabulary of syntactic relationships when faced with extraction examples it cannot cover.
Reference: [Riloff, 1993] <author> E. Riloff. </author> <title> Automatically constructing a dictionary for information extraction tasks. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> pages 811-16. </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Although significant progress has been made on information extraction systems in recent years (for instance through the MUC conferences [MUC, 1992; MUC, 1993]), coding the knowledge these systems need to extract new kinds of information and events is an arduous and time-consuming process <ref> [Riloff, 1993] </ref>. The dictionaries of syntactic and semantic patterns used to recognize 1 each type of event are typically built by hand by a team of highly-trained specialists. <p> Most previous work on learning for information extraction has used the large corpus of pre-scored training texts provided for the MUC contests as training input (e.g., <ref> [Riloff, 1993; Soderland and Lehnert, 1994] </ref>). However, since such a corpus is not available for most extraction tasks (including extracting management changes), LIEP allows a user to interactively identify events in texts. <p> Not surprisingly, as the number of training examples increases, the number of 12 new patterns LIEP has to learn begins to level off, and more of the learning involves generalizing previously learned patterns. 6 Discussion LIEP is perhaps most closely related to Riloff's AutoSlog system <ref> [Riloff, 1993] </ref>. AutoSlog is a knowledge acquisition tool that uses a training corpus to generate proposed extraction patterns for the CIRCUS extraction system. A user either verifies or rejects each proposed pattern.
Reference: [Soderland and Lehnert, 1994] <author> S. Soderland and W. Lehnert. Wrap-Up: </author> <title> A trainable discourse module for information extraction. </title> <journal> Journal of Artificial Intelligence Research (JAIR), </journal> <volume> 2 </volume> <pages> 131-158, </pages> <year> 1994. </year>
Reference-contexts: Most previous work on learning for information extraction has used the large corpus of pre-scored training texts provided for the MUC contests as training input (e.g., <ref> [Riloff, 1993; Soderland and Lehnert, 1994] </ref>). However, since such a corpus is not available for most extraction tasks (including extracting management changes), LIEP allows a user to interactively identify events in texts.
Reference: [VanLehn, 1987] <author> K. VanLehn. </author> <title> Learning one subprocedure per lesson. </title> <journal> Artificial Intelligence, </journal> <volume> 31(1) </volume> <pages> 1-40, </pages> <year> 1987. </year> <month> 15 </month>
Reference-contexts: The theory is incomplete in that it cannot form an explanation (a covering set of syntactic relationships) for some examples, because the set of syntactic relationships is insufficient. A number of methods have been proposed for inductively extending domain theories to cover previously unexplainable examples (e.g., <ref> [VanLehn, 1987; Hall, 1988; Pazzani, 1991] </ref>; many others). One area of future work on LIEP is in applying such methods to inductively extend the system's vocabulary of syntactic relationships when faced with extraction examples it cannot cover.
References-found: 14

