URL: http://www.neci.nj.nec.com/homepages/eric/bw.ps
Refering-URL: http://www.cs.rutgers.edu/~davison/agoric-bib.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Toward a Model of Mind as a Laissez-Faire Economy of Idiots  
Author: Eric B. Baum 
Date: December 15, 1995  
Address: 4 Independence Way Princeton, NJ 08540  
Affiliation: NEC Research Institute  
Abstract: A learning machine called "The Hayek Machine" is proposed and tested on a simulated Blocks World planning problem. Hayek learns a set of agents from reinforcement. The agents interact in a market economy. A price mechanism is proposed and seen to have three desirable effects. First, the market price learns to estimate Hayek's future reward from using a given agent. Second, the market automatically selects the agent with highest estimate to act next. Third, new agents can enter the market if and only if they have greater expected utility than direct competitors. Hayek learns by gradual accretion of useful agents and elimination of poor ones,and by refinement of its price estimates. Many agents act in consort to solve problems. Our Blocks World (BW) problems, which involve discovering the abstract goal of copying a stack, and necessitate solving Towers of Hanoi-like problems, are far more complex than any BW problems previously addressed by a learning algorithm. Starting from tabula rasa, and with reinforcement only upon completion of an instance, Hayek learns to solve eight block problems. These are larger than can be solved by a simple handcrafted program, and of comparable complexity to those solvable by general purpose planners. Given intermediate reinforcement or simple features such as "top of stack", Hayek does much better. Given both, Hayek produces a set of agents which solves arbitrary Blocks World Instances, and does so efficiently on almost all such instances. My goals in studying Hayek are threefold. First, Hayek represents progress toward a useful program for learning to reason. Second, it is intended as a model of mind. It models how human-like mental capabilities can be autonomously broken into simple components nowhere invoking a homunculus. Third, it is a model of economics. Utilizing very limited agents and starting far from equilibrium, Hayek achieves a productive and stable economy. It thus gives insight as to why and how far mathematical economic predictions based on assumptions of computationally powerful and rational agents, and on convergence to equilibrium, can be expected to hold in the real world. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ackley, D., Hinton, G., and Sejnowski, T. </author> <title> (1985) A learning algorithm for Boltzmann machines. </title> <journal> cognitive Science, </journal> <volume> 9 </volume> <pages> 147-169. </pages>
Reference-contexts: As will be discussed, it is not evident that any better approach can exist for complex problems. 1 The field of Machine Learning has a Boltzmann Machine <ref> [1] </ref> and a Helmholtz machine [12] named for, respectively, an Austrian and a German physicist. Our machine is named for an Austrian economist. 2 Note, our BW problem is slightly different from the standard AI BW problem.
Reference: [2] <author> Bacchus, F., Kabanza, F. </author> <title> (1995) Using temporal logic to control search in planning, </title> <note> unpublished document available from http://logos.uwaterloo.ca/tlplan/tlplan.html. </note>
Reference-contexts: There is an extensive literature on planning. Domain independent planning is a computationally intractable problem (see e.g [14]). Empirically, general planners are challenged by BW problems with more than about five blocks (see e.g. <ref> [2] </ref>). A proposed solution is to incorporate domain knowledge (see e.g. [2]). However, experience does not encourage confidence that hand programming will generate robust, non-brittle, reasoning or planning systems in complex domains. <p> There is an extensive literature on planning. Domain independent planning is a computationally intractable problem (see e.g [14]). Empirically, general planners are challenged by BW problems with more than about five blocks (see e.g. <ref> [2] </ref>). A proposed solution is to incorporate domain knowledge (see e.g. [2]). However, experience does not encourage confidence that hand programming will generate robust, non-brittle, reasoning or planning systems in complex domains. <p> Since we are trying to model a brain, this is perhaps a good standard for judgement. The solutions Hayek invents compare favorably with our simple programming efforts, c.f. Appendix B. Bacchus and Kabanza <ref> [2] </ref> tried some sophisticated planning algorithms such as SNLP [20],[28], Prodigy 4.0 [10], and their own TLPlan on Blocks World Problems related to (but different from) ours 30 . Note that these planning algorithms were run on a Blocks World with an unbounded table.
Reference: [3] <author> Bacchus, F., </author> <type> (1995) Personal communication. </type>
Reference: [4] <author> Barkow, J. H., L. Cosimidies, and J. </author> <title> Tooby (1992) The adapted mind, </title> <publisher> Oxford University Press. </publisher> <address> NY. </address> <month> 21 </month>
Reference-contexts: It may be objected that evolution has equipped human infants with knowledge coded in. Recent research has in fact provided evidence that humans have evolved computational modules to deal with certain types of problems <ref> [4] </ref>. For example humans reason much more facilely in problems of detecting cheating and verifying social obligations than they do in logically isomorphic, and equally familiar, contexts not involving social obligations 6 [11]. However, evolution itself is a learning process, and it clearly started off with a tabula rasa.
Reference: [5] <author> Barto, A. G., Bradtke, S. J., Singh, S. P. </author> <title> (1995) learning to act using real-time dynamic programming, </title> <journal> AI Journal, </journal> <note> to appear. </note>
Reference-contexts: Note that there is an interesting difference between this framework and the standard Q-learning [35] or RTDP <ref> [5] </ref> framework. In the standard frameworks, one maintains an evaluation function that maps states of the world to numerical estimates of expected value, and chooses the action which goes to the best succeeding state. Here we are maintaining an evaluation function which maps condition action pairs to expected value.
Reference: [6] <author> Baum, E. B., Boneh, D. Garrett, C. </author> <booktitle> (1995) On Genetic Algorithms, in Proceedings of the Eighth Annual Conference on Computational Learning Theory, </booktitle> <pages> pp 230-239. </pages>
Reference-contexts: It is not evident that they are a particularly efficient, or efficiently learnable, encoding of finite state machines. It is also possibile that Genetic algorithms (GA's) are not efficient at training Classifier systems. While recent results <ref> [6] </ref> show that Genetic Algorithms can beat hill climbing dramatically in some contexts, and even provide some direct motivation for their use in training classifier-like systems, it is far from clear the idealizations necessary to prove these results will hold up in classifier systems.
Reference: [7] <author> E. B. </author> <title> Baum (1990), When are k-Nearest Neighbor and Back Propagation Accurate for Feasible Sized Sets of Examples, </title> <booktitle> in Neural Networks, EURASIP Workshop Proceedings eds. </booktitle> <editor> L.B. Almeida, C. J. Wellekens, </editor> <booktitle> Number 412 in Lecture Notes in Computer Science, </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: Theorems typically include logarithmic terms, which we are ignoring as unimportant. Some experiments seem to support the size relationship we are alleging in practice <ref> [7] </ref>, and some indicate much friendlier values (see eg [19]). 18 The question of intrinsic bias is inherently a touchy one. Evidently our Cartesian encoding has some implicit topological bias. As discussed in the introduction, this may not be unreasonable.
Reference: [8] <author> Birk, A., Paul, W. J., </author> <title> (1995) Schemas and Genetic Programming, </title> <note> document to be published. </note>
Reference-contexts: A number of authors have considered how mental capabilities may arise from the interaction of smaller units. Minsky's "Society of Mind"[23] gives one such proposal. Drescher's "schema mechanism"[13] builds up an understanding of the world through statistical means and models Piagetian development. Recently Birk and Paul <ref> [8] </ref> have extended this research to Blocks World domains (although not addressing planning problems of our type). Like Drescher, we posit intelligence as arising by automatically learning a large number of simple rules which interact to plan. <p> Agents which "go broke" can inject fictitious money into the system, resulting in inflation and distorted economic incentives. This problem, as well as alternative price mechanisms which hopefully avoid it, is described in section 3.2. 8 See also <ref> [8] </ref> and [25] for statistical arguments about the capabilities of learning systems. 9 Standard Holland Classifiers use a trinary alphabet f0; 1; flg. A * in the action string posts the corresponding component value in the condition string. It is not evident why this choice of encoding is desirable. <p> They reported experiments with at most three other blocks on top of the target green one. Since we began this work, we've seen a preprint by Birk and Paul <ref> [8] </ref> which attempts to learn also a simpler problem: to move a single block around an otherwise empty table.
Reference: [9] <author> Blumer, A. Ehrenfeucht, A., Haussler, D., Warmuth, M. K. </author> <title> (1989) Learnability and the Vapnik-Chervonenkis dimension, </title> <journal> JACM 36 </journal> <pages> 929-965. </pages>
Reference: [10] <author> Carbonell, J. G., J. Blythe, O. Etzioni, Y. Gill, R. Joseph, D. Khan, C. Knoblock, S. Minton, A. Perez, S. Reilly, M. Veloso, and X. </author> <title> Wang (1992) Prodigy 4.0: The manual and Tutorial. </title> <type> Technical Report CMU-CS-92-150, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: Since we are trying to model a brain, this is perhaps a good standard for judgement. The solutions Hayek invents compare favorably with our simple programming efforts, c.f. Appendix B. Bacchus and Kabanza [2] tried some sophisticated planning algorithms such as SNLP [20],[28], Prodigy 4.0 <ref> [10] </ref>, and their own TLPlan on Blocks World Problems related to (but different from) ours 30 . Note that these planning algorithms were run on a Blocks World with an unbounded table. SNLP, Prodigy, and TLPlan all exceeded resource bounds on problems of about six blocks.
Reference: [11] <author> Cosimidies, L. and J. </author> <title> Tooby (1992) Cognitive adaptations for Social Exchange, </title> <booktitle> in [4], </booktitle> <pages> pp 163-228. </pages>
Reference-contexts: For example humans reason much more facilely in problems of detecting cheating and verifying social obligations than they do in logically isomorphic, and equally familiar, contexts not involving social obligations 6 <ref> [11] </ref>. However, evolution itself is a learning process, and it clearly started off with a tabula rasa. Furthermore it seems plausible that much of human reasoning ability is learned within an individual lifespan, for example planning in abstract arenas such as Blocks World.
Reference: [12] <author> Dayan, P., Hinton, G., Neal, R. M., and R. S. </author> <title> Zemel,(1995) The Helmholtz machine, Neural Computation, </title> <note> to appear. </note>
Reference-contexts: As will be discussed, it is not evident that any better approach can exist for complex problems. 1 The field of Machine Learning has a Boltzmann Machine [1] and a Helmholtz machine <ref> [12] </ref> named for, respectively, an Austrian and a German physicist. Our machine is named for an Austrian economist. 2 Note, our BW problem is slightly different from the standard AI BW problem.
Reference: [13] <author> Drescher, G. L. </author> , <title> Made-Up Minds, </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference: [14] <author> Erol, K., Nau, D. S., Subrahmanian, V. S.. </author> <title> (1992) On the complexity of domain independent planning. </title> <booktitle> In Proceedings of the AAAI National Conference, </booktitle> <pages> pp 381-386. </pages>
Reference-contexts: In its learning aspect, Hayek may be viewed as a hill climbing approach in algorithm space. There is an extensive literature on planning. Domain independent planning is a computationally intractable problem (see e.g <ref> [14] </ref>). Empirically, general planners are challenged by BW problems with more than about five blocks (see e.g. [2]). A proposed solution is to incorporate domain knowledge (see e.g. [2]). However, experience does not encourage confidence that hand programming will generate robust, non-brittle, reasoning or planning systems in complex domains.
Reference: [15] <author> Forrest, S. </author> <title> (1985) Implementing semantic network structures using the classifier system. </title> <booktitle> In Proc. First International Conference on Genetic Algorithms, </booktitle> <pages> pp 188-196. </pages> <address> Hillsdale NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: [16] <author> Holland, J. H. </author> <title> (1986) Escaping brittleness: the possibilities of general purpose learning algorithms applied to parallel rule-based systems. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, (eds.) </editor> <booktitle> Machine Learning II pp 593-623, </booktitle> <publisher> Los Altos CA Morgan Kauffman. </publisher>
Reference-contexts: The highest bid wins and: (a) its action is taken, (b) it pays out its bid, (c) it may receive payment. Insufficiently profitable agents die and new agents are created by a random process. Hayek is inspired by Holland classifier systems <ref> [16] </ref> but differs from them in having more flexibility in its encoding and in important aspects of its price and rule learning mechanisms. In its planning aspect, Hayek may be viewed as an economy, composed of agents whose individual actions are organized by a price mechanism to perform useful computations. <p> We investigate here proposals for some questions he has postponed answering, such as how a mind might decide what to learn, and what the control structure of a `brain' may be. Holland's Classifier systems <ref> [16] </ref> were (to our knowledge) the first explicit proposal of an economic analog of mind. They also use condition, action, bid agents. Holland classifiers have, however, been disappointing empirically [36]. There are a number of plausible causes of this disappointment. One is the inflexible encoding Holland Classifiers use 9 . <p> Any agent satisfying this is dubbed consistent. If there is more than one such wildcard instantiation the first one found is employed 14 . This choice instantiates the wildcard variables in its action, which then becomes well defined. This handling of wildcards is analagous to that of <ref> [16] </ref>. The action of the consistent agent with the highest bid 15 is taken 16 . As the system acts, the agents accumulate wealth by paying out their bids and getting paid in return. The wealth of agents fluctuates from instance to instance. <p> The metarule learning, being higher up the hierarchy, occurs relatively infrequently. 3.2 Bid determination As the owner of Hayek, we wish to solve Blocks World Problems. We have done this by subcontracting to agents. We have set up a bidding scheme where each agent pays the previous one <ref> [16] </ref>. Thus each agent buys the right to perform one action, to receive any payoff on that turn, and to receive payoff from the next agent. The point of this is that it both estimates the best agent at each step, and motivates the agents to be useful. <p> The second method we tried was suggested by the "Bucket Brigade" approach Holland used in his classifier systems <ref> [16] </ref>. Holland proposed using b = ffsW where ff is a small constant, s is the specificity of a classifier, and W its wealth. The specificity basically measures how general the rule is. The notion was that more specific rules should be used preferentially when they are applicable. <p> Thus this system prefers a more general agent over a more specific agent with the same overall expected value. This is precisely the opposite of what intuition tells us we should douse the more specific agent which is probably more pertinent <ref> [16] </ref>. Possibly the reason why imposing a rent has been useful is because of transient, as opposed to equilibrium effects. Imagine an agent entering which has negative expected payoff each time it is used.
Reference: [17] <author> Khardon, R., Roth, D. </author> <title> (1994) Learning to reason. </title> <booktitle> Proc. 12th National Conference on Artificial Intelligence, </booktitle> <publisher> AAAI Press/ MIT Press pp 682-687. </publisher>
Reference-contexts: Khardon and Roth have however constructed examples where simultaneously (1) reasoning from given representations of the world is intractable, (2) learning representations of the world is intractable, but (3) directly learning to reason about the world is feasible <ref> [17] </ref>. The approach taken in the present paper is to learn directly how to plan relying only on reinforcement guided local search. There are at least two evident concerns about this approach, which we hope to address.
Reference: [18] <editor> Koza, J.R., </editor> <booktitle> (1992) Genetic Programming, </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge MA, </address> <pages> pp 459-470. </pages>
Reference-contexts: Since we began this work, we've seen a preprint by Birk and Paul [8] which attempts to learn also a simpler problem: to move a single block around an otherwise empty table. Finally Koza <ref> [18] </ref> addressed a simplified problem where the table was unbounded (so there was no Tower of Hanoi aspect), the goal is fixed from instance to instance (so instead of learning the abstract goal of copying a stack, he was learning the concrete goal 11 of producing a fixed stack), the number
Reference: [19] <author> Martin, G. M., Pittman, J. A., </author> <title> (1990) Recognizing hand-printed letters and digits, </title> <booktitle> in Advances in Neural Information Processing Systems 2 ed D. </booktitle> <editor> S. Touretzky pp504-414, </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo CA. </address>
Reference-contexts: Theorems typically include logarithmic terms, which we are ignoring as unimportant. Some experiments seem to support the size relationship we are alleging in practice [7], and some indicate much friendlier values (see eg <ref> [19] </ref>). 18 The question of intrinsic bias is inherently a touchy one. Evidently our Cartesian encoding has some implicit topological bias. As discussed in the introduction, this may not be unreasonable.
Reference: [20] <author> McAllester, D., and D. </author> <booktitle> Rosenblitt (1991) "Systematic nonlinear planning" in Proceedings of the AAAI National Conference, </booktitle> <pages> pp 634-639. </pages>
Reference: [21] <author> Miller, M. S., and K. E. Drexler, </author> <title> "Markets and computation: Agoric open systems", </title> <editor> in B. A. Huberman, ed, </editor> <booktitle> The Ecology of Computation, Studies in Computer Science and Artificial Intelligence 2, </booktitle> <publisher> North Holland, </publisher> <address> New York, pp133-176, </address> <year> (1988). </year>
Reference-contexts: But to add agents slowly in a smooth way, one must address carefully the question of their initial bids. Miller and Drexler have proposed "Agoric computation", a model of computing based on an economic analog <ref> [21] </ref>. These authors point out that it is possible to imagine constructing a computational market on one's computer free from any problems some might worry would plague a free market among humans.
Reference: [22] <author> Palmer, R. G., Arthur, W. B., Holland, J. H., LeBaron, B., Tyler, P. </author> <title> (1994) Articifial economic life: a simple model of a stockmarket, </title> <journal> Physica D 75 pp 264-274. </journal>
Reference-contexts: A number of economic phenomena, such as "speculative bubbles", "cherrypicking", and competition forcing profit margins to zero are observed or analyzed, particularly in sections 3.2 and 3.3. For work somewhat related to the present paper, studying deviations from RE by "Evolutionary Economics", see e.g. <ref> [22] </ref>. 12 We are indebted to some prior author, unknown to us (Adam Smith?), for this pencil koan. 6 2 Blocks World Our blocks world 13 is a simulation of the following physical situation. We have a `table' consisting of S stacks of blocks. In our experiments S was 4.
Reference: [23] <author> Minsky, M., </author> <title> (1986)The Society of Mind Simon and Schuster, </title> <address> NY. </address>
Reference: [24] <author> Myhrvold, N., </author> <title> (1994) Roadkill on the information highway, </title> <institution> Stanford, Calif.: University Video Communications, Distinguished Lecture Series IX; Leaders in Computer Science and electrical Engineering. </institution> <month> 22 </month>
Reference-contexts: Myhrvold, for one, predicts that the cost of computing will continue to drop by 10 3 per decade for the next four decades <ref> [24] </ref>. Assuming this comes to pass, what will we do with all these cycles? To date the primary sink of cycles has been graphics, but Myhrvold notes that this use will soon be saturated. We predict many cycles will be used to self-organize computation.
Reference: [25] <author> Paul, W., Solomonoff, R. </author> <title> (1990) Autonomous theory building systems, in Neural networks and adaptive learning, Schloss Reisenberg Knowledge Processing and its applications series, </title> <publisher> Elsevier science publishers B.V. </publisher>
Reference-contexts: Agents which "go broke" can inject fictitious money into the system, resulting in inflation and distorted economic incentives. This problem, as well as alternative price mechanisms which hopefully avoid it, is described in section 3.2. 8 See also [8] and <ref> [25] </ref> for statistical arguments about the capabilities of learning systems. 9 Standard Holland Classifiers use a trinary alphabet f0; 1; flg. A * in the action string posts the corresponding component value in the condition string. It is not evident why this choice of encoding is desirable.
Reference: [26] <author> Ray, T. S. </author> <title> (1991) An approach to the synthesis of life. </title> <editor> In C. Langton, C. Taylor, J. D. Farmer, and Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <volume> volume XI, </volume> <pages> pages 371-408. </pages> <publisher> Addison-Wesley, </publisher> <address> Redwood City, CA. </address>
Reference-contexts: We compare the results achieved by Hayek to several of these efforts in x 8. Results of several authors suggest large naive autonomous learners may in general be surprisingly effective. Ray's Tierra system evolved to contain behavior <ref> [26] </ref> that impresses one as complex and lifelike, although it is not clear to us how to quantify this impression. In another context, large, dumb, neural nets have been surprisingly effective at a variety of problems.
Reference: [27] <author> Rothschild, M. </author> <note> (199?) Bionomics, Economy as Ecosystem </note>
Reference-contexts: Another question is whether it can stably apply separate agents to more than one problem. Human economies, like ecosystems, develop multiple niches. For example, wherever you go in the the US today you find grocery stores occupying seven distinct economic niches, ranging from convenience through high-end through warehouse <ref> [27] </ref>. You also find distinct businesses, like lawyers, or auto mechanics. Some businesses operate entirely independently of other businesses, others operate in different industries but have common suppliers or consultants or consumers. Our minds, likewise, have many different skills. Some interact with each other, and some are seemingly largely distinct.
Reference: [28] <author> Soderlan, S. , Barrett, T., and Weld, D. </author> <title> (1990) The SNLP planner implementation, contact bug-snlp@cs.washington.edu. </title>
Reference: [29] <author> Sutton, R. S. </author> <title> (1988) Learning to predict by the methods of temporal differences, </title> <booktitle> Machine Learning 3: </booktitle> <pages> 9-44. </pages>
Reference-contexts: We have considered four different methods for determining the bid of a agent. The first is Real Time Dynamic Programming (RTDP) or Temporal Difference type (TD) learning. TD is a well known method for learning an estimate of the expected reward coming from using an agent <ref> [29] </ref>. A simple realization of a TD method, for instance, is to update the bid, whenever an agent is used, by b ! b (1 *) + (b 0 + payoff)(*) where b 0 is the bid of the following rule and payoff is any reward on that particular step.
Reference: [30] <author> Tesauro, G. </author> <title> (1992) Practical issues in temporal difference learing, </title> <booktitle> Machine Learning 8. </booktitle>
Reference-contexts: Possibly the most striking example is Tesauro's backgammon player, which used Temporal Difference learning and starting from zero knowledge trained a neural network to serve as a strong evaluation function for the game of backgammon <ref> [30] </ref>. If started with hand coded features, the evaluation function produced sufficed to play at near championship level. Tesauro's success with backgammon is striking because noone has succeeded in using this method to solve any other problem of comparable apparent complexity.
Reference: [31] <author> Tooby, J. and L. </author> <note> Cosimidies(1992) The psycological foundations of culture, in [4] pp19- 136 (see esp.pp 69-73). </note>
Reference-contexts: Our encoding of the BW problems represents "blocks" of a particular color, rather than, say, direct sensory input. The recent psychophysical experiments contradicting Piagetian notions of a tabula rasa indicate that humans are born with some notion of objects and object permanence <ref> [31] </ref>. As will be seen, our encoding implicitly contains some influences of physical topology. But this encoding is fairly weak, and within this encoding, Hayek is initialized entirely randomly.
Reference: [32] <author> Valiant, L. </author> <title> (1995) Rationality, </title> <booktitle> in Proceedings of the Eighth Annual Conference on Computational Learning Theory, </booktitle> <pages> 3-14. </pages>
Reference: [33] <author> Valiant, L. </author> <title> (1994) Circuits of the Mind, </title> <publisher> Oxford University Press. </publisher>
Reference: [34] <author> Whitehead, S. D. and D. H. Ballard. </author> <title> (1991) "Learning to Perceive and Act." </title> <journal> Machine Learning 7, </journal> <volume> 1, </volume> <pages> 45-83. </pages>
Reference-contexts: Several authors have studied learning to plan in a Blocks world context. However the versions of Blocks World they have studied are far simpler than that studied here. Whitehead and Ballard <ref> [34] </ref> applied Reinforcement Learning techniques to a BW problem in which the goal is simply to pick up a green block.
Reference: [35] <author> Watkins, C. J. C. H. </author> <title> (1989) Learning from delayed rewards, </title> <type> Doctoral thesis, </type> <institution> Cambridge University, </institution> <address> Cam-bridge England. </address>
Reference-contexts: Note that there is an interesting difference between this framework and the standard Q-learning <ref> [35] </ref> or RTDP [5] framework. In the standard frameworks, one maintains an evaluation function that maps states of the world to numerical estimates of expected value, and chooses the action which goes to the best succeeding state.
Reference: [36] <author> Wilson, S. W., Goldberg, D. E. </author> <title> (1989) A critical review of classifier systems. </title> <editor> In J. D. Schaffer, ed. </editor> <booktitle> Proc. Third International Conf. </booktitle> <address> on Genetic Algorithms San Mateo CA, </address> <publisher> Morgan Kauffman. </publisher>
Reference-contexts: Holland's Classifier systems [16] were (to our knowledge) the first explicit proposal of an economic analog of mind. They also use condition, action, bid agents. Holland classifiers have, however, been disappointing empirically <ref> [36] </ref>. There are a number of plausible causes of this disappointment. One is the inflexible encoding Holland Classifiers use 9 . While Holland Classifiers have been shown to be capable of "universal computation"[15], universal computers require infinite memory. Memory is realized in Holland Classifier Systems by `classifiers'.

References-found: 36

