URL: http://www.cs.columbia.edu:80/~sal/hpapers/jiis.ps
Refering-URL: http://www.cs.columbia.edu:80/~sal/recent-papers.html
Root-URL: 
Title: On the Accuracy of Meta-learning for Scalable Data Mining  Editor:  
Author: PHILIP K. CHAN SALVATORE J. STOLFO 
Keyword: machine learning, meta-learning, scalability, data mining, classifiers.  
Address: Melbourne, FL 32901  New York, NY 10027  
Affiliation: Computer Science, Florida Institute of Technology,  Department of Computer Science, Columbia University,  
Note: 1-25 c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Email: pkc@cs.fit.edu  sal@cs.columbia.edu  
Date: Received May, 1995  
Abstract: In this paper, we describe a general approach to scaling data mining applications that we have come to call meta-learning. Meta-Learning refers to a general strategy that seeks to learn how to combine a number of separate learning processes in an intelligent fashion. We desire a meta-learning architecture that exhibits two key behaviors. First, the meta-learning strategy must produce an accurate final classification system. This means that a meta-learning architecture must produce a final outcome that is at least as accurate as a conventional learning algorithm applied to all available data. Second, it must be fast, relative to an individual sequential learning algorithm when applied to massive databases of examples, and operate in a reasonable amount of time. This paper focussed primarily on issues related to the accuracy and efficacy of meta-learning as a general strategy. A number of empirical results are presented demonstrating that meta-learning is technically feasible in wide-area, network computing environments. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> K. Ali and M. Pazzani. </author> <title> Error reduction through learning multiple descriptions. </title> <booktitle> Machine Learning, </booktitle> <year> 1996. </year> <note> to appear. </note>
Reference-contexts: These latter ideas suggest a general approach that may exhibit favorable scaling characteristics as we discuss later. Other researchers investigate different characteristics for successful integration of multiple classifiers. Ali and Pazzani <ref> [1] </ref> empirically show that classifiers with fewer uncorrelated errors reduce the error rate for the integrated model. Krogh and Vedelsby [13] prove that the overall error rate can be reduced by classifiers generating highly independent predictions. Next we are going to detail our meta-learning approach. 3.
Reference: 2. <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA, </address> <year> 1984. </year>
Reference-contexts: Our results are reported next. 6. Experimental Results and Evaluation One of the more common techniques used in evaluating the accuracy of a learning program is cross-validation <ref> [2] </ref>. In this technique, the entire data set is divided into a training set and a disjoint test set. Classifiers are computed only from the training set and are evaluated only against the test set. <p> Also, statistical significance in difference of averages is measured by using the one-sided t-test with a 90% confidence value. 15 6.1. Learning Algorithms Four inductive learning algorithms are used in our experiments. We obtained ID3 [16] and CART <ref> [2] </ref> as part of the IND package [3] from NASA Ames Research Center; both algorithms compute decision trees. WPEBLS is the weighted version of PEBLS [10], which is a nearest-neighbor learning algorithm. BAYES is a Bayesian classifier that is based on computing conditional probabilities as described in [9].
Reference: 3. <author> W. Buntine and R. Caruana. </author> <title> Introduction to IND and Recursive Partitioning. </title> <institution> NASA Ames Research Center, </institution> <year> 1991. </year>
Reference-contexts: Also, statistical significance in difference of averages is measured by using the one-sided t-test with a 90% confidence value. 15 6.1. Learning Algorithms Four inductive learning algorithms are used in our experiments. We obtained ID3 [16] and CART [2] as part of the IND package <ref> [3] </ref> from NASA Ames Research Center; both algorithms compute decision trees. WPEBLS is the weighted version of PEBLS [10], which is a nearest-neighbor learning algorithm. BAYES is a Bayesian classifier that is based on computing conditional probabilities as described in [9]. The latter two algorithms were reimplemented in C. 6.2.
Reference: 4. <author> J. Catlett. </author> <title> Megainduction: A test flight. </title> <booktitle> In Proc. Eighth Intl. Work. Machine Learning, </booktitle> <pages> pages 596-599, </pages> <year> 1991. </year>
Reference-contexts: Otherwise, using a massive database would imply that we have unbounded resources and time in order to compute baseline statistics. As we have noted (as well as <ref> [4] </ref>) this might take many years of computing. Furthermore, scaling studies are possible on these smaller sets simply by varying the number and size of the subsets formed in the initial data reduction schemes and extrapolating.
Reference: 5. <author> P. Chan and S. Stolfo. </author> <title> Experiments on multistrategy learning by meta-learning. </title> <booktitle> In Proc. Second Intl. Conf. Info. Know. Manag., </booktitle> <pages> pages 314-323, </pages> <year> 1993. </year>
Reference-contexts: Combiner Strategies In the combiner <ref> [5] </ref> strategy, the predictions of the learned base classifiers on the training set form the basis of the meta-learner's training set. A composition rule, which varies in different schemes, determines the content of training examples for the meta-learner.
Reference: 6. <author> P. Chan and S. Stolfo. </author> <title> Meta-learning for multistrategy and parallel learning. </title> <booktitle> In Proc. Second Intl. Work. on Multistrategy Learning, </booktitle> <pages> pages 150-165, </pages> <year> 1993. </year>
Reference-contexts: scaling problem is to execute a number of learning processes (each implemented as a distinct serial program) on a number of data subsets (a data reduction technique) in parallel (eg. over a network of separate processing sites) and then to integrate the collective results through a process we call meta-learning <ref> [6] </ref>. Without any integration, as we discuss later, individual results generated from the data subsets are far from desired. Here, meta-learning serves as the means of "gluing" multiple knowledge sources together.
Reference: 7. <author> P. Chan and S. Stolfo. </author> <title> Toward parallel and distributed learning by meta-learning. </title> <booktitle> In Working Notes AAAI Work. Know. Disc. Databases, </booktitle> <pages> pages 227-240, </pages> <year> 1993. </year>
Reference-contexts: The arbiter/combiner is also a classifier, and hence other arbiters or combiners can be computed from the set of predictions of other arbiters/combiners. 4.1. Arbiter Strategies An arbiter <ref> [7] </ref> is learned by some learning algorithm to arbitrate among predictions generated by different base classifiers. This arbiter, together with an arbitration rule, decides a final classification outcome based upon the base predictions. <p> For example, in a network computing environment each classifier may be encapsulated as an "agent" that is communicated among sites. We experimented with several different arbiter strategies besides the one described in Section 4.1. (The entire set of results we obtained for all the various strategies are reported in <ref> [7] </ref>.) Next, we discuss the computational efficiency of the various strategies we explored. 5.1.1. Discussion Since an arbiter training set is constructed from the results of the arbiter's two subtrees, each node in the arbiter tree is a synchronization point.
Reference: 8. <author> P. Chan and S. Stolfo. </author> <title> Scaling learning by meta-learning over disjoint and partially replicated data. </title> <booktitle> In Proc. Ninth Florida AI Research Symposium, </booktitle> <pages> pages 151-155, </pages> <year> 1996. </year>
Reference-contexts: architecture can learn effectively with a fraction of the total available information at any one site, that accuracy can be boosted over the global classifier trained from all available data, and that maximal parallelism can be effectively exploited by meta-learning over disjoint data partitions without a substantial loss of accuracy <ref> [8] </ref>. These results suggest strongly that a "field test" of these techniques over a real world network computing environment (eg. over database server sites on the web) is not only technically feasible, but also an important next step in the development of these ideas. <p> The classifiers generated from these subsets may be closer in behavior to the global classifier produced from the entire training set than those trained on random class distributions. In addition, disjoint data subsets promote the maximum amount of parallelism and hence are more desirable. Yet partial replication <ref> [8] </ref> may mitigate the problem of extreme bias potentially introduced by disjoint data. Strategies: There are indeed many strategies for arbitration and combining as detailed here, each impacting the size of training data required to implement them effectively.
Reference: 9. <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 261-285, </pages> <year> 1989. </year>
Reference-contexts: one classifier predicts y, the other does not) might have much more predictive value (eg. when combined with a third classifier) than merely knowing that the two classifiers predict y with equal probability! We view the purely Bayesian approach as a baseline, and use methods derived from this approach, BAYES <ref> [9] </ref> and Bayesian-belief [22], for comparative purposes in our experiments reported later. There are many other approaches we might imagine that are based upon learning relationships between classifiers. <p> WPEBLS is the weighted version of PEBLS [10], which is a nearest-neighbor learning algorithm. BAYES is a Bayesian classifier that is based on computing conditional probabilities as described in <ref> [9] </ref>. The latter two algorithms were reimplemented in C. 6.2. Learning Tasks Two molecular biology sequence analysis data sets, obtained from the UCI Machine Learning Database, were used in our studies.
Reference: 10. <author> S. Cost and S. Salzberg. </author> <title> A weighted nearest neighbor algorithm for learning with symbolic features. </title> <journal> Machine Learning, </journal> <volume> 10 </volume> <pages> 57-78, </pages> <year> 1993. </year>
Reference-contexts: Learning Algorithms Four inductive learning algorithms are used in our experiments. We obtained ID3 [16] and CART [2] as part of the IND package [3] from NASA Ames Research Center; both algorithms compute decision trees. WPEBLS is the weighted version of PEBLS <ref> [10] </ref>, which is a nearest-neighbor learning algorithm. BAYES is a Bayesian classifier that is based on computing conditional probabilities as described in [9]. The latter two algorithms were reimplemented in C. 6.2.
Reference: 11. <author> M. Craven and J. Shavlik. </author> <title> Learning to represent codons: A challenge problem for constructive induction. </title> <booktitle> In Proc. IJCAI-93, </booktitle> <pages> pages 1319-1324, </pages> <year> 1993. </year>
Reference-contexts: Each sequence has 60 nucleotides with eight different values each (four base ones plus four combinations). The protein coding regions (PCR) data set <ref> [11] </ref>, courtesy of Craven and Shavlik, contains 20,000 DNA nucleotide sequences and their binary classifications (coding or non-coding). Each sequence has 15 nucleotides with four different values each.
Reference: 12. <author> N. Flann and T. Dietterich. </author> <title> A study of explanation-based mehtods for inductive learning. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 187-266, </pages> <year> 1989. </year>
Reference-contexts: There are mainly two strategies that we may consider in integrating different learning strategies. One strategy is to increase the amount of knowledge in the learning system. For example, some work has been reported on integrating inductive and explanation-based learning <ref> [12] </ref>. Explanation-based techniques are integrated to provide the appropriate domain knowledge that complements inductive learning, which is knowledge poor. This approach requires a complicated new algorithm that implements both strategies to learning in a single system.
Reference: 13. <author> A. Krogh and J. Vedelsby. </author> <title> Neural network ensembles, cross validation, and active learning. </title> <editor> In G. Tesauro, D. Touretzky, and T. Leen, editors, </editor> <booktitle> Advances in Neural Info. Proc. Sys. </booktitle> <volume> 7, </volume> <pages> pages 231-238. </pages> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: Other researchers investigate different characteristics for successful integration of multiple classifiers. Ali and Pazzani [1] empirically show that classifiers with fewer uncorrelated errors reduce the error rate for the integrated model. Krogh and Vedelsby <ref> [13] </ref> prove that the overall error rate can be reduced by classifiers generating highly independent predictions. Next we are going to detail our meta-learning approach. 3. Meta-Learning Meta-learning is loosely defined as learning of meta-knowledge about learned knowledge.
Reference: 14. <author> N. Littlestone and M. Warmuth. </author> <title> The weighted majority algorithm. </title> <type> Technical Report UCSC-CRL-89-16, </type> <institution> Univ. Cal., Santa Cruz, </institution> <year> 1989. </year>
Reference-contexts: The weights of each classification are summed and the final prediction is the classification with the most weight. Littlestone and Warmuth <ref> [14] </ref> propose several weighted majority algorithms for integrating different classifiers. (In their work the classifiers are different prediction algorithms, which are not necessarily learned.
Reference: 15. <author> T. M. Mitchell. </author> <title> The need for biases in learning generalizaions. </title> <type> Technical Report CBM-TR-117, </type> <institution> Dept. Comp. Sci., Rutgers Univ., </institution> <year> 1980. </year>
Reference-contexts: Several experiments have been conducted and are reported below to explore these issues. 3.2. Integrating Base Classifiers Since different learning algorithms employ different knowledge representations and search heuristics, different search spaces may be explored by each and hence potentially diverse results can be obtained. Mitchell <ref> [15] </ref> refers to this phenomenon as inductive bias; the outcome of running an algorithm is biased towards a certain outcome. Furthermore, different partitions of a data set have different statistical 6 characteristics and the performance of any single learning algorithm might differ substantially over these partitions.
Reference: 16. <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: This represents hundreds of experimental runs over the various meta-learning strategies in-toto. Also, statistical significance in difference of averages is measured by using the one-sided t-test with a 90% confidence value. 15 6.1. Learning Algorithms Four inductive learning algorithms are used in our experiments. We obtained ID3 <ref> [16] </ref> and CART [2] as part of the IND package [3] from NASA Ames Research Center; both algorithms compute decision trees. WPEBLS is the weighted version of PEBLS [10], which is a nearest-neighbor learning algorithm.
Reference: 17. <author> R. Schapire. </author> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 197-226, </pages> <year> 1990. </year>
Reference-contexts: Some research has concentrated on methods to improve an 3 existing algorithm by using the algorithm itself to generate purposely biased distributions of training data. The most notable work in this area is due to Schapire <ref> [17] </ref>. Schapire proves, under the theoretical PAC (Probabilistic Approximately Correct) learning model [20], that his boosting technique can improve a "weak" learner to achieve arbitrary high accuracy. Other researchers have proposed implementing learning systems by integrating in some fashion a number of different algorithms to boost overall accuracy.
Reference: 18. <author> S. Stolfo, Z. Galil, K. McKeown, and R. Mills. </author> <title> Speech recognition in parallel. </title> <booktitle> In Proc. Speech Nat. Lang. Work., </booktitle> <pages> pages 353-373. DARPA, </pages> <year> 1989. </year>
Reference-contexts: In our experiments reported below, we estimate the conditional probabilities from the frequencies generated from the validation set. A more interesting approach to loosely combine learning programs is to learn how to combine independently learned concepts. Stolfo et al. <ref> [18] </ref> propose learning rules by training weighted voting schemes, for merging different phoneme output representations from multiple trained speech recognizers.
Reference: 19. <author> G. Towell, J. Shavlik, and M. Noordewier. </author> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proc. AAAI-90, </booktitle> <pages> pages 861-866, </pages> <year> 1990. </year>
Reference-contexts: The latter two algorithms were reimplemented in C. 6.2. Learning Tasks Two molecular biology sequence analysis data sets, obtained from the UCI Machine Learning Database, were used in our studies. The DNA splice junctions (SJ) data set <ref> [19] </ref>, courtesy of Towell, Shavlik and No-ordewier, contains 3,190 sequences of nucleotides and the type of splice junction, if any, at the center of each sequence (three classes). Each sequence has 60 nucleotides with eight different values each (four base ones plus four combinations).
Reference: 20. <author> L. Valiant. </author> <title> A theory of the learnable. </title> <journal> Comm. ACM, </journal> <volume> 27 </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: Some research has concentrated on methods to improve an 3 existing algorithm by using the algorithm itself to generate purposely biased distributions of training data. The most notable work in this area is due to Schapire [17]. Schapire proves, under the theoretical PAC (Probabilistic Approximately Correct) learning model <ref> [20] </ref>, that his boosting technique can improve a "weak" learner to achieve arbitrary high accuracy. Other researchers have proposed implementing learning systems by integrating in some fashion a number of different algorithms to boost overall accuracy.
Reference: 21. <author> D. Wolpert. </author> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 241-259, </pages> <year> 1992. </year>
Reference-contexts: A more interesting approach to loosely combine learning programs is to learn how to combine independently learned concepts. Stolfo et al. [18] propose learning rules by training weighted voting schemes, for merging different phoneme output representations from multiple trained speech recognizers. Wolpert <ref> [21] </ref> presents a theory of stacked generalization to combine several classifiers. (Indeed, this work is closest to what we mean by meta-learning as we will describe later.) Several (level 0) classifiers are first learned from the same training set. <p> Return meta-level training instances with the correct classification and the pre dictions; i.e., 10 T = f (class (x); C 1 (x); C 2 (x); :::C k (x)) j x 2 Eg: This scheme was also used by Wolpert <ref> [21] </ref>. (For further reference, this scheme is denoted as class-combiner.) 2.
Reference: 22. <author> L. Xu, A. Krzyzak, and C. Suen. </author> <title> Methods of combining multiple classifires and their applications to handwriting recognition. </title> <journal> IEEE Trans. Sys. Man. Cyb., </journal> <volume> 22 </volume> <pages> 418-435, </pages> <year> 1992. </year>
Reference-contexts: predictions are incorrect are multiplied by a fixed discount fi, where 0 fi &lt; 1, that decreases their contribution to final predictions. (A variation of the basic W M algorithm, called W M L, does not allow the weights to be discounted beyond a predefined limit.) 4 Xu et al. <ref> [22] </ref> developed a method for integrating predictions from multiple classifiers based on the Bayesian formalism. <p> y, the other does not) might have much more predictive value (eg. when combined with a third classifier) than merely knowing that the two classifiers predict y with equal probability! We view the purely Bayesian approach as a baseline, and use methods derived from this approach, BAYES [9] and Bayesian-belief <ref> [22] </ref>, for comparative purposes in our experiments reported later. There are many other approaches we might imagine that are based upon learning relationships between classifiers.
Reference: 23. <author> X. Zhang, J. Mesirov, and D. Waltz. </author> <title> A hybrid system for protein secondary structure prediction. </title> <journal> J. Mol. Biol., </journal> <volume> 225 </volume> <pages> 1049-1063, </pages> <year> 1992. </year>
Reference-contexts: When an instance is being classified, the level 0 classifiers first make their predictions on the instance. The predictions are then presented to the level 1 classifier, which makes the final prediction. Zhang et al.'s <ref> [23] </ref> work utilizes a similar approach to learn a combiner based on the predictions made by three different classifiers. These latter ideas suggest a general approach that may exhibit favorable scaling characteristics as we discuss later. Other researchers investigate different characteristics for successful integration of multiple classifiers.
References-found: 23

