URL: ftp://ftp.cs.utexas.edu/pub/lam/MiSock.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/lam/NRL/video_services.html
Root-URL: 
Email: fyau,lamg@cs.utexas.edu  
Title: Migrating Sockets for Networking with Quality of Service Guarantees  
Author: David K.Y. Yau and Simon S. Lam 
Address: Austin, Texas 78712-1188  
Affiliation: Department of Computer Sciences The University of Texas at Austin  
Abstract: Migrating Sockets is the protocol processing component of an end system architecture designed for networking with QoS guarantees. The architecture provides (1) adaptive rate-controlled scheduling of protocol threads in Migrating Sockets, (2) rate-based flow control for reserved rate connections in future integrated services networks, and (3) a constant overhead active demultiplexing mechanism. Migrating Sockets achieves its efficiency by allowing user applications to manage a network endpoint with minimal system intervention, providing user level protocols read-only access to routing information in a well-known shared memory region, and integrating efficient kernel level support we previously built. It is backward compatible with Unix semantics and Berkeley sockets, and has been used to implement Internet protocols such as TCP, UDP and IP (including IP multicast). We also show that active demultiplex-ing supported by Migrating Sockets can be transparently enabled in wide-area TCP/IP internetworking (although it is not restricted to TCP/IP). We have an implementation of Migrating Sockets in Solaris 2.5. We discuss our implementation experience, and present performance results of our system running on the Ultra-1, SPARC 10 and SPARC 20 architectures. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M.L. Bailey, B. Gopal, M.A. Pagels, L.L. Peterson, and P. Sarkar. PATHFINDER: </author> <title> A pattern-based packet classifier. </title> <booktitle> In Proc. First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 115123, </pages> <address> Monterey, CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: On the receive side, packet arrivals to a network interface are processed by the interrupt handler of the interface. Kernel level code must then demultiplex the packets to their destination processes. Traditionally, such demultiplexing is performed by packet filters [5, 12] (also known as packet classifiers in <ref> [1] </ref>). Our system makes use of packet filters, but, in addition, can exploit exclusive packet receiver information exported by Migrating Sockets to perform active packet demultiplexing.
Reference: 2. <author> S. Bradner and A. Mankin. </author> <title> The recommendation for the IP next generation protocol. Internet RFC 1752, </title> <month> January </month> <year> 1995. </year>
Reference-contexts: Such work on end system support complements recent research on integrated services networks. QoS guarantees provided by network level packet scheduling and admission control through Internet resource reservation protocols being developed <ref> [2, 6, 23] </ref> can thus be extended to the ultimate endpoints of an end-to-end communication, namely applications running in user space of general purpose operating systems. End system support for networking with QoS guarantees is a challenging problem.
Reference: 3. <author> Torsten Braun and Christophe Diot. </author> <title> Protocol implementation using integrated layer processing. </title> <booktitle> In Proc. ACM SIGCOMM '95, </booktitle> <address> Boston, MA, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: These works target high performance on the send/receive path, without paying much attention to the issues of connection management, routing management, and the semantics of sharing network endpoints. Performance benefits of Integrated Layer Processing in user level protocols are evaluated in <ref> [3] </ref>.
Reference: 4. <author> Chris Dalton, Greg Watson, David Banks, Costas Calamvokis, Aled Edwards, and John Lumley. </author> <title> Afterburner. </title> <journal> IEEE Network, </journal> <volume> 7(4):3643, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: There has been growing interest in user level protocol implementation in recent years [11, 19]. A user level TCP implementation on top of the Jetstream high-speed network interface is described in <ref> [4] </ref>. U-Net [20] integrates interface firmware with host software in a design that provides user level access to a network without kernel intervention.
Reference: 5. <author> D.R. Engler and M.F. Kaashoek. DPF: </author> <title> fast, flexible message demultiplexing using dynamic code generation. </title> <booktitle> In Proc. ACM SIGCOMM '96, </booktitle> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: On the receive side, packet arrivals to a network interface are processed by the interrupt handler of the interface. Kernel level code must then demultiplex the packets to their destination processes. Traditionally, such demultiplexing is performed by packet filters <ref> [5, 12] </ref> (also known as packet classifiers in [1]). Our system makes use of packet filters, but, in addition, can exploit exclusive packet receiver information exported by Migrating Sockets to perform active packet demultiplexing.
Reference: 6. <author> ATM Forum. </author> <title> ATM traffic management specification, </title> <note> version 4.0, </note> <year> 1995. </year> <title> size (in bytes) for Ultra-1. versus data size (in bytes) for small memory footprint (Ultra-1). </title>
Reference-contexts: Such work on end system support complements recent research on integrated services networks. QoS guarantees provided by network level packet scheduling and admission control through Internet resource reservation protocols being developed <ref> [2, 6, 23] </ref> can thus be extended to the ultimate endpoints of an end-to-end communication, namely applications running in user space of general purpose operating systems. End system support for networking with QoS guarantees is a challenging problem.
Reference: 7. <author> R. Gopalakrishnan and G.M. Parulkar. </author> <title> Real-time upcalls: A mechanism to provide real-time processing guarantees. </title> <type> Technical report, </type> <institution> Washington University, </institution> <year> 1995. </year>
Reference-contexts: ARC scheduling of protocol threads is presented in section 5. Active demultiplexing is described in section 6. We present experimental results on the performance of our current system in section 7, and conclude in section 8. 1.3 Related work Real-time upcalls were proposed in <ref> [7] </ref> to achieve QoS guarantees in protocol processing. While the approach is an interesting alterna 1 tive to real-time threads, it is specifically designed for periodic pro-tocol processing and appears to be less general than our approach.
Reference: 8. <author> N.C. Hutchinson, S. Mishra, L.L. Peterson, and V.T. Thomas. </author> <title> Tools for implementing network protocols. </title> <journal> Software Practice and Experience, </journal> <year> 1989. </year>
Reference-contexts: However, parts of the runtime support system have been rewritten. First, we replaced BSD mbuf buffer management by message blocks similar to those used in SVR4 streams. This is because mbuf has been found to treat small and large messages non-uniformly and hence exhibit undesirable performance idiosyncrasies <ref> [8] </ref>. Moreover, message blocks can very naturally handle both normal data buffers and network buffers (see section 4.4) supported in our system (using the esballoc () library call). Second, we implemented a timer management interface for timer 3 grating Sockets. tions accessing cached sockets. activities.
Reference: 9. <author> Van Jacobson. </author> <note> LBL whiteboard. </note> <institution> Lawrence Berkeley Lab, </institution> <note> software on-line at ftp://ftp.ee.lbl.gov/conferencing/wb. </note>
Reference-contexts: Moreover, the run time environment for protocol processing, which provides such services as timer management, buffer management and demul-tiplexing table lookup, should be designed to support predictable performance. Besides QoS guarantees, recent proliferation of heterogeneous networking technologies and user application requirements <ref> [9, 10, 13, 23] </ref> will make customized development and flexible deployment fl Research supported in part by National Science Foundation under grant no. NCR-9506048, an equipment grant from AT&T Foundation, and an IBM graduate fellowship. of network protocols highly desirable. Protocol implementation at user level can help achieve these goals.
Reference: 10. <author> Van Jacobson. </author> <title> Visual audio tool. </title> <institution> Lawrence Berkeley Lab, </institution> <note> software on-line at ftp://ftp.ee.lbl.gov/conferencing/vat. </note>
Reference-contexts: Moreover, the run time environment for protocol processing, which provides such services as timer management, buffer management and demul-tiplexing table lookup, should be designed to support predictable performance. Besides QoS guarantees, recent proliferation of heterogeneous networking technologies and user application requirements <ref> [9, 10, 13, 23] </ref> will make customized development and flexible deployment fl Research supported in part by National Science Foundation under grant no. NCR-9506048, an equipment grant from AT&T Foundation, and an IBM graduate fellowship. of network protocols highly desirable. Protocol implementation at user level can help achieve these goals.
Reference: 11. <author> Chris Maeda and Brian N. Bershad. </author> <title> Protocol service decomposition for high-performance networking. </title> <booktitle> In Proc. 14th SOSP, </booktitle> <pages> pages 244255, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Protocol processing with predictable performance has also been investigated in the context of Real-Time Mach [14] based upon design principles for CPU scheduling different from ours. There has been growing interest in user level protocol implementation in recent years <ref> [11, 19] </ref>. A user level TCP implementation on top of the Jetstream high-speed network interface is described in [4]. U-Net [20] integrates interface firmware with host software in a design that provides user level access to a network without kernel intervention. <p> We there 2 fore decided to maintain backward compatibility with the widely used Berkeley socket interface. In concept, our migrating sockets framework draws upon previous experience in user level protocol implementation <ref> [11, 19] </ref>. In what follows, we give an overview of Migrating Sockets. Several novel ideas implemented in the framework are presented in section 4. 3.1 Berkeley sockets Sockets are used by applications to access local endpoints of network connections. <p> Hence, it was higher for a larger packet size. We note that although high performance is not the main concern in our work, our TCP/UDP latency numbers do seem to compare very well with those reported in the literature (e.g. <ref> [11] </ref>). 3 7.4 Protocol runtime support Migrating Sockets implements a buffer management subsystem and timer subsystem different from those in 4.4 BSD. We measured the performance of the buffer management subsystem in our current 3 Our numbers are smaller.
Reference: 12. <author> S. McCanne and Van Jacobson. </author> <title> The BSD packet filter: A new architecture for user-level packet capture. </title> <booktitle> In USENIX Technical Conference Proceedings, </booktitle> <pages> pages 259269, </pages> <address> San Diego, CA, </address> <month> Winter </month> <year> 1993. </year>
Reference-contexts: On the receive side, packet arrivals to a network interface are processed by the interrupt handler of the interface. Kernel level code must then demultiplex the packets to their destination processes. Traditionally, such demultiplexing is performed by packet filters <ref> [5, 12] </ref> (also known as packet classifiers in [1]). Our system makes use of packet filters, but, in addition, can exploit exclusive packet receiver information exported by Migrating Sockets to perform active packet demultiplexing.
Reference: 13. <author> S. McCanne and Van Jacobson. </author> <title> vic: A flexible framework for packet video. </title> <booktitle> In Proc. ACM Multimedia '95, </booktitle> <year> 1995. </year>
Reference-contexts: Moreover, the run time environment for protocol processing, which provides such services as timer management, buffer management and demul-tiplexing table lookup, should be designed to support predictable performance. Besides QoS guarantees, recent proliferation of heterogeneous networking technologies and user application requirements <ref> [9, 10, 13, 23] </ref> will make customized development and flexible deployment fl Research supported in part by National Science Foundation under grant no. NCR-9506048, an equipment grant from AT&T Foundation, and an IBM graduate fellowship. of network protocols highly desirable. Protocol implementation at user level can help achieve these goals.
Reference: 14. <author> Clifford W. Mercer, Jim Zelenka, and Ragunathan Rajkumar. </author> <title> On predictable operating system protocol processing. </title> <type> Technical Report CMU-CS-94-165, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: While the approach is an interesting alterna 1 tive to real-time threads, it is specifically designed for periodic pro-tocol processing and appears to be less general than our approach. Protocol processing with predictable performance has also been investigated in the context of Real-Time Mach <ref> [14] </ref> based upon design principles for CPU scheduling different from ours. There has been growing interest in user level protocol implementation in recent years [11, 19]. A user level TCP implementation on top of the Jetstream high-speed network interface is described in [4].
Reference: 15. <author> C. Partridge and S. Pink. </author> <title> A faster UDP. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 1(4):429440, </volume> <month> August </month> <year> 1993. </year>
Reference-contexts: For UDP, we have incorporated the following optimization techniques proposed in <ref> [15] </ref>: (1) Integrated checksumming and copying of data from application buffers to network buffers, (2) replacement of general purpose socket send code with more efficient UDP specific code, and (3) delete of pseudo-connect in UDP send.
Reference: 16. <author> K.K. Ramakrishnan, L. Vaitzblit, C. Gray, U. Vahalia, D. Ting, P. Tzelnic, S. Glaser, and W. Duso. </author> <title> Operating system sup-Figure 18: Data checksum and copy overhead (in s) versus data size (in bytes) for large memory footprint (Ultra-1). Machine Insert IP Data fault Other kernel Total option protection overhead SPARC 10 5.9 0.702 0.256 6.858 Ultra-1 2.5 0.225 0.056 2.781 Table 5: Breakdown of per packet active demultiplex-ing overhead (in s). port for a video-on-demand service. Multimedia Systems, </title> <address> 1995(3):5365, </address> <year> 1995. </year>
Reference-contexts: Aside from the use of background system services, traditional kernel level protocols perform entire receive side protocol processing in the context of interrupt handling. From a QoS perspective, it is similarly difficult to control the rate of progress of interrupt handling code (some researchers, such as <ref> [16] </ref>, have considered disabling device interrupt for more predictable performance). Migrating Sockets reduces the use of such hidden scheduling for cached sockets. First, each user process has a dedicated timer thread that handles timer events only for network endpoints local to the process.
Reference: 17. <author> D.M. Ritchie. </author> <title> A stream input-output system. </title> <journal> AT&T Bell Laboratories Technical Journal, </journal> <volume> 63(8):18971910, </volume> <month> October </month> <year> 1984. </year>
Reference-contexts: In streams <ref> [17] </ref>, for example, network send and receive can take place in service routines run by background system threads of control. In BSD Unix, a single system timeout invocation has to handle outstanding timer activities of all the network endpoints in the system.
Reference: 18. <author> Richard Stevens. </author> <title> UNIX Network Programming. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: Section 5 discusses ARC scheduling for protocol threads in Migrating Sockets. 4.2 Optimization for concurrent server model In client/server programming, there are two principal programming models. They are the iterative server model and the concurrent server model (see, for example, <ref> [18] </ref>). In the latter model, the server's role is only to listen for service requests from remote hosts. Once a request has been received, the server forks a child process to handle it, and itself goes back to listening for more requests.
Reference: 19. <author> C.A. Thekkath, T.D. Nguyen, E. Moy, and E.D. Lazowska. </author> <title> Implementing network protocols at user level. </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> 1(5):554565, </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: With fault containment in user processes and the availability of sophisticated tools for developing user level code, the cost of protocol development and experimentation will go down, and the lead time to deployment of protocols in a production environment will be reduced <ref> [19] </ref>. <p> Protocol processing with predictable performance has also been investigated in the context of Real-Time Mach [14] based upon design principles for CPU scheduling different from ours. There has been growing interest in user level protocol implementation in recent years <ref> [11, 19] </ref>. A user level TCP implementation on top of the Jetstream high-speed network interface is described in [4]. U-Net [20] integrates interface firmware with host software in a design that provides user level access to a network without kernel intervention. <p> We there 2 fore decided to maintain backward compatibility with the widely used Berkeley socket interface. In concept, our migrating sockets framework draws upon previous experience in user level protocol implementation <ref> [11, 19] </ref>. In what follows, we give an overview of Migrating Sockets. Several novel ideas implemented in the framework are presented in section 4. 3.1 Berkeley sockets Sockets are used by applications to access local endpoints of network connections.
Reference: 20. <author> Thorsten von Eicken, Anindya Basu, Vineet Buch, and Werner Vogels. U-Net: </author> <title> A user-level network interface for parallel and distributed computing. </title> <booktitle> In Proc. 15th SOSP, </booktitle> <month> November </month> <year> 1995. </year>
Reference-contexts: There has been growing interest in user level protocol implementation in recent years [11, 19]. A user level TCP implementation on top of the Jetstream high-speed network interface is described in [4]. U-Net <ref> [20] </ref> integrates interface firmware with host software in a design that provides user level access to a network without kernel intervention. These works target high performance on the send/receive path, without paying much attention to the issues of connection management, routing management, and the semantics of sharing network endpoints.
Reference: 21. <author> David K.Y. Yau and Simon S. Lam. </author> <title> An architecture towards efficient OS support for distributed multimedia. </title> <booktitle> In Proc. IS&T/SPIE Multimedia Computing and Networking, </booktitle> <pages> pages 424435, </pages> <address> San Jose, CA, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: Fourth, Migrating Sockets has been integrated with operating system techniques that minimize data copying and system call overhead for network communication <ref> [21] </ref>. Lastly, exclusive packet receiver information exported by Migrating Sockets enables a constant overhead packet demultiplexing mechanism called active de-multiplexing. By eliminating table search, active demultiplexing is highly efficient and is suitable for networking with QoS guarantees. 1.2 Organization of this paper The balance of this paper is as follows. <p> QoS guarantees. network connection for an extended period of time <ref> [21] </ref>, thereby jeopardizing the bandwidth requirements of other processes. This problem is especially pronounced if the connection has a moderate or low reserved rate. To solve the problem, an end system should provide rate-based flow control to reserved-rate network connections. In our proposal [21], flow control is enforced by a lightweight <p> connection for an extended period of time <ref> [21] </ref>, thereby jeopardizing the bandwidth requirements of other processes. This problem is especially pronounced if the connection has a moderate or low reserved rate. To solve the problem, an end system should provide rate-based flow control to reserved-rate network connections. In our proposal [21], flow control is enforced by a lightweight kernel thread. The approach is quite flexible in that different flow control policies can be provided by different loadable kernel modules. On the receive side, packet arrivals to a network interface are processed by the interrupt handler of the interface. <p> minimizing hidden scheduling in protocol processing, (2) caching optimization for the concurrent server programming model, (3) sharing of routing information between network and higher level protocols using a well-known shared memory region, and (4) a kernel/user interface that provides user level protocol code with access to efficient kernel level support <ref> [21] </ref> through Unix file descriptors. 4.1 Minimizing hidden scheduling Our experience [22] has been that it is difficult to provide QoS guarantees in certain protocol implementation frameworks. In streams [17], for example, network send and receive can take place in service routines run by background system threads of control. <p> For example, users on a Unix system are often permitted to use the netstat (1) command to return the same kind of information. 4.4 Protocol/kernel interface For efficiency, Migrating Sockets runs on top of an OS architecture (Figure 6) we have previously prototyped for supporting continuous media (CM) applications <ref> [21] </ref>. Send/receive buffers shown in Figure 6 are allocated using the IOBuffer::IOBuffer () method in Table 1. The method creates a network buffer region for direct send/receive to/from the network (i.e. no intermediate data copies are required). <p> The method causes a multiplex group, a data structure used by the kernel thread for rate-based packet scheduling, to be created within the kernel. The alg parameter specifies the packet scheduling algorithm to use for the multiplex group. Currently, the KT RC algorithm in <ref> [21] </ref> is supported. Parameters of the scheduling algorithm can be passed with the params pointer. For example, the KT RC algorithm takes the scheduling period (in s) of the kernel thread as a parameter.
Reference: 22. <author> David K.Y. Yau and Simon S. Lam. </author> <title> Adaptive rate-controlled scheduling for multimedia applications. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <note> August 1997 (to appear); an earlier version in Proc. </note> <institution> ACM Multimedia, </institution> <address> Cambridge, MA, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: Based on the progress requirements of all threads in the system, an ARC CPU scheduler can perform admission control and provide conditional progress guarantees to threads. The ARC scheduler in <ref> [22] </ref> provides the following progress guarantee: a punctual thread with rate r and period p is guaranteed at least krp CPU time over time interval kp, for k = 1; 2; : : :. <p> concurrent server programming model, (3) sharing of routing information between network and higher level protocols using a well-known shared memory region, and (4) a kernel/user interface that provides user level protocol code with access to efficient kernel level support [21] through Unix file descriptors. 4.1 Minimizing hidden scheduling Our experience <ref> [22] </ref> has been that it is difficult to provide QoS guarantees in certain protocol implementation frameworks. In streams [17], for example, network send and receive can take place in service routines run by background system threads of control. <p> The IOBuffer::IOBuffer () method creates device dependent DMA resources backing allocated network buffers. 5 ARC Scheduling of Protocol Threads Application and protocol threads in Migrating Sockets can specify their CPU requirements using the rate-based reservation model of ARC scheduling <ref> [22] </ref>. The rate-based model has two parameters: (1) rate, r, (0 &lt; r 1), and (2) period, p, in s. <p> ARC schedulers have the following properties: (1) reserved rate can be negotiated, (2) QoS guarantees are conditional upon thread behavior, and (3) firewall protection between threads is provided. The first property is provided by a monitoring module and a rate-adaptation interface as discussed in <ref> [22] </ref>. The second and third properties are provided by using an on-line CPU scheduling algorithm with the firewall property, such as the RC scheduler in [22]. <p> The first property is provided by a monitoring module and a rate-adaptation interface as discussed in <ref> [22] </ref>. The second and third properties are provided by using an on-line CPU scheduling algorithm with the firewall property, such as the RC scheduler in [22].
Reference: 23. <author> Lixia Zhang, Stephen Deering, Deborah Estrin, Scott Shenker, and Daniel Zappala. RSVP: </author> <title> A new resource ReSerVation Protocol. </title> <journal> IEEE Network, </journal> <pages> pages 818, </pages> <month> September </month> <year> 1993. </year> <month> 12 </month>
Reference-contexts: Such work on end system support complements recent research on integrated services networks. QoS guarantees provided by network level packet scheduling and admission control through Internet resource reservation protocols being developed <ref> [2, 6, 23] </ref> can thus be extended to the ultimate endpoints of an end-to-end communication, namely applications running in user space of general purpose operating systems. End system support for networking with QoS guarantees is a challenging problem. <p> Moreover, the run time environment for protocol processing, which provides such services as timer management, buffer management and demul-tiplexing table lookup, should be designed to support predictable performance. Besides QoS guarantees, recent proliferation of heterogeneous networking technologies and user application requirements <ref> [9, 10, 13, 23] </ref> will make customized development and flexible deployment fl Research supported in part by National Science Foundation under grant no. NCR-9506048, an equipment grant from AT&T Foundation, and an IBM graduate fellowship. of network protocols highly desirable. Protocol implementation at user level can help achieve these goals.
References-found: 23

