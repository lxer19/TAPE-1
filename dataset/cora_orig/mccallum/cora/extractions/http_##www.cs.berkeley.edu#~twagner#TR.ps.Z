URL: http://www.cs.berkeley.edu/~twagner/TR.ps.Z
Refering-URL: http://www.cs.berkeley.edu/~twagner/
Root-URL: http://www.cs.berkeley.edu
Title: Practical Algorithms for Incremental Software Development Environments  
Author: Tim A. Wagner 
Date: March 10, 1998  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Annika Aasa. </author> <title> Precedences in specifications and implementations of programming languages. </title> <journal> Theor. Comput. Sci., </journal> <volume> 142(1) </volume> <pages> 3-26, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: One possible solution would be to encode the dynamic selection of desired parse trees in the incremental parsing algorithm itself. For example, an existing theory of operators <ref> [1] </ref> could be extended to produce an incremental evaluator by maintaining synthesized attributes that describe, for each expression subtree, the precedence and associativity of the `exposed' operators within it. The incremental parser would expose operands through additional left- and right-breakdown operations in accordance with the operator specifications.
Reference: [2] <author> Rolf Adams, Walter Tichy, and Annette Weinert. </author> <title> The cost of selective recompilation and environment processing. </title> <journal> ACM Trans. Softw. Eng. and Meth., </journal> <volume> 3(1) </volume> <pages> 3-28, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: Increasingly sophisticated languages, software systems, and analysis demands have outpaced aggressive performance growth in both computing hardware and network bandwidth, resulting in a net increase in compilation delays <ref> [2] </ref>. <p> Increased complexity in languages and improved compile-time checking, coupled with the growing size of software systems have outpaced gains in hardware and network performance: recompilation after a minor change to the program often takes minutes or even hours to complete <ref> [2] </ref>. Lengthy delays decrease productivity and cause programmers to lose track of their working context when attempting to debug or maintain a complex program [93].
Reference: [3] <author> Rakesh Agrawal and Keith D. Detro. </author> <title> An efficient incremental LR parser for grammars with epsilon productions. </title> <journal> Acta Inf., </journal> <volume> 19 </volume> <pages> 369-376, </pages> <year> 1983. </year>
Reference-contexts: Error detection is discussed in conjunction with the incremental parsing algorithm; error recovery is described in Chapter 8. 6.2 Related Work Several early approaches to incremental parsing use data structures other than a persistent parse tree to achieve incremen-tality <ref> [3, 106] </ref>. While these algorithms decrease the time required to parse a program after a change has been made to its text, they do not materialize the persistent syntax tree required in most applications of incremental parsing.
Reference: [4] <author> A. V. Aho, S. C. Johnson, and J. D. Ullman. </author> <title> Deterministic parsing of ambiguous grammars. </title> <journal> Commun. ACM, </journal> <volume> 18(8) </volume> <pages> 441-452, </pages> <month> Aug. </month> <year> 1975. </year>
Reference-contexts: such as bison, permit some forms of ambiguity in conjunction with mechanisms for eliminating the resulting non-determinism in the parse table. 15 These methods include default resolution mechanisms (prefer shift, prefer earliest reduction in order of appearance in grammar) as well as a notation for expressing operator precedence and associativity <ref> [4] </ref>. 16 Resolving the conflicts in the parse table through additional information (including default mechanisms built into the parser generator) interferes with sentential-form parsing, which assumes that the parse table reflects the grammar of the language. <p> We describe mechanisms for applying both types of resolution using existing formal techniques, such as attribute grammars, while also permitting ad hoc resolution. Pre-compiled filters such as precedence and associativity declarations in bison <ref> [4] </ref> are supported in a uniform fashion. In the presence of missing or malformed program text, multiple interpretations may be retained indefinitely as a direct expression of the possibilities. We have developed a novel algorithm for incremental, non-deterministic parsing to (re)construct this IR. <p> The second item production becomes the second child. 7.5. RESOLVING AMBIGUITY 85 86 CHAPTER 7. NON-DETERMINISTIC PARSING AND MULTIPLE REPRESENTATIONS 7.5.1 Syntactic Disambiguation Static syntactic filters, in conjunction with ambiguous grammars, are used frequently in compiler construction. Examples include the operator precedence and associativity specifications in bison <ref> [4] </ref> as well as techniques associated with a particular parse table construction algorithm, such as `prefer shifting'. Such methods can be applied at language specification time by selectively removing conflicts from the parse table, and therefore do not result in non-deterministic parsing or multiple representations.
Reference: [5] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1986. </year>
Reference-contexts: GOTO (s i , X) indicates the transition on symbol X in state s i . (This is not a partial function; illegal transitions are denoted by a distinguished error value.) We use additional terminology from Aho et al. <ref> [5] </ref>. Theorem 6.3.1.1 Consider a conventional batch LR (1) parser in the configuration: 5 All textual and structural modifications are reflected in the tree itself. Section 4.3 discusses the representation of programs and the techniques for summarizing changes. 6.3. <p> If one or more actions were incorrect, the problem will 9 The change to existing table generators is minor: the parse table must be augmented slightly to represent all valid (and invalid) nonterminal transitions explicitly. Algorithms for constructing parse tables for the classes of parsers described here <ref> [5] </ref> are easily modified to enumerate all lookahead symbols rather than terminals alone. 6.4.
Reference: [6] <author> Rolf Bahlke and Gregor Snelting. </author> <title> The PSG system: From formal language definitions to interactive programming environments. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 8(4) </volume> <pages> 547-576, </pages> <month> Oct. </month> <year> 1986. </year>
Reference-contexts: Restoring database consistency is so time-consuming that it is often done overnight [17]. Incremental software development environments ( ISDEs) provide the foundation to maintain a consistent executable image, database, or other program-wide analysis results with truly interactive speeds <ref> [6, 8, 54, 77, 66, 81] </ref>. By integrating the (typically small) set of new changes with the results of a previous analysis, incremental services can operate `instantaneously'. <p> The Galaxy environment [10] touches every token on any textual modification to the program, and is therefore not an incremental approach. The Synthesizer Generator [81] limits the user to a single outstanding edit, for which batch lexical analysis is employed to incorporate a textual modification. PSG <ref> [6] </ref> permits either textual or structural modifications, but not both, and halts its incorporation of textual modifications at the first error it encounters, rather than continuing its analysis. Its lexical generator, Aladin [31], produces incremental lexers that cannot use more than a single character of lookahead. <p> Our approach discovers all three errors without attempting to correct the program; the visual presentation would be similar to the second version above with the explanatory text removed. the interactive nature of the environment <ref> [6, 49, 87] </ref>. Unfortunately, these approaches all demand direct user intervention at each error site and therefore impose an unnecessary serialization on the analysis and the user's (manual) recovery actions.
Reference: [7] <author> Robert A. Ballance, Jacob Butcher, and Susan L. Graham. </author> <title> Grammatical abstraction and incremental syntax analysis in a language-based editor. </title> <booktitle> In Proceedings of the ACM SIGPLAN '88 Symposium on Compiler Construction, </booktitle> <pages> pages 185-198, </pages> <address> Atlanta, Ga., </address> <month> Jun. </month> <year> 1988. </year> <note> ACM Press. </note>
Reference-contexts: Incremental parsers retain the document's structure, in the form of its parse tree, and use this data structure to update the parse after changes have been made by the user or by other tools <ref> [7, 36, 49, 58, 104] </ref>. Although the topic of incremental parsing has been treated previously, no published algorithms are completely adequate, and most are inefficient in time, space, or both. Several are incorrect or overly restrictive in the class of grammars to which they apply.
Reference: [8] <author> Robert A. Ballance, Susan L. Graham, and Michael L. Van De Vanter. </author> <title> The Pan language-based editing system. </title> <journal> ACM Trans. Softw. Eng. and Meth., </journal> <volume> 1(1) </volume> <pages> 95-127, </pages> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: Restoring database consistency is so time-consuming that it is often done overnight [17]. Incremental software development environments ( ISDEs) provide the foundation to maintain a consistent executable image, database, or other program-wide analysis results with truly interactive speeds <ref> [6, 8, 54, 77, 66, 81] </ref>. By integrating the (typically small) set of new changes with the results of a previous analysis, incremental services can operate `instantaneously'. <p> Graham and Michael A. Harrison. Over 20 graduate and undergraduate students have contributed to its implementation. As a research program, Ensemble represents the confluence of two earlier projects: Pan <ref> [8] </ref>, a prototype of an incremental, multilingual programming environment, and VORT E X [16], an interactive document typesetting system formulated as an incremental version of T E X [55]. <p> Its lexical generator, Aladin [31], produces incremental lexers that cannot use more than a single character of lookahead. The Pan system <ref> [8] </ref> possesses truly incremental lexical analysis, in that an unlimited number of disjoint textual edits can be applied to the program between analyses, and lexing is then applied only to the out-of-date portions of the program. <p> Unfortunately, these approaches all demand direct user intervention at each error site and therefore impose an unnecessary serialization on the analysis and the user's (manual) recovery actions. A few research and commercial environments support unattended incremental error recovery in the context of incremental parsing <ref> [8, 48, 83] </ref> but there has been little discussion or analysis of the technologies employed. No existing systems make use of the vast amount of information available in the development log being maintained by the environment.
Reference: [9] <author> Joseph Bates and Alon Lavie. </author> <title> Recognizing substrings of LR(k) languages in linear time. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 16(3) </volume> <pages> 1051-1077, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Our approach instead `corrects' the problem by refusing to insert the extra opening brace into the structural representation of the program (although it remains visible in the text)a better and more comprehensible response given the actual change made by the user. 2 Right-to-left substring parsing (interval analysis <ref> [9, 82] </ref>) has been proposed to further constrain the location of detected errors, but common mistakes can result in intervals so large that the user must still locate the problem manually. Interval analysis does not address the detection problems of batch non-correcting recoveries. 8.1. INTRODUCTION 93 of the unincorporated modification.
Reference: [10] <author> John F. Beetem and Anne F. Beetem. </author> <title> Incremental scanning and parsing with Galaxy. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 17(7) </volume> <pages> 641-651, </pages> <month> Jul. </month> <year> 1991. </year>
Reference-contexts: All previous approaches to incremental lexing require a static bound on the length of lexical dependencies. Several monolingual environments have included incremental lexical analysis [23, 83]. These systems only require sufficient expressiveness for a single language, and do not constitute general solutions. The Galaxy environment <ref> [10] </ref> touches every token on any textual modification to the program, and is therefore not an incremental approach. The Synthesizer Generator [81] limits the user to a single outstanding edit, for which batch lexical analysis is employed to incorporate a textual modification. <p> Their algorithm has several desirable characteristics, but its restriction to LR (0) grammars limits its applicability. LL (1) grammars are more practical ( having been used in the definitions of several programming languages) and techniques have been developed for incremental top-down parsing using this grammar class <ref> [10, 71, 86] </ref>. Li [60] describes a sentential-form LL (1) parser that can accommodate multiple edit sites. Jalili and Gallier [49] were the first to provide an incremental parsing algorithm suitable for LR (1) grammars and multiple edit sites and based on a persistent parse tree representation.
Reference: [11] <author> U. Bianchi, P. Degano, S. Mannucci, S. Martini, B. Mojana, C. Priami, and E. Salvator. </author> <title> Generating the analytic component parts of syntax-directed editors with efficient error recovery. </title> <journal> J. Syst. Softw., </journal> <volume> 23(1) </volume> <pages> 65-79, </pages> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: No satisfactory approach to this problem has previously been available. Several systems have tried to minimize or circumvent the difficulty of error handing in an ISDE by limiting the class of modifications available to the programmer <ref> [11] </ref>; in the extreme case, only structural operations that preserve all correctness properties are permitted [72]. Our approach is the other extreme: we place no restrictions on the editing model, allowing arbitrary textual and structural modifications and arbitrary timing of the analysis.
Reference: [12] <author> P. Borras, D. Clement, Th. Despeyroux, J. Incerpi, G. Kahn, B. Lang, and V. Pascual. </author> <title> CENTAUR: The system. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <pages> pages 14-24, </pages> <month> Nov. </month> <year> 1988. </year>
Reference-contexts: we discuss methods to mitigate these problems, then motivate and characterize our solution in the form of software development environments that operate incrementally. 1.1 Software Development Environments The term `environment' is typically used to describe an integrated collection of tools that assist the programmer in developing or maintaining software artifacts <ref> [12, 29, 47, 83] </ref>. Though historically derived from a collection of independent programscompilers, debuggers, recompilation managers, etc.the software development environment (SDE) attempts to be more than the sum of its parts. Its twin goals are to simplify and speed the development process through a tighter integration of the underlying tools.
Reference: [13] <author> Robert Bretl et al. </author> <title> The GemStone data management system. </title> <editor> In Won Kim and Federick H. Lochovsky, editors, </editor> <booktitle> Object-Oriented Concepts, Databases, and Applications, </booktitle> <pages> pages 283-308, </pages> <year> 1989. </year>
Reference-contexts: This is in contrast to the usual design of editor `undo' logs, where the primary indexing method is temporal (and often limited to a single entry). Our work augments techniques for object caching and off-line storage developed for object-oriented databases <ref> [13] </ref> and for multi-user locking and nested transaction support [64]. Recording modifications at this level of granularity requires attention to bandwidth constraints and representation issues: a typical document has many nodes, each containing several versioned fields.
Reference: [14] <author> Michael G. Burke and Gerald A. Fisher. </author> <title> A practical method for LR and LL syntactic error diagnosis and recovery. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 9(2) </volume> <pages> 164-197, </pages> <month> Apr. </month> <year> 1987. </year>
Reference-contexts: The algorithm in Figure 6.6 implements the optimistic strategy by a technique similar to the trial parsing used in batch parser error recovery <ref> [14] </ref>. Suppose we can legally shift a reused subtree, and, in the resulting state, can continue by shifting additional symbols deriving at least one terminal symbol (or incorporating the end of the input). <p> The best methods known rely on the ability to delay actions or reproduce part of the parse on demand, so that a variety of repairs may be tried at locations other than the detection point <ref> [14, 19, 38] </ref>. Since the recovery routine has no knowledge of the user's changes with respect to previous versions of the program, it attempts to correlate the problem with the detection point by comparing the results of different repairs.
Reference: [15] <author> Martin R. Cagan. </author> <title> The HP SoftBench environment: An architecture for a new generation of software tools. </title> <journal> Hewlett-Packard Journal, </journal> <volume> 41(3) </volume> <pages> 36-47, </pages> <month> Jun. </month> <year> 1990. </year>
Reference-contexts: The first goal, simplifying the development process, is well addressed by the state of the practice in commercial SDEs: interactive design and better tool cooperation, along with such useful additions as hypertext manuals, have clearly reduced the learning curve for these complex tools <ref> [15, 68] </ref>. Unfortunately, the second goalimproved productivityhas gone unrealized. Since these environments can operate no faster than the collection of batch programs they replace, development time for an experienced programmerand overall productivityremain essentially unchanged. The limitations of existing systems are a direct result of their continued reliance on batch technologies.
Reference: [16] <author> Pehong Chen, John Coker, Michael A. Harrison, Jeffrey McCarrell, and Steven Procter. </author> <title> The VorTeX document preparation environment. </title> <editor> In J. Desarmenien, editor, </editor> <booktitle> Second European Conference on T E X for Scientific Documentation, </booktitle> <pages> pages 45-54, </pages> <address> Strasbourg, France, </address> <month> Jun. </month> <year> 1986. </year> <note> 109 110 BIBLIOGRAPHY </note>
Reference-contexts: Graham and Michael A. Harrison. Over 20 graduate and undergraduate students have contributed to its implementation. As a research program, Ensemble represents the confluence of two earlier projects: Pan [8], a prototype of an incremental, multilingual programming environment, and VORT E X <ref> [16] </ref>, an interactive document typesetting system formulated as an incremental version of T E X [55].
Reference: [17] <author> Yih-Farn Chen, Michael Y. Nishimoto, and C. V. Ramamoorthy. </author> <title> The C information abstraction system. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 16(3) </volume> <pages> 325-334, </pages> <month> Mar. </month> <year> 1990. </year>
Reference-contexts: INTRODUCTION ing, understanding, and transforming programs. However, changes to the program are often not immediately reflected in the content of the database, allowing it to produce incorrect results. Restoring database consistency is so time-consuming that it is often done overnight <ref> [17] </ref>. Incremental software development environments ( ISDEs) provide the foundation to maintain a consistent executable image, database, or other program-wide analysis results with truly interactive speeds [6, 8, 54, 77, 66, 81].
Reference: [18] <author> Robert Corbett. bison release 1.24, </author> <year> 1992. </year>
Reference-contexts: Lexical descriptions are written using the flex specification language [75]. Grammars can be written in either extended BNF or the syntax of bison <ref> [18] </ref>. Semantic attribution is defined by a specialized language, adl [63]. The algorithms described in subsequent chapters have all been implemented as part of Ensemble, and have been tested with multiple languages and multiple documents. <p> Meta-language notation for the lexical and context-free syntax was not a specific focus of our research, which reuses established formalisms <ref> [18, 75] </ref>. An integrated language specification language that permits the automated derivation of efficient incremental evaluators remains an area of active research [96]. 4.3. <p> Unlike many published algorithms for incremental parsing, the location of the changes does not affect the running time, and the algorithm supports multiple edit sites, which may include any combination of textual and structural updates. The technique applies to any LR-based approach; our implementation uses bison <ref> [18] </ref> and existing grammars to produce table-driven incremental parsers for any language whose syntax is LALR (1). The parsing algorithm has no additional space cost over that intrinsic to storing the parse tree.
Reference: [19] <author> Robert Paul Corbett. </author> <title> Static Semantics and Compiler Error Recovery. </title> <type> PhD dissertation, </type> <institution> University of California, Berkeley, </institution> <year> 1985. </year> <note> Available as technical report UCB/CSD-85-251. </note>
Reference-contexts: The best methods known rely on the ability to delay actions or reproduce part of the parse on demand, so that a variety of repairs may be tried at locations other than the detection point <ref> [14, 19, 38] </ref>. Since the recovery routine has no knowledge of the user's changes with respect to previous versions of the program, it attempts to correlate the problem with the detection point by comparing the results of different repairs.
Reference: [20] <author> Gordon V. Cormack. </author> <title> An LR substring parser for noncorrecting syntax error recovery. </title> <booktitle> In Proceedings of the ACM SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <volume> volume 24(7), </volume> <pages> pages 161-169. </pages> <publisher> ACM Press, </publisher> <month> Jun. </month> <year> 1989. </year>
Reference-contexts: The well-known drawbacks of correcting strategies are avoided: no conjectures are necessary, spurious repairs never arise, and no heuristic `language tuning' is needed. The correctness of any repair we perform can be established easily, even in a multilingual, incremental setting. Non-correcting approaches <ref> [20, 80, 82] </ref> have not received much attention in batch compilers. Despite the theoretical advantages described above, the practical limitations imposed by a batch setting cause even the best of these approaches to be less useful than correcting methods.
Reference: [21] <author> Pierpaolo Degano, Stefano Mannucci, and Bruno Mojana. </author> <title> Efficient incremental LR parsing for syntax-directed editors. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 10(3) </volume> <pages> 345-373, </pages> <month> Jul. </month> <year> 1988. </year>
Reference-contexts: Some incremental parsing algorithms restrict the user to single-site editing [81] or to editing of only a select set of syntactic categories <ref> [21] </ref>, or can only parse up to the current (single) cursor point [86]. <p> None of these approaches is ideal. Those that work for unrestricted LR (1) grammars all require additional space in every node of the parse tree (for example, Larcheveque [58] requires five extra fields per node). Only Degano et al. <ref> [21] </ref> address the problem of mixed textual and structural editing, but they then impose a restricted editing framework and require novel table construction techniques. The algorithms that employ matching conditions fail to reuse nodes that overlap modification sites. <p> or immediately after the out-of-context analysis of a subtree results in a nested recovery that isolates the subtree being processed. ( In general, partial analysis results will be valid and will be retained within the subtree, even though the out-of-context analysis as a whole did not succeed.) 9 Unlike Degano <ref> [21] </ref>, we apply this restriction only as a mechanism for improving error recovery; this restriction does not apply to the user's editing model. 102 CHAPTER 8.
Reference: [22] <author> Pierpaolo Degano and Corrado Priami. </author> <title> Comparison of syntactic error handling in LR parsers. </title> <journal> SoftwarePractice & Experience, </journal> <volume> 25(6) </volume> <pages> 657-679, </pages> <month> Jun. </month> <year> 1995. </year>
Reference-contexts: (un)affected by errors, and that any transformations of the program required to isolate or present errors are themselves efficiently reversible operations. 8.1 Introduction Syntactic error recovery in batch systems is essentially a solved problem, involving a heuristic computation based on the configuration of the parser when the error is detected <ref> [22] </ref>. The best methods known rely on the ability to delay actions or reproduce part of the parse on demand, so that a variety of repairs may be tried at locations other than the detection point [14, 19, 38].
Reference: [23] <author> Norman M. Delisle, David E. Menicosy, and Mayer D. Schwartz. </author> <title> Viewing a programming environment as a single tool. </title> <booktitle> In Proceedings of the Second ACM SIGSOFT/SIGPLAN Symposium on Practical Software Development Environments, </booktitle> <pages> pages 49-56. </pages> <publisher> ACM Press, </publisher> <year> 1986. </year>
Reference-contexts: All previous approaches to incremental lexing require a static bound on the length of lexical dependencies. Several monolingual environments have included incremental lexical analysis <ref> [23, 83] </ref>. These systems only require sufficient expressiveness for a single language, and do not constitute general solutions. The Galaxy environment [10] touches every token on any textual modification to the program, and is therefore not an incremental approach.
Reference: [24] <author> Brian M. Dennis. ExL: </author> <title> The Ensemble extension language. </title> <type> Master's thesis, </type> <institution> Computer Science DivisionEECS, University of California, Berkeley, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Dynamic loading can be used to add new environment services in other areas, facilitating rapid prototyping of the environment itself. Central elements of Ensemble's domain model are exported through ExL, a Lisp-based extension language <ref> [24] </ref>. As in the EMACS editor, key and mouse bindings can be modified through ExL, which also provides customization of cursor management and event mapping in compound documents.
Reference: [25] <author> Paul F. Dietz and Daniel D. Sleator. </author> <title> Two algorithms for maintaining order in a list. </title> <booktitle> In Proceedings of the 19th Annual ACM Symp. on Theory of Computing, </booktitle> <pages> pages 365-372, </pages> <year> 1987. </year>
Reference-contexts: When global versions belong to different GVT nodes, the pre-order comparison can be made efficient by representing the GVT's pre-order sorted list as a data structure supporting O (1) order queries <ref> [25] </ref>. 8 An implementation based on balanced binary trees can be used to guarantee logarithmic access time to each local value at a modest increase in space overhead. 9 Driscoll's original test for determining the need for a second entry is flawed: i+ &lt; i 2 should be replaced with i+
Reference: [26] <author> James R. Driscoll, Neil Sarnak, Daniel D. Sleator, and Robert E. Tarjan. </author> <title> Making data structures persistent. </title> <journal> J. Comput. Syst. Sci., </journal> <volume> 38(1) </volume> <pages> 86-124, </pages> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: individual versioned objects rarely conflict; in cases where they do, the resolution is necessarily media-specific. 6 Commit-time operations, such as rebalancing sequences and computing the set of deleted nodes, are performed at this time. 7 The pre-order sort of the GVT corresponds to the version list in Driscoll et al. <ref> [26] </ref>. The implementation of these lists is not shown in Figure 3.4. 3.5. IMPLEMENTING VERSIONED OBJECTS 21 on the left illustrates the conceptual relationships among the versions. <p> The theoretical basis for the design is a corrected version of the `fat node' approach to persistent linked data structures developed by Driscoll et al. <ref> [26] </ref>. 3.5.1 Full-State Storage Many of the elements of a self-versioning document, such as the links between the nodes themselves, are small datatypes that are treated as intrinsic values.
Reference: [27] <author> J. Earley. </author> <title> An efficient context-free parsing algorithm. </title> <journal> Commun. ACM, </journal> <volume> 13(2) </volume> <pages> 94-102, </pages> <month> Feb. </month> <year> 1970. </year>
Reference-contexts: contexts, the increase in space 3 Even with GLR parsing, some erasing of concrete elements unnecessary for the abstract structure, such as parentheses, is often done. 4 This property was indirectly measured by Tomita [92] and Rekers [79], who compared the speed of a batch GLR parser to Earley's algorithm <ref> [27] </ref> on natural and programming language grammars, respectively. Both authors concluded that grammars are `close' to LR (1) in practice, and therefore GLR parsing exhibits linear behavior despite its exponential worst-case asymptotic result. 7.3. CONSTRUCTING THE ABSTRACT PARSE DAG 81 amount of syntactic ambiguity they possess.
Reference: [28] <author> Margaret A. Ellis and Bjarne Stroustrup. </author> <title> The Annotated C ++ Reference Manual. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year> <institution> Sect. 6.8, 8.1.1. </institution>
Reference-contexts: Semantic filters address the `feedback' problem (syntactic structure dependent upon semantic information) arising in C and Fortran. Parsing filters [53] address such problems as the declaration/expression ambiguity in C ++ <ref> [28] </ref> and the `off-side' rule in Haskell [46]. We describe mechanisms for applying both types of resolution using existing formal techniques, such as attribute grammars, while also permitting ad hoc resolution. Pre-compiled filters such as precedence and associativity declarations in bison [4] are supported in a uniform fashion. <p> For example, the syntactic ambiguity in C ++ expressed as `prefer a declaration to an expression' requires a dynamic filter, since competing reductions cannot be delayed until sufficient lookahead has been accumulated <ref> [28] </ref>.
Reference: [29] <author> P. Feiler, S. Dart, and G. Downey. </author> <title> Evaluation of the Rational environment. </title> <type> Technical Report CMU/SEI-88-TR-15, </type> <institution> Software Engineering Institute, Carnegie-Mellon University, </institution> <year> 1988. </year>
Reference-contexts: we discuss methods to mitigate these problems, then motivate and characterize our solution in the form of software development environments that operate incrementally. 1.1 Software Development Environments The term `environment' is typically used to describe an integrated collection of tools that assist the programmer in developing or maintaining software artifacts <ref> [12, 29, 47, 83] </ref>. Though historically derived from a collection of independent programscompilers, debuggers, recompilation managers, etc.the software development environment (SDE) attempts to be more than the sum of its parts. Its twin goals are to simplify and speed the development process through a tighter integration of the underlying tools.
Reference: [30] <author> M. V. Ferro and B. A. Dion. </author> <title> Efficient incremental parsing for context-free languages. </title> <booktitle> In Proc. 1994 IEEE Intl. Conf. Comp. Lang., </booktitle> <pages> pages 241-252. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1994. </year>
Reference-contexts: the work of subsequent analysis passes. ( Together they also ensure the preservation of user context and program annotations.) Lookahead information is dynamically tracked and encoded in parsing states stored in the nodes, eliminating the space overhead of previous approaches that require persistent maintenance of the entire graph-structured parse stack <ref> [30] </ref>. As an example of an inherent context-free syntax ambiguity addressed by this representation, consider the syntax of C. needed to resolve the ambiguity. 1 A similar problem arises in C ++ , Fortran, Oberon, and other languages. <p> The correctness of incremental GLR parsing can then be established by an induction over the input stream. Our approach differs significantly from the non-deterministic PDA simulator of Ferro and Dion <ref> [30] </ref>, which uses the GSS itself as the persistent representation of the program. <p> Unlike Ferro and Dion <ref> [30] </ref>, we do not retain interpretations eliminated by syntactic filters. In general, disambiguation specifications [42, 53] can be compiled into a combination of static and dynamic filters.
Reference: [31] <author> Bernd Fischer, Carsten Hammer, and Werner Struckmann. </author> <title> ALADIN: A scanner generator for incremental programming environments. </title> <journal> SoftwarePractice & Experience, </journal> <volume> 22(11) </volume> <pages> 1011-1025, </pages> <year> 1992. </year>
Reference-contexts: PSG [6] permits either textual or structural modifications, but not both, and halts its incorporation of textual modifications at the first error it encounters, rather than continuing its analysis. Its lexical generator, Aladin <ref> [31] </ref>, produces incremental lexers that cannot use more than a single character of lookahead.
Reference: [32] <author> C. N. Fischer, Gregory F. Johnson, John Mauney, Anil Pal, and Daniel L. </author> <title> Stock. The Poe languages-based editor project. </title> <booktitle> In Proceedings of the Second ACM SIGSOFT/SIGPLAN Symposium on Practical Software Development Environments. </booktitle> <publisher> ACM Press, </publisher> <year> 1986. </year>
Reference-contexts: The edit disturbs the context surrounding the preprocessor keyword PP_IF, requiring the incremental lexer to replace it with a normal keyword token (IDENT), even though the lexeme remains unchanged. The lexical specification is shown in Figure 5.2. The POE environment <ref> [32] </ref> provides per-keystroke error reporting by using a lexical analyzer capable of stopping and resuming at any character. This approach does not provide additional functionality relative to our system, 6 and actually decreases performance, due to the additional overhead required.
Reference: [33] <author> Francois Fluckiger. </author> <title> Understanding Distributed Multimedia: Applications and Technology. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1996. </year>
Reference-contexts: Lazy history log instantiation optimizes storage for unmodified objects. The interface provided by the versioning scheme is both simple and largely media-independent. 1 Objects transparently 1 We do not describe multimedia encoding methods; formats such as MPEG are well-known <ref> [33] </ref>, and Section 3.5 describes data structures for versioning such datatypes as pointers, booleans, and large text buffers. 15 16 CHAPTER 3.
Reference: [34] <author> Christopher W. Fraser and Eugene W. Myers. </author> <title> An editor for revision control. </title> <journal> SoftwarePractice & Experience, </journal> <volume> 9(2) </volume> <pages> 277-295, </pages> <year> 1987. </year>
Reference-contexts: bracket the terminal yield of the tree, while a third sentinel (the UltraRoot) points to both of these tokens as well as the current root of the document tree. the techniques described here enable a seamless integration of source code control, editor undo logging, and filesystem caching for software documents <ref> [34] </ref>, and a similar degree of support for natural language documents (for which commercial application programs rarely provide useful history-related services). The document's own structure (along with any imposed tree structure for sequences) is used as an `implicit' spatial indexing scheme for many version-related operations. <p> Our approach provides interoperability with these designs, and also suggests a framework in which automated transformations (e.g., page breaking) can be considered as first-class edit operations similar to the incremental analysis performed in formal languages. Fraser and Myers <ref> [34] </ref> present a single-level storage model for integrating an editor's undo/redo facility with a source code control system. They use a text-based model (developed from vi) where revisions are described in line-oriented terms.
Reference: [35] <author> Neal M. Gafter. </author> <title> Parallel Incremental Compilation. </title> <type> PhD dissertation, </type> <institution> University of Rochester, Rochester, </institution> <address> N.Y., </address> <year> 1990. </year>
Reference-contexts: Many parser generators accept ambiguous grammars in combination with additional specifications (e.g., operator precedence and default conflict resolution rules). 3 These techniques provide notational convenience and often result in signifi 1 Gafter <ref> [35] </ref> is the notable exception, but his approach precludes possibly-empty sequences, which arise in virtually every programming language. 2 In most systems, nodes will already carry run-time type information. Thus, no additional space is typically required to encode the production represented by a node. <p> To avoid this problem, we represent associative sequences non-deterministically; the ordering of the yield is maintained, but otherwise the internal structure is unspecified <ref> [35] </ref>.
Reference: [36] <author> Carlo Ghezzi and Dino Mandrioli. </author> <title> Augmenting parsers to support incrementality. </title> <journal> Journal of the ACM, </journal> <volume> 27(3) </volume> <pages> 564-579, </pages> <month> Jul. </month> <year> 1980. </year>
Reference-contexts: Incremental parsers retain the document's structure, in the form of its parse tree, and use this data structure to update the parse after changes have been made by the user or by other tools <ref> [7, 36, 49, 58, 104] </ref>. Although the topic of incremental parsing has been treated previously, no published algorithms are completely adequate, and most are inefficient in time, space, or both. Several are incorrect or overly restrictive in the class of grammars to which they apply. <p> A description of incremental LR (0) parsing suitable for multiple (textual) edit sites was presented by Ghezzi and Man-drioli <ref> [36] </ref>. Their algorithm has several desirable characteristics, but its restriction to LR (0) grammars limits its applicability. LL (1) grammars are more practical ( having been used in the definitions of several programming languages) and techniques have been developed for incremental top-down parsing using this grammar class [10, 71, 86]. <p> This is a test that indicates when a change can be `spliced' into existing tree structure, thus avoiding the complete reconstruction of the spine nodes. The technique has a historical basis (it was first introduced by Ghezzi and Mandrioli <ref> [36] </ref>) that has precluded better approaches: the time to test matching conditions and maintain the data needed to perform the tests outweighs the cost of a simple parsing algorithm followed by a direct reuse computation. 23 The combination of bottom-up and top-down reuse results in optimal node reuse: the set of <p> locates a well-formed subtree that existed in the previous version and that can be retained in the current version of the program structure to contain the site of the error. ( The `matching condition' used by some state-matching incremental parsers computes a similar relationship between the old and new trees <ref> [36, 58] </ref>.) When isolated regions are small, each is likely to contain only a single error (thus preventing the recovery of one problem from contaminating another) and most correct modifications will lie outside all isolated regions (allowing them to be successfully incorporated). contained within the if_stmt from the previous version of
Reference: [37] <author> Robert Giegerich. </author> <title> Considerate code selection. </title> <editor> In Robert Giegerich and Susan L. Graham, editors, </editor> <title> Code Generation Concepts, Tools, Techniques., </title> <booktitle> Workshops in Computing, </booktitle> <pages> pages 51-65, </pages> <address> Berlin, </address> <month> May </month> <year> 1991. </year> <note> Springer-Verlag. BIBLIOGRAPHY 111 </note>
Reference-contexts: Visser [97] makes this integration explicit for a batch system by using a single GLR parser for both lexical and context-free analysis. This approach can be made incremental using the techniques we describe. Code generation also benefits from retaining multiple representations until additional information has been gathered. Giegerich <ref> [37] </ref> applies context-sharing in this domain to intersperse code selection and register allocation. We have measured the space costs of our representation and the time overhead to rebuild it incrementally using a benchmark suite that includes both C ++ programs and the C programs in SPEC95.
Reference: [38] <author> Susan L. Graham, C. B. Haley, and W. N. Joy. </author> <title> Practical LR error recovery. </title> <booktitle> In Proc. SIGPLAN 79 Symposium on Compiler Construction, </booktitle> <pages> pages 168-175, </pages> <address> DenverCol., Aug. 1979. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The best methods known rely on the ability to delay actions or reproduce part of the parse on demand, so that a variety of repairs may be tried at locations other than the detection point <ref> [14, 19, 38] </ref>. Since the recovery routine has no knowledge of the user's changes with respect to previous versions of the program, it attempts to correlate the problem with the detection point by comparing the results of different repairs.
Reference: [39] <author> Susan L. Graham, Michael A. Harrison, and Ethan V. Munson. </author> <title> The Proteus presentation system. </title> <booktitle> In Proceedings of the Fifth ACM SIGSOFT Symposium on Software Development Environments, </booktitle> <pages> pages 130-138. </pages> <publisher> ACM Press, </publisher> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: Chapter 7.3.2 investigates the construction of multiple representations within a single program module through non-deterministic parsing. 2.3.3 Presentations and Views Several presentation services have been developed within the context of Ensemble, providing specification-driven display based on the document content model. These include general purpose tools, such as Proteus <ref> [39, 70] </ref> and tree-transformation systems [40], as well as several specialized tools for program presentation [65]. Each presentation instance is derived from a presentation schema, separate from the document content, which determines the appearance of the document.
Reference: [40] <author> Michael A. Harrison and Vance Maverick. </author> <title> Presentation by tree transformation. </title> <booktitle> In CompCon '97, </booktitle> <pages> pages 68-73, </pages> <address> San Jose, Calif., Feb. 1997. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: These include general purpose tools, such as Proteus [39, 70] and tree-transformation systems <ref> [40] </ref>, as well as several specialized tools for program presentation [65]. Each presentation instance is derived from a presentation schema, separate from the document content, which determines the appearance of the document. In addition, the user can override (temporarily or permanently) any automatically generated presentation attribute.
Reference: [41] <author> G orel Hedin. </author> <title> Incremental Semantic Analysis. </title> <type> PhD dissertation, </type> <institution> Department of Computer Science, Lund University, </institution> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Other tools, such as semantic analysis, can further specialize the representation of productions by adding additional fields and/or methods <ref> [41, 63] </ref>. The grammar provides a constructor routine for each production (node class).
Reference: [42] <author> J. Heering, P. R. H. Hendriks, P. Klint, and J. Rekers. </author> <title> The syntax definition formalism SDF Reference Manual. ASF+SDF Project, </title> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: operators in grammars that create recursive structure: those that might have semantic significance, such as arithmetic operators, and those that are truly associative, such as the (possibly implicit) sequencing operators that 17 Visser [95] examines an alternative approach that instead modifies the item set construction to encode parse forest filters <ref> [42] </ref>. <p> Unlike Ferro and Dion [30], we do not retain interpretations eliminated by syntactic filters. In general, disambiguation specifications <ref> [42, 53] </ref> can be compiled into a combination of static and dynamic filters.
Reference: [43] <author> J. Heering, P. Klint, and J. Rekers. </author> <title> Incremental generation of lexical scanners. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 14(4) </volume> <pages> 490-520, </pages> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: This approach does not provide additional functionality relative to our system, 6 and actually decreases performance, due to the additional overhead required. Other researchers have focused on the problem of incremental generation of batch lexical analyzers, as opposed to incremental lexing <ref> [43, 88] </ref>. Since language specifications are long-lived and infrequently changed relative to the number and frequency of changes made to programs written in those languages, we have been more concerned with the speed of the compile cycle than the speed of the compiler-compile cycle.
Reference: [44] <author> Stephan Heilbrunner. </author> <title> On the definition of elr(k) and ell(k) grammars. </title> <journal> Acta Inf., </journal> <volume> 11 </volume> <pages> 169-176, </pages> <year> 1979. </year>
Reference: [45] <author> Susan B. Horwitz. </author> <title> Generating language-based editors: A relationally-attributed approach. </title> <type> Technical Report TR 85-696, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1985. </year>
Reference-contexts: Long-range dependencies such as name binding <ref> [45] </ref> are outside the purview of incremental lexing, and we will never mean this type of relationship when we use the term `contextual dependency'. 11 Some generators require a special option to indicate that minimal lookahead is to be used.
Reference: [46] <editor> Paul Hudak et al. </editor> <title> Haskell report. SIGPLAN Not., </title> <address> 27(5):R, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Semantic filters address the `feedback' problem (syntactic structure dependent upon semantic information) arising in C and Fortran. Parsing filters [53] address such problems as the declaration/expression ambiguity in C ++ [28] and the `off-side' rule in Haskell <ref> [46] </ref>. We describe mechanisms for applying both types of resolution using existing formal techniques, such as attribute grammars, while also permitting ad hoc resolution. Pre-compiled filters such as precedence and associativity declarations in bison [4] are supported in a uniform fashion.
Reference: [47] <author> Scott E. Hudson and Roger King. </author> <title> The Cactis project: Database support for software environments. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 14(6) </volume> <pages> 709-719, </pages> <month> Jun. </month> <year> 1988. </year>
Reference-contexts: we discuss methods to mitigate these problems, then motivate and characterize our solution in the form of software development environments that operate incrementally. 1.1 Software Development Environments The term `environment' is typically used to describe an integrated collection of tools that assist the programmer in developing or maintaining software artifacts <ref> [12, 29, 47, 83] </ref>. Though historically derived from a collection of independent programscompilers, debuggers, recompilation managers, etc.the software development environment (SDE) attempts to be more than the sum of its parts. Its twin goals are to simplify and speed the development process through a tighter integration of the underlying tools.
Reference: [48] <author> Ian Jacobs and Laurence Rideau-Gallot. </author> <title> A Centaur tutorial. </title> <type> Technical Report 140, </type> <institution> INRIA, </institution> <month> Jul. </month> <year> 1992. </year>
Reference-contexts: Unfortunately, these approaches all demand direct user intervention at each error site and therefore impose an unnecessary serialization on the analysis and the user's (manual) recovery actions. A few research and commercial environments support unattended incremental error recovery in the context of incremental parsing <ref> [8, 48, 83] </ref> but there has been little discussion or analysis of the technologies employed. No existing systems make use of the vast amount of information available in the development log being maintained by the environment.
Reference: [49] <author> Fahimeh Jalili and Jean H. Gallier. </author> <title> Building friendly parsers. </title> <booktitle> In 9th ACM Symp. Principles of Prog. Lang., </booktitle> <pages> pages 196-206, </pages> <address> Albuquerque, N.Mex., 1982. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Incremental parsers retain the document's structure, in the form of its parse tree, and use this data structure to update the parse after changes have been made by the user or by other tools <ref> [7, 36, 49, 58, 104] </ref>. Although the topic of incremental parsing has been treated previously, no published algorithms are completely adequate, and most are inefficient in time, space, or both. Several are incorrect or overly restrictive in the class of grammars to which they apply. <p> Li [60] describes a sentential-form LL (1) parser that can accommodate multiple edit sites. Jalili and Gallier <ref> [49] </ref> were the first to provide an incremental parsing algorithm suitable for LR (1) grammars and multiple edit sites and based on a persistent parse tree representation. <p> The parser accepts all context-free grammars: generalized LR parsing [79, 92] is used to support non-determinism and ambiguity, eliminating restrictions on the parsing grammar and the attendant need for abstraction services. Shifting of entire subtrees via state-matching <ref> [49] </ref> provides efficient incremental behavior, and explicit node retention minimizes the work of subsequent analysis passes. ( Together they also ensure the preservation of user context and program annotations.) Lookahead information is dynamically tracked and encoded in parsing states stored in the nodes, eliminating the space overhead of previous approaches that <p> Our approach discovers all three errors without attempting to correct the program; the visual presentation would be similar to the second version above with the explanatory text removed. the interactive nature of the environment <ref> [6, 49, 87] </ref>. Unfortunately, these approaches all demand direct user intervention at each error site and therefore impose an unnecessary serialization on the analysis and the user's (manual) recovery actions.
Reference: [50] <author> Mark Johnson. </author> <title> The computational complexity of GLR parsing. </title> <editor> In Masaru Tomita, editor, </editor> <booktitle> Generalized LR Parsing, </booktitle> <pages> pages 35-42. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: single, shared list of reused nodes; maintaining separate lists when multiple parsers are active imposes a performance and complexity cost for minimal gain in the number of reused nodes.) 7.3.3 Asymptotic Analysis The IGLR parsing algorithm works for any context-free grammar and, like GLR parsing, is exponential in the worst-case <ref> [50] </ref> but linear on actual programming language grammars. To ensure incremental performance that improves on batch parsing, we impose the same restrictions on the grammar and the representation of associative sequences in the abstract parse dag as in deterministic parsing (Section 6.6).
Reference: [51] <author> Neil D. Jones and Michael Madsen. </author> <title> Attribute-influenced LR parsing. </title> <editor> In U. D. Jones, editor, </editor> <booktitle> Semantics-Directed Compiler Generation, number 94 in LNCS, </booktitle> <pages> pages 393-407, </pages> <address> Berlin, 1980. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: A trace of the parser actions on a small C ++ example is given 1 Batch systems typically handle this problem by having the lexer query the symbol table in order to separate identifiers into two distinct categories. Attribute-influenced parsing <ref> [51, 84] </ref> is a combination of LR parsing and a restricted class of attribute grammars that addresses the same problem in a formal way. Neither of these solutions can be applied to an incremental setting where non-trivial subtrees appear in the parser's input stream. 7.2.
Reference: [52] <author> Randy H. Katz. </author> <title> Toward a unified framework for version modeling in engineering databases. </title> <journal> ACM Comput. Surv., </journal> <volume> 22(4) </volume> <pages> 275-408, </pages> <year> 1990. </year>
Reference-contexts: of these ideas, suitable for use in software development environments, multimedia authoring systems, and non-traditional databases. 3.1 Introduction Documents based on linked, hierarchical data structures with media content in their leaves are at the core of software development environments, multimedia authoring systems, and various types of non-traditional (`engineering') database implementations <ref> [52] </ref>. The management of versions and configurations is essential to each of these domains, requiring the environment to capture and organize both large-scale and small-scale updates. Coarse-grained changes provide the basis for release and configuration management and are conventionally handled by a source code control system. <p> RELATED WORK 31 4.6 Related Work Many proposals for handling versioning have been discussed in the database community <ref> [52] </ref>; the focus has been primarily on coarse-grained updates and non-incremental tools. Magnusson, et al. describe the sharing and collaborative framework of the Mjlner project [54, 64]. Our concept of integrating analysis-based transformations with history services is compatible with such an approach.
Reference: [53] <author> Paul Klint and Eelco Visser. </author> <title> Using filters for the disambiguation of context-free grammars. </title> <booktitle> In Proc. ASMICS Workshop on Parsing Theory, </booktitle> <address> Milan, Italy, </address> <year> 1994. </year>
Reference-contexts: In the absence of the history services we describe, two bits per node are needed to track changes made between applications of the parser, and the old value of each structural link must remain accessible until the completion of parsing. 3 This is essentially a form of parse forest filtering <ref> [53] </ref> that can be statically encoded so that the parser remains deterministic. 55 56 CHAPTER 6. EFFICIENT AND FLEXIBLE INCREMENTAL PARSING cantly smaller parse trees, especially in languages like C that are terse and expression-dense. <p> Thorup [90] examines methods to eliminate conflicts while preserving the completeness, termination, and performance results of conventional LR parsers. Klint and Visser <ref> [53] </ref> describe parse tree filters, some of which can be applied at parse table construction time. 6.5. AMBIGUOUS GRAMMARS AND PARSE FOREST FILTERING 67 %token IDENT Order indicates precedence: %left '+' low %left '*' high %% e : IDENT | e '+' e | '(' e ')' 8a. <p> Semantic filters address the `feedback' problem (syntactic structure dependent upon semantic information) arising in C and Fortran. Parsing filters <ref> [53] </ref> address such problems as the declaration/expression ambiguity in C ++ [28] and the `off-side' rule in Haskell [46]. We describe mechanisms for applying both types of resolution using existing formal techniques, such as attribute grammars, while also permitting ad hoc resolution. <p> Unlike Ferro and Dion [30], we do not retain interpretations eliminated by syntactic filters. In general, disambiguation specifications <ref> [42, 53] </ref> can be compiled into a combination of static and dynamic filters.
Reference: [54] <author> J. L. Knudsen, M. Lofgren, O. L. Madsen, and B. Magnusson. </author> <title> Object-Oriented Environments The Mjlner Approach. </title> <publisher> Prentice-Hall, </publisher> <year> 1993. </year>
Reference-contexts: Restoring database consistency is so time-consuming that it is often done overnight [17]. Incremental software development environments ( ISDEs) provide the foundation to maintain a consistent executable image, database, or other program-wide analysis results with truly interactive speeds <ref> [6, 8, 54, 77, 66, 81] </ref>. By integrating the (typically small) set of new changes with the results of a previous analysis, incremental services can operate `instantaneously'. <p> RELATED WORK 31 4.6 Related Work Many proposals for handling versioning have been discussed in the database community [52]; the focus has been primarily on coarse-grained updates and non-incremental tools. Magnusson, et al. describe the sharing and collaborative framework of the Mjlner project <ref> [54, 64] </ref>. Our concept of integrating analysis-based transformations with history services is compatible with such an approach. Our analyses are designed to maximize component (and information) preservation within structured documents, rather than duplicating paths as the Mjlner system does.
Reference: [55] <author> Donald E. Knuth. </author> <title> The T E Xbook, volume A of Computers and Typesetting. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1986. </year>
Reference-contexts: As a research program, Ensemble represents the confluence of two earlier projects: Pan [8], a prototype of an incremental, multilingual programming environment, and VORT E X [16], an interactive document typesetting system formulated as an incremental version of T E X <ref> [55] </ref>.
Reference: [56] <author> Wilf R. LaLonde. </author> <title> Regular right part grammars and their parsers. </title> <journal> Commun. ACM, </journal> 20(10) 731-740, 1977. 
Reference-contexts: An obvious way to indicate the freedom to choose an internal representation for associative sequences is to describe the syntax of the language using an extended context-free (regular right part) grammar <ref> [56] </ref>. We can use the grammar both to specify the syntax of the language and to declaratively describe the representation of the resulting syntax trees.
Reference: [57] <author> Marc Lankhorst. </author> <title> An empirical comparison of generalized LR tables. </title> <editor> In R. Heemels, A. Nijholt, and K. Sikkel, editors, </editor> <title> Tomita's Algorithm: Extensions and Applications (TWLT1), </title> <booktitle> number 91-68 of Memoranda Informatica in Twente Workshops on Language Technology, </booktitle> <pages> pages 87-93. </pages> <address> Universeit Twente, </address> <year> 1991. </year>
Reference-contexts: LALR (1) tables are used to drive the parser: not only are they significantly smaller than LR (1) tables, but they also yield faster parsing speeds in non-deterministic regions <ref> [57] </ref> and improved incremental reuse in deterministic regions (due to the merging of states with like cores). 5 Left context checks involve the same integer comparison used by a deterministic state-matching incremental parser.
Reference: [58] <author> J. M. Larcheveque. </author> <title> Optimal incremental parsing. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 17(1) </volume> <pages> 1-15, </pages> <year> 1995. </year>
Reference-contexts: their effects to be distinguished: each change will be `tagged' with the version in which it occurred, uniquely identifying the authoring tool. 7 Thus the reference version for semantics is not necessarily the same as the reference version for lexing and parsing. 8 With the exception of Larcheveque's parsing algorithm <ref> [58] </ref>, previously published incremental algorithms have largely ignored tool interaction. 9 Additional node reuse also saves space by decreasing the size of the history log, since fewer modifications will be outstanding when the version is committed. 4.6. <p> They use a text-based model (developed from vi) where revisions are described in line-oriented terms. Hierarchical document models are a more natural representation for structural changes and support the specialization of media-specific updates. Larcheveque <ref> [58] </ref> discusses the motivation for component reuse in the context of an ISDE, and describes how the incremental parser for O 2 was designed to accommodate this goal. <p> Incremental parsers retain the document's structure, in the form of its parse tree, and use this data structure to update the parse after changes have been made by the user or by other tools <ref> [7, 36, 49, 58, 104] </ref>. Although the topic of incremental parsing has been treated previously, no published algorithms are completely adequate, and most are inefficient in time, space, or both. Several are incorrect or overly restrictive in the class of grammars to which they apply. <p> the reusability of previous subtrees by state matching. 4 This test is sufficient but not necessary, decreasing performance and requiring additional work to compute optimal reuse. ( The effect is especially severe for LR (1) grammars, due to their large number of distinct states with equivalent cores.) More recently, Larcheveque <ref> [58] </ref> has extended to LR (k) grammars the matching condition originally formulated by Ghezzi and Mandrioli, which allows the parser to retain structural units that fully contain the modification. His work focuses on the indirect performance gains that accrue from node reuse in an ISDE. <p> None of these approaches is ideal. Those that work for unrestricted LR (1) grammars all require additional space in every node of the parse tree (for example, Larcheveque <ref> [58] </ref> requires five extra fields per node). Only Degano et al. [21] address the problem of mixed textual and structural editing, but they then impose a restricted editing framework and require novel table construction techniques. The algorithms that employ matching conditions fail to reuse nodes that overlap modification sites. <p> Figure 6.12 illustrates both types of reuse paths. Several incremental parsing algorithms have tried to capture a subset of top-down reuse by implementing a matching condition <ref> [58, 61, 76] </ref>. This is a test that indicates when a change can be `spliced' into existing tree structure, thus avoiding the complete reconstruction of the spine nodes. <p> As with deterministic parsing, IGLR parsing can be extended to retain existing program structure through node reuse <ref> [58, 76, 99] </ref>. <p> locates a well-formed subtree that existed in the previous version and that can be retained in the current version of the program structure to contain the site of the error. ( The `matching condition' used by some state-matching incremental parsers computes a similar relationship between the old and new trees <ref> [36, 58] </ref>.) When isolated regions are small, each is likely to contain only a single error (thus preventing the recovery of one problem from contaminating another) and most correct modifications will lie outside all isolated regions (allowing them to be successfully incorporated). contained within the if_stmt from the previous version of
Reference: [59] <author> M. E. Lesk and E. Schmidt. </author> <title> LEXa lexical analyzer generator. In Unix Programmer's Manual. Bell Telephone Laboratories, </title> <booktitle> 7th edition, </booktitle> <month> Jan. </month> <year> 1979. </year>
Reference-contexts: Several tools that facilitate the construction of such lexers have been devised, including the well-known Unix tools lex <ref> [59] </ref> and flex [75]. These tools support an extension of regular expression notation as their pattern set.
Reference: [60] <author> Warren Xiaohui Li. </author> <title> A simple and efficient incremental LL(1) parsing [sic]. </title> <booktitle> In SOFSEM '95: Theory and Practice of Informatics, </booktitle> <publisher> LNCS, </publisher> <pages> pages 399-404, </pages> <address> Berlin, November/December 1995. </address> <publisher> Springer-Verlag. 112 BIBLIOGRAPHY </publisher>
Reference-contexts: LL (1) grammars are more practical ( having been used in the definitions of several programming languages) and techniques have been developed for incremental top-down parsing using this grammar class [10, 71, 86]. Li <ref> [60] </ref> describes a sentential-form LL (1) parser that can accommodate multiple edit sites. Jalili and Gallier [49] were the first to provide an incremental parsing algorithm suitable for LR (1) grammars and multiple edit sites and based on a persistent parse tree representation.
Reference: [61] <author> Warren Xiaohui Li. </author> <title> Towards Generating Practical Language-Based Editing Systems. </title> <type> PhD dissertation, </type> <institution> University of Western Australia, </institution> <year> 1995. </year>
Reference-contexts: Node reuse is a subset of that discovered by Larcheveque's algorithm. Yang [105] recognizes the utility of sentential-form parsing, but still records parse states in nodes and thus requires a post-pass to relabel subtrees. Li <ref> [61] </ref> describes a sentential-form parser, but his algorithm can generate incorrect parse errors on grammars with *-rules. ( It is also limited to complete LR (1) parse tables, since invalid reductions can induce cycling in his algorithm.) Both of these authors suggest `improving' the parsing algorithm through matching condition checks that <p> Figure 6.12 illustrates both types of reuse paths. Several incremental parsing algorithms have tried to capture a subset of top-down reuse by implementing a matching condition <ref> [58, 61, 76] </ref>. This is a test that indicates when a change can be `spliced' into existing tree structure, thus avoiding the complete reconstruction of the spine nodes.
Reference: [62] <author> Maryellen C. MacDonald, Marcel Adam Just, and Patricia A. Carpenter. </author> <title> Working memory constraints on the processing of syntactic ambiguity. Cog. </title> <journal> Psych., </journal> <volume> 24(1) </volume> <pages> 56-98, </pages> <year> 1992. </year>
Reference-contexts: We return to issues of sharing in Section 7.3.4 after explaining incremental GLR parsing. 7.2.1 Space Overhead for Ambiguity Cognitive studies suggest that localization of ambiguity is an inherent property of natural languages, a constraint imposed by limitations on short-term memory <ref> [62, 69] </ref>.
Reference: [63] <author> William Maddox. </author> <title> Incremental Static Semantic Analysis. </title> <type> PhD dissertation, </type> <institution> University of California, Berkeley, </institution> <year> 1997. </year> <note> Available as technical report UCB/CSD-97-948. </note>
Reference-contexts: Our specification methods intentionally reuse the notation of familiar batch tools whenever possible, in order to decrease the time and effort required to port existing language descriptions to Ensemble. Other Ensemble researchers have investigated specification language design in the context of particular domains, including semantic attribution <ref> [63] </ref> and presentation [65, 70]. 2.3.2 Document Model Documents in Ensemble are always represented structurally, although users typically choose to view and edit them as text. Each node in the document structure is an instance of a C ++ class identified with a production in the language's grammar. <p> Lexical descriptions are written using the flex specification language [75]. Grammars can be written in either extended BNF or the syntax of bison [18]. Semantic attribution is defined by a specialized language, adl <ref> [63] </ref>. The algorithms described in subsequent chapters have all been implemented as part of Ensemble, and have been tested with multiple languages and multiple documents. <p> Other tools, such as semantic analysis, can further specialize the representation of productions by adding additional fields and/or methods <ref> [41, 63] </ref>. The grammar provides a constructor routine for each production (node class). <p> In the incremental case, each stage inspects or updates only those portions of the program that have changed or could possibly be affected by preceding changes <ref> [63] </ref>. An interesting case occurs when a typedef declaration is removed: Binding information stored in semantic attributes allows the former uses of the declaration to be efficiently located.
Reference: [64] <author> Boris Magnusson, Ulf Asklund, </author> <title> and Sten Minor. Fine-grained revision control for collaborative software development. </title> <booktitle> In First ACM SIGSOFT Symposium on the Foundations of Software Engineering, </booktitle> <pages> pages 33-41. </pages> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: This is in contrast to the usual design of editor `undo' logs, where the primary indexing method is temporal (and often limited to a single entry). Our work augments techniques for object caching and off-line storage developed for object-oriented databases [13] and for multi-user locking and nested transaction support <ref> [64] </ref>. Recording modifications at this level of granularity requires attention to bandwidth constraints and representation issues: a typical document has many nodes, each containing several versioned fields. <p> RELATED WORK 31 4.6 Related Work Many proposals for handling versioning have been discussed in the database community [52]; the focus has been primarily on coarse-grained updates and non-incremental tools. Magnusson, et al. describe the sharing and collaborative framework of the Mjlner project <ref> [54, 64] </ref>. Our concept of integrating analysis-based transformations with history services is compatible with such an approach. Our analyses are designed to maximize component (and information) preservation within structured documents, rather than duplicating paths as the Mjlner system does.
Reference: [65] <author> Vance Maverick. </author> <title> Presentation by Tree Transformation. </title> <type> PhD dissertation, </type> <institution> University of California, Berkeley, </institution> <year> 1997. </year> <note> Available as technical report UCB/CSD-97-947. </note>
Reference-contexts: Our specification methods intentionally reuse the notation of familiar batch tools whenever possible, in order to decrease the time and effort required to port existing language descriptions to Ensemble. Other Ensemble researchers have investigated specification language design in the context of particular domains, including semantic attribution [63] and presentation <ref> [65, 70] </ref>. 2.3.2 Document Model Documents in Ensemble are always represented structurally, although users typically choose to view and edit them as text. Each node in the document structure is an instance of a C ++ class identified with a production in the language's grammar. <p> The representation and editing of multimedia components and natural language documents is described elsewhere <ref> [65] </ref>. Additional tokens are used to represent material outside the grammar, including explicit whitespace, textual comments, and so forth. 8 CHAPTER 2. THE ENSEMBLE ENVIRONMENT Incrementality is only productive when it results in rapid response times for the user. <p> Unlike existing commercial or research systems, Ensemble can restore any version quickly, even if it involves reversing or re-applying a complex, language-based transformation. We focus primarily on single-language programs represented as trees. Ensemble's compound document architecture has been described elsewhere <ref> [65] </ref>, and is largely orthogonal to the issues discussed here. Chapter 7.3.2 investigates the construction of multiple representations within a single program module through non-deterministic parsing. 2.3.3 Presentations and Views Several presentation services have been developed within the context of Ensemble, providing specification-driven display based on the document content model. <p> These include general purpose tools, such as Proteus [39, 70] and tree-transformation systems [40], as well as several specialized tools for program presentation <ref> [65] </ref>. Each presentation instance is derived from a presentation schema, separate from the document content, which determines the appearance of the document. In addition, the user can override (temporarily or permanently) any automatically generated presentation attribute. Multiple presentations, using the same or different schemas, may be active simultaneously. <p> When combined with high-performance object-oriented database technology, 2 Extensions to the Ensemble document model to support compound documents and a discussion of issues involving multimedia elements and natural language documents are described by Maverick <ref> [65] </ref>. 3.2. DOCUMENT REPRESENTATION AND SERVICES 17 &lt;T&gt; get () void set (&lt;T&gt; value) bool changed () bool changed (from_version, to_version) void alter_version (version_id) bool had_value (&lt;T&gt; value, from_version, to_version) bool exists ([version_id]) void discard () void mark_deleted () void undelete () Table 3.1: Interface to low-level versioned objects.
Reference: [66] <author> Raul Medina-Mora. </author> <title> Syntax directed editing: Towards integrated programming environments. </title> <type> Technical Report CMU-CS-81-113, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <month> March </month> <year> 1982. </year> <type> Ph.D. dissertation. </type>
Reference-contexts: Restoring database consistency is so time-consuming that it is often done overnight [17]. Incremental software development environments ( ISDEs) provide the foundation to maintain a consistent executable image, database, or other program-wide analysis results with truly interactive speeds <ref> [6, 8, 54, 77, 66, 81] </ref>. By integrating the (typically small) set of new changes with the results of a previous analysis, incremental services can operate `instantaneously'.
Reference: [67] <author> B. Meyer. </author> <title> Eiffel: The Language. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1992. </year>
Reference: [68] <institution> Microsoft Corp., Inc. Visual C ++ , 1997. </institution>
Reference-contexts: The first goal, simplifying the development process, is well addressed by the state of the practice in commercial SDEs: interactive design and better tool cooperation, along with such useful additions as hypertext manuals, have clearly reduced the learning curve for these complex tools <ref> [15, 68] </ref>. Unfortunately, the second goalimproved productivityhas gone unrealized. Since these environments can operate no faster than the collection of batch programs they replace, development time for an experienced programmerand overall productivityremain essentially unchanged. The limitations of existing systems are a direct result of their continued reliance on batch technologies.
Reference: [69] <author> Akira Miyake, Marcel Adam Just, and Patricia A. Carpenter. </author> <title> Working memory constraints on the resolution of lexical ambiguity: Maintaining multiple interpretations in neutral contexts. </title> <journal> J. Memory and Lang., </journal> <volume> 33(2) </volume> <pages> 175-202, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: We return to issues of sharing in Section 7.3.4 after explaining incremental GLR parsing. 7.2.1 Space Overhead for Ambiguity Cognitive studies suggest that localization of ambiguity is an inherent property of natural languages, a constraint imposed by limitations on short-term memory <ref> [62, 69] </ref>.
Reference: [70] <author> Ethan V. Munson. </author> <title> The Proteus Presentation System. </title> <type> PhD dissertation, </type> <institution> University of California, Berkeley, </institution> <year> 1992. </year> <note> Available as technical report UCB/CSD-94-833. </note>
Reference-contexts: Our specification methods intentionally reuse the notation of familiar batch tools whenever possible, in order to decrease the time and effort required to port existing language descriptions to Ensemble. Other Ensemble researchers have investigated specification language design in the context of particular domains, including semantic attribution [63] and presentation <ref> [65, 70] </ref>. 2.3.2 Document Model Documents in Ensemble are always represented structurally, although users typically choose to view and edit them as text. Each node in the document structure is an instance of a C ++ class identified with a production in the language's grammar. <p> Chapter 7.3.2 investigates the construction of multiple representations within a single program module through non-deterministic parsing. 2.3.3 Presentations and Views Several presentation services have been developed within the context of Ensemble, providing specification-driven display based on the document content model. These include general purpose tools, such as Proteus <ref> [39, 70] </ref> and tree-transformation systems [40], as well as several specialized tools for program presentation [65]. Each presentation instance is derived from a presentation schema, separate from the document content, which determines the appearance of the document.
Reference: [71] <author> Arvind M. Murching, Y. V. Prasad, and Y. N. Srikant. </author> <title> Incremental recursive descent parsing. </title> <journal> Computer Languages, </journal> <volume> 15(4) </volume> <pages> 193-204, </pages> <year> 1990. </year>
Reference-contexts: Their algorithm has several desirable characteristics, but its restriction to LR (0) grammars limits its applicability. LL (1) grammars are more practical ( having been used in the definitions of several programming languages) and techniques have been developed for incremental top-down parsing using this grammar class <ref> [10, 71, 86] </ref>. Li [60] describes a sentential-form LL (1) parser that can accommodate multiple edit sites. Jalili and Gallier [49] were the first to provide an incremental parsing algorithm suitable for LR (1) grammars and multiple edit sites and based on a persistent parse tree representation.
Reference: [72] <author> D. Notkin, R. J. Ellison, B. J. Staudt, G. E. Kaiser, E. Kant, A. N. Habermann, V. Ambriola, and C. Montangero. </author> <title> Special issue on the GANDALF project. </title> <journal> J. Syst. Softw., </journal> <volume> 5(2), </volume> <month> May </month> <year> 1985. </year>
Reference-contexts: Several systems have tried to minimize or circumvent the difficulty of error handing in an ISDE by limiting the class of modifications available to the programmer [11]; in the extreme case, only structural operations that preserve all correctness properties are permitted <ref> [72] </ref>. Our approach is the other extreme: we place no restrictions on the editing model, allowing arbitrary textual and structural modifications and arbitrary timing of the analysis. Multiple errors, including nested errors, may exist simultaneously and do not preclude the incorporation of other modifications.
Reference: [73] <author> R. Nozohoor-Farshi. </author> <title> GLR parsing for *-grammars. </title> <editor> In Masaru Tomita, editor, </editor> <booktitle> Generalized LR Parsing, </booktitle> <pages> pages 61-75. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: We introduce a performance model to analyze the asymptotic behavior of the parser, and conclude the section by proving that sharing in the abstract parse dag is both optimal and correct. The algorithm itself appears in Appendix B. 7.3.1 Generalized LR Parsing Batch GLR parsing <ref> [73, 79, 92] </ref> is a technique for parsing arbitrary context-free grammars that utilizes conventional LR table construction methods. Unlike deterministic parsers, however, a GLR parser permits these tables to contain conflicts: when a state transition is multiply defined, the GLR parser simply forks multiple parsers to follow each possibility. <p> In most cases, non-determinism for dynamic lookahead results in deterministic (and unshared) structure in the parse tree, since unsuccessful parses eventually terminate. In the GSS, however, sharing needed to handle certain types of grammars with *-productions results in sharing in the parse tree even for unambiguous grammars <ref> [73] </ref>.
Reference: [74] <author> John K. Ousterhout. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1994. </year>
Reference-contexts: Central elements of Ensemble's domain model are exported through ExL, a Lisp-based extension language [24]. As in the EMACS editor, key and mouse bindings can be modified through ExL, which also provides customization of cursor management and event mapping in compound documents. Ensemble's user interface is written in Tcl/Tk <ref> [74] </ref>, making it easy to add new features or to change existing elements of the user interface quickly. The user interface is accessible from ExL, allowing extension writers to associate visual components with new functionality. New presentations can be created and used to alter the display of a document.
Reference: [75] <author> Vern Paxson. </author> <booktitle> flex 2.5.2 man pages, </booktitle> <month> Nov. </month> <year> 1995. </year> <title> Free Software Foundation. </title>
Reference-contexts: Lexical descriptions are written using the flex specification language <ref> [75] </ref>. Grammars can be written in either extended BNF or the syntax of bison [18]. Semantic attribution is defined by a specialized language, adl [63]. The algorithms described in subsequent chapters have all been implemented as part of Ensemble, and have been tested with multiple languages and multiple documents. <p> Meta-language notation for the lexical and context-free syntax was not a specific focus of our research, which reuses established formalisms <ref> [18, 75] </ref>. An integrated language specification language that permits the automated derivation of efficient incremental evaluators remains an area of active research [96]. 4.3. <p> Several tools that facilitate the construction of such lexers have been devised, including the well-known Unix tools lex [59] and flex <ref> [75] </ref>. These tools support an extension of regular expression notation as their pattern set. <p> The user has modified the text in order to delay the choice between normal and debugging mode to run-time. (Previously it was decided at compile-time, requiring the use of a preprocessor conditional.) The lexical description in Figure 5.2 uses flex's notation <ref> [75] </ref> to specify a portion of the tokenization required by the preprocessor language. No previously published work or existing environments supporting incremental lex-ing can correctly implement this combination of language features and editing sequence.
Reference: [76] <author> Luigi Petrone. </author> <title> Reusing batch parsers as incremental parsers. </title> <booktitle> In Proc. 15th Conf. Foundations Softw. Tech. and Theor. Comput. Sci., number 1026 in LNCS, </booktitle> <pages> pages 111-123, </pages> <address> Berlin, Dec. 1995. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: INCREMENTAL PARSING OF SENTENTIAL FORMS 57 describe all opportunities for reuse and cannot be considered truly optimal. (It is also linked to the operational semantics of the particular parsing algorithm.) The history mechanisms we define subsume the mark/dispose operations described by Larcheveque. Petrone <ref> [76] </ref> recognizes that explicit states need not be stored in nodes of the parse tree. However, his parsing theory is unnecessarily restrictive; it requires the grammar to be in LR (k) " RL (h) for incremental behavior. <p> Figure 6.12 illustrates both types of reuse paths. Several incremental parsing algorithms have tried to capture a subset of top-down reuse by implementing a matching condition <ref> [58, 61, 76] </ref>. This is a test that indicates when a change can be `spliced' into existing tree structure, thus avoiding the complete reconstruction of the spine nodes. <p> As with deterministic parsing, IGLR parsing can be extended to retain existing program structure through node reuse <ref> [58, 76, 99] </ref>. <p> To simplify the handling of out-of-context analysis, we can build a temporary set of sentinel nodes that allow the subtree to appear as the entire program (see Figure 8.12). Out-of-context parsing also requires augmenting the parse table to allow any symbol to serve as the start symbol <ref> [76] </ref>.
Reference: [77] <institution> PROCASE Corporation, </institution> <address> 2694 Orchard Parkway, San Jose, California 95134. </address> <note> SMARTsystem TM Reference Guide, release 2.0 edition, </note> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: Restoring database consistency is so time-consuming that it is often done overnight [17]. Incremental software development environments ( ISDEs) provide the foundation to maintain a consistent executable image, database, or other program-wide analysis results with truly interactive speeds <ref> [6, 8, 54, 77, 66, 81] </ref>. By integrating the (typically small) set of new changes with the results of a previous analysis, incremental services can operate `instantaneously'. <p> and presentation services can then be employed across languages and document types in addition to allowing for customization on a per-language or per-document basis. 1 Beyond their obvious restriction to single-language development, this appears to have been the central technological problem with commercial mono lingual environments, such as SmartSystem TM <ref> [77] </ref>. 1.3. SCOPE OF WORK 3 Unrestricted editing model The environment should not contain inherent restrictions on the type of edits (textual, structural), their location within the program, or the timing of user modifications with respect to consistency restoration.
Reference: [78] <author> Vincent Quint and Irene Vatton. Grif: </author> <title> An interactive system for structured document manipulation. </title> <editor> In J. C. van Vliet, editor, </editor> <booktitle> Text processing and document manipulation, </booktitle> <pages> pages 200-213. </pages> <publisher> Cambridge University Press, </publisher> <month> Apr. </month> <year> 1986. </year>
Reference-contexts: Our analyses are designed to maximize component (and information) preservation within structured documents, rather than duplicating paths as the Mjlner system does. Document processing systems have explored the role of structure in the context of natural language rather than programming language documents <ref> [78] </ref>. Our approach provides interoperability with these designs, and also suggests a framework in which automated transformations (e.g., page breaking) can be considered as first-class edit operations similar to the incremental analysis performed in formal languages.
Reference: [79] <author> Jan Rekers. </author> <title> Parser Generation for Interactive Environments. </title> <type> PhD dissertation, </type> <institution> University of Amsterdam, </institution> <year> 1992. </year>
Reference-contexts: In the presence of missing or malformed program text, multiple interpretations may be retained indefinitely as a direct expression of the possibilities. We have developed a novel algorithm for incremental, non-deterministic parsing to (re)construct this IR. The parser accepts all context-free grammars: generalized LR parsing <ref> [79, 92] </ref> is used to support non-determinism and ambiguity, eliminating restrictions on the parsing grammar and the attendant need for abstraction services. <p> abstract parse dag exploits localization of ambiguity through the sharing of subtrees and contexts, the increase in space 3 Even with GLR parsing, some erasing of concrete elements unnecessary for the abstract structure, such as parentheses, is often done. 4 This property was indirectly measured by Tomita [92] and Rekers <ref> [79] </ref>, who compared the speed of a batch GLR parser to Earley's algorithm [27] on natural and programming language grammars, respectively. Both authors concluded that grammars are `close' to LR (1) in practice, and therefore GLR parsing exhibits linear behavior despite its exponential worst-case asymptotic result. 7.3. <p> We introduce a performance model to analyze the asymptotic behavior of the parser, and conclude the section by proving that sharing in the abstract parse dag is both optimal and correct. The algorithm itself appears in Appendix B. 7.3.1 Generalized LR Parsing Batch GLR parsing <ref> [73, 79, 92] </ref> is a technique for parsing arbitrary context-free grammars that utilizes conventional LR table construction methods. Unlike deterministic parsers, however, a GLR parser permits these tables to contain conflicts: when a state transition is multiply defined, the GLR parser simply forks multiple parsers to follow each possibility. <p> originally defined [92] results in under-sharing in the shared parse forest when isomorphic subtrees with the same yield are created in different states (i.e., by different parsers) due to left or right contextual restrictions. 6 Rekers corrects under-sharing in his batch GLR parser by merging nodes that have identical yields <ref> [79] </ref>. Merging is performed separately for both symbol and `rule' (production) nodes. The same approach can be applied in our algorithm, since non-deterministic regions are reconstructed atomically. A different problem exhibited by GLR algorithms is over-sharing. <p> Encoding as much filtering as possible at language specification time decreases both the size of the representation and the analysis time. ( This contrasts with existing batch GLR environments, which perform all syntactic filtering dynamically <ref> [79, 92] </ref>, and thus require quadratic space for each expression, in contrast to the negligible increases we report in Section 7.2.1.) 7.5.2 Semantic Disambiguation Filters for which the selection criteria are not context-free are referred to as `semantic' filters.
Reference: [80] <author> Jan Rekers and Wilco Koorn. </author> <title> Substring parsing for arbitrary context-free grammars. </title> <journal> SIGPLAN Not., </journal> <volume> 26(5) </volume> <pages> 59-66, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The well-known drawbacks of correcting strategies are avoided: no conjectures are necessary, spurious repairs never arise, and no heuristic `language tuning' is needed. The correctness of any repair we perform can be established easily, even in a multilingual, incremental setting. Non-correcting approaches <ref> [20, 80, 82] </ref> have not received much attention in batch compilers. Despite the theoretical advantages described above, the practical limitations imposed by a batch setting cause even the best of these approaches to be less useful than correcting methods.
Reference: [81] <author> Thomas W. Reps and Tim Teitelbaum. </author> <title> The Synthesizer Generator: A System for Constructing Language-Based Editors. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference-contexts: Restoring database consistency is so time-consuming that it is often done overnight [17]. Incremental software development environments ( ISDEs) provide the foundation to maintain a consistent executable image, database, or other program-wide analysis results with truly interactive speeds <ref> [6, 8, 54, 77, 66, 81] </ref>. By integrating the (typically small) set of new changes with the results of a previous analysis, incremental services can operate `instantaneously'. <p> A new program can be introduced to the environment by treating it as a single text insertion into an (otherwise empty) structural representation. 1 Thus Ensemble is not a `template-based' monolingual environment as are the environments produced by the Synthesizer Generator <ref> [81] </ref>. 2 In addition to text, terminals and node attributes can consist of such multimedia elements as graphic objects, images, audio/video clips, etc. The representation and editing of multimedia components and natural language documents is described elsewhere [65]. <p> These systems only require sufficient expressiveness for a single language, and do not constitute general solutions. The Galaxy environment [10] touches every token on any textual modification to the program, and is therefore not an incremental approach. The Synthesizer Generator <ref> [81] </ref> limits the user to a single outstanding edit, for which batch lexical analysis is employed to incorporate a textual modification. PSG [6] permits either textual or structural modifications, but not both, and halts its incorporation of textual modifications at the first error it encounters, rather than continuing its analysis. <p> While these algorithms decrease the time required to parse a program after a change has been made to its text, they do not materialize the persistent syntax tree required in most applications of incremental parsing. Some incremental parsing algorithms restrict the user to single-site editing <ref> [81] </ref> or to editing of only a select set of syntactic categories [21], or can only parse up to the current (single) cursor point [86].
Reference: [82] <author> H. Richter. </author> <title> Noncorrecting syntax error recovery. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 7(3) </volume> <pages> 478-489, </pages> <month> Jul. </month> <year> 1985. </year>
Reference-contexts: The well-known drawbacks of correcting strategies are avoided: no conjectures are necessary, spurious repairs never arise, and no heuristic `language tuning' is needed. The correctness of any repair we perform can be established easily, even in a multilingual, incremental setting. Non-correcting approaches <ref> [20, 80, 82] </ref> have not received much attention in batch compilers. Despite the theoretical advantages described above, the practical limitations imposed by a batch setting cause even the best of these approaches to be less useful than correcting methods. <p> Our approach instead `corrects' the problem by refusing to insert the extra opening brace into the structural representation of the program (although it remains visible in the text)a better and more comprehensible response given the actual change made by the user. 2 Right-to-left substring parsing (interval analysis <ref> [9, 82] </ref>) has been proposed to further constrain the location of detected errors, but common mistakes can result in intervals so large that the user must still locate the problem manually. Interval analysis does not address the detection problems of batch non-correcting recoveries. 8.1. INTRODUCTION 93 of the unincorporated modification.
Reference: [83] <author> Graham Ross. </author> <title> Integral C A practical environment for C programming. </title> <booktitle> In Proceedings of the Second ACM SIGSOFT/SIGPLAN Symposium on Practical Software Development Environments, </booktitle> <pages> pages 42-48. </pages> <publisher> ACM Press, </publisher> <year> 1986. </year> <note> BIBLIOGRAPHY 113 </note>
Reference-contexts: we discuss methods to mitigate these problems, then motivate and characterize our solution in the form of software development environments that operate incrementally. 1.1 Software Development Environments The term `environment' is typically used to describe an integrated collection of tools that assist the programmer in developing or maintaining software artifacts <ref> [12, 29, 47, 83] </ref>. Though historically derived from a collection of independent programscompilers, debuggers, recompilation managers, etc.the software development environment (SDE) attempts to be more than the sum of its parts. Its twin goals are to simplify and speed the development process through a tighter integration of the underlying tools. <p> All previous approaches to incremental lexing require a static bound on the length of lexical dependencies. Several monolingual environments have included incremental lexical analysis <ref> [23, 83] </ref>. These systems only require sufficient expressiveness for a single language, and do not constitute general solutions. The Galaxy environment [10] touches every token on any textual modification to the program, and is therefore not an incremental approach. <p> Unfortunately, these approaches all demand direct user intervention at each error site and therefore impose an unnecessary serialization on the analysis and the user's (manual) recovery actions. A few research and commercial environments support unattended incremental error recovery in the context of incremental parsing <ref> [8, 48, 83] </ref> but there has been little discussion or analysis of the technologies employed. No existing systems make use of the vast amount of information available in the development log being maintained by the environment.
Reference: [84] <author> Masataka Sassa, Harushi Ishizuka, and Ikuo Nakata. </author> <title> Rie, a compiler generator based on a one-pass-type attribute grammar. </title> <journal> SoftwarePractice & Experience, </journal> <volume> 25(3) </volume> <pages> 229-250, </pages> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: A trace of the parser actions on a small C ++ example is given 1 Batch systems typically handle this problem by having the lexer query the symbol table in order to separate identifiers into two distinct categories. Attribute-influenced parsing <ref> [51, 84] </ref> is a combination of LR parsing and a restricted class of attribute grammars that addresses the same problem in a formal way. Neither of these solutions can be applied to an incremental setting where non-trivial subtrees appear in the parser's input stream. 7.2.
Reference: [85] <author> Masataka Sassa and Ikuo Nakata. </author> <title> A simple realization of LR-parsers for regular right part grammars. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 113-120, </pages> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: The class of grammars permitted will be exactly those that are acceptable given a left-recursive expansion of all sequences. Existing techniques for constructing batch parsers directly from ELR (k) grammars <ref> [85] </ref> cannot be used; these algorithms treat sequences in an inherently batch fashion. 20 It is not only not necessary but undesirable for the incremental parser itself to restore the balancing condition.
Reference: [86] <author> John J. Shilling. </author> <title> Incremental LL(1) parsing in language-based editors. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 19(9) </volume> <pages> 935-940, </pages> <month> Sep. </month> <year> 1992. </year>
Reference-contexts: Some incremental parsing algorithms restrict the user to single-site editing [81] or to editing of only a select set of syntactic categories [21], or can only parse up to the current (single) cursor point <ref> [86] </ref>. Our goal was to provide an unrestricted editing model that permits mixed textual and structural editing at any number of points (including erroneous edits of indefinite extent and scope) and to analyze the entire program, not merely a prefix or syntactic fragment. <p> Their algorithm has several desirable characteristics, but its restriction to LR (0) grammars limits its applicability. LL (1) grammars are more practical ( having been used in the definitions of several programming languages) and techniques have been developed for incremental top-down parsing using this grammar class <ref> [10, 71, 86] </ref>. Li [60] describes a sentential-form LL (1) parser that can accommodate multiple edit sites. Jalili and Gallier [49] were the first to provide an incremental parsing algorithm suitable for LR (1) grammars and multiple edit sites and based on a persistent parse tree representation.
Reference: [87] <author> E. Steegmans, J. Lewi, and I. Van Horebeek. </author> <title> Generation of interactive parsers with error handling. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 18(5) </volume> <pages> 357-367, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Our approach discovers all three errors without attempting to correct the program; the visual presentation would be similar to the second version above with the explanatory text removed. the interactive nature of the environment <ref> [6, 49, 87] </ref>. Unfortunately, these approaches all demand direct user intervention at each error site and therefore impose an unnecessary serialization on the analysis and the user's (manual) recovery actions.
Reference: [88] <author> Duane Szafron and Randy Ng. LexAGen: </author> <title> An interactive incremental scanner generator. </title> <journal> SoftwarePractice & Experience, </journal> <volume> 20(5) </volume> <pages> 459-483, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: This approach does not provide additional functionality relative to our system, 6 and actually decreases performance, due to the additional overhead required. Other researchers have focused on the problem of incremental generation of batch lexical analyzers, as opposed to incremental lexing <ref> [43, 88] </ref>. Since language specifications are long-lived and infrequently changed relative to the number and frequency of changes made to programs written in those languages, we have been more concerned with the speed of the compile cycle than the speed of the compiler-compile cycle.
Reference: [89] <author> Robert Endre Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <institution> Society for Industrial and Applied Mathematics, Philadelphia, Penn., </institution> <year> 1983. </year>
Reference-contexts: and its tools the freedom to impose a balancing condition, of the sort normally used for binary trees. ( The small amount of reorganization due to re-balancing does not affect user-visible tree structure and results in a net performance gain in practice.) The appropriate data structures and algorithms are well-known <ref> [89] </ref>, so we will concentrate instead on the interaction of non-deterministic structure with incremental parsing. An obvious way to indicate the freedom to choose an internal representation for associative sequences is to describe the syntax of the language using an extended context-free (regular right part) grammar [56].
Reference: [90] <author> Mikkel Thorup. </author> <title> Controlled grammatic ambiguity. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 16(3) </volume> <pages> 1024-1050, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The following chapter discusses incremental parsing of languages in which ambiguity cannot be statically resolved. 16 These resolution methods are the most widely used, but have several theoretical disadvantages, including the fact that they may result in incomplete or even non-terminating parsers. Thorup <ref> [90] </ref> examines methods to eliminate conflicts while preserving the completeness, termination, and performance results of conventional LR parsers. Klint and Visser [53] describe parse tree filters, some of which can be applied at parse table construction time. 6.5.
Reference: [91] <author> Walter F. Tichy. </author> <title> RCS a system for version control. </title> <journal> SoftwarePractice & Experience, </journal> <volume> 15(7) </volume> <pages> 637-654, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Recording modifications at this level of granularity requires attention to bandwidth constraints and representation issues: a typical document has many nodes, each containing several versioned fields. Existing methods for capturing document updates (such as rcs <ref> [91] </ref>) are too slow and heavyweight to support fine-grained capture, and lack crucial support for structural representations and multimedia elements.
Reference: [92] <author> Masaru Tomita. </author> <title> Efficient Parsing for Natural Languages. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1985. </year>
Reference-contexts: In the presence of missing or malformed program text, multiple interpretations may be retained indefinitely as a direct expression of the possibilities. We have developed a novel algorithm for incremental, non-deterministic parsing to (re)construct this IR. The parser accepts all context-free grammars: generalized LR parsing <ref> [79, 92] </ref> is used to support non-determinism and ambiguity, eliminating restrictions on the parsing grammar and the attendant need for abstraction services. <p> 4 Since an abstract parse dag exploits localization of ambiguity through the sharing of subtrees and contexts, the increase in space 3 Even with GLR parsing, some erasing of concrete elements unnecessary for the abstract structure, such as parentheses, is often done. 4 This property was indirectly measured by Tomita <ref> [92] </ref> and Rekers [79], who compared the speed of a batch GLR parser to Earley's algorithm [27] on natural and programming language grammars, respectively. Both authors concluded that grammars are `close' to LR (1) in practice, and therefore GLR parsing exhibits linear behavior despite its exponential worst-case asymptotic result. 7.3. <p> We introduce a performance model to analyze the asymptotic behavior of the parser, and conclude the section by proving that sharing in the abstract parse dag is both optimal and correct. The algorithm itself appears in Appendix B. 7.3.1 Generalized LR Parsing Batch GLR parsing <ref> [73, 79, 92] </ref> is a technique for parsing arbitrary context-free grammars that utilizes conventional LR table construction methods. Unlike deterministic parsers, however, a GLR parser permits these tables to contain conflicts: when a state transition is multiply defined, the GLR parser simply forks multiple parsers to follow each possibility. <p> The parse forest produced by GLR parsing results in both over- and under-sharing, complicating (in some cases precluding) the application of existing methods for semantic attribution and similar tools. GLR parsing as originally defined <ref> [92] </ref> results in under-sharing in the shared parse forest when isomorphic subtrees with the same yield are created in different states (i.e., by different parsers) due to left or right contextual restrictions. 6 Rekers corrects under-sharing in his batch GLR parser by merging nodes that have identical yields [79]. <p> Encoding as much filtering as possible at language specification time decreases both the size of the representation and the analysis time. ( This contrasts with existing batch GLR environments, which perform all syntactic filtering dynamically <ref> [79, 92] </ref>, and thus require quadratic space for each expression, in contrast to the negligible increases we report in Section 7.2.1.) 7.5.2 Semantic Disambiguation Filters for which the selection criteria are not context-free are referred to as `semantic' filters.
Reference: [93] <author> Michael L. Van De Vanter, Susan L. Graham, and Robert A. Ballance. </author> <title> Coherent user interfaces for language-based editing systems. </title> <journal> Intl. J. Man-Machine Studies, </journal> <volume> 37 </volume> <pages> 431-466, </pages> <year> 1992. </year>
Reference-contexts: Lengthy delays decrease productivity and cause programmers to lose track of their working context when attempting to debug or maintain a complex program <ref> [93] </ref>. Despite the appearance of an array of techniques to salvage incrementality without discarding batch algorithms (parallel make, incremental linking, pre-compiled system headers), compilation delays remain, and remain fundamentally limiting. <p> policy and environment tools, may be permitted to directly update a subset of the semantic attributes or database entries as well. 3 This policy reflects experience showing that re-analysis after every keystroke is unnecessary for adequate performance and the (typically invalid) results will be distracting if presented to the user <ref> [93] </ref>. 4 There are no restrictions on structural updates save that a node's type remain fixed and that the resulting structure remain a tree. Structural changes not compatible with the grammar are permitted; special error nodes are introduced as necessary to accommodate such changes (see Section 8.5.1). <p> Multiple errors, including nested errors, may exist simultaneously and do not preclude the incorporation of other modifications. Errors may persist indefinitely; the environment must tolerate the presence of any invalid or inconsistent material and continue to provide as much functionality as possible <ref> [93] </ref>. The goal of the environment is to isolate problematic regions, inform the user of their location, and provide assistance by explaining the reason these modifications could not be adopted successfully.
Reference: [94] <author> Mark van den Brand and Eelco Visser. </author> <title> Generation of formatters for context-free languages. </title> <journal> ACM Trans. Softw. Eng. and Meth., </journal> <volume> 5(1) </volume> <pages> 1-41, </pages> <month> Jan. </month> <year> 1996. </year>
Reference: [95] <author> Eelco Visser. </author> <title> A case study in optimizing parsing schemata by disambiguation filters. </title> <type> Technical Report P9507, </type> <institution> Programming Research Group, University of Amsterdam, </institution> <month> Jul. </month> <year> 1995. </year>
Reference-contexts: There are two types of operators in grammars that create recursive structure: those that might have semantic significance, such as arithmetic operators, and those that are truly associative, such as the (possibly implicit) sequencing operators that 17 Visser <ref> [95] </ref> examines an alternative approach that instead modifies the item set construction to encode parse forest filters [42]. <p> Visser uses priorities and tree patterns to produce static filters <ref> [95] </ref>, but further work is needed. An integrated model of semantic attribution and dynamic (semantic) filters remains an open problem. It requires extending scheduling algorithms to dags, balancing the restrictions required for efficient static scheduling with sufficient expressive power to model disambiguation methods that arise in practice.
Reference: [96] <author> Eelco Visser. </author> <title> A family of syntax definition formalisms. </title> <booktitle> In Proceedings of ASF+SDF95A Workshop on Generating Tools from Algebraic Specifications, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: Meta-language notation for the lexical and context-free syntax was not a specific focus of our research, which reuses established formalisms [18, 75]. An integrated language specification language that permits the automated derivation of efficient incremental evaluators remains an area of active research <ref> [96] </ref>. 4.3. EDITING MODEL 27 &lt;LanguageClass&gt; (filename) Construct a new instance of a language class by dynamically loading a compiled language specification in the form of a shared library. LanguageObject *copy () Construct a new instance of a language class by duplicating an existing instance.
Reference: [97] <author> Eelco Visser. </author> <title> Scannerless generalized-LR parsing, </title> <note> 1997. In preparation. </note>
Reference-contexts: Encoding alternatives for later resolution is useful in a number of stages in the compilation pipeline. Lexical decisions are often deferred until parsing or semantic analysis by having the lexer recognize only equivalence classes of tokens. Visser <ref> [97] </ref> makes this integration explicit for a batch system by using a single GLR parser for both lexical and context-free analysis. This approach can be made incremental using the techniques we describe. Code generation also benefits from retaining multiple representations until additional information has been gathered.
Reference: [98] <author> Tim A. Wagner and Susan L. Graham. </author> <title> Integrating incremental analysis with version management. </title> <booktitle> In 5th European Softw. Eng. Conf., number 989 in LNCS, </booktitle> <pages> pages 205-218, </pages> <address> Berlin, </address> <month> Sep. </month> <title> 1995. </title> <publisher> Springer-Verlag. </publisher>
Reference: [99] <author> Tim A. Wagner and Susan L. Graham. </author> <title> Efficient and flexible incremental parsing, </title> <note> 1996. Submitted to ACM Trans. </note> <institution> Program. Lang. Syst. </institution>
Reference-contexts: As with deterministic parsing, IGLR parsing can be extended to retain existing program structure through node reuse <ref> [58, 76, 99] </ref>.
Reference: [100] <author> Tim A. Wagner and Susan L. Graham. </author> <title> Efficient self-versioning documents. </title> <booktitle> In CompCon '97, </booktitle> <pages> pages 62-67, </pages> <address> San Jose, Calif., Feb. 1997. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: [101] <author> Tim A. Wagner and Susan L. Graham. </author> <title> Incremental analysis of real programming languages. </title> <booktitle> In Proceedings of the ACM SIGPLAN '97 Conference on Programming Language Design and Implementation, page To appear. </booktitle> <publisher> ACM Press, </publisher> <month> Jun. </month> <year> 1997. </year>
Reference: [102] <author> W. M. Waite. </author> <title> The cost of lexical analysis. </title> <journal> SoftwarePractice & Experience, </journal> <volume> 16(5) </volume> <pages> 473-488, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: GVT nodes are maintained to support efficient `ancestor-of' queries. 7 Each versioned object's private history is a subset of the global version tree; an efficient array-based representation for these local version `trees' is described in the following section. 4 In a program, tokens average only a few characters in length <ref> [102] </ref>; in an essay, however, each `token' typically represents an entire paragraph. 5 We do not consider the merging of different versions here.
Reference: [103] <author> David A. Watt. </author> <title> Rule splitting and attribute-directed parsing. </title> <editor> In U. D. Jones, editor, </editor> <booktitle> Semantics-Directed Compiler Generation, number 94 in LNCS, </booktitle> <pages> pages 363-392, </pages> <address> Berlin, 1980. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: This problem arises whenever the natural context-free syntax depends on non-local type information <ref> [103] </ref>. Ambiguity is discovered during analysis of the context-free syntax, leaving multiple alternatives encoded in the parse dag.
Reference: [104] <author> Mark N. Wegman. </author> <title> Parsing for structural editors. </title> <booktitle> In Proc. of 21st Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 320-327, </pages> <address> Syracuse, N.Y., Oct. 1980. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: Incremental parsers retain the document's structure, in the form of its parse tree, and use this data structure to update the parse after changes have been made by the user or by other tools <ref> [7, 36, 49, 58, 104] </ref>. Although the topic of incremental parsing has been treated previously, no published algorithms are completely adequate, and most are inefficient in time, space, or both. Several are incorrect or overly restrictive in the class of grammars to which they apply. <p> Our recovery scheme overcomes these deficiences by using historical information: the sequence by which the programmer arrived at the current state affects the treatment and reporting of errors <ref> [104] </ref>. Changes recorded in the development log permit comparisons between the current and previous versions of the program, providing a guide for determining the source of a given problem in terms of the user's own modifications.
Reference: [105] <author> Wuu Yang. </author> <title> Incremental LR parsing. </title> <booktitle> In 1994 International Computer Symposium Conference Proceedings, </booktitle> <pages> pages 577-583 vol. 1, </pages> <institution> National Chiao Tung University, Hsinchu, Taiwan, </institution> <year> 1994. </year>
Reference-contexts: Grammars outside this class require batch parsing to the right of the first edit in each region (as defined by a matching condition similar to Larcheveque). Node reuse is a subset of that discovered by Larcheveque's algorithm. Yang <ref> [105] </ref> recognizes the utility of sentential-form parsing, but still records parse states in nodes and thus requires a post-pass to relabel subtrees.
Reference: [106] <author> Dashing Yeh and Uwe Kastens. </author> <title> Automatic construction of incremental LR(1) parsers. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 23(3) </volume> <pages> 33-42, </pages> <month> Mar. </month> <year> 1988. </year>
Reference-contexts: Error detection is discussed in conjunction with the incremental parsing algorithm; error recovery is described in Chapter 8. 6.2 Related Work Several early approaches to incremental parsing use data structures other than a persistent parse tree to achieve incremen-tality <ref> [3, 106] </ref>. While these algorithms decrease the time required to parse a program after a change has been made to its text, they do not materialize the persistent syntax tree required in most applications of incremental parsing.
References-found: 106

