URL: http://www.cs.purdue.edu/homes/sb/Projects/Musketeers/doc/hicss28_jan95.ps
Refering-URL: http://www.cs.purdue.edu/homes/sb/papers/LIST.html
Root-URL: http://www.cs.purdue.edu
Email: fkywang@cs.purdue.edu, dcm@cs.purdue.edug  
Title: Correlation of the Paging Activity of Individual Node Programs in the SPMD Execution Mode  
Author: Kuei Yu Wang and Dan C. Marinescu 
Address: West Lafayette, IN 47907  
Affiliation: Computer Sciences Department Purdue University  
Abstract: In this paper we introduce a methodology for the analysis of the paging activity of parallel programs running on massively parallel systems. The methodology includes parallel program monitoring and the analysis of the collected data. We study the correlation of the paging activities of individual node programs in the SPMD execution mode and its effect on scheduling. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.C.Burger, R.S.Hyder, B.P.Miller, and D.A.Wood. </author> <title> Paging Tradeoffs in Distributed-Shared-Memory Multiprocessors. </title> <booktitle> In: Proceedings of Supercomputing '94, to appear, </booktitle> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: The support for demand paging is an important step towards making massively parallel systems more usable and more appealing for a broader class of applications <ref> [1] </ref>. Yet, existing distributed memory MIMD systems are unbalanced; their I/O and communication bandwidths are insufficient to sustain the request rates generated by powerful processors. There is a legitimate concern that the paging activity may lead to a significant performance penalty by increasing the I/O and the communication load.
Reference: [2] <author> M.A. Cornea-Hasegan, D.C. Marinescu, and Z. Zhang, </author> <title> Data Management for a Class of Iterative Computations on Distributed Memory MIMD Systems, </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol 6(3), </volume> <pages> pp. 205-229, </pages> <year> 1994. </year>
Reference: [3] <author> Intel Corporation, </author> <title> Paragon T M OSF/1 User's Guide, Inter Supercomputer Systems Division, </title> <institution> Beaverton, Oregon, </institution> <year> 1993. </year>
Reference: [4] <author> K. Loepere. </author> <title> Mach 3 Kernel Interfaces. In: Open Software Foundation, </title> <institution> Carnegie Mellon University, </institution> <year> 1992. </year>
Reference-contexts: For our research purpose, the important measures of the paging activity are: faults, page-ins, page-outs, and cow-faults. Based on the behavior of these counters we are able to characterize the paging activity of the application under study. Other counters <ref> [4] </ref>, such as free, active, inactive count, lookup, and hits, are mostly related to the status of the physical memory cache, which depend primary on the kernel. 3 Parallel program profiling An event-driven parallel profiling library is provided to monitor and profile the execution of the parallel programs on the Paragon
Reference: [5] <author> A.D. Malony, D.A. Reed, </author> <title> and D.C. Rudolph, Integrating Performance, Data Collection, Analysis and Visualization. In: Performance Instrumentation and Visualization, </title> <editor> (M. Simmons, R. Koskela, eds.), </editor> <publisher> Addison Wesley, </publisher> <pages> 289 pages, </pages> <year> 1990. </year>
Reference: [6] <author> D.C. Marinescu, J.R. Rice, M.A. Cornea-Hasegan, R.E. Lynch, and M.G. Rossmann, </author> <title> Macromolecular Electron Density Averaging on Distributed Memory MIMD Systems. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol 5(8), </volume> <year> 1993. </year> <pages> pp. 635-657. </pages>
Reference: [7] <author> D.C. Marinescu, J.E. Lumpp, T.L. Casavant, and H.J. Siegel, </author> <title> Models for Monitoring and Debugging Tools for Parallel and Distributed Software. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol 9, </volume> <year> 1990, </year> <pages> pp. 171-184. </pages>
Reference-contexts: The system was running Paragon OSF/1, Release 1.0.4, Patch R1.1.6. We discuss briefly the intrusion due to our monitoring <ref> [7] </ref>. Comparing the size of the original load module and of the load module of the instrumented programs, we noted that the instrumented code is 5-11% larger than the original code.
Reference: [8] <author> J.K.Ousterhout. </author> <title> Scheduling Techniques for Concurrent Systems. </title> <booktitle> In Proceedings of the 3rd Distributed Computing Systems Conference. </booktitle> <pages> pp. 22-30, </pages> <month> October </month> <year> 1982. </year>
Reference-contexts: The scheduling strategy in which all processes in a process group are activated at the same time, then suspended at the same time, activated again at the same time and so on, is called gang scheduling or co-scheduling, <ref> [8] </ref>. Gang scheduling can be used to hide the latency of page faults if and only if different processes of a process group experience page faults at the same time and if the overhead for a process group context switch is low.
Reference: [9] <author> R.F. Rashid, A. Tevanian, Jr., M. Young, D. Golub, R. Baron, D. Black, W.J. Bolosky, and J. Chew, </author> <title> Machine-independent Virtual Management for Paged Uniprocessor and Multiprocessor Architectures, </title> <journal> IEEE Transactions on Computers. v.37, </journal> <volume> n.8, </volume> <pages> pp. 896-908, </pages> <year> 1988. </year>
Reference: [10] <author> D. Wybranietz and D. Haban, </author> <title> Monitoring and Measuring Distributed Systems. In: PerformanceInstrumentation and Visualization, </title> <editor> (M. Simmons, R. Koskela, eds.), </editor> <booktitle> 289 pages, </booktitle> <year> 1990. </year>
Reference: [11] <author> K. Y. Wang and D. C. Marinescu. </author> <title> An analysis of the paging activity of parallel programs. Part I: Correlation of the paging activity of individual node programsin the SPMD execution mode. </title> <type> Technical Report CSD-TR-94-042, </type> <institution> Purdue University, Department of Computer Sciences, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: A brief outline of the computations and the algorithms used by the Envelope program follows. The algorithms and profiling results of the FFTsynth program and the Recip program are presented in <ref> [11] </ref>. The Envelope program The input for this program is a 3-D lattice with nx fi ny fi nz points. Every grid point with coordinates (x 0 ; y 0 ; z 0 ) has an electron density x 0 ;y 0 ;z 0 . <p> The effects of instrumentation upon the execution are visible in the execution time of instrumented code of FFTsynth program which takes about 15-25% more time (see <ref> [11] </ref> for more details). Yet another form of intrusion which affects the data obtained through monitoring, is caused by interactions of the program being monitored with programs running concurrently in other partitions of the system. <p> For example, the 15-th peak occurred first after about 220 seconds and the last PE experienced this peak some 1700 seconds later. The complete set of results is presented in <ref> [11] </ref>. For each run we presented the page fault, page-in, copy-on-write and page-out paging activity indicators. 6 Conclusions An accurate analysis of the paging activity of a parallel program can only be done if there is enough hardware and kernel support for monitoring the execution of the program.
Reference: [12] <author> M. Young, A. Tevanian, R. Rashid, D. Golub, J. Eppinger, J. Chew, W. Bolosky, D. Black, and R. Baron, </author> <title> The Duality of Memory and Communication in the Implementation of a Multiprocessor Operating System, </title> <booktitle> Proceedings of the 11th Symposium on Operating Systems Principles, </booktitle> <pages> pp. 63-76, </pages> <year> 1987. </year>
References-found: 12

