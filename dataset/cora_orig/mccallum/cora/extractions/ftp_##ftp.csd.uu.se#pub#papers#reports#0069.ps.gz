URL: ftp://ftp.csd.uu.se/pub/papers/reports/0069.ps.gz
Refering-URL: http://www.csd.uu.se/papers/reports.html
Root-URL: 
Email: hakanm@csd.uu.se  
Title: Using the Reform Inference System for Parallel Prolog  
Author: H-akan Millroth 
Note: Electronic mail:  
Address: Box 520, S-751 20 Uppsala, Sweden  
Affiliation: Computing Science Dept., Uppsala University  
Abstract: We show how a new method for parallel logic programming, based on compilation of Tarnlund's inference system Reform, can be applied to the logic programming language Prolog. We retain the sequential left-to-right depth-first backtracking scheme with one exception: the recursion levels of a recursive program, including the head unifications at each level, are computed in parallel. We discuss criteria for when a program is amenable to this kind of parallel processing and describe parallel Reform Prolog solutions of some programming problems. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barklund, J. </author> <title> (1990) Parallel Unification, </title> <type> Ph.D. Thesis, </type> <institution> Computing Science Dept., Uppsala University. </institution>
Reference-contexts: Hence we can run the recursion levels efficiently in parallel. 5. PROGRAM EXAMPLES In this section we describe parallel Reform Prolog solutions of some programming problems. In the first example all work is done by head unification. Such programs can exploit parallel unification <ref> (Barklund, 1990) </ref> with our method, but are hard to parallelize efficiently in other parallel models. Since mutual recursion cannot be handled directly with our compilation technique it must be, automatically or manually, transformed to straight recursion. Our second example illustrates this.
Reference: <author> Clark, K. L. & S. </author> <title> Gregory (1983) PARLOG: a parallel logic programming language. </title> <type> Research report DOC 83/5, </type> <institution> Dept. of Computing, Imperial College, Lon-don. </institution>
Reference-contexts: Neither balanced/2 nor stack/2 are, by themselves, amenable for traditional AND-parallelism since each clause contains at most one literal. 2. In a concurrent logic programming language, like Parlog <ref> (Clark & Gregory, 1983) </ref> or GHC (Ueda, 1986), the balanced/2 and stack/2 calls can run as concurrent processes. The variable Ss acts as a communication channel on which balanced/2 writes messages to be consumed by stack/2.
Reference: <author> Fox, G. </author> <title> (1990) Talk given at a workshop on Massively Parallel Reasoning Systems, </title> <address> Syracuse, New York, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: In both cases one starts from a sequential program and parallelizes it by exploiting parallelism in the language construct for repetition. In the Fortran case, 12 this is often a very complicated procedure which requires expertise <ref> (Fox, 1990) </ref>. In our case, a few simple rules of programming is sufficient for writing efficient parallel programs. ACKNOWLEDGEMENT Jonas Barklund, Johan Bevemyr, Thomas Lindgren and Margus Veanes gave valuable comments on earlier drafts of this paper.
Reference: <author> Harrison III, W. L. </author> <title> (1989) The interprocedural analysis and automatic paralleliza-tion of Scheme programs. </title> <booktitle> Lisp and Symbolic Computation 2, </booktitle> <volume> No. 3/4, </volume> <pages> 179-396. </pages>
Reference-contexts: Now, let us look outside the logic programming world. A parallelization technique for recursion in Lisp, which gives essentially the same degree of parallelism as with AND-parallelism, is described by Larus (1991). Parcel <ref> (Harrison, 1989) </ref> is a compiler, for the Lisp-dialect Scheme, that paral-lelizes recursion for execution on shared-memory multiprocessors. This work addresses the same problem as we do: compiling recursion to parallel iteration. Let us point out some notable differences in the solutions.
Reference: <author> Kowalski, R. A. </author> <title> (1974) Predicate logic as a computer language. </title> <booktitle> In Information Processing 74, </booktitle> <pages> pp. 569-574. </pages> <publisher> North-Holland, Amsterdam. </publisher>
Reference: <author> Larus, J. R. </author> <title> (1991) Compiling Lisp programs for parallel execution. </title> <booktitle> Lisp and Symbolic Computation 4, </booktitle> <volume> No. 1, </volume> <pages> 29-99. </pages>
Reference: <author> Millroth, H. </author> <title> (1990) Reforming Compilation of Logic Programs, </title> <type> Ph.D. Thesis, </type> <institution> Computing Science Dept., Uppsala University. </institution> <note> (Summary to appear at Int. Logic Programming Symp., </note> <institution> San Diego, CA., </institution> <note> October 1991) Millroth, H. (1991) Compiling Reform, (to appear in) Massively Parallel Reasoning Systems (eds. </note> <editor> J. A. Robinson & E. E. Siebert), </editor> <publisher> MIT Press. </publisher>
Reference-contexts: Our basic idea is that parallelization takes place across recursion levels: the recursion levels of a program, including the head unifications at each level, are computed in parallel. The sequential left-to-right depth-first backtracking scheme of Prolog is retained within each recursion level. We compile structural recursion to bounded iteration <ref> (Millroth, 1990) </ref>. The iterative programs are parallelized by standard methods developed for imperative programs. The technique is based on an analysis of the unification patterns of recursive programs. This approach has a number of appealing consequences: 1. It gives the parallel program a natural and easy-to-understand parallel reading. <p> Compilation of nonlinear structural recursion follows the same principles as in the linear case. This is possible since a temporary linear representation of the recursion tree is obtained in the single large head unification that replaces the smaller unifications of a traditional system <ref> (Millroth, 1990) </ref>. We shall limit the discussion in this paper to linear recursion. 3. REFORM PROGRAMMING IN PROLOG We now apply Reform to the logic programming language Prolog.
Reference: <author> Mycroft, A. & R. A. </author> <title> O'Keefe (1984) A Polymorphic Type System for Prolog. </title> <journal> Artificial Intelligence 23, </journal> <volume> No. 3, </volume> <pages> 295-307. </pages>
Reference: <author> Naish, L. </author> <title> (1988) Parallelizing NU-Prolog. </title> <booktitle> Proc. 5th Int. Conf./Symp. Logic Programming (eds. </booktitle> <editor> K. A. Bowen & R. A. Kowalski), </editor> <address> Seattle, Washington. </address>
Reference-contexts: Each recursion level is deterministic with respect to the bindings made to the global variables. We say that the recursion levels are binding deterministic <ref> (Naish, 1988) </ref> with respect to the global variables, if this condition is fulfilled. Note that the concept of binding determinism is different from the concept of data dependency in programming languages lacking logical variables. <p> Hence one must be careful not to bind any global variables before tests or before cut in a clause. Consequently, one must sometimes defer output unification to the clause body. We observe that it would be convenient to do this program transformation automatically. The declarations used in Parallel NU-Prolog <ref> (Naish, 1988) </ref> seems to be adequate for this purpose.
Reference: <author> O'Keefe, R. A. </author> <title> (1990) The Craft of Prolog. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass. </address>
Reference: <editor> Press, W. H. et al. </editor> <booktitle> (1989) Numerical Recepies. The Art of Scientific Computing. </booktitle>
Reference: <editor> Cambridge U. P., </editor> <address> Cambridge. </address>
Reference: <author> Shapiro, E. Y. </author> <title> (1983) A Subset of Concurrent Prolog and its Interpreter. </title> <type> Technical report TR-003, </type> <institution> ICOT, </institution> <address> Tokyo. </address>
Reference: <author> T arnlund, S. A. </author> <year> (1991) </year> <month> Reform, </month> <note> (to appear in) Massively Parallel Reasoning Systems (eds. </note> <editor> J. A. Robinson & E. E. Siebert), </editor> <publisher> MIT Press. </publisher>
Reference-contexts: Supplying the input data to the node processors. 2. Computing one instance of the body of the recursive clause on each node proces sor. 3. Returning control to the root processor. The parallel abstract machine used in the Reform project at Uppsala University <ref> (Tarnlund et al., 1991) </ref> has an inter-processor topology incorporating both a ring and 6 a binary tree. The ring is used for communication between adjacent recursion levels of a parallel predicate whereas the tree is used for transmitting data between the sequential and the parallel parts of the computation. Example.
Reference: <author> T arnlund, S. A, H. Millroth, J. Bevemyr, T. Lindgren & M. </author> <note> Veanes (1991) Perform: a Parallel Reform Machine, submitted for publication. </note>
Reference-contexts: Supplying the input data to the node processors. 2. Computing one instance of the body of the recursive clause on each node proces sor. 3. Returning control to the root processor. The parallel abstract machine used in the Reform project at Uppsala University <ref> (Tarnlund et al., 1991) </ref> has an inter-processor topology incorporating both a ring and 6 a binary tree. The ring is used for communication between adjacent recursion levels of a parallel predicate whereas the tree is used for transmitting data between the sequential and the parallel parts of the computation. Example.
Reference: <author> Ueda, K. </author> <title> (1986) Guarded Horn Clauses, Eng.D. </title> <type> Thesis, </type> <institution> University of Tokyo. </institution> <month> 13 </month>
Reference-contexts: Neither balanced/2 nor stack/2 are, by themselves, amenable for traditional AND-parallelism since each clause contains at most one literal. 2. In a concurrent logic programming language, like Parlog (Clark & Gregory, 1983) or GHC <ref> (Ueda, 1986) </ref>, the balanced/2 and stack/2 calls can run as concurrent processes. The variable Ss acts as a communication channel on which balanced/2 writes messages to be consumed by stack/2.
References-found: 16

