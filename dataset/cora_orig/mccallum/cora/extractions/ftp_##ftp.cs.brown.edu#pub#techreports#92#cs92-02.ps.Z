URL: ftp://ftp.cs.brown.edu/pub/techreports/92/cs92-02.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-92-02.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: <institution> 17 </institution>
Reference: [1] <author> Aggarwal, A., Alpern, B., Chandra, A. K. and Snir, M., </author> <title> A model for hierarchical memory, </title> <booktitle> Proceedings of 19th Annual ACM Symposium on Theory of Computing, </booktitle> <address> New York, NY (May 1987), </address> <pages> 305-314. </pages>
Reference-contexts: Several interesting and elegant hierarchical memory models have been proposed recently to model the many levels of memory typically found in large-scale computer systems. The Hierarchical Memory Model (HMM) of Aggarwal, Alpern, Chandra, and Snir <ref> [1] </ref> views the entire memory hierarchy as a linear address space and allows access to individual location x in time f (x). <p> log H if f (x) = x ff , ff = 1; H + H N log H if f (x) = x ff , ff &gt; 1, The algorithms were based on their randomized two-level partitioning technique applied to the optimal single-hierarchy algorithms for HMM and BT developed in <ref> [1, 2] </ref>. 7 We can consider parallel UMH hierarchies (analogous to P-HMM and P-BT), and we call the resulting model P-UMH. (This is fundamentally different from the parallel type of UMH called UPHM mentioned in [5].) Each level ` in each of the H hierarchies of the P-UMH holds ff 2`
Reference: [2] <author> Aggarwal, A., Chandra, A. and Snir, M., </author> <title> Hierarchical memory with block transfer, </title> <booktitle> Proceedings of 28th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <address> Los Angeles, CA (October 1987), </address> <pages> 204-216. </pages>
Reference-contexts: Accordingly, data are usually transferred in large units of blocks. The Block Transfer (BT) model of Aggarwal, Chandra, and Snir <ref> [2] </ref> represents a notion of block transfer applied to HMM; in the BT model, access to the t + 1 records at locations x t, x t + 1, . . . , x takes time f (x) + t. <p> log H if f (x) = x ff , ff = 1; H + H N log H if f (x) = x ff , ff &gt; 1, The algorithms were based on their randomized two-level partitioning technique applied to the optimal single-hierarchy algorithms for HMM and BT developed in <ref> [1, 2] </ref>. 7 We can consider parallel UMH hierarchies (analogous to P-HMM and P-BT), and we call the resulting model P-UMH. (This is fundamentally different from the parallel type of UMH called UPHM mentioned in [5].) Each level ` in each of the H hierarchies of the P-UMH holds ff 2` <p> We insert a step into the P-HMM algorithm that permutes the elements on each hierarchy so that each bucket appears in contiguous locations; an algorithm to perform this generalized transposition permutation was described in <ref> [2] </ref>.
Reference: [3] <author> Aggarwal, A. and Vitter, J. S., </author> <title> The input/output complexity of sorting and related problems, </title> <journal> Communications of the ACM (September 1988), </journal> <pages> 1116-1127. </pages>
Reference-contexts: The minimum number of I/Os required for sorting in the `th two-level memory is N log (N=B ` ) B ` ; as shown in <ref> [3] </ref>. Each such I/O contributes C i to the sequential time in the P-SUMH model, since in the P-SUMH model only one level can be active at a time in each hierarchy.
Reference: [4] <author> Akl, S. G., </author> <title> Parallel Sorting Algorithms, </title> <booktitle> Notes and Reports in Computer Science and Applied Mathematics #12, </booktitle> <publisher> Academic Press, Inc., </publisher> <address> Orlando, </address> <year> 1985. </year>
Reference-contexts: The fastest oblivious algorithm we have found for sorting in UMH 1=(`+1) is based on a simple schedule of Batcher's bitonic sort <ref> [4] </ref> where each of the log 2 N parallel time steps is implemented in O (N log N ) time for an overall running time of O (N log 3 N ).
Reference: [5] <author> Alpern, B., Carter, L. and Feig, E., </author> <title> Uniform memory hierarchies, </title> <booktitle> Proceedings of the 31st Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <address> St. Louis, </address> <month> MO (October </month> <year> 1990), </year> <pages> 600-608. </pages>
Reference-contexts: two-level partitioning technique applied to the optimal single-hierarchy algorithms for HMM and BT developed in [1, 2]. 7 We can consider parallel UMH hierarchies (analogous to P-HMM and P-BT), and we call the resulting model P-UMH. (This is fundamentally different from the parallel type of UMH called UPHM mentioned in <ref> [5] </ref>.) Each level ` in each of the H hierarchies of the P-UMH holds ff 2` records, for a total of ffH 2` records on level `. <p> For the special case of constant bandwidth, we present a parsimonious algorithm. Since optimal sorting seems to require nonoblivious UMH programs, the oblivious UMH model of <ref> [5] </ref> must be modified in a reasonable way. In Theorem 1, we assume that the `th level of the hierarchy can initiate a transfer from the (` + 1)st level without involving the CPU when one of its blocks becomes empty. <p> An earlier version of <ref> [5] </ref> introduced a sequential UMH model, appropriately called SUMH, that allowed at most one bus to be active at a time. However, the SUMH restriction can be regarded as too severe, since it forfeits much power of the UMH model.
Reference: [6] <author> Alpern, B., Carter, L. and Selker, T., </author> <title> Visualizing computer memory architectures, </title> <booktitle> Proceedings of the 1990 IEEE Visualization Conference Foundations of Computer Science (October 1990). </booktitle>
Reference: [7] <author> Leighton, T., </author> <title> Tight bounds on the complexity of parallel sorting, </title> <journal> IEEE Transactions on Computers C-34 (April 1985), </journal> <pages> 344-354. </pages>
Reference-contexts: It is also possible to schedule a recursive version of Columnsort <ref> [7] </ref> on UMH 1=(`+1) in a manner that is efficient with respective to the RAM algorithm, but this observation is not very useful since both algorithms have running time that is O (N log c N ), where c 3:4. 2.1 Parsimonious sorting in UMH 1 Theorem 1 A variant of
Reference: [8] <author> Luccio, F. and Pagli, L., </author> <title> A model of sequential computation based on a pipelined access to memory, </title> <booktitle> Proceedings of the 27th Annual Allerton Conference on Communication, Control, and Computing, Allerton, </booktitle> <address> IL (September 1989). </address>
Reference-contexts: A model similar to the BT model that allows pipelined access to memory in O (log n) time was developed independently by Luccio and Pagli <ref> [8] </ref>. Optimal sorting algorithms for each of these models have been developed [1,2,8]. In this paper, we concentrate on a newer hierarchical memory model introduced by Alpern, Carter, and Feig [5,6], called the Uniform Memory Hierarchy (UMH), which offers an alternative model of blocked multilevel memories.
Reference: [9] <author> Nodine, M. H. and Vitter, J. S., </author> <title> Optimal Deterministic Sorting on Parallel Memory Hierarchies, </title> <type> Technical Report, </type> <institution> Department of Computer Science, Brown University, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: The related FFT computation can be done in UMH 1=(`+1) in O (N log N ) time. Another open problem is whether a parsimonious oblivious algorithm can be found to replace our non-oblivious one in UMH 1 . Addendum After submitting this paper, Nodine and Vitter <ref> [9] </ref> have developed an optimal deterministic sorting algorithm for the P-HMM and P-BT parallel memory hierarchies, assuming that the interconnection network at the base level consists of a CRCW PRAM to allow optimal internal sorting. This improves upon the optimal randomized algorithms of [11]. <p> This improves upon the optimal randomized algorithms of [11]. With such an interconnection network, the deterministic algorithms in <ref> [9] </ref> can then be used in place of those of [11] in the simulations in this paper, thus transforming all the randomized algorithms in this paper into deterministic ones. Acknowledgments We thank the referees for their helpful comments.
Reference: [10] <author> Reif, J. H. and Valiant, L. G., </author> <title> A Logarithmic time sort on linear size networks, </title> <journal> Journal of the ACM 34 (January 1987), </journal> <pages> 60-76. </pages>
Reference-contexts: The H base memory level locations are interconnected via a network such as the hypercube or cube-connected cycles so that the H records in the base memory level can be sorted in O (log H) time (perhaps via a randomized algorithm <ref> [10] </ref>). The parallel versions of HMM and BT are called P-HMM and P-BT, respectively.
Reference: [11] <author> Vitter, J. S. and Shriver, E. A. M., </author> <title> Algorithms for Parallel Memory II: Hierarchical Multilevel Memories, </title> <institution> Brown University, CS-92-05, </institution> <year> 1992, </year> <title> also appears in summarized form in Optimal disk I/O with parallel block transfer, </title> <booktitle> Proceedings of the 22nd Annual ACM Symposium on Theory of Computing, </booktitle> <address> Baltimore, MD (May 1990) 159-169. 18 4 CONCLUSIONS </address>
Reference-contexts: The algorithm that achieves the upper bound for the first case b (`) = 1 is based on a simulation of the P-BT algorithm for access cost function f (x) = p x given in <ref> [11] </ref>. The time for the simulation is bounded by a constant times the P-BT running time. <p> The algorithms given in <ref> [11] </ref> all meet this constraint. For the second case b (`) = 1=(` + 1), the upper bound is related to the P-HMM approach for f (x) = log x [11]. The P-HMM algorithm needs to be modified to reblock the buckets prior to sorting them recursively. <p> The algorithms given in <ref> [11] </ref> all meet this constraint. For the second case b (`) = 1=(` + 1), the upper bound is related to the P-HMM approach for f (x) = log x [11]. The P-HMM algorithm needs to be modified to reblock the buckets prior to sorting them recursively. <p> Hence, the lower bound for P-HMM for f (x) = log x given in <ref> [11] </ref> also holds for P-RUMH 1=(`+1) . 2 Theorem 4 The following bounds are matching upper and lower bounds for sorting in P-SUMH. <p> N log N log log N !! fi N log N log H if b (`) = ` + 1 fi N 1+c=2 N log N if b (`) = c` , c &gt; 0. 15 Proof : We prove the lower bounds using an approach similar to that of <ref> [11] </ref>. Let us define the "sequential time" of a P-SUMH algorithm to be the sum of its time costs for each of the H hierarchies. The sequential time can be at most H times the P-SUMH running time. <p> The b (`) = c` case additionally requires the use of the the conventional N log N serial bound for sorting. The upper bounds for the first two cases b (`) = 1 and b (`) = 1=(` + 1) are achieved by simulating the optimal P-HMM algorithm of <ref> [11] </ref>, for access cost functions f (x) = log x and f (x) = log 2 x, respectively. <p> This improves upon the optimal randomized algorithms of <ref> [11] </ref>. With such an interconnection network, the deterministic algorithms in [9] can then be used in place of those of [11] in the simulations in this paper, thus transforming all the randomized algorithms in this paper into deterministic ones. Acknowledgments We thank the referees for their helpful comments. <p> This improves upon the optimal randomized algorithms of <ref> [11] </ref>. With such an interconnection network, the deterministic algorithms in [9] can then be used in place of those of [11] in the simulations in this paper, thus transforming all the randomized algorithms in this paper into deterministic ones. Acknowledgments We thank the referees for their helpful comments.
Reference: [12] <author> Vitter, J. S. and Shriver, E. A. M., </author> <title> Algorithms for parallel memory I: two-level memories, </title> <institution> Brown University, CS-92-04, </institution> <year> 1992, </year> <title> also appears in summarized form in Optimal disk I/O with parallel block transfer, </title> <booktitle> Proceedings of the 22nd Annual ACM Symposium on Theory of Computing, </booktitle> <address> Baltimore, MD (May 1990) 159-169. </address>
Reference-contexts: The parallel versions of HMM and BT are called P-HMM and P-BT, respectively. Vitter and Shriver introduced optimal randomized sorting algorithms for P-HMM and P-BT <ref> [12] </ref> to sort with the following bounds: T P-HMM = &gt; &gt; &gt; &gt; &gt; &lt; fi N log N log log N !! fi N ff+1 N log N if f (x) = x ff , ff &gt; 0; 6 1 INTRODUCTION all of the same type, such as HMM, <p> The structures of the formulas in Theorems 3 and 4 suggest several different relationships between the RUMH and SUMH models on the one hand and the HMM, BT, and two-level models on the other hand (cf. Theorems 5 and 6 in <ref> [12] </ref>); accordingly the upper and lower bounds combine in an interesting way several techniques from [1,2,3,12]. Theorem 3 The running times mentioned in Theorem 2 are matching upper and lower bounds for sorting in P-RUMH.
References-found: 13

