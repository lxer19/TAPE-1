URL: http://theory.lcs.mit.edu/~rajiyer/papers/FreundIyScSi98b.ps
Refering-URL: http://theory.lcs.mit.edu/~rajiyer/
Root-URL: 
Email: yoav@research.att.com  rajiyer@mit.edu  schapire@research.att.com  singer@research.att.com  
Title: DRAFT. An Efficient Boosting Algorithm for Combining Preferences  
Author: Yoav Freund Raj Iyer Robert E. Schapire Yoram Singer 
Note: Research conducted while visiting AT&T Labs and with support from an NSF Graduate Fellowship  
Date: February 27, 1998  
Affiliation: AT&T Labs  MIT Laboratory for Computer Science  AT&T Labs  AT&T Labs  
Abstract: The problem of combining preferences arises in several applications, such as combining the results of different search engines. This work describes an efficient algorithm for combining multiple preferences. We first give a formal framework for the problem. We then describe and analyze a new boosting algorithm for combining preferences called RankBoost. We also describe an efficient implementation of the algorithm for a restricted case. We discuss two experiments we carried out to assess the performance of RankBoost. In the first experiment, we used the algorithm to combine different search strategies, each of which is a query expension for a given domain. For this task, we compare the performance of RankBoost to the individual search strategies. The second experiment is a collaborative-filtering task, specifically, for making movie recommendations. Here, we present results comparing RankBoost to nearest neighbor and regression algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brian T. Bartell, Garrison W. Cottrell, and Richard K. Belew. </author> <title> Automatic combination of multiple ranked retrieval systems. </title> <booktitle> In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1994. </year>
Reference-contexts: Despite the wide range of applications that use and combine rankings, this problem has received relatively little attention in the machine-learning community. The few methods that have been devised for combining rankings tend to be based either on nearest-neighbor methods [8, 11] or numerical-optimization techniques <ref> [1, 2] </ref>. In the latter case, the rankings are viewed as real-valued scores and the problem of combining different rankings reduces to numerical search for a set of parameters that will minimize the disparity between the combined scores and the feedback of a user. <p> Thus, if we are using weak hypotheses with range restricted to f0; 1g, we should attempt to find h which tends to minimize this value of Z and we should then set ff accordingly. For weak hypotheses with range <ref> [0; 1] </ref>, we can use a third method based on an approximation of Z. Specifically, note that e ffx 1 + x 2 e ff for all real ff and x 2 [1; +1]. <p> For weak hypotheses with range [0; 1], we can use a third method based on an approximation of Z. Specifically, note that e ffx 1 + x 2 e ff for all real ff and x 2 <ref> [1; +1] </ref>. <p> Thus, to approximately minimize Z using weak hypotheses with range <ref> [0; 1] </ref>, we can attempt to maximize jrj as defined in Eq. (3) and then set ff as in Eq. (4). This is the method used in our experiments. 3.3 An efficient implementation for bipartite feedback. <p> For the remainder of this section, we show how to choose the best feature, threshold and default score. Let us fix t and drop it from all subscripts to simplify the notation. Since the ranges of our weak hypotheses are bounded in <ref> [0; 1] </ref>, we can use the third method 1 described in Section 3.2 to guide us in our search for a weak hypothesis. Recall that, according to this method, the weak learner should seek a weak hypothesis which maximizes jrj as given by Eq. (3). <p> The definitions can be extended by assuming that ties are broken randomly and taking expectations (details omitted for lack of space). All our measures have range <ref> [0; 1] </ref>, with a value 0 being a perfect score. Disagreement. Disagreement is the fraction of distinct pairs of instances which are misordered by H (with respect to c). If c were used to construct a feedback function, this would be equivalent to the ranking loss of H. Predicted-rank-of-top (PROT). <p> Predicted-rank-of-top (PROT). This is the minimum rank (according to H) of any of the truly top-rated instances (according to c). The score is then rescaled to have a possible range of <ref> [0; 1] </ref>. 14 Coverage. This is the maximum rank (according to H) of any of the truly top-rated instances (according to c). The score is then rescaled to have a possible range of [0; 1]. (Note that coverage and PROT are equal if there is a unique top-rated instances according to <p> The score is then rescaled to have a possible range of <ref> [0; 1] </ref>. 14 Coverage. This is the maximum rank (according to H) of any of the truly top-rated instances (according to c). The score is then rescaled to have a possible range of [0; 1]. (Note that coverage and PROT are equal if there is a unique top-rated instances according to c.) Rank-of-predicted-top (ROPT). This is the number of instances ranked strictly higher (according to c) than the predicted top-rated instance (according to H). <p> This is the number of instances ranked strictly higher (according to c) than the predicted top-rated instance (according to H). The score is then rescaled to have a possible range of <ref> [0; 1] </ref>. We now describe our experimental results. We ran a series of three tests, examining the performance of the algorithms as we varied the number of features, the density of the features (number of movies ranked by each user), and the density of the feedback.
Reference: [2] <author> R. Caruana, S. Baluja, and T. Mitchell. </author> <title> Using the future to sort out the present: Rankprop and multitask learning for medical risk analysis. </title> <booktitle> In Advances in Neural Information Processing Systems 7, </booktitle> <year> 1995. </year>
Reference-contexts: Despite the wide range of applications that use and combine rankings, this problem has received relatively little attention in the machine-learning community. The few methods that have been devised for combining rankings tend to be based either on nearest-neighbor methods [8, 11] or numerical-optimization techniques <ref> [1, 2] </ref>. In the latter case, the rankings are viewed as real-valued scores and the problem of combining different rankings reduces to numerical search for a set of parameters that will minimize the disparity between the combined scores and the feedback of a user.
Reference: [3] <author> William W. Cohen, Robert E. Schapire, and Yoram Singer. </author> <title> Learning ro order things. </title> <booktitle> In Advances in Neural Information Processing Systems 10, </booktitle> <year> 1997. </year>
Reference-contexts: While the above (and other) approaches might work well in practice, they still do not guarantee that the combined system will match the user's preference when we view the scores as a means to express preferences. Recently, Cohen, Schapire and Singer <ref> [3] </ref> proposed a framework for manipulating and combining multiple rankings in order to directly minimize the number of disagreements. <p> For instance, approaches that learn to combine similarity scores are not applicable since the similarity scores of Web search engines are often unavailable. In order to test RankBoost on this task, we used the data of Cohen, Schapire and Singer <ref> [3] </ref>. Their goal was to simulate the problem of building a domain-specific search engine. As test cases, they picked two fairly narrow classes of queriesretrieving the homepages of machine-learning researchers (ML), and retrieving the homepages of universities (UNIV).
Reference: [4] <author> O. Etzioni, S. Hanks, T. Jiang, R. M. Karp, O. Madani, and O. Waarts. </author> <title> Efficient information gathering on the internet. </title> <booktitle> In 37th Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1996. </year> <month> 16 </month>
Reference-contexts: This distinction becomes very important when we combine the rankings of many users who often use completely different ranges of scores to express identical preferences. Situations where we need to combine the ranking of different models also arise in meta-searching problems <ref> [4] </ref> and in information-retrieval problems [10, 9]. In this paper, we introduce and analyze an efficient algorithm called RankBoost for combining multiple rankings. This algorithm is based on Freund and Schapire's [5] AdaBoost algorithm and its recent successor developed by Schapire and Singer [12].
Reference: [5] <author> Yoav Freund and Robert E. Schapire. </author> <title> A decision-theoretic generalization of on-line learning and an application to boosting. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 55(1) </volume> <pages> 119-139, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: Situations where we need to combine the ranking of different models also arise in meta-searching problems [4] and in information-retrieval problems [10, 9]. In this paper, we introduce and analyze an efficient algorithm called RankBoost for combining multiple rankings. This algorithm is based on Freund and Schapire's <ref> [5] </ref> AdaBoost algorithm and its recent successor developed by Schapire and Singer [12]. Similar to other boosting algorithms, RankBoost works by combining many weak rankings of the given instances. Each of these may be only weakly correlated with the target ranking that we are attempting to approximate. <p> Output the final hypothesis: H (x) = T X ff t h t (x): 3 A boosting algorithm for the ranking task. In this section, we describe an approach to the ranking problem based on a machine learning method called boosting, in particular, Freund and Schapire's <ref> [5] </ref> AdaBoost algorithm and its successor developed by Schapire and Singer [12]. Boosting is a method of producing highly accurate prediction rules by combining many weak rules which may be only moderately accurate.
Reference: [6] <author> W.C. Hill, L. Stead, M. Rosenstein, and G.W. Furnas. </author> <title> Recommending and evaluating choices in a virtual community of use. </title> <booktitle> In Porceedings of the 1995 Human Factors in Computing Systems Conference, </booktitle> <pages> pages 194-201, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction. Consider the following movie-recommendation task, some-times called a collaborative-filtering problem <ref> [6, 11] </ref>. In this task, a new user, Alice, seeks recommendations of movies that she is likely to enjoy. A collaborative-filtering system first asks Alice to rank movies that she has already seen. <p> In these experiments, we ran RankBoost for 100 rounds. We compared the performance of RankBoost on this data set to two other algo 13 rithms, a regression algorithm and a nearest-neighbor algorithm. Regression. We used a regression algorithm similar to the ones used by Hill and others <ref> [6] </ref>. The regression algorithm employs the assumption that the preferences of a target user Alice can be described as a linear combination of the preferences of other users. Formally, let ~a be a row vector whose components are the scores Alice assigned to movies (discarding unranked movies).
Reference: [7] <author> Paul McJones. </author> <title> Eachmovie collaborative filtering data set. </title> <note> DEC Systems Research Center, 1997. http://www.research.digital.com/SRC/eachmovie/. </note>
Reference-contexts: We also tested RankBoost on the movie-recommendations task described in the introduction. For our experiments, we used the publicly available data of DEC SRC <ref> [7] </ref> which ran its own EachMovie recommendation service for eighteen months from March 1996 to September 1997 and collected user preference data. Users were able to assign a movie a score from the set R = f0:0; 0:2; 0:4; 0:6; 0:8; 1:0g, 1.0 being the best.
Reference: [8] <author> Paul Resnick, Neophytos Iacovou, Mitesh Sushak, and John Riedl Peter Bergstrom. Grouplens: </author> <title> An open architecture for collaborative filtering of netnews. </title> <booktitle> In Proceedings of Computer Suppo-erted Cooperative Work, </booktitle> <year> 1995. </year>
Reference-contexts: Despite the wide range of applications that use and combine rankings, this problem has received relatively little attention in the machine-learning community. The few methods that have been devised for combining rankings tend to be based either on nearest-neighbor methods <ref> [8, 11] </ref> or numerical-optimization techniques [1, 2]. In the latter case, the rankings are viewed as real-valued scores and the problem of combining different rankings reduces to numerical search for a set of parameters that will minimize the disparity between the combined scores and the feedback of a user.
Reference: [9] <author> Gerard Salton. </author> <title> Automatic text processingthe transformation, analysis and retrieval of information by computer. </title> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: This distinction becomes very important when we combine the rankings of many users who often use completely different ranges of scores to express identical preferences. Situations where we need to combine the ranking of different models also arise in meta-searching problems [4] and in information-retrieval problems <ref> [10, 9] </ref>. In this paper, we introduce and analyze an efficient algorithm called RankBoost for combining multiple rankings. This algorithm is based on Freund and Schapire's [5] AdaBoost algorithm and its recent successor developed by Schapire and Singer [12].
Reference: [10] <author> Gerard Salton and M.J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw Hill, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: This distinction becomes very important when we combine the rankings of many users who often use completely different ranges of scores to express identical preferences. Situations where we need to combine the ranking of different models also arise in meta-searching problems [4] and in information-retrieval problems <ref> [10, 9] </ref>. In this paper, we introduce and analyze an efficient algorithm called RankBoost for combining multiple rankings. This algorithm is based on Freund and Schapire's [5] AdaBoost algorithm and its recent successor developed by Schapire and Singer [12].
Reference: [11] <editor> Upendra Shardananda and Pattie Maes. </editor> <title> Social information filtering: Algorithms for automating word of mouth. </title> <booktitle> In Proc. of the International Conference on Computer-Human Interfaces, </booktitle> <year> 1995. </year>
Reference-contexts: 1 Introduction. Consider the following movie-recommendation task, some-times called a collaborative-filtering problem <ref> [6, 11] </ref>. In this task, a new user, Alice, seeks recommendations of movies that she is likely to enjoy. A collaborative-filtering system first asks Alice to rank movies that she has already seen. <p> Despite the wide range of applications that use and combine rankings, this problem has received relatively little attention in the machine-learning community. The few methods that have been devised for combining rankings tend to be based either on nearest-neighbor methods <ref> [8, 11] </ref> or numerical-optimization techniques [1, 2]. In the latter case, the rankings are viewed as real-valued scores and the problem of combining different rankings reduces to numerical search for a set of parameters that will minimize the disparity between the combined scores and the feedback of a user.
Reference: [12] <author> Robert E. Schapire Yoram Singer. </author> <title> Improved boosting algorithms using confidence-rated predictions. </title> <note> Submitted for publication. 17 </note>
Reference-contexts: In this paper, we introduce and analyze an efficient algorithm called RankBoost for combining multiple rankings. This algorithm is based on Freund and Schapire's [5] AdaBoost algorithm and its recent successor developed by Schapire and Singer <ref> [12] </ref>. Similar to other boosting algorithms, RankBoost works by combining many weak rankings of the given instances. Each of these may be only weakly correlated with the target ranking that we are attempting to approximate. <p> In this section, we describe an approach to the ranking problem based on a machine learning method called boosting, in particular, Freund and Schapire's [5] AdaBoost algorithm and its successor developed by Schapire and Singer <ref> [12] </ref>. Boosting is a method of producing highly accurate prediction rules by combining many weak rules which may be only moderately accurate.
References-found: 12

