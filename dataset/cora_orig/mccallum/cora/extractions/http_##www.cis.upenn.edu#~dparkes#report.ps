URL: http://www.cis.upenn.edu/~dparkes/report.ps
Refering-URL: http://www.cis.upenn.edu/~dparkes/home.html
Root-URL: 
Email: dparkes@unagi.cis.upenn.edu dsteinig@gradient.cis.upenn.edu  
Title: The Santa Fe Bar Problem: A Study in Multiagent Learning  
Author: David C. Parkes and Debbie Steinig 
Address: 200 South 33rd Street, Philadelphia, PA 19104  
Affiliation: Computer and Information Science Department University of Pennsylvania  
Abstract: We study the process of multiagent learning in the context of the "Santa Fe Bar Problem" (Arthur 1994). We imagine a system of bounded rational agents taking decisions within a repeated game. Each agent has a finite number of decision procedures with which to reason, and access to the entire history of outcomes of the game. We first allow the agents to use only deterministic decision procedures. We show that an efficient solution emerges, without central coordination or explicit coordination, through the dynamics and diversity of the agents. We then introduce randomized decision procedures and demonstrate that good coordination emerges more quickly, and that the long term equilibrium is more stable and less bursty. keywords: multiagent learning, resource contention
Abstract-found: 1
Intro-found: 1
Reference: <author> Arthur, W. B. </author> <year> 1994. </year> <title> Inductive reasoning and bounded rationality. </title> <booktitle> AEA Papers and Proceedings 84(2) </booktitle> <pages> 406-411. </pages>
Reference-contexts: 1 Introduction Brian Arthur <ref> (Arthur 1994) </ref> poses the Santa Fe Bar Problem: a certain bar in Santa Fe comfortably holds 60 people. 100 people would like to go to the bar each week, but nobody will enjoy themselves at the bar if there are more than 60 people present; staying home has a higher utility
Reference: <author> Axelrod, R., and Hamilton, W. D. </author> <year> 1981. </year> <title> The evolution of cooperation. </title> <booktitle> Science 211 </booktitle> <pages> 1390-1396. </pages>
Reference-contexts: However, if all of the agents are non-cooperative then all of them will lose, because there will be no exploration in the system. This is a classic example of Prisoners Dilemma <ref> (Axelrod & Hamilton 1981) </ref>. The agents are able to adapt to changing system loads and changing resource capacities. Schaerf et. al. also consider the effect of adding communication to the system, which brings the model closer to Arthur's, by introducing global information.
Reference: <author> Hogg, T., and Huberman, B. A. </author> <year> 1991. </year> <title> Controlling chaos in distributed systems. </title> <journal> IEEE Trans. on Systems, Man and Cybernetics 21(6) </journal> <pages> 1325-1332. </pages>
Reference-contexts: Kephart also shows that a system with inhomogeneous preferences gives increased stability. Hogg and Huberman show that systems with imperfect information can also be stabilized by al 14 lowing agents to follow different strategies <ref> (Hogg & Huberman 1991) </ref>. The Hogg-Huberman mechanism assumes that the agents switch strategies according to a Poisson distribution (analogous to using a different predictor in the Santa Fe problem).
Reference: <author> Huberman, B. A., and Hogg, T. </author> <year> 1988. </year> <title> The behavior of computational ecologies. </title> <editor> In Huberman, B. A., ed., </editor> <booktitle> The Ecology of Computation. </booktitle> <publisher> North-Holland. </publisher> <pages> 77-115. </pages>
Reference-contexts: A system of agents using only purely random strategies is able to attain a good level of performance. 5 Comparison to other work Huberman and Hogg present an analytical study of the performance of computational ecosystems <ref> (Huberman & Hogg 1988) </ref>. There are a large number of tasks to be performed on a network of interconnected computers. The tasks are managed by agents, which are responsible for choosing among various computational resources to perform the task.
Reference: <author> Kephart, J. O.; Hogg, T.; and Huberman, B. A. </author> <year> 1989. </year> <title> Dynamics of computational ecosystems. </title> <journal> Physical Review A 40 </journal> <pages> 404-421. </pages>
Reference-contexts: The model used by the agents is that the demand on each resource will be the same this week as it was last week the agents optimize their actions based on that prediction and their utility for each resource. Huberman and Hogg, in analysis later experimentally supported by Kephart <ref> (Kephart, Hogg, & Huberman 1989) </ref>, are able to reach some very interesting conclusions. The presence of noise without delay reduces performance because some agents take suboptimal decisions.
Reference: <author> Russell, S. </author> <year> 1995. </year> <booktitle> Ratonality and intelligence. In Proc. 14th International Joint Conference on Artificial Intelligence (IJCAI-95). </booktitle>
Reference-contexts: go; the third week, each agent, assuming the bar will be crowded like last week, decides to stay home; and so we cycle, with everybody attending on odd weeks and nobody attending on even weeks. 1.1 Arthur's Solution to the Santa Fe Problem Arthur proposes a model of bounded rationality <ref> (Russell 1995) </ref> for the people in the Santa Fe problem, and demonstrates that the system converges to a long term equilibrium of 60 people attending the bar. An agent has a set of belief models, and acts on the one that is currently most credible.
Reference: <author> Schaerf, A.; Shoham, Y.; and Tennenholtz, M. </author> <year> 1995. </year> <title> Adaptive load balancing: A study in multi-agent learning. </title> <journal> Journal of Artificial Intelligence Research 2 </journal> <pages> 475-500. </pages> <note> 17 Youssefmir, </note> <author> M., and Huberman, B. </author> <year> 1995. </year> <title> Resource contention in multiagent systems. </title> <booktitle> In (ICMAS-95), </booktitle> <pages> 398-403. 18 </pages>
Reference-contexts: Schaerf et. al. have studied a multiagent multiresource stochastic system, where jobs arrive probabilistically, and an agent must select a resource for each new job <ref> (Schaerf, Shoham, & Tennenholtz 1995) </ref>. <p> In a parallel with Huberman and Hogg's randomization claims, and our mixed-strategy results, Schaerf et. al. note that ...the fact that some agents may have a distorted view of the system ... turns out to be an advantage for the population as a whole <ref> (Schaerf, Shoham, & Tennenholtz 1995) </ref> 6 Future Work The biggest flaw in our experiments is that we generate only one model for each particular set of specifications. <p> It would be interesting to mix agent types, that is have mixed agents and take-the-best agents in the same system, and examine which agent does better, in a similar way to <ref> (Schaerf, Shoham, & Tennenholtz 1995) </ref>. We would like to track the performance of individual agents under various models, to examine the fairness of a solution.
References-found: 7

