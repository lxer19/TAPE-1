URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1090/CS-TR-92-1090.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1090/
Root-URL: http://www.cs.wisc.edu
Email: fmt,naughtong@cs.wisc.edu  
Title: On the Performance of Object Clustering Techniques  
Author: Manolis M. Tsangaris and Jeffrey F. Naughton 
Date: 1090 1992  1992  
Affiliation: Department of Computer Sciences University of Wisconsin-Madison  
Pubnum: Technical Report  May,1  
Abstract: We investigate the performance of some of the best-known object clustering algorithms on four different workloads based upon the Tektronix benchmark. For all four workloads, stochastic clustering gave the best performance for a variety of performance metrics. Since stochastic clustering is computationally expensive, it is interesting that for every workload there was at least one cheaper clustering algorithm that matched or almost matched stochastic clustering. Unfortunately, for each workload, the algorithm that approximated stochastic clustering was different. Our experiments also demonstrated that even when the workload and object graph are fixed, the choice of the clustering algorithm depends upon the goals of the system. For example, if the goal is to perform well on traversals of small portions of the database starting with a cold cache, the important metric is the per-traversal expansion factor, and a well-chosen placement tree will be nearly optimal; if the goal is to achieve a high steady-state performance with a reasonably large cache, the appropriate metric is the number of pages to which the clustering algorithm maps the active portion of the database. For this metric, the PRP clustering algorithm, which only uses access probabilities achieves nearly optimal performance. 0 This work was supported by NSF grant number IRI-9157357, and partially by a NATO Fellowship. A shorter version of this report appears in the proceedings of the International Conference on Management of Data - SIGMOD 1992, San Diego, CA. 
Abstract-found: 1
Intro-found: 1
Reference: [And90] <author> T. Lougenia Anderson et al. </author> <title> The Tektronix HyperModel Benchmark. </title> <address> EDBT, </address> <year> 1990. </year>
Reference-contexts: In this paper we investigate the relative performances of a number of these clustering algorithms on four different workloads based upon the Tektronix <ref> [And90] </ref> benchmark. Our results apply directly to object bases with similar object structure, properties, and usage as in the Tektronix Benchmark. The algorithms we compared were BFS, DFS, and WDFS [Sta84], Placement Trees [BD90], Cactis [DK90], PRP [YW73] and stochastic clustering [TN91]. <p> CLUB-0 uses synthetic workloads based on a subset of the Tektronix Hyper-model 8 Benchmark <ref> [And90] </ref>. The object graph in CLUB-0 is a DAG, derived from a balanced 5-way tree with some additional edges. 2 Figure 2 illustrates the first levels of an actual tree we have used in our simulation. Each node of the tree has edges to 10 other nodes.
Reference: [Bai89] <author> P. Bailey. </author> <title> Performance evaluation in a persistent object system. </title> <booktitle> In Proceedings of the Third International Workshop on Persistent Object Systems, Newcastle, </booktitle> <address> Australia, </address> <month> September </month> <year> 1989. </year>
Reference-contexts: trace. (Recall that saying that the training and testing traces are from the same workload does not imply that they are identical traces, since all of the workloads have a strong random component.) The experiments presented here are for a uniform object sizes of 200 bytes (typical, as reported in <ref> [Bai89] </ref>), and pages of 4k bytes each. 4.1 Performance of single traversals This experiment tests the algorithms with respect only to their EF, i.e. their capability to group all objects requested during a single traversal as dense as possible.
Reference: [BD90] <author> Veronique Benzaken and Claude Delobel. </author> <title> Enhancing performance in a persistent object store: Clustering strategies in O 2 . Technical Report 50-90, </title> <type> Altair, </type> <month> August </month> <year> 1990. </year>
Reference-contexts: Our results apply directly to object bases with similar object structure, properties, and usage as in the Tektronix Benchmark. The algorithms we compared were BFS, DFS, and WDFS [Sta84], Placement Trees <ref> [BD90] </ref>, Cactis [DK90], PRP [YW73] and stochastic clustering [TN91]. Of these algorithms, BFS and DFS depend only on the structure of the object graph, while the other algorithms depend in addition on a information gleaned from a training trace representative of some workload. <p> The input to the simulator is the testing trace and a clustering mapping. Each object reference is converted to the corresponding page reference using the mapping. Then, that page is 12 Algorithm Complexity Proposed OG.DFS O (n) [Sta84] OG.PT O (n) <ref> [BD90] </ref> SG.WDFS O (n) [Sta84] SG.CACTIS O (n log n) [DK90] SMC.PRP O (n log n) [TN91] SMC.WISC O (n log n) here SMC.KL O (n 2:4 ) [TN91] Table 1: Tested clustering algorithms retrieved from a variable size LRU cache, and the number of page hits is updated for each
Reference: [Den68] <author> P. J. Denning. </author> <title> The working set model of program behavior. </title> <journal> Comm. ACM, </journal> <volume> 11(5) </volume> <pages> 323-333, </pages> <month> May </month> <year> 1968. </year>
Reference-contexts: Clustering maps many objects to each page and thus it increases the page locality. On small caches mappings that achieve better locality will perform better. The average working set size can be used to measure locality <ref> [Den68] </ref>, the lower the working set size the higher the locality.
Reference: [Deu91] <editor> O. Deux et al. </editor> <title> The O 2 system. </title> <journal> ACM Communications, </journal> <volume> 34(10) </volume> <pages> 34-49, </pages> <year> 1991. </year>
Reference-contexts: All matched un-clustered objects are inserted to a logical cluster, which is subsequently assigned to physical pages. Although OG.PT is very intuitive, it is not an automatic method. On O 2 the data base administrator selects the placement trees <ref> [Deu91] </ref> based on his system experience. In our implementation, OG.PT refers to the performance of the best placement tree we were able to find for the workload in question.
Reference: [DK90] <author> Pamela Drew and Roger King. </author> <title> The performance and utility of the CACTIS implementation algorithms. </title> <booktitle> In Proceedings of the 16-th VLDB Conference, </booktitle> <pages> pages 135-147, </pages> <address> Brisbane, Australia, </address> <year> 1990. </year>
Reference-contexts: Our results apply directly to object bases with similar object structure, properties, and usage as in the Tektronix Benchmark. The algorithms we compared were BFS, DFS, and WDFS [Sta84], Placement Trees [BD90], Cactis <ref> [DK90] </ref>, PRP [YW73] and stochastic clustering [TN91]. Of these algorithms, BFS and DFS depend only on the structure of the object graph, while the other algorithms depend in addition on a information gleaned from a training trace representative of some workload. <p> OG.BFS, OG.DFS and SG.WDFS have been proposed first in [Sta84] for clustering Smalltalk objects. The SG.CACTIS is based upon the clustering algorithm proposed in [HK89], a heuristic algorithm that performs PRP scan of the objects, clustering the closure of each group as it is formed. Quoting from <ref> [DK90] </ref>, Clustering starts by placing the most frequently referenced object in the database in an empty block. The system then considers all relationships that go from an object inside the block to an object outside of the block. <p> Each object reference is converted to the corresponding page reference using the mapping. Then, that page is 12 Algorithm Complexity Proposed OG.DFS O (n) [Sta84] OG.PT O (n) [BD90] SG.WDFS O (n) [Sta84] SG.CACTIS O (n log n) <ref> [DK90] </ref> SMC.PRP O (n log n) [TN91] SMC.WISC O (n log n) here SMC.KL O (n 2:4 ) [TN91] Table 1: Tested clustering algorithms retrieved from a variable size LRU cache, and the number of page hits is updated for each cache size.
Reference: [HBD91] <author> Gilbert Harrus, Veronique Benzaken, and Claude Delobel. </author> <title> Measuring performance of clustering strategies: the CluB-0 benchmark. </title> <type> Technical Report 66-91, </type> <institution> Altair, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: Finally, the generated clustering mapping is evaluated by running test traces over the object base using a cache simulator. 3.1 The Workload Our experiments were selected from the CLUB-0 clustering benchmark for the O 2 system <ref> [HBD91] </ref>. CLUB-0 uses synthetic workloads based on a subset of the Tektronix Hyper-model 8 Benchmark [And90]. <p> As we will see, there are cases where OG.PT achieves very good performance, mainly when the object graph is regular and is used in a uniform way. 3.3 Cache Simulation and Performance Metrics Each clustering mapping was tested using a client simulator as in [TN91], and <ref> [HBD91] </ref>. The input to the simulator is the testing trace and a clustering mapping. Each object reference is converted to the corresponding page reference using the mapping.
Reference: [HK89] <author> Scott E. Hudson and Roger King. Cactis: </author> <title> A self-adaptive, concurrent implementation of an object-oriented database management system. </title> <journal> ACM Transactions on Data Base Systems, </journal> <volume> 14(3) </volume> <pages> 291-321, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: In our case, SG.WDFS gets its hints from the sample traces. SG.WDFS has linear cost O (n). OG.BFS, OG.DFS and SG.WDFS have been proposed first in [Sta84] for clustering Smalltalk objects. The SG.CACTIS is based upon the clustering algorithm proposed in <ref> [HK89] </ref>, a heuristic algorithm that performs PRP scan of the objects, clustering the closure of each group as it is formed. Quoting from [DK90], Clustering starts by placing the most frequently referenced object in the database in an empty block.
Reference: [KL70] <author> B.W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> Bell System Technical Journal, </journal> <volume> 49(2) </volume> <pages> 291-307, </pages> <month> February </month> <year> 1970. </year>
Reference-contexts: This scheme is also known as Probability Ranking Partitioning. The SMC.PRP algorithm has O (n log n) cost. The SMC.KL algorithm uses the standard Kernighan-Lin <ref> [KL70] </ref> graph partitioning algorithm to find a near to optimal clustering of the SMC graph. SMC.KL is the algorithm we have referred to in the introduction as "Stochastic Clustering." SMC.KL partitions the object graph so that the expected working set for window size 2 is minimized.
Reference: [KSC78] <author> Valentin F. Kolchin, Boris A. Sevast'yanov, and Vladimir P. Chist'yakov. </author> <title> Random Allocations. </title> <publisher> Halsted Press, </publisher> <year> 1978. </year>
Reference: [PS82] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice-Hall Inc, </publisher> <year> 1982. </year>
Reference: [PZ91] <author> Mark Palmer and Stanley B. Zdonik. </author> <title> FIDO: a cache that learns to fetch. </title> <booktitle> In Proceedings of the 17-th VLDB Conference, </booktitle> <address> Barcelona Spain, </address> <year> 1991. </year> <month> 25 </month>
Reference-contexts: Real access patterns however, may be different than the ones used for training. One way real access patterns may be different is that some unexpected 21 references may appear in the actual trace. To study this effect we added white noise to the testing object stream (as in <ref> [PZ91] </ref>). White Noise is a stream of random references chosen with uniform probability from the whole object population. The graph of Figure 10 shows the average number of traversal pages of mn2 as a function of noise level.
Reference: [RC89] <author> J. Richardson and M. Carey. </author> <title> Persistence in the E Language: Issues and Implemen--tation. </title> <journal> Software Practice and Experience, </journal> <volume> 19, </volume> <month> 12 </month> <year> 1989. </year>
Reference-contexts: The traversal trace is obtained by trapping all object accesses occurring during the execution of that traversal, as if the code was running on an object oriented run time system. As a guide, we used the code produced by the non-swizzling E compiler <ref> [RC89] </ref> with all optimizations having to do with persistent objects turned off, so that object references appear every time the original traversal code requires access to the object state. <p> This algorithm attempts to minimize the number of clusters "probable" DFS traversals will touch. Edge probability information can be supplied by the compiler based on static usage information (like in Semantic Clustering [SS90]), or as user hints (like those originally planned for E <ref> [RC89] </ref>). In our case, SG.WDFS gets its hints from the sample traces. SG.WDFS has linear cost O (n). OG.BFS, OG.DFS and SG.WDFS have been proposed first in [Sta84] for clustering Smalltalk objects.
Reference: [SS90] <author> Karen Shannon and Richard Snodgrass. </author> <title> Semantic clustering. </title> <booktitle> In Proceedings of the 4th Int'l Workshop in Persistent Object Systems, </booktitle> <pages> pages 361-374, </pages> <address> Martha's Vineyard, MA, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: This algorithm attempts to minimize the number of clusters "probable" DFS traversals will touch. Edge probability information can be supplied by the compiler based on static usage information (like in Semantic Clustering <ref> [SS90] </ref>), or as user hints (like those originally planned for E [RC89]). In our case, SG.WDFS gets its hints from the sample traces. SG.WDFS has linear cost O (n). OG.BFS, OG.DFS and SG.WDFS have been proposed first in [Sta84] for clustering Smalltalk objects.
Reference: [Sta84] <author> James W. Stamos. </author> <title> Static grouping of small objects to enhance performance of a paged virtual memory. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(2) </volume> <pages> 155-180, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: Our results apply directly to object bases with similar object structure, properties, and usage as in the Tektronix Benchmark. The algorithms we compared were BFS, DFS, and WDFS <ref> [Sta84] </ref>, Placement Trees [BD90], Cactis [DK90], PRP [YW73] and stochastic clustering [TN91]. Of these algorithms, BFS and DFS depend only on the structure of the object graph, while the other algorithms depend in addition on a information gleaned from a training trace representative of some workload. <p> In our case, SG.WDFS gets its hints from the sample traces. SG.WDFS has linear cost O (n). OG.BFS, OG.DFS and SG.WDFS have been proposed first in <ref> [Sta84] </ref> for clustering Smalltalk objects. The SG.CACTIS is based upon the clustering algorithm proposed in [HK89], a heuristic algorithm that performs PRP scan of the objects, clustering the closure of each group as it is formed. <p> The input to the simulator is the testing trace and a clustering mapping. Each object reference is converted to the corresponding page reference using the mapping. Then, that page is 12 Algorithm Complexity Proposed OG.DFS O (n) <ref> [Sta84] </ref> OG.PT O (n) [BD90] SG.WDFS O (n) [Sta84] SG.CACTIS O (n log n) [DK90] SMC.PRP O (n log n) [TN91] SMC.WISC O (n log n) here SMC.KL O (n 2:4 ) [TN91] Table 1: Tested clustering algorithms retrieved from a variable size LRU cache, and the number of page hits <p> The input to the simulator is the testing trace and a clustering mapping. Each object reference is converted to the corresponding page reference using the mapping. Then, that page is 12 Algorithm Complexity Proposed OG.DFS O (n) <ref> [Sta84] </ref> OG.PT O (n) [BD90] SG.WDFS O (n) [Sta84] SG.CACTIS O (n log n) [DK90] SMC.PRP O (n log n) [TN91] SMC.WISC O (n log n) here SMC.KL O (n 2:4 ) [TN91] Table 1: Tested clustering algorithms retrieved from a variable size LRU cache, and the number of page hits is updated for each cache size.
Reference: [TN91] <author> Manolis M. Tsangaris and Jeffrey F. Naughton. </author> <title> A stochastic approach for clustering in object stores. </title> <booktitle> In Proceedings of the SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 12-21, </pages> <address> Denver, Colorado, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Our results apply directly to object bases with similar object structure, properties, and usage as in the Tektronix Benchmark. The algorithms we compared were BFS, DFS, and WDFS [Sta84], Placement Trees [BD90], Cactis [DK90], PRP [YW73] and stochastic clustering <ref> [TN91] </ref>. Of these algorithms, BFS and DFS depend only on the structure of the object graph, while the other algorithms depend in addition on a information gleaned from a training trace representative of some workload. <p> The complexity of "optimal clustering" in general (which has been shown to be NP-complete in <ref> [TN91] </ref>) makes it very hard to find the optimal clustering mapping. However, this formulation gives a new view to the problem, helps to 7 come up with some more reasonable (close to "optimal") clustering algorithms, and also gives a practical limit to how much clustering can help performance. <p> The notation in that table is to generate the name of an algorithm from the type of clustering graph it uses (OG, SG, or SMC) and the style of the graph traversal or operation they perform. The SMC.PRP and SMC.KL algorithms were proposed in <ref> [TN91] </ref>. The PRP (initially proposed for record clustering in [YW73]) method just uses the node weights of the SMC graph (i.e. the absolute probabilities), by sorting objects with respect to their probability and then assigning them to pages in that order. This scheme is also known as Probability Ranking Partitioning. <p> As we will see, there are cases where OG.PT achieves very good performance, mainly when the object graph is regular and is used in a uniform way. 3.3 Cache Simulation and Performance Metrics Each clustering mapping was tested using a client simulator as in <ref> [TN91] </ref>, and [HBD91]. The input to the simulator is the testing trace and a clustering mapping. Each object reference is converted to the corresponding page reference using the mapping. <p> Each object reference is converted to the corresponding page reference using the mapping. Then, that page is 12 Algorithm Complexity Proposed OG.DFS O (n) [Sta84] OG.PT O (n) [BD90] SG.WDFS O (n) [Sta84] SG.CACTIS O (n log n) [DK90] SMC.PRP O (n log n) <ref> [TN91] </ref> SMC.WISC O (n log n) here SMC.KL O (n 2:4 ) [TN91] Table 1: Tested clustering algorithms retrieved from a variable size LRU cache, and the number of page hits is updated for each cache size. <p> Then, that page is 12 Algorithm Complexity Proposed OG.DFS O (n) [Sta84] OG.PT O (n) [BD90] SG.WDFS O (n) [Sta84] SG.CACTIS O (n log n) [DK90] SMC.PRP O (n log n) <ref> [TN91] </ref> SMC.WISC O (n log n) here SMC.KL O (n 2:4 ) [TN91] Table 1: Tested clustering algorithms retrieved from a variable size LRU cache, and the number of page hits is updated for each cache size. Periodically or at the end of the simulation the average cache hit rate is reported.
Reference: [YSLS85] <author> C. T. Yu, Cheing-Mei Suen, K. Lam, and M. K. Siu. </author> <title> Adaptive record clustering. </title> <journal> ACM Transactions on Data Base Systems, </journal> <volume> 10(2) </volume> <pages> 180-204, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: Although it is easy to avoid bad clustering mappings of EF = L, in general it is very hard or impossible to find a clustering mapping of EF = 1 <ref> [YSLS85] </ref>. Although this definition makes sense for records and queries, EF alone is not an adequate metric for clustering. The EF measures the distribution of objects to pages, but does not take into account the order and frequency with which each object is needed.
Reference: [YW73] <author> P.C. Yue and C.K. Wong. </author> <title> On the optimality of the probability ranking scheme in storage applications. </title> <journal> JACM, </journal> <volume> 20(4) </volume> <pages> 624-633, </pages> <month> October </month> <year> 1973. </year> <month> 26 </month>
Reference-contexts: Our results apply directly to object bases with similar object structure, properties, and usage as in the Tektronix Benchmark. The algorithms we compared were BFS, DFS, and WDFS [Sta84], Placement Trees [BD90], Cactis [DK90], PRP <ref> [YW73] </ref> and stochastic clustering [TN91]. Of these algorithms, BFS and DFS depend only on the structure of the object graph, while the other algorithms depend in addition on a information gleaned from a training trace representative of some workload. <p> The SMC.PRP and SMC.KL algorithms were proposed in [TN91]. The PRP (initially proposed for record clustering in <ref> [YW73] </ref>) method just uses the node weights of the SMC graph (i.e. the absolute probabilities), by sorting objects with respect to their probability and then assigning them to pages in that order. This scheme is also known as Probability Ranking Partitioning. The SMC.PRP algorithm has O (n log n) cost.
References-found: 18

