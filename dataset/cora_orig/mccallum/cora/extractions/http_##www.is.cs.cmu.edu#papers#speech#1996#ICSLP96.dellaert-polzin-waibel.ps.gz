URL: http://www.is.cs.cmu.edu/papers/speech/1996/ICSLP96.dellaert-polzin-waibel.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Title: RECOGNIZING EMOTION IN SPEECH  
Author: Frank Dellaert, Thomas Polzin and Alex Waibel 
Address: Pittsburgh, Pennsylvania 15213-3890  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: This paper explores several statistical pattern recognition techniques to classify utterances according to their emotional content. We have recorded a corpus containing emotional speech with over a 1000 utterances from different speakers. We present a new method of extracting prosodic features from speech, based on a smoothing spline approximation of the pitch contour. To make maximal use of the limited amount of training data available, we introduce a novel pattern recognition technique: majority voting of subspace specialists. Using this technique, we obtain classification performance that is close to human performance on the task. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Bates, J. </author> <year> 1994. </year> <title> The Role of Emotion in Believable Agents, </title> <type> Technical Report CMU-CS-94-136, </type> <institution> Carnegie Mellon Univ. </institution>
Reference-contexts: Moreover, in addition to making new applications possible, a working implementation might benefit the understanding of how emotion is encoded in speech. To investigate, we have recorded a corpus containing emotional speech taken from the believable agent domain <ref> [1] </ref>, of over 1000 utterances from several different speakers. 50 short sentences, selected as representative for the domain, were recorded with different emotions. The speakers were shown a sentence and an emotion label on the screen, after which they were asked to speak that particular sentence with that particular emotion.
Reference: 2. <author> Duda, R.O. and P.E. Hart. </author> <year> 1973. </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley and Sons: </publisher> <address> New York. </address>
Reference-contexts: The MLB classifier is a parametric method where it is assumed that the class-conditional probability density function P (x|w) of each class can be adequately described by a multivariate Gaussian centered around a prototype vector. The maximum likelihood estimation of the Gaussians is easily calculated from the training data <ref> [2] </ref>. The class chosen is the one with the maximum posterior probability P (w|x), which can be calculated from P (x|w) using Bayes theorem. As you can see from Table 2, the MLB results are not impressive, due to the fact that the assumption of Gaussian densities is invalid.
Reference: 3. <author> Kursawe, F. </author> <year> 1993. </year> <title> Evolution Strategies - Simple Models of Natural Processes? Revue Intl. </title> <booktitle> de Systmique 7 </booktitle> <pages> 627-642. </pages>
Reference-contexts: As you can see, the performance landscape in this metric space is quite rugged, so classical optimization techniques like gradient descent are likely to fail. One approach we explored to find a good distance metric was population hillclimbing (a variant on Evolutionary Strategies <ref> [3] </ref>). This technique consists of initializing a number of starting points in metric space, generating nearby points according to a Gaussian distribution centered around these points, and then selecting those points from the population with minimum error.
Reference: 4. <author> Littlestone, N. </author> <year> 1988. </year> <title> Learning Quickly When Irrelevant Attributes Abound: A new Linear Threshold Algorithm. </title> <booktitle> Machine Learning 2 </booktitle> <pages> 285-318. </pages>
Reference: 5. <author> Littlestone, N. and M.K. Warmuth. </author> <year> 1994. </year> <title> The Weighed Majority Algorithm. </title> <note> Information and Computation 212-261. </note>
Reference: 6. <author> Scherer, K.R., R. Banse, H.G. Wallbott, and T. Goldbeck. </author> <year> 1991. </year> <title> Vocal cues in Emotion Encoding and Decoding. </title> <booktitle> Motivation and Emotion 15 </booktitle> <pages> 123-148. </pages>
Reference-contexts: In Section 7 we interpret the features selected by these methods as the likely correlates of emotion, and finally Section 8 concludes. 2. FEATURE EXTRACTION In this paper, we used only the pitch information extracted from the utterances for purposes of classification. Several studies <ref> [6] </ref> indicate the importance of summary features of f0, the fundamental pitch signal. Below we discuss two ways to extract features from the pitch signal for use in later pattern recognition algorithms. 2.1.
Reference: 7. <author> Waibel, A. </author> <year> 1986. </year> <title> Prosody and Speech Recognition, </title> <type> Doctoral Thesis, </type> <institution> Carnegie Mellon Univ. </institution>
Reference-contexts: This method can be seen as the logical extension of the smoothing approximation techniques used in <ref> [7] </ref>, where both linear and quadratic models were used. We have measured a total of seventeen features on the newly obtained signals, grouped under the headings below.
Reference: 8. <author> Young, T.Y. and K.-S. Fu, ed. </author> <year> 1986. </year> <title> Handbook of pattern Recognition and Image Processing. </title> <publisher> Academic Press: </publisher> <editor> Orlando. </editor> <title> Method Error (A) Error (B) SC 36% (5) 25% (31) Table 4: Master classifier results, respectively for selective (SC) and cooperative (CC) composition. </title>
Reference-contexts: The method gets its name because it selects the most promising dimensions first, and is very fast because of its simplicity. Forward Selection. Where above dimensions were added in order of how they perform in isolation, forward selection <ref> (Young & Fu 1986) </ref> adds that dimension that performs best in conjunction with the dimensions already selected. Since forward selection has to try out all the new possible combinations, it is computationally more expensive. Results.
References-found: 8

