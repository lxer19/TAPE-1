URL: http://www.cs.utexas.edu/users/plaxton/ps/1990/ibm_rj7347.ps
Refering-URL: http://www.cs.utexas.edu/users/plaxton/html/abc.html
Root-URL: 
Title: Techniques for Shared Key Sorting  
Author: Robert Cypher C. Greg Plaxton 
Note: Supported in part by an NSF graduate fellowship. Supported by DARPA contracts N00014-87-K-825 and N00014-89-J-1988, and an NSERC postdoctoral fellowship.  
Address: 650 Harry Rd. 545 Technology Square San Jose, CA 95120 Cambridge, MA 02139  
Affiliation: IBM Almaden Research Center MIT Lab for Computer Science  
Abstract: This paper presents deterministic algorithms for sorting n records on a p processor hypercube, shu*e-exchange or cube-connected cycles computer when n p. The fastest known deterministic sorting algorithm running on any of these computers for the case n = p is Sharesort, which runs in O(log n(log log n) 2 ) time in the worst case. An important subroutine in Sharesort solves a problem called shared key sorting. This paper presents new techniques for shared key sorting. These techniques yield algorithms for the sorting problem that are faster than all previously known algorithms over a wide range of the ratio n=p. Specifically, the techniques described in this paper yield 1) a relatively simple sorting algorithm that runs in O((n=p) log n(log log n log log(2n=p)) + log 3 n) time, 2) an O((n=p) 3=4 log 3=2 n) time sorting algorithm for the case p n p log 2 p, 3) a nonconstructive O(log n log log n) time sorting algorithm for the case n = p, and 4) an O(log n log log n log fl n) time sorting algorithm for the case n = p which has certain preprocessing requirements. The preprocessing required by the fourth algorithm is the loading of a constant amount of routing information in each processor. This routing information can be calculated in O(log 3 p) time, and it is independent of the sorting problem to be solved, so it can be loaded just once prior to performing any sorts. Finally, we also give an O(log n log log n) time algorithm for sorting n packets on a multi-butterfly with p = n log n processors. All of the above algorithms require only O(n=p + 1) storage at each processor. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alok Aggarwal and Ming-Deh A. Huang. </author> <title> Network complexity of sorting and graph problems and simulating CRCW PRAMS by interconnection networks (preliminary version). </title> <booktitle> In Proc. 3rd Aegean Workshop on Computing, </booktitle> <pages> pages 339-350, </pages> <year> 1988. </year>
Reference-contexts: The problem of sorting on cube-type computers when n &gt; p has been addressed by a number of researchers. Aggarwal and Huang created an algorithm that sorts in O ((n=p) log n (log n= log (n=p)) ff ) time, where ff = (3 log 3)=(log 3 1) 2:419 <ref> [1] </ref>. This was improved by Cypher and Sanz, who created an algorithm called Cubesort that runs in O ((n=p) log 2 n= log (n=p)) time, provided p log (x) p n for some positive integer x (see Section 2.2 for the definition of log (x) p).
Reference: [2] <author> Miklos Ajtai, Janos Komlos, and Endre Szemeredi. </author> <title> An O(n log n) sorting network. </title> <booktitle> In Proc. 15th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 1-9, </pages> <year> 1983. </year>
Reference-contexts: The problem of sorting with message-passing parallel computers has received a great deal of attention. One of the most notable results was obtained by Leighton [8], who used the O (log n) depth 2 sorting network of Ajtai, Komlos and Szemeredi <ref> [2] </ref> to obtain an O (log n) time sorting algorithm for a bounded degree message-passing parallel computer with p = n processors. This result is clearly optimal, as it performs only O (n log n) comparisons.
Reference: [3] <author> Kenneth E. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In Proc. AFIPS Spring Joint Computer Conf., </booktitle> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference-contexts: Unfortunately, no algorithm with an optimal worst case complexity has been created for sorting on cube-type computers with p = n processors. One of the earliest results is Batcher's bitonic sort <ref> [3] </ref>, which runs in O (log 2 n) time on cube-type computers when n = p [18, 16].
Reference: [4] <author> V. E. </author> <title> Benes. Mathematical Theory of Connecting Networks and Telephone Traffic. </title> <publisher> Academic Press, </publisher> <year> 1965. </year>
Reference-contexts: These new algorithms for shared key sorting will in turn yield new algorithms for sorting on cube-type computers that improve upon all previous deterministic solutions to the problem for many values of the ratio n=p. Two of the new algorithms use a well known technique called Benes routing <ref> [4] </ref> to perform the desired permutation of the rows. The first of these algorithms performs a shared key sort in O ((n=p) log n + log n) time, while the second performs a shared key sort in O ((n=p) 3=4 log 3=2 time when p n p log 2 p. <p> Bit-Permute-Complement (BPC) routing performs a permutation of n records where the destination addresses are calculated by permuting and complementing the bits of the source addresses [12]. Broadcasting copies a record from one processor to all n processors [11]. Benes routing is a technique for implementing arbitrary permutations efficiently <ref> [4] </ref>. Benes routing permutes n records by sending each record first to an intermediate destination and then to its final destination given by the permutation. The intermediate destinations are chosen so that the records will not collide with one another.
Reference: [5] <author> Robert Cypher. </author> <title> Efficient Communication in Massively Parallel Computers. </title> <type> PhD thesis, </type> <institution> University of Washington, Dept. of Computer Science, </institution> <month> August </month> <year> 1989. </year> <month> 9 </month>
Reference-contexts: However, it has been shown that this complication can be managed in time proportional to the running time of the shu*e-exchange implementation <ref> [5] </ref>. 3 Benes Shared Key Sorting This section presents two shared key sorting algorithms that are based on Benes routing. Both algorithms use sparse enumeration sorts to find the correct sorted position of each record.
Reference: [6] <author> Robert Cypher and C. Greg Plaxton. </author> <title> Deterministic sorting in nearly logarithmic time on the hypercube and related computers. </title> <booktitle> In Proc. 22nd Annual Symposium on Theory of Computing, </booktitle> <year> 1990. </year> <note> to appear. </note>
Reference-contexts: Recently, Cypher and Plaxton presented an algorithm called Sharesort that runs in O (log n (log log n) 2 ) time on cube-type computers with p = n processors <ref> [6] </ref>. In terms of worst case analysis, this is the first result to improve upon the O (log 2 n) time bitonic sort for cube-type computers with p = n processors. <p> Thus the planning stage can use the excess processors to calculate a plan very efficiently. In the original description of Sharesort, an O ((n=p) log n log log n) time algorithm for shared key sorting was presented <ref> [6] </ref>. The remainder of this paper is devoted to obtaining new solutions to the shared key sorting problem that have improved running times. <p> The algorithms then calculate the intermediate destinations for the Benes route which sends each record from its original position to its sorted position. Finally, this Benes route is implemented to complete the sort. Both algorithms are simpler than the original shared key sorting algorithm <ref> [6] </ref>, and they both provide the fastest known solution to the shared key sorting problem for certain ranges of the the ratio n=p. <p> This algorithm improves upon the running time of BenesSKS () when when 2 v = o (a 2 ), and it improves upon the running time of the original shared key sorting algorithm <ref> [6] </ref> when 2 v = !(a 2 = log 4 a). The idea is to use Cubesort to reduce the problem of sorting the entire set of records into a number of smaller sorting problems. These smaller sorting problems are then solved by performing Benes routes. <p> This time bound for shared key sorting implies a non-constructive O (log n log log n) time bound for sorting <ref> [6] </ref>. The algorithm is termed "nonconstructive" because no efficent (polynomial time) algorithm is known for its construction. In the following, let P (n) denote the set of all n! possible permutations of n objects, and for each n let X (n) denote some fixed set of "advice" strings. <p> The sorting algorithm uses the deterministic routing capability of the multi-butterfly to perform optimal shared key sorting. Otherwise, the structure of the algorithm is essentially the same as that presented in <ref> [6] </ref>.
Reference: [7] <author> A. R. Karlin and E. Upfal. </author> <title> Parallel hashing an efficient implementation of shared memory. </title> <booktitle> In Proc. 18th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 160-168, </pages> <year> 1986. </year>
Reference-contexts: Another significant improvement in randomized routing algorithms has been the reduction in the number of random bits from O (n log n) to O (log 2 n) <ref> [7] </ref>.
Reference: [8] <author> F. T. Leighton. </author> <title> Tight bounds on the complexity of parallel sorting. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(4):344-354, </volume> <month> April </month> <year> 1985. </year>
Reference-contexts: Thus improvements in sorting can lead to improvements in a wide range of other problems. The problem of sorting with message-passing parallel computers has received a great deal of attention. One of the most notable results was obtained by Leighton <ref> [8] </ref>, who used the O (log n) depth 2 sorting network of Ajtai, Komlos and Szemeredi [2] to obtain an O (log n) time sorting algorithm for a bounded degree message-passing parallel computer with p = n processors.
Reference: [9] <author> F. T. Leighton and B. M. Maggs. </author> <title> Expanders might be practical: Fast algorithms for routing around faults on multibutterflies. </title> <booktitle> In Proc. 30th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 384-389, </pages> <year> 1989. </year>
Reference-contexts: The multi-butterfly was studied further by Leighton and Maggs, who simplified some of Upfal's work and also showed that the multi-butterfly possesses a high degree of fault tolerance <ref> [9] </ref>. The shared key sorting techniques described in this paper lead easily to an O (log n log log n) time, O (1) storage sorting algorithm for sorting n= log n records on an n processor multi-butterfly.
Reference: [10] <author> F. T. Leighton, B. M. Maggs, and S. Rao. </author> <title> Universal packet routing algorithms. </title> <booktitle> In Proc. 29th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 256-269, </pages> <year> 1988. </year>
Reference-contexts: For the most recent improvements to randomized routing techniques, and for pointers to previous work in this area, the reader is referred to <ref> [10] </ref>. Another significant improvement in randomized routing algorithms has been the reduction in the number of random bits from O (n log n) to O (log 2 n) [7].
Reference: [11] <author> David Nassimi and Sartaj Sahni. </author> <title> Data broadcasting in SIMD computers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(2):101-107, </volume> <month> February </month> <year> 1981. </year>
Reference-contexts: Specifically, let a cube-type computer of size p denote a hypercube, shu*e-exchange or cube-connected cycles computer with p processors, and let Sort (n; p) be the worst case time required to sort n records on a cube-type computer of size p. Algorithms given by Nassimi and Sahni <ref> [11] </ref> can be used to implement a single operation of a powerful shared memory model (the Priority CRCW PRAM) that has n processors and n words of memory using a cube-type computer of size p in O (Sort (n; p)) time. <p> Bit-Permute-Complement (BPC) routing performs a permutation of n records where the destination addresses are calculated by permuting and complementing the bits of the source addresses [12]. Broadcasting copies a record from one processor to all n processors <ref> [11] </ref>. Benes routing is a technique for implementing arbitrary permutations efficiently [4]. Benes routing permutes n records by sending each record first to an intermediate destination and then to its final destination given by the permutation.
Reference: [12] <author> David Nassimi and Sartaj Sahni. </author> <title> A self-routing Benes network and parallel permutation algorithms. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(5):332-340, </volume> <month> May </month> <year> 1981. </year>
Reference-contexts: Bit-Permute-Complement (BPC) routing performs a permutation of n records where the destination addresses are calculated by permuting and complementing the bits of the source addresses <ref> [12] </ref>. Broadcasting copies a record from one processor to all n processors [11]. Benes routing is a technique for implementing arbitrary permutations efficiently [4]. Benes routing permutes n records by sending each record first to an intermediate destination and then to its final destination given by the permutation.
Reference: [13] <author> David Nassimi and Sartaj Sahni. </author> <title> Parallel algorithms to set up the Benes permutation network. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-31(2):148-154, </volume> <month> February </month> <year> 1982. </year>
Reference-contexts: In particular, Nassimi and Sahni have shown that the intermediate destinations for a Benes route of n records can be calculated in O (log 3 p) time when n p ff for some constant ff, 0 &lt; ff &lt; 1 <ref> [13] </ref>. Sparse enumeration sort is a useful sorting technique for the case when the number of records to be sorted, n, is much smaller than the number of processors available, p [14]. Sparse enumeration sort runs in O (log n log p= log (p=n)) time.
Reference: [14] <author> David Nassimi and Sartaj Sahni. </author> <title> Parallel permutation and sorting algorithms and a new generalized connection network. </title> <journal> Journal of the ACM, </journal> <volume> 29 </volume> <pages> 642-667, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: When n is sufficiently small with respect to p, the fastest known algorithm for sorting on cube-type computers is Nassimi and Sahni's sparse enumeration sort, which runs in O (log n log p= log (p=n)) time <ref> [14] </ref>. The problem of sorting on cube-type computers when n &gt; p has been addressed by a number of researchers. Aggarwal and Huang created an algorithm that sorts in O ((n=p) log n (log n= log (n=p)) ff ) time, where ff = (3 log 3)=(log 3 1) 2:419 [1]. <p> Sparse enumeration sort is a useful sorting technique for the case when the number of records to be sorted, n, is much smaller than the number of processors available, p <ref> [14] </ref>. Sparse enumeration sort runs in O (log n log p= log (p=n)) time. Cubesort is a sorting algorithm that reduces the problem of sorting n records into a number of smaller sorting problems.
Reference: [15] <author> C. Greg Plaxton. </author> <title> Load balancing, selection and sorting on the hypercube. </title> <booktitle> In Proc. ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 64-73, </pages> <year> 1989. </year>
Reference-contexts: A further improvement was given by Plaxton's Smoothsort algorithm <ref> [15] </ref>. If q = log 3=2 p log log p, then Smoothsort runs on a hypercube in O (log (n=p) log 3 p) time when n pq and in O ((n=p) log 3=2 p= log 1=2 (n=pq)) time when n &gt; pq.
Reference: [16] <author> Franco P. Preparata and Jean Vuillemin. </author> <title> The cube-connected cycles: A versatile network for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 24(5) </volume> <pages> 300-309, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: 1 Introduction This paper presents new algorithms for sorting on hypercube, shu*e-exchange [18] and cube-connected cycles <ref> [16] </ref> computers when there are at least as many records to sort as processors available. <p> Unfortunately, no algorithm with an optimal worst case complexity has been created for sorting on cube-type computers with p = n processors. One of the earliest results is Batcher's bitonic sort [3], which runs in O (log 2 n) time on cube-type computers when n = p <ref> [18, 16] </ref>. When n is sufficiently small with respect to p, the fastest known algorithm for sorting on cube-type computers is Nassimi and Sahni's sparse enumeration sort, which runs in O (log n log p= log (p=n)) time [14].
Reference: [17] <author> John H. Reif and Leslie G. Valiant. </author> <title> A logarithmic time sort for linear size networks. </title> <journal> Journal of the ACM, </journal> <volume> 34(1) </volume> <pages> 60-76, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: This result is clearly optimal, as it performs only O (n log n) comparisons. Another breakthrough was provided by the randomized Flashsort algorithm of Reif and Valiant <ref> [17] </ref>, which sorts every possible input permutation with high probability in O (log n) time on a cube-connected cycles with p = n processors. Unfortunately, no algorithm with an optimal worst case complexity has been created for sorting on cube-type computers with p = n processors.
Reference: [18] <author> Harold S. Stone. </author> <title> Parallel processing with the perfect shu*e. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-20(2):153-161, </volume> <month> February </month> <year> 1971. </year>
Reference-contexts: 1 Introduction This paper presents new algorithms for sorting on hypercube, shu*e-exchange <ref> [18] </ref> and cube-connected cycles [16] computers when there are at least as many records to sort as processors available. <p> Unfortunately, no algorithm with an optimal worst case complexity has been created for sorting on cube-type computers with p = n processors. One of the earliest results is Batcher's bitonic sort [3], which runs in O (log 2 n) time on cube-type computers when n = p <ref> [18, 16] </ref>. When n is sufficiently small with respect to p, the fastest known algorithm for sorting on cube-type computers is Nassimi and Sahni's sparse enumeration sort, which runs in O (log n log p= log (p=n)) time [14].
Reference: [19] <author> E. Upfal. </author> <title> An o(log n) deterministic packet routing scheme. </title> <booktitle> In Proceedings of the 21st Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 241-250, </pages> <year> 1989. </year>
Reference-contexts: In order to obtain the given time bound, the calls at any given level of the recursion overlap according to a fairly complex formula. 6 Sorting on the Multi-Butterfly The multi-butterfly family of interconnection networks was defined by Upfal <ref> [19] </ref>, who proved that computers of this sort can deterministically route an arbitrary permutation in O (log n) time. The multi-butterfly was studied further by Leighton and Maggs, who simplified some of Upfal's work and also showed that the multi-butterfly possesses a high degree of fault tolerance [9].
Reference: [20] <author> L. G. Valiant and G. J. Brebner. </author> <title> Universal schemes for parallel communication. </title> <booktitle> In Proceedings of the 13th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 263-277, </pages> <year> 1981. </year>
Reference-contexts: Every permutation in P (n) is covered by at least a 1 1 n fraction of the strings in X (n). The well-known hypercube routing scheme of Valiant and Brebner <ref> [20] </ref> may be viewed as an example of such an algorithm, with X (n) = P (n). The following lemma proves the existence of a small set of strings that together cover every permutation in P (n). <p> These algorithms route every input permutation in O (log n) with high probability. The first such algorithm is due to Valiant and Brebner, and runs on the hypercube using O (log n) storage per processor <ref> [20] </ref>. A succession of papers have led to similar results for the CCC and SE, and have reduced the per processor storage requirement to a constant in each case.
References-found: 20

