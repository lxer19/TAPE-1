URL: http://www.cs.toronto.edu/~herpers/AVBPA-SAVI.ps.gz
Refering-URL: http://www.cs.toronto.edu/~herpers/veroeff2.html
Root-URL: http://www.cs.toronto.edu
Phone: 2  3  
Title: An Active Stereo Vision System for Recognition of Faces and Related Hand Gestures  
Author: R. Herpers G. Verghese L. Chang K. Darcourt K. Derpanis R. F. Enenkel J. Kaufman M. Jenkin E. Milios A. Jepson J. K. Tsotsos 
Address: 6 King's College Road, Toronto, Ontario M5S 3G4  1150 Eglinton Avenue Road, North York, Ontario M3C 1H7  4700 Keele Street, Toronto, Ontario M3J 1P3  
Affiliation: 1 Department of Computer Science, University of Toronto  Centre for Advanced Studies, IBM Canada Ltd.  Department of Computer Science, York University  
Abstract: The system is based on a robotically controlled binocular head, of which both cameras can be controlled independently. A control supervisor is established which evaluates all visual information and controls particular jobs or actions based on recently obtained results. The presented system design and implementation allows the detection, the zoom, and the tracking of the face, as well as the detection and evaluation of the hand gestures, to be performed in real-time. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. T. Freeman and C. D. Weissman, </author> <title> "Television control by hand gestures," </title> <booktitle> Int. Workshop on Autom. </booktitle> <editor> Face- and Gesture-Rec., M. Bichsel (edt.), </editor> <address> Zurich, Switzerland, </address> <pages> pp. 179-183, </pages> <year> 1995. </year>
Reference: [2] <author> J. Cai, A. Goshtasby, and C. Yu, </author> <title> "Detecting human faces in color images," Int. Workshop on MultiMedia Database Management Systems, </title> <note> to be published, </note> <year> 1998. </year>
Reference-contexts: In this contribution, the design and first realized versions of modules of an active vision system for teleconferencing purposes is introduced. Our work is mostly related to the work done in the area of intelligent environments [11, 7], multimodal user interfaces, and advanced multi-media systems <ref> [2, 9] </ref>. But the system presented here differs mainly in the application for which it is developed as well as in the constraints and requirements. The presented Stereo Active Vision Interface (SAVI) integrates a Perception-Action-Cycle (PAC) into the processing of sensory data of different kinds and qualities.
Reference: [3] <author> A. J. Colmenarez and T. Huang, </author> <title> "Maximum likelihood face detection," </title> <booktitle> Second Int. Conf. on Automatic Face and Gesture Recognition, </booktitle> <address> Killington, Vermont, </address> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 307-311, </pages> <year> 1996. </year>
Reference-contexts: A two step classification method is developed, which is able to distinguish between faces and non faces within skin colour blobs. Motivated by the work done in the area of template based face detection (see for instance <ref> [3] </ref>) a fast implementation of a template based method has been realized. A 3-level-colour-quantized face template has been designed consisting of areas in which skin tone (black), not exactly fitting skin tone (gray) and non-skin tone (bright) are assumed (see fig. 2d).
Reference: [4] <author> R. Herpers, H. Kattner, H. Rodax, and G. Sommer, </author> <title> "GAZE: An attentional processing strategy to detect and analyze the prominent facial regions," </title> <booktitle> Int. Workshop on Autom. </booktitle> <editor> Face- and Gesture-Rec., M. Bichsel (edt.), </editor> <address> Zurich, Switzerland, </address> <pages> pp. 214-220, </pages> <year> 1995. </year>
Reference-contexts: By calculating a 3-level face image, the correlation with the template can be computed very efficiently. If the computation shows a high probability for the presence of a face, several facial features such as the eye region are considered in more detail (see for instance <ref> [4, 5] </ref>). During this processing the face is zoomed in and tracked to stabilize the face's image area. The zooming is controlled by the recently computed face size. The zoomed face should cover approximately 20% 30% of the visual field of the attentive camera.
Reference: [5] <author> R. Herpers, M. Michaelis, K.H. Lichtenauer and G. Sommer, </author> <title> "Edge and keypoint detection in facial regions," </title> <booktitle> Second Int. Conf. on Automatic Face and Gesture Recognition, </booktitle> <address> Killington, Vermont, </address> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 212-217, </pages> <year> 1996. </year>
Reference-contexts: By calculating a 3-level face image, the correlation with the template can be computed very efficiently. If the computation shows a high probability for the presence of a face, several facial features such as the eye region are considered in more detail (see for instance <ref> [4, 5] </ref>). During this processing the face is zoomed in and tracked to stabilize the face's image area. The zooming is controlled by the recently computed face size. The zoomed face should cover approximately 20% 30% of the visual field of the attentive camera.
Reference: [6] <author> R. Kjeldsen and J. Kender, </author> <title> "Finding skin in colour images," </title> <booktitle> Second Int. Conf. on Automatic Face and Gesture Recognition, </booktitle> <address> Killington, Vermont, </address> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 312-317, </pages> <year> 1996. </year>
Reference-contexts: The use of the HSV colour space is advantageous because skin colour of different races and under different lighting conditions (see fig. 4 and fig. 5a,b) forms a connected volume in the HSV colour space <ref> [6] </ref>. For efficient real time skin colour blob detection, a radial scan line detection method has been developed. Starting at the center of a particular rectangular image region (region of interest, ROI), it scans radially outward along concentric circles with a particular step width sw (see fig. 4). <p> A 2D-Gaussian function is applied to the colour value distribution for boundary pixels of an already existing skin colour blob. The underlying idea is motivated by the work of Kjeldsen et al. <ref> [6] </ref> who have developed a colour predicate based on a histogram evaluation. The processing, developed here, acts similarly to a conditional dilatation which is only executed if several predefined constraints are fulfilled.
Reference: [7] <author> M. Lucente, G.-J. Zwart, and A. D. George, </author> <title> "Visualization space: A testbed for deviceless multimodal user interfaces" Intelligent Environments Symposium '98, </title> <booktitle> AAAI Spring Symposium Series, </booktitle> <year> 1998. </year>
Reference-contexts: In this contribution, the design and first realized versions of modules of an active vision system for teleconferencing purposes is introduced. Our work is mostly related to the work done in the area of intelligent environments <ref> [11, 7] </ref>, multimodal user interfaces, and advanced multi-media systems [2, 9]. But the system presented here differs mainly in the application for which it is developed as well as in the constraints and requirements.
Reference: [8] <author> E. Milios, M. Jenkin and J. K. Tsotsos, </author> <title> "Design and performance of TRISH, a binocular robot head with torsional eye movements," </title> <journal> Int. J. of Pattern Rec. and Artificial Intelligence, </journal> <volume> Vol. 7(1), </volume> <pages> pp. 51-68, </pages> <year> 1993. </year>
Reference-contexts: a flexible user interface to the SAVI system. 1 For more details concerning current teleconferencing and distance teaching systems in medicine we refer the reader to the web sites: http://www.nlm.nih.gov or http://tie.telemed.org SAVI is based on a robotically controlled binocu-lar head called TRISH-2 which is a new development of TRISH-1 <ref> [8] </ref>. Both cameras can be controlled independently and are fixed on a platform which should be positioned approximately at eye level (at the height of 1.60 meters).
Reference: [9] <author> Y. Raja, S. J. Mckenna, and S. Gong, </author> <title> "Tracking and segmenting people in varying lighting conditions using colour," </title> <booktitle> Third Int. Conf. on Automatic Face and Gesture Recognition, </booktitle> <address> Nara, Japan, </address> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 228-233, </pages> <year> 1998. </year>
Reference-contexts: In this contribution, the design and first realized versions of modules of an active vision system for teleconferencing purposes is introduced. Our work is mostly related to the work done in the area of intelligent environments [11, 7], multimodal user interfaces, and advanced multi-media systems <ref> [2, 9] </ref>. But the system presented here differs mainly in the application for which it is developed as well as in the constraints and requirements. The presented Stereo Active Vision Interface (SAVI) integrates a Perception-Action-Cycle (PAC) into the processing of sensory data of different kinds and qualities.
Reference: [10] <author> J. K. Tsotsos, G. Verghese et al., </author> <title> "PLAYBOT A visually-guided robot for physically disabled children," </title> <journal> Image and Vision Computing, </journal> <volume> Vol. 16, </volume> <pages> pp. 275-292, </pages> <year> 1998. </year>
Reference-contexts: The design of the control supervisor is based on research on a robot system done in the past called PLAYBOT <ref> [10] </ref>. It has to be mentioned that SAVI is still under development. For that reason the vision and control aspects of the system will be discussed in more detail than the audio, transmission, or coding related aspects. The system design presented refers to the functionality of two independently controllable cameras.

References-found: 10

