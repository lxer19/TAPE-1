URL: http://www.cs.bu.edu/techreports/97-020-head-tracking.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Title: Head Tracking via Robust Registration in Texture Map Images  
Phone: 1998.  
Author: Marco La Cascia and John Isidoro and Stan Sclaroff 
Affiliation: Computer Science Department Boston University  
Address: Santa Barbara, CA,  Boston, MA 02215  
Note: BU CS TR97-020. To appear in IEEE Conf. on Computer Vision and Pattern Recognition,  
Abstract: A novel method for 3D head tracking in the presence of large head rotations and facial expression changes is described. Tracking is formulated in terms of color image registration in the texture map of a 3D surface model. Model appearance is recursively updated via image mo-saicking in the texture map as the head orientation varies. The resulting dynamic texture map provides a stabilized view of the face that can be used as input to many existing 2D techniques for face recognition, facial expressions analysis, lip reading, and eye tracking. Parameters are estimated via a robust minimization procedure; this provides robustness to occlusions, wrinkles, shadows, and specular highlights. The system was tested on a variety of sequences taken with low quality, uncalibrated video cameras. Experimental results are reported. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Azarbayejani, T. Starner, B. Horowitz, and A. Pentland. </author> <title> Visually controlled graphics. </title> <journal> PAMI, </journal> <volume> 15(6), </volume> <year> 1993. </year>
Reference-contexts: Some methods for recovering 3D head parameters are based on tracking of salient points, features, or 2D image patches. The outputs of these 2D trackers can be processed by an extended Kalman filter to recover 3D structure, focal length and facial pose <ref> [1] </ref>. In [12], a statistically-based 3D head model (eigen-head) is used to further constrain the estimated 3D structure. Another point-based technique for 3D tracking is based on the tracking of five salient points on the face to estimate the head orientation with respect to the camera plane [11]. <p> The latter coordinate system (s; t) will be also referred to as the texture plane as this is the texture map of the model. The (u; v) image coordinate system is defined over the range <ref> [1; 1] </ref> fi [1; 1] and the texture plane (s; t) is defined over the unit square. The mapping between (s; t) and (u; v) can be expressed as follows. <p> The latter coordinate system (s; t) will be also referred to as the texture plane as this is the texture map of the model. The (u; v) image coordinate system is defined over the range <ref> [1; 1] </ref> fi [1; 1] and the texture plane (s; t) is defined over the unit square. The mapping between (s; t) and (u; v) can be expressed as follows. First, assume a parametric surface equation: (x; y; z; 1) = x (s; t); (1) where 3D surface points are in homogeneous coordinates.
Reference: [2] <author> S. Basu, I. Essa, and A. Pentland. </author> <title> Motion regularization for model-based head tracking. </title> <address> ICPR, </address> <year> 1996. </year>
Reference-contexts: Another point-based technique for 3D tracking is based on the tracking of five salient points on the face to estimate the head orientation with respect to the camera plane [11]. Others use optic flow coupled to a 3D surface model. In <ref> [2] </ref>, rigid body motion parameters of an ellipsoid model are estimated from a flow field using a standard minimization algorithm. In other approaches [6] flow is used to constrain the motion of an anatomically-motivated face model and integrated with edge forces to improve the results.
Reference: [3] <author> M. Black and P. Anandan. </author> <title> The robust estimation of multiple motions: Affine and piecewise-smooth flow fields. </title> <journal> TR P93-00104, </journal> <note> Xerox PARC, </note> <year> 1993. </year>
Reference-contexts: Using the Lorentzian is equivalent to the incorporation of an analog outlier process in our objective function <ref> [3] </ref>. The provides in better robustness to specular highlights and occlusions. For efficiency, the log function can be implemented via table look-up. As previously noted, the reference and the transformed video images have an associated confidence map.
Reference: [4] <author> M.J. Black and Y. Yacoob. </author> <title> Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motions. </title> <address> ICCV, </address> <year> 1995. </year>
Reference-contexts: In [18], deformable contour models were used to track the non-rigid facial motion while estimating muscle actuator controls. In [7], a control theoretic approach was employed, based on normalized correlation between the incoming data and templates. Finally, global head motion can be tracked using a plane under perspective projection <ref> [4] </ref>. Recovered global planar motion is used to stabilize incoming images. Facial expression recognition is accomplished by tracking deforming image patches in the stabilized images. <p> The resulting mosaic could be useful in 2D face recognition applications. 6 Nonrigid Tracking in the Texture Map Given the stabilized view provided in the dynamic texture map, we can track nonrigid deformation of the face. Our approach takes its inspiration from <ref> [4] </ref>: nonrigid facial motions are modeled using local parametric models of image motion in the texture map. Our approach confines nonrigid motion to lie on a curved surface, rather than in a flat plane. This enables view independent modeling of nonrigid motion of the face. <p> A parametric warping function controls local nonrigid deformation of the texture map: I = W (I; a) (17) where a is a vector containing warping parameters, and I is the resulting warped image. For purposes of tracking facial features, the warping functions can be quadratic polynomials <ref> [4] </ref>, or nonrigid modes [16].
Reference: [5] <author> J.L. Crowley and F. Berard. </author> <title> Multi-modal tracking of faces for video communications. </title> <address> CVPR, </address> <year> 1997. </year>
Reference-contexts: Unrestricted head motion is critical if these systems are to be non-intrusive and general. 1.1 Related Work Several techniques have been proposed for free head motion and face tracking. Some of these techniques focus on 2D tracking (e.g., <ref> [5, 8, 10, 14, 19, 20] </ref>), while others focus on 3D tracking or stabilization. Some methods for recovering 3D head parameters are based on tracking of salient points, features, or 2D image patches.
Reference: [6] <author> D. DeCarlo and D. Metaxas. </author> <title> The integration of optical flow and deformable models with applications to human face shape and motion estimation. </title> <address> CVPR, </address> <year> 1996. </year>
Reference-contexts: Others use optic flow coupled to a 3D surface model. In [2], rigid body motion parameters of an ellipsoid model are estimated from a flow field using a standard minimization algorithm. In other approaches <ref> [6] </ref> flow is used to constrain the motion of an anatomically-motivated face model and integrated with edge forces to improve the results. In [13], a render-feedback loop was used to guide tracking for an image coding application.
Reference: [7] <author> I.A. Essa and A.P. Pentland. </author> <title> Coding analysis, interpretation, and recognition of facial expressions. </title> <journal> PAMI, </journal> <volume> 19(7):757 763, </volume> <year> 1997. </year>
Reference-contexts: Still others employ more complex physically-based models for the face that include both skin and muscle dynamics for facial motion. In [18], deformable contour models were used to track the non-rigid facial motion while estimating muscle actuator controls. In <ref> [7] </ref>, a control theoretic approach was employed, based on normalized correlation between the incoming data and templates. Finally, global head motion can be tracked using a plane under perspective projection [4]. Recovered global planar motion is used to stabilize incoming images. <p> In any case, a strategy to combat the accumulation error is needed. In all tests the initial positioning of the model was done by hand. In the future, we plan to use one of the methods presented in literature to automate this step <ref> [7] </ref>.
Reference: [8] <author> P. Fieguth and D. Terzopoulos. </author> <title> Color based tracking of heads and other mobile objects at video frame rates. </title> <address> CVPR, </address> <year> 1997. </year>
Reference-contexts: Unrestricted head motion is critical if these systems are to be non-intrusive and general. 1.1 Related Work Several techniques have been proposed for free head motion and face tracking. Some of these techniques focus on 2D tracking (e.g., <ref> [5, 8, 10, 14, 19, 20] </ref>), while others focus on 3D tracking or stabilization. Some methods for recovering 3D head parameters are based on tracking of salient points, features, or 2D image patches.
Reference: [9] <author> M. Gleicher. </author> <title> Projective registration with difference decomposition. </title> <address> CVPR, </address> <year> 1997. </year>
Reference-contexts: To solve the registration problem, we minimize Eq. 10. Three nonlinear minimization approaches have been tested in our system: Powell line minimization [15], Marquardt-Levenberg [15, 17], and the difference decomposition <ref> [9] </ref>. Powell and Marquardt-Levenberg procedures were taken directly from [15], and will not be repeated here.
Reference: [10] <author> G.D. Hager and P.N. Belhumeur. </author> <title> Real-time tracking of image regions with chenges in geometry and illumination. </title> <address> CVPR, </address> <year> 1996. </year>
Reference-contexts: Unrestricted head motion is critical if these systems are to be non-intrusive and general. 1.1 Related Work Several techniques have been proposed for free head motion and face tracking. Some of these techniques focus on 2D tracking (e.g., <ref> [5, 8, 10, 14, 19, 20] </ref>), while others focus on 3D tracking or stabilization. Some methods for recovering 3D head parameters are based on tracking of salient points, features, or 2D image patches.
Reference: [11] <author> T. Horprasert, Y. Yacoob, and L.S. Davis. </author> <title> Computing 3D head orientation from a monocular image sequence. </title> <booktitle> Int. Conf. on Face and Gesture Recognition, </booktitle> <year> 1996. </year>
Reference-contexts: In [12], a statistically-based 3D head model (eigen-head) is used to further constrain the estimated 3D structure. Another point-based technique for 3D tracking is based on the tracking of five salient points on the face to estimate the head orientation with respect to the camera plane <ref> [11] </ref>. Others use optic flow coupled to a 3D surface model. In [2], rigid body motion parameters of an ellipsoid model are estimated from a flow field using a standard minimization algorithm.
Reference: [12] <author> T.S. Jebara and A. Pentland. </author> <title> Prametrized structure from motion for 3D adaptative feedback tracking of faces. </title> <address> CVPR, </address> <year> 1997. </year>
Reference-contexts: Some methods for recovering 3D head parameters are based on tracking of salient points, features, or 2D image patches. The outputs of these 2D trackers can be processed by an extended Kalman filter to recover 3D structure, focal length and facial pose [1]. In <ref> [12] </ref>, a statistically-based 3D head model (eigen-head) is used to further constrain the estimated 3D structure. Another point-based technique for 3D tracking is based on the tracking of five salient points on the face to estimate the head orientation with respect to the camera plane [11].
Reference: [13] <author> H. Li, P. Rovainen, and R. Forcheimer. </author> <title> 3D motion estimation in model-based facial image coding. </title> <journal> PAMI, </journal> <volume> 15(6), </volume> <year> 1993. </year>
Reference-contexts: In [2], rigid body motion parameters of an ellipsoid model are estimated from a flow field using a standard minimization algorithm. In other approaches [6] flow is used to constrain the motion of an anatomically-motivated face model and integrated with edge forces to improve the results. In <ref> [13] </ref>, a render-feedback loop was used to guide tracking for an image coding application. Still others employ more complex physically-based models for the face that include both skin and muscle dynamics for facial motion.
Reference: [14] <author> N. Olivier, A. Pentland, and F. Berard. Lafter: </author> <title> Lips and face real time tracker. </title> <address> CVPR, </address> <year> 1997. </year>
Reference-contexts: Unrestricted head motion is critical if these systems are to be non-intrusive and general. 1.1 Related Work Several techniques have been proposed for free head motion and face tracking. Some of these techniques focus on 2D tracking (e.g., <ref> [5, 8, 10, 14, 19, 20] </ref>), while others focus on 3D tracking or stabilization. Some methods for recovering 3D head parameters are based on tracking of salient points, features, or 2D image patches.
Reference: [15] <author> W. Press, B. Flannery, S. Teukolsky, and W. Vetterling. </author> <title> Numerical Recipes in C. </title> <publisher> Cambridge University Press, </publisher> <address> Cam-bridge, UK, </address> <year> 1988. </year>
Reference-contexts: To solve the registration problem, we minimize Eq. 10. Three nonlinear minimization approaches have been tested in our system: Powell line minimization <ref> [15] </ref>, Marquardt-Levenberg [15, 17], and the difference decomposition [9]. Powell and Marquardt-Levenberg procedures were taken directly from [15], and will not be repeated here. <p> To solve the registration problem, we minimize Eq. 10. Three nonlinear minimization approaches have been tested in our system: Powell line minimization [15], Marquardt-Levenberg <ref> [15, 17] </ref>, and the difference decomposition [9]. Powell and Marquardt-Levenberg procedures were taken directly from [15], and will not be repeated here. <p> To solve the registration problem, we minimize Eq. 10. Three nonlinear minimization approaches have been tested in our system: Powell line minimization <ref> [15] </ref>, Marquardt-Levenberg [15, 17], and the difference decomposition [9]. Powell and Marquardt-Levenberg procedures were taken directly from [15], and will not be repeated here.
Reference: [16] <author> S. Sclaroff and J. Isidoro. Active blobs. ICCV, </author> <year> 1998. </year>
Reference-contexts: In other words, difference basis images are obtained by slightly changing one of the transformation parameters, leaving the other parameters unaltered, to obtain a difference template for that parameter. Each resultant difference image becomes a column in a difference decomposition basis matrix B as described in <ref> [16] </ref>. In practice, four basis vectors per model parameter are sufficient. For the k th parameter, these four basis images correspond with the difference patterns that result by changing that parameter by ffi k and 2ffi k . <p> For purposes of tracking facial features, the warping functions can be quadratic polynomials [4], or nonrigid modes <ref> [16] </ref>. <p> In our implementation, facial deformations are modeled with image templates, using the active blobs formulation <ref> [16] </ref>. Each blob consists of a 2D triangular mesh with a color texture map applied, and deformation is parameterized in terms of each blob's low-order, nonrigid modes. <p> During tracking, the rigid 3D model parameters are computed first, followed by estimation of the 2D blob deformation parameters using robust error minimization procedure in Sec. 4. Due to space limitations, readers are directed to <ref> [16] </ref> for details about the blob formulation. 7 Experimental Results The system was implemented using the cylindrical model of Eq. 4. Experiments were conducted on an SGI O2 R5K workstation, using both the Powell and difference decomposition minimization techniques.
Reference: [17] <author> R. Szeliski. </author> <title> Image mosaicing for tele-reality applications. </title> <type> CRL-TR 94/2, </type> <institution> DEC Cambridge Research Lab, </institution> <year> 1994. </year>
Reference-contexts: To solve the registration problem, we minimize Eq. 10. Three nonlinear minimization approaches have been tested in our system: Powell line minimization [15], Marquardt-Levenberg <ref> [15, 17] </ref>, and the difference decomposition [9]. Powell and Marquardt-Levenberg procedures were taken directly from [15], and will not be repeated here.
Reference: [18] <author> D. Terzopoulos and K. Waters. </author> <title> Analysis and synthesis of facial image sequences using physical and anatomical models. </title> <journal> PAMI, </journal> <volume> 15(6):569579, </volume> <year> 1993. </year>
Reference-contexts: In [13], a render-feedback loop was used to guide tracking for an image coding application. Still others employ more complex physically-based models for the face that include both skin and muscle dynamics for facial motion. In <ref> [18] </ref>, deformable contour models were used to track the non-rigid facial motion while estimating muscle actuator controls. In [7], a control theoretic approach was employed, based on normalized correlation between the incoming data and templates. Finally, global head motion can be tracked using a plane under perspective projection [4].
Reference: [19] <author> Y. Yacoob and L.S. Davis. </author> <title> Computing spatio-temporal representations of human faces. </title> <journal> PAMI, </journal> <volume> 18(6):636642, </volume> <year> 1996. </year>
Reference-contexts: Unrestricted head motion is critical if these systems are to be non-intrusive and general. 1.1 Related Work Several techniques have been proposed for free head motion and face tracking. Some of these techniques focus on 2D tracking (e.g., <ref> [5, 8, 10, 14, 19, 20] </ref>), while others focus on 3D tracking or stabilization. Some methods for recovering 3D head parameters are based on tracking of salient points, features, or 2D image patches.
Reference: [20] <author> A.L. Yuille, D.S. Cohen, and P.W. Hallinan. </author> <title> Feature extraction from faces using deformable templates. </title> <journal> IJCV, </journal> <volume> 8:104 109, </volume> <year> 1992. </year>
Reference-contexts: Unrestricted head motion is critical if these systems are to be non-intrusive and general. 1.1 Related Work Several techniques have been proposed for free head motion and face tracking. Some of these techniques focus on 2D tracking (e.g., <ref> [5, 8, 10, 14, 19, 20] </ref>), while others focus on 3D tracking or stabilization. Some methods for recovering 3D head parameters are based on tracking of salient points, features, or 2D image patches.
References-found: 20

