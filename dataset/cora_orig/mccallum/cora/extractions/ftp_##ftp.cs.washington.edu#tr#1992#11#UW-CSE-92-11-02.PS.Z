URL: ftp://ftp.cs.washington.edu/tr/1992/11/UW-CSE-92-11-02.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: Improving Cache Performance by Eliminating Transfers of Dead Data  
Author: Edward W. Felten Eric J. Koldinger Raj Vaswani John Zahorjan 
Date: March 13, 1992  
Address: Seattle, WA 98195 U.S.A.  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract-found: 0
Intro-found: 0
Reference: [Berry et al. 89] <author> M. Berry, D. Chen, D. Kuck, S. Lo, Y. Pang, L. Pointer, R. Roloff, A. Samah, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orszag, F. Seidl, O. Johnson, R. Goodrum, and J. Martin. </author> <title> The Perfect Club benchmarks: Effective performance evaluation of supercomputers. </title> <journal> Intl. Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <year> 1989. </year>
Reference-contexts: Our benchmarks included some of the Livermore Loops [McMahon 72], and members of the SPEC [SPE 89] and Perfect Club <ref> [Berry et al. 89] </ref> suites. The SPEC programs are intended to model a general-purpose workload, while Perfect Club programs are typical of scientific computations. Livermore Loops are small programs that model the inner loops of scientific programs.
Reference: [Gupta et al. 91] <author> A. Gupta, J. Hennessy, K. Gharachorloo, T. Mowry, and W.-D. Weber. </author> <title> Comparative evaluation of latency reducing and tolerating techniques. </title> <booktitle> In 18th Intl. Symposium on Computer Architecture, </booktitle> <pages> pages 254-263, </pages> <year> 1991. </year>
Reference-contexts: Scholarship and a Mercury Seven Fellowship. 1 in reducing the effects of memory latency, but as latency continues to grow, naive caching is no longer sufficient to meet the performance demands of applications. A great deal of research effort has gone into the study of alternative caching techniques <ref> [Jouppi 90, McFarling 92, Gupta et al. 91] </ref>. Traditional main memory caches provide fetch and writeback semantics that are based on memory locations, rather than on the data that those locations contain.
Reference: [Hew 90] <author> Hewlett-Packard Co. </author> <title> PA-RISC 1.1 Architecture and Instruction Set Reference Manual, </title> <booktitle> first edition, </booktitle> <month> Nov. </month> <year> 1990. </year>
Reference-contexts: In principle, any level in the cache hierarchy could take advantage of these instructions. We now discuss the consequences of the instructions just described on both uniprocessor and multiprocessor architectures. Cache control instructions exist in some current architectures, such as the Hewlett-Packard PA-RISC <ref> [Hew 90] </ref>. Accordingly, we first contrast the PA-RISC's cache control instructions with the abstract instructions defined above. We then consider multiprocessor issues. 2.1 Comparison with PA-RISC The PA-RISC's "cache hint" is similar to our store&zero instruction.
Reference: [Jouppi 90] <author> N. P. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In 17th Intl. Symposium on Computer Architecture, </booktitle> <pages> pages 364-373, </pages> <year> 1990. </year>
Reference-contexts: Scholarship and a Mercury Seven Fellowship. 1 in reducing the effects of memory latency, but as latency continues to grow, naive caching is no longer sufficient to meet the performance demands of applications. A great deal of research effort has gone into the study of alternative caching techniques <ref> [Jouppi 90, McFarling 92, Gupta et al. 91] </ref>. Traditional main memory caches provide fetch and writeback semantics that are based on memory locations, rather than on the data that those locations contain.
Reference: [Kane & Heinrich 92] <author> G. Kane and J. Heinrich. </author> <title> MIPS RISC Architecture. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1992. </year> <title> 15 as a function of miss penalty, averaged over the Perfect Club benchmark suite. </title>
Reference-contexts: Since unrolled loops are a prerequisite to inserting cache control instructions, we also unrolled some loops by hand 2 . We used the pixie tool [MIPS Computer Systems 86] to generate data-reference traces for the benchmark programs on a MIPS R3000 <ref> [Kane & Heinrich 92] </ref> based workstation. The traces were fed to a cache simulator that simulates a direct-mapped, virtually-addressed data cache with variable cache size and line size.
Reference: [McFarling 92] <author> S. McFarling. </author> <title> Cache replacement with dynamic exclusion. </title> <type> Technical Report TN-22, </type> <institution> DEC WRL, </institution> <year> 1992. </year> <booktitle> To appear in Proceedings of 19th Intl. Symposium on Computer Architecture. </booktitle>
Reference-contexts: Scholarship and a Mercury Seven Fellowship. 1 in reducing the effects of memory latency, but as latency continues to grow, naive caching is no longer sufficient to meet the performance demands of applications. A great deal of research effort has gone into the study of alternative caching techniques <ref> [Jouppi 90, McFarling 92, Gupta et al. 91] </ref>. Traditional main memory caches provide fetch and writeback semantics that are based on memory locations, rather than on the data that those locations contain.
Reference: [McMahon 72] <author> F. McMahon. </author> <title> FORTRAN CPU performance analysis. </title> <type> Technical report, </type> <institution> Lawrence Livermore National Laboratories, </institution> <year> 1972. </year>
Reference-contexts: These instructions would be inserted into the storage allocation system by hand. 4 Experimental Procedure We used trace-driven simulation to measure the effect of using cache control instructions on the performance of a set of benchmark programs. Our benchmarks included some of the Livermore Loops <ref> [McMahon 72] </ref>, and members of the SPEC [SPE 89] and Perfect Club [Berry et al. 89] suites. The SPEC programs are intended to model a general-purpose workload, while Perfect Club programs are typical of scientific computations. Livermore Loops are small programs that model the inner loops of scientific programs.
Reference: [MIPS Computer Systems 86] <author> I. </author> <title> MIPS Computer Systems. Languages and Programmer's Manual, </title> <year> 1986. </year>
Reference-contexts: The programs were linked to a library containing special hand-written bzero and bcopy procedures. Cache control instructions were inserted into loops by hand. Since unrolled loops are a prerequisite to inserting cache control instructions, we also unrolled some loops by hand 2 . We used the pixie tool <ref> [MIPS Computer Systems 86] </ref> to generate data-reference traces for the benchmark programs on a MIPS R3000 [Kane & Heinrich 92] based workstation. The traces were fed to a cache simulator that simulates a direct-mapped, virtually-addressed data cache with variable cache size and line size.
Reference: [SPE 89] <institution> System Performance Evaluation Cooperative. SPEC Benchmark Suite Release 1.0, </institution> <year> 1989. </year>
Reference-contexts: Our benchmarks included some of the Livermore Loops [McMahon 72], and members of the SPEC <ref> [SPE 89] </ref> and Perfect Club [Berry et al. 89] suites. The SPEC programs are intended to model a general-purpose workload, while Perfect Club programs are typical of scientific computations. Livermore Loops are small programs that model the inner loops of scientific programs.
Reference: [Wilkes 92] <author> J. Wilkes. </author> <type> Personal communication, </type> <year> 1992. </year>
Reference-contexts: Detailed simulations of some of our benchmarks confirmed our assumption that write-buffer stalls are extremely rare. (Raw data concerning the number of writebacks saved by clean instructions are given in Appendix B.) Current implementations of the PA-RISC (in the HP9000/s700 and HP9000/s8x7 systems) do not use the cache hint <ref> [Wilkes 92] </ref>; we do not know whether the current PA-RISC compilers and assemblers generate the hint, or whether they use the purge instruction.
Reference: [Wittenbrink et al. 92] <author> C. Wittenbrink, A. Somani, and C. Chen. </author> <title> Cache write generate for high performance parallel processing. </title> <note> Submitted for publication, 1992. 16 </note>
Reference-contexts: We also evaluate the effect of cache control instructions on the performance of kernel primitives. Finally, we use our data to extrapolate these effects to future architectures. Wittenbrink et al. have proposed a similar idea <ref> [Wittenbrink et al. 92] </ref>, but their implementation, based on special page-table bits, is considerably more expensive than the one described below, and their experiments used a smaller and more specialized benchmark suite than ours. 2 Instructions to Eliminate Dead Data Accesses We envision two instructions to control the cache treatment of
References-found: 11

