URL: http://www.ai.sri.com/~luong/research/publications/RR-1894.ps.Z
Refering-URL: http://www.ai.sri.com/~luong/research/publications/publications.html
Root-URL: 
Title: N ffi 1894 Programme 4 Robotique, Image et Vision ON DETERMINING THE FUNDAMENTAL MATRIX: ANALYSIS
Note: Theo Papadopoulo Avril 1993  
Address: 2004 route des Lucioles B.P. 93 06902 Sophia-Antipolis France  
Affiliation: UNIT E DE RECHERCHE INRIA-SOPHIA ANTIPOLIS Institut National de Recherche en Informatique et en Automatique  Rapports de Recherche  
Abstract: EXPERIMENTAL RESULTS Quang-Tuan Luong Rachid Deriche Olivier Faugeras 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. L. Bookstein. </author> <title> Fitting conic sections to scattered data. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 9(1) </volume> <pages> 56-71, </pages> <month> Jan </month> <year> 1979. </year>
Reference-contexts: The linear criterion can be considered as a generalization of the Bookstein distance <ref> [1] </ref> for conic fitting. The straightforward idea is to approximate the true distance of the point x to the surface by the number g (x; f ), in order to get a closed-form solution. A more precise approximation has been introduced by Sampson [19].
Reference: [2] <author> J.Q. Fang and T.S. Huang. </author> <title> Some experiments on estimating the 3D motion parameters of a rigid body from two consecutive image frames. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 545-554, </pages> <year> 1984. </year>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [13] and has been extensively studied in the literature [12] [22] <ref> [2] </ref> [23] [11], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation.
Reference: [3] <author> O.D. Faugeras. </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 563-578, </pages> <year> 1992. </year>
Reference-contexts: However, it is not always possible to assume that cameras can be calibrated off-line, particularly when using active vision systems. Thus a second approach is emerging, which consists in using projective invariants [16], whose non-metric nature allows to use uncalibrated cameras. Recent work [8] <ref> [3] </ref> [15] [6] has shown that it is possible to recover the projective structure of a scene from point correspondences only, without the need for camera calibration. It is even possible to use these projective invariants to compute the camera calibration [4] [14].
Reference: [4] <author> O.D. Faugeras, Q.-T. Luong, and S.J. Maybank. </author> <title> Camera self-calibration: theory and experiments. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 321-334, </pages> <year> 1992. </year>
Reference-contexts: Recent work [8] [3] [15] [6] has shown that it is possible to recover the projective structure of a scene from point correspondences only, without the need for camera calibration. It is even possible to use these projective invariants to compute the camera calibration <ref> [4] </ref> [14]. These approaches use only geometric information which relates the different viewpoints. This information is entirely contained in the Fundamental matrix, thus it is very important to develop precise techniques to compute it. <p> It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. Some recent work has indeed pointed out that it is also relevant for the purpose of working from uncalibrated cameras [18], <ref> [4] </ref> [6].
Reference: [5] <author> O.D. Faugeras and G. Toscani. </author> <title> The calibration problem for stereo. </title> <booktitle> In Proceedings of CVPR'86, </booktitle> <pages> pages 15-20, </pages> <year> 1986. </year>
Reference-contexts: This is done by camera calibration [21] <ref> [5] </ref>, which typically computes the projection matrices P, which relates the image coordinates to a world reference frame. However, it is not always possible to assume that cameras can be calibrated off-line, particularly when using active vision systems.
Reference: [6] <author> R.I. </author> <title> Hartley. Estimation of relative camera positions for uncalibrated cameras. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 579-587, </pages> <year> 1992. </year> <month> 24 </month>
Reference-contexts: However, it is not always possible to assume that cameras can be calibrated off-line, particularly when using active vision systems. Thus a second approach is emerging, which consists in using projective invariants [16], whose non-metric nature allows to use uncalibrated cameras. Recent work [8] [3] [15] <ref> [6] </ref> has shown that it is possible to recover the projective structure of a scene from point correspondences only, without the need for camera calibration. It is even possible to use these projective invariants to compute the camera calibration [4] [14]. <p> Another approach is to use linear filters tuned to a range of orientations and scales. Jones and Malik [9] have shown that it is also possible in this framework to recover the location of epipolar lines. The computation technique used by most of the authors <ref> [6] </ref> [18] [20] is just a linear one, which generalizes the eight-point algorithm of Longuet-Higgins [13]. After a first part where we clarify the concept of Fundamental matrix, we show that this computation technique suffers from two majors intrinsic drawbacks. <p> It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. Some recent work has indeed pointed out that it is also relevant for the purpose of working from uncalibrated cameras [18], [4] <ref> [6] </ref>.
Reference: [7] <author> T.S. Huang and O.D. Faugeras. </author> <title> Some properties of the E-matrix in two view motion estimation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11 </volume> <pages> 1310-1312, </pages> <year> 1989. </year>
Reference-contexts: l 0 q by definition, it follows that q It can be seen that the two equations (2) and (3) are equivalent, and that we have the relation: F = A 1T EA 1 Unlike the essential matrix, which is characterized by the two constraints found by Huang and Faugeras <ref> [7] </ref> which are the nullity of the determinant and the equality of the two non-zero singular values, the only property of the fundamental matrix is that it is of rank two.
Reference: [8] <author> Koenderink J. J. and A. J. van Doorn. </author> <title> Affine Structure from Motion. </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 8(2) </volume> <pages> 377-385, </pages> <year> 1992. </year>
Reference-contexts: However, it is not always possible to assume that cameras can be calibrated off-line, particularly when using active vision systems. Thus a second approach is emerging, which consists in using projective invariants [16], whose non-metric nature allows to use uncalibrated cameras. Recent work <ref> [8] </ref> [3] [15] [6] has shown that it is possible to recover the projective structure of a scene from point correspondences only, without the need for camera calibration. It is even possible to use these projective invariants to compute the camera calibration [4] [14].
Reference: [9] <author> D.G. Jones and J. Malik. </author> <title> A Computational Framework for Determining Stereo Correspondence from a Set of Linear Spatial Filters. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 395-410, </pages> <year> 1992. </year>
Reference-contexts: Line correspondences are not sufficient with two views. Another approach is to use linear filters tuned to a range of orientations and scales. Jones and Malik <ref> [9] </ref> have shown that it is also possible in this framework to recover the location of epipolar lines. The computation technique used by most of the authors [6] [18] [20] is just a linear one, which generalizes the eight-point algorithm of Longuet-Higgins [13].
Reference: [10] <author> K. Kanatani. </author> <title> Computational projective geometry. Computer Vision, Graphics, </title> <booktitle> and Image Processing. Image Understanding, </booktitle> <volume> 54(3), </volume> <year> 1991. </year>
Reference-contexts: The advantage of this second approach is that all the coefficients of F play the same role. We have also tried to normalize the projective coordinates to use the Kanatani N-vectors representation <ref> [10] </ref> (DIAG-N). The advantage of the linear criterion is that it leads to a non-iterative computation method, however, we have found that it is quite sensitive to noise, even with numerous data points.
Reference: [11] <author> C.H. Lee. </author> <title> Time-varying images: the effect of finite resolution on uniqueness. Computer Vision, Graphics, </title> <booktitle> and Image Processing. Image Understanding, </booktitle> <volume> 54(3) </volume> <pages> 325-332, </pages> <year> 1991. </year>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [13] and has been extensively studied in the literature [12] [22] [2] [23] <ref> [11] </ref>, for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation.
Reference: [12] <author> C. Longuet-Higgins. </author> <title> The reconstruction of a scene from two projections: configurations that defeat the 8-point algorithm. </title> <booktitle> In Proc. 1st Conf. on Artificial intelligence applications, </booktitle> <pages> pages 395-397, </pages> <address> Denver, </address> <year> 1984. </year>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [13] and has been extensively studied in the literature <ref> [12] </ref> [22] [2] [23] [11], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation.
Reference: [13] <author> H.C. Longuet-Higgins. </author> <title> A Computer Algorithm for Reconstructing a Scene from Two Projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: Jones and Malik [9] have shown that it is also possible in this framework to recover the location of epipolar lines. The computation technique used by most of the authors [6] [18] [20] is just a linear one, which generalizes the eight-point algorithm of Longuet-Higgins <ref> [13] </ref>. After a first part where we clarify the concept of Fundamental matrix, we show that this computation technique suffers from two majors intrinsic drawbacks. Analyzing these drawbacks enables us to introduce a new, non-linear computation technique, based on criteria that have a nice interpretation in terms of distances. <p> In that case, the fundamental matrix reduces to an essential matrix. But if one wants to proceed only from image measurements, the fundamental matrix is the key concept, as it contains the all the geometrical information relating two different images. 2.3 Relation with Longuet-Higgins equation The Longuet-Higgins equation <ref> [13] </ref>, applies when using normalized coordinates, and thus calibrated cameras. <p> Thus we know that if we are given 8 matches we will be able, in general, to determine a unique solution for F, defined up to a scale factor. This approach, known as the eight point algorithm, was introduced by Longuet-Higgins <ref> [13] </ref> and has been extensively studied in the literature [12] [22] [2] [23] [11], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation.
Reference: [14] <author> S.J. Maybank and O.D. Faugeras. </author> <title> A Theory of Self-Calibration of a Moving Camera. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 123-151, </pages> <year> 1992. </year>
Reference-contexts: Recent work [8] [3] [15] [6] has shown that it is possible to recover the projective structure of a scene from point correspondences only, without the need for camera calibration. It is even possible to use these projective invariants to compute the camera calibration [4] <ref> [14] </ref>. These approaches use only geometric information which relates the different viewpoints. This information is entirely contained in the Fundamental matrix, thus it is very important to develop precise techniques to compute it.
Reference: [15] <author> R. Mohr, L. Quan, F. Veillon, and B. Boufama. </author> <title> Relative 3d reconstruction using multiple uncalibrated images. </title> <type> Technical Report RT84-IMAG12, </type> <institution> LIFIA, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: However, it is not always possible to assume that cameras can be calibrated off-line, particularly when using active vision systems. Thus a second approach is emerging, which consists in using projective invariants [16], whose non-metric nature allows to use uncalibrated cameras. Recent work [8] [3] <ref> [15] </ref> [6] has shown that it is possible to recover the projective structure of a scene from point correspondences only, without the need for camera calibration. It is even possible to use these projective invariants to compute the camera calibration [4] [14].
Reference: [16] <author> J. L. Mundy and A. Zisserman, </author> <title> editors. Geometric invariance in computer vision. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: However, it is not always possible to assume that cameras can be calibrated off-line, particularly when using active vision systems. Thus a second approach is emerging, which consists in using projective invariants <ref> [16] </ref>, whose non-metric nature allows to use uncalibrated cameras. Recent work [8] [3] [15] [6] has shown that it is possible to recover the projective structure of a scene from point correspondences only, without the need for camera calibration.
Reference: [17] <author> V.S. Nalwa and E. Pauchon. </author> <title> Edgel aggregation and edge description. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 40(1) </volume> <pages> 79-94, </pages> <month> Oct. </month> <year> 1987. </year>
Reference-contexts: : cos (xx 0 ; rg (x 0 )) ' cos (xx 0 ; rg (x)), we get: g (x) Il is now obvious that the criterion (18) can be written: P It would be possible to use a second-order approximation such as the one introduced by Nalwa and Pauchon <ref> [17] </ref>, however the experimental results presented in the next section show that it would not be very useful practically.
Reference: [18] <author> S.I. Olsen. </author> <title> Epipolar line estimation. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 307-311, </pages> <year> 1992. </year>
Reference-contexts: Another approach is to use linear filters tuned to a range of orientations and scales. Jones and Malik [9] have shown that it is also possible in this framework to recover the location of epipolar lines. The computation technique used by most of the authors [6] <ref> [18] </ref> [20] is just a linear one, which generalizes the eight-point algorithm of Longuet-Higgins [13]. After a first part where we clarify the concept of Fundamental matrix, we show that this computation technique suffers from two majors intrinsic drawbacks. <p> It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. Some recent work has indeed pointed out that it is also relevant for the purpose of working from uncalibrated cameras <ref> [18] </ref>, [4] [6].
Reference: [19] <author> P.D. Sampson. </author> <title> Fitting conic sections to very scattered data. an iterative refinement of the Bookstein algorithm. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 18(1) </volume> <pages> 97-108, </pages> <month> Jan. </month> <year> 1982. </year>
Reference-contexts: The straightforward idea is to approximate the true distance of the point x to the surface by the number g (x; f ), in order to get a closed-form solution. A more precise approximation has been introduced by Sampson <ref> [19] </ref>.
Reference: [20] <author> A. Shashua. </author> <title> Projective structure from two uncalibrated images: structure from motion and recognition. </title> <journal> Technical Report A.I. </journal> <volume> Memo No. 1363, </volume> <publisher> MIT, </publisher> <month> Sept </month> <year> 1992. </year>
Reference-contexts: Another approach is to use linear filters tuned to a range of orientations and scales. Jones and Malik [9] have shown that it is also possible in this framework to recover the location of epipolar lines. The computation technique used by most of the authors [6] [18] <ref> [20] </ref> is just a linear one, which generalizes the eight-point algorithm of Longuet-Higgins [13]. After a first part where we clarify the concept of Fundamental matrix, we show that this computation technique suffers from two majors intrinsic drawbacks.
Reference: [21] <author> R.Y. Tsai. </author> <title> An Efficient and Accurate Camera Calibration Technique for 3D Machine Vision. </title> <booktitle> In Proceedings CVPR '86, </booktitle> <address> Miami Beach, Florida, </address> <pages> pages 364-374. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1986. </year>
Reference-contexts: This is done by camera calibration <ref> [21] </ref> [5], which typically computes the projection matrices P, which relates the image coordinates to a world reference frame. However, it is not always possible to assume that cameras can be calibrated off-line, particularly when using active vision systems.
Reference: [22] <author> R.Y. Tsai and T.S. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects wirth curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 13-27, </pages> <year> 1984. </year> <month> 25 </month>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [13] and has been extensively studied in the literature [12] <ref> [22] </ref> [2] [23] [11], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation.
Reference: [23] <author> J. Weng, T.S. Huang, and N. Ahuja. </author> <title> Motion and structure from two perspective views: algorithms, error analysis and error estimation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(5) </volume> <pages> 451-476, </pages> <year> 1989. </year> <type> 26 27 non-linear criterion (bottom) 28 </type>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [13] and has been extensively studied in the literature [12] [22] [2] <ref> [23] </ref> [11], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation.
References-found: 23

