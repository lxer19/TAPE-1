URL: ftp://ftp.cs.uoregon.edu/pub/lo/kncube_alloc.ps.gz
Refering-URL: http://www.cs.uoregon.edu/research/DistributedComputing/archive.html
Root-URL: http://www.cs.uoregon.edu
Email: Email: kurtw, lo@cs.uoregon.edu  Email: bose@cs.orst.edu  
Phone: Tel: (503) 346-4408  
Title: Contiguous and Non-contiguous Processor Allocation Algorithms for k-ary n-cubes 1  
Author: Kurt Windisch and Virginia Lo Bella Bose 
Keyword: processor allocation, k-ary n-cubes, resource management, fragmentation  
Address: OR 97403  Corvallis OR 97331  
Affiliation: Department of Computer and Information Science University of Oregon, Eugene,  Department of Computer Science Oregon State University,  
Abstract: Efficient utilization of processing resources in a large, multi-user parallel computer depends on processor allocation algorithms that minimize system fragmentation. We propose three processor allocation algorithms for the k-ary n-cube class of parallel architectures, which includes the hypercube and multidimensional torus. The k-ary Partner strategy is a conventional contiguous processor allocation strategy that improves subcube recognition. The non-contiguous Multiple Buddy and Multiple Partner strategies lift the restriction of contiguity in order to address the problem of fragmentation associated with contiguous strategies. Simulations compare the performance of these three strategies with the performance of other k-ary n-cube allocation strategies, showing that non-contiguous allocation provides significantly increased system utilization by eliminating fragmentation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Al-Dhelaan and B. Bose. </author> <title> A new strategy for processors allocation in an n-cube multiprocessor. </title> <booktitle> In Proceedings of the International Phoenix Conference on Computers and Communication, </booktitle> <pages> pages 114-118, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Despite this drawback, contiguous strategies remain the most commonly implemented processor allocation algorithms in real distributed memory parallel computers. 4.1 k-ary Partner Strategy We propose a new contiguous strategy, the k-ary Partner strategy, by extending our earlier Partner strategy developed for the binary hypercube <ref> [1] </ref> to the k-ary n-cube. Although it is similar to the k-ary Buddy strategy, in that it also uses the tree representation of subcubes, it provides significantly better performance. <p> However, the 1-st partner set contains the nodes 12, 22, and 32, all of which are free. Therefore, those four nodes, 02 and its 0-th partners, are allocated to the job. Al-Dhelaan and Bose's subcube recognition proof <ref> [1] </ref> can be extended, without loss of generality, to show that the Partner strategy can recognize (n m + 1)k nm Q k m subcubes from a Q k n . <p> Deallocation simply costs O (k n ) to reset the allocation bits of each allocated processor. An implementation of the k-ary Partner strategy using free lists as described in <ref> [1] </ref> and similar to those used in MBS, could be used to reduce this overhead. 18 3 , which is represented by decomposing the three dimensional structure into its two dimensional planes.
Reference: [2] <author> B. Bose, B. Broeg, Y. Kwon, and Y. Ashir. </author> <title> Lee distance and topological properties of k-ary n-cubes. </title> <journal> IEEE Transactions on Computers, </journal> <note> 1995. To appear. 25 </note>
Reference-contexts: Sections 4 and 5 introduce new contiguous and non-contiguous processor allocation strategies for the k-ary n-cube. Section 6 analyzes the performance of these strategies through simulation, and Section 7 summarizes our results and discusses future work. 2 Mathematical Preliminaries A k-ary n-cube [5] <ref> [2] </ref>, also denoted as Q k n , is a graph containing k n nodes, each labeled with a distinct base-k, n-bit address, (a n 1; a n 2; : : : ; a i ; : : : ; a 1 ; a 0 ), with 0 a i k
Reference: [3] <author> M. Chen and K. G. Shin. </author> <title> Processor allocation in an n-cube multiprocessor using gray codes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(12):1396-1407, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: Since the hypercube is simply a k-ary n-cube where k = 2 (Q 2 n ), the most obvious allocation algorithms for k-ary n-cubes are generalizations of the common binary hypercube strategies. Gautam and Chaudhary [6] extended the traditional hypercube algorithms, Buddy and Gray Code <ref> [3] </ref>, to the k-ary n-cube topology. In the k-ary Buddy strategy, the tree is arranged such that the leaves, representing individual processors, are ordered in increasing order from 0 to n.
Reference: [4] <author> R. Covington, S. Dwarkadas, J. Jump, J. Sinclair, and S. Madala. </author> <title> The efficient simulation of parallel computer system. </title> <journal> International Journal in Computer Simulations, </journal> <volume> 1 </volume> <pages> 31-58, </pages> <year> 1991. </year>
Reference-contexts: Our discrete event simulator, ProcSimity [11], was implemented in C using the Rice Parallel Processing Testbed Tools YACSIM, a general simulation library, and NETSIM, a library of network simulation extensions <ref> [4] </ref>. The experiments model the arrival, service, and departure of a stream of 1000 jobs in k-ary n-cube systems using first-come, first-serve scheduling (FCFS) and many of the allocation algorithms presented already. Jobs arrive, delay for an amount of time taken from an exponential distribution, and then depart.
Reference: [5] <author> W. J. Dally. </author> <title> Performance analysis of k-ary n-cube interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(6) </volume> <pages> 775-784, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Sections 4 and 5 introduce new contiguous and non-contiguous processor allocation strategies for the k-ary n-cube. Section 6 analyzes the performance of these strategies through simulation, and Section 7 summarizes our results and discusses future work. 2 Mathematical Preliminaries A k-ary n-cube <ref> [5] </ref> [2], also denoted as Q k n , is a graph containing k n nodes, each labeled with a distinct base-k, n-bit address, (a n 1; a n 2; : : : ; a i ; : : : ; a 1 ; a 0 ), with 0 a i
Reference: [6] <author> V. Gautam and V. Chaudhary. </author> <title> Subcube allocation strategies in a k-ary n-cube. </title> <booktitle> In Proceedings of the Sixth ISCA International Conference on Parallel and Distributed Computing Systems, </booktitle> <address> Louisville, KY, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: Since the hypercube is simply a k-ary n-cube where k = 2 (Q 2 n ), the most obvious allocation algorithms for k-ary n-cubes are generalizations of the common binary hypercube strategies. Gautam and Chaudhary <ref> [6] </ref> extended the traditional hypercube algorithms, Buddy and Gray Code [3], to the k-ary n-cube topology. In the k-ary Buddy strategy, the tree is arranged such that the leaves, representing individual processors, are ordered in increasing order from 0 to n. <p> subcube of any base (arity) could be searched for, but noted that they return incorrect results if the subcube base was not identical to the base of the topology. 3.2 Sniffing Strategy In addition to the above algorithms, Gautam and Chaudhary also proposed a new algorithm, called the Sniffing strategy <ref> [6] </ref>. They contend that Sniffing is an improvement over the previous strategies, because it is able to satisfy requests of any base, j, in a Q k n . <p> This is due 12 Recognizable Allocation Deallocation Strategy Q k m 's Time Complexity Time Complexity Reference Buddy k nm O (k n ) O (k n ) <ref> [6] </ref> Gray Code k nm+1 O (k n ) O (k n ) [6] Sniffing k nm O (k n+2 ) O (k n ) [6] 3D Tori any multidimensional mesh O (num allocs 2 ) y O (num allocs 2 ) y [10] Partner (n m + 1)k nm O <p> This is due 12 Recognizable Allocation Deallocation Strategy Q k m 's Time Complexity Time Complexity Reference Buddy k nm O (k n ) O (k n ) <ref> [6] </ref> Gray Code k nm+1 O (k n ) O (k n ) [6] Sniffing k nm O (k n+2 ) O (k n ) [6] 3D Tori any multidimensional mesh O (num allocs 2 ) y O (num allocs 2 ) y [10] Partner (n m + 1)k nm O (k n+1 ) O (k n ) z yAssuming k is fixed. zProposed <p> 12 Recognizable Allocation Deallocation Strategy Q k m 's Time Complexity Time Complexity Reference Buddy k nm O (k n ) O (k n ) <ref> [6] </ref> Gray Code k nm+1 O (k n ) O (k n ) [6] Sniffing k nm O (k n+2 ) O (k n ) [6] 3D Tori any multidimensional mesh O (num allocs 2 ) y O (num allocs 2 ) y [10] Partner (n m + 1)k nm O (k n+1 ) O (k n ) z yAssuming k is fixed. zProposed in this paper.
Reference: [7] <author> Phillip Krueger, Ten-Hwang Lai, and Vibha A. Dixit-Radiya. </author> <title> Job scheduling is more important than processor allocation for hypercube computers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(5) </volume> <pages> 488-497, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: When servicing a dynamic workload under FCFS scheduling, significant pockets of wasted processors become scattered around the system. These regions of wasted processors lead to impaired utilization of the system's processor resources. In binary hypercubes, Kreuger, Lai and Radiya <ref> [7] </ref> have shown that the maximum utilization attainable by contiguous allocation for uniform workloads is 58%. For the mesh architectures, we have shown in [9] that the maximum utilization attainable by contiguous allocation is 46%. <p> Table 1: Comparison of contiguous allocation strategies for the k-ary n-cube. to the nature the contiguity constraint and will be studied quantitatively in Section 6, where we will compare many allocation strategies by simulation. Improved performance requires exploration of other alternatives, including scheduling policies <ref> [7] </ref> and the approach we propose: non-contiguous allocation. <p> We have made extensive efforts to verify and validate our simulation model and its implementation through code verification, testing, output analysis, and comparison with other simulators [12] <ref> [7] </ref>. The job request streams were modeled taking the job request sizes from the uniform distribution, and the exponential distribution, in which small jobs occur more frequently while very large jobs occur less frequently.
Reference: [8] <author> Keqin Li and Kam-Hoi Cheng. </author> <title> A two-dimensional buddy system for dynamic resource allocation in a partitionable mesh connected system. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 12 </volume> <pages> 79-83, </pages> <year> 1991. </year>
Reference-contexts: MBS is an extension of our mesh-based MBS algorithm [9] and is based on the k-ary Buddy strategy and the mesh 2D Buddy strategy <ref> [8] </ref>. MBS eliminates the problems of fragmentation found in these contiguous strategies by allowing multiple contiguous blocks to be allocated to a job non-contiguously.
Reference: [9] <author> W. Liu, V. M. Lo, K. Windisch, and B. Nitzberg. </author> <title> Non-contiguous processor allocation algorithms for distributed memory multicomputers. </title> <booktitle> In Proceedings Supercomputing '94, </booktitle> <pages> pages 227-236, </pages> <year> 1994. </year>
Reference-contexts: These regions of wasted processors lead to impaired utilization of the system's processor resources. In binary hypercubes, Kreuger, Lai and Radiya [7] have shown that the maximum utilization attainable by contiguous allocation for uniform workloads is 58%. For the mesh architectures, we have shown in <ref> [9] </ref> that the maximum utilization attainable by contiguous allocation is 46%. <p> MBS is an extension of our mesh-based MBS algorithm <ref> [9] </ref> and is based on the k-ary Buddy strategy and the mesh 2D Buddy strategy [8]. MBS eliminates the problems of fragmentation found in these contiguous strategies by allowing multiple contiguous blocks to be allocated to a job non-contiguously. <p> For mesh architectures, we have seen that the increased contention due to non-contiguous allocation is not as serious as the fragmentation effects of the contiguous allocation. Thus, we observed that non-contiguous allocation performed better overall, even when message-passing contention was considered <ref> [9] </ref>.
Reference: [10] <author> W. Qiao and L. M. Ni. </author> <title> Efficient processor allocation for 3d tori. </title> <type> Technical report, </type> <institution> Michigan State University, </institution> <address> East Lansing, MI 48824-1027, </address> <year> 1994. </year> <month> 26 </month>
Reference-contexts: Allocation time complexity is O (k n+2 ) and deallocation time complexity is O (k n ). As with the other strategies, fragmentation of the system is still a major concern in Sniffing. 3.3 3D Tori Strategy Qiao and Ni <ref> [10] </ref> developed a new processor allocation algorithm specifically for the 3D Tori (k-ary 3-cube) that is extendable to tori of any dimension. <p> (k n ) O (k n ) [6] Gray Code k nm+1 O (k n ) O (k n ) [6] Sniffing k nm O (k n+2 ) O (k n ) [6] 3D Tori any multidimensional mesh O (num allocs 2 ) y O (num allocs 2 ) y <ref> [10] </ref> Partner (n m + 1)k nm O (k n+1 ) O (k n ) z yAssuming k is fixed. zProposed in this paper.
Reference: [11] <author> K. Windisch, J. V. Miller, and V. Lo. Procsimity: </author> <title> an experimental tool for processor allocation and scheduling in highly parallel systems. </title> <booktitle> In Proceedings of the Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <month> February </month> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: Our discrete event simulator, ProcSimity <ref> [11] </ref>, was implemented in C using the Rice Parallel Processing Testbed Tools YACSIM, a general simulation library, and NETSIM, a library of network simulation extensions [4].
Reference: [12] <author> Yahui Zhu. </author> <title> Efficient processor allocation strategies for mesh-connected parallel computers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16 </volume> <pages> 328-337, </pages> <year> 1992. </year> <month> 27 </month>
Reference-contexts: We have made extensive efforts to verify and validate our simulation model and its implementation through code verification, testing, output analysis, and comparison with other simulators <ref> [12] </ref> [7]. The job request streams were modeled taking the job request sizes from the uniform distribution, and the exponential distribution, in which small jobs occur more frequently while very large jobs occur less frequently.
References-found: 12

