URL: http://www.cs.yale.edu/users/rasmussen/lib/papers/iros98.ps.gz
Refering-URL: http://www.cs.yale.edu/users/rasmussen/research.html
Root-URL: http://www.cs.yale.edu
Title: Joint Probabilistic Techniques for Tracking Objects Using Multiple Visual Cues  
Author: Christopher Rasmussen Gregory D. Hager 
Address: New Haven, CT 06520-8267  
Affiliation: Department of Computer Science Yale University  
Date: 1998  
Note: Submitted to International Conference on Intelligent Robotic Systems  
Abstract: Autonomous robots relying on vision as a primary sensor frequently must identify and track common objects such as people and cars in order to successfully perform navigation, interaction, and grasping tasks. These objects comprise many visual parts and attributes, yet image-based tracking algorithms are often keyed to only one of a target's identifying characteristics. In this paper, we present a framework for sharing information among disparate state estimation processes operating on the same underlying visual object. Well-known techniques for joint probabilistic data association are adapted to yield increased robustness when multiple trackers attuned to different cues such as color and shape are deployed simultaneously. The utility of each cue varies according to image conditions, necessitating adaptation in the weighting of the various methods to avoid bias. This is achieved by formulating a measure of tracker confidence based on distinctiveness and occlusion probability, which permits deactivating trackers before erroneous state estimates adversely affect the ensemble. We will discuss experiments using color-region-based tracking in tandem with snake tracking that demonstrate the efficacy of this approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Bar-Shalom and T. Fortmann. </author> <title> Tracking and Data Association. </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: In this paper we consider some of the issues which arise in constructing vision-based tracking systems that rely on multiple visual cues and part-based decompositions to track complex objects. The probabilistic and joint probabilistic data association filters introduced in <ref> [1] </ref> serve as a starting point for developing multi-attribute, multi-part tracking methods. <p> Moreover, in many situations other moving objects and variegated backgrounds can further aggravate problems of occlusion and distraction <ref> [6, 1] </ref>. Following multiple parts and attributes of an object in parallel can alleviate many such difficulties. Consider a person tracker that regards its target as consisting of two colored regions|a flesh-colored face above a red-colored shirt|and a head silhouette, represented by a snake. <p> an exposition of the data association background material, describe its extension to include inter-part and inter-attribute constraints, abstract some principles that can be applied to other tracking methods, and discuss our approach to focus-switching, which we term variable tracker activation. 3 Data Association Filters The probabilistic data association filter (PDAF) <ref> [1] </ref> is an extension of the Kalman filter [1] that casts the problem of data association, or how to update the state when there are multiple measurements and a single target, in a Bayesian framework. <p> describe its extension to include inter-part and inter-attribute constraints, abstract some principles that can be applied to other tracking methods, and discuss our approach to focus-switching, which we term variable tracker activation. 3 Data Association Filters The probabilistic data association filter (PDAF) <ref> [1] </ref> is an extension of the Kalman filter [1] that casts the problem of data association, or how to update the state when there are multiple measurements and a single target, in a Bayesian framework. <p> Also computed is fi 0 , the probability of the event that none of the measurements is target-originated. These events encompass all possible interpretations of the data, so P n i=0 fi i = 1. Details of the calculation of each fi i are given in <ref> [1] </ref>. The PDAF also develops the notion of a validation gate, or an ellipsoidal volume in measurement space, derived from the current estimate and uncertainty of the target state, such that the probability of a target-originated measurement appearing outside of it is negligible. <p> Such persistent interference, were one to simply run a separate PDA filter on each part, could lead to multiple trackers locked onto the same part. The joint probabilistic data association filter (JPDAF) <ref> [1] </ref> deals with this problem by sharing information among separate PDAF trackers in order to more accurately calculate association probabilities. The essential result is an exclusion principle of sorts that prevents two trackers from latching onto the same target. <p> of association between measurement j and target t given measurements Z is fi jt = P Z)! jt (fi), where: P (fi j Z) = j=1 T Y fl t : (1) contains terms for normalization and scaling, fl t is a prior probability on the target being visible (see <ref> [1] </ref> for details), and N j is the Gaussian PDF N [z j ; ^ z t j ; S t j ] for measurement j (z j is the measurement value, ^ z t j is the predicted measurement value for target t j , and S t j is <p> For each part pair p i ; p j , an expected measurement difference vector ij = H j X j 0 is computed (H is the measurement matrix from a tracker's filter equations <ref> [1] </ref>), as well a covariance ij on the expected measurement difference. Then we can define a Gaussian C ij (z i ; z j ; X t i ; X t j ) = N [z j z i ; t i t j ; t i t j ]. <p> Combining snakes with regions seems like a more challenging and fruitful endeavor, but for a number of reasons it is problematic to cast snakes in a JPDAF mold. Kalman snakes [11], for example, effectively use nearest-neighbor data association <ref> [1] </ref> with short lines as validation gates; considering multiple edges within search windows large enough that they all overlap would lead to a combinatorial explosion. (See also [4] for more discussion of this). <p> We are currently investigating heuristics for these values for Condensation tracking. When (p i ) of the tracker for a part p i with constraint links at least one other part falls below some threshold 2 <ref> [0; 1] </ref>, it is deactivated. This means that its image-based state estimation is switched off discretely, and C ij = 1 for purposes of calculating (2).
Reference: [2] <author> A. Blake, M. Isard, and D. Reynard. </author> <title> Learning to track the visual motion of contours. </title> <journal> Artificial Intelligence, </journal> <volume> No. 78, </volume> <pages> pp. 101-133, </pages> <year> 1995. </year>
Reference-contexts: For many tasks, techniques for tracking generic edges, curves, blobs, and textures have proven to be applicable with minor modifications to tracking hands, arms, heads, faces, and cars <ref> [2, 3, 4, 6] </ref>. Despite these advances, most visual tracking algorithms are quite brittle. In particular, many systems are easily confused in commonly occurring visual situations because of their reliance on a single cue or methodology for locating their target. <p> By its nature, a single part can possess multiple attributes, so it does not make sense to retain a JPDAF-style exclusion principle that prevents multiple trackers of different modalities from following the same target. However, constraints do apply: a color region tracker and a B-spline snake <ref> [2] </ref> both locked onto a hand, for instance, could be expected to have coincident centers of image mass, or the angle of the major axis of the region could be expected to agree with that of the B-spline.
Reference: [3] <author> G. Hager and P. Belhumeur. </author> <title> Real-Time Tracking of Image Regions with Changes in Geometry and Illumination. </title> <booktitle> In CVPR '96, </booktitle> <pages> pp. 403-410, </pages> <year> 1996. </year>
Reference-contexts: For many tasks, techniques for tracking generic edges, curves, blobs, and textures have proven to be applicable with minor modifications to tracking hands, arms, heads, faces, and cars <ref> [2, 3, 4, 6] </ref>. Despite these advances, most visual tracking algorithms are quite brittle. In particular, many systems are easily confused in commonly occurring visual situations because of their reliance on a single cue or methodology for locating their target.
Reference: [4] <author> M. Isard and A. Blake. </author> <title> Contour Tracking by Stochastic Propagation of Conditional Density. </title> <booktitle> In ECCV '96, </booktitle> <pages> pp. 343-356, </pages> <year> 1996. </year>
Reference-contexts: For many tasks, techniques for tracking generic edges, curves, blobs, and textures have proven to be applicable with minor modifications to tracking hands, arms, heads, faces, and cars <ref> [2, 3, 4, 6] </ref>. Despite these advances, most visual tracking algorithms are quite brittle. In particular, many systems are easily confused in commonly occurring visual situations because of their reliance on a single cue or methodology for locating their target. <p> Kalman snakes [11], for example, effectively use nearest-neighbor data association [1] with short lines as validation gates; considering multiple edges within search windows large enough that they all overlap would lead to a combinatorial explosion. (See also <ref> [4] </ref> for more discussion of this). Nonetheless, we believe that the JPDAF exclusion principle and the constraint function machinery that we have de-veloped here can be abstracted and applied to other state estimation techniques. <p> Nonetheless, we believe that the JPDAF exclusion principle and the constraint function machinery that we have de-veloped here can be abstracted and applied to other state estimation techniques. In particular, we have been investigating modifications to the Condensation algorithm <ref> [4, 5] </ref> for state estimation. 5.1 Condensation: Color and Snakes The Condensation algorithm has been used, with more complexity than we can do justice to here, to successfully track snakes in highly cluttered environments.
Reference: [5] <author> M. Isard and A. Blake. </author> <title> A Mixed-state Condensation Tracker with Automatic Model-switching. </title> <booktitle> In ICCV '98, </booktitle> <pages> pp. 107-112, </pages> <year> 1998. </year>
Reference-contexts: Nonetheless, we believe that the JPDAF exclusion principle and the constraint function machinery that we have de-veloped here can be abstracted and applied to other state estimation techniques. In particular, we have been investigating modifications to the Condensation algorithm <ref> [4, 5] </ref> for state estimation. 5.1 Condensation: Color and Snakes The Condensation algorithm has been used, with more complexity than we can do justice to here, to successfully track snakes in highly cluttered environments.
Reference: [6] <author> D. Koller, J. Weber, and J. Malik. </author> <title> Robust Multiple Car Tracking with Occlusion Reasoning. </title> <booktitle> In ECCV '94, </booktitle> <pages> pp. 189-196, </pages> <year> 1994. </year>
Reference-contexts: For many tasks, techniques for tracking generic edges, curves, blobs, and textures have proven to be applicable with minor modifications to tracking hands, arms, heads, faces, and cars <ref> [2, 3, 4, 6] </ref>. Despite these advances, most visual tracking algorithms are quite brittle. In particular, many systems are easily confused in commonly occurring visual situations because of their reliance on a single cue or methodology for locating their target. <p> Moreover, in many situations other moving objects and variegated backgrounds can further aggravate problems of occlusion and distraction <ref> [6, 1] </ref>. Following multiple parts and attributes of an object in parallel can alleviate many such difficulties. Consider a person tracker that regards its target as consisting of two colored regions|a flesh-colored face above a red-colored shirt|and a head silhouette, represented by a snake.
Reference: [7] <author> C. Rasmussen and G. Hager. </author> <title> An Adaptive Model for Tracking Objects by Color Alone. </title> <type> Techical Report, </type> <institution> DCS-TR-1200, Yale University, </institution> <year> 1997. </year>
Reference-contexts: The probabilistic and joint probabilistic data association filters introduced in [1] serve as a starting point for developing multi-attribute, multi-part tracking methods. We show how object state estimation using an appropriate mixture of color region <ref> [7] </ref> and snake trackers [11] can be made less sensitive to distraction (clutter) by exploiting inter-part relationships, and also how target occlusion can be accommodated in a natural manner through measures for deciding to "switch" a component tracking algorithm on or off. 2 Using Multiple Cues A vision-equipped autonomous robot tasked <p> an interpretation of the data that best matches the target model. (a) (b) (c) (a) Tracking window; (b) Largest connected components of flesh color; (c) Measurements derived from their centroids. 4.1 Color Regions as Parts We now discuss applying the PDAF and JPDAF to parts consisting of uniformly colored regions <ref> [7] </ref>. A part's color is formally defined by pixel membership in a five-dimensional ellipsoid in image-RGB space with mean and covariance [; ]. For reasons explained in [7], the state X of a color part is restricted to the ellipsoid mean = [x; y; r; g; b] T , while is <p> from their centroids. 4.1 Color Regions as Parts We now discuss applying the PDAF and JPDAF to parts consisting of uniformly colored regions <ref> [7] </ref>. A part's color is formally defined by pixel membership in a five-dimensional ellipsoid in image-RGB space with mean and covariance [; ]. For reasons explained in [7], the state X of a color part is restricted to the ellipsoid mean = [x; y; r; g; b] T , while is retained as a fixed parameter. The state is initialized by computing the principal components of manually-sampled target pixels.
Reference: [8] <author> C. Rasmussen and G. Hager. </author> <title> Color Region Tracking Using the Condensation Algorithm. </title> <type> Techical Report, </type> <institution> DCS-TR-1222, Yale University, </institution> <year> 1998. </year>
Reference-contexts: One can estimate the object state as ^ X = P n We have implemented a simple version of a Condensation snake tracker, as well as a Condensation analog of the color region tracking method described in Section 4.1 <ref> [8] </ref>, in order to demonstrate some of the benefits of multi-attribute tracking. Figure 3 illustrates how more than one of an object's attributes may be necessary to distinguish it. <p> More details and preliminary results are given in <ref> [8] </ref>. 6 Variable Tracker Activation Tracking failure [12] occurs when contact with a target is lost, either from occlusion or because clutter distracts the tracker away from the true target. The JPDAF and constrained JPDAF try to prevent failure due to distraction, but they can not completely eliminate it.
Reference: [9] <author> J. Rehg and T. Kanade. </author> <title> Model-based tracking of self-occluding articulated objects. </title> <booktitle> In ICCV '95, </booktitle> <pages> pp. 612-617, </pages> <year> 1995. </year>
Reference-contexts: Robust state estimation processes that furnish information not only about where a target is in robot coordinates, but also about its current posture and orientation, are critical for motion planning and object and gesture recognition modules. The articulation of human bodies and much industrial machinery implies that self-occlusion <ref> [9] </ref> (where one part of the body moves in front of another) and self-distraction (when similar parts|e.g., hands or grippers|are close to one another) are common hurdles to be overcome. Moreover, in many situations other moving objects and variegated backgrounds can further aggravate problems of occlusion and distraction [6, 1].
Reference: [10] <author> D. Reynard, A. Wildenberg, A. Blake, and J. Marchant. </author> <title> Learning Dynamics of Complex Motions from Image Sequences. </title> <booktitle> In ECCV '96, </booktitle> <pages> pp. 357-368, </pages> <year> 1996. </year>
Reference-contexts: The approach to an object model here should be distinguished from other methods that affect state update directly <ref> [10, 11] </ref>. <p> Each part tracker has used a single method|color so far, but one could easily imagine a collection of snakes, as with <ref> [10] </ref>, in which coupled snakes track a person's mouth and head (using a different approach to constraints). In this situation, the JPDAF guards against multiple trackers "clumping" on the same target or swapping places when their respective targets are brought into proximity.
Reference: [11] <author> D. Terzopoulos and R. Szeliski. </author> <title> Tracking with Kalman Snakes. In Active Vision, </title> <editor> A. Blake and A. Yuille, </editor> <booktitle> eds., </booktitle> <pages> pp. 3-20, </pages> <year> 1992. </year>
Reference-contexts: The probabilistic and joint probabilistic data association filters introduced in [1] serve as a starting point for developing multi-attribute, multi-part tracking methods. We show how object state estimation using an appropriate mixture of color region [7] and snake trackers <ref> [11] </ref> can be made less sensitive to distraction (clutter) by exploiting inter-part relationships, and also how target occlusion can be accommodated in a natural manner through measures for deciding to "switch" a component tracking algorithm on or off. 2 Using Multiple Cues A vision-equipped autonomous robot tasked with moving among and <p> The approach to an object model here should be distinguished from other methods that affect state update directly <ref> [10, 11] </ref>. <p> Combining snakes with regions seems like a more challenging and fruitful endeavor, but for a number of reasons it is problematic to cast snakes in a JPDAF mold. Kalman snakes <ref> [11] </ref>, for example, effectively use nearest-neighbor data association [1] with short lines as validation gates; considering multiple edges within search windows large enough that they all overlap would lead to a combinatorial explosion. (See also [4] for more discussion of this).
Reference: [12] <author> K. Toyama and G. Hager. </author> <title> Incremental Focus of Attention for Robust Visual Tracking. </title> <booktitle> In CVPR '96, </booktitle> <pages> pp. 189-195, </pages> <year> 1996. </year>
Reference-contexts: Despite these advances, most visual tracking algorithms are quite brittle. In particular, many systems are easily confused in commonly occurring visual situations because of their reliance on a single cue or methodology for locating their target. As recent work in multi-cue tracking suggests <ref> [12] </ref>, one way toward robust visual tracking is through exploiting several simultaneously measured visual cues in as flexible a fashion as possible. <p> More details and preliminary results are given in [8]. 6 Variable Tracker Activation Tracking failure <ref> [12] </ref> occurs when contact with a target is lost, either from occlusion or because clutter distracts the tracker away from the true target. The JPDAF and constrained JPDAF try to prevent failure due to distraction, but they can not completely eliminate it.
Reference: [13] <author> C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: </author> <title> Real-Time Tracking of the Human Body. </title> <booktitle> In SPIE, </booktitle> <volume> Vol. 2615, </volume> <year> 1995. </year>
Reference-contexts: As recent work in multi-cue tracking suggests [12], one way toward robust visual tracking is through exploiting several simultaneously measured visual cues in as flexible a fashion as possible. Approaches to tracking in this spirit have been successful <ref> [13] </ref>, yet even more flexibility may become necessary in order to track increasingly complex objects through a wide range of poses, backgrounds, and lighting conditions.
References-found: 13

