URL: http://www.eecs.umich.edu/techreports/systems/control_group/cgr43.ps.Z
Refering-URL: http://www.eecs.umich.edu/home/techreports/sys90.html
Root-URL: http://www.cs.umich.edu
Title: AND &gt; Abstract.  state-space methods, CONTROL OF LINEAR TIME-VARYING SYSTEMS: A STATE-SPACE APPROACH Key words:  
Author: H H H H H H 
Note: AMS Classification:  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> B. D. O. Anderson, </author> , <note> SIAM Journal on Control and Optimization, </note> <month> 20 </month> <year> (1982), </year> <pages> pp. 408-413. </pages>
Reference-contexts: We also use the notation ( ) stabilizable (respectively ( ) detectable) to denote this. It is a fact that if is stabilizable and detectable then it is exponentially stable iff is a bounded operator (a proof for the discrete-time case is in <ref> [1] </ref>; the continuous-time case is also easily shown). We briefly review the concept of a dual, which was first introduced by Kalman (see e.g. [12]) as a means of relating regulation and estimation. We begin by considering the system defined only over a finite time interval [0 ]. <p> Let be an auxiliary system defined as _ = ( ) + As is exponentially stable the corresponding input output system, assuming to be the output, is input output stable (see <ref> [1] </ref>). This implies that s.t. ( ) ( )(44) Using the fact that = and taking into account (43) and (44) we get that for all initial states ( ) = , ( ) where the bound is independent of the initial time or state.
Reference: [2] <author> B. D. O. Anderson and J. B. Moore, </author> , <note> SIAM Journal on Control and Optimization, </note> <month> 19 </month> <year> (1981), </year> <pages> pp. 20-32. </pages> <publisher> [3] , , Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: Indeed, even in the context of the linear quadratic Gaussian (LQG) problem, such generalizations involve significant technical difficulties. See (for the discrete-time case) <ref> [2] </ref> and [3] in this connection. For the control problem, these generalizations are nontrivial as well. Indeed, our proof techniques are quite different, and in our opinion simpler, than those employed in [20]. <p> Before going on to the main result we state three preliminary lemmas we will need in the proof of Theorem 3.1. The first is a version of the Lyapunov stability theorem proved for discrete time systems in <ref> [2] </ref>.
Reference: [4] <author> R. W. </author> <title> Brockett, </title> , <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: The exponential stability of follows from Theorem 3, page 190, in <ref> [4] </ref>. We will now demonstrate the existence of a uniform bound satisfying (43). To this end recall the definitions of and from (38). Set ( )(1 + 1 + ), and consider the system . <p> (71) can be equivalently written as _ ( ) = ( ( ) ( ) + ) )( ) ( ) ( ) = we can easily derive a bound , independent of s.t. (76) By appropriately dualizing the arguments found in the proof of Theorem 3, page 190 in <ref> [4] </ref> we can conclude from (76) that _ ( ) = ( ( ) )( ) ( ) is stable on (the interested reader may also see [16]).
Reference: [5] <author> J. C. Doyle, K. Glover, P. P. Khargonekar, and B. A. </author> <title> Francis, </title> , <journal> IEEE Transactions on Automatic Control, </journal> <volume> 34 (1989), </volume> <pages> pp. 831-847. </pages>
Reference-contexts: By we are referring to the systematic use of state-space ideas e.g., state-feedback, state-estimation, separation principle etc., for deriving and computing solutions.) This state-space approach has proved to be quite successful in providing simple and intuitive solutions to the control problem. The interested reader is referred to <ref> [5, 13] </ref> and the references contained there for these recent developments. The state-space approach is particularly natural and appealing for the problem of control of linear time-varying systems. Tadmor [21, 20] was the first to apply the state-space approach for linear time-varying systems. <p> The results in [15], for the finite horizon case, are derived under much less restrictive assumptions. In the present paper, we give a solution to the infinite horizon case building on the previous work of <ref> [5] </ref>, [15], [21], and [20]. We obtain necessary and sufficient conditions for the existence of solutions under the assumption that the plant is stabilizable from the exogenous inputs and detectable from the controlled outputs. <p> These assumptions are significantly weaker than those in [20] | thus the main contribution of the paper is the generalization of existing results in [20] by relaxing assumptions to stabilizability and detectability. While it is trivial to conjecture our main results in view of the results in <ref> [5] </ref> the proofs of these results are not so easy to generalize. Indeed, even in the context of the linear quadratic Gaussian (LQG) problem, such generalizations involve significant technical difficulties. See (for the discrete-time case) [2] and [3] in this connection. <p> The first is a version of the Lyapunov stability theorem proved for discrete time systems in [2]. The following continuous-time version is proved in [16]. ( ) ( ) ( ) [0 ) ( ) [0 ) The next result is the time-varying version of Lemma 15 in <ref> [5] </ref>. = 6 zw wr zw rw r ;r 2 21 1 2 2 2 2 21 21 22 21 22 21 21 22 2 2 2 2 2 w z P T &lt; Q w z P Q z r w v v r " r T " &gt; T
Reference: [6] <author> A. Feintuch and B. A. </author> <title> Francis, </title> , <journal> Systems and Control Letters, </journal> <volume> 5 (1984), </volume> <pages> pp. 67-71. [7] , , Automatica, </pages> <month> 21 </month> <year> (1985), </year> <pages> pp. 563-574. </pages>
Reference-contexts: The book by Francis [9] contains an excellent account of the results obtained using this approach. While most of the results were for linear time-invariant systems, several results on or uniformly optimal control of linear time-varying discrete-time systems were obtained using these methods. See for example <ref> [6, 7, 8, 10] </ref> and the references cited there. Recently some new and very interesting results on the control of slowly varying systems using operator theoretic methods have also been obtained [23].
Reference: [8] <author> A. Feintuch, P. P. Khargonekar, and A. Tannenbaum, </author> , <note> SIAM Journal on Control and Optimization, 24 (1986), pp. 1076- 1085. </note>
Reference-contexts: The book by Francis [9] contains an excellent account of the results obtained using this approach. While most of the results were for linear time-invariant systems, several results on or uniformly optimal control of linear time-varying discrete-time systems were obtained using these methods. See for example <ref> [6, 7, 8, 10] </ref> and the references cited there. Recently some new and very interesting results on the control of slowly varying systems using operator theoretic methods have also been obtained [23].
Reference: [9] <author> B. A. </author> <title> Francis, </title> , <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year> <booktitle> Lecture Notes in Control and Information Sciences, </booktitle> <volume> no. </volume> <pages> 88. </pages>
Reference-contexts: The book by Francis <ref> [9] </ref> contains an excellent account of the results obtained using this approach. While most of the results were for linear time-invariant systems, several results on or uniformly optimal control of linear time-varying discrete-time systems were obtained using these methods.
Reference: [10] <author> T. T. Georgiou and P. P. </author> <title> Khargonekar, </title> , <journal> SIAM Journal on Control and Optimization, </journal> <volume> 25 (1987), </volume> <pages> pp. 334-340. </pages>
Reference-contexts: The book by Francis [9] contains an excellent account of the results obtained using this approach. While most of the results were for linear time-invariant systems, several results on or uniformly optimal control of linear time-varying discrete-time systems were obtained using these methods. See for example <ref> [6, 7, 8, 10] </ref> and the references cited there. Recently some new and very interesting results on the control of slowly varying systems using operator theoretic methods have also been obtained [23].
Reference: [11] <author> K. Glover and J. C. </author> <title> Doyle, </title> , <journal> Systems and Control Letters, </journal> <volume> 11 (1988), </volume> <pages> pp. 167-172. </pages>
Reference-contexts: Assumptions A (5,6) are necessary for the existence of an exponentially stabilizing controller. For LTI systems, the assumptions A (3,4) can be relaxed further to requiring that certain rank conditions be satisfied on the imaginary axis <ref> [11] </ref>. In the linear time-varying case however, it is unclear what the corresponding assumptions should be since the role of the imaginary axis is very strongly related to time-invariance.
Reference: [12] <author> R. E. </author> <title> Kalman, , Bol. </title> <journal> Soc. Mat. </journal> <volume> Mexicana (2), 5 (1960), </volume> <pages> pp. 102-119. </pages>
Reference-contexts: We briefly review the concept of a dual, which was first introduced by Kalman (see e.g. <ref> [12] </ref>) as a means of relating regulation and estimation. We begin by considering the system defined only over a finite time interval [0 ]. Let := and define ( ) := ( ), ( ) := ( ), ( ) := ( ), and ( ) := ( ). <p> Note, in addition, that for each the function ( ) is the solution to the finite time Riccati equation (30) and is continuous with respect to initial conditions. It follows (using the same arguments as in <ref> [12] </ref>), that ( ) satisfies the infinite horizon Riccati equation (16). ( ) We will now show that is stabilizing, i.e. the system defined as _ ( ) = ( ( ) )( ) ( ) is exponentially stable.
Reference: [13] <author> P. P. Khargonekar, </author> , <type> tech. report, </type> <institution> Department of Electrical Engineering and Computer Science, The University of Michigan, </institution> <address> Ann Arbor, MI 48109-2122, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: By we are referring to the systematic use of state-space ideas e.g., state-feedback, state-estimation, separation principle etc., for deriving and computing solutions.) This state-space approach has proved to be quite successful in providing simple and intuitive solutions to the control problem. The interested reader is referred to <ref> [5, 13] </ref> and the references contained there for these recent developments. The state-space approach is particularly natural and appealing for the problem of control of linear time-varying systems. Tadmor [21, 20] was the first to apply the state-space approach for linear time-varying systems. <p> ) ( )(52) By adding together (51) and (52) and by defining over as ( ) := ( ) ( ) ( ) ( ) we get, for the system in (50), (53) (We note that this idea of splitting the input has been used in a similar context in <ref> [13] </ref>.) But with = we have 1 or 0 = 0. Hence it follows from (53) that 0 whenever = 0 (54) for the system (50).
Reference: [14] <author> P. P. Khargonekar, I. R. Petersen, and K. </author> <title> Zhou, </title> , <journal> IEEE Transactions on Automatic Control, </journal> <volume> 35 (1990), </volume> <pages> pp. 356-361. </pages>
Reference-contexts: The full rank conditions on and are restrictive but essential for the theory to work. To remove this assumption one can use a reasoning similar to that in <ref> [14] </ref> where it is shown that if these conditions are not satisfied, one can perturb the matrices slightly so that they are satisfied, ensuring at the same time that the solution to the new problem is also a solution to the original one.
Reference: [15] <author> D. J. N. Limebeer, B. D. O. Anderson, P. P. Khargonekar, and M. Green, </author> , <type> tech. report, </type> <institution> Department of Electrical Engineering, Imperial College, </institution> <address> London, </address> <year> 1989. </year>
Reference-contexts: Tadmor [21, 20] was the first to apply the state-space approach for linear time-varying systems. Recently a simple game theoretic solution to the control problem for the finite horizon case was given in <ref> [15] </ref>. In [21], Tadmor gave a solution to the control problem for the finite horizon case, while [20] contained a solution for the infinite horizon case. <p> Tadmor derived his results under the hypothesis that the input matrix for the exogenous signal and the output matrix for the controlled variables are nonsingular. The results in <ref> [15] </ref>, for the finite horizon case, are derived under much less restrictive assumptions. In the present paper, we give a solution to the infinite horizon case building on the previous work of [5], [15], [21], and [20]. <p> The results in <ref> [15] </ref>, for the finite horizon case, are derived under much less restrictive assumptions. In the present paper, we give a solution to the infinite horizon case building on the previous work of [5], [15], [21], and [20]. We obtain necessary and sufficient conditions for the existence of solutions under the assumption that the plant is stabilizable from the exogenous inputs and detectable from the controlled outputs. <p> This assumption, especially the first one, greatly reduces the length and complexity of the formulae to be derived in Section 3. The general forms can be obtained by constructions similar to those in <ref> [15, 17, 25] </ref>. Let denote the closed loop operator mapping to . Then the standard problem of control theory for linear time-varying systems can be stated as follows. <p> It is possible to give an alternative set of necessary and sufficient conditions involving 2 uncoupled Riccati differential equations and a spectral radius condition. This is quite standard, see for example, <ref> [15] </ref>, [20]. . Note that there is no loss of generality in replacing by 1 | hence in the proof we will work with this simplifying normalization. We will show that , defined in (19), both stabilizes the system and makes 1. <p> Let be the terminal time. As is a admissible controller over it is also admissible over [0 ] for any . In other words, 1 sup 1 (29) &gt;From existing results on the finite horizon control of linear time-varying systems in [21], <ref> [15] </ref>, we conclude that this condition is sufficient for the existence of a bounded non-negative definite solution to the finite horizon Riccati equation, _ ( ) = ( ) ( ) + ( ) ( ) ( )( )( ) ( ) + ( ) ( ) The existence of a
Reference: [16] <author> R. Ravi, A. M. Pascoal, and P. P. Khargonekar, </author> , <booktitle> in Proc. 29th Conference on Decision and Control, </booktitle> <address> Honolulu, Hawaii, </address> <month> December </month> <year> 1990, </year> <pages> pp. 1241-1246. </pages>
Reference-contexts: Before going on to the main result we state three preliminary lemmas we will need in the proof of Theorem 3.1. The first is a version of the Lyapunov stability theorem proved for discrete time systems in [2]. The following continuous-time version is proved in <ref> [16] </ref>. ( ) ( ) ( ) [0 ) ( ) [0 ) The next result is the time-varying version of Lemma 15 in [5]. = 6 zw wr zw rw r ;r 2 21 1 2 2 2 2 21 21 22 21 22 21 21 22 2 2 2 <p> derive a bound , independent of s.t. (76) By appropriately dualizing the arguments found in the proof of Theorem 3, page 190 in [4] we can conclude from (76) that _ ( ) = ( ( ) )( ) ( ) is stable on (the interested reader may also see <ref> [16] </ref>).
Reference: [17] <author> M. G. Safonov, D. J. N. Limebeer, and R. Y. </author> <title> Chiang, </title> , <journal> International Journal of Control, </journal> <volume> 50 (1989), </volume> <pages> pp. 2467-2488. </pages>
Reference-contexts: This assumption, especially the first one, greatly reduces the length and complexity of the formulae to be derived in Section 3. The general forms can be obtained by constructions similar to those in <ref> [15, 17, 25] </ref>. Let denote the closed loop operator mapping to . Then the standard problem of control theory for linear time-varying systems can be stated as follows.
Reference: [18] <author> C. Scherer, </author> , <type> tech. report, </type> <institution> Math-ematisches Institut Am Hubland, </institution> <month> October </month> <year> 1989. </year> <note> Submitted to </note> . 
Reference-contexts: Dealing with these assumptions in a more direct manner is more difficult and has been done in the case via the use of methods from singular control theory and almost invariant subspaces <ref> [19, 18] </ref>. It is unclear at this time if these methods can be " # 5 Q - 0 0 21 22 Lemma 2.1. Lemma 2.2.
Reference: [19] <author> A. A. Stoorvogel and H. Trentelman, </author> , <note> SIAM Journal on Control and Optimization, (1988). To be published. </note>
Reference-contexts: Dealing with these assumptions in a more direct manner is more difficult and has been done in the case via the use of methods from singular control theory and almost invariant subspaces <ref> [19, 18] </ref>. It is unclear at this time if these methods can be " # 5 Q - 0 0 21 22 Lemma 2.1. Lemma 2.2.
Reference: [20] <author> G. Tadmor, </author> , <type> Tech. Report 192, </type> <institution> University of Texas at Dallas, </institution> <month> May </month> <year> 1989. </year> <note> [21] , , MCSS, (1989). in Press. </note>
Reference-contexts: The interested reader is referred to [5, 13] and the references contained there for these recent developments. The state-space approach is particularly natural and appealing for the problem of control of linear time-varying systems. Tadmor <ref> [21, 20] </ref> was the first to apply the state-space approach for linear time-varying systems. Recently a simple game theoretic solution to the control problem for the finite horizon case was given in [15]. <p> Recently a simple game theoretic solution to the control problem for the finite horizon case was given in [15]. In [21], Tadmor gave a solution to the control problem for the finite horizon case, while <ref> [20] </ref> contained a solution for the infinite horizon case. <p> The results in [15], for the finite horizon case, are derived under much less restrictive assumptions. In the present paper, we give a solution to the infinite horizon case building on the previous work of [5], [15], [21], and <ref> [20] </ref>. We obtain necessary and sufficient conditions for the existence of solutions under the assumption that the plant is stabilizable from the exogenous inputs and detectable from the controlled outputs. These assumptions are significantly weaker than those in [20] | thus the main contribution of the paper is the generalization of <p> horizon case building on the previous work of [5], [15], [21], and <ref> [20] </ref>. We obtain necessary and sufficient conditions for the existence of solutions under the assumption that the plant is stabilizable from the exogenous inputs and detectable from the controlled outputs. These assumptions are significantly weaker than those in [20] | thus the main contribution of the paper is the generalization of existing results in [20] by relaxing assumptions to stabilizability and detectability. <p> These assumptions are significantly weaker than those in <ref> [20] </ref> | thus the main contribution of the paper is the generalization of existing results in [20] by relaxing assumptions to stabilizability and detectability. While it is trivial to conjecture our main results in view of the results in [5] the proofs of these results are not so easy to generalize. <p> See (for the discrete-time case) [2] and [3] in this connection. For the control problem, these generalizations are nontrivial as well. Indeed, our proof techniques are quite different, and in our opinion simpler, than those employed in <ref> [20] </ref>. Thus it is hoped that in additon to generalizing existing results, these techniques will provide an alternative approach to proving some of the existing results even in the linear time-invariant case. This paper is organized as follows. In Section 2, we set up the notation and the problem formulation. <p> It is possible to give an alternative set of necessary and sufficient conditions involving 2 uncoupled Riccati differential equations and a spectral radius condition. This is quite standard, see for example, [15], <ref> [20] </ref>. . Note that there is no loss of generality in replacing by 1 | hence in the proof we will work with this simplifying normalization. We will show that , defined in (19), both stabilizes the system and makes 1.
Reference: [22] <author> S. Takeda and A. R. </author> <title> Bergen, </title> , <journal> IEEE Transactions on Automatic Control, </journal> <volume> 18 (1973), </volume> <pages> pp. 631-636. </pages>
Reference-contexts: T x x : x t A LC t x t B t u t L t z t ; x A LC t &lt; x T &lt; P z P u : To establish the stability of we use a time-varying version of the proof of Theorem 1 in <ref> [22] </ref>. Assume is unstable. Because has finite gain on the set (see equation (12)), it follows from Lemma 1 in [22] that is a closed subspace of . If = then there is at least one non-zero in , the orthogonal complement of in . <p> x A LC t &lt; x T &lt; P z P u : To establish the stability of we use a time-varying version of the proof of Theorem 1 in <ref> [22] </ref>. Assume is unstable. Because has finite gain on the set (see equation (12)), it follows from Lemma 1 in [22] that is a closed subspace of . If = then there is at least one non-zero in , the orthogonal complement of in .
Reference: [23] <author> L. Y. Wang and G. Zames, </author> , <booktitle> in Proc. 28th Conference on Decision and Control, </booktitle> <address> Tampa, FL, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: See for example [6, 7, 8, 10] and the references cited there. Recently some new and very interesting results on the control of slowly varying systems using operator theoretic methods have also been obtained <ref> [23] </ref>. A major new development in control theory during the last three years has been the introduction of state-space methods. (State-space representations were used even earlier in computing solutions to control problems.
Reference: [24] <author> G. </author> <title> Zames, </title> , <journal> IEEE Transactions on Automatic Control, </journal> <volume> 26 (1981), </volume> <pages> pp. 301-320. </pages>
Reference-contexts: 48109. (Presently at the Coordinated Science Laboratory, University of Illinois, Urbana, IL.) Department of Electrical Engineering and Computer Science, The University of Michigan, Ann Arbor, MI 48109. control theory, linear time-varying systems, Riccati differential equations, optimal control. 93B50, 93C35, 93C05, 49A40 After the introduction of the control problem by Zames <ref> [24] </ref>, initial developments in control theory were based on frequency domain and operator theoretic methods. The book by Francis [9] contains an excellent account of the results obtained using this approach.
Reference: [25] <author> K. Zhou and P. P. </author> <title> Khargonekar, </title> , <journal> Systems and Control Letters, </journal> <volume> 11 (1988), </volume> <pages> pp. 85-92. 20 </pages>
Reference-contexts: This assumption, especially the first one, greatly reduces the length and complexity of the formulae to be derived in Section 3. The general forms can be obtained by constructions similar to those in <ref> [15, 17, 25] </ref>. Let denote the closed loop operator mapping to . Then the standard problem of control theory for linear time-varying systems can be stated as follows.
References-found: 22

