URL: http://www.cs.arizona.edu/people/debray/papers/scheme.ps
Refering-URL: http://www.cs.arizona.edu/alto/
Root-URL: http://www.cs.arizona.edu
Email: fdebray, muth, sawg@cs.arizona.edu  
Title: Link-time Improvement of Scheme Programs  
Author: Saumya Debray Robert Muth Scott Watterson 
Address: Tucson, AZ 85721, U.S.A.  
Affiliation: Department of Computer Science University of Arizona  
Abstract: Optimizing compilers typically limit the scope of their analyses and optimizations to individual modules. This has two drawbacks: first, library code cannot be optimized together with their callers, which implies that reusing code through libraries incurs a penalty; and second, the results of analysis and optimization cannot be propagated from an application module written in one language to a module written in another. A possible solution is to carry out (additional) program optimization at link time. This paper describes our experiences with such optimization using three different optimizing Scheme compilers, and several benchmark programs, via alto, a link-time optimizer we have developed for the DEC Alpha architecture. Experiments indicate that significant performance improvements are possible via link-time optimization even when the input programs have already been subjected to high levels of compile-time optimization.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Agesen and U. Holzle, </author> <title> "Type Feedback vs. Concrete Type Inference: A Comparison of Optimization Techniques for Object-Oriented Languages", </title> <booktitle> Proc. Tenth Annual Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA '95), </booktitle> <month> Oct. </month> <year> 1995, </year> <pages> pp. 91-107. </pages>
Reference-contexts: The notion of guarded inlining is conceptually very similar to a technique for optimizing dynamically dispatched function calls in object-oriented languages, variously referred to as "type feedback" <ref> [1, 11] </ref> and "receiver class prediction" [7, 10]. The transformation we describe is somewhat more general, for two reasons. First, it doesn't rely on specific language features such as an inheritance hierarchy, and so is applicable to any language.
Reference: [2] <author> A. V. Aho, R. Sethi and J. D. Ullman, </author> <booktitle> Compilers Principles, Techniques and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: The determination of intra-procedural control flow is not too difficult; and since an intermediate representation is used, there is no need to deal with machine-level idioms for control transfer. As a result, the construction of a control flow graph is a fairly straightforward process <ref> [2] </ref>. Things are somewhat more complex at link time because machine code is harder to decompile. The algorithm used by alto to construct a control flow graph for an input program is as follows: 1. <p> The start address of the program appears at a fixed location within the header of the file (this location may be different for different file formats). Using this as a starting point, the "standard" algorithm <ref> [2] </ref> is used to identify leaders and basic blocks, as well as function entry blocks. At this stage alto makes two assumptions: (i) that each function has a single entry block; and (ii) that all of the basic blocks of a function are laid out contiguously.
Reference: [3] <author> A. W. Appel, </author> <title> "Unrolling Recursions Saves Space", </title> <institution> CS-TR-363-92, Dept. of Computer Science, Princeton University, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: Usually, inlining a function call gets rid of at least 6 instructions (the call and return instructions; load and store instructions for saving and restoring the return address at the callee; and allocating and deallocating the callee's stack frame; but see also <ref> [3] </ref>). Additionally, register reassignment can be used to reduce the overhead of saving and restoring registers across call boundaries.
Reference: [4] <author> J. M. Ashley, </author> <title> "The Effectiveness of Flow Analysis for Inlining", </title> <booktitle> Proc. 1997 SIGPLAN International Conference on Functional Programming, </booktitle> <month> June </month> <year> 1997, </year> <pages> pp. 99-111. </pages>
Reference-contexts: hot blocks of a program usually comprise only a small fraction of the entire program: e.g., for the benchmarks considered, the hot blocks comprised about 1%-2% of the instructions in the program. 5.1 Inlining Traditionally, Scheme compilers carry out inlining at, or close to, the level of the source program <ref> [4, 6, 14, 23] </ref>. At this level, the primary benefits of inlining come from specializing and simplifying the inlined function, e.g., by evaluating conditionals and pruning away code that becomes unreachable. <p> At this level, the primary benefits of inlining come from specializing and simplifying the inlined function, e.g., by evaluating conditionals and pruning away code that becomes unreachable. Code growth during inlining is usually controlled via syntax-driven techniques, ranging from simple syntax-directed estimates of the size of the callee <ref> [4, 6, 14] </ref> to more refined estimates based on the residual size of the callee after specializing it to the call site under consideration [23].
Reference: [5] <author> D. Blickstein et al., </author> <title> "The GEM Optimizing Compiler System", </title> <journal> Digital Technical Journal, </journal> <volume> 4(4) </volume> <pages> 121-136. </pages>
Reference-contexts: The resulting C code was compiled with the DEC C compiler V5.2-036 (the highly optimizing GEM compiler system <ref> [5] </ref>, which we found generates faster code than current versions of gcc) invoked as cc -O4 -Wl,-r -Wl,-d -Wl,-z -non shared, resulting in statically linked executables.
Reference: [6] <author> M. Blume and A. W. Appel, "Lambda-splitting: </author> <title> A Higher-Order Approach to Cross-Module Optimizations", </title> <booktitle> Proc. 1997 SIGPLAN International Conference on Functional Programming, </booktitle> <month> June </month> <year> 1997, </year> <pages> pp. 112-124. </pages>
Reference-contexts: calls to library routines, or to functions defined in separately compiled modules, cannot be effectively optimized; this is unfortunate, because one expects programmers to rely more and more on code reuse through libraries as the complexity of software systems grows, (there has been some work recently on cross-module code optimization <ref> [6, 18] </ref>: this works for separately compiled user modules but not for libraries). The second problem is that a compiler can only analyze and optimize code written in the language it is designed to compile. <p> hot blocks of a program usually comprise only a small fraction of the entire program: e.g., for the benchmarks considered, the hot blocks comprised about 1%-2% of the instructions in the program. 5.1 Inlining Traditionally, Scheme compilers carry out inlining at, or close to, the level of the source program <ref> [4, 6, 14, 23] </ref>. At this level, the primary benefits of inlining come from specializing and simplifying the inlined function, e.g., by evaluating conditionals and pruning away code that becomes unreachable. <p> At this level, the primary benefits of inlining come from specializing and simplifying the inlined function, e.g., by evaluating conditionals and pruning away code that becomes unreachable. Code growth during inlining is usually controlled via syntax-driven techniques, ranging from simple syntax-directed estimates of the size of the callee <ref> [4, 6, 14] </ref> to more refined estimates based on the residual size of the callee after specializing it to the call site under consideration [23].
Reference: [7] <author> B. Calder and D. Grunwald, </author> <title> "Reducing Indirect Function Call Overhead in C++ Programs", </title> <booktitle> Proc. 21st ACM Symposium on Principles of Programming Languages, </booktitle> <month> Jan. </month> <year> 1994, </year> <pages> pp. 397-408. </pages>
Reference-contexts: The notion of guarded inlining is conceptually very similar to a technique for optimizing dynamically dispatched function calls in object-oriented languages, variously referred to as "type feedback" [1, 11] and "receiver class prediction" <ref> [7, 10] </ref>. The transformation we describe is somewhat more general, for two reasons. First, it doesn't rely on specific language features such as an inheritance hierarchy, and so is applicable to any language. More importantly, it can be adapted to any indirect jump, not just indirect function calls.
Reference: [8] <author> F. C. Chow, </author> <title> "Minimizing Register Usage Penalty at Procedure Calls", </title> <booktitle> Proc. SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1988, </year> <pages> pp. 85-94. </pages>
Reference-contexts: For example, the combination of copy propagation, inlining of recursive functions, basic block fusion, and dead code elimination can lead to the elimination of some saves and restores of callee-saved registers that cannot be accomplished using techniques such as shrink-wrapping <ref> [8] </ref> (we see this, for example, in the code generated by Bigloo on the boyer benchmark). Space constraints preclude a detailed discussion of these optimizations: here we discuss only the most important ones.
Reference: [9] <author> M. F. Fernandez, </author> <title> "Simple and Effective Link-Time Optimization of Modula-3 Programs", </title> <booktitle> Proc. SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1995, </year> <pages> pp. 103-115. </pages>
Reference-contexts: Most of the prior work on link-time optimization has focused on imperative languages <ref> [9, 17, 21, 22, 24] </ref>.
Reference: [10] <author> D. Grove, J. Dean, C. Garrett, and C. Chambers, </author> <title> "Profile-Guided Receiver Class Prediction", </title> <booktitle> Proc. Tenth Annual Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA '95), </booktitle> <month> Oct. </month> <year> 1995, </year> <pages> pp. 108-123. </pages>
Reference-contexts: The notion of guarded inlining is conceptually very similar to a technique for optimizing dynamically dispatched function calls in object-oriented languages, variously referred to as "type feedback" [1, 11] and "receiver class prediction" <ref> [7, 10] </ref>. The transformation we describe is somewhat more general, for two reasons. First, it doesn't rely on specific language features such as an inheritance hierarchy, and so is applicable to any language. More importantly, it can be adapted to any indirect jump, not just indirect function calls.
Reference: [11] <author> U. Holzle and D. Ungar, </author> <title> "Optimizing Dynamically-Dispatched Calls with Run-Time Type Feedback", </title> <booktitle> Proc. SIGPLAN '94 Conference on Programming Language Design and Implementation (PLDI), </booktitle> <month> June </month> <year> 1994, </year> <pages> pp. 326-336. </pages>
Reference-contexts: The notion of guarded inlining is conceptually very similar to a technique for optimizing dynamically dispatched function calls in object-oriented languages, variously referred to as "type feedback" <ref> [1, 11] </ref> and "receiver class prediction" [7, 10]. The transformation we describe is somewhat more general, for two reasons. First, it doesn't rely on specific language features such as an inheritance hierarchy, and so is applicable to any language.
Reference: [12] <author> F. Henglein, </author> <title> "Global Tagging Optimization by Type Inference", </title> <booktitle> Proc. 1992 ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pp. 205-215. </pages>
Reference-contexts: Siskind. 6 Our experiments were run using six commonly used Scheme benchmarks (we expect to have results for more benchmarks soon): boyer, a term-rewriting theorem prover; dynamic, an implementation of a tagging optimization algorithm for Scheme <ref> [12] </ref>, applied to itself; 7 earley, an implementation of Earley's parsing algorithm, by Marc Feeley; graphs, a program that counts the number of directed graphs with a distinguished root and k vertices each having out-degree at most 2; lattice, a program that enumerates the lattice of maps between two lattices; and
Reference: [13] <author> S. Jagannathan and A. Wright, </author> <title> "Effective Flow Analysis for Avoiding Run-Time Checks", </title> <booktitle> Proc. 1995 Static Analysis Symposium (SAS '95), </booktitle> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: the current development version of Stalin because the number-&gt;string primitive has not been implemented at this time. 8 Despite the fact that these are widely used benchmarks, there seems to be some disagreement over the number of lines of code in each (even among different papers by the same authors!) <ref> [13, 14, 20] </ref>. The numbers reported here are for the programs available with the Gambit-C 2.7 distribution (http://www.iro.umontreal.ca/~gambit), measured for the "core program", i.e., without system-specific definitions, using the wc utility.
Reference: [14] <author> S. Jagannathan and A. Wright, </author> <title> "Flow-directed Inlining", </title> <booktitle> Proc. SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <month> May </month> <year> 1996, </year> <pages> pp. 193-205. </pages>
Reference-contexts: hot blocks of a program usually comprise only a small fraction of the entire program: e.g., for the benchmarks considered, the hot blocks comprised about 1%-2% of the instructions in the program. 5.1 Inlining Traditionally, Scheme compilers carry out inlining at, or close to, the level of the source program <ref> [4, 6, 14, 23] </ref>. At this level, the primary benefits of inlining come from specializing and simplifying the inlined function, e.g., by evaluating conditionals and pruning away code that becomes unreachable. <p> At this level, the primary benefits of inlining come from specializing and simplifying the inlined function, e.g., by evaluating conditionals and pruning away code that becomes unreachable. Code growth during inlining is usually controlled via syntax-driven techniques, ranging from simple syntax-directed estimates of the size of the callee <ref> [4, 6, 14] </ref> to more refined estimates based on the residual size of the callee after specializing it to the call site under consideration [23]. <p> Inlining in the presence of higher order functions has typically been accomplished using sophisticated control flow analyses <ref> [14] </ref>. We believe that such analyses are too expensive to be practical at the level of machine code. Instead, we use a simple profile-guided inlining technique we call guarded inlining to achieve similar results. Suppose we have an indirect function call whose target we are unable to resolve. <p> This mechanism allows us to get the benefits of inlining even for call sites that can, in fact, have multiple possible targets, in contrast to schemes that require control flow analysis to identify a unique target for a call site before inlining can take place <ref> [14] </ref>. <p> the current development version of Stalin because the number-&gt;string primitive has not been implemented at this time. 8 Despite the fact that these are widely used benchmarks, there seems to be some disagreement over the number of lines of code in each (even among different papers by the same authors!) <ref> [13, 14, 20] </ref>. The numbers reported here are for the programs available with the Gambit-C 2.7 distribution (http://www.iro.umontreal.ca/~gambit), measured for the "core program", i.e., without system-specific definitions, using the wc utility.
Reference: [15] <author> W. Landi and B. G. Ryder, </author> <title> "Pointer-induced Aliasing: A Problem Classification", </title> <booktitle> Proc. 18th ACM Symposium on Principles of Programming Languages, </booktitle> <month> Jan. </month> <year> 1991, </year> <pages> pp. 93-103. 12 </pages>
Reference-contexts: Code generated for programs in dynamically typed languages usually also carries out pointer arithmetic to manipulate tagged pointers, in a way that can defeat most alias analysis algorithms developed for languages such as C (see, for example, <ref> [15, 26] </ref>). As a result, it is not obvious that systems designed for executables resulting from (human-written) C programs will be effective on code generated from Scheme programs.
Reference: [16] <author> K. Pettis and R. C. Hansen, </author> <title> "Profile-Guided Code Positioning", </title> <booktitle> Proc. SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1990, </year> <pages> pp. 16-27. </pages>
Reference-contexts: This is followed by a function inlining phase. The fourth phase repeats the optimizations carried out in the second phase to the code resulting from inlining. Finally, the final phase carries out profile-directed code layout <ref> [16] </ref>, instruction scheduling, and insertion of no-ops for alignment purposes, after which the code is written out. 3 Control Flow Analysis Traditional compilers generally construct control flow graphs for individual functions, based on some intermediate representation of the program. <p> The final reason is to improve branch prediction and instruction cache behavior using profile-directed code layout <ref> [16] </ref>.
Reference: [17] <author> T. Romer, G. Voelker, D. Lee, A. Wolman, W. Wong, H. Levy, B. N. Bershad, and J. B. Chen, </author> <title> "Instrumentation and Optimization of Win32/Intel Executables", </title> <booktitle> Proc. 1997 USENIX Windows NT Workshop. </booktitle>
Reference-contexts: Most of the prior work on link-time optimization has focused on imperative languages <ref> [9, 17, 21, 22, 24] </ref>.
Reference: [18] <author> V. Santhanam and D. Odnert, </author> <title> "Register Allocation across Procedure and Module Boundaries", </title> <booktitle> Proc. SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1990, </year> <pages> pp. 28-39 </pages>
Reference-contexts: calls to library routines, or to functions defined in separately compiled modules, cannot be effectively optimized; this is unfortunate, because one expects programmers to rely more and more on code reuse through libraries as the complexity of software systems grows, (there has been some work recently on cross-module code optimization <ref> [6, 18] </ref>: this works for separately compiled user modules but not for libraries). The second problem is that a compiler can only analyze and optimize code written in the language it is designed to compile.
Reference: [19] <author> M. Serrano and P. Weis, "Bigloo: </author> <title> a portable and optimizing compiler for strict functional languages" Proc. </title> <booktitle> Static Analysis Symposium (SAS '95), </booktitle> <year> 1995, </year> <pages> pp. 366-381. </pages>
Reference-contexts: Serrano <ref> [19] </ref>, Gambit-C version 3.0 by Marc Feeley, and Stalin version 0.8 by J.
Reference: [20] <author> M. Serrano and M. Feeley, </author> <title> "Storage Use Analysis and its Applications", </title> <booktitle> Proc. 1996 SIGPLAN International Conference on Functional Programming, </booktitle> <month> May </month> <year> 1996, </year> <pages> pp. 50-61. </pages>
Reference-contexts: the current development version of Stalin because the number-&gt;string primitive has not been implemented at this time. 8 Despite the fact that these are widely used benchmarks, there seems to be some disagreement over the number of lines of code in each (even among different papers by the same authors!) <ref> [13, 14, 20] </ref>. The numbers reported here are for the programs available with the Gambit-C 2.7 distribution (http://www.iro.umontreal.ca/~gambit), measured for the "core program", i.e., without system-specific definitions, using the wc utility.
Reference: [21] <author> A. Srivastava and D. W. Wall, </author> <title> "A Practical System for Intermodule Code Optimization at Link-Time", </title> <journal> Journal of Programming Languages, </journal> <pages> pp. 1-18, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Most of the prior work on link-time optimization has focused on imperative languages <ref> [9, 17, 21, 22, 24] </ref>.
Reference: [22] <author> A. Srivastava and D. W. Wall, </author> <title> "Link-time Optimization of Address Calculation on a 64-bit Architecture", </title> <booktitle> Proc. SIGPLAN '94 Conference Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1994, </year> <pages> pp. 49-60. </pages>
Reference-contexts: Most of the prior work on link-time optimization has focused on imperative languages <ref> [9, 17, 21, 22, 24] </ref>.
Reference: [23] <author> O. Waddell and R. K. Dybvig, </author> <title> "Fast and Effective Procedure Inlining", </title> <booktitle> Proc. 1997 Static Analysis Symposium (SAS '97), </booktitle> <month> Sept. </month> <year> 1997, </year> <pages> pp. 35-52. </pages> <publisher> Springer-Verlag LNCS vol. </publisher> <pages> 1302. </pages>
Reference-contexts: hot blocks of a program usually comprise only a small fraction of the entire program: e.g., for the benchmarks considered, the hot blocks comprised about 1%-2% of the instructions in the program. 5.1 Inlining Traditionally, Scheme compilers carry out inlining at, or close to, the level of the source program <ref> [4, 6, 14, 23] </ref>. At this level, the primary benefits of inlining come from specializing and simplifying the inlined function, e.g., by evaluating conditionals and pruning away code that becomes unreachable. <p> Code growth during inlining is usually controlled via syntax-driven techniques, ranging from simple syntax-directed estimates of the size of the callee [4, 6, 14] to more refined estimates based on the residual size of the callee after specializing it to the call site under consideration <ref> [23] </ref>. At link time, by contrast, it is reasonable to expect that considerable amounts of inlining have already been carried out by the Scheme compiler being used (and then possibly some more by the C compiler, if the compilation is via translation to C).
Reference: [24] <author> D. W. Wall, </author> <title> "Global Register Allocation at Link Time", </title> <booktitle> Proc. SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <month> July </month> <year> 1986, </year> <pages> pp. 264-275. </pages>
Reference-contexts: Most of the prior work on link-time optimization has focused on imperative languages <ref> [9, 17, 21, 22, 24] </ref>.
Reference: [25] <author> D. W. Wall, </author> <title> "Predicting Program Behavior Using Real or Estimated Profiles", </title> <booktitle> Proc. SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991, </year> <pages> pp. 59-70. </pages>
Reference-contexts: is not within any loop, then the total number of instructions in the critical subgraphs of the caller and the callee should not exceed the capacity of the level-1 instruction cache. 2 This can be estimated from profile information, or using heuristics based on the structure of the flow graph <ref> [25] </ref>. 3 This benchmark happens to be a C program, but there is no reason to believe that similar concerns don't apply to programs in other languages. 5 We don't allow code expansion into the secondary or backup caches because these are mixed instruc-tion and data caches, and allowing inlining to
Reference: [26] <author> R. P. Wilson and M. S. Lam, </author> <title> "Efficient Context-Sensitive Pointer Analysis for C Programs", </title> <booktitle> Proc. SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1995, </year> <pages> pp. 1-12. </pages>
Reference-contexts: Code generated for programs in dynamically typed languages usually also carries out pointer arithmetic to manipulate tagged pointers, in a way that can defeat most alias analysis algorithms developed for languages such as C (see, for example, <ref> [15, 26] </ref>). As a result, it is not obvious that systems designed for executables resulting from (human-written) C programs will be effective on code generated from Scheme programs.
References-found: 26

