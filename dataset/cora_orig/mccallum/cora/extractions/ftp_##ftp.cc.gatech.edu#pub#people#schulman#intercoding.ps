URL: ftp://ftp.cc.gatech.edu/pub/people/schulman/intercoding.ps
Refering-URL: http://www.cs.gatech.edu/people/home/schulman/
Root-URL: 
Title: Coding for Interactive Communication increasing importance of communication as a resource in computing, and by
Author: Leonard J. Schulman and expense. 
Keyword: Key words: Interactive Communication, Coding Theorem, Tree Code, Distributed Computing, Reliable Communication, Error Correction.  
Note: Technologically this concern is motivated by the  
Address: Berkeley  
Affiliation: Computer Science Division U. C.  
Abstract: Let the input to a computation problem be split between two processors connected by a communication link; and let an interactive protocol be known by which, on any input, the processors can solve the problem using no more than T transmissions of bits between them, provided the channel is noiseless in each direction. We study the following question: if in fact the channel is noisy, what is the effect upon the number of transmissions needed in order to solve the computation problem reliably? We treat a model with random channel noise. We describe a deterministic method for simulating noiseless-channel protocols on noisy channels, with only a constant slow-down. This is an analog for general interactive protocols of Shannon's coding theorem, which deals only with data transmission, i.e. one-way protocols. We cannot use Shannon's block coding method because the bits exchanged in the protocol are determined only one at a time, dynamically, in the course of the interaction. Instead we describe a simulation protocol using a new kind of code, explicit tree codes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. R. Berlekamp. </author> <title> Block coding for the binary symmetric channel with noiseless, delayless feedback. </title> <editor> In H. B. Mann, editor, </editor> <booktitle> Error Correcting Codes, </booktitle> <pages> pages 61-85. </pages> <publisher> Wiley, </publisher> <year> 1968. </year>
Reference-contexts: This is a phenomenon familiar already from data transmission, where the BECF model and variants of it have been studied in work beginning with Berlekamp <ref> [1] </ref>. 6 Discussion Insofar as interactive protocols model the operation of a computer whose inputs and processing power are not localized, this paper may be regarded as presenting a coding theorem for computation.
Reference: [2] <author> R. L. Dobrushin and S. I. Ortyukov. </author> <title> Lower bound for the redundancy of self-correcting arrangements of unreliable functional elements. </title> <journal> Prob. Inf. Trans., </journal> <volume> 13 </volume> <pages> 59-65, </pages> <year> 1977. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [3] <author> R. L. Dobrushin and S. I. Ortyukov. </author> <title> Upper bound for the redundancy of self-correcting arrangements of unreliable functional elements. </title> <journal> Prob. Inf. Trans., </journal> <volume> 13 </volume> <pages> 203-218, </pages> <year> 1977. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [4] <author> P. Elias. </author> <title> Computation in the presence of noise. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 2(4) </volume> <pages> 346-353, </pages> <month> October </month> <year> 1958. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. [33, 21, 23, 22, 2, 3, 8, 11, 25, 6]), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each. Elias <ref> [4] </ref> and later Peterson and Rabin [20] investigated the possibility of encoding data for computation on noisy gates, and the extent to which these gates might be said to have a finite (nonzero) capacity for computation. (Here, as for channel transmission, noiseless encoding and decoding of the data before and after
Reference: [5] <author> W. Evans, M. Klugerman, and L. J. Schulman. </author> <title> Constructive tree codes with polynomial size alphabet. </title> <type> Manuscript. </type>
Reference-contexts: First, a construction is known with alphabet size polynomial in the depth of the tree <ref> [5] </ref>.
Reference: [6] <author> W. Evans and L. J. Schulman. </author> <title> Signal propagation, with application to a lower bound on the depth of noisy formulas. </title> <booktitle> In Proceedings of the 34th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 594-603, </pages> <year> 1993. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [7] <author> R. M. Fano. </author> <title> A heuristic discussion of probabilistic decoding. </title> <journal> IEEE Transactions on Information Theory, </journal> <pages> pages 64-74, </pages> <year> 1963. </year>
Reference-contexts: The idea of such a probabilistically constrained search was introduced in the work of Wozencraft, Reiffen, Fano and others <ref> [34, 24, 7] </ref> on sequential decoding.
Reference: [8] <author> T. Feder. </author> <title> Reliable computation by networks in the presence of noise. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 35(3) </volume> <pages> 569-571, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [9] <author> P. Gacs. </author> <title> Reliable computation with cellular automata. </title> <journal> J. Computer and System Sciences, </journal> <volume> 32 </volume> <pages> 15-78, </pages> <year> 1986. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. [33, 21, 23, 22, 2, 3, 8, 11, 25, 6]), (as have noisy cellular automata, <ref> [31, 9, 10] </ref>) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [10] <author> P. Gacs and J. Reif. </author> <title> A simple three-dimensional real-time reliable cellular array. </title> <journal> J. Computer and System Sciences, </journal> <volume> 36 </volume> <pages> 125-147, </pages> <year> 1988. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. [33, 21, 23, 22, 2, 3, 8, 11, 25, 6]), (as have noisy cellular automata, <ref> [31, 9, 10] </ref>) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [11] <author> A. Gal. </author> <title> Lower bounds for the complexity of reliable boolean circuits with noisy gates. </title> <booktitle> In Proceedings of the 32nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 594-601, </pages> <year> 1991. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [12] <author> R. G. Gallager. </author> <title> Information Theory and Reliable Communication. </title> <publisher> Wiley, </publisher> <year> 1968. </year>
Reference-contexts: Random tree codes | essentially, distributions over labelled trees | were introduced by Wozencraft and used by him and others for the purpose of sequential decoding ([34, 24, 7]; see <ref> [12] </ref> x6.9). However, random tree codes are not sufficient for our purpose. We introduce below the stronger notion of tree code which we use in our work. 2.1 Tree codes Let S be a finite alphabet.
Reference: [13] <author> R. G. Gallager. </author> <title> Finding parity in a simple broadcast network. </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> 34(2) </volume> <pages> 176-180, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: In particular one would ask to what extent the coding theorem might be extended to the efficient simulation of noiseless distributed protocols, on networks with noise. This question has been answered by Rajagopalan and the author in a forthcoming publication. We draw attention also to the work of Gallager <ref> [13] </ref>, who has previously considered a different problem concerning noise in a distributed computation. He considered a complete network of n processors, each of which in a single transmission can broadcast one bit, which arrives at each of the other processors subject to independent noise.
Reference: [14] <author> G. H. Hardy and E. M. Wright. </author> <title> An Introduction to the Theory of Numbers. </title> <publisher> Oxford, </publisher> <address> fifth edition, </address> <year> 1979. </year>
Reference-contexts: Hence some string produces a tree code of depth n. 5 (B) What follows is the best currently known existence argument for tree codes 2 . Let jSj be the smallest prime greater or equal to (2 (ff)d) 1 1ff . By Bertrand's postulate <ref> [14] </ref>, there is a prime strictly between n and 2n for any integer n &gt; 1. Hence jSj &lt; 2b (2 (ff)d) 1 1ff c. Identify S with the set f0; 1; :::; jSj 1g.
Reference: [15] <author> J. Justesen. </author> <title> A class of constructive, asymptotically good algebraic codes. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-18:652-656, </volume> <month> September </month> <year> 1972. </year> <month> 18 </month>
Reference-contexts: From a practical standpoint this was not necessarily a severe problem for data transmission, since a randomly constructed code almost surely has good properties. Even so this was hardly satisfactory. Explicit codes achieving arbitrarily low error at a positive asymptotic rate were not exhibited until Justesen's work of 1972 <ref> [15] </ref>. This drawback is even greater for implementation of the present work, since the existence arguments for the required tree codes do not provide one with high probability.
Reference: [16] <author> M. Karchmer and A. Wigderson. </author> <title> Monotone circuits for connectivity require super-logarithmic depth. </title> <booktitle> In Proceedings of the 20th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 539-550, </pages> <year> 1988. </year>
Reference-contexts: a specific problem on this network: supposing that each processor receives a single input bit, he showed how to quickly and reliably compute the combined parity of all the inputs. (There is as yet a gap between the upper and lower bounds in this interesting problem, however.) Karchmer and Wigderson <ref> [16] </ref> observed a certain equivalence between communication complexity and circuit complexity, and thereby stimulated great recent interest in communication complexity.
Reference: [17] <author> Lipton and Sedgewick. </author> <title> Lower bounds for VLSI. </title> <booktitle> In Proceedings of the 13th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 300-307, </pages> <year> 1981. </year>
Reference-contexts: Yao in 3 1979 [36] to measure the cost incurred in departing from the single-processor model of computation. It has been intensively investigated (e.g. <ref> [37, 19, 32, 17] </ref>; and see [18] for a survey). The present work can be viewed as guaranteeing that every upper bound in that model, yields an upper bound in the noisy model.
Reference: [18] <author> L. Lovasz. </author> <title> Communication complexity: A survey. </title> <editor> In Korde et al, editor, </editor> <booktitle> Algorithms and Combinatorics. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Yao in 3 1979 [36] to measure the cost incurred in departing from the single-processor model of computation. It has been intensively investigated (e.g. [37, 19, 32, 17]; and see <ref> [18] </ref> for a survey). The present work can be viewed as guaranteeing that every upper bound in that model, yields an upper bound in the noisy model.
Reference: [19] <author> C. H. Papadimitriou and M. Sipser. </author> <title> Communication complexity. </title> <booktitle> In Proceedings of the 14th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 196-200, </pages> <year> 1982. </year>
Reference-contexts: Yao in 3 1979 [36] to measure the cost incurred in departing from the single-processor model of computation. It has been intensively investigated (e.g. <ref> [37, 19, 32, 17] </ref>; and see [18] for a survey). The present work can be viewed as guaranteeing that every upper bound in that model, yields an upper bound in the noisy model.
Reference: [20] <author> W. W. Peterson and M. O. Rabin. </author> <title> On codes for checking logical operations. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 3 </volume> <pages> 163-168, </pages> <month> April </month> <year> 1959. </year>
Reference-contexts: Elias [4] and later Peterson and Rabin <ref> [20] </ref> investigated the possibility of encoding data for computation on noisy gates, and the extent to which these gates might be said to have a finite (nonzero) capacity for computation. (Here, as for channel transmission, noiseless encoding and decoding of the data before and after the computation are allowed.) Acknowledgments This
Reference: [21] <author> N. Pippenger. </author> <title> On networks of noisy gates. </title> <booktitle> In Proceedings of the 26th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 30-36, </pages> <year> 1985. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [22] <author> N. Pippenger. </author> <title> Reliable computation by formulas in the presence of noise. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 34(2) </volume> <pages> 194-197, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [23] <author> N. Pippenger. </author> <title> Invariance of complexity measures for networks with unreliable gates. </title> <journal> J. ACM, </journal> <volume> 36 </volume> <pages> 531-539, </pages> <year> 1989. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [24] <author> B. Reiffen. </author> <title> Sequential encoding and decoding for the discrete memoryless channel. </title> <institution> Res. Lab. of Electronics, M.I.T. </institution> <type> Technical Report, 374, </type> <year> 1960. </year>
Reference-contexts: The idea of such a probabilistically constrained search was introduced in the work of Wozencraft, Reiffen, Fano and others <ref> [34, 24, 7] </ref> on sequential decoding.
Reference: [25] <author> R. Reischuk and B. Schmeltz. </author> <title> Reliable computation with noisy circuits and decision trees | a general n log n lower bound. </title> <booktitle> In Proceedings of the 32nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 602-611, </pages> <year> 1991. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [26] <author> L. J. Schulman. </author> <title> Communication in the Presence of Noise. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: The present work can be viewed as guaranteeing that every upper bound in that model, yields an upper bound in the noisy model. A weaker interactive analog of Shannon's coding theorem, which made use of randomization in the simulation process, was given by the author in <ref> [26] </ref> and [27]. The present result was presented in preliminary form in [28]. The binary symmetric channel (BSC) is a simple noise model which nevertheless captures the chief difficulties of the problem considered in this paper; therefore we have focussed on it. <p> In earlier work of the author in this area it was proposed that the problem of interactive communication in the presence of noise, also be studied for networks of more than two processors <ref> [26] </ref>. In particular one would ask to what extent the coding theorem might be extended to the efficient simulation of noiseless distributed protocols, on networks with noise. This question has been answered by Rajagopalan and the author in a forthcoming publication. <p> for computation on noisy gates, and the extent to which these gates might be said to have a finite (nonzero) capacity for computation. (Here, as for channel transmission, noiseless encoding and decoding of the data before and after the computation are allowed.) Acknowledgments This research was conducted at MIT (see <ref> [26, 27] </ref> for preliminary presentations and related work) and at U. C. Berkeley (see [28]). Thanks to my advisor Mike Sipser whose oversight and encouragement in the early stages of this work were invaluable.
Reference: [27] <author> L. J. Schulman. </author> <title> Communication on noisy channels: A coding theorem for computation. </title> <booktitle> In Proceedings of the 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 724-733, </pages> <year> 1992. </year>
Reference-contexts: The present work can be viewed as guaranteeing that every upper bound in that model, yields an upper bound in the noisy model. A weaker interactive analog of Shannon's coding theorem, which made use of randomization in the simulation process, was given by the author in [26] and <ref> [27] </ref>. The present result was presented in preliminary form in [28]. The binary symmetric channel (BSC) is a simple noise model which nevertheless captures the chief difficulties of the problem considered in this paper; therefore we have focussed on it. <p> for computation on noisy gates, and the extent to which these gates might be said to have a finite (nonzero) capacity for computation. (Here, as for channel transmission, noiseless encoding and decoding of the data before and after the computation are allowed.) Acknowledgments This research was conducted at MIT (see <ref> [26, 27] </ref> for preliminary presentations and related work) and at U. C. Berkeley (see [28]). Thanks to my advisor Mike Sipser whose oversight and encouragement in the early stages of this work were invaluable.
Reference: [28] <author> L. J. Schulman. </author> <title> Deterministic coding for interactive communication. </title> <booktitle> In Proceedings of the 25th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 747-756, </pages> <year> 1993. </year>
Reference-contexts: A weaker interactive analog of Shannon's coding theorem, which made use of randomization in the simulation process, was given by the author in [26] and [27]. The present result was presented in preliminary form in <ref> [28] </ref>. The binary symmetric channel (BSC) is a simple noise model which nevertheless captures the chief difficulties of the problem considered in this paper; therefore we have focussed on it. However with little additional effort our result can be extended to far more general channels. <p> C. Berkeley (see <ref> [28] </ref>). Thanks to my advisor Mike Sipser whose oversight and encouragement in the early stages of this work were invaluable.
Reference: [29] <author> C. E. Shannon. </author> <title> A mathematical theory of communication. </title> <journal> Bell System Tech. J., </journal> <volume> 27 </volume> <pages> 379-423; 623-656, </pages> <year> 1948. </year>
Reference-contexts: Said another way, the "rate" of the simulation (number of protocol steps simulated per transmission) goes to zero as T increases. Shannon considered this matter in 1948 in his seminal study of communication <ref> [29] </ref>. Shannon studied the case of "one-way" communication problems, i.e. data transmission. <p> The original proof of such a theorem appears in <ref> [29] </ref> (formulated already for the more general class of Markov channels). The ramifications of this insight for data transmission have been explored in coding theory and information theory. Recently, in computer science, communication has come to be critical to distributed computing, parallel computing, and the performance of VLSI chips.
Reference: [30] <author> C. E. Shannon. </author> <title> Two-way communication channels. </title> <booktitle> Proc. 4th Berkeley Symp. </booktitle> <institution> Math. Stat. and Prob. </institution> <note> (reprinted in Key Papers in Information Theory, </note> <editor> D. Slepian, ed., </editor> <publisher> IEEE Press, </publisher> <year> 1974), </year> <pages> 1 611-644, </pages> <year> 1961. </year>
Reference-contexts: In this regard one may also want to keep in mind the work of Shannon on two-way channels with a joint constraint on capacity <ref> [30] </ref>. In the above context, we mention that the use of randomness as a resource must be considered carefully. If it is allowed, then one should compare randomized complexities in both the noiseless and noisy settings.
Reference: [31] <author> M. C. Taylor. </author> <title> Reliable information storage in memories designed from unreliable components. </title> <journal> Bell System Tech. J., </journal> <volume> 47(10) </volume> <pages> 2299-2337, </pages> <year> 1968. </year>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. [33, 21, 23, 22, 2, 3, 8, 11, 25, 6]), (as have noisy cellular automata, <ref> [31, 9, 10] </ref>) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [32] <author> C. D. Thompson. </author> <title> Area-time complexity for VLSI. </title> <booktitle> In Proceedings of the 11th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 81-88, </pages> <year> 1979. </year>
Reference-contexts: Yao in 3 1979 [36] to measure the cost incurred in departing from the single-processor model of computation. It has been intensively investigated (e.g. <ref> [37, 19, 32, 17] </ref>; and see [18] for a survey). The present work can be viewed as guaranteeing that every upper bound in that model, yields an upper bound in the noisy model.
Reference: [33] <author> J. von Neumann. </author> <title> Probabilistic logics and the synthesis of reliable organisms from unreliable components. </title> <editor> In C. E. Shannon and J. McCarthy, editors, </editor> <booktitle> Automata Studies, </booktitle> <pages> pages 43-98. </pages> <publisher> Princeton University Press, </publisher> <year> 1956. </year> <month> 19 </month>
Reference-contexts: While noisy circuits have been studied in the literature (e.g. <ref> [33, 21, 23, 22, 2, 3, 8, 11, 25, 6] </ref>), (as have noisy cellular automata, [31, 9, 10]) the correspondence between circuits and communication protocols does not appear to extend to the noisy cases of each.
Reference: [34] <author> J. M. Wozencraft. </author> <title> Sequential decoding for reliable communications. </title> <institution> Res. Lab. of Electronics, M.I.T. </institution> <type> Technical Report, 325, </type> <year> 1957. </year>
Reference-contexts: The idea of such a probabilistically constrained search was introduced in the work of Wozencraft, Reiffen, Fano and others <ref> [34, 24, 7] </ref> on sequential decoding.
Reference: [35] <author> A. C. Yao. </author> <title> Probabilistic computations: Toward a unified measure of complexity. </title> <booktitle> In Proceedings of the 18th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 222-227, </pages> <year> 1977. </year>
Reference-contexts: Now define the complexity C BECF of the problem as the product of the previous quantity with the capacity of the channel. Let C R BECF denote the corresponding quantity on a specified distribution R on input pairs. Recall the distributional complexity D for noiseless channels <ref> [35] </ref>, which is defined as the maximum over distributions on input pairs, of the minimum over protocols, of the expected number of transmissions until the problem is solved. Let D R denote the corresponding quantity on a specified distribution R on input pairs.
Reference: [36] <author> A. C. Yao. </author> <title> Some complexity questions related to distributive computing. </title> <booktitle> In Proceedings of the 11th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 209-213, </pages> <year> 1979. </year>
Reference-contexts: It is enough just to bring the redundancy above the threshold value 1=C. For a noiseless environment, the interactive model for communication problems, in which the input to a problem is split between two processors linked by a noiseless channel, was introduced by A. Yao in 3 1979 <ref> [36] </ref> to measure the cost incurred in departing from the single-processor model of computation. It has been intensively investigated (e.g. [37, 19, 32, 17]; and see [18] for a survey).
Reference: [37] <author> A. C. Yao. </author> <title> The entropic limitations on VLSI computations. </title> <booktitle> In Proceedings of the 13th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 308-311, </pages> <year> 1981. </year> <month> 20 </month>
Reference-contexts: Yao in 3 1979 [36] to measure the cost incurred in departing from the single-processor model of computation. It has been intensively investigated (e.g. <ref> [37, 19, 32, 17] </ref>; and see [18] for a survey). The present work can be viewed as guaranteeing that every upper bound in that model, yields an upper bound in the noisy model.
References-found: 37

