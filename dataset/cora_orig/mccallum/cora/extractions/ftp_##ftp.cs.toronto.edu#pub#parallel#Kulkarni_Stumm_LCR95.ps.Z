URL: ftp://ftp.cs.toronto.edu/pub/parallel/Kulkarni_Stumm_LCR95.ps.Z
Refering-URL: http://www.cs.toronto.edu/~kulki/pubs_abs.html
Root-URL: 
Title: Languages, Compilers and Run-time Systems for Scalable Computers, Chapter  CDA LOOP TRANSFORMATIONS  
Author: Dattatraya Kulkarni and Michael Stumm 
Address: Toronto, Toronto, Canada, M5S 1A4  
Affiliation: Department of Computer Science and Department of Electrical and Computer Engineering University of  
Note: 3, pages 29--42, Kluwer Academic Publishers, Boston, 1995.  
Abstract: In this paper we present a new loop transformation technique called Computation Decomposition and Alignment (CDA). Computation Decomposition first decomposes the iteration space into finer computation spaces. Computation Alignment subsequently, linearly transforms each computation space independently. CDA is a general framework in that linear transformations and its recent extensions are just special cases of CDA. CDA's fine grained loop restructuring can incur considerable computational effort, but can exploit optimization opportunities that earlier frameworks cannot. We present four optimization contexts in which CDA can be useful. Our initial experiments demonstrate that CDA adds a new dimension to performance optimization. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abraham, S.G., and Hudak, D.E., </author> <title> "Compile-time partitioning of iterative parallel loops to reduce cache coherency traffic," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 318-328, </pages> <month> July 91. </month>
Reference-contexts: However, CDA is constrained by dependences and therefore may not be able to eliminate all conflicts. Moreover, CDA may introduce extra loop overhead compared to array padding. Reducing communication for a reference stencil A communication optimal distribution of an array depends on its reference stencil in the loop <ref> [1, 3, 8] </ref>. A CDA can modify the reference stencil, thus providing an additional dimension of optimization in the choice of distribution.
Reference: [2] <author> Allen, R., Callahan, D., and Kennedy, K., </author> <title> "Automatic decomposition of scientific programs for parallel execution," </title> <booktitle> In Conference Record of the 14th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 63-76, </pages> <address> Munich, West Germany, </address> <month> January </month> <year> 1987. </year>
Reference-contexts: Since the new execution order of a statement can be different from that of another statement, CA transformations can alter the constitution of the iterations. A statement is, however, always mapped in its entirety. The origins of the basic idea in CA can be traced to loop alignment <ref> [2, 18] </ref> which is a special case of CA. The statement level transformation retains the advantages of linear transformations while enabling additional code optimizations.
Reference: [3] <author> Ancourt, C. and Irigoin, F., </author> <title> "Scanning polyhedra with DO loops," </title> <booktitle> In Proceedings of the 3rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <volume> volume 26, </volume> <pages> pages 39-50, </pages> <address> Williamsburg, VA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: However, CDA is constrained by dependences and therefore may not be able to eliminate all conflicts. Moreover, CDA may introduce extra loop overhead compared to array padding. Reducing communication for a reference stencil A communication optimal distribution of an array depends on its reference stencil in the loop <ref> [1, 3, 8] </ref>. A CDA can modify the reference stencil, thus providing an additional dimension of optimization in the choice of distribution.
Reference: [4] <author> Anderson, J. and Lam, M., </author> <title> "Global optimizations for parallelism and locality on scalable parallel machines," </title> <booktitle> In Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <volume> volume 28, </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: Second, the framework allowed the development of a set of generic techniques to transform loops in a systematic way, independent of the nature of transformations in the compound transformation. Finally, it made possible semi-quantitative evaluation of candidate transformations <ref> [4, 13, 15, 22] </ref>. A linear transformation changes the structure of a loop so as to change the execution order of the iterations.
Reference: [5] <author> Banerjee, U., </author> <title> "Unimodular transformations of double loops," </title> <booktitle> In Proceedings of Third Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <address> Irvine, CA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: 1 INTRODUCTION The introduction of linear transformations in 1990 as an algebraic framework for loop optimization <ref> [5, 22] </ref> was a major contribution for three reasons: First, the framework provides a unified approach to loop restructuring since most existing loop transformations [19, 23] and arbitrary sequences of these transformations can be represented by a single transformation matrix.
Reference: [6] <author> P. Feautrier. </author> <title> Dataflow analysis of array and scalar references. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20, </volume> <year> 1991. </year>
Reference-contexts: If the dependences are non-uniform, then more sophisticated techniques are necessary, such as those that reason with symbolic affine constraints <ref> [6, 20] </ref>. There are cases, when the only violated dependences are (0) flow dependences between statements and textual interchange will then suffice to make these positive again. The new loop bounds have to account for each of the transformed computation spaces.
Reference: [7] <author> Gilbert, J. and Schreiber, R., </author> <title> "Optimal expression evaluation for data parallel architectures," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13 </volume> <pages> 58-64, </pages> <year> 1991. </year>
Reference-contexts: The example of Figure 2 also shows that in general CDA can be viewed to be implementing a class of flexible computation <ref> [7] </ref> rules with the aid of a fixed computation rule such as owner-computes. The original statement S 1 is executed in parts by two processors instead of the owner of A (i; j) alone.
Reference: [8] <author> Irigoin, F. and Triolet, R., </author> <title> "Supernode partitioning," </title> <booktitle> In Conference Record of the 15th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 319-329, </pages> <address> San Diego, CA, </address> <year> 1988. </year>
Reference-contexts: However, CDA is constrained by dependences and therefore may not be able to eliminate all conflicts. Moreover, CDA may introduce extra loop overhead compared to array padding. Reducing communication for a reference stencil A communication optimal distribution of an array depends on its reference stencil in the loop <ref> [1, 3, 8] </ref>. A CDA can modify the reference stencil, thus providing an additional dimension of optimization in the choice of distribution.
Reference: [9] <author> Kelly, W. and Pugh, W., </author> <title> "A framework for unifying reordering transformations," </title> <type> Technical Report UMIACS-TR-92-126, </type> <institution> University of Maryland, </institution> <year> 1992. </year>
Reference-contexts: In the last three years Computational Alignment (CA) frameworks have been proposed that extend linear transformations <ref> [9, 11, 21] </ref>. CA applies a separate linear transformation to each statement in the loop body. Since the new execution order of a statement can be different from that of another statement, CA transformations can alter the constitution of the iterations. A statement is, however, always mapped in its entirety. <p> We can now employ CA to transform each statement of the new loop body <ref> [9, 11, 21] </ref>. Analogous to the iteration space, the computation space of a statement S, CS (S), is an integer space representing all execution instances of S in the loop. A separate linear transformation is applied to each computation space. <p> An algorithm to generate a guard-free loop for T when all statements require the same loop stride is described in Kelly et al <ref> [9] </ref>. They also developed an algorithm to generate code for general linear transformations but with conditionals [10]. These algorithms reduce to the algorithm developed by Torres et al. when the transformations are simple offsets corresponding to loop alignments [21].
Reference: [10] <author> Kelly, W., Pugh, W., and Rosser, E., </author> <title> "Code generation for multiple mappings," </title> <type> Technical Report UMIACS-TR-94-87, </type> <institution> University of Maryland, </institution> <year> 1994. </year>
Reference-contexts: An algorithm to generate a guard-free loop for T when all statements require the same loop stride is described in Kelly et al [9]. They also developed an algorithm to generate code for general linear transformations but with conditionals <ref> [10] </ref>. These algorithms reduce to the algorithm developed by Torres et al. when the transformations are simple offsets corresponding to loop alignments [21]. For completeness, we illustrate a typical way to generate guard free code in a loop with two statements S 1 and S 2 .
Reference: [11] <author> Kulkarni, D. and Stumm, M., </author> <title> "Computational alignment: A new, unified program transformation for local and global optimization," </title> <type> Technical Report CSRI-292, </type> <institution> Computer Systems Research Institute, University of Toronto, </institution> <month> January </month> <year> 1994. </year> <note> http://www.eecg.toronto.edu/EECG/RESEARCH/ParallelSys. CDA Loop Transformations 15 </note>
Reference-contexts: In the last three years Computational Alignment (CA) frameworks have been proposed that extend linear transformations <ref> [9, 11, 21] </ref>. CA applies a separate linear transformation to each statement in the loop body. Since the new execution order of a statement can be different from that of another statement, CA transformations can alter the constitution of the iterations. A statement is, however, always mapped in its entirety. <p> We can now employ CA to transform each statement of the new loop body <ref> [9, 11, 21] </ref>. Analogous to the iteration space, the computation space of a statement S, CS (S), is an integer space representing all execution instances of S in the loop. A separate linear transformation is applied to each computation space.
Reference: [12] <author> Kulkarni, D., Stumm, M., Unrau, R., and Li, W., </author> <title> "A generalized theory of linear loop transformations," </title> <type> Technical Report CSRI-317, </type> <institution> Computer Systems Research Institute, University of Toronto, </institution> <month> December </month> <year> 1994. </year> <note> http://www.eecg.toronto.edu/EECG/RESEARCH/ParallelSys. </note>
Reference-contexts: Listings of the original and transformed loops, details of the applied CDA, and all of the measurement data can be found in <ref> [12] </ref>. SLIA Objective: Removal of data alignment constraints. SLIA is a synthetic two dimensional loop with i c references to three arrays A, B, and C [12]. The original loop needs data alignment of both (fl; j 1) and (fl; j) references of arrays to A (i; j). <p> Listings of the original and transformed loops, details of the applied CDA, and all of the measurement data can be found in <ref> [12] </ref>. SLIA Objective: Removal of data alignment constraints. SLIA is a synthetic two dimensional loop with i c references to three arrays A, B, and C [12]. The original loop needs data alignment of both (fl; j 1) and (fl; j) references of arrays to A (i; j). Clearly, a data alignment can satisfy only one reference pattern to A (i; j), not both. We applied CDA to remove the (fl; j 1) data alignment constraints.
Reference: [13] <author> Kumar, K.G., Kulkarni, D., and Basu, A., </author> <title> "Deriving good transformations for mapping nested loops on hierarchical parallel machines in polynomial time," </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <address> Washington, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Second, the framework allowed the development of a set of generic techniques to transform loops in a systematic way, independent of the nature of transformations in the compound transformation. Finally, it made possible semi-quantitative evaluation of candidate transformations <ref> [4, 13, 15, 22] </ref>. A linear transformation changes the structure of a loop so as to change the execution order of the iterations.
Reference: [14] <author> C.H. Li. </author> <title> Program wanal1. </title> <note> ftp ftp.cs.rice.edu, </note> <institution> Rice University, </institution> <year> 1992. </year>
Reference-contexts: Because of the shared address space and relatively low cost of remote accesses on the KSR1, the execution time of the transformed code improved by only 17%. Wanal Objective: Improving cache locality. Wanal is a wave equation solver that is part of the Riceps benchmark suite <ref> [14] </ref>. The three dimensional loop we CDA transformed has two statements in its loop body. A linear transformation cannot improve cache locality here, because only one statement requires a loop interchange, while the other does not.
Reference: [15] <author> Li, W. and Pingali, K., </author> <title> "A singular loop transformation framework based on non-singular matrices," </title> <booktitle> In Proceedings of the Fifth Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: Second, the framework allowed the development of a set of generic techniques to transform loops in a systematic way, independent of the nature of transformations in the compound transformation. Finally, it made possible semi-quantitative evaluation of candidate transformations <ref> [4, 13, 15, 22] </ref>. A linear transformation changes the structure of a loop so as to change the execution order of the iterations.
Reference: [16] <author> Mosher, C., </author> <title> "Arco Seismic Benchmarks," </title> <publisher> ARCO E&PT. </publisher>
Reference-contexts: Rtmg Objective: Elimination of cache conflicts on the SUN Sparc 20. The rtmg loop from the Arco Seismic benchmarks suite is a two a dimensional loop with a single statement in the loop body which accesses two dimensional arrays p1 and p2 <ref> [16] </ref>. There are cache conflicts between the lhs reference p1 (i; k) and the rhs reference p2 (i; k) on a Sparc 20 (with a 1MB, direct-mapped cache).
Reference: [17] <institution> NASA, Ames Research Center "NAS Parallel Benchmarks" </institution>
Reference-contexts: Mg Objective: Elimination of cache conflicts on the KSR1. NAS mg is a multigrid solver in the NAS benchmarks suite <ref> [17] </ref>. We CDA transformed the psinv subroutine and were able to improve the speed up by a factor of 2 over the original by eliminating cache conflicts. However, the dependence introduced by CDA reduced the available degree of parallelism.
Reference: [18] <author> Padua, D., </author> <title> "Multiprocessors: Discussion of some theoretical and practical problems," </title> <type> Phd thesis, </type> <institution> University of Illinois, Urbana-Champaign, </institution> <year> 1979. </year>
Reference-contexts: Since the new execution order of a statement can be different from that of another statement, CA transformations can alter the constitution of the iterations. A statement is, however, always mapped in its entirety. The origins of the basic idea in CA can be traced to loop alignment <ref> [2, 18] </ref> which is a special case of CA. The statement level transformation retains the advantages of linear transformations while enabling additional code optimizations.
Reference: [19] <author> Padua, D. and Wolfe, M., </author> <title> "Advanced compiler optimizations for supercomputers," </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: 1 INTRODUCTION The introduction of linear transformations in 1990 as an algebraic framework for loop optimization [5, 22] was a major contribution for three reasons: First, the framework provides a unified approach to loop restructuring since most existing loop transformations <ref> [19, 23] </ref> and arbitrary sequences of these transformations can be represented by a single transformation matrix. Second, the framework allowed the development of a set of generic techniques to transform loops in a systematic way, independent of the nature of transformations in the compound transformation.
Reference: [20] <author> Pugh, W. and Wonnacott, D., </author> <title> "An exact method for analysis of value-based array data dependences," </title> <type> Technical Report CS-TR-3196, </type> <institution> University of Maryland, </institution> <year> 1993. </year>
Reference-contexts: If the dependences are non-uniform, then more sophisticated techniques are necessary, such as those that reason with symbolic affine constraints <ref> [6, 20] </ref>. There are cases, when the only violated dependences are (0) flow dependences between statements and textual interchange will then suffice to make these positive again. The new loop bounds have to account for each of the transformed computation spaces.
Reference: [21] <author> Torres, J., Ayguade, E., Labarta, J., and Valero, M., </author> <title> "Align and distribute-based linear loop transformations," </title> <booktitle> In Proceedings of Sixth Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <year> 1993. </year>
Reference-contexts: In the last three years Computational Alignment (CA) frameworks have been proposed that extend linear transformations <ref> [9, 11, 21] </ref>. CA applies a separate linear transformation to each statement in the loop body. Since the new execution order of a statement can be different from that of another statement, CA transformations can alter the constitution of the iterations. A statement is, however, always mapped in its entirety. <p> We can now employ CA to transform each statement of the new loop body <ref> [9, 11, 21] </ref>. Analogous to the iteration space, the computation space of a statement S, CS (S), is an integer space representing all execution instances of S in the loop. A separate linear transformation is applied to each computation space. <p> They also developed an algorithm to generate code for general linear transformations but with conditionals [10]. These algorithms reduce to the algorithm developed by Torres et al. when the transformations are simple offsets corresponding to loop alignments <ref> [21] </ref>. For completeness, we illustrate a typical way to generate guard free code in a loop with two statements S 1 and S 2 . <p> One way to eliminate ownership tests is to ensure that all statement instances in an iteration are to be executed by the same processor. This can be achieved by transforming statements so as to collocate all the lhs references of the loop body if this can be legally done <ref> [21] </ref>. To achieve this in the CDA transformed loop, we first choose a lhs reference, say A (i; j) that serves as a basis. Each temporary array is data aligned so that its lhs reference is collocated with A (i; j).
Reference: [22] <author> Wolf, M. and Lam, M., </author> <title> "An algorithmic approach to compound loop transformation," </title> <booktitle> In Proceedings of Third Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <address> Irvine, CA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: 1 INTRODUCTION The introduction of linear transformations in 1990 as an algebraic framework for loop optimization <ref> [5, 22] </ref> was a major contribution for three reasons: First, the framework provides a unified approach to loop restructuring since most existing loop transformations [19, 23] and arbitrary sequences of these transformations can be represented by a single transformation matrix. <p> Second, the framework allowed the development of a set of generic techniques to transform loops in a systematic way, independent of the nature of transformations in the compound transformation. Finally, it made possible semi-quantitative evaluation of candidate transformations <ref> [4, 13, 15, 22] </ref>. A linear transformation changes the structure of a loop so as to change the execution order of the iterations.
Reference: [23] <author> Wolfe, M., </author> <title> Optimizing supercompilers for supercomputers. </title> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: 1 INTRODUCTION The introduction of linear transformations in 1990 as an algebraic framework for loop optimization [5, 22] was a major contribution for three reasons: First, the framework provides a unified approach to loop restructuring since most existing loop transformations <ref> [19, 23] </ref> and arbitrary sequences of these transformations can be represented by a single transformation matrix. Second, the framework allowed the development of a set of generic techniques to transform loops in a systematic way, independent of the nature of transformations in the compound transformation.
References-found: 23

