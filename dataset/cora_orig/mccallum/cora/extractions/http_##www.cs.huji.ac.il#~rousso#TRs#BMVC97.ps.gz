URL: http://www.cs.huji.ac.il/~rousso/TRs/BMVC97.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~rousso/
Root-URL: http://www.cs.huji.ac.il
Email: Contact E-Mail: peleg@cs.huji.ac.il  
Title: Video Mosaicing using Manifold Projection projection enables to define high-quality mosaicing even for the most
Author: Benny Rousso Shmuel Peleg Ilan Finci 
Note: Manifold  
Address: 91904 Jerusalem, ISRAEL  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Abstract: Video mosaicing is commonly used to increase the visual field of view by pasting together many video frames. Existing mosaicing methods are effective only in very limited cases where the image motion is almost a uniform translation or the camera performs a pure pan. Forward camera motion or camera zoom are very problematic for traditional mosaicing. A mosaicing methodology to allow image mosaicing in the most general cases is presented, where frames in the video sequence are transformed such that the optical flow becomes parallel. This transformation is modelled by a projection of the scene into some manifold. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Fifth International Conference on Computer Vision, </institution> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year> <pages> IEEE-CS. </pages>
Reference: [2] <author> P.J. Burt and P. Anandan. </author> <title> Image stabilization by registration to a reference mosaic. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <pages> pages 457-465, </pages> <address> Monterey, California, November 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [2, 8, 13, 6] </ref>. In these cases images are aligned pairwise, using a parametric transformation like an affine transformation or a planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [3] <author> S.E. Chen and L. Williams. </author> <title> View interpolation for image synthesis. </title> <booktitle> In SIG-GRAPH, </booktitle> <pages> pages 279-288, </pages> <address> Anahiem, California, </address> <month> August </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: For example, we can take a collection of N synthesized in-between images, taking from each interpolated image a strip one pixel wide. In order to synthesize in-between views we can use various methods, such as optical flow interpolation <ref> [3, 14] </ref>, trilinear tensor methods [12], and others. In most cases even approximate methods will give good results for view interpolation. The use of intermediate views for strips collection gives the effect of orthographic projection, which avoids parallax discontinuities.
Reference: [4] <author> T.R. Halfhill. </author> <title> See you around. </title> <journal> Byte Magazine, </journal> <pages> pages 85-90, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Such translations can either be computed by manually pointing to corresponding points, or by image correlation methods. Other simple mosaics are created by rotating the camera around its optical center using a special device, and creating a panoramic image which represents the projection of the scene onto a cylinder <ref> [4, 10, 9, 11] </ref>. But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach.
Reference: [5] <author> R. Hartley and R. Gupta. </author> <title> Linear pushbroom cameras. </title> <editor> In J.O. Eklundh, editor, </editor> <booktitle> Third European Conference on Computer Vision, </booktitle> <pages> pages 555-566, </pages> <address> Stock-holm, Sweden, May 1994. </address> <publisher> Springer. </publisher>
Reference-contexts: In the simple case of a camera which is moving horizontally, vertical strips are taken from each image and pasted side by side [11] (see Fig. 1.a). This process can also be viewed as scanning the scene with a vertical broom <ref> [5, 16] </ref>. This vertical broom scans the entire sequence, extracts vertical strips along the sequence, and pastes them one next to the other to create the panoramic mosaic.
Reference: [6] <author> M. Irani, P. Anandan, and S. Hsu. </author> <title> Mosaic based representations of video sequences and their applications. </title> <booktitle> In Fifth International Conference on Computer Vision [1], </booktitle> <pages> pages 605-611. </pages>
Reference-contexts: A more common solution is photo-mosaicing: aligning, and pasting, frames in a video sequence, which enables a more complete view. Digital photography enabled new implementations for mo-saicing <ref> [13, 6, 15] </ref>, which were first applied to aerial and satellite images, and later used for scene and object representation. The simplest mosaics are created from a set of images whose mutual displacements are pure image-plane translations. <p> But the limitations to motion which is a pure rotation about the optical center limits the applicability of this approach. In more general camera motions, that may include both camera translations and small camera rotations, more general transformation for image alignment are used <ref> [2, 8, 13, 6] </ref>. In these cases images are aligned pairwise, using a parametric transformation like an affine transformation or a planar-projective transformation. A reference frame is selected, and all images are aligned with this reference frame and combined to create the panoramic mosaic.
Reference: [7] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Detecting and tracking multiple moving objects using temporal integration. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Second European </booktitle>
Reference-contexts: The following section describes a practical implementation for determining the shape of the scanning broom for the case of affine motion, which can give good approximation for image motion in many cases. Numerous methods exist to recover the parameters of an affine transformation <ref> [7, 13] </ref>.
References-found: 7

