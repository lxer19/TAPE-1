URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/umsi-98-98.ps.gz
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/
Root-URL: http://www.cs.umn.edu
Title: Enhanced Multi-Level Block ILU Preconditioning Strategies for General Sparse Linear Systems  
Author: Yousef Saad and Jun Zhang 
Keyword: Key words: Incomplete LU factorization, multi-level ILU preconditioner, Krylov subspace methods, multi-elimination ILU factorization, algebraic multigrid method.  
Note: AMS subject classifications: 65F10, 65F50, 65N55, 65Y05.  
Date: May 27, 1998  
Address: 4-192 EE/CS Building, 200 Union Street S.E., Minneapolis, MN 55455  
Affiliation: Department of Computer Science and Engineering, University of Minnesota,  
Abstract: This paper introduces several strategies to deal with pivot blocks in multi-level block incomplete LU factorization (BILUM) preconditioning techniques. These techniques are aimed at increasing the robustness and controlling the amount of fill-ins of BILUM for solving large sparse linear systems when large size blocks are used to form block independent set. Techniques proposed in this paper include double dropping strategies, approximate singular value decomposition, variable size blocks and use of arrowhead block submatrix. We point out the advantages and disadvantages of the new techniques and discuss their efficient implementations. Numerical experiments are conducted to show the usefulness of the new techniques in dealing with hard-to-solve problems arising from computational fluid dynamics. In addition, we discuss the relation between multi-level ILU preconditioning methods and algebraic multi-level methods.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <title> LAPACK Users' Guide, Second Edition. </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1995. </year>
Reference-contexts: An additional array is needed to store the size of each block and an additional pointer array is needed for the starting position of each block. The inverse of each block may be computed using a LAPACK routine <ref> [1] </ref>, using skyline blocks, or employing the approximate singular value decomposition technique. The latter two techniques will be described next. 3.3 Skyline blocks Let G be the set of edges of the adjacency graph of a given matrix.
Reference: [2] <author> O. Axelsson. </author> <title> Iterative Solution Methods. </title> <publisher> Cambridge Univ. Press, </publisher> <address> Cambridge, </address> <year> 1994. </year>
Reference-contexts: Another research direction in algebraic multi-level preconditioning methods is towards the analysis of such methods for solving regularly structured problems arising from finite element or finite difference discretization of partial differential equations <ref> [2, 4, 3, 6, 12] </ref>. Although these results are restricted to structured matrices, they support a theory of near optimality of algebraic multi-level preconditioning methods for certain problems [25, 26].

Reference: [4] <author> O. Axelsson and P. S. Vassilevski. </author> <title> Algebraic multilevel preconditioning methods. II. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 27(6) </volume> <pages> 1569-1590, </pages> <year> 1990. </year>
Reference-contexts: Another research direction in algebraic multi-level preconditioning methods is towards the analysis of such methods for solving regularly structured problems arising from finite element or finite difference discretization of partial differential equations <ref> [2, 4, 3, 6, 12] </ref>. Although these results are restricted to structured matrices, they support a theory of near optimality of algebraic multi-level preconditioning methods for certain problems [25, 26].
Reference: [5] <author> R. E. Bank, T. F. Dupont, and H. Yserentant. </author> <title> The hierarchical basis multigrid method. </title> <journal> Numer. Math., </journal> <volume> 52 </volume> <pages> 427-458, </pages> <year> 1988. </year>
Reference-contexts: Although these results are restricted to structured matrices, they support a theory of near optimality of algebraic multi-level preconditioning methods for certain problems [25, 26]. The multi-level structure of BILUM is more similar to the hierarchical basis multigrid method <ref> [5] </ref> than to the standard multigrid method. For example, each unknown of the linear system is uniquely associated with exactly one level. Hence, unknowns on the coarse level are not represented on the fine level and vice versa.
Reference: [6] <author> R. E. Bank and C. Wagner. </author> <title> Multilevel ILU decomposition. </title> <type> Technical report, </type> <institution> Department of Mathematics, University of California at San Diego, La Jolla, </institution> <address> CA, </address> <year> 1997. </year>
Reference-contexts: Another research direction in algebraic multi-level preconditioning methods is towards the analysis of such methods for solving regularly structured problems arising from finite element or finite difference discretization of partial differential equations <ref> [2, 4, 3, 6, 12] </ref>. Although these results are restricted to structured matrices, they support a theory of near optimality of algebraic multi-level preconditioning methods for certain problems [25, 26].
Reference: [7] <author> A. Bjork. </author> <title> Numerical Methods for Least-Squares Problems. </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, PA, </address> <year> 1996. </year>
Reference-contexts: Thus, some elements of 1 may be very large if some of its singular values are small. Standard methods for properly `inverting' a singular or nearly singular matrix are referred to as 'regularization' <ref> [7] </ref>. The most common method used is to add a constant to all singular values in order to move the smaller ones away from zero. This is referred to as Tychonov regularization [7, p. 101] and is mathematically equivalent to solving a damped least-squares problem with the matrix B. <p> Standard methods for properly `inverting' a singular or nearly singular matrix are referred to as 'regularization' [7]. The most common method used is to add a constant to all singular values in order to move the smaller ones away from zero. This is referred to as Tychonov regularization <ref> [7, p. 101] </ref> and is mathematically equivalent to solving a damped least-squares problem with the matrix B. We use a variation of this regularization approach which consists of perturbing only the smallest singular values. A similar strategy was advocated in [17].
Reference: [8] <author> E. F. F. Botta, A. van der Ploeg, and F. W. Wubs. </author> <title> Nested grids ILU-decomposition (NGILU). </title> <journal> J. Comput. Appl. Math., </journal> <volume> 66 </volume> <pages> 515-526, </pages> <year> 1996. </year>
Reference-contexts: This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., [9, 11, 27, 31, 35]. Some of these methods <ref> [8, 27] </ref> take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques. As pointed out in [34], the major difference of these two types of methods are the choice of the reduced system (the coarse level system). <p> Solve with a relative tolerance *: 7. A last x last := x last . 8. For j = last 1; : : : ; 1; 0, do backward sweep: 9. y j := D 1 1 This may be viewed as a domain-based multi-level method. Other methods <ref> [8, 27] </ref> choose to list the unknowns of the independent set last and may be viewed as grid-based multi-level methods. 3 9a. y j := D 1 10. Apply inverse permutation P T j to the solution y j . 11. End do.
Reference: [9] <author> E. F. F. Botta and F. W. Wubs. MRILU: </author> <title> an effective algebraic multi-level ILU-preconditioner for sparse matrices. </title> <note> SIAM J. Matrix Anal. Appl. to appear. </note>
Reference-contexts: Thus, a judicious combination of both methods may result in a powerful general-purpose iterative solver. This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., <ref> [9, 11, 27, 31, 35] </ref>. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques. <p> This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., [9, 11, 27, 31, 35]. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others <ref> [9, 31, 35] </ref> are more akin to domain decomposition techniques. As pointed out in [34], the major difference of these two types of methods are the choice of the reduced system (the coarse level system). <p> BILUM combines the generality of Krylov subspace methods and the robustness of the ILU factorization techniques with the scalability of multigrid methods. The tests show near grid-independent convergence for certain type of problems <ref> [9, 35] </ref>. Yet, BILUM can be constructed purely algebraically and requires no physical grid information (although such information, if available, may be used to facilitate preconditioner construction and increase robustness of the resulting preconditioner [36]).
Reference: [10] <author> W. L. Briggs. </author> <title> A Multigrid Tutorial. </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1987. </year>
Reference-contexts: Each of the two classes of methods contains a rich variety of methods and each has its own advantages and disadvantages. An attractive feature of the multigrid method is its grid-independent convergence and optimal scalability <ref> [10, 39] </ref>. For certain type of problems, the CPU and memory costs are proportional to the size of the problems. The obvious disadvantage of multigrid methods is their limited applicability.
Reference: [11] <author> T. F. Chan and V. Eijkhout. ParPre: </author> <title> a parallel preconditioners package reference manual for version 2.0.17. </title> <type> Technical Report CAM 97-24, </type> <institution> Department of Mathematics, UCLA, </institution> <address> Los Angeles, CA, </address> <year> 1997. </year>
Reference-contexts: Thus, a judicious combination of both methods may result in a powerful general-purpose iterative solver. This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., <ref> [9, 11, 27, 31, 35] </ref>. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques.
Reference: [12] <author> T. F. Chan, S. Go, and J. Zou. </author> <title> Multilevel domain decomposition and multigrid methods for unstructured meshes: algorithms and theory. </title> <type> Technical Report CAM 95-24, </type> <institution> Department of Mathematics, UCLA, </institution> <address> Los Angeles, CA, </address> <year> 1995. </year>
Reference-contexts: Another research direction in algebraic multi-level preconditioning methods is towards the analysis of such methods for solving regularly structured problems arising from finite element or finite difference discretization of partial differential equations <ref> [2, 4, 3, 6, 12] </ref>. Although these results are restricted to structured matrices, they support a theory of near optimality of algebraic multi-level preconditioning methods for certain problems [25, 26].
Reference: [13] <author> T. F. Chan and T. P. Mathew. </author> <title> Domain decomposition algorithms. </title> <booktitle> In Acta Numerica, </booktitle> <year> 1994, </year> <pages> pages 61-143, </pages> <address> Cambridge, 1994. </address> <publisher> Cambridge Univ. Press. </publisher>
Reference-contexts: In the successive Schur complement matrices obtained, each block contains the internal nodes of a subdomain. The inverse and application of all blocks on the same level can be done in parallel. What distinguishes BILUM from traditional domain decomposition methods <ref> [13, 24] </ref> is that all subdomains are constructed algebraically and exploit no physical information.
Reference: [14] <author> Q. S. Chang, Y. S. Wong, and L. Z. Feng. </author> <title> New interpolation formulas of using geometric assumptions in the algebraic multigrid method. </title> <journal> Appl. Math. Comput., </journal> <volume> 50(2-3):223-254, </volume> <year> 1992. </year> <month> 16 </month>
Reference-contexts: Full multigrid efficiency can only be achieved for problems associated with certain types of Partial Differential Equations defined on regularly structured domains which have sufficient regularity. Though some algebraic multigrid (AMG) methods have been designed to deal with more general problems <ref> [14, 15, 28, 29] </ref>, the success of such methods and the type of problems solved are still limited. There seems to exist no fl This work was supported in part by NSF under grant CCR-9618827 and in part by the Minnesota Supercomputer Institute. y E-mail: saad@cs.umn.edu. <p> It is unclear in AMG what are the best inter-grid (level) transfer operators. Recent advances have been reported on improving the quality and accuracy of these operators by proposing different formulas <ref> [14, 15] </ref>. On the other hand, BILUM provides a coherent and natural way to define the inter-level transfer operators that are suitable for general sparse matrices.
Reference: [15] <author> Q. S. Chang, Y. S. Wong, and H. Q. Fu. </author> <title> On the algebraic multigrid method. </title> <journal> J. Comput. Phys., </journal> <volume> 125 </volume> <pages> 279-292, </pages> <year> 1996. </year>
Reference-contexts: Full multigrid efficiency can only be achieved for problems associated with certain types of Partial Differential Equations defined on regularly structured domains which have sufficient regularity. Though some algebraic multigrid (AMG) methods have been designed to deal with more general problems <ref> [14, 15, 28, 29] </ref>, the success of such methods and the type of problems solved are still limited. There seems to exist no fl This work was supported in part by NSF under grant CCR-9618827 and in part by the Minnesota Supercomputer Institute. y E-mail: saad@cs.umn.edu. <p> It is unclear in AMG what are the best inter-grid (level) transfer operators. Recent advances have been reported on improving the quality and accuracy of these operators by proposing different formulas <ref> [14, 15] </ref>. On the other hand, BILUM provides a coherent and natural way to define the inter-level transfer operators that are suitable for general sparse matrices.
Reference: [16] <author> E. Chow. </author> <title> Robust Preconditioning Technique for Sparse Linear Systems. </title> <type> PhD thesis, </type> <institution> University of Minnesota, Minneapolis, MN, </institution> <year> 1997. </year>
Reference-contexts: These matrices were extracted from the test problems provided in the FIDAP package [19]. They model the incompressible Navier-Stokes equations. Several of these matrices contain small or zero diagonal values <ref> [16, 18] </ref> and have a block structure of the form C 0 where 0 is a zero block. The zero diagonals are due to the incompressibility condition of the Navier-Stokes equations [18]. The substantial amount of zero diagonals makes these matrices indefinite.
Reference: [17] <author> E. Chow and Y. Saad. </author> <title> Approximate inverse techniques for block-partitioned matrices. </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 18 </volume> <pages> 1657-1675, </pages> <year> 1997. </year>
Reference-contexts: Direct inversion of these near singular matrices leads to large elements in the inverse and the resulting preconditioner is less efficient. A common strategy to mitigate this problem in developing preconditioners is to perturb the Singular Value Decomposition (SVD) of the block submatrix <ref> [17] </ref>. <p> This is referred to as Tychonov regularization [7, p. 101] and is mathematically equivalent to solving a damped least-squares problem with the matrix B. We use a variation of this regularization approach which consists of perturbing only the smallest singular values. A similar strategy was advocated in <ref> [17] </ref>. We replace the smallest singular values of by larger values. Specifically, given a threshold parameter ! &gt; 0, the singular values i such that i &lt; ! are replaced by ! + i . This may be done dynamically with a threshold strategy. <p> However, the dropping strategy for the blocks should be related to the dropping strategies used to control other parts of the LU factorization and to set an overall dropping level that is consistent throughout the construction of the BILUM factors. On the other hand, some approximate inverse techniques <ref> [17] </ref> may be used to compute sparse approximate inverses of the large size blocks. 4.2 Approximate SVD technique We run tests with two matrices from the FIDAP collection 5 using the approximate SVD technique. These matrices were extracted from the test problems provided in the FIDAP package [19].
Reference: [18] <author> E. Chow and Y. Saad. </author> <title> Experimental study of ILU preconditioners for indefinite matrices. </title> <journal> J. Comput. Appl. Math., </journal> <volume> 86(2) </volume> <pages> 387-414, </pages> <year> 1997. </year>
Reference-contexts: These matrices were extracted from the test problems provided in the FIDAP package [19]. They model the incompressible Navier-Stokes equations. Several of these matrices contain small or zero diagonal values <ref> [16, 18] </ref> and have a block structure of the form C 0 where 0 is a zero block. The zero diagonals are due to the incompressibility condition of the Navier-Stokes equations [18]. The substantial amount of zero diagonals makes these matrices indefinite. <p> They model the incompressible Navier-Stokes equations. Several of these matrices contain small or zero diagonal values [16, 18] and have a block structure of the form C 0 where 0 is a zero block. The zero diagonals are due to the incompressibility condition of the Navier-Stokes equations <ref> [18] </ref>. The substantial amount of zero diagonals makes these matrices indefinite. Standard ILU preconditioners may fail to converge for solving these matrices unless a small t and a large p are used.
Reference: [19] <author> M. Engelman. FIDAP: </author> <title> Examples Manual, Revision 6.0. </title> <type> Technical report, </type> <institution> Fluid Dynamics International, </institution> <address> Evanston, IL, </address> <year> 1991. </year>
Reference-contexts: These matrices were extracted from the test problems provided in the FIDAP package <ref> [19] </ref>. They model the incompressible Navier-Stokes equations. Several of these matrices contain small or zero diagonal values [16, 18] and have a block structure of the form C 0 where 0 is a zero block. The zero diagonals are due to the incompressibility condition of the Navier-Stokes equations [18].
Reference: [20] <author> G. H. Golub and J. M. Ortega. </author> <title> Scientific Computing: An Introduction with Parallel Computing. </title> <publisher> Academic Press, </publisher> <address> Boston, MA, </address> <year> 1993. </year>
Reference-contexts: Note that the seed node must be listed as the last one in order to have a downward arrowhead. If it is listed as the first one, we will have an upward arrowhead matrix which is the worst matrix for LU factorization in terms of controlling fill-ins <ref> [20, p. 228] </ref>. In what follows a skyline or an arrowhead matrix will mean a downward arrowhead matrix. 4 We assume that the matrix B is structurally symmetric.
Reference: [21] <author> G. H. Golub and H. A. van der Vorst. </author> <title> Closer to the solution: iterative linear solvers. </title> <editor> In I. S. Duff and G. A. Watson, editors, </editor> <booktitle> The State of the Art in Numerical Analysis, </booktitle> <pages> pages 63-92, </pages> <address> Oxford, 1997. </address> <publisher> Clarendon Press. </publisher>
Reference-contexts: The above discussion suggests that multigrid and Krylov subspace methods are complementary in that one method's weakness is a strength of the other. Thus, a judicious combination of both methods may result in a powerful general-purpose iterative solver. This idea has been suggested by several authors <ref> [21, 31, 35] </ref> and some results using this type of methods have appeared in the literature, see e.g., [9, 11, 27, 31, 35]. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques.
Reference: [22] <author> G. H. Golub and C. F. van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, MD, </address> <year> 1983. </year>
Reference-contexts: In other words, suppose the SVD of the matrix B is B = U V T ; (12) where U and V are two orthogonal matrices and = diag [ 1 ; 2 ; : : : ; s ], with 1 2 s 0: See Theorem 2.3-1 of <ref> [22, p. 16-17] </ref> for details on the SVD factorization. It is well-known that kBk 2 = 1 . If B is ill-conditioned or near-singular, some of its small singular values are close to zero.
Reference: [23] <author> M. M. Gupta, R. .P. Manohar, and J. W. Stephenson. </author> <title> A single cell high order scheme for the convection-diffusion equation with variable coefficients. </title> <journal> Int. J. Numer. Methods Fluids, </journal> <volume> 4 </volume> <pages> 614-615, </pages> <year> 1984. </year>
Reference-contexts: We report tests with the block sparsification strategy for solving the 9-POINT and VENKAT01 matrices here. The 9-POINT matrix was first used in [35] and is from a 9-point fourth-oder compact finite difference discretization of a convection-diffusion equation with a Reynolds number 10 4 <ref> [23] </ref>. It has 40; 000 unknowns and 357; 604 nonzeros. For the 9-POINT matrix, we used a single dropping strategy with t = 0:01 and 0:1, and blocks of uniform size s = 20. The title ~p=s indicates the number of elements kept in each row of the blocks.
Reference: [24] <author> J. Mandel. </author> <title> Balancing domain decomposition. </title> <journal> Comm. Appl. Numer. Methods, </journal> <volume> 9 </volume> <pages> 233-241, </pages> <year> 1993. </year>
Reference-contexts: In the successive Schur complement matrices obtained, each block contains the internal nodes of a subdomain. The inverse and application of all blocks on the same level can be done in parallel. What distinguishes BILUM from traditional domain decomposition methods <ref> [13, 24] </ref> is that all subdomains are constructed algebraically and exploit no physical information. <p> However, the approximate Schur complement must be computed and sparsified. 3.4 Singular Value Decomposition Each block submatrix must be inverted in the factorization process. However, it may sometimes happen that a block is singular or nearly singular. This is not uncommon, for example, in traditional domain decomposition approaches <ref> [24] </ref>. Direct inversion of these near singular matrices leads to large elements in the inverse and the resulting preconditioner is less efficient. A common strategy to mitigate this problem in developing preconditioners is to perturb the Singular Value Decomposition (SVD) of the block submatrix [17].
Reference: [25] <author> Y. Notay and Z. Ould Amar. </author> <title> Incomplete factorization preconditioning may lead to multigrid like speed of convergence. </title> <editor> In A. S. Alekseev and N. S. Bakhvalov, editors, </editor> <booktitle> Advanced Mathematics: Computation and Applications, </booktitle> <pages> pages 435-446, </pages> <address> Novosibirsk, Russia, 1996. </address> <publisher> NCC Publisher. </publisher>
Reference-contexts: Although these results are restricted to structured matrices, they support a theory of near optimality of algebraic multi-level preconditioning methods for certain problems <ref> [25, 26] </ref>. The multi-level structure of BILUM is more similar to the hierarchical basis multigrid method [5] than to the standard multigrid method. For example, each unknown of the linear system is uniquely associated with exactly one level.
Reference: [26] <author> Y. Notay and Z. Ould Amar. </author> <title> A nearly optimal preconditioning based on recursive red-black orderings. </title> <journal> Numer. Linear Algebra Appl., </journal> <volume> 4 </volume> <pages> 369-391, </pages> <year> 1997. </year>
Reference-contexts: Although these results are restricted to structured matrices, they support a theory of near optimality of algebraic multi-level preconditioning methods for certain problems <ref> [25, 26] </ref>. The multi-level structure of BILUM is more similar to the hierarchical basis multigrid method [5] than to the standard multigrid method. For example, each unknown of the linear system is uniquely associated with exactly one level.
Reference: [27] <author> A. A. Reusken. </author> <title> Approximate cyclic reduction preconditioning. </title> <type> Technical Report RANA 97-02, </type> <institution> Department of Mathematics and Computing Science, Eindhoven University of Technology, The Nether-lands, </institution> <year> 1997. </year>
Reference-contexts: Thus, a judicious combination of both methods may result in a powerful general-purpose iterative solver. This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., <ref> [9, 11, 27, 31, 35] </ref>. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques. <p> This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., [9, 11, 27, 31, 35]. Some of these methods <ref> [8, 27] </ref> take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques. As pointed out in [34], the major difference of these two types of methods are the choice of the reduced system (the coarse level system). <p> Solve with a relative tolerance *: 7. A last x last := x last . 8. For j = last 1; : : : ; 1; 0, do backward sweep: 9. y j := D 1 1 This may be viewed as a domain-based multi-level method. Other methods <ref> [8, 27] </ref> choose to list the unknowns of the independent set last and may be viewed as grid-based multi-level methods. 3 9a. y j := D 1 10. Apply inverse permutation P T j to the solution y j . 11. End do.
Reference: [28] <author> J. W. Ruge and K. Stuben. </author> <title> Efficient solution of finite difference and finite element equations. </title> <editor> In D. J. Paddon and H. Holstein, editors, </editor> <title> Multigrid Methods for Integral and Differential Equations, </title> <address> pages 169-212, Oxford, 1985. </address> <publisher> Clarendon Press. </publisher>
Reference-contexts: Full multigrid efficiency can only be achieved for problems associated with certain types of Partial Differential Equations defined on regularly structured domains which have sufficient regularity. Though some algebraic multigrid (AMG) methods have been designed to deal with more general problems <ref> [14, 15, 28, 29] </ref>, the success of such methods and the type of problems solved are still limited. There seems to exist no fl This work was supported in part by NSF under grant CCR-9618827 and in part by the Minnesota Supercomputer Institute. y E-mail: saad@cs.umn.edu.
Reference: [29] <author> J. W. Ruge and K. Stuben. </author> <title> Algebraic multigrid. </title> <editor> In S. McCormick, editor, </editor> <title> Multigrid Methods, Frontiers in Appl. </title> <journal> Math., </journal> <volume> chapter 4, </volume> <pages> pages 73-130. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1987. </year>
Reference-contexts: Full multigrid efficiency can only be achieved for problems associated with certain types of Partial Differential Equations defined on regularly structured domains which have sufficient regularity. Though some algebraic multigrid (AMG) methods have been designed to deal with more general problems <ref> [14, 15, 28, 29] </ref>, the success of such methods and the type of problems solved are still limited. There seems to exist no fl This work was supported in part by NSF under grant CCR-9618827 and in part by the Minnesota Supercomputer Institute. y E-mail: saad@cs.umn.edu.
Reference: [30] <author> Y. Saad. </author> <title> A flexible inner-outer preconditioned GMRES algorithm. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 14(2) </volume> <pages> 461-469, </pages> <year> 1993. </year>
Reference-contexts: In those papers, the multi-level preconditioned FGMRES is also compared with its single-level counterpart in terms of performance efficiency and storage cost. We used FGMRES (10) <ref> [30] </ref> as an accelerator for both the inner and outer iterations. The outer iteration process was preconditioned by BILUM with a dropping strategy. The inner iteration process to solve the last reduced system approximately was preconditioned by ILUT (t ,p) [32].
Reference: [31] <author> Y. Saad. ILUM: </author> <title> a multi-elimination ILU preconditioner for general sparse matrices. </title> <journal> SIAM J. Sci. Comput., </journal> <volume> 17(4) </volume> <pages> 830-847, </pages> <year> 1996. </year>
Reference-contexts: The above discussion suggests that multigrid and Krylov subspace methods are complementary in that one method's weakness is a strength of the other. Thus, a judicious combination of both methods may result in a powerful general-purpose iterative solver. This idea has been suggested by several authors <ref> [21, 31, 35] </ref> and some results using this type of methods have appeared in the literature, see e.g., [9, 11, 27, 31, 35]. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques. <p> Thus, a judicious combination of both methods may result in a powerful general-purpose iterative solver. This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., <ref> [9, 11, 27, 31, 35] </ref>. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques. <p> This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., [9, 11, 27, 31, 35]. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others <ref> [9, 31, 35] </ref> are more akin to domain decomposition techniques. As pointed out in [34], the major difference of these two types of methods are the choice of the reduced system (the coarse level system). <p> As pointed out in [34], the major difference of these two types of methods are the choice of the reduced system (the coarse level system). We note in passing that the parallelism is originally emphasized in domain decomposition type multi-level methods <ref> [31] </ref>. Promising test results with two-level implementations of similar methods on shared and distributed memory parallel computers have been reported [33, 34]. <p> For example, each unknown of the linear system is uniquely associated with exactly one level. Hence, unknowns on the coarse level are not represented on the fine level and vice versa. Preconditioning techniques based on multi-level block incomplete LU factorization (BILUM) <ref> [31, 35] </ref> have recently been shown to be very effective when solving general large sparse linear systems. BILUM combines the generality of Krylov subspace methods and the robustness of the ILU factorization techniques with the scalability of multigrid methods. <p> A block independent set (BIS) is a set of groups (blocks) of unknowns such that there is no coupling between unknowns of any two different groups (blocks) [35]. Unknowns within the same group may be coupled. The ILUM factorization defined in <ref> [31] </ref> uses blocks of size one. BILUM in [35] is constructed with blocks of small sizes, e.g., of size two or three. BIS with blocks of large sizes is considered in [34], along with a double dropping strategy introduced to control the sparsity. <p> Uniform block sizes have always been used in BILUM so far. Suppose that a (block) independent set ordering has been found by one of the techniques introduced in this paper or in <ref> [31, 35] </ref>. <p> The dimensions of the blocks ~ D i ; i = 1; : : : ; r; may not be the same. In <ref> [31, 35] </ref>, a block LU factorization of the form E C = I 0 0 A 1 = LU (3) is performed. Here A 1 = C ED 1 F (4) is the Schur complement with respect to C and I is the generic identity matrix. <p> The last reduced system obtained is then solved by a direct method or a preconditioned iterative method. The solution process (application of BILUM) consists of block forward and backward steps <ref> [31, 35, 34] </ref>. At each level j, we partition the vector x j as x j = y j corresponding to the two-by-two block matrix (2) and perform the following steps: Algorithm 2.1 Application of BILUM Preconditioner. 1. Copy the right-hand side vector b to x 0 . 2. <p> End do. Note that Lines 9 and 9a are written for illustration purposes and are redundant. The computation is actually performed as 9b. y j := D 1 The solution on the last level may not need to be exact. In <ref> [31, 35] </ref>, the coarsest level solution is obtained by applying several iterations of preconditioned GMRES. However, if A last is close to a dense matrix and is of small dimension, a direct solver may be used. <p> In a different way, we may combine the level by level permutation matrices as a global permutation matrix P = P last1 : : : P 1 P 0 and only perform permutation and inverse permutation before and after the application of BILUM as in <ref> [31] </ref>. In this implementation, the definition of inter-level transfer operators is cleaner and contains no permutation matrices. <p> In this implementation, the definition of inter-level transfer operators is cleaner and contains no permutation matrices. These are just some of the seemingly endless possibilities, the framework of BILUM and successive Schur complements can indeed generate numerous AMG-like algorithms. 2.2 BIS with large size blocks In <ref> [31, 35] </ref>, blocks of small sizes were used as pivots. Heuristics based on local optimization arguments were introduced in [35] to find Block Independent Sets (BIS) having various properties. <p> 3.90 1.89 16 19 39.17 1.44 5.32 2.18 16 66 66.28 0.33 3.61 1.89 14 49 62.33 0.55 4.86 2.14 14 117 103.9 0.19 3.30 1.86 4 Numerical Experiments Additional experiments with BILUM and some implementation details, specifically with small size blocks and some dropping strategies, have been reported in <ref> [31, 35, 34] </ref>. In those papers, the multi-level preconditioned FGMRES is also compared with its single-level counterpart in terms of performance efficiency and storage cost. We used FGMRES (10) [30] as an accelerator for both the inner and outer iterations.
Reference: [32] <author> Y. Saad. </author> <title> Iterative Methods for Sparse Linear Systems. </title> <publisher> PWS Publishing, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: In addition, their convergence rates depend heavily on problem-size, in contrast with multigrid techniques. This lack of scalability puts severe limits on the application of such methods to solving large scale problems. The robustness and efficiency of Krylov subspace methods can be improved dramatically by using a suitable preconditioner <ref> [32] </ref>. The above discussion suggests that multigrid and Krylov subspace methods are complementary in that one method's weakness is a strength of the other. Thus, a judicious combination of both methods may result in a powerful general-purpose iterative solver. <p> Numerical results with the 5-POINT matrices in [34] show that the sparsity ratio is doubled when the block size increases from 1 to 15, The potentially uncontrolled large storage requirement may overflow memory in large scale applications. Inspired by the dual threshold dropping strategy of ILUT <ref> [32] </ref>, we proposed a similar dual threshold dropping strategy for BILUM in [34]. We first apply the single dropping strategy as above to the ED 1 and A 1 matrices and keep only the largest p elements (absolute value) in each row of the LU factors at each level. <p> We used FGMRES (10) [30] as an accelerator for both the inner and outer iterations. The outer iteration process was preconditioned by BILUM with a dropping strategy. The inner iteration process to solve the last reduced system approximately was preconditioned by ILUT (t ,p) <ref> [32] </ref>. The construction and application of the BILUM preconditioner was similar to those described in [34]. The right-hand side was generated by assuming that the solution is a vector of all ones and the initial guess was random numbers. In all cases, 10 levels of reduction were performed.
Reference: [33] <author> Y. Saad and M. Sosonkina. </author> <title> Distributed Schur complement techniques for general sparse linear systems. </title> <type> Technical Report UMSI 97/159, </type> <institution> Minnesota Supercomputer Institute, University of Minnesota, Minneapolis, MN, </institution> <year> 1997. </year> <month> 17 </month>
Reference-contexts: We note in passing that the parallelism is originally emphasized in domain decomposition type multi-level methods [31]. Promising test results with two-level implementations of similar methods on shared and distributed memory parallel computers have been reported <ref> [33, 34] </ref>. Another research direction in algebraic multi-level preconditioning methods is towards the analysis of such methods for solving regularly structured problems arising from finite element or finite difference discretization of partial differential equations [2, 4, 3, 6, 12].
Reference: [34] <author> Y. Saad, M. Sosonkina, and J. Zhang. </author> <title> Domain decomposition and multi-level type techniques for general sparse linear systems. </title> <editor> In J. Mandel, C. Farhat, and X.-C. Cai, editors, </editor> <title> Domain Decomposition Methods 10, </title> <booktitle> number 218 in Contemporary Mathematics, </booktitle> <pages> pages 200-216, </pages> <address> Providence, RI, 1998. </address> <publisher> AMS. </publisher>
Reference-contexts: Some of these methods [8, 27] take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques. As pointed out in <ref> [34] </ref>, the major difference of these two types of methods are the choice of the reduced system (the coarse level system). We note in passing that the parallelism is originally emphasized in domain decomposition type multi-level methods [31]. <p> We note in passing that the parallelism is originally emphasized in domain decomposition type multi-level methods [31]. Promising test results with two-level implementations of similar methods on shared and distributed memory parallel computers have been reported <ref> [33, 34] </ref>. Another research direction in algebraic multi-level preconditioning methods is towards the analysis of such methods for solving regularly structured problems arising from finite element or finite difference discretization of partial differential equations [2, 4, 3, 6, 12]. <p> Unknowns within the same group may be coupled. The ILUM factorization defined in [31] uses blocks of size one. BILUM in [35] is constructed with blocks of small sizes, e.g., of size two or three. BIS with blocks of large sizes is considered in <ref> [34] </ref>, along with a double dropping strategy introduced to control the sparsity. Uniform block sizes have always been used in BILUM so far. Suppose that a (block) independent set ordering has been found by one of the techniques introduced in this paper or in [31, 35]. <p> The last reduced system obtained is then solved by a direct method or a preconditioned iterative method. The solution process (application of BILUM) consists of block forward and backward steps <ref> [31, 35, 34] </ref>. At each level j, we partition the vector x j as x j = y j corresponding to the two-by-two block matrix (2) and perform the following steps: Algorithm 2.1 Application of BILUM Preconditioner. 1. Copy the right-hand side vector b to x 0 . 2. <p> This measure alone is inadequate for comparing different preconditioning techniques, as it does not completely reflect the usage of resources, such as the computational and memory costs in constructing the preconditioner. In order to describe and compare different preconditioning techniques more accurately, we use several measures defined in <ref> [34] </ref> to characterize the efficiency of a preconditioning technique. The first one is called the efficiency ratio (e-ratio) which is defined as the ratio of the CPU time spent on computing the preconditioner to that on computing the solution by the preconditioned solver. <p> This measures the quality of the independent sets found by an algorithm. (Note that the precise definition of the reduction ratio is slightly different from what we used in <ref> [34] </ref>, both represent similar meaning.) Better performance is usually associated with larger independent sets. The sparsity ratio and the reduction ratio have been used in some of the earliest algebraic multigrid literature [37] to describe the efficiency of the algorithms 3 . <p> For BILUM with large size BIS formed by the greedy algorithm, this single dropping strategy is not enough to obtain a desired sparsity BILUM. Numerical results with the 5-POINT matrices in <ref> [34] </ref> show that the sparsity ratio is doubled when the block size increases from 1 to 15, The potentially uncontrolled large storage requirement may overflow memory in large scale applications. <p> Inspired by the dual threshold dropping strategy of ILUT [32], we proposed a similar dual threshold dropping strategy for BILUM in <ref> [34] </ref>. We first apply the single dropping strategy as above to the ED 1 and A 1 matrices and keep only the largest p elements (absolute value) in each row of the LU factors at each level. Another cause of loss of sparsity comes from the matrix D 1 . <p> 3.90 1.89 16 19 39.17 1.44 5.32 2.18 16 66 66.28 0.33 3.61 1.89 14 49 62.33 0.55 4.86 2.14 14 117 103.9 0.19 3.30 1.86 4 Numerical Experiments Additional experiments with BILUM and some implementation details, specifically with small size blocks and some dropping strategies, have been reported in <ref> [31, 35, 34] </ref>. In those papers, the multi-level preconditioned FGMRES is also compared with its single-level counterpart in terms of performance efficiency and storage cost. We used FGMRES (10) [30] as an accelerator for both the inner and outer iterations. <p> The outer iteration process was preconditioned by BILUM with a dropping strategy. The inner iteration process to solve the last reduced system approximately was preconditioned by ILUT (t ,p) [32]. The construction and application of the BILUM preconditioner was similar to those described in <ref> [34] </ref>. The right-hand side was generated by assuming that the solution is a vector of all ones and the initial guess was random numbers. In all cases, 10 levels of reduction were performed. <p> We used FORTRAN 77 in 64-bit arithmetic. 4.1 Experiments with dropping strategies Experiments with large size blocks and double dropping strategy for solving several large and hard-to-solve matrices have been reported in <ref> [34] </ref>. It has been shown that BIS with large size blocks are essential for solving some problems and the double dropping strategy is useful in controlling the amount of fill-ins. We report tests with the block sparsification strategy for solving the 9-POINT and VENKAT01 matrices here.
Reference: [35] <author> Y. Saad and J. Zhang. BILUM: </author> <title> block versions of multi-elimination and multi-level ILU precondi-tioner for general sparse linear systems. </title> <type> Technical Report UMSI 97/126, </type> <institution> Minnesota Supercomputer Institute, University of Minnesota, Minneapolis, MN, </institution> <year> 1997. </year>
Reference-contexts: The above discussion suggests that multigrid and Krylov subspace methods are complementary in that one method's weakness is a strength of the other. Thus, a judicious combination of both methods may result in a powerful general-purpose iterative solver. This idea has been suggested by several authors <ref> [21, 31, 35] </ref> and some results using this type of methods have appeared in the literature, see e.g., [9, 11, 27, 31, 35]. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques. <p> Thus, a judicious combination of both methods may result in a powerful general-purpose iterative solver. This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., <ref> [9, 11, 27, 31, 35] </ref>. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others [9, 31, 35] are more akin to domain decomposition techniques. <p> This idea has been suggested by several authors [21, 31, 35] and some results using this type of methods have appeared in the literature, see e.g., [9, 11, 27, 31, 35]. Some of these methods [8, 27] take the approach of algebraic multigrid methods, others <ref> [9, 31, 35] </ref> are more akin to domain decomposition techniques. As pointed out in [34], the major difference of these two types of methods are the choice of the reduced system (the coarse level system). <p> For example, each unknown of the linear system is uniquely associated with exactly one level. Hence, unknowns on the coarse level are not represented on the fine level and vice versa. Preconditioning techniques based on multi-level block incomplete LU factorization (BILUM) <ref> [31, 35] </ref> have recently been shown to be very effective when solving general large sparse linear systems. BILUM combines the generality of Krylov subspace methods and the robustness of the ILU factorization techniques with the scalability of multigrid methods. <p> BILUM combines the generality of Krylov subspace methods and the robustness of the ILU factorization techniques with the scalability of multigrid methods. The tests show near grid-independent convergence for certain type of problems <ref> [9, 35] </ref>. Yet, BILUM can be constructed purely algebraically and requires no physical grid information (although such information, if available, may be used to facilitate preconditioner construction and increase robustness of the resulting preconditioner [36]). <p> If the underlying PDEs are discretized by high order finite elements on unstructured domains, the coefficient matrices may have many nonzeros in each row. These features of the coefficient matrices make the problems harder to solve and the simple strategies used in the standard BILUM technique proposed in <ref> [35] </ref> may become inefficient. First, small pivoting blocks are no longer suitable for matrices with many nonzeros in each row and blocks of large sizes are preferable. <p> A block independent set (BIS) is a set of groups (blocks) of unknowns such that there is no coupling between unknowns of any two different groups (blocks) <ref> [35] </ref>. Unknowns within the same group may be coupled. The ILUM factorization defined in [31] uses blocks of size one. BILUM in [35] is constructed with blocks of small sizes, e.g., of size two or three. <p> A block independent set (BIS) is a set of groups (blocks) of unknowns such that there is no coupling between unknowns of any two different groups (blocks) <ref> [35] </ref>. Unknowns within the same group may be coupled. The ILUM factorization defined in [31] uses blocks of size one. BILUM in [35] is constructed with blocks of small sizes, e.g., of size two or three. BIS with blocks of large sizes is considered in [34], along with a double dropping strategy introduced to control the sparsity. Uniform block sizes have always been used in BILUM so far. <p> Uniform block sizes have always been used in BILUM so far. Suppose that a (block) independent set ordering has been found by one of the techniques introduced in this paper or in <ref> [31, 35] </ref>. <p> The dimensions of the blocks ~ D i ; i = 1; : : : ; r; may not be the same. In <ref> [31, 35] </ref>, a block LU factorization of the form E C = I 0 0 A 1 = LU (3) is performed. Here A 1 = C ED 1 F (4) is the Schur complement with respect to C and I is the generic identity matrix. <p> The last reduced system obtained is then solved by a direct method or a preconditioned iterative method. The solution process (application of BILUM) consists of block forward and backward steps <ref> [31, 35, 34] </ref>. At each level j, we partition the vector x j as x j = y j corresponding to the two-by-two block matrix (2) and perform the following steps: Algorithm 2.1 Application of BILUM Preconditioner. 1. Copy the right-hand side vector b to x 0 . 2. <p> End do. Note that Lines 9 and 9a are written for illustration purposes and are redundant. The computation is actually performed as 9b. y j := D 1 The solution on the last level may not need to be exact. In <ref> [31, 35] </ref>, the coarsest level solution is obtained by applying several iterations of preconditioned GMRES. However, if A last is close to a dense matrix and is of small dimension, a direct solver may be used. <p> In this implementation, the definition of inter-level transfer operators is cleaner and contains no permutation matrices. These are just some of the seemingly endless possibilities, the framework of BILUM and successive Schur complements can indeed generate numerous AMG-like algorithms. 2.2 BIS with large size blocks In <ref> [31, 35] </ref>, blocks of small sizes were used as pivots. Heuristics based on local optimization arguments were introduced in [35] to find Block Independent Sets (BIS) having various properties. <p> These are just some of the seemingly endless possibilities, the framework of BILUM and successive Schur complements can indeed generate numerous AMG-like algorithms. 2.2 BIS with large size blocks In [31, 35], blocks of small sizes were used as pivots. Heuristics based on local optimization arguments were introduced in <ref> [35] </ref> to find Block Independent Sets (BIS) having various properties. It has been shown numerically that selecting new subsets according to the lowest possible number of outgoing edges in the subgraph, usually yields better performance and frequently the smallest reduced system (also see some analyses and comments in [36]). <p> As a result, the construction and application of a BILUM preconditioner associated with a BIS having large subsets tends to be expensive <ref> [35] </ref>. Numerical tests in [35] also indicates that large size blocks, which yield large independent sets, tend to result in a better BILUM preconditioner. <p> As a result, the construction and application of a BILUM preconditioner associated with a BIS having large subsets tends to be expensive <ref> [35] </ref>. Numerical tests in [35] also indicates that large size blocks, which yield large independent sets, tend to result in a better BILUM preconditioner. <p> These four performance measures are more informative than the measure provided by the iteration count alone. 3 Enhanced Block Preconditioning Techniques Our experience and analysis suggest that larger independent set results in a better BILUM preconditioner <ref> [35, 36] </ref> and this leads to the use of large size blocks. However, as we mentioned in the introduction, there are some problems associated with using blocks of large sizes. These problems include the potentially near-singular blocks and potentially large amount of fill-ins. <p> These problems include the potentially near-singular blocks and potentially large amount of fill-ins. Several new techniques are introduced in this section to deal with some of these problems. 3.1 Double dropping strategy The dropping strategy used in <ref> [35, 36] </ref> is to drop elements in the U factor ED 1 and in the reduced system A 1 whenever their absolute value is less than a threshold tolerance t times the average nonzero value of the current row. <p> 3.90 1.89 16 19 39.17 1.44 5.32 2.18 16 66 66.28 0.33 3.61 1.89 14 49 62.33 0.55 4.86 2.14 14 117 103.9 0.19 3.30 1.86 4 Numerical Experiments Additional experiments with BILUM and some implementation details, specifically with small size blocks and some dropping strategies, have been reported in <ref> [31, 35, 34] </ref>. In those papers, the multi-level preconditioned FGMRES is also compared with its single-level counterpart in terms of performance efficiency and storage cost. We used FGMRES (10) [30] as an accelerator for both the inner and outer iterations. <p> We report tests with the block sparsification strategy for solving the 9-POINT and VENKAT01 matrices here. The 9-POINT matrix was first used in <ref> [35] </ref> and is from a 9-point fourth-oder compact finite difference discretization of a convection-diffusion equation with a Reynolds number 10 4 [23]. It has 40; 000 unknowns and 357; 604 nonzeros. <p> The blocking strategies used in this paper do not consider the values of the matrix and thus are blind to physical information that may be contained in the matrix. Those used in <ref> [35] </ref> extract full information and are expensive to implement for large size blocks. A middle ground would be to use limited information on the values of the matrix, such as the diagonal values as we did for ILUM in [36].
Reference: [36] <author> Y. Saad and J. Zhang. </author> <title> Diagonal threshold techniques in robust multi-level ILU preconditioners for general sparse linear systems. </title> <type> Technical Report UMSI 98/7, </type> <institution> Minnesota Supercomputer Institute, University of Minnesota, Minneapolis, MN, </institution> <year> 1998. </year>
Reference-contexts: The tests show near grid-independent convergence for certain type of problems [9, 35]. Yet, BILUM can be constructed purely algebraically and requires no physical grid information (although such information, if available, may be used to facilitate preconditioner construction and increase robustness of the resulting preconditioner <ref> [36] </ref>). BILUM is a hybrid method that blends characteristics of multigrid methods, domain decomposition techniques, and ILU factorizations. For problems arising from practical applications, such as those from computational fluid dynamics, the coefficient matrices are often irregularly structured, ill-conditioned, and of very large size. <p> First, small pivoting blocks are no longer suitable for matrices with many nonzeros in each row and blocks of large sizes are preferable. It has been shown that the size of the independent set influences the convergence rate of the preconditioned iterative solver <ref> [36] </ref> and the use of large size blocks is advantageous. Second, the inverse of a large sparse block is a full dense matrix in general, so the amount of fill-ins in BILUM increases rapidly as the block size increases. This makes the process more complex and more costly. <p> It has been shown numerically that selecting new subsets according to the lowest possible number of outgoing edges in the subgraph, usually yields better performance and frequently the smallest reduced system (also see some analyses and comments in <ref> [36] </ref>). These algorithms were devised for finding independent sets with blocks of small sizes. Extending these heuristic algorithms for extracting BIS with large size blocks is straightforward. However, these extensions may have some undesirable consequences. <p> Analytical investigation on the preconditioned errors of ILUM (BILUM with blocks of size one) shows that the Frobenius norms of the factorization and preconditioned errors are proportional to the size of the independent set <ref> [36] </ref>. Hence, both numerical and analytical results lead to the need for large independent set and the most convenient way to achieve this seems to use blocks of large size. 5 2.3 Performance measures A traditional performance measure for iterative methods is the iteration counts. <p> These four performance measures are more informative than the measure provided by the iteration count alone. 3 Enhanced Block Preconditioning Techniques Our experience and analysis suggest that larger independent set results in a better BILUM preconditioner <ref> [35, 36] </ref> and this leads to the use of large size blocks. However, as we mentioned in the introduction, there are some problems associated with using blocks of large sizes. These problems include the potentially near-singular blocks and potentially large amount of fill-ins. <p> These problems include the potentially near-singular blocks and potentially large amount of fill-ins. Several new techniques are introduced in this section to deal with some of these problems. 3.1 Double dropping strategy The dropping strategy used in <ref> [35, 36] </ref> is to drop elements in the U factor ED 1 and in the reduced system A 1 whenever their absolute value is less than a threshold tolerance t times the average nonzero value of the current row. <p> In general, the dimension of each block is different and we have to deal with the issue of implementing BIS with variable size blocks. In order to have a stable inverse, we may also restrict the magnitude of the diagonal entries by a threshold tolerance as we did in <ref> [36] </ref>, or perturb the small diagonal values as in the SVD technique. Given a threshold tolerance ", we need to impose the restriction that jb i;i j " for all 1 i s. If jb i;i j &lt; ", we replace jb i;i j by ". <p> The substantial amount of zero diagonals makes these matrices indefinite. Standard ILU preconditioners may fail to converge for solving these matrices unless a small t and a large p are used. In the case of ILUM (BILUM with block size 1), the diagonal threshold technique introduced in <ref> [36] </ref> seems to offer a simple yet effective way of dealing with such indefinite matrices. The FIDAP012 matrix is from a model of flow in lid-driven wedge. Uniform blocks of size s = 10 were used. The FIDAP036 matrix is a problem of modeling chemical vapor deposition. <p> Those used in [35] extract full information and are expensive to implement for large size blocks. A middle ground would be to use limited information on the values of the matrix, such as the diagonal values as we did for ILUM in <ref> [36] </ref>. This may offer an informative yet inexpensive way to construct robust and efficient preconditioners.
Reference: [37] <author> K. Stuben. </author> <title> Algebraic multigrid (AMG), experiences and comparisons. </title> <journal> Appl. Math. Comput., </journal> <volume> 13 </volume> <pages> 419-451, </pages> <year> 1983. </year>
Reference-contexts: The smoothing operator may be defined as D 1 j , i.e., exact solve for the fine grid nodes as in Line 9. Similar to AMG, the coarse grid operator may be defined by the so-called Galerkin condition (or Galerkin coarse grid approximation) <ref> [37, 39] </ref> as A j+1 = I j A j I j+1 : (9) Line 9 is equivalent to applying a pre-smoothing operation on the fine grid nodes (the nodes in the independent set) 2 . <p> Hence, Algorithm 2.1 may be considered as an algebraic multigrid method with one pre-smoothing and no post-smoothing, i.e., a V (1,0) cycle algorithm <ref> [37] </ref>. The smoothing operation on the whole grid is carried out by one Krylov subspace iteration. <p> Proposition 2.1 Using the above assumptions and definitions, the coarse grid operator defined in (9) is the same as the Schur complement (4). 2 The definition of fine grid nodes in AMG is different from that in geometric multigrid method <ref> [37] </ref>. The algorithm can be written in an equivalent form so that the pre-smoothing operation is performed in the forward sweep, i.e., in the first half cycle. 4 Proof. <p> The sparsity ratio and the reduction ratio have been used in some of the earliest algebraic multigrid literature <ref> [37] </ref> to describe the efficiency of the algorithms 3 . <p> Hence, small elements of D 1 may be dropped without loosing much in the quality of the preconditioner. In practice, we may use a similar 3 In <ref> [37] </ref> the sparsity ratio is called the operator complexity and the reduction ratio the grid complexity. 6 double dropping strategy as just suggested for the ED 1 and A 1 matrices, but we should use different parameters.
Reference: [38] <author> W.-P. Tang. </author> <title> Towards an effective sparse approximate inverse preconditioner. </title> <note> SIAM J. Sci. Comput. to appear. </note>
Reference-contexts: For BIS with large size blocks this results in a matrix D 1 that is much denser than D. However, if a block is diagonally dominant, the elements of the block inverse are expected to decay rapidly away from the main diagonal <ref> [38] </ref>. Hence, small elements of D 1 may be dropped without loosing much in the quality of the preconditioner.
Reference: [39] <author> P. </author> <title> Wesseling. An Introduction to Multigrid Methods. </title> <publisher> John Wiley & Sons, </publisher> <address> Chichester, </address> <year> 1992. </year> <month> 18 </month>
Reference-contexts: Each of the two classes of methods contains a rich variety of methods and each has its own advantages and disadvantages. An attractive feature of the multigrid method is its grid-independent convergence and optimal scalability <ref> [10, 39] </ref>. For certain type of problems, the CPU and memory costs are proportional to the size of the problems. The obvious disadvantage of multigrid methods is their limited applicability. <p> we define the prolongation operator in Lines 9a and 10 as I j+1 = P T j F j and the restriction operator as the transpose of the prolongation operator, i.e., I j = I j+1 : (7) Equation (7) is usually satisfied by classical geometric and algebraic multigrid methods <ref> [39] </ref>. It can be verified that the restriction operator just defined is actually equivalent to I j = E j D 1 as in Lines 3 and 4. <p> The smoothing operator may be defined as D 1 j , i.e., exact solve for the fine grid nodes as in Line 9. Similar to AMG, the coarse grid operator may be defined by the so-called Galerkin condition (or Galerkin coarse grid approximation) <ref> [37, 39] </ref> as A j+1 = I j A j I j+1 : (9) Line 9 is equivalent to applying a pre-smoothing operation on the fine grid nodes (the nodes in the independent set) 2 .
References-found: 38

