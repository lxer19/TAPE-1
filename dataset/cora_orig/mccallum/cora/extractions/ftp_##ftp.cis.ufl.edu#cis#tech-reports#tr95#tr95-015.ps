URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr95/tr95-015.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr95-abstracts.html
Root-URL: http://www.cis.ufl.edu
Email: pk@cis.ufl.edu ted@cis.ufl.edu  
Title: Highly Scalable Data Balanced Distributed B-trees  
Author: Padmashree A. Krishna Theodore Johnson 
Address: Gainesville, FL 32611  
Affiliation: Computer and Information Sciences Department University of Florida  
Abstract: Scalable distributed search structures are needed to maintain large volumes of data and for parallel databases. In this paper, we analyze the performance of two large scale data-balanced distributed search structures, the dB-tree and the dE-tree. The dB-tree is a distributed B-tree that replicates its interior nodes. The dE-tree is a dB-tree in which leaf nodes represent key ranges, and thus requires far fewer nodes to represent a distributed index. The performance of both algorithms depends on the method by which tree nodes are assigned to processors (i.e., the algorithm for performing data balancing). We present a simulation study of data balancing algorithms for the dB-tree and the dE-tree. We find that a simple distributed data balancing algorithm works well for the dB-tree, requiring only a small space and message passing overhead. We compare three algorithms for data balancing in a dE-tree, and find that the most aggressive of the algorithms makes the dE-tree scalable. Using the data from the simulation experiments, we present an analytical performance model of the dB-tree and the dE-tree. We find that both algorithms are scalable to large numbers of processors. Keywords: Distributed Search Structures, Distributed Databases, Data-Balancing, Performance Anal ysis.
Abstract-found: 1
Intro-found: 1
Reference: [BY89] <author> Baeza-Yates R. </author> <title> Expected Behavior of B + -trees Under Random Inserts, </title> <journal> Acta Informatica, </journal> <volume> Vol. 27, </volume> <year> 1989. </year>
Reference-contexts: We performed simulations on fixed height large dB-trees by inserting upto 2.5 million keys and varying the average fanout from 10 to 40 (average fanout is 69% of the maximum fanout <ref> [BY89] </ref>). When the root of the tree had the desired average fanout we collected statistics. We noted the processors' capacity in terms of the number of leaves it has, the number of index level nodes, and the number of keys.
Reference: [BHG87] <author> Bernstein P. A., Hadzilacos V. and Goodman, N. </author> <title> Concurreny Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference: [BS77] <author> Bayer R. and M. Schkolnick. </author> <title> Concurrency of operations on B-trees, </title> <journal> Acta Informatica, </journal> <volume> Vol. 9, </volume> <year> 1977, </year> <pages> pp. 1-21. </pages>
Reference-contexts: Based on our simulation results, we develop a model for large scale dB-tree and dE-tree characteristics. We use the model of the distributed search structures to develop a performance model. 2 Previous Work Several approaches to concurrent access of the B-tree have been proposed <ref> [BS77, MR85] </ref>. Each of these approaches uses some form of locking technique to ensure exclusive access to a node. Lock contention is more pronounced at the higher levels of the tree. Sagiv [S86] and Lehman and Yao [LY81] use a link technique to reduce contention.
Reference: [CBDW91] <author> Colbrook, A., Brewer, E. A., Dellarocas, C.N. and Weihl, W. E. </author> <title> An Algorithm for Concurrent Search Trees, </title> <booktitle> Proccedings of the 20th International Conference on Parallel Processing, </booktitle> <year> 1991, </year> <pages> pp. 38-41. </pages>
Reference: [E85] <author> Ellis, C.S. </author> <title> Distributed Data Structures: A Case Study IEEE Transcations on Computers Vol. </title> <journal> c-34, </journal> <volume> No. 12, </volume> <month> December </month> <year> 1985., </year> <pages> pp. 1178-1185. </pages>
Reference-contexts: Each of these approaches uses some form of locking technique to ensure exclusive access to a node. Lock contention is more pronounced at the higher levels of the tree. Sagiv [S86] and Lehman and Yao [LY81] use a link technique to reduce contention. Ellis <ref> [E85] </ref> has proposed a distributed extendible hashing technique, that uses techniques similar to the ones we use here. A distributed linear hashing method that's particularly useful for main memory databases is discussed in [S90]. Linear Hashing for distributed files, LH* has been proposed by Litwin et al. [LNS93]. <p> Linear Hashing for distributed files, LH* has been proposed by Litwin et al. [LNS93]. In this work, Litwin et al. propose a general class of distributed data structures which they term scalable distributed data structures, or SDDS. An SDDS algorithm is similar to the algorithms discussed by Ellis <ref> [E85] </ref>. A significant difference is the manner in which modifications to the global state are distributed. An SDDS algorithm distributes updates passively, after a processor takes an incorrect action. After updating the processor's state, the action is re-issued. <p> We found that a distributed search structure permits a much larger throughput than a centralized index server, at the cost of a modestly increased response time. Much work has been done lately on distributed hash tables <ref> [LNS93, LNS94, S90, E85] </ref>. Because of their 18 two level structure, a search operation typically requires two messages (the request and the reply), while we have found that a four level dB-tree requires 3 messages per search operation (two for the request and one for the reply).
Reference: [H89] <author> Herlihy M. </author> <title> A Methodology for Implementing Highly Concurrent Data Structures, </title> <booktitle> Proceeding of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, ACM 1989, </booktitle> <pages> pp. 197-206. </pages>
Reference: [JC92] <author> Johnson T. and Colbrook A. </author> <title> A Distributed Data-Balanced Dictionary Based on the B-link Tree, </title> <booktitle> International Parallel Processing Symposium, </booktitle> <month> March </month> <year> 1992, </year> <pages> pp. 319-325. 19 </pages>
Reference-contexts: Their results indicate that scalability is achieved at a controlled cost/performance. Matsliach and Shmueli [MS91] address the problem of designing search structures to fit shared memory multiprocessor multidisk systems. Other related works are multi-disk B-trees proposed by Seeger and Larson [SL91]. Johnson and Colbrook <ref> [JC92] </ref> present a distributed B-tree suitable for message-passing architectures. The interior nodes are replicated to improve parallelism and alleviate the bottleneck. Restructuring decisions are made locally thereby reducing the communication overhead and increasing parallelism. <p> As a result, path replication permits highly scalable distributed B-trees. A good data balance is achieved with little node movement overhead. 3 Distributed Search Structure Algorithms The algorithms for implementing dB-trees and dE-trees are well discussed in our previous work <ref> [JC92, JK92b, KJ94, KJ94b] </ref>. In this section, we briefly review the algorithms. 3.1 Concurrent B-link tree The dB-tree is a distributed B link -tree, which in turn is a B + -tree in which every node has a pointer to its right sibling at the same level.
Reference: [JK92] <author> Johnson T. and Krishna P. </author> <booktitle> Distributed indices for accessing distributed data Proceedings of the 12th IEEE Mass Storage Symposium, </booktitle> <year> 1992. </year>
Reference-contexts: 1 Introduction Current commercial and scientific database systems deal with vast amounts of data. Since the volume of data to be handled is large, it may not be possible to store all the data at one place. Hence, distributed techniques are necessary to create large scale efficient distributed storage <ref> [JK92] </ref>. Larger amounts of data can be stored by partitioning the data, which also allows for parallel access to the data. Managing and indexing large volumes of distributed and dynamically changing data require the use of distributed data structures.
Reference: [JK92b] <author> Johnson T. and Krishna P. </author> <booktitle> Lazy Updates for Distributed Search Structures Proceedings of the 1993 ACM SIGMOD, </booktitle> <pages> pages 337-346, </pages> <year> 1993. </year>
Reference-contexts: They discuss data balancing among processors and suggest a way of reducing communication cost by storing neighboring leaves on the same processor. In a previous paper, we have proposed algorithms for efficiently replicating the index of a distributed hierarchical search structure <ref> [JK92b] </ref>. In contract to the passive approach of the SDDS algorithms, we propose methods for actively distributing updates to the index nodes, but in a lazy manner. <p> As a result, path replication permits highly scalable distributed B-trees. A good data balance is achieved with little node movement overhead. 3 Distributed Search Structure Algorithms The algorithms for implementing dB-trees and dE-trees are well discussed in our previous work <ref> [JC92, JK92b, KJ94, KJ94b] </ref>. In this section, we briefly review the algorithms. 3.1 Concurrent B-link tree The dB-tree is a distributed B link -tree, which in turn is a B + -tree in which every node has a pointer to its right sibling at the same level. <p> As we saw in Section 4.1, H approaches an asymptote for a fixed-height tree. The algorithms described in <ref> [JK92b] </ref> require R 2 actions for every split of a level 1 node. Fortunately, we found that R 2 grows very slowly with increasing P .
Reference: [JS90] <author> Johnson T. and Shasha D. </author> <title> A Framework for the performance Analysis of Concurrent B-tree Algorithms, </title> <booktitle> Proceedings of the 9th ACM Symposium on Principles of Database Systems, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: The link provides a means of reaching a node when a split has occurred, thereby 3 helping the node to recover from misnavigated operations. The B link -tree algorithms have been found to have the highest performance of all concurrent B-tree algorithms <ref> [JS90] </ref>. In the concurrent B link -tree proposed by Sagiv [S86], every node has a field that is the highest-valued key stored in the subtree. The reason for the high performance of the B link -tree algorithms is the use of the half-split operation, shown in Figure 1.
Reference: [JS93] <author> Johnson T. and Shasha D. </author> <title> The Performance of Concurrent Data Structure Algorithms, </title> <journal> Transactions on Database Systems, </journal> <month> March </month> <year> 1993, </year> <pages> pp. 51-101. </pages>
Reference-contexts: For this reason, we will use the estimates of the number of hops and the degree of replication developed in Section 4.1. The model described in this section is loosely based on the model presented in <ref> [JS93] </ref>. We assume that operations are generated uniformly at all processors, and the accesses are made to the data uniformly. We first define the variables that we use in the analysis: L: Number of levels in the search structure (level 1 is the leaf, level L is the root). <p> Since there are L levels, L search actions are required. Since each operation requires H hops, H + 1 messages are required (a slightly pessimistic estimate). In addition, an operation might cause restructuring. If there are more inserts than deletes, then p res 1=(:68 fl F ) <ref> [JS93] </ref>. When a node splits, the sibling is created, its right and left neighbors must be informed, and all copies of the parent must be informed about the new sibling. In turn the parent might split, with probability p res .
Reference: [KJ94] <author> Krishna P. A. and Johnson T. </author> <booktitle> Index Replication in a Distributed B-tree Proceedings of the Sixth International Conference on the Management of Data, </booktitle> <month> COMAD </month> <year> 1994. </year>
Reference-contexts: The algorithms are also message efficient, requiring one message per copy per insert. In [KJ94b] we discuss implementational issues of distributed search structure algorithms. In a previous paper <ref> [KJ94] </ref>, we proposed two strategies for replication, namely path replication and full replication. We found that path replication is better, with far lower message and space overhead. Path replication imposes only a small overhead on the number of messages required to search for a key. <p> As a result, path replication permits highly scalable distributed B-trees. A good data balance is achieved with little node movement overhead. 3 Distributed Search Structure Algorithms The algorithms for implementing dB-trees and dE-trees are well discussed in our previous work <ref> [JC92, JK92b, KJ94, KJ94b] </ref>. In this section, we briefly review the algorithms. 3.1 Concurrent B-link tree The dB-tree is a distributed B link -tree, which in turn is a B + -tree in which every node has a pointer to its right sibling at the same level. <p> An overall B-tree manager called the anchor overlooks the entire B-tree operations. (the responsibility of the anchor is minimal). The queue manager and the node manager communicate with the anchor and with the other processors by sockets. A more detailed discussion of the implementation appears in <ref> [KJ94, KJ94b] </ref>. When distributing a B-tree, each node of the B-tree in addition to maintaining the indices, must also contain information that will help in the maintenance of the B-tree. <p> Both these algorithms designate one copy of a node to be the primary copy (PC). Our 5 implementation of the Fixed-Position copies algorithm is termed Full Replication and that of Variable copies is Path Replication. A previous work shows that path replication is better than full replication <ref> [KJ94] </ref>, so we discuss only the variable copies algorithm here. In the Variable-copies algorithm ([JK92b]), a processor that holds a leaf node also holds a path from the root to that leaf node. Hence, index level nodes are replicated to different extents. <p> Similarly, a processor will `unjoin' a node when it has no copies of the node's children. In the implementation <ref> [KJ94] </ref>, whenever a leaf node migrates to a different processor, the entire path from the root to that leaf is replicated at this processor. <p> Otherwise, a relayed insert is sent. In most cases, a split requires only c 1 messages. 3.2.3 Implementation and Performance In <ref> [KJ94] </ref> we discussed the design issues in the implementation of a distributed B-tree, such as synchronization, implementing data balancing, and replication strategies. We briefly summarize the results obtained for our replicated B-trees here. We inserted a total of 15000 keys in a B-tree distributed over 4 to 12 processors. <p> Especially in the case of centralized load balancing, the anchor is likely to have poor information about the receiver's load. 4.1.1 Performance Analysis We were interested in answering several questions about the performance of data balancing algorithms and about dB-trees. A previous study <ref> [KJ94] </ref> showed us that the data balancing algorithms are effective in balancing the load, and at a low overhead. For this study, we are interested in determining their effect on the structure of the dB-tree the storage overhead and the message passing overhead.
Reference: [KJ94b] <author> Krishna P. and Johnson T. </author> <title> Implementing Distributed Search Structures, </title> <type> Technical Report TR94-009, </type> <institution> University of Florida. </institution>
Reference-contexts: By taking advantage of the commutativity of the actions on index nodes, different operations can read and update the same node concurrently (though at different copies). The algorithms are also message efficient, requiring one message per copy per insert. In <ref> [KJ94b] </ref> we discuss implementational issues of distributed search structure algorithms. In a previous paper [KJ94], we proposed two strategies for replication, namely path replication and full replication. We found that path replication is better, with far lower message and space overhead. <p> As a result, path replication permits highly scalable distributed B-trees. A good data balance is achieved with little node movement overhead. 3 Distributed Search Structure Algorithms The algorithms for implementing dB-trees and dE-trees are well discussed in our previous work <ref> [JC92, JK92b, KJ94, KJ94b] </ref>. In this section, we briefly review the algorithms. 3.1 Concurrent B-link tree The dB-tree is a distributed B link -tree, which in turn is a B + -tree in which every node has a pointer to its right sibling at the same level. <p> An overall B-tree manager called the anchor overlooks the entire B-tree operations. (the responsibility of the anchor is minimal). The queue manager and the node manager communicate with the anchor and with the other processors by sockets. A more detailed discussion of the implementation appears in <ref> [KJ94, KJ94b] </ref>. When distributing a B-tree, each node of the B-tree in addition to maintaining the indices, must also contain information that will help in the maintenance of the B-tree.
Reference: [KSR91] <institution> KSR1 Principles of Operation, Copyright Kendall Research Corporation, </institution> <year> 1991. </year>
Reference: [LLS92] <author> Ladin R., Liskov B. and Shira L. </author> <title> Providing High Reliability Using Lazy Replication, </title> <journal> ACM Transactions on Computer Systems Vol. </journal> <volume> 10, No. 4, </volume> <year> 1992, </year> <pages> pp. 360-391. </pages>
Reference: [LCH91] <author> Lee, P., Chen, Y. and Holdman, J. M. DRISP: </author> <title> A Versatile Scheme For Distributed Fault -Tolerant Queues, </title> <booktitle> IEEE 11th International Conference on Distributed Computing Systems, 1991 pp. </booktitle> <pages> 600-606. </pages>
Reference: [LY81] <author> Lehman P.L. and Yao S.B. </author> <title> Efficient Locking for Concurrent Operations on B-trees, </title> <journal> ACM Transactions on Database Systems 6, </journal> <month> December </month> <year> 1981, </year> <pages> pp. 650-670. </pages>
Reference-contexts: Each of these approaches uses some form of locking technique to ensure exclusive access to a node. Lock contention is more pronounced at the higher levels of the tree. Sagiv [S86] and Lehman and Yao <ref> [LY81] </ref> use a link technique to reduce contention. Ellis [E85] has proposed a distributed extendible hashing technique, that uses techniques similar to the ones we use here. A distributed linear hashing method that's particularly useful for main memory databases is discussed in [S90].
Reference: [LNS93] <author> Litwin W., and Neimat M., and Schneider D. </author> <title> LH*-Linear Hashing for Distributed Files, </title> <booktitle> Proceedings of the 1993 ACM SIGMOD, </booktitle> <pages> pages 332-336. </pages>
Reference-contexts: Ellis [E85] has proposed a distributed extendible hashing technique, that uses techniques similar to the ones we use here. A distributed linear hashing method that's particularly useful for main memory databases is discussed in [S90]. Linear Hashing for distributed files, LH* has been proposed by Litwin et al. <ref> [LNS93] </ref>. In this work, Litwin et al. propose a general class of distributed data structures which they term scalable distributed data structures, or SDDS. An SDDS algorithm is similar to the algorithms discussed by Ellis [E85]. <p> We found that a distributed search structure permits a much larger throughput than a centralized index server, at the cost of a modestly increased response time. Much work has been done lately on distributed hash tables <ref> [LNS93, LNS94, S90, E85] </ref>. Because of their 18 two level structure, a search operation typically requires two messages (the request and the reply), while we have found that a four level dB-tree requires 3 messages per search operation (two for the request and one for the reply).
Reference: [LNS94] <author> Litwin W., Neimat M., and Schneider D. A. </author> <title> RP* A Family of Order-Preserving Scalable Distributed Data Structures, </title> <booktitle> Proceedings of the 20th VLDB Conference, </booktitle> <year> 1994, </year> <pages> pp. 342-353. </pages>
Reference-contexts: An SDDS algorithm distributes updates passively, after a processor takes an incorrect action. After updating the processor's state, the action is re-issued. The algorithms that underlie the distributed data structures actively distribute changes to the global state, but handle requests based on out-of-date information. Litwin et al. <ref> [LNS94] </ref> extend the SDDS family with the RP* hash table. The RP* hash table is order-preserving, and thus can 2 support range queries. Distributed file organization for disk resident files has been discussed by Vingraek et al. [VBW94]. <p> We found that a distributed search structure permits a much larger throughput than a centralized index server, at the cost of a modestly increased response time. Much work has been done lately on distributed hash tables <ref> [LNS93, LNS94, S90, E85] </ref>. Because of their 18 two level structure, a search operation typically requires two messages (the request and the reply), while we have found that a four level dB-tree requires 3 messages per search operation (two for the request and one for the reply).
Reference: [MR85] <author> Mond Y. and Raz Y. </author> <title> Concurrency Control in B + -trees Databases Using Preparatory Operations, </title> <booktitle> Proceedings of the 11th International Conference on Very Large Databases, </booktitle> <month> August </month> <year> 1985, </year> <pages> pp. 331-334. </pages>
Reference-contexts: Based on our simulation results, we develop a model for large scale dB-tree and dE-tree characteristics. We use the model of the distributed search structures to develop a performance model. 2 Previous Work Several approaches to concurrent access of the B-tree have been proposed <ref> [BS77, MR85] </ref>. Each of these approaches uses some form of locking technique to ensure exclusive access to a node. Lock contention is more pronounced at the higher levels of the tree. Sagiv [S86] and Lehman and Yao [LY81] use a link technique to reduce contention.
Reference: [MS91] <author> Matsliach, G. and Shmueli, O. </author> <title> An Efficient Method for Distributing Search Structures Proceedings of the First International Conference on Parallel and Distributed Information Systems, </title> <booktitle> 1991, </booktitle> <pages> pp. 159-166. 20 </pages>
Reference-contexts: The focus of their work has been to achieve scalability (in terms of the number of servers) of the throughput and the file size while dynamically distributing data. Their results indicate that scalability is achieved at a controlled cost/performance. Matsliach and Shmueli <ref> [MS91] </ref> address the problem of designing search structures to fit shared memory multiprocessor multidisk systems. Other related works are multi-disk B-trees proposed by Seeger and Larson [SL91]. Johnson and Colbrook [JC92] present a distributed B-tree suitable for message-passing architectures.
Reference: [P90] <author> Peleg, D. </author> <title> Distributed Data Structures: A Complexity Oriented View, </title> <booktitle> Fourth International workshop on Distributed Algorithms, </booktitle> <pages> 1990 pp 71-89. </pages>
Reference: [S76] <author> Samadi B. </author> <title> B-trees in a system with multiple users, </title> <journal> Information Processing Letters, </journal> <volume> 5, </volume> <year> 1976, </year> <pages> pp. 107-112. </pages>
Reference: [S86] <author> Sagiv Y. </author> <title> Concurrent Operations on B-Trees with Overtaking, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33(2), </volume> <month> October </month> <year> 1986, </year> <pages> pp. 275-296. </pages>
Reference-contexts: Each of these approaches uses some form of locking technique to ensure exclusive access to a node. Lock contention is more pronounced at the higher levels of the tree. Sagiv <ref> [S86] </ref> and Lehman and Yao [LY81] use a link technique to reduce contention. Ellis [E85] has proposed a distributed extendible hashing technique, that uses techniques similar to the ones we use here. A distributed linear hashing method that's particularly useful for main memory databases is discussed in [S90]. <p> The B link -tree algorithms have been found to have the highest performance of all concurrent B-tree algorithms [JS90]. In the concurrent B link -tree proposed by Sagiv <ref> [S86] </ref>, every node has a field that is the highest-valued key stored in the subtree. The reason for the high performance of the B link -tree algorithms is the use of the half-split operation, shown in Figure 1.
Reference: [SL91] <author> Seeger, B. and Larson P. </author> <title> Multi-Disk B-trees, </title> <booktitle> Proceedings of the 1991 ACM SIGMOD, </booktitle> <pages> pages 436-445, </pages> <year> 1991. </year>
Reference-contexts: Their results indicate that scalability is achieved at a controlled cost/performance. Matsliach and Shmueli [MS91] address the problem of designing search structures to fit shared memory multiprocessor multidisk systems. Other related works are multi-disk B-trees proposed by Seeger and Larson <ref> [SL91] </ref>. Johnson and Colbrook [JC92] present a distributed B-tree suitable for message-passing architectures. The interior nodes are replicated to improve parallelism and alleviate the bottleneck. Restructuring decisions are made locally thereby reducing the communication overhead and increasing parallelism.
Reference: [S90] <author> Severance C. and Pramanik S. </author> <booktitle> Distributed linear hashing for main memory databases Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <pages> pages 92-95, </pages> <year> 1990. </year>
Reference-contexts: Sagiv [S86] and Lehman and Yao [LY81] use a link technique to reduce contention. Ellis [E85] has proposed a distributed extendible hashing technique, that uses techniques similar to the ones we use here. A distributed linear hashing method that's particularly useful for main memory databases is discussed in <ref> [S90] </ref>. Linear Hashing for distributed files, LH* has been proposed by Litwin et al. [LNS93]. In this work, Litwin et al. propose a general class of distributed data structures which they term scalable distributed data structures, or SDDS. An SDDS algorithm is similar to the algorithms discussed by Ellis [E85]. <p> We found that a distributed search structure permits a much larger throughput than a centralized index server, at the cost of a modestly increased response time. Much work has been done lately on distributed hash tables <ref> [LNS93, LNS94, S90, E85] </ref>. Because of their 18 two level structure, a search operation typically requires two messages (the request and the reply), while we have found that a four level dB-tree requires 3 messages per search operation (two for the request and one for the reply).
Reference: [TSP91] <author> Turek J., Shasha D. and Prakash S. </author> <title> Locking without Blocking: Making Lock Based Concurrent Data Structure Algorithms Nonblocking, </title> <booktitle> ACM Symposium on Principles of Database Systems, </booktitle> <year> 1992, </year> <pages> pp. 212-222. </pages>
Reference: [VBW94] <author> Vingraek R. and Breitbart Y., and Weikum G. </author> <title> Distributed File Organization with Scalable Cost/Performance, </title> <booktitle> Proceedings of the 1994 ACM SIGMOD, </booktitle> <pages> pages 253-264, </pages> <year> 1994. </year>
Reference-contexts: Litwin et al. [LNS94] extend the SDDS family with the RP* hash table. The RP* hash table is order-preserving, and thus can 2 support range queries. Distributed file organization for disk resident files has been discussed by Vingraek et al. <ref> [VBW94] </ref>. The focus of their work has been to achieve scalability (in terms of the number of servers) of the throughput and the file size while dynamically distributing data. Their results indicate that scalability is achieved at a controlled cost/performance.
Reference: [WW90] <author> Weihl E. W. and Wang P. </author> <title> Multi-version Memory: Software cache Management for Concurrent B-Trees, </title> <booktitle> Proceedings of the 2nd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1990, </year> <pages> pp. 650-655. 22 23 24 25 </pages>
References-found: 29

