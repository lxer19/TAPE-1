URL: ftp://ftp.cs.rochester.edu/pub/u/fuentes/mfi.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/fuentes/fuentespub.html
Root-URL: 
Email: ffuentes,nelsong@cs.rochester.edu  
Title: Learning Dextrous Manipulation Skills Using Multisensory Information  
Author: Olac Fuentes and Randal C. Nelson 
Address: Rochester, New York 14627  
Affiliation: Computer Science Department University of Rochester  
Abstract: In this paper we present a method for autonomous learning of dextrous manipulation skills with multifin-gered robot hands. We use heuristics derived from observations made on human hands to reduce the degrees of freedom of the task and make learning tractable. Our approach consists of learning and storing a few basic manipulation primitives for a few prototypical objects and then using an associative memory to obtain the required parameters for new objects and/or manipulations. During learning, sensory information from tactile sensors and a position measuring device is used to evaluate the quality of a candidate manipulation. The parameter space of the robot is searched using a modified version of the evolution strategy, which is robust to the noise normally present in real-world complex robotic tasks. Given the difficulty of modeling and simulating accurately the interactions of multiple fingers and an object, and to ensure that the learned skills are applicable in the real world, our system does not rely on simulation; all the experimentation is performed by a physical robot, in this case the 16-degree-of-freedom Utah/MIT hand. Experimental results show that accurate dextrous manipulation skills can be learned by the robot in a short period of time. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Arbib, T. Iberall, and D. Lyons. </author> <title> Coordinated control programs for movements of the hand. </title> <type> Technical Report 83-25, </type> <institution> Department of Computer and Information Science, University of Massachusetts at Amherst, Amherst, Massachusetts, </institution> <year> 1983. </year>
Reference-contexts: Observations made on human hands offer some clues about how to deal with the problem of the high dimensionality of the parameter space of dextrous manipulators. Arbib et al. <ref> [1] </ref> introduced the concept of virtual fingers as a model for task representation at higher levels in the human central nervous system. In this model, a virtual finger is composed of one or more real fingers working together to solve a problem in a task.
Reference: [2] <author> R. E. Bellman. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1957. </year>
Reference-contexts: by means of the robot's interaction with the world. fl This material is based upon work supported by ONR grant N00014-93-I-0221 and NSF IIP Grant CDA-94-01142 Due to the large number of degrees of freedom of dextrous manipulators, machine learning approaches to this problem face the well-known "curse of dimensionality" <ref> [2] </ref>, which states that the number of samples required to learn a task grows exponentially with the number of parameters of the task. Another problem is that autonomous experimentation with real robots is expensive in terms of time and equipment wear.
Reference: [3] <author> A. D. Christiansen, M. T. Mason, and T. M. Mitchell. </author> <title> Learning Reliable Manipulation Strategies without Initial Physical Models. </title> <booktitle> In Proceedings of the 1990 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1224-1230, </pages> <address> Cincin-nati, Ohio, </address> <year> 1990. </year>
Reference-contexts: Their system learned likely to succeed grasping strategies in the form of the azimuth and elevation approach angles of the gripper to the object given a superellipsoid fit of the object as input. Christiansen, Mason and Mitchell <ref> [3] </ref> described a system that learned models of manipulation actions from observations of the effects of such actions. In their experimental implementation, a robot learned how to re-position and re-orient an object located on a tray, held by the robot from underneath, by a sequence of tray tilts.
Reference: [4] <author> G. B. Dunn and J. Segen. </author> <title> Automatic discovery of robotic grasping configurations. </title> <booktitle> In Proceedings of the 1988 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 396-401, </pages> <year> 1988. </year>
Reference-contexts: In general, these approaches have dealt with simple tasks such as grasping with parallel jaw grippers, and simple manipulation strategies using robot arms. Dunn and Segen <ref> [4] </ref> presented a robotic system that learns how to grasp objects. In their system, when an object is presented for the first time the robot experiments with it, seeking a way to grasp it by trial and error using visual information and input from the robot gripper.
Reference: [5] <author> O. Fuentes and R. C. Nelson. </author> <title> Experiments on dextrous manipulation without prior object models. </title> <type> Technical Report 606, </type> <institution> Computer Science Department, University of Rochester, Rochester, </institution> <address> New York, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Although few quantitative results for other systems have been reported, the quality of the manipulations seems comparable to the one obtained by other systems where the manipulations are programmed by hand, such as <ref> [15, 9, 7, 5] </ref>. function of generation for perceptual goal [25; 0; 0; 0; 0; 0], corresponding to a 25 mm translation along the x axis. [0; 25; 0; 0; 0; 0]. x axis as a function of the generation.
Reference: [6] <author> S. Jacobsen, E. Iversen, D. Knutti, R. Johnson, and K. Bigger. </author> <title> Design of the Utah/MIT Dextrous Hand. </title> <booktitle> In Proceedings of the 1986 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 96-102, </pages> <year> 1986. </year>
Reference-contexts: jj i j meas j jj p j meas j + jj q j meas j jg r g fl j + jg s g fl j 3 Experimental Results The algorithms described in the previous section were implemented in our vision and robotics lab using the Utah/MIT dextrous hand <ref> [6] </ref>. We used an Ascension flock of birds tm magnetic sensor attached to the object being manipulated for position and orientation sensing. For tactile sensing we used interlink tm pressure-sensitive resistors, which were taped to the object. The experimental setup is shown in figure 2.
Reference: [7] <author> M. Jagersand, O. Fuentes, and R. C. Nelson. </author> <title> Acquiring visual-motor models for precision manipulation with robot hands. </title> <booktitle> In Proceedings of the Fourth European Conference on Computer Vision, </booktitle> <editor> Cam-bridge, U. K., </editor> <year> 1996. </year>
Reference-contexts: Although few quantitative results for other systems have been reported, the quality of the manipulations seems comparable to the one obtained by other systems where the manipulations are programmed by hand, such as <ref> [15, 9, 7, 5] </ref>. function of generation for perceptual goal [25; 0; 0; 0; 0; 0], corresponding to a 25 mm translation along the x axis. [0; 25; 0; 0; 0; 0]. x axis as a function of the generation.
Reference: [8] <author> I. Kamon, T. Flash, and S. Edelman. </author> <title> Learning to grasp using visual information. </title> <type> Technical report, </type> <institution> The Weizmann Institute of Science, Revhovot, Is-rael, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: A discovered grasp is saved along with the object's shape. The system generalizes to different positions and orientations but not to sizes. Kamon et al. <ref> [8] </ref> presented a robotic system that learned to grasp objects with a parallel-jaw gripper using visual information. Their system learns two separate subproblems: to choose grasping points, and to predict the quality of a given grasp. It incrementally improves its performance over the course of a training session.
Reference: [9] <author> P. Michelman and P. Allen. </author> <title> Compliant manipulation with a dexterous robot hand. </title> <booktitle> In Proceedings of the 1993 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 711-716, </pages> <address> Atlanta, Georgia, </address> <year> 1993. </year>
Reference-contexts: Although few quantitative results for other systems have been reported, the quality of the manipulations seems comparable to the one obtained by other systems where the manipulations are programmed by hand, such as <ref> [15, 9, 7, 5] </ref>. function of generation for perceptual goal [25; 0; 0; 0; 0; 0], corresponding to a 25 mm translation along the x axis. [0; 25; 0; 0; 0; 0]. x axis as a function of the generation.
Reference: [10] <author> S. Narasimhan. </author> <title> Dexterous robot hands: Kinematics and control. </title> <type> Master's thesis, </type> <institution> MIT Artificial Intelligence Laboratory, Cambridge, Massachusetts, </institution> <month> November </month> <year> 1988. </year>
Reference-contexts: To solve this redundancy we use another observation made on human hands, namely, that the angles of the last two joints of each finger are roughly equal 3 . This form of redundancy resolution and 3 This observation has been used in other systems (e. g. <ref> [10] </ref>) for computing the inverse kinematics of the Utah/MIT hand. the use of virtual fingers, reduce the dimensionality of the parameter space from 16 to 6 and make autonomous learning in a reasonably short period of time feasible. <p> After approximately 25 generations a good level of performance is attained. Near the goal, further exploration yields slower improvement, due in part to the fact that the noise makes the choices between two very similar parameter sets almost random. After 63 generations the prespecified accu <ref> [0; 0; 10; 0; 0; 0] </ref>. <p> After 63 generations the prespecified accu [0; 0; 10; 0; 0; 0]. Goal Position Error Orientation Error [25, 0, 0, 0, 0, 0] 1.21 1.56 [0, 25, 0, 0, 0, 0] 2.08 6.64 <ref> [0, 0, 10, 0, 0, 0] </ref> 1.79 2.99 Table 2: Goal positions and errors for a few selected learned manipulations. racy was obtained and the program stopped. <p> The final error was slightly larger in position and smaller in orientation, with a a final perception of p = [0:99; 26:28; 0:11; 0:243; 0:091; 0:066], an error of 1.6 mm in position and 0.26 degrees in orientation. Figure 8 shows the learning plot for p = <ref> [0; 0; 10; 0; 0; 0] </ref>; the overall behavior of the optimization is similar to the previous two cases. Table 2 shows goal positions, actual positions after learning and errors for a few selected manipulations. In general the results are consistent with the ones described above. new objects.
Reference: [11] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: It incrementally improves its performance over the course of a training session. The system used very little information about the target object; in particular, no attempt was made to recover the object's shape. Salganicoff et al. [13] used a modified version of the ID-3 inductive learning algorithm <ref> [11] </ref> in a robotic system that learned to grasp objects using visual information. Their system learned likely to succeed grasping strategies in the form of the azimuth and elevation approach angles of the gripper to the object given a superellipsoid fit of the object as input.
Reference: [12] <author> I. Rechenberg. </author> <title> Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der biolo-gischen Evolution. </title> <publisher> Frommann-Holzboog Verlag, Stuttgart, </publisher> <year> 1973. </year>
Reference-contexts: The choice of 1 5 as a constant to modify and is based on Rechenberg's 1/5 success rule <ref> [12] </ref> and was proven to be optimal for a restricted kind of object functions and has been observed to work well in practice. The learning algorithm is used to fill-up a table containing virtual finger commands and indexed by object and perceptual goal as shown in table 1.
Reference: [13] <author> M. Salganicoff, L. G. Kunin, and L. H. Ungar. </author> <title> Active exploration based ID-3 learning for robot grasping. </title> <booktitle> In 1994 Workshop on Robot Learning, </booktitle> <address> New Brunswick, NJ, </address> <year> 1994. </year>
Reference-contexts: It incrementally improves its performance over the course of a training session. The system used very little information about the target object; in particular, no attempt was made to recover the object's shape. Salganicoff et al. <ref> [13] </ref> used a modified version of the ID-3 inductive learning algorithm [11] in a robotic system that learned to grasp objects using visual information.
Reference: [14] <author> H.-P. Schwefel. </author> <title> Numerical Optimization of Computer Models. </title> <publisher> John Wiley & Sons, Ltd., </publisher> <year> 1981. </year>
Reference-contexts: Therefore we have to resort to optimization techniques that are better at dealing with local minima and handling an apparently non-deterministic environment. The optimization method we use is a modification of the well-known evolution strategy <ref> [14] </ref>, an iterative probabilistic optimization algorithm loosely based on biological evolution.
Reference: [15] <author> T. H. Speeter. </author> <title> Primitive Based Control of the Utah/MIT Dextrous Hand. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 866-877, </pages> <address> Sacramento, California, </address> <year> 1991. </year>
Reference-contexts: Essentially, the system learns to manipulate objects using 1 These primitives are analogous to Speeter's motion primitives <ref> [15] </ref>, but in his system the primitives were supplied by the programmer, while in ours they are learned automatically. two 3 degree-of-freedom virtual fingers, while the programmer provides the mappings from virtual finger parameters to the joint angles of the particular robot used. <p> Although few quantitative results for other systems have been reported, the quality of the manipulations seems comparable to the one obtained by other systems where the manipulations are programmed by hand, such as <ref> [15, 9, 7, 5] </ref>. function of generation for perceptual goal [25; 0; 0; 0; 0; 0], corresponding to a 25 mm translation along the x axis. [0; 25; 0; 0; 0; 0]. x axis as a function of the generation.
References-found: 15

