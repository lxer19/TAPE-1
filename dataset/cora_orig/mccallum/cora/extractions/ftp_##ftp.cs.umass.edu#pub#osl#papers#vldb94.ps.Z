URL: ftp://ftp.cs.umass.edu/pub/osl/papers/vldb94.ps.Z
Refering-URL: http://www.cs.umass.edu/~brown/
Root-URL: 
Email: brown@cs.umass.edu  callan@cs.umass.edu  croft@cs.umass.edu  
Title: Fast Incremental Indexing for Full-Text Information Retrieval  
Author: Eric W. Brown James P. Callan W. Bruce Croft 
Keyword: full-text document retrieval, incremental indexing, persistent object store, perfor mance  
Address: Amherst, MA 01003 USA  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: Full-text information retrieval systems have traditionally been designed for archival environments. They often provide little or no support for adding new documents to an existing document collection, requiring instead that the entire collection be re-indexed. Modern applications, such as information filtering, operate in dynamic environments that require frequent additions to document collections. We provide this ability using a traditional inverted file index built on top of a persistent object store. The data management facilities of the persistent object store are used to produce efficient incremental update of the inverted lists. We describe our system and present experimental results showing superior incremental indexing and competitive query processing performance. 
Abstract-found: 1
Intro-found: 1
Reference: [BCCM94] <author> Eric W. Brown, James P. Callan, W. Bruce Croft, and J. Eliot B. Moss. </author> <title> Supporting full-text information retrieval with a persistent object store. </title> <booktitle> In Proc. of the 4th Inter. Conf. on Extending Database Technology, </booktitle> <pages> pages 365-378, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Instead, we would prefer the cost of the update to be proportional to the size of the new documents being added. The INQUERY full-text information retrieval system [TC91, CCH92] provides this desirable update performance using the Mneme persistent object store [Mos90] to manage its inverted file index <ref> [BCCM94] </ref>. The key to providing fast incremental indexing is a unique inverted file structure made possible by the data management facilities of the persistent object store. Inverted lists are allocated in fixed size objects with a finite range of sizes, limiting the number of relocations a growing list will experience. <p> Most of the inverted file size is accounted for by a very small number of large inverted lists. These inverted lists will experience continuous, possibly vigorous growth. We have also observed that these large lists have a high probability of being accessed during query processing <ref> [BCCM94] </ref>, so they must be allocated in a manner that affords efficient access. <p> Their data structure manages small inverted lists in buckets (similar to the disk blocks in [ZMSD92]) and dynamically selects large inverted lists to be managed separately, not unlike our use of different object pools for different sized lists <ref> [BCCM94] </ref>. Their simulation results indicate that the best long list allocation scheme for update performance is to write the new portion of a long list in a new chunk at the end of the file. This is essentially what we do with our linked lists.
Reference: [CCH92] <author> James P. Callan, W. Bruce Croft, and Stephen M. Harding. </author> <title> The INQUERY retrieval system. </title> <booktitle> In Proc. of the 3rd Inter. Conf. on Database and Expert Sys. Apps., </booktitle> <month> September </month> <year> 1992. </year>
Reference-contexts: Instead, we would prefer the cost of the update to be proportional to the size of the new documents being added. The INQUERY full-text information retrieval system <ref> [TC91, CCH92] </ref> provides this desirable update performance using the Mneme persistent object store [Mos90] to manage its inverted file index [BCCM94]. The key to providing fast incremental indexing is a unique inverted file structure made possible by the data management facilities of the persistent object store. <p> Throughout the paper we will refer to the system as it is described here as the old version. 2.1 INQUERY INQUERY is a probabilistic information retrieval system based upon a Bayesian inference network model <ref> [TC91, CCH92] </ref>. The power of the inference network model is the consistent formalism it provides for reasoning about evidence of differing types, allowing multiple retrieval models, document representations, and query representations to be combined simultaneously.
Reference: [CP90] <author> Doug Cutting and Jan Pedersen. </author> <title> Optimizations for dynamic inverted index maintenance. </title> <booktitle> In Proc. of the 13th Inter. ACM SIGIR Conf. on Res. and Develop. in Infor. Retr., </booktitle> <pages> pages 405-411, </pages> <year> 1990. </year>
Reference-contexts: Rather than argue analytically, we have shown experimentally that our scheme provides good update and search costs, with acceptable space overheads. Cutting and Pedersen <ref> [CP90] </ref> investigate optimizations for dynamic update of inverted lists managed with a B-tree. For a speed optimization, they propose accumulating postings in a main memory postings buffer, and give both analytical and experimental results.
Reference: [Fal85] <author> Christos Faloutsos. </author> <title> Access methods for text. </title> <journal> ACM Computing Surveys, </journal> <volume> 17 </volume> <pages> 50-74, </pages> <year> 1985. </year>
Reference-contexts: A prerequisite to supporting a growing document collection is the ability to update the data structures used to index the collection. An indexing structure used by many IR systems is the inverted file index <ref> [SM83, Fal85, HFBYL92] </ref>. An inverted file index consists of a record, or inverted list, for each term that appears in the document collection. A term's inverted list stores a document identifier and weight for every document in which the term appears. <p> Faloutsos <ref> [Fal85] </ref> gives an early survey of the common indexing techniques. The two techniques that seem to predominate are signature files and inverted files. Since INQUERY uses an inverted file index, we do not discuss signature files.
Reference: [FJ92a] <author> Christos Faloutsos and H. V. Jagadish. </author> <title> Hybrid index organizations for text databases. </title> <booktitle> In Proc. of the 3rd Inter. Conf. on Extending Database Technology, </booktitle> <pages> pages 310-327, </pages> <year> 1992. </year>
Reference-contexts: Moreover, their simulations assume that all buckets can fit in main memory during indexing, potentially requiring significant main memory resources. Our scheme makes no such assumption, requiring substantially less main memory. Another scheme that handles large lists distinctly from small lists is proposed by Faloutsos and Jagadish <ref> [FJ92a] </ref>. In their scheme, small lists are stored as inverted lists, while large lists are stored as signature files. Again, we are primarily concerned with inverted lists and do not consider signature file solutions.
Reference: [FJ92b] <author> Christos Faloutsos and H. V. Jagadish. </author> <title> On b-tree indices for skewed distributions. </title> <booktitle> In Proc. of the 18th Inter. Conf. on VLDB, </booktitle> <pages> pages 363-374, </pages> <address> Vancouver, </address> <year> 1992. </year>
Reference-contexts: In their scheme, small lists are stored as inverted lists, while large lists are stored as signature files. Again, we are primarily concerned with inverted lists and do not consider signature file solutions. In <ref> [FJ92b] </ref>, Faloutsos and Jagadish examine update and storage costs for a family of long inverted list implementations, where the general case is their HYBRID scheme.
Reference: [FL91] <author> Edward A. Fox and Whay C. Lee. FAST-INV: </author> <title> A fast algorithm for building large inverted files. </title> <type> Technical Report TR-91-10, </type> <institution> VPI&SU Department of Computer Science, Blacksburg, VA, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Increasing I/O and main memory costs for the term dictionary for the sake of rarely accessed inverted lists would be disastrous. A number of other approaches to document indexing have been proposed. Fox and Lee <ref> [FL91] </ref> describe a technique that eliminates the sorting involved in indexing by making multiple passes over the input documents. Indexing is divided into loads, where a load is a contiguous chunk of the final inverted file. First, an initial pass over the input is made to determine the load boundaries.
Reference: [Har94] <author> Donna Harman, </author> <title> editor. </title> <booktitle> The Second Text REtrieval Conference (TREC2). National Institute of Standards and Technology Special Publication, </booktitle> <address> Gaithersburg, MD, </address> <year> 1994. </year>
Reference-contexts: Extensive testing has shown IN-QUERY to be one of the best IR systems, as measured by the standard IR metrics of recall and precision <ref> [Har94, TC92] </ref>. INQUERY is fast, scales well to large document collections, and can be embedded in specialized applications. In INQUERY, document retrieval is accomplished by combining evidence from the document collection with ev idence from the query to produce a ranking of the documents in the collection.
Reference: [Hea78] <author> H. S. </author> <title> Heaps. Information Retrieval, Computational and Theoretical Aspects. </title> <publisher> Academic Press, Inc., </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: Therefore, they should be allocated in a space efficient manner, i.e., reserving extra space for these lists in anticipation of growth would be a mistake. Also, it is well known that the vocabulary will continue to grow indefinitely <ref> [Hea78] </ref>, so we must always be prepared to create more of these small inverted lists. Most of the inverted file size is accounted for by a very small number of large inverted lists. These inverted lists will experience continuous, possibly vigorous growth.
Reference: [HFBYL92] <author> Donna Harman, Edward Fox, Ricardo Baeza-Yates, and Whay Lee. </author> <title> Inverted files. </title> <editor> In William B. Frakes and Ricardo Baeza-Yates, editors, </editor> <booktitle> Information Retrieval: Data Structures & Algorithms, chapter 3, </booktitle> <pages> pages 28-43. </pages> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: A prerequisite to supporting a growing document collection is the ability to update the data structures used to index the collection. An indexing structure used by many IR systems is the inverted file index <ref> [SM83, Fal85, HFBYL92] </ref>. An inverted file index consists of a record, or inverted list, for each term that appears in the document collection. A term's inverted list stores a document identifier and weight for every document in which the term appears. <p> How these operations are implemented determines the policies used to manage the buffer. 3 Indexing The old version of INQUERY uses the traditional method of indexing a document collection and building the inverted Page 2 file <ref> [HFBYL92] </ref>. This method is referred to as the alternative scheme in [STGM94]. The process involves multiple steps, diagramed in Figure 1. The input to the process is a file of documents, which in INQUERY may currently be at most 256 Mbytes 1 .
Reference: [Mos90] <author> J. Eliot B. Moss. </author> <title> Design of the Mneme persistent object store. </title> <journal> ACM Trans. Inf. Syst., </journal> <volume> 8(2) </volume> <pages> 103-139, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Instead, we would prefer the cost of the update to be proportional to the size of the new documents being added. The INQUERY full-text information retrieval system [TC91, CCH92] provides this desirable update performance using the Mneme persistent object store <ref> [Mos90] </ref> to manage its inverted file index [BCCM94]. The key to providing fast incremental indexing is a unique inverted file structure made possible by the data management facilities of the persistent object store. <p> A term's entry in the dictionary contains collection statistics for the term and a reference to the term's inverted list. Inverted lists are stored as Mneme objects, where a single object of the exact size is allocated for each inverted list. 2.2 Mneme The Mneme persistent object store <ref> [Mos90] </ref> was designed to be efficient and extensible. The basic services provided by Mneme are storage and retrieval of objects, where an object is a chunk of contiguous bytes that has been assigned a unique identifier. Mneme has no notion of type or class for objects.
Reference: [MZ94a] <author> Alistair Moffat and Justin Zobel. </author> <title> Compression and fast indexing for multi-gigabyte text databases. </title> <journal> Australian Comput. J., </journal> <volume> 26(1) </volume> <pages> 1-9, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: They also enhance the traditional sort-based method with compression techniques and in-place and mul-tiway merging to greatly improve efficiency in terms of main memory, disk space, and time. Results of applying some of these techniques to the TIPSTER document collection are presented in <ref> [MZ94a] </ref>. All of these other approaches were developed for large static document collections, and do not directly support incremental indexing. Some of the techniques, such as the sorting enhancements and making multiple passes through the input to pre-allocate the output, might be usefully incorporated into an incremental system.
Reference: [MZ94b] <author> Alistair Moffat and Justin Zobel. </author> <title> Self-indexing inverted files for fast text retrieval. </title> <type> Technical Report 94/2, </type> <institution> Collaborative Information Technology Research Institute, Department of Computer Science, Royal Melbourne Institute of Technology, Australia, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: In this model, the inverted lists are read in small chunks, a technique ideally suited to the linked list structure. Second, our inverted file structure might be combined with the query optimization techniques proposed by Wong and Lee [WL93] and Moffat and Zobel <ref> [MZ94b] </ref>, who describe methods for eliminating processing on portions of inverted lists. Again, the linked list structure could be used to avoid I/O on these portions of the lists. Third, buffer management has not been tuned for the new file structure.
Reference: [SM83] <author> Gerard Salton and Michael J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: A prerequisite to supporting a growing document collection is the ability to update the data structures used to index the collection. An indexing structure used by many IR systems is the inverted file index <ref> [SM83, Fal85, HFBYL92] </ref>. An inverted file index consists of a record, or inverted list, for each term that appears in the document collection. A term's inverted list stores a document identifier and weight for every document in which the term appears.
Reference: [STGM94] <author> Kurt Shoens, Anthony Tomasic, and Hector Garcia-Molina. </author> <title> Synthetic workload performance analysis of incremental updates. </title> <booktitle> In Proc. of the 17th Inter. ACM SIGIR Conf. on Res. and Develop. in Infor. </booktitle> <address> Retr., Dublin, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: How these operations are implemented determines the policies used to manage the buffer. 3 Indexing The old version of INQUERY uses the traditional method of indexing a document collection and building the inverted Page 2 file [HFBYL92]. This method is referred to as the alternative scheme in <ref> [STGM94] </ref>. The process involves multiple steps, diagramed in Figure 1. The input to the process is a file of documents, which in INQUERY may currently be at most 256 Mbytes 1 . Collections larger than this limit must be broken up into multiple files. <p> Tomasic et al. [TGMS94] propose a new data structure to support incremental indexing, and present a detailed simulation study over a variety of disk allocation schemes. The study is extended with a larger synthetic document collection in <ref> [STGM94] </ref>, and a comparison is made with the traditional indexing technique. Their data structure manages small inverted lists in buckets (similar to the disk blocks in [ZMSD92]) and dynamically selects large inverted lists to be managed separately, not unlike our use of different object pools for different sized lists [BCCM94].
Reference: [TC91] <author> Howard Turtle and W. Bruce Croft. </author> <title> Evaluation of an inference network-based retrieval model. </title> <journal> ACM Trans. Inf. Syst., </journal> <volume> 9(3) </volume> <pages> 187-222, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Instead, we would prefer the cost of the update to be proportional to the size of the new documents being added. The INQUERY full-text information retrieval system <ref> [TC91, CCH92] </ref> provides this desirable update performance using the Mneme persistent object store [Mos90] to manage its inverted file index [BCCM94]. The key to providing fast incremental indexing is a unique inverted file structure made possible by the data management facilities of the persistent object store. <p> Throughout the paper we will refer to the system as it is described here as the old version. 2.1 INQUERY INQUERY is a probabilistic information retrieval system based upon a Bayesian inference network model <ref> [TC91, CCH92] </ref>. The power of the inference network model is the consistent formalism it provides for reasoning about evidence of differing types, allowing multiple retrieval models, document representations, and query representations to be combined simultaneously.
Reference: [TC92] <author> Howard R. Turtle and W. Bruce Croft. </author> <title> A comparison of text retrieval models. </title> <journal> Comput. J., </journal> <volume> 35(3) </volume> <pages> 279-290, </pages> <year> 1992. </year>
Reference-contexts: Extensive testing has shown IN-QUERY to be one of the best IR systems, as measured by the standard IR metrics of recall and precision <ref> [Har94, TC92] </ref>. INQUERY is fast, scales well to large document collections, and can be embedded in specialized applications. In INQUERY, document retrieval is accomplished by combining evidence from the document collection with ev idence from the query to produce a ranking of the documents in the collection.
Reference: [TGMS94] <author> Anthony Tomasic, Hector Garcia-Molina, and Kurt Shoens. </author> <title> Incremental updates of inverted lists for text document retrieval. </title> <booktitle> In Proc. of the ACM SIGMOD Inter. Conf. on Management of Data, </booktitle> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Techniques for handling inverted lists larger than a disk block are not discussed, nor is the disk block technique fully evaluated. Our experience indicates that efficient management of large inverted lists is critical to performance, and we present experimental results demonstrating the effectiveness of our solution. Tomasic et al. <ref> [TGMS94] </ref> propose a new data structure to support incremental indexing, and present a detailed simulation study over a variety of disk allocation schemes. The study is extended with a larger synthetic document collection in [STGM94], and a comparison is made with the traditional indexing technique.
Reference: [Wil84] <author> Peter Willett. </author> <title> A nearest neighbour search algorithm for bibliographic retrieval from multilist files. </title> <journal> Inform. Tech., </journal> <volume> 3(2) </volume> <pages> 78-83, </pages> <month> April </month> <year> 1984. </year> <pages> Page 10 </pages>
Reference-contexts: We expect that query processing can be further improved for the following reasons. First, the query processing model used in these experiments is term-at-a-time, where the entire inverted list for a term is read and processed all at once. Many modern systems have adopted document-at-a-time processing <ref> [Wil84] </ref>, which calculates the complete score for one document before proceeding to the next. In this model, the inverted lists are read in small chunks, a technique ideally suited to the linked list structure.
Reference: [WL93] <author> Wai Yee Peter Wong and Dik Lun Lee. </author> <title> Implementations of partial document ranking using inverted files. </title> <journal> Inf. Process. & Mgmnt., </journal> <volume> 29(5) </volume> <pages> 647-669, </pages> <year> 1993. </year>
Reference-contexts: In this model, the inverted lists are read in small chunks, a technique ideally suited to the linked list structure. Second, our inverted file structure might be combined with the query optimization techniques proposed by Wong and Lee <ref> [WL93] </ref> and Moffat and Zobel [MZ94b], who describe methods for eliminating processing on portions of inverted lists. Again, the linked list structure could be used to avoid I/O on these portions of the lists. Third, buffer management has not been tuned for the new file structure.
Reference: [WMB94] <author> Ian H. Witten, Alistair Moffat, and Timothy C. Bell. </author> <title> Managing Gigabytes: Compressing and Indexing Documents and Images. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: At the end of the pass, the inverted lists for the load can simply be appended to the inverted file. Witten et al. <ref> [WMB94] </ref> present a variety of indexing algorithms, including an extended version of Fox and Lee's algorithm. They also enhance the traditional sort-based method with compression techniques and in-place and mul-tiway merging to greatly improve efficiency in terms of main memory, disk space, and time.
Reference: [Wol92a] <author> Dietmar Wolfram. </author> <title> Applying informetric characteristics of databases to IR system file design, Part I: informetric models. </title> <journal> Inf. Process. & Mgmnt., </journal> <volume> 28(1) </volume> <pages> 121-133, </pages> <year> 1992. </year>
Reference-contexts: A better integration might use one of the above algorithms the first time a large collection is indexed, and switch to an incremental technique thereafter. Properly modeling the size distribution of inverted lists is addressed by Wolfram in <ref> [Wol92a, Wol92b] </ref>. He suggests that the informetric characteristics of document databases should be taken into consideration when designing the files used by an IR system.
Reference: [Wol92b] <author> Dietmar Wolfram. </author> <title> Applying informetric characteristics of databases to IR system file design, Part II: simulation comparisons. </title> <journal> Inf. Process. & Mgmnt., </journal> <volume> 28(1) </volume> <pages> 135-151, </pages> <year> 1992. </year>
Reference-contexts: A better integration might use one of the above algorithms the first time a large collection is indexed, and switch to an incremental technique thereafter. Properly modeling the size distribution of inverted lists is addressed by Wolfram in <ref> [Wol92a, Wol92b] </ref>. He suggests that the informetric characteristics of document databases should be taken into consideration when designing the files used by an IR system.
Reference: [Zip49] <author> George Kingsley Zipf. </author> <title> Human Behavior and the Principle of Least Effort. </title> <publisher> Addison-Wesley Press, </publisher> <year> 1949. </year>
Reference-contexts: To guide this design, we first consider some of the characteristics of inverted lists, all of which can be derived from the early observations of Zipf <ref> [Zip49] </ref>. Figure 2 shows the distribution of inverted list sizes for the TIPSTER volume 1 document collection used in our performance evaluation below (see Table 1).
Reference: [ZMSD92] <author> Justin Zobel, Alistair Moffat, and Ron Sacks-Davis. </author> <title> An efficient indexing technique for full-text database systems. </title> <booktitle> In Proc. of the 18th Inter. Conf. on VLDB, </booktitle> <pages> pages 352-362, </pages> <address> Vancouver, </address> <year> 1992. </year> <pages> Page 11 </pages>
Reference-contexts: Faloutsos [Fal85] gives an early survey of the common indexing techniques. The two techniques that seem to predominate are signature files and inverted files. Since INQUERY uses an inverted file index, we do not discuss signature files. Zobel et al. <ref> [ZMSD92] </ref> investigate the efficient implementation of an inverted file index for a full-text database system. Their focus is on compression techniques to limit the size of the inverted file index. These techniques could be usefully incorporated into our system. <p> The study is extended with a larger synthetic document collection in [STGM94], and a comparison is made with the traditional indexing technique. Their data structure manages small inverted lists in buckets (similar to the disk blocks in <ref> [ZMSD92] </ref>) and dynamically selects large inverted lists to be managed separately, not unlike our use of different object pools for different sized lists [BCCM94].
References-found: 25

