URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3176/3176.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: HUMAN FACE SEGMENTATION AND IDENTIFICATION  
Author: Saad Ahmed Sirohey 
Address: College Park, MD 20742-3275  
Affiliation: Computer Vision Laboratory Center for Automation Research University of Maryland  
Date: November 1993  
Pubnum: CAR-TR-695 DACA76-92-C-0009  
Abstract: This thesis considers segmentation and identification of human faces from grey scale images with clutter. The segmentation developed utilizes the elliptical structure of the human head. It uses the information present in the edge map of the image and through some preprocessing separates the head from the background clutter. An ellipse is then fitted to mark the boundary between the head region and the background. The identification procedure finds feature points in the segmented face through a Gabor wavelet decomposition and performs graph matching. The segmentation and identification algorithms were tested on a database of 48 images of 16 persons with encouraging results. The support of the Advanced Research Projects Agency (ARPA Order No. 8459) and the U.S. Army Topographic Engineering Center under Contract DACA76-92-C-0009 is gratefully acknowledged, as is the help of Sandy German in preparing this paper. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. H. Ballard. </author> <title> Generalizing the Hough transform to detect arbitrary shapes. </title> <journal> Pattern Recognition, </journal> <volume> 13 </volume> <pages> 111-122, </pages> <year> 1981. </year>
Reference-contexts: Several methods were considered to realize this approach. These methods were tested both on images with uniform backgrounds and on images having moderately cluttered backgrounds. One such method, utilizing the Hough transform <ref> [1, 12] </ref>, was considered, at first, to be the best approach. This method is described below, where we will also mention our reason for not opting for this method. 3.1 Elliptic Hough Transform The basis of the Hough transformation is the use of a parameter domain. <p> In the case of the elliptic Hough transform this means, given a point (x; y) in the plane, find the parameters of an ellipse passing through that point (see Ballard <ref> [1] </ref>). The parameters are the center point (x 0 ; y 0 ), the semi-major axis a, and the semi-minor axis b of the ellipse. The method of finding them is outlined below. 1.
Reference: [2] <author> R. Brunelli and T. Poggio. </author> <title> Face recognition through geometrical features. </title> <booktitle> Proc. Euro-pean Conf. Computer Vision, </booktitle> <pages> pages 792-800, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Kanade was one of the earliest researcher on automatic face recognition, as reported in his pioneering work [9]. He used projection analysis on a binary image obtained by applying a Laplacian operator to the grey scale image. Brunelli and Poggio <ref> [2] </ref> augmented the projection analysis by performing vertical and horizontal edge detection. They also discussed the classification of automatic face identification methods into two broad classes of techniques, geometric feature based matching and template matching.
Reference: [3] <author> R. Brunelli and T. Poggio. </author> <title> Hyperbf networks for gender classification. </title> <booktitle> Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 311-314, </pages> <year> 1992. </year>
Reference-contexts: They also discussed the classification of automatic face identification methods into two broad classes of techniques, geometric feature based matching and template matching. Geometric feature based matching involves decomposing the face image into pertinent features like eyes, nose, mouth, chin, etc. Several studies <ref> [3, 5, 6, 10, 11] </ref> involve, in one way or another, feature based identification. The features range from the locations of eyes, nose, mouth and chin and their spatial relationship to one another [3] to feature point detection utilizing Gabor 5 wavelet decomposition [10]. <p> Several studies [3, 5, 6, 10, 11] involve, in one way or another, feature based identification. The features range from the locations of eyes, nose, mouth and chin and their spatial relationship to one another <ref> [3] </ref> to feature point detection utilizing Gabor 5 wavelet decomposition [10]. For matching or identification purposes, the relevant information present in the spatial structure of these features, compensated for scale and orientation, is compared with a known database.
Reference: [4] <author> J. Canny. </author> <title> A computational approach to edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-8:679-689, </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: The following procedure was developed for the image database obtained from MIT. It assumes that a good edge map of the image is available. This is obtained by using the Canny edge detector <ref> [4] </ref> from the KBVision software package. The remaining discussion will assume the availability of an edge map of the intensity image. 3.4.1 Removal of Intersection Points numerous intersecting edge segments. If it is cross-referenced with its parent intensity image, (a) (b) these intersections can be attributed to occlusions of objects.
Reference: [5] <author> I. Craw, D. Tock, and A. Bennett. </author> <title> Finding face features. </title> <booktitle> Proc. European Conf. Computer Vision, </booktitle> <pages> pages 92-96, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: They also discussed the classification of automatic face identification methods into two broad classes of techniques, geometric feature based matching and template matching. Geometric feature based matching involves decomposing the face image into pertinent features like eyes, nose, mouth, chin, etc. Several studies <ref> [3, 5, 6, 10, 11] </ref> involve, in one way or another, feature based identification. The features range from the locations of eyes, nose, mouth and chin and their spatial relationship to one another [3] to feature point detection utilizing Gabor 5 wavelet decomposition [10].
Reference: [6] <author> S. Edelman, D. Reisfeld, and Y. Yeshurun. </author> <title> Learning to recognize faces from examples. </title> <booktitle> Proc. European Conf. Computer Vision, </booktitle> <pages> pages 787-791, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: They also discussed the classification of automatic face identification methods into two broad classes of techniques, geometric feature based matching and template matching. Geometric feature based matching involves decomposing the face image into pertinent features like eyes, nose, mouth, chin, etc. Several studies <ref> [3, 5, 6, 10, 11] </ref> involve, in one way or another, feature based identification. The features range from the locations of eyes, nose, mouth and chin and their spatial relationship to one another [3] to feature point detection utilizing Gabor 5 wavelet decomposition [10].
Reference: [7] <author> G. G. Gordon. </author> <title> Application of morphology to feature extraction for face recognition. </title> <booktitle> In Proc. SPIE, </booktitle> <volume> Vol. 1658, </volume> <month> February </month> <year> 1992. </year>
Reference-contexts: Intuitively, a 3-D representation provides an added dimension to the useful information available from the data for the description of the face. Furthermore, the problem of segmentation of the face from the background becomes a trivial exercise. Two studies <ref> [7, 14] </ref> have demonstrated the advantages of having this additional information.
Reference: [8] <author> V. Govindaraju, S. N. Srihari, and D. B. Sher. </author> <title> A computational model for face location. </title> <booktitle> Proc. Intl. Conf. Computer Vision, </booktitle> <pages> pages 718-721, </pages> <year> 1990. </year>
Reference-contexts: However, the starting point of the template was critical to their approach. Govindaraju, Srihari and Sher <ref> [8] </ref> attempted to locate the face in an image using a model template constructed of a hair curve and face side curves. They used a cost function approach to group together prospective left and right face side curves having the appropriate displacement and angular orientation.
Reference: [9] <author> T. Kanade. </author> <title> Picture Processing System by Computer Complex and Recognition of Human Faces. </title> <type> PhD thesis, </type> <institution> Dept. of Information Science, Kyoto University, </institution> <address> Japan, </address> <month> November </month> <year> 1973. </year>
Reference-contexts: Kanade was one of the earliest researcher on automatic face recognition, as reported in his pioneering work <ref> [9] </ref>. He used projection analysis on a binary image obtained by applying a Laplacian operator to the grey scale image. Brunelli and Poggio [2] augmented the projection analysis by performing vertical and horizontal edge detection. <p> For matching or identification purposes, the relevant information present in the spatial structure of these features, compensated for scale and orientation, is compared with a known database. Work on this technique started primarily with Kanade <ref> [9] </ref>; it has blossomed into a very promising technique for face identification. Another class of techniques is the template matching approach. The general idea behind this approach is the construction of an artificial template to match with the prominent features of the face.
Reference: [10] <author> B. S. Manjunath, R. Chellappa, and C. von der Malsburg. </author> <title> A feature based approach to face recognition. </title> <booktitle> Proc. IEEE Conf. Computer Vision Pattern Recognition, </booktitle> <pages> pages 373-378, </pages> <year> 1992. </year>
Reference-contexts: One such feature based approach, utilizing a bank of dilated Gabor wavelet filters, has been used in various image understanding/recognition algorithms. Applications of these algorithms range from image registration [16] to motion analysis [Wu & Chellappa] to a face identification system <ref> [10] </ref>. Intuitively it can be argued that for any system performing face recognition, the first step would be locating the face in the image. Finding the face gives the recognition system a specific area in the image to work on. <p> Under the constraints of real-time implementation, it is required that the algorithm for finding the face be fast. Hence the algorithm developed 2 for locating the face should have the property of being easily transformable into a parallel structure. In Manjunath and Chellappa <ref> [10] </ref>, the image database used for the face identification system consists of face images with a uniform background. This forces the feature points to be located within the head/shoulder region. <p> Since no prior consideration is given to locating the detected features in the face region, images which include part of the upper chest/shoulder area will contain feature points in those areas too. The purpose of this thesis is to extend the face identification system of <ref> [10] </ref> to a more general class of input images, namely, images that need not necessarily have uniform backgrounds, and also to maintain the integrity of the face identification system by segmenting the face region and using it for the purpose of recognition. <p> In this connection, a new face image database was obtained from MIT. This new database consists of face images with moderately cluttered backgrounds. If the algorithm in <ref> [10] </ref> is used without any preprocessing on this database, feature points are detected which are outside the face region. An attempt is made to localize the feature points within the face region of the image. <p> When the approach was tested on a database of 48 images, more than 80% correct seg 3 mentation was achieved. Since we had available to us the recognition algorithm of Manjunath and Chellappa <ref> [10] </ref>, it was used to test the hypothesis that segmentation of the face first will improve the recognition rate. Without segmentation, an accuracy of less than 50% was achieved. This improved to more than 70% with the segmentation algorithm. <p> They also discussed the classification of automatic face identification methods into two broad classes of techniques, geometric feature based matching and template matching. Geometric feature based matching involves decomposing the face image into pertinent features like eyes, nose, mouth, chin, etc. Several studies <ref> [3, 5, 6, 10, 11] </ref> involve, in one way or another, feature based identification. The features range from the locations of eyes, nose, mouth and chin and their spatial relationship to one another [3] to feature point detection utilizing Gabor 5 wavelet decomposition [10]. <p> Several studies [3, 5, 6, 10, 11] involve, in one way or another, feature based identification. The features range from the locations of eyes, nose, mouth and chin and their spatial relationship to one another [3] to feature point detection utilizing Gabor 5 wavelet decomposition <ref> [10] </ref>. For matching or identification purposes, the relevant information present in the spatial structure of these features, compensated for scale and orientation, is compared with a known database. Work on this technique started primarily with Kanade [9]; it has blossomed into a very promising technique for face identification. <p> If an image is segmented so that the only part of the original image that we keep is the elliptical region containing the face, and the remaining background is set to an arbitrary value, then the boundary of this segmentation will cause false feature points to be detected using <ref> [10] </ref>. Furthermore, since most of the fitted ellipses fall within a small range of parameter values, the matching scheme (Section 4.2) will yield false identification results caused by these elliptically configured feature points. <p> The next section considers a more general segmentation algorithm which takes into account the case of a moderately cluttered background; a uniform background can be regarded as a special case of a cluttered background. 10 3.4 Segmentation from Moderately Cluttered Background The feature extraction algorithm (Chapter 4) <ref> [10] </ref> locates the feature points at maxima of local curvature in the intensity image. If the background is other than uniform then the intensity discontinuities in the background will give rise to feature points that are not part of the face region. Since the matching algorithm (Chapter 4) [10] requires all <p> (Chapter 4) <ref> [10] </ref> locates the feature points at maxima of local curvature in the intensity image. If the background is other than uniform then the intensity discontinuities in the background will give rise to feature points that are not part of the face region. Since the matching algorithm (Chapter 4) [10] requires all the feature points in the image to be matched in a graph matching manner, the feature points that lie in the background lower the accuracy of the face identification system. <p> In this experiment the threshold t is set to 0:07 and 1:3 a=b 2:0 is the bound on the aspect ratio of the ellipse. (a) (b) 17 Chapter 4 Face Recognition System 1 The face recognition system uses a biologically motivated algorithm developed by Manjunath and Chellappa <ref> [10] </ref>. It employs a Gabor wavelet decomposition and local scale interaction to extract features at points of curvature maxima in the image, corresponding to orientation and local neighborhood. These feature points are then stored in a database and subsequent target face images are matched using a graph matching technique. In [10] <p> <ref> [10] </ref>. It employs a Gabor wavelet decomposition and local scale interaction to extract features at points of curvature maxima in the image, corresponding to orientation and local neighborhood. These feature points are then stored in a database and subsequent target face images are matched using a graph matching technique. In [10] the algorithm was shown to work with an accuracy of up to 94%, using a database of about 300 images of 88 persons with uniform background. <p> A salient feature of these functions is their ability to achieve minimum 1 Paraphrased from <ref> [10] </ref>. 18 joint resolution in the spatial and frequency domains. The Gabor functions form a complete though non-orthogonal basis set. As in the case of Fourier series, a function g (x; y) can easily be expanded using Gabor functions. <p> The parameters were set at m = 2; n = 5 and the number of orientations N = 4 in (4.8). For graph matching the number of points in the neighborhood was set to 5. 23 (a) (b) Although in <ref> [10] </ref> an accuracy of more than 94% is reported, the new database which was used for the experiments consisted of images taken with a change in the illumination direction.
Reference: [11] <author> D. Reisfeld and Y. Yeshurun. </author> <title> Robust detection of facial features by generalized symmetry. </title> <booktitle> Proc. Intl. Conf. Pattern Recognition, </booktitle> <volume> Vol. 1, </volume> <pages> pages 117-120, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: They also discussed the classification of automatic face identification methods into two broad classes of techniques, geometric feature based matching and template matching. Geometric feature based matching involves decomposing the face image into pertinent features like eyes, nose, mouth, chin, etc. Several studies <ref> [3, 5, 6, 10, 11] </ref> involve, in one way or another, feature based identification. The features range from the locations of eyes, nose, mouth and chin and their spatial relationship to one another [3] to feature point detection utilizing Gabor 5 wavelet decomposition [10].
Reference: [12] <author> S. D. Shapiro. </author> <title> Feature space transforms for curve detection. </title> <journal> Pattern Recognition, </journal> <volume> 10 </volume> <pages> 129-143, </pages> <year> 1978. </year>
Reference-contexts: Several methods were considered to realize this approach. These methods were tested both on images with uniform backgrounds and on images having moderately cluttered backgrounds. One such method, utilizing the Hough transform <ref> [1, 12] </ref>, was considered, at first, to be the best approach. This method is described below, where we will also mention our reason for not opting for this method. 3.1 Elliptic Hough Transform The basis of the Hough transformation is the use of a parameter domain.
Reference: [13] <author> M. A. Turk and A. P. Pentland. </author> <title> Face recognition using eigenfaces. </title> <booktitle> Proc. IEEE Conf. Computer Vision Pattern Recognition, </booktitle> <pages> pages 586-591, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: They do not mention testing their scheme on a large image set, and they state that they often encounter false alarms. Another approach, slightly different from those mentioned above, is used by Turk and Pentland <ref> [13] </ref>. In their approach face images are projected onto a feature space called the "face space". The face space is defined by "eigen-faces", which are determined by the set of eigenvectors of the set of training faces. A new target face is projected onto this face space.
Reference: [14] <author> Y. Yacoob and L. S. Davis. </author> <title> Qualitative labeling of human face components from range data. </title> <type> Technical Report CAR-TR-642, </type> <institution> Center for Automation Research, University of Maryland, College Park, MD, </institution> <year> 1992. </year>
Reference-contexts: Intuitively, a 3-D representation provides an added dimension to the useful information available from the data for the description of the face. Furthermore, the problem of segmentation of the face from the background becomes a trivial exercise. Two studies <ref> [7, 14] </ref> have demonstrated the advantages of having this additional information.
Reference: [15] <author> A. L. Yuille, D. S. Cohen, and P. W. Hallinan. </author> <title> Feature extraction from faces using deformable templates. </title> <booktitle> Proc. IEEE Conf. Computer Vision Pattern Recognition, </booktitle> <pages> pages 104-109, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Another class of techniques is the template matching approach. The general idea behind this approach is the construction of an artificial template to match with the prominent features of the face. Yuille et al. <ref> [15] </ref> described two such templates, one for the eye and the other for the mouth. Utilizing a condition of deformability, and allowing the template to translate and deform to fit its most likely representation in the image, they were able to locate the eyes and the mouth within the face.
Reference: [16] <author> Q. Zheng and R. Chellappa. </author> <title> Automatic feature point extraction and tracking in image sequences for arbitrary camera motion. </title> <type> Technical Report CAR-TR-628, </type> <institution> Center for Automation Research, University of Maryland, College Park, MD, </institution> <year> 1992. </year> <month> 33 </month>
Reference-contexts: One such feature based approach, utilizing a bank of dilated Gabor wavelet filters, has been used in various image understanding/recognition algorithms. Applications of these algorithms range from image registration <ref> [16] </ref> to motion analysis [Wu & Chellappa] to a face identification system [10]. Intuitively it can be argued that for any system performing face recognition, the first step would be locating the face in the image.
References-found: 16

