URL: http://w3c.org/Protocols/HTTP/Performance/Pipeline.ps
Refering-URL: http://www.cs.washington.edu/education/courses/590s/w98/index.html
Root-URL: 
Email: frystyk@w3.org  jg@pa.dec.com  chris@w3.org  
Title: Network Performance Effects of HTTP/1.1, CSS1, and PNG  World Wide Web  World Wide Web Consortium  
Author: Henrik Frystyk Nielsen Consortium James Gettys Anselm Baird-Smith, Eric Prudhommeaux, Hkon Wium Lie, Chris Lilley abaird, eric, howcome, 
Note: Visiting Scientist, World Wide Web Consortium Digital Equipment Corporation  
Abstract: We describe our investigation of the effect of persistent connections, pipelining and link level document compression on our client and server HTTP implementations. A simple test setup is used to verify HTTP/1.1's design and understand HTTP/1.1 implementation strategies. We present TCP and real time performance data between the libwww robot [27] and both the W3Cs Jigsaw [28] and Apache [29] HTTP servers using HTTP/1.0, HTTP/1.1 with persistent connections, HTTP/1.1 with pipelined requests, and HTTP/1.1 with pipelined requests and deflate data compression [22]. We also investigate whether the TCP Nagle algorithm has an effect on HTTP/1.1 performance. While somewhat artificial and possibly overstating the benefits of HTTP/1.1, we believe the tests and results approximate some common behavior seen in browsers. The results confirm that HTTP/1.1 is meeting its major design goals. Our experience has been that implementation details are very important to achieve all of the benefits of HTTP/1.1. For all our tests, a pipelined HTTP/1.1 implementation outperformed HTTP/1.0, even when the HTTP/1.0 implementation used multiple connections in parallel, under all network environments tested. The savings were at least a factor of two, and sometimes as much as a factor of ten, in terms of packets transmitted. Elapsed time improvement is less dramatic, and strongly depends on your network connection. Some data is presented showing further savings possible by changes in Web content, specifically by the use of CSS style sheets [10], and the more compact PNG [20] image representation, both recent recommendations of W3C. Time did not allow full end to end data collection on these cases. The results show that HTTP/1.1 and changes in Web content will have dramatic results in Internet and Web performance as HTTP/1.1 and related technologies deploy over the near future. Universal use of style sheets, even without deployment of HTTP/1.1, would cause a very significant reduction in network traffic. This paper does not investigate further performance and network savings enabled by the improved caching facilities provided by the HTTP/1.1 protocol, or by sophisticated use of range requests. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Padmanabhan, V. N. and J. Mogul, </author> <title> Improving HTTP Latency, Computer Networks and ISDN Systems, </title> <booktitle> v.28, </booktitle> <pages> pp. 25-35, </pages> <month> Dec. </month> <year> 1995. </year> <note> Slightly Revised Version in Proceedings of the 2nd International WWW Conference '94: Mosaic and the Web, </note> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: MNG is an animation format in the PNG family, which along with other advantages - is more compact than animated GIF. 2 Prior Work Padmanabhan and Mogul <ref> [1] </ref> show results from a prototype implementation which extended HTTP to support both persistent connections and pipelining, and study latencies, throughput, and system overhead issues involved in persistent connections. This analysis formed the basic data and justification behind HTTP/1.1's persistent connection and pipelining design. <p> Optimal server implementations for HTTP/1.1 will likely be significantly different than current servers. Connection management is worth further experimentation and modeling. Padmanabhan <ref> [1] </ref> gives some guidance on how long connections should be kept open, but this work needs updating to reflect current content and usage of the Web, which have changed significantly since completion of the work. Persistent connections, pipelining, transport compression, as well as the widespread adoption of style sheets (e.g.
Reference: [2] <author> Nagle, J., </author> <title> Congestion Control in IP/TCP Internetworks, </title> <type> RFC 896, </type> <institution> Ford Aerospace and Communications Corporation, </institution> <month> January </month> <year> 1984. </year>
Reference-contexts: flush buffers automatically after a timeout, taking advantage of knowledge in the application can result in a considerably faster implementation than relying on such a timeout. 4.1.2 Nagle Interaction We expected, due to experience of one of the authors, that a pipelined implementation of HTTP might encounter the Nagle algorithm <ref> [2] </ref> [5] in TCP. The Nagle algorithm was introduced in TCP as a means of reducing the number of small TCP segments by delaying their transmission in hopes of further data becoming available, as commonly occurs in telnet or rlogin traffic.
Reference: [3] <author> Berners-Lee, Tim, R. Fielding, H. Frystyk. </author> <title> Informational RFC 1945 - Hypertext Transfer Protocol - HTTP/1.0, MIT/LCS, </title> <institution> UC Irvine, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: Further information, the data itself (and later data collection runs) can be found on the Web [25]. 1.1 Changes to HTTP HTTP/1.1 [4] is an upward compatible protocol to HTTP/1.0 <ref> [3] </ref>. Both HTTP/1.0 and HTTP/1.1 use the TCP protocol [12] for data transport. However, the two versions of HTTP use TCP differently. HTTP/1.0 opens and closes a new TCP connection for each operation.
Reference: [4] <author> Fielding, R., J. Gettys, J.C. Mogul, H. Frystyk, T. Berners-Lee, </author> <title> RFC 2068 - Hypertext Transfer Protocol - HTTP/1.1, UC Irvine, Digital Equipment Corporation, </title> <publisher> MIT. </publisher>
Reference-contexts: Our hope is that our experience may guide others through their own implementation efforts and help them avoid some nonobvious performance pits we fell into. Further information, the data itself (and later data collection runs) can be found on the Web [25]. 1.1 Changes to HTTP HTTP/1.1 <ref> [4] </ref> is an upward compatible protocol to HTTP/1.0 [3]. Both HTTP/1.0 and HTTP/1.1 use the TCP protocol [12] for data transport. However, the two versions of HTTP use TCP differently. HTTP/1.0 opens and closes a new TCP connection for each operation.
Reference: [5] <author> Touch, J., J. Heidemann, K. Obraczka, </author> <title> Analysis of HTTP Performance, </title> <institution> USC/Information Sciences Institute, </institution> <month> June, </month> <year> 1996. </year>
Reference-contexts: Pipelining, or batching, have been successfully used in a number of other systems, notably graphics protocols such as the X Window System [15] or Trestle [16], in its original RPC based implementation. Touch, Heidemann, and Obraczka <ref> [5] </ref> explore a number of possible changes that might help HTTP behavior, including the sharing of TCP control blocks [19] and Transaction TCP (T/TCP) [17], [18]. <p> buffers automatically after a timeout, taking advantage of knowledge in the application can result in a considerably faster implementation than relying on such a timeout. 4.1.2 Nagle Interaction We expected, due to experience of one of the authors, that a pipelined implementation of HTTP might encounter the Nagle algorithm [2] <ref> [5] </ref> in TCP. The Nagle algorithm was introduced in TCP as a means of reducing the number of small TCP segments by delaying their transmission in hopes of further data becoming available, as commonly occurs in telnet or rlogin traffic.
Reference: [6] <author> Spero, S., </author> <title> Analysis of HTTP Performance Problems, </title> <note> http://www.w3.org/Protocols/HTTP/1.0/HTTPPerformance.html July 1994. </note>
Reference-contexts: Again, because Web objects are small, most objects are transferred before their TCP connection completes the slow start algorithm. In other words, most HTTP/1.0 operations use TCP at its least efficient. The results have been major problems due to resulting congestion and unnecessary overhead <ref> [6] </ref>. HTTP/1.1 leaves the TCP connection open between consecutive operations. This technique is called persistent connections, which both avoids the costs of multiple opens and closes and reduces the impact of slow start. Persistent connections are more efficient than the current practice of running multiple short TCP connections in parallel. <p> His experience is confirmed by our experience described in this paper, and by the experience of one of the authors with the X Window System, which caused the original introduction of the ability to disable Nagle's algorithm into BSD derived TCP implementations. Simon Spero analyzed HTTP/1.0 performance <ref> [6] </ref> and prepared a proposal for a replacement for HTTP. HTTP/1.1, however, was constrained to maintain upward compatibility with HTTP/1.0. Many of his suggestions are worthwhile and should be explored further. Style sheets have a long history in the Web [30].
Reference: [7] <author> Heidemann, J., </author> <title> Performance Interactions Between PHTTP and TCP Implementation, </title> <journal> ACM Computer Communication Review, </journal> <volume> 27 2, </volume> <pages> 65-73, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: T/TCP might help reduce latency when revisiting a Web server after the server has closed its connection. Sharing of TCP control blocks would primarily help HTTP/1.0, however, since the HTTP/1.1 limits the number of connections between a client/server pair. In independent work, Heidemann <ref> [7] </ref> describes the interactions of persistent connections with Nagle's algorithm. <p> In later experiments in which the buffering behavior of the implementations were changed, we did observe significant (sometimes dramatic) transmission delays due to Nagle; we recommend therefore that HTTP/1.1 implementations that buffer output disable Nagle's algorithm (set the TCP_NODELAY socket option). This confirms the experiences of Heidemann <ref> [7] </ref>. We also performed some tests against the Apache 1.2b2 server, which also supports HTTP/1.1, and observed essentially similar results to Jigsaw.
Reference: [8] <author> Shepard, T., </author> <title> Source for this very useful program is available at ftp://mercury.lcs.mit.edu/pub/shep. S.M. thesis TCP Packet Trace Analysis. The thesis can be ordered from MIT/LCS Publications. Ordering information can be obtained from +1 617 253 5851 or send mail to publications@lcs.mit.edu. Ask for MIT/LCS/TR-494. </title>
Reference-contexts: We also used Tim Shepard's xplot program <ref> [8] </ref> to graphically plot the dumps; this was very useful to find a number of problems in our implementation not visible in the raw dumps. We looked at data in both directions of the TCP connections.
Reference: [9] <author> Mogul, J. </author> <note> The Case for Persistent-Connection HTTP, Western Research Laboratory Research Report 95/4, http://www.research.digital.com/wrl/publications/abstracts/95.4. html, </note> <institution> Digital Equipment Corporation, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Range requests need to be exploited to enable good interactive feel in Web browsers while using a single connection. Connections should be maintained as long as makes reasonable engineering sense <ref> [9] </ref>, to pick up user's click ahead while following links. 5 After Initial Tuning Tests To make our final round of tests as close as possible to likely real implementations, we took the opportunity to change the HTTP/1.1 version of the robot to issue full HTTP/1.1 cache validation requests.
Reference: [10] <author> Lie, H., B. Bos, </author> <title> Cascading Style Sheets, level 1, W3C Recommendation, World Wide Web Consortium, </title> <month> 17 Dec </month> <year> 1996. </year>
Reference: [11] <author> Jacobson, Van, </author> <title> Congestion Avoidance and Control. </title> <booktitle> Proceedings of ACM SIGCOMM 88, </booktitle> <pages> page 314-329. </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Since most Web objects are small, this practice means a high fraction of packets are simply TCP control packets used to open and close a connection. Furthermore, when a TCP connection is first opened, TCP employs an algorithm known as slow start <ref> [11] </ref>. Slow start uses the first several data packets to probe the network to determine the optimal transmission rate. Again, because Web objects are small, most objects are transferred before their TCP connection completes the slow start algorithm. In other words, most HTTP/1.0 operations use TCP at its least efficient. <p> Servers must therefore close each half of the connection independently. TCP's congestion control algorithms <ref> [11] </ref> work best when there are enough packets in a connection that TCP can determine the approximate optimal maximum rate at which to insert packets into the Internet.
Reference: [12] <author> Postel, Jon B., </author> <title> Transmission Control Protocol, </title> <type> RFC 793, </type> <institution> Network Information Center, SRI International, </institution> <month> September </month> <year> 1981. </year>
Reference-contexts: Further information, the data itself (and later data collection runs) can be found on the Web [25]. 1.1 Changes to HTTP HTTP/1.1 [4] is an upward compatible protocol to HTTP/1.0 [3]. Both HTTP/1.0 and HTTP/1.1 use the TCP protocol <ref> [12] </ref> for data transport. However, the two versions of HTTP use TCP differently. HTTP/1.0 opens and closes a new TCP connection for each operation. Since most Web objects are small, this practice means a high fraction of packets are simply TCP control packets used to open and close a connection.
Reference: [13] <author> Paxson, V., </author> <title> Growth Trends in Wide-Area TCP Connections, </title> <journal> IEEE Network, </journal> <volume> Vol. 8 No. 4, </volume> <pages> pp. 8-17, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: TCP's congestion control algorithms [11] work best when there are enough packets in a connection that TCP can determine the approximate optimal maximum rate at which to insert packets into the Internet. Observed packet trains in the Internet have been dropping <ref> [13] </ref>, almost certainly due to HTTP/1.0's behavior, as demonstrated in the data above, where a single connection rarely involves more than 10 packets, including TCP open and close. Some IP switch technology exploits packet trains to enable faster IP routing.
Reference: [14] <author> Jacobson, V., C. Leres, and S. McCanne, tcpdump, </author> <note> available at ftp://ftp.ee.lbl.gov/tcpdump.tar.Z. </note>
Reference-contexts: We expect others leveraging from the experience reported here might accomplish the same result in much less time, though of course we may be more expert than many due to our involvement in HTTP/1.1 design. 10.1 Tools Our principle data gathering tool is the widely available tcpdump program <ref> [14] </ref>; on Windows we used Microsofts NetMon program. We also used Tim Shepard's xplot program [8] to graphically plot the dumps; this was very useful to find a number of problems in our implementation not visible in the raw dumps.
Reference: [15] <author> Scheifler, R.W., J. Gettys, </author> <title> The X Window System, </title> <journal> ACM Transactions on Graphics # 63, Special Issue on User Interface Software. </journal>
Reference-contexts: As this paper makes clear, both pipelining and persistent connections are needed to achieve high performance over a single HTTP connection. Pipelining, or batching, have been successfully used in a number of other systems, notably graphics protocols such as the X Window System <ref> [15] </ref> or Trestle [16], in its original RPC based implementation. Touch, Heidemann, and Obraczka [5] explore a number of possible changes that might help HTTP behavior, including the sharing of TCP control blocks [19] and Transaction TCP (T/TCP) [17], [18].
Reference: [16] <author> Manasse, Mark S., and Greg Nelson, </author> <note> Trestle Reference Manual, Digital Systems Research Center Research Report # 68, </note> <month> December </month> <year> 1991. </year>
Reference-contexts: As this paper makes clear, both pipelining and persistent connections are needed to achieve high performance over a single HTTP connection. Pipelining, or batching, have been successfully used in a number of other systems, notably graphics protocols such as the X Window System [15] or Trestle <ref> [16] </ref>, in its original RPC based implementation. Touch, Heidemann, and Obraczka [5] explore a number of possible changes that might help HTTP behavior, including the sharing of TCP control blocks [19] and Transaction TCP (T/TCP) [17], [18].
Reference: [17] <author> Braden, R., </author> <title> Extending TCP for Transactions - Concepts, </title> <address> RFC-1379, USC/ISI, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Touch, Heidemann, and Obraczka [5] explore a number of possible changes that might help HTTP behavior, including the sharing of TCP control blocks [19] and Transaction TCP (T/TCP) <ref> [17] </ref>, [18]. The extended length of deployment of changes to TCP argued against any dependency of HTTP/1.1 on either of these; however, we believe that both mechanisms may improve performance, independently to the improvements made by HTTP/1.1.
Reference: [18] <author> Braden, R., </author> <title> T/TCP - TCP Extensions for Transactions: Functional Specification, </title> <address> RFC-1644, USC/ISI, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Touch, Heidemann, and Obraczka [5] explore a number of possible changes that might help HTTP behavior, including the sharing of TCP control blocks [19] and Transaction TCP (T/TCP) [17], <ref> [18] </ref>. The extended length of deployment of changes to TCP argued against any dependency of HTTP/1.1 on either of these; however, we believe that both mechanisms may improve performance, independently to the improvements made by HTTP/1.1.
Reference: [19] <author> Touch, J., </author> <title> TCP Control Block Interdependence, </title> <type> RFC 2140, </type> <institution> USC/ISI, </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: Touch, Heidemann, and Obraczka [5] explore a number of possible changes that might help HTTP behavior, including the sharing of TCP control blocks <ref> [19] </ref> and Transaction TCP (T/TCP) [17], [18]. The extended length of deployment of changes to TCP argued against any dependency of HTTP/1.1 on either of these; however, we believe that both mechanisms may improve performance, independently to the improvements made by HTTP/1.1.
Reference: [20] <author> Boutell, T., T. Lane et. al. </author> <title> PNG (Portable Network Graphics) Specification, W3C Recommendation, </title> <month> October </month> <year> 1996, </year> <title> RFC 2083, </title> <publisher> Boutell.Com Inc., </publisher> <month> January </month> <year> 1997. </year> <note> http://www.w3.org/pub/WWW/Graphics/PNG has extensive PNG information. </note>
Reference-contexts: become a very common idiom of HTTP/1.1. 1.3 Changes to Web Content Roughly simultaneously to the deployment of the HTTP/1.1 protocol, (but not dependent upon it), the Web will see the deployment of Cascading Style Sheets (CSS) [30] and new image and animation formats such as Portable Network Graphics (PNG) <ref> [20] </ref> and Multiple-image Network Graphics (MNG) [31]. In the scientific environment where the Web was born, people were generally more concerned with the content of their documents than the presentation.
Reference: [21] <author> Ryan, M., tcpshow, </author> <title> I.T. </title> <publisher> NetworX Ltd., </publisher> <address> 67 Merrion Square, Dublin 2, Ireland, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: We looked at data in both directions of the TCP connections. In the detailed data summary, there are direct links to all dumps in xplot formats. The tcpshow program <ref> [21] </ref> was very useful when we needed to see the contents of packets to understand what was happening. 11 Future Work We believe the CPU time savings of HTTP/1.1 is very substantial due to the great reduction in TCP open and close and savings in packet overhead, and could now be
Reference: [22] <author> Deutsch, P., </author> <title> DEFLATE Compressed Data Format Specification version 1.3, RFC 1951, </title> <publisher> Aladdin Enterprises, </publisher> <month> May </month> <year> 1996. </year>
Reference: [23] <author> Deutsch, L. Peter, Jean-Loup Gailly, </author> <title> ZLIB Compressed Data Format Specification version 3.3, RFC 1950, </title> <publisher> Aladdin Enterprises, </publisher> <address> Info-ZIP, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: We therefore investigated how much we would gain by using data compression of the HTTP message body. That is, we do not compress the HTTP headers, but only the body using the Content-Encoding header to describe the encoding mechanism. We use the zlib compression library <ref> [23] </ref> version 1.04, which is a freely available C based code base. It has a stream based interface which interacts nicely with the libwww stream model. Note that the PNG library also uses zlib, so common implementations will share the same data compression code.
Reference: [24] <institution> Recommendation V.42bis (01/90 Data Compression procedures for data circuit terminating equipment (DCE) using error correction procedures, ITU, Geneva, Switzerland, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: Faster retrieval of HTML pages will also help time to render significantly, for all environments. 8.3 Further Compression Experiments We also performed a simple test confirming that zlib compression is significantly better than the data compression found in current modems <ref> [24] </ref>. The compression used the zlib compression algorithm and the test is done on the HTML page of the Microscape test site. We performed the HTML retrieval (a single HTTP GET request) only with no embedded objects. The test was run over standard 28.8Kbps modems.
Reference: [25] <institution> Online summary of results and complete data can be found at http://www.w3.org/Protocols/HTTP/Performance/. </institution>
Reference-contexts: Our hope is that our experience may guide others through their own implementation efforts and help them avoid some nonobvious performance pits we fell into. Further information, the data itself (and later data collection runs) can be found on the Web <ref> [25] </ref>. 1.1 Changes to HTTP HTTP/1.1 [4] is an upward compatible protocol to HTTP/1.0 [3]. Both HTTP/1.0 and HTTP/1.1 use the TCP protocol [12] for data transport. However, the two versions of HTTP use TCP differently. HTTP/1.0 opens and closes a new TCP connection for each operation.
Reference: [26] <author> Mogul, Jeffery, Fred Douglis, Anja Feldmann, Balachander Krishnamurthy, </author> <title> Potential benefits of delta-encoding and data compression for HTTP, Proceedings of ACM SIGCOMM 97, </title> <address> Cannes France, </address> <month> September </month> <year> 1997. </year>
Reference-contexts: This technique is called pipelining in HTTP. HTTP/1.1 also enables transport compression of data types so those clients can retrieve HTML (or other) uncompressed documents using data compression; HTTP/1.0 does not have sufficient facilities for transport compression. Further work is continuing in this area <ref> [26] </ref>.
Reference: [27] <author> Nielsen, Henrik Frystyk, </author> <title> Libwww - the W3C Sample Code Library, World Wide Web Consortium, </title> <month> April </month> <year> 1997. </year> <note> Source code is available at http://www.w3.org/Library. </note>
Reference: [28] <author> Baird-Smith, Anselm, Jigsaw: </author> <title> An object oriented server, World Wide Web Consortium, </title> <month> February </month> <year> 1997. </year> <note> Source and other information are available at http://www.w3.org/Jigsaw. </note>
Reference: [29] <author> The Apache Group, </author> <title> The Apache Web Server Project. The Apache Web server is the most common Web server on the Internet at the time of this papers publication. </title> <note> Full source is available at http://www.apache.org. </note>
Reference: [30] <institution> A Web page pointing to style sheet information in general can be found at http://www.w3.org/Style/. </institution>
Reference-contexts: We believe cache validation combined with range requests will likely become a very common idiom of HTTP/1.1. 1.3 Changes to Web Content Roughly simultaneously to the deployment of the HTTP/1.1 protocol, (but not dependent upon it), the Web will see the deployment of Cascading Style Sheets (CSS) <ref> [30] </ref> and new image and animation formats such as Portable Network Graphics (PNG) [20] and Multiple-image Network Graphics (MNG) [31]. In the scientific environment where the Web was born, people were generally more concerned with the content of their documents than the presentation. <p> Simon Spero analyzed HTTP/1.0 performance [6] and prepared a proposal for a replacement for HTTP. HTTP/1.1, however, was constrained to maintain upward compatibility with HTTP/1.0. Many of his suggestions are worthwhile and should be explored further. Style sheets have a long history in the Web <ref> [30] </ref>. We believe that the character of our results will likely be similar for other style sheet systems.

References-found: 30

