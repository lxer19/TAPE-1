URL: http://www.cis.ohio-state.edu/volviz/Papers/1996/realtime.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/volviz/papers_subject.html
Root-URL: 
Title: Towards Real Time Volume Rendering  
Author: Roni Yagel 
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: The task of real time rendering of todays volumetric datasets is still being tackled by several research groups. A quick calculation of the amount of computation required for real-time rendering of a high resolution volume puts us in the teraop range. Yet, the demand to support such rendering capabilities is increasing due to emerging technologies such as virtual surgery simulation and rapid prototyping. There are five main approaches to overcoming this seemingly insurmountable performance barrier: (i) data reduction by means of model extraction or data simplification, (ii) realization of special-purpose volume rendering engines, (iii) software-based algorithm optimization and acceleration, (iv) implementation on general purpose parallel architectures, and (v) use of contemporary of-the-shelf graphics hardware. In this presentation we first describe the vision of real-time high-resolution volume rendering and estimate the computing power it demands. We survey the state-of-the art in rapid volume rendering and compare the achievements and effectivity of the various approaches. We look ahead and describe the remaining challenges and some possible ways of providing the needs of this ever demanding field.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Amin A.B., A. Grama, and V. Singh, </author> <title> Fast Volume Rendering Using an Efficient, Scalable Parallel Formulation of the Shear-Warp Algorithm, </title> <booktitle> Proceedings 1995 Parallel Rendering Symposium, </booktitle> <address> Atlanta, Georgia, </address> <month> October </month> <year> 1995, </year> <pages> pp. 7-14. </pages>
Reference-contexts: While waiting, it transforms the next assigned slice. One disadvantage of this implementation is the sorting which is required for each of the slices. The efficient shearing algorithm [19] was also parallelized, for a shared-memory architecture (Silicon Graphics Challenge) [20] and on TMC CM-5 <ref> [1] </ref>. In [20], synchronization time is minimized by using dynamic load balancing and a task partition that minimizes synchronization events.
Reference: 2. <author> Avila, R., Sobierajski, L. M., and Kaufman, A. E., </author> <title> Towards a Comprehensive Volume Visualization System, </title> <booktitle> Proceedings Visualization 92, </booktitle> <address> Boston, MA, 13-20, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The object is surrounded by a tightly fit box (or other easy-to-intersect object such as sphere). Rays are intersected with the bounding object and start their actual volume traversal from this intersection point as opposed to starting from the volume boundary. The PARC (Polygon Assisted Ray Casting) approach <ref> [2] </ref> strives to have a better fit by allowing a convex polyhedral envelope to be constructed around the object. PARC utilizes available graphics hardware to render the front faces of the envelope (to determine, for each pixel, the ray entry point) and back faces (to determine the ray exit point).
Reference: 3. <author> Bergman, L., Fuchs, H., Grant, E., and Spach, S., </author> <title> Image Rendering by Adaptive Refinement, </title> <journal> Computer Graphics, </journal> <volume> 20,(4):29-37, </volume> <month> August </month> <year> 1986. </year>
Reference-contexts: Therefore it is observed that it might be the case that we could avoid sending a ray for such obviously identical pixels. The adaptive image supersampling, exploits the pixel-space coherency. It was originally developed for traditional ray-tracing <ref> [3] </ref>] and later adapted to volume rendering [28]. First, rays are cast from only a subset of the screen pixels (e.g., every other pixel). Empty pixels residing between pixels with similar value are assigned an interpolated value. In areas of high image gradient additional rays are cast to resolve ambiguities.
Reference: 4. <author> Cabral B., N. Cam and J.Foran, </author> <title> Accelerated Volume Rendering and Tomographic Reconstruction Using Texture Mapping Hardware, </title> <booktitle> Proceedings 1994 Symposium on Volume Visualization, </booktitle> <pages> pp. 91-98. </pages>
Reference-contexts: However, these polygon rendering engines seem inherently unsuitable to the task. Recently, some new methods have tapped to this rendering power by either utilizing texture mapping capabilities for rendering splats [8][21], or by exploiting solid texturing capabili 9 ties to implement a slicing-based volume rendering <ref> [4] </ref>. The Volume Splatter [54] relies on the notion of fuzzy voxel set which consists of a subset of the volumes voxels. For each voxel in the original volume, we evaluate a transfer function that maps the gradient and the density of the given voxel to an importance number. <p> These three dimensional rasters (called 3D texture maps) are mapped on polygons in 3D space using either zero order or first order interpolation. By rendering polygons slicing the volume and perpendicular to the view direction one generates a view of a rectangular volume data set <ref> [4] </ref>. Rendering these polygons from back to front and blending them into the frame buffer generates a correct image of the volume. <p> Some examples of this trend are <ref> [4] </ref>[8][21][55]. While fastest known parallel implementations achieve close to real-time (~10 frames per second) on expensive high-end parallel machines [20], the same, or even slightly better performance is achieved on mid-range texture hardware [4].
Reference: 5. <author> Cameron, G. and Underill, P. E., </author> <title> Rendering Volumetric Medical Image Data on a SIMD Architecture Computer, </title> <booktitle> Proceedings of Third Eurographics Workshop on Rendering, </booktitle> <month> May </month> <year> 1992. </year>
Reference: 6. <author> Cohen, D. and Shefer, Z., </author> <title> Proximity Clouds - An Acceleration Technique for 3D Grid Traversal, </title> <type> Technical Report FC 93-01, </type> <institution> Department of Mathematics and Computer Science, Ben Gurion University of the Negev, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Rays which are cast into the volume encounter either a data voxel, or a voxel containing uniformity information which instructs the ray to perform a leap forward that brings it to the first voxel beyond the uniform region <ref> [6] </ref>. This approach saves the need to perform a tree search for the appropriate neighbor - an operation that is the most time consuming and the major disadvantage in the hierarchical data structure. <p> This suggests that the ray can take a n-step leap forward, being assured that there is no object in the skipped span of voxels. The effectiveness of this algorithm is obviously dependent on the ability of the line traversal algorithm to efficiently jump arbitrary number of steps <ref> [6] </ref>. 3. Parallel and Distributed Architectures The viewing algorithms adopted for parallel implementations are many and varied. Both traditional direct volume rendering methods, namely feed-forward and backward-feed as well as an hybrid approach, was adapted for parallel processors.
Reference: 7. <author> Corrie, B. and Mackerras, P., </author> <title> Parallel Volume Rendering and Data Coherence on the Fujitsu AP100, </title> <type> Technical Report TR-CS-92-11, </type> <institution> Department of Computer Science, Australian National University, Canberra, ACT, Australia, </institution> <year> 1992. </year>
Reference-contexts: A dynamic data distribution scheme is used to assign the slices to the various nodes An efficient incremental transformation method, was used for transforming each slice. Corrie and Mackerras employed the Fujitsu AP1000 MIMD multiprocessor to implement a ray-caster <ref> [7] </ref>. A master slave paradigm was used to dynamically distribute square regions of pixels to slave cells. An adaptive distribution scheme is obtained by having the slave cells notify the master when they spend more than their allocated time to render the assigned image.
Reference: 8. <author> R. Crawfis, </author> <title> New Techniques for the Scientific Visualization of Three-Dimensional Multi-variate and Vector Fields, </title> <type> Ph.D. Dissertation, </type> <institution> University of California, Davis, </institution> <year> 1995. </year>
Reference: 9. <author> Danskin, J. and Hanrahan, P., </author> <title> Fast Algorithms for Volume Ray Tracing, </title> <booktitle> Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <address> Boston, MA, 91-105, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: Recently, this basic idea was extended to efficiently lower the sampling rate in either areas where only small contributions of opacities are made, or in regions where the volume is homogeneous <ref> [9] </ref>. This method efficiently detects regions of N Nlog 5 low presence or low variation by employing a pyramid of volumes that decode the minimum and maximum voxel value in a small neighborhood, as well as the distance between these measures. <p> One early example of this trend is the shear-warp algorithm that combines the work on shearing-based rendering [15], run-length encoding [35], min-max pyramids <ref> [9] </ref>, and multi-dimensional summed area tables. Parallel implementations on state-of-the art distributed shared-memory machines, taking advantage of hardware caches and interleaved dedicated communication processors. Several examples of this trend are already available [23][24][25].
Reference: 10. <author> Drebin, R. A., Carpenter, L., and Hanrahan, P., </author> <title> Volume Rendering, </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 65-74, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: One solution is based on transforming each slice from voxel-space to pixel-space using 3D affine transformation (shearing) [15][19][39] followed by projection onto the screen in a FTB fashion, and blending with the projection formed by previous slices <ref> [10] </ref>. Westover [46] has introduced another reconstruction technique for forward viewing methods - the splatting algorithm. Each voxel, after being transformed into screen space is blurred, based on a 2D lookup table (footprint) that spreads the voxels energy across multiple pixels. These are then composited with the image array.
Reference: 11. <author> Farrell, E. J., Zappulla, R., and Yang, W. C., </author> <title> Color 3D Imaging of Normal and Pathologic Intracranial Structures, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 4(9) </volume> <pages> 5-17, </pages> <month> September </month> <year> 1984. </year>
Reference-contexts: This avoids the need for a Z-buffer for hidden voxel removal considerations by applying the painters algorithm by simply drawing the current voxel on top of previously drawn voxels or by compositing the current voxel with the screen value <ref> [11] </ref> [12]. The front-to-back (FTB) algorithm is essentially the same as BTF only that now the voxels are traversed in increasing distance order.
Reference: 12. <author> Frieder, G., Gordon, D., and Reynolds, R. A., </author> <title> Back-to-Front Display of Voxel-Based Objects, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 5(1) </volume> <pages> 52-60, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: This avoids the need for a Z-buffer for hidden voxel removal considerations by applying the painters algorithm by simply drawing the current voxel on top of previously drawn voxels or by compositing the current voxel with the screen value [11] <ref> [12] </ref>. The front-to-back (FTB) algorithm is essentially the same as BTF only that now the voxels are traversed in increasing distance order. <p> Algorithm Optimization 2.1 Optimizing Object-Space Forward Rendering Some methods have been suggested to reduce the amount of computations needed for the transformation by exploiting the spatial coherency between voxels. These methods are: recursive divide and conquer [32], pre-calculated tables <ref> [12] </ref>, incremental transformation [30], and shearing-based transforms [15]. The first method [32] exploits coherency in voxel space by representing the 3D volume by an octree. <p> In addition, since each octree node has eight equally-sized octants, given the transformation of the parent node, the transformation of its sub-octants can be efficiently computed. The table-driven transformation method <ref> [12] </ref> is based on the observation that volume transformation involves the multiplication of the matrix elements with integer values which are always in the range , where N is the volume resolution. Therefore, in a short preprocessing stage each matrix element is allocated a table such that .
Reference: 13. <author> Fruhauff, T., </author> <title> Volume Rendering on a Multiprocessor Architecture with Shared Memory: A Concurrent Volume Rendering Algorithm, </title> <booktitle> Proceedings of the Third Eurographics Workshop on Scientific Visualization, </booktitle> <address> Pisa, Italy, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Later when each node is finished all these portions are combined to obtain the color. Such a scheme can lead to a load balanced and scalable implementation and the data distribution scheme maps well to the Hypercube interconnection network. Fruhaffs implementation on a multiprocessor Silicon Graphics workstation <ref> [13] </ref> is similar in spirit to Schroeder and Salems implementation on CM-2. The volume is rotated along the viewing rays and then parallel rays are cast.
Reference: 14. <author> Gudmundsson, B. and Randen, M., </author> <title> Incremental Generation of Projections of CT-Volumes, </title> <booktitle> Proceedings of the First Conference on Visualization in Biomedical Computing, </booktitle> <address> Atlanta, GA, 27-34, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: For each change in the viewing parameters, the C-buffer is transformed accordingly. In the case of rotation the transformed C-buffer goes through a process of eliminating coordinates that possibly became hidden <ref> [14] </ref>. The remaining values in the C-buffer serve as an estimate of the point where the new rays should start their volume traversal. Space-leaping: The passage of a ray through the volume is two phased. In the first phase the ray advances through the empty space searching for an object.
Reference: 15. <author> Hanrahan, P., </author> <title> Three-Pass Affine Transforms for Volume Rendering, </title> <journal> Computer Graphics, </journal> <volume> 24(5) </volume> <pages> 71-78, </pages> <booktitle> Proceedings of San Diego Workshop on Volume Visualization, </booktitle> <month> November </month> <year> 1990. </year>
Reference-contexts: Algorithm Optimization 2.1 Optimizing Object-Space Forward Rendering Some methods have been suggested to reduce the amount of computations needed for the transformation by exploiting the spatial coherency between voxels. These methods are: recursive divide and conquer [32], pre-calculated tables [12], incremental transformation [30], and shearing-based transforms <ref> [15] </ref>. The first method [32] exploits coherency in voxel space by representing the 3D volume by an octree. A group of neighboring voxels having the same value (or similar, up to a threshold value) may, under some restrictions, be grouped into a uniform cubic subvolume. <p> The shearing algorithm decomposes the 3D affine transformation into five 1D shearing transformations <ref> [15] </ref>. The major advantage of this approach is its ability (using simple averaging techniques) to overcome some of the sampling problems causing the production of low quality images. In addition, this approach replaces the 3D transformation by five 1D transformations which require only one oating-point addition each. <p> These can be tested against each other in runs rather than by comparing individual voxels. This idea was later adopted for expediting the shearing algorithm [19]. The shearing algorithm was also optimized [19] by devising a factorization that is faster than the original decomposition <ref> [15] </ref>. Also, they introduced a data structure for encoding spatial coherence in unclassified volumes (i.e. scalar fields with no precomputed opacity). 2.2 Optimizing Image-Space Backward Rendering Backward viewing of volumes, based on casting rays, has three major variations: parallel (orthographic) ray casting, perspective ray casting, and ray tracing. <p> One early example of this trend is the shear-warp algorithm that combines the work on shearing-based rendering <ref> [15] </ref>, run-length encoding [35], min-max pyramids [9], and multi-dimensional summed area tables. Parallel implementations on state-of-the art distributed shared-memory machines, taking advantage of hardware caches and interleaved dedicated communication processors. Several examples of this trend are already available [23][24][25].
Reference: 16. <author> Kajiya, J. T. and Von Herzen, B. P., </author> <title> Ray Tracing Volume Densities, </title> <journal> Computer Graphics, </journal> <volume> 18(3) </volume> <pages> 165-174, </pages> <month> July </month> <year> 1984. </year>
Reference: 17. <author> Kaufman A., D. Cohen, and R. Yagel, </author> <title> Volumetric Graphics, </title> <journal> IEEE Computer, </journal> <volume> 26(7) </volume> <pages> 51-64, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Rendering and processing does not depend of the objects complexity or type, it depends only on volume resolution. It easily supports operations such as subtraction, addition, collision detection, and deformation. For a complete comparison see <ref> [17] </ref>. Although compute power required for volume rendering is immense, so are the benefits from some potential applications which rely on such capability. One such application is the simulation of surgery on a virtual patient [55].
Reference: 18. <author> Krueger W., </author> <title> The Application of Transport Theory to Visualization of 3D Scalar Data Field, </title> <booktitle> Proceedings Visualization 90, </booktitle> <address> October 1990, San Francisco, CA, </address> <pages> pp. 273-280. </pages>
Reference: 19. <author> Lacroute P. and M. Levoy, </author> <title> Fast Volume Rendering Using a Shear-Warp Factorization of the Viewing Transformation, </title> <booktitle> Proceedings SIGGRAPH '94, </booktitle> <address> Orlando, Florida, </address> <month> July 24-29, </month> <year> 1994. </year> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, 1994, ACM SIGGRAPH, </booktitle> <pages> pp. 451-458. </pages>
Reference-contexts: The transformation guarantees that a row of voxels always transforms into a row of pixels. These can be tested against each other in runs rather than by comparing individual voxels. This idea was later adopted for expediting the shearing algorithm <ref> [19] </ref>. The shearing algorithm was also optimized [19] by devising a factorization that is faster than the original decomposition [15]. <p> The transformation guarantees that a row of voxels always transforms into a row of pixels. These can be tested against each other in runs rather than by comparing individual voxels. This idea was later adopted for expediting the shearing algorithm <ref> [19] </ref>. The shearing algorithm was also optimized [19] by devising a factorization that is faster than the original decomposition [15]. <p> A graphics processor waits for the a circulating token to reach it before it can send the next slice for rendering. While waiting, it transforms the next assigned slice. One disadvantage of this implementation is the sorting which is required for each of the slices. The efficient shearing algorithm <ref> [19] </ref> was also parallelized, for a shared-memory architecture (Silicon Graphics Challenge) [20] and on TMC CM-5 [1]. In [20], synchronization time is minimized by using dynamic load balancing and a task partition that minimizes synchronization events.
Reference: 20. <author> Lacroute P., </author> <title> Real-Time Volume Rendering on Shared Memory Multiprocessors Using the Shear-Warp Factorization, </title> <booktitle> Proceedings 1995 Parallel Rendering Symposium, </booktitle> <address> Atlanta, Georgia, </address> <month> October </month> <year> 1995, </year> <pages> pp. 15-22. 11 </pages>
Reference-contexts: While waiting, it transforms the next assigned slice. One disadvantage of this implementation is the sorting which is required for each of the slices. The efficient shearing algorithm [19] was also parallelized, for a shared-memory architecture (Silicon Graphics Challenge) <ref> [20] </ref> and on TMC CM-5 [1]. In [20], synchronization time is minimized by using dynamic load balancing and a task partition that minimizes synchronization events. <p> While waiting, it transforms the next assigned slice. One disadvantage of this implementation is the sorting which is required for each of the slices. The efficient shearing algorithm [19] was also parallelized, for a shared-memory architecture (Silicon Graphics Challenge) <ref> [20] </ref> and on TMC CM-5 [1]. In [20], synchronization time is minimized by using dynamic load balancing and a task partition that minimizes synchronization events. <p> Increased utilization of existing general purpose, affordable graphics engine with the final disappearance of special purpose volume engines. Some examples of this trend are [4][8][21][55]. While fastest known parallel implementations achieve close to real-time (~10 frames per second) on expensive high-end parallel machines <ref> [20] </ref>, the same, or even slightly better performance is achieved on mid-range texture hardware [4].
Reference: 21. <author> Laur, D. and Hanrahan, P., </author> <title> Hierarchical Splatting: A Progressive Refinement Algorithm for Volume Rendering, </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 285-288, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: These ideas was further explored to allow non-binary surfaces by extracting all voxels that contribute to the final image [54]. Another efficient implementation of the splatting algorithm, called hierarchical splatting <ref> [21] </ref> uses a pyramid data structure to hold a multi-resolution representation of the volume. For a volume of resolution, the pyramid data structure consists of a sequence of volumes. The first volume contains the original dataset, the next volume in the sequence is half the resolution of the previous one.
Reference: 22. <author> Law, A., Yagel, R., and Jayasimha, D. N., VoxelFlow: </author> <title> A Parallel Volume Rendering Method for Scientific Visualization, </title> <journal> ISCA Journal of Computers and Their Applications, </journal> <note> accepted April 1996. </note>
Reference: 23. <author> Law A. and R. Yagel, CellFlow: </author> <title> A Parallel Rendering Scheme for Distributed Memory Architectures, </title> <booktitle> Proceedings of International Conference on Parallel and Distributed Processing Techniques and Applications (PDPTA `95), </booktitle> <month> November </month> <year> 1995, </year> <pages> pp. 1-10. </pages>
Reference: 24. <author> Law A. and R. Yagel, </author> <title> Multi-Frame Thrashless Ray Casting with Advancing Ray-Front, Graphics Interface `96, </title> <address> Toronto, Canada, </address> <month> May </month> <year> 1996, </year> <pages> pp. 71-77. </pages>
Reference-contexts: Depending on the local memory availability, this data allocation scheme can be extended to provide what is termed as frame-to-frame coherence, where data are allocated in such a way that a processor is self-sufficient to generate a number of slowly changing frames <ref> [24] </ref> with no need for additional communication. If the animator happens to have the knowledge of subsequent screen positions, then the data needed for the next set of frames can similarly be fetched. <p> Only two reported implementations [53][47] and one recent work <ref> [24] </ref> are known. Wittenbrink and Somanis [47] method is applicable to affine transformations. They decompose the transformation into a series of shears used to determine the address of a voxel in the transformed space. This address is used for interpolating in object space and obtaining the sample value. <p> The transformed extents of these sub-cubes are determined in the image space. These image extents are then traversed in scanline order and interpolated in object space. An efficient inverse incremental transformation is employed to obtain points in object space. Recently <ref> [24] </ref>, the Active Ray method, which exploits coherency in object-space, was implemented. The data is divided into cells that are distributed randomly to processors. Rays are intersected with the cell boundaries and are placed in a queue associated with the cell they intersect first.
Reference: 25. <author> Law A. and R. Yagel, </author> <title> An Optimal Ray Traversal Scheme for Visualizing Colossal Medical Volumes, Visualization in Biomedical Computing, </title> <address> VBC `96, </address> <month> September </month> <year> 1996, </year> <note> accepted. </note>
Reference-contexts: We developed a method for exploiting frame-to-frame coherence in a more general way, i.e., for real time animation where the screen positions are unpredictable. Several memory optimizations were made and a directory-based protocol was designed to further optimize memory utilization <ref> [25] </ref>. It was seen that with sufficient local memory size to hold all the objects for a single frame, the data requirement for the next (close) frame was just 5% of the volume.
Reference: 26. <author> Law, A. and Yagel, R., </author> <title> Exploiting Spatial, Ray, and Frame Coherency for Efficient Parallel Volume Rendering, </title> <address> GRAPHI-CON96, Saint-Petersburg, Russia, </address> <month> July </month> <year> 1996. </year>
Reference-contexts: Shading, interpolation and compositing is done by each processor along the ray. After a set of rays have been completely traced, new rays are traced by conducting shifts along one axis. We have designed and implemented three coherent algorithms on the Cray T3D <ref> [26] </ref>, which have proven to be extremely scalable, with scope for further improvement. These algorithms are primarily based on efficient utilization of local memory and attempt to hide the latency of locally unavailable objects.
Reference: 27. <author> Levoy, M., </author> <title> Display of Surfaces from Volume Data, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 8(5) </volume> <pages> 29-37, </pages> <month> May </month> <year> 1988. </year>
Reference: 28. <author> Levoy, M., </author> <title> Volume Rendering by Adaptive Refinement, </title> <journal> The Visual Computer, </journal> <volume> 6(1) </volume> <pages> 2-7, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: Therefore it is observed that it might be the case that we could avoid sending a ray for such obviously identical pixels. The adaptive image supersampling, exploits the pixel-space coherency. It was originally developed for traditional ray-tracing [3]] and later adapted to volume rendering <ref> [28] </ref>. First, rays are cast from only a subset of the screen pixels (e.g., every other pixel). Empty pixels residing between pixels with similar value are assigned an interpolated value. In areas of high image gradient additional rays are cast to resolve ambiguities.
Reference: 29. <author> Levoy, M., </author> <title> Efficient Ray Tracing of Volume Data, </title> <journal> ACM Transactions on Graphics, </journal> <volume> 9(3): </volume> <pages> 245-261, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The hierarchical representation (e.g., octree) decomposes the volume into uniform regions that can be represented by nodes in a hierarchical data structure [37]. An adjusted ray traversal algorithm skips the (uniform) empty space by maneuvering through the hierarchical data structure <ref> [29] </ref>. It was also observed that traversing the hierarchical data structure is inefficient compared to the traversal of regular grids. A combination of the advantages of both representations is the uniform buffer.
Reference: 30. <author> Machiraju, R., Yagel, R., and Schwiebert, L., </author> <title> Parallel Algorithms for Volume Rendering, </title> <institution> OSU-CISRC-10/92-TR29, Department of Computer and Information Science, The Ohio State University, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Algorithm Optimization 2.1 Optimizing Object-Space Forward Rendering Some methods have been suggested to reduce the amount of computations needed for the transformation by exploiting the spatial coherency between voxels. These methods are: recursive divide and conquer [32], pre-calculated tables [12], incremental transformation <ref> [30] </ref>, and shearing-based transforms [15]. The first method [32] exploits coherency in voxel space by representing the 3D volume by an octree. A group of neighboring voxels having the same value (or similar, up to a threshold value) may, under some restrictions, be grouped into a uniform cubic subvolume. <p> To employ this approach, all volume elements, including the empty ones, have to be transformed. This approach is therefore more suitable to parallel architecture where it is desired to keep the computation pipeline busy <ref> [30] </ref>. This approach is especially attractive for vector processors since the transformations of the set of voxels , called beam and denoted by , can be computed from the transformation of the vector by adding, to each element in this vector, the same three matrix elements.
Reference: 31. <author> Max N., </author> <title> Optical Models for Direct Volume Rendering, </title> <journal> IEEE Transactions on Visualization and Computer Graphics, </journal> <volume> 1(2), </volume> <month> June </month> <year> 1995. </year>
Reference: 32. <author> Meagher, D. J., </author> <title> Geometric Modeling Using Octree Encoding, </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 19(2) </volume> <pages> 129-147, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: Algorithm Optimization 2.1 Optimizing Object-Space Forward Rendering Some methods have been suggested to reduce the amount of computations needed for the transformation by exploiting the spatial coherency between voxels. These methods are: recursive divide and conquer <ref> [32] </ref>, pre-calculated tables [12], incremental transformation [30], and shearing-based transforms [15]. The first method [32] exploits coherency in voxel space by representing the 3D volume by an octree. <p> These methods are: recursive divide and conquer <ref> [32] </ref>, pre-calculated tables [12], incremental transformation [30], and shearing-based transforms [15]. The first method [32] exploits coherency in voxel space by representing the 3D volume by an octree. A group of neighboring voxels having the same value (or similar, up to a threshold value) may, under some restrictions, be grouped into a uniform cubic subvolume.
Reference: 33. <author> Montani, C., Perego, R., and Scopingo, R., </author> <title> Parallel Volume Visualization on a Hypercube Architecture, </title> <booktitle> Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <address> Boston, MA, 9-16, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: To alleviate non-local access the volume is distributed in a round-robin fashion among the nodes. The efficient caching subsystem of the DASH multiprocessor is relied upon to fetch non-local data. Montani et. al.s implementation of a ray-tracer on the Intel iPSC/2 used a purely static data distribution scheme <ref> [33] </ref>. The scanlines are divided among clusters of processors in an interleaved fashion. The entire volume data is replicated on all clusters with each node of the cluster getting a slab of slices.
Reference: 34. <author> Neih, J. and Levoy, M., </author> <booktitle> Volume Rendering on Scalable Shared Memory Architecture, Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <address> Boston, MA, 17-24, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The algorithm relies on hardware support for low-latency fine-grain communication and hardware caching to hide latency. 3.2 Parallel Backward Viewing Methods Backward-feed or image space methods have received a lot of attention in the parallel volume rendering community. Neih and Levoys <ref> [34] </ref> contribution lies in the development of a hybrid data distribution scheme. The screen is divided into several regions which are again subdivided into tiles. Each node of the DASH multicomputer is assigned a portion of the screen.
Reference: 35. <author> Reynolds, R. A., Gordon, D., and Chen, L. S., </author> <title> A Dynamic Screen Technique for Shaded Graphic Display of Slice-Represented Objects, Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 38(3) </volume> <pages> 275-298, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The splats themselves are approximated by polygons which can efficiently be rendered by graphics hardware (see Section 4). It seems that in forward methods voxels need to be transformed and tested against the screen so as to avoid compositing at already opaque pixels. Reynolds et al <ref> [35] </ref> developed the dynamic screen which decodes the screen lines as run-length of non-opaque pixels. The transformation guarantees that a row of voxels always transforms into a row of pixels. These can be tested against each other in runs rather than by comparing individual voxels. <p> One early example of this trend is the shear-warp algorithm that combines the work on shearing-based rendering [15], run-length encoding <ref> [35] </ref>, min-max pyramids [9], and multi-dimensional summed area tables. Parallel implementations on state-of-the art distributed shared-memory machines, taking advantage of hardware caches and interleaved dedicated communication processors. Several examples of this trend are already available [23][24][25].
Reference: 36. <author> Sabella, P., </author> <title> A Rendering Algorithm for Visualizing 3D Scalar Fields, </title> <journal> Computer Graphics, </journal> <pages> 22(4)51-58, </pages> <month> August </month> <year> 1988. </year>
Reference: 37. <author> Samet, H. and Webber, R. E., </author> <title> Hierarchical Data Structures and Algorithms for Computer Graphics, Part II: </title> <journal> Applications, IEEE Computer Graphics and Applications, </journal> <volume> 8(7) </volume> <pages> 59-75, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: The hierarchical representation (e.g., octree) decomposes the volume into uniform regions that can be represented by nodes in a hierarchical data structure <ref> [37] </ref>. An adjusted ray traversal algorithm skips the (uniform) empty space by maneuvering through the hierarchical data structure [29]. It was also observed that traversing the hierarchical data structure is inefficient compared to the traversal of regular grids. A combination of the advantages of both representations is the uniform buffer.
Reference: 38. <author> Schlusselberg, D. S., Smith, K., and Woodward, D. J., </author> <title> Three Dimensional Display of Medical Image Volumes, </title> <booktitle> Proceedings of NCGA86 Conference, III, </booktitle> <pages> 114-123, </pages> <month> (May </month> <year> 1986). </year>
Reference-contexts: The simplest method for implementing resampling performs zero order interpolation to locate the nearest voxel while stepping along the discrete ray representation which is generated by a 3D line algorithm <ref> [38] </ref>. Alternatively, the volume is sampled at the intersection points of the ray and the voxels faces, its value is interpolated, and then composited [43]. A more precise algorithm uses higher order interpolation to estimate the appropriate value at evenly spaced sample points along the ray [16][27][36].
Reference: 39. <author> Schroeder, P. and Salem, J. B., </author> <title> Fast Rotation of Volume Data on Data Parallel Architecture, </title> <booktitle> Proceedings of Visualization91, </booktitle> <address> San Diego, CA, 50-57, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: In [45] the implementation was conducted on a Maspar MP-1. Beams of voxels are provided to a toroidally connected processors. This implementation relies on the efficient interconnection network of the MP-1 for optimal communications performance. In the other implementation <ref> [39] </ref> no efforts were made to perform any explicit distribution or virtualization on the CM-2. Indirect addressing was employed and data exchange was avoided until the composition phase of the algorithm.
Reference: 40. <author> Schroeder, P. and Stoll, G., </author> <title> Data Parallel Volume Rendering as Line Drawing, </title> <booktitle> Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <address> Boston, MA, 25-31, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The third phase of the algorithm transforms the projected image from the base-plane to the screen-plane. The regularity and simplicity of this efficient algorithm make it very attractive for hardware implementation [48] and for massively parallel computers such as the CM-2 <ref> [40] </ref>. Frame coherency: When an animation sequence is generated, in many cases, there is not much difference between successive images. Therefore, much of the work invested to produce one image may be used to expedite the generation of the next image. <p> By converting the three-dimensional view matrix into a series of one-dimensional shears and scales along the orthogonal axis, both Schroeder and Salem <ref> [40] </ref> and Vezina et. al [45] implemented feed-forward rendering on SIMD processors. A one-dimensional shear leads to regular communication along the shear axis and hence the decomposition of the transformation into shears. In [45] the implementation was conducted on a Maspar MP-1.
Reference: 41. <author> Sobierajski L., D. Cohen, A. Kaufman, R. Yagel, and D. Acker, </author> <title> A Fast Display Method for Volumetric Data, </title> <journal> The Visual Computer, </journal> <volume> 10(2) </volume> <pages> 116-124, </pages> <year> 1993. </year>
Reference-contexts: In addition, this approach replaces the 3D transformation by five 1D transformations which require only one oating-point addition each. The splatting algorithm requires extensive filtering and is therefore very time consuming. We have described <ref> [41] </ref> a simplified approximation to the splatting method for interactive volume viewing in which only voxels comprising the objects surface are maintained.
Reference: 42. <author> Tuy, H. K. and Tuy, L. T., </author> <title> Direct 2-D Display of 3-D Objects, </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 4(10) </volume> <pages> 29-33, </pages> <month> (November </month> <year> 1984). </year>
Reference: 43. <author> Upson, C. and Keeler, M., V-BUFFER: </author> <title> Visible Volume Rendering, </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 59-64, </pages> <month> August </month> <year> 1988. </year> <note> 44. </note> <author> van Walsum, T., Hin, A. J. S., Versloot, J., and Post, F. H., </author> <title> Efficient Hybrid Rendering of Volume data and Polygons, </title> <booktitle> Second Eurographics Workshop on Visualization in Scientific Computing, </booktitle> <address> Delft, Netherlands, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: In contrast to the forward viewing approach, the backward viewing scheme (also called image space method) casts a ray from the eye, through each pixel on the screen, into the volume data, until it intersect an opaque object or accumulates an opaque value through compositing [27][42] <ref> [43] </ref>. The simplest method for implementing resampling performs zero order interpolation to locate the nearest voxel while stepping along the discrete ray representation which is generated by a 3D line algorithm [38]. <p> Alternatively, the volume is sampled at the intersection points of the ray and the voxels faces, its value is interpolated, and then composited <ref> [43] </ref>. A more precise algorithm uses higher order interpolation to estimate the appropriate value at evenly spaced sample points along the ray [16][27][36]. Since ray casting follows only primary rays, it does not directly support the simulation of light phenomena such as reection, shadows, and refraction.
Reference: 45. <author> Vezina, G., Fletcher, P., and Robertson, P. K., </author> <title> Volume Rendering on the MasPar MP-1, </title> <booktitle> Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <address> Boston, MA, 3-8, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: By converting the three-dimensional view matrix into a series of one-dimensional shears and scales along the orthogonal axis, both Schroeder and Salem [40] and Vezina et. al <ref> [45] </ref> implemented feed-forward rendering on SIMD processors. A one-dimensional shear leads to regular communication along the shear axis and hence the decomposition of the transformation into shears. In [45] the implementation was conducted on a Maspar MP-1. Beams of voxels are provided to a toroidally connected processors. <p> matrix into a series of one-dimensional shears and scales along the orthogonal axis, both Schroeder and Salem [40] and Vezina et. al <ref> [45] </ref> implemented feed-forward rendering on SIMD processors. A one-dimensional shear leads to regular communication along the shear axis and hence the decomposition of the transformation into shears. In [45] the implementation was conducted on a Maspar MP-1. Beams of voxels are provided to a toroidally connected processors. This implementation relies on the efficient interconnection network of the MP-1 for optimal communications performance.
Reference: 46. <author> Westover, L., </author> <title> Footprint Evaluation for Volume Rendering, </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 367-376, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: One solution is based on transforming each slice from voxel-space to pixel-space using 3D affine transformation (shearing) [15][19][39] followed by projection onto the screen in a FTB fashion, and blending with the projection formed by previous slices [10]. Westover <ref> [46] </ref> has introduced another reconstruction technique for forward viewing methods - the splatting algorithm. Each voxel, after being transformed into screen space is blurred, based on a 2D lookup table (footprint) that spreads the voxels energy across multiple pixels. These are then composited with the image array. <p> Splatting is another reconstruction technique which has gained attention in the parallel volume rendering community. The earliest splatting implementation was conducted on a network of SUNs by Westover <ref> [46] </ref>. Voxels are enumerated in a front-to-back or back-to-front order and a subset of these is sent to processes which are executed on a network of Suns. These processes transform and splat the voxels onto image sheets which are then sent to N compositing processes.
Reference: 47. <author> Wittenbrink, C. M. and Somani, A. K., </author> <title> 2D and 3D Optimal Image Warping, </title> <booktitle> Proceedings of Seventh International Parallel Processing Symposium, </booktitle> <address> Newport Beach, CA, </address> <month> April </month> <year> 1993. </year> <month> 12 </month>
Reference-contexts: Only two reported implementations [53]<ref> [47] </ref> and one recent work [24] are known. Wittenbrink and Somanis [47] method is applicable to affine transformations. They decompose the transformation into a series of shears used to determine the address of a voxel in the transformed space. This address is used for interpolating in object space and obtaining the sample value.
Reference: 48. <author> Yagel, R., </author> <title> Efficient Methods for Volume Graphics, </title> <type> Doctoral Dissertation, </type> <institution> Department of Computer Science, SUNY at Stony Brook, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: The result of the second phase of the algorithm is a projection of the volume on the base-plane. The third phase of the algorithm transforms the projected image from the base-plane to the screen-plane. The regularity and simplicity of this efficient algorithm make it very attractive for hardware implementation <ref> [48] </ref> and for massively parallel computers such as the CM-2 [40]. Frame coherency: When an animation sequence is generated, in many cases, there is not much difference between successive images.
Reference: 49. <author> Yagel R., </author> <title> High Quality Template-Based Volume Viewing, </title> <institution> OSU-CISRC-10/92-TR28, Department of Computer and Information Science, The Ohio State University, </institution> <month> October </month> <year> 1992. </year>
Reference: 50. <author> Yagel, R., Cohen, D., and Kaufman, A., </author> <title> Discrete Ray Tracing, </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 12(5) </volume> <pages> 19-28, </pages> <month> Sep-tember </month> <year> 1992. </year>
Reference-contexts: Since ray casting follows only primary rays, it does not directly support the simulation of light phenomena such as reection, shadows, and refraction. As an alternative we have developed the 3D raster ray tracer (RRT) <ref> [50] </ref> that recursively considers both primary and secondary rays and thus can create photorealistic images. In conventional ray tracing algorithms analytical rays, searching for the closest intersection, are intersected with the object list. <p> Alternatively, ray casting can be implemented to support also perspective viewing. Since ray casting follows only primary rays, it does not directly support the simulation of light phenomena such as reection, shadows, and refraction. As an alternative we have developed the 3D raster ray tracer (RRT) <ref> [50] </ref> that recursively considers both primary and secondary rays and thus can create photorealistic images.
Reference: 51. <author> Yagel, R. and Kaufman, A., </author> <title> Template-Based Volume Viewing, </title> <journal> Computer Graphics Forum, </journal> <volume> 11(3) </volume> <pages> 153-157, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: The master then subdivides the image region further and distributes the new sub-regions to idle cells. To support such a dynamic scheme the volume is replicated among clusters of neighboring cells. The template based viewing method <ref> [51] </ref> has been successfully implemented in [5][40] on SIMD machines. Both implementations are very similar. Parallel rays are traced in a lock step fashion by all nodes of the SIMD node. Each node is mapped to a voxel in both implementations.
Reference: 52. <author> Yagel R. and Z. Shi, </author> <title> Accelerating Volume Animation by Space-Leaping, </title> <booktitle> Proceedings of Visualization93, </booktitle> <address> San Jose, Califor-nia, </address> <month> October </month> <year> 1993, </year> <pages> pp. 62-69. </pages>
Reference-contexts: Frame coherency: When an animation sequence is generated, in many cases, there is not much difference between successive images. Therefore, much of the work invested to produce one image may be used to expedite the generation of the next image. Yagel and Shi <ref> [52] </ref> have reported on a method for speeding up the process of volume rendering a sequence of images. It is based on exploiting coherency between consecutive images to shorten the path rays take through the volume.
Reference: 53. <author> Yagel R. and R. Machiraju, </author> <title> Data Parallel Volume Rendering Algorithms, </title> <journal> The Visual Computer, </journal> <volume> 11(6) </volume> <pages> 319-338, </pages> <year> 1995. </year>
Reference-contexts: These processes transform and splat the voxels onto image sheets which are then sent to N compositing processes. N 7 Machiraju and Yagel implement a similar splatting algorithm on a IBM Power Visualization System (PVS) <ref> [53] </ref>. In this method a computational scheme is utilized which allows very efficient transformations based on incremental vec-torized computation. Also, the volume is statically divided into an ordered set of slabs (of slices). <p> This address is used for interpolating in object space and obtaining the sample value. The advantage of this address computation scheme is that communication required for interpolation is nearest neighbor and regular. In the final stages another communication step is required for actually rearranging the transformed volume. In <ref> [53] </ref>, a hybrid method was implemented on the IBM Power Visualization System (PVS). The volume data is subdivided into sub-cubes and assigned to different processors. The transformed extents of these sub-cubes are determined in the image space.
Reference: 54. <author> Yagel R., D.S. Ebert, J. Scott, and Y. </author> <title> Kurzion Grouping Volume Renderers for Enhanced Visualization in Computational Fluid Dynamics, </title> <journal> IEEE Transactions on Visualization and Computer Graphics, </journal> <volume> 1(2) </volume> <pages> 117-132, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: When the volume remains stationary and unchanged for some short period, the rendering system renders the rest of the points to increase image quality. These ideas was further explored to allow non-binary surfaces by extracting all voxels that contribute to the final image <ref> [54] </ref>. Another efficient implementation of the splatting algorithm, called hierarchical splatting [21] uses a pyramid data structure to hold a multi-resolution representation of the volume. For a volume of resolution, the pyramid data structure consists of a sequence of volumes. <p> However, these polygon rendering engines seem inherently unsuitable to the task. Recently, some new methods have tapped to this rendering power by either utilizing texture mapping capabilities for rendering splats [8][21], or by exploiting solid texturing capabili 9 ties to implement a slicing-based volume rendering [4]. The Volume Splatter <ref> [54] </ref> relies on the notion of fuzzy voxel set which consists of a subset of the volumes voxels. For each voxel in the original volume, we evaluate a transfer function that maps the gradient and the density of the given voxel to an importance number.
Reference: 55. <author> R. Yagel, D. Stredney, G.J. Wiet, P. Schmalbrock, L. Rosenberg, D.J. Sessanna, Y. Kurzion, and S. King, </author> <title> Multisensory Platform for Surgical Simulation, </title> <booktitle> IEEE Virtual Reality Annual International Symposium 1996 - VRAIS'96, </booktitle> <address> Santa Clara CA, </address> <month> March </month> <year> 1996, </year> <pages> pp. 72-78. </pages>
Reference-contexts: For a complete comparison see [17]. Although compute power required for volume rendering is immense, so are the benefits from some potential applications which rely on such capability. One such application is the simulation of surgery on a virtual patient <ref> [55] </ref>. The patient is first 'digitized' by a medical scanners such as CT, MRI, or Ultrasound. Surgery can then be planned, rehearsed, and redesigned while operating on the digital model in a non-threatening virtual environment.
Reference: 56. <author> Yoo, T. S., Neumann, U., Fuchs, H., Pizer, S. M., Cullip, T., Rhoades, J., and Whitaker, R., </author> <title> Direct Visualization of Volume Data, </title> <journal> Computer Graphics and Applications, </journal> <volume> 12(4) </volume> <pages> 63-71, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Thus, inter-node communication is required only in this final stage. The amount of communication required is low and this implementation scales well with increased number of processors. In Neumanns implementation on the Pixel Planes 5 architecture <ref> [56] </ref> graphics processors transform and shade the voxels, while the rendering processors implement splatting and receive the requisite instruction stream from the graphics processors. Each rendering processor is assigned a subsection of the screen. Only voxels which map to that screen area are sent to this renderer.
Reference: 57. <author> Zuiderveld, K., Koning, A. H. J., and Viergever, M. A., </author> <title> Acceleration of Ray Casting Using 3D Distance Transforms, </title> <booktitle> Proceedings of Visualization in Biomedical Computing 1992, </booktitle> <volume> 1808, </volume> <month> October </month> <year> 1992, </year> <pages> pp 324-335. </pages>
References-found: 56

