URL: http://theory.lcs.mit.edu/~miccianc/papers/inchash.ps
Refering-URL: http://theory.lcs.mit.edu/~cis/cis-publications.html
Root-URL: 
Email: E-Mail: mihir@watson.ibm.com.  E-Mail: miccianc@theory.lcs.mit.edu.  
Title: A New Paradigm for Collision-free Hashing: Incrementality at Reduced Cost  
Author: Mihir Bellare Daniele Micciancio 
Web: URL: http://www-cse.ucsd.edu/users/mihir.  
Address: San Diego, 9500 Gilman Drive, La Jolla, California 92093, USA.  545 Technology Square, Cambridge, MA 02139, USA.  
Affiliation: Dept. of Computer Science Engineering, University of California at  Science and Engineering. MIT Laboratory for Computer Science,  
Date: November 1996  
Note: Lecture Notes in Computer Science Vol. W. Fumy ed., Springer-Verlag, 1997.  Supported in part by NSF CAREER Award CCR-9624439 and a Packard Foundation Fellowship in  Supported in part by DARPA contract DABT63-96-C-0018.  
Abstract: An abridged version of this paper appears in Advances in Cryptology - Eurocrypt 97 Proceedings, Abstract We present a simple, new paradigm for the design of collision-free hash functions. A key feature of this paradigm is that any function emanating from it is incremental. This means that if a message x which I have previously hashed is modified to x 0 then rather than having to re-compute the hash of x 0 from scratch, I can quickly "update" the old hash value to the new one, in time proportional to the amount of modification made in x to get x 0 . Another property of any function emanating from this paradigm is to be parallelizable, useful for hardware implementation. We derive several specific functions from our paradigm. All use a standard hash function, assumed ideal, and some algebraic operations. The first function, MuHASH, uses one modular multiplication per block of the message, making it reasonably efficient, and significantly faster than previous incremental hash functions. Moreover its security is proven, based on the hardness of the discrete logarithm problem. A second function, AdHASH, is even faster, using additions instead of multiplications. Its security too is proven, given either that approximation of the length of shortest lattice vectors is hard or that the weighted subset sum problem is hard. A third function, LtHASH, is a practical variant of recent lattice based functions, with security proven based, again on the hardness of shortest lattice vector approximation. 
Abstract-found: 1
Intro-found: 1
Reference: [Aj] <author> M. Ajtai, </author> <title> "Generating hard instances of lattice problems," </title> <booktitle> Proceedings of the 28th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1996. </year>
Reference-contexts: In fact AdHASH is competitive with standard hash functions in speed, with the added advantages of incrementality and parallelizability. AdHASH also has strong security guarantees. We show that it is collision-free as long as the "weighted knapsack problem" (which we define) is hard and h is ideal. But Ajtai <ref> [Aj] </ref> has given strong evidence that the weighted subset sum problem is hard: he has shown that this is true as long as there is no polynomial time approximation algorithm for the shortest vector problem in a 6 lattice, in the worst case. <p> See Appendix D.) In summary AdHASH is quite attractive both on the efficiency and on the security fronts. 1.5 Hashing from Lattice Problems Ajtai introduced a linear function which is provably one-way if the problem of approximating the (Euclidean) length of the shortest vector in a lattice is hard <ref> [Aj] </ref>. (The function is matrix-vector multiplication, with particular parameters). Goldreich, Goldwasser and Halevi [GGH] observed that Ajtai's main lemma can be applied to show that the function is actually collision-free, not just one-way. We observe that this hash function is incremental. But we also point out some impracticalities. <p> Assuming h is ideal the security of this hash function can be directly related to the problem underlying the security of Ajtai's one-way function <ref> [Aj, GGH] </ref> so that it is collision-free as long as the shortest lattice vector approximation problem is hard. <p> We will see how the hardness of the balance problem follows from the hardness of discrete logs; how in additive groups it is just the weighted subset sum problem; and that it captures the matrix kernel problem presented in <ref> [Aj] </ref> which is the basis of lattice based hash functions [GGH]. 7 The problem is simply that given random group elements a 1 ; : : : ; a n , find disjoint subsets I; J f1; : : :; ng, not both empty, such that J J j2J a j <p> The best known polynomial time algorithms [LLL, SH] achieve only an exponential approximation factor. It has been suggested that there is no polynomial time algorithm which achieves a polynomial approximation factor. Under this assumption, Ajtai showed that both the standard and the weighted subset-sum problems are hard <ref> [Aj] </ref>. (Actually he allows any small integer weights, not just 1; 0; +1 like we do). That is, there is no polynomial time algorithm to solve these problems. This is important evidence in favor of both the knapsack assumptions discussed above. <p> and the observation that weighted knapsack is a particular case of the balance problem, as mentioned in Section 5.2. 6 Incremental Hashing via Lattice Problems Ajtai introduced a function which he showed was one-way if the problem of approximating the shortest vector in a lattice to polynomial factors is hard <ref> [Aj] </ref>. Goldreich, Goldwasser and Halevi observed that Ajtai's main lemma could be applied to show that the same function is in fact collision-free [GGH]. Here we observe this hash function is incremental, and consider its practicality. <p> Here we observe this hash function is incremental, and consider its practicality. We then use our paradigm to derive a more practical version of this function whose security is based on the same assumption as in <ref> [Aj, GGH] </ref> plus the assumption that our h is ideal. <p> This shows how the balance problem unifies so many hash functions. 6.2 The Ajtai-GGH Function The function. Let M be a random k by n matrix with entries in Z p and let x be an n vector with entries in f0; 1g. The function of <ref> [Aj, GGH] </ref> is H M;p (x) = M x mod p : Note M x mod p is a k-vector over Z p , meaning it is k lg (p) bits long. <p> Thus it is a hash function. Now, if the matrix kernel problem is hard this function is one-way <ref> [Aj] </ref>. Moreover, under the same assumption it is collision-free [GGH]. It follows from [Aj] that the function is collision-free as long as shortest vector approximation is hard. Incrementality. We observe the above function is incremental. <p> Thus it is a hash function. Now, if the matrix kernel problem is hard this function is one-way <ref> [Aj] </ref>. Moreover, under the same assumption it is collision-free [GGH]. It follows from [Aj] that the function is collision-free as long as shortest vector approximation is hard. Incrementality. We observe the above function is incremental. Let M i denote the i-th column of M , for i = 1; : : : ; n. This is a k-vector over Z p . <p> We want to allow q, the number of oracle queries, to be quite large, say q = 2 70 . To ensure q &lt; 2 s =(2k 4 ) we must take s about 110. Namely p is 110 bits long. This is longer than what the function of <ref> [Aj, GGH] </ref> needs, making operations modulo p slower for LtHASH, but this is compensated for by having much fewer such operations to do, since we can make the block size b large. Of course LtHASH is still incremental. Incrementing takes one addition and one subtraction over Z k p .
Reference: [BGG1] <author> M. Bellare, O. Goldreich and S. Goldwasser, </author> <title> "Incremental cryptography: The case of hashing and signing," </title> <booktitle> Advances in Cryptology - Crypto 94 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 839, </volume> <editor> Y. Desmedt ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: It turns out that even putting incrementality aside, functions resulting from our paradigm have attractive features, such as parallelizability. 1.1 Incremental Hashing The idea. The notion of incrementality was advanced by Bellare, Goldreich and Goldwasser <ref> [BGG1] </ref>. They point out that when we cryptographically process documents in bulk, these documents may be related to each other, something we could take advantage of to speed up the computation of the cryptographic transformations. <p> The problem is you need to store the entire tree, meaning all the intermediate hash values. What we want is to store only the final hash value and be able to increment given only this. Past work. To date the only incremental hash function was proposed by <ref> [BGG1] </ref>, based on work of [CHP]. This function is based on discrete exponentiation in a group of prime order. It uses one modular exponentiation per message block to hash the message. This is very expensive, especially compared with standard hash functions. <p> And of course the previous functions, barring those of <ref> [BGG1] </ref>, are non-incremental.) Collision-free versus universal one-way. Collision-freeness is a stronger property than the property of universal one-wayness defined by Naor and Yung [NY]. Functions meeting their conditions are not necessarily collision-free. (But they do suffice for many applications.) Subset-sum based hashing. <p> If the random oracle is not present, we simply drop the "q", and have (t; *)-breaking and (t; *)-security. 2.2 Incrementality We follow <ref> [BGG1] </ref>. Suppose we have computed the hash value y = F (K; x) of a message x = x 1 : : : x n . Now x is modified: block i is replaced by a new block x 0 i .
Reference: [BGG2] <author> M. Bellare, O. Goldreich and S. Goldwasser, </author> <title> "Incremental cryptography with application to virus protection," </title> <booktitle> Proceedings of the 27th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1995. </year>
Reference-contexts: Incrementality. Other work on incremental cryptography includes <ref> [BGG2, Mi] </ref>.
Reference: [BGR] <author> M. Bellare, R. Gu erin and P. Rogaway, </author> <title> "XOR MAcs: New methods for message authentication using finite pseudorandom functions," </title> <booktitle> Advances in Cryptology - Crypto 95 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 963, </volume> <editor> D. Coppersmith ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: However, attacks have been found by Coppersmith and Preneel [CP]. 8 XOR MACs. Our paradigm for hashing is somewhat inspired by, and related to, the XOR MACs of <ref> [BGR] </ref>. There, XOR worked as a combining operation. But the goal and assumptions were different. Those schemes were for message authentication, which is a private key based primitive. <p> Those schemes were for message authentication, which is a private key based primitive. In particular, the function playing the role of h was secret, computable only by the legitimate parties and not the adversary. (So in particular, the attack of Appendix A does not apply to the schemes of <ref> [BGR] </ref>.) However, hash functions have to have a public description, and what we see is that in such a case the security vanishes if the combining operation is XOR. Incrementality. Other work on incremental cryptography includes [BGG2, Mi].
Reference: [BR] <author> M. Bellare and P. Rogaway, </author> <title> "Random oracles are practical: A paradigm for designing efficient protocols," </title> <booktitle> Proceedings of the First Annual Conference on Computer and Communications Security, ACM, </booktitle> <year> 1993. </year>
Reference-contexts: value y = y 1 fi y 2 fi : : :fi y n , where fi denotes the "combining operation." Here h, the "randomizing" function, is derived in practice from some standard hash function like SHA-1, and treated in the analysis as an "ideal" hash function or random oracle <ref> [BR] </ref>. (For completeness a brief discussion of this paradigm is provided in Appendix E). The combining operation fi is typically a group operation, meaning that we interpret y 1 ; : : : ; y n as members of some commutative group G whose operation is denoted fi. <p> The key K then becomes public, available to all parties including the adversary: these hash functions involve no hidden randomness. In our constructions an "ideal hash function" h is also present. We follow the paradigm of <ref> [BR] </ref>: In practice, h is derived from a standard cryptographic hash function like SHA, while formally it is modeled as a "random oracle." The latter means h is initially drawn at random from some family of functions, and then made public. <p> We provide in Appendix E a discussion of what security in this random oracle paradigm can guarantee and not guarantee. For yet more information the reader is referred to <ref> [BR] </ref>. We want hash functions that compress their data. A typical desired choice is that Dom (F ) = f0; 1g fl and Range (F ) is some finite set, for example f0; 1g k for some integer k. But other choices are possible too. Collision-resistance. <p> as part of the key specifying the hash function and H (y) is an apprporiate length prefix of SHA-1 (0 : y) : SHA-1 (1 : y) : : :.) In the analyses, we in fact assume much more, namely that it is an "ideal" hash function or random oracle <ref> [BR] </ref>.) Its computation is assumed fast. 12 3.4 Choosing the Combining Operation Making the right choice of combining operation is crucial for security and efficiency. Combining by XORing doesn't work.
Reference: [Co] <author> D. Coppersmith, </author> <title> "Two Broken Hash Functions," </title> <institution> IBM Research Report RC-18397, IBM Research Center, </institution> <address> Yorktown Heights, NY, </address> <month> October </month> <year> 1992. </year> <month> 22 </month>
Reference: [CP] <author> D. Coppersmith and B. Preneel, </author> <title> "Comments on MASH-1 and MASH-1," </title> <type> Manuscript, </type> <month> February </month> <year> 1995. </year>
Reference-contexts: More recent in this vein are MASH-1 and MASH-2, designed by GMD (Gesellschaft fur Mathematik im Dataverarbeitung) and being proposed as ISO standards. However, attacks have been found by Coppersmith and Preneel <ref> [CP] </ref>. 8 XOR MACs. Our paradigm for hashing is somewhat inspired by, and related to, the XOR MACs of [BGR]. There, XOR worked as a combining operation. But the goal and assumptions were different. Those schemes were for message authentication, which is a private key based primitive.
Reference: [CHP] <author> D. Chaum, E. Heijst and B. Pfitzmann, </author> <title> "Cryptographically strong undeniable signatures, unconditionally secure for the signer," </title> <booktitle> Advances in Cryptology - Crypto 91 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 576, </volume> <editor> J. Feigenbaum ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: What we want is to store only the final hash value and be able to increment given only this. Past work. To date the only incremental hash function was proposed by [BGG1], based on work of <ref> [CHP] </ref>. This function is based on discrete exponentiation in a group of prime order. It uses one modular exponentiation per message block to hash the message. This is very expensive, especially compared with standard hash functions.
Reference: [CLR] <author> T. Cormen, C. Leiserson and R. Rivest, </author> <title> "Introduction to Algorithms," </title> <publisher> McGraw-Hill, </publisher> <year> 1992. </year>
Reference-contexts: In general we would also measure the amount of memory used, but for simplicity we only measure time. The model of computation is that used in any standard text on algorithms, for example <ref> [CLR] </ref>, and we analyze the running time of algorithms in the same way as in any algorithms course). If a random oracle h is present, we consider the number of h-computations (formally, the number of oracle queries) as a separate resource of the collision-finder, and denote it by q.
Reference: [Da1] <author> I. </author> <title> Damgard "Collision Free Hash Functions and Public Key Signature Schemes," </title> <booktitle> Advances in Cryptology - Eurocrypt 87 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 304, </volume> <editor> D. Chaum ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: The last includes popular functions like MD5 [Ri], SHA-1 [SHA] and RIPEMD-160 [DBP]. The modular arithmetic based hash functions are in fact also iterative, and so are the bulk of number-theory based ones, eg. <ref> [Da1] </ref>. <p> our knowledge, all previous discrete logarithm or factoring based hash functions which have a security that can be provably related to that of the underlying number theoretic problem use at least one multiplication per bit of the message, and sometimes more. (For example this is true of the functions of <ref> [Da1] </ref>, which are based on claw-free permutations [GMR].) In contrast, MuHASH uses one multiplication per b-bit block and can make b large to mitigate the cost of the multiplication. (But MuHASH uses a random oracle assumption which the previous constructions do not.
Reference: [Da2] <author> I. </author> <title> Damgard "A Design Principle for Hash Functions," </title> <booktitle> Advances in Cryptology - Crypto 89 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 435, </volume> <editor> G. Brassard ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: This is true for constructions based on block ciphers. (For description of these constructions see for example the survey [PGV].) It is also true for the compression function based constructions that use the Merkle-Damg-ard meta-method <ref> [Me, Da2] </ref>. The last includes popular functions like MD5 [Ri], SHA-1 [SHA] and RIPEMD-160 [DBP]. The modular arithmetic based hash functions are in fact also iterative, and so are the bulk of number-theory based ones, eg. [Da1]. <p> The modular arithmetic based hash functions are in fact also iterative, and so are the bulk of number-theory based ones, eg. [Da1]. A thought that comes to mind is to use a tree structure for hashing, as described in <ref> [Me, Da2] </ref>. (Adjacent blocks are first hashed together, yielding a text half the length of the original one, and then the process is repeated until a final hash value is obtained.) One is tempted to think this is incremental because if a message block is modified, work proportional only to the <p> By choosing different groups we get various specific, incremental, collision-free hash functions, as we now describe. Notice that h needs itself to be collision-free, but applies only to fixed length inputs. Thus, it can be viewed as a "compression function." Like <ref> [Me, Da2] </ref>, our paradigm can thus be viewed as constructing variable input length hash functions from compression functions. However, our construction is "parallel" rather than iterative. <p> Impagliazzo and Naor [IN1, IN2] define a hash function and prove that it is a universal one-way function (which is weaker than collision-free) as long as the subset-sum function is one-way. The same function is defined in <ref> [Da2, Section 4.3] </ref>. There it is conjectured to be collision-free as well, but no proof is provided. These functions have a key length as long as the input to be hashed (very impractical) and use one addition per bit of the message. <p> we describe next not only has small key size and no limit on input length, but is also more efficient. 3 3 Another way to reduce the key size is define H M;P only on relatively short data, and then, viewing it as a compression function, apply Damg-ard's iteration method <ref> [Da2] </ref>. But then incrementality is lost. Also, the key sizes, although no longer proportional to the data length, are still larger than for the construction we will describe. 20 6.3 LtHASH Our function is called LtHASH for "lattice based hash." The construction.
Reference: [DBP] <author> H. Dobbertin, A. Bosselaers and B. Preneel, "RIPEMD-160: </author> <title> A strengthened version of RIPEMD," Fast Software Encryption, </title> <booktitle> Lecture Notes in Computer Science 1039, </booktitle> <editor> D. Gollmann, ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: This is true for constructions based on block ciphers. (For description of these constructions see for example the survey [PGV].) It is also true for the compression function based constructions that use the Merkle-Damg-ard meta-method [Me, Da2]. The last includes popular functions like MD5 [Ri], SHA-1 [SHA] and RIPEMD-160 <ref> [DBP] </ref>. The modular arithmetic based hash functions are in fact also iterative, and so are the bulk of number-theory based ones, eg. [Da1].
Reference: [GJ] <author> M. Garey and D. Johnson, </author> <title> "Computers and intractability: A guide to the theory of NP-completeness," </title> <editor> W. H. </editor> <publisher> Freedman and Company, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference: [Gi] <author> M. Girault, </author> <title> "Hash functions using modulo-N operations," </title> <booktitle> Advances in Cryptology - Eurocrypt 87 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 304, </volume> <editor> D. Chaum ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: Modular arithmetic hash functions. Several iterative modular arithmetic based hash functions have been proposed in the past. (These do not try to provably relate the ability to find collisions to any underlying hard arithmetic problems.) See Girault <ref> [Gi] </ref> for a list and some attacks. More recent in this vein are MASH-1 and MASH-2, designed by GMD (Gesellschaft fur Mathematik im Dataverarbeitung) and being proposed as ISO standards. However, attacks have been found by Coppersmith and Preneel [CP]. 8 XOR MACs.
Reference: [GGH] <author> O. Goldreich, S. Goldwasser and S. Halevi, </author> <title> "Collision-Free Hashing from Lattice Problems," Theory of Cryptography Library (http://theory.lcs.mit.edu/~tcryptol/) 96-09, </title> <month> July </month> <year> 1996. </year>
Reference-contexts: Goldreich, Goldwasser and Halevi <ref> [GGH] </ref> observed that Ajtai's main lemma can be applied to show that the function is actually collision-free, not just one-way. We observe that this hash function is incremental. But we also point out some impracticalities. <p> Assuming h is ideal the security of this hash function can be directly related to the problem underlying the security of Ajtai's one-way function <ref> [Aj, GGH] </ref> so that it is collision-free as long as the shortest lattice vector approximation problem is hard. <p> We will see how the hardness of the balance problem follows from the hardness of discrete logs; how in additive groups it is just the weighted subset sum problem; and that it captures the matrix kernel problem presented in [Aj] which is the basis of lattice based hash functions <ref> [GGH] </ref>. 7 The problem is simply that given random group elements a 1 ; : : : ; a n , find disjoint subsets I; J f1; : : :; ng, not both empty, such that J J j2J a j , where fi is the group operation. <p> Goldreich, Goldwasser and Halevi observed that Ajtai's main lemma could be applied to show that the same function is in fact collision-free <ref> [GGH] </ref>. Here we observe this hash function is incremental, and consider its practicality. We then use our paradigm to derive a more practical version of this function whose security is based on the same assumption as in [Aj, GGH] plus the assumption that our h is ideal. <p> Here we observe this hash function is incremental, and consider its practicality. We then use our paradigm to derive a more practical version of this function whose security is based on the same assumption as in <ref> [Aj, GGH] </ref> plus the assumption that our h is ideal. <p> However <ref> [GGH] </ref> observed that weights of 1; 0; +1 are what is important in the context of hashing and we restrict our attention to these). <p> This shows how the balance problem unifies so many hash functions. 6.2 The Ajtai-GGH Function The function. Let M be a random k by n matrix with entries in Z p and let x be an n vector with entries in f0; 1g. The function of <ref> [Aj, GGH] </ref> is H M;p (x) = M x mod p : Note M x mod p is a k-vector over Z p , meaning it is k lg (p) bits long. <p> Thus it is a hash function. Now, if the matrix kernel problem is hard this function is one-way [Aj]. Moreover, under the same assumption it is collision-free <ref> [GGH] </ref>. It follows from [Aj] that the function is collision-free as long as shortest vector approximation is hard. Incrementality. We observe the above function is incremental. Let M i denote the i-th column of M , for i = 1; : : : ; n. <p> In particular, it does not seem clear how big we need take k (which corresponds to the dimension of the lattice) before we can be sure of security. One must also take into account the exact security of the reductions, which are far from tight. (Some discussion is in <ref> [GGH, Section 3] </ref>). 21 Keeping all this in mind let us look at our case. It seems safe to set k = 500. (Less will probably suffice). We want to allow q, the number of oracle queries, to be quite large, say q = 2 70 . <p> We want to allow q, the number of oracle queries, to be quite large, say q = 2 70 . To ensure q &lt; 2 s =(2k 4 ) we must take s about 110. Namely p is 110 bits long. This is longer than what the function of <ref> [Aj, GGH] </ref> needs, making operations modulo p slower for LtHASH, but this is compensated for by having much fewer such operations to do, since we can make the block size b large. Of course LtHASH is still incremental. Incrementing takes one addition and one subtraction over Z k p .
Reference: [GMR] <author> S. Goldwasser, S. Micali and R. Rivest, </author> <title> "A digital signature scheme secure against adaptive chosen-message attacks," </title> <journal> SIAM Journal of Computing, </journal> <volume> Vol. 17, No. 2, </volume> <pages> pp. 281-308, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: factoring based hash functions which have a security that can be provably related to that of the underlying number theoretic problem use at least one multiplication per bit of the message, and sometimes more. (For example this is true of the functions of [Da1], which are based on claw-free permutations <ref> [GMR] </ref>.) In contrast, MuHASH uses one multiplication per b-bit block and can make b large to mitigate the cost of the multiplication. (But MuHASH uses a random oracle assumption which the previous constructions do not.
Reference: [IN1] <author> R. Impagliazzo and M. Naor, </author> <title> "Efficient cryptographic schemes provably as secure as subset sum," </title> <booktitle> Proceedings of the 30th Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1989. </year>
Reference-contexts: We also prove that AdHASH is a universal one-way hash function in the sense of Naor and Yung [NY], assuming the subset sum function of <ref> [IN1, IN2] </ref> is one-way and h is ideal. (Thus, under a weaker assumption, we can show that a weaker form but still useful form of collision-freeness holds. We note our reductions here are tight, unlike those of [IN1, IN2]. <p> the sense of Naor and Yung [NY], assuming the subset sum function of <ref> [IN1, IN2] </ref> is one-way and h is ideal. (Thus, under a weaker assumption, we can show that a weaker form but still useful form of collision-freeness holds. We note our reductions here are tight, unlike those of [IN1, IN2]. <p> Collision-freeness is a stronger property than the property of universal one-wayness defined by Naor and Yung [NY]. Functions meeting their conditions are not necessarily collision-free. (But they do suffice for many applications.) Subset-sum based hashing. Impagliazzo and Naor <ref> [IN1, IN2] </ref> define a hash function and prove that it is a universal one-way function (which is weaker than collision-free) as long as the subset-sum function is one-way. The same function is defined in [Da2, Section 4.3]. <p> Hashing by multiplying in a group. Independently of our work, Impagliazzo and Naor have also considered hashing by multiplying in a group. These results have been included in [IN2], the recent journal version of their earlier <ref> [IN1] </ref>. <p> This hardness assumption is essentially the same as Impagliazzo and Naor's assumption that the subset sum function is one-way <ref> [IN1, IN2] </ref>. We must be careful how we choose the parameters: it is well known that for certain values of k and q, the problem is not hard. We must avoid these values. Specifically, we will make sure that (log q) &lt; k &lt; q.
Reference: [IN2] <author> R. Impagliazzo and M. Naor, </author> <title> "Efficient cryptographic schemes provably as secure as subset sum," </title> <journal> Journal of Cryptology, </journal> <volume> Vol. 9, No. 4, </volume> <month> Autumn </month> <year> 1996. </year>
Reference-contexts: We also prove that AdHASH is a universal one-way hash function in the sense of Naor and Yung [NY], assuming the subset sum function of <ref> [IN1, IN2] </ref> is one-way and h is ideal. (Thus, under a weaker assumption, we can show that a weaker form but still useful form of collision-freeness holds. We note our reductions here are tight, unlike those of [IN1, IN2]. <p> the sense of Naor and Yung [NY], assuming the subset sum function of <ref> [IN1, IN2] </ref> is one-way and h is ideal. (Thus, under a weaker assumption, we can show that a weaker form but still useful form of collision-freeness holds. We note our reductions here are tight, unlike those of [IN1, IN2]. <p> Collision-freeness is a stronger property than the property of universal one-wayness defined by Naor and Yung [NY]. Functions meeting their conditions are not necessarily collision-free. (But they do suffice for many applications.) Subset-sum based hashing. Impagliazzo and Naor <ref> [IN1, IN2] </ref> define a hash function and prove that it is a universal one-way function (which is weaker than collision-free) as long as the subset-sum function is one-way. The same function is defined in [Da2, Section 4.3]. <p> Hashing by multiplying in a group. Independently of our work, Impagliazzo and Naor have also considered hashing by multiplying in a group. These results have been included in <ref> [IN2] </ref>, the recent journal version of their earlier [IN1]. <p> Thus there is one group operation per bit of the message, and also the key size is proportional to the input to be hashed. Functions resulting from our paradigm use one group operation per b-bit block, which is faster, and have fixed key size. On the security side, <ref> [IN2] </ref> show that their hash function is universal one-way as long as any homomorphism with image the given group is one-way. (In particular, if the discrete logarithm problem in the group is hard.) In contrast we show that our functions have the stronger property of being collision-free. <p> But the techniques are related and it is also important to note that we use a random oracle assumption and they do not. On the other hand our reductions are tight and theirs are not. The general security assumption of <ref> [IN2] </ref> and their results provide insight into why MuHASH may be secure even if the discrete logarithm problem is easy. Modular arithmetic hash functions. <p> In fact this suggests that the hash function obtained by setting the combining operation in our paradigm to addition might be already collision-free. This function and its security are discussed in Section 5. Some evidence that breaking MuHASH is harder than computing discrete logarithms comes from the results of <ref> [IN2] </ref> who indicate that multiplication in G is a one-way hash as long as any homomorphism with image G is hard. We can extend their proofs, with added conditions, to our setting. This indicates that unless all such homomorphisms are invertible via discrete logarithm computation, MuHASH will be collision-free. <p> This hardness assumption is essentially the same as Impagliazzo and Naor's assumption that the subset sum function is one-way <ref> [IN1, IN2] </ref>. We must be careful how we choose the parameters: it is well known that for certain values of k and q, the problem is not hard. We must avoid these values. Specifically, we will make sure that (log q) &lt; k &lt; q. <p> We must avoid these values. Specifically, we will make sure that (log q) &lt; k &lt; q. It turns out this choice will not be a restriction for us anyway. Nice discussions of what is known are available in [Od] and <ref> [IN2, Section 1.2] </ref>, and the reader is referred there for more information. This assumption will suffice to show that AdHASH is a universal one-way hash function (cf. Appendix D). In order to show collision-freeness we make a stronger assumption. Weighted knapsack problem. <p> Acknowledgments We thank Russell Impagliazzo for telling us about the relations between subset-sum and lattices, and for bringing <ref> [IN2] </ref> to our attention. We thank the (anonymous) referees of Eurocrypt 97 for comments which improved the presentation of this paper.
Reference: [LLL] <author> A. Lenstra, H. Lenstra and L. Lov asz, </author> <title> "Factoring polynomials with rational coefficients," </title> <journal> Mathematische Annalen Vol. </journal> <volume> 261, </volume> <pages> pp. 515-534, </pages> <year> 1982. </year>
Reference-contexts: However, there is important evidence about the hardness of the weighted knapsack problems that we discuss next. Relation to lattice problems. A well-known hard problem is to approximate the length of 18 the shortest vector in a lattice. The best known polynomial time algorithms <ref> [LLL, SH] </ref> achieve only an exponential approximation factor. It has been suggested that there is no polynomial time algorithm which achieves a polynomial approximation factor. <p> concrete complexity of the shortest lattice vector approximation problem vary across the community: it is not clear how high must be the dimension of the lattice to get a specific desired security level. (Although the best known algorithm for shortest vector approximation is only proven to achieve an exponential factor <ref> [LLL] </ref>, its in practice performance is often much better. And Schnorr and Horner [SH] have found heuristics that do better still). In particular, it does not seem clear how big we need take k (which corresponds to the dimension of the lattice) before we can be sure of security.
Reference: [MVV] <editor> A. Menezes, P. Van Oorschot and S. Vanstone, </editor> <booktitle> "Handbook of Applied Cryptography," </booktitle> <publisher> CRC Press, </publisher> <year> 1996. </year>
Reference-contexts: Having reduced the security of our hash function to this problem in Lemma 3.1, our main technical effort will be in relating the balance problem in a group to other problems in the group. 1.8 Related Work For a comprehensive survey of hashing see <ref> [MVV, Chapter 9] </ref>. Discrete logarithm or factoring based functions.
Reference: [Me] <author> R. </author> <title> Merkle "One Way Hash Functions and DES," </title> <booktitle> Advances in Cryptology - Crypto 89 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 435, </volume> <editor> G. Brassard ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: This is true for constructions based on block ciphers. (For description of these constructions see for example the survey [PGV].) It is also true for the compression function based constructions that use the Merkle-Damg-ard meta-method <ref> [Me, Da2] </ref>. The last includes popular functions like MD5 [Ri], SHA-1 [SHA] and RIPEMD-160 [DBP]. The modular arithmetic based hash functions are in fact also iterative, and so are the bulk of number-theory based ones, eg. [Da1]. <p> The modular arithmetic based hash functions are in fact also iterative, and so are the bulk of number-theory based ones, eg. [Da1]. A thought that comes to mind is to use a tree structure for hashing, as described in <ref> [Me, Da2] </ref>. (Adjacent blocks are first hashed together, yielding a text half the length of the original one, and then the process is repeated until a final hash value is obtained.) One is tempted to think this is incremental because if a message block is modified, work proportional only to the <p> By choosing different groups we get various specific, incremental, collision-free hash functions, as we now describe. Notice that h needs itself to be collision-free, but applies only to fixed length inputs. Thus, it can be viewed as a "compression function." Like <ref> [Me, Da2] </ref>, our paradigm can thus be viewed as constructing variable input length hash functions from compression functions. However, our construction is "parallel" rather than iterative.
Reference: [Mi] <author> D. Micciancio, </author> <title> "Oblivious data structures: applications to cryptography," </title> <booktitle> Proceedings of the 29th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1997. </year>
Reference-contexts: Incrementality. Other work on incremental cryptography includes <ref> [BGG2, Mi] </ref>.
Reference: [NY] <author> M. Naor and M. Yung, </author> <title> "Universal one-way hash functions and their cryptographic applications," </title> <booktitle> Proceedings of the 21st Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1989. </year>
Reference-contexts: But even if this approximation turns out to be feasible (which we don't expect) the weighted subset sum problem may still be hard, so that AdHASH may still be secure. We also prove that AdHASH is a universal one-way hash function in the sense of Naor and Yung <ref> [NY] </ref>, assuming the subset sum function of [IN1, IN2] is one-way and h is ideal. (Thus, under a weaker assumption, we can show that a weaker form but still useful form of collision-freeness holds. We note our reductions here are tight, unlike those of [IN1, IN2]. <p> And of course the previous functions, barring those of [BGG1], are non-incremental.) Collision-free versus universal one-way. Collision-freeness is a stronger property than the property of universal one-wayness defined by Naor and Yung <ref> [NY] </ref>. Functions meeting their conditions are not necessarily collision-free. (But they do suffice for many applications.) Subset-sum based hashing. Impagliazzo and Naor [IN1, IN2] define a hash function and prove that it is a universal one-way function (which is weaker than collision-free) as long as the subset-sum function is one-way.
Reference: [Od] <author> A. Odlyzko, </author> <title> "The rise and fall of knapsack cryptosystems," Advances in computational number theory, </title> <editor> C. Pomerance ed., </editor> <booktitle> Proc. Symp. Applied Math No. </booktitle> <volume> 42, </volume> <pages> pp. 75-88, </pages> <publisher> AMS, </publisher> <year> 1990. </year>
Reference-contexts: We must avoid these values. Specifically, we will make sure that (log q) &lt; k &lt; q. It turns out this choice will not be a restriction for us anyway. Nice discussions of what is known are available in <ref> [Od] </ref> and [IN2, Section 1.2], and the reader is referred there for more information. This assumption will suffice to show that AdHASH is a universal one-way hash function (cf. Appendix D). In order to show collision-freeness we make a stronger assumption. Weighted knapsack problem.
Reference: [PGV] <author> B. Preneel, R. Govaerts and J. Vandewalle, </author> <title> "Hash functions based on block ciphers: a synthetic approach," </title> <booktitle> Advances in Cryptology - Crypto 93 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 773, </volume> <editor> D. Stinson ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <month> 23 </month>
Reference-contexts: Standard constructions fail. Incrementality does not seem easy to achieve. Standard methods of hash function construction fail to achieve it because they involve some sort of iteration. This is true for constructions based on block ciphers. (For description of these constructions see for example the survey <ref> [PGV] </ref>.) It is also true for the compression function based constructions that use the Merkle-Damg-ard meta-method [Me, Da2]. The last includes popular functions like MD5 [Ri], SHA-1 [SHA] and RIPEMD-160 [DBP].
Reference: [Ri] <author> R. Rivest, </author> <title> "The MD5 Message-Digest Algorithm," </title> <type> IETF RFC 1321, </type> <month> April </month> <year> 1992. </year>
Reference-contexts: This is true for constructions based on block ciphers. (For description of these constructions see for example the survey [PGV].) It is also true for the compression function based constructions that use the Merkle-Damg-ard meta-method [Me, Da2]. The last includes popular functions like MD5 <ref> [Ri] </ref>, SHA-1 [SHA] and RIPEMD-160 [DBP]. The modular arithmetic based hash functions are in fact also iterative, and so are the bulk of number-theory based ones, eg. [Da1].
Reference: [RS] <author> J. Rosser and L. Schoenfeld, </author> <title> "Approximate formulas for some functions of prime numbers," </title> <journal> Illinois Journal of Math Vol. </journal> <volume> 6, </volume> <year> 1962. </year>
Reference: [SH] <author> C. Schnorr and H. H orner, </author> <title> "Attacking the Chor-Rivest cryptosystem with improved lattice reduction," </title> <booktitle> Advances in Cryptology - Eurocrypt 95 Proceedings, Lecture Notes in Computer Science Vol. </booktitle> <volume> 921, </volume> <editor> L. Guillou and J. Quisquater ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: However, there is important evidence about the hardness of the weighted knapsack problems that we discuss next. Relation to lattice problems. A well-known hard problem is to approximate the length of 18 the shortest vector in a lattice. The best known polynomial time algorithms <ref> [LLL, SH] </ref> achieve only an exponential approximation factor. It has been suggested that there is no polynomial time algorithm which achieves a polynomial approximation factor. <p> And Schnorr and Horner <ref> [SH] </ref> have found heuristics that do better still). In particular, it does not seem clear how big we need take k (which corresponds to the dimension of the lattice) before we can be sure of security.
Reference: [SHA] <editor> FIPS 180-1. </editor> <title> "Secure Hash Standard," Federal Information Processing Standard (FIPS), </title> <type> Publication 180-1, </type> <institution> National Institute of Standards and Technology, US Department of Commerce, </institution> <address> Wash-ington D.C., </address> <month> April </month> <year> 1995. </year>
Reference-contexts: This is true for constructions based on block ciphers. (For description of these constructions see for example the survey [PGV].) It is also true for the compression function based constructions that use the Merkle-Damg-ard meta-method [Me, Da2]. The last includes popular functions like MD5 [Ri], SHA-1 <ref> [SHA] </ref> and RIPEMD-160 [DBP]. The modular arithmetic based hash functions are in fact also iterative, and so are the bulk of number-theory based ones, eg. [Da1].
References-found: 29

