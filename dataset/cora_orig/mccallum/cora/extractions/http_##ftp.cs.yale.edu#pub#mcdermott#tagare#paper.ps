URL: http://ftp.cs.yale.edu/pub/mcdermott/tagare/paper.ps
Refering-URL: http://ftp.cs.yale.edu/pub/mcdermott/tagare/
Root-URL: http://www.cs.yale.edu
Title: Visual Place Recognition for Autonomous Robots  
Author: Hemant D. Tagare Drew McDermott Hong Xiao 
Address: New Haven, CT 06520 New Haven, CT 06520 New Haven, CT 06520 USA USA USA  
Affiliation: Department of Radiology Computer Science Department Computer Science Department Computer Science Department Yale University Yale University Yale University  
Abstract: The problem of place recognition is central to robot map learning. A robot needs to be able to recognize when it has returned to a previously visited place, or at least to be able to estimate the likelihood that it has been at a place before. Our approach is to compare images taken at two places, using a stochastic model of changes due to shift, zoom, and occlusion to predict the probability that one of them could be a perturbation of the other. We have performed experiments to gather the value of a 2 statistic applied to image matches from a variety of indoor locations. Image pairs gathered from nearby locations generate low 2 values, and images gathered from different locations generate high values. The rate of false positive and false negative matches is low. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew Blake and Andrew Zisserman. </author> <title> Visual Reconstruction. </title> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: During the search for the maximum likelihood, the maximizing values of and m are found by an iterative coordinate ascent procedure. This procedure alternately maximizes and m. For a given interpolated image and m, the correspondence domain which maximizes the log likelihood is easily found using the standard method <ref> [1] </ref>, namely, removing all pixels the Gaussian probability of whose gray levels are low. Having chosen , we pick m (the aperture factor) by estimating the mean illumination over the set .
Reference: [2] <author> Joachim Buhmann, Wolfram Burgard, Armin B. Cremers, Dieter Fox, Thomas Hofmann, Frank E. Schneider, Jiannis Strikos, and Sebastian Thrun. </author> <title> The mobile robot Rhino. </title> <journal> AI Magazine , 16(2) </journal> <pages> 31-38, </pages> <year> 1995. </year>
Reference-contexts: The major competing paradigm for map representation is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square <ref> [3, 2] </ref>. Data from stereo vision can be used in a similar way [12]. Matching panoramic views (as we describe below) to achieve place recognition has been pursued before. Hong et al. [7] describe a system for taking a one-dimensional panorama for use in robot localization.
Reference: [3] <author> Alberto Elfes. </author> <title> Using occupancy grids for mobile robot perception and navigation. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 46-58, </pages> <year> 1989. </year> <note> special issue on Autonomous Intelligent Machines, </note> <month> June. </month>
Reference-contexts: The major competing paradigm for map representation is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square <ref> [3, 2] </ref>. Data from stereo vision can be used in a similar way [12]. Matching panoramic views (as we describe below) to achieve place recognition has been pursued before. Hong et al. [7] describe a system for taking a one-dimensional panorama for use in robot localization.
Reference: [4] <author> Sean Engelson. </author> <title> Passive Map Learning and Visual Place Recognition. </title> <type> Technical Report 1032, </type> <institution> Yale Computer Science Department, </institution> <year> 1994. </year>
Reference-contexts: In [15], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9, 8] and especially <ref> [13, 15, 4, 5, 6] </ref>. The major competing paradigm for map representation is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square [3, 2].
Reference: [5] <author> Sean P. Engelson and Drew V. McDermott. </author> <title> Image signatures for place recognition and map construction. </title> <booktitle> In Proceedings of SPIE Symposium on Intelligent Robotic Systems, Sensor Fusion IV, </booktitle> <year> 1991. </year>
Reference-contexts: In [15], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9, 8] and especially <ref> [13, 15, 4, 5, 6] </ref>. The major competing paradigm for map representation is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square [3, 2].
Reference: [6] <author> Sean P. Engelson and Drew V. McDermott. </author> <title> Error correction in mobile robot map learning. </title> <booktitle> In Proc. IEEE Conf. on Robotics and Automation, </booktitle> <pages> pages 2555-2560, </pages> <year> 1992. </year>
Reference-contexts: As mentioned above, visual place recognition is only a part of the larger problem of map building. We intend to use this algorithm in the context of a map-learning algorithm that represents maps as networks of places with probabilistic transitions between them <ref> [10, 6, 14] </ref>. However, space constraints prevent us from discussing this higher-level algorithm in detail. Suffice it to say that we plan to use visual place recognition to verify that the robot is near a previously visited location, thus allowing it to correct accumulated odometric error since that previous visit. <p> In [15], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9, 8] and especially <ref> [13, 15, 4, 5, 6] </ref>. The major competing paradigm for map representation is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square [3, 2].
Reference: [7] <author> Jiawei Hong, Xianan Tan, Brian Pinette, Richard Weiss, and Edward M. Riseman. </author> <title> Image-based homing. </title> <booktitle> In Proc. IEEE Conf. on Robotics and Automation, </booktitle> <pages> pages 620-625, </pages> <year> 1991. </year>
Reference-contexts: Data from stereo vision can be used in a similar way [12]. Matching panoramic views (as we describe below) to achieve place recognition has been pursued before. Hong et al. <ref> [7] </ref> describe a system for taking a one-dimensional panorama for use in robot localization. It uses a spherical mirror to produce a 360-degree image of a location. One slice through this image remains at the same height as the robot moves around.
Reference: [8] <author> Ian Horswill. </author> <title> Specialization of Perceptual Processes. </title> <type> PhD thesis, </type> <year> 1993. </year>
Reference-contexts: This implies that the amount of change in gray levels at corresponding pixels is small. The exact nature of the relation is the third issue in image comparison. The simplest image-based algorithms use correlation to compare the two images <ref> [8] </ref>, which makes sense only if the correspondence is the identity function. More sophisticated approaches attempt to estimate the correspondence during image comparison. These approaches tend to be expensive, and usually require further simplifying assumptions. <p> In [15], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including <ref> [9, 8] </ref> and especially [13, 15, 4, 5, 6]. The major competing paradigm for map representation is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square [3, 2].
Reference: [9] <author> David Kortenkamp, L. Douglas Baker, and Terry Weymouth. </author> <title> Using gateways to build a route map. </title> <booktitle> In Proc. IEEE/RSJ Int'l. Workshop on Intelligent Robots and Systems, </booktitle> <year> 1992. </year>
Reference-contexts: In [15], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including <ref> [9, 8] </ref> and especially [13, 15, 4, 5, 6]. The major competing paradigm for map representation is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square [3, 2].
Reference: [10] <author> Benjamin Kuipers and Yung tai Byun. </author> <title> A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. </title> <booktitle> Robotics and Autonomous Systems , 8 </booktitle> <pages> 47-63, </pages> <year> 1991. </year>
Reference-contexts: As mentioned above, visual place recognition is only a part of the larger problem of map building. We intend to use this algorithm in the context of a map-learning algorithm that represents maps as networks of places with probabilistic transitions between them <ref> [10, 6, 14] </ref>. However, space constraints prevent us from discussing this higher-level algorithm in detail. Suffice it to say that we plan to use visual place recognition to verify that the robot is near a previously visited location, thus allowing it to correct accumulated odometric error since that previous visit. <p> The class of geometries is specified as non-informatively as possible (analogous to models for white noise). Finally, we pose the recognition problem in the framework of statistical decision theory. 2 Related Work The basic idea of treating maps as networks of places is from <ref> [10] </ref>. It has recently been refined by treating the networks as Markov decision processes with probabilistic transitions [14]. In [15], nodes are obstacle boundaries from which landmarks are visible.
Reference: [11] <author> Don Murray and Cullen Jennings. </author> <title> Stereo vision based mapping and navigation for mobile robots. </title> <booktitle> In Proc. IEE Int'l Conf. on Robotics and Automation, </booktitle> <pages> pages 1694-1699, </pages> <year> 1997. </year>
Reference: [12] <author> Randall Nelson. </author> <title> Visual Navigation. </title> <type> PhD thesis, </type> <year> 1989. </year>
Reference-contexts: Data from stereo vision can be used in a similar way <ref> [12] </ref>. Matching panoramic views (as we describe below) to achieve place recognition has been pursued before. Hong et al. [7] describe a system for taking a one-dimensional panorama for use in robot localization. It uses a spherical mirror to produce a 360-degree image of a location.
Reference: [13] <author> Reid Simmons and Sven Koenig. </author> <title> Probabilistic navigation in partially observable environments. </title> <booktitle> In Proc. Ijcai, </booktitle> <year> 1995. </year>
Reference-contexts: In [15], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9, 8] and especially <ref> [13, 15, 4, 5, 6] </ref>. The major competing paradigm for map representation is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square [3, 2].
Reference: [14] <author> Camillo J. Taylor and David J. Kriegman. </author> <title> Exploration strategies for mobile robots. </title> <booktitle> In Proc. IEEE Int'l. Conf. on Robots and Automation, </booktitle> <year> 1993. </year>
Reference-contexts: As mentioned above, visual place recognition is only a part of the larger problem of map building. We intend to use this algorithm in the context of a map-learning algorithm that represents maps as networks of places with probabilistic transitions between them <ref> [10, 6, 14] </ref>. However, space constraints prevent us from discussing this higher-level algorithm in detail. Suffice it to say that we plan to use visual place recognition to verify that the robot is near a previously visited location, thus allowing it to correct accumulated odometric error since that previous visit. <p> Finally, we pose the recognition problem in the framework of statistical decision theory. 2 Related Work The basic idea of treating maps as networks of places is from [10]. It has recently been refined by treating the networks as Markov decision processes with probabilistic transitions <ref> [14] </ref>. In [15], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9, 8] and especially [13, 15, 4, 5, 6].
Reference: [15] <author> Jian YuZheng, Matthew Barth, and Saburo Tsuji. </author> <title> Autonomous landmark selection for route recognition by a mobile robot. </title> <booktitle> In Proc. IEEE Conf. on Robotics and Automation, </booktitle> <pages> pages 2004-2009, </pages> <year> 1991. </year>
Reference-contexts: Finally, we pose the recognition problem in the framework of statistical decision theory. 2 Related Work The basic idea of treating maps as networks of places is from [10]. It has recently been refined by treating the networks as Markov decision processes with probabilistic transitions [14]. In <ref> [15] </ref>, nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9, 8] and especially [13, 15, 4, 5, 6]. <p> In [15], nodes are obstacle boundaries from which landmarks are visible. Most workers in this area have used sonar as their main sensor for place recognition Others have used data from cameras, including [9, 8] and especially <ref> [13, 15, 4, 5, 6] </ref>. The major competing paradigm for map representation is the use of certainty grids, in which space is resolved into a grid of squares, and sonar data are used to assign a probability of occupancy to each square [3, 2].
References-found: 15

