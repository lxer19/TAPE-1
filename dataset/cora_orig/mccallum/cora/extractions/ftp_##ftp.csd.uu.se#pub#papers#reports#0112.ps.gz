URL: ftp://ftp.csd.uu.se/pub/papers/reports/0112.ps.gz
Refering-URL: http://www.csd.uu.se/papers/reports.html
Root-URL: 
Email: e-mail: thomasl@csd.uu.se  
Phone: Phone: +481818 25 00 Fax: +461851 19 25  
Title: Control flow analysis of Prolog (extended remix) how to translate a Prolog program into a
Author: Thomas Lindgren 
Address: Box 311, S-751 05 Uppsala, Sweden  
Affiliation: Computing Science Dept., Uppsala University  
Date: August, 1995 ISSN 1100-0686  
Note: 22  The paper describes  this information, a CFG can be constructed straightforwardly, which is described. Finally, the  is more complex, though there are typically 10 or  
Abstract: UPMAIL Technical Report No. 112 Abstract In order to represent control information compactly, the paper proposes a method to structure the solution of the analysis to share information. Compressing the control information reduces the size of the control information at least by half for 18 out of 26 benchmarks, and for some programs by an order of magnitude or more. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aho, R. Sethi, J. Ullman, </author> <booktitle> Compilers: Principles, Techniques, Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference: [2] <author> T. Chen, I.V. Ramakrishnan, R. Ramesh, </author> <title> Multistage indexing algorithms, </title> <booktitle> in Proc. Joint Intl. Conf. & Symp. Logic Programming'92, </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: We close with noting that the choice of indexing algorithm influenced these numbers heavily at times. More sophisticated indexing algorithms, e.g., Refs. <ref> [2, 17] </ref>, could be used to further improve the precision of the control flow analysis. Future work.
Reference: [3] <author> K. De Boesschere, S. Debray, D. Gudeman, S. Kannan, </author> <title> Call forwarding: a simple interprocedural optimization technique for dynamically typed languages, </title> <booktitle> in ACM Symposium on Principles of Programming Languages 1994. </booktitle>
Reference-contexts: Compilers for Prolog and related languages have so far mostly taken a predicate-level view of compilation, even if global analysis has been used to improve the compilation of each predicate, and concentrated their efforts on reducing the cost of primitive operations. (Exceptions include call forwarding <ref> [3] </ref>.) Perhaps unsurprisingly, the greatest improvements have been in smaller programs, where primitive operations are relatively common and the compiler has some scope to improve sequences of primitives.
Reference: [4] <author> S.K.Debray, </author> <title> A simple code improvement scheme for Prolog, </title> <editor> in J. </editor> <booktitle> Logic Programming, </booktitle> <address> 1992:13:57-88. </address>
Reference-contexts: This defect can be remedied. Finally, we note that changing the indexing algorithm turned out to reduce control flow information substantially, by (a) improving indexing and (b) reducing the number of new predicates generated to avoid code duplication. 7 Related work Debray <ref> [4] </ref> and Sehr [11, 12] use control flow graphs to optimize sequential programs and extract parallelism, respectively. However, both authors considered only intraprocedural control flow. In our formulation, procedure calls disappear in an interprocedural sea of assignments, continuation creation and primitive operations.
Reference: [5] <author> S.K. Debray, </author> <type> personal communication, </type> <month> June </month> <year> 1995. </year>
Reference-contexts: However, both authors considered only intraprocedural control flow. In our formulation, procedure calls disappear in an interprocedural sea of assignments, continuation creation and primitive operations. Debray et al have recently implemented a control flow analysis based on context free grammars <ref> [5] </ref> in the jc system. The net result is equivalent to the success control flow analysis described in this paper, though their analysis also handles concurrency. Shivers [13] proposed control flow analysis for the purpose of recovering the control flow graph of higher-order functional programs.
Reference: [6] <author> M.A. Friedman, </author> <title> A characterization of Prolog execution, </title> <type> Ph.D. Thesis, </type> <institution> University of Wisconsin at Madison, </institution> <year> 1992. </year> <month> 21 </month>
Reference-contexts: 1 Introduction Prolog programs spend much of their time in control management <ref> [15, 16, 6] </ref>. Since procedure calls are very common, much effort is spent in saving and restoring parameters from the stack; furthermore, a procedure call typically requires some shu*ing of parameters, as well as building new arguments.
Reference: [7] <author> A. Krall, T. Berger, </author> <title> Incremental global compilation of Prolog with the Vienna Abstract Machine, </title> <booktitle> in Proc. Intl. Conf. Logic Programming 1995, </booktitle> <publisher> MIT Press 1995. </publisher>
Reference-contexts: If we permit such code to call static code, it is easiest interfaced by using call/1 as defined above. Otherwise, we could include interpreted versions of the static code. A more promising approach is to dynamically analyze and compile dynamic code <ref> [7] </ref>. If such facilities are available, they can probably use (suitably modified versions of) the methods developed in this paper. Exceptions. Control flow analysis of exceptions is not considered in detail in this paper.
Reference: [8] <author> T. Lindgren, </author> <title> A continuation-passing style for Prolog, </title> <booktitle> in Proc. Intl. Logic Programming Symposium 1994, </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: discusses future work. 2 2 Preliminaries We assume that all predicates are in single-clausal form, i.e., each predicate consist of a single clause where the head is a linear sequence of variables, and the clause body consists of disjunction, conjunction, if-then-else, cut and calls to primitive operations and user-defined predicates <ref> [8] </ref>. We furthermore assume that predicates have been converted into first-order programs (call/1 is assumed not to be present, or transformed away) and do not use dynamic scheduling, calls to dynamic code or similar operations. <p> At each procedure call, we compute the live and defined variables (i.e., the set of variables that occur in the predicate both prior to and after the call) as in Ref <ref> [8] </ref>. A continuation frame, or simply frame, L [Xs] consists of a label L and a set of variables Xs = fX 1 ; : : : ; X n g to be restored when the continuation is 6 invoked.
Reference: [9] <author> T. Lindgren, </author> <title> Control flow analysis of Prolog (extended remix), </title> <type> technical report, </type> <institution> Uppsala University, </institution> <year> 1995. </year>
Reference: [10] <author> M. Meier, </author> <title> Recursion vs. iteration in Prolog, </title> <booktitle> in Proc. Eighth Intl. Conf. on Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Future work. Future work involves extending the analysis to handle exceptions and dynamic scheduling, improving the precision of the CFA, developing optimizations based on the ideas developed in this paper <ref> [10] </ref>, and using the CFG for native code compilation. We expect previously developed techniques [17, 14] to be useful in the latter regard. Acknowledgements. I would like to thank Per Mildner and H-akan Mill-roth for valuable discussions and their comments on this paper, and Saumya Debray for valuable comments.
Reference: [11] <author> D.C. Sehr, L.V. Kale, D.A. Padua, </author> <title> Loop transformations for Prolog programs, </title> <publisher> LNCS 768. </publisher>
Reference-contexts: This defect can be remedied. Finally, we note that changing the indexing algorithm turned out to reduce control flow information substantially, by (a) improving indexing and (b) reducing the number of new predicates generated to avoid code duplication. 7 Related work Debray [4] and Sehr <ref> [11, 12] </ref> use control flow graphs to optimize sequential programs and extract parallelism, respectively. However, both authors considered only intraprocedural control flow. In our formulation, procedure calls disappear in an interprocedural sea of assignments, continuation creation and primitive operations.
Reference: [12] <author> D.C. Sehr, </author> <title> Automatic Parallelization of Prolog Programs, </title> <type> Ph.D. Thesis, </type> <institution> Univ. of Illinois at Urbana Champaign, </institution> <year> 1992. </year>
Reference-contexts: This defect can be remedied. Finally, we note that changing the indexing algorithm turned out to reduce control flow information substantially, by (a) improving indexing and (b) reducing the number of new predicates generated to avoid code duplication. 7 Related work Debray [4] and Sehr <ref> [11, 12] </ref> use control flow graphs to optimize sequential programs and extract parallelism, respectively. However, both authors considered only intraprocedural control flow. In our formulation, procedure calls disappear in an interprocedural sea of assignments, continuation creation and primitive operations.
Reference: [13] <author> O. Shivers, </author> <title> Control flow analysis in Scheme, </title> <booktitle> in ACM SIGPLAN'88 Conf. on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Debray et al have recently implemented a control flow analysis based on context free grammars [5] in the jc system. The net result is equivalent to the success control flow analysis described in this paper, though their analysis also handles concurrency. Shivers <ref> [13] </ref> proposed control flow analysis for the purpose of recovering the control flow graph of higher-order functional programs. We have studied control flow analysis for a language with less general and somewhat different control structures.
Reference: [14] <author> A. Taylor, </author> <title> High Performance Prolog Implementation, </title> <type> Ph.D. Thesis, </type> <institution> Basser Dept. of Computer Science, Sydney University, </institution> <year> 1991. </year>
Reference-contexts: In essence, we add a specialized meta-interpreter per module that uses call/1. This has the advantage that modules that do not require call/1 are not affected. Taylor <ref> [14] </ref> proposes that predicates that can be invoked by call/1 be marked as `callable'. In that case, the latter part of the case expression can be pruned. Dynamic calls. Prolog implementations often require dynamically modified predicates to be declared as such. <p> Future work. Future work involves extending the analysis to handle exceptions and dynamic scheduling, improving the precision of the CFA, developing optimizations based on the ideas developed in this paper [10], and using the CFG for native code compilation. We expect previously developed techniques <ref> [17, 14] </ref> to be useful in the latter regard. Acknowledgements. I would like to thank Per Mildner and H-akan Mill-roth for valuable discussions and their comments on this paper, and Saumya Debray for valuable comments.
Reference: [15] <author> E. Tick, </author> <title> Memory- and buffer-referencing characteristics of a WAM-based Prolog, </title> <journal> J. Logic Programming, </journal> <volume> Vol. 11, </volume> <pages> pp. 133-162, </pages> <year> 1991 </year>
Reference-contexts: 1 Introduction Prolog programs spend much of their time in control management <ref> [15, 16, 6] </ref>. Since procedure calls are very common, much effort is spent in saving and restoring parameters from the stack; furthermore, a procedure call typically requires some shu*ing of parameters, as well as building new arguments.
Reference: [16] <author> H. Touati, A. Despain, </author> <title> An empirical study of the Warren Abstract Machine, </title> <booktitle> in IEEE Symp. Logic Programming 1987, </booktitle> <publisher> IEEE Press, </publisher> <year> 1987. </year>
Reference-contexts: 1 Introduction Prolog programs spend much of their time in control management <ref> [15, 16, 6] </ref>. Since procedure calls are very common, much effort is spent in saving and restoring parameters from the stack; furthermore, a procedure call typically requires some shu*ing of parameters, as well as building new arguments.
Reference: [17] <author> P.L. Van Roy, </author> <title> Can Logic Programming Execute as Fast as Imperative Programming?, </title> <type> Ph.D. Thesis, Report UCB/CSD-90-600, </type> <institution> UC Berkeley, </institution> <year> 1990. </year>
Reference-contexts: We close with noting that the choice of indexing algorithm influenced these numbers heavily at times. More sophisticated indexing algorithms, e.g., Refs. <ref> [2, 17] </ref>, could be used to further improve the precision of the control flow analysis. Future work. <p> Future work. Future work involves extending the analysis to handle exceptions and dynamic scheduling, improving the precision of the CFA, developing optimizations based on the ideas developed in this paper [10], and using the CFG for native code compilation. We expect previously developed techniques <ref> [17, 14] </ref> to be useful in the latter regard. Acknowledgements. I would like to thank Per Mildner and H-akan Mill-roth for valuable discussions and their comments on this paper, and Saumya Debray for valuable comments.
Reference: [18] <author> D.H.D. Warren, </author> <title> An abstract Prolog instruction set, </title> <type> Report 309, </type> <institution> SRI International, </institution> <address> Menlo Park, California, USA, </address> <year> 1983. </year>
Reference-contexts: However, procedure calls have mainly been handled as in the WAM <ref> [18] </ref> (an exception is the stack-based WAM of Zhou [19]), using a fixed procedure calling convention and a pessimistic caller-saves assumption on what variables must be saved at a procedure call. <p> Clause indexing is expressed by explicit type-tests and if-then-else operations, rather than by `black box' instructions in the abstract machine. Indexing. We can model the first-argument indexing of WAM <ref> [18] </ref> by simple type tests as follows. WAM indexing occurs in three stages. 1. First, the type is tested. This is modelled by a sequence of if-then-else type tests. 2. Second, the functor or value of a term is tested. This is modelled by an appropriate test. 3.
Reference: [19] <author> N.-F. Zhou, </author> <title> On the scheme for passing arguments in stack frames for Prolog, </title> <booktitle> in Proc. Eleventh Intl. Conf. on Logic Programming, </booktitle> <publisher> MIT Press 1994. </publisher> <pages> 22 </pages>
Reference-contexts: However, procedure calls have mainly been handled as in the WAM [18] (an exception is the stack-based WAM of Zhou <ref> [19] </ref>), using a fixed procedure calling convention and a pessimistic caller-saves assumption on what variables must be saved at a procedure call. In this paper, we show how to take a whole-program view of compilation by converting an entire Prolog program into a control flow graph.
References-found: 19

