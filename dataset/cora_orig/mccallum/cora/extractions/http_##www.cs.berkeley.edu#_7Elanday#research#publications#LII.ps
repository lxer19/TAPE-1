URL: http://www.cs.berkeley.edu/%7Elanday/research/publications/LII.ps
Refering-URL: http://www.cs.berkeley.edu/%7Elanday/research/publications/publications.html
Root-URL: http://www.cs.berkeley.edu
Email: pier@parc.xerox.com  landay@cs.cmu.edu  
Title: Issues for Location-Independent Interfaces  
Author: Ken Pier and James A. Landay 
Address: 3333 Coyote Hill Rd., Palo Alto, CA 94304,  4825 Frew St., Pittsburgh, PA 15213,  
Affiliation: Xerox PARC,  Currently: Box 200, Carnegie Mellon University,  
Abstract-found: 0
Intro-found: 1
Reference: [Adobe] <institution> Adobe Systems Inc. </institution> <note> Adobe Illustrator (TM) User's Manual Version 1.0, </note> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: Collaborative design can be facilitated by large display surfaces visible to everyone in a room and available for interaction by one or more designers. However, typical CAD-like user interfaces <ref> [AutoCAD, Adobe, Pier] </ref> are festooned with buttons, pop-up menus, scroll bars, and other static user interface elements around the top and side of the display surface.
Reference: [Alto] <editor> Thacker, C.P., et al. </editor> <title> Alto: a Personal Computer, in Computer Structures: Principles and Examples, </title> <editor> eds. D. P. Siewiorek, C.G. Bell and A. Newell. </editor> <publisher> Mcgraw-Hill, </publisher> <year> 1982. </year>
Reference-contexts: Markup at Xerox PARC In 1976, in the Markup [Newman] graphical editing program on the Xerox Alto <ref> [Alto] </ref>, a mouse button was reserved to pop up a single large icon-based menu, part of which is shown in Figure 1, centered around the display cursor. The user could then invoke an operation from that menu by releasing the mouse button over the desired function icon.
Reference: [AutoCAD] <author> Lubow, M. </author> <title> Working out with AutoCAD. </title> <publisher> New Riders Publishing, </publisher> <address> P.O. Box 4846, Thousand Oaks, CA 91360 U.S.A., </address> <year> 1987. </year> <title> [Borenstein]: Borenstein, N. Multimedia electronic mail: </title> <booktitle> will the dream become a reality? In Communications of the ACM 34, </booktitle> <volume> 4. </volume> <month> (April, </month> <year> 1991), </year> <pages> pp. 117-119. </pages>
Reference-contexts: Collaborative design can be facilitated by large display surfaces visible to everyone in a room and available for interaction by one or more designers. However, typical CAD-like user interfaces <ref> [AutoCAD, Adobe, Pier] </ref> are festooned with buttons, pop-up menus, scroll bars, and other static user interface elements around the top and side of the display surface.
Reference: [Buxton] <author> Buxton, W. and Myers, B. </author> <title> A Study in Two-Handed Input. </title> <booktitle> In Proceedings of the CHI'86 Conference on Human Factors in Computing Systems. </booktitle> <address> (Boston, MA. </address> <month> Apr. </month> <pages> 13-17, </pages> <address> 1986). </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1986, </year> <pages> pp. 321-326. </pages>
Reference-contexts: Auxiliary devices for mode invocation Finally, we note that when using stylus input on a device that is freestanding or fully supported, the weak hand is free and could be put to good use. Buxton <ref> [Buxton] </ref> has long advocated the use of two-handed interfaces. Mouse, keyboard, and trackball are an example of a multi-handed input suite that works on conventional workstations. In the case of the Liveboard, we can use ParcTab buttons (viz.
Reference: [Callahan] <author> Callahan, J., Hopkins, D., Weiser, M., and Shneiderman, B. </author> <title> An Empirical Comparison of Pie vs. Linear Menus. </title> <booktitle> In Proceedings of the CHI'88 Conference on Human Factors in Computing Systems. </booktitle> <address> (Washington, DC. </address> <month> May. </month> <pages> 15-19, </pages> <address> 1988). </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1988, </year> <pages> pp. 95-100. </pages> <month> [DevGuide]: </month> <title> Open Windows Developers Guide 1.1, User's Manual. Sun Microsystems, </title> <publisher> Inc. </publisher> <year> 1990. </year>
Reference-contexts: Use of voice requires only that the input generated by the vocal tract be received by a microphone, recognized in real time, and that recognition results be quickly transmitted to the computing device at hand. Examples of location-independent interface elements for the stylus include pie menus <ref> [Callahan] </ref>, hierarchical pie menus [Hopkins], pop-up menus, pop-up property sheets [Johnson], pop-up handwriting recognition pads [GO], and gesture-based interfaces [Kurtenbach, GO, Rubine]. Vocal user interface elements have been demonstrated by Schmandt [Schmandt], Bush and Wilcox [Wilcox], and are available in commercial speech-based user interface builders [SimonSays]. 2 Photo 2. <p> The user could then invoke an operation from that menu by releasing the mouse button over the desired function icon. The menu subsequently disappeared. Pie menus at the University of Maryland In 1986, Don Hopkins <ref> [Callahan] </ref> produced a pie menu interface element for the X10 window system. Implementations for Sunview and NeWS window systems were produced in subsequent years. Figure 2 illustrates a pie-menu.
Reference: [Elrod] <editor> Elrod, S., et. al. Liveboard. </editor> <booktitle> In Proceedings of the CHI'92 Conference on Human Factors in Computing Systems. </booktitle> <address> (Monterey, CA. </address> <month> May. </month> <pages> 3-7, </pages> <address> 1992). </address> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1992, </year> <pages> pp. 599-607. </pages>
Reference-contexts: Within some size range of these devices, and for some tasks, traditional "widget" style interfaces may suffice. However, for devices at the extremes of the size range, such as the Xerox ParcTab in Photo 1 and the Xerox Liveboard <ref> [Elrod] </ref> in Photo 2, widget style interfaces break down. The elements of interfaces required for outsize devices are different than interface elements in use today. <p> In fact, the Xerox Liveboard <ref> [Elrod] </ref> stylus has three rather awkward buttons on the stylus itself, intended to emulate the three-button mouse attached to conventional workstations. Although providing this mouse mimicry allows existing software to run unchanged, it is a poor substitute for a true stylus-based interface and in fact hinders development of new interfaces. <p> Note: the Xerox Liveboard stylus actually has three buttons, but one of them duplicates the function of the tip switch, so that only three independent buttons are available. Stylus buttons have empirically been observed to be awkward to use <ref> [Elrod] </ref>. In particular, a stylus has very little surface area near the fingertips not covered by the user's grip, so buttons tend to be placed close together on the "top" or "side" of the stylus case.
Reference: [Garnet] <author> Myers, Brad A., et al. Garnet: </author> <title> Comprehensive Support for Graphical, Highly-Interactive User Interfaces. </title> <journal> In IEEE Computer, </journal> <volume> Vol. 23, No. 11, </volume> <month> (Nov </month> <year> 1990), </year> <pages> pp. 71-85. </pages>
Reference-contexts: The Politic (Pen Oriented Location-Independent Tools & Interface Components) toolkit is a collection of interface elements written in Common Lisp and added to the Garnet User Interface Development Environment within the X11 Window System <ref> [Garnet, XWindow] </ref>. The interface elements implemented, pie menus and gesture recognizers, are not generally available in user interface toolkits for X11. Garnet was chosen because it is designed specifically with our kind of task in mind: the exploration of advanced and novel user interface techniques.
Reference: [GO] <author> Carr, R. and Shafer, D. </author> <title> The Power of PenPoint. </title> <publisher> Addison 8 Wesley, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: The elements of interfaces required for outsize devices are different than interface elements in use today. Existing stylus-based interfaces <ref> [GO, Momenta, PenWindows] </ref> have made some strides in addressing the needs of users in a stylus-centric interface, but they have an unstated underlying assumption; that is, that they are in use on traditional size display and interaction surfaces, whose diagonal dimension approximates the human forearm in length. <p> For example, if we display a Macintosh screen on an existing Liveboard, its pull-down menus will be above the reach of many, and above the reach of all on a 2X Liveboard. If we run the GO Corp. stylus-based Notebook User Interface <ref> [GO] </ref> on a 2X Liveboard, the screen image will scale up, thanks to ImagePoint resolution-independent imaging, but the BookShelf where icons are displayed will be below our knees, and the pull-down menu bar above our reach. <p> Examples of location-independent interface elements for the stylus include pie menus [Callahan], hierarchical pie menus [Hopkins], pop-up menus, pop-up property sheets [Johnson], pop-up handwriting recognition pads <ref> [GO] </ref>, and gesture-based interfaces [Kurtenbach, GO, Rubine]. Vocal user interface elements have been demonstrated by Schmandt [Schmandt], Bush and Wilcox [Wilcox], and are available in commercial speech-based user interface builders [SimonSays]. 2 Photo 2. <p> Examples of location-independent interface elements for the stylus include pie menus [Callahan], hierarchical pie menus [Hopkins], pop-up menus, pop-up property sheets [Johnson], pop-up handwriting recognition pads [GO], and gesture-based interfaces <ref> [Kurtenbach, GO, Rubine] </ref>. Vocal user interface elements have been demonstrated by Schmandt [Schmandt], Bush and Wilcox [Wilcox], and are available in commercial speech-based user interface builders [SimonSays]. 2 Photo 2. <p> In the linear menu, the choice may be all the way at the end of the list and, if the list is even moderately long, choosing the last entry can become tedious. Modern stylus-based user interfaces and location independence GO The stylus-based Notebook User Interface by the GO Corp. <ref> [GO] </ref> is nearly entirely gesture based. There are about a dozen basic gestures for navigating through and displaying documents (i.e. applications), and many more gestures 3 available for document-specific editing of such elements as graphics, text, and handprinting with recognition. <p> When display sizes range from palmtop to palm tree, this cavalier approach simply will not work. Location-independent interfaces must be flexible and able to respond to the variety of work surfaces available. Ease of discovery and use Emphasis on paper-like interfaces <ref> [Rhyne, GO] </ref> for individual use and on "walk up and use" interfaces for collaboration (in the Xerox Liveboard community) raise fundamental questions concerning ease of discovery and use.
Reference: [Goldberg] <author> Goldberg, D. </author> <title> Touch Typing With a Stylus. </title> <note> Submitted for Publication to INTERCHI'93. </note>
Reference-contexts: Other arrangements of characters on pop-up keyboards would be possible, and users could tailor such arrangements to their individual preferences. David Goldberg, at Xerox PARC, has devised a clever alphabet called Unistrokes for what he calls "touch typing with a stylus" <ref> [Goldberg] </ref>. He eliminates the need for hard or soft keyboards, substituting what he claims is an easy-to-learn shorthand alphabet using simple, single stroke characters.
Reference: [Hopkins] <author> Don Hopkins. </author> <title> The design and implementation of pie menus. </title> <journal> Dr. Dobb's Journal. </journal> <volume> Vol. 16, No. 12, </volume> <month> (Dec </month> <year> 1991), </year> <pages> pp. 16-26. </pages>
Reference-contexts: Examples of location-independent interface elements for the stylus include pie menus [Callahan], hierarchical pie menus <ref> [Hopkins] </ref>, pop-up menus, pop-up property sheets [Johnson], pop-up handwriting recognition pads [GO], and gesture-based interfaces [Kurtenbach, GO, Rubine]. Vocal user interface elements have been demonstrated by Schmandt [Schmandt], Bush and Wilcox [Wilcox], and are available in commercial speech-based user interface builders [SimonSays]. 2 Photo 2. <p> Another difficulty is the interpretation of the meaning of "held still." Is a motion of a single pixel really meant as a motion? What about two pixels? Three? A millimeter? Lack of a rock-steady hand should not bar the user from interacting. Hopkins <ref> [Hopkins] </ref> and Kurtenbach [Kurtenbach] report the use of temporal modes as accelerators for pie menus.
Reference: [Johnson] <author> Jeff Johnson, Teresa L. Roberts, et. al. </author> <title> The Xerox Star: A Retrospective. </title> <journal> In IEEE Computer, </journal> <volume> Vol. 22, No. 9, </volume> <month> (Sep </month> <year> 1989), </year> <pages> pp. 11-29. </pages>
Reference-contexts: Examples of location-independent interface elements for the stylus include pie menus [Callahan], hierarchical pie menus [Hopkins], pop-up menus, pop-up property sheets <ref> [Johnson] </ref>, pop-up handwriting recognition pads [GO], and gesture-based interfaces [Kurtenbach, GO, Rubine]. Vocal user interface elements have been demonstrated by Schmandt [Schmandt], Bush and Wilcox [Wilcox], and are available in commercial speech-based user interface builders [SimonSays]. 2 Photo 2.
Reference: [Kurtenbach] <author> Kurtenbach, G., and Buxton, W. </author> <title> Issues in Combining Marking and Direct Manipulation Techniques. </title> <booktitle> In Proceedings of UIST'91, the Fourth Annual Symposium on User Interface Software and Technology (Hilton Head, </booktitle> <address> SC. </address> <month> Nov. </month> <pages> 11-13). </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1991, </year> <pages> pp. 137-144. </pages>
Reference-contexts: Examples of location-independent interface elements for the stylus include pie menus [Callahan], hierarchical pie menus [Hopkins], pop-up menus, pop-up property sheets [Johnson], pop-up handwriting recognition pads [GO], and gesture-based interfaces <ref> [Kurtenbach, GO, Rubine] </ref>. Vocal user interface elements have been demonstrated by Schmandt [Schmandt], Bush and Wilcox [Wilcox], and are available in commercial speech-based user interface builders [SimonSays]. 2 Photo 2. <p> It is therefore impossible to draw over a button or to have a button in the midst of the drawing surface. This is the manner in which conventional drawing programs are organized. Interference does not occur in programs such as GEdit <ref> [Kurtenbach] </ref>, which uses a combination of gestures and pie menus for interaction, because the stylus input is always aimed at the interface and does not interfere with the synthetic graphical objects that GEdit creates and modifies. In freehand drawing or markup applications, interference occurs. <p> Another difficulty is the interpretation of the meaning of "held still." Is a motion of a single pixel really meant as a motion? What about two pixels? Three? A millimeter? Lack of a rock-steady hand should not bar the user from interacting. Hopkins [Hopkins] and Kurtenbach <ref> [Kurtenbach] </ref> report the use of temporal modes as accelerators for pie menus.
Reference: [Linton] <author> Linton, M.A., Vlissides, J.M., and Calder, P.R. </author> <title> Composing user interfaces with InterViews. </title> <journal> In IEEE Computer, </journal> <volume> Vol. 22, No. 2, </volume> <month> (Feb </month> <year> 1989), </year> <pages> pp. 8-22. </pages>
Reference-contexts: Unistrokes, like touch typing, can be very fast, once learned, and also allows eyes-free "heads up" writing, since all of the strokes can be written on top of each other; recognized characters appear immediately in text being created or edited. Toolkits and user interface builders Existing toolkits <ref> [XView, Linton] </ref> and user interface builders [DevGuide] do not readily extend to the location-independent paradigm. They are targeted at arranging a set of interactors that are constantly visible in fixed places on a display.
Reference: [Momenta] <institution> Momenta Corp. </institution> <note> Momenta User's Manual Version 1.0, </note> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: The elements of interfaces required for outsize devices are different than interface elements in use today. Existing stylus-based interfaces <ref> [GO, Momenta, PenWindows] </ref> have made some strides in addressing the needs of users in a stylus-centric interface, but they have an unstated underlying assumption; that is, that they are in use on traditional size display and interaction surfaces, whose diagonal dimension approximates the human forearm in length. <p> Microsoft makes no claims for scalability of Windows to larger or smaller display surfaces. Momenta (R.I.P. 1988-1992) In the stylus-based interface for the notebook computer by the Momenta Corp. <ref> [Momenta] </ref>, a pie menu called the Command Compass is the main interactor for Momenta applications. There is partial location independence in this interface since selecting an object, like a graphic or text, causes an icon for the application-specific command compass to appear on or near the selected object.
Reference: [Myers] <author> Myers, Brad A. </author> <title> A New Model for Handling Input. </title> <journal> In ACM Transactions on Information Systems, </journal> <volume> Vol. 8, No. 3, </volume> <month> (Jul </month> <year> 1990), </year> <pages> pp. 289-320. </pages>
Reference-contexts: The interface elements implemented, pie menus and gesture recognizers, are not generally available in user interface toolkits for X11. Garnet was chosen because it is designed specifically with our kind of task in mind: the exploration of advanced and novel user interface techniques. In addition, the Garnet interactor abstraction <ref> [Myers] </ref>, which separates interaction mechanisms from graphics presentation, is ideal for creating an implementation of pie menus. Our pie menus use much of the same interaction code as do other Garnet menus (e.g. pull-down menu bars).
Reference: [Newman] <author> Newman, W. </author> <title> Markup. In the Alto User's Handbook, </title> <institution> Xerox Palo Alto Research Center, </institution> <address> 3333 Coyote Hill Rd., Palo Alto, CA 94304, </address> <year> 1979. </year>
Reference-contexts: Related work Early location-independent user interfaces Movable Menu Location-independent interfaces date back to 1969, when Wiseman [Wiseman] first proposed the idea of a "movable menu" displayed close to the cursor and appearing only when the user needs it. Markup at Xerox PARC In 1976, in the Markup <ref> [Newman] </ref> graphical editing program on the Xerox Alto [Alto], a mouse button was reserved to pop up a single large icon-based menu, part of which is shown in Figure 1, centered around the display cursor.
Reference: [PenWindows] <institution> Microsoft Windows For Pen Computing: </institution> <note> Guide to Pen Computing. </note> <institution> NCR Corp. </institution> <year> 1992. </year>
Reference-contexts: The elements of interfaces required for outsize devices are different than interface elements in use today. Existing stylus-based interfaces <ref> [GO, Momenta, PenWindows] </ref> have made some strides in addressing the needs of users in a stylus-centric interface, but they have an unstated underlying assumption; that is, that they are in use on traditional size display and interaction surfaces, whose diagonal dimension approximates the human forearm in length.
Reference: [Pier] <author> Pier, K.A., Bier, E.A., and Stone, </author> <title> M.C. An Introduction to Gargoyle: an Interactive Illustration Tool. </title> <booktitle> In Proceedings of EP88, the International Conference on Electronic Publishing, Document Manipulation and Typography (Nice, </booktitle> <address> France. </address> <month> Apr. </month> <pages> 20-22). </pages> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1988, </year> <pages> pp. 223-238. </pages> <note> Also available in Xerox PARC Technical Report EDL-89-1, </note> <year> 1989. </year>
Reference-contexts: Collaborative design can be facilitated by large display surfaces visible to everyone in a room and available for interaction by one or more designers. However, typical CAD-like user interfaces <ref> [AutoCAD, Adobe, Pier] </ref> are festooned with buttons, pop-up menus, scroll bars, and other static user interface elements around the top and side of the display surface. <p> The pie menu will pop up if a sufficiently long period elapses without stylus motion. A similar form of temporal accelerator appears in the Cedar system pop-up buttons <ref> [Pier] </ref>, in which a static button can be quickly clicked on using a combination of mouse buttons and keyboard modifiers to invoke an operation, instead of pressing down and waiting for the pop-up button to appear with menu choices and documentation.
Reference: [Rhyne] <author> Rhyne, J.R., and Wolf, </author> <title> C.G. Paperlike User Interfaces. </title> <institution> IBM T. J. Watson Research Center, </institution> <address> Yorktown Heights, New York, </address> <year> 1991. </year>
Reference-contexts: When display sizes range from palmtop to palm tree, this cavalier approach simply will not work. Location-independent interfaces must be flexible and able to respond to the variety of work surfaces available. Ease of discovery and use Emphasis on paper-like interfaces <ref> [Rhyne, GO] </ref> for individual use and on "walk up and use" interfaces for collaboration (in the Xerox Liveboard community) raise fundamental questions concerning ease of discovery and use.
Reference: [Rubine] <author> Rubine, D. </author> <title> Integrating Gesture Recognition and Direct Manipulation. </title> <booktitle> In Proceedings of the Summer '91 USENIX Technical Conference. </booktitle> <month> (June, </month> <year> 1991). </year> <institution> USENIX Association, </institution> <year> 1991, </year> <pages> pp. 95-100. </pages>
Reference-contexts: Examples of location-independent interface elements for the stylus include pie menus [Callahan], hierarchical pie menus [Hopkins], pop-up menus, pop-up property sheets [Johnson], pop-up handwriting recognition pads [GO], and gesture-based interfaces <ref> [Kurtenbach, GO, Rubine] </ref>. Vocal user interface elements have been demonstrated by Schmandt [Schmandt], Bush and Wilcox [Wilcox], and are available in commercial speech-based user interface builders [SimonSays]. 2 Photo 2.
Reference: [Schmandt] <author> Schmandt, C., et al. </author> <title> Observations on Using Speech Input for Window Navigation. </title> <booktitle> In Proceedings of IFIP INTERACT'90: Human-Computer Interaction, </booktitle> <year> 1990, </year> <pages> pp. 787-793. </pages>
Reference-contexts: Examples of location-independent interface elements for the stylus include pie menus [Callahan], hierarchical pie menus [Hopkins], pop-up menus, pop-up property sheets [Johnson], pop-up handwriting recognition pads [GO], and gesture-based interfaces [Kurtenbach, GO, Rubine]. Vocal user interface elements have been demonstrated by Schmandt <ref> [Schmandt] </ref>, Bush and Wilcox [Wilcox], and are available in commercial speech-based user interface builders [SimonSays]. 2 Photo 2. Actual Xerox Liveboard Photo 3. 2X Liveboard mock up This paper addresses issues raised by location-independence on a large display surface as exemplified by the Xerox Liveboard.
Reference: [Shneiderman] <author> Shneiderman, B., et al. </author> <title> A New Era for Touchscreen Applications. In User Interface Strategies '91, A Live, Interactive Satellite Broadcast. </title> <institution> (College Park, MD. Dec. 5). University of Maryland Instructional Television System, </institution> <year> 1990. </year>
Reference-contexts: Such "multimedia" mail messages are becoming more common in the Internet community [Borenstein]. Shneiderman <ref> [Shneiderman] </ref> has demonstrated that a competent typist can achieve up to 25 words per minute typing speed on a pop-up touchscreen keyboard. The pop-up keyboard consists of a picture of a conventional QWERTY keyboard upon which the user pecks out characters with the stylus.
Reference: [SimonSays] <author> SimonSays User's Manual, </author> <note> Version 1.1, available from HSD Microcomputer Inc., </note> <institution> Mountain View, </institution> <address> CA. </address>
Reference-contexts: Vocal user interface elements have been demonstrated by Schmandt [Schmandt], Bush and Wilcox [Wilcox], and are available in commercial speech-based user interface builders <ref> [SimonSays] </ref>. 2 Photo 2. Actual Xerox Liveboard Photo 3. 2X Liveboard mock up This paper addresses issues raised by location-independence on a large display surface as exemplified by the Xerox Liveboard. <p> Most efforts at speech recognition in real time have produced limited results until recently. It is now possible to do real time, speaker dependent, isolated word, small vocabulary recognition with sufficiently high hit rates, in software, to be useful in user interfaces. Systems such as SimonSays <ref> [SimonSays] </ref> provide an interactive user interface builder for voice commands to window applications. SimonSays builds a macro-like event sequence by capturing standard user input to an application, and allows the user to assign a word or short phrase to name the macro.
Reference: [Weiser] <author> Weiser, M. </author> <booktitle> The Computer for the 21st Century. In Scientific American 265, </booktitle> <month> 3 (Sep. </month> <year> 1991), </year> <pages> pp. 94-104. </pages>
Reference-contexts: Introduction In the future world of ubiquitous computing <ref> [Weiser] </ref>, interactive devices ranging in size from pocket to wall will be strewn about the user's environment, be it office or home. Display and digitizer surfaces will be merged so that users appear to interact directly on the display surface using an electronic stylus or touchscreen.
Reference: [Wilcox] <author> Wilcox, L.D., and Bush, M. A. </author> <title> HMM-based Wordspotting for Voice Editing and Indexing. </title> <booktitle> In Proceedings of Eurospeech '91 (Genova, </booktitle> <address> Italy, </address> <month> Sep. </month> <pages> 24-26). ESCA, </pages> <year> 1991, </year> <pages> pp. 25-28. </pages>
Reference-contexts: Examples of location-independent interface elements for the stylus include pie menus [Callahan], hierarchical pie menus [Hopkins], pop-up menus, pop-up property sheets [Johnson], pop-up handwriting recognition pads [GO], and gesture-based interfaces [Kurtenbach, GO, Rubine]. Vocal user interface elements have been demonstrated by Schmandt [Schmandt], Bush and Wilcox <ref> [Wilcox] </ref>, and are available in commercial speech-based user interface builders [SimonSays]. 2 Photo 2. Actual Xerox Liveboard Photo 3. 2X Liveboard mock up This paper addresses issues raised by location-independence on a large display surface as exemplified by the Xerox Liveboard.
Reference: [Wiseman] <author> Wiseman, N. E., et al. PIXIE: </author> <title> A New Approach to Graphical Man-Machine Communication. </title> <booktitle> In Proc. 1969 CAD Conf., IEE Conf. </booktitle> <publisher> Pub. </publisher> <address> 51, (Southampton, </address> <year> 1969), </year> <note> p. 463. </note> <author> [XView]: Heller, D. </author> <title> XView Programming Manual. </title> <publisher> O'Reilly Associates, Inc. </publisher> <year> 1990. </year>
Reference-contexts: Related work Early location-independent user interfaces Movable Menu Location-independent interfaces date back to 1969, when Wiseman <ref> [Wiseman] </ref> first proposed the idea of a "movable menu" displayed close to the cursor and appearing only when the user needs it.
Reference: [XWindow] <author> Scheifler, R.W., and Gettys, J. </author> <title> The X window system. </title> <journal> ACM Transactions on Graphics Vol. </journal> <volume> 5, No. 2, </volume> <month> (Apr </month> <year> 1986), </year> <pages> pp. 79-109. </pages>
Reference-contexts: The Politic (Pen Oriented Location-Independent Tools & Interface Components) toolkit is a collection of interface elements written in Common Lisp and added to the Garnet User Interface Development Environment within the X11 Window System <ref> [Garnet, XWindow] </ref>. The interface elements implemented, pie menus and gesture recognizers, are not generally available in user interface toolkits for X11. Garnet was chosen because it is designed specifically with our kind of task in mind: the exploration of advanced and novel user interface techniques.
References-found: 27

