URL: ftp://ftp.tik.ee.ethz.ch/pub/people/blickle/tikreport_v2.ps.gz
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fblickle,thieleg@tik.ee.ethz.ch  
Title: A Comparison of Selection Schemes used in Genetic Algorithms  
Author: Tobias Blickle and Lothar Thiele 
Address: Gloriastrasse 35, 8092 Zurich Switzerland  
Affiliation: Computer Engineering and Communication Networks Lab (TIK) Swiss Federal Institute of Technology (ETH)  
Abstract: TIK-Report Nr. 11, December 1995 Version 2 (2. Edition) 
Abstract-found: 1
Intro-found: 1
Reference: [ Arnold et al., 1992 ] <author> B.C. Arnold, N. Balakrishnan, and H. N. Nagaraja. </author> <title> A First Course in Order Statistics. Wiley Series in Probability and Mathematical Statistics, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1992. </year>
Reference: [ Back, 1994 ] <author> Thomas Back. </author> <title> Selective pressure in evolutionary algorithms: A characterization of selection mechanisms. </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (ICEC94), </booktitle> <pages> pages 57-62, </pages> <year> 1994. </year>
Reference-contexts: Goldberg [ Goldberg and Deb, 1991 ] introduced the term of takeover time. The takeover time is the number of generations that is needed for a single best individual to fill up the whole generation if no recombination is used. Recently Back <ref> [ Back, 1994 ] </ref> has analyzed the most prominent selection schemes used in Evolutionary Algorithms with respect to their takeover time. In [ Muhlenbein and Schlierkamp-Voosen, 1993 ] the selection intensity in the so called Breeder Genetic Algorithm (BGA) is used to measure the progress in the population. <p> Goldberg and Deb [ Goldberg and Deb, 1991 ] and Back <ref> [ Back, 1994 ] </ref> use the "takeover time" to define the selection pressure. Whitley calls the parameter c (see chapter 5) of his ranking selection method selection pressure. 11 We use the term "selection intensity" in the same way it is used in popula-tion genetic [ Bulmer, 1980 ] . <p> Obviously for t = 1 we obtain (in average) the unchanged initial distribution as fl T (s; 1)(f i ) = N S (f i ) S (f i1 ) S (f i1 ) = s (f i ). In <ref> [ Back, 1994 ] </ref> the probability for the individual number i to be selected by tournament selection is given by p i = N t ((N i + 1) t (N i) t ), under the assumption that the individuals are ordered according to their fitness value f (J 1 ) <p> Back has shown that for 1 &lt; c 2 this method is almost identical to the probabilities in (5.1) with + = c <ref> [ Back, 1994 ] </ref> .
Reference: [ Back, 1995 ] <author> Thomas Back. </author> <title> Generalized convergence models for tournament-and (,)-selection. </title> <editor> In L. Eshelman, editor, </editor> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms (ICGA95), </booktitle> <address> San Francisco, CA, 1995. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: Muhlenbein has introduced this selection scheme to the domain of genetic algorithms [ Muhlenbein and Schlierkamp-Voosen, 1993 ] . This method is equivalent to (; )-selection used in evolution strategies with T = <ref> [ Back, 1995 ] </ref> . The outline of the algorithm is given by algorithm 2.
Reference: [ Baker, 1987 ] <author> J. E. Baker. </author> <title> Reducing bias and inefficiency in the selection algorithm. </title> <booktitle> In Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 14-21, </pages> <address> Cambridge, MA, 1987. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: The variance of (2.3) is obtained by performing the selection method in N independent experiments. It is possible to reduce the variance almost completely by using more sophisticated sampling algorithms to select the individuals. We will introduce Baker's "stochastic universal sampling" algorithm (SUS) <ref> [ Baker, 1987 ] </ref> , which is an optimal sampling algorithm when we compare the different selection schemes in chapter 8. <p> As can be seen from table 8.1 we can calculate the expected distribution in advance without carrying out a "real" selection method. This calculation also enables us to use stochastic universal sampling (SUS) <ref> [ Baker, 1987 ] </ref> for all selection schemes discussed herein. The SUS algorithm can be stated to be an optimal sampling algorithm.
Reference: [ Baker, 1989 ] <author> J. E. Baker. </author> <title> An Analysis of the Effects of Selection in Genetic Algorithms. </title> <type> PhD thesis, </type> <institution> Graduate School of Vanderbilt University, Nashville, Tennessee, </institution> <year> 1989. </year>
Reference-contexts: In his dissertation <ref> [ Baker, 1989 ] </ref> , Baker has introduced a similar measure called "reproduction rate RR". <p> we calculate: p d;R ( ) = N S (f z ) S fl (f z ) = N S (f z ) S (f z ) N ! 1 2 2 1 N 2 ! 1 (1 ) Baker has derived this result using his term of "reproduction rate" <ref> [ Baker, 1989 ] </ref> .
Reference: [ Blickle and Thiele, 1994 ] <author> Tobias Blickle and Lothar Thiele. </author> <title> Genetic programming and redundancy. </title> <editor> In J. Hopf, editor, </editor> <booktitle> Genetic Algorithms within the Framework of Evolutionary Computation (Workshop at KI-94, Saarbrucken), </booktitle> <pages> pages 33-38. </pages> <institution> Max-Planck-Institut fur Informatik (MPI-I-94-241), </institution> <year> 1994. </year>
Reference-contexts: The parameter for the optimization are: * population size 10.000 * maximum tree size 15 * maximum number of generations 30 * tournament selection with tournament size 5 * reducing redundancy using marking crossover <ref> [ Blickle and Thiele, 1994 ] </ref> 53 * use of one step hill-climbing to adjust the RF P C numbers The last two items need further explanation: the marking crossover introduced in [ Blickle and Thiele, 1994 ] works as follows. <p> maximum number of generations 30 * tournament selection with tournament size 5 * reducing redundancy using marking crossover <ref> [ Blickle and Thiele, 1994 ] </ref> 53 * use of one step hill-climbing to adjust the RF P C numbers The last two items need further explanation: the marking crossover introduced in [ Blickle and Thiele, 1994 ] works as follows. During the evaluation of the fitness function all edges in the tree of the individual are marked. The edges that remain unmarked after calculating the fitness value are said to be redundant, because they were never used for fitness calculation. <p> The crossover operator now only selects the edges for crossover that are marked, because only changes at these edges may lead to individuals with a different fitness score. With this approach an increase in performance of almost 50% for the 6-multiplexer problem was achieved <ref> [ Blickle and Thiele, 1994 ] </ref> . "One step hill-climbing" works in the following way: after evaluation the fitness of an individual, successively all random constants in the trees are change by a little amount ffi. If this change leads to a better individual it is accepted, otherwise rejected.
Reference: [ Blickle and Thiele, 1995 ] <author> Tobias Blickle and Lothar Thiele. </author> <title> A mathematical analysis of tournament selection. </title> <editor> In L. Eshelman, editor, </editor> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms (ICGA95), </booktitle> <address> San Fran-cisco, CA, 1995. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: The description is based on the fitness distribution of the population before and after selection as introduced in <ref> [ Blickle and Thiele, 1995 ] </ref> . <p> Using the notation introduced in the previous chapter, the entire fitness distribution after selection can be predicted. The prediction will be made for the discrete (exact) fitness distribution as well as for a continuous fitness distribution. These results were first published in <ref> [ Blickle and Thiele, 1995 ] </ref> . The calculations assume that tournament selection is done with replacement.
Reference: [ Blickle, 1995 ] <author> Tobias Blickle. </author> <title> YAGPLIC User Manual. </title> <institution> Computer Engineering and Communication Networks Lab (TIK), Swiss Federal Institute of Technology (ETH) Zurich, </institution> <address> Gloriastrasse 35, CH-8092 Zurich, </address> <year> 1995. </year> <month> 63 </month>
Reference-contexts: The intention was only to find one good approximation for each data set. The problem was programmed on a SPARC Station 20 using the YAGPLIC library <ref> [ Blickle, 1995 ] </ref> . A run over 30 generations took about 15 minutes CPU time. The given solution were found after 15 - 23 generations.
Reference: [ Brill et al., 1992 ] <author> F. Z. Brill, D. E. Brown, and W. N. Martin. </author> <title> Fast genetic selection of features for neural network classifiers. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 2(3) </volume> <pages> 324-328, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Because of this several scaling methods have been proposed to keep proportional selection working, e.g. linear static scaling, linear dynamic scaling, exponential scaling, logarithmic scaling [ Grefenstette and Baker, 1989 ] ; sigma truncation <ref> [ Brill et al., 1992 ] </ref> . Another method to improve proportional selection is the "over selection" of a certain percentage of the best individuals, i.e. to force that 80 % of all individuals are taken from the best 20 % of the population.
Reference: [ Bulmer, 1980 ] <author> M.G. Bulmer. </author> <title> The Mathematical Theory of Quantitative Genetics. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1980. </year>
Reference-contexts: Whitley calls the parameter c (see chapter 5) of his ranking selection method selection pressure. 11 We use the term "selection intensity" in the same way it is used in popula-tion genetic <ref> [ Bulmer, 1980 ] </ref> . Muhlenbein has adopted the definition and applied it to genetic algorithms [ Muhlenbein and Schlierkamp-Voosen, 1993 ] . <p> This selection method is often used by breeders and in population genetic <ref> [ Bulmer, 1980; Crow and Kimura, 1970 ] </ref> . Muhlenbein has introduced this selection scheme to the domain of genetic algorithms [ Muhlenbein and Schlierkamp-Voosen, 1993 ] . This method is equivalent to (; )-selection used in evolution strategies with T = [ Back, 1995 ] . <p> proof: The substitution of (4.2) in the definition equation (2.17) gives V (T ) = f c T p e f 2 After some calculations this equation can be simplified to (4.7). 2 The selection variance is plotted on the right of Figure 4.1. (4.7) has also been derived in <ref> [ Bulmer, 1980 ] </ref> . 26 Chapter 5 Linear Ranking Selection Ranking selection was first suggested by Baker to eliminate the serious disadvantages of proportionate selection [ Grefenstette and Baker, 1989; Whitley, 1989 ] .
Reference: [ Crow and Kimura, 1970 ] <author> J.F. Crow and M. Kimura. </author> <title> An Introduction to Population Genetics Theory. </title> <publisher> Harper and Row, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: This selection method is often used by breeders and in population genetic <ref> [ Bulmer, 1980; Crow and Kimura, 1970 ] </ref> . Muhlenbein has introduced this selection scheme to the domain of genetic algorithms [ Muhlenbein and Schlierkamp-Voosen, 1993 ] . This method is equivalent to (; )-selection used in evolution strategies with T = [ Back, 1995 ] . <p> of Diversity By construction of the selection method only the fraction T of the population will be selected, i.e. the loss of diversity is p d; (T ) = 1 T (4.4) 4.3 Selection Intensity The results presented in this subsection have been already derived in a different way in <ref> [ Crow and Kimura, 1970 ] </ref> . Theorem 4.3.1 The selection intensity of truncation selection is I (T ) = T p e f 2 c where f c is determined by T = R 1 1 p 2 df .
Reference: [ de la Maza and Tidor, 1993 ] <author> Michael de la Maza and Bruce Tidor. </author> <title> An analysis of selection procedures with particular attention paid to proportional and bolzmann selection. </title> <editor> In Stefanie Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 124-131, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: In [ Muhlenbein and Schlierkamp-Voosen, 1993 ] the selection intensity in the so called Breeder Genetic Algorithm (BGA) is used to measure the progress in the population. The selection intensity is derived for proportional selection and truncation selection. De la Maza and Tidor <ref> [ de la Maza and Tidor, 1993 ] </ref> analyzed several selection methods according 4 to their scale and translation invariance. <p> The selection probabilities of the best and the worst individual are now almost identical. This undesirable property arises from the fact that proportional selection is not translation invariant (see e.g. <ref> [ de la Maza and Tidor, 1993 ] </ref> ). Because of this several scaling methods have been proposed to keep proportional selection working, e.g. linear static scaling, linear dynamic scaling, exponential scaling, logarithmic scaling [ Grefenstette and Baker, 1989 ] ; sigma truncation [ Brill et al., 1992 ] .
Reference: [ Goldberg and Deb, 1991 ] <editor> David E. Goldberg and Kalyanmoy Deb. </editor> <title> A comparative analysis of selection schemes used in genetic algorithms. </title> <editor> In G. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 69-93, </pages> <address> San Mateo, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Some work has been done to classify the different selection schemes such as proportionate selection, ranking selection, tournament selection. Goldberg <ref> [ Goldberg and Deb, 1991 ] </ref> introduced the term of takeover time. The takeover time is the number of generations that is needed for a single best individual to fill up the whole generation if no recombination is used. <p> RR gives the percentage of individuals that is selected to reproduce, hence RR = 100 (1 p d ). 2.5 Selection Intensity The term "selection intensity" or "selection pressure" is often used in different contexts and for different properties of a selection method. Goldberg and Deb <ref> [ Goldberg and Deb, 1991 ] </ref> and Back [ Back, 1994 ] use the "takeover time" to define the selection pressure. <p> f 0 ! t 1 A = t 2 t 1 s (f ) 1 Z f s (x) dx 1 Z f s (x) dx = t 2 t 1 s (f ) 1 Z f s (x) dx = T (s; t 1 t 2 )(f ) In <ref> [ Goldberg and Deb, 1991 ] </ref> the proportion P t of best-fit individuals after t selections with tournament size t (without recombination) is given to P t = 1 (1 P 0 ) t t This can be obtained as a special case from Theorem 3.1.1, if only the best-fit individuals <p> Hence an analysis is only possible if we make some further assumptions on the initial fitness distribution. This is why other work on proportional selection assume some special functions to be optimized (e.g. <ref> [ Goldberg and Deb, 1991 ] </ref> ). Another weak point is that the selection intensity even in the early stage of the optimization (when the variance is high) is too low. Measurements on a broad range of problems showed sometimes a negative selection intensity. <p> expected fitness distributions of linear ranking selection with = 1 N and tournament selection with t = 2 are identical, i.e. fl 1 ) = fl Proof: fl 1 )(f i ) = s (f i ) N 1 + N 1 T (s; 2)(f i ) Goldberg and Deb <ref> [ Goldberg and Deb, 1991 ] </ref> have also shown this result, but only for the behavior of the best fit individual. By this we see the complementary character of the two selection schemes.
Reference: [ Goldberg, 1989 ] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: Recombination includes crossover and mutation or any other operator that changes the "genetic material". This kind of description differs from the common paradigms where selection is made to obtain the individuals for recombination <ref> [ Goldberg, 1989; Koza, 1992 ] </ref> . But it is mathematically equivalent and allows to analyze the selection method separately. For selection only the fitness values of the individuals are taken into account. Hence, the state of the population is completely described by the fitness values of all individuals.
Reference: [ Grefenstette and Baker, 1989 ] <author> John J. Grefenstette and James E. Baker. </author> <title> How genetic algorithms work: A critical look at implicit parallelism. </title> <editor> In J. David Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 20 - 27, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: equation can be simplified to (4.7). 2 The selection variance is plotted on the right of Figure 4.1. (4.7) has also been derived in [ Bulmer, 1980 ] . 26 Chapter 5 Linear Ranking Selection Ranking selection was first suggested by Baker to eliminate the serious disadvantages of proportionate selection <ref> [ Grefenstette and Baker, 1989; Whitley, 1989 ] </ref> . For ranking selection the individuals are sorted according their fitness values and the rank N is assigned to the best individual and the rank 1 to the worst individual. <p> Because of this several scaling methods have been proposed to keep proportional selection working, e.g. linear static scaling, linear dynamic scaling, exponential scaling, logarithmic scaling <ref> [ Grefenstette and Baker, 1989 ] </ref> ; sigma truncation [ Brill et al., 1992 ] .
Reference: [ Henrici, 1977 ] <author> P. Henrici. </author> <title> Applied and Computational Complex Analysis, volume 2. A Wiley-Interscience Series of Texts, Monographs, </title> <publisher> and Tracts, </publisher> <year> 1977. </year>
Reference-contexts: For larger tournament sizes (3.13) can be accurately evaluated by numerical integration. The result is shown on the left side of Figure 3.5 for a tournament size from 1 to 30. But an explicit expression of (3.13) may not exist. By means of the steepest descent method (see, e.g. <ref> [ Henrici, 1977 ] </ref> ) an approximation for large tournament sizes can be given. But even for small tournament sizes this approximation gives acceptable results.
Reference: [ Holland, 1975 ] <author> John H. Holland. </author> <booktitle> Adaption in Natural and Artificial Systems. </booktitle> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: The following formula approximates the selection variance with an relative error of less than 5% for ff 2 [10 20 ; 0:8]: V E (ff) ln 1:2 + 2:225ff ln ff (6.10) Chapter 7 Proportional Selection Proportional selection is the original selection method proposed for genetic algorithms by Holland <ref> [ Holland, 1975 ] </ref> . We include the analysis of the selection method mostly because of its fame.
Reference: [ Koza, 1992 ] <author> John R. Koza. </author> <title> Genetic programming: on the programming of computers by means of natural selection. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1992. </year> [ <title> Muhlenbein and Schlierkamp-Voosen, 1993 ] Heinz Muhlenbein and Dirk Schlierkamp-Voosen. Predictive models for the breeder genetic algorithm. </title> <journal> Evolutionary Computation, </journal> <volume> 1(1), </volume> <year> 1993. </year> <month> 64 </month>
Reference-contexts: Recombination includes crossover and mutation or any other operator that changes the "genetic material". This kind of description differs from the common paradigms where selection is made to obtain the individuals for recombination <ref> [ Goldberg, 1989; Koza, 1992 ] </ref> . But it is mathematically equivalent and allows to analyze the selection method separately. For selection only the fitness values of the individuals are taken into account. Hence, the state of the population is completely described by the fitness values of all individuals. <p> S (f i ) = &gt; &lt; 0 : i &lt; 1 j=1 s (f j ) : 1 i n (2.4) Example 2.0.1 As an example of a discrete fitness distribution we use the initial fitness distribution of the "wall-following-robot" from Koza <ref> [ Koza, 1992 ] </ref> . This distribution is typical of problems solved by genetic programming (many bad and only very few good individuals exist). Figure 2.2 shows the distribution s (f ) (left) and the cumulative distribution S (f ) (right). <p> As the population size is held constant, the conditions + = 2 and 0 must be fulfilled. Note that all individuals get a different rank, i.e. a different selection probability, even if they have the same fitness value. Koza <ref> [ Koza, 1992 ] </ref> determines the probability by a multiplication factor r m that determines the gradient of the linear function. <p> Another method to improve proportional selection is the "over selection" of a certain percentage of the best individuals, i.e. to force that 80 % of all individuals are taken from the best 20 % of the population. This method was used in <ref> [ Koza, 1992 ] </ref> . In [ Muhlenbein and Schlierkamp-Voosen, 1993 ] it is already stated that "these modifications are necessary, not tricks to speed up the algorithm". The following analysis will confirm this statement. <p> In general we use the same approach as Koza in his first book on genetic programming <ref> [ Koza, 1992 ] </ref> . Genetic Programming (GP) is an optimization method based on natural evolution similar to genetic algorithms. The major difference is that GP uses trees to represent the individuals where GA uses bit-strings. The tree structure can represent functional dependencies or complete computer programs.
Reference: [ Muhlenbein and Voigt, 1995 ] <author> Heinz Muhlenbein and Hans-Michael Voigt. </author> <title> Gene pool recombination in genetic algorithms. </title> <editor> In I. H. Osman and J. P. Kelly, editors, </editor> <booktitle> Proceedings of the Metaheuristics Inter. Conf., </booktitle> <address> Norwell, 1995. </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: Solving (4.6) for T yields T = 1 1 p e f 2 = f c p e f 2 2 A lower bound for the selection intensity reported by <ref> [ Muhlenbein and Voigt, 1995 ] </ref> is I (T ) 1T T . 4.4 Selection Variance Theorem 4.4.1 The selection variance of truncation selection is V (T ) = 1 I (T )(I (T ) f c ) (4.7) selection. <p> But again this graph may help to decide for the "appropriate" selection method for a particular optimization problem. If we accept the assumption that a higher variance is advantageous to the optimization process, exponential ranking selection selection reveals itself to be the best selection scheme. In <ref> [ Muhlenbein and Voigt, 1995 ] </ref> it is stated that "if two selection selection methods have the same selection intensity, the method giving the higher standard deviation of the selected parents is to be preferred".
Reference: [ Shapiro et al., 1994 ] <author> Jonathan Shapiro, Adam Prugel-Bennett, and Magnus Rattray. </author> <title> A statistical mechanical formulation of the dynamics of genetic algorithms. </title> <editor> In Terence C. Fogarty, editor, </editor> <booktitle> Evolutionary Computing AISB Workshop. </booktitle> <publisher> Springer , LNCS 865, </publisher> <year> 1994. </year>
Reference-contexts: The characterization of the population by its fitness distribution has also been used by other researches, but in a more informal way. In [ Muhlenbein and Schlierkamp-Voosen, 1993 ] the fitness distribution is used to calculate some properties of truncation selection. In <ref> [ Shapiro et al., 1994 ] </ref> a statistical mechanics approach is taken to describe the dynamics of a Genetic Algorithm that makes use of fitness distributions, too. 6 It is possible to describe a selection method as a function that transforms a fitness distribution into another fitness distribution.
Reference: [ Thierens and Goldberg, 1994a ] <author> D. Thierens and D. Goldberg. </author> <title> Convergence models of genetic algorithm selection schemes. </title> <editor> In Yuval Davidor, Hans-Paul Schwefel, and Reinhard Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature - PPSN III, </booktitle> <pages> pages 119 - 129, </pages> <address> Berlin, </address> <year> 1994. </year> <note> Lecture Notes in Computer Science 866 Springer-Verlag. </note>
Reference-contexts: Thiele, 1995; Back, 1995; Arnold et al., 1992 ] ): I T (1) = 0 1 3 p I T (4) = arctan p I T (5) = p ( 2 arctan p 1 ) For a tournament size of two Thierens and Goldberg derive the same average fitness value <ref> [ Thierens and Goldberg, 1994a ] </ref> in a completely different manner. But their formulation can not be extended to other tournament sizes. For larger tournament sizes (3.13) can be accurately evaluated by numerical integration.
Reference: [ Thierens and Goldberg, 1994b ] <author> Dirk Thierens and David Goldberg. </author> <title> Elitist recombination: an integrated selection recombination ga. </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (ICEC94), </booktitle> <pages> pages 508-512, </pages> <year> 1994. </year>
Reference: [ Whitley, 1989 ] <author> Darrell Whitley. </author> <title> The GENITOR algorithm and selection pressure: Why rank-based allocation of reproductive trials is best. </title> <editor> In J. David Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 116 - 121, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann Publishers. </publisher> <pages> 65 </pages>
Reference-contexts: equation can be simplified to (4.7). 2 The selection variance is plotted on the right of Figure 4.1. (4.7) has also been derived in [ Bulmer, 1980 ] . 26 Chapter 5 Linear Ranking Selection Ranking selection was first suggested by Baker to eliminate the serious disadvantages of proportionate selection <ref> [ Grefenstette and Baker, 1989; Whitley, 1989 ] </ref> . For ranking selection the individuals are sorted according their fitness values and the rank N is assigned to the best individual and the rank 1 to the worst individual. <p> Koza [ Koza, 1992 ] determines the probability by a multiplication factor r m that determines the gradient of the linear function. A transformation into the form of (5.1) is possible by = 2 r m +1 and + = 2r m Whitley <ref> [ Whitley, 1989 ] </ref> describes the ranking selection by transforming an equally distributed random variable 2 [0; 1] to determine the index of the selected individual j = b 2 (c 1) c c 2 4 (c 1) c (5.2) where c is a parameter called "selection bias".
References-found: 23

