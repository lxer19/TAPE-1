URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/rapier-proposal-97.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: mecaliff@cs.utexas.edu  
Title: Relational Learning Techniques for Natural Language Information Extraction  
Author: Mary Elaine Califf 
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences University of Texas at Austin  
Abstract: The recent growth of online information available in the form of natural language documents creates a greater need for computing systems with the ability to process those documents to simplify access to the information. One type of processing appropriate for many tasks is information extraction, a type of text skimming that retrieves specific types of information from text. Although information extraction systems have existed for two decades, these systems have generally been built by hand and contain domain specific information, making them difficult to port to other domains. A few researchers have begun to apply machine learning to information extraction tasks, but most of this work has involved applying learning to pieces of a much larger system. This paper presents a novel rule representation specific to natural language and a learning system, Rapier, which learns information extraction rules. Rapier takes pairs of documents and filled templates indicating the information to be extracted and learns patterns to extract fillers for the slots in the template. This proposal presents initial results on a small corpus of computer-related job postings with a preliminary version of Rapier. Future research will involve several enhancements to Rapier as well as more thorough testing on several domains and extension to additional natural language processing tasks. We intend to extend the rule representation and algorithm to allow for more types of constraints than are currently supported. We also plan to incorporate active learning, or sample selection, methods, specifically query by committee, into Rapier. These methods have the potential to substantially reduce the amount of annotation required. We will explore the issue of distinguishing relevant and irrelevant messages, since currently Rapier only extracts from the any messages given to it, assuming that all are relevant. We also intend to run much larger tests with Rapier on multiple domains including the terrorism domain from the third and fourth Message Uncderstanding Conferences, which will allow comparison against other systems. Finally, we plan to demonstrate the generality of Rapier`s representation and algorithm by applying it to other natural language processing tasks such as word sense disambiguation. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anoe, C., & Bennett, S. W. </author> <year> (1995). </year> <title> Evaluating automated and manual acquisition of anaphora resolution strategies. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Lenguistics, </booktitle> <pages> pp. </pages> <address> 122-129 Cambridge, MA. </address> <booktitle> ARPA (Ed.). (1992). Proceedings of the Fourth DARPA Message Understanding Evaluation and Conference, </booktitle> <address> San Mateo, CA. </address> <publisher> Morgan Kaufman. </publisher> <address> ARPA (Ed.). </address> <year> (1993). </year> <booktitle> Proceedings of the Fifth DARPA Message Understanding Evaluation and Conference, </booktitle> <address> San Mateo, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference: <editor> Birnbaum, L. A., & Collins, G. C. (Eds.). </editor> <booktitle> (1991). Proceedings of the Eighth International Workshop on Machine Learning: Part VI Learning Relations, </booktitle> <address> Evanston, IL. </address>
Reference-contexts: However, these techniques still require the system developer to specify a manageable, finite set of features for use in making decisions. Developing this set of features can require significant representation engineering and may still exclude important contextual information. In contrast, relational learning methods <ref> (Birnbaum & Collins, 1991) </ref> allow induction over structured examples that can include first-order logical predicates and functions and unbounded data structures such as lists and trees. In particular, inductive logic programming (ILP) (Lavrac & Dzeroski, 1994; Muggleton, 1992) studies the induction of rules in first-order logic (Prolog programs).
Reference: <author> Brill, E. </author> <year> (1993). </year> <title> Automatic grammar induction and parsing free text: A transformation-based approach. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. </pages> <address> 259-265 Columbus, Ohio. </address>
Reference-contexts: There has also been significant research applying neural-network methods to language processing (Reilly & Sharkey, 1992; Miikkulainen, 1993). However, there has been relatively little recent language research using symbolic learning, although some recent systems have successfully employed decision trees (Magerman, 1995; Anoe & Bennett, 1995), transformation rules <ref> (Brill, 1993, 1995) </ref>, and other symbolic methods (Wermter, Riloff, & Scheler, 1996).
Reference: <author> Brill, E. </author> <year> (1995). </year> <title> Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. </title> <journal> Computational Linguistics, </journal> <volume> 21 (4), </volume> <pages> 543-565. </pages>
Reference: <author> Brill, E., & Church, K. </author> <title> (Eds.). </title> <booktitle> (1996). Proceedings of the Conference on Empirical Methods in Natural Language Processing. </booktitle> <institution> University of Pennsylvania, </institution> <address> Philadelphia, PA. </address>
Reference: <author> Brill, E. </author> <year> (1994). </year> <title> Some advances in rule-based part of speech tagging. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: This doesn't provide as much information as a parser, but a tagger is faster and more robust than a full parser. At present we are using Eric Brill's tagger as trained on a Wall Street Journal corpus <ref> (Brill, 1994) </ref>. One advantage to this particular tagger is that it can be trained on a new domain to improve performance. For semantic information, we plan to employ a domain-independent lexicon which includes a semantic hierarchy, possibly supplemented by domain specific lexicons.
Reference: <author> Cardie, C. </author> <year> (1993). </year> <title> A case-based apprach to knowledge acquisition for domain-specific sentence analysis. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 798-803. </pages>
Reference: <author> Charniak, E. </author> <year> (1993). </year> <title> Statistical Language Learning. </title> <publisher> MIT Press. </publisher>
Reference: <author> Church, K., & Mercer, R. L. </author> <year> (1993). </year> <title> Introduction to the special issue on computational linguistics using large corpora. </title> <journal> Computational Linguistics, </journal> <volume> 19 (1), </volume> <pages> 1-24. </pages>
Reference: <author> Cohen, W. W. </author> <year> (1995). </year> <title> Text categorization and relational learning. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 124-132 San Francisco, CA. </address> <publisher> Morgan Kaufman. 23 Cohen, W. W. </publisher> <year> (1996). </year> <title> Learning rules that classify e-mail. </title> <booktitle> In Papers from the AAAI Fall Symposium on AI Applications in Knowledge Navigation & Retrieval, </booktitle> <pages> pp. 18-25. </pages> <publisher> AAAI Press. </publisher>
Reference-contexts: Detailed experimental comparisons of ILP and feature-based induction have demonstrated the advantages of relational representations in two language related tasks, text categorization <ref> (Cohen, 1995) </ref> and generating the past tense of an English verb (Mooney & Califf, 1995). Two other advantages of ILP-based techniques are comprehensibility and the ability to use background knowledge.
Reference: <author> Cohn, D., Atlas, L., & Ladner, R. </author> <year> (1994). </year> <title> Improving generalization with active learning. </title> <journal> Machine Learning, </journal> <volume> 15 (2), </volume> <pages> 201-221. </pages>
Reference-contexts: In order to more fairly sample the version space and avoid over-agreement, it may be preferable to encourage one hypothesis to be quite specific and the other to be quite general, as in <ref> (Cohn et al., 1994) </ref>. Since the induction algorithm performs a combination of top-down and bottom-up search, it should be possible to alter these in various ways to control the generality of the learned rules.
Reference: <author> Dagan, I., & Engelson, S. P. </author> <year> (1995). </year> <title> Committee-based sampling for training probabilistic classifiers. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 150-157 San Francisco, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Engelson, S., & Dagan, I. </author> <year> (1996). </year> <title> Minimizing manual annotation cost in supervised training from corpora. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Association for Computational Lenguistics Santa Cruz, </booktitle> <address> CA. </address>
Reference-contexts: Not all training examples are equally useful to a learning system, and by carefully selecting useful examples, annotation effort can be dramatically reduced. This approach has been successfully used in training part-of-speech taggers <ref> (Engelson & Dagan, 1996) </ref>, and we believe that it will be helpful in the information extraction domain, as well. Active learning involves constructing or selecting informative training examples rather than passively accepting them. <p> Active learning involves constructing or selecting informative training examples rather than passively accepting them. Since raw text is widely available, sample selection, choosing a subset of examples to annotate from an unanalyzed corpus, is the style of active learning most useful for natural language applications <ref> (Engelson & Dagan, 1996) </ref>. <p> the label of the example, add it to the training set, a nd Update the two hypotheses to be consistent with all current training data Alternatively, a larger committee can be used and each example selected for annotation with a probability proportional to the amount of disagreement over its label <ref> (Engelson & Dagan, 1996) </ref>. Since the learning algorithm is not incremental, retraining after each selected example may be too time consuming, so samples will probably need to be selected in batches (Lewis & Catlett, 1994).
Reference: <editor> Frakes, W., & Baeza-Yates, R. (Eds.). </editor> <year> (1992). </year> <title> Information Retrieval: Data Structures and Algorithms. </title> <publisher> Prentice Hall. </publisher>
Reference: <author> Huffmann, S. B. </author> <year> (1996). </year> <title> Learning information extraction patterns from examples. </title> <editor> In Wermter, S., Riloff, E., & Scheller, G. (Eds.), </editor> <title> Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing, </title> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. 246-260. </pages> <publisher> Springer. </publisher>
Reference-contexts: Information extraction can be useful in a variety of domains. The various MUC's have focused on tasks such as Latin American terrorism, joint ventures, microelectronics, and company management changes. Others have used information extraction to track medical patient records (Soderland et al., 1995) and to track company mergers <ref> (Huffmann, 1996) </ref>. Another domain which seems appropriate, particularly in the light of dealing with the wealth of online information, is to extract information from text documents in order to create easily searchable databases from the information, thus making the wealth of text online more easily accessible. <p> Like the previous systems, Palka relies on prior sentence analysis to identify syntactic elements and their relationships. Liep <ref> (Huffmann, 1996) </ref> also learns information extraction patterns. In many ways, Liep functions like AutoSlog except that it learns only patterns that extract multiple slots, 21 rather than a single slot per pattern. Liep's extraction rules have syntactic constraints on pair-wise syntactic relationship between sentence elements.
Reference: <author> Kijsirikul, B., Numao, M., & Shimura, M. </author> <year> (1992). </year> <title> Discrimination-based constructive induction of logic programs. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 44-49 San Jose, CA. </address>
Reference: <author> Kim, J.-T., & Moldovan, D. I. </author> <year> (1995). </year> <title> Acquisition of linguistic patterns for knowledge-based information extraction. </title> <journal> IEEE Transactions on Knowledge and DataEngineering, </journal> <volume> 7 (5), </volume> <pages> 713-724. </pages>
Reference-contexts: Generalization ends when too many negative examples will be covered by further relaxation of the constraints. Another system that learns information extraction patterns is Palka <ref> (Kim & Moldovan, 1995) </ref>. Palka represents it rules as FP-structures, which constrain the root of the verb and have semantic constraints on the phrases to be extracted. It generalizes and specializes the rules by moving up and down in a semantic hierarchy or adding disjunctions of semantic classes.
Reference: <author> Lavrac, N., & Dzeroski, S. </author> <year> (1994). </year> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood. </publisher>
Reference-contexts: One advantage of the MDL metric is that it does allow for noise handling, but we may also want to look at other metrics which are better for handling noise <ref> (Lavrac & Dzeroski, 1994) </ref>. There are also several parameters to the system which should be empirically tuned.
Reference: <author> Lehnert, W., & Sundheim, B. </author> <year> (1991). </year> <title> A performance evaluation of text-analysis technologies. </title> <journal> AI Magazine, </journal> <volume> 12 (3), </volume> <pages> 81-94. </pages>
Reference-contexts: One way of providing more "understanding" is with information extraction. Information extraction is the task of locating specific pieces of data from a natural language document, and has been the focus of ARPA's MUC program <ref> (Lehnert & Sundheim, 1991) </ref>. The extracted information can then be stored in a database which could then be queried using either standard database query languages or a natural language database interface.
Reference: <author> Lewis, D. D., & Catlett, J. </author> <year> (1994). </year> <title> Heterogeneous uncertainty sampling for supervised learning. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 148-156 San Francisco, CA. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Since the learning algorithm is not incremental, retraining after each selected example may be too time consuming, so samples will probably need to be selected in batches <ref> (Lewis & Catlett, 1994) </ref>. Since Rapier employs a random sampling of pairs as seeds to the bottom-up generalization algorithm, committee member can be generated by using different random samples.
Reference: <author> Magerman, D. M. </author> <year> (1995). </year> <title> Statistical decision-tree models for parsing. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Lenguistics, </booktitle> <pages> pp. </pages> <address> 276-283 Cambridge, MA. </address>
Reference: <author> Marcus, M., Santorini, B., & Marcinkiewicz, M. </author> <year> (1993). </year> <title> Building a large annotated corpus of English: The Penn treebank. </title> <journal> Computational Linguistics, </journal> <volume> 19 (2), </volume> <pages> 313-330. </pages> <note> 24 McCarthy, </note> <author> J., & Lehnert, W. </author> <year> (1995). </year> <title> Using decision trees for coreference resolution. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 1050-1055. </pages>
Reference-contexts: These methods automate the acquisition of much of the complex knowledge required for NLP by training on suitably annotated natural language corpora, e.g. treebanks of parsed sentences <ref> (Marcus, Santorini, & Marcinkiewicz, 1993) </ref>. Most of these empirical NLP methods employ statistical techniques such as n-gram models, hidden Markov models (HMMs), and probabilistic context free grammars (PCFGs). There has also been significant research applying neural-network methods to language processing (Reilly & Sharkey, 1992; Miikkulainen, 1993).
Reference: <author> Miikkulainen, R. </author> <year> (1993). </year> <title> Subsymbolic Natural Language Processing: An Integrated Model of Scripts, Lexicon, and Memory. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Miller, G., Beckwith, R., Fellbaum, C., Gross, D., & Miller, K. </author> <year> (1993). </year> <title> Introduction to WordNet: An on-line lexical database. </title> <note> Available by ftp to clarity.princeton.edu. </note>
Reference-contexts: One advantage to this particular tagger is that it can be trained on a new domain to improve performance. For semantic information, we plan to employ a domain-independent lexicon which includes a semantic hierarchy, possibly supplemented by domain specific lexicons. Initially, we plan to use WordNet <ref> (Miller, Beckwith, Fellbaum, Gross, & Miller, 1993) </ref>, a lexical database of over 50,000 words which contains a semantic hierarchy in the form of hypernym links. 8 Pre-filler Pattern: Filler Pattern: Post-filler Pattern: 1) word: leading 1) list: max length: 2 1) word: [firm, company] syntactic: [nn, nns] 3 Rapier Algorithm 3.1
Reference: <author> Miller, S., Stallard, D., Bobrow, R., & Schwartz, R. </author> <year> (1996). </year> <title> A fully statistical approach to natural language interfaces. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Association for Computational Lenguistics, </booktitle> <pages> pp. </pages> <address> 55-61 Santa Cruz, CA. </address>
Reference: <author> Mitchell, T. M. </author> <year> (1982). </year> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18 (2), </volume> <pages> 203-226. </pages>
Reference-contexts: In committee-based sampling, the learner maintains multiple definitions consistent with the current training data (i.e. multiple elements of the version space <ref> (Mitchell, 1982) </ref>), categorizes unlabelled examples with each definition, and selects for labelling those examples with the most disagreement amongst the "committee members" (Seung, Opper, & Sompolinsky, 1992; Cohn et al., 1994).
Reference: <author> Mooney, R. J. </author> <year> (1996). </year> <title> Comparative experiments on disambiguating word senses: An illustration of the role of bias in machine learning. </title> <booktitle> In Proceedings of the Conference on Empirical Methods in Natural Language Processing, </booktitle> <pages> pp. </pages> <address> 82-91 Philadelphia, PA. </address>
Reference-contexts: HUM TGT: TOTAL NUMBER - 5 databases would be particularly useful as part of a complete NLP system which supported natural language querying of the system. The architecture for such a complete system is shown in figure 3. A query parser can be learned using Chill <ref> (Zelle & Mooney, 1996) </ref>, a system which learns parsers from example sentences paired with their parses, and a semantic lexicon could be produced using Wolfie (Thompson, 1995), a system which learns a lexicon from sentences paired with their semantic representations. <p> We intend to run some experiments with word disambiguation corpora that have been used with other learning systems <ref> (Mooney, 1996) </ref> to see whether Rapier's representation and algorithm are successful at this task. We also hope to find additional natural language processing tasks for which our representation and algorithm seem appropriate. One possibility would be text classification using patterns automatically anchored as described above for fixed-value slots.
Reference: <author> Mooney, R. J., & Califf, M. E. </author> <year> (1995). </year> <title> Induction of first-order decision lists: Results on learning the past tense of English verbs. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3, </volume> <pages> 1-24. </pages>
Reference-contexts: Detailed experimental comparisons of ILP and feature-based induction have demonstrated the advantages of relational representations in two language related tasks, text categorization (Cohen, 1995) and generating the past tense of an English verb <ref> (Mooney & Califf, 1995) </ref>. Two other advantages of ILP-based techniques are comprehensibility and the ability to use background knowledge. The comprehensibility of symbolic rules makes it easier for the system developer to understand and verify the resulting system and perhaps even edit the learned knowledge (Cohen, 1996).
Reference: <author> Muggleton, S., & Feng, C. </author> <year> (1992). </year> <title> Efficient induction of logic programs. </title> <editor> In Muggleton, S. (Ed.), </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pp. 281-297. </pages> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: The ILP-based ideas are appropriate because they were designed to with rich, unbounded representations. The following sections briefly describe the three systems which most directly influenced Rapier's algorithm. 2.2.2 Golem Golem <ref> (Muggleton & Feng, 1992) </ref> is a bottom-up (specific to general) ILP algorithm based on the construction of relative least-general generalizations, rlggs (Plotkin, 1970). The idea of least-general generalizations (LGGs) is, given two items (in ILP, two clauses), finding the least general item that covers the original pair.
Reference: <author> Muggleton, S., King, R., & Sternberg, M. </author> <year> (1992). </year> <title> Protein secondary structure prediction using logic-based machine learning. </title> <journal> Protein Engineering, </journal> <volume> 5 (7), </volume> <pages> 647-657. </pages>
Reference-contexts: The ILP-based ideas are appropriate because they were designed to with rich, unbounded representations. The following sections briefly describe the three systems which most directly influenced Rapier's algorithm. 2.2.2 Golem Golem <ref> (Muggleton & Feng, 1992) </ref> is a bottom-up (specific to general) ILP algorithm based on the construction of relative least-general generalizations, rlggs (Plotkin, 1970). The idea of least-general generalizations (LGGs) is, given two items (in ILP, two clauses), finding the least general item that covers the original pair.
Reference: <author> Muggleton, S. H. (Ed.). </author> <year> (1992). </year> <title> Inductive Logic Programming. </title> <publisher> Academic Press, </publisher> <address> New York, NY. </address>
Reference-contexts: The ILP-based ideas are appropriate because they were designed to with rich, unbounded representations. The following sections briefly describe the three systems which most directly influenced Rapier's algorithm. 2.2.2 Golem Golem <ref> (Muggleton & Feng, 1992) </ref> is a bottom-up (specific to general) ILP algorithm based on the construction of relative least-general generalizations, rlggs (Plotkin, 1970). The idea of least-general generalizations (LGGs) is, given two items (in ILP, two clauses), finding the least general item that covers the original pair.
Reference: <author> Muggleton, S. </author> <year> (1995). </year> <title> Inverse entailment and Progol. </title> <journal> New Generation Computing Journal, </journal> <volume> 13, </volume> <pages> 245-286. </pages>
Reference-contexts: Chillin uses the notion of empirical subsumption, which means that as new, more general clauses are added, all of the clauses which are not needed to prove positive examples are removed from the definition. 2.2.4 Progol Progol <ref> (Muggleton, 1995) </ref> also combines bottom-up and top-down search. Using mode declarations provided for both the background predicates and the predicate being learned, it constructs a most specific clause for a random seed example.
Reference: <author> Ng, H. T., & Lee, H. B. </author> <year> (1996). </year> <title> Integrating multiple knowledge sources to disambiguate word sense: An exemplar-based approach. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Association for Computational Lenguistics, </booktitle> <pages> pp. </pages> <address> 40-47 Santa Cruz, CA. </address>
Reference-contexts: Not all training examples are equally useful to a learning system, and by carefully selecting useful examples, annotation effort can be dramatically reduced. This approach has been successfully used in training part-of-speech taggers <ref> (Engelson & Dagan, 1996) </ref>, and we believe that it will be helpful in the information extraction domain, as well. Active learning involves constructing or selecting informative training examples rather than passively accepting them. <p> Active learning involves constructing or selecting informative training examples rather than passively accepting them. Since raw text is widely available, sample selection, choosing a subset of examples to annotate from an unanalyzed corpus, is the style of active learning most useful for natural language applications <ref> (Engelson & Dagan, 1996) </ref>. <p> the label of the example, add it to the training set, a nd Update the two hypotheses to be consistent with all current training data Alternatively, a larger committee can be used and each example selected for annotation with a probability proportional to the amount of disagreement over its label <ref> (Engelson & Dagan, 1996) </ref>. Since the learning algorithm is not incremental, retraining after each selected example may be too time consuming, so samples will probably need to be selected in batches (Lewis & Catlett, 1994).
Reference: <author> Plotkin, G. D. </author> <year> (1970). </year> <title> A note on inductive generalization. </title> <editor> In Meltzer, B., & Michie, D. (Eds.), </editor> <booktitle> Machine Intelligence (Vol. </booktitle> <volume> 5). </volume> <publisher> Elsevier North-Holland, </publisher> <address> New York. </address>
Reference-contexts: The following sections briefly describe the three systems which most directly influenced Rapier's algorithm. 2.2.2 Golem Golem (Muggleton & Feng, 1992) is a bottom-up (specific to general) ILP algorithm based on the construction of relative least-general generalizations, rlggs <ref> (Plotkin, 1970) </ref>. The idea of least-general generalizations (LGGs) is, given two items (in ILP, two clauses), finding the least general item that covers the original pair. This is usually a fairly simple computation. Rlggs are the LGGs relative to a set of background relations.
Reference: <author> Quinlan, J. R., & Rivest, R. L. </author> <year> (1989). </year> <title> Inferring decision trees using the minimum description length principle. </title> <journal> Information and Computation, </journal> <volume> 80, </volume> <pages> 227-248. </pages>
Reference-contexts: The current metric for evaluating rules is based on the information value of the rule penalized by the size of the rule. We would like to explore variations on this metric. We would also like to explore metrics based on the minimum description length (MDL) principle <ref> (Quinlan & Rivest, 1989) </ref>. The idea behind MDL is that the "best" generalization is one that minimizes the size of the description of the data.
Reference: <author> Quinlan, J. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 (3), </volume> <pages> 239-266. </pages>
Reference-contexts: If the resulting clause covers negative examples, it is specialized by adding antecedent literals in a top-down fashion. The search for new literals is carried out in a hill-climbing fashion, using an information gain metric for evaluating literals. This is similar to the search employed by Foil <ref> (Quinlan, 1990) </ref>. In cases where a correct clause cannot be learned with the existing background relations, Chillin attempts to construct new predicates which 7 will distinguish the covered negative examples from the covered positives. <p> We maintain a list of the best n rules created and specialize the rules under consideration by adding pieces of the generalizations of the pre- and post-filler patterns of the two seed rules, working outward from the fillers. The rules are ordered using an information value metric <ref> (Quinlan, 1990) </ref> weighted by the size of the rule (preferring smaller rules): ruleV al = log 2 (p=(p + n)) + ruleSize=10 where p is the number of correct fillers extracted by the rule.
Reference: <editor> Reilly, R. G., & Sharkey, N. E. (Eds.). </editor> <year> (1992). </year> <title> Connectionist Approaches to Natural Language Processing. </title> <publisher> Lawrence Erlbaum and Associates, </publisher> <address> Hilldale, NJ. </address>
Reference: <author> Riloff, E. </author> <year> (1993). </year> <title> Automatically constructing a dictionary for information extraction tasks. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pp. 811-816. </pages>
Reference-contexts: One of the earliest attempts to use learning in an information extraction system was AutoSlog <ref> (Riloff, 1993) </ref>. AutoSlog creates a dictionary of extraction patterns by specializing a set of general syntactic patterns. These patterns are used by a larger information extraction system including a parser and a discourse analysis module. AutoSlog has two major drawbacks.
Reference: <author> Riloff, E. </author> <year> (1996). </year> <title> Automatically generating extraction patterns from untagged text. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 1044-1049. </pages>
Reference-contexts: However, there has been relatively little recent language research using symbolic learning, although some recent systems have successfully employed decision trees (Magerman, 1995; Anoe & Bennett, 1995), transformation rules (Brill, 1993, 1995), and other symbolic methods <ref> (Wermter, Riloff, & Scheler, 1996) </ref>. Given the successes of empirical NLP methods, researchers have recently begun to apply learning methods to the construction of information extraction systems (McCarthy & Lehnert, 1995; Soderland, Fisher, Aseltine, & Lehnert, 1995, 1996; Riloff, 1993, 1996; Kim & Moldovan, 1995; Huffmann, 1996). <p> This performance is comparable to that of Crystal on a medical domain task (Soderland et al., 1996), and better than that of AutoSlog and AutoSlog-TS on part of the MUC4 terrorism task <ref> (Riloff, 1996) </ref>. It also compares favorably with the typical system performance on the MUC tasks (ARPA, 1992, 1993). All of these comparisons are only general, since the tasks are different, but they do indicate that Rapier is doing relatively well. <p> The anchor is necessary to provide the Rapier heuristics a starting point to work from. We may, however, explore the possibility of finding words or phrases common to documents sharing a particular slot value but rare in other documents as AutoSlog-TS does <ref> (Riloff, 1996) </ref>, and then using those words or phrases as anchors for rules. A final issue which we need to address in the Rapier system is that of identifying relevant documents. <p> This is one reason why a human expert is necessary to examine the validity of the patterns generated. A newer version-AutoSlog-TS <ref> (Riloff, 1996) </ref>-generates potentially useful patterns by using statistics about those patterns matching relevant and irrelevant documents.
Reference: <author> Salton, G. </author> <year> (1989). </year> <title> Automatic Text Processing: The Transformation, Analysis and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley. </publisher>
Reference: <author> Seung, H. S., Opper, M., & Sompolinsky, H. </author> <year> (1992). </year> <title> Query by committee.. </title> <booktitle> In Proceedings of the ACM Workshop on Computational Learning Theory Pittsburgh, </booktitle> <address> PA. </address>
Reference-contexts: By singling out only such potentially informative examples for annotation, equivalent accuracy can be gained from labelling significantly fewer examples compared to random selection. We intend to apply selective sampling by using a version of Query by Committee <ref> (Seung et al., 1992) </ref>: Initialize the committee to two hypotheses formed from some initial labelled data For each unlabelled example do If the two committee members disagree on its label 18 Then Request the label of the example, add it to the training set, a nd Update the two hypotheses to
Reference: <author> Soderland, S., Fisher, D., Aseltine, J., & Lehnert, W. </author> <year> (1995). </year> <title> Crystal: Inducing a conceptual dictionary. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 1314-1319. </pages>
Reference-contexts: Information extraction can be useful in a variety of domains. The various MUC's have focused on tasks such as Latin American terrorism, joint ventures, microelectronics, and company management changes. Others have used information extraction to track medical patient records <ref> (Soderland et al., 1995) </ref> and to track company mergers (Huffmann, 1996). <p> A human must determine which slot a given extraction pattern is for, and as with the earlier system a human must go through the generated patterns and select those that will actually be used by the system. Crystal <ref> (Soderland et al., 1995, 1996) </ref> is a more recent attempt to apply machine learning to the creation of information extraction patterns. Its training instances are created by a sentence analyzer which identifies syntactic constituents such as subject, verb, object and tags each word with a semantic class.
Reference: <author> Soderland, S., Fisher, D., Aseltine, J., & Lehnert, W. </author> <year> (1996). </year> <title> Issues in inductive learning of domain-specific text extraction rules. </title> <editor> In Wermter, S., Riloff, E., & Scheller, G. (Eds.), </editor> <title> Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing, </title> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <pages> pp. 290-301. </pages> <publisher> Springer. </publisher>
Reference-contexts: These numbers look quite promising when compared to the measured performance of other information extraction systems on various domains. This performance is comparable to that of Crystal on a medical domain task <ref> (Soderland et al., 1996) </ref>, and better than that of AutoSlog and AutoSlog-TS on part of the MUC4 terrorism task (Riloff, 1996). It also compares favorably with the typical system performance on the MUC tasks (ARPA, 1992, 1993).
Reference: <author> Srinivasan, A., Muggleton, S., Sternberg, M., & King, R. </author> <year> (1996). </year> <title> Theories for mutagenicity: A study in first-order and feature-based induction. </title> <journal> Artificial Intelligence, </journal> <volume> 85, </volume> <pages> 277-300. </pages>
Reference: <author> Thompson, C. A. </author> <year> (1995). </year> <title> Acquisition of a lexicon from semantic representations of sentences. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. </pages> <address> 335-337 Cambridge, MA. </address>
Reference-contexts: The architecture for such a complete system is shown in figure 3. A query parser can be learned using Chill (Zelle & Mooney, 1996), a system which learns parsers from example sentences paired with their parses, and a semantic lexicon could be produced using Wolfie <ref> (Thompson, 1995) </ref>, a system which learns a lexicon from sentences paired with their semantic representations. Information extraction systems are generally complex, with several modules, some of which are very domain specific. They usually incorporate parsers, specialized lexicons, and discourse processing modules to handle issues such as coreference.
Reference: <author> Weizenbaum, J. </author> <year> (1966). </year> <title> ELIZA A computer program for the study of natural language communications between men and machines. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 9, </volume> <pages> 36-45. </pages>
Reference-contexts: We do this by using a structured (relational) symbolic representation, rather than learning classifications. Using only a corpus of documents paired with filled template, Rapier learns Eliza-like patterns <ref> (Weizenbaum, 1966) </ref> that make use of limited syntactic and semantic information, using freely available, robust knowledge sources such as a part-of-speech tagger or a lexicon. The rules built from these patterns can consider an unbounded context, giving them an advantage over more limited representations. <p> database of over 50,000 words which contains a semantic hierarchy in the form of hypernym links. 8 Pre-filler Pattern: Filler Pattern: Post-filler Pattern: 1) word: leading 1) list: max length: 2 1) word: [firm, company] syntactic: [nn, nns] 3 Rapier Algorithm 3.1 Rule Representation Rapier's rule representation uses Eliza-like patterns <ref> (Weizenbaum, 1966) </ref> that make use of limited syntactic and semantic information.
Reference: <editor> Wermter, S., Riloff, E., & Scheler, G. (Eds.). </editor> <year> (1996). </year> <title> Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing. </title> <publisher> Springer Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: However, there has been relatively little recent language research using symbolic learning, although some recent systems have successfully employed decision trees (Magerman, 1995; Anoe & Bennett, 1995), transformation rules (Brill, 1993, 1995), and other symbolic methods <ref> (Wermter, Riloff, & Scheler, 1996) </ref>. Given the successes of empirical NLP methods, researchers have recently begun to apply learning methods to the construction of information extraction systems (McCarthy & Lehnert, 1995; Soderland, Fisher, Aseltine, & Lehnert, 1995, 1996; Riloff, 1993, 1996; Kim & Moldovan, 1995; Huffmann, 1996).
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1994). </year> <title> Combining top-down and bottom-up methods in inductive logic programming. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 343-351 New Brunswick, NJ. </address>
Reference-contexts: The generalization process stops when the coverage of the best clause no longer increases. 2.2.3 Chillin The Chillin <ref> (Zelle & Mooney, 1994) </ref> system combines top-down (general to specific) and bottom-up ILP techniques. The algorithm starts with a most specific definition (the set of positive examples) and introduces generalizations which make the definition more compact. Generalizations are created by selecting pairs of clauses in the definition and computing LGGs.
Reference: <author> Zelle, J. M., & Mooney, R. J. </author> <year> (1996). </year> <title> Learning to parse database queries using inductive logic programming. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence Portland, </booktitle> <address> OR. </address> <month> 26 </month>
Reference-contexts: HUM TGT: TOTAL NUMBER - 5 databases would be particularly useful as part of a complete NLP system which supported natural language querying of the system. The architecture for such a complete system is shown in figure 3. A query parser can be learned using Chill <ref> (Zelle & Mooney, 1996) </ref>, a system which learns parsers from example sentences paired with their parses, and a semantic lexicon could be produced using Wolfie (Thompson, 1995), a system which learns a lexicon from sentences paired with their semantic representations.
References-found: 49

