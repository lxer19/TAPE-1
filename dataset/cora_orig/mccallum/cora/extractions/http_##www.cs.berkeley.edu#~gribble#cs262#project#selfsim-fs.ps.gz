URL: http://www.cs.berkeley.edu/~gribble/cs262/project/selfsim-fs.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~gribble/cs262/project/
Root-URL: 
Email: fgribble,manku,brewerg@cs.berkeley.edu  
Title: Self-Similarity in File-Systems: Measurement and Applications  
Author: Steven D. Gribble, Gurmeet Singh Manku, and Eric A. Brewer 
Address: Berkeley  
Affiliation: Computer Science Division, University of California at  
Abstract: This paper demonstrates that high-level file system events are self-similar in nature. Self-similarity is detected both visually and through the use of analysis techniques such as variance-time plots and Pox plots. Two sets of file system trace data (of 1991 Sprite and 1994 NFS traffic) are analyzed; both are shown to have consistent Hurst parameters (a measure of self-similarity) for all file system traffic as well as individual classes of file system events. Sources of file system traffic are shown to exhibit ON/OFF source behaviour, which is characterized by highly variably lengthed bursts of activity, followed by similarly variably lengthed periods of inactivity. The ON/OFF behaviour of sources is used to design and implement a rudimentary but flexible and extensible file system model. File system trace data is synthesized using measured properties of the available trace data as inputs to this model. The synthesized traffic is then analyzed, and demonstrated to exhibit the correct self-similar behaviour. Finally, we demonstrate how self-similarity helps to detect idleness in file systems and predict the lengths of these idle periods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anderson, T. E., Culler, D. E., and Patterson, D. </author> <title> A case for now (networks of workstations). </title> <booktitle> IEEE Micro 12, </booktitle> <month> 1 (Feb </month> <year> 1995), </year> <pages> 54-64. </pages>
Reference-contexts: The ON/OFF behaviour of file system clients can also be used to assist in the scheduling of cleaners for file systems such as xFS [2], in which cleaning processes can potentially be spawned from any of a number of hosts within a network of workstations <ref> [1] </ref>. By monitoring the lengths of observed idle periods on a client, and by again noticing that OFF period lengths on clients have a heavy-tailed distribution, the remaining length of an observed OFF period can be characterized probabilistically.
Reference: [2] <author> Anderson, T. E., Dahlin, M. D., Neefe, J. M., Patterson, D. A., Roselli, D. S., and Wang, R. Y. </author> <title> Serverless network file systems. </title> <booktitle> In Proceedings of the 15th ACM Symposium on Operating Systems Principles (December 1995). </booktitle>
Reference-contexts: By increasing the number of clients modeled and by changing the parameters, distributions, and probabilities used as input to the model, we can easily generate loads of widely different characteristics. Our model is 3 For some file systems such as xFS <ref> [2] </ref>, even read events can change the state of the system. 9 capable of generating very large amounts of file system events which exhibit the same bulk properties as the traces from which the measured parameters are derived. 5.4 Measurement of Probabilities and Distributions In order to test our file system <p> Another example of a way to take advantage of idleness in a file system is to schedule cleaning in a log-structured file system [21] (such as xFS <ref> [2] </ref>) during idle periods. In an LFS, data is written to disk in a log-structured fashion to achieve high write performance and reliability. <p> The interarrival time distributions described in [5] are very consistent with the heavy-tailed distributions that we observed in both the NFS and Sprite traces. The ON/OFF behaviour of file system clients can also be used to assist in the scheduling of cleaners for file systems such as xFS <ref> [2] </ref>, in which cleaning processes can potentially be spawned from any of a number of hosts within a network of workstations [1].
Reference: [3] <author> Baker, M. G., Hartman, J. H., Kupfer, M. D., Shirriff, K. W., and Ousterhout, J. K. </author> <title> Measure 13 ments of a distributed file system. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles (1991). </booktitle>
Reference-contexts: The analysis of file system performance, access characteristics, and traffic patterns has received considerable attention in the past few years. In [23], the effects of file layout and fragmentation of a disk on file system performance are measured using synthesized work-loads. Baker et al. <ref> [3] </ref> analyzed the user-level file access patterns in the Sprite distributed file system using traces gathered via kernel instrumentation in a Sprite installation [13]. The design and performance of a log-structured file system is presented in [21], including the analysis of various cleaning policies. <p> The first set of traces was collected in 1991 for a study of the file access patterns and caching behaviour of the Sprite distributed file system <ref> [3] </ref>. The traces were collected on a Sprite cluster 2 of approximately 40 workstations sharing a single Eth--ernet, over eight separate 24 hour intervals. <p> This difference is easily explainable. First and foremost, files are known to be read far more frequently than they are written; from table 1 we see that approximately 13.4% of NFS files are opened with write or RW privileges, while 86.6% of files are opened with read-only privilege. Similarly, <ref> [3] </ref> reported that 88% of files within the Sprite traces were opened with read-only privilege. Secondly, many file read and write events occur in between a given file open and close pair. <p> We estimated that the ratio of file open (W) events performed on existing files to those on new files was 4.71:1. Also, the ratio of serial rewrites to random updates was estimated to be 12.9:1. Both of these estimations correspond well with previously reported values in <ref> [3] </ref>. 5.5 Model Results To test the validity of our model, we synthesized file system event time series for 20 clients and aggregated them to obtain the overall traffic for the server. <p> This cleaning process must be run periodically, and there has been considerable contention about whether or not the overhead of the cleaning process negates the utility of an LFS (see, for example, [22], <ref> [3] </ref>, or [5]). Cleaning can either be performed on demand (such as when a log-structured file system becomes full) or opportunistically in the background when idle periods are detected at the file server.
Reference: [4] <author> Beran, J., Sherman, R., Taqqu, M. S., and Will-inger, W. </author> <title> Long-range dependence in variable-bit-rate video traffic. </title> <journal> IEEE Transactions on Communications 43 (Mar. </journal> <year> 1995), </year> <pages> 1566-79. </pages>
Reference-contexts: 1 Introduction Recent studies of high quality network traces (see [16], <ref> [4] </ref>, and [19]) have revealed an unexpected property of network traffic, namely that the traffic is self-similar in nature. Intuitively, a self-similar process looks similar and bursty across all time-scales. Mathematically, the autocorrelation function of a self-similar process is invariant across all aggregated processes. <p> If the combined traffic is self-similar, this is not necessarily the case. Further studies have shown that the total traffic (measured in bytes/s or packets/s) on Ethernet LANs [16] and on WANs [20] is self-similar. Similarly, investigations into variable-bit-rate (VBR) video traffic <ref> [4] </ref> have shown that traffic to exhibit long-range dependence, which is an indicator of self-similarity. The purpose of this paper is to demonstrate the existence of self-similarity in high-level file-system events such as file opens, block writes, and file closes. <p> We borrow heavily upon the theory and analysis techniques presented in these two papers to demonstrate the presence of self-similarity in file system traffic. Self-similarity in various other types of systems (such as wide-area traffic [20], ATM networks [11], variable bit-rate video <ref> [4] </ref>, and World Wide Web traffic [7]) has been detected using similar techniques. Work has also been done on exploring efficient techniques for synthesizing self-similar traffic. <p> variance-time plots: This table summarizes the estimated values of the Hurst parameters H derived from variance-time plots of the Sprite and NFS trace data. 4.3 R/S-Analysis and Pox plots A second estimate of the Hurst parameter can be obtained through R/S analysis (originally presented in [18], and fully explained in <ref> [4] </ref>). Given a set of observations (X k : k = 1; 2; : : :; N ), that set is subdivided into K disjoint subsets of length (N=K).
Reference: [5] <author> Blackwell, T., Harris, J., and Seltzer, M. </author> <title> Heuristic cleaning algorithms in log-structured file systems. </title> <booktitle> In Proceedings of the 1995 USENIX Technical Conference (Berkeley, </booktitle> <address> CA, USA, </address> <month> Jan </month> <year> 1995), </year> <pages> pp. 277-287. </pages>
Reference-contexts: The design and performance of a log-structured file system is presented in [21], including the analysis of various cleaning policies. Algorithms for heuristically scheduling cleaning in an LFS based on idle time detection and prediction are discussed in <ref> [5] </ref>. <p> This cleaning process must be run periodically, and there has been considerable contention about whether or not the overhead of the cleaning process negates the utility of an LFS (see, for example, [22], [3], or <ref> [5] </ref>). Cleaning can either be performed on demand (such as when a log-structured file system becomes full) or opportunistically in the background when idle periods are detected at the file server. In [5] it is observed that heuristic methods can be used to identify ample background cleaning opportunities to nearly eliminate <p> the overhead of the cleaning process negates the utility of an LFS (see, for example, [22], [3], or <ref> [5] </ref>). Cleaning can either be performed on demand (such as when a log-structured file system becomes full) or opportunistically in the background when idle periods are detected at the file server. In [5] it is observed that heuristic methods can be used to identify ample background cleaning opportunities to nearly eliminate the probability that on-demand cleaning is ever required. <p> They further observed that a long observed waiting time for an event was a good predictor of an even longer expected future waiting time for that same event. The self-similar nature of file system activity explains these phenomena completely. The interarrival time distributions described in <ref> [5] </ref> are very consistent with the heavy-tailed distributions that we observed in both the NFS and Sprite traces.
Reference: [6] <author> Chen, P., and Patterson, D. </author> <title> A new approach to i/o performance evaluation - self-scaling i/o benchmarks, predicted i/o performance. </title> <journal> ACM Transactions on Computer Systems 12, </journal> <month> 4 (Nov </month> <year> 1994), </year> <pages> 308-39. </pages>
Reference-contexts: Since we base our synthesis technique on a known property of real file system traffic, the synthesized workload also exhibits this property, and is therefore more realistic. 5.2 An Ideal Model It is clear that there is a need for a scalable file-system model, such as that presented in <ref> [6] </ref>. In addition to scalability, it would be beneficial to use a representative portion of trace data as input to the model, and then output arbitrarily large amounts of file system events which exhibit the same bulk properties as the traces fed to it.
Reference: [7] <author> Crovella, M. E., and Bestavros, A. </author> <title> Explaining world wide web traffic self-similarity. </title> <type> Tech. Rep. </type> <institution> TR-95-015, Computer Science Department, Boston University, </institution> <month> Oct </month> <year> 1995. </year>
Reference-contexts: We borrow heavily upon the theory and analysis techniques presented in these two papers to demonstrate the presence of self-similarity in file system traffic. Self-similarity in various other types of systems (such as wide-area traffic [20], ATM networks [11], variable bit-rate video [4], and World Wide Web traffic <ref> [7] </ref>) has been detected using similar techniques. Work has also been done on exploring efficient techniques for synthesizing self-similar traffic.
Reference: [8] <author> Dahlin, M. D., Mather, C. J., Wang, R. Y., An-derson, T. E., and Patterson, D. A. </author> <title> A quantitative analysis of cache policies for scalable network file systems. </title> <booktitle> In Proceedings of the SIGMETRICS '94 Annual Conference on Measurement and Modeling of Computer Systems (Nashville, </booktitle> <address> Tennessee, </address> <month> May </month> <year> 1994), </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: The second set of traces used in this paper was gathered from a relatively large NFS installation served by a single Auspex file server. These traces were collected in 1994 to study the impact of different cache policies on scalable network file system performance <ref> [8] </ref>. The Auspex file server straddled four separate Ethernets, on which resided a total of 237 clients. The traces were collected by monitoring network activity on each of the four Ethernets. <p> Lastly, we justify the design of our model and then describe its details. 5.1 Why a Flexible File-System Model? Current methods for testing the efficacy of a new file system fall into two broad categories: simulation through file system trace playback (as in <ref> [8] </ref>), and simulation through the use of simple file system heuristics (for example, the repeated creation and deletion of a mix of large and small files, as in [23]). Both methods suffer from several shortcomings. As argued in [8], simulation through trace playback limits the simulation to characteristics of the file <p> into two broad categories: simulation through file system trace playback (as in <ref> [8] </ref>), and simulation through the use of simple file system heuristics (for example, the repeated creation and deletion of a mix of large and small files, as in [23]). Both methods suffer from several shortcomings. As argued in [8], simulation through trace playback limits the simulation to characteristics of the file system for which the trace was gathered. Quantities such as the number of file system clients, density of file system activity, and peak load presented to a file server cannot be easily modified.
Reference: [9] <author> Ferrari, D., and Verma, D. C. </author> <title> A scheme for real-time channel establishment in wide-area networks. </title> <journal> IEEE Journal on Selected Areas in Communications 8, </journal> <month> 3 (Apr. </month> <year> 1990), </year> <pages> 368-379. </pages>
Reference-contexts: A common assumption in the design of networks and operating systems is that the aggregation of a large number of bursty sources tends to be smooth. For example, statistical admissions criteria in real-time channel establishment (see, for example, <ref> [9] </ref> or [10]) assume that while an individual source may exceed its average resource requirements at any given time, the aggregate resource requirements across many such sources has a low variance. If the combined traffic is self-similar, this is not necessarily the case.
Reference: [10] <author> Gemmell, D. J., Vin, H. M., Kandlur, D. D., Ran-gan, P. V., and Rowe, L. A. </author> <title> Multimedia storage servers: a tutorial. </title> <booktitle> Computer 28, </booktitle> <month> 5 (May </month> <year> 1995), </year> <pages> 40-49. </pages>
Reference-contexts: A common assumption in the design of networks and operating systems is that the aggregation of a large number of bursty sources tends to be smooth. For example, statistical admissions criteria in real-time channel establishment (see, for example, [9] or <ref> [10] </ref>) assume that while an individual source may exceed its average resource requirements at any given time, the aggregate resource requirements across many such sources has a low variance. If the combined traffic is self-similar, this is not necessarily the case.
Reference: [11] <author> Georganas, N. D. </author> <title> Self-similar ("fractal") traffic in atm networks. </title> <booktitle> In Proceedings of the 2nd International Workshop on Advanced Teleservices and High-Speed Communications Architectures (IWACA '94) (Heidel-berg, </booktitle> <address> Germany, </address> <month> Sept. </month> <year> 1994), </year> <pages> pp. 1-7. </pages>
Reference-contexts: We borrow heavily upon the theory and analysis techniques presented in these two papers to demonstrate the presence of self-similarity in file system traffic. Self-similarity in various other types of systems (such as wide-area traffic [20], ATM networks <ref> [11] </ref>, variable bit-rate video [4], and World Wide Web traffic [7]) has been detected using similar techniques. Work has also been done on exploring efficient techniques for synthesizing self-similar traffic. <p> Note that the plot for the smallest time scale (1f) shows discretization artifacts, due to the small number of events arriving per time unit. The finite capabilities of computer systems intrinsically limit the file system event arrival rate; file system events are thus only asymptotically self-similar (as defined in <ref> [11] </ref>) in the limit of large time scales. hours worth of open events were analyzed, resulting in 232076 open (R) events, 21326 open (W) events, and 12643 open (RW) events. 3 increasingly refined time units, varying by a total factor of 150. 4.2 Variance-time plots We can take advantage of equation
Reference: [12] <author> Golding, R., Bosch, P., Staelin, C., Sullivan, T., and Wilkes, J. </author> <title> Idleness is not sloth. </title> <booktitle> In Proceedings of the 1995 USENIX Technical Conference (Berkeley, </booktitle> <address> CA, USA, </address> <month> Jan </month> <year> 1995), </year> <pages> pp. 201-212. </pages>
Reference-contexts: times, the time between file open and close events, and file sizes are all represented well by a Pareto distribution. * the ON/OFF behaviour of file system clients can be used to model aggregate file system traffic that exhibits self-similarity. 6 Self-similarity and Idleness in File Systems Golding et al. <ref> [12] </ref> have argued that idleness in a file system can be exploited in many ways. For example, activity during busy periods can be o*oaded to more idle periods in order to improve the responsiveness of the file system.
Reference: [13] <author> Hartman, J. H. </author> <title> Using the Sprite file system traces. </title> <institution> Computer Science Division, EECS Department, University of California at Berkeley, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: In [23], the effects of file layout and fragmentation of a disk on file system performance are measured using synthesized work-loads. Baker et al. [3] analyzed the user-level file access patterns in the Sprite distributed file system using traces gathered via kernel instrumentation in a Sprite installation <ref> [13] </ref>. The design and performance of a log-structured file system is presented in [21], including the analysis of various cleaning policies. Algorithms for heuristically scheduling cleaning in an LFS based on idle time detection and prediction are discussed in [5].
Reference: [14] <author> Huang, C., Devetsikiotis, M., Lambadaris, I., and Kaye, A. R. </author> <title> Modeling and Simulation of Self-Similar Variable Bit Rate Compressed Video: A Unified Approach. </title> <booktitle> In ACM SIGCOMM '95 Conference on Communications Architectures, Protocols and Applications (Cambridge, </booktitle> <address> MA, USA, </address> <year> 1995). </year>
Reference-contexts: Self-similarity in various other types of systems (such as wide-area traffic [20], ATM networks [11], variable bit-rate video [4], and World Wide Web traffic [7]) has been detected using similar techniques. Work has also been done on exploring efficient techniques for synthesizing self-similar traffic. In <ref> [14] </ref>, self-similar variable bit rate compressed video is modeled and synthesized, and in [19], a fast Fourier transform method for rapid and efficient synthesis of self-similar network traffic is presented.
Reference: [15] <author> Kratz, M. F., and Resnick, S. I. </author> <title> The qq-estimator and heavy tails. </title> <type> Preprint, </type> <year> 1995. </year>
Reference: [16] <author> Leland, W. E., Taqqu, M. S., Willinger, W., and Wilson, D. V. </author> <title> On the self-similar nature of Ethernet traffic (extended version). </title> <journal> IEEE/ACM Transactions on Networking 2 (Feb. </journal> <year> 1994). </year>
Reference-contexts: 1 Introduction Recent studies of high quality network traces (see <ref> [16] </ref>, [4], and [19]) have revealed an unexpected property of network traffic, namely that the traffic is self-similar in nature. Intuitively, a self-similar process looks similar and bursty across all time-scales. Mathematically, the autocorrelation function of a self-similar process is invariant across all aggregated processes. <p> If the combined traffic is self-similar, this is not necessarily the case. Further studies have shown that the total traffic (measured in bytes/s or packets/s) on Ethernet LANs <ref> [16] </ref> and on WANs [20] is self-similar. Similarly, investigations into variable-bit-rate (VBR) video traffic [4] have shown that traffic to exhibit long-range dependence, which is an indicator of self-similarity. <p> Applications of self-similarity to detecting idleness in file systems are discussed in section 6. Finally, a summary of this paper is presented and general conclusions drawn in section 7. 2 Related Work The study of self-similarity in computer networks was pioneered by the work of Leland et al. <ref> [16] </ref>, in which they demonstrated that Ethernet traffic was self-similar in nature. Further work showed that the self-similarity could be attributed to the ON/OFF behaviour of traffic sources within their system [26]. <p> A more thorough treatment can be found in <ref> [16] </ref>, [26], or [20]; the goal of this section is to outline the enough of the theory to motivate the methodology discussed in 4. <p> As described in <ref> [16] </ref>, self-similar processes provide an explanation for an empirical law known as the Hurst effect.
Reference: [17] <author> Mandelbrot, B. </author> <title> Self-similar error clusters in communication systems and the concept of conditional station-arity. </title> <journal> IEEE Transactions on Communication Technology COM-13 (1965). </journal>
Reference-contexts: However, we have not yet attempted to explain the underlying cause of this observed phenomenon. Willinger et al.[26] proposed a physical explanation of observed self-similarity in Ethernet LAN traffic, based on theory developed initially by Mandelbrot <ref> [17] </ref> and Taqqu and Levy [24]. The theory states that the aggregation of many ON/OFF sources, each exhibiting a characteristic known as the Noah effect, results in self-similar total traffic.
Reference: [18] <author> Mandelbrot, B. B., and Wallis, J. R. </author> <title> Computer experiments with fractional gaussian noises. </title> <booktitle> Water Resources Research 5 (1969), </booktitle> <pages> 228-267. </pages>
Reference-contexts: 2: Estimates of H from variance-time plots: This table summarizes the estimated values of the Hurst parameters H derived from variance-time plots of the Sprite and NFS trace data. 4.3 R/S-Analysis and Pox plots A second estimate of the Hurst parameter can be obtained through R/S analysis (originally presented in <ref> [18] </ref>, and fully explained in [4]). Given a set of observations (X k : k = 1; 2; : : :; N ), that set is subdivided into K disjoint subsets of length (N=K).
Reference: [19] <author> Paxson, V. </author> <title> Fast approximation of self-similar network traffic. </title> <type> Tech. rep., </type> <institution> Lawrence Berkeley Laboratory and EECS Division, University of California, Berkeley, </institution> <address> 1 Cyclotron Road, Berkeley, CA 94720, </address> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Recent studies of high quality network traces (see [16], [4], and <ref> [19] </ref>) have revealed an unexpected property of network traffic, namely that the traffic is self-similar in nature. Intuitively, a self-similar process looks similar and bursty across all time-scales. Mathematically, the autocorrelation function of a self-similar process is invariant across all aggregated processes. <p> Work has also been done on exploring efficient techniques for synthesizing self-similar traffic. In [14], self-similar variable bit rate compressed video is modeled and synthesized, and in <ref> [19] </ref>, a fast Fourier transform method for rapid and efficient synthesis of self-similar network traffic is presented.
Reference: [20] <author> Paxson, V., and Floyd, S. </author> <title> Wide-area traffic: the failure of Poisson modeling. </title> <booktitle> In ACM SIGCOMM '94 Conference on Communications Architectures, Protocols and Applications (London, </booktitle> <address> UK, </address> <month> Aug. </month> <year> 1994). </year>
Reference-contexts: If the combined traffic is self-similar, this is not necessarily the case. Further studies have shown that the total traffic (measured in bytes/s or packets/s) on Ethernet LANs [16] and on WANs <ref> [20] </ref> is self-similar. Similarly, investigations into variable-bit-rate (VBR) video traffic [4] have shown that traffic to exhibit long-range dependence, which is an indicator of self-similarity. The purpose of this paper is to demonstrate the existence of self-similarity in high-level file-system events such as file opens, block writes, and file closes. <p> We borrow heavily upon the theory and analysis techniques presented in these two papers to demonstrate the presence of self-similarity in file system traffic. Self-similarity in various other types of systems (such as wide-area traffic <ref> [20] </ref>, ATM networks [11], variable bit-rate video [4], and World Wide Web traffic [7]) has been detected using similar techniques. Work has also been done on exploring efficient techniques for synthesizing self-similar traffic. <p> A more thorough treatment can be found in [16], [26], or <ref> [20] </ref>; the goal of this section is to outline the enough of the theory to motivate the methodology discussed in 4. <p> Mathematically, this future expected waiting time is given by the conditional mean exceedance (CME), where we define CM E x = E [X xjX x] (18) for some random variable x <ref> [20] </ref>. For a heavy tailed distribution, the CME is a linearly increasing function of the observed waiting time x: CM E x = fi 1 Long observed waiting times can therefore be used as a reliable predictor of a long future waiting time.
Reference: [21] <author> Rosenblum, M., and Ousterhout, J. K. </author> <title> The design and implementation of a log-structured file system. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles (1991). </booktitle>
Reference-contexts: Baker et al. [3] analyzed the user-level file access patterns in the Sprite distributed file system using traces gathered via kernel instrumentation in a Sprite installation [13]. The design and performance of a log-structured file system is presented in <ref> [21] </ref>, including the analysis of various cleaning policies. Algorithms for heuristically scheduling cleaning in an LFS based on idle time detection and prediction are discussed in [5]. <p> Another example of a way to take advantage of idleness in a file system is to schedule cleaning in a log-structured file system <ref> [21] </ref> (such as xFS [2]) during idle periods. In an LFS, data is written to disk in a log-structured fashion to achieve high write performance and reliability.
Reference: [22] <author> Seltzer, M., Smith, K., Balakrishnan, H., Chang, J., et al. </author> <title> File system logging versus clustering: a performance comparison. </title> <booktitle> In Proceedings of the 1995 USENIX Technical Conference (Berkeley, </booktitle> <address> CA, USA, </address> <month> Jan </month> <year> 1995), </year> <pages> pp. 249-64. </pages>
Reference-contexts: This cleaning process must be run periodically, and there has been considerable contention about whether or not the overhead of the cleaning process negates the utility of an LFS (see, for example, <ref> [22] </ref>, [3], or [5]). Cleaning can either be performed on demand (such as when a log-structured file system becomes full) or opportunistically in the background when idle periods are detected at the file server.
Reference: [23] <author> Smith, K., and Seltzer, M. </author> <title> File layout and file system performance. </title> <type> Tech. Rep. </type> <institution> TR-35-94, Harvard University, </institution> <year> 1994. </year>
Reference-contexts: The analysis of file system performance, access characteristics, and traffic patterns has received considerable attention in the past few years. In <ref> [23] </ref>, the effects of file layout and fragmentation of a disk on file system performance are measured using synthesized work-loads. Baker et al. [3] analyzed the user-level file access patterns in the Sprite distributed file system using traces gathered via kernel instrumentation in a Sprite installation [13]. <p> for testing the efficacy of a new file system fall into two broad categories: simulation through file system trace playback (as in [8]), and simulation through the use of simple file system heuristics (for example, the repeated creation and deletion of a mix of large and small files, as in <ref> [23] </ref>). Both methods suffer from several shortcomings. As argued in [8], simulation through trace playback limits the simulation to characteristics of the file system for which the trace was gathered.
Reference: [24] <author> Taqqu, M., and Levy, J. </author> <title> Using renewal processes to generate long-range dependence and high variability. In Dependence in Probability and Statistics (Boston, </title> <address> MA, </address> <year> 1986), </year> <editor> E. Eberlein and M. Taqqu, </editor> <booktitle> Eds., </booktitle> <pages> pp. 73-89. </pages>
Reference-contexts: However, we have not yet attempted to explain the underlying cause of this observed phenomenon. Willinger et al.[26] proposed a physical explanation of observed self-similarity in Ethernet LAN traffic, based on theory developed initially by Mandelbrot [17] and Taqqu and Levy <ref> [24] </ref>. The theory states that the aggregation of many ON/OFF sources, each exhibiting a characteristic known as the Noah effect, results in self-similar total traffic. <p> The Noah effect refers to the high variability of the ON and OFF periods. If the distribution of ON and OFF period lengths from individual sources is heavy-tailed, 2 then the aggregate traffic exhibits the Noah effect, and can be shown to exhibit self-similarity. The theory presented in <ref> [24] </ref> makes the simplifying assumption that events within an ON period are evenly distributed. The ON/OFF source model is thus similar to packet-train models often used to model network sources, but with the exception that packet interarrival times must have a heavy-tailed distribution.
Reference: [25] <author> Tukey, J., and Tukey, P. </author> <title> Strips displaying empirical distributions: I. textured dot strips. </title> <type> bellcore technical memorandum. Tech. rep., </type> <year> 1990. </year>
Reference-contexts: Figure 4 presents two textured dot strip plots obtained from the Sprite and NFS traces. A textured dot strip plot (proposed in <ref> [25] </ref>) is a two-dimensional representation of a one-dimensional time-series. Each vertical column in a plot corresponds to one time unit; the displacement of dots (representing events) within that column represents the fractional position of the event in that time unit.
Reference: [26] <author> Willinger, W., Taqqu, M. S., Sherman, R., and Wilson, D. V. </author> <title> Self-similarity through high-variability: statistical analysis of ethernet lan traffic at the source level. </title> <booktitle> In ACM SIGCOMM '95 Conference on Communications Architectures, Protocols and Applications (Cambridge, </booktitle> <address> MA, USA, </address> <year> 1995). </year> <month> 14 </month>
Reference-contexts: Further work showed that the self-similarity could be attributed to the ON/OFF behaviour of traffic sources within their system <ref> [26] </ref>. We borrow heavily upon the theory and analysis techniques presented in these two papers to demonstrate the presence of self-similarity in file system traffic. <p> A more thorough treatment can be found in [16], <ref> [26] </ref>, or [20]; the goal of this section is to outline the enough of the theory to motivate the methodology discussed in 4. <p> To do so, we use a method similar to that described in <ref> [26] </ref>. The source's trace is scanned linearly; given an event from the trace, we assume that subsequent events belong to the same ON period if they occur within some threshold amount of time, otherwise we mark the interval to the next event as an OFF period. <p> The ON/OFF period size distributions were calculated for the Sprite file open (W) events, using a threshold value of 60 seconds. The resulting number of ON and OFF periods was 182 and 181, respectively. It is shown in <ref> [26] </ref> that if both the ON and OFF period length distributions are heavy-tailed, i.e. they satisfy P (U &gt; u) ~ cu ff with u ! 1; 1 &lt; ff &lt; 2; (14) for period length U, and if the activity within an ON-period is uniform, then the aggregation of many
References-found: 26

