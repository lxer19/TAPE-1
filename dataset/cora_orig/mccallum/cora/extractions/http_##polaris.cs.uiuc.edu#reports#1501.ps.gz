URL: http://polaris.cs.uiuc.edu/reports/1501.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Title: IMPLEMENTATION OF RUN TIME TECHNIQUES IN THE POLARIS FORTRAN RESTRUCTURER  
Author: BY THOMAS ROBERT LAWRENCE B. A., 
Degree: THESIS Submitted in partial fulfillment of the requirements for the degree of Master of Science in Computer Science in the Graduate College of the  
Date: 1994  
Address: Wisconsin Madison,  1996 Urbana, Illinois  
Affiliation: University of  University of Illinois at Urbana-Champaign,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer. </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference: [2] <author> M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P.Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orzag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, J. Martin. </author> <title> The PERFECT club benchmarks: Effective performance evaluation of supercomputers. </title> <type> Technical report CSRD-827, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <month> May </month> <year> 1989. </year>
Reference: [3] <author> H. Berryman, J. Saltz. </author> <title> A manual for PARTI runtime primitives. </title> <type> Interim Report. 90-30, </type> <institution> ICASE, </institution> <year> 1990. </year>
Reference-contexts: Then the lists are linked across processors and analyzed in a manner similar to that proposed by Zhu and Yew [36]. The loop is parallelized using doacross parallelization. For loops without output dependences, Saltz et al have proposed several methods <ref> [3, 26, 28, 29, 35] </ref> which employ an inspector-executor model. The inspector performs a runtime dependence analysis and builds a schedule, and the executor performs the work according to the schedule. Some of these methods use sequential topological sorts.
Reference: [4] <author> W. Blume. </author> <title> Symbolic analysis techniques for effective automatic parallelization. </title> <type> Ph. D. Thesis. </type> <institution> University of Illinois, Urbana, IL, </institution> <year> 1995. </year>
Reference-contexts: However, in many cases, such as for formal array parameters, the size is not directly available. The following series of successively more conservative rules is used to determine the best compile time approximation of array size: 1. First, range propagation <ref> [4] </ref> is used to attempt to symbolically and intraprocedurally determine the union of subscript ranges accessed. Range propagation attempts to compute the range of values that each program expression can take on. Note that the compiler need only consider array references which are being tested. 2.
Reference: [5] <author> W. Blume, R. Eigenmann. </author> <title> Performance analysis of parallelizing compilers on the Perfect Benchmarks programs. </title> <journal> In IEEE Transactions of Parallel and Distributed Systems, </journal> <volume> 3(6), </volume> <pages> pages 643-656, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: This is known as a speculative parallelization [24]. There are some transformations which can be applied to parallelize loops which are not parallel in their initial form. Array privatization has proven to be very important in practice <ref> [5, 9, 13, 32, 33] </ref>. Array privatization breaks anti and output dependences by recognizing that no data flows between iterations when a write to an array element is followed by a read from the same element in the same iteration. <p> Such information could be used to determine whether dependence arcs are likely to be real dependences or artifacts of analysis. 3.6 Reduction Transformation and Code Generation Issues Reduction parallelization is a very important facilitating transformation <ref> [5, 9, 11, 21] </ref>. The run time compiler pass must be able to generate code for loops containing reductions. Generating efficient and correct code requires cooperation between the reduction code generator 16 and the run time pass.
Reference: [6] <author> W. Blume, R. Eigenmann, K. Faigin, J. Grout, J. Hoeflinger, D. Padua, P. Petersen, W. Pottenger, L. Rauchwerger, P. Tu, S. Weatherford. </author> <title> Polaris: Improving the effectiveness of parallelizing compilers. </title> <booktitle> In Proceedings of the Seventh Workshop on Languages and Compilers for Parallel Computing , Ithaca, NY. Also, Lecture Notes in Computer Science 892, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pages 141-154, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: If each processor is given its own copy of X, then these dependences can be broken and the loop executed in parallel. 1.4 Overview This thesis presents an implementation of the aforementioned run time parallelization techniques in the Polaris FORTRAN restructurer <ref> [6] </ref>. These techniques were developed by Lawrence Rauchwerger [23, 24, 25]. The implementation supports parallelization of DO loops in the presence of partial static analysis, privatized arrays, and reductions. Chapter 2 describes the dependence test algorithm in more detail.
Reference: [7] <author> J. Bruner. </author> <title> Convex parallelization of P3M2. </title> <type> Technical report, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: in each program were parallelized by hand with no run time overhead, and compare this performance with results obtained from using various forms of the run time test. 5.1 P3M2 Loop 100 in subroutine PP of P3M2 iterates over linked lists of bins to compute short range interactions between particles <ref> [7] </ref>. This loop consumes almost 50% of the sequential execution time. Some manual modification of the loop was necessary. In particular, the loop contains if-write-stop sequences which check to see if a work array is large enough, and stop the program with an error message if it is not.
Reference: [8] <author> D. Chen, P. Yew, J. Torrellas. </author> <title> An efficient algorithm for the runtime parallelization of doacross loops. </title> <booktitle> In Proceedings of Supercomputing 1994 , pages 518-527, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Their method dynamically allocates additional storage to break the output dependences and maps the array references to the new storage using indirection. Flow dependences are enforced using synchronization on the data elements with full/empty bits. Chen, Yew, and Torrellas <ref> [8] </ref> have proposed a method which performs part of the work of an inspector in private storage. Each processor builds a list of all accesses to each memory location. Then the lists are linked across processors and analyzed in a manner similar to that proposed by Zhu and Yew [36].
Reference: [9] <author> R. Eigenmann, W. Blume. </author> <title> An effectiveness study of parallelizing compiler techniques. </title> <booktitle> In Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 17-25, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: This is known as a speculative parallelization [24]. There are some transformations which can be applied to parallelize loops which are not parallel in their initial form. Array privatization has proven to be very important in practice <ref> [5, 9, 13, 32, 33] </ref>. Array privatization breaks anti and output dependences by recognizing that no data flows between iterations when a write to an array element is followed by a read from the same element in the same iteration. <p> Such information could be used to determine whether dependence arcs are likely to be real dependences or artifacts of analysis. 3.6 Reduction Transformation and Code Generation Issues Reduction parallelization is a very important facilitating transformation <ref> [5, 9, 11, 21] </ref>. The run time compiler pass must be able to generate code for loops containing reductions. Generating efficient and correct code requires cooperation between the reduction code generator 16 and the run time pass.
Reference: [10] <author> V. Krothapalli, P. Sadayappan. </author> <title> An approach to synchronization of parallel computing. </title> <booktitle> In Proceedings of 1988 International Conference on Supercomputing , pages 573-581, </booktitle> <month> June 40 </month> <year> 1988. </year>
Reference-contexts: Both methods use synchronization on shadow array elements to enforce 2 dependences. When the same array element is accessed heavily on all processors, synchronization contention can lead to severe performance degradation . Krothapalli and Sadayappan <ref> [10] </ref> present a method which removes anti and output dependences. Their method dynamically allocates additional storage to break the output dependences and maps the array references to the new storage using indirection. Flow dependences are enforced using synchronization on the data elements with full/empty bits.
Reference: [11] <author> J. Ku. </author> <title> The design of an efficient and portable interface between a parallelizing compiler and its target machine. M. S. </title> <type> Thesis. </type> <institution> University of Illinois, Urbana, IL, </institution> <year> 1995. </year>
Reference-contexts: Such information could be used to determine whether dependence arcs are likely to be real dependences or artifacts of analysis. 3.6 Reduction Transformation and Code Generation Issues Reduction parallelization is a very important facilitating transformation <ref> [5, 9, 11, 21] </ref>. The run time compiler pass must be able to generate code for loops containing reductions. Generating efficient and correct code requires cooperation between the reduction code generator 16 and the run time pass.
Reference: [12] <author> S. Leung, J. Zahorjan. </author> <title> Improving the performance of run time parallelization. </title> <booktitle> In 4th ACM Symposium on Principles and Practice of Parallel Programming , pages 83-91, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: The inspector performs a runtime dependence analysis and builds a schedule, and the executor performs the work according to the schedule. Some of these methods use sequential topological sorts. Leung and Zahorjan <ref> [12] </ref> have proposed some methods for parallelizing the inspectors of Saltz et al . Polychronopoulos [18] proposed a method where wavefronts are maximal sets of contiguous iterations rather than placing iterations in the earliest possible wavefront. Nicolau [17] has also proposed a method for disambiguating memory references at run time.
Reference: [13] <author> Z. Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture , pages 313-322, </booktitle> <year> 1992. </year>
Reference-contexts: This is known as a speculative parallelization [24]. There are some transformations which can be applied to parallelize loops which are not parallel in their initial form. Array privatization has proven to be very important in practice <ref> [5, 9, 13, 32, 33] </ref>. Array privatization breaks anti and output dependences by recognizing that no data flows between iterations when a write to an array element is followed by a read from the same element in the same iteration.
Reference: [14] <author> D. Maydan, S. Amarasinghe, M. Lam. </author> <title> Data dependence and dataflow analysis of arrays. </title> <booktitle> In Proceedings of the 5th Workshop on Programming Languages and Compilers for Parallel Computing , August 1992. </booktitle>
Reference: [15] <author> S. Midkiff, D. Padua. </author> <title> Compiler algorithms for synchronization. </title> <journal> In IEEE Transactions on Computers , C-36(12), </journal> <pages> pages 1485-1495, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: Their method schedules iterations in wavefronts. An iteration is added to a wavefront if it does not access any data referenced by a previous iteration which has not yet been assigned to a wavefront. Midkiff and Padua <ref> [15] </ref> extend the method to handle reads of the same element in multiple iterations. Both methods use synchronization on shadow array elements to enforce 2 dependences. When the same array element is accessed heavily on all processors, synchronization contention can lead to severe performance degradation .
Reference: [16] <author> D. Nicol, J. Saltz, J. Townsend. </author> <title> Delay point scheduling for irregular parallel computations. </title> <journal> In International Journal of Parallel Programming, </journal> <volume> Vol. 18, No. 1, </volume> <year> 1989. </year>
Reference: [17] <author> A. Nicolau. </author> <title> Runtime disambiguation: coping with statically unpredictable dependencies. </title> <journal> In IEEE Transactions on Computers, </journal> <volume> 38(5), </volume> <pages> pages 663-678, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Some of these methods use sequential topological sorts. Leung and Zahorjan [12] have proposed some methods for parallelizing the inspectors of Saltz et al . Polychronopoulos [18] proposed a method where wavefronts are maximal sets of contiguous iterations rather than placing iterations in the earliest possible wavefront. Nicolau <ref> [17] </ref> has also proposed a method for disambiguating memory references at run time. For a more detailed comparison of these techniques, see chapter 7 of [23]. 1.3 Brief Description of Technique Our run time dependence testing works by analyzing the access pattern of arrays as the program executes.
Reference: [18] <author> C. Polychronopoulos. </author> <title> Compiler optimizations for enhancing parallelism and their impact on architecture design. </title> <journal> In IEEE Transactions on Computers, </journal> <volume> C-37(8), </volume> <pages> pages 991-1004, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The inspector performs a runtime dependence analysis and builds a schedule, and the executor performs the work according to the schedule. Some of these methods use sequential topological sorts. Leung and Zahorjan [12] have proposed some methods for parallelizing the inspectors of Saltz et al . Polychronopoulos <ref> [18] </ref> proposed a method where wavefronts are maximal sets of contiguous iterations rather than placing iterations in the earliest possible wavefront. Nicolau [17] has also proposed a method for disambiguating memory references at run time.
Reference: [19] <author> C. Polychronopoulos. </author> <title> Advanced loop optimizations for parallel computers. </title> <booktitle> In Lecture Notes in Computer Scien ce, </booktitle> <volume> no. 297: </volume> <booktitle> Proce edings of the First International Conference on Supercomputing , pages 255-277, </booktitle> <year> 1987. </year> <editor> E. Houstis, T. Papatheodorou, C. Polychronopoulos, Editors. </editor> <publisher> Springer-Verlag, </publisher> <address> New York, NY. </address>
Reference: [20] <author> R. Ponnusamy, J. Saltz, A. Choudhary. </author> <title> Run time compilation techniques for data partitioning and communication schedule reuse. </title> <booktitle> In Proceedings of Supercomputing 1993 , pages 361-370, </booktitle> <month> November </month> <year> 1993. </year>
Reference: [21] <author> W. Pottenger. </author> <title> Induction variable substitution and reduction recognition in the Polaris parallelizing compiler. M. S. </title> <type> Thesis. </type> <institution> University of Illinois, Urbana, IL, </institution> <year> 1995. </year>
Reference-contexts: Such information could be used to determine whether dependence arcs are likely to be real dependences or artifacts of analysis. 3.6 Reduction Transformation and Code Generation Issues Reduction parallelization is a very important facilitating transformation <ref> [5, 9, 11, 21] </ref>. The run time compiler pass must be able to generate code for loops containing reductions. Generating efficient and correct code requires cooperation between the reduction code generator 16 and the run time pass.
Reference: [22] <author> L. </author> <title> Rauchwerger. </title> <journal> Personal communications. </journal> <pages> 1994-1996. </pages>
Reference-contexts: Since all write counts are summed during analysis, there is no need to keep separate counts for each iteration. 2.2.2 Marking Phase The marking phase uses the iteration number as a time stamp, rather than simply marking Boolean values in the shadow structure <ref> [22] </ref>. This allows efficient implementation of the read mark rule (A r [i] is marked only if A [i] is never written at any time during the iteration). It also allows the determination of last values even when the values were not created during the last iteration. <p> It also allows the determination of last values even when the values were not created during the last iteration. Read references to an array, such as the following: X = A (I) are converted into the following <ref> [22] </ref>: 1 IF (ASHADOW (WRITE,I) .NE. <p> If privatization is not to be used, then lines 2 through 4 can be omitted, and line 9 will reference the actual array A instead of APRIVATE . Write references to an array, such as the following: A (I) = X are converted into the following <ref> [22] </ref>: 8 1 IF (ASHADOW (WRITE,I) .NE. STAMP) THEN 2 ASHADOW (WRITE,I) = STAMP 3 AWRITECNT = AWRITECNT + 1 4 IF (ASHADOW (NOTPRIV,I) .EQ. -STAMP) THEN 5 ASHADOW (NOTPRIV,I) = STAMP 6 ENDIF 7 IF (ASHADOW (READ,I) .EQ. <p> A more flexible method of code generation would be to generate function calls to a library of test routines. These routines could be provided to the compiler, and the inliner used to inject the code <ref> [22] </ref>. This would allow alternative test algorithms to be used without modifying the compiler. 3.3 Interprocedural Considerations In order to be fully general, the compiler must be prepared to deal with subroutine and function calls. There are several issues involved. <p> And in some cases, the data type or element size of an array may change across a procedure call boundary, although standard FORTRAN does not sanction this. Procedure calls are handled according to the philosophy wherever the array goes, so goes the shadow <ref> [22] </ref>. Every time an array is passed as an argument to a subroutine or function, the shadow variables are added as additional arguments to the call. The called program unit is cloned, and formal arguments for the shadow variables are added. <p> An inspector is most useful when it can be parallelized. There is no guarantee that an inspector of this sort can be parallelized since there may still be potential data dependences with respect to the subscript computations, so a data dependence test should be applied <ref> [22] </ref>. Inspectors are more likely to be parallel since the complexity of the array references has been reduced by slicing. 3.5 Eliminating Ineligible Loops The compiler cannot transform all loops for run time parallelization. <p> However, if loop iterations are executed in increasing order on each processor, then dependences between iterations on the same processor can be ignored, since the execution order is being preserved on that processor <ref> [22, 24] </ref>. This test requires fewer conditional tests. It also assigns Boolean values to the shadow arrays instead of iteration numbers, reducing the amount of storage required. <p> This test requires fewer conditional tests. It also assigns Boolean values to the shadow arrays instead of iteration numbers, reducing the amount of storage required. The processor-wise read test code looks like this <ref> [22] </ref>: 1 IF (ASHADOW (WRITE,I) .EQ. 0) THEN 2 ASHADOW (NOTPRIV,I) = 1 3 ASHADOW (READ,I) = 1 4 APRIVATE (I) = A (I) 5 ENDIF 6 X = APRIVATE (I) If dynamic copy-in is not being used, then line 4 can be omitted. <p> If privatization is not being used, then lines 2 and 4 can be omitted and line 6 will refer to the original array. The processor wise write test code looks like this <ref> [22] </ref>: 1 IF (ASHADOW (WRITE,I) .EQ. 0) THEN 2 ASHADOW (READ,I) = 0 3 ASHADOW (WRITE,I) = 1 4 AWRITECNT = AWRITECNT + 1 5 ENDIF 6 APRIVATE (I) = X 24 If the array is not read, then line 2 can be omitted. <p> This second option would require synchronization, which would likely cause performance problems. 6.1.2 Linked Lists Another method for handling sparse access patterns is to build linked lists of shadow structures as the loop executes <ref> [22] </ref>. Starting with a zeroed shadow array, each time a new element is referenced, the corresponding record in the shadow array can be linked onto a list of records. The code to mark the shadow structure remains nearly the same. <p> One possible method of analysis would be to sort the lists on each processor, and then use parallel prefix techniques to break the lists into regions based on zones in the subscript space, then assign each processor to comparing the list fragments for each zone to look for conflicts <ref> [22] </ref>. 6.2 Reuse and Inspectors One advantage of using an inspector loop to perform the dependence test is that its result can sometimes be reused statically. <p> In particular, if static analysis indicates that the inspectors 37 result is invariant with respect to a surrounding loop, then the inspector can be hoisted from the loop <ref> [22] </ref>. One execution of the inspector can then be applied to several executions of the executor during the iterations of the enclosing loop. <p> that can determine that the access pattern traced in the inspector depends on values which are invariant with respect to surrounding loops in the program. 6.3 Interleaving Shadow and Data In loops with very poor locality properties, it is possible to interleave the shadow array elements with the data elements <ref> [22] </ref>. Currently, the shadow and data arrays occupy different contiguous areas of storage, as shown in Figure 19.
Reference: [23] <author> L. Rauchwerger. </author> <title> Runtime parallelization: a framework for parallel computation. </title> <type> Ph. D. Thesis. </type> <institution> University of Illinois, Urbana, IL, </institution> <year> 1995. </year>
Reference-contexts: Polychronopoulos [18] proposed a method where wavefronts are maximal sets of contiguous iterations rather than placing iterations in the earliest possible wavefront. Nicolau [17] has also proposed a method for disambiguating memory references at run time. For a more detailed comparison of these techniques, see chapter 7 of <ref> [23] </ref>. 1.3 Brief Description of Technique Our run time dependence testing works by analyzing the access pattern of arrays as the program executes. Code is inserted into the program which detects the presence of data dependences. This can be accomplished in two ways. <p> If each processor is given its own copy of X, then these dependences can be broken and the loop executed in parallel. 1.4 Overview This thesis presents an implementation of the aforementioned run time parallelization techniques in the Polaris FORTRAN restructurer [6]. These techniques were developed by Lawrence Rauchwerger <ref> [23, 24, 25] </ref>. The implementation supports parallelization of DO loops in the presence of partial static analysis, privatized arrays, and reductions. Chapter 2 describes the dependence test algorithm in more detail. Chapter 3 discusses various details that an implementation must support in order to provide practical capabilities. <p> Also, the base algorithm implemented in the Polaris FORTRAN restructurer for the Silicon Graphics Challenge machine is presented. 2.1 Generalized Algorithm This section describes how dependence testing is done in a loop which has been speculatively executed in parallel <ref> [23, 24, 25] </ref>. This test will determine whether any such dependences exist, but it will not identify where they are. The most general form of the test is presented below, which determines if a shared variable that has been privatized has any cross-iteration dependences.
Reference: [24] <author> L. Rauchwerger, D. Padua. </author> <title> The LRPD Test: speculative runtime parallelization of loops with privatization and reduction parallelization. </title> <booktitle> In Proceedings of the SIGPLAN 1995 Conference on Programming Language Design and Implementation , June 1995. </booktitle> <pages> 41 </pages>
Reference-contexts: If dependences are found, then the execution is undone by restoring the original values of modified variables, or discarding privatized copies, and the loop is re-executed sequentially. This is known as a speculative parallelization <ref> [24] </ref>. There are some transformations which can be applied to parallelize loops which are not parallel in their initial form. Array privatization has proven to be very important in practice [5, 9, 13, 32, 33]. <p> If each processor is given its own copy of X, then these dependences can be broken and the loop executed in parallel. 1.4 Overview This thesis presents an implementation of the aforementioned run time parallelization techniques in the Polaris FORTRAN restructurer [6]. These techniques were developed by Lawrence Rauchwerger <ref> [23, 24, 25] </ref>. The implementation supports parallelization of DO loops in the presence of partial static analysis, privatized arrays, and reductions. Chapter 2 describes the dependence test algorithm in more detail. Chapter 3 discusses various details that an implementation must support in order to provide practical capabilities. <p> Also, the base algorithm implemented in the Polaris FORTRAN restructurer for the Silicon Graphics Challenge machine is presented. 2.1 Generalized Algorithm This section describes how dependence testing is done in a loop which has been speculatively executed in parallel <ref> [23, 24, 25] </ref>. This test will determine whether any such dependences exist, but it will not identify where they are. The most general form of the test is presented below, which determines if a shared variable that has been privatized has any cross-iteration dependences. <p> However, if loop iterations are executed in increasing order on each processor, then dependences between iterations on the same processor can be ignored, since the execution order is being preserved on that processor <ref> [22, 24] </ref>. This test requires fewer conditional tests. It also assigns Boolean values to the shadow arrays instead of iteration numbers, reducing the amount of storage required. <p> There were some other lessons learned from the project as well. The first lesson is that it is problematic to trade computation time for memory usage on modern machines. The results reported in <ref> [24, 25] </ref> were obtained on Alliant FX-80 and FX-2800 hardware. Memory references were very cheap compared to computation on these machines. Interprocessor communication was perhaps the cheapest operation of all, owing to the shared cache and hardware synchronization support. On modern machines, the situation is turned on its head.
Reference: [25] <author> L. Rauchwerger, D. Padua. </author> <title> The privatizing doall test: A runtime technique for doall loop identification and array privatization. </title> <booktitle> In Proceedings of the 1994 ACM International Conference on Supercomputing, </booktitle> <address> Manchester England, </address> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Code is inserted into the program which detects the presence of data dependences. This can be accomplished in two ways. First, an inspector containing only the array subscript computation can be extracted from the original loop <ref> [25, 26] </ref>. The inspector can be executed to determine the access pattern without actually modifying program data. Based on the dependence analysis of the access pattern from the inspector, either a fully parallel or sequential executor is selected. <p> If each processor is given its own copy of X, then these dependences can be broken and the loop executed in parallel. 1.4 Overview This thesis presents an implementation of the aforementioned run time parallelization techniques in the Polaris FORTRAN restructurer [6]. These techniques were developed by Lawrence Rauchwerger <ref> [23, 24, 25] </ref>. The implementation supports parallelization of DO loops in the presence of partial static analysis, privatized arrays, and reductions. Chapter 2 describes the dependence test algorithm in more detail. Chapter 3 discusses various details that an implementation must support in order to provide practical capabilities. <p> Also, the base algorithm implemented in the Polaris FORTRAN restructurer for the Silicon Graphics Challenge machine is presented. 2.1 Generalized Algorithm This section describes how dependence testing is done in a loop which has been speculatively executed in parallel <ref> [23, 24, 25] </ref>. This test will determine whether any such dependences exist, but it will not identify where they are. The most general form of the test is presented below, which determines if a shared variable that has been privatized has any cross-iteration dependences. <p> Alternatively, there may be a small set of distinct access patterns which manifest themselves on alternate loop executions. In these cases, schedule reuse can be used to amortize the analysis of each distinct access pattern over all the loop executions <ref> [25, 26] </ref>. If the loop is executed many times, the analysis cost may nearly disappear. In order to apply schedule reuse, the compiler must first determine if reuse is even applicable to the loop. <p> In these cases, it might be more advantageous to pay a larger overhead per element for marking and analysis, but reduce the number of elements stored and analyzed. 6.1.1 Hash Tables A hash table <ref> [25] </ref> provides fairly efficient and compact access to sparse data. For the run time test, a hash table shadow structure would use the array subscript as a key and would store records for elements that had been accessed in the table. <p> There were some other lessons learned from the project as well. The first lesson is that it is problematic to trade computation time for memory usage on modern machines. The results reported in <ref> [24, 25] </ref> were obtained on Alliant FX-80 and FX-2800 hardware. Memory references were very cheap compared to computation on these machines. Interprocessor communication was perhaps the cheapest operation of all, owing to the shared cache and hardware synchronization support. On modern machines, the situation is turned on its head.
Reference: [26] <author> J. Saltz, R. Mirchandaney, K. Crowley. </author> <title> Run time parallelization and scheduling of loops. </title> <journal> In IEEE Transactions on Computers, </journal> <volume> 40(5), </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: Then the lists are linked across processors and analyzed in a manner similar to that proposed by Zhu and Yew [36]. The loop is parallelized using doacross parallelization. For loops without output dependences, Saltz et al have proposed several methods <ref> [3, 26, 28, 29, 35] </ref> which employ an inspector-executor model. The inspector performs a runtime dependence analysis and builds a schedule, and the executor performs the work according to the schedule. Some of these methods use sequential topological sorts. <p> Code is inserted into the program which detects the presence of data dependences. This can be accomplished in two ways. First, an inspector containing only the array subscript computation can be extracted from the original loop <ref> [25, 26] </ref>. The inspector can be executed to determine the access pattern without actually modifying program data. Based on the dependence analysis of the access pattern from the inspector, either a fully parallel or sequential executor is selected. <p> Alternatively, there may be a small set of distinct access patterns which manifest themselves on alternate loop executions. In these cases, schedule reuse can be used to amortize the analysis of each distinct access pattern over all the loop executions <ref> [25, 26] </ref>. If the loop is executed many times, the analysis cost may nearly disappear. In order to apply schedule reuse, the compiler must first determine if reuse is even applicable to the loop.
Reference: [27] <author> J. Saltz, K. Crowley. </author> <title> Run time scheduling and execution of loops on message passing machines. </title> <booktitle> In Journal of Parallel and Distributed Computing 8 , pages 303-312, </booktitle> <year> 1990. </year>
Reference: [28] <author> J. Saltz, R. Mirchandaney, K. Crowley. </author> <title> The preprocessed doacross loop. In Dr. </title> <editor> H. D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Paralle l Pro cessing, </booktitle> <address> St. Charles, </address> <publisher> Illinois, </publisher> <pages> August 12-16 , pages 174-178, </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Volume II - Software. </title>
Reference-contexts: Then the lists are linked across processors and analyzed in a manner similar to that proposed by Zhu and Yew [36]. The loop is parallelized using doacross parallelization. For loops without output dependences, Saltz et al have proposed several methods <ref> [3, 26, 28, 29, 35] </ref> which employ an inspector-executor model. The inspector performs a runtime dependence analysis and builds a schedule, and the executor performs the work according to the schedule. Some of these methods use sequential topological sorts.
Reference: [29] <author> J. Saltz, R. Mirchandaney, K. Crowley. </author> <title> The doconsider loop. </title> <booktitle> In Proceedings of the 1989 ACM International Conference on Supercomputing, </booktitle> <address> Crete, Greece , pages 29-40, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Then the lists are linked across processors and analyzed in a manner similar to that proposed by Zhu and Yew [36]. The loop is parallelized using doacross parallelization. For loops without output dependences, Saltz et al have proposed several methods <ref> [3, 26, 28, 29, 35] </ref> which employ an inspector-executor model. The inspector performs a runtime dependence analysis and builds a schedule, and the executor performs the work according to the schedule. Some of these methods use sequential topological sorts.
Reference: [30] <author> F. </author> <title> Tip. A survey of program slicing techniques. </title> <type> Technical report CS-R9438 1994, </type> <institution> Centrum voor Wiskunde en Informatica, </institution> <address> Amsterdam, The Netherlands. </address>
Reference-contexts: This section describes one possible way of implementing an array size inspector. The current run time implementation in Polaris does not provide this facility. The construction of an inspector loop is an application of static program slicing <ref> [30] </ref>. A set of sli cing c riteria is created for the original loop. The criteria determine the values that need to be computed. For the array size inspector, the criteria are the subscripts for array references being tested.
Reference: [31] <author> P. Tu. </author> <title> Automatic array privatization and demand-driven symbolic analysis. </title> <type> Ph. D. Thesis, </type> <institution> University of Illinois, Urbana, IL, </institution> <year> 1995. </year>
Reference-contexts: Range propagation attempts to compute the range of values that each program expression can take on. Note that the compiler need only consider array references which are being tested. 2. If intraprocedural range propagation fails, then the compiler computes the union of the access ranges provided by array privatization <ref> [31] </ref>. Privatization uses a different method for computing ranges and may find ranges which range propagation cold not find, although it often does not find ranges which range propagation can find. 13 3. If privatization range computation fails, then a conservative interprocedural range summarization is used.
Reference: [32] <author> P. Tu, D. Padua. </author> <title> Array privatization for shared and distributed memory machines. </title> <booktitle> In Proceedings of the 2nd Workshop on Languages, Compilers, and RunTime Environments for Distributed Memory Machines, </booktitle> <month> September </month> <year> 1992. </year>
Reference-contexts: This is known as a speculative parallelization [24]. There are some transformations which can be applied to parallelize loops which are not parallel in their initial form. Array privatization has proven to be very important in practice <ref> [5, 9, 13, 32, 33] </ref>. Array privatization breaks anti and output dependences by recognizing that no data flows between iterations when a write to an array element is followed by a read from the same element in the same iteration.
Reference: [33] <author> P. Tu, D. Padua. </author> <title> Automatic array privatization. </title> <booktitle> In Proceedings of the 6th Annual Workshop on Languages and Compilers for Parallel Computing , Portland, </booktitle> <address> OR, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: This is known as a speculative parallelization [24]. There are some transformations which can be applied to parallelize loops which are not parallel in their initial form. Array privatization has proven to be very important in practice <ref> [5, 9, 13, 32, 33] </ref>. Array privatization breaks anti and output dependences by recognizing that no data flows between iterations when a write to an array element is followed by a read from the same element in the same iteration.
Reference: [34] <author> M. Wolfe. </author> <title> Optimizing Compilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference: [35] <author> J. Wu, J. Saltz, S. Hiranandani, H. Berryman. </author> <title> Run time compilation methods for multicomputers. In Dr. </title> <editor> H. D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Pro cessing, </booktitle> <address> St. Charles, </address> <publisher> Illinois, </publisher> <pages> August 12-16 , pages 26-30, </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Volume II - Software. </title>
Reference-contexts: Then the lists are linked across processors and analyzed in a manner similar to that proposed by Zhu and Yew [36]. The loop is parallelized using doacross parallelization. For loops without output dependences, Saltz et al have proposed several methods <ref> [3, 26, 28, 29, 35] </ref> which employ an inspector-executor model. The inspector performs a runtime dependence analysis and builds a schedule, and the executor performs the work according to the schedule. Some of these methods use sequential topological sorts.
Reference: [36] <author> C. Zhu, P. Yew. </author> <title> A scheme to enforce data dependence on large multiprocessor systems. </title> <journal> In IEEE Transactions on Software Engineering , 13(6), </journal> <pages> pages 726-739, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: This analysis determines whether the iterations of a loop can be executed in parallel or must be executed sequentially. In the example above, the contents of K can be analyzed at run time to determine if any output dependences actually exist. 1.2 Prior Work Zhu and Yew <ref> [36] </ref> proposed one of the earliest methods for parallelizing loops at run time. Their method schedules iterations in wavefronts. An iteration is added to a wavefront if it does not access any data referenced by a previous iteration which has not yet been assigned to a wavefront. <p> Each processor builds a list of all accesses to each memory location. Then the lists are linked across processors and analyzed in a manner similar to that proposed by Zhu and Yew <ref> [36] </ref>. The loop is parallelized using doacross parallelization. For loops without output dependences, Saltz et al have proposed several methods [3, 26, 28, 29, 35] which employ an inspector-executor model.
Reference: [37] <author> H. Zima. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1991. </year>
References-found: 37

