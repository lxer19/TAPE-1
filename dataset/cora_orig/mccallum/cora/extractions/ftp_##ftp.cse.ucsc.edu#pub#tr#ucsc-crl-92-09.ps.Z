URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-92-09.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Email: cabrera@almaden.ibm.com  Internet: darrell@cis.ucsc.edu  
Title: Using Data Striping in a Local Area Network  
Author: Luis-Felipe Cabrera Darrell D. E. Long 
Address: Internet:  Santa Cruz  
Affiliation: IBM Almaden Research Center Computer Science Department  Computer Information Sciences University of California at  
Abstract: We use the technique of storing the data of a single object across several storage servers, called data striping, to achieve high transfer data rates in a local area network. Using parallel paths to data allows a client to transfer data to and from storage at a higher rate than that supported by a single storage server. We have implemented a network data service, called Swift, that uses data striping. Swift exhibits the expected scaling property in the number of storage servers connected to a network and in the number of interconnection networks present in the system. We have also simulated a version of Swift to explore the limits of possible future configurations. We observe that the system can evolve to support very high speed interconnection networks as well as large numbers of storage servers. Since Swift is a distributed system made up of independently replaceable components, any component that limits the performance can either be replaced by a faster component when it becomes available or can be replicated and used in parallel. This should allow the system to incorporate and exploit emerging storage and networking technologies.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. C. </author> <title> Luther, Digital Video in the PC Environment. M c Graw-Hill, </title> <year> 1989. </year>
Reference-contexts: For example, multimedia applications that require this level of service include scientific visualization, image processing, and recording and play back of color video. The data rates required by some of these applications range from 1:2 1 megabytes/second for DVI compressed video and 1:4 megabits/second for CD-quality audio <ref> [1] </ref>, and up to 90 megabytes/second for uncompressed full-frame color video.
Reference: [2] <author> K. Salem and H. Garcia-Molina, </author> <title> Disk striping, </title> <booktitle> in Proceeding of the 2 nd International Conference on Data Engineering, </booktitle> <pages> pp. 336-342, </pages> <publisher> IEEE, </publisher> <month> Feb. </month> <year> 1986. </year>
Reference-contexts: The data rates required by some of these applications range from 1:2 1 megabytes/second for DVI compressed video and 1:4 megabits/second for CD-quality audio [1], and up to 90 megabytes/second for uncompressed full-frame color video. Using data striping <ref> [2] </ref>, a technique that distributes the data of an individual object over several storage servers, we have built a system, called Swift, that addresses the problem of data rate mismatches between the requirements of an application, storage devices, and the interconnection medium. <p> explains why the pure read data rates did not increase as much as the write data rates did, even though both the network interconnection medium and the disk storage subsystem had spare capacity. 17 18 5 Related Research The notion of disk striping was formally introduced by Salem and Garcia-Molina <ref> [2] </ref>. The technique, however, has been in use for many years in the I/O subsystems of super computers [11] and high-performance mainframe systems [9]. Disk striping has also been used in some versions of the UNIX operating system as a means of improving swapping performance [2]. <p> introduced by Salem and Garcia-Molina <ref> [2] </ref>. The technique, however, has been in use for many years in the I/O subsystems of super computers [11] and high-performance mainframe systems [9]. Disk striping has also been used in some versions of the UNIX operating system as a means of improving swapping performance [2]. To our knowledge, Swift is the first to use disk striping in a distributed environment, striping files over multiple servers in a local-area network.
Reference: [3] <author> D. Patterson, G. Gibson, and R. Katz, </author> <title> A case for redundant arrays of inexpensive disks (RAID), </title> <booktitle> in Proceedings of the ACM SIGMOD Conference, </booktitle> <publisher> (Chicago), </publisher> <pages> pp. 109-116, </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1988. </year>
Reference-contexts: In addition, Swift has the flexibility to use any appropriate storage technology, including a disk array, or other high-performance storage devices such as an array of tapes. However, much like RAID <ref> [3] </ref>, Swift drives storage servers in parallel to provide high data rates. In [4] we have described the underlying I/O architecture of this system. Swift was build using the UNIX 1 operating system. The prototype provides a UNIX-like file system interface, that includes open, close, read, write and seek. <p> In Swift, sets of storage servers work concurrently to satisfy the requests made by clients. Several concurrent I/O architectures, such as Imprimis ArrayMaster [4], DataVault [5], CFS [6], RADD [7] and RAID <ref> [3, 8] </ref>, are based on this observation. Mainframes [9, 10] and super computers [11] have also exploited this approach. Swift is a client/server system made up of independently replaceable components. Clients are connected to sets of storage servers through an interconnection medium. <p> The accepted solution for this problem is to use redundant data, including multiple copy [12] and computed copy (erasure-correcting codes) <ref> [3] </ref>. While either choice is compatible with our system, the prototype will use computed copy redundancy (in the form of parity). <p> For all of these the maximum data rate is limited by the interconnection medium which is an I/O channel. Higher data rates can be achieved by using multiple I/O channels. The aggregation of data rates used in Swift generalizes that proposed by the RAID disk array system <ref> [3, 8] </ref> in its ability to support data rates beyond that of the single disk array controller. In fact, Swift can concurrently drive a collection of RAIDs as high speed devices.
Reference: [4] <author> L.-F. Cabrera and D. D. E. Long, Swift: </author> <title> Using distributed disk striping to provide high i/o data rates, </title> <journal> Computing Systems, </journal> <volume> vol. 4, </volume> <pages> pp. 407-438, </pages> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: In addition, Swift has the flexibility to use any appropriate storage technology, including a disk array, or other high-performance storage devices such as an array of tapes. However, much like RAID [3], Swift drives storage servers in parallel to provide high data rates. In <ref> [4] </ref> we have described the underlying I/O architecture of this system. Swift was build using the UNIX 1 operating system. The prototype provides a UNIX-like file system interface, that includes open, close, read, write and seek. <p> The principle behind Swift is simple: aggregate many (slow) storage devices into a faster logical storage service, making all applications unaware of this aggregation. In Swift, sets of storage servers work concurrently to satisfy the requests made by clients. Several concurrent I/O architectures, such as Imprimis ArrayMaster <ref> [4] </ref>, DataVault [5], CFS [6], RADD [7] and RAID [3, 8], are based on this observation. Mainframes [9, 10] and super computers [11] have also exploited this approach. Swift is a client/server system made up of independently replaceable components. <p> A generator process creates client requests using an exponential distribution to govern request interarrival times. The client requests are differentiated according to pure read, pure write, and a conservative read-to-write ratio of 4:1 <ref> [4] </ref>. There is no modeling of overlapping execution, instead requests are modeled serially: only after a request has completed is the next issued. In our simulation of Swift, for a read operation, a small request packet is multicast to the storage servers. <p> The time to transfer a block consists of the seek time, the rotational delay and the time to transfer the data from disk. The seek time and rotational latency are assumed to be independent uniform random variables, a pessimistic assumption when advanced layout policies are used <ref> [4] </ref>. Once a block has been read from disk it is scheduled for transmission over the network. 4.2 Simulation Results The simulator gave us the ability to determine what data rates were possible given a configuration of processors, interconnection medium and storage devices. <p> Examples of some commercial systems that utilize disk striping include super computers [11], DataVault for the CM-2 [5], the airline reservation system TPF [9], the IBM AS/400 [10], CFS from Intel [6], and the Imprimis ArrayMaster <ref> [4] </ref>. Hewlett-Packard is developing a system called DataMesh that uses an array of storage processors connected by a high-speed switched network [4]. For all of these the maximum data rate is limited by the interconnection medium which is an I/O channel. <p> disk striping include super computers [11], DataVault for the CM-2 [5], the airline reservation system TPF [9], the IBM AS/400 [10], CFS from Intel [6], and the Imprimis ArrayMaster <ref> [4] </ref>. Hewlett-Packard is developing a system called DataMesh that uses an array of storage processors connected by a high-speed switched network [4]. For all of these the maximum data rate is limited by the interconnection medium which is an I/O channel. Higher data rates can be achieved by using multiple I/O channels.
Reference: [5] <author> Thinking Machines, </author> <title> Incorporated, Connection Machine Model CM-2 Technical Summary, </title> <month> May </month> <year> 1989. </year>
Reference-contexts: The principle behind Swift is simple: aggregate many (slow) storage devices into a faster logical storage service, making all applications unaware of this aggregation. In Swift, sets of storage servers work concurrently to satisfy the requests made by clients. Several concurrent I/O architectures, such as Imprimis ArrayMaster [4], DataVault <ref> [5] </ref>, CFS [6], RADD [7] and RAID [3, 8], are based on this observation. Mainframes [9, 10] and super computers [11] have also exploited this approach. Swift is a client/server system made up of independently replaceable components. Clients are connected to sets of storage servers through an interconnection medium. <p> To our knowledge, Swift is the first to use disk striping in a distributed environment, striping files over multiple servers in a local-area network. Examples of some commercial systems that utilize disk striping include super computers [11], DataVault for the CM-2 <ref> [5] </ref>, the airline reservation system TPF [9], the IBM AS/400 [10], CFS from Intel [6], and the Imprimis ArrayMaster [4]. Hewlett-Packard is developing a system called DataMesh that uses an array of storage processors connected by a high-speed switched network [4].
Reference: [6] <author> T. W. Pratt, J. C. French, P. M. Dickens, and S. A. Janet, </author> <title> A comparison of the architecture and performance of two parallel file systems, </title> <booktitle> in Proceedings of the 4 th Conference on Hypercubes, </booktitle> <address> (Monterey), </address> <month> Mar. </month> <year> 1989. </year> <month> 21 </month>
Reference-contexts: In Swift, sets of storage servers work concurrently to satisfy the requests made by clients. Several concurrent I/O architectures, such as Imprimis ArrayMaster [4], DataVault [5], CFS <ref> [6] </ref>, RADD [7] and RAID [3, 8], are based on this observation. Mainframes [9, 10] and super computers [11] have also exploited this approach. Swift is a client/server system made up of independently replaceable components. Clients are connected to sets of storage servers through an interconnection medium. <p> Examples of some commercial systems that utilize disk striping include super computers [11], DataVault for the CM-2 [5], the airline reservation system TPF [9], the IBM AS/400 [10], CFS from Intel <ref> [6] </ref>, and the Imprimis ArrayMaster [4]. Hewlett-Packard is developing a system called DataMesh that uses an array of storage processors connected by a high-speed switched network [4]. For all of these the maximum data rate is limited by the interconnection medium which is an I/O channel.
Reference: [7] <author> M. Stonebraker and G. A. Schloss, </author> <title> Distributed RAID anew multiple copy algorithm, </title> <booktitle> in Proceedings of the 6 th International Conference on Data Engineering, </booktitle> <address> (Los Angeles), </address> <pages> pp. 430-437, </pages> <publisher> IEEE Computer Society, </publisher> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: In Swift, sets of storage servers work concurrently to satisfy the requests made by clients. Several concurrent I/O architectures, such as Imprimis ArrayMaster [4], DataVault [5], CFS [6], RADD <ref> [7] </ref> and RAID [3, 8], are based on this observation. Mainframes [9, 10] and super computers [11] have also exploited this approach. Swift is a client/server system made up of independently replaceable components. Clients are connected to sets of storage servers through an interconnection medium.
Reference: [8] <author> S. Ng, </author> <title> Pitfalls in designing disk arrays, </title> <booktitle> in Proceedings of the IEEE COMPCON Conference, </booktitle> <address> (San Francisco), </address> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: In Swift, sets of storage servers work concurrently to satisfy the requests made by clients. Several concurrent I/O architectures, such as Imprimis ArrayMaster [4], DataVault [5], CFS [6], RADD [7] and RAID <ref> [3, 8] </ref>, are based on this observation. Mainframes [9, 10] and super computers [11] have also exploited this approach. Swift is a client/server system made up of independently replaceable components. Clients are connected to sets of storage servers through an interconnection medium. <p> For all of these the maximum data rate is limited by the interconnection medium which is an I/O channel. Higher data rates can be achieved by using multiple I/O channels. The aggregation of data rates used in Swift generalizes that proposed by the RAID disk array system <ref> [3, 8] </ref> in its ability to support data rates beyond that of the single disk array controller. In fact, Swift can concurrently drive a collection of RAIDs as high speed devices.
Reference: [9] <author> IBM Corporation, </author> <title> TPF-3 Concepts and Structure Manual. </title>
Reference-contexts: In Swift, sets of storage servers work concurrently to satisfy the requests made by clients. Several concurrent I/O architectures, such as Imprimis ArrayMaster [4], DataVault [5], CFS [6], RADD [7] and RAID [3, 8], are based on this observation. Mainframes <ref> [9, 10] </ref> and super computers [11] have also exploited this approach. Swift is a client/server system made up of independently replaceable components. Clients are connected to sets of storage servers through an interconnection medium. Both the storage servers and the interconnection medium can be upgraded independently. <p> The technique, however, has been in use for many years in the I/O subsystems of super computers [11] and high-performance mainframe systems <ref> [9] </ref>. Disk striping has also been used in some versions of the UNIX operating system as a means of improving swapping performance [2]. To our knowledge, Swift is the first to use disk striping in a distributed environment, striping files over multiple servers in a local-area network. <p> To our knowledge, Swift is the first to use disk striping in a distributed environment, striping files over multiple servers in a local-area network. Examples of some commercial systems that utilize disk striping include super computers [11], DataVault for the CM-2 [5], the airline reservation system TPF <ref> [9] </ref>, the IBM AS/400 [10], CFS from Intel [6], and the Imprimis ArrayMaster [4]. Hewlett-Packard is developing a system called DataMesh that uses an array of storage processors connected by a high-speed switched network [4].
Reference: [10] <author> B. E. Clark and M. J. Corrigan, </author> <title> Application System/400 performance characteristics, </title> <journal> IBM Systems Journal, </journal> <volume> vol. 28, no. 3, </volume> <pages> pp. 407-423, </pages> <year> 1989. </year>
Reference-contexts: In Swift, sets of storage servers work concurrently to satisfy the requests made by clients. Several concurrent I/O architectures, such as Imprimis ArrayMaster [4], DataVault [5], CFS [6], RADD [7] and RAID [3, 8], are based on this observation. Mainframes <ref> [9, 10] </ref> and super computers [11] have also exploited this approach. Swift is a client/server system made up of independently replaceable components. Clients are connected to sets of storage servers through an interconnection medium. Both the storage servers and the interconnection medium can be upgraded independently. <p> Examples of some commercial systems that utilize disk striping include super computers [11], DataVault for the CM-2 [5], the airline reservation system TPF [9], the IBM AS/400 <ref> [10] </ref>, CFS from Intel [6], and the Imprimis ArrayMaster [4]. Hewlett-Packard is developing a system called DataMesh that uses an array of storage processors connected by a high-speed switched network [4]. For all of these the maximum data rate is limited by the interconnection medium which is an I/O channel.
Reference: [11] <author> O. G. Johnson, </author> <title> Three-dimensional wave equation computations on vector computers, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 72, </volume> <month> Jan. </month> <year> 1984. </year>
Reference-contexts: In Swift, sets of storage servers work concurrently to satisfy the requests made by clients. Several concurrent I/O architectures, such as Imprimis ArrayMaster [4], DataVault [5], CFS [6], RADD [7] and RAID [3, 8], are based on this observation. Mainframes [9, 10] and super computers <ref> [11] </ref> have also exploited this approach. Swift is a client/server system made up of independently replaceable components. Clients are connected to sets of storage servers through an interconnection medium. Both the storage servers and the interconnection medium can be upgraded independently. <p> The technique, however, has been in use for many years in the I/O subsystems of super computers <ref> [11] </ref> and high-performance mainframe systems [9]. Disk striping has also been used in some versions of the UNIX operating system as a means of improving swapping performance [2]. <p> To our knowledge, Swift is the first to use disk striping in a distributed environment, striping files over multiple servers in a local-area network. Examples of some commercial systems that utilize disk striping include super computers <ref> [11] </ref>, DataVault for the CM-2 [5], the airline reservation system TPF [9], the IBM AS/400 [10], CFS from Intel [6], and the Imprimis ArrayMaster [4]. Hewlett-Packard is developing a system called DataMesh that uses an array of storage processors connected by a high-speed switched network [4].
Reference: [12] <author> S. B. Davidson, H. Garcia-Molina, and D. Skeen, </author> <title> Consistency in partitioned networks, </title> <journal> Computing Surveys, </journal> <volume> vol. 17, </volume> <pages> pp. 341-370, </pages> <month> Sept. </month> <year> 1985. </year>
Reference-contexts: For example, any object which has data in a failed storage server would become unavailable, and any object that has data being written into the failed storage server 3 could be damaged. The accepted solution for this problem is to use redundant data, including multiple copy <ref> [12] </ref> and computed copy (erasure-correcting codes) [3]. While either choice is compatible with our system, the prototype will use computed copy redundancy (in the form of parity).
Reference: [13] <author> D. E. Comer, </author> <title> Internetworking with TCP/IP: Principles, Protocols, and Architecture. </title> <publisher> Prentice-Hall, </publisher> <year> 1988. </year>
Reference-contexts: Our prototype has allowed us to confirm that a high aggregate data rate can be achieved. The data transfer protocol of Swift has been built using a light-weight data transfer protocol on top of the UDP <ref> [13] </ref> datagram protocol. To avoid as much unnecessary data copying as possible, scatter-gather I/O was used to have the kernel deposit the data coming over the network directly into the buffer in the client address space. <p> This was done in an effort to allocate as much buffer space as possible to the client. The client services an open request by contacting a storage server at its advertised UDP port address. Each Swift storage server waits for open requests on a well-known UDP <ref> [13] </ref> port address. When an open request is received, a new (secondary) thread of control is established along with a private port for further communication regarding that file with the client.
Reference: [14] <author> L.-F. Cabrera, E. Hunter, M. J. Karels, and D. A. </author> <title> Mosher, User-process communication performance in networks of computers, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 14, </volume> <pages> pp. 38-53, </pages> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: The per-message network data transfer processing costs are also an important factor in the effect of the transfer unit. For example, it was assumed that protocol processing required 1500 instructions plus 1 instruction per byte in the packet <ref> [14] </ref>. As the size of the packet increases, the protocol cost decreases proportionally to the packet size. The cost of 1 instruction per byte in the packet is for the most part unavoidable, since it reflects necessary data copying.
Reference: [15] <author> J. Buzen and A. Shum, </author> <title> I/O architecture in MVS/370 and MVS/XA, </title> <journal> ICMG Transactions, </journal> <volume> vol. 54, </volume> <pages> pp. 19-26, </pages> <year> 1986. </year> <month> 22 </month>
Reference-contexts: Clients may access several independent 19 sets of storage servers. Swift incorporates data management techniques long present in centralized computing systems into a distributed environment. In particular, it can be viewed as a generalization to distributed systems of I/O channel architectures found in mainframe computers <ref> [15] </ref>. 6 Conclusions This paper presents Swift, a scalable distributed I/O system that achieves high data rates by striping data across several storage servers and driving them concurrently. The system validates the concept of distributed disk striping in a local-area network.
References-found: 15

