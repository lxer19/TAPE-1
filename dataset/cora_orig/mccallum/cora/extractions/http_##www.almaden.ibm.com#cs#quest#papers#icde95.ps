URL: http://www.almaden.ibm.com/cs/quest/papers/icde95.ps
Refering-URL: http://www.almaden.ibm.com/cs/quest/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Mining Sequential Patterns  
Author: Rakesh Agrawal Ramakrishnan Srikant 
Address: 650 Harry Road, San Jose, CA 95120  
Affiliation: IBM Almaden Research Center  
Abstract: We are given a large database of customer transactions, where each transaction consists of customer-id, transaction time, and the items bought in the transaction. We introduce the problem of mining sequential patterns over such databases. We present three algorithms to solve this problem, and empirically evaluate their performance using synthetic data. Two of the proposed algorithms, AprioriSome and Apriori-All, have comparable performance, albeit AprioriSome performs a little better when the minimum number of customers that must support a sequential pattern is low. Scale-up experiments show that both Apri-oriSome and AprioriAll scale linearly with the number of customer transactions. They also have excellent scale-up properties with respect to the number of transactions per customer and the number of items in a transaction. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proc. of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 207-216, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The sequences h (30) i, h (40) i, h (70) i, h (90) i, h (30) (40) i, h (30) (70) i and h (40 70) i, though having minimum support, are not in the answer because they are not maximal. Related Work In <ref> [1] </ref>, the problem of discovering "what items are bought together in a transaction" over basket data was introduced. While related, the problem of finding what items are bought together is concerned with finding intra-transaction patterns, whereas the problem of finding sequential patterns is concerned with inter-transaction patterns. <p> We are also simultaneously finding the set of all large 1-sequences, since this set is just fh l i j l 2 Lg. The problem of finding large itemsets in a given set of customer transactions, albeit with a slightly different definition of support, has been considered in <ref> [1] </ref> [2]. In these papers, the support for an itemset has been defined as the fraction of transactions in which an itemset is present, whereas in the sequential pattern finding problem, the support is the fraction of customers who bought the itemset in any one of their possibly many transactions.
Reference: [2] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules. </title> <booktitle> In Proc. of the VLDB Conference, </booktitle> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year> <note> Expanded version available as IBM Research Report RJ9839, </note> <month> June </month> <year> 1994. </year>
Reference-contexts: We are also simultaneously finding the set of all large 1-sequences, since this set is just fh l i j l 2 Lg. The problem of finding large itemsets in a given set of customer transactions, albeit with a slightly different definition of support, has been considered in [1] <ref> [2] </ref>. In these papers, the support for an itemset has been defined as the fraction of transactions in which an itemset is present, whereas in the sequential pattern finding problem, the support is the fraction of customers who bought the itemset in any one of their possibly many transactions. <p> It is straightforward to adapt any of the algorithms in <ref> [2] </ref> to find litemsets. The main difference is that the support count should be incremented only once per customer even if the customer buys the same set of items in two different transactions. The set of litemsets is mapped to a set of contiguous integers. <p> 1; k ) do foreach k-sequence s k do Delete from S all subsequences of s k Data structures (the hash-tree) and algorithm to quickly find all subsequences of a given sequence are described in [3] (and are similar to those used to find all subsets of a given itemset <ref> [2] </ref>). 3 The Sequence Phase The general structure of the algorithms for the sequence phase is that they make multiple passes over the data. In each pass, we start with a seed set of large sequences. We use the seed set for generating new potentially large sequences, called candidate sequences. <p> The count-all algorithms count all the large sequences, including non-maximal sequences. The non-maximal sequences must then be pruned out (in the maximal phase). We present one count-all algorithm, called AprioriAll, based on the Apriori algorithm for finding large itemsets presented in <ref> [2] </ref>. 1 We present two count-some algorithms: Apriori-Some and DynamicSome. The intuition behind these algorithms is that since we are only interested in maximal sequences, we can avoid counting sequences which are contained in a longer sequence if we first count longer sequences. <p> DynamicSome generates candidates on-the-fly using the large sequences found in the previous passes and the customer sequences read from the 1 The AprioriHybrid algorithm presented in <ref> [2] </ref> did better than Apriori for finding large itemsets. However, it used the property that a k-itemset is present in a transaction if any two of its (k 1)-subsets are present in the transaction to avoid scanning the database in later passes. <p> At the end of the pass, the support of the candidates is used to determine the large sequences. In the first pass, the output of the litemset phase is used to initialize the set of large 1-sequences. The candidates are stored in hash-tree <ref> [2] </ref> [3] to quickly find all candidates contained in a customer sequence. 3.1.1 Apriori Candidate Generation The apriori-generate function takes as argument L k1 , the set of all large (k 1)-sequences. The function works as follows. <p> The reason is that apriori-generate generates less candidates than otf-generate when we generate C k+1 from L k <ref> [2] </ref>. However, this may not hold when we try to find L k+step from L k and L step 2 , as is the case in the forward phase.
Reference: [3] <author> R. Agrawal and R. Srikant. </author> <title> Mining sequential patterns. </title> <type> Research Report RJ 9910, </type> <institution> IBM Al-maden Research Center, </institution> <address> San Jose, California, </address> <month> Oc-tober </month> <year> 1994. </year>
Reference-contexts: Then, for ( k = n; k &gt; 1; k ) do foreach k-sequence s k do Delete from S all subsequences of s k Data structures (the hash-tree) and algorithm to quickly find all subsequences of a given sequence are described in <ref> [3] </ref> (and are similar to those used to find all subsets of a given itemset [2]). 3 The Sequence Phase The general structure of the algorithms for the sequence phase is that they make multiple passes over the data. <p> At the end of the pass, the support of the candidates is used to determine the large sequences. In the first pass, the output of the litemset phase is used to initialize the set of large 1-sequences. The candidates are stored in hash-tree [2] <ref> [3] </ref> to quickly find all candidates contained in a customer sequence. 3.1.1 Apriori Candidate Generation The apriori-generate function takes as argument L k1 , the set of all large (k 1)-sequences. The function works as follows. <p> For example, h 1 2 4 3 i is pruned out because the subsequence h 2 4 3 i is not in L 3 . Proof of correctness of the candidate generation procedure is given in <ref> [3] </ref>. 3.1.2 Example Consider a database with the customer-sequences shown in Fig. 8. We have not shown the original database in this example. <p> The number of customers, jDj was set to 250,000. Table 2 summarizes the dataset parameter settings. We refer the reader to <ref> [3] </ref> for the details of the data generation program. 4.2 Relative Performance Fig. 14 shows the relative execution times for the three algorithms for the six datasets given in Table 2 as the minimum support is decreased from 1% support to 0.2% support.
Reference: [4] <author> S. Altschul, W. Gish, W. Miller, E. Myers, and D. Lipman. </author> <title> A basic local alignment search tool. </title> <journal> Journal of Molecular Biology, </journal> <year> 1990. </year>
Reference-contexts: Techniques based on multiple alignment [11] have been proposed to find entire text sequences that are similar. There also has been work to find locally similar subsequences <ref> [4] </ref> [8] [9]. However, as pointed out in [10], these techniques apply when the discovered patterns consist of consecutive characters or multiple lists of consecutive characters separated by a fixed length of noise characters.
Reference: [5] <author> A. Califano and I. Rigoutsos. </author> <title> Flash: A fast lookup algorithm for string homology. </title> <booktitle> In Proc. of the 1st International Converence on Intelligent Systems for Molecular Biology, </booktitle> <address> Bethesda, MD, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Our problem is related to the problem of finding text subsequences that match a given regular expression (c.f. the UNIX grep utility). There also has been work on finding text subsequences that approximately match a given string (e.g. <ref> [5] </ref> [12]). These techniques are oriented toward finding matches for one pattern. In our problem, the difficulty is in figuring out what patterns to try and then efficiently finding out which ones are contained in a customer sequence.
Reference: [6] <author> T. G. Dietterich and R. S. Michalski. </author> <title> Discovering patterns in sequences of events. </title> <journal> Artificial Intelligence, </journal> <volume> 25 </volume> <pages> 187-232, </pages> <year> 1985. </year>
Reference-contexts: A pattern in the first problem consists of an unordered set of items whereas a pattern in the latter case is an ordered list of sets of items. Discovering patterns in sequences of events has been an area of active research in AI (see, for example, <ref> [6] </ref>). However, the focus in this body of work is on discovering the rule underlying the generation of a given sequence in order to be able to predict a plausible sequence continuation (e.g. the rule to predict what number will come next, given a sequence of numbers).
Reference: [7] <author> L. Hui. </author> <title> Color set size problem with applications to string matching. </title> <editor> In A. Apostolico, M. Crochemere, Z. Galil, and U. Manber, editors, </editor> <title> Combinatorial Pattern Matching, </title> <publisher> LNCS 644, </publisher> <pages> pages 230-243. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: The solution in [10] is not guaranteed to be complete, whereas we guarantee that we have discovered all sequential patterns of interest that are present in a specified minimum number of sequences. The algorithm in [10] is a main memory algorithm based on generalized suffix tree <ref> [7] </ref> and was tested against a database of 150 sequences (although the paper does contain some hints on how they might extend their approach to handle larger databases). Our solution is targeted at millions of customer sequences.
Reference: [8] <author> M. Roytberg. </author> <title> A search for common patterns in many sequences. </title> <booktitle> Computer Applications in the Biosciences, </booktitle> <volume> 8(1) </volume> <pages> 57-64, </pages> <year> 1992. </year>
Reference-contexts: Techniques based on multiple alignment [11] have been proposed to find entire text sequences that are similar. There also has been work to find locally similar subsequences [4] <ref> [8] </ref> [9]. However, as pointed out in [10], these techniques apply when the discovered patterns consist of consecutive characters or multiple lists of consecutive characters separated by a fixed length of noise characters.
Reference: [9] <author> M. Vingron and P. Argos. </author> <title> A fast and sensitive multiple sequence alignment algorithm. </title> <booktitle> Computer Applications in the Biosciences, </booktitle> <volume> 5 </volume> <pages> 115-122, </pages> <year> 1989. </year>
Reference-contexts: Techniques based on multiple alignment [11] have been proposed to find entire text sequences that are similar. There also has been work to find locally similar subsequences [4] [8] <ref> [9] </ref>. However, as pointed out in [10], these techniques apply when the discovered patterns consist of consecutive characters or multiple lists of consecutive characters separated by a fixed length of noise characters.
Reference: [10] <author> J. T.-L. Wang, G.-W. Chirn, T. G. Marr, B. Shapiro, D. Shasha, and K. Zhang. </author> <title> Combinatorial pattern discovery for scientific data: Some preliminary results. </title> <booktitle> In Proc. of the ACM SIG-MOD Conference on Management of Data, </booktitle> <address> Min-neapolis, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Techniques based on multiple alignment [11] have been proposed to find entire text sequences that are similar. There also has been work to find locally similar subsequences [4] [8] [9]. However, as pointed out in <ref> [10] </ref>, these techniques apply when the discovered patterns consist of consecutive characters or multiple lists of consecutive characters separated by a fixed length of noise characters. Closest to our problem is the problem formulation in [10] in the context of discovering similarities in a database of genetic sequences. <p> However, as pointed out in <ref> [10] </ref>, these techniques apply when the discovered patterns consist of consecutive characters or multiple lists of consecutive characters separated by a fixed length of noise characters. Closest to our problem is the problem formulation in [10] in the context of discovering similarities in a database of genetic sequences. The patterns they wish to discover are subsequences made up of consecutive characters separated by a variable number of noise characters. <p> Thus, an element of the sequential pattern we discover can be a set of characters (items), rather than being simply a character. Our solution approach is entirely different. The solution in <ref> [10] </ref> is not guaranteed to be complete, whereas we guarantee that we have discovered all sequential patterns of interest that are present in a specified minimum number of sequences. The algorithm in [10] is a main memory algorithm based on generalized suffix tree [7] and was tested against a database of <p> Our solution approach is entirely different. The solution in <ref> [10] </ref> is not guaranteed to be complete, whereas we guarantee that we have discovered all sequential patterns of interest that are present in a specified minimum number of sequences. The algorithm in [10] is a main memory algorithm based on generalized suffix tree [7] and was tested against a database of 150 sequences (although the paper does contain some hints on how they might extend their approach to handle larger databases). Our solution is targeted at millions of customer sequences.
Reference: [11] <author> M. Waterman, </author> <title> editor. Mathematical Methods for DNA Sequence Analysis. </title> <publisher> CRC Press, </publisher> <year> 1989. </year>
Reference-contexts: These techniques are oriented toward finding matches for one pattern. In our problem, the difficulty is in figuring out what patterns to try and then efficiently finding out which ones are contained in a customer sequence. Techniques based on multiple alignment <ref> [11] </ref> have been proposed to find entire text sequences that are similar. There also has been work to find locally similar subsequences [4] [8] [9].
Reference: [12] <author> S. Wu and U. Manber. </author> <title> Fast text searching allowing errors. </title> <journal> Communications of the ACM, </journal> <volume> 35(10) </volume> <pages> 83-91, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Our problem is related to the problem of finding text subsequences that match a given regular expression (c.f. the UNIX grep utility). There also has been work on finding text subsequences that approximately match a given string (e.g. [5] <ref> [12] </ref>). These techniques are oriented toward finding matches for one pattern. In our problem, the difficulty is in figuring out what patterns to try and then efficiently finding out which ones are contained in a customer sequence.
References-found: 12

