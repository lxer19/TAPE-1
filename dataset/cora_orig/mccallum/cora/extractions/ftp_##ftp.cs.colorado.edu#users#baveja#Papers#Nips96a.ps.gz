URL: ftp://ftp.cs.colorado.edu/users/baveja/Papers/Nips96a.ps.gz
Refering-URL: http://www.cs.colorado.edu/~baveja/papers.html
Root-URL: 
Email: baveja@cs.colorado.edu  bertsekas@lids.mit.edu  
Title: Reinforcement Learning for Dynamic Channel Allocation in Cellular Telephone Systems  
Author: Satinder Singh Dimitri Bertsekas 
Address: Boulder, CO 80309-0430  Cambridge, MA 02139  
Affiliation: Department of Computer Science University of Colorado  Lab. for Info. and Decision Sciences MIT  
Abstract: In cellular telephone systems, an important problem is to dynamically allocate the communication resource (channels) so as to maximize service in a stochastic caller environment. This problem is naturally formulated as a dynamic programming problem and we use a reinforcement learning (RL) method to find dynamic channel allocation policies that are better than previous heuristic solutions. The policies obtained perform well for a broad variety of call traffic patterns. We present results on a large cellular system with In cellular communication systems, an important problem is to allocate the communication resource (bandwidth) so as to maximize the service provided to a set of mobile callers whose demand for service changes stochastically. A given geographical area is divided into mutually disjoint cells, and each cell serves the calls that are within its boundaries (see Figure 1a). The total system bandwidth is divided into channels, with each channel centered around a frequency. Each channel can be used simultaneously at different cells, provided these cells are sufficiently separated spatially, so that there is no interference between them. The minimum separation distance between simultaneous reuse of the same channel is called the channel reuse constraint . When a call requests service in a given cell either a free channel (one that does not violate the channel reuse constraint) may be assigned to the call, or else the call is blocked from the system; this will happen if no free channel can be found. Also, when a mobile caller crosses from one cell to another, the call is "handed off" to the cell of entry; that is, a new free channel is provided to the call at the new cell. If no such channel is available, the call must be dropped/disconnected from the system. approximately 49 49 states.
Abstract-found: 1
Intro-found: 1
Reference: <author> Barto, A.G., Bradtke, S.J. & Singh, S. </author> <title> (1995) Learning to act using real-time dynamic programming. </title> <journal> Artificial Intelligence, </journal> <volume> 72 </volume> <pages> 81-138. </pages>
Reference-contexts: The results show that RL is able to adapt its allocation strategy and thereby is better able to exploit the non-uniform call arrival rates. of backgammon (Tesauro, 1992), elevator-scheduling <ref> (Crites & Barto, 1995) </ref>, and job-shop scheduling (Zhang & Dietterich, 1995). The neuro-dynamic programming textbook (Bertsekas and Tsitsiklis, 1996) presents a variety of related case studies.
Reference: <author> Bertsekas, </author> <title> D.P. (1995) Dynamic Programming and Optimal Control: Vols 1 and 2. </title> <address> Athena-Scientific, Belmont, MA. </address>
Reference-contexts: In this paper, we compare the performance of dynamic channel allocation policies learned by RL with both FA and BDCL. 1.1 DYNAMIC PROGRAMMING FORMULATION We can formulate the dynamic channel allocation problem using dynamic programming <ref> (e.g., Bertsekas, 1995) </ref>.
Reference: <author> Bertsekas, </author> <title> D.P. & Tsitsiklis, </title> <editor> J. </editor> <booktitle> (1996) Neuro-Dynamic Programming Athena-Scientific, </booktitle> <address> Belmont, MA. </address>
Reference-contexts: The results show that RL is able to adapt its allocation strategy and thereby is better able to exploit the non-uniform call arrival rates. of backgammon (Tesauro, 1992), elevator-scheduling (Crites & Barto, 1995), and job-shop scheduling (Zhang & Dietterich, 1995). The neuro-dynamic programming textbook <ref> (Bertsekas and Tsitsiklis, 1996) </ref> presents a variety of related case studies.
Reference: <author> Crites, R.H. & Barto, </author> <title> A.G. (1996) Improving elevator performance using reinforcement learning. </title> <booktitle> In Advances is Neural Information Processing Systems 8. </booktitle>
Reference: <author> Del Re, W., Fantacci, R. & Ronga, L. </author> <title> (1996) A dynamic channel allocation technique based on Hopfield Neural Networks. </title> <journal> IEEE Transactions on Vehicular Technology, 45:1. </journal>
Reference: <author> McEliece, R.J. & Sivarajan, K.N. </author> <year> (1994), </year> <title> Performance limits for channelized cellular telephone systems. </title> <journal> IEEE Trans. Inform. Theory, </journal> <pages> pp. 21-34, </pages> <month> Jan. </month>
Reference-contexts: Note that learning is quite rapid. As the mean call arrival rate is increased the relative difference between the 3 algorithms decreases. In fact, FA can be shown to be optimal in the limit of infinite call arrival rates <ref> (see McEliece and Sivarajan, 1994) </ref>. With so many customers in every cell there are no short-term fluctuations to exploit. However, as demonstrated in Figure 2, for practical traffic rates RL consistently gives a big win over FA and a smaller win over BDCL.
Reference: <author> Sutton, </author> <title> R.S. (1988) Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 9-44. </pages>
Reference: <author> Tesauro, G.J. </author> <title> (1992) Practical issues in temporal difference learning. </title> <journal> Machine Learning, </journal> 8(3/4):257-277. 
Reference-contexts: The results show that RL is able to adapt its allocation strategy and thereby is better able to exploit the non-uniform call arrival rates. of backgammon <ref> (Tesauro, 1992) </ref>, elevator-scheduling (Crites & Barto, 1995), and job-shop scheduling (Zhang & Dietterich, 1995). The neuro-dynamic programming textbook (Bertsekas and Tsitsiklis, 1996) presents a variety of related case studies.
Reference: <author> Zhang, M. & Yum, </author> <title> T.P. (1989) Comparisons of Channel-Assignment Strategies in Cellular Mobile Telephone Systems. </title> <journal> IEEE Transactions on Vehicular Technology Vol. </journal> <volume> 38, No. </volume> <pages> 4. </pages>
Reference: <author> Zhang, W. & Dietterich, T.G. </author> <title> (1996) High-performance job-shop scheduling with a time-delay TD(lambda) network. </title> <booktitle> In Advances is Neural Information Processing Systems 8. </booktitle>
References-found: 10

