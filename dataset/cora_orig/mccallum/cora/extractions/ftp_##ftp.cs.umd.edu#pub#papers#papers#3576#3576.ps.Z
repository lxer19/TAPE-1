URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3576/3576.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: Arnoldi versus Nonsymmetric Lanczos Algorithms for Solving Nonsymmetric Matrix Eigenvalue Problems  
Author: Jane K. Cullum 
Note: NSF grant GER-9450081  
Address: Yorktown Heights, NY 10598,  College Park, MD 20742,  
Affiliation: University of Maryland College Park Institute for Advanced Computer Studies TR-95-123 Department of Computer Science  Mathematical Sciences Department, IBM Research Division, T.J. Watson Research Center,  USA, and Department of Computer Science, Institute for Advanced Computer Studies, and Institute for Systems Research, University of Maryland,  
Pubnum: TR-3576  
Abstract: We obtain several results which may be useful in determining the convergence behavior of eigenvalue algorithms based upo n Arnoldi and nonsymmetric Lanczos recursions. We derive a relationship between nonsymmetric Lanczos eigenvalue procedures and Arnoldi eigenvalue procedures. We demonstrate that the Arnoldi recursions preserve a property which characterizes normal matrices, and that if we could determine the appropriate starting vectors, we could mimic the nonsymmetric Lanczos eigenvalue convergence on a general diagonalizable matrix by its convergence on related normal matrices. Using a unitary equivalence for each of these Krylov subspace methods, we define sets of test problems where we can easily vary certain spectral properties of the matrices. We use these and other test problems to examine the behavior of an Arnoldi and of a nonsymmetric Lanczos procedure. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Z. Bai, </author> <title> Error analysis of the Lanczos algorithm for nonsymmetric eigenvalue problem, </title> <journal> Math. Comp., </journal> <volume> 62(205) (1994), </volume> <pages> pp. 209-226. </pages>
Reference-contexts: As in the symmetric case, convergence of eigenvalue approximations occurs in conjunction with losses in the biorthogonality of the Lanczos vectors. Using a symmetrized version of the nonsymmetric Lanczos procedure, we derive a variant of a theorem in Bai <ref> [1] </ref> connecting losses in biorthogonality to convergence of eigenvalue approximations, relaxing his assumptions of exact local biorthogonality and normalization. In section 5 we derive a simple unitary invariance for each of these methods. <p> Losses in Biorthogonality Imply Convergence The stability of our algorithm depends upon the error propagation. In Theorem 4.1, we derive an apparently stronger version of a theorem in <ref> [1] </ref> relating the loss of biorthogonality of the Lanczos vectors to convergence of Ritz vector approximations. Bai [1] considered a different nonsymmetric variant of the nonsymmetric Lanczos eigenvalue procedure and obtained extensions of theorems in Paige [20, 21] to the error terms F j and G j in equations (19). <p> Losses in Biorthogonality Imply Convergence The stability of our algorithm depends upon the error propagation. In Theorem 4.1, we derive an apparently stronger version of a theorem in <ref> [1] </ref> relating the loss of biorthogonality of the Lanczos vectors to convergence of Ritz vector approximations. Bai [1] considered a different nonsymmetric variant of the nonsymmetric Lanczos eigenvalue procedure and obtained extensions of theorems in Paige [20, 21] to the error terms F j and G j in equations (19). In his proof, Bai assumed exact local biorthogonality and normalizability. <p> a V H 1 and Gr48a2r2b03 a V H 1 ;(53) where V R is the unitary matrix used in examples 4 and 6. a was obtained by computing the 48 points in the interval [10 4 ,1] whose logarithms of their square roots are equally spaced in the interval <ref> [10 2 ; 1] </ref> and then scaling these numbers by the reciprocal of the square root of the product of the smallest and the largest values. The scaled values in a varied from 10 2 to 10 2 . Example 9 is of size n = 32.
Reference: [2] <author> M. Bennani and T. Braconnier, </author> <title> Comparative behaviour of eigensolvers on highly nonnormal matrices. </title> <type> CERFACS Technical Report TR-PA-94-23 (1994). </type> <institution> CERFACS, Toulouse, France. </institution>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods.
Reference: [3] <author> T. Braconnier, </author> <title> Importance of the orthogonalization scheme used for eigensolvers applied to nonnormal matrices, </title> <type> CERFACS Technical Report TR-PA-94-20, </type> <institution> (1994). CERFACS, Toulouse, France. </institution>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods.
Reference: [4] <author> T. Braconnier, F. Chatelin and V. Fraysse, </author> <title> The influence of large nonnormality on the quality of convergence of iterative methods in linear algebra, </title> <type> CERFACS Technical Report TR-PA-94-07 (1994). </type> <institution> CERFACS, Toulouse, France. </institution>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods.
Reference: [5] <author> F. Chatelin, V. Fraysse, and T. Braconnier, </author> <title> Computations in the neighbourhood of algebraic singularities, </title> <journal> Numer. Funct. Anal. and Optimiz., </journal> <volume> 16(3&4) (1995), </volume> <pages> pp. 287-302. </pages>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods.
Reference: [6] <author> F. Chaitin-Chatelin, </author> <note> Is nonnormality a serious difficulty? , CERFACS Technical Report TR-PA-94-18, 1994. </note> <institution> CERFACS, Toulouse, France. </institution>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods.
Reference: [7] <author> F. Chaitin-Chatelin, </author> <title> Finite precision computations, reliability of numerical software, </title> <type> CERFACS Technical Report TR-PA-94-05 (1994). </type> <institution> CERFACS, Toulouse, France. </institution>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods.
Reference: [8] <author> F. Chatelin and V. Fraysse, </author> <title> numerical illustrations by T. Braconnier, Qualitative computing, elements for a theory for finitie precision computation, </title> <type> CERFACS Technical Report TR-PA-93-12 (1993). </type> <institution> CERFACS, Toulouse, France. </institution>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods.
Reference: [9] <author> J. Cullum, </author> <title> GMRES versus QMR/BICG methods for solving Ax = b, </title> <note> to appear IBM Research Report, </note> <month> December </month> <year> 1995, </year> <institution> IBM Research, Yorktown Heights, NY. </institution>
Reference-contexts: The results of these tests suggest that to characterize the behavior of these methods on nonnormal problems it is not sufficient to know the singular values of the eigenvector matrix. They also suggest a potential source of numerical difficulties for both types of methods. In <ref> [9] </ref> we consider similar questions for the problem Ax = b. We use the following notation. 1.1. Notation. <p> In section 8 we will consider the convergence of these two procedures when they are applied to the same test problems. In <ref> [9] </ref> we derive an analog of this theorem for the Ax = b problem, In Theorem 3.1 we assume that B has n distinct eigenvalues, that the starting vectors have projections on each of the right and the left eigenvectors of B, and that there is no breakdown in the nonsymmetric <p> There are many open questions regarding the behavior of either or both of these types of methods, and even questions about the design of tests for comparisons both between methods and for a given method. In <ref> [9] </ref> we examine similar questions in the context of the problem Ax = b.
Reference: [10] <author> J. Cullum, </author> <title> Testing iterative methods for nonsymmetric matrices, </title> <note> to appear, IBM Research Report, January 1996, </note> <institution> IBM Research, Yorktown Heights, NY. </institution>
Reference-contexts: If A is real and diagonalizable we can replace complex V and fl in equation (45) by a real orthogonal matrix and a real block diagonal matrix with 1 fi 1 and 2 fi 2 blocks, <ref> [10] </ref>. We can use equations (45) to specify various eigenvalue distributions and eigenvector spaces. In this paper we focus on diagonalizable test matrices. In [10] where we study the convergence of iterative procedures for Ax = b, we also consider defective matrices. 6.2. <p> V and fl in equation (45) by a real orthogonal matrix and a real block diagonal matrix with 1 fi 1 and 2 fi 2 blocks, <ref> [10] </ref>. We can use equations (45) to specify various eigenvalue distributions and eigenvector spaces. In this paper we focus on diagonalizable test matrices. In [10] where we study the convergence of iterative procedures for Ax = b, we also consider defective matrices. 6.2. <p> A Property of Arnoldi Methods The following lemma may indicate that an Arnoldi method should perform well when applied to a matrix which is nearly normal. Theorem 7.1 gives a characterization of any normal matrix A in terms of its Hermitian-skew Hermitian decomposition. For a proof, see for example, <ref> [10] </ref>. We use C to denote an eigenvalue of C. Theorem 7.1. Let A be any n fi n matrix. Define M A (A + A H )=2 and N A (A A H )=2. <p> Output from any of these computations can be plotted using MATLAB routines written specifically for such tests. There are also codes for generating pseudospectra of test matrices and contour plots of the pseudospectra. These codes are described in <ref> [10] </ref>. We considered 9 different test problems. We applied a complex Arnoldi method with reorthog-onalization and our complex symmetric variant of the nonsymmetric Lanczos method with no re-biorthogonalization to each problem and computed eigenvalue approximations and true errors for various size Arnoldi and Lanczos matrices.
Reference: [11] <author> J. Cullum, </author> <title> Lanczos algorithms for large scale symmetric and nonsymmetric matrix eigenvalues problems, </title> <booktitle> Proceedings of the Cornelius Lanczos International Centenary Conference, </booktitle> <editor> eds. J. David Brown, Moody T. Chu, Donald C. Ellison, and Robert J. Plemmons, </editor> <publisher> SIAM, </publisher> <address> Philadelphia, PA (1994) pp. </address> <pages> 11-31. </pages>
Reference-contexts: That approach suffers from the same difficulties as an approach which uses error estimates. We use a completely different approach. No convergence tolerances are used. Our identification test is a simple extension of the test used in our real symmetric Lanczos procedures. This extension is discussed in detail in <ref> [11] </ref>. The argument requires only the symmetry of the Lanczos tridiagonal matrices and is valid in finite precision arithmetic, as long as the error terms in the Lanczos recursions remain small. <p> In order to study the numerical behavior of these algorithms we need test matrices where we can systematically vary spectral properties. In this section we list several theorems which identify one such possible class of matrices. We have the following unitary invariance for the real symmetric Lanczos methods <ref> [11] </ref>. Theorem 5.1 is stated for real C but the complex Hermitian analog follows easily. In this section we use C and ~ C to denote two matrices which are unitarily similar. Theorem 5.1. (Exact Arithmetic): Let C and ~ C be similar real symmetric matrices.
Reference: [12] <author> J. Cullum, W. Kerner, and R. Willoughby, </author> <title> A generalized nonsymmetric Lanczos procedure, </title> <journal> Comput. Phys. Comm., </journal> <volume> 53 (1989), </volume> <pages> pp. 19-48. </pages>
Reference: [13] <author> J. Cullum and R. Willoughby, </author> <title> A practical procedure for computing eigenvalues of large sparse nonsymmetric matrices, in Large Scale Eigenvalue Problems, </title> <editor> J. Cullum and R. Willoughby (eds.), </editor> <publisher> North-Holland, </publisher> <year> 1986, </year> <pages> pp. 193-240. </pages>
Reference: [14] <author> J. Cullum and R. A. Willoughby, </author> <title> Lanczos Algorithms for Large Symmetric Eigenvalue Computations, </title> <booktitle> Vol. 1, Theory, Progress in Scientific Computing Vol. </booktitle> <volume> 3, </volume> <editor> eds. S. Abarbanel et al., </editor> <publisher> Birkhauser, </publisher> <address> Basel, Switzerland (1985). </address>
Reference-contexts: Therefore, kr R k k = j k+1 u k 4. Finite Precision Arithmetic and Nonsymmetric Lanczos Procedures Typically, in finite precision the Lanczos vectors do not remain biorthogonal, and the basic procedure must be modified. We use modifications analogous to our modifications for the real symmetric Lanczos procedure <ref> [14] </ref>. We require the following assumptions. Assumption 4.1:. Lanczos Phenomenon. For large enough m, all of the desired eigenvalues of A will appear in ! (T m ).
Reference: [15] <author> V. Druskin and L. Knizhnerman, </author> <title> Krylov subspace approximation of eigenpairs and matrix functions in exact and computer arithmetic, </title> <note> Schlumberger-Doll Research Note, October 20, 1992, Schlumberger-Doll, Ridgefield, CT; to appear in Numerical Linear Algebra. </note>
Reference: [16] <author> R. W. Freund, M. H. Gutknecht, and N. M. Nachtigal, </author> <title> An implementation of the look-ahead Lanczos algorithm for non-Hermitian matrices, </title> <journal> SIAM J on Scientific and Statistical Computing, 14,(1993) pp. </journal> <pages> 137-58. </pages>
Reference: [17] <author> R. W. Freund, G. H. Golub, Noel Nachtigal, </author> <title> Iterative solution of linear systems, </title> <journal> Acta Numerica., </journal> <note> 1 (1992), pp.57-100. </note>
Reference: [18] <author> R. Freund and N. Nachtigal, </author> <title> QMR: a quasi-minimal residual method for non-Hermitian linear systems, </title> <journal> Numer. Math., </journal> <volume> 8 (1992), </volume> <pages> pp. 43-71. </pages>
Reference-contexts: If w j = 0 or v j = 0, then this means an invariant subspace for either A T or A has been found. Exact breakdown is highly improbable, near breakdowns may cause numerical instabilities. To avoid such problems, various look-ahead strategies have been proposed, see e.g. <ref> [25, 18] </ref>. The discussions in this paper are equally applicable to the look-ahead variants of these methods. If look-ahead steps are performed, then the scalar coefficients in Equations (4) become matrices, and the Lanczos vectors become block biorthogonal.
Reference: [19] <author> C. Moler et al., </author> <title> MATLAB User's Guide, MathWorks, </title> <publisher> Inc., </publisher> <address> 24 Prime Park Way, Natick, MA (1992). </address>
Reference-contexts: Therefore , without loss of generality, we can restrict ourselves to test matrices with eigenvalues whose real parts are all positive. We have written a suite of MATLAB <ref> [19] </ref> codes which allow the user to generate and regenerate test matrices of the form given in equation (45). The user can also call either a Ax = b routine or a basic real or complex Arnoldi eigenvalue routine.
Reference: [20] <author> C. C. Paige, </author> <title> Accuracy and effectiveness of the Lanczos algorithm for the symmetric eigenproblem, </title> <journal> Lin. Alg. Appl. </journal> <volume> 34 (1980), </volume> <pages> pp. 235-258. </pages>
Reference-contexts: In Theorem 4.1, we derive an apparently stronger version of a theorem in [1] relating the loss of biorthogonality of the Lanczos vectors to convergence of Ritz vector approximations. Bai [1] considered a different nonsymmetric variant of the nonsymmetric Lanczos eigenvalue procedure and obtained extensions of theorems in Paige <ref> [20, 21] </ref> to the error terms F j and G j in equations (19). In his proof, Bai assumed exact local biorthogonality and normalizability. We prove a similar result for the complex symmetric variant which requires only *-biorthogonality and normalizability.
Reference: [21] <author> C. C. Paige, </author> <title> Error analysis of the Lanczos algorithm for tridiagonalizing a symmetric matrix , J. </title> <journal> Inst. Math. Appl. </journal> <volume> 18 (1976), </volume> <pages> pp. 341-349. </pages>
Reference-contexts: In Theorem 4.1, we derive an apparently stronger version of a theorem in [1] relating the loss of biorthogonality of the Lanczos vectors to convergence of Ritz vector approximations. Bai [1] considered a different nonsymmetric variant of the nonsymmetric Lanczos eigenvalue procedure and obtained extensions of theorems in Paige <ref> [20, 21] </ref> to the error terms F j and G j in equations (19). In his proof, Bai assumed exact local biorthogonality and normalizability. We prove a similar result for the complex symmetric variant which requires only *-biorthogonality and normalizability.
Reference: [22] <author> C. C. Paige, </author> <title> The computation of eigenvalues and eigenvectors of very large sparse matrices, </title> <type> Ph.D. thesis, </type> <institution> London University, Institute of Computer Science, </institution> <address> London, England, </address> <year> 1971. </year>
Reference-contexts: These eigenvector computations require regeneration of the Lanczos vectors. 4.1. Spurious Eigenvalues The success of any Lanczos procedure which does not use reorthogonalization depends upon a procedure for identifying the spurious eigenvalues which appear when biorthogonality is lost. For the real symmetric case, Paige <ref> [22] </ref> proposed that error estimates be used to make this identification. An eigenvalue of some T m would be accepted as good and an approximation to an eigenvalue of A only if its corresponding error estimate was sufficiently small. There are two problems associated with that approach.
Reference: [23] <author> B. N. Parlett, </author> <title> Reduction to tridiagonal form and minimal realizations, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13 (1992), </volume> <pages> pp. 567-593. </pages>
Reference: [24] <author> B. N. Parlett and J. K. Reid, </author> <title> Tracking the progress of the Lanczos algorithm for large symmetric eigenproblems, </title> <journal> IMA J. Num. Anal., </journal> <volume> 1 (1981), </volume> <pages> pp. 135-155. </pages>
Reference-contexts: Presumably spurious eigenvalues which are not close to converged eigenvalues would not have small error estimates and would be excluded on that basis, along with these other good eigenvalues. Error estimates cannot distinquish between these two types of Lanczos eigenvalues. Alternatively, references <ref> [24, 30] </ref> track the convergence of approximations as the size of the Lanczos matrix is increased and only accept converged approximations. That approach suffers from the same difficulties as an approach which uses error estimates. We use a completely different approach. No convergence tolerances are used.
Reference: [25] <author> B. N. Parlett, D. R. Taylor, and Z.A. Liu, </author> <title> A look-ahead Lanczos algorithm for unsymmetric matrices, </title> <journal> Math. Comp., </journal> <volume> 44 (1985), </volume> <pages> pp. 105-124. </pages>
Reference-contexts: If A is a real, normal matrix, and v 1 has reasonable projections on the desired right eigenvectors of A, then setting w 1 = v 1 may be an optimal choice in terms of the mismatch theorem <ref> [25] </ref>. . Lemma 2.1. Let A be a real, normal matrix with n distinct eigenvalues. Let v 1 have a significant projection on each unit right eigenvector of A. Then v 1 has a significant projection on each unit left eigenvector of A. Proof. <p> Existing error estimates for any k j , when it is considered as an estimate of some eigenvalue of A, require estimates of both a right and a left normalized residual norm <ref> [25] </ref>, and the condition of that eigenvalue, cond (). k k j k cond ()max (kr R j k; kr L In practice we do not know the condition of the eigenvalues, and do not have an estimate of the error matrices F j and G j . <p> If w j = 0 or v j = 0, then this means an invariant subspace for either A T or A has been found. Exact breakdown is highly improbable, near breakdowns may cause numerical instabilities. To avoid such problems, various look-ahead strategies have been proposed, see e.g. <ref> [25, 18] </ref>. The discussions in this paper are equally applicable to the look-ahead variants of these methods. If look-ahead steps are performed, then the scalar coefficients in Equations (4) become matrices, and the Lanczos vectors become block biorthogonal.
Reference: [26] <author> Y. Saad, </author> <title> Numerical Methods for Large Eigenvalue Problems, </title> <publisher> Manchester University Press, </publisher> <address> Manchester, UK, </address> <year> 1992. </year>
Reference-contexts: We consider an Arnoldi method and two nonsymmetric Lanczos methods. Consider Equation (1) where A is a n fi n nonsymmetric matrix. A may be real or complex. 2.1. Arnoldi Methods The Arnoldi method is based upon the Arnoldi recursion <ref> [26] </ref>. Arnoldi Recursion: 1. Given v 1 with kv 1 k = 1, for j = 2; 3; : : : compute: v j+1 = Av j 2. For each j and for i = 1; : : : ; j compute: h ij = v H 3.
Reference: [27] <author> L. N. Trefethen, </author> <title> Spectra and Psuedospectra: The Behavior of Non-Normal Matrices and Operators, </title> <note> book in preparation. </note>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods.
Reference: [28] <author> L. N. Trefethen, A. E. Trefethen, S. C. Reddy, and T. A. Driscoll, </author> <title> Hydrodynamic stability without eigenvalues, </title> <booktitle> Science, 261 (1993), </booktitle> <pages> 578-584. </pages>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods.
Reference: [29] <author> L. N. Trefethen, </author> <title> Pseudospectra of matrices, </title> <editor> in D. F. Griffiths and G. A. Watson, eds., </editor> <title> Numerical Analysis 1991, </title> <publisher> Longman Scientific and Technical, </publisher> <address> Harlow, UK, </address> <year> 1992. </year>
Reference-contexts: See for example, the related work <ref> [2, 3, 4, 5, 6, 7, 8, 27, 28, 29] </ref>. In section 2 we outline briefly the Arnoldi and the nonsymmetric Lanczos eigenvalue procedures we are considering. In section 3 we exhibit a certain relationship between these two methods. <p> We also demonstrate that if we were able to select the starting vectors in a nonsymmetric Lanczos procedure appropriately, we could simulate any eigenvalue convergence using only normal test matrices. In section 8 we consider the Grcar test matrix <ref> [29] </ref> and several variants of it based upon the test matrices discussed in section 6, in an attempt to gain some insight into the behavior of both the Arnoldi and the nonsymmetric Lanczos procedure. <p> We will develop these ideas in another paper. 8.1. Test Problems Used We consider 9 different examples. For examples 18, n = 48, and all have the same eigenvalue distribution. The first two examples are the Grcar matrix n = 48, <ref> [29] </ref>, and its transpose. We denote this matrix by Gr48true. This matrix is real. The subdiagonal entries are 1. The diagonal entries and the entries on the first 3 superdiagonals are 1. All other entries are 0. Each eigenvalue is simple. <p> We observe that, for examples 1-8, the approximations to the left tails of the eigenvalue distribution converge prior to convergence of the leading edge. Example 1 is well-conditioned in the sense that its singular values vary from :922 to 3:23. This matrix is however very nonnormal <ref> [29] </ref>. In Figs. 1-2, for m = 24 and m = 32, we plot the true eigenvalues, the complex Arnoldi approximations, and the nonsymmetric Lanczos approximations . We observe that in both figures the nonsymmetric Lanczos approximations are closer to the actual eigenvalue curve than the Arnoldi approximations.
Reference: [30] <author> J. M. van Kats and H. A. van der Vorst, </author> <title> Automatic monitoring of Lanczos-schemes for symmetric or skew-symmetric generalized eigenproblems, </title> <type> Report TR-7, </type> <institution> Academisch Computer Centrum, </institution> <address> Utrecht, The Netherlands, </address> <year> 1977. </year>
Reference-contexts: Presumably spurious eigenvalues which are not close to converged eigenvalues would not have small error estimates and would be excluded on that basis, along with these other good eigenvalues. Error estimates cannot distinquish between these two types of Lanczos eigenvalues. Alternatively, references <ref> [24, 30] </ref> track the convergence of approximations as the size of the Lanczos matrix is increased and only accept converged approximations. That approach suffers from the same difficulties as an approach which uses error estimates. We use a completely different approach. No convergence tolerances are used.

References-found: 30

