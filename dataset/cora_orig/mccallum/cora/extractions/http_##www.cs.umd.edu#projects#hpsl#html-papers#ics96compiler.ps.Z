URL: http://www.cs.umd.edu/projects/hpsl/html-papers/ics96compiler.ps.Z
Refering-URL: http://www.cs.umd.edu/projects/hpsl/html-papers/ics96compiler.html
Root-URL: 
Email: fgagan,acha,saltzg@cs.umd.edu  
Phone: (301)-405-2756  
Title: An Interprocedural Framework for Placement of Asynchronous I/O Operations  
Author: Gagan Agrawal and Anurag Acharya and Joel Saltz 
Address: College Park, MD 20742  
Affiliation: UMIACS and Department of Computer Science University of Maryland  
Abstract: Overlapping memory accesses with computations is a standard technique for improving performance on modern architectures, which have deep memory hierarchies. In this paper, we present a compiler technique for overlapping accesses to secondary memory (disks) with computation. We have developed an Interproce-dural Balanced Code Placement (IBCP) framework, which performs analysis on arbitrary recursive procedures and arbitrary control flow and replaces synchronous I/O operations with a balanced pair of asynchronous operations. We demonstrate how this analysis is useful for the applications which perform frequent and large accesses to secondary memory, including the applications which snapshot or checkpoint their computations or the out-of-core applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anurag Acharya, Mustafa Uysal, Robert Bennett, Assaf Mendelson, Mike Beynon, Jeff Hollingsworth, Joel Saltz, and Alan Sussman. </author> <title> Tuning the Performance of I/O Intensive Parallel Applications. </title> <note> To appear in IOPADS'96, </note> <month> May </month> <year> 1996. </year>
Reference-contexts: All our experiments were done on an IBM RS/6000 running AIX 3.2.5, with 64 MB of primary memory and one 2.2 GB IBM Starfire 7200 SCSI disk. The Starfire 7200 is rated at a maximum bandwidth of 8 MB/s; the maximum measured application-level file I/O bandwidth is 7.5 MB/s <ref> [1] </ref>. For all our experi ments, we measured end-to-end execution time including a final fsync () to ensure that all data has been written to disk. 4.1 Direct Simulation Monte Carlo Direction Simulation Monte Carlo is a well known technique for studying the interaction of particles in cells [4]. <p> To implement this out-of-core max-reduction efficiently, a bounding region of the image containing the pixels to be updated, is read, modified in-core and written back to disk. This template was loosely based on pathfinder, the AVHRR program from the NASA Goddard Distributed Active Archive Center <ref> [1] </ref>. It has a similar organization, the same memory requirement and processes its input in same size (500 KB) chunks. <p> In both these applications, almost no overlap would have been possible if the analysis was restricted within single procedures. Our experimental results have been restricted to single processor applications only. However, experiences with I/O on parallel applications have shown that accesses to local disks are very important <ref> [1] </ref>. Our analysis is directly applicable to performing placement of accesses to local disk on parallel applications. Acknowledgements We have implemented our source to source compiler using the Parascope/ D System Fortran front end. We gratefully acknowledge our debt to its implementers.
Reference: [2] <author> Gagan Agrawal, Anurag Acharya, and Joel Saltz. </author> <title> An inter-procedural framework for placement of asynchronous i/o operations. </title> <type> Technical Report CS-TR-3563, </type> <institution> UMD, </institution> <month> Decem-ber </month> <year> 1995. </year>
Reference-contexts: Full details of this program representation are available elsewhere <ref> [2, 3] </ref>. We assume that a variable is either global to the entire program or is local to a single procedure. We further assume that all parameters are passed by reference. We do not consider the possibility of aliasing in our discussion. <p> In this paper, we will only present the details of the analysis for the placement of Start op (Section 3.4). Analysis for the placement of End op is analogous and the details are presented elsewhere <ref> [2] </ref>. We now list the two major problems that need to be addressed in our analysis: 1. <p> The details of this analysis are omitted from this paper <ref> [2] </ref>. 4 Experimental Results We have implemented a source to source Fortran translation tool based on our interprocedural balanced code placement technique. This tool is based upon the Parascope/D System front end.
Reference: [3] <author> Gagan Agrawal, Joel Saltz, and Raja Das. </author> <title> Interprocedural partial redundancy elimination and its application to distributed memory compilation. </title> <booktitle> In Proceedings of the SIG-PLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 258-269. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1995. </year> <journal> ACM SIGPLAN Notices, </journal> <volume> Vol. 30, No. </volume> <pages> 6. </pages> <note> Also available as University of Maryland Technical Report CS-TR-3446 and UMIACS-TR-95-42. </note>
Reference-contexts: In the case of out-of-core programs, the initial phase of the compilation can possibly generate redundant requests. In this case, some redundancy elimination analysis like Interprocedural Partial Redundancy Elimination (IPRE) <ref> [3] </ref> can be applied before applying the analysis we present in this paper. Our method is broadly applicable for the placement of both the read and write operations. However, performing an early start of a read operation involves additional memory usage. <p> Full details of this program representation are available elsewhere <ref> [2, 3] </ref>. We assume that a variable is either global to the entire program or is local to a single procedure. We further assume that all parameters are passed by reference. We do not consider the possibility of aliasing in our discussion.
Reference: [4] <author> Graeme A. Bird. </author> <title> Molecular Gas Dynamics and the Direct Simulation of Gas Flows. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1994. </year>
Reference-contexts: For all our experi ments, we measured end-to-end execution time including a final fsync () to ensure that all data has been written to disk. 4.1 Direct Simulation Monte Carlo Direction Simulation Monte Carlo is a well known technique for studying the interaction of particles in cells <ref> [4] </ref>. The program we used in our experiments, dsmc-3d, was originally developed by Richard Wilmoth at NASA Langley. To study the evolution of the process being simulated, it is useful to snapshot the po sition of all the particles after every time-step.
Reference: [5] <author> R. Bordawekar, A. Choudhary, K. Kennedy, C. Koelbel, and M. Paleczny. </author> <title> A model and compilation strategy for out-of-core data parallel programs. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming (PPOPP), </booktitle> <pages> pages 1-10. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1995. </year> <journal> ACM SIGPLAN Notices, </journal> <volume> Vol. 30, No. </volume> <pages> 8. </pages>
Reference-contexts: In such cases, our analysis needs to be used in conjunction with additional analysis for estimating resource constraints. This is especially important for the read operations in the out-of-core applications, which are constrained by the limits of the primary memory <ref> [5] </ref>. We are not aware of any other work on overlapping operations with computation interprocedurally. In previous work, Hanxleden and Kennedy have developed a general framework for placement of asynchronous operations and redundancy elimination [6], but this framework is restricted to performing analysis within a single procedure. <p> Compiler optimizations for improving I/O accesses have been addressed by at least two projects. PASSION compiler (based upon Syracuse F90D system) performs loop transformations for improving locality in out-of-core applications <ref> [5] </ref>. Similar optimizations have also been performed as part of the Fortran D compilation system's support for out-of-core applications [8].
Reference: [6] <author> Reinhard von Hanxleden and Ken Kennedy. </author> <title> Give-n-take - a balanced code placement framework. </title> <booktitle> In Proceedings of the SIGPLAN '94 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 107-120. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1994. </year> <journal> ACM SIGPLAN Notices, </journal> <volume> Vol. 29, No. </volume> <pages> 6. </pages>
Reference-contexts: We are not aware of any other work on overlapping operations with computation interprocedurally. In previous work, Hanxleden and Kennedy have developed a general framework for placement of asynchronous operations and redundancy elimination <ref> [6] </ref>, but this framework is restricted to performing analysis within a single procedure. Compiler optimizations for improving I/O accesses have been addressed by at least two projects. PASSION compiler (based upon Syracuse F90D system) performs loop transformations for improving locality in out-of-core applications [5].
Reference: [7] <author> E. Myers. </author> <title> A precise interprocedural data flow algorithm. </title> <booktitle> In Conference Record of the Eighth ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 219-230, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: any general techniques for placement of asynchronous operations or any interprocedural optimizations. 3 Interprocedural Balanced Code Placement Frame work 3.1 Program Representation We have developed a new full program representation which extends the call graph by preserving information about the call sites but is more concise than the Myers's SuperGraph <ref> [7] </ref>. Full details of this program representation are available elsewhere [2, 3]. We assume that a variable is either global to the entire program or is local to a single procedure. We further assume that all parameters are passed by reference.
Reference: [8] <author> M. Paleczny, K. Kennedy, and C. Koelbel. </author> <title> Compiler support for out-of-core arrays on parallel machines. </title> <booktitle> In Proceedings of the Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 110-118. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> February </month> <year> 1995. </year>
Reference-contexts: Compiler optimizations for improving I/O accesses have been addressed by at least two projects. PASSION compiler (based upon Syracuse F90D system) performs loop transformations for improving locality in out-of-core applications [5]. Similar optimizations have also been performed as part of the Fortran D compilation system's support for out-of-core applications <ref> [8] </ref>.
References-found: 8

