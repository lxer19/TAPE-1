URL: http://www.is.cs.cmu.edu/papers/speech/1994/ICASSP94.janus.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Title: JANUS 93: TOWARDS SPONTANEOUS SPEECH TRANSLATION  
Author: M.Woszczyna N.Aoki-Waibel F.D.But N.Coccaro K.Horiguchi T.Kemp A.Lavie A.McNair T.Polzin I.Rogina C.P.Rose T.Schultz B.Suhm M.Tomita A.Waibel 
Address: Germany  
Affiliation: Carnegie Mellon University USA University of Karlsruhe  
Abstract: We present first results from our efforts toward translation of spontaneously spoken speech. Improvements include increasing coverage, robustness, generality and speed of JANUS, the speech-to-speech translation system of Carnegie Mellon and Karlsruhe University. Recognition and Machine Translation Engine have been upgraded to deal with requirements introduced by spontaneous human to human dialogs. To allow for development and evaluation of our system on adequate data, a large database with spontaneous scheduling dialogs is being gathered for English, German and Spanish. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Woszczyna, N. Coccaro, A. Eisele, A. Lavie, A. Mc-Nair, T .Polzin, I. Rogina, C.P. Rose, T. Sloboda, M. Tomita, J. Tsutsumi, N. Aoki-Waibel, A. Waibel, and W. Ward, </author> <title> Recent Advances in Janus, a Speech to Speech Translation System, </title> <booktitle> EUROSPEECH 1993. </booktitle>
Reference-contexts: 1. OVERVIEW JANUS <ref> [1, 2] </ref> has been among early systems to attempt the translation of spoken dialogs. It had initially been built based on a speech database of 12 read dialogs of the conference registration task, encompassing a vocabulary of around 500 words.
Reference: [2] <author> L. Osterholtz, A. McNair, I. Rogina, H. Saito, T. Slo-boda, J. Tebelskis, A. Waibel, and M. Woszczyna, </author> <title> Testing Generality in JANUS: A Multi-Lingual Speech to Speech Translation System, </title> <booktitle> ICASSP 1992, </booktitle> <volume> volume 1, </volume> <pages> pp 209-212. </pages>
Reference-contexts: 1. OVERVIEW JANUS <ref> [1, 2] </ref> has been among early systems to attempt the translation of spoken dialogs. It had initially been built based on a speech database of 12 read dialogs of the conference registration task, encompassing a vocabulary of around 500 words.
Reference: [3] <author> T. Morimoto, T. Takezawa, F. Yato, S. Sagayama, T. Tashiro, M. Nagata, and A. Kurematsu, </author> <title> ATR's Speech Translation System: </title> <booktitle> ASURA, EUROSPEECH 1993, </booktitle> <pages> pp 1295-1299. </pages>
Reference-contexts: Speech in L1 Generate L1 Synthesize L1 Speech in L2 Generate L2 Synthesize L2 Interlingua N-best Search LR-Parser NN-Parser Speech in Source Language Semantic Parser Recognition In cooperation with partner efforts at ATR <ref> [3] </ref> and Siemens, feasibility and potential of multilingual speech translation on limited task has been demonstrated by a public demonstration in spring 1993. Independently, other speech translation systems [4, 5] have been presented, showing the growing interest in the field.
Reference: [4] <author> D.B. Roe, F.C.N Pereira, R.W. Sproat and M.D. Riley, </author> <title> Efficient Grammar Processing for a Spoken Language Translation System, </title> <booktitle> ICASSP 1992, </booktitle> <volume> volume 1, </volume> <pages> pp 213-216. </pages>
Reference-contexts: Independently, other speech translation systems <ref> [4, 5] </ref> have been presented, showing the growing interest in the field.
Reference: [5] <author> M. Rayner et al., </author> <title> A Speech to Speech Translation System Built from Standard Components, </title> <booktitle> ARPA HLT Workshop Proceedings, </booktitle> <month> March </month> <year> 1993, </year> <note> Session 6. </note>
Reference-contexts: Independently, other speech translation systems <ref> [4, 5] </ref> have been presented, showing the growing interest in the field.
Reference: [6] <author> J. Tebelskis and A. Waibel, </author> <title> Performance through consistency: MS-TDNNs for large vocabulary continuous speech recognition, </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: RECOGNITION ENGINE 3.1. Acoustic Modeling For acoustic modeling, several alternative algorithms are being explored including TDNN, MS-TDNN, MLP and LVQ <ref> [6, 7] </ref>. In the main JANUS system, an LVQ algorithm with context-dependent phonemes is currently used for speaker independent recognition. For each phoneme, there is a context independent set of prototypical vectors. The output scores for each phoneme segment are computed from the euclidean distance using context dependent segment weights.
Reference: [7] <author> I. Rogina and A. Waibel, </author> <title> Learning State-Dependent Stream Weights for Multi-Codebook HMM Speech Recognition Systems, </title> <booktitle> ICASSP 1994. </booktitle>
Reference-contexts: RECOGNITION ENGINE 3.1. Acoustic Modeling For acoustic modeling, several alternative algorithms are being explored including TDNN, MS-TDNN, MLP and LVQ <ref> [6, 7] </ref>. In the main JANUS system, an LVQ algorithm with context-dependent phonemes is currently used for speaker independent recognition. For each phoneme, there is a context independent set of prototypical vectors. The output scores for each phoneme segment are computed from the euclidean distance using context dependent segment weights.
Reference: [8] <author> S. Austin and R. Schwartz, </author> <title> A Comparison of Several Approximate Algorithms for Finding N-best Hypotheses, </title> <booktitle> ICASSP 1991, </booktitle> <volume> volume 1, </volume> <pages> pp 701-704. </pages>
Reference-contexts: Recent Improvements of the Search Module. Timings and memory usage are given for the English CR Task. This was achieved by using the word dependent N-best algorithm <ref> [8] </ref> as a backward pass in the forward backward pruning algorithm. Recent experiments with the Wall Street Journal Task show, that the recognizer can handle vocabularies of up to 10000 words at a perplexity of 110. 3.3.
Reference: [9] <author> R. Kneser and H. Ney, </author> <title> Improved Cluster Techniques for Class-Based Statistical Language Modeling, </title> <address> EU-ROSPEECH 93. </address>
Reference-contexts: Language Models The most successful language model so far used for the scheduling task is a model that interpolates a cluster based model with smoothed bigrams. The cluster based model is using automatically build classes. The optimization criterion is to minimize the leaving-one-out perplexity on the training set <ref> [9] </ref>. The results shown in table 4 were obtained using 150 word classes. ESST GSST Smoothed Bigrams 46.8 88.2 Cluster 42.3 71.8 Interpolated 39.2 62.1 Table 4. Perplexity Reduction due to automatic clustering 3.4.
Reference: [10] <author> M. Tomita (ed.), </author> <title> Generalized LR Parsing, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston MA, </address> <year> 1991. </year>
Reference-contexts: It can use syntactic or semantic based grammars. For application to the spontaneously spoken English scheduling task, we found semantic based grammars most useful. The Generalized LR parsing algorithm is an extension of LR parsing with a "Graph-Structured Stack" <ref> [10] </ref>, and it can handle arbitrary context-free grammars while most of the LR efficiency is preserved. We use a recently developed robust version of the GLR parser to parse the input sentence.
Reference: [11] <author> J.G. Carbonell and P.J. Hayes, </author> <title> Recovery Strategies for Parsing Extragrammatical Language, </title> <institution> Carnegie-Mellon University Computer Science Technical Report 1984, (CMU-CS-84-107). </institution>
Reference-contexts: Semantic Pattern Based Parsing Our robust semantic parser combines frame based semantics with semantic phrase grammars [12]. We use a frame based parser similar to the DYPAR parser used by Carbonell, et al. to process ill-formed text <ref> [11] </ref>, and the MINDS system previously developed at CMU. Semantic information is represented in a set of frames. Each frame contains a set of slots representing pieces of information. In order to fill the slots in the frames, we use semantic fragment grammars.
Reference: [12] <author> W. Ward, </author> <title> Understanding Spontaneous Speech, </title> <booktitle> DARPA Speech and Natural Language Workshop 1989, </booktitle> <pages> pp 137-141. </pages>
Reference-contexts: Semantic Pattern Based Parsing Our robust semantic parser combines frame based semantics with semantic phrase grammars <ref> [12] </ref>. We use a frame based parser similar to the DYPAR parser used by Carbonell, et al. to process ill-formed text [11], and the MINDS system previously developed at CMU. Semantic information is represented in a set of frames. Each frame contains a set of slots representing pieces of information.
Reference: [13] <author> A.J. Jain, A. Waibel and D. Touretzky, </author> <title> PARSEC: A Structured Connectionist Parsing System for Spoken Language, </title> <booktitle> ICASSP 1992, </booktitle> <volume> volume 1, </volume> <pages> pp 205-208. </pages>
Reference-contexts: Each slot type is represented by a separate Recursive Transition Network, which specifies all ways of saying the meaning represented by the slot. The grammar is a semantic grammar, non-terminals are semantic concepts instead of parts of speech. 4.4. Connectionist Parsing The connectionist parsing system PARSEC <ref> [13] </ref> is used as a fall-back module if the LR parser fails to analyze the input. One important aspect of the PARSEC system is that it learns to parse sentences from a corpus of training examples. This eliminates the very difficult work of writing robust grammars.
Reference: [14] <author> F.D. But, T. Polzin and A. </author> <title> Waibel Learning Complex Output Representations in Connectionist Parsing, </title> <booktitle> ICASSP 1994. </booktitle> <pages> 4 </pages>
Reference-contexts: Another aspect is that it has proven robust towards spontaneous utterances which frequently are "corrupted" with disfluencies, restarts, repairs or ungram-matical constructions. Third, integration with other information sources, e.g intonation, is easier. More information about the recent developments in PAR SEC can be found in <ref> [14] </ref> 3 4.5. The Generator The generation of target language from an Interlingua representation involves two steps. First, with the same Transformation Kit used in the analysis phase, Interlingua representation is mapped into syntactic f-structure of the target language.
References-found: 14

