URL: http://www.cs.brown.edu/people/tld/postscript/BoddyandDeanAIJ-94.ps
Refering-URL: http://www.cs.brown.edu/people/tld/
Root-URL: 
Email: boddy@src.honeywell.com  tld@cs.brown.edu  
Title: Decision-Theoretic Deliberation Scheduling for Problem Solving in Time-Constrained Environments  
Author: Mark Boddy Thomas Dean 
Date: March 21, 1993  
Address: MN65-2100 3660 Technology Drive Minneapolis, MN 55418  Providence, Rhode Island 02912  
Affiliation: Honeywell Systems and Research Center  Department of Computer Science Brown University  
Abstract: We are interested in the problem faced by an agent with limited computational capabilities, embedded in a complex environment with other agents and processes not under its control. Careful management of computational resources is important for complex problem-solving tasks in which the time spent in decision making affects the quality of the responses generated by a system. This paper describes an approach to designing systems that are capable of taking their own computational resources into consideration during planning and problem solving. In particular, we address the design of systems that manage their computational resources by using expectations about the performance of decision-making procedures and preferences over the outcomes resulting from applying those procedures. The approach we propose is deliberation scheduling: explicit manipulation of expectations on the behavior of the environment and the benefits of computation in order to determine how computational resources should be allocated. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Barnett, V., </author> <title> Comparative Statistical Inference, </title> <publisher> (John Wiley and Sons, </publisher> <year> 1982). </year>
Reference-contexts: In such cases, the agent will generally assign an expected 3 Inferential actions are also useful for learning purposes, as in learning search strategies, but even here the actions are ultimately in service to selecting physical actions that lead to desirable outcomes. 4 See Chernoff and Moses [8], Barnett <ref> [1] </ref>, or Pearl [30] for discussions regarding the axioms of utility theory. 4 utility to a given state based upon the immediate rewards available in that state and expectations about the subsequent states, given that the agent continues to select actions based upon its current policy.
Reference: [2] <author> Bellman, R.E., </author> <title> Dynamic Programming, </title> <publisher> (Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1957). </year>
Reference-contexts: algorithms we found: * Numerical approximation For example, Taylor series approximations (e.g., computing or e) and iterative finite-element methods [40]. * Heuristic search Algorithms for heuristic search, in particular those employing variable lookahead and fast evaluation functions, can be cast as anytime algorithms [29, 28]. * Dynamic Programming Dynamic programming <ref> [2] </ref> is a general and flexible methodology that can be applied to a wide variety of optimization and control problems, many of them relevant to current AI research (e.g., scheduling, probabilistic reasoning, and controlling machinery). <p> Each instant of time provides new information (a new state) and requires a new allocation decision. Following methods used in operations research, we might try using dynamic programming <ref> [2, 34] </ref> to solve our optimization problem. Dynamic programming involves caching the optimal answer to a series of subproblems of increasing size, until finally we can determine the optimal answer to the full problem.
Reference: [3] <author> Boddy, Mark, </author> <title> Anytime Problem Solving Using Dynamic Programming, </title> <booktitle> Proceedings AAAI-91, </booktitle> <address> Anaheim, CA, </address> <publisher> AAAI, </publisher> <year> 1991. </year>
Reference-contexts: The algorithm presented here is exact given the restrictions on the form of performance profiles. These restrictions are perhaps limiting, but by no means debilitating. Empirical evidence reported on in Section 7.2 and discussed in considerably more detail in <ref> [4, 3] </ref>, suggests that a profile exhibiting diminishing returns may be obtained experimentally for decision procedures of a wide variety of types. For example, probabilistic testing of primes and heuristic search in some domains both exhibit this property. <p> Boddy <ref> [3] </ref> discusses a method for constructing anytime procedures for solving dynamic programs. * Probablistic algorithms One family of probabilistic algorithms that can easily be adapted for anytime use are Monte Carlo algorithms [20]. * Probabilistic inference A wide variety of methods has been developed for approximate evaluation of belief nets (i.e.,
Reference: [4] <author> Boddy, Mark, </author> <title> Solving Time-Dependent Problems: A Decision-Theoretic Approach to Planning in Dynamic Environments, </title> <type> Technical Report CS-91-06, </type> <institution> Brown University Department of Computer Science, </institution> <year> 1991. </year>
Reference-contexts: The implications of using algorithms whose answers are only expected to improve is addressed in somewhat more detail in Section 6, and at considerable length in <ref> [4] </ref>. Dean and Boddy [10] employ decision procedures whose answers are expected to increase in value monotonically throughout the range of computation times, and exploit this fact to expedite deliberation scheduling for a special class of planning 10 problems referred to as time-dependent planning problems. <p> This issue is discussed in more detail in Section 6.3, and in <ref> [4] </ref>. It is worth pointing out some connections between the Russell and Wefald work and that of Dean and Boddy and Horvitz. <p> The basis for making these decisions should be the agent's expectations regarding the outcome of a given sequence of decisions. This starts to get complicated only when we attempt to model the decisions to be made by the agent, their effects, and the agent's expectations. The formal specification in <ref> [4] </ref> provides a language for constructing such models, as does Russell and Wefald's definition and analysis of meta-reasoning [36]. These two views of time-dependent problems are distinct and may not be easy to reconcile. <p> The algorithm presented here is exact given the restrictions on the form of performance profiles. These restrictions are perhaps limiting, but by no means debilitating. Empirical evidence reported on in Section 7.2 and discussed in considerably more detail in <ref> [4, 3] </ref>, suggests that a profile exhibiting diminishing returns may be obtained experimentally for decision procedures of a wide variety of types. For example, probabilistic testing of primes and heuristic search in some domains both exhibit this property. <p> In this case, the total time required for n 2 is L=3 + (n 1)L=2 + L=4 = (2n 1)L=4 + L=3 &lt; (2n + 1)L=4: in problems whose performance criteria depend on minimizing the total time spent in deliberation and execution. Boddy <ref> [4] </ref> provides a provably optimal, efficient algorithm for a special case in which all of the performance profiles are piecewise linear composed of two linear segments such that the slope of the first segment is the same for all profiles and the slope of the second is 0. <p> It is also possible for several anytime decision procedures to use the result of a single procedure (e.g., a sensor interpretation routine). One approach as to how this combination can be accomplished, including constructing a performance profile for the composite procedure, is given in <ref> [4] </ref>. Moving beyond simple combinations complicates the situation. <p> We report on the results of experiments in three domains: time-dependent planning problems as defined in Section 5, the Robot Courier, and the Shooting Gallery. 15 15 More detailed descriptions of these domains and the experiments described in this section may be found in <ref> [4] </ref>. 39 7.2.1 Time-Dependent Planning The deliberation schedules generated by the procedure DS in Section 5 are optimal for a decision model that does not include expectations on the future occurrence of events. Suppose that we are given a dynamic environment in which observations occur as time passes. <p> We call the process of choosing this ordering tour-improvement planning. Once the robot has an ordering for the locations, it may spend time determining how best to get from one of them to another (path planning). Boddy <ref> [4] </ref> presents three different deliberation-scheduling algorithms for different variants of this problem: * Pr-I, in which only path planning may be scheduled. * Pr-II, in which all tour improvement must occur before the robot moves or does any path planning. * Pr-III, in which the robot may plan paths for and <p> There are other factors affecting the dynamic behavior of the system as well, for example the relative cost of tour improvement and path planning. For a more complete description of the effect of these factors, see <ref> [4] </ref>. For a set of experiments in which the "clock rate" for path planning was twice that for tour improvement, the gain in the average time required for Pr-I in the dynamic case is less than 10%.
Reference: [5] <author> Boddy, Mark and Dean, Thomas, </author> <title> Solving Time-Dependent Planning Problems, </title> <booktitle> IJCAI89, </booktitle> <address> Detroit, Michigan, </address> <year> 1989. </year>
Reference-contexts: Both of these approaches are discussed in more detail in Section 4. The use of deliberation scheduling has been explored in several domains, including planning [13, 11], search [35, 19, 28], medical decision making [26], and robot control <ref> [10, 5] </ref>. 3 Decision Theory and the Control of Inference Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior [31]. <p> The use of flexible computations can also simplify problems in which one decision procedure produces an intermediate result that is used as input to a second decision procedure. Boddy and Dean <ref> [5] </ref> investigate one such problem involving a robot courier assigned the task of delivering packages to a set of locations. <p> Boddy and Dean employ iterative refinement approximation routines for solving each of these problems, and gather statistics on their performance to be used at run-time in guiding deliberation scheduling. The statistics are summarized in performance profiles. Figure 3 (from <ref> [5] </ref>) shows experimentally derived profiles for path planning and tour improvement in a domain called the gridworld. Figure 3.i shows how the expected savings in travel time increase as a function of time spent in path planning. <p> It should be possible to apply the Russell and Wefald approach to scheduling anytime algorithms. For some purposes (e.g., the game-playing and search applications described in [36]), the monolithic approach of Russell and Wefald seems perfectly suited. For other applications (e.g., the robotic applications described in <ref> [5] </ref> or the intensive-care applications described in [24]), it is convenient to think in terms of scheduling existing approximation algorithms. At one level, a unified view of time-dependent problems is straightforward. <p> Shell sort produces a gradually decreasing maximum distance for entries from their true position. Which of these algorithms is most appropriate for a particular application depends in part on what kind of "approximate sort" is most useful. In previous work <ref> [10, 5] </ref>, we have compiled performance profiles that tracked the expected value of (some parameter of) the answer returned by a given anytime decision procedure as a function of deliberation time.
Reference: [6] <author> Bodin, L. and Golden, B., </author> <title> Classification in Vehicle Routing and Scheduling, Networks, </title> <month> 11 </month> <year> (1981) </year> <month> 97-108. </month>
Reference-contexts: The NP-completeness result reported by Etzioni does not apply in this more general case. In job-shop scheduling, if it is possible to suspend and later resume a job, then many otherwise difficult problems become trivial <ref> [18, 6] </ref>.
Reference: [7] <author> Brooks, Rodney A., </author> <title> A Robust Layered Control System for a Mobile Robot, </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 864, </pages> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1985. </year>
Reference-contexts: This movement brought about the advent of the so-called "reactive systems" <ref> [7, 33, 16] </ref>. Most reactive systems are essentially programming languages for building systems that must be responsive to their environment. Many of the researchers building reactive systems were interested in robotics and decision-support applications requiring real-time response.
Reference: [8] <author> Chernoff, Herman and Moses, Lincoln E., </author> <title> Elementary Decision Theory, </title> <publisher> (John Wiley and Sons, </publisher> <address> New York, </address> <year> 1959). </year>
Reference-contexts: In such cases, the agent will generally assign an expected 3 Inferential actions are also useful for learning purposes, as in learning search strategies, but even here the actions are ultimately in service to selecting physical actions that lead to desirable outcomes. 4 See Chernoff and Moses <ref> [8] </ref>, Barnett [1], or Pearl [30] for discussions regarding the axioms of utility theory. 4 utility to a given state based upon the immediate rewards available in that state and expectations about the subsequent states, given that the agent continues to select actions based upon its current policy.
Reference: [9] <author> Dean, Thomas, </author> <title> Decision-Theoretic Control of Inference for Time-Critical Applications, </title> <journal> International Journal of Intelligent Systems, </journal> <note> to appear (1991). </note>
Reference-contexts: First, it is assumed that the agent considers only single computation steps, estimates their ultimate effect, and then chooses the step appearing to have highest 5 For a more detailed discussion of the work presented in this section, see <ref> [9] </ref>. 6 benefit. This is referred to as the meta-greedy assumption. Second, the computa-tion of expected utility assumes that the agent will take only a single additional search step. This is referred to as the single-step assumption.
Reference: [10] <author> Dean, Thomas and Boddy, Mark, </author> <title> An Analysis of Time-Dependent Planning, </title> <booktitle> Proceedings AAAI-88, </booktitle> <address> St. Paul, Minnesota, </address> <publisher> AAAI, </publisher> <year> 1988, </year> <pages> 49-54. 48 </pages>
Reference-contexts: One of the problems with allocating deliberation time in discrete increments is that it is easy to wind up with a combinatorial problem [12]. An alternative approach is to assume that deliberation is performed using anytime decision procedures <ref> [10] </ref> (also called flexible computations in [25]), and that time can be allocated in values drawn from a continuous range (this is inevitably an approximation). <p> Both of these approaches are discussed in more detail in Section 4. The use of deliberation scheduling has been explored in several domains, including planning [13, 11], search [35, 19, 28], medical decision making [26], and robot control <ref> [10, 5] </ref>. 3 Decision Theory and the Control of Inference Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior [31]. <p> In the work discussed in this paper, an agent is assumed to engage in meta-reasoning. For our purposes, meta-reasoning consists of running a decision procedure whose purpose it is to determine what other decision procedures should run and when. We prefer the term deliberation scheduling <ref> [10] </ref> to the more general meta-reasoning and will use the two interchangeably in this paper. If the meta-level decision procedure takes a significant amount of time to run, it must be argued that this time is well spent. <p> The two approaches are due to Dean and Boddy <ref> [10] </ref> and Horvitz [25]. Horvitz refers to his decision procedures as flexible computations and Dean and Boddy refer to theirs as anytime algorithms, but the basic idea behind the two proposals is the same, and we will use the two terms interchangeably. <p> The implications of using algorithms whose answers are only expected to improve is addressed in somewhat more detail in Section 6, and at considerable length in [4]. Dean and Boddy <ref> [10] </ref> employ decision procedures whose answers are expected to increase in value monotonically throughout the range of computation times, and exploit this fact to expedite deliberation scheduling for a special class of planning 10 problems referred to as time-dependent planning problems. <p> We add the further restriction that the slopes of consecutive line seg-ments be decreasing. If the functions representing the performance profiles were everywhere differentiable, this restriction would correspond to the first derivative function being monotonic decreasing. In <ref> [10] </ref>, we suggested a similar restriction referred to as diminishing returns, and defined as follows: 8 c 2 C; 9 f; c (t) = f (t) such that f is monotonic increasing, continuous, and piecewise differentiable, and 8 x; y 2 R + such that f 0 (x) and f 0 <p> Shell sort produces a gradually decreasing maximum distance for entries from their true position. Which of these algorithms is most appropriate for a particular application depends in part on what kind of "approximate sort" is most useful. In previous work <ref> [10, 5] </ref>, we have compiled performance profiles that tracked the expected value of (some parameter of) the answer returned by a given anytime decision procedure as a function of deliberation time.
Reference: [11] <author> Drummond, Mark and Bresina, John, </author> <title> Anytime Synthetic Projection: Maxi--mizing the Probability of Goal Satisfaction, </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <year> 1990, </year> <pages> 138-144. </pages>
Reference-contexts: A line of work running back to [38] views deliberation time as being quantized into chunks of fixed, though not necessarily constant, size. Sproull [39] applies this 1 Not all of it, however. See, for example <ref> [37, 11, 13] </ref> 2 model to a system for planning travel itineraries, though he is more concerned with the use of decision theory to guide planning choices. <p> Both of these approaches are discussed in more detail in Section 4. The use of deliberation scheduling has been explored in several domains, including planning <ref> [13, 11] </ref>, search [35, 19, 28], medical decision making [26], and robot control [10, 5]. 3 Decision Theory and the Control of Inference Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior [31].
Reference: [12] <author> Einav, David, </author> <title> Computationally-Optimal Real-Resource Strategies for Independent, Uninterruptible Methods, </title> <booktitle> Proceedings of the Sixth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Cambridge, MA, </address> <year> 1990, </year> <pages> 73-81. </pages>
Reference-contexts: One of the problems with allocating deliberation time in discrete increments is that it is easy to wind up with a combinatorial problem <ref> [12] </ref>. An alternative approach is to assume that deliberation is performed using anytime decision procedures [10] (also called flexible computations in [25]), and that time can be allocated in values drawn from a continuous range (this is inevitably an approximation).
Reference: [13] <author> Elkan, Charles, </author> <title> Incremental, Approximate Planning, </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <year> 1990, </year> <pages> 145-150. </pages>
Reference-contexts: A line of work running back to [38] views deliberation time as being quantized into chunks of fixed, though not necessarily constant, size. Sproull [39] applies this 1 Not all of it, however. See, for example <ref> [37, 11, 13] </ref> 2 model to a system for planning travel itineraries, though he is more concerned with the use of decision theory to guide planning choices. <p> Both of these approaches are discussed in more detail in Section 4. The use of deliberation scheduling has been explored in several domains, including planning <ref> [13, 11] </ref>, search [35, 19, 28], medical decision making [26], and robot control [10, 5]. 3 Decision Theory and the Control of Inference Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior [31].
Reference: [14] <author> Etzioni, Oren, </author> <title> Tractable Decision-Analytic Control, </title> <booktitle> First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> 114-125, </pages> <publisher> (Morgan-Kaufmann, </publisher> <year> 1989), </year> <pages> 114-125. </pages>
Reference-contexts: Sproull [39] applies this 1 Not all of it, however. See, for example [37, 11, 13] 2 model to a system for planning travel itineraries, though he is more concerned with the use of decision theory to guide planning choices. In <ref> [14] </ref>, the deliberative chunks are called "methods." In [36], the computation to be controlled is modeled as a sequence of "inference steps" leading to the performance of an action. <p> Assessments of information sources based on the no-competition and one-step-horizon assumptions are referred to as myopic, and most practical systems employ myopic decision policies. The next piece of research that we consider in this section is due to Etzioni <ref> [14] </ref>, and it borrows from the Russell and Wefald work, and builds on the early work of Simon and Kadane [38] on satisficing search.
Reference: [15] <author> Garey, Michael R. and Johnson, David S., </author> <title> Computing and Intractibility: A Guide to the Theory of NP-Completeness, </title> <editor> (W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979). </year>
Reference-contexts: In the case of an agent faced with multiple goals, even where there is only one method for each goal, optimal choice of a sequence of methods is more difficult. By reducing the knapsack problem <ref> [15] </ref> to the problem of computing the expected opportunity cost, Etzioni shows that computing the expected opportunity cost of a method is NP-complete. 6 The "expected opportunity cost" of a method is a measure of the benefit that might 6 The knapsack problem involves a set of objects represented by value/volume
Reference: [16] <author> Georgeff, Michael P. and Lansky, Amy L., </author> <title> Reactive Reasoning and Planning, </title> <booktitle> Proceedings AAAI-87, </booktitle> <address> Seattle, Washington, </address> <publisher> AAAI, </publisher> <year> 1987, </year> <pages> 677-682. </pages>
Reference-contexts: This movement brought about the advent of the so-called "reactive systems" <ref> [7, 33, 16] </ref>. Most reactive systems are essentially programming languages for building systems that must be responsive to their environment. Many of the researchers building reactive systems were interested in robotics and decision-support applications requiring real-time response.
Reference: [17] <author> Good, I. J., </author> <title> Good Thinking, </title> <publisher> (University of Minnesota Press, </publisher> <year> 1976). </year>
Reference-contexts: I. J. Good's work on Type II rationality laid the foundations for most of the work on decision theoretic deliberation scheduling that has been done since <ref> [17] </ref>. A line of work running back to [38] views deliberation time as being quantized into chunks of fixed, though not necessarily constant, size. Sproull [39] applies this 1 Not all of it, however.
Reference: [18] <author> Graham, R.L., Lawler, E.L., Lenstra, J.K., and Rinnooy Kan, A.H.G., </author> <title> Optimization and Approximation in Deterministic Sequencing and Scheduling: A Survey, </title> <booktitle> Proceedings Discrete Optimization, </booktitle> <address> Vancouver, </address> <year> 1977. </year>
Reference-contexts: The NP-completeness result reported by Etzioni does not apply in this more general case. In job-shop scheduling, if it is possible to suspend and later resume a job, then many otherwise difficult problems become trivial <ref> [18, 6] </ref>.
Reference: [19] <author> Hansson, Othar and Mayer, Andrew, </author> <title> The Optimality of Satisficing Solutions, </title> <booktitle> Proceedings of the Fourth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Minneapolis, MN, </address> <year> 1988. </year>
Reference-contexts: Both of these approaches are discussed in more detail in Section 4. The use of deliberation scheduling has been explored in several domains, including planning [13, 11], search <ref> [35, 19, 28] </ref>, medical decision making [26], and robot control [10, 5]. 3 Decision Theory and the Control of Inference Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior [31].
Reference: [20] <author> Harel, David, </author> <title> ALGORITHMICS: </title> <booktitle> The Spirit of Computing, </booktitle> <publisher> (Addison-Wesley, </publisher> <year> 1987). </year>
Reference-contexts: Boddy [3] discusses a method for constructing anytime procedures for solving dynamic programs. * Probablistic algorithms One family of probabilistic algorithms that can easily be adapted for anytime use are Monte Carlo algorithms <ref> [20] </ref>. * Probabilistic inference A wide variety of methods has been developed for approximate evaluation of belief nets (i.e., providing bounds on the posterior distribution, rather than the exact distribution).
Reference: [21] <author> Hayes-Roth, Barbara, Washington, Richard, Hewett, Rattikorn, Hewett, Michael, and Seiver, Adam, </author> <title> Intelligent Monitoring and Control, </title> <booktitle> Proceedings IJCAI 11, </booktitle> <address> Detroit, </address> <institution> Michigan, IJCAI, </institution> <year> 1989, </year> <pages> 243-249. </pages>
Reference-contexts: In many time-critical problem solving applications, calculating the time cost can be quite complicated (e.g., consider the sort of medical care applications investigated in [24] and <ref> [21] </ref>). There are a number of assumptions that Russell and Wefald make in their analysis.
Reference: [22] <author> Henrion, M., </author> <title> The Value of Knowing How Little You Know, </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1984. </year> <month> 49 </month>
Reference-contexts: An optimal decision policy is defined as a policy that at each point makes the 13 Henrion <ref> [22] </ref> calls this the expected value of including uncertainty. (EVIU) 37 decision maximizing the expected utility of the current decision, given expectations on the decisions yet to be made. 14 Consider the simple example of a database server that must respond to queries by fixed deadlines (this is a time-dependent planning
Reference: [23] <author> Henrion, M., </author> <title> Propagating Uncertainty by Logic Sampling in Bayes' Networks, </title> <booktitle> Proceedings of the Second Workshop on Uncertainty in Artificial Intelligence, </booktitle> <year> 1986. </year>
Reference-contexts: Several of these methods are anytime algorithms in the sense that the bounds get smaller for additional iterations of the basic method, e.g., <ref> [24, 23] </ref>. * Discrete or symbolic processing Symbolic processing can be viewed as the manipulation of finite sets (of bindings, constraints, entities, etc.) [32].
Reference: [24] <author> Horvitz, E. J., Suermondt, H. J., and Cooper, G. F., </author> <title> Bounded Conditioning: Flexible Inference for Decisions Under Scarce Resources, </title> <booktitle> Proceedings of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Windsor, Ontario, </address> <year> 1989. </year>
Reference-contexts: In many time-critical problem solving applications, calculating the time cost can be quite complicated (e.g., consider the sort of medical care applications investigated in <ref> [24] </ref> and [21]). There are a number of assumptions that Russell and Wefald make in their analysis. <p> For some purposes (e.g., the game-playing and search applications described in [36]), the monolithic approach of Russell and Wefald seems perfectly suited. For other applications (e.g., the robotic applications described in [5] or the intensive-care applications described in <ref> [24] </ref>), it is convenient to think in terms of scheduling existing approximation algorithms. At one level, a unified view of time-dependent problems is straightforward. <p> Several of these methods are anytime algorithms in the sense that the bounds get smaller for additional iterations of the basic method, e.g., <ref> [24, 23] </ref>. * Discrete or symbolic processing Symbolic processing can be viewed as the manipulation of finite sets (of bindings, constraints, entities, etc.) [32].
Reference: [25] <author> Horvitz, Eric J., </author> <title> Reasoning About Beliefs and Actions Under Computational Resource Constraints, </title> <booktitle> Proceedings of the Third Workshop on Uncertainty in Artificial Intelligence, </booktitle> <address> Seattle, Washington, </address> <year> 1987. </year>
Reference-contexts: One of the problems with allocating deliberation time in discrete increments is that it is easy to wind up with a combinatorial problem [12]. An alternative approach is to assume that deliberation is performed using anytime decision procedures [10] (also called flexible computations in <ref> [25] </ref>), and that time can be allocated in values drawn from a continuous range (this is inevitably an approximation). <p> The problem 7 correct and treating the patient accordingly (after <ref> [25] </ref>). have been gained using other methods (for goals of equal weight, the difference in the probabilities of achieving a goal using this method as opposed to another). <p> The two approaches are due to Dean and Boddy [10] and Horvitz <ref> [25] </ref>. Horvitz refers to his decision procedures as flexible computations and Dean and Boddy refer to theirs as anytime algorithms, but the basic idea behind the two proposals is the same, and we will use the two terms interchangeably. <p> Suppose that we have an anytime algorithm that computes a posterior distribution for a set of possible diagnoses given certain information regarding a particular patient. Figure 1.i (from <ref> [25] </ref>) shows a graph that relates the precision of the result returned by this algorithm to the time spent in computation. <p> The comprehensive value of computation is meant to account for the costs and benefits related to the time at which the results of decision procedures are made use of to initiate physical actions. Figure 2.i (from <ref> [25] </ref>) indicates how a physician might discount the object-related value of a computation as a function of delay in administering treatment. <p> (object-related value and the cost of delaying a decision are independent functions of time) and a one-step horizon (the value of the physician's response is not dependent on 7 Object-related value is exactly Russell and Wefald's intrinsic utility. 9 the comprehensive value of computation as a function of time (after <ref> [25] </ref>). any further decision-making or information gathering). Horvitz has addressed a number of interesting theoretical issues in the use of anytime algorithms.
Reference: [26] <author> Horvitz, Eric J., </author> <title> Reasoning Under Varying and Uncertain Resource Constraints, </title> <booktitle> Proceedings AAAI-88, </booktitle> <address> St. Paul, Minnesota, </address> <publisher> AAAI, </publisher> <year> 1988, </year> <pages> 111-116. </pages>
Reference-contexts: Both of these approaches are discussed in more detail in Section 4. The use of deliberation scheduling has been explored in several domains, including planning [13, 11], search [35, 19, 28], medical decision making <ref> [26] </ref>, and robot control [10, 5]. 3 Decision Theory and the Control of Inference Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior [31]. <p> These include the difficulty of providing a single characterization of the "utility" associated with a given procedure and showing how differing time costs can affect the optimal choice of a decision procedure in a particular situation <ref> [26] </ref>. Horvitz has so far concentrated on the theoretical problems involving deliberating about a single task. In contrast, we have pursued a more empirical course in trying to find approximate solutions to the kind of deliberation-scheduling problems that arise in controlling robots. <p> Which of these profiles is most appropriate or useful depends on the task at hand. Horvitz <ref> [26] </ref> discusses various algorithms for sorting an array viewed as anytime algorithms (he calls them flexible computations). Each algorithm makes repeated changes to the array, each one bringing the array closer to being sorted. What is meant by "closer" differs for each algorithm, however.
Reference: [27] <author> King, John R. and Spachis, Alexander S., </author> <title> Scheduling: Bibliography and Review, </title> <journal> International Journal of Physical Distribution and Materials Management, </journal> <month> 10(3) </month> <year> (1980) </year> <month> 105-132. </month>
Reference-contexts: In addition, consider what has happened in the work on scheduling: there are a myriad of separate problems, distinguished by minor differences in problem characteristics, for which the difficulty of providing a scheduler (and the best way of doing so) varies enormously <ref> [27] </ref>.
Reference: [28] <author> Korf, Richard, </author> <title> Real-Time Heuristic Search, </title> <journal> Artificial Intelligence, </journal> <month> 42(2) </month> <year> (1990) </year> <month> 189-212. </month>
Reference-contexts: Both of these approaches are discussed in more detail in Section 4. The use of deliberation scheduling has been explored in several domains, including planning [13, 11], search <ref> [35, 19, 28] </ref>, medical decision making [26], and robot control [10, 5]. 3 Decision Theory and the Control of Inference Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior [31]. <p> Among the kinds of algorithms we found: * Numerical approximation For example, Taylor series approximations (e.g., computing or e) and iterative finite-element methods [40]. * Heuristic search Algorithms for heuristic search, in particular those employing variable lookahead and fast evaluation functions, can be cast as anytime algorithms <ref> [29, 28] </ref>. * Dynamic Programming Dynamic programming [2] is a general and flexible methodology that can be applied to a wide variety of optimization and control problems, many of them relevant to current AI research (e.g., scheduling, probabilistic reasoning, and controlling machinery).
Reference: [29] <author> Pearl, Judea, </author> <title> Heuristics, </title> <publisher> (Addison-Wesley, </publisher> <year> 1985). </year>
Reference-contexts: Among the kinds of algorithms we found: * Numerical approximation For example, Taylor series approximations (e.g., computing or e) and iterative finite-element methods [40]. * Heuristic search Algorithms for heuristic search, in particular those employing variable lookahead and fast evaluation functions, can be cast as anytime algorithms <ref> [29, 28] </ref>. * Dynamic Programming Dynamic programming [2] is a general and flexible methodology that can be applied to a wide variety of optimization and control problems, many of them relevant to current AI research (e.g., scheduling, probabilistic reasoning, and controlling machinery).
Reference: [30] <author> Pearl, Judea, </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, </title> <address> (Morgan-Kaufman, Los Altos, California, </address> <year> 1988). </year>
Reference-contexts: cases, the agent will generally assign an expected 3 Inferential actions are also useful for learning purposes, as in learning search strategies, but even here the actions are ultimately in service to selecting physical actions that lead to desirable outcomes. 4 See Chernoff and Moses [8], Barnett [1], or Pearl <ref> [30] </ref> for discussions regarding the axioms of utility theory. 4 utility to a given state based upon the immediate rewards available in that state and expectations about the subsequent states, given that the agent continues to select actions based upon its current policy. <p> In Russell and Wefald's state-space search paradigm, this is referred to as the subtree-independence assumption. The assumptions stated in the previous paragraph may seem overly restrictive, but it is quite difficult to avoid these or similar assumptions in general. Pearl <ref> [30] </ref> identifies two assumptions that most practical meta-reasoning systems ascribe to: no competition, each information source is evaluated in isolation from all the others, and one-step horizon, we consult at most one additional information source before committing to a base-level action.
Reference: [31] <author> Raiffa, Howard, </author> <title> Decision Analysis: Introductory Lectures on Choices Under Uncertainty, </title> <publisher> (Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1968). </year>
Reference-contexts: including planning [13, 11], search [35, 19, 28], medical decision making [26], and robot control [10, 5]. 3 Decision Theory and the Control of Inference Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior <ref> [31] </ref>. If you accept the axioms, decision theory provides a powerful set of tools for modelling and evaluating decision making under uncertainty.
Reference: [32] <author> Robert, F., </author> <title> Discrete Iterations: A Metric Study, </title> <publisher> (Springer-Verlag, </publisher> <year> 1986). </year>
Reference-contexts: Several of these methods are anytime algorithms in the sense that the bounds get smaller for additional iterations of the basic method, e.g., [24, 23]. * Discrete or symbolic processing Symbolic processing can be viewed as the manipulation of finite sets (of bindings, constraints, entities, etc.) <ref> [32] </ref>.
Reference: [33] <author> Rosenschein, Stan and Kaelbling, Leslie Pack, </author> <title> The Synthesis of Digital Machines with Provable Epistemic Properties, </title> <editor> Halpern, Joseph Y., (Ed.), </editor> <booktitle> Theoretical Aspects of Reasoning About Knowledge, Proceedings of the 1986 Conference, </booktitle> <address> Morgan-Kaufman, </address> <year> 1987, </year> <pages> 83-98. </pages>
Reference-contexts: This movement brought about the advent of the so-called "reactive systems" <ref> [7, 33, 16] </ref>. Most reactive systems are essentially programming languages for building systems that must be responsive to their environment. Many of the researchers building reactive systems were interested in robotics and decision-support applications requiring real-time response.
Reference: [34] <author> Ross, Sheldon, </author> <title> Introduction to Stochastic Dynamic Programming, </title> <publisher> (Academic Press, </publisher> <address> New York, NY, </address> <year> 1983). </year> <month> 50 </month>
Reference-contexts: The basic decision to be made is made repeatedly: for each increment of time, which of the available decision procedures will be run? This is a sequential decision problem of a form commonly addressed in operations research <ref> [34] </ref>. <p> Each instant of time provides new information (a new state) and requires a new allocation decision. Following methods used in operations research, we might try using dynamic programming <ref> [2, 34] </ref> to solve our optimization problem. Dynamic programming involves caching the optimal answer to a series of subproblems of increasing size, until finally we can determine the optimal answer to the full problem.
Reference: [35] <author> Russell, Stuart J. and Wefald, Eric H., </author> <title> On Optimal Game-Tree Search using Rational Meta-Reasoning, </title> <booktitle> Proceedings IJCAI 11, </booktitle> <address> Detroit, </address> <institution> Michigan, IJCAI, </institution> <year> 1989, </year> <pages> 334-340. </pages>
Reference-contexts: Both of these approaches are discussed in more detail in Section 4. The use of deliberation scheduling has been explored in several domains, including planning [13, 11], search <ref> [35, 19, 28] </ref>, medical decision making [26], and robot control [10, 5]. 3 Decision Theory and the Control of Inference Probability and decision theory are methods for dealing with uncertain information and outcomes on the basis of a small set of axioms concerning rational behavior [31]. <p> In particular, costs concerning hard and soft deadlines must be accounted for by this function. In the game-playing application explored in <ref> [35] </ref>, there are no hard deadlines on a per-move basis, instead there is a per-game time limit that is factored into the time cost.
Reference: [36] <author> Russell, Stuart J. and Wefald, Eric H., </author> <booktitle> Principles of Metareasoning, First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <publisher> (Morgan-Kaufmann, </publisher> <year> 1989). </year>
Reference-contexts: Sproull [39] applies this 1 Not all of it, however. See, for example [37, 11, 13] 2 model to a system for planning travel itineraries, though he is more concerned with the use of decision theory to guide planning choices. In [14], the deliberative chunks are called "methods." In <ref> [36] </ref>, the computation to be controlled is modeled as a sequence of "inference steps" leading to the performance of an action. One of the problems with allocating deliberation time in discrete increments is that it is easy to wind up with a combinatorial problem [12]. <p> The second approach approximates deliberation allocations as being drawn from a continuous range, such that the decisions being made are both what procedure to run and how much time to allocate to it. 5 4.1 Discrete Deliberation Scheduling In Russell and Wefald's work <ref> [36] </ref>, the computation to be controlled is modeled as a sequence of inference steps leading to the performance of an action. <p> It should be possible to apply the Russell and Wefald approach to scheduling anytime algorithms. For some purposes (e.g., the game-playing and search applications described in <ref> [36] </ref>), the monolithic approach of Russell and Wefald seems perfectly suited. For other applications (e.g., the robotic applications described in [5] or the intensive-care applications described in [24]), it is convenient to think in terms of scheduling existing approximation algorithms. <p> This starts to get complicated only when we attempt to model the decisions to be made by the agent, their effects, and the agent's expectations. The formal specification in [4] provides a language for constructing such models, as does Russell and Wefald's definition and analysis of meta-reasoning <ref> [36] </ref>. These two views of time-dependent problems are distinct and may not be easy to reconcile.
Reference: [37] <author> Shekhar, S. and Dutta, S., </author> <title> Minimizing Response Times in Real Time Planning, </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, </address> <institution> Michigan, IJCAI, </institution> <year> 1989, </year> <pages> 972-978. </pages>
Reference-contexts: A line of work running back to [38] views deliberation time as being quantized into chunks of fixed, though not necessarily constant, size. Sproull [39] applies this 1 Not all of it, however. See, for example <ref> [37, 11, 13] </ref> 2 model to a system for planning travel itineraries, though he is more concerned with the use of decision theory to guide planning choices. <p> For our purposes, such computational actions correspond to an agent running a decision procedure, and we refer to such actions as inferential. The results of inferential actions have no immediate effect on the world external to the 2 Not all of it, however. See for example <ref> [37] </ref>. 3 agent, but they do have an effect on the internal state of the agent. In particular, inferential actions consume computational resources that might be spent otherwise and result in the agent revising its estimations regarding how to act in various circumstances.
Reference: [38] <author> Simon, H. A. and Kadane, J. B., </author> <title> Optimal Problem-Solving Search: All-or-None Solutions, </title> <journal> Artificial Intelligence, </journal> <month> 6 </month> <year> (1975) </year> <month> 235-247. </month>
Reference-contexts: I. J. Good's work on Type II rationality laid the foundations for most of the work on decision theoretic deliberation scheduling that has been done since [17]. A line of work running back to <ref> [38] </ref> views deliberation time as being quantized into chunks of fixed, though not necessarily constant, size. Sproull [39] applies this 1 Not all of it, however. <p> The next piece of research that we consider in this section is due to Etzioni [14], and it borrows from the Russell and Wefald work, and builds on the early work of Simon and Kadane <ref> [38] </ref> on satisficing search. It is particularly interesting for the fact that it attempts to combine the sort of goal-driven behavior prevalent in artificial intelligence with the decision theoretic view of maximizing expected utility.
Reference: [39] <author> Sproull, Robert F., </author> <title> Strategy Construction Using a Synthesis of Heuristic and Decision-Theoretic Methods, </title> <type> Technical Report CSL-77-2, </type> <note> Xerox PARC, </note> <year> 1977. </year>
Reference-contexts: Good's work on Type II rationality laid the foundations for most of the work on decision theoretic deliberation scheduling that has been done since [17]. A line of work running back to [38] views deliberation time as being quantized into chunks of fixed, though not necessarily constant, size. Sproull <ref> [39] </ref> applies this 1 Not all of it, however. See, for example [37, 11, 13] 2 model to a system for planning travel itineraries, though he is more concerned with the use of decision theory to guide planning choices.
Reference: [40] <author> Varga, R. S., </author> <title> Matrix Iterative Methods, </title> <publisher> (Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1962). </year>
Reference-contexts: Among the kinds of algorithms we found: * Numerical approximation For example, Taylor series approximations (e.g., computing or e) and iterative finite-element methods <ref> [40] </ref>. * Heuristic search Algorithms for heuristic search, in particular those employing variable lookahead and fast evaluation functions, can be cast as anytime algorithms [29, 28]. * Dynamic Programming Dynamic programming [2] is a general and flexible methodology that can be applied to a wide variety of optimization and control problems,
References-found: 40

