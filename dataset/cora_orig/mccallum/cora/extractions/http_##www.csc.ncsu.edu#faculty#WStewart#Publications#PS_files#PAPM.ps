URL: http://www.csc.ncsu.edu/faculty/WStewart/Publications/PS_files/PAPM.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/WStewart/Publications/Publications.html
Root-URL: http://www.csc.ncsu.edu
Title: Numerical Issues for Stochastic Automata Networks  
Author: Paulo Fernandes Brigitte Plateau and William J. Stewart 
Keyword: Markov chains, Stochastic automata networks, Vector-descriptor multiplications, Grouping of automata, Tensor algebra.  
Date: November 4, 1996  
Abstract: In this paper we consider some numerical issues in computing solutions to networks of stochastic automata (SAN). In particular our concern is with keeping the amount of computation per iteration to a minimum, since iterative methods appear to be the most effective in determining numerical solutions. In a previous paper we presented complexity results concerning the vector-descriptor multiplication phase of the analysis. In this paper our concern is with implementation details. We experiment with the size and sparsity of individual automata; with the ordering of the automata; with the percentage and location of functional elements; with the occurrence of different types of synchronizing events and with the occurrence of cyclic dependencies within terms of the descriptor. We also consider the possible benefits of grouping automata in a SAN with many small automata, to create an equivalent SAN having a smaller number of larger automata. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. </author> <month> Atif. </month> <institution> Modelisation du Parallelisme et de la Synchronisation. These de Docteur de l'Institut National Polytechnique de Grenoble, </institution> <month> 24 September </month> <year> 1992, </year> <institution> Grenoble, France. </institution>
Reference-contexts: In SANs, it is possible to make use use of symmetries as well as lumping and various su-perpositioning of the automata to reduce the computational burden, <ref> [1, 4, 16] </ref>. Furthermore, in [8], structural properties of the Markov chain graph (specifi 2 cially the occurrence of cycles) are used to compute steady state solutions. In the next section the concept of a SAN descriptor is described by means of two examples. <p> Some numerical effects of this phenomenon are illstrated in the next section. Third simplification: Reduction of the reachable state space. In the process of grouping, a situation might arise in which a grouped au tomata G i has a reachable state space smaller than the product state space <ref> [1; : : :; i=c j +1 n i ] </ref>. This happens after simplifications one and/or two have been performed. For example, functions may evaluate to zero, or synchronizing events may disable certain transitions.
Reference: [2] <author> F. Baccelli, A. Jean-Marie and I. Mitrani, </author> <title> Editors, Quantitative Methods in Parallel Systems, Part I : Stochastic Process Algebras; Basic Research Series, </title> <publisher> Springer, </publisher> <year> 1995. </year>
Reference-contexts: The development of languages for specifying stochastic process algebras is mainly concerned with structural properties of the nets (com-positionality, equivalence, etc.) and with the mapping of these specifications onto Markov chains for the computation of performance measures <ref> [2, 3, 10] </ref>. Indeed it is possible to generate the Markov transition matrix of any Stochastic Process Algebra formula in a tensor form, similar to the SAN descriptor.
Reference: [3] <author> P. Buchholz. </author> <title> Equivalence Relations for Stochastic Automata Networks. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year> <month> 22 </month>
Reference-contexts: The development of languages for specifying stochastic process algebras is mainly concerned with structural properties of the nets (com-positionality, equivalence, etc.) and with the mapping of these specifications onto Markov chains for the computation of performance measures <ref> [2, 3, 10] </ref>. Indeed it is possible to generate the Markov transition matrix of any Stochastic Process Algebra formula in a tensor form, similar to the SAN descriptor.
Reference: [4] <author> P. Buchholz. </author> <title> Hierarchical Markovian Models Symmetries and Aggregation; Modelling Techniques and Tools for Computer Performance Evaluation, </title> <editor> Ed. R. Pooley, J.Hillston, </editor> <publisher> Edinburgh, Scotland, </publisher> <pages> pp. 234-246, </pages> <year> 1992. </year>
Reference-contexts: In SANs, it is possible to make use use of symmetries as well as lumping and various su-perpositioning of the automata to reduce the computational burden, <ref> [1, 4, 16] </ref>. Furthermore, in [8], structural properties of the Markov chain graph (specifi 2 cially the occurrence of cycles) are used to compute steady state solutions. In the next section the concept of a SAN descriptor is described by means of two examples.
Reference: [5] <author> M. Davio. </author> <title> Kronecker Products and Shu*e Algebra. </title> <journal> IEEE Trans. Comput, </journal> <volume> Vol. C-30, No. 2, </volume> <pages> pp. 1099-1109, </pages> <year> 1981. </year>
Reference-contexts: The implication is that a considerable saving in memory is effected by storing the matrix in this fashion <ref> [5, 6, 14] </ref>. In this paper we concentrate on procedures that allow us to keep the amount of computation per iteration to a minimum.
Reference: [6] <author> S. Donatelli. </author> <title> Superposed Stochastic Automata: A Class of Stochastic Petri Nets with Parallel Solution and Distributed State Space. </title> <journal> Performance Evaluation, </journal> <volume> Vol. 18, </volume> <pages> pp. 21-36, </pages> <year> 1993. </year>
Reference-contexts: The implication is that a considerable saving in memory is effected by storing the matrix in this fashion <ref> [5, 6, 14] </ref>. In this paper we concentrate on procedures that allow us to keep the amount of computation per iteration to a minimum.
Reference: [7] <author> P. Fernandes, B. Plateau and W.J. Stewart. </author> <title> Efficient Vector-Descriptor Multiplications in Stochastic Automata Networks. </title> <note> INRIA Report # 2935. Anonymous ftp ftp ftp.inria.fr/INRIA/Publication/RR. </note>
Reference-contexts: The implication is that a considerable saving in memory is effected by storing the matrix in this fashion [5, 6, 14]. In this paper we concentrate on procedures that allow us to keep the amount of computation per iteration to a minimum. In a previous paper, <ref> [7] </ref>, we proved a theorem concerning the complexity of a matrix-vector multiplication when the matrix is stored as a compact SAN descriptor, since this step is fundamental to all iterative methods and is usually the most expensive operation in each iteration. <p> Finally, we would like to draw our readers attention to the sparsity of the matrices presented above. 3 Algorithm Analysis 3.1 The Complexity Result and Algorithm We present without proof, the theorem concerning vector-descriptor multiplication and its accompanying algorithm, <ref> [7] </ref>. <p> A given automaton may actually depend on a subset of the automata in its parameter list. Now consider an arbitrary permutation of the factors on the left-hand side of equation (1). In <ref> [7] </ref>, we show how to perform this simple transformation, which gives us the freedom of ordering the factors of a term to optimize computation cost. <p> It is shown in <ref> [7] </ref> that if such a function cannot be found, that is to say, if there is a cyclic dependency of function and argument in a term, this term cannot be exactly decomposed into a number of non-cyclic terms. <p> 3.2.5. 11 4 Some Small Examples Our first objective is to experiment with the size and sparsity of individual automata; with the ordering of automata; with the percentage and location of functional elements; with the occurrence of different types of synchronizing events and with the occurrence of cyclic dependencies, (see <ref> [7] </ref>), within terms of the descriptor. We choose to do so by means of the set of small examples given in Table 1. <p> Usually, we are interested by the smallest cutset for a given graph and cycle. This concept can be used to decompose a tensor term with cyclic dependecy into a sum of cyclic-free tensor terms (see <ref> [7] </ref>). If we compare, for example, the CPU times for SANs S2a and S2b, we see that it is not sensitive to the proportion of synchronized transitions.
Reference: [8] <author> J-M. Fourneau and F. Quessette. </author> <title> Graphs and Stochastic Automata Networks. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: In SANs, it is possible to make use use of symmetries as well as lumping and various su-perpositioning of the automata to reduce the computational burden, [1, 4, 16]. Furthermore, in <ref> [8] </ref>, structural properties of the Markov chain graph (specifi 2 cially the occurrence of cycles) are used to compute steady state solutions. In the next section the concept of a SAN descriptor is described by means of two examples.
Reference: [9] <author> H. Hermanns and M. Rettelbach. </author> <title> Syntax, Semantics, Equivalences, and Axioms for MTIPP. </title> <booktitle> Proc. of the 2nd Workshop on Process Algebras and Performance Modelling, </booktitle> <editor> U. Herzog, M. Rettelbach, Editors, Arbeitsberichte, </editor> <volume> Band 27, No. 4, </volume> <pages> Erlangen, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: The objective of this paper is to analyze the cost of the implementation of this algorithm and to propose improvements that bring its performance close to those of the more usual sparse methods. Stochastic Automata Networks are related to the concept of Stochastic Process Algebras <ref> [9, 10] </ref>. The development of languages for specifying stochastic process algebras is mainly concerned with structural properties of the nets (com-positionality, equivalence, etc.) and with the mapping of these specifications onto Markov chains for the computation of performance measures [2, 3, 10].
Reference: [10] <author> J. Hillston. </author> <title> Computational Markovian Modelling using a Process Algebra. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: The objective of this paper is to analyze the cost of the implementation of this algorithm and to propose improvements that bring its performance close to those of the more usual sparse methods. Stochastic Automata Networks are related to the concept of Stochastic Process Algebras <ref> [9, 10] </ref>. The development of languages for specifying stochastic process algebras is mainly concerned with structural properties of the nets (com-positionality, equivalence, etc.) and with the mapping of these specifications onto Markov chains for the computation of performance measures [2, 3, 10]. <p> The development of languages for specifying stochastic process algebras is mainly concerned with structural properties of the nets (com-positionality, equivalence, etc.) and with the mapping of these specifications onto Markov chains for the computation of performance measures <ref> [2, 3, 10] </ref>. Indeed it is possible to generate the Markov transition matrix of any Stochastic Process Algebra formula in a tensor form, similar to the SAN descriptor.
Reference: [11] <author> P. Kemper. </author> <title> Closing the Gap between Classical and Tensor Based Iteration Techniques. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: The size of the state space generated may become so large that it effectively prohibits the computation of a solution. This is true whether the Markov chain results from a stochastic Petri net formalism, or from a straightforward Markov chain analyzer <ref> [17, 11] </ref>. In many instances, the SAN formalism is an appropriate choice.
Reference: [12] <author> B. </author> <title> Plateau. On the Stochastic Structure of Parallelism and Synchronization Models for Distributed Algorithms. </title> <booktitle> Proc. ACM Sigmetrics Conference on Measurement and Modelling of Computer Systems, </booktitle> <address> Austin, Texas, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: A synchronizing transition may be either functional or constant. In any given automaton, transitions that are not synchronizing transitions are said to be local transitions. As a general rule, it is shown in <ref> [12] </ref>, that stochastic automata networks may always be treated by separating out the local transitions, handling these in the usual fashion by means of a tensor sum and then incorporating the sum of two additional tensor products per synchronizing event.
Reference: [13] <author> B. Plateau and K. Atif. </author> <title> Stochastic Automata Network for Modelling Parallel Systems. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. 17, No. 10, </volume> <pages> pp. 1093-1108, </pages> <year> 1991. </year>
Reference-contexts: Although a SAN may be viewed as a simple stochastic process algebra, its original purpose was to provide an efficient and convenient methodology for the study of quantitive rather than structural properties of complex systems, <ref> [13] </ref>. Nevertheless, computational results such as those presented in this paper can also be applied in the context of stochastic process algebras. There are two overriding concerns in the application of any Markovian mod-elling methodology, viz., memory requirements and computation time.
Reference: [14] <author> B. Plateau and J.M. Fourneau. </author> <title> A Methodology for Solving Markov Models of Parallel Systems. </title> <journal> Journal of Parallel and Distributed Computing. </journal> <volume> Vol. 12, </volume> <pages> pp. 370-387, </pages> <year> 1991. </year>
Reference-contexts: Parallel and distributed systems are often viewed as collections of components that operate more or less independently, requiring only infrequent interaction such as synchronizing their actions, or operating at different rates depending on the state of parts of the overall system. This is exactly the viewpoint adopted by SANs <ref> [14, 19] </ref>. The components are modelled as individual stochastic automata that interact with each other. Furthermore, the state space explosion problem associated with Markov chain models is mitigated by the fact that the state transition matrix is not stored, nor even generated. <p> The implication is that a considerable saving in memory is effected by storing the matrix in this fashion <ref> [5, 6, 14] </ref>. In this paper we concentrate on procedures that allow us to keep the amount of computation per iteration to a minimum.
Reference: [15] <author> B. Plateau, J.M. Fourneau and K.H. Lee. PEPS: </author> <title> A Package for Solving Complex Markov Models of Parallel Systems. </title> <editor> In R. Puigjaner, D. Potier, Eds., </editor> <title> Modelling Techniques and Tools for Computer Performance Evaluation, </title> <address> Spain, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: Better performance is obtained when, considering these constraints, they are ranked in non decreasing size. * Then take the automata that are neither functional nor arguments and rank them last, in any order. All numerical experiments were conducted using the software package PEPS, version 3.0 <ref> [15] </ref>. This version of PEPS is implemented in C++. Only the non-diagonal elements of the descriptor are handled by this algorithm. The diagonal elements of the descriptor are pre-calculated once and stored in a vector. The vector-matrix multiplication includes a dot product with the diagonal entries.
Reference: [16] <author> M. Siegle. </author> <title> On Efficient Markov Modelling. </title> <booktitle> In Proc. QMIPS Workshop on Stochastic Petri Nets, </booktitle> <pages> pp. 213-225, </pages> <address> Sophia-Antipolis, France, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: In SANs, it is possible to make use use of symmetries as well as lumping and various su-perpositioning of the automata to reduce the computational burden, <ref> [1, 4, 16] </ref>. Furthermore, in [8], structural properties of the Markov chain graph (specifi 2 cially the occurrence of cycles) are used to compute steady state solutions. In the next section the concept of a SAN descriptor is described by means of two examples.
Reference: [17] <author> W.J. Stewart. </author> <title> An Introduction to the Numerical Solution of Markov Chains, </title> <publisher> Princeton University Press, </publisher> <address> New Jersey, </address> <year> 1994. </year> <month> 23 </month>
Reference-contexts: The size of the state space generated may become so large that it effectively prohibits the computation of a solution. This is true whether the Markov chain results from a stochastic Petri net formalism, or from a straightforward Markov chain analyzer <ref> [17, 11] </ref>. In many instances, the SAN formalism is an appropriate choice.
Reference: [18] <author> W.J. Stewart. marca: </author> <title> Markov Chain Analyzer. </title> <journal> IEEE Computer Repository No. </journal> <volume> R76 232, </volume> <year> 1976. </year> <note> Also IRISA Publication Interne No. 45, </note> <institution> Universite de Rennes, France. </institution>
Reference-contexts: It is much better to generate the small number of states using a standard sparse matrix approach <ref> [18] </ref>. It may be argued that the best approach (at least for this particular example) is to combine all the automata into just two groups, for this allows us to avoid the state space explosion problem with just a minimal increase in CPU time over a purely sparse approach.
Reference: [19] <author> W.J. Stewart, K. Atif and B. </author> <title> Plateau. The Numerical Solution of Stochastic Automata Networks. </title> <journal> European Journal of Operations Research, </journal> <volume> Vol. 86, No. 3, </volume> <pages> pp. 503-525, </pages> <year> 1995. </year>
Reference-contexts: Parallel and distributed systems are often viewed as collections of components that operate more or less independently, requiring only infrequent interaction such as synchronizing their actions, or operating at different rates depending on the state of parts of the overall system. This is exactly the viewpoint adopted by SANs <ref> [14, 19] </ref>. The components are modelled as individual stochastic automata that interact with each other. Furthermore, the state space explosion problem associated with Markov chain models is mitigated by the fact that the state transition matrix is not stored, nor even generated.
References-found: 19

