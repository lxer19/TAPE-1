URL: http://www.cs.cornell.edu/Info/People/csun/papers/pp93.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/csun/sun.html
Root-URL: 
Title: orthogonal factorizations of large sparse matrices on distributed-memory multiprocessors 1  
Author: Thomas F. Coleman and Chunguang Sun 
Note: Parallel  
Abstract: This paper appears in Proceedings of the Sixth SIAM Conference on Parallel Processing for Scientific Computing, R. F. Sinovec, D. E. Keyes, M. R. Leuze, L. R. Petzold, and D. A. Reed, eds., SIAM, Philadelphia, 1993, pp.457-461. Abstract We describe the issues involved in the design and implementation of an efficient parallel multifrontal algorithm for computing the QR factorization of a large sparse matrix on distributed-memory multiprocessors. The proposed algorithm has the following novel features. First, a supernodal tree computed from the sparsity structure of R is used to organize the numerical factorization. Second, a new algorithm has been designed for the most crucial task in this context|the QR factorization of two upper trapezoidal matrices in parallel. Third, the overall factorization is accomplished by a sequence of Householder and Givens transformations. Experimental results on an Intel iPSC/860 are included. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Chu and A. George, </author> <title> Sparse orthogonal decomposition on a hypercube multiprocessor, </title> <journal> SIAM J. Mat. Anal. Appl., </journal> <volume> 11 (1990), </volume> <pages> pp. 453-465. </pages>
Reference-contexts: A parallel multifrontal sparse QR factorization algorithm. Several parallel algorithms for the numeric phase of the sparse QR factorization on distributed-memory multiprocessors have been described in the literature <ref> [1, 8] </ref>. We propose a new distributed algorithm for the numeric phase of the multifrontal sparse QR factorization described in Section 2. The supernodal tree is mapped onto the multiprocessors by a proportional mapping algorithm [9]. The root of the supernodal tree is partitioned among all processors. <p> The distributed sparse submatrix merge is accomplished by a block approach on a chain of processors. This approach tries to reduce the communication cost and avoids the potential danger of communication deadlock on a ring of processors such as the algorithm described in <ref> [1] </ref>. No practical performance results are given in [1]. Our approach also avoids the disadvantage of the algorithm described in [8] where the amount of arithmetic work increases as number of processors increases. <p> This approach tries to reduce the communication cost and avoids the potential danger of communication deadlock on a ring of processors such as the algorithm described in <ref> [1] </ref>. No practical performance results are given in [1]. Our approach also avoids the disadvantage of the algorithm described in [8] where the amount of arithmetic work increases as number of processors increases.
Reference: [2] <author> T. F. Coleman and C. Sun, </author> <title> Parallel orthogonal factorizations of large sparse matrices on distributed-memory multiprocessors. Work in preparation, </title> <year> 1992. </year>
Reference-contexts: A comprehensive description of our algorithm and experimental results will be given in <ref> [2] </ref>. Acknowledgements. This research was partially supported by the Cornell Theory Center, which receives major funding from the National Science Foundation and the IBM corporation, with additional support from New York State and members of its Corporate Research Institute.
Reference: [3] <author> J. A. George, </author> <title> Nested dissection of a regular finite element mesh, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 10 (1973), </volume> <pages> pp. 345-363. </pages>
Reference-contexts: This row is repeated r times to obtain a (k 1) 2 r by k 2 sparse matrix. A matrix associated with a 3D grid can be similarly constructed. The grid problems are ordered by the nested dissection ordering <ref> [3] </ref>. The problems with irregular sparsity structure are generated randomly. The number of nonzero entries in a row is limited. However, the locations of the nonzero entries in a row are randomly distributed. Random problems are ordered by the minimum degree ordering [5].
Reference: [4] <author> J. A. George and M. T. Heath, </author> <title> Solution of sparse linear least squares problems using Givens rotations, Linear Algebra and its Appl., </title> <booktitle> 34 (1980), </booktitle> <pages> pp. 69-83. </pages>
Reference-contexts: Usually Q is not formed explicitly. It is well known that the upper triangular matrix R is mathematically equivalent to the Cholesky factor of A T A. George and Heath <ref> [4] </ref> propose a row merging scheme for reducing A to R by a sequence of Givens rotations. Liu [7] generalizes the George and Heath scheme into a general row merging scheme which leads to substantial reduction in arithmetic operations. 2. A multifrontal sparse QR factorization algorithm.
Reference: [5] <author> J. A. George and J. W. H. Liu, </author> <title> The evolution of the minimum degree algorithm, </title> <journal> SIAM Review, </journal> <volume> 31 (1989), </volume> <pages> pp. 1-19. </pages>
Reference-contexts: The problems with irregular sparsity structure are generated randomly. The number of nonzero entries in a row is limited. However, the locations of the nonzero entries in a row are randomly distributed. Random problems are ordered by the minimum degree ordering <ref> [5] </ref>.
Reference: [6] <author> J. W. H. Liu, </author> <title> A compact row storage scheme for Cholesky factors using elimination trees, </title> <journal> ACM Trans. on Math. Software, </journal> <volume> 12 (1986), </volume> <pages> pp. </pages> <month> 127-148. </month> <title> [7] , On general row merging schemes for sparse Givens transformations, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 7 (1986), </volume> <pages> pp. 1190-1211. </pages>
Reference-contexts: A multifrontal algorithm for sparse QR factorization is described below. 1. find a column ordering for A such that R is sparse. 2. compute the elimination tree of R T by using the algorithm described in <ref> [6] </ref> and number the nodes of the elimination tree in postorder. 3. determine the symbolic structure of R. 4. compute the supernodal tree of R T from the corresponding elimination tree and number the supernodes in postorder. 5. perform numerical factorization by processing the supernodes in order.
Reference: [8] <author> P. E. Plassmann, </author> <title> Sparse Jacobian estimation and factorization on a multiprocessor, in Large-Scale Numerical Optimization, </title> <editor> T. F. Coleman and Y. Li, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1990, </year> <pages> pp. 152-179. </pages>
Reference-contexts: A parallel multifrontal sparse QR factorization algorithm. Several parallel algorithms for the numeric phase of the sparse QR factorization on distributed-memory multiprocessors have been described in the literature <ref> [1, 8] </ref>. We propose a new distributed algorithm for the numeric phase of the multifrontal sparse QR factorization described in Section 2. The supernodal tree is mapped onto the multiprocessors by a proportional mapping algorithm [9]. The root of the supernodal tree is partitioned among all processors. <p> This approach tries to reduce the communication cost and avoids the potential danger of communication deadlock on a ring of processors such as the algorithm described in [1]. No practical performance results are given in [1]. Our approach also avoids the disadvantage of the algorithm described in <ref> [8] </ref> where the amount of arithmetic work increases as number of processors increases.
Reference: [9] <author> A. Pothen and C. Sun, </author> <title> A distributed multifrontal algorithm using clique trees, </title> <type> Tech. Report 91-24, </type> <institution> Computer Science, Pennsylvania State University, University Park, </institution> <address> PA, </address> <year> 1991. </year> <month> 5 </month>
Reference-contexts: We propose a new distributed algorithm for the numeric phase of the multifrontal sparse QR factorization described in Section 2. The supernodal tree is mapped onto the multiprocessors by a proportional mapping algorithm <ref> [9] </ref>. The root of the supernodal tree is partitioned among all processors. If a supernode has already been mapped to a set of processors, each subtree rooted at a child of that supernode is allocated a subset of processors whose size is proportional to the workload associated with that subtree.
References-found: 8

