URL: http://www.isi.edu/soar/jihie/papers/95.ps
Refering-URL: http://www.isi.edu/soar/jihie/chunking.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A Transformational Analysis of the EBL Utility Problem in Soar  
Author: Jihie Kim and Paul S. Rosenbloom 
Keyword: Key words: Learning, EBL, utility problem, expensive chunks, Soar  
Address: 4676 Admiralty Way Marina del Rey, CA 90292, U.S.A.  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Email: jihie@isi.edu, rosenbloom@isi.edu  
Phone: (310) 822-1510  
Web: (x769)  
Abstract: Efficiency is a major concern for all planning systems. One way of achieving efficiency is the application of learning techniques to speed up planning. Accordingly, there has been considerable amount of research on applying EBL (explanation-based learning) techniques to planning. However, EBL is known to suffer from the utility problem, where the cost of using the learned knowledge overwhelms its benefit. This paper shows how the cost increase of a learned rule in an EBL system can be analyzed by characterizing the learning process as a sequence of transformations from a planning (problem solving) episode to a learned rule. The analysis of how the cost changes through the transformations can be a useful tool for revealing the sources of cost increase in the learning system. In this paper, we focus on the Soar planning system which uses a variant of EBL called chunking. The chunking process has been decomposed into a sequence of transformations from the planning to a chunk. By analyzing these transformations, we have identified a set of sources which can make the output chunk expensive. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. M. Mitchell, R. M. Keller, and S. T. Kedar-Cabelli. </author> <title> Explanation-based generalization a unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: Finally, Section 4 describes work done beyond the analysis and discusses issues for future work. 2 Background In Soar, productions comprise the domain theory for EBL <ref> [1, 2] </ref>. Each production consists of a set of conditions and a set of actions. Conditions test working memory for the presence or absence of patterns of tuples, where each tuple consists of an object identifier, an attribute and a value.
Reference: [2] <author> G. F. DeJong and R. Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-176, </pages> <year> 1986. </year>
Reference-contexts: Finally, Section 4 describes work done beyond the analysis and discusses issues for future work. 2 Background In Soar, productions comprise the domain theory for EBL <ref> [1, 2] </ref>. Each production consists of a set of conditions and a set of actions. Conditions test working memory for the presence or absence of patterns of tuples, where each tuple consists of an object identifier, an attribute and a value.
Reference: [3] <author> S. Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 564-569, </pages> <year> 1988. </year>
Reference-contexts: Given the four informational components (the goal concept, the training example, the domain theory, and the operationality criterion), EBL generates a new rule which can cut down the search in subsequent planning problems. Accordingly, there has been a considerable amount of research on applying EBL techniques to planning <ref> [3, 4, 5] </ref>. For example, [5] uses EBL to learn search-control rules from SNLP's [6, 7] failures, and improves the planning performance. They claim that their framework can be easily extended to UCPOP [8] as well. <p> Research on the utility problem has focused on two key issues. The first issue is the expensive chunk problem 2 [9], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [3, 10, 11, 12, 13] </ref>. The second issue is the average growth effect [14], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use [14, 15]. This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules <ref> [16, 3, 12, 17, 11, 10] </ref> or filtering out expensive rules [3, 18, 19, 20]. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned. <p> This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules [16, 3, 12, 17, 11, 10] or filtering out expensive rules <ref> [3, 18, 19, 20] </ref>. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned. <p> This structure can be 5 In addition, architectural actions that occurred during the planning episode are replaced in the P-chunk by dummy rules that have the same effect, much in the way that architectural axioms are used in Prodigy/EBL <ref> [3] </ref>. 8 mapped onto the normal backtrace in chunking. The only difference between an E-chunk and a backtrace is that a backtrace consists of instantiations while an E-chunk consists of rules. By replacing the rules in the trace, a backtrace can be directly mapped to an E-chunk.
Reference: [4] <author> P. S. Rosenbloom, S. Lee, and A. Unruh. </author> <title> Responding to impasses in memory-driven behavior. </title> <booktitle> In Proceedings of the Workshop on Innovative Approaches to Planning, Scheduling, and Control, </booktitle> <pages> pages 181-191, </pages> <year> 1990. </year>
Reference-contexts: Given the four informational components (the goal concept, the training example, the domain theory, and the operationality criterion), EBL generates a new rule which can cut down the search in subsequent planning problems. Accordingly, there has been a considerable amount of research on applying EBL techniques to planning <ref> [3, 4, 5] </ref>. For example, [5] uses EBL to learn search-control rules from SNLP's [6, 7] failures, and improves the planning performance. They claim that their framework can be easily extended to UCPOP [8] as well. <p> Plans in Soar are represented as sets of control rules that jointly specify which operators should be executed at each point in time. Research on Soar-based planning has demonstrated how standard planning methods (both linear and partial order) can be derived from Soar's problem solving context <ref> [4, 25, 26] </ref>. Note that the term planning in this paper will mean the derived planning from Soar's problem solving.
Reference: [5] <author> S. Katukam and S. Kambhampati. </author> <title> Learning explanation-based search control rules for partial order planning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 582-587, </pages> <year> 1994. </year>
Reference-contexts: Given the four informational components (the goal concept, the training example, the domain theory, and the operationality criterion), EBL generates a new rule which can cut down the search in subsequent planning problems. Accordingly, there has been a considerable amount of research on applying EBL techniques to planning <ref> [3, 4, 5] </ref>. For example, [5] uses EBL to learn search-control rules from SNLP's [6, 7] failures, and improves the planning performance. They claim that their framework can be easily extended to UCPOP [8] as well. <p> Accordingly, there has been a considerable amount of research on applying EBL techniques to planning [3, 4, 5]. For example, <ref> [5] </ref> uses EBL to learn search-control rules from SNLP's [6, 7] failures, and improves the planning performance. They claim that their framework can be easily extended to UCPOP [8] as well.
Reference: [6] <author> A. Barrett and D.S. Weld. </author> <title> Partial order planning: Evaluating possible efficiency gains. </title> <journal> Artificial Intelligence, </journal> <volume> 67(1), </volume> <year> 1994. </year>
Reference-contexts: Accordingly, there has been a considerable amount of research on applying EBL techniques to planning [3, 4, 5]. For example, [5] uses EBL to learn search-control rules from SNLP's <ref> [6, 7] </ref> failures, and improves the planning performance. They claim that their framework can be easily extended to UCPOP [8] as well.
Reference: [7] <author> D. McAllester and D. Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <year> 1991. </year>
Reference-contexts: Accordingly, there has been a considerable amount of research on applying EBL techniques to planning [3, 4, 5]. For example, [5] uses EBL to learn search-control rules from SNLP's <ref> [6, 7] </ref> failures, and improves the planning performance. They claim that their framework can be easily extended to UCPOP [8] as well.
Reference: [8] <author> J.S. Penberthy and D.S. Weld. UCPOP: </author> <title> A sound, complete partial order planner for adl. </title> <booktitle> In Proceedings of KRR-92, </booktitle> <year> 1992. </year>
Reference-contexts: Accordingly, there has been a considerable amount of research on applying EBL techniques to planning [3, 4, 5]. For example, [5] uses EBL to learn search-control rules from SNLP's [6, 7] failures, and improves the planning performance. They claim that their framework can be easily extended to UCPOP <ref> [8] </ref> as well. Unfortunately, EBL is known to suffer from the utility problem, where the cost of using the learned knowledge may overwhelm its benefit. 1 Addressing this problem is critical for planning systems which intend to speed up by learning EBL rules.
Reference: [9] <author> M. Tambe, A. Newell, and P. S. Rosenbloom. </author> <title> The problem of expensive chunks and its solution by restricting expressiveness. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 299-348, </pages> <year> 1990. </year>
Reference-contexts: Research on the utility problem has focused on two key issues. The first issue is the expensive chunk problem 2 <ref> [9] </ref>, in which individual learned rules are so expensive to match that the system suffers a slow down from learning [3, 10, 11, 12, 13].
Reference: [10] <author> M. Tambe. </author> <title> Eliminating combinatorics from production match. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <year> 1991. </year>
Reference-contexts: Research on the utility problem has focused on two key issues. The first issue is the expensive chunk problem 2 [9], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [3, 10, 11, 12, 13] </ref>. The second issue is the average growth effect [14], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use [14, 15]. This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules <ref> [16, 3, 12, 17, 11, 10] </ref> or filtering out expensive rules [3, 18, 19, 20]. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned. <p> A negative node passes a partial instantiation when there are no consistent WMEs. 5 C2. Beta memories store partial instantiations of productions, that is, instantiations of initial subsequences of conditions. The partial instantiations are called tokens. Because match time per token is known to be approximately constant in Rete <ref> [30, 10] </ref> | and because counting tokens yields a measure that is independent of machines, optimizations, and implementation details | we will follow the standard practice established within the match-algorithm community and use the number of tokens, rather than time, as our comparative measure of match cost. 3 Transforming planning to <p> By analyzing how the transformations alter these costs, the sources of added expensiveness are revealed. The following subsections discuss each transformation shown in Figure 3, including their resulting (pseudo-)chunks and their effects on cost. These discussions are presented in the context of a simplified Grid task <ref> [10] </ref>. Each problem in the Grid task is to find a path between two points in two dimensional space. Figure 4-(a) shows an example Grid task, and Figure 4-(b) shows a part of the Grid task; that of evaluating which operator is best in particular situations.
Reference: [11] <author> O. Etzioni. </author> <title> Why prodigy/ebl works. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 916-922, </pages> <year> 1990. </year>
Reference-contexts: Research on the utility problem has focused on two key issues. The first issue is the expensive chunk problem 2 [9], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [3, 10, 11, 12, 13] </ref>. The second issue is the average growth effect [14], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use [14, 15]. This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules <ref> [16, 3, 12, 17, 11, 10] </ref> or filtering out expensive rules [3, 18, 19, 20]. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned.
Reference: [12] <author> P. Shell and J. Carbonell. </author> <title> Empirical and analytical performance of iterative operators. </title> <booktitle> In The 13th Annual Conference of The Cognitive Science Society, </booktitle> <pages> pages 898-902. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1991. </year>
Reference-contexts: Research on the utility problem has focused on two key issues. The first issue is the expensive chunk problem 2 [9], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [3, 10, 11, 12, 13] </ref>. The second issue is the average growth effect [14], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use [14, 15]. This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules <ref> [16, 3, 12, 17, 11, 10] </ref> or filtering out expensive rules [3, 18, 19, 20]. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned.
Reference: [13] <author> D. Subramanian and R. Feldman. </author> <title> The utility of ebl in recursive domain theories. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 942-949, </pages> <year> 1990. </year>
Reference-contexts: Research on the utility problem has focused on two key issues. The first issue is the expensive chunk problem 2 [9], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [3, 10, 11, 12, 13] </ref>. The second issue is the average growth effect [14], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive.
Reference: [14] <author> B. Doorenbos, M. Tambe, and A. </author> <title> Newell. </title> <booktitle> Learning 10,000 chunks: What's it like out there? In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 830-836, </pages> <year> 1992. </year>
Reference-contexts: The first issue is the expensive chunk problem 2 [9], in which individual learned rules are so expensive to match that the system suffers a slow down from learning [3, 10, 11, 12, 13]. The second issue is the average growth effect <ref> [14] </ref>, in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use [14, 15]. <p> Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use <ref> [14, 15] </ref>. This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules [16, 3, 12, 17, 11, 10] or filtering out expensive rules [3, 18, 19, 20].
Reference: [15] <author> B. Doorenbos. </author> <title> Matching 100,000 learned rules. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <year> 1993. </year> <month> 14 </month>
Reference-contexts: Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use <ref> [14, 15] </ref>. This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules [16, 3, 12, 17, 11, 10] or filtering out expensive rules [3, 18, 19, 20].
Reference: [16] <author> A. E. Prieditis and J. Mostow. Prolearn: </author> <title> Towards a prolog interpreter that learns. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 494-498, </pages> <year> 1987. </year>
Reference-contexts: Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use [14, 15]. This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules <ref> [16, 3, 12, 17, 11, 10] </ref> or filtering out expensive rules [3, 18, 19, 20]. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned.
Reference: [17] <author> Jude W. Shavlik. </author> <title> Aquiring recursive and iterative concepts with explanation-based learning. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 39-70, </pages> <year> 1990. </year>
Reference-contexts: Recent work on the average growth effect has shown that it is possible to learn over one million rules while still allowing their efficient use [14, 15]. This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules <ref> [16, 3, 12, 17, 11, 10] </ref> or filtering out expensive rules [3, 18, 19, 20]. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned.
Reference: [18] <author> R. Greiner and I. Jurisica. </author> <title> A statistical approach to solving the ebl utility problem. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 241-248, </pages> <year> 1992. </year>
Reference-contexts: This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules [16, 3, 12, 17, 11, 10] or filtering out expensive rules <ref> [3, 18, 19, 20] </ref>. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned.
Reference: [19] <author> J. Gratch and G. Dejong. Composer: </author> <title> A probabilistic solution to the utility problem in speed-up learning. </title> <booktitle> In Proceedings of the Tenth National Conference on Aritificial Intelligence, </booktitle> <pages> pages 235-240, </pages> <year> 1992. </year>
Reference-contexts: This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules [16, 3, 12, 17, 11, 10] or filtering out expensive rules <ref> [3, 18, 19, 20] </ref>. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned.
Reference: [20] <author> S. Markovitch and P. D. Scott. </author> <title> Information filtering : Selection mechanism in learning systems. </title> <journal> Machine Learning, </journal> <volume> 10(2) </volume> <pages> 113-151, </pages> <year> 1993. </year>
Reference-contexts: This research focuses on the expensive chunk problem in EBL. There have been approaches which are useful for producing cheaper rules [16, 3, 12, 17, 11, 10] or filtering out expensive rules <ref> [3, 18, 19, 20] </ref>. However, these approaches cannot generally guarantee that the cost of using the learned rules will always be bounded by the cost of the planning episode from which they are learned.
Reference: [21] <author> A. Segre and C. Elkan. </author> <title> A high-performance explanation-based learning algorithm. </title> <journal> Artificial Intelligence, </journal> <volume> 69 </volume> <pages> 1-50, </pages> <year> 1994. </year>
Reference-contexts: In the context of solving the expensive chunk problem, we can use the analysis as a tool for pointing out where extra cost is being added. This approach is similar in spirit to <ref> [21, 22] </ref> in its use of a transformational analysis of the learning algorithm. However, the focus of their analysis and resulting algorithm development was on speedup rather than on boundedness, and on STRIPS-type macro-operator learning rather than on search control learning.
Reference: [22] <author> Henrik Bostrom. </author> <title> Improving example-guided unfolding. </title> <booktitle> In Proceedings of ECML-93, </booktitle> <pages> pages 124-135, </pages> <year> 1993. </year>
Reference-contexts: In the context of solving the expensive chunk problem, we can use the analysis as a tool for pointing out where extra cost is being added. This approach is similar in spirit to <ref> [21, 22] </ref> in its use of a transformational analysis of the learning algorithm. However, the focus of their analysis and resulting algorithm development was on speedup rather than on boundedness, and on STRIPS-type macro-operator learning rather than on search control learning. <p> However, the focus of their analysis and resulting algorithm development was on speedup rather than on boundedness, and on STRIPS-type macro-operator learning rather than on search control learning. Also note that transformation in <ref> [22] </ref> means construction of a new domain theory, while transformation here refers to the changes from one planning/rule hybrid to the next hybrid until it becomes a rule. 1 The utility problem is discussed in terms of two general techniques; macro-operator learning and search-control learning.
Reference: [23] <author> P. S. Rosenbloom, J. E. Laird, A. Newell, and R. McCarl. </author> <title> A preliminary analysis of the Soar architecture as a basis for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 47(1-3):289-325, </volume> <year> 1991. </year>
Reference-contexts: This research focuses on the utility problem in acquiring search-control rules. 2 Chunk means any learned rule. This is a generalization of the term used in the Soar system. 2 The focus of the analysis in this paper is chunking in Soar <ref> [23] </ref>. Soar is an architecture that combines general problem solving abilities with a chunking mechanism that is a variant of explanation-based learning [24]. Plans in Soar are represented as sets of control rules that jointly specify which operators should be executed at each point in time. <p> However, chunking employs only traces from task-definition rules; that is, rules that directly propose values of WMEs. Search-control rules, as distinguished from task-definition rules, suggest the relative worth of the proposed values. The search-control rules are missing in chunking <ref> [31, 23] </ref> (and other EBL systems [32]) based on the assumption that they only affect the efficiency, not the correctness of learned rules.
Reference: [24] <author> P. S. Rosenbloom and J. E. Laird. </author> <title> Mapping explanation-based generalization onto Soar. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 561-567, </pages> <address> Philadelphia, 1986. </address> <publisher> AAAI. </publisher>
Reference-contexts: This is a generalization of the term used in the Soar system. 2 The focus of the analysis in this paper is chunking in Soar [23]. Soar is an architecture that combines general problem solving abilities with a chunking mechanism that is a variant of explanation-based learning <ref> [24] </ref>. Plans in Soar are represented as sets of control rules that jointly specify which operators should be executed at each point in time. Research on Soar-based planning has demonstrated how standard planning methods (both linear and partial order) can be derived from Soar's problem solving context [4, 25, 26].
Reference: [25] <author> S. Lee and P.S. Rosenbloom. </author> <title> Granularity in multi-method planning. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence. American Association for Artificial Intelligence, </booktitle> <year> 1993. </year>
Reference-contexts: Plans in Soar are represented as sets of control rules that jointly specify which operators should be executed at each point in time. Research on Soar-based planning has demonstrated how standard planning methods (both linear and partial order) can be derived from Soar's problem solving context <ref> [4, 25, 26] </ref>. Note that the term planning in this paper will mean the derived planning from Soar's problem solving.
Reference: [26] <author> P. S. Rosenbloom, S. Lee, and A. Unruh. </author> <title> Bias in planning and explanation-based learning. </title> <editor> In S. Minton, editor, </editor> <title> Machine Learning Methods for Planning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Plans in Soar are represented as sets of control rules that jointly specify which operators should be executed at each point in time. Research on Soar-based planning has demonstrated how standard planning methods (both linear and partial order) can be derived from Soar's problem solving context <ref> [4, 25, 26] </ref>. Note that the term planning in this paper will mean the derived planning from Soar's problem solving.
Reference: [27] <author> J. Kim and P. S. Rosenbloom. </author> <title> Constraining learning with search control. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 174-181, </pages> <year> 1993. </year>
Reference-contexts: In the context of characterizing learning systems as a sequence of transformations, our prior work has revealed one source of added expensiveness: in chunking (and other EBL systems which use search control in planning), eliminating search control in learning can increase the cost of the learned rules <ref> [27] </ref>. <p> The consequence of eliminating search control is that the E-chunk is not constrained by the path actually taken in the search space, and thus can perform an exponential amount of search even when the original search was highly directed (by the control rules), as analyzed in <ref> [27] </ref>. In the above example, without constraining eval-operator to the best candidate | which has priority 1 | the number of tokens in the match of rule R3 increases from 7 to 14. Overall, the total number of tokens increases from 17 to 20. <p> We are currently investigating three such modifications, one for each cost-increasing transformation in the current sequence: 1. Removing search control: to incorporate search control in chunking <ref> [27] </ref>. By incorporating search control in the explanation structure, the match process for the learned rule can focus on the path that was actually followed. 2. Unifying: to preprocess instantiations before they are used.
Reference: [28] <author> C. L. Forgy. </author> <title> Rete: A fast algorithm for the many pattern/many object pattern match problem. </title> <journal> Artificial Intelligence, </journal> <volume> 19(1) </volume> <pages> 17-37, </pages> <year> 1982. </year>
Reference-contexts: will mean just the match cost of all of the rules that fired to generate the result (whether this be via multiple rules during the initial planning, or via a single chunk). 3 Because computing match cost is dependent on the match algorithm used, we briefly review the Rete algorithm <ref> [28, 29] </ref> employed in Soar. Rete is one of the most efficient rule-match algorithms presently known. Its efficiency stems primarily from two key optimizations: sharing and state saving. Sharing of common conditions in a production, or across a set of productions, reduces the number of tests performed during match.
Reference: [29] <author> P. Nayak, A. Gupta, and P. S. Rosenbloom. </author> <title> Comparison of the Rete and Treat production matchers for Soar (a summary). </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 693-698, </pages> <year> 1988. </year>
Reference-contexts: will mean just the match cost of all of the rules that fired to generate the result (whether this be via multiple rules during the initial planning, or via a single chunk). 3 Because computing match cost is dependent on the match algorithm used, we briefly review the Rete algorithm <ref> [28, 29] </ref> employed in Soar. Rete is one of the most efficient rule-match algorithms presently known. Its efficiency stems primarily from two key optimizations: sharing and state saving. Sharing of common conditions in a production, or across a set of productions, reduces the number of tests performed during match.
Reference: [30] <author> M. Tambe, D. Kalp, A. Gupta, C. L. Forgy, B. G. Milnes, and A. Newell. Soar/psm-e: </author> <title> Investigating match parallelism in a learning production system. </title> <booktitle> In Proceedings of the ACM/SIGPLAN Symposium on Parallel Programming: Experience with applications, languages, and systems, </booktitle> <pages> pages 146-160, </pages> <year> 1988. </year> <month> 15 </month>
Reference-contexts: A negative node passes a partial instantiation when there are no consistent WMEs. 5 C2. Beta memories store partial instantiations of productions, that is, instantiations of initial subsequences of conditions. The partial instantiations are called tokens. Because match time per token is known to be approximately constant in Rete <ref> [30, 10] </ref> | and because counting tokens yields a measure that is independent of machines, optimizations, and implementation details | we will follow the standard practice established within the match-algorithm community and use the number of tokens, rather than time, as our comparative measure of match cost. 3 Transforming planning to
Reference: [31] <author> J. E. Laird, P. S. Rosenbloom, and A. Newell. </author> <title> Overgeneralization during knowledge com-pilation in Soar. </title> <booktitle> In Proceedings of the Workshop on Knowledge Compilation, </booktitle> <pages> pages 46-57, </pages> <year> 1986. </year>
Reference-contexts: However, chunking employs only traces from task-definition rules; that is, rules that directly propose values of WMEs. Search-control rules, as distinguished from task-definition rules, suggest the relative worth of the proposed values. The search-control rules are missing in chunking <ref> [31, 23] </ref> (and other EBL systems [32]) based on the assumption that they only affect the efficiency, not the correctness of learned rules.
Reference: [32] <author> S. Minton. </author> <type> Personal communication. </type> <year> 1993. </year>
Reference-contexts: However, chunking employs only traces from task-definition rules; that is, rules that directly propose values of WMEs. Search-control rules, as distinguished from task-definition rules, suggest the relative worth of the proposed values. The search-control rules are missing in chunking [31, 23] (and other EBL systems <ref> [32] </ref>) based on the assumption that they only affect the efficiency, not the correctness of learned rules.
Reference: [33] <author> J. Kim and P.S. Rosenbloom. </author> <title> Mapping explanation-based learning onto Soar: The sequel. In Technical Report :Transformation analyses of learning in SOAR. </title> <institution> ISI/RR-95-4221, Information Science Institute and Computer Science Department University of Southern California, </institution> <year> 1995. </year> <month> 16 </month>
Reference-contexts: A similar transformational analysis should also be possible for any planning systems which use EBL techniques. As with the analysis of chunking, this analysis should identify sources of expensiveness in EBL, and help guide the design of safer EBL mechanisms <ref> [33] </ref>.
References-found: 33

