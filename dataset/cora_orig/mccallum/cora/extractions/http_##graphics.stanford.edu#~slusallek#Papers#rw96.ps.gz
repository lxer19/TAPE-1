URL: http://graphics.stanford.edu/~slusallek/Papers/rw96.ps.gz
Refering-URL: http://graphics.stanford.edu/~slusallek/cv.html
Root-URL: http://www.cs.stanford.edu
Email: Email: fslusallek,seidelg@informatik.uni-erlangen.de  
Title: Towards an Open Rendering Kernel for Image Synthesis  
Author: Philipp Slusallek and Hans-Peter Seidel 
Address: Am Weichselgarten 9, D-91058 Erlangen, Germany  
Affiliation: Universitat Erlangen, IMMD IX, Graphische Datenverarbeitung  
Abstract: In order to use realistic image synthesis successfully in research and development as well as in commercial products, two important prerequisites have to be fulfilled. First of all, good, accurate, robust, and fast algorithms are required. Impressive progress has been made in this respect during the last years, which has also been documented in this workshop. The second step is the creation of a suitable and general software architecture, that offers an environment into which these rendering algorithms can be integrated. In this paper, we develop an architecture that consists of a small, but flexible rendering kernel. This kernel provides a general framework for rendering algorithms and defines suitable interfaces for specific aspects of rendering, like reflection (BRDF) or emission. Algorithms for a certain aspect of the rendering process can then be plugged into the kernel in order to implement a particular rendering strategy. The benefits of this approach is demonstrated with several applications.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> P. H. Christensen, E. J. Stollnitz, D. Salesin, and T. D. DeRose. </author> <title> Wavelet radiance. </title> <booktitle> In Fifth EUROGRAPHICS Workshop on Rendering, </booktitle> <pages> pages 287-301, </pages> <address> Darmstadt, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: The current list of supported algorithms includes finite element algorithms like Progressive Refinement Radiosity [2], Galerkin Ra-diosity [29], Hierarchical and Wavelet Radiosity [8, 7], as well as three Wavelet Radiance algorithms <ref> [16, 1] </ref>. From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators [25] have been implemented. Several hybrid techniques like Irradiance Gradients [28, 27], and Backward Beam-Tracing [3] are also available.
Reference: 2. <author> M. Cohen, S. E. Chen, J. R. Wallace, and D. P. Greenberg. </author> <title> A progressive refinement approach to fast radiosity image generation. </title> <booktitle> Computer Graphics (SIGGRAPH '88 Proceedings), </booktitle> <volume> 22(4) </volume> <pages> 75-84, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The current list of supported algorithms includes finite element algorithms like Progressive Refinement Radiosity <ref> [2] </ref>, Galerkin Ra-diosity [29], Hierarchical and Wavelet Radiosity [8, 7], as well as three Wavelet Radiance algorithms [16, 1]. From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators [25] have been implemented.
Reference: 3. <author> S. Collins. </author> <title> Adaptive splatting for specular to diffuse light transport. </title> <editor> In S. Haas, S. Muller, G. Sakas, and P. Shirley, editors, </editor> <booktitle> Fifth EUROGRAPHICS Workshop on Rendering, </booktitle> <pages> pages 119-135, </pages> <address> Darmstadt, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Of course, a number of hybrid techniques that combine aspects of both approaches are also available <ref> [26, 3] </ref>. 2.2 Stages The process of rendering can be divided into three distinct stages, which also roughly correspond to three different phases during rendering: scene description, lighting calculation, image rendering (see Figure 1). Fig. 1. The three stages of the rendering process: scene description, lighting calculation, and image rendering. <p> From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators [25] have been implemented. Several hybrid techniques like Irradiance Gradients [28, 27], and Backward Beam-Tracing <ref> [3] </ref> are also available. This collection of algorithms is the basis for much of our current work in this area. (a) Monte-Carlo (b) Wavelet Radiosity Fig. 3. Two example images computed with global illumination.
Reference: 4. <author> R. Cook, L. Carpenter, and E. Catmull. </author> <title> The Reyes image rendering architecture. </title> <booktitle> Computer Graphics (SIGGRAPH '87 Proceedings), </booktitle> <volume> 21(4) </volume> <pages> 95-102, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: The kernel software with selected will be made available to interested researchers. 1.2 Previous work Several other architectures for rendering have been published. However, most of them were restricted to a single rendering technique, e.g. <ref> [4, 10, 17, 26] </ref>. In contrast, the Cornell "testbed for image synthesis" [23] offers a large tool box of modules for implementing advanced rendering and global illumination algorithms, but it lacks a well-structured framework.
Reference: 5. <author> A. Glassner. </author> <title> Spectrum: An architecture for image synthesis, research, education, and practice. </title> <editor> In P. S. Strauss, editor, </editor> <title> Developing Large-scale Graphics Software Toolkits, </title> <booktitle> (SIGGRAPH '93 Course Notes 3), pages 1.1-1.44. SIGGRAPH, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: In contrast, the Cornell "testbed for image synthesis" [23] offers a large tool box of modules for implementing advanced rendering and global illumination algorithms, but it lacks a well-structured framework. Another interesting approach is Glassner's "Spectrum" architecture <ref> [5] </ref>, which describes a general object-oriented framework for global illumination based on a signal processing approach.
Reference: 6. <author> C. M. Goral, K. E. Torrance, and D. P. Greenberg. </author> <title> Modeling the interaction of light between diffuse surfaces. </title> <booktitle> Computer Graphics (SIGGRAPH '84 Proceedings), </booktitle> <volume> 18(3) </volume> <pages> 212-222, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: All solution techniques in use today for solving the problem, which is described mathematically by the radiance or rendering equation [9], can be roughly classified into two groups: the Monte-Carlo [9, 25, 18], and the finite-element approach <ref> [6, 8, 16] </ref>.
Reference: 7. <author> S. J. Gortler, P. Schroder, M. Cohen, and P. M. Hanrahan. </author> <title> Wavelet radiosity. </title> <booktitle> Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <volume> 27 </volume> <pages> 221-230, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: The current list of supported algorithms includes finite element algorithms like Progressive Refinement Radiosity [2], Galerkin Ra-diosity [29], Hierarchical and Wavelet Radiosity <ref> [8, 7] </ref>, as well as three Wavelet Radiance algorithms [16, 1]. From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators [25] have been implemented. Several hybrid techniques like Irradiance Gradients [28, 27], and Backward Beam-Tracing [3] are also available.
Reference: 8. <author> P. Hanrahan, D. Salzmann, and L. Aupperle. </author> <title> A rapid hierarchical radiosity algorithm. </title> <booktitle> Computer Graphics (SIGGRAPH '91 Proceedings), </booktitle> <volume> 25(4) </volume> <pages> 197-206, </pages> <year> 1991. </year>
Reference-contexts: All solution techniques in use today for solving the problem, which is described mathematically by the radiance or rendering equation [9], can be roughly classified into two groups: the Monte-Carlo [9, 25, 18], and the finite-element approach <ref> [6, 8, 16] </ref>. <p> The current list of supported algorithms includes finite element algorithms like Progressive Refinement Radiosity [2], Galerkin Ra-diosity [29], Hierarchical and Wavelet Radiosity <ref> [8, 7] </ref>, as well as three Wavelet Radiance algorithms [16, 1]. From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators [25] have been implemented. Several hybrid techniques like Irradiance Gradients [28, 27], and Backward Beam-Tracing [3] are also available.
Reference: 9. <author> J. T. Kajiya. </author> <title> The rendering equation. </title> <booktitle> Computer Graphics (SIGGRAPH '86 Proceedings), </booktitle> <volume> 20(4) </volume> <pages> 143-150, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: An image is then a snapshot of this light field at the point of the virtual camera. All solution techniques in use today for solving the problem, which is described mathematically by the radiance or rendering equation <ref> [9] </ref>, can be roughly classified into two groups: the Monte-Carlo [9, 25, 18], and the finite-element approach [6, 8, 16]. <p> An image is then a snapshot of this light field at the point of the virtual camera. All solution techniques in use today for solving the problem, which is described mathematically by the radiance or rendering equation [9], can be roughly classified into two groups: the Monte-Carlo <ref> [9, 25, 18] </ref>, and the finite-element approach [6, 8, 16]. <p> The current list of supported algorithms includes finite element algorithms like Progressive Refinement Radiosity [2], Galerkin Ra-diosity [29], Hierarchical and Wavelet Radiosity [8, 7], as well as three Wavelet Radiance algorithms [16, 1]. From the class of Monte-Carlo algorithms simple path tracing <ref> [9] </ref> and Bidirectional Estimators [25] have been implemented. Several hybrid techniques like Irradiance Gradients [28, 27], and Backward Beam-Tracing [3] are also available. This collection of algorithms is the basis for much of our current work in this area. (a) Monte-Carlo (b) Wavelet Radiosity Fig. 3.
Reference: 10. <author> D. Kirk and J. Arvo. </author> <title> The ray tracing kernel. </title> <booktitle> In Proceedings of Ausgraph, </booktitle> <pages> pages 75-82, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: The kernel software with selected will be made available to interested researchers. 1.2 Previous work Several other architectures for rendering have been published. However, most of them were restricted to a single rendering technique, e.g. <ref> [4, 10, 17, 26] </ref>. In contrast, the Cornell "testbed for image synthesis" [23] offers a large tool box of modules for implementing advanced rendering and global illumination algorithms, but it lacks a well-structured framework.
Reference: 11. <author> C. E. Kolb. </author> <title> Rayshade User's Guide and Reference Manual, </title> <note> Version 0.1, </note> <year> 1991. </year>
Reference-contexts: 1 Introduction In the past, rendering systems have mostly been monolithic systems with little flexibility in the fundamental rendering algorithms they offered, and even less flexibility for integrating new developments. This is true both for the research community <ref> [17, 26, 23, 11, 15] </ref> and in particular for commercial rendering systems like Alias, SoftImage, and Wavefront. This situation is unsatisfying in many respects.
Reference: 12. <author> J. Loos, G. Greiner, H.-P. Seidel, P. Slusallek, and E. Wirsching. </author> <title> Advanced spectacle lens design by combining wavefront tracing and variational design. </title> <booktitle> Computer Graphics Forum (EUROGRAPHICS '96 Proceedings), </booktitle> <year> 1996. </year>
Reference-contexts: The four images show the uncorrected view (a), the result of correcting with standard near and far distance lenses (b) and (c), and finally the result of using the progressive addition lenses (d) <ref> [12] </ref>. In the last image, we see that almost the complete field of view is in focus, with some small, but continuous distortions and blurring near the lower left and right of the image. <p> All images have been computed using the proposed rendering kernel with a special Lenses and Camera subsystem for simulating the behavior of the human eye and the optical properties of the lenses. Wavefront tracing <ref> [12] </ref> and distribution tracing has been used for computing the optical properties of the lens and the depth-of-field, respectively.
Reference: 13. <author> N. L. Max. </author> <title> Computer graphics distortion for IMAX and OMNIMAX projection. </title> <booktitle> In Nicograph '83 Proceedings, </booktitle> <pages> pages 137-159, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: The pairs of grids are used to describe morphing of the projected images and allows for very general viewing transformations, like a 180 degree fish-eye lens, 360 degree spherical environment maps as used in OpenGL [14], or even more general projections <ref> [13] </ref> (see Figure 4 for example images) By offering appropriate interfaces, both flexible realistic rendering algorithms like ray tracing, and the more limited, but hardware-supported rendering techniques can be supported efficiently within the same software architecture.
Reference: 14. <author> J. Neider, T. Davis, and M. Woo. </author> <title> OpenGL Programming Guide. </title> <publisher> Addison Wesley, </publisher> <year> 1993. </year>
Reference-contexts: The pairs of grids are used to describe morphing of the projected images and allows for very general viewing transformations, like a 180 degree fish-eye lens, 360 degree spherical environment maps as used in OpenGL <ref> [14] </ref>, or even more general projections [13] (see Figure 4 for example images) By offering appropriate interfaces, both flexible realistic rendering algorithms like ray tracing, and the more limited, but hardware-supported rendering techniques can be supported efficiently within the same software architecture.
Reference: 15. <author> POV-Ray Team. </author> <title> Persistence of Vision Ray Tracer (POV-Ray), </title> <note> Version 2.0, </note> <year> 1993. </year>
Reference-contexts: 1 Introduction In the past, rendering systems have mostly been monolithic systems with little flexibility in the fundamental rendering algorithms they offered, and even less flexibility for integrating new developments. This is true both for the research community <ref> [17, 26, 23, 11, 15] </ref> and in particular for commercial rendering systems like Alias, SoftImage, and Wavefront. This situation is unsatisfying in many respects.
Reference: 16. <author> P. Schroder and P. Hanrahan. </author> <title> Wavelet methods for radiance computations. </title> <booktitle> In Fifth EURO-GRAPHICS Workshop on Rendering, </booktitle> <pages> pages 303-311, </pages> <address> Darmstadt, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: All solution techniques in use today for solving the problem, which is described mathematically by the radiance or rendering equation [9], can be roughly classified into two groups: the Monte-Carlo [9, 25, 18], and the finite-element approach <ref> [6, 8, 16] </ref>. <p> The current list of supported algorithms includes finite element algorithms like Progressive Refinement Radiosity [2], Galerkin Ra-diosity [29], Hierarchical and Wavelet Radiosity [8, 7], as well as three Wavelet Radiance algorithms <ref> [16, 1] </ref>. From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators [25] have been implemented. Several hybrid techniques like Irradiance Gradients [28, 27], and Backward Beam-Tracing [3] are also available.
Reference: 17. <author> P. Shirley and K. Sung. </author> <title> A ray tracing framework for global illumination systems. </title> <booktitle> In Proceedings Graphics Interface '91, </booktitle> <pages> pages 117-128, </pages> <address> Calgary, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: 1 Introduction In the past, rendering systems have mostly been monolithic systems with little flexibility in the fundamental rendering algorithms they offered, and even less flexibility for integrating new developments. This is true both for the research community <ref> [17, 26, 23, 11, 15] </ref> and in particular for commercial rendering systems like Alias, SoftImage, and Wavefront. This situation is unsatisfying in many respects. <p> The kernel software with selected will be made available to interested researchers. 1.2 Previous work Several other architectures for rendering have been published. However, most of them were restricted to a single rendering technique, e.g. <ref> [4, 10, 17, 26] </ref>. In contrast, the Cornell "testbed for image synthesis" [23] offers a large tool box of modules for implementing advanced rendering and global illumination algorithms, but it lacks a well-structured framework.
Reference: 18. <author> P. Shirley, B. Wade, P. M. Hubbard, D. Zareski, B. Walter, and D. P. Greenberg. </author> <title> Global illumination via density-estimation. </title> <editor> In P. Hanrahan and W. Purgathofer, editors, </editor> <booktitle> Proceedings of the 6th EUROGRAPHICS Workshop on Rendering, </booktitle> <pages> pages 187-199, </pages> <address> Dublin, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: An image is then a snapshot of this light field at the point of the virtual camera. All solution techniques in use today for solving the problem, which is described mathematically by the radiance or rendering equation [9], can be roughly classified into two groups: the Monte-Carlo <ref> [9, 25, 18] </ref>, and the finite-element approach [6, 8, 16].
Reference: 19. <author> P. Slusallek. </author> <title> Vision AnArchitecture for Physically Based Rendering. </title> <type> PhD thesis, </type> <institution> University of Erlangen, IMMD IX, Computer Graphics Group, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: It also serves as a the oretic framework for future work in realistic image synthesis. The work presented in this paper builds on the experience that we have gained during the design and implementation of the Vision rendering architecture <ref> [22, 19] </ref>. Here, we extend and generalize the ideas of Vision in order to create a self-contained and open rendering kernel. The kernel software with selected will be made available to interested researchers. 1.2 Previous work Several other architectures for rendering have been published. <p> As a system paper, we can only give a rough overview over the details of our architecture. Many interesting details are outside the scope of this paper. The interested reader should refer to other publications for more detail <ref> [22, 19] </ref>. 2 Analysis Before we discuss aspects of rendering architectures, we briefly analyze the overall structure of the rendering process and then use this analysis for the design of the rendering kernel. 2.1 Rendering Process Physically speaking, rendering is the simulation of light transfer in a scene and the computation
Reference: 20. <author> P. Slusallek, T. Pflaum, and H.-P. Seidel. </author> <title> Implementing RenderMan practice, problems, and enhancements. </title> <booktitle> Computer Graphics Forum (EUROGRAPHICS '94 Proceedings), </booktitle> <volume> 13(3) </volume> <pages> 443-454, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: However, the concrete choice of the algorithms for global illumination is irrelevant both for the input scene description and for all other subsystems that are involved in the computation. 4.2 RenderMan The architecture has also been used to implement a RenderMan compliant renderer <ref> [20] </ref>. This extension makes use of a special library to interpret RIB files or corresponding calls through the RenderMan API. These calls are used to build a suitable scene description.
Reference: 21. <author> P. Slusallek, T. Pflaum, and H.-P. Seidel. </author> <title> Using procedural RenderMan shaders for global illumination. </title> <editor> In F. Post and M. Gobel, editors, </editor> <booktitle> Computer Graphics Forum (EUROGRAPHICS '95 Proceedings), pages C-311-C-324, </booktitle> <address> Maastricht, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Requests to these objects are converted into calls to the appropriate RenderMan shaders and vice versa. The flexible attribute handling of the scene graph is being used for supporting the attribute features of RenderMan <ref> [21] </ref>. For all images in this paper, we used the implementation of the RenderMan interface for scene description. 4.3 Non-Standard Viewing Transformations The responsibility of the Lenses subsystem is the mapping of a 3D environment onto a 2D film.
Reference: 22. <author> P. Slusallek and H.-P. Seidel. </author> <title> Vision: An architecture for global illumination calculations. </title> <journal> IEEE Transactions on Visualization and Computer Graphics, </journal> <volume> 1(1) </volume> <pages> 77-96, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: It also serves as a the oretic framework for future work in realistic image synthesis. The work presented in this paper builds on the experience that we have gained during the design and implementation of the Vision rendering architecture <ref> [22, 19] </ref>. Here, we extend and generalize the ideas of Vision in order to create a self-contained and open rendering kernel. The kernel software with selected will be made available to interested researchers. 1.2 Previous work Several other architectures for rendering have been published. <p> As a system paper, we can only give a rough overview over the details of our architecture. Many interesting details are outside the scope of this paper. The interested reader should refer to other publications for more detail <ref> [22, 19] </ref>. 2 Analysis Before we discuss aspects of rendering architectures, we briefly analyze the overall structure of the rendering process and then use this analysis for the design of the rendering kernel. 2.1 Rendering Process Physically speaking, rendering is the simulation of light transfer in a scene and the computation
Reference: 23. <author> B. Trumbore, W. Lytle, and D. P. Greenberg. </author> <title> A testbed for image synthesis. </title> <editor> In P. S. Strauss and B. Trumbore, editors, </editor> <booktitle> Developing Large-Scale Graphics Software Toolkits (SIGGRAPH '93 Course Notes 3), pages 4.7-4.17, </booktitle> <address> Anaheim, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: 1 Introduction In the past, rendering systems have mostly been monolithic systems with little flexibility in the fundamental rendering algorithms they offered, and even less flexibility for integrating new developments. This is true both for the research community <ref> [17, 26, 23, 11, 15] </ref> and in particular for commercial rendering systems like Alias, SoftImage, and Wavefront. This situation is unsatisfying in many respects. <p> The kernel software with selected will be made available to interested researchers. 1.2 Previous work Several other architectures for rendering have been published. However, most of them were restricted to a single rendering technique, e.g. [4, 10, 17, 26]. In contrast, the Cornell "testbed for image synthesis" <ref> [23] </ref> offers a large tool box of modules for implementing advanced rendering and global illumination algorithms, but it lacks a well-structured framework. Another interesting approach is Glassner's "Spectrum" architecture [5], which describes a general object-oriented framework for global illumination based on a signal processing approach.
Reference: 24. <author> J. Tumblin and H. E. Rushmeier. </author> <title> Tone reproduction for realistic computer generated images. </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 13(6) </volume> <pages> 42-48, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Finally, image rendering combines the scene description with the lighting calculation and computes an image of the scene. This stage is responsible for computing the viewing transformation, hidden surface removal, image sampling and filtering, and finally image post-processing, e.g. by tone mapping <ref> [24] </ref>. Each of these three stages depends on the services of the preceding stages. A scene description may be useful in itself (e.g. in a CAD editing application), but is a requirement for the other two steps. <p> An important aspect of the Film object is the mapping process, which is described by an object of the Imager implementing tone mapping operations <ref> [24] </ref>. The passive Lenses object describes the viewing transformation, i.e. the mapping from 3D to 2D. Two example applications that use special implementations of this subsystem are presented in Section 4. The only active entity is the Renderer object.
Reference: 25. <author> E. Veach and L. J. Guibas. </author> <title> Optimally combining sampling techniques for monte carlo rendering. </title> <booktitle> Computer Graphics (SIGGRAPH '95 Proceedings), </booktitle> <pages> pages 419-428, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: An image is then a snapshot of this light field at the point of the virtual camera. All solution techniques in use today for solving the problem, which is described mathematically by the radiance or rendering equation [9], can be roughly classified into two groups: the Monte-Carlo <ref> [9, 25, 18] </ref>, and the finite-element approach [6, 8, 16]. <p> The current list of supported algorithms includes finite element algorithms like Progressive Refinement Radiosity [2], Galerkin Ra-diosity [29], Hierarchical and Wavelet Radiosity [8, 7], as well as three Wavelet Radiance algorithms [16, 1]. From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators <ref> [25] </ref> have been implemented. Several hybrid techniques like Irradiance Gradients [28, 27], and Backward Beam-Tracing [3] are also available. This collection of algorithms is the basis for much of our current work in this area. (a) Monte-Carlo (b) Wavelet Radiosity Fig. 3. Two example images computed with global illumination.
Reference: 26. <author> G. J. Ward. </author> <title> The RADIANCE lighting simulation and rendering system. </title> <booktitle> Computer Graphics (SIGGRAPH '94 Proceedings), </booktitle> <pages> pages 459-472, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: 1 Introduction In the past, rendering systems have mostly been monolithic systems with little flexibility in the fundamental rendering algorithms they offered, and even less flexibility for integrating new developments. This is true both for the research community <ref> [17, 26, 23, 11, 15] </ref> and in particular for commercial rendering systems like Alias, SoftImage, and Wavefront. This situation is unsatisfying in many respects. <p> The kernel software with selected will be made available to interested researchers. 1.2 Previous work Several other architectures for rendering have been published. However, most of them were restricted to a single rendering technique, e.g. <ref> [4, 10, 17, 26] </ref>. In contrast, the Cornell "testbed for image synthesis" [23] offers a large tool box of modules for implementing advanced rendering and global illumination algorithms, but it lacks a well-structured framework. <p> Of course, a number of hybrid techniques that combine aspects of both approaches are also available <ref> [26, 3] </ref>. 2.2 Stages The process of rendering can be divided into three distinct stages, which also roughly correspond to three different phases during rendering: scene description, lighting calculation, image rendering (see Figure 1). Fig. 1. The three stages of the rendering process: scene description, lighting calculation, and image rendering.
Reference: 27. <author> G. J. Ward and P. S. Heckbert. </author> <title> Irradiance gradients. </title> <editor> In A. Chalmers and D. Paddon, editors, </editor> <booktitle> Third EUROGRAPHICS Workshop on Rendering, </booktitle> <pages> pages 85-98, </pages> <address> Bristol, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators [25] have been implemented. Several hybrid techniques like Irradiance Gradients <ref> [28, 27] </ref>, and Backward Beam-Tracing [3] are also available. This collection of algorithms is the basis for much of our current work in this area. (a) Monte-Carlo (b) Wavelet Radiosity Fig. 3. Two example images computed with global illumination.
Reference: 28. <author> G. J. Ward and F. Rubinstein. </author> <title> A ray tracing solution for diffuse interreflection. </title> <booktitle> Computer Graphics (SIGGRAPH '88 Proceedings), </booktitle> <volume> 22(4) </volume> <pages> 85-92, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators [25] have been implemented. Several hybrid techniques like Irradiance Gradients <ref> [28, 27] </ref>, and Backward Beam-Tracing [3] are also available. This collection of algorithms is the basis for much of our current work in this area. (a) Monte-Carlo (b) Wavelet Radiosity Fig. 3. Two example images computed with global illumination.
Reference: 29. <author> H. R. Zatz. </author> <title> Galerkin radiosity: A higher order solution method for global illumination. </title> <booktitle> Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <pages> pages 213-220, </pages> <month> August </month> <year> 1993. </year> <title> (a) Uncorrected view (b) Near focus lens (c) Far focus lens (d) PAL lens Fig. 5. Simulating the effect of different spectacle lenses on the human vision. See text for details. </title>
Reference-contexts: The current list of supported algorithms includes finite element algorithms like Progressive Refinement Radiosity [2], Galerkin Ra-diosity <ref> [29] </ref>, Hierarchical and Wavelet Radiosity [8, 7], as well as three Wavelet Radiance algorithms [16, 1]. From the class of Monte-Carlo algorithms simple path tracing [9] and Bidirectional Estimators [25] have been implemented. Several hybrid techniques like Irradiance Gradients [28, 27], and Backward Beam-Tracing [3] are also available.
References-found: 29

