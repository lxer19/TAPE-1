URL: http://www.cs.orst.edu/~tadepall/research/papers/determinations.ps
Refering-URL: 
Root-URL: 
Email: (sridhar@watson.ibm.com)  (tadepalli@cs.orst.edu)  
Title: Quantifying Prior Determination Knowledge using the PAC Learning Model  
Author: Sridhar Mahadevan Prasad Tadepalli 
Keyword: Determinations, PAC Learning, Bias, Prior Knowledge, Incomplete Theories. Running Head: Quantitative Analysis of Determination Knowledge.  
Address: Box 704, Yorktown Heights NY 10598  Corvallis, OR 97331  
Affiliation: IBM T.J. Watson Research Center  Department of Computer Science Oregon State University  
Abstract: Prior knowledge, or bias, regarding a concept can speed up the task of learning it. Probably Approximately Correct (PAC) learning is a mathematical model of concept learning that can be used to quantify the speed up due to different forms of bias on learning. Thus far, PAC learning has mostly been used to analyze syntactic bias, such as limiting concepts to conjunctions of boolean prepositions. This paper demonstrates that PAC learning can also be used to analyze semantic bias, such as a domain theory about the concept being learned. The key idea is to view the hypothesis space in PAC learning as that consistent with all prior knowledge, syntactic and semantic. In particular, the paper presents a PAC analysis of determinations, a type of relevance knowledge. The results of the analysis reveal crisp distinctions and relations among different determinations, and illustrate the usefulness of an analysis based on the PAC model. 
Abstract-found: 1
Intro-found: 1
Reference: [ Angluin, 1988 ] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <year> 1988. </year>
Reference-contexts: Hence, strictly speaking, our proof of Theorem 4 is only an existence proof of a learning algorithm. However, it is possible to convert it into an "on-line" learning algorithm that does not assume the knowledge of these bounds by using the stochastic testing method in troduced in <ref> [ Angluin, 1988 ] </ref> . This method works by incrementally training the system until it correctly classifies a set of randomly drawn test examples. <p> It might also suggest the need for learning from additional sources of information such as "membership queries," when learning from random examples alone is not computationally tractable <ref> [ Angluin, 1988 ] </ref> . It may not always be realistic to find a small number of relevant attributes that can determine a target function.
Reference: [ Blumer et al., 1989 ] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. </author> <title> Learn-ability and the Vapnik-Chervonenkis Dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: Given a particular determination, we estimate the size of the function space consistent with the determination. The main result in PAC learning that we use is the dimensionality theorem, which relates the number of training examples needed for successful learning to the size of the function space <ref> [ Blumer et al., 1989, Natarajan, 1989 ] </ref> . Informally, this theorem says that the number of examples sufficient for successful learning varies logarithmically with the asymptotic size of the function space. <p> Since f can be produced in time polynomial in the number of examples, B is polynomial-time identifiable. We now introduce Natarajan's notion of "dimension," a measure of the size of a function space [ Natarajan, 1989 ] . The relationship of Natarajan's dimension to the more popular Vapnik-Chervonenkis dimension <ref> [ Blumer et al., 1989 ] </ref> is discussed in [ Natarajan, 1989 ] . Definition 8 The dimension of F n , the n th subspace of F , is log 2 jF n j. <p> The proof for the above theorem follows a similar result for concept learning given in <ref> [ Blumer et al., 1989 ] </ref> or [ Natarajan, 1987 ] . 4 Learnability Results This section describes the main results of this paper on quantifying relevance knowledge defined by various determinations. 4.1 Determinations Determinations are intended as a formalization of the notion of relevance.
Reference: [ Brooks, 1991 ] <author> R. Brooks. </author> <title> Intelligence without reason. </title> <booktitle> In Proceedings of the 12th IJCAI. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Note, however, that our work is agnostic about whether prior knowledge should be declaratively represented in the system. The analysis holds whether or not this is the case. In [ Russell and Grosof, 1989 ] , the benefits of declarative bias are eloquently argued, while in <ref> [ Brooks, 1991 ] </ref> the necessity of any declarative representations in reasoning and learning is seriously questioned. The problem is that declarative representations of prior knowledge, while being more flexible, might introduce computational intractability.
Reference: [ Bylander, 1992 ] <author> T. Bylander. </author> <title> Complexity results for serial decomposability. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence (AAAI), </booktitle> <pages> pages 729-734. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: Thus, similar to determinations, the knowledge of serial decomposability allows the learner to effectively generalize from a small number of examples. Although serial decomposability can be detected by exhaustive search, this problem is known to be NP-hard <ref> [ Bylander, 1992 ] </ref> . Hence the knowledge of the ordering of features that makes a domain serially decomposable also reduces the time complexity of learning. 6 Conclusions This paper employed the PAC learning framework to analyze the effectiveness of various forms of prior knowledge in learning.
Reference: [ Danyluk, 1989 ] <author> A. Danyluk. </author> <title> Finding new rules for incomplete theories: Explicit biases for induction with contextual information. </title> <booktitle> In Proceedings of the Sixth International Machine Learning Workshop. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Most approaches to this "incomplete theory problem" are based on using pre-classified training examples to expose and fill in missing parts of the domain theory <ref> [ Hirsh, 1989, Hall, 1988, Mahadevan, 1989, Danyluk, 1989 ] </ref> . For example, one approach involves using determinations to represent gaps in the domain theory, which are filled by extracting implicative rules from the determinations [ Russell, 1987, Mahadevan, 1989 ] .
Reference: [ Davies and Russell, 1987 ] <author> T. Davies and S. Russell. </author> <title> A logical approach to reasoning by analogy. </title> <booktitle> In Proceedings of The Tenth International Joint Conference on Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: Relevance knowledge consists of information about the dependence among different features. A feature P is relevant to another feature Q if the fact that P holds for some object affects whether Q also holds for that object. Determinations were originally proposed by Davies and Russell <ref> [ Davies and Russell, 1987, Russell, 1986, Russell, 1989 ] </ref> in the context of analogical reasoning. An example of a determination is the prior knowledge that "nationality" determines "language", that is, individuals of the same nationality speak the same language.
Reference: [ Davies, 1988 ] <author> T. Davies. </author> <title> Determination, uniformity, and relevance: Normative criteria for generalization and reasoning by analogy. </title> <editor> In D. H. Helman, editor, </editor> <booktitle> Analogical Reasoning, </booktitle> <pages> pages 227-250. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: A partial determi nation is introduced through a probability measure, d (P; Q), which is an empirical estimate of the relevance of one attribute P to another attribute Q [ Russell, 1986 ] . This measure is also similar to the "uniformity" measure discussed in <ref> [ Davies, 1988 ] </ref> . 19 Consider two relations P and Q as before, where P I fi N and Q I fi L. Let us denote the set fx j P (x; w)g by P 1 w . <p> Thus, intuitively d (P; Q) is a measure on how relevant P is to making predictions about Q. A good discussion of how this measure is related to other metrics for relevance in statistics, such as correlation, is given in <ref> [ Davies, 1988 ] </ref> . desJardins considered the task of predicting the value of a target feature Q from a single input feature P , which is assumed to be statistically correlated to Q, making some strong assumptions on the distribution of the input and output features [ desJardins, 1989 ]
Reference: [ Dejong and Mooney, 1986 ] <author> G. Dejong and R. Mooney. </author> <title> Explanation-Based Learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2), </volume> <year> 1986. </year>
Reference-contexts: We believe our theoretical results have direct relevance to implementors of practical knowledge-based learning systems. For example, Explanation-Based Learning (EBL) is a knowledge-intensive learning technique that relies on its ability to classify an instance using a theory of the domain <ref> [ Mitchell et al., 1986, Dejong and Mooney, 1986 ] </ref> .
Reference: [ desJardins, 1989 ] <author> M. desJardins. </author> <title> Probabilistic evaluation of bias for learning systems. </title> <booktitle> In Proceedings of the Sixth International Machine Learning Workshop, </booktitle> <pages> pages 495-499. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: is given in [ Davies, 1988 ] . desJardins considered the task of predicting the value of a target feature Q from a single input feature P , which is assumed to be statistically correlated to Q, making some strong assumptions on the distribution of the input and output features <ref> [ desJardins, 1989 ] </ref> . In the spirit of our previous results, we derive distribution-independent sufficient conditions for learnability which rely on the asymptotic growth rate of d (P; Q) with the size of the learning problem.
Reference: [ Dietterich, 1989 ] <author> T. Dietterich. </author> <title> Limitations on inductive learning. </title> <booktitle> In Proceedings of the Sixth Machine Learning Workshop, </booktitle> <pages> pages 124-128. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Our algorithms do not require the first order logic representations of the various determinations. 5.2 Tree-structured Bias Our results suggest that knowledge-based learning is not automatically immune to the observed statistical limitations of inductive learning systems <ref> [ Dietterich, 1989 ] </ref> . The analysis of the kind performed here can help the designer of a learning system decide whether some existing prior knowledge is adequate, or if more knowledge is needed to make learning feasible.
Reference: [ Hall, 1988 ] <author> R. Hall. </author> <title> Learning by failing to explain. </title> <journal> Machine Learning, </journal> <volume> 3(1), </volume> <year> 1988. </year>
Reference-contexts: Most approaches to this "incomplete theory problem" are based on using pre-classified training examples to expose and fill in missing parts of the domain theory <ref> [ Hirsh, 1989, Hall, 1988, Mahadevan, 1989, Danyluk, 1989 ] </ref> . For example, one approach involves using determinations to represent gaps in the domain theory, which are filled by extracting implicative rules from the determinations [ Russell, 1987, Mahadevan, 1989 ] .
Reference: [ Haussler et al., 1988 ] <author> D. Haussler, N. Littlestone, and M. Warmuth. </author> <title> Predicting 0; 1 functions on randomly drawn points. </title> <booktitle> In Proceedings of the 29th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 100-109, </pages> <year> 1988. </year>
Reference-contexts: The advantage of this definition is that it avoids the problem of having to check that g is consistent with the prior knowledge, which could sometimes be computationally complex <ref> [ Haussler et al., 1988, Pitt and Valiant, 1988 ] </ref> . This definition of learnability is also called "predictability" in PAC learning literature [ Haussler et al., 1988, Natarajan, 1991 ] . To study the time requirements of learning, we need to assume a representation or index for the functions. <p> This definition of learnability is also called "predictability" in PAC learning literature <ref> [ Haussler et al., 1988, Natarajan, 1991 ] </ref> . To study the time requirements of learning, we need to assume a representation or index for the functions. Since each function may have multiple names, the index maps functions to sets of binary strings.
Reference: [ Haussler, 1988 ] <author> D Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artifical Intelligence, </journal> <volume> 36(2), </volume> <year> 1988. </year>
Reference-contexts: While prior knowledge will always reduce the number of examples sufficient for learning, it might sometimes increase the time complexity of searching for a function consistent with it <ref> [ Haussler, 1988 ] </ref> . In those cases, it may be appropriate to ignore some prior knowledge and consider a bigger function space than is necessary, thus requiring a few more examples while gaining computational tractability.
Reference: [ Hirsh, 1989 ] <author> H Hirsh. </author> <title> Incremental Version-Space Merging: A General Framework for Concept Learning. </title> <type> PhD thesis, </type> <institution> Stanford University., </institution> <year> 1989. </year> <month> 35 </month>
Reference-contexts: Most approaches to this "incomplete theory problem" are based on using pre-classified training examples to expose and fill in missing parts of the domain theory <ref> [ Hirsh, 1989, Hall, 1988, Mahadevan, 1989, Danyluk, 1989 ] </ref> . For example, one approach involves using determinations to represent gaps in the domain theory, which are filled by extracting implicative rules from the determinations [ Russell, 1987, Mahadevan, 1989 ] .
Reference: [ Kearns and Valiant, 1989 ] <author> M. Kearns and L. Valiant. </author> <title> Cryptographic limitations on learning boolean formulae and finite automata. </title> <booktitle> In Proceedings of the 21 st Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1989. </year>
Reference-contexts: However, Russell showed that the tree structure provides additional bias so that a function class which is not feasibly learnable with the flat determination might still be learnable with the tree of determinations. It had been shown <ref> [ Pitt and Warmuth, 1990, Kearns and Valiant, 1989 ] </ref> that learning with tree-structured bias from random examples is computationally as hard as inverting some cryptographic functions such as the RSA cryptosystem, which is believed to be intractable.
Reference: [ Korf, 1985 ] <author> R. Korf. Macro-Operators: </author> <title> A Weak Method for Learning. </title> <journal> Artificial Intelligence, </journal> <volume> 26(1) </volume> <pages> 35-77, </pages> <year> 1985. </year>
Reference-contexts: In [ Tadepalli, 1991 ] , an analysis similar to that we used in this paper was carried out for EBL systems when the hypotheses are in the form of sets of macro-operators. The learning algorithm exploits a piece of domain knowledge called "serial decomposability" <ref> [ Korf, 1985 ] </ref> . This property is relevant to problem solving domains whose states can be represented as discrete valued feature vectors. <p> A domain is said to be serially decomposable when its features can be ordered such that the effect of any operator (and hence a macro-operator) on a feature is a function of, (or is determined by), only that feature and the features that come before it in the ordering <ref> [ Korf, 1985 ] </ref> . Given such an ordering of features and an operator sequence that achieves the goal values for those features in that order, it is possible to efficiently decompose the operator sequence into general macro-operators by ignoring all the irrelevant features in the initial state.
Reference: [ Mahadevan and Tadepalli, 1988 ] <author> S. Mahadevan and P. Tadepalli. </author> <title> On the tractability of learning from incomplete theories. </title> <booktitle> In Proceedings of the Fifth International Machine Learning Conference, </booktitle> <pages> pages 235-241. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: In this paper we show that the authors' pessimism is somewhat unwarranted, and that semantic bias can be quantified using essentially the same PAC learning framework used to analyze syntactic bias. To our knowledge, the work described here which was first reported in <ref> [ Mahadevan and Tadepalli, 1988 ] </ref> represents one of the first attempts to analyze semantic bias using PAC learning. Russell's work on "tree-structured bias" is another early example of such an analysis [ Russell, 1988 ] .
Reference: [ Mahadevan, 1989 ] <author> S. Mahadevan. </author> <title> Using determinations in EBL: A solution to the incomplete theory problem. </title> <booktitle> In Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <pages> pages 320-325. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Most approaches to this "incomplete theory problem" are based on using pre-classified training examples to expose and fill in missing parts of the domain theory <ref> [ Hirsh, 1989, Hall, 1988, Mahadevan, 1989, Danyluk, 1989 ] </ref> . For example, one approach involves using determinations to represent gaps in the domain theory, which are filled by extracting implicative rules from the determinations [ Russell, 1987, Mahadevan, 1989 ] . <p> For example, one approach involves using determinations to represent gaps in the domain theory, which are filled by extracting implicative rules from the determinations <ref> [ Russell, 1987, Mahadevan, 1989 ] </ref> . A PAC analysis can be used to determine whether the gaps in a domain theory are "small" enough so that they can be filled with a reasonably small number of examples. The rest of this paper is organized as follows. <p> For example, PED is a technique that extends EBL to partial domain theories containing determinations by using classified training instances to extract implicative rules from the determinations <ref> [ Mahadevan, 1989 ] </ref> .
Reference: [ Mitchell et al., 1986 ] <author> T. Mitchell, R. Keller, and S. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1), </volume> <year> 1986. </year>
Reference-contexts: We believe our theoretical results have direct relevance to implementors of practical knowledge-based learning systems. For example, Explanation-Based Learning (EBL) is a knowledge-intensive learning technique that relies on its ability to classify an instance using a theory of the domain <ref> [ Mitchell et al., 1986, Dejong and Mooney, 1986 ] </ref> . <p> One of the open 1 Negative results using the PAC learning model should be interpreted as "worst-case" theorems similar to the NP-completeness results in computational complexity theory. 3 problems in EBL arises when the domain theory is not adequate to classify every instance <ref> [ Mitchell et al., 1986 ] </ref> . Most approaches to this "incomplete theory problem" are based on using pre-classified training examples to expose and fill in missing parts of the domain theory [ Hirsh, 1989, Hall, 1988, Mahadevan, 1989, Danyluk, 1989 ] . <p> Examples are required to fill in this knowledge, and thus they are a source of new information (unlike the situation in EBL where examples are a logical consequence of the domain theory <ref> [ Mitchell et al., 1986 ] </ref> ).
Reference: [ Mitchell, 1980 ] <author> T. Mitchell. </author> <title> The need for biases in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Rutgers University, </institution> <year> 1980. </year>
Reference: [ Natarajan and Tadepalli, 1988 ] <author> B. Natarajan and P. Tadepalli. </author> <title> Two new frameworks for learning. </title> <booktitle> In Proceedings of the Fifth International Machine Learning Conference. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Another approach for acquiring prior knowledge might be through some other means of learning: by being told, for example. However, the results of <ref> [ Natarajan and Tadepalli, 1988 ] </ref> 25 show that this approach too suffers from the same information theoretic limitations.
Reference: [ Natarajan, 1987 ] <author> B. Natarajan. </author> <title> On learning boolean functions. </title> <booktitle> In ACM Symposium on Theory of Computing, </booktitle> <year> 1987. </year>
Reference-contexts: The proof for the above theorem follows a similar result for concept learning given in [ Blumer et al., 1989 ] or <ref> [ Natarajan, 1987 ] </ref> . 4 Learnability Results This section describes the main results of this paper on quantifying relevance knowledge defined by various determinations. 4.1 Determinations Determinations are intended as a formalization of the notion of relevance.
Reference: [ Natarajan, 1989 ] <author> B. Natarajan. </author> <title> On learning sets and functions. </title> <journal> Machine Learning, </journal> <volume> 4(1), </volume> <year> 1989. </year>
Reference-contexts: Given a particular determination, we estimate the size of the function space consistent with the determination. The main result in PAC learning that we use is the dimensionality theorem, which relates the number of training examples needed for successful learning to the size of the function space <ref> [ Blumer et al., 1989, Natarajan, 1989 ] </ref> . Informally, this theorem says that the number of examples sufficient for successful learning varies logarithmically with the asymptotic size of the function space. <p> In particular, we will use a generalization of Valiant's original model to function learning studied by Natarajan <ref> [ Natarajan, 1989, Natarajan, 1991 ] </ref> . 3.1 Preliminaries Since any domain/range element of a function can be encoded as a binary string, without loss of generality we consider learning functions from binary strings to binary strings. An example of a function f is a pair (x; f (x)). <p> Since f can be produced in time polynomial in the number of examples, B is polynomial-time identifiable. We now introduce Natarajan's notion of "dimension," a measure of the size of a function space <ref> [ Natarajan, 1989 ] </ref> . The relationship of Natarajan's dimension to the more popular Vapnik-Chervonenkis dimension [ Blumer et al., 1989 ] is discussed in [ Natarajan, 1989 ] . <p> We now introduce Natarajan's notion of "dimension," a measure of the size of a function space <ref> [ Natarajan, 1989 ] </ref> . The relationship of Natarajan's dimension to the more popular Vapnik-Chervonenkis dimension [ Blumer et al., 1989 ] is discussed in [ Natarajan, 1989 ] . Definition 8 The dimension of F n , the n th subspace of F , is log 2 jF n j. <p> The dimension of this new function space B 0 is the polynomial D (n) = n. 3.4 Learnability Theorems The main results we will be using from the theory of PAC learnability can now be stated <ref> [ Natarajan, 1989 ] </ref> . Theorem 1 (Natarajan) A space of functions F is feasibly learnable if and only if it is of polynomial dimension. Theorem 2 (Natarajan) A space of functions is polynomial-time learnable if it is of polynomial dimension and is polynomial-time identifiable.
Reference: [ Natarajan, 1991 ] <author> B. Natarajan. </author> <title> Machine Learning: A Theoretical Approach. </title> <publisher> Morgan Kauf-mann, </publisher> <year> 1991. </year>
Reference-contexts: introduction to the model, see <ref> [ Natarajan, 1991 ] </ref> . However, humans, and indeed some machine learning systems, draw their power not only from syntactic bias, but also from knowing something about the content of the particular concept being learned. <p> In particular, we will use a generalization of Valiant's original model to function learning studied by Natarajan <ref> [ Natarajan, 1989, Natarajan, 1991 ] </ref> . 3.1 Preliminaries Since any domain/range element of a function can be encoded as a binary string, without loss of generality we consider learning functions from binary strings to binary strings. An example of a function f is a pair (x; f (x)). <p> This definition of learnability is also called "predictability" in PAC learning literature <ref> [ Haussler et al., 1988, Natarajan, 1991 ] </ref> . To study the time requirements of learning, we need to assume a representation or index for the functions. Since each function may have multiple names, the index maps functions to sets of binary strings.
Reference: [ Pazzani, 1992 ] <author> M. Pazzani. </author> <title> The Utility of Knowledge in Inductive Learning. </title> <journal> Machine Learning, </journal> <volume> 9(1) </volume> <pages> 57-94, </pages> <year> 1992. </year>
Reference-contexts: For example, a human learning to play a new game often uses his general knowledge of competitive games to accelerate learning. Similarly, machine learning programs like FOCL rely on a "domain theory" to expedite learning new knowledge <ref> [ Pazzani, 1992 ] </ref> . In other words, these systems exploit a "semantic bias" in addition to a syntactic bias. Quantifying semantic bias or prior knowledge is an important problem in artificial intelligence (AI).
Reference: [ Pearl, 1988 ] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: It suffices if the probability of this can be made asymptotically close to 1. Interestingly, the notion of partial determination seems similar to the *-semantics, proposed by Pearl to give probabilistic semantics to default logic <ref> [ Pearl, 1988 ] </ref> . 3 Here default rules are interpreted to be sentences which are true with a probability 1 *, where * can be made arbitrarily small.
Reference: [ Pitt and Valiant, 1988 ] <author> L. Pitt and L. G. Valiant. </author> <title> Computational limits of learning from examples. </title> <journal> Journal of the ACM, </journal> <volume> 35(4) </volume> <pages> 965-984, </pages> <year> 1988. </year>
Reference-contexts: The advantage of this definition is that it avoids the problem of having to check that g is consistent with the prior knowledge, which could sometimes be computationally complex <ref> [ Haussler et al., 1988, Pitt and Valiant, 1988 ] </ref> . This definition of learnability is also called "predictability" in PAC learning literature [ Haussler et al., 1988, Natarajan, 1991 ] . To study the time requirements of learning, we need to assume a representation or index for the functions.
Reference: [ Pitt and Warmuth, 1990 ] <author> L. Pitt and M. Warmuth. </author> <title> Prediction preserving reducibility. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 41(3), </volume> <year> 1990. </year>
Reference-contexts: However, Russell showed that the tree structure provides additional bias so that a function class which is not feasibly learnable with the flat determination might still be learnable with the tree of determinations. It had been shown <ref> [ Pitt and Warmuth, 1990, Kearns and Valiant, 1989 ] </ref> that learning with tree-structured bias from random examples is computationally as hard as inverting some cryptographic functions such as the RSA cryptosystem, which is believed to be intractable.
Reference: [ Rich and Knight, 1991 ] <author> E. Rich and K. Knight. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1991. </year> <month> 36 </month>
Reference-contexts: In other words, these systems exploit a "semantic bias" in addition to a syntactic bias. Quantifying semantic bias or prior knowledge is an important problem in artificial intelligence (AI). In a recent introductory book on AI <ref> [ Rich and Knight, 1991 ] </ref> , after discussing Valiant's model of PAC learning, the authors of the book note (pages 482-483): After all, people are able to solve many exponentially hard problems by using knowledge to constrain the space of possible solutions.
Reference: [ Rivest, 1987 ] <author> R. Rivest. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2(3) </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: Definition 6 A function f is consistent with a set of examples S if (x; y) 2 S ) f (x) = y. Typically, learning algorithms work by guessing a function which is consistent with all the input examples. Following <ref> [ Rivest, 1987 ] </ref> we call such an algorithm an identification.
Reference: [ Russell and Grosof, 1989 ] <author> S. Russell and B. Grosof. </author> <title> A sketch of autonomous learning using declarative bias. </title> <editor> In P. Brazdil and K. Konolige, editors, </editor> <booktitle> Machine Learning, Meta-Reasoning, and Logics. </booktitle> <publisher> Kluwer Academic, </publisher> <year> 1989. </year>
Reference-contexts: Note, however, that our work is agnostic about whether prior knowledge should be declaratively represented in the system. The analysis holds whether or not this is the case. In <ref> [ Russell and Grosof, 1989 ] </ref> , the benefits of declarative bias are eloquently argued, while in [ Brooks, 1991 ] the necessity of any declarative representations in reasoning and learning is seriously questioned.
Reference: [ Russell, 1986 ] <author> S. Russell. </author> <title> Analogical and Inductive Reasoning. </title> <type> PhD thesis, </type> <institution> Stanford University., </institution> <year> 1986. </year>
Reference-contexts: Relevance knowledge consists of information about the dependence among different features. A feature P is relevant to another feature Q if the fact that P holds for some object affects whether Q also holds for that object. Determinations were originally proposed by Davies and Russell <ref> [ Davies and Russell, 1987, Russell, 1986, Russell, 1989 ] </ref> in the context of analogical reasoning. An example of a determination is the prior knowledge that "nationality" determines "language", that is, individuals of the same nationality speak the same language. <p> On the other hand, we feel reasonably certain that the Height attribute will not similarly affect the Speaks-English attribute. The simplest type of determinations are called total determinations. Russell introduced five types of total determination in his thesis <ref> [ Russell, 1986 ] </ref> . <p> One would like to be able to tolerate a small number of "exceptions" to a total determination. Russell proposes two solutions to this problem: extended determinations, and partial determinations <ref> [ Russell, 1986 ] </ref> . We analyze the former first. <p> A set of elements sharing a given P value all map to a given subset of L, except for a set of "exceptional" individuals who map to larger subsets of L. We now carry out an analysis of extended determinations. Following <ref> [ Russell, 1986 ] </ref> we define the notion of an extended determination as follows: Definition 18 We say P (x; y) p 8w 1 ; . . . ; w p ; y; z [P (w 1 ; y) ^ Q (w 1 ; z) ^ . . . ^ P <p> A partial determi nation is introduced through a probability measure, d (P; Q), which is an empirical estimate of the relevance of one attribute P to another attribute Q <ref> [ Russell, 1986 ] </ref> . This measure is also similar to the "uniformity" measure discussed in [ Davies, 1988 ] . 19 Consider two relations P and Q as before, where P I fi N and Q I fi L.
Reference: [ Russell, 1987 ] <author> S. Russell. </author> <title> Analogy and single instance generalization. </title> <booktitle> In Proceedings of the 4th International Conference on Machine Learning, </booktitle> <pages> pages 390-397. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: For example, one approach involves using determinations to represent gaps in the domain theory, which are filled by extracting implicative rules from the determinations <ref> [ Russell, 1987, Mahadevan, 1989 ] </ref> . A PAC analysis can be used to determine whether the gaps in a domain theory are "small" enough so that they can be filled with a reasonably small number of examples. The rest of this paper is organized as follows. <p> Then, the above total determination states that if there exist two individuals x and w who share a nationality y, then x and w will speak the same set of languages. 9 Determinations can be viewed as a form of incomplete knowledge <ref> [ Russell, 1987 ] </ref> .
Reference: [ Russell, 1988 ] <author> S. Russell. </author> <title> Tree-structured bias. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI), </booktitle> <pages> pages 641-645. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: To our knowledge, the work described here which was first reported in [ Mahadevan and Tadepalli, 1988 ] represents one of the first attempts to analyze semantic bias using PAC learning. Russell's work on "tree-structured bias" is another early example of such an analysis <ref> [ Russell, 1988 ] </ref> . PAC learning is based on a paradigm wherein a teacher provides a learner with examples of a target function from an initially agreed upon space of possible functions. This space can be viewed as representing the syntactic bias of the learner.
Reference: [ Russell, 1989 ] <author> S. Russell. </author> <title> The use of knowledge in analogy and induction. </title> <publisher> Morgan Kauf-mann, </publisher> <year> 1989. </year>
Reference-contexts: Relevance knowledge consists of information about the dependence among different features. A feature P is relevant to another feature Q if the fact that P holds for some object affects whether Q also holds for that object. Determinations were originally proposed by Davies and Russell <ref> [ Davies and Russell, 1987, Russell, 1986, Russell, 1989 ] </ref> in the context of analogical reasoning. An example of a determination is the prior knowledge that "nationality" determines "language", that is, individuals of the same nationality speak the same language. <p> Russell showed that if the learner has a set of determinations structured as a tree, the number of examples needed to learn a target function is significantly reduced even while the total number of relevant attributes is large <ref> [ Russell, 1989 ] </ref> . Tree-structured bias consists of a tree of attributes such that each attribute at a node is determined by at most a small constant number (k) of other attributes, which are represented as its children.
Reference: [ Tadepalli, 1991 ] <author> P. Tadepalli. </author> <title> A formalization of explanation-based macro-operator learning. </title> <booktitle> In Proceedings of the IJCAI, </booktitle> <pages> pages 616-622, </pages> <year> 1991. </year>
Reference-contexts: However, only one of these possible hypotheses (functions) is correct, and the task is to find an approximation to the correct function with a high probability. In <ref> [ Tadepalli, 1991 ] </ref> , an analysis similar to that we used in this paper was carried out for EBL systems when the hypotheses are in the form of sets of macro-operators. The learning algorithm exploits a piece of domain knowledge called "serial decomposability" [ Korf, 1985 ] .
Reference: [ Tadepalli, 1993 ] <author> P. Tadepalli. </author> <title> Learning from queries and examples with tree-structured bias. </title> <booktitle> In Proceedings of the Tenth International Machine Learning Conference. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: However, there is an efficient learning algorithm for boolean functions that obey tree-structured bias if the learner is also allowed to query the output of the target function for any arbitrary input, i.e., ask "membership queries" <ref> [ Tadepalli, 1993 ] </ref> . This algorithm was implemented as a program called TSB and was shown to learn the target functions consistent with a determination tree of a few dozen nodes to almost 100% accuracy with a modest number of examples and queries [ Tadepalli, 1993 ] . <p> arbitrary input, i.e., ask "membership queries" <ref> [ Tadepalli, 1993 ] </ref> . This algorithm was implemented as a program called TSB and was shown to learn the target functions consistent with a determination tree of a few dozen nodes to almost 100% accuracy with a modest number of examples and queries [ Tadepalli, 1993 ] . A knowledge-free induction program (ID3) using the same data could only achieve a maximum of 75% accuracy.
Reference: [ Valiant, 1984 ] <author> L. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11), </volume> <year> 1984. </year>
Reference-contexts: For example the class of k-CNF boolean formulas, which is defined as the set of conjunctions of at most k disjuncts, is known to 23 be learnable <ref> [ Valiant, 1984 ] </ref> . Semantic bias allows one to make finer distinctions between the objects of the same syntactic type. For example, it allows us to talk about something being a function of one attribute rather than another, which cannot be done with purely syntactic constraints.
References-found: 38

