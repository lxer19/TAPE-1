URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/94.heeman.ACL.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/heeman/papers.html
Root-URL: 
Email: fheeman,jamesg@cs.rochester.edu  
Title: Detecting and Correcting Speech Repairs  
Author: Peter Heeman and James Allen 
Address: Rochester, New York, 14627  
Affiliation: Department of Computer Science University of Rochester  
Abstract: Interactive spoken dialog provides many new challenges for spoken language systems. One of the most critical is the prevalence of speech repairs. This paper presents an algorithm that detects and corrects speech repairs based on finding the repair pattern. The repair pattern is built by finding word matches and word replacements, and identifying fragments and editing terms. Rather than using a set of pre-built templates, we build the pattern on the fly. In a fair test, our method, when combined with a statistical model to filter possible repairs, was successful at detecting and correcting 80% of the repairs, without using prosodic information or a parser. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, James F. and Lenhart K. Schubert. </author> <year> 1991. </year> <title> The TRAINS project. </title> <type> Technical Report 382, </type> <institution> Department of Computer Science, University of Rochester, </institution> <month> May. </month>
Reference-contexts: Their system looks for parts of the input utterance that were not used by the parser, and then uses semantic and pragmatic knowledge (of the limited domain) to correct the interpretation. The Corpus As part of the TRAINS project <ref> (Allen and Schubert, 1991) </ref>, which is a long term research project to build a conversationally proficient planning assistant, we are collecting a corpus of problem solving dialogs.
Reference: <author> Bear, John, John Dowding, and Elizabeth Shriberg. </author> <year> 1992. </year> <title> Integrating multiple knowledge sources for detection and correction of repairs in human-computer dialog. </title> <booktitle> In Proceedings of the 30 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 56-63. </pages>
Reference-contexts: The algorithm de-termines the text that needs to be removed by building a repair pattern, based on identification of word fragments, editing terms, and word correspondences between the removed and the resumed text <ref> (cf. Bear, Dowding, and Shriberg, 1992) </ref>. The resulting potential repairs are then passed to a statistical model that judges the proposal as either fluent speech or an actual repair. Previous Work Several different strategies have been discussed in the literature for detecting and correcting speech repairs. <p> Labov, 1966) has been difficult to find, and it is unlikely to be represented as a binary feature (cf. Nakatani and Hirschberg, 1993). The SRI group <ref> (Bear et al., 1992) </ref> employed simple pattern matching techniques for detecting and correcting modification repairs. 3 For detection, they were able to achieve a recall rate of 76%, and a precision of 62%, and they were able to find the correct repair 57% of the time, leading to an overall correction <p> But, we still will have a problem with false positives, and detecting the extent of the repair. Determining the Correction Based on the work done at SRI <ref> (Bear, Dowding, and Shriberg, 1992) </ref>, we next looked at the speech repair patterns in our annotated training corpus. If we can automatically determine the pattern, then the deletion of the removed text along with the editing terms gives the correction.
Reference: <author> Church, K. </author> <year> 1988. </year> <title> A stochastic parts program and noun phrase parser for unrestricted text. </title> <booktitle> In Preceedings of the 2nd Conference on Applied Natural Language Processing, </booktitle> <pages> pages 136-143, </pages> <month> Febuary. </month>
Reference-contexts: I think we| need| to uh| I| need| r| m| et| r| m| Algorithm Our algorithm for labeling potential repair patterns encodes the assumption that speech repairs can be processed one at a time. The algorithm runs in lockstep with a part-of-speech tagger <ref> (Church, 1988) </ref>, which is used for deciding possible word replacements. Words are fed in one at a time. The detection clues are checked first. If one of them succeeds, and there is not a repair being processed, then a new repair pattern is started. <p> So, by giving these distributions to the part-of-speech tagger (obtained from our test corpus), the tagger can decide if a transition signals a modification repair or not. Part-of-speech tagging is the process of assigning to a word the category that is most probable given the sentential context <ref> (Church, 1988) </ref>. The sentential context is typically approximated by only a set number of previous categories, usually one or two. Good part-of-speech results can be obtained using only the preceding category (Weischedel et al., 1993), which is what we will be using.
Reference: <author> Dowding, John, Jean Mark Gawron, Doug Appelt, John Bear, Lynn Cherny, Robert Moore, and Douglas Moran. </author> <year> 1993. </year> <title> Gemini: A natural language system for spoken-language understanding. </title> <booktitle> In Proceedings of the 31 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 54-61. </pages>
Reference-contexts: They also tried combining syntactic and semantic knowledge in a "parser-first" approachfirst try to parse the input and if that fails, invoke repair strategies based on word patterns in the input. In a test set containing 26 repairs <ref> (Dowding et al., 1993) </ref>, they obtained a detection recall rate of 42% and a precision of 84.6%; for correction, they obtained a recall rate of 30% and a recall rate of 62%. Nakatani and Hirschberg (1993) investigated using acoustic information to detect the interruption point of speech repairs.
Reference: <author> Gross, Derek, James Allen, and David Traum. </author> <year> 1992. </year> <title> The TRAINS 91 dialogues. </title> <type> Trains Technical Note 92-1, </type> <institution> Department of Computer Science, University of Rochester. </institution>
Reference: <author> Heeman, Peter A. and James Allen. </author> <year> 1994a. </year> <title> Annotating speech repairs. </title> <type> unpublished manuscript. </type>
Reference-contexts: Also, editing terms (filled pauses and clue words) are labeled with et, and the moment of interruption with int, which will occur before any editing terms associated with the repair, and after the fragment, if present. (Further details of this scheme can be found in <ref> (Heeman and Allen, 1994a) </ref>.) Below is a sample annotation, with removed text go to oran-, editing term um, and resumed text go to (d93-14.2 utt60). go| to| oran-| um| go| to| Corning m1| m2| x| int| et| m1| m2| A speech repair can also be characterized by its repair pattern, which
Reference: <author> Heeman, Peter A. and James Allen. </author> <year> 1994b. </year> <title> Dialogue transcription tools. </title> <type> unpublished manuscript. </type>
Reference-contexts: These dialogs have been segmented into utterance files <ref> (cf. Heeman and Allen, 1994b) </ref>; words have been transcribed and the speech repairs have been annotated.
Reference: <author> Heeman, Peter A. and James Allen. </author> <year> 1994c. </year> <title> Tagging speech repairs. </title> <booktitle> In ARPA Workshop on Human Language Technology, </booktitle> <address> Princeton, </address> <month> March. </month>
Reference: <author> Hindle, Donald. </author> <year> 1983. </year> <title> Deterministic parsing of syntactic non-fluencies. </title> <booktitle> In Proceedings of the 21 st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 123-128. </pages>
Reference: <author> Labov, William. </author> <year> 1966. </year> <title> On the grammaticality of everyday speech. </title> <booktitle> Paper presented at the Linguistic Society of America Annual Meeting. </booktitle>
Reference-contexts: Hindle admits that [self-repair], by its nature, disrupts the local context. Second, Hindle's algorithm depends on the presence of an edit signal; so far, however, the abrupt cut-off that some have suggested signals the repair <ref> (cf. Labov, 1966) </ref> has been difficult to find, and it is unlikely to be represented as a binary feature (cf. Nakatani and Hirschberg, 1993).
Reference: <author> Levelt, Willem J. M. </author> <year> 1983. </year> <title> Monitoring and self-repair in speech. </title> <journal> Cognition, </journal> <volume> 14 </volume> <pages> 41-104. </pages>
Reference: <author> Nakatani, Christine and Julia Hirschberg. </author> <year> 1993. </year> <title> A speech-first model for repair detection and correction. </title> <booktitle> In Proceedings of the 31 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 46-53. </pages>
Reference-contexts: Second, Hindle's algorithm depends on the presence of an edit signal; so far, however, the abrupt cut-off that some have suggested signals the repair (cf. Labov, 1966) has been difficult to find, and it is unlikely to be represented as a binary feature <ref> (cf. Nakatani and Hirschberg, 1993) </ref>. <p> The repair pattern for the example is mm-.emm. Repair Indicators In order to correct speech repairs, we first need to detect them. If we were using prosodic information, we could focus on the actual interruption point <ref> (cf. Nakatani and Hirschberg, 1993) </ref>; however, we are restricting ourselves to lexical clues, and so need to be more lenient.
Reference: <author> Wang, Michelle Q. and Julia Hirschberg. </author> <year> 1992. </year> <title> Automatic classification of intonational phrase boundaries. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 6 </volume> <pages> 175-196. </pages>
Reference-contexts: Recently, Dowding et al. (1993) reported syntactic and semantic coverage of 86% for the DARPA Airline reservation corpus. Unrestricted dialogs will present even more difficulties; not only will the speech be less grammatical, but there is also the problem of segmenting the dialog into utterance units <ref> (cf. Wang and Hirschberg, 1992) </ref>. If speech repairs can be detected and corrected before parsing and semantic interpretation, this should simplify those modules as well as make them more robust.
Reference: <author> Weischedel, Ralph, Marie Meteer, Richard Schwartz, Lance Ramshaw, and Jeff Palmucci. </author> <year> 1993. </year> <title> Coping with ambiguity and unknown words through probabilistic models. </title> <journal> Computational Linguistics, </journal> <volume> 19(2) </volume> <pages> 359-382. </pages>
Reference-contexts: The sentential context is typically approximated by only a set number of previous categories, usually one or two. Good part-of-speech results can be obtained using only the preceding category <ref> (Weischedel et al., 1993) </ref>, which is what we will be using. In this case, the number of states of the Markov model will be N , where N is the number of tags.
Reference: <author> Young, Sheryl R. and Michael Matessa. </author> <year> 1991. </year> <title> Using pragmatic and semantic knowledge to correct parsing of spoken language utterances. </title> <booktitle> In Proceedings of the 2nd European Conference on Speech Communication and Technology (Eurospeech 91), </booktitle> <address> Genova, Italy, </address> <month> September. </month>
Reference-contexts: The clues that they found relevant were duration of pause between words, presence of fragments, and lexical matching within a window of three words. However, they do not address the problem of determining the correction or distinguishing modification repairs from abridged repairs. Young and Matessa <ref> (Young and Matessa, 1991) </ref> have also done work in this area. In their approach, speech repairs are corrected after a opportunistic case-frame parser analyzes the utterance.
References-found: 15

