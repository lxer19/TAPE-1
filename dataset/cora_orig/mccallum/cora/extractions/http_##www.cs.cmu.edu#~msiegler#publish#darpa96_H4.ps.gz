URL: http://www.cs.cmu.edu/~msiegler/publish/darpa96_H4.ps.gz
Refering-URL: http://www.cs.cmu.edu/~msiegler/
Root-URL: 
Title: ABSTRACT  
Abstract: Practical applications of continuous speech recognition in realistic environments place increasing demands for speaker and environment independence. Until recently , this robustness has been measured using evaluation procedures where speaker and environment boundaries are known, with utterances containing complete or nearly complete sentences. This paper describes recent efforts by the CMU speech group to improve the recognition of speech found in long sections of the broadcast news show Marketplace. Most of our ef fort was concentrated in two areas: the automatic segmentation and classif ication of environments, and the construction of a suitable lexicon and language model. We review the extensions to SPHINX-II that were necessary to enable it to process continuous broadcast news and we compare the recognition accuracy of the SPHINX-II system for dif ferent environmental and speaker conditions. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Acero, A., </author> <title> Acoustical and Environmental Robustness in Automatic Speech Recognition, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1993. </year>
Reference-contexts: The process also incorporated classifier information so as to ensure that the final segments were acoustically homogenous. 2.3. Environmental Compensation Results of pilot experiments showed that recognition error rate increased when the background environment was in the music or degraded categories. In these situations, we used the CDCN algorithm <ref> [1] </ref> to compensate for environmental effects. 2.4. Acoustic Modelling Optimum recognition could be achieved if each of the environmental and speaker conditions would be recognized with fine-tuned models for the specific conditions. We used telephone-bandwidth speech models for the telephone speech and clean full-bandwidth models for all other speech. 3. <p> After all breakpoints were found, the segments were reclassified over each segment in its entirety rather than independently for each individual 1-second window. 4.2. Acoustic Compensation Speech that is classified as either noisy or telephone-bandwidth is compensated using an improved version of the Codeword-Dependent Cepstral Normalization (CDCN) algorithm <ref> [1] </ref>. CDCN improves the recognition accuracy of speech when the recording environment is dif ferent from that of the speech used to train the acoustic models. CDCN distributions for the evaluation system were trained from SI-284 WSJ0 and WSJ1 Corpora for use with noisy speech.
Reference: 2. <author> Bernstein, J. and Taussig, K.,Macrophone: </author> <title> An American English Telephone Speech Corpus for the Polyphone Project. </title> <address> ICASSP-94, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: For the Marketplace broadcasts we trained gender independent telephone-bandwidth models with a subset of utterances from the Macrophone telephone speech corpus <ref> [2] </ref>. A duration-based rejection method is used to discard words falsely decoded during music-only passages. Phonetic duration models based on the SI-284 WSJ0 and WSJ1 Corpora were used to discard words where the probability of duration was less than 0.001. 4.4.
Reference: 3. <author> Huang, X., Alleva, F. A., Hon, H.-W., Hwang, M.-Y., Lee, K.- F., and Rosenfeld, R.: </author> <title> The Sphinx-II Speech Recognition System: An Overview, </title> <booktitle> Computer Speech and Language, </booktitle> <volume> Volume 2, </volume> <pages> pp. 137 - 148. </pages>
Reference-contexts: For telephone-bandwidth speech, the SI-284 WSJ0 and WSJ1 Corpora were passed through a filter representing an average telephone channel and then used to train the CDCN distributions. Table 5 shows how recognition in adverse environments improves with the addition of CDCN. 4.3. Initial-pass recognition A fast version of SPHINX-II <ref> [3] </ref>, CMUs semi-continuous hidden Markov model recognition system, is used to decode the speech for each segment. The only modif ica-tion to the SPHINX-II system as described in [3] is that reduced-bandwidth signal processing is used to process speech that the initial-pass segmenter determines to be of telephone bandwidth. <p> Initial-pass recognition A fast version of SPHINX-II <ref> [3] </ref>, CMUs semi-continuous hidden Markov model recognition system, is used to decode the speech for each segment. The only modif ica-tion to the SPHINX-II system as described in [3] is that reduced-bandwidth signal processing is used to process speech that the initial-pass segmenter determines to be of telephone bandwidth. Environment WER (%) Baseline CDCN Music 58.4 40.9 Noise 56.2 47.0 Table 5: Changes in recognition performance for Show 940204 with the addition of CDCN environmental compensation.
Reference: 4. <author> Hwang, M.-Y., </author> <title> Subphonetic Acoustic Modeling for Speaker-Independent Continuous Speech Recognition, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1993. </year>
Reference: 5. <author> Moreno, P. J., Siegler, M. A., Jain, U., And Stern, R. M. </author> <title> Continuous Recognition of Large-Vocabulary Telephone-Quality Speech, </title> <booktitle> Proceedings of the ARPA Workshop on Spoken Language Technology, 1994, </booktitle> <address> Austin, TX, </address> <publisher> Morgan Kaufmann, J,. Cohen, Ed. </publisher>
Reference-contexts: In the Hub-2 component of the 1994 ARP A CSR evaluation we found that telephonespecific acoustic models were more effective than acoustic compensation schemes that manipulate the feature vectors <ref> [5] </ref>. For the Marketplace broadcasts we trained gender independent telephone-bandwidth models with a subset of utterances from the Macrophone telephone speech corpus [2]. A duration-based rejection method is used to discard words falsely decoded during music-only passages.
Reference: 6. <author> Rudnicky, A., </author> <title> Language Modelling with Limited Domain Data, </title> <booktitle> Proceedings of the ARPA Workshop on Spoken Language Technology, 1994, </booktitle> <address> Austin, TX, </address> <publisher> Morgan Kaufmann, J,. Cohen, Ed. </publisher>
Reference-contexts: These considerations suggest that the best language model for the task would be a combination of models from several domains. 3.1. The Language Model The language model (LM) is built from an interpolation <ref> [6] </ref> of a large static model with two smaller adaptation models. The static model is the publicly-distributed standard trigram model for the 1995 ARPA Hub 3 evaluation.
References-found: 6

