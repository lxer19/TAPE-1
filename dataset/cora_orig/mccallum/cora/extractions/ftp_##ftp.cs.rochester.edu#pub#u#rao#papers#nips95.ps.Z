URL: ftp://ftp.cs.rochester.edu/pub/u/rao/papers/nips95.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/rao/papers.html
Root-URL: 
Email: rao@cs.rochester.edu  greg@cvs.rochester.edu  mary@cvs.rochester.edu  dana@cs.rochester.edu  
Title: Modeling Saccadic Targeting in Visual Search  
Author: Rajesh P. N. Rao Gregory J. Zelinsky Mary M. Hayhoe Dana H. Ballard 
Address: Rochester, NY 14627  Rochester, NY 14627  Rochester, NY 14627  Rochester, NY 14627  
Affiliation: Computer Science Department University of Rochester  Center for Visual Science University of Rochester  Center for Visual Science University of Rochester  Computer Science Department University of Rochester  
Note: Advances in Neural Information Processing Systems 8 (NIPS*95), D. Touretzky, M. Mozer and M. Hasselmo (Eds.), MIT Press, 1996.  
Abstract: Visual cognition depends critically on the ability to make rapid eye movements known as saccades that orient the fovea over targets of interest in a visual scene. Saccades are known to be ballistic: the pattern of muscle activation for foveating a prespecified target location is computed prior to the movement and visual feedback is precluded. Despite these distinctive properties, there has been no general model of the saccadic targeting strategy employed by the human visual system during visual search in natural scenes. This paper proposes a model for saccadic targeting that uses iconic scene representations derived from oriented spatial filters at multiple scales. Visual search proceeds in a coarse-to-fine fashion with the largest scale filter responses being compared first. The model was empirically tested by comparing its performance with actual eye movement data from human subjects in a natural visual search task; preliminary results indicate substantial agreement between eye movements predicted by the model and those recorded from human subjects.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Subutai Ahmad and Stephen Omohundro. </author> <title> Efficient visual search: A connectionist solution. </title> <booktitle> In Proceeding of the 13th Annual Conference of the Cognitive Science Society, </booktitle> <address> Chicago, </address> <year> 1991. </year>
Reference-contexts: The purpose of this paper is to describe a mechanism for programming saccades that can approximately model the saccadic targeting method used by human subjects. Previous models of human visual search have focused on simple search tasks involving elementary features such as horizontal/vertical bars of possibly different color <ref> [1, 4, 8] </ref> or have relied exclusively on bottom-up input-driven saliency criteria for generating scan-paths [10, 19].
Reference: [2] <author> Dana H. Ballard, Mary M. Hayhoe, and Polly K. Pook. </author> <title> Deictic codes for the embodiment of cognition. </title> <type> Technical Report 95.1, </type> <institution> National Resource Laboratory for the study of Brain and Behavior, University of Rochester, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: In a task involving the copying of a model block pattern located on a board, fixations have been shown to be used in accessing crucial information for different stages of the copying task <ref> [2] </ref>. In natural language processing, there has been recent evidence that fixations reflect the instantaneous parsing of a spoken sentence [18]. However, none of the above work addresses the important question of what possible computational mechanisms underlie saccadic targeting.
Reference: [3] <author> P.J. Burt. </author> <title> Attention mechanisms for vision in a dynamic world. </title> <booktitle> In ICPR, </booktitle> <pages> pages 977-987, </pages> <year> 1988. </year>
Reference-contexts: The main benefit of a coarse-to-fine strategy is that it allows continuous execution of the decision/oculomotor processes, thereby increasing the probability of an early match. Coarse-to-fine strategies have enjoyed recent popularity in computer vision with the advent of image pyramids in tasks such as motion detection <ref> [3] </ref>.
Reference: [4] <author> David Chapman. </author> <title> Vision, Instruction, and Action. </title> <type> PhD thesis, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <year> 1990. </year> <type> (Technical Report 1204). </type>
Reference-contexts: The purpose of this paper is to describe a mechanism for programming saccades that can approximately model the saccadic targeting method used by human subjects. Previous models of human visual search have focused on simple search tasks involving elementary features such as horizontal/vertical bars of possibly different color <ref> [1, 4, 8] </ref> or have relied exclusively on bottom-up input-driven saliency criteria for generating scan-paths [10, 19].
Reference: [5] <author> W.G. Chase and H.A. Simon. </author> <title> Perception in chess. </title> <journal> Cognitive Psychology, </journal> <volume> 4 </volume> <pages> 55-81, </pages> <year> 1973. </year>
Reference-contexts: In chess, it has been shown that saccades are used to assess the current situation on the board in the course of making a decision to move, but the exact information that is being represented is not yet known <ref> [5] </ref>. In a task involving the copying of a model block pattern located on a board, fixations have been shown to be used in accessing crucial information for different stages of the copying task [2].
Reference: [6] <author> William T. Freeman and Edward H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE PAMI, </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: to approximate the dominant eigenvectors of natural image distributions as obtained from principal component analysis [7, 17]. 2 ICONIC REPRESENTATIONS The current implementation of our model uses a set of non-orthogonal basis functions as given by a zeroth order Gaussian G 0 and nine of its oriented derivatives as follows <ref> [6] </ref>: G n where n denotes the order of the filter and n refers to the preferred orientation of the filter (Figure 2). <p> The iconic representations can also be made invariant to rotations in the image plane (for a fixed scale) without additional convolutions by exploiting the property of steerability <ref> [6] </ref>. Rotations about an image plane axis are handled by storing feature vectors from different views.
Reference: [7] <author> Peter J.B. Hancock, Roland J. Baddeley, and Leslie S. Smith. </author> <title> The principal components of natural images. </title> <journal> Network, </journal> <volume> 3 </volume> <pages> 61-70, </pages> <year> 1992. </year>
Reference-contexts: These filters resemble the receptive field profiles of cells in the primate visual cortex [20] and have been shown to approximate the dominant eigenvectors of natural image distributions as obtained from principal component analysis <ref> [7, 17] </ref>. 2 ICONIC REPRESENTATIONS The current implementation of our model uses a set of non-orthogonal basis functions as given by a zeroth order Gaussian G 0 and nine of its oriented derivatives as follows [6]: G n where n denotes the order of the filter and n refers to the
Reference: [8] <author> Michael C. Mozer. </author> <title> The perception of multiple objects : A connectionist approach. </title> <address> Cam-bridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: The purpose of this paper is to describe a mechanism for programming saccades that can approximately model the saccadic targeting method used by human subjects. Previous models of human visual search have focused on simple search tasks involving elementary features such as horizontal/vertical bars of possibly different color <ref> [1, 4, 8] </ref> or have relied exclusively on bottom-up input-driven saliency criteria for generating scan-paths [10, 19].
Reference: [9] <author> D. Navon. </author> <title> Forest before trees: The precedence of global features in visual perception. </title> <journal> Cognitive Psychology, </journal> <volume> 9 </volume> <pages> 353-383, </pages> <year> 1977. </year>
Reference-contexts: This interpretation of the data is appealing in two aspects. First, it reflects a long history of observations on the priority of large scale channels <ref> [9] </ref>, and second, it reflects current thinking about eye movement programming suggesting that fixation times are approximately constant and that the eyes are moved as soon as they can be during the course of visual problem solving.
Reference: [10] <author> Ernst Niebur and Christof Koch. </author> <title> Control of selective visual attention: </title> <booktitle> Modeling the where pathway. This volume, </booktitle> <year> 1996. </year>
Reference-contexts: Previous models of human visual search have focused on simple search tasks involving elementary features such as horizontal/vertical bars of possibly different color [1, 4, 8] or have relied exclusively on bottom-up input-driven saliency criteria for generating scan-paths <ref> [10, 19] </ref>. The proposed model achieves targeting in arbitrary visual scenes by using bottom-up scene representations in conjunction with previously memorized top-down object representations; both of these representations are iconic, based on oriented spatial filters at multiple scales.
Reference: [11] <author> D. Noton and L. Stark. </author> <title> Scanpaths in saccadic eye movements while viewing and recognizing patterns. </title> <journal> Vision Reseach, </journal> <volume> 11 </volume> <pages> 929-942, </pages> <year> 1971. </year>
Reference-contexts: The initial fixation point is denoted by `+'. (b) depicts a summary of such movements over many experiments as a function of the six possible locations of a target object on the table. objects <ref> [11] </ref> but subsequent work has suggested that the role of saccades is more tightly coupled to the momentary problem solving strategy being employed by the subject.
Reference: [12] <author> Steven J. Nowlan. </author> <title> Maximum likelihood competitive learning. </title> <booktitle> In Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 574-582. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: For the experiments, we chose: F (S m (x; y)) = P This choice is attractive since it allows an interpretation of our algorithm as computing maximum likelihood estimates (cf. <ref> [12] </ref>) of target locations. In the above, (k) is decreased with k. 4.
Reference: [13] <author> J.K. O'Regan. </author> <title> Eye movements and reading. </title> <editor> In E. Kowler, editor, </editor> <booktitle> Eye Movements and Their Role in Visual and Cognitive Processes, </booktitle> <pages> pages 455-477. </pages> <address> New York: </address> <publisher> Elsevier, </publisher> <year> 1990. </year>
Reference-contexts: The high velocity of saccades, reaching up to 700 ffi per second for large movements, serves to minimize the time in flight; most of the time is spent fixating the chosen targets. The objective of saccades is currently best understood for reading text <ref> [13] </ref> where the eyes fixate almost every word, sometimes skipping over small function words. In general scenes, however, the purpose of saccades is much more difficult to analyze.
Reference: [14] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> An active vision architecture based on iconic representations. </title> <journal> Artificial Intelligence (Special Issue on Vision), </journal> <volume> 78 </volume> <pages> 461-505, </pages> <year> 1995. </year>
Reference-contexts: The iconic representations can also be made invariant to rotations in the image plane (for a fixed scale) without additional convolutions by exploiting the property of steerability [6]. Rotations about an image plane axis are handled by storing feature vectors from different views. We refer the interested reader to <ref> [14] </ref> for more details regarding the above properties. 3 THE VISUAL SEARCH MODEL Our model for visual search is derived from a model for vision that we previously proposed in [14]. <p> We refer the interested reader to <ref> [14] </ref> for more details regarding the above properties. 3 THE VISUAL SEARCH MODEL Our model for visual search is derived from a model for vision that we previously proposed in [14]. <p> The visual search model assumes the existence of three independent processes running concurrently: (a) a targeting process (similar to the where routine of <ref> [14] </ref>) that computes the next location to be fixated; (b) an oculomotor process that accepts target locations and executes a saccade to foveate that location (see [16] for more details); and (c) a decision process that models the cortico-cortical dynamics of the V 1 $ V 2 $ V 4 $
Reference: [15] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> Dynamic model of visual memory predicts neural response properties in the visual cortex. </title> <type> Technical Report 95.4, </type> <institution> National Resource Laboratory for the study of Brain and Behavior, Computer Sci. Dept., University of Rochester, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: that accepts target locations and executes a saccade to foveate that location (see [16] for more details); and (c) a decision process that models the cortico-cortical dynamics of the V 1 $ V 2 $ V 4 $ IT pathway related to the identification of objects in the fovea (see <ref> [15] </ref> for more details). Here, we focus on the saccadic targeting process. Objects of interest to the current search task are assumed to be represented by a set of previously memorized iconic feature vectors r m s where s denotes the scale of the filters.
Reference: [16] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> Learning saccadic eye movements using multiscale spatial filters. </title> <editor> In G. Tesauro, D.S. Touretzky, and T.K. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 7, </booktitle> <pages> pages 893-900. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: The visual search model assumes the existence of three independent processes running concurrently: (a) a targeting process (similar to the where routine of [14]) that computes the next location to be fixated; (b) an oculomotor process that accepts target locations and executes a saccade to foveate that location (see <ref> [16] </ref> for more details); and (c) a decision process that models the cortico-cortical dynamics of the V 1 $ V 2 $ V 4 $ IT pathway related to the identification of objects in the fovea (see [15] for more details). Here, we focus on the saccadic targeting process.
Reference: [17] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> Natural basis functions and topographic memory for face recognition. </title> <booktitle> In Proc. of IJCAI, </booktitle> <pages> pages 10-17, </pages> <year> 1995. </year>
Reference-contexts: These filters resemble the receptive field profiles of cells in the primate visual cortex [20] and have been shown to approximate the dominant eigenvectors of natural image distributions as obtained from principal component analysis <ref> [7, 17] </ref>. 2 ICONIC REPRESENTATIONS The current implementation of our model uses a set of non-orthogonal basis functions as given by a zeroth order Gaussian G 0 and nine of its oriented derivatives as follows [6]: G n where n denotes the order of the filter and n refers to the
Reference: [18] <author> M. Tanenhaus, M. Spivey-Knowlton, K. Eberhard, and J. Sedivy. </author> <title> Integration of visual and linguistic information in spoken language comprehension. </title> <note> To appear in Science, </note> <year> 1995. </year>
Reference-contexts: In natural language processing, there has been recent evidence that fixations reflect the instantaneous parsing of a spoken sentence <ref> [18] </ref>. However, none of the above work addresses the important question of what possible computational mechanisms underlie saccadic targeting. The complexity of the targeting problem can be illustrated by the saccades employed by subjects to solve a natural visual search task.
Reference: [19] <author> Keiji Yamada and Garrison W. Cottrell. </author> <title> A model of scan paths applied to face recognition. </title> <booktitle> In Proc. 17th Annual Conf. of the Cognitive Science Society, </booktitle> <year> 1995. </year>
Reference-contexts: Previous models of human visual search have focused on simple search tasks involving elementary features such as horizontal/vertical bars of possibly different color [1, 4, 8] or have relied exclusively on bottom-up input-driven saliency criteria for generating scan-paths <ref> [10, 19] </ref>. The proposed model achieves targeting in arbitrary visual scenes by using bottom-up scene representations in conjunction with previously memorized top-down object representations; both of these representations are iconic, based on oriented spatial filters at multiple scales.
Reference: [20] <author> R.A. Young. </author> <title> The Gaussian derivative theory of spatial vision: Analysis of cortical cell receptive field line-weighting profiles. </title> <journal> General Motors Research Publication GMR-4920, </journal> <year> 1985. </year>
Reference-contexts: These filters resemble the receptive field profiles of cells in the primate visual cortex <ref> [20] </ref> and have been shown to approximate the dominant eigenvectors of natural image distributions as obtained from principal component analysis [7, 17]. 2 ICONIC REPRESENTATIONS The current implementation of our model uses a set of non-orthogonal basis functions as given by a zeroth order Gaussian G 0 and nine of its
References-found: 20

