URL: http://foxnet.cs.cmu.edu/people/petel/papers/staged/mleone-pldi96.ps
Refering-URL: http://foxnet.cs.cmu.edu/people/petel/papers/staged/staged.html
Root-URL: 
Title: Optimizing ML with Run-Time Code Generation  
Author: Mark Leone Peter Lee 
Note: The authors' electronic mail addresses are  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Pubnum: CMU-CS-95-205  
Email: Mark.Leone@cs.cmu.edu and Peter.Lee@cs.cmu.edu.  
Date: December 1995  
Abstract: We describe the design and implementation of a compiler that automatically translates ordinary programs written in a subset of ML into code that generates native code at run time. Run-time code generation can make use of values and invariants that cannot be exploited at compile time, yielding code that is superior to statically optimal code. But the cost of optimizing and generating code at run time can be prohibitive. We demonstrate how compile-time specialization can reduce the cost of run-time code generation by an order of magnitude without greatly affecting code quality. Several benchmark programs are examined, which exhibit an average cost of six cycles per instruction generated at run time. This research was sponsored in part by the Advanced Research Projects Agency CSTO under the title "The Fox Project: Advanced Langauges for Systems Software," ARPA Order No. C533, issued by ESC/ENS under Contract No. F19628-95-C-0050. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Advanced Research Projects Agency or the U.S. Government. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: The early instructions are simply executed, but the late instructions are emitted into a dynamic code segment, as explained below. For example, when supplied with the vector v1 = <ref> [1, 2, 3] </ref>, the following dot-product function is dynamically created: 3 There are other simplifications as well: we omitted the code for subscript checking and run-time instruction selection, and used a single pseudo-instruction for multiplication that actually requires multiple instructions to implement on the MIPS. <p> membership is also well suited to run-time code generation, because repeated membership tests on the same set require duplicate effort that can be amortized. function written in ML, and Figure 4 (e) shows how this improves the performance of a commonly used ML benchmark, Conway's game of life (adapted from <ref> [1] </ref>), which uses a set to record the locations of living cells. Run-time code generation does not always improve performance, of course.
Reference: [2] <author> Brian Bershad, Stefan Savage, Przemyslaw Pardyak, Emin Gun Sirer, Marc Fiuczynski, David Becker, Craig Chambers, and Susan Eggers. </author> <title> Extensibility, safety and performance in the SPIN operating system. </title> <booktitle> In 1995 ACM Symposium on Operating Systems Principles, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: This trend has prompted a corresponding increase of interest in run-time (and link-time) optimization and code generation as a way to regain the performance advantage enjoyed by special-purpose, monolithic systems <ref> [2] </ref>. Additional arguments for run-time code generation can be found in [15]. 2.1 Run-Time Compilers Despite the increasing attention, researchers have done relatively little to automate and optimize the process of run-time optimization and compilation itself. <p> The early instructions are simply executed, but the late instructions are emitted into a dynamic code segment, as explained below. For example, when supplied with the vector v1 = <ref> [1, 2, 3] </ref>, the following dot-product function is dynamically created: 3 There are other simplifications as well: we omitted the code for subscript checking and run-time instruction selection, and used a single pseudo-instruction for multiplication that actually requires multiple instructions to implement on the MIPS. <p> Run-time code generation can eliminate the overhead of interpretation by compiling a selection predicate into trusted native code. More generally, run-time code generation can allow a kernel to efficiently execute "agents" supplied by user-level processes while avoiding context switches. Such an approach has also been investigated by others <ref> [12, 2] </ref>.
Reference: [3] <author> Edoardo Biagioni, Robert Harper, and Peter Lee. </author> <title> Signatures for a protocol stack: A systems application of Standard ML. </title> <booktitle> In Proceedings of the 1994 ACM Conference on Lisp and Functional Programming, </booktitle> <address> Orlando, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: His primary strategy was to delay confrontation; repeated small attacks eventually led to victory without a single decisive conflict. 3 protocols) <ref> [3] </ref>. Thus, we have a special interest in the optimization of ML programs. Second, ML provides good support for expressing staged computations in a way that might be usefully exploited by run-time code generation. <p> The early instructions are simply executed, but the late instructions are emitted into a dynamic code segment, as explained below. For example, when supplied with the vector v1 = <ref> [1, 2, 3] </ref>, the following dot-product function is dynamically created: 3 There are other simplifications as well: we omitted the code for subscript checking and run-time instruction selection, and used a single pseudo-instruction for multiplication that actually requires multiple instructions to implement on the MIPS.
Reference: [4] <author> Chaig Chambers, Susan J. Eggers, Joel Auslander, Matthai Philipose, Markus Mock, and Prze-myslaw Pardyak. </author> <title> Automatic dynamic compilation support for event dispatching in extensible systems. </title> <note> In preparation, </note> <year> 1995. </year>
Reference-contexts: Templates and the code that instantiates them are typically constructed manually, which is non-portable and error prone. Recent work has explored the automatic derivation of templates from 2 programs written in higher-level languages such as C <ref> [7, 23, 4] </ref>. Some amount of programmer effort is still required in such systems to guide template creation and manage run-time generated code. A significant drawback of templates is that they severely limit the range of optimizations that may be applied at run time.
Reference: [5] <author> Craig Chambers and David Ungar. </author> <title> Customization: Optimizing compiler technology for SELF, a dynamically-typed object-oriented programming language. </title> <booktitle> In ACM SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 146-160, </pages> <month> June </month> <year> 1989. </year> <month> 17 </month>
Reference-contexts: Run-time code generation also led to notable performance improvements in the areas of graphics (in bitblt code [22]), operating systems (in the Synthesis kernel [17]), method dispatch in object-oriented systems (in Smalltalk [9] and SELF <ref> [5] </ref>), instruction-set simulation (in Shade [6]), and many others. Indeed, with the emergence of highly distributed and Web computing, more applications 1 demand software that is general-purpose, safe, and highly composable. <p> An even better approach is to design the programming language so that run-time code generation can be smoothly integrated into the semantics of the language. For example, in an implementation of SELF <ref> [5] </ref>, the system provides run-time compilation of type-specialized versions of methods by invoking the compiler at run time automatically, without any need for the programmer to specify anything in the program.
Reference: [6] <author> Robert F. Cmelik and David Keppel. Shade: </author> <title> A fast instruction-set simulator for execution profiling. </title> <type> Technical Report 93-06-06, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Run-time code generation also led to notable performance improvements in the areas of graphics (in bitblt code [22]), operating systems (in the Synthesis kernel [17]), method dispatch in object-oriented systems (in Smalltalk [9] and SELF [5]), instruction-set simulation (in Shade <ref> [6] </ref>), and many others. Indeed, with the emergence of highly distributed and Web computing, more applications 1 demand software that is general-purpose, safe, and highly composable.
Reference: [7] <author> Charles Consel and Francois Noel. </author> <title> A general approach to run-time specialization and its application to C. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Templates and the code that instantiates them are typically constructed manually, which is non-portable and error prone. Recent work has explored the automatic derivation of templates from 2 programs written in higher-level languages such as C <ref> [7, 23, 4] </ref>. Some amount of programmer effort is still required in such systems to guide template creation and manage run-time generated code. A significant drawback of templates is that they severely limit the range of optimizations that may be applied at run time.
Reference: [8] <author> Rowan Davies and Frank Pfenning. </author> <title> A modal analysis of staged computation. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1996. </year> <note> To appear. An earlier version is available as Technical Report CMU-CS-95-145, </note> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: Memoization can be expensive and is sometimes ineffective, and the heuristic we employ to control run-time inlining occasionally leads to overspecialization or under-specialization. Recent advances in type theory have suggested a mechanism for providing better feedback to programmers <ref> [8] </ref>. Ultimately, the feasibility of deferred compilation will have to be demonstrated on larger, more realistic programs. It is encouraging to see that a prototype such as Fabius can already achieve good results.
Reference: [9] <author> L. Peter Deutsch and Allan M. Schiffman. </author> <title> Efficient implementation of the Smalltalk-80 system. </title> <booktitle> In Conference Record of the 11th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <address> Salt Lake City, </address> <pages> pages 297-302, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: Run-time code generation also led to notable performance improvements in the areas of graphics (in bitblt code [22]), operating systems (in the Synthesis kernel [17]), method dispatch in object-oriented systems (in Smalltalk <ref> [9] </ref> and SELF [5]), instruction-set simulation (in Shade [6]), and many others. Indeed, with the emergence of highly distributed and Web computing, more applications 1 demand software that is general-purpose, safe, and highly composable.
Reference: [10] <author> Dawson R. Engler, Wilson C. Hsieh, and M. Frans Kaashoek. </author> <title> `C: A language for high-level, efficient, and machine-independent dynamic code generation. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: The advantage of S-expressions is that the programmer can specify the construction of Lisp terms at the source level, rather than as intermediate code trees. Recently, Engler and colleagues added support for this style of run-time code generation on top of DCG, in a system called `C <ref> [10] </ref>, with good results. An even better approach is to design the programming language so that run-time code generation can be smoothly integrated into the semantics of the language.
Reference: [11] <author> Dawson R. Engler and Todd A. Proebsting. </author> <title> DCG: An efficient, retargetable dynamic code generation system. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS VI), </booktitle> <pages> pages 263-272. </pages> <publisher> ACM Press, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: A standard approach is to provide programming support for constructing representations of programs at run time, and for invoking an optimizing compiler to transform such representations into native code. This approach is relatively easy to implement, and systems such as DCG <ref> [11] </ref> based on this approach have been shown to be useful in interesting applications. Using DCG, a C programmer can write a program that constructs intermediate code trees and then invokes a compiler back-end to translate them into optimized native code that can be dynamically linked and executed. <p> For example, DCG's reported overhead of generating an instruction at run time is about 350 instructions per instruction generated <ref> [11] </ref>. Fundamentally, the use of a general tool such as a compiler|even if it is just the back-end of a compiler|is at odds with the goal of eliminating the cost of generality in favor of the efficiency of specialization. 2.2 Templates vs. <p> For comparison purposes, we also evaluated the performance of two matrix multiplication algorithms implemented in C. One was a conventional triply nested loop (in row-major order) and the other was a more complicated specialized algorithm from <ref> [11] </ref>, based on indirection vectors, that is well-suited to sparse matrices that lack predictable characteristics. The ML implementation was purely functional and used dynamically dimensioned arrays, which were implemented using immutable one-dimensional vectors; each subscript operation included a bounds check.
Reference: [12] <author> Dawson R. Engler, Deborah Wallach, and M. Frans Kaashoek. </author> <title> Efficient, safe, application-specific message processing. </title> <type> Technical Report MIT/LCS/TM533, </type> <institution> Massachussetts Institute of Technology Laboratory for Computer Science, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: Run-time code generation can eliminate the overhead of interpretation by compiling a selection predicate into trusted native code. More generally, run-time code generation can allow a kernel to efficiently execute "agents" supplied by user-level processes while avoiding context switches. Such an approach has also been investigated by others <ref> [12, 2] </ref>.
Reference: [13] <author> Marc Feeley, Marcel Turcotte, and Guy Lapalme. </author> <title> Using Multilisp for solving constraint satisfaction problems: An application to nucleic acid 3D structure determination. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 7 </volume> <pages> 231-247, </pages> <year> 1994. </year>
Reference-contexts: Even with favorable input (in this case, a reverse-sorted prefix of /usr/dict/words), most of the comparisons do not examine more than two or three characters of each string, so the time spent generating code for the remaining characters is wasted. We also experimented with the Pseudoknot benchmark <ref> [13] </ref>, which is a floating-point intensive program that attempts to determine the three-dimensional structure of portions of RNA molecules using constraint satisfaction and backtracking search.
Reference: [14] <author> David Keppel. </author> <title> A portable interface for on-the-fly instruction space modification. </title> <booktitle> In Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 86-95, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Thus, invalidating or updating the instruction cache is necessary to ensure that it remains coherent with memory. Coherency mechanisms vary, but portability does not appear to be a major concern <ref> [14] </ref>. The cost of instruction-cache invalidation varies widely, however. On a typical modern architecture, the DECstation 5000/200, flushing the instruction cache requires a kernel trap plus approximately 0.8 nanoseconds per byte flushed [14]. Fortunately, it is relatively easy to amortize this cost. <p> Coherency mechanisms vary, but portability does not appear to be a major concern <ref> [14] </ref>. The cost of instruction-cache invalidation varies widely, however. On a typical modern architecture, the DECstation 5000/200, flushing the instruction cache requires a kernel trap plus approximately 0.8 nanoseconds per byte flushed [14]. Fortunately, it is relatively easy to amortize this cost. Since Fabius-generated code generators do not modify existing code, it is not necessary to flush individual words from the instruction cache as new instructions are written.
Reference: [15] <author> David Keppel, Susan J. Eggers, and Robert R. Henry. </author> <title> A case for runtime code generation. </title> <type> Technical Report 91-11-04, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: This trend has prompted a corresponding increase of interest in run-time (and link-time) optimization and code generation as a way to regain the performance advantage enjoyed by special-purpose, monolithic systems [2]. Additional arguments for run-time code generation can be found in <ref> [15] </ref>. 2.1 Run-Time Compilers Despite the increasing attention, researchers have done relatively little to automate and optimize the process of run-time optimization and compilation itself. Indeed, existing approaches, while quite effective for some applications, are themselves rather specialized and require significant effort on the part of the programmer.
Reference: [16] <author> Mark Leone and Peter Lee. </author> <title> Lightweight run-time code generation. In PEPM 94 Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </title> <type> pages 97-106. Technical Report 94/9, </type> <institution> Department of Computer Science, University of Melbourne, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: a partial evaluator, but it does use partial evaluation techniques to create specialized run-time code generators that do not manipulate templates or any other intermediate representation of code at run time. 3 The Fabius Compiler We have previously given a high-level overview of our approach, which we call deferred compilation <ref> [16] </ref>. The main goals of deferred compilation are to minimize the costs of run-time code generation while at the same time allowing a full range of optimizations in both the statically and dynamically generated code. <p> Syntactically, these hints are given by declaring functions so that they take their arguments in curried form. 2 In particular, this staging analysis is more difficult than binding-time analysis because an initial division of program inputs is not supplied by the programmer <ref> [16] </ref>. 4 When a curried function is applied to its first argument|referred to as the "early" argument|it invokes a code generator to create a specialized function that is parameterized by the remaining "late" arguments. <p> Function applications have also been given early annotations, which is taken as an indication that they should be inlined at run time. Determining the treatment of function calls is actually a rather subtle problem, which we do not discuss here. (See <ref> [16] </ref> for details.) After annotating the program, Fabius compiles it into an RTL-like intermediate representation, also containing early and late annotations, which in turn is translated into a representation of annotated MIPS assembly code. <p> Fabius is forced to insert spill code around inlined code in several of the benchmarks we have examined. We propose an efficient solution to this problem in <ref> [16] </ref>. 4 Preliminary Results To evaluate the performance of Fabius, we have experimented with a number of small and medium-sized benchmark programs. Since the current Fabius prototype does not yet have a garbage collector, the measurements we report here do not reflect the cost of reclaiming data and code space.
Reference: [17] <author> Henry Massalin. </author> <title> Synthesis: An Efficient Implementation of Fundamental Operating System Services. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <year> 1992. </year>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it quickly generated special-purpose code). Run-time code generation also led to notable performance improvements in the areas of graphics (in bitblt code [22]), operating systems (in the Synthesis kernel <ref> [17] </ref>), method dispatch in object-oriented systems (in Smalltalk [9] and SELF [5]), instruction-set simulation (in Shade [6]), and many others. Indeed, with the emergence of highly distributed and Web computing, more applications 1 demand software that is general-purpose, safe, and highly composable. <p> Fabius automatically compiles a curried lookup function into a code generator that, in essence, creates executable data structures <ref> [17] </ref> that require no memory accesses; a sample of the lookup code generated at run time is contained in Figure 5.
Reference: [18] <author> Henry Massalin and Calton Pu. </author> <title> Threads and input/output in the Synthesis kernel. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 191-201, </pages> <year> 1989. </year> <month> 18 </month>
Reference-contexts: Several systems have used this approach with great success, such as Pike, Locanthi, and Reiser's bitblt compiler [22] and in Massalin and Pu's Synthesis kernel <ref> [18] </ref>. Until very recently, the use of templates has imposed a significant burden on programmers. Templates and the code that instantiates them are typically constructed manually, which is non-portable and error prone.
Reference: [19] <author> Steven McCanne. </author> <title> The Berkeley Packet Filter man page. </title> <note> BPF distribution available at ftp://ftp.ee.lbl.gov. </note>
Reference-contexts: Jump if accumulator equals immediate. *) else if opcode = JEQ K then if a = filter sub (pc+1) then eval (filter, pc + ((instr &gt;> 8) andb 255)) (a, x, mem, pkt) else eval (filter, pc + (instr andb 255)) (a, x, mem, pkt) ... end 11 in C <ref> [19] </ref>. The interpreter shown in Figure 2 is a simple ML function, called eval, that is pa-rameterized by the filter program, a network packet, and variables that encode the machine state.
Reference: [20] <author> Steven McCanne and Van Jacobson. </author> <title> The BSD packet filter: A new architecture for user-level packet capture. </title> <booktitle> In Proceedings of the Winter 1993 USENIX Conference, </booktitle> <pages> pages 259-269. </pages> <publisher> USENIX Association, </publisher> <month> January </month> <year> 1993. </year>
Reference-contexts: Many useless packets may be delivered as a result, with a consequent degradation of performance. A commonly adopted solution to this problem is to parameterize a packet filter by a selection predicate that is dynamically constructed by a user-level process <ref> [21, 20] </ref>. A selection predicate is expressed in the abstract syntax of a "safe" or easily verified programming language, so that it can be trusted by the kernel. But this approach has significant overhead: the selection predicate is re-interpreted every time a packet is received. <p> More generally, run-time code generation can allow a kernel to efficiently execute "agents" supplied by user-level processes while avoiding context switches. Such an approach has also been investigated by others [12, 2]. To investigate the feasibility of this idea, we implemented the BSD packet filter language <ref> [20] </ref> using Fabius and compared its performance to BPF, a kernel-resident interpreter implemented 10 (* The BSD packet filter language is comprised of RISC-like instructions for a simple abstract machine with an accumulator, an index register, and a small scratch memory.
Reference: [21] <author> Jeffrey C. Mogul, Richard F. Rashid, and Michael J. Accetta. </author> <title> The packet filter: An efficient mechanism for user-level network code. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 39-51. </pages> <publisher> ACM Press, </publisher> <month> November </month> <year> 1987. </year> <note> An updated version is available as DEC WRL Research Report 87/2. </note>
Reference-contexts: Many useless packets may be delivered as a result, with a consequent degradation of performance. A commonly adopted solution to this problem is to parameterize a packet filter by a selection predicate that is dynamically constructed by a user-level process <ref> [21, 20] </ref>. A selection predicate is expressed in the abstract syntax of a "safe" or easily verified programming language, so that it can be trusted by the kernel. But this approach has significant overhead: the selection predicate is re-interpreted every time a packet is received.
Reference: [22] <author> Rob Pike, Bart Locanthi, and John Reiser. </author> <title> Hardware/software trade-offs for bitmap graphics on the Blit. </title> <journal> Software | Practice and Experience, </journal> <volume> 15(2) </volume> <pages> 131-151, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: This program was both general (because it accepted any regular expression) and fast (because it quickly generated special-purpose code). Run-time code generation also led to notable performance improvements in the areas of graphics (in bitblt code <ref> [22] </ref>), operating systems (in the Synthesis kernel [17]), method dispatch in object-oriented systems (in Smalltalk [9] and SELF [5]), instruction-set simulation (in Shade [6]), and many others. Indeed, with the emergence of highly distributed and Web computing, more applications 1 demand software that is general-purpose, safe, and highly composable. <p> Code is generated at run time by simply copying templates and instantiating holes with values computed at run time; templates may also be concatenated to effect loop unrolling and function inlining. Several systems have used this approach with great success, such as Pike, Locanthi, and Reiser's bitblt compiler <ref> [22] </ref> and in Massalin and Pu's Synthesis kernel [18]. Until very recently, the use of templates has imposed a significant burden on programmers. Templates and the code that instantiates them are typically constructed manually, which is non-portable and error prone.
Reference: [23] <author> Massimiliano Poletto, Dawson R. Engler, and M. Frans Kaashoek. tcc: </author> <title> A template-based compiler for `C. </title> <note> In preparation, </note> <year> 1995. </year>
Reference-contexts: Templates and the code that instantiates them are typically constructed manually, which is non-portable and error prone. Recent work has explored the automatic derivation of templates from 2 programs written in higher-level languages such as C <ref> [7, 23, 4] </ref>. Some amount of programmer effort is still required in such systems to guide template creation and manage run-time generated code. A significant drawback of templates is that they severely limit the range of optimizations that may be applied at run time.
Reference: [24] <author> David Tarditi, Greg Morrisett, Perry Cheng, Christopher Stone, Robert Harper, and Peter Lee. </author> <title> TIL: A type-directed optimizing compiler for ML. </title> <note> Submitted for publication, </note> <year> 1995. </year>
Reference-contexts: Existing ML compilers commonly use tags to distinguish between integers and pointers in order to support efficient garbage collection, but this has undesirable side effects: integers are restricted to 31 bits and numerous tagging and untagging operations are involved in arithmetic operations. The TIL compiler project <ref> [24] </ref> has shown that a principled use of types at compile time and run time permits most ML code to be compiled into tag-free, monomorphic code. Hence, we have focused on efficiently compiling such code and have ignored the problem of tagging.
Reference: [25] <author> Ken Thompson. </author> <title> Regular expression search algorithm. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 11(6) </volume> <pages> 419-422, </pages> <month> June </month> <year> 1968. </year>
Reference-contexts: For example, in 1968 Ken Thompson implemented a search algorithm that compiled a user-supplied regular expression into an executable finite-state machine in the form of native code for the IBM 7094 <ref> [25] </ref>. This program was both general (because it accepted any regular expression) and fast (because it quickly generated special-purpose code). <p> Because the cost of run-time code generation was low, performance on smaller systems of equations was also superior to the statically optimized code. using run-time code generation. Unlike Thompson's compiler for regular expressions <ref> [25] </ref>, our program is a simple backtracking interpreter. Fabius compiled it into a code generator that, given a regular expression, creates a finite state machine (in native MIPS code).
Reference: [26] <author> Roger L. Wainwright and Marian E. Sexton. </author> <title> A study of sparse matrix representations for solving linear systems in a functional language. </title> <journal> Journal of Functional Programming, </journal> <volume> 2(1) </volume> <pages> 61-72, </pages> <month> January </month> <year> 1992. </year> <month> 19 </month>
Reference-contexts: The total cost of run-time code generation varied from one benchmark to the next, but its relative cost was low, averaging roughly six cycles per generated instruction. The first benchmark (Figure 4a) is an iterative solver for sparse linear systems of equations, adapted from <ref> [26] </ref>. It is based on the conjugate gradient method, which finds solutions to systems of equations of the form Ax = b, where A is a square, symmetric, positive-definite matrix of double-floating-point values.
References-found: 26

