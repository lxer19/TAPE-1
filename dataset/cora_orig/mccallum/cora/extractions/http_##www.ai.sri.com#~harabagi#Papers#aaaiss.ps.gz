URL: http://www.ai.sri.com/~harabagi/Papers/aaaiss.ps.gz
Refering-URL: http://www.ai.sri.com/~harabagi/
Root-URL: 
Email: harabagi@usc.edu  moldovan@seas.smu.edu  yukawa@nttkb.ntt.jp  
Title: Testing Gricean Constraints on a WordNet-based Coherence Evaluation System Whenever two markers originated from different
Author: Sanda M. Harabagiu Dan I. Moldovan Takashi Yukawa 
Note: The main idea  
Address: Los Angeles, CA 90089-2562  Dallas, TX 75275  R&D Center Kanagawa 238-03, Japan  
Affiliation: University of Southern California  Southern Methodist University  NTT  
Abstract: This paper presents a computational method for analyzing Gricean constraints for the purpose of evaluating text coherence. Our system consists of a knowledge base constructed on top of WordNet, an inference engine that establishes discourse semantic paths between the input concepts and a mechanism of relating them to the context. Grice's maxims provide conditions to test coherence, while the semantic paths provide the space on which these conditions are tested. The computational method is based on a marker-propagation technique that is independent of the size of the knowledge base. The paper describes the method and provides results obtained with the system. The key idea of this paper is to link Grice's maxims for conversational logic with high level inferences drawn from a linguistic knowledge base. We discuss how the Gricean maxims may be tested in a real natural language processing system and how the information extracted plays a role in the analysis of context, dialogue coherence, and intentions. A text is considered to be coherent when it is logically connected and intelligible. The logical connections are semantic relationships between concepts. We are experimenting with a text understanding system that operates on a large linguistic knowledge base with concepts and relations between concepts. Inference rules are constructed by chaining semantic relations in the knowledge base. A few of these rules lead to deductions, but many provide only plausible inferences. Semantic paths between concepts may be established as patterns of inference rules. The information along such paths provides an explanation for the relationship between two concepts. In this paper, we link these semantic paths to Gricean constraints. The concepts and the relations that form the semantic paths provide context and information about text coherence. The Gricean constraints are first tested by analyzing the paths; and this provides information to validate or filter out irrelevant inferences. The path finding algorithm designed by us uses a marker propagation paradigm that is highly parallel and asynchronous. Unlike other attempts that use marker-passing (Charniak 1986), (Norvig 1987), we use propagation rules that guide the movement of markers along some selected relations. Any marker present on a node may further propagate along semantic relations that (a) generalize, (b) define the features or (c) entail or are entailed by the properties of the concept represented by that node. The knowledge base of our system was created starting from WordNet, the on-line dictionary developed at Princeton(Fellbaum & Gross & Miller 1991). Word-Net, created as a computer based dictionary, is built as a semantic knowledge base covering the vast majority of nouns, verbs, adjectives and adverbs from the English language. The words in WordNet are organized in synsets, which are representations of concepts expressed by synonymous words. The relations from WordNet are the building blocks to our solution for semantic paths finding. The semantic relations between concepts are : hypernymy/hyponymy (isa relations), meronymy/holonymy (part-of relations), tro-ponymy (kind-of relations), causation, entailment and pertanymy (pertain relations between words with common morphological properties). Approximately 85% of the WordNet concepts have a gloss expressed in English that define that concept. These defining features 
Abstract-found: 1
Intro-found: 0
Reference: <author> R. Alterman. </author> <title> A dictionary based on concept coherence. </title> <journal> Artificial Intelligence, </journal> <volume> 25 </volume> <pages> 153-186, </pages> <year> 1985. </year>
Reference: <author> E. Charniak. </author> <title> A neat theory of marker passing. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence AAAI-86, </booktitle> <pages> 584-588, </pages> <year> 1986. </year>
Reference: <author> P.R. Cohen and C.L. Loiselle. </author> <title> Beyond ISA: Structures for Plausible Inference in Semantic Networks. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence AAAI-88, </booktitle> <pages> 415-420, </pages> <year> 1988. </year>
Reference: <author> B. Di Eugenio. </author> <title> Understanding Natural Language Instructions: the Case of Purpose Clauses. </title> <booktitle> In Proceedings of the 30th Meeting of the Association for Computational Linguistics, ACL-92, </booktitle> <pages> 120-127, </pages> <year> 1992. </year>
Reference: <author> C. Fellbaum. </author> <title> English verbs as a semantic net. </title> <type> Technical Report CSL 90-43, </type> <institution> Princeton University, </institution> <month> July </month> <year> 1990. </year>
Reference: <author> C. Fellbaum, D. Gross, and G. Miller. </author> <title> Wordnet : A lexical database organized on psycholinguistic principles. </title> <publisher> In Lawrence Erlbaum Associates, </publisher> <editor> editor, </editor> <title> Lexical Aquisition: Exploiting On-Line Resources to Build a Lexicon, </title> <type> 141-170. Zernik, </type> <address> U., Washington, </address> <year> 1991. </year>
Reference: <author> P. Grice. </author> <title> Logic and conversation. </title> <editor> In P. Cole and J.L. Morgan, editors, Syntax and Sematics Vol.3:Speech Acts, </editor> <address> 41-58. </address> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1975. </year>
Reference: <author> B.J. Grosz. </author> <title> The representation and use of focus in a system for understanding dialogs. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI-77, </booktitle> <pages> 67-76, </pages> <year> 1983. </year>
Reference: <author> S. Harabagiu and D. Moldovan. </author> <title> A Marker-Propagation Algorithm for Text Coherence. </title> <booktitle> In Proceedings of the Workshop on Parallel Processing in Artificial Intelligence, , IJCAI-95, </booktitle> <pages> 23-35, </pages> <year> 1995. </year>
Reference: <author> J.R. Hobbs. </author> <title> On the Coherence and Structure of Discourse. </title> <type> Technical Report CSLI-85-37, </type> <institution> Stanford University, </institution> <year> 1985. </year>
Reference: <author> W.C. Mann and S.A. Thomson. </author> <title> Rhetorical Structure Theory. Text, </title> <address> 8-3:243-281, </address> <year> 1988. </year>
Reference: <author> D. Moldovan and S. Harabagiu. </author> <title> Plausible Inference on Extended WordNet. </title> <type> Technical Report 96-CSE-1, </type> <institution> Southern Methodist University, </institution> <year> 1996. </year>
Reference: <author> J. Moore and C. Paris. </author> <title> Planning Text for Advisory Dialogues: Capturing Intentional and Rhetorical Information Technical Report ISI-USC, </title> <institution> University of Southern California, </institution> <year> 1993. </year>
Reference: <author> P. Norvig. </author> <title> Inference in text understanding. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence AAAI-87, </booktitle> <pages> 561-565, </pages> <year> 1987. </year>
Reference: <author> R.J. Passonneau. </author> <title> Integrating Gricean and Attentional Constraints. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI-95, </booktitle> <pages> 1267-1373, </pages> <year> 1995. </year>
References-found: 15

