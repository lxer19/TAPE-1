URL: http://www.cs.tamu.edu/people/ninan/TR98011.ps
Refering-URL: http://www.cs.tamu.edu/people/ninan/
Root-URL: http://www.cs.tamu.edu
Email: E-mail: ninan, pirvum, bhuyan@cs.tamu.edu  
Title: Circular Buffered Switch Design with Wormhole Routing and Virtual Channels  
Author: Nan Ni, Marius Pirvu and Laxmi Bhuyan 
Address: College Station, TX 77845  
Affiliation: Department of Computer Science Texas A&M University  
Abstract: Switch design for interconnection networks plays an important role in the overall performance of multiprocessors and computer networks. In this paper, we discuss design alternatives for switch architectures with input queueing. A new switch design, namely FC-CB, is proposed that offers low average message latency and high throughput over a wide range of input workloads. The FC-CB switch incorporates wormhole routing and virtual channels with a full crossbar connection. Its structure is based on a novel circular buffer design with dynamic allocation. We have performed extensive simulations to compare its performance with other alternatives. Our results show that the proposed design is superior in terms of latency and throughput, especially for heavy input traffic rate and low buffer space. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. N. Bhuyan, H. Wang, R. Iyer, and A. Kumar. </author> <title> Impact of switch design on the application performance of cache-coherent multiprocessors. </title> <booktitle> In Proceedings of the IPPS/SPDP '98, </booktitle> <pages> pages 466-475, </pages> <address> Orlando, FL, </address> <month> March </month> <year> 1998. </year>
Reference-contexts: A virtual channel consists of a buffer that can hold one or more flits and associated state information. By using virtual channels (VCs), buffer allocation is decoupled from the link resources. Therefore, active messages can bypass blocked messages dramatically improving the network throughput. Switches with buffered virtual channels <ref> [1] </ref> exhibit low average message latency. Regarding the second switch design parameter, the buffering technique, we can distinguish between input queueing and output queueing. In input queueing, all the messages in an input buffer come from the same input port, but they can go to different output ports. <p> For example it is known that traffic in shared memory multiprocessors can be very bursty. There are moments when there is no message in the network, but also there are periods of time when the network is flooded with packets <ref> [1] </ref>. Therefore, the study of network behavior at saturation is definitely of practical interest. Effect of input buffer size.
Reference: [2] <author> J. Carbonaro and F. Verhoom. Cavallino: </author> <title> The teraflops router and NIC. </title> <booktitle> In Proceedings of Symposium on High Performance Interconnects, </booktitle> <pages> pages 157-160, </pages> <month> August </month> <year> 1996. </year> <month> 22 </month>
Reference-contexts: Furthermore, our design is better than traditional wormhole routing with virtual channels. Its use of dynamic buffer allocation results in better utilization of the buffer space, compared to the existing virtual channel switches with fixed size channels <ref> [2, 5] </ref>. We have compared our switch design with both dynamically allocated fully connected switches based on virtual cut-through and traditional wormhole routing switches. Our simulation results show the superiority of our design in terms of both network latency and throughput. <p> For each generated packet its destination is randomly determined. Other default architectural parameters pertinent to our test-bed are presented in Table 1. These parameters have been selected to reflect the current state-of-the-art interconnect. For example, most of the current switches like Spider [5] or Cavallino <ref> [2] </ref> use four virtual channels and have a wire delay comparable with the processor clock cycle while the time needed for arbitration and routing is about four cycles. In our simulations we employ two performance metrics: throughput and message latency.
Reference: [3] <author> W. Dally. </author> <title> Virtual-channel flow control. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2) </volume> <pages> 194-205, </pages> <year> 1992. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. 1 The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> In contrast to virtual cut-through, it is not necessary to allocate a packet sized buffer before accepting each packet. However, should the packet be blocked, it obstructs the entire path. This problem can be solved by multiplexing several virtual channels <ref> [3] </ref> on a physical link. A virtual channel consists of a buffer that can hold one or more flits and associated state information. By using virtual channels (VCs), buffer allocation is decoupled from the link resources. Therefore, active messages can bypass blocked messages dramatically improving the network throughput. <p> If there is still free space, a virtual channel of the receiving link is requested. We have two options in case all virtual channels are busy: 1. Postpone the request for a later time. This is the original concept of virtual channel proposed by Dally <ref> [3] </ref> which restricts the number of packets in a virtual channel to one. However, with a large buffer size to packet size ratio, this option may often lead to a situation where there is still buffer space but no more free virtual channels. <p> The average message latency is in between the cases where all the packets had either 8 or 32 flits. 4.3.2 Comparison with Traditional Virtual Channels The classic virtual channel architecture as defined by Dally <ref> [3] </ref> has statically allocated buffers for each channel. Such a design is currently employed in switches like Spider and Cavallino. In contrast, our switch has a global set of buffers dynamically allocated to virtual channels as needed. However, we do reserve one flit buffer for each virtual channel.
Reference: [4] <author> J. Ding and L. N. Bhuyan. </author> <title> Evaluation of multi-queue buffered multistage interconnection networks under uniform and non-uniform traffic patterns. </title> <journal> International Journal of Systems Science, </journal> <volume> 28(11) </volume> <pages> 1115-1128, </pages> <year> 1997. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. 1 The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> However, the head of line (HOL) problem is inherent in such a design since the first packet in the queue may block the way of others behind it. Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing fully connected input ports <ref> [8, 4, 11] </ref>, and dynamically allocated buffer management [12, 4, 11]. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management [12, 11]. However, a good buffer management and implementation has high impact on performance. <p> Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing fully connected input ports [8, 4, 11], and dynamically allocated buffer management <ref> [12, 4, 11] </ref>. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management [12, 11]. However, a good buffer management and implementation has high impact on performance. <p> A combination of the ideas of SAFC and DAMQ results in a switch which is both fully connected and has shared input queueing space as shown in Figure 1 (d). Such a dynamically allocated fully connected (DAFC) switch was analyzed in <ref> [4] </ref> and its performance was shown to be better than other categories. HIPIQS [11] is an example of such a DAFC switch based on virtual cut-through switching.
Reference: [5] <author> M. Galles. Spider: </author> <title> A high-speed network interconnect. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 34-39, </pages> <month> January/Febrary </month> <year> 1997. </year>
Reference-contexts: Furthermore, our design is better than traditional wormhole routing with virtual channels. Its use of dynamic buffer allocation results in better utilization of the buffer space, compared to the existing virtual channel switches with fixed size channels <ref> [2, 5] </ref>. We have compared our switch design with both dynamically allocated fully connected switches based on virtual cut-through and traditional wormhole routing switches. Our simulation results show the superiority of our design in terms of both network latency and throughput. <p> For each generated packet its destination is randomly determined. Other default architectural parameters pertinent to our test-bed are presented in Table 1. These parameters have been selected to reflect the current state-of-the-art interconnect. For example, most of the current switches like Spider <ref> [5] </ref> or Cavallino [2] use four virtual channels and have a wire delay comparable with the processor clock cycle while the time needed for arbitration and routing is about four cycles. In our simulations we employ two performance metrics: throughput and message latency.
Reference: [6] <author> M. J. Karol, M. G. Hluchyj, and S. P. Morgan. </author> <title> Input versus output queueing on a space-division packet switch. </title> <journal> IEEE Transactions on Communications, </journal> <volume> COM-35(12):1347-1356, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: With output queueing, messages from various input ports are put in the same output buffer as long as they are heading for the same port. Although switches with output queueing have been shown to outperform those with input queueing <ref> [6] </ref>, their higher hardware complexity has restricted their popularity. For this reason, in this paper we concentrate on input queueing. The simplest way to build an input buffer is with a single FIFO queue.
Reference: [7] <author> P. Kermani and L. Kleinrock. </author> <title> Virtual cut-through: a new computer communication switching technique. </title> <journal> Computer Networks, </journal> <volume> 3(4) </volume> <pages> 267-286, </pages> <year> 1979. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. 1 The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> Two main factors differentiate their design: the switching technique, and the buffer management. 1 The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. Virtual cut-through <ref> [7] </ref> is an improvement over packet switching. In packet switching the whole packet is stored in a switch buffer and then forwarded only if sufficient buffer space is available in the next node. The network latency for a packet depends on the length of the packet.
Reference: [8] <author> M. Kumar and J. </author> <title> Jump. Performance enhancement in buffered Delta networks using crossbar switches and multiple links. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 1(1) </volume> <pages> 81-103, </pages> <year> 1984. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. 1 The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> However, the head of line (HOL) problem is inherent in such a design since the first packet in the queue may block the way of others behind it. Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing fully connected input ports <ref> [8, 4, 11] </ref>, and dynamically allocated buffer management [12, 4, 11]. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management [12, 11]. However, a good buffer management and implementation has high impact on performance. <p> These small queues decouple buffer resources from transmission and allow active packets to bypass blocked packets using links that would otherwise be left idle. Kumar and Jump <ref> [8] </ref> proposed a design to overcome the HOL problem. As illustrated in Figure 1 (b), the buffers at each input port are equally divided into separate small queues dedicated to each output port. <p> Channel allocation works on a packet basis and handles the assignment of virtual channels from one switch to the next switch. Our switch architecture provides us with the flexibility that any free virtual channel can be used for any packet regardless of its destination. This is in contrast with <ref> [8] </ref>, [11] and [12], where a packet has to join a specific queue dedicated to an output port. The sending switch is responsible for channel allocation. The output link is determined by the routing algorithm based on the information on buffer availability supplied by the next switch.
Reference: [9] <author> L. Ni and P. McKinley. </author> <title> A survey of wormhole routing techniques in direct networks. </title> <journal> IEEE Computer, </journal> <volume> 26(2) </volume> <pages> 62-76, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: The optimization introduced by virtual cut-through is that the head of the message is not required to wait for the tail before it can start moving to the next switch. However, the entire message/packet has to be buffered at an intermediate node in case of blocking. In wormhole routing <ref> [9] </ref>, a packet is divided into a number of flits. The flits of a packet follow the same path from source to destination. They can be transmitted over the network in a pipelined fashion and the packet length has less impact on the message latency.
Reference: [10] <author> J. Park, B. O'Krafka, S. Vassiliadis, and J. Kelgado-Frias. </author> <title> Design and evaluation of a DAMQ multiprocessor network with self-compacting buffers. </title> <booktitle> In IEEE Supercomputing '94, The Conference on High Performance Computing and Communications, </booktitle> <pages> pages 713-722, </pages> <month> Nov.14-18 </month> <year> 1994. </year>
Reference-contexts: Third, the dynamic buffer allocation is based on a linked list scheme, originally proposed in [12]. It has been shown in <ref> [10] </ref> that control circuits with less hardware complexity can be designed by using self-compacting buffers instead of linked lists. To overcome the first problem, we introduce wormhole routing into the design depicted in Figure 1 (d). <p> In the case of light workload, it performs at least as good as HIPIQS. The other major change we suggest is the avoidance of the linked list scheme used in HIPIQS. The work reported in <ref> [10] </ref> improved the hardware complexity by using a self-compacting buffer. We further reduce the complexity by proposing a circular buffer scheme for dynamic allocation of space. We show that our switch architecture improves performance compared to HIPIQS. <p> The head register of a list points to the first slot in the queue while the tail register points to the last slot. For each slot, a pointer is needed to indicate the position of the next slot belonging to the queue. Self-compacting buffer management. According to <ref> [10] </ref>, a self-compacting buffer has less overhead compared to the linked list approach. The basic idea is to keep the slots belonging to the same queue together and in the order of the flit sequence. The regions occupied by different queues follow one another. <p> We think that the equations above are simple and therefore the complexity of implementation is low. 3.2.3 Advantages of the Circular Buffer over Previous Schemes Park et al. <ref> [10] </ref> showed that a self-compacting buffer has less hardware overhead when compared to a linked list approach. Our circular buffer further reduces the hardware complexity of the self-compacting buffer. The ring structure permits us to shift the slots in just one direction instead of two in [10]. <p> Schemes Park et al. <ref> [10] </ref> showed that a self-compacting buffer has less hardware overhead when compared to a linked list approach. Our circular buffer further reduces the hardware complexity of the self-compacting buffer. The ring structure permits us to shift the slots in just one direction instead of two in [10]. Moreover, we do not need any comparators to decide which flits must shift. The main disadvantage of the self-compacting buffer is that only one flit is read-out at a time. Conceptually, the design can be modified to allow more flits to be read-out.
Reference: [11] <author> R. Sivaram, C. B. Stunkel, and D. K. Panda. HIPIQS: </author> <title> a High-performance switch architecture using input queueing. </title> <booktitle> In Proceedings of the IPPS/SPDP '98, </booktitle> <pages> pages 134-143, </pages> <address> Orlando, FL, </address> <month> March </month> <year> 1998. </year>
Reference-contexts: The architecture is based on a novel circular buffer design with reduced hardware complexity. A plethora of switch architectures have been described in the literature <ref> [7, 3, 8, 4, 11] </ref>. Two main factors differentiate their design: the switching technique, and the buffer management. 1 The switching technique determines the way a message is transmitted over the network. In this paper we consider two well known switching techniques: virtual cut-through and wormhole-routing. <p> However, the head of line (HOL) problem is inherent in such a design since the first packet in the queue may block the way of others behind it. Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing fully connected input ports <ref> [8, 4, 11] </ref>, and dynamically allocated buffer management [12, 4, 11]. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management [12, 11]. However, a good buffer management and implementation has high impact on performance. <p> Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing fully connected input ports [8, 4, 11], and dynamically allocated buffer management <ref> [12, 4, 11] </ref>. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management [12, 11]. However, a good buffer management and implementation has high impact on performance. <p> On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management <ref> [12, 11] </ref>. However, a good buffer management and implementation has high impact on performance. Most of the research in this area, and in particular all the related work mentioned above, has been confined to using packet switching or virtual cut-through switching. <p> Such a dynamically allocated fully connected (DAFC) switch was analyzed in [4] and its performance was shown to be better than other categories. HIPIQS <ref> [11] </ref> is an example of such a DAFC switch based on virtual cut-through switching. It always performs better than the DAMQ switch because it allows multiple packets to be read-out from one input port and almost always outperforms SAFC due to the better utilization of the buffer space. <p> We introduce the new switch architecture in Section 3 and demonstrate its superiority in Section 4. 3 Switch with Fully Connected Circular Buffer (FC CB) The new switch architecture we propose here is called FC-CB and strengthens HIPIQS <ref> [11] </ref> by the use of wormhole routing and virtual channels. A common pool of buffers is dynamically allocated to the virtual channels according to the message needs. Flits from different virtual channels of the same input port can be simultaneously sent to their output links. <p> We first present an overview of existing buffer allocation schemes, then introduce our approach and lastly compare our design with the existing schemes. 8 3.2.1 Existing Buffer Allocation Schemes Linked list buffer management. In <ref> [11] </ref> and [12] the shared buffers are implemented using linked lists. This approach usually keeps (k+1) lists: one for each small queue and one for the free space. Shared buffers are maintained in different units of size chosen by the designers. <p> Shared buffers are maintained in different units of size chosen by the designers. For example, a "slot" consisting of 8 bytes is used in [12] and a "chunk" of k flits is adopted in <ref> [11] </ref>. In this paper we refer to this unit size as slot. The head register of a list points to the first slot in the queue while the tail register points to the last slot. <p> This is due to the fact that the circular structure allows us to eliminate the compacting requirement. We mentioned previously the reserved slot per virtual channel in our design. A positive side effect of this reservation is the following. To facilitate cut-through, HIPIQS <ref> [11] </ref> needs a separate circuit which includes an input register and an extra input to the crossbar. In our case the preserved slot can serve the purpose of the input register in HIPIQS and no additional input to the crossbar is necessary. <p> Our switch architecture provides us with the flexibility that any free virtual channel can be used for any packet regardless of its destination. This is in contrast with [8], <ref> [11] </ref> and [12], where a packet has to join a specific queue dedicated to an output port. The sending switch is responsible for channel allocation. The output link is determined by the routing algorithm based on the information on buffer availability supplied by the next switch. <p> Once it starts, the message keeps the physical link occupied until the tail flit has passed. A good example of the VCT category is the HIPIQS switch <ref> [11] </ref>. SWR is an improvement over VCT because a worm can move as soon as there is at least one slot available in the input buffer.
Reference: [12] <author> Y. Tamir and G. L. Frazier. </author> <title> Dynamically-allocated multi-queue buffers for VLSI communication switches. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 41(2) </volume> <pages> 725-737, </pages> <month> June </month> <year> 1992. </year> <month> 23 </month>
Reference-contexts: Newer switch designs, have significantly improved performance compared to the FIFO queue by introducing fully connected input ports [8, 4, 11], and dynamically allocated buffer management <ref> [12, 4, 11] </ref>. On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management [12, 11]. However, a good buffer management and implementation has high impact on performance. <p> On the other hand, the performance benefits come at the expense of increased hardware complexity, as in the linked list buffer management <ref> [12, 11] </ref>. However, a good buffer management and implementation has high impact on performance. Most of the research in this area, and in particular all the related work mentioned above, has been confined to using packet switching or virtual cut-through switching. <p> Therefore, each input port has four read ports and four write ports and the entire switch needs four 4 fi 1 crossbars. A switch with such a feature is called fully connected. This type of design is referred to as SAFC (Statically Allocated Fully Connected) <ref> [12] </ref>, with "static" meaning that the size of the small queue is fixed. Nevertheless, there is still one important disadvantage. The buffer for one small queue can be full while all the other small queues of the same input port can be empty. <p> In this way, we can achieve better buffer utilization. Such a design is illustrated in Figure 1 (c). Each input port has one write port to the 4 fi 4 crossbar. Tamir and Frazier <ref> [12] </ref> presented a detailed design for such a DAMQ (Dynamically Allocated Multi-Queue) switch and demonstrated its performance improvement over SAFC. <p> Third, the dynamic buffer allocation is based on a linked list scheme, originally proposed in <ref> [12] </ref>. It has been shown in [10] that control circuits with less hardware complexity can be designed by using self-compacting buffers instead of linked lists. To overcome the first problem, we introduce wormhole routing into the design depicted in Figure 1 (d). <p> We first present an overview of existing buffer allocation schemes, then introduce our approach and lastly compare our design with the existing schemes. 8 3.2.1 Existing Buffer Allocation Schemes Linked list buffer management. In [11] and <ref> [12] </ref> the shared buffers are implemented using linked lists. This approach usually keeps (k+1) lists: one for each small queue and one for the free space. Shared buffers are maintained in different units of size chosen by the designers. For example, a "slot" consisting of 8 bytes is used in [12] <p> <ref> [12] </ref> the shared buffers are implemented using linked lists. This approach usually keeps (k+1) lists: one for each small queue and one for the free space. Shared buffers are maintained in different units of size chosen by the designers. For example, a "slot" consisting of 8 bytes is used in [12] and a "chunk" of k flits is adopted in [11]. In this paper we refer to this unit size as slot. The head register of a list points to the first slot in the queue while the tail register points to the last slot. <p> Our switch architecture provides us with the flexibility that any free virtual channel can be used for any packet regardless of its destination. This is in contrast with [8], [11] and <ref> [12] </ref>, where a packet has to join a specific queue dedicated to an output port. The sending switch is responsible for channel allocation. The output link is determined by the routing algorithm based on the information on buffer availability supplied by the next switch.
References-found: 12

