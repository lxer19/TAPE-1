URL: http://www.isi.edu/dasher/new/infospace-tools.ps
Refering-URL: http://www.isi.edu/dasher/new/doc.html
Root-URL: http://www.isi.edu
Email: zhu,will-@isi.edu  
Title: Collaborative Information Space Analysis Tools  
Author: Robert Neches, Fangqi Hu, In-Young Ko, Ke-Thia Yao, Quan Zhu, Peter Will -rneches, fhu, iko, kyao, 
Keyword: collaborative information analysis, integrated usage of services, electronic commerce  
Address: Marina del Rey, CA 90292  
Affiliation: University of Southern California Information Sciences Institute  
Abstract: The DASHER Project at USC/ISI has focused upon helping organizations with rapid-response mission requirements. Such organizations need to be able to quickly stand up tiger teams backed by the information, materiel, and support services they need to do their job. To do so, they need to find and assess sources of those services who are potential participants in the tiger team. To support this very initial phase of team development, the project has developed information analysis tools that help make sense of sets of data sources in an intranet or internet: characterizing them, partitioning them, sorting and filtering them. These tools focus on three key issues in forming a collaborative team: helping individuals responsible for forming the team to understand what is available, helping them structure and categorize on the information available to them in a manner specifically suited to the task at hand, and helping them understand the mappings between their organization of the information and those used by others who might participate. DASHERs Information Space Analysis Tools are unique in combining multiple methods to assist in this task. This makes the suite particularly wellsuited to integrating additional technologies in order to create specialized systems. 
Abstract-found: 1
Intro-found: 1
Reference: [Ashish and Knoblock, 1997] <author> N. Ashish and C. Knoblock, </author> <title> "Semi-automatic Wrapper Generation for Internet information sources," </title> <booktitle> Proc. Cooperative Information Systems, </booktitle> <year> 1997. </year>
Reference-contexts: However, we do not use the induction technique to make our Web wrapper to handle different result-page structures from different search engines. Instead, we use simple heuristics similar to the token identification methods described in <ref> [Ashish and Knoblock, 1997] </ref>. To improve the efficiency, we make use of the parallelism in the Web wrapper by using multiple threads in Java. Our multi-threaded Web wrapper can access several Web pages at the same time and improve the data retrieval speed.
Reference: [Cohen, 1995] <author> William W. Cohen, </author> <title> "Fast effective rule induction," </title> <booktitle> Machine Learning: Proceedings of the Twelfth International Conference, </booktitle> <address> Lake Taho, CA, </address> <year> 1995. </year>
Reference-contexts: These rules can then be used either to find similar documents or to categorize unseen documents. The word-based rules can be generated automatically using machine learning rule-induction algorithms, such Ripper <ref> [Cohen, 1995] </ref> and Swap-1 [Weiss and Indurkhya, 1993]. All induction learning algorithms require a set of training examples. In this case each example is a set of words labeled with the appropriate category. The extraction tools described in Section 3 can be used to obtain categories and documents.
Reference: [Frakes and Baeza-Yates] <author> William B. Frakes and Ricardo Baeza-Yates, </author> <title> Information Retrieval: Data Structure & Algorithms, </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1992. </year>
Reference-contexts: Stemming should allow the induction algorithms to generate a more compact set of rules, because words used in each rule have greater coverage. To perform these document-level preprocessing we are using a set of algorithms found in the book Information Retrieval: Data structures & Algorithms <ref> [Frakes and Baeza-Yates, 1992] </ref>. The rule-induction algorithms generate word-based rules of the form: If word 1 word 2 word n fi category i . If a document contains word 1 , through word n , then the document belongs in category i .
Reference: [Kushmerick et al., 1997] <author> N. Kushmerick, D.S. Weld, and R. Doorenbos, </author> <title> "Wrapper induction for information extraction," </title> <booktitle> International Joint Conference on Artificial Intelligence(IJCAI), </booktitle> <address> Nagoya, Japan, </address> <year> 1997. </year>
Reference-contexts: We built a Web Wrapper to extract the tuples for category and Web site information from search-result pages of the COTS Web search engines. Our extraction algorithm is based on the HBELRT (Head-Beginning-End-Left-Right-Tail) approach described in <ref> [Kushmerick et al., 1997] </ref>. However, we do not use the induction technique to make our Web wrapper to handle different result-page structures from different search engines. Instead, we use simple heuristics similar to the token identification methods described in [Ashish and Knoblock, 1997].
Reference: [LookSmart] <institution> LookSmart [http://www.looksmart.com/] </institution>
Reference: [Ron Weiss, 1996] <author> Ron Weiss, David Gifford et al, "HyPursuit: </author> <title> A Hierarchical Network Search Engine that Exploits Content-Link Hypertext Clustering", </title> <booktitle> Proceedings of the Seventh ACM Conference on Hypertext, </booktitle> <address> March 1996, Washington, DC </address>
Reference: [Sergey Brin and Lawrence Page, 1998] <author> Sergey Brin and Lawrence Page, </author> <title> "The Anatomy of a Large-Scale Hypertextual Web Search Engine", </title> <booktitle> to appear in Proceedings of the 7 th International WWW Conference, </booktitle> <address> April 14 18, Brisbane, Australia. </address>
Reference: [Quan Zhu et al, 1997] <author> Quan Zhu et al, </author> <title> "Searching for Parts and Services on the Web", </title> <booktitle> Proceedings of International Symposium on Research, Development, and Practice in Digital Libraries, </booktitle> <address> Nov. 18 21, 1997, Tsukuba, Japan. </address>
Reference: [Weiss and Indurkhya, 1993] <author> S. Weiss and N. Indurkhya, </author> <title> "Optimized rule induction," </title> <journal> IEEE Expert 8, </journal> <volume> 6, </volume> <pages> 61-69. </pages>
Reference-contexts: These rules can then be used either to find similar documents or to categorize unseen documents. The word-based rules can be generated automatically using machine learning rule-induction algorithms, such Ripper [Cohen, 1995] and Swap-1 <ref> [Weiss and Indurkhya, 1993] </ref>. All induction learning algorithms require a set of training examples. In this case each example is a set of words labeled with the appropriate category. The extraction tools described in Section 3 can be used to obtain categories and documents.
Reference: [Yahoo] <institution> Yahoo [http://www.yahoo.com/] </institution>
References-found: 10

