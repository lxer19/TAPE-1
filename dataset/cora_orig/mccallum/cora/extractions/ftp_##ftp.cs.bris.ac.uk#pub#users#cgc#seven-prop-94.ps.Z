URL: ftp://ftp.cs.bris.ac.uk/pub/users/cgc/seven-prop-94.ps.Z
Refering-URL: http://www.cs.bris.ac.uk/~cgc/papers.ml.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: cgc@axon.cs.byu.edu, martinez@cs.byu.edu  
Title: SEVEN DESIRABLE PROPERTIES FOR ARTIFICIAL LEARNING SYSTEMS  
Author: Christophe Giraud-Carrier and Tony Martinez 
Note: dealing with a greater variety of interesting problems.  
Address: Provo, UT 84602  
Affiliation: Brigham Young University, Department of Computer Science,  
Abstract: We propose seven desirable properties for artificial learning systems, namely: incrementality, non-monotonicity, inconsistency and conflicting defaults handling, abstraction, self-organization, generalization, and computational tractability. This proposed set of properties is not claimed to be complete, nor does it imply that all properties must necessarily be present in all learning models. Rather, it focuses on issues that are not often explicitly addressed and provides a basic foundation for the design of more efficient algorithms. As most other computer-based systems, learning systems are difficult to reverse engineer, and desirable properties should be part of the original design rather than retrofitted into the system after the fact. Much effort has been devoted to understanding learning and reasoning in artificial intelligence, giving rise to a wide collection of models. For the most part, these models focus on some observed characteristic of human learning, such as induction or analogy, in an effort to emulate (and possibly exceed) human abilities. We propose seven desirable properties for artificial learning systems: incrementality, non-monotonicity, inconsistency and conflicting defaults handling, abstraction, self-organization, generalization, and computational tractability. We examine each of these properties in turn and show how their (combined) use can improve learning and reasoning, as well as potentially widen the range of applications of artificial learning systems. An overview of the algorithm PDL2, that begins to integrate the above properties, is given as a proof of concept. In the following sections, we examine each property in turn and show how their use can improve learning and reasoning, and potentially widen the range of applications of artificial learning systems. As a proof of concept, the algorithm PDL2 [5] is overviewed. PDL2 begins to integrate the above properties into a unified framework in which inductive learning supplements the use of prior knowledge to yield a model capable of 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brewka, G. </author> <title> Nonmonotonic Reasoning: Logical Foundations of Commonsense. </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: Such a combination may prove useful in commonsense reasoning. In particular, it allows the system to retain the self-adaptivity inherent in human learning, while not having to unnecessarily suffer from poor or atypical learning environments. Such patterns of reasoning, often equated with commonsense reasoning by logicians (see, for example <ref> [1, 6] </ref>), are pervasive in the way humans deal with the inherent uncertainty and incompleteness of the world (or their representation thereof). The development of systems that effectively handle classical commonsense protocols, such as inheritance, is a first step in overcoming the brittleness bottleneck. Non-monotonicity results from incrementality.
Reference: [2] <author> Elman, J.L. </author> <title> Incremental learning, or The importance of starting small. </title> <type> CRL Technical Report 9101, </type> <institution> La Jolla, CA: University of California, San Diego, Center for Research in Language, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Unless the teacher is another machine, such an assumption seems to go against the long term goal of building artificial systems capable of learning. Moreover, in the context of learning grammar with a recurrent network, Elman <ref> [2] </ref> also gives empirical evidence that the "network fails to learn the task when the entire data set is presented all at once, but succeeds when the data are presented incrementally." derivable from any superset of A. <p> For example, as shown in [4], it is common that humans first get exposed to general rules and then to exceptions. Elman <ref> [2] </ref> suggests that the same form of incrementality may actually be the result of an early handicap (e.g., limited memory and attention span characteristic of children). In other words, it may be that the learning system itself evolves over time, rather than the knowledge it is presented.
Reference: [3] <author> Forguson, L. </author> <title> Common Sense. </title> <publisher> Routledge, </publisher> <year> 1989. </year>
Reference-contexts: We would also suggest, from a more psychological standpoint, that the ability to self-organize constitutes a first step in the direction of self-awareness and metarepresentational ability, which appear to be prerequisites to common sense (see <ref> [3] </ref>). Indeed, self-organization presupposes that the system knows that it knows something. This awareness may in turn be exploited to represent knowledge about knowledge.
Reference: [4] <author> Giraud-Carrier, C., and Martinez, T.R. </author> <title> Using Precepts to Augment Training Set Learning. </title> <booktitle> In Proceedings of the 1993 International Conference on Artificial Neural Networks and Expert Systems (ANNES'93), </booktitle> <year> 1993, </year> <pages> 46-51. </pages>
Reference-contexts: Because of built-in mechanisms (e.g., pain) and social structures (e.g., the family, school), humans are able to combine both specific examples and more general rules to efficiently learn complex problems. For example, as shown in <ref> [4] </ref>, it is common that humans first get exposed to general rules and then to exceptions. Elman [2] suggests that the same form of incrementality may actually be the result of an early handicap (e.g., limited memory and attention span characteristic of children). <p> In either case, the ability to use rules and examples increases learning speed by pruning and constraining the search in the input space, reduces memory requirements, and improves overall predictive accuracy (see, for example <ref> [4] </ref>). Moreover, with appropriate generalization mechanisms, examples can effectively supplement rules given a priori by generating new rules, and modifying existing ones. Hence, the system combines the intensional approach (based on features, expressed by rules) and the extensional approach (based on instances, expressed by examples). <p> In an iterated training set approach for example, this implies that convergence on the training set is not as important an issue as is predictive accuracy on the test set. Any viable mechanism should exhibit good generalization performance. Incrementality may improve such performance (see, for example <ref> [4] </ref>). Predictive accuracy is intimately related to the generalization language, since that language also determines the generality of the generated concepts. PDL2 handles non-monotonicity naturally. Its execution mode implements default reasoning, where the defaults are the precepts.
References-found: 4

