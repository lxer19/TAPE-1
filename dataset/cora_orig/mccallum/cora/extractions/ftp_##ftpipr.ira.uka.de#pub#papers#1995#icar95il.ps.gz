URL: ftp://ftpipr.ira.uka.de/pub/papers/1995/icar95il.ps.gz
Refering-URL: ftp://ftpipr.ira.uka.de/.public_html/papersna.html
Root-URL: 
Title: Interactive Environment Modeling and Vision-Based Task Specification for a Teleoperated Mobile Robot  
Author: Lin, I.S. Perret flfl J., Wallner, F Dillmann, R. 
Keyword: Key Words. Telerobotics, Environment Modeling, Man-Machine Systems, Task Specification  
Address: Kaiserstrae 12, D-76128 Karlsruhe, Germany  LAAS/CNRS, 7 avenue du Colonel Roche, 31077 Toulouse Cedex, France  
Affiliation: Institute for Real-Time Computer Systems Robotics, University of Karlsruhe,  flfl  
Note: In: 7 th International Conference on Advanced Robotics (ICAR '95), Sant Feliu de Guixols, Spain  
Email: e-mail: lin@ira.uka.de  
Phone: phone: +49 721 608-4059; fax: +49 721 606740;  
Abstract: phone: +33 61.33.64.51; fax: +33 61.33.64.55; e-mail: jerome@laas.fr Abstract. To enable a mobile robot to perform intervention or service tasks in a remote environment, the robot should be able to learn the unknown world and execute high level task commands from the operator. In this paper an interactive modeling of man-made environment from a single camera is presented. In this model the geometrical, topological and semantic information are integrated in a hierarchical structure. Vision-based interactive task specification is proposed to allow the operator to specify a task and the behavior associated with it directly on the visual interface. The underlying planner works on the interactively created world model and maps the specification to a suitable sequence of actions. With such schemes a teleoperation system can extend its task to object level, which is essential in the application of the service or intervention robot.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. M. Angle and R. A. Brooks. </author> <title> Small Planetary Rovers. </title> <booktitle> In Proceedings of the IEEE International Workshop on Intelligent Robots and Systems (IROS'90), </booktitle> <address> Tsuchiura, Japan, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: The input strategy has changed accordingly, from continuous control of joint positions to end-effector cartesian space to inference of intention and symbolic task description [10]. However, these developments have been mostly devoted to manipulation tasks, and, but for a few nearly-autonomous experimental platforms <ref> [1, 2] </ref>, most mobile teleoperated robots are still based on simple control strategies.
Reference: [2] <author> R. Chatila, R. Alami, S. Lacroix, J. Perret, and C. </author> <title> Proust. Planet Exploration by Robots: From Mission Planning to Autonomous Navigation. </title> <booktitle> In Proceedings of the ICAR'93, </booktitle> <year> 1993. </year>
Reference-contexts: The input strategy has changed accordingly, from continuous control of joint positions to end-effector cartesian space to inference of intention and symbolic task description [10]. However, these developments have been mostly devoted to manipulation tasks, and, but for a few nearly-autonomous experimental platforms <ref> [1, 2] </ref>, most mobile teleoperated robots are still based on simple control strategies. <p> In deed, mobile robots have a much larger operational space than manipulators, so that the issue of environment modeling becomes crucial. 4.1 Vision-Based Task Specification Traditionally the task specification for mobile robot is either off-line created <ref> [2] </ref> or through the graphical user interface (GUI) [8]. [7] proposes a land-vehicle that is guided by a supervising operator from video feedback. In this paper we extend this approach and combine the task specification and monitoring in the single visual interface.
Reference: [3] <editor> R. Dillmann, J. Kreuzinger, and F. Wallner. </editor> <booktitle> The Control Architecture of the Mobile System PRIAMOS. In Proc. of the 1st IFAC International Workshop on Intelligent Autonomous Vehicles, </booktitle> <year> 1993. </year>
Reference-contexts: On the other hand it provides a model for an autonomous system to plan and execute a task. The created world model is closely related to the layered architecture of many mobile robots <ref> [3] </ref>. In such architecture a task will be successively decomposed into subtasks. The representation of the world is accordingly refined, as seen from the topology.
Reference: [4] <author> P. Even and L. Marce. </author> <booktitle> Manned Geometry Modelling for Computer Aided Teleoperation. In Proc. Int. Symposium Teleoperation and Control, </booktitle> <pages> pages 113-122, </pages> <year> 1988. </year>
Reference-contexts: The second part deals with our interactive environ ment modeling interface, which enables the operator to define the structure of the world in the sensory space of the robot. Unlike previous approaches, like <ref> [4] </ref>, we do not limit the model to purely geometric primitives, but propose a hierarchical structure including topological and semantic information. In the third part, we address the problem of high-level task specification based on the environment model. <p> The basic principle is to benefit from the human interpretation capacities in order to extract relevant information out of the robot's sensor readings. Such a system has already been proposed by <ref> [4] </ref> and used in industrial applications, for example in subsea servicing of off-shore installations. However, the previous implementations concentrated on the geometrical aspects of the environment, and thus constituted but a bad compromise.
Reference: [5] <author> R. Fournier, P. Gravez, and M. Dupont. </author> <title> Computer Aided Teleoperation of the Centaure Remote Controlled Mobile Robot. </title> <booktitle> In Proc. Int. Symposium Teleoperation and Control, </booktitle> <pages> pages 97-105, </pages> <year> 1988. </year>
Reference-contexts: In a first part, we describe our telerobotic system and give examples of the use of shared control applied to our mobile robot PRIAMOS [12, 9], which can be seen as an extension of the system presented in <ref> [5] </ref>. The second part deals with our interactive environ ment modeling interface, which enables the operator to define the structure of the world in the sensory space of the robot.
Reference: [6] <author> J. Funda. Teleprogramming: </author> <title> Towards Delay-Invariant Remote Manipulation. </title> <type> Technical report, </type> <institution> GRASP Laboratory, University of Pennsylvania, </institution> <address> Philadelphia, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: This framework offers a simple solution to the operation of mobile robots in an unknown but structured environment, and under small time-delay. It was shown by Paul and Funda <ref> [6] </ref> in the case of a manipulator that the transmission of sensor-based actions is liable to overcome communication delays. At the expense of the environment modeling time, of course, but the time and safety gained soon outranks standard teleoperation schemes.
Reference: [7] <author> Jennifer Kay and Charles Thorpe. STRIPE: </author> <title> Supervised Telerobotics Using Incremental Polygonal Earth Geometry. </title> <booktitle> In Proceedings of the 3rd International Conference on Intelligent Autonomous System, </booktitle> <pages> pages 399-405, </pages> <year> 1993. </year>
Reference-contexts: Unlike previous approaches, like [4], we do not limit the model to purely geometric primitives, but propose a hierarchical structure including topological and semantic information. In the third part, we address the problem of high-level task specification based on the environment model. In <ref> [7] </ref>, Kay and Thorpe propose a trajectory definition scheme based on polygonal earth geometry, which can be used in real-time but relies on a very clear structure of the world (a road). <p> In deed, mobile robots have a much larger operational space than manipulators, so that the issue of environment modeling becomes crucial. 4.1 Vision-Based Task Specification Traditionally the task specification for mobile robot is either off-line created [2] or through the graphical user interface (GUI) [8]. <ref> [7] </ref> proposes a land-vehicle that is guided by a supervising operator from video feedback. In this paper we extend this approach and combine the task specification and monitoring in the single visual interface. In addition to specifying a sequence of movements as in [7], the task specifications are object-oriented and directly <p> through the graphical user interface (GUI) [8]. <ref> [7] </ref> proposes a land-vehicle that is guided by a supervising operator from video feedback. In this paper we extend this approach and combine the task specification and monitoring in the single visual interface. In addition to specifying a sequence of movements as in [7], the task specifications are object-oriented and directly on the visual interface. In a common teleoperation system GUI is extensively used to facilitate the off-line task analysis and on-line visualization [8]. Task analysis presumes a known world model, which is not always available.
Reference: [8] <author> Won S. Kim. </author> <title> Graphic Operator Interface for Space Telerotics. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 761-768, </pages> <year> 1993. </year>
Reference-contexts: In deed, mobile robots have a much larger operational space than manipulators, so that the issue of environment modeling becomes crucial. 4.1 Vision-Based Task Specification Traditionally the task specification for mobile robot is either off-line created [2] or through the graphical user interface (GUI) <ref> [8] </ref>. [7] proposes a land-vehicle that is guided by a supervising operator from video feedback. In this paper we extend this approach and combine the task specification and monitoring in the single visual interface. <p> In addition to specifying a sequence of movements as in [7], the task specifications are object-oriented and directly on the visual interface. In a common teleoperation system GUI is extensively used to facilitate the off-line task analysis and on-line visualization <ref> [8] </ref>. Task analysis presumes a known world model, which is not always available. In the on-line visualization the real sensor data (e.g. odom-etry, ultrasonic sensors) are visualized on the workstation. However such visualization is not proper for a mobile robot, because the slip in wheels makes the odometry unreliable.
Reference: [9] <author> I-S. Lin, F. Wallner, and R. Dillmann. </author> <title> An Advanced Telerobotic Control System for a Mobile Robot with Mul-tisensor Feedback. </title> <booktitle> In Proceedings of the International Conference on Intelligent Autonomous Systems (IAS-4), </booktitle> <address> Karlsruhe, Germany, </address> <year> 1995. </year>
Reference-contexts: We concentrate here on the aspects of advanced teleoperation schemes applied to mobile platforms, interactive environment modeling, and task specification. In a first part, we describe our telerobotic system and give examples of the use of shared control applied to our mobile robot PRIAMOS <ref> [12, 9] </ref>, which can be seen as an extension of the system presented in [5]. The second part deals with our interactive environ ment modeling interface, which enables the operator to define the structure of the world in the sensory space of the robot. <p> On the other hand the telecontrol of mobile robot implies velocity control instead of position control. The time delay causes proportional positional error under constant velocity. To overcome these problems the presented advanced teleoperation system adopts the shared autonomy scheme <ref> [9] </ref>. Fig. 1 gives an overview of the configuration of the system. The global system consists of two subsystems, the local operator control and monitoring station and the remote mobile robot control system. At the local site an operator is continuously receiving video images of the remote environment.
Reference: [10] <author> Thomas B. Sheridan. Telerobotics, </author> <title> Automation, and Human Supervisory Control. </title> <publisher> The MIT Press, </publisher> <address> Lon-don,England, </address> <year> 1992. </year>
Reference-contexts: It has entered the area of telerobotics, characterized by the introduction of supervision and decision processes at the remote site, both relieving the operator from burdensome tasks and improving efficiency <ref> [10] </ref>. However, little work has concentrated on mobile robots, so that most industrial products still rely on the old teleoperation paradigm. <p> Telerobotics and telepresence have broadened the range of available man-machine interface supports, like six-degrees-of-freedom mice, datagloves and all kinds of exoskeletons. The input strategy has changed accordingly, from continuous control of joint positions to end-effector cartesian space to inference of intention and symbolic task description <ref> [10] </ref>. However, these developments have been mostly devoted to manipulation tasks, and, but for a few nearly-autonomous experimental platforms [1, 2], most mobile teleoperated robots are still based on simple control strategies.
Reference: [11] <author> Roger Y. Tsai. </author> <title> A Versitile Camera Calibration Technique for High-accuracy 3D Machine Vision Metrology Using Off-the-shelf TV Cameras and Lenses. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3, </volume> <year> 1987. </year>
Reference-contexts: In this paper we use a two-stage calibration approach to find the relation between image and world. The first stage is an off-line intrinsic calibration, which is independent of the environment and is performed with the help of Tsai's algorithm <ref> [11] </ref> and a calibration object [12]. Fig. 3 illustrates the calibration object and the extracted circles. the 16 extracted circles The second stage is to find the extrinsic parameters, i.e. the translation and orientation of camera w.r.t. the world.
Reference: [12] <author> P. Weckesser and G. Hetzel. </author> <title> Photogrammetric Calibration Methods for an Active Stereo Vision System. </title> <booktitle> In Intelligent Robot System, </booktitle> <pages> pages 430-436, </pages> <year> 1994. </year>
Reference-contexts: We concentrate here on the aspects of advanced teleoperation schemes applied to mobile platforms, interactive environment modeling, and task specification. In a first part, we describe our telerobotic system and give examples of the use of shared control applied to our mobile robot PRIAMOS <ref> [12, 9] </ref>, which can be seen as an extension of the system presented in [5]. The second part deals with our interactive environ ment modeling interface, which enables the operator to define the structure of the world in the sensory space of the robot. <p> In this paper we use a two-stage calibration approach to find the relation between image and world. The first stage is an off-line intrinsic calibration, which is independent of the environment and is performed with the help of Tsai's algorithm [11] and a calibration object <ref> [12] </ref>. Fig. 3 illustrates the calibration object and the extracted circles. the 16 extracted circles The second stage is to find the extrinsic parameters, i.e. the translation and orientation of camera w.r.t. the world.
References-found: 12

