URL: http://www-acaps.cs.mcgill.ca/~ghiya/ftp/thesis.ps.gz
Refering-URL: http://www.csd.uu.se/~thomasl/wpo/alias-papers.html
Root-URL: 
Title: PUTTING POINTER ANALYSIS TO WORK  
Author: by Rakesh Ghiya 
Degree: a thesis submitted to the Faculty of Graduate Studies and Research in partial fulfillment of the requirements for the degree of Doctor of Philosophy  
Note: Copyright c 1998 by Rakesh Ghiya  
Date: May 1998  
Address: Montreal  
Affiliation: School of Computer Science McGill University,  
Abstract-found: 0
Intro-found: 1
Reference: [ABS94] <author> Todd M. Austin, Scott E. Breach, and Gurindar S. Sohi. </author> <title> Efficient detection of all pointer and array access errors. </title> <booktitle> In Proceedings of the ACM SIGPLAN '94 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 290-301, </pages> <address> Orlando, Florida, </address> <month> June 20-24, </month> <year> 1994. </year> <journal> SIGPLAN Notices, </journal> <volume> 29(6), </volume> <month> June </month> <year> 1994. </year>
Reference-contexts: and Lists eigen Eigenvalue Computation Dynamic Arrays Table 3.2: Benchmark Descriptions 3.5 Empirical Evaluation of the Analyses We have evaluated the efficiency of our analyses with respect to a set of 16 pointer-intensive C benchmark programs, drawn from the SPEC92, SPLASH-2 [WOT + 95], Olden [RCRH95], Irvine [HHN94] and Wisconsin <ref> [ABS94] </ref> benchmark suites. A brief description of the benchmarks is provided in Table 3.2. The table also summarizes the principal data structures used by the benchmarks. In Table 3.3 we provide the analysis times measured on an UltraSparc machine in seconds.
Reference: [And94] <author> L. O. Andersen. </author> <title> Program Analysis and Specialization for the C Programming Language. </title> <type> PhD thesis, </type> <institution> University of Copenhagen, </institution> <month> May </month> <year> 1994. </year> <type> DIKU report 94/19. </type>
Reference-contexts: Two types are merged (unified) during analysis, when a potential assignment is seen between program variables represented by them. Shapiro and Horwitz [SH97b] compare Steensgaard's algorithm with that of An-dersen <ref> [And94] </ref>. In contrast to Steensgaard, Andersen's algorithm represents each program variable with one type variable, and allows one type variable to point to several type variables. It also has cubic time complexity.
Reference: [APC + 96] <author> Joel Auslander, Matthai Philipose, Craig Chambers, Susan J. Eggers, and Brian N. Bershad. </author> <title> Fast, effective dynamic compilation. </title> <booktitle> In Proceedings of the ACM SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 149-159, </pages> <address> Philadelphia, Pennsylvania, </address> <month> May 22-24, </month> <year> 1996. </year> <journal> SIGPLAN Notices, </journal> <volume> 31(6), </volume> <month> June </month> <year> 1996. </year>
Reference-contexts: Reducing communication overhead and exposing more parallelism for par allel EARTH-C [HTZ + 96] programs (section 4.3); 23 3. Providing improved input to array dependence testers [GH98] (section 4.4); 4. Providing summary information that is useful for program understanding [GH98], dynamic compilation <ref> [APC + 96] </ref> and prefetching of pointer data structures [LM96] (section 4.6). Implementations and Empirical studies: We have implemented our techniques in the McCAT C compiler, and we present empirical data to illustrate the costs and benefits of the techniques (chapter 4). <p> We discuss the applications below. 4.6.1 Detecting Run-Time Constants Dynamic compilation is currently an active area of research, with its main focus on using run-time constant information to generate more efficient code. Auslander et al. <ref> [APC + 96] </ref> mention several applications where heap data structures can be run-time constants (interpreters, simulators, graphic renderers etc.). However, they rely on programmer annotation to specify which variables/data structures to consider as run-time constants.
Reference: [ASU88] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers | Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, corrected edition, </address> <year> 1988. </year>
Reference-contexts: Alternatively the statement itself can be moved out if the following additional constraints are satisfied <ref> [ASU88] </ref>: (i) lhs is a scalar variable, say x, (ii) this variable x is not assigned by any other statement in the loop, (iii) no use of x in the loop is reached by a definition of x other than at S, and (iv) definition of x at S does not <p> We have implemented the common subexpression elimination (CSE) algorithm from <ref> [ASU88] </ref>. It is global in scope, i.e., is applied over a function, and is based on first collecting available expressions.
Reference: [Ban79] <author> J. P. Banning. </author> <title> An efficient way to find the side effects of procedure calls and the aliases of variables. </title> <booktitle> In Proceedings of the 6th ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1979. </year>
Reference-contexts: Effective techniques for computing such aliases have been developed and described <ref> [Bar78, Ban79, Mye81, Coo85, CK89] </ref>. Most of these analyses collect the alias information in two passes over the program: (i) an introductory pass to compute all the obvious aliases generated at call-sites, (ii) a propagation pass to propagate the aliases through the call-graph of the program. <p> First, we consider methods that use the results of pointer analyses that are designed primarily for stack-directed pointers, and give conservative results for heap-directed pointers. Banning gave one of the seminal methods for computing side effects in the presence of aliases that arise due to call-by-reference <ref> [Ban79] </ref>. More recent algorithms based on alias analysis, for languages with explicit pointers, have been presented by Landi et. al [LRZ93] and Choi et. al [CBC93].
Reference: [Ban88] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer, </publisher> <year> 1988. </year>
Reference-contexts: For example, the array references a [i+2*j] and a [j+2*i], the pointer dereferences *q and *p, and the structure accesses p-&gt;item and q-&gt;next->item, can lead to the same memory location. Over the past twenty years, powerful data dependence analyses have been developed to resolve the problem of array aliases <ref> [Ban88, Wol89, ZC90] </ref>. These analyses use integer programming techniques to determine if two array subscript expressions can evaluate to the same value. They form the core of present day optimizing/parallelizing compilers.
Reference: [Bar78] <author> J. Barth. </author> <title> A practical interprocedural data flow analysis algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 21 </volume> <pages> 724-736, </pages> <year> 1978. </year> <month> 172 </month>
Reference-contexts: Effective techniques for computing such aliases have been developed and described <ref> [Bar78, Ban79, Mye81, Coo85, CK89] </ref>. Most of these analyses collect the alias information in two passes over the program: (i) an introductory pass to compute all the obvious aliases generated at call-sites, (ii) a propagation pass to propagate the aliases through the call-graph of the program.
Reference: [BGSP94] <author> U. Bruening, W. K. Giloi, and W. Schroeder-Preikschat. </author> <title> Latency hiding in message-passing architectures. </title> <booktitle> In Proceedings of the 8th International Parallel Processing Symposium, </booktitle> <pages> pages 704-709, </pages> <address> Cancun, Mexico, April 26-29, 1994. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: The detailed results are presented in [TGHG97]. Here we briefly discuss the main points. The EARTH-MANNA architecture emulator runs on top of the MANNA parallel machine <ref> [BGSP94] </ref>, which consists of multiple nodes connected by an interconnection network. It supports a distributed shared memory model. Each node (consisting of two processors) has its own local memory, and the aggregate of the local memories of all the nodes represents a global memory address space.
Reference: [Bri92] <author> Preston Briggs. </author> <title> Register Allocation via Graph Coloring. </title> <type> PhD thesis, </type> <institution> Rice University, Houston, Texas, </institution> <month> April </month> <year> 1992. </year> <note> Published as Rice COMP TR92-183. </note>
Reference-contexts: Thus CSE cannot be applied to the expression x * i, as statement U can potentially update both x and i between S and V. For similar reasons, the expression x * y cannot be considered loop-invariant. Another side-effect of the above conservative assumption impacts register allocation. Register allocation <ref> [Bri92] </ref> is an important program optimization that assigns frequently used variables to registers, instead of loading/storing their values from memory on each access. This is significant because for modern microprocessors, register accesses are an order of magnitude faster than memory accesses.
Reference: [CBC93] <author> J. Choi, M. Burke, and P. Carini. </author> <title> Efficient flow-sensitive interprocedural computation of pointer-induced aliases and side-effects. </title> <booktitle> In Proceedings of the ACM 20th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 232-245, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: They form the core of present day optimizing/parallelizing compilers. The problem of calculating pointer-induced aliases, termed pointer analysis, has also received significant attention from the research community over the past few years <ref> [LR92, CBC93, EGH94, WL95, Ruf95, Ste96, ZRL96, SH97b] </ref>. This emphasis has mainly stemmed from the increasing popularity of languages supporting pointers such as C, C++ and Fortran90. <p> The naming schemes proposed are as simple as using one name, heap, to represent all heap objects [EGH94]. More precise schemes name objects using their allocation site [LR92], or allocation site prepended with the procedure string representing the given calling context <ref> [CBC93, WL95] </ref>. 3 For the code fragment in Figure 1.1, the first naming scheme gives the points-to pairs (r, heap) and (s, heap). Using allocation sites instead, would give the pairs (r, malloc_U), (s, malloc V). <p> It is not designed to accurately handle heap-allocated recursive data structures. In some special cases it can help detect completely unaliased data structures (lists and trees) built by a program, but neither empirical nor theoretical evidence is available to draw any general conclusions. Choi, Burke and Carini <ref> [CBC93] </ref> presented another algorithm for flow-sensitive alias analysis. They compute aliases as pairs of access paths. Their access paths are similar to object names [LR92]. However, they do not use access paths to name heap objects. <p> Other approaches discussed above only use one name to represent aggregate structures like arrays and structures. They name heap objects in the same fashion as <ref> [CBC93] </ref>: allocation site qualified with a procedure string. All the techniques presented above handle procedure calls in a context-sensitive manner i.e. the effect of a procedure call is estimated specific to a calling context, and not just summarized for all possible calling contexts. <p> They use different strategies to abstract calling contexts: assumed alias sets [LR92], last call site and source alias sets <ref> [CBC93] </ref>, invocation graphs [EGH94], and partial transfer functions [WL95]. In addition, Emami et. al [EGH94] precisely handle indirect calls through function pointers in C. Wilson and Lam follow their strategy for handling function pointers. Ruf [Ruf95] compared a context-insensitive alias analysis with a context-sensitive 7 analysis. <p> Banning gave one of the seminal methods for computing side effects in the presence of aliases that arise due to call-by-reference [Ban79]. More recent algorithms based on alias analysis, for languages with explicit pointers, have been presented by Landi et. al [LRZ93] and Choi et. al <ref> [CBC93] </ref>.
Reference: [CC77] <author> P. Cousot and R. Cousot. </author> <title> Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fix-points. </title> <booktitle> In Proceedings of the 4th ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1977. </year>
Reference-contexts: They then define a retrieval function to finitely represent the relationships between tokens and data values. The definition of the retrieval function is based on the simulation of program statements, using abstract interpretation <ref> [CC77] </ref>. The analysis framework is parameterized by the choice of token sets. Thus a wide range of analyses can be expressed 9 in this framework. However, this method has remained mostly of theoretical interest, being expensive in both space and time. <p> They maintain a set of storage graphs at each program point, unlike a single alias graph [LH88]. This makes their analysis more precise, but also more expensive. They use abstract interpretation <ref> [CC77] </ref> augmented with an instrumented semantics, to prove the correctness of their technique. However, it is unclear how effective it would prove to be in practice. Another approach to abstracting the heap structure in the form of a bounded graph was given by Chase, Wegman and Zadeck [CWZ90].
Reference: [CCK90] <author> David Callahan, Steve Carr, and Ken Kennedy. </author> <title> Improving register allocation for subscripted variables. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 53-65, </pages> <address> White Plains, New York, </address> <month> June 20-22, </month> <year> 1990. </year> <journal> SIGPLAN Notices, </journal> <volume> 25(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: A location invariant access can also be replaced by a scalar access, under some constraints. This optimization is similar in spirit to the scalar replacement technique proposed for array references <ref> [CCK90] </ref>. Consider the loop in Figure 4.4 (a). In this loop the heap access r-&gt;i is location invariant as the origin pointer r is not written inside the loop.
Reference: [CK89] <author> Keith D. Cooper and Ken Kennedy. </author> <title> Fast interprocedural alias analysis. </title> <booktitle> In Conference Record of the Sixteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 49-59, </pages> <address> Austin, Texas, </address> <month> January 11-13, </month> <year> 1989. </year> <journal> ACM SIGACT and SIGPLAN. </journal>
Reference-contexts: Effective techniques for computing such aliases have been developed and described <ref> [Bar78, Ban79, Mye81, Coo85, CK89] </ref>. Most of these analyses collect the alias information in two passes over the program: (i) an introductory pass to compute all the obvious aliases generated at call-sites, (ii) a propagation pass to propagate the aliases through the call-graph of the program.
Reference: [CL97] <author> Keith D. Cooper and John Lu. </author> <title> Register promotion in C programs. </title> <booktitle> In Proceedings of the ACM SIGPLAN '97 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 308-319, </pages> <address> Las Vegas, Nevada, </address> <month> June 15-18, </month> <year> 1997. </year> <journal> SIGPLAN Notices, </journal> <volume> 32(6), </volume> <month> June </month> <year> 1997. </year>
Reference-contexts: We assume that other compilers with points-to analyses have similar applications. In terms of using the improved read/write sets from pointer analysis, for other analyses and transformations, the most relevant related work is of Wilson and Lam [WL95], Shapiro and Horwitz [SH97a] and Cooper and Lu <ref> [CL97] </ref>. Wilson and Lam used pointer analysis results for loop parallelization in the context of two numeric C benchmarks, alvinn and specear (Table 3.2).
Reference: [Coo85] <author> Keith D. Cooper. </author> <title> Analyzing aliases of reference formal parameters. </title> <booktitle> In Conference Record of the Twelfth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 281-290, </pages> <address> New Orleans, Louisiana, </address> <month> January 13-16, </month> <year> 1985. </year> <journal> ACM SIGACT and SIGPLAN. </journal> <volume> 173 </volume>
Reference-contexts: Effective techniques for computing such aliases have been developed and described <ref> [Bar78, Ban79, Mye81, Coo85, CK89] </ref>. Most of these analyses collect the alias information in two passes over the program: (i) an introductory pass to compute all the obvious aliases generated at call-sites, (ii) a propagation pass to propagate the aliases through the call-graph of the program.
Reference: [Cou86] <author> D. Coutant. </author> <title> Retargetable high-level alias analysis. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 110-118, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: Early work on pointer aliasing includes: (i) a flow-insensitive algorithm from Weihl [Wei80] which turned out to be very imprecise in practice [Lan92b], (ii) an approach proposed by Chow and Rudmik [CR82] for their CHILL compiling system, which handles only single-level pointers, and (iii) a study by Coutant <ref> [Cou86] </ref> of Weihl's algorithm, which suggested the use of pragmas for collecting more accurate information. Landi and Ryder [LR92] designed and implemented one of the first flow-sensitive interprocedural alias analysis algorithms for C programs. They collect alias information in the form of pairs of object names.
Reference: [CR82] <author> Anita L. Chow and Andres Rudmik. </author> <title> The design of a data flow analyzer. </title> <booktitle> In Proceedings of the SIGPLAN '82 Symposium on Compiler Construction, </booktitle> <pages> pages 106-113, </pages> <address> Boston, Massachusetts, </address> <month> June 23-25, </month> <year> 1982. </year> <journal> ACM SIGPLAN. SIGPLAN Notices, </journal> <volume> 17(6), </volume> <month> June </month> <year> 1982. </year>
Reference-contexts: Early work on pointer aliasing includes: (i) a flow-insensitive algorithm from Weihl [Wei80] which turned out to be very imprecise in practice [Lan92b], (ii) an approach proposed by Chow and Rudmik <ref> [CR82] </ref> for their CHILL compiling system, which handles only single-level pointers, and (iii) a study by Coutant [Cou86] of Weihl's algorithm, which suggested the use of pragmas for collecting more accurate information.
Reference: [CWZ90] <author> D. R. Chase, M. Wegman, and F. K. Zadek. </author> <title> Analysis of pointers and structures. </title> <booktitle> In Proceedings of the SIGPLAN `90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310, </pages> <year> 1990. </year>
Reference-contexts: However, it is unclear how effective it would prove to be in practice. Another approach to abstracting the heap structure in the form of a bounded graph was given by Chase, Wegman and Zadeck <ref> [CWZ90] </ref>. Their abstraction, called storage shape graph (SSG), contains one node for each variable and one for each allocation site in the program. <p> For example, it would give highly imprecise results, if the program uses a single routine for allocating nodes (authors suggest the use of function inlining to overcome this.). Further, the meet operation is fairly complex. Plevyak, Chien and Karamcheti [PCK94] have extended the model of Chase et al. <ref> [CWZ90] </ref> to handle regular cyclic structures like doubly linked lists and trees with parent pointers, more precisely. They introduce additional nodes called choice nodes, to represent that two given links coming into a summary node would not exist at the same time. <p> Further, their analysis needs empirical verification, though they give some examples in the paper. Recently, Sagiv et. al [SRW96] have presented a new approach to estimate the shape properties of heap data structures. They also abstract the heap as a storage shape graph <ref> [CWZ90] </ref>. However, their graph contains nodes only for heap locations pointed to by program variables (i.e. stack-resident heap-directed pointers). The rest of the heap locations are represented by one summary node. <p> Further, nodes in the graph are sometimes labeled to facilitate conflict detection between 12 statements [LH88, HPR89]. Procedure calls are either not handled [JM81, HPR89, PCK94, SRW96] or are analyzed with different degrees of precision <ref> [JM82, LH88, CWZ90] </ref>. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. To avoid this trap, Hendren and Nicolau [HN90] took a different approach. <p> speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures <ref> [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96] </ref>. These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers [HN90]. <p> These analyses either explicitly estimate the structure of heap as a storage shape graph <ref> [CWZ90] </ref>, or compute some abstract relationships between heap-directed pointers [HN90]. More directly related to this chapter are methods that use the results of heap pointer analysis in the context of dependence analysis and parallelization.
Reference: [Deu90] <author> A. Deutsch. </author> <title> On determining lifetime and aliasing of dynamically allocated data in higher-order functional specifications. </title> <booktitle> In Proceedings of the ACM 17th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 157-168, </pages> <year> 1990. </year>
Reference-contexts: Thus, graph types can only describe data structures with a spanning tree backbone. A large body of work on analysis of heap-allocated objects, has focused on other problems like reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Deu90, WH92] </ref>. 1.3 Pointer Analysis in the McCAT C Compiler All the techniques we have discussed so far, either focus on stack analysis with a conservative approximation of the heap, or present sophisticated heap analyses considered in isolation from stack analysis (assuming stack-directed pointers do not exist). 15
Reference: [Deu92] <author> A. Deutsch. </author> <title> A storeless model of aliasing and its abstractions using finite representations of right-regular equivalence relations. </title> <booktitle> In Proceedings of the IEEE 1992 International Conference on Computer Languages, </booktitle> <pages> pages 2-13, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Using allocation sites instead, would give the pairs (r, malloc_U), (s, malloc V). However, treating the heap as a set of static named locations can lead to significant imprecision, as one name can represent several heap objects which may be completely unrelated <ref> [Deu92] </ref>. Another approach in this regard has been to develop special storeless heap analyses which provide more accurate information. In contrast to store-based techniques like points-to analysis, which try to identify potential targets of a given pointer, storeless models are designed to compute abstract relationships between heap-directed pointers themselves. <p> Their method is precise and effective for trees and to some extent for DAGs. However, it cannot handle cyclic structures, which are commonly used in programs, like doubly-linked lists and trees with parent pointers. Deutsch <ref> [Deu92, Deu94] </ref> calculates aliases in the form of pairs of symbolic access paths. This abstraction is particularly suited to recursive data structure analysis.
Reference: [Deu94] <author> A. Deutsch. </author> <title> Interprocedural may-alias analysis for pointers: Beyond k-limiting. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 230-241, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Their method is precise and effective for trees and to some extent for DAGs. However, it cannot handle cyclic structures, which are commonly used in programs, like doubly-linked lists and trees with parent pointers. Deutsch <ref> [Deu92, Deu94] </ref> calculates aliases in the form of pairs of symbolic access paths. This abstraction is particularly suited to recursive data structure analysis. <p> speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures <ref> [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96] </ref>. These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers [HN90].
Reference: [EGH94] <author> Maryam Emami, Rakesh Ghiya, and Laurie J. Hendren. </author> <title> Context-sensitive interprocedural points-to analysis in the presence of function pointers. </title> <booktitle> In Proceedings of the ACM SIGPLAN '94 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 242-256, </pages> <address> Orlando, Florida, </address> <month> June 20-24, </month> <year> 1994. </year> <journal> SIGPLAN Notices, </journal> <volume> 29(6), </volume> <month> June </month> <year> 1994. </year>
Reference-contexts: They form the core of present day optimizing/parallelizing compilers. The problem of calculating pointer-induced aliases, termed pointer analysis, has also received significant attention from the research community over the past few years <ref> [LR92, CBC93, EGH94, WL95, Ruf95, Ste96, ZRL96, SH97b] </ref>. This emphasis has mainly stemmed from the increasing popularity of languages supporting pointers such as C, C++ and Fortran90. <p> For example in Figure 1.1, we have points-to pairs (p, x) and (q, y) denoting that pointer variable p points to the data object x and pointer variable q points to the data object y. This approach was initially proposed by Emami et. al <ref> [EGH94] </ref> and is used by most of the recent pointer analysis algorithms [Ruf95, WL95, Ste96, SH97b]. Unfortunately this nice property does not hold for heap-allocated data items. In fact all the objects in the heap are anonymous. <p> The first approach has been to associate heap objects with some set of static names, and use the same framework for heap analysis as for stack analysis. The naming schemes proposed are as simple as using one name, heap, to represent all heap objects <ref> [EGH94] </ref>. More precise schemes name objects using their allocation site [LR92], or allocation site prepended with the procedure string representing the given calling context [CBC93, WL95]. 3 For the code fragment in Figure 1.1, the first naming scheme gives the points-to pairs (r, heap) and (s, heap). <p> They mention that they combine this naming scheme with k-limiting to analyze recursive structures. It is not clear from their paper, what type of k-limiting they perform [MLR + 93]. They also propose the idea of transitive reduction of alias pairs into points-to pairs. Emami, Ghiya and Hendren <ref> [EGH94] </ref> proposed the approach of decoupling stack and heap analyses. They focus on analysis of stack-directed pointers, and collect alias information in the form of points-to relationships. <p> They use different strategies to abstract calling contexts: assumed alias sets [LR92], last call site and source alias sets [CBC93], invocation graphs <ref> [EGH94] </ref>, and partial transfer functions [WL95]. In addition, Emami et. al [EGH94] precisely handle indirect calls through function pointers in C. Wilson and Lam follow their strategy for handling function pointers. Ruf [Ruf95] compared a context-insensitive alias analysis with a context-sensitive 7 analysis. <p> They use different strategies to abstract calling contexts: assumed alias sets [LR92], last call site and source alias sets [CBC93], invocation graphs <ref> [EGH94] </ref>, and partial transfer functions [WL95]. In addition, Emami et. al [EGH94] precisely handle indirect calls through function pointers in C. Wilson and Lam follow their strategy for handling function pointers. Ruf [Ruf95] compared a context-insensitive alias analysis with a context-sensitive 7 analysis. He reported that for his benchmark suite the latter provides more accurate information in general. <p> This framework decouples stack and heap analyses, instead of solving the two problems using the same abstraction. First points-to analysis <ref> [EGH94] </ref> is used for accurately estimating stack pointer relationships, approximating all heap locations as a single symbolic location heap. On the subset of pointers reported to be pointing to heap, two storeless heap analyses are applied: connection analysis [GH96a] and shape analysis [GH96b]. <p> This is denoted by the triple (x,y,P). The complete description of points-to analysis can be found in [Ema93] and an overview in <ref> [EGH94] </ref>. We demonstrate it on an example program, in Figure 2.5. 30 Part (a) of the figure shows the original program, while part (b) shows the simplified program decorated with program-point-specific points-to information. Note that all heap-directed pointers are reported to be possibly pointing to the abstract stack location heap. <p> To support this analysis strategy, it builds a framework for interprocedural analysis. Other context-sensitive interprocedural analyses like heap analyses, are built on top of this framework. A complete description of the framework can be found in <ref> [Ema93, HEGV93, EGH94] </ref>. Below, we briefly describe its salient features. 2.4.1 Representing Calling Contexts In general, a calling context depends on the invocation path followed by the program, i.e., the chain of procedure invocations starting from main and ending with the procedure call under analysis. <p> Future iterations do not modify the points-to set of fp, and thus the points-to analysis constructs the complete invocation graph for other interprocedural analyses. The complete algorithm for resolving function pointers can be found in <ref> [Ghi92, EGH94] </ref>. <p> if (listA == NULL) return; p = copyList (listA); t = p; while (listA-&gt;next != NULL) - listA-&gt;next-&gt;index = t-&gt;index; t = t-&gt;next; list = list-&gt;next; - S: p = copyList (listB); /* Memory Leak */ T: t = p; /* Memory Leak Warning */ ... 117 any points-to analysis <ref> [EGH94, WL95, Ruf95, Ste96] </ref>, where all locations have names is quite straight-forward and only slight modifications of standard transformations are needed as shown in section 2.5. We assume that other compilers with points-to analyses have similar applications. <p> For analyzing heap-directed pointers, we proposed using storeless analyses, as locations in the heap are inherently anonymous and do not have natural compile-time names. Following this approach, we used the family of pointer analyses implemented in the McCAT compiler: store-based points-to analysis <ref> [EGH94] </ref> for stack-directed pointers, and two storeless heap analyses, connection analysis [GH96a] and shape analysis [GH96b] for heap-directed pointers. We used these analyses to study the applications and benefits of pointer analysis.
Reference: [EH94] <author> A. M. Erosa and L. J. Hendren. </author> <title> Taming control flow: A structured approach to eliminating goto statements. </title> <booktitle> In Proceedings of IEEE 1994 International Conference on Computer Languages, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: In addition, the return statement is supported for exiting a procedure, and break and continue statements are supported for exiting a loop. Since the unrestricted use of goto is not compositional, the compiler provides a structuring phase that eliminates all goto statements from a C program <ref> [Ero94, EH94] </ref>. With a compositional representation, structured analysis techniques can be used to analyze all control constructs. For example, a while loop can be analyzed by considering only its components: the conditional expression and the body.
Reference: [Ema93] <author> M. Emami. </author> <title> A practical interprocedural alias analysis for an optimizing/parallelizing compiler. </title> <type> Master's thesis, </type> <institution> School of Computer Science, McGill University, </institution> <month> September </month> <year> 1993. </year> <month> 174 </month>
Reference-contexts: This is denoted by the triple (x,y,P). The complete description of points-to analysis can be found in <ref> [Ema93] </ref> and an overview in [EGH94]. We demonstrate it on an example program, in Figure 2.5. 30 Part (a) of the figure shows the original program, while part (b) shows the simplified program decorated with program-point-specific points-to information. <p> To support this analysis strategy, it builds a framework for interprocedural analysis. Other context-sensitive interprocedural analyses like heap analyses, are built on top of this framework. A complete description of the framework can be found in <ref> [Ema93, HEGV93, EGH94] </ref>. Below, we briefly describe its salient features. 2.4.1 Representing Calling Contexts In general, a calling context depends on the invocation path followed by the program, i.e., the chain of procedure invocations starting from main and ending with the procedure call under analysis. <p> This association of invisible variables with symbolic names is recorded in the invocation graph nodes as map information. Figure 2.10 (b) shows the map information for various procedure calls. Complete details of the mapping process can be found in <ref> [Ema93] </ref>. The map information is context-sensitive as can be seen from the different mappings for the two calls to procedure incr in Figure 2.10 (b). The symbolic names are independent of the context. <p> This information is obtained from points-to analysis information and stack read/write sets. Subsequently, these functions are excluded from the search space of connection analysis, enabling it to analyze a sparser program. The memoization optimization was initially proposed in <ref> [Ema93] </ref>. The goal of this optimization is to reduce the number of times a function is analyzed. Under context-sensitive schemes, a function is re-analyzed for each of its invocation contexts. With memoization, the input/output analysis information for each visit to the function is recorded.
Reference: [Ero94] <author> A. M. Erosa. </author> <title> A goto-elimination method and its implementation for the McCAT C compiler. </title> <type> Master's thesis, </type> <institution> McGill University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: In addition, the return statement is supported for exiting a procedure, and break and continue statements are supported for exiting a loop. Since the unrestricted use of goto is not compositional, the compiler provides a structuring phase that eliminates all goto statements from a C program <ref> [Ero94, EH94] </ref>. With a compositional representation, structured analysis techniques can be used to analyze all control constructs. For example, a while loop can be analyzed by considering only its components: the conditional expression and the body.
Reference: [GH95] <author> Rakesh Ghiya and Laurie J. Hendren. </author> <title> Connection analysis: A practical interprocedural heap analysis for C. </title> <booktitle> In Proceedings of the Eight Workshop on Languages and Compilers for Parallel Computing, number 1033 in Lecture Notes in Computer Science, </booktitle> <pages> pages 515-534, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures <ref> [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96] </ref>. These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers [HN90].
Reference: [GH96a] <author> Rakesh Ghiya and Laurie J. Hendren. </author> <title> Connection analysis: A practical interprocedural heap analysis for C. </title> <journal> Intl. J. of Parallel Programming, </journal> <volume> 24(6), </volume> <pages> pages 547-578, </pages> <year> 1996. </year>
Reference-contexts: First points-to analysis [EGH94] is used for accurately estimating stack pointer relationships, approximating all heap locations as a single symbolic location heap. On the subset of pointers reported to be pointing to heap, two storeless heap analyses are applied: connection analysis <ref> [GH96a] </ref> and shape analysis [GH96b]. These heap analyses use simple storeless abstractions that capture boolean relationships between stack-resident heap-directed pointers in the program, computed at each program point. Below, we briefly describe the two analyses and identify their specific application domains: * Connection Analysis [GH96a]: This analysis determines if two heap-directed <p> heap analyses are applied: connection analysis <ref> [GH96a] </ref> and shape analysis [GH96b]. These heap analyses use simple storeless abstractions that capture boolean relationships between stack-resident heap-directed pointers in the program, computed at each program point. Below, we briefly describe the two analyses and identify their specific application domains: * Connection Analysis [GH96a]: This analysis determines if two heap-directed pointers point to the same linked structure (i.e. they are connected) or to disjoint regions in the heap (i.e. they are not connected). It uses a connection matrix abstraction, which is a boolean matrix of heap-directed pointers, to collect connection information. <p> However, McCAT heap analyses capture coarser path relationships, which can be stored as boolean matrices. This enables faster data flow merge operation and substantially reduces the storage requirements for the analyses, while the analyses still gather useful information. Thus the first heap analysis, connection analysis <ref> [GH96a] </ref> only abstracts the information, if two handles point to nodes in the same data structure, using a connection matrix. <p> Stack read/write sets provide a very conservative approximation of the heap. In this chapter we develop techniques for computing sharper heap read/write set information with respect to a heap analysis. We have chosen connection analysis <ref> [GH96a] </ref>, the first analysis in the McCAT hierarchy of storeless heap analyses, for this purpose. Connection analysis was chosen, because it is a relatively simple heap analysis, clearly illustrates the problems in computing read/write sets from a storeless analysis, and yields interesting results when "put to work" properly. <p> The connection relationships shown in Figure 3.1 (b) illustrate this property. It is used in the actual implementation to reduce the storage requirement by half. 3.1.1 Illustrative Examples In this section, we briefly illustrate the rules to compute connection relationships. The complete details can be found in <ref> [Ghi95, GH96a] </ref>. 48 Let us follow the computation of connection relationships for the code segment shown in Figure 3.2 (a). <p> The overall interprocedural framework for connection analysis is similar to that described for points-to analysis in section 2.4. The complete details of the implementation can be found in <ref> [Ghi95, GH96a] </ref>. 52 3.2 Computing Read/Write Sets Based on Con- nection Analysis Our main goal is to identify the set of locations read/written by a given statement or program region. <p> of type q@S next fl= fieldSet = fieldSet [ fieldsAccessed (anchor); =fl include next field fl= return fieldSet; 61 3.4.3 Augmented Connection Analysis for Control Statements Compositional control statements in Simple (for, if, while etc.), are handled by augmented connection analysis, in a fashion similar to the original connection analysis <ref> [Ghi95, GH96a] </ref> (Figure 3.10), with two differences. First, the function augmented-ConnectionAnalyze invokes the augmented versions of connectionAnalyze functions for the constituent statements of the given control statement. Second, heap read/write sets are computed for the control statement as a whole, which is a straightforward process. <p> 0 53 10 0.19 0.16 0.05 blocks2 1149 82 279 9 0.48 1.66 4.30 sim 1845 69 340 6 0.28 1.56 2.60 eigen 296 11 44 2 0.30 0.10 0.05 Table 3.3: Analysis Statistics 71 namely function exclusion and memoization, which significantly reduce the interpro--cedural overhead of the context-sensitive analyses <ref> [GH96a] </ref>. The function exclusion optimization identifies functions in the program, that do not update heap-directed pointers and also do not involve accesses to heap locations. This information is obtained from points-to analysis information and stack read/write sets. <p> speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures <ref> [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96] </ref>. These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers [HN90]. <p> Following this approach, we used the family of pointer analyses implemented in the McCAT compiler: store-based points-to analysis [EGH94] for stack-directed pointers, and two storeless heap analyses, connection analysis <ref> [GH96a] </ref> and shape analysis [GH96b] for heap-directed pointers. We used these analyses to study the applications and benefits of pointer analysis.
Reference: [GH96b] <author> Rakesh Ghiya and Laurie J. Hendren. </author> <title> Is it a tree, a DAG, or a cyclic graph? a shape analysis for heap-directed pointers in C. </title> <booktitle> In Conference Record of the 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 1-15, </pages> <address> St. Petersburg, Florida, </address> <month> January 21-24, </month> <year> 1996. </year>
Reference-contexts: First points-to analysis [EGH94] is used for accurately estimating stack pointer relationships, approximating all heap locations as a single symbolic location heap. On the subset of pointers reported to be pointing to heap, two storeless heap analyses are applied: connection analysis [GH96a] and shape analysis <ref> [GH96b] </ref>. These heap analyses use simple storeless abstractions that capture boolean relationships between stack-resident heap-directed pointers in the program, computed at each program point. <p> This information is useful in disambiguating heap accesses to completely disjoint data structures like dynamically-allocated arrays and other non-recursively defined structures. Scientific applications written in C typically use these constructs. * Shape Analysis <ref> [GH96b] </ref>: This analysis focuses on estimating the shape of the structure accessible from a given pointer: is it tree-like, DAG-like or a general graph containing cycles. It uses three simple abstractions to achieve this goal, which include: 1. <p> Thus the first heap analysis, connection analysis [GH96a] only abstracts the information, if two handles point to nodes in the same data structure, using a connection matrix. The second heap analysis, shape analysis <ref> [GH96b] </ref>, abstracts the boolean information if a path exists from the node pointed by one handle to the node pointed by another handle (as opposed to the actual path expression). <p> This is because connection analysis is designed to disambiguate heap accesses at the data structure level (for efficiency reasons). To do more fine-grain disambiguation, one can use more sophisticated analyses like shape analysis <ref> [GH96b] </ref>, which can distinguish between subpieces of a data structure itself. This is the topic of chapter 5. The following are some other important characteristics of the connection matrix abstraction: * It abstracts relationships only between stack-resident heap-directed pointers. <p> We use points-to based stack read/write sets to detect dependencies due to scalars and stack-directed pointers. To detect dependencies due to heap-directed pointers, we use connection-based heap read/write sets, as well as the information about the "shape" of the data structures obtained from shape analysis <ref> [GH96b] </ref>. For detecting the above parallelism patterns, shape information proves to be the critical component, as the patterns are based on recursive heap data structures. The remainder of this chapter is structured as follows. In section 5.1 we introduce the three parallelism patterns in more detail. <p> Its detailed description can be found in <ref> [GH96b, Ghi95] </ref>. <p> The analysis is performed on the Simple intermediate representation. The implementation is structured as a simple analysis for each basic statement, a compositional rule for each control construct, and a context-sensitive approach for handling procedure calls. Complete details can be found in <ref> [GH96b, Ghi95] </ref>. 5.3 Identifying Parallelism In this section, we briefly review the notion of data dependence [Wol89] between statements, which is at the heart of our algorithms for detecting the three parallelism patterns. <p> speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures <ref> [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96] </ref>. These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers [HN90]. <p> Following this approach, we used the family of pointer analyses implemented in the McCAT compiler: store-based points-to analysis [EGH94] for stack-directed pointers, and two storeless heap analyses, connection analysis [GH96a] and shape analysis <ref> [GH96b] </ref> for heap-directed pointers. We used these analyses to study the applications and benefits of pointer analysis.
Reference: [GH98] <author> Rakesh Ghiya and Laurie J. Hendren. </author> <title> Putting pointer analysis to work. </title> <booktitle> In Conf. Rec. of the 25th Ann. ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Applications based on read/write sets: Based on read/write sets, we demonstrate how to use the information for a wide variety of applications (chapter 4). These applications include: 1. Extending standard scalar compiler transformations, like loop-invariant removal, location-invariant removal, and common subexpression elimination, to include pointers references <ref> [GH98] </ref> (section 4.1); 2. Reducing communication overhead and exposing more parallelism for par allel EARTH-C [HTZ + 96] programs (section 4.3); 23 3. Providing improved input to array dependence testers [GH98] (section 4.4); 4. Providing summary information that is useful for program understanding [GH98], dynamic compilation [APC + 96] and prefetching <p> Extending standard scalar compiler transformations, like loop-invariant removal, location-invariant removal, and common subexpression elimination, to include pointers references <ref> [GH98] </ref> (section 4.1); 2. Reducing communication overhead and exposing more parallelism for par allel EARTH-C [HTZ + 96] programs (section 4.3); 23 3. Providing improved input to array dependence testers [GH98] (section 4.4); 4. Providing summary information that is useful for program understanding [GH98], dynamic compilation [APC + 96] and prefetching of pointer data structures [LM96] (section 4.6). <p> common subexpression elimination, to include pointers references <ref> [GH98] </ref> (section 4.1); 2. Reducing communication overhead and exposing more parallelism for par allel EARTH-C [HTZ + 96] programs (section 4.3); 23 3. Providing improved input to array dependence testers [GH98] (section 4.4); 4. Providing summary information that is useful for program understanding [GH98], dynamic compilation [APC + 96] and prefetching of pointer data structures [LM96] (section 4.6). Implementations and Empirical studies: We have implemented our techniques in the McCAT C compiler, and we present empirical data to illustrate the costs and benefits of the techniques (chapter 4).
Reference: [Ghi92] <author> Rakesh Ghiya. </author> <title> Interprocedural analysis in the presence of function pointers. </title> <type> ACAPS Technical Memo 62, </type> <institution> School of Computer Science, McGill University, </institution> <address> Montreal, Quebec, </address> <month> December </month> <year> 1992. </year> <note> In ftp://ftp-acaps.cs.mcgill.ca/pub/doc/memos. </note>
Reference-contexts: Future iterations do not modify the points-to set of fp, and thus the points-to analysis constructs the complete invocation graph for other interprocedural analyses. The complete algorithm for resolving function pointers can be found in <ref> [Ghi92, EGH94] </ref>.
Reference: [Ghi95] <author> Rakesh Ghiya. </author> <title> Practical techniques for interprocedural heap analysis. </title> <type> Master's thesis, </type> <institution> School of Computer Science, McGill University, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Connection analysis was chosen, because it is a relatively simple heap analysis, clearly illustrates the problems in computing read/write sets from a storeless analysis, and yields interesting results when "put to work" properly. Connection analysis was previously designed and implemented in the McCAT C compiler <ref> [Ghi95] </ref>. Thus, the focus of this chapter is not on connection analysis itself. Rather, its emphasis is on new techniques that augment the existing connection analysis, and enable the accurate computation of heap read/write sets. The rest of this chapter is organized as follows. <p> The connection relationships shown in Figure 3.1 (b) illustrate this property. It is used in the actual implementation to reduce the storage requirement by half. 3.1.1 Illustrative Examples In this section, we briefly illustrate the rules to compute connection relationships. The complete details can be found in <ref> [Ghi95, GH96a] </ref>. 48 Let us follow the computation of connection relationships for the code segment shown in Figure 3.2 (a). <p> The overall interprocedural framework for connection analysis is similar to that described for points-to analysis in section 2.4. The complete details of the implementation can be found in <ref> [Ghi95, GH96a] </ref>. 52 3.2 Computing Read/Write Sets Based on Con- nection Analysis Our main goal is to identify the set of locations read/written by a given statement or program region. <p> of type q@S next fl= fieldSet = fieldSet [ fieldsAccessed (anchor); =fl include next field fl= return fieldSet; 61 3.4.3 Augmented Connection Analysis for Control Statements Compositional control statements in Simple (for, if, while etc.), are handled by augmented connection analysis, in a fashion similar to the original connection analysis <ref> [Ghi95, GH96a] </ref> (Figure 3.10), with two differences. First, the function augmented-ConnectionAnalyze invokes the augmented versions of connectionAnalyze functions for the constituent statements of the given control statement. Second, heap read/write sets are computed for the control statement as a whole, which is a straightforward process. <p> The map process involves generating special symbolic names to represent pointers in caller which are out-of-scope in callee. The association between symbolic variables and the caller variables mapped to them, is recorded as mapInfo. Detailed information about the map process can be found in <ref> [Ghi95] </ref>. 2. Ghost Copy Assignments: Next, ghost copy assignments are performed to anchor all heap-directed formal parameters and global variables at the entry of the callee function. <p> Its detailed description can be found in <ref> [GH96b, Ghi95] </ref>. <p> The analysis is performed on the Simple intermediate representation. The implementation is structured as a simple analysis for each basic statement, a compositional rule for each control construct, and a context-sensitive approach for handling procedure calls. Complete details can be found in <ref> [GH96b, Ghi95] </ref>. 5.3 Identifying Parallelism In this section, we briefly review the notion of data dependence [Wol89] between statements, which is at the heart of our algorithms for detecting the three parallelism patterns.
Reference: [Gua88] <author> V. A. Guarna Jr. </author> <title> A technique for analyzing pointer and structure references in parallel restructuring compilers. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 212-220, </pages> <year> 1988. </year>
Reference-contexts: Other approaches that use the results of pointer analysis have primarily focused on dependence analysis and parallelization <ref> [LH88, Gua88, HPR89, HN90, HHN94] </ref>. <p> More directly related to this chapter are methods that use the results of heap pointer analysis in the context of dependence analysis and parallelization. These approaches include: techniques using path expressions to name locations [LH88], using syntax trees to name locations <ref> [Gua88] </ref>, extending k-limited graphs with location names [HPR89]; and dependence analysis based on shape information and path expressions [HN90] The focus of these techniques is on identifying function-call parallelism for recursive data structures, and the heap analyses used are substantially more complex than our connection and shape analyses.
Reference: [HDE + 93] <author> L. J. Hendren, C. Donawa, M. Emami, G. Gao, Justiani, and B. Srid-haran. </author> <title> Designing the McCAT compiler based on a family of structured intermediate representations. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Fifth International Workshop on Languages and 175 Compilers for Parallel Computing, volume 757 of Lecture Notes in Com--puter Science, </booktitle> <pages> pages 406-420. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: This is the focus of this thesis. In the rest of this chapter, we first illustrate the pointer analysis problem in section 1.1. We discuss related work on this topic in section 1.2. In section 1.3, we present the McCAT <ref> [HDE + 93] </ref> pointer analysis framework that is used in this thesis. In section 1.4, we identify the missing links between pointer analysis and its use for program optimization. <p> far, either focus on stack analysis with a conservative approximation of the heap, or present sophisticated heap analyses considered in isolation from stack analysis (assuming stack-directed pointers do not exist). 15 The work reported in this thesis is built upon the pointer analysis framework implemented in the McCAT C compiler <ref> [HDE + 93] </ref>. This framework decouples stack and heap analyses, instead of solving the two problems using the same abstraction. First points-to analysis [EGH94] is used for accurately estimating stack pointer relationships, approximating all heap locations as a single symbolic location heap. <p> we briefly discuss the heap analyses and review the overall compilation framework, to put our goals in proper perspective. 2.1 The McCAT C Compiler The McCAT C compiler is part of the McGill Compiler Architecture Testbed, being developed to study the interaction between smart compilation techniques and advanced architectural features <ref> [HDE + 93] </ref>. The most important goal in its design was to develop appropriate intermediate representations to facilitate implementation of 25 various compiler analyses and transformations in a simple and straightforward man-ner.
Reference: [HEGV93] <author> L. J. Hendren, M. Emami, R. Ghiya, and C. Verbrugge. </author> <title> A practical context-sensitive interprocedural analysis framework for C compilers. </title> <type> ACAPS Technical Memo 72, </type> <institution> School of Computer Science, McGill University, </institution> <address> Montreal, Quebec, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: To support this analysis strategy, it builds a framework for interprocedural analysis. Other context-sensitive interprocedural analyses like heap analyses, are built on top of this framework. A complete description of the framework can be found in <ref> [Ema93, HEGV93, EGH94] </ref>. Below, we briefly describe its salient features. 2.4.1 Representing Calling Contexts In general, a calling context depends on the invocation path followed by the program, i.e., the chain of procedure invocations starting from main and ending with the procedure call under analysis.
Reference: [Hen90] <author> L. J. Hendren. </author> <title> Parallelizing Programs with Recursive Data Structures. </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <month> April </month> <year> 1990. </year> <type> TR 90-1114. </type>
Reference-contexts: The motivation behind shape analysis is to identify tree and list-like structures in programs in a simple and efficient way. This knowledge can then be gainfully exploited for parallelizing programs <ref> [Lar89, Hen90] </ref>, and performing optimizing transformations like loop unrolling [HG92] and software pipelining [HHN92a]. There is a large body of applications which use trees and lists as principal data structures. It can be noted that these abstractions are practical variations on the path matrix model of Hendren and Nicolau [HN90].
Reference: [HG92] <author> L. J. Hendren and G. R. Gao. </author> <title> Designing programming languages for analyzability: A fresh look at pointer data structures. </title> <booktitle> In Proceedings of the 4th IEEE International Conference on Computer Languages, </booktitle> <month> April </month> <year> 1992. </year>
Reference-contexts: The motivation behind shape analysis is to identify tree and list-like structures in programs in a simple and efficient way. This knowledge can then be gainfully exploited for parallelizing programs [Lar89, Hen90], and performing optimizing transformations like loop unrolling <ref> [HG92] </ref> and software pipelining [HHN92a]. There is a large body of applications which use trees and lists as principal data structures. It can be noted that these abstractions are practical variations on the path matrix model of Hendren and Nicolau [HN90].
Reference: [HHN92a] <author> L. J. Hendren, J. Hummel, and A. Nicolau. </author> <title> Abstractions for recursive pointer data structures: Improving the analysis and transformation of imperative programs. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 249-260, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The effect of a computation must be explicitly associated with a region of memory. The effect system differentiates between totally disjoint linked structures, but fails to distinguish between disjoint subpieces of a data structure. Hendren, Hummel and Nicolau <ref> [HHN92a, HHN92b] </ref> presented a mechanism called ADDS (Abstract Description of Data Structures), to explicitly convey the dimension and direction properties of a data structure, to the compiler. This involves enriching the type definitions of data structures with some semantic information. <p> The motivation behind shape analysis is to identify tree and list-like structures in programs in a simple and efficient way. This knowledge can then be gainfully exploited for parallelizing programs [Lar89, Hen90], and performing optimizing transformations like loop unrolling [HG92] and software pipelining <ref> [HHN92a] </ref>. There is a large body of applications which use trees and lists as principal data structures. It can be noted that these abstractions are practical variations on the path matrix model of Hendren and Nicolau [HN90].
Reference: [HHN92b] <author> J. Hummel, L. J. Hendren, and A. Nicolau. </author> <title> Abstract description of pointer data structures: An approach for improving the analysis and optimization of imperative programs. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(3) </volume> <pages> 243-260, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: The effect of a computation must be explicitly associated with a region of memory. The effect system differentiates between totally disjoint linked structures, but fails to distinguish between disjoint subpieces of a data structure. Hendren, Hummel and Nicolau <ref> [HHN92a, HHN92b] </ref> presented a mechanism called ADDS (Abstract Description of Data Structures), to explicitly convey the dimension and direction properties of a data structure, to the compiler. This involves enriching the type definitions of data structures with some semantic information.
Reference: [HHN94] <author> J. Hummel, L. J. Hendren, and A. Nicolau. </author> <title> A general data dependence test for dynamic, pointer-based data structures. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 218-229, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: They demonstrate that using such information, the compiler can perform useful transformations like software pipelining. Hummel, Hendren and Nicolau <ref> [HHN94] </ref> presented a more formal approach, to convey the alias properties of data structures. <p> Biology Dynamic Arrays and Lists eigen Eigenvalue Computation Dynamic Arrays Table 3.2: Benchmark Descriptions 3.5 Empirical Evaluation of the Analyses We have evaluated the efficiency of our analyses with respect to a set of 16 pointer-intensive C benchmark programs, drawn from the SPEC92, SPLASH-2 [WOT + 95], Olden [RCRH95], Irvine <ref> [HHN94] </ref> and Wisconsin [ABS94] benchmark suites. A brief description of the benchmarks is provided in Table 3.2. The table also summarizes the principal data structures used by the benchmarks. In Table 3.3 we provide the analysis times measured on an UltraSparc machine in seconds. <p> Parts (a) and (b) show loops from the Olden [RCRH95] benchmarks health and power respectively. From both the loops, the compiler pulls out an address calculation required to access arrays embedded inside heap objects. Parts (c) and (d) show loops from the benchmark circuit <ref> [HHN94] </ref>. In part (c) the loop test involves a loop invariant which is pulled out. In part (d) the access (* botRH).row is loop-invariant, but the given statement cannot be moved out of the loop as the left hand side is also a pointer access. <p> Other approaches that use the results of pointer analysis have primarily focused on dependence analysis and parallelization <ref> [LH88, Gua88, HPR89, HN90, HHN94] </ref>. <p> However, this array is embedded inside the list node being visited, so it cannot be shared with other nodes, thus excluding the possibility of LCDs. The benchmark circuit implements a sparse matrix used in circuit simulation <ref> [HHN94] </ref>. The matrix is implemented using doubly linked lists, with nodes having links to nodes in the previous and next rows as well as columns. Again shape information is not useful for this benchmark. <p> Further, they do not consider the detection of loop parallelism. Finally, none of these techniques consider the presence of stack-directed pointers. In contrast to the above techniques which are based on automatic heap analysis, Hummel et al. <ref> [HHN94] </ref> use a language-based approach. They rely on the programmer to provide the information about the shape of the data structure via aliasing axioms. To compute dependence between two statements, they collect access paths with respect to an anchor.
Reference: [HMT + 95] <author> Herbert H. J. Hum, Olivier Maquelin, Kevin B. Theobald, Xinmin Tian, Xinan Tang, Guang R. Gao, Phil Cupryk, Nasser Elmasri, Laurie J. Hen-dren, Alberto Jimenez, Shoba Krishnan, Andres Marquez, Shamir Merali, Shashank S. Nemawarkar, Prakash Panangaden, Xun Xue, and Yingchun Zhu. </author> <title> A design study of the EARTH multiprocessor. </title> <editor> In Lubomir Bic, Wim Bohm, Paraskevas Evripidou, and Jean-Luc Gaudiot, editors, </editor> <booktitle> Proceedings of the IFIP WG 10.3 Working Conference on Parallel Architectures and 176 Compilation Techniques, PACT '95, </booktitle> <pages> pages 59-68, </pages> <address> Limassol, Cyprus, June 27-29, 1995. </address> <publisher> ACM Press. </publisher>
Reference-contexts: All the analyses and transformations are performed at the Simple representation as shown in the figure. The transformed Simple AST can either be directly given as input to the EARTH-C compiler [HTZ + 96], which generates code for the EARTH-MANNA multithreaded architecture <ref> [HMT + 95] </ref>, or dumped back as an optimized C source file which can then be compiled with any native C compiler. Alternatively, the C-dump utility can generate Html or C source files, annotated with the analysis information. <p> for specear achieves better speedup than the Sopt version. 101 4.3 Performance Improvement for EARTH-C Pro- grams The effects of our sharper read/write sets and the scalar optimizations presented above, have also been studied in the context of parallel EARTH-C [HTZ + 96] programs run on the EARTH-MANNA multithreaded architecture <ref> [HMT + 95] </ref>, as shown in Figure 4.11. The detailed results are presented in [TGHG97]. Here we briefly discuss the main points. The EARTH-MANNA architecture emulator runs on top of the MANNA parallel machine [BGSP94], which consists of multiple nodes connected by an interconnection network. <p> The parallel program is obtained by introducing parallel EARTH-C constructs like parallel statement sequences and forall loops in the original C program. The EARTH-C program can then be used as input to the EARTH-McCAT parallelizing compiler for the EARTH-MANNA parallel machine <ref> [HMT + 95] </ref> (Figure 4.11, page number 103). <p> Finally, based on our experience with hand-written Earth-C [HTZ + 96] versions of the benchmarks treeadd and power, the parallelism detected by our dependence tests, respectively provides speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine <ref> [HMT + 95] </ref> using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96].
Reference: [HN90] <author> L. J. Hendren and A. Nicolau. </author> <title> Parallelizing programs with recursive data structures. </title> <journal> IEEE Trans. on Parallel and Distributed Computing, </journal> <volume> 1(1) </volume> <pages> 35-47, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Procedure calls are either not handled [JM81, HPR89, PCK94, SRW96] or are analyzed with different degrees of precision [JM82, LH88, CWZ90]. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. To avoid this trap, Hendren and Nicolau <ref> [HN90] </ref> took a different approach. They focus on abstracting the properties of data structures being built and manipulated, instead of abstracting each cell in the heap. Their main focus is on identifying data structures with regular properties like trees and DAGs. <p> There is a large body of applications which use trees and lists as principal data structures. It can be noted that these abstractions are practical variations on the path matrix model of Hendren and Nicolau <ref> [HN90] </ref>. The differences lie in collecting coarser path information for efficiency reasons, and associating additional attributes with each pointer (e.g. shape attribute). In the McCAT C compiler, these pointer analyses are applied in a hierarchical fashion. <p> ensures that read/write sets for a function call do not contain locations accessed by the callee function in invocation contexts not relevant for the given call. 2.6 Heap Analyses The abstractions for heap analysis, implemented in the McCAT compiler, are variations on the path matrix model of Hendren and Nicolau <ref> [HN90] </ref>. The path matrix approach captures the structure of the heap using an abstraction, orthogonal to the k-limited graphs. It essentially exploits the fact, that though there are potentially infinite number of objects in the heap, they are always accessed using access-paths which originate from stack-resident heap-directed pointers. <p> Other approaches that use the results of pointer analysis have primarily focused on dependence analysis and parallelization <ref> [LH88, Gua88, HPR89, HN90, HHN94] </ref>. <p> speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures <ref> [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96] </ref>. These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers [HN90]. <p> These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers <ref> [HN90] </ref>. More directly related to this chapter are methods that use the results of heap pointer analysis in the context of dependence analysis and parallelization. <p> These approaches include: techniques using path expressions to name locations [LH88], using syntax trees to name locations [Gua88], extending k-limited graphs with location names [HPR89]; and dependence analysis based on shape information and path expressions <ref> [HN90] </ref> The focus of these techniques is on identifying function-call parallelism for recursive data structures, and the heap analyses used are substantially more complex than our connection and shape analyses. Further, they do not consider the detection of loop parallelism.
Reference: [HP96] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Fran-cisco, California, 2nd edition, </address> <year> 1996. </year>
Reference-contexts: The scalar replacement does not save any computation. However, it saves one memory reference per iteration, as the scalar temporary tq can be register-allocated. With the increasing memory-processor performance gap in modern computer systems <ref> [HP96] </ref>, reduction in memory traffic is of critical importance, and can result in substantial performance gains. Besides the LIR and CSE optimizations, we have also implemented a new optimization, which we call location invariant removal (LcIR).
Reference: [HPR89] <author> S. Horwitz, P. Pfeiffer, and T. Reps. </author> <title> Dependence analysis for pointer variables. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 28-40, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: This method works well only for simple data structures like trees and lists. It is rendered expensive by its complex meet, node summary and node labeling operations. Horwitz, Pfeiffer and Reps <ref> [HPR89] </ref> presented another variation on k-limited graphs, called storage graphs which abstract the dynamic store. They present a variety of ways to k-limit the storage graphs. The goal of their analysis is detection of dependences between program statements. <p> They basically differ from each other in the way they choose to bound the graph. Further, nodes in the graph are sometimes labeled to facilitate conflict detection between 12 statements <ref> [LH88, HPR89] </ref>. Procedure calls are either not handled [JM81, HPR89, PCK94, SRW96] or are analyzed with different degrees of precision [JM82, LH88, CWZ90]. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. <p> They basically differ from each other in the way they choose to bound the graph. Further, nodes in the graph are sometimes labeled to facilitate conflict detection between 12 statements [LH88, HPR89]. Procedure calls are either not handled <ref> [JM81, HPR89, PCK94, SRW96] </ref> or are analyzed with different degrees of precision [JM82, LH88, CWZ90]. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. To avoid this trap, Hendren and Nicolau [HN90] took a different approach. <p> Other approaches that use the results of pointer analysis have primarily focused on dependence analysis and parallelization <ref> [LH88, Gua88, HPR89, HN90, HHN94] </ref>. <p> More directly related to this chapter are methods that use the results of heap pointer analysis in the context of dependence analysis and parallelization. These approaches include: techniques using path expressions to name locations [LH88], using syntax trees to name locations [Gua88], extending k-limited graphs with location names <ref> [HPR89] </ref>; and dependence analysis based on shape information and path expressions [HN90] The focus of these techniques is on identifying function-call parallelism for recursive data structures, and the heap analyses used are substantially more complex than our connection and shape analyses.
Reference: [HS90] <author> Ben Heggy and Mary Lou Soffa. </author> <title> Architectural support for register allocation in the presence of aliasing. </title> <booktitle> In Proceedings of Supercomputing 90, </booktitle> <year> 1990. </year>
Reference-contexts: However, it cannot do so due to the potential back-door access problem <ref> [HS90] </ref>. This problem arises when an access to a variable assigned to a register, can go to its memory location instead. We illustrate it below. Suppose the compiler assigns variable x to register regX.
Reference: [HTZ + 96] <author> Laurie J. Hendren, Xinan Tang, Yingchun Zhu, Guang R. Gao, Xun Xue, Haiying Cai, and Pierre Ouellet. </author> <title> Compiling C for the EARTH multi-threaded architecture. </title> <booktitle> In Proceedings of the 1996 Conference on Parallel Architectures and Compilation Techniques (PACT '96), </booktitle> <pages> pages 12-23, </pages> <address> Boston, Massachusetts, </address> <month> October 20-23, </month> <title> 1996. </title> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: These applications include: 1. Extending standard scalar compiler transformations, like loop-invariant removal, location-invariant removal, and common subexpression elimination, to include pointers references [GH98] (section 4.1); 2. Reducing communication overhead and exposing more parallelism for par allel EARTH-C <ref> [HTZ + 96] </ref> programs (section 4.3); 23 3. Providing improved input to array dependence testers [GH98] (section 4.4); 4. Providing summary information that is useful for program understanding [GH98], dynamic compilation [APC + 96] and prefetching of pointer data structures [LM96] (section 4.6). <p> This is necessary in order to have the whole source program available for interpro-cedural analysis. All the analyses and transformations are performed at the Simple representation as shown in the figure. The transformed Simple AST can either be directly given as input to the EARTH-C compiler <ref> [HTZ + 96] </ref>, which generates code for the EARTH-MANNA multithreaded architecture [HMT + 95], or dumped back as an optimized C source file which can then be compiled with any native C compiler. Alternatively, the C-dump utility can generate Html or C source files, annotated with the analysis information. <p> the same instruction and memory reference counts, the Hopt version for specear achieves better speedup than the Sopt version. 101 4.3 Performance Improvement for EARTH-C Pro- grams The effects of our sharper read/write sets and the scalar optimizations presented above, have also been studied in the context of parallel EARTH-C <ref> [HTZ + 96] </ref> programs run on the EARTH-MANNA multithreaded architecture [HMT + 95], as shown in Figure 4.11. The detailed results are presented in [TGHG97]. Here we briefly discuss the main points. <p> The overall goal is to detect these patterns in a sequential C program, and produce an equivalent parallel EARTH-C <ref> [HTZ + 96] </ref> program. The parallel program is obtained by introducing parallel EARTH-C constructs like parallel statement sequences and forall loops in the original C program. <p> A sample foreach loop from this benchmark is shown in Figure 5.28 (d), which also represents the most compute-intensive part of the code. Finally, based on our experience with hand-written Earth-C <ref> [HTZ + 96] </ref> versions of the benchmarks treeadd and power, the parallelism detected by our dependence tests, respectively provides speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in
Reference: [Hud86] <author> P. Hudak. </author> <title> A semantic model of reference counting and its abstraction. </title> <booktitle> In Proceedings of the 1986 ACM Conference on LISP and Functional Programming, </booktitle> <year> 1986. </year>
Reference-contexts: Thus, graph types can only describe data structures with a spanning tree backbone. A large body of work on analysis of heap-allocated objects, has focused on other problems like reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Deu90, WH92] </ref>. 1.3 Pointer Analysis in the McCAT C Compiler All the techniques we have discussed so far, either focus on stack analysis with a conservative approximation of the heap, or present sophisticated heap analyses considered in isolation from stack analysis (assuming stack-directed pointers do not exist). 15
Reference: [ISY88] <author> K. Inoue, H. Seki, and H. Yagi. </author> <title> Analysis of functional programs to detect run-time garbage cells. </title> <journal> ACM TOPLAS, </journal> <volume> 10(4) </volume> <pages> 555-578, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Thus, graph types can only describe data structures with a spanning tree backbone. A large body of work on analysis of heap-allocated objects, has focused on other problems like reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Deu90, WH92] </ref>. 1.3 Pointer Analysis in the McCAT C Compiler All the techniques we have discussed so far, either focus on stack analysis with a conservative approximation of the heap, or present sophisticated heap analyses considered in isolation from stack analysis (assuming stack-directed pointers do not exist). 15
Reference: [JM81] <author> N. D. Jones and S. S. Muchnick. </author> <title> Program Flow Analysis, Theory and Applications, chapter 4, </title> <journal> Flow Analysis and Optimization of LISP-like Structures, </journal> <pages> pages 102-131. </pages> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: This was because these analyses were designed for languages like LISP and Scheme which do not support the address-of (&) operator like C, and hence do not have stack-directed pointers. 8 Jones and Muchnick <ref> [JM81] </ref> proposed one of the first approaches to the heap analysis problem. They analyze LISP-like structures for a simple language without procedures. They abstract the structure of the heap at each program-point, in the form of a set of graphs. <p> A newly allocated node is labeled by an aggregate of the labels of the arguments to the allocation function (cons). This proves to be more precise than labeling the node by the program point where it is allocated. Unlike <ref> [JM81] </ref>, they maintain only one alias graph per program point instead of a set of graphs. They define a meet operator that combines two alias graphs into a new alias graph that contains all aliases in either graph. <p> They basically differ from each other in the way they choose to bound the graph. Further, nodes in the graph are sometimes labeled to facilitate conflict detection between 12 statements [LH88, HPR89]. Procedure calls are either not handled <ref> [JM81, HPR89, PCK94, SRW96] </ref> or are analyzed with different degrees of precision [JM82, LH88, CWZ90]. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. To avoid this trap, Hendren and Nicolau [HN90] took a different approach.
Reference: [JM82] <author> N. D. Jones and S. S. Muchnick. </author> <title> A flexible approach to interprocedural data flow analysis and programs with recursive data structures. </title> <booktitle> In 9th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 66-74, </pages> <year> 1982. </year>
Reference-contexts: Due to k-limiting all the information about nodes beyond depth k is lost. The introduction of summary nodes can generate spurious cycles in otherwise acyclic structures. Finally, maintaining a set of graphs at every program point, can prove to be quite expensive. Jones and Muchnick <ref> [JM82] </ref> also proposed a flexible framework for analysis of programs with recursive data structures. They designate program points which create or modify recursive structures with tokens. The tokens can be considered as local representations of the data structures at the given program points. <p> Further, nodes in the graph are sometimes labeled to facilitate conflict detection between 12 statements [LH88, HPR89]. Procedure calls are either not handled [JM81, HPR89, PCK94, SRW96] or are analyzed with different degrees of precision <ref> [JM82, LH88, CWZ90] </ref>. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. To avoid this trap, Hendren and Nicolau [HN90] took a different approach. <p> speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures <ref> [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96] </ref>. These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers [HN90].
Reference: [Jus94] <author> Justiani. </author> <title> An array dependence testing framework for the McCAT com-piler. </title> <type> Master's thesis, </type> <institution> School of Computer Science, McGill University, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: We have measured the effectiveness of our pointer analyses for more precise ADT, using a set of 6 array-based C programs (described in Table 3.2, page number 70). We used the ADT implemented in the McCAT C compiler (McADT) <ref> [Jus94, Lap97] </ref> for our study. On encountering pointer-based array references, McADT invokes a routine called checkAliasToSameVar, that checks if the two pointer-based arrays references actually access the same array. <p> For example, array references a [i] and a [j] can induce an LCD if the subscript tests can detect that j can be expressed as an affine function of i (j = m * i +/- k where m and k denote constants). Further details can be found in <ref> [Jus94, Lap97] </ref>. <p> Further, if it needs to compare access paths of the form list arr [i + j] and list arr [i + k], it uses subscript tests from array dependence testing <ref> [Jus94, Lap97] </ref>, to identify LCDs. 160 Program Description Principal Data Structures treeadd Tree Addition Binary Tree power Power System Optimization k-ary Tree circuit Sparse Matrix Solver Doubly-linked Lists pug Grid Triangulation Interconnected Linked Lists Table 5.1: Benchmark Descriptions 5.6 Experimental Results We have implemented the dependence tests described in sections 5.4
Reference: [KS93] <author> N. Klarlund and M. Schwartzbach. </author> <title> Graph types. </title> <booktitle> In Proceedings of the ACM 20th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 196-205, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: This technique is general purpose (i.e. is not restricted to data structures of certain types like lists and trees). The initial results provided in the paper are encouraging. It would be interesting to see more detailed experimental results. Klarlund and Schwartzbach <ref> [KS93] </ref> also proposed a similar approach called Graph Types to describe data structures using regular-like expressions. With graph types, pointer fields are separated into two types, tree and routing fields.
Reference: [Lan92a] <author> W. Landi. </author> <title> Undecidability of static analysis. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(4), </volume> <month> December </month> <year> 1992. </year>
Reference-contexts: Note that in the light of theoretical results establishing the undecidability of calculating precise alias relationships via static analysis <ref> [Lan92a] </ref>, the analysis is not expected to give precise information.
Reference: [Lan92b] <author> William A. Landi. </author> <title> Interprocedural aliasing in the presence of pointers. </title> <type> PhD thesis, </type> <institution> Rutgers University, </institution> <year> 1992. </year>
Reference-contexts: Early work on pointer aliasing includes: (i) a flow-insensitive algorithm from Weihl [Wei80] which turned out to be very imprecise in practice <ref> [Lan92b] </ref>, (ii) an approach proposed by Chow and Rudmik [CR82] for their CHILL compiling system, which handles only single-level pointers, and (iii) a study by Coutant [Cou86] of Weihl's algorithm, which suggested the use of pragmas for collecting more accurate information.
Reference: [Lap97] <author> Christopher Lapkowski. </author> <title> A practical symbolic array dependence analysis framework for C. </title> <type> Master's thesis, </type> <institution> School of Computer Science, McGill University, </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: We have measured the effectiveness of our pointer analyses for more precise ADT, using a set of 6 array-based C programs (described in Table 3.2, page number 70). We used the ADT implemented in the McCAT C compiler (McADT) <ref> [Jus94, Lap97] </ref> for our study. On encountering pointer-based array references, McADT invokes a routine called checkAliasToSameVar, that checks if the two pointer-based arrays references actually access the same array. <p> For example, array references a [i] and a [j] can induce an LCD if the subscript tests can detect that j can be expressed as an affine function of i (j = m * i +/- k where m and k denote constants). Further details can be found in <ref> [Jus94, Lap97] </ref>. <p> Further, if it needs to compare access paths of the form list arr [i + j] and list arr [i + k], it uses subscript tests from array dependence testing <ref> [Jus94, Lap97] </ref>, to identify LCDs. 160 Program Description Principal Data Structures treeadd Tree Addition Binary Tree power Power System Optimization k-ary Tree circuit Sparse Matrix Solver Doubly-linked Lists pug Grid Triangulation Interconnected Linked Lists Table 5.1: Benchmark Descriptions 5.6 Experimental Results We have implemented the dependence tests described in sections 5.4
Reference: [Lar89] <author> J. R. Larus. </author> <title> Restructuring Symbolic Programs for Concurrent Execution on Multiprocessors. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1989. </year>
Reference-contexts: The motivation behind shape analysis is to identify tree and list-like structures in programs in a simple and efficient way. This knowledge can then be gainfully exploited for parallelizing programs <ref> [Lar89, Hen90] </ref>, and performing optimizing transformations like loop unrolling [HG92] and software pipelining [HHN92a]. There is a large body of applications which use trees and lists as principal data structures. It can be noted that these abstractions are practical variations on the path matrix model of Hendren and Nicolau [HN90].
Reference: [LG88] <author> J. M. Lucassen and D. K. Gifford. </author> <title> Polymorphic effect systems. </title> <booktitle> In Proceedings 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 47-57, </pages> <year> 1988. </year>
Reference-contexts: Besides the automatic analysis techniques discussed above, certain language-based approaches have been proposed to get the information from the programmer. A brief discussion follows. Lucassen and Gifford <ref> [LG88] </ref> defined a language (FX-87), which incorporates both an effect and a type system. The effect of a computation must be explicitly associated with a region of memory. The effect system differentiates between totally disjoint linked structures, but fails to distinguish between disjoint subpieces of a data structure.
Reference: [LH88] <author> J. R. Larus and P. N. Hilfinger. </author> <title> Detecting conflicts between structure accesses. </title> <booktitle> In Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 21-34, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The analysis framework is parameterized by the choice of token sets. Thus a wide range of analyses can be expressed 9 in this framework. However, this method has remained mostly of theoretical interest, being expensive in both space and time. Larus and Hilfinger <ref> [LH88] </ref> use a variation of k-limited graphs called alias graphs for analyzing Lisp programs. Their goal is to detect potential conflicts between heap accesses at different program statements. They label edges in the alias graph by names of corresponding accessors (pointer fields). <p> A statement S is (flow) dependent on statement T, if S reads a location whose abstraction in the storage graph is labeled with statement T. They maintain a set of storage graphs at each program point, unlike a single alias graph <ref> [LH88] </ref>. This makes their analysis more precise, but also more expensive. They use abstract interpretation [CC77] augmented with an instrumented semantics, to prove the correctness of their technique. However, it is unclear how effective it would prove to be in practice. <p> They basically differ from each other in the way they choose to bound the graph. Further, nodes in the graph are sometimes labeled to facilitate conflict detection between 12 statements <ref> [LH88, HPR89] </ref>. Procedure calls are either not handled [JM81, HPR89, PCK94, SRW96] or are analyzed with different degrees of precision [JM82, LH88, CWZ90]. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. <p> Further, nodes in the graph are sometimes labeled to facilitate conflict detection between 12 statements [LH88, HPR89]. Procedure calls are either not handled [JM81, HPR89, PCK94, SRW96] or are analyzed with different degrees of precision <ref> [JM82, LH88, CWZ90] </ref>. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. To avoid this trap, Hendren and Nicolau [HN90] took a different approach. <p> Other approaches that use the results of pointer analysis have primarily focused on dependence analysis and parallelization <ref> [LH88, Gua88, HPR89, HN90, HHN94] </ref>. <p> More directly related to this chapter are methods that use the results of heap pointer analysis in the context of dependence analysis and parallelization. These approaches include: techniques using path expressions to name locations <ref> [LH88] </ref>, using syntax trees to name locations [Gua88], extending k-limited graphs with location names [HPR89]; and dependence analysis based on shape information and path expressions [HN90] The focus of these techniques is on identifying function-call parallelism for recursive data structures, and the heap analyses used are substantially more complex than our
Reference: [LH96] <author> Christopher Lapkowski and Laurie J. Hendren. </author> <title> Extended SSA numbering: Introducing SSA properties to languages with multi-level pointers. </title> <booktitle> In Proceedings of CASCON'96, </booktitle> <address> Toronto, Ontario, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: Next, points-to analysis is performed, which calculates possible pointer targets at each program point for stack-directed pointers, and also resolves indirect calls through function pointers. After points-to analysis, hierarchical stack read/write sets are computed. Using the read/write set information, SSA numbering is performed <ref> [LH96] </ref>. Subsequently various interprocedural heap analyses are conducted. At this stage, several new components are added to the compilation framework to put pointer analysis to work. These components are shown in bold face in Figure 2.1, and are based on the work reported in this thesis. <p> It enables us to determine which pointers can point to the heap, and ignore the pointers that can only point to stack locations. We use extended SSA numbers <ref> [LH96] </ref> to further reduce the number of anchor handles required. Although conceptually one requires a new anchor handle for each indirect reference to the heap, in fact, anchor handles can often be reused.
Reference: [LM96] <author> Chi-Keung Luk and Todd C. Mowry. </author> <title> Compiler-based prefetching for recursive data structures. </title> <booktitle> In Proceedings of the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Cambridge, Massachusetts, </address> <month> October 1-5, </month> <year> 1996. </year> <journal> ACM SIGARCH, SIGOPS, SIGPLAN, and the IEEE Computer Society. Computer Architecture News, 24, October 1996; Operating Systems Review, 30(5), December 1996; SIGPLAN Notices, </journal> <volume> 31(9), </volume> <month> September </month> <year> 1996. </year> <month> 178 </month>
Reference-contexts: Providing improved input to array dependence testers [GH98] (section 4.4); 4. Providing summary information that is useful for program understanding [GH98], dynamic compilation [APC + 96] and prefetching of pointer data structures <ref> [LM96] </ref> (section 4.6). Implementations and Empirical studies: We have implemented our techniques in the McCAT C compiler, and we present empirical data to illustrate the costs and benefits of the techniques (chapter 4). <p> Since connection analysis disambiguates heap accesses at the data structure level, it can track reads and writes to such data structures with great accuracy, without requiring a more sophisticated and expensive heap analysis. 4.6.2 Compiler-Directed Prefetching Recently there has been focus on prefetching accesses to recursive heap data structures <ref> [LM96] </ref>. The information needed here is which fields are potentially accessed with respect to a pointer, inside a function or a loop. <p> In Figure 4.17, we show a loop from the bitonic sort benchmark, used by Luk and Mowry in their study <ref> [LM96] </ref>. The loop is shown with the prefetch instructions, as presented in their paper. At the beginning of the loop, the left and right fields are prefetched with respect to the pointers pl and pr.
Reference: [LR92] <author> W. Landi and B. Ryder. </author> <title> A safe approximation algorithm for interpro--cedural pointer aliasing. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 235-248, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: They form the core of present day optimizing/parallelizing compilers. The problem of calculating pointer-induced aliases, termed pointer analysis, has also received significant attention from the research community over the past few years <ref> [LR92, CBC93, EGH94, WL95, Ruf95, Ste96, ZRL96, SH97b] </ref>. This emphasis has mainly stemmed from the increasing popularity of languages supporting pointers such as C, C++ and Fortran90. <p> The naming schemes proposed are as simple as using one name, heap, to represent all heap objects [EGH94]. More precise schemes name objects using their allocation site <ref> [LR92] </ref>, or allocation site prepended with the procedure string representing the given calling context [CBC93, WL95]. 3 For the code fragment in Figure 1.1, the first naming scheme gives the points-to pairs (r, heap) and (s, heap). Using allocation sites instead, would give the pairs (r, malloc_U), (s, malloc V). <p> Landi and Ryder <ref> [LR92] </ref> designed and implemented one of the first flow-sensitive interprocedural alias analysis algorithms for C programs. They collect alias information in the form of pairs of object names. An object name consists of a variable and a (possibly empty) sequence of dereferences and field accesses. <p> Choi, Burke and Carini [CBC93] presented another algorithm for flow-sensitive alias analysis. They compute aliases as pairs of access paths. Their access paths are similar to object names <ref> [LR92] </ref>. However, they do not use access paths to name heap objects. They use the place (statement) in the program, where an anonymous 6 heap object is created, to name it. <p> All the techniques presented above handle procedure calls in a context-sensitive manner i.e. the effect of a procedure call is estimated specific to a calling context, and not just summarized for all possible calling contexts. They use different strategies to abstract calling contexts: assumed alias sets <ref> [LR92] </ref>, last call site and source alias sets [CBC93], invocation graphs [EGH94], and partial transfer functions [WL95]. In addition, Emami et. al [EGH94] precisely handle indirect calls through function pointers in C. Wilson and Lam follow their strategy for handling function pointers. <p> This SAP, when parameterized on i, finitely represents an infinite number of access paths from the head of a list to the hd fields of its nodes. No imprecision is incurred, as happens with the k-limiting of object names <ref> [LR92] </ref>. 13 An alias pair in this framework consists of a pair of symbolic access paths qualified by an equation.
Reference: [LRZ93] <author> William Landi, Barbara G. Ryder, and Sean Zhang. </author> <title> Interprocedural modification side effect analysis with pointer aliasing. </title> <booktitle> In Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 56-67, </pages> <address> Albuquerque, New Mexico, </address> <month> June 23-25, </month> <year> 1993. </year> <journal> SIGPLAN Notices, </journal> <volume> 28(6), </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: Banning gave one of the seminal methods for computing side effects in the presence of aliases that arise due to call-by-reference [Ban79]. More recent algorithms based on alias analysis, for languages with explicit pointers, have been presented by Landi et. al <ref> [LRZ93] </ref> and Choi et. al [CBC93].
Reference: [LS95] <author> James R. Larus and Eric Schnarr. EEL: </author> <title> Machine-independent executable editing. </title> <booktitle> In Proceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 291-300, </pages> <address> La Jolla, California, </address> <month> June 18-21, </month> <year> 1995. </year> <journal> SIGPLAN Notices, </journal> <volume> 30(6), </volume> <month> June </month> <year> 1995. </year>
Reference-contexts: The run time was calculated as the sum of the system and user time reported by the "time" utility. Also the run time was averaged over three runs of the program. We collected the first two statistics using the EEL based <ref> [LS95] </ref> QPT2 tool developed by Jim Larus, which instruments the program executable to give exact counts. However, note that run time reported is not from the QPT2-instrumented versions of the executables. The comparison of the above statistics is presented in Table 4.5.
Reference: [MLR + 93] <author> T. Marlowe, W. Landi, B. Ryder, J. Choi, M. Burke, and P. Carini. </author> <title> Pointer-induced aliasing: A clarification. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 28(9) </volume> <pages> 67-70, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: In the presence of recursion, this qualification proves to be of limited use. They mention that they combine this naming scheme with k-limiting to analyze recursive structures. It is not clear from their paper, what type of k-limiting they perform <ref> [MLR + 93] </ref>. They also propose the idea of transitive reduction of alias pairs into points-to pairs. Emami, Ghiya and Hendren [EGH94] proposed the approach of decoupling stack and heap analyses. They focus on analysis of stack-directed pointers, and collect alias information in the form of points-to relationships.
Reference: [Mye81] <author> E. Myers. </author> <title> A precise interprocedural data flow algorithm. </title> <booktitle> In Proceedings of the ACM 8th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 219-230, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: Effective techniques for computing such aliases have been developed and described <ref> [Bar78, Ban79, Mye81, Coo85, CK89] </ref>. Most of these analyses collect the alias information in two passes over the program: (i) an introductory pass to compute all the obvious aliases generated at call-sites, (ii) a propagation pass to propagate the aliases through the call-graph of the program.
Reference: [PCK93] <author> John Plevyak, Andrew A. Chien, and Vijay Karamcheti. </author> <title> Analysis of dynamic structures for efficient parallel execution. </title> <editor> In Uptal Banerjee, David Gelernter, Alex Nicolau, and David Padua, editors, </editor> <booktitle> Proceedings of the 6th International Workshop on Languages and Compilers for Parallel Computing, number 768 in Lecture Notes in Computer Science, </booktitle> <pages> pages 37-56, </pages> <address> Portland, Ore., </address> <month> August 12-14, </month> <year> 1993. </year> <institution> Intel Corp. and the Portland Group, Inc., </institution> <note> Springer-Verlag. Published in 1994. </note>
Reference-contexts: speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures <ref> [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96] </ref>. These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers [HN90].
Reference: [PCK94] <author> J. Plevyak, A. Chien, and V. Karamcheti. </author> <title> Analysis of dynamic structures for efficient parallel execution. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Sixth International Workshop on Languages and Compilers for Parallel Computing, volume 768 of Lecture Notes in Computer Science, </booktitle> <pages> pages 37-56. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: For example, it would give highly imprecise results, if the program uses a single routine for allocating nodes (authors suggest the use of function inlining to overcome this.). Further, the meet operation is fairly complex. Plevyak, Chien and Karamcheti <ref> [PCK94] </ref> have extended the model of Chase et al. [CWZ90] to handle regular cyclic structures like doubly linked lists and trees with parent pointers, more precisely. <p> They basically differ from each other in the way they choose to bound the graph. Further, nodes in the graph are sometimes labeled to facilitate conflict detection between 12 statements [LH88, HPR89]. Procedure calls are either not handled <ref> [JM81, HPR89, PCK94, SRW96] </ref> or are analyzed with different degrees of precision [JM82, LH88, CWZ90]. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. To avoid this trap, Hendren and Nicolau [HN90] took a different approach.
Reference: [RCRH95] <author> Anne Rogers, Martin C. Carlisle, John H. Reppy, and Laurie J. Hendren. </author> <title> Supporting dynamic data structures on distributed-memory machines. </title> <journal> 179 ACM Transactions on Programming Languages and Systems, </journal> <volume> 17(2):233--263, </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: sim Computational Biology Dynamic Arrays and Lists eigen Eigenvalue Computation Dynamic Arrays Table 3.2: Benchmark Descriptions 3.5 Empirical Evaluation of the Analyses We have evaluated the efficiency of our analyses with respect to a set of 16 pointer-intensive C benchmark programs, drawn from the SPEC92, SPLASH-2 [WOT + 95], Olden <ref> [RCRH95] </ref>, Irvine [HHN94] and Wisconsin [ABS94] benchmark suites. A brief description of the benchmarks is provided in Table 3.2. The table also summarizes the principal data structures used by the benchmarks. In Table 3.3 we provide the analysis times measured on an UltraSparc machine in seconds. <p> Loop invariant pointer references frequently arise in C programs, typically in deeply embedded heap accesses, loop condition tests and inner loops. We show some examples from our benchmark programs (in simplified version) in has been moved. Parts (a) and (b) show loops from the Olden <ref> [RCRH95] </ref> benchmarks health and power respectively. From both the loops, the compiler pulls out an address calculation required to access arrays embedded inside heap objects. Parts (c) and (d) show loops from the benchmark circuit [HHN94]. In part (c) the loop test involves a loop invariant which is pulled out. <p> The second pair includes the two calls to the function treeAdd as shown in Figure 5.1 (a). To identify these calls as parallel, shape dependence test is used as they access disjoint sub-pieces of the same data structure. The benchmark power implements a power network tree <ref> [RCRH95] </ref>. Each node uses an array of pointers to point to its child nodes, as opposed to named links like left and right. Shape analysis identifies the shape of this data structure as Tree.
Reference: [RM88] <author> C. Ruggieri and T. P. Murtagh. </author> <title> Lifetime analysis of dynamically allocated objects. </title> <booktitle> In Proceedings of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 285-293, </pages> <year> 1988. </year>
Reference-contexts: Thus, graph types can only describe data structures with a spanning tree backbone. A large body of work on analysis of heap-allocated objects, has focused on other problems like reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Deu90, WH92] </ref>. 1.3 Pointer Analysis in the McCAT C Compiler All the techniques we have discussed so far, either focus on stack analysis with a conservative approximation of the heap, or present sophisticated heap analyses considered in isolation from stack analysis (assuming stack-directed pointers do not exist). 15
Reference: [Ruf95] <author> Erik Ruf. </author> <title> Context-insensitive alias analysis reconsidered. </title> <booktitle> In Proceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 13-22, </pages> <address> La Jolla, California, </address> <month> June 18-21, </month> <year> 1995. </year> <journal> SIGPLAN Notices, </journal> <volume> 30(6), </volume> <month> June </month> <year> 1995. </year>
Reference-contexts: They form the core of present day optimizing/parallelizing compilers. The problem of calculating pointer-induced aliases, termed pointer analysis, has also received significant attention from the research community over the past few years <ref> [LR92, CBC93, EGH94, WL95, Ruf95, Ste96, ZRL96, SH97b] </ref>. This emphasis has mainly stemmed from the increasing popularity of languages supporting pointers such as C, C++ and Fortran90. <p> This approach was initially proposed by Emami et. al [EGH94] and is used by most of the recent pointer analysis algorithms <ref> [Ruf95, WL95, Ste96, SH97b] </ref>. Unfortunately this nice property does not hold for heap-allocated data items. In fact all the objects in the heap are anonymous. They can be accessed only through pointer dereferences like *r, r-&gt;item or a [i], where r and a are heap-directed pointers. <p> In addition, Emami et. al [EGH94] precisely handle indirect calls through function pointers in C. Wilson and Lam follow their strategy for handling function pointers. Ruf <ref> [Ruf95] </ref> compared a context-insensitive alias analysis with a context-sensitive 7 analysis. He reported that for his benchmark suite the latter provides more accurate information in general. However, this additional accuracy is not seen at indirect references where the analysis information is actually used. <p> if (listA == NULL) return; p = copyList (listA); t = p; while (listA-&gt;next != NULL) - listA-&gt;next-&gt;index = t-&gt;index; t = t-&gt;next; list = list-&gt;next; - S: p = copyList (listB); /* Memory Leak */ T: t = p; /* Memory Leak Warning */ ... 117 any points-to analysis <ref> [EGH94, WL95, Ruf95, Ste96] </ref>, where all locations have names is quite straight-forward and only slight modifications of standard transformations are needed as shown in section 2.5. We assume that other compilers with points-to analyses have similar applications.
Reference: [Ruf97] <author> Erik Ruf. </author> <title> Partitioning dataflow analyses using types. </title> <booktitle> In Conference Record of POPL'97: The 24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 15-26, </pages> <address> Paris, France, Jan-uary 15-17, </address> <year> 1997. </year>
Reference-contexts: This approach has been explored to some extent in <ref> [ZRL96, Ruf97] </ref>. In the context of using pointer analysis information for parallelism detection, there is considerable scope for future work. More general approaches need to be developed for extracting loop parallelism.
Reference: [SH97a] <author> Marc Shapiro and Susan Horwitz. </author> <title> The effects of the precision of pointer analysis. </title> <booktitle> In Proceedings of the 1997 Static Analysis Symposium, </booktitle> <address> Paris, France, </address> <month> Sep. </month> <year> 1997. </year>
Reference-contexts: We assume that other compilers with points-to analyses have similar applications. In terms of using the improved read/write sets from pointer analysis, for other analyses and transformations, the most relevant related work is of Wilson and Lam [WL95], Shapiro and Horwitz <ref> [SH97a] </ref> and Cooper and Lu [CL97]. Wilson and Lam used pointer analysis results for loop parallelization in the context of two numeric C benchmarks, alvinn and specear (Table 3.2).
Reference: [SH97b] <author> Marc Shapiro and Susan Horwitz. </author> <title> Fast and accurate flow-insensitive points-to analysis. </title> <booktitle> In Conference Record of POPL'97: The 24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 1-14, </pages> <address> Paris, France, </address> <month> January 15-17, </month> <year> 1997. </year>
Reference-contexts: They form the core of present day optimizing/parallelizing compilers. The problem of calculating pointer-induced aliases, termed pointer analysis, has also received significant attention from the research community over the past few years <ref> [LR92, CBC93, EGH94, WL95, Ruf95, Ste96, ZRL96, SH97b] </ref>. This emphasis has mainly stemmed from the increasing popularity of languages supporting pointers such as C, C++ and Fortran90. <p> This approach was initially proposed by Emami et. al [EGH94] and is used by most of the recent pointer analysis algorithms <ref> [Ruf95, WL95, Ste96, SH97b] </ref>. Unfortunately this nice property does not hold for heap-allocated data items. In fact all the objects in the heap are anonymous. They can be accessed only through pointer dereferences like *r, r-&gt;item or a [i], where r and a are heap-directed pointers. <p> One type is assumed to be pointing to another type, if any program variable represented by the former, can point to a variable represented by the latter. Two types are merged (unified) during analysis, when a potential assignment is seen between program variables represented by them. Shapiro and Horwitz <ref> [SH97b] </ref> compare Steensgaard's algorithm with that of An-dersen [And94]. In contrast to Steensgaard, Andersen's algorithm represents each program variable with one type variable, and allows one type variable to point to several type variables. It also has cubic time complexity. <p> The above observations also indicate that for larger programs, if interesting sections of the program can be identified using linear points-to analyses <ref> [Ste96, SH97b] </ref>, precise information for these sections can be obtained efficiently via context-sensitive approaches. We are presently experimenting with this approach to efficiently analyze larger programs. <p> One such example was the negative interaction between CSE optimization and register allocation, for the power benchmark in our study (section 4.2.3). Another area for further exploration is comparing the benefits of context-sensitive, 169 flow-sensitive pointer analyses (used in this thesis), vs. context-insensitive and flow--insensitive analyses <ref> [Ste96, SH97b] </ref>. The flow-insensitive analyses have almost linear time complexity in the size of the program, and can efficiently analyze large programs. Being flow- and context-insensitive, they provide less accurate information about pointer relationships as compared to context-sensitive analyses. However, the flow-insensitive information may still suffice for many compiler optimizations.
Reference: [Sri92] <author> Bhama Sridharan. </author> <title> An analysis framework for the McCAT compiler. </title> <type> Master's thesis, </type> <institution> McGill University, </institution> <address> Montreal, Quebec, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: It also makes control flow structured and explicit. Simple forms the appropriate program representation for high-level analyses like alias and dependence analysis, and for high-level loop and parallelization transformations. We discuss it in more detail in the next section. A complete description is given in <ref> [Sri92] </ref>. The overall design of the McCAT compiler is shown in Figure 2.1. Note that the compiler takes as input a set of C files, which are linked by a source-level linker. This is necessary in order to have the whole source program available for interpro-cedural analysis.
Reference: [SRW96] <author> Mooly Sagiv, Thomas Reps, and Reinhard Wilhelm. </author> <title> Solving shape-analysis problems in languages with destructive updating. </title> <booktitle> In Conference Record of the 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 16-31, </pages> <address> St. Petersburg, Florida, </address> <month> January 21-24, </month> <year> 1996. </year>
Reference-contexts: They also annotate summary nodes with identity paths, to indicate which combinations of link fields can create cycles. Presently they do not handle procedure calls. Further, their analysis needs empirical verification, though they give some examples in the paper. Recently, Sagiv et. al <ref> [SRW96] </ref> have presented a new approach to estimate the shape properties of heap data structures. They also abstract the heap as a storage shape graph [CWZ90]. However, their graph contains nodes only for heap locations pointed to by program variables (i.e. stack-resident heap-directed pointers). <p> They basically differ from each other in the way they choose to bound the graph. Further, nodes in the graph are sometimes labeled to facilitate conflict detection between 12 statements [LH88, HPR89]. Procedure calls are either not handled <ref> [JM81, HPR89, PCK94, SRW96] </ref> or are analyzed with different degrees of precision [JM82, LH88, CWZ90]. The restriction of representing several heap locations with one abstract location, forms the main source of imprecision for the store-based techniques. To avoid this trap, Hendren and Nicolau [HN90] took a different approach. <p> speed-up by factors of 16 and 12 on the EARTH-MANNA mul-tithreaded machine [HMT + 95] using 16 processors (Figure 4.11, page number 103). 5.7 Related Work As summarized in section 1.2.2 in chapter 1, a considerable amount of work has been done on analyzing programs with recursive heap data structures <ref> [JM82, CWZ90, HN90, PCK93, Deu94, GH95, GH96a, GH96b, SRW96] </ref>. These analyses either explicitly estimate the structure of heap as a storage shape graph [CWZ90], or compute some abstract relationships between heap-directed pointers [HN90].
Reference: [Sta92] <author> Richard M. Stallman. </author> <title> Using and Porting GNU CC. </title> <address> Cambridge, Massachusetts, </address> <month> June </month> <year> 1992. </year> <note> Available via anonymous ftp from prep.ai.mit.edu. 180 </note>
Reference-contexts: By performing source-to-source scalar transformations based on our read/write sets, we demonstrate performance improvement of 3.4% on average, and up to 10.3%, over the GNU C compiler <ref> [Sta92] </ref> compiling at the highest level of optimization. For array dependence testers we show significant improvements with pointer read/write sets, and we demonstrate the use of our read/write sets for program understanding via a tool that produces output that can be browsed via Web browsers. <p> 4.9 (a) can also be applied without any pointer analysis information (in fact gcc applies them). 4.2.3 Runtime Improvements with Stack and Heap Read/Write Sets In order to measure the additional benefits of our analyses over a state-of-the-art optimizing compiler, we have compared our results with the GNU C compiler <ref> [Sta92] </ref> (gcc version 2.7.2) working at the highest level of optimization (with -O3 flag). Since our transformations are source-to-source and are performed at the Simple intermediate representation, we performed the following experiment.
Reference: [Ste96] <author> Bjarne Steensgaard. </author> <title> Points-to analysis in almost linear time. </title> <booktitle> In Confer--ence Record of the 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 32-41, </pages> <address> St. Petersburg, Florida, </address> <month> January 21-24, </month> <year> 1996. </year>
Reference-contexts: They form the core of present day optimizing/parallelizing compilers. The problem of calculating pointer-induced aliases, termed pointer analysis, has also received significant attention from the research community over the past few years <ref> [LR92, CBC93, EGH94, WL95, Ruf95, Ste96, ZRL96, SH97b] </ref>. This emphasis has mainly stemmed from the increasing popularity of languages supporting pointers such as C, C++ and Fortran90. <p> This approach was initially proposed by Emami et. al [EGH94] and is used by most of the recent pointer analysis algorithms <ref> [Ruf95, WL95, Ste96, SH97b] </ref>. Unfortunately this nice property does not hold for heap-allocated data items. In fact all the objects in the heap are anonymous. They can be accessed only through pointer dereferences like *r, r-&gt;item or a [i], where r and a are heap-directed pointers. <p> However, this additional accuracy is not seen at indirect references where the analysis information is actually used. Our belief is that while this may be true for programs with a simple interprocedural structure, for larger programs with more complex call-graphs context-sensitivity is required. Steensgaard <ref> [Ste96] </ref> proposed a type-inference-based near linear time (in the size of the program) points-to analysis algorithm, which is both flow- and context-insensitive. Types are used to represent locations of variables as well as possible runtime contents of these locations. <p> The above observations also indicate that for larger programs, if interesting sections of the program can be identified using linear points-to analyses <ref> [Ste96, SH97b] </ref>, precise information for these sections can be obtained efficiently via context-sensitive approaches. We are presently experimenting with this approach to efficiently analyze larger programs. <p> if (listA == NULL) return; p = copyList (listA); t = p; while (listA-&gt;next != NULL) - listA-&gt;next-&gt;index = t-&gt;index; t = t-&gt;next; list = list-&gt;next; - S: p = copyList (listB); /* Memory Leak */ T: t = p; /* Memory Leak Warning */ ... 117 any points-to analysis <ref> [EGH94, WL95, Ruf95, Ste96] </ref>, where all locations have names is quite straight-forward and only slight modifications of standard transformations are needed as shown in section 2.5. We assume that other compilers with points-to analyses have similar applications. <p> One such example was the negative interaction between CSE optimization and register allocation, for the power benchmark in our study (section 4.2.3). Another area for further exploration is comparing the benefits of context-sensitive, 169 flow-sensitive pointer analyses (used in this thesis), vs. context-insensitive and flow--insensitive analyses <ref> [Ste96, SH97b] </ref>. The flow-insensitive analyses have almost linear time complexity in the size of the program, and can efficiently analyze large programs. Being flow- and context-insensitive, they provide less accurate information about pointer relationships as compared to context-sensitive analyses. However, the flow-insensitive information may still suffice for many compiler optimizations.
Reference: [TGHG97] <author> X. Tang, R. Ghiya, L. J. Hendren, and G. R. Gao. </author> <title> Heap analysis and optimizations for threaded programs. </title> <booktitle> In Proc. of the 1997 Conf. on Parallel Architectures and Compilation Techniques (PACT'97), </booktitle> <address> San Francisco, Calif., </address> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: The benefits of our scalar optimizations on pointer references, have also been studied in the context of parallel EARTH-C programs, where they provide up to 25% performance improvement <ref> [TGHG97] </ref>. Detecting parallelism in programs with recursive data structures: We have developed effective techniques to use program-point specific shape information in combination with our read/write set information, to identify coarse-grain parallelism in C programs with recursive data structures (chapter 5). <p> The detailed results are presented in <ref> [TGHG97] </ref>. Here we briefly discuss the main points. The EARTH-MANNA architecture emulator runs on top of the MANNA parallel machine [BGSP94], which consists of multiple nodes connected by an interconnection network. It supports a distributed shared memory model. <p> To indicate statements that can be executed in parallel, we use our dependence test (depTest) during the DDG (data dependence graph) construction phase of the EARTH-McCAT compiler <ref> [TGHG97] </ref>. The DDG is then used to identify statements/function calls that can be executed in parallel, and to partition the program into threads.
Reference: [Wei80] <author> W. Weihl. </author> <title> Interprocedural data flow analysis in the presence of pointers, procedure variables, and label variables. </title> <booktitle> In Proceedings of the 7th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 83-94, </pages> <month> January </month> <year> 1980. </year>
Reference-contexts: Early work on pointer aliasing includes: (i) a flow-insensitive algorithm from Weihl <ref> [Wei80] </ref> which turned out to be very imprecise in practice [Lan92b], (ii) an approach proposed by Chow and Rudmik [CR82] for their CHILL compiling system, which handles only single-level pointers, and (iii) a study by Coutant [Cou86] of Weihl's algorithm, which suggested the use of pragmas for collecting more accurate information.
Reference: [WH92] <author> E. Wang and P. N. Hilfinger. </author> <title> Analysis of recursive types in LISP-like languages. </title> <booktitle> In Proceedings of the '92 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 216-225, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Thus, graph types can only describe data structures with a spanning tree backbone. A large body of work on analysis of heap-allocated objects, has focused on other problems like reference counting and memory lifetimes <ref> [Hud86, ISY88, RM88, Deu90, WH92] </ref>. 1.3 Pointer Analysis in the McCAT C Compiler All the techniques we have discussed so far, either focus on stack analysis with a conservative approximation of the heap, or present sophisticated heap analyses considered in isolation from stack analysis (assuming stack-directed pointers do not exist). 15
Reference: [WL95] <author> Robert P. Wilson and Monica S. Lam. </author> <title> Efficient context-sensitive pointer analysis for C programs. </title> <booktitle> In Proceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 1-12, </pages> <address> La Jolla, California, </address> <month> June 18-21, </month> <year> 1995. </year> <journal> SIGPLAN Notices, </journal> <volume> 30(6), </volume> <month> June </month> <year> 1995. </year>
Reference-contexts: They form the core of present day optimizing/parallelizing compilers. The problem of calculating pointer-induced aliases, termed pointer analysis, has also received significant attention from the research community over the past few years <ref> [LR92, CBC93, EGH94, WL95, Ruf95, Ste96, ZRL96, SH97b] </ref>. This emphasis has mainly stemmed from the increasing popularity of languages supporting pointers such as C, C++ and Fortran90. <p> This approach was initially proposed by Emami et. al [EGH94] and is used by most of the recent pointer analysis algorithms <ref> [Ruf95, WL95, Ste96, SH97b] </ref>. Unfortunately this nice property does not hold for heap-allocated data items. In fact all the objects in the heap are anonymous. They can be accessed only through pointer dereferences like *r, r-&gt;item or a [i], where r and a are heap-directed pointers. <p> The naming schemes proposed are as simple as using one name, heap, to represent all heap objects [EGH94]. More precise schemes name objects using their allocation site [LR92], or allocation site prepended with the procedure string representing the given calling context <ref> [CBC93, WL95] </ref>. 3 For the code fragment in Figure 1.1, the first naming scheme gives the points-to pairs (r, heap) and (s, heap). Using allocation sites instead, would give the pairs (r, malloc_U), (s, malloc V). <p> It also enables simultaneous calculation of both possible and definite relationships. Empirical results reported indicate that this method collects highly precise information for stack-based aliases. At the same time, it builds a framework for conducting a variety of heap analyses (discussed in sections 2.4 and 2.6). Wilson and Lam <ref> [WL95] </ref> also use a points-to abstraction. Additionally they use the concept of location sets to name both a block of memory (arrays and structures), and a set of positions within that block. Other approaches discussed above only use one name to represent aggregate structures like arrays and structures. <p> They use different strategies to abstract calling contexts: assumed alias sets [LR92], last call site and source alias sets [CBC93], invocation graphs [EGH94], and partial transfer functions <ref> [WL95] </ref>. In addition, Emami et. al [EGH94] precisely handle indirect calls through function pointers in C. Wilson and Lam follow their strategy for handling function pointers. Ruf [Ruf95] compared a context-insensitive alias analysis with a context-sensitive 7 analysis. <p> if (listA == NULL) return; p = copyList (listA); t = p; while (listA-&gt;next != NULL) - listA-&gt;next-&gt;index = t-&gt;index; t = t-&gt;next; list = list-&gt;next; - S: p = copyList (listB); /* Memory Leak */ T: t = p; /* Memory Leak Warning */ ... 117 any points-to analysis <ref> [EGH94, WL95, Ruf95, Ste96] </ref>, where all locations have names is quite straight-forward and only slight modifications of standard transformations are needed as shown in section 2.5. We assume that other compilers with points-to analyses have similar applications. <p> We assume that other compilers with points-to analyses have similar applications. In terms of using the improved read/write sets from pointer analysis, for other analyses and transformations, the most relevant related work is of Wilson and Lam <ref> [WL95] </ref>, Shapiro and Horwitz [SH97a] and Cooper and Lu [CL97]. Wilson and Lam used pointer analysis results for loop parallelization in the context of two numeric C benchmarks, alvinn and specear (Table 3.2).
Reference: [Wol89] <author> Michael J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> Pitman, London and MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1989. </year> <note> In Research Monographs in Parallel and Distributed Computing; revised version of the author's Ph.D. dissertation published as Report No. </note> <institution> UIUCDCS-R-82-1105, University of Illinois at Urbana-Champaign, </institution> <year> 1982. </year>
Reference-contexts: For example, the array references a [i+2*j] and a [j+2*i], the pointer dereferences *q and *p, and the structure accesses p-&gt;item and q-&gt;next->item, can lead to the same memory location. Over the past twenty years, powerful data dependence analyses have been developed to resolve the problem of array aliases <ref> [Ban88, Wol89, ZC90] </ref>. These analyses use integer programming techniques to determine if two array subscript expressions can evaluate to the same value. They form the core of present day optimizing/parallelizing compilers. <p> The implementation is structured as a simple analysis for each basic statement, a compositional rule for each control construct, and a context-sensitive approach for handling procedure calls. Complete details can be found in [GH96b, Ghi95]. 5.3 Identifying Parallelism In this section, we briefly review the notion of data dependence <ref> [Wol89] </ref> between statements, which is at the heart of our algorithms for detecting the three parallelism patterns. Definition 5.3.1 Given two statements S and T belonging to a given function in the program, a data dependence exists from statement S to statement T if 1.
Reference: [WOT + 95] <author> Steven Cameron Woo, Moriyoshi Ohara, Evan Torrie, Jaswinder Pal Shingh, and Anoop Gupta. </author> <title> The SPLASH-2 programs: Characterization and methodological considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 24-36, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> June 22-24, </month> <year> 1995. </year> <journal> ACM SIGARCH and IEEE Computer Society. Computer Architecture News, </journal> <volume> 23(2), </volume> <month> May </month> <year> 1995. </year>
Reference-contexts: Dynamic Arrays and Lists sim Computational Biology Dynamic Arrays and Lists eigen Eigenvalue Computation Dynamic Arrays Table 3.2: Benchmark Descriptions 3.5 Empirical Evaluation of the Analyses We have evaluated the efficiency of our analyses with respect to a set of 16 pointer-intensive C benchmark programs, drawn from the SPEC92, SPLASH-2 <ref> [WOT + 95] </ref>, Olden [RCRH95], Irvine [HHN94] and Wisconsin [ABS94] benchmark suites. A brief description of the benchmarks is provided in Table 3.2. The table also summarizes the principal data structures used by the benchmarks. In Table 3.3 we provide the analysis times measured on an UltraSparc machine in seconds.
Reference: [ZC90] <author> H. Zima and B. Chapman. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <year> 1990. </year> <month> 181 </month>
Reference-contexts: For example, the array references a [i+2*j] and a [j+2*i], the pointer dereferences *q and *p, and the structure accesses p-&gt;item and q-&gt;next->item, can lead to the same memory location. Over the past twenty years, powerful data dependence analyses have been developed to resolve the problem of array aliases <ref> [Ban88, Wol89, ZC90] </ref>. These analyses use integer programming techniques to determine if two array subscript expressions can evaluate to the same value. They form the core of present day optimizing/parallelizing compilers.
Reference: [ZRL96] <author> Sean Zhang, Barbara G. Ryder, and William Landi. </author> <title> Program decomposi-tion for pointer aliasing: A step towards practical analyses. </title> <booktitle> In Proceedings of the 4th Symposium on the Foundations of Software Engineering, Octo-ber 1996. </booktitle> <pages> 182 </pages>
Reference-contexts: They form the core of present day optimizing/parallelizing compilers. The problem of calculating pointer-induced aliases, termed pointer analysis, has also received significant attention from the research community over the past few years <ref> [LR92, CBC93, EGH94, WL95, Ruf95, Ste96, ZRL96, SH97b] </ref>. This emphasis has mainly stemmed from the increasing popularity of languages supporting pointers such as C, C++ and Fortran90. <p> The above two approaches are promising for analyzing industry-scale large programs. They can provide accurate information for programs with simple call-structure. For more complex programs, the information provided by them can be used to reduce the search space of more precise pointer analyses. Such an approach is proposed in <ref> [ZRL96] </ref>. However, these approaches also provide a very conservative approximation for heap, based on malloc sites. 1.2.2 Heap Pointer Analysis Much of the earlier work on pointer analysis, was devoted to heap analysis, more specifically to analysis of heap-based recursive data structures. <p> This approach has been explored to some extent in <ref> [ZRL96, Ruf97] </ref>. In the context of using pointer analysis information for parallelism detection, there is considerable scope for future work. More general approaches need to be developed for extracting loop parallelism.
References-found: 84

