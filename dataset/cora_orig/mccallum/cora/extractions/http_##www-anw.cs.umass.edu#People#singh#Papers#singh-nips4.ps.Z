URL: http://www-anw.cs.umass.edu/People/singh/Papers/singh-nips4.ps.Z
Refering-URL: http://www-anw.cs.umass.edu/People/singh/Papers/
Root-URL: 
Title: The Efficient Learning of Multiple Task Sequences  
Author: Satinder P. Singh 
Address: Amherst, MA 01003  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: I present a modular network architecture and a learning algorithm based on incremental dynamic programming that allows a single learning agent to learn to solve multiple Markovian decision tasks (MDTs) with significant transfer of learning across the tasks. I consider a class of MDTs, called composite tasks, formed by temporally concatenating a number of simpler, elemental MDTs. The architecture is trained on a set of composite and elemental MDTs. The temporal structure of a composite task is assumed to be unknown and the architecture learns to produce a temporal decomposition. It is shown that under certain conditions the solution of a composite MDT can be constructed by computationally inexpensive modifications of the solutions of its constituent elemental MDTs.
Abstract-found: 1
Intro-found: 1
Reference: <institution> References </institution>
Reference: [1] <author> J. R. Bachrach. </author> <title> A connectionist learning control architecture for navigation. </title> <editor> In R. P. Lippmann, J. E. Moody, and D. S. Touretzky, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <pages> pages 457-463, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [2] <author> A.G. Barto, S.J. Bradtke, and S.P. Singh. </author> <title> Real-time learning and control using asynchronous dynamic programming. </title> <type> Technical Report 91-57, </type> <institution> University of Massachusetts, </institution> <address> Amherst, MA, </address> <year> 1991. </year> <note> Also submitted to AI Journal. </note>
Reference: [3] <author> R. A. Jacobs. </author> <title> Task decomposition through competition in a modular connectionist architecture. </title> <type> PhD thesis, </type> <institution> COINS dept Univ. of Massachusetts, </institution> <address> Amherst, Mass. U.S.A., </address> <year> 1990. </year>
Reference: [4] <author> R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton. </author> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3(1), </volume> <year> 1991. </year>
Reference: [5] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vol.1: Foundations. </booktitle> <publisher> Bradford Books/MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference: [6] <author> S.P. Singh. </author> <title> Transfer of learning by composing solutions for elemental sequential tasks. </title> <booktitle> Machine Learning, </booktitle> <year> 1992. </year>
Reference: [7] <author> R. S. Sutton. </author> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 9-44, </pages> <year> 1988. </year>
Reference: [8] <author> C. J. C. H. Watkins. </author> <title> Learning from Delayed Rewards. </title> <type> PhD thesis, </type> <institution> Cambridge Univ., </institution> <address> Cambridge, England, </address> <year> 1989. </year>
Reference: [9] <author> C. J. C. H. Watkins and P. </author> <title> Dayan. </title> <booktitle> Q-learning. Machine Learning, </booktitle> <year> 1992. </year>
References-found: 10

