URL: http://www-cse.uta.edu/~holder/pubs/msl91.ps
Refering-URL: http://www-cse.uta.edu/~holder/pubs.html
Root-URL: 
Note: This is the first column. This is the first column. This is the first column. This is the first column. This is the first column. This is the first column. This is the first column. This is the first column. This is the first column. This is the first column. This is the second column. This is the second column. This is the second column. This is the second column. This is the second column. This is the second column. This is the second column. This is the second column. This is the second column. This is the second column.  
Abstract-found: 0
Intro-found: 1
Reference: <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <year> 1984. </year>
Reference-contexts: In order to combat overfit in ID3, Quinlan developed chi-square pre-pruning (Quinlan, 1986) and reduced-error post-pruning (Quinlan, 1987). Experimentation by Holder (1991) shows that these techniques alleviate some overfitting, but the general utility problem trend remains. Performance response curves for other splitting methods, PLS1 (Rendell, 1983) and CART <ref> (Breiman et al., 1984) </ref>, follow a similar pattern (Holder, 1991). Experimentation by Michalski (1989) on AQ15 and Holte et al. (1989) on CN2 reveal the general utility problem in set-covering methods as the method learns an increasing number of disjuncts.
Reference: <author> B. Carlson, J. Weinberg, and D. Fisher. </author> <title> Search control, utility, and concept induction. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 85-92, </pages> <year> 1990. </year>
Reference: <author> O. Etzioni. </author> <title> Hypothesis filtering: A practical approach to reliable learning. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 416-429, </pages> <year> 1988. </year>
Reference: <author> R. E. Fikes, P. E. Hart, and N. J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 4(3) </volume> <pages> 189-208, </pages> <year> 1972. </year>
Reference-contexts: Although experimentation with Prodigy and Soar confirms the existence of the utility problem, the experiments typically do not show the performance response of the system. Figure 3 plots the performance response of a simple analytical learning method. The method consists of a forward-chaining planner and a Strips plan generalizer <ref> (Fikes et al., 1972) </ref>. Two domains are used in the experimentation: blocks and robot (see Section 2.4).
Reference: <author> L. B. Holder. </author> <title> The general utility problem in machine learning. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 402-410, </pages> <year> 1990. </year>
Reference-contexts: General Utility Problem The general utility problem in machine learning is the degradation of performance due to increasing amounts of learned knowledge <ref> (Holder, 1990) </ref>. The term derives from the utility problem used by Minton (1988) to describe this phenomenon in analytical learning, but generalizes to other machine learning strategies. Other researchers have observed the ubiquity of the utility problem in machine learning paradigms.
Reference: <author> L. B. Holder. </author> <title> Maintaining the Utility of Learned Knowledge Using Model-Based Adaptive Control. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Experimentation by Holder (1991) shows that these techniques alleviate some overfitting, but the general utility problem trend remains. Performance response curves for other splitting methods, PLS1 (Rendell, 1983) and CART (Breiman et al., 1984), follow a similar pattern <ref> (Holder, 1991) </ref>. Experimentation by Michalski (1989) on AQ15 and Holte et al. (1989) on CN2 reveal the general utility problem in set-covering methods as the method learns an increasing number of disjuncts. <p> Plots of the performance response for AQ15 on several medical domains reveal the general utility problem trend of Figure 1 <ref> (Holder, 1991) </ref>. Error back-propagation (Rumelhart et al., 1986) is a connectionist learning method that also suffers from the general utility problem. As the number of cycles increases, the network overfits the training instances. <p> The Planner analytical learning method uses two domains: blocks and robot. The blocks domain consists of four operators for moving blocks in the blocks-world. The robot domain consists of eight operators using a robot to move boxes within a layout of connected rooms. See <ref> (Holder, 1991) </ref> for a complete description of these domains. As shown in Tables 1 and 2, the final performance is less than the peak performance for all but one case. <p> Therefore, the transformation selection procedure, which picks the highest predicted performance, consistently chooses the best (or near best) transformation. Further experimentation in <ref> (Holder, 1991) </ref> demonstrates MBAC's ability to accurately model the performance response, build models starting with no samples from the performance response curve, and transfer knowledge about one domain to another new domain. 4.
Reference: <author> R. C. Holte, L. E. Acker, and B. W. Porter. </author> <title> Concept learning and the problem of small disjuncts. </title> <booktitle> In Proceedings of the Eleventh IJ-CAI, </booktitle> <pages> pages 813-818, </pages> <year> 1989. </year>
Reference: <author> R. M. Keller. </author> <title> The Role of Contextual Knowledge in Learning Concepts to Improve Performance. </title> <type> PhD thesis, </type> <institution> Department of Com puter Science, Rutgers University, </institution> <month> January </month> <year> 1987. </year>
Reference-contexts: Model-based adaptive control (MBAC) addresses these two control dimensions of the general utility problem by using a model of the performance response trend common among several learning methods. Several systems relate to the adaptive approach in MBAC. The MetaLEX system <ref> (Keller, 1987) </ref> transforms search control knowledge according to two performance objectives. MetaLEX uses a qualitative model of the relationship between knowledge and performance that is restricted to the two performance objectives. MBAC's model applies to multiple learning strategies and multiple performance objectives.
Reference: <author> R. S. Michalski. </author> <title> How to learn imprecise concepts: A method based on two-tiered representation and the AQ15 program. </title> <editor> In Y. Kodratoff and R. S. Michalski, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach III. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: <author> S. Minton. </author> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: Minton called this phenomenon the utility problem and offered the Prodigy system as a solution <ref> (Minton, 1988) </ref>. The system empirically estimates the utility of each rule and discards a rule when the utility becomes negative. Experimentation on the Soar system has uncovered similar results (Tambe and Newell, 1988).
Reference: <author> G. Pagallo and D. Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5(1) </volume> <pages> 71-100, </pages> <year> 1990. </year>
Reference-contexts: For the empirical learners, the Breast Cancer (BC), Flag, Flare and Voting (Vote) domains come from the UC Irvine machine learning databases. The DNF2 domain is defined by a DNF concept over forty binary-valued features that appears in <ref> (Pagallo and Haussler, 1990) </ref>. The Planner analytical learning method uses two domains: blocks and robot. The blocks domain consists of four operators for moving blocks in the blocks-world. The robot domain consists of eight operators using a robot to move boxes within a layout of connected rooms.
Reference: <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: For empirical learning the performance response curve plots the classification accuracy of the knowledge after each transformation. For analytical learning the performance response curve plots the inverse of the CPU time needed by the knowledge to solve a set of test problems. 2.2 Empirical learning The ID3 program <ref> (Quinlan, 1986) </ref> induces decision trees by recursively splitting the given set of training instances. The performance response for ID3 plots the accuracy of the decision tree on a separate set of testing instances after each split. <p> As the figure illustrates, the performance responses follow the trend of Figure 1. In order to combat overfit in ID3, Quinlan developed chi-square pre-pruning <ref> (Quinlan, 1986) </ref> and reduced-error post-pruning (Quinlan, 1987). Experimentation by Holder (1991) shows that these techniques alleviate some overfitting, but the general utility problem trend remains. Performance response curves for other splitting methods, PLS1 (Rendell, 1983) and CART (Breiman et al., 1984), follow a similar pattern (Holder, 1991).
Reference: <author> J. R. Quinlan. </author> <title> Simplifying decision trees. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27 </volume> <pages> 221-234, </pages> <year> 1987. </year>
Reference-contexts: As the figure illustrates, the performance responses follow the trend of Figure 1. In order to combat overfit in ID3, Quinlan developed chi-square pre-pruning (Quinlan, 1986) and reduced-error post-pruning <ref> (Quinlan, 1987) </ref>. Experimentation by Holder (1991) shows that these techniques alleviate some overfitting, but the general utility problem trend remains. Performance response curves for other splitting methods, PLS1 (Rendell, 1983) and CART (Breiman et al., 1984), follow a similar pattern (Holder, 1991).
Reference: <author> L. Rendell, R. Seshu, and D. Tcheng. </author> <title> Layered concept learning and dynamically-variable bias management. </title> <booktitle> In Proceedings of the Tenth IJCAI, </booktitle> <pages> pages 308-314, </pages> <year> 1987. </year>
Reference-contexts: The MetaLEX system (Keller, 1987) transforms search control knowledge according to two performance objectives. MetaLEX uses a qualitative model of the relationship between knowledge and performance that is restricted to the two performance objectives. MBAC's model applies to multiple learning strategies and multiple performance objectives. The VBMS system <ref> (Rendell et al., 1987) </ref> and the AIMS system (Tcheng et al., 1991) learn models for selecting an appropriate empirical learning method. Both systems use a general method for learning the relationship between performance objectives and learning method. MBAC advocates a more constrained model describing less-complex learning transformations.
Reference: <author> L. A. Rendell. </author> <title> A new basis for state-space learning systems and a successful implementation. </title> <journal> Artificial Intelligence, </journal> <volume> 20(4) </volume> <pages> 369-392, </pages> <year> 1983. </year>
Reference-contexts: In order to combat overfit in ID3, Quinlan developed chi-square pre-pruning (Quinlan, 1986) and reduced-error post-pruning (Quinlan, 1987). Experimentation by Holder (1991) shows that these techniques alleviate some overfitting, but the general utility problem trend remains. Performance response curves for other splitting methods, PLS1 <ref> (Rendell, 1983) </ref> and CART (Breiman et al., 1984), follow a similar pattern (Holder, 1991). Experimentation by Michalski (1989) on AQ15 and Holte et al. (1989) on CN2 reveal the general utility problem in set-covering methods as the method learns an increasing number of disjuncts.
Reference: <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <booktitle> In Parallel Distributed Processing, </booktitle> <volume> Volume 1, chapter 8, </volume> <pages> pages 318-362. </pages> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Plots of the performance response for AQ15 on several medical domains reveal the general utility problem trend of Figure 1 (Holder, 1991). Error back-propagation <ref> (Rumelhart et al., 1986) </ref> is a connectionist learning method that also suffers from the general utility problem. As the number of cycles increases, the network overfits the training instances.
Reference: <author> M. Tambe and A. Newell. </author> <title> Some chunks are expensive. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 451-458, </pages> <year> 1988. </year>
Reference-contexts: Minton called this phenomenon the utility problem and offered the Prodigy system as a solution (Minton, 1988). The system empirically estimates the utility of each rule and discards a rule when the utility becomes negative. Experimentation on the Soar system has uncovered similar results <ref> (Tambe and Newell, 1988) </ref>. Although experimentation with Prodigy and Soar confirms the existence of the utility problem, the experiments typically do not show the performance response of the system. Figure 3 plots the performance response of a simple analytical learning method.
Reference: <author> D. K. Tcheng, B. L. Lambert, S. C. Lu, and L. A. Rendell. </author> <title> AIMS: An adaptive interactive modeling system for supporting engineering decision making. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 645-649, </pages> <year> 1991. </year>
Reference-contexts: MetaLEX uses a qualitative model of the relationship between knowledge and performance that is restricted to the two performance objectives. MBAC's model applies to multiple learning strategies and multiple performance objectives. The VBMS system (Rendell et al., 1987) and the AIMS system <ref> (Tcheng et al., 1991) </ref> learn models for selecting an appropriate empirical learning method. Both systems use a general method for learning the relationship between performance objectives and learning method. MBAC advocates a more constrained model describing less-complex learning transformations.
References-found: 18

