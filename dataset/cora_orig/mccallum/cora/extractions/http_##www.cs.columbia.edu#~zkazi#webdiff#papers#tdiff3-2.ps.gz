URL: http://www.cs.columbia.edu/~zkazi/webdiff/papers/tdiff3-2.ps.gz
Refering-URL: http://www.cs.columbia.edu/~zkazi/webdiff/biblio.html
Root-URL: http://www.cs.columbia.edu
Email: fchaw,anand,hector,widomg@cs.stanford.edu  
Title: Change Detection in Hierarchically Structured Information  
Author: Sudarshan S. Chawathe, Anand Rajaraman, Hector Garcia-Molina, and Jennifer Widom 
Address: Stanford, California 94305  
Affiliation: Department of Computer Science Stanford University  
Abstract: Detecting and representing changes to data is important for active databases, data warehousing, view maintenance, and version and configuration management. Most previous work in change management has dealt with flat-file and relational data; we focus on hierarchically structured data. Since in many cases changes must be computed from old and new versions of the data, we define the hierarchical change detection problem as the problem of finding a minimum-cost edit script that transforms one data tree to another, and we present efficient algorithms for computing such an edit script. Our algorithms make use of some key domain characteristics to achieve substantially better performance than previous, general-purpose algorithms. We study the performance of our algorithms both analytically and empirically, and we describe the application of our techniques to hierarchically structured documents. 
Abstract-found: 1
Intro-found: 1
Reference: [ACM95] <author> S. Abiteboul, S. Cluet, and T. Milo. </author> <title> A database interface for file update. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1995. </year>
Reference-contexts: The hierarchical keyless data we are comparing does have labels, and these labels usually follow a structuring schema, such as the one defined in <ref> [ACM95] </ref>.
Reference: [GHJ + 93] <author> S. Ghandeharizadeh, R. Hull, D. Jacobs, et al. </author> <title> On implementing a language for specifying active database execution models. </title> <booktitle> In Proceedings of the Nineteenth International Conference on Very Large Data Bases, </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Our focus is on hierarchical information, not flat information (e.g., files containing records or relations containing tuples). With flat information deltas may be represented simply as sets of tuples or records inserted into, deleted from, and updated in relations <ref> [GHJ + 93, LGM95] </ref>. In hierarchical information, we want to identify changes not just to the nodes in the data, but also to their relationships. <p> In a relational database, deltas usually are represented using delta relations: For a relation R, delta relations inserted (R) and deleted (R) contain the tuples inserted to and deleted from R, while delta relations old-updated (R) and new-updated (R) contain the old and new values of updated tuples <ref> [GHJ + 93, WC95] </ref>. One can contrast this representation with the relational version of an edit script, which would (presumably) be a list of tuple-level inserts, deletes, and updates, possibly based on tuple identifiers. We are interested in a representation comparable to delta relations but for hierarchically structured data.
Reference: [GM95] <author> A. Gupta and I.S. Mumick. </author> <title> Maintenance of materialized views: Problems, techniques, </title> <journal> and applications. IEEE Data Engineering Bulletin, Special Issue on Materialized Views and Data Warehousing, </journal> <volume> 18(2) </volume> <pages> 3-18, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: 1 Introduction We study the problem of detecting and representing changes to hierarchically structured information. Detecting changes to data (henceforth referred to as deltas) is a basic function of many important database facilities and applications, including active databases [WC95], data warehousing [HGMW + 95, IK93, ZGMHW95], view maintenance <ref> [GM95] </ref>, and version and configuration management [HKG + 94]. As one example, consider the world-wide web. A user may visit certain (HTML) documents repeatedly and is interested in knowing how each document has changed since the last visit.
Reference: [HGMW + 95] <author> J. Hammer, H. Garcia-Molina, J. Widom, W. Labio, and Y. Zhuge. </author> <title> The Stanford Data Warehousing Project. </title> <journal> IEEE Data Engineering Bulletin, Special Issue on Materialized Views and Data Warehousing, </journal> <volume> 18(2) </volume> <pages> 41-48, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: 1 Introduction We study the problem of detecting and representing changes to hierarchically structured information. Detecting changes to data (henceforth referred to as deltas) is a basic function of many important database facilities and applications, including active databases [WC95], data warehousing <ref> [HGMW + 95, IK93, ZGMHW95] </ref>, view maintenance [GM95], and version and configuration management [HKG + 94]. As one example, consider the world-wide web. A user may visit certain (HTML) documents repeatedly and is interested in knowing how each document has changed since the last visit. <p> We believe that a common scenario for change detectionespecially for applications such as data warehousing, or querying and browsing over changesinvolves uncooperative legacy databases (or other data management systems), where the best we can hope for is a sequence of data snapshots or dumps <ref> [HGMW + 95, LGM95] </ref>. While our change detection algorithms are designed for this scenario, our basic approach and representation schemes should be applicable to built-in change management facilities as well. * High Performance.
Reference: [HKG + 94] <author> H.C. Howard, A.M. Keller, A. Gupta, K. Krishnamurthy, K.H. Law, P.M. Teicholz, S. Tiwari, and J. Ullman. </author> <title> Versions, configurations, and constraints in CEDB. </title> <note> CIFE Working Paper 31, </note> <institution> Center for Integrated Facilities Engineering, Stanford University, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: Detecting changes to data (henceforth referred to as deltas) is a basic function of many important database facilities and applications, including active databases [WC95], data warehousing [HGMW + 95, IK93, ZGMHW95], view maintenance [GM95], and version and configuration management <ref> [HKG + 94] </ref>. As one example, consider the world-wide web. A user may visit certain (HTML) documents repeatedly and is interested in knowing how each document has changed since the last visit. <p> For autonomy reasons, the databases are updated independently. However, periodic consistent configurations of the entire design must be produced. This can be done by computing the deltas with respect to the last configuration and highlighting any conflicts that have arisen <ref> [HKG + 94] </ref>. The work on change detection reported in this paper has four key characteristics: fl Research sponsored by the Wright Laboratory Aeronautical Systems Center, Air Force Material Command, USAF, under Grant Number F33615-93-1-1339.
Reference: [IK93] <author> W.H. Inmon and C. Kelley. Rdb/VMS: </author> <title> Developing the Data Warehouse. </title> <publisher> QED Publishing Group, </publisher> <address> Boston, Massachussetts, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction We study the problem of detecting and representing changes to hierarchically structured information. Detecting changes to data (henceforth referred to as deltas) is a basic function of many important database facilities and applications, including active databases [WC95], data warehousing <ref> [HGMW + 95, IK93, ZGMHW95] </ref>, view maintenance [GM95], and version and configuration management [HKG + 94]. As one example, consider the world-wide web. A user may visit certain (HTML) documents repeatedly and is interested in knowing how each document has changed since the last visit.
Reference: [Kif95] <author> M. Kifer. </author> <title> EDIFF-a comprehensive interface to diff for Emacs 19. </title> <note> Available through anonymous ftp at ftp.cs.sunysb.edu in /pub/TechReports/kifer/ediff.tar.Z, </note> <year> 1995. </year>
Reference-contexts: It is used by the GNU diff utility, and compares two files by computing the LCS 1 of their lines. There are also a number of front-ends to this standard diff program that display the results of diff in a nicer manner. (The ediff program <ref> [Kif95] </ref> is a good example.) However, since 1 We define the Longest Common Subsequence (LCS) in Section 4. 3 the standard diff program does not understand the hierarchical structure of data, such utilities suffer from certain inherent drawbacks.
Reference: [Knu86] <author> D. Knuth. </author> <title> Computers and Typesetting. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1986. </year>
Reference: [LGM95] <author> W. Labio and H. Garcia-Molina. </author> <title> Efficient algorithms to compare snapshots. </title> <note> Available through anonymous ftp from db.stanford.edu, in pub/labio/1995, </note> <year> 1995. </year>
Reference-contexts: Our focus is on hierarchical information, not flat information (e.g., files containing records or relations containing tuples). With flat information deltas may be represented simply as sets of tuples or records inserted into, deleted from, and updated in relations <ref> [GHJ + 93, LGM95] </ref>. In hierarchical information, we want to identify changes not just to the nodes in the data, but also to their relationships. <p> We believe that a common scenario for change detectionespecially for applications such as data warehousing, or querying and browsing over changesinvolves uncooperative legacy databases (or other data management systems), where the best we can hope for is a sequence of data snapshots or dumps <ref> [HGMW + 95, LGM95] </ref>. While our change detection algorithms are designed for this scenario, our basic approach and representation schemes should be applicable to built-in change management facilities as well. * High Performance. <p> Appendix B provides details of the performance analysis of our algorithms. Appendix C provides proofs for formal results stated in the body of the paper. 2 Related Work Most previous work in change management has dealt only with flat-file and relational data. For example, <ref> [LGM95] </ref> presents algorithms for efficiently comparing sets of records that have keys. The paper [Mye86] describes an algorithm for flat text. It is used by the GNU diff utility, and compares two files by computing the LCS 1 of their lines.
Reference: [Mye86] <author> E. Myers. </author> <title> An O(N D) difference algorithm and its variations. </title> <journal> Algorithmica, </journal> <volume> 1(2) </volume> <pages> 251-266, </pages> <year> 1986. </year>
Reference-contexts: Appendix C provides proofs for formal results stated in the body of the paper. 2 Related Work Most previous work in change management has dealt only with flat-file and relational data. For example, [LGM95] presents algorithms for efficiently comparing sets of records that have keys. The paper <ref> [Mye86] </ref> describes an algorithm for flat text. It is used by the GNU diff utility, and compares two files by computing the LCS 1 of their lines. <p> The length of an LCS of S 1 and S 2 is denoted by jLCS (S 1 ; S2)j. 2 We use an algorithm due to Myers <ref> [Mye86] </ref> that computes an LCS of two sequences in time O (N D), where N = jS 1 j + jS 2 j and D = N 2jLCS (S 1 ; S 2 )j. <p> A sample run of LaDiff is shown in Appendix A. To save space, the sample run uses a toy document that illustrates only some of the features of the program. Our implementation uses a modified version of the LCS algorithm from <ref> [Mye86] </ref>.
Reference: [PGMW95] <author> Y. Papakonstantinou, H. Garcia-Molina, and J. Widom. </author> <title> Object exchange across heterogeneous information sources. </title> <booktitle> In Proceedings of the Eleventh International Conference on Data Engineering, </booktitle> <pages> pages 251-260, </pages> <address> Taipei, Taiwan, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: Intuitively, these are nodes that either remain unchanged or have their value updated in the 3 We have found this label-value model to be useful for semi-structured data in general <ref> [PGMW95] </ref>. We have defaults for the label and value of a node that does not specify them explicitly. 5 transformation from T 1 to T 2 (rather than, say, deleting the old node and inserting a new one).
Reference: [SZ90] <author> D. Shasha and K. Zhang. </author> <title> Fast algorithms for the unit cost editing distance between trees. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 581-621, </pages> <year> 1990. </year>
Reference-contexts: Our goal is to develop high performance algorithms that exploit features common to many applications and can be used on very large structures. In particular, <ref> [ZS89, SZ90] </ref> present algorithms that always find the most compact deltas, but are expensive to run, especially for large structures. (The running time is at least quadratic in the number of objects in each structure compared. <p> Even in domains where these characteristics may not hold for all of the data, it may be preferable to get a quick, correct, but not guaranteed optimal, solution using our approach. 2 Efficient parallel algorithms for unit-cost editing are presented in <ref> [SZ90] </ref>, which also presents a uniprocessor variant that runs in time O (e 2 n 1 min (n 1 ; n 2 )), where n 1 and n 2 are the tree sizes. 4 3 Overview and Preliminaries In this section, we formulate the change detection problem and split it into
Reference: [WC95] <author> J. Widom and S. Ceri. </author> <title> Active Database Systems: Triggers and Rules for Advanced Database Processing. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1995. </year>
Reference-contexts: 1 Introduction We study the problem of detecting and representing changes to hierarchically structured information. Detecting changes to data (henceforth referred to as deltas) is a basic function of many important database facilities and applications, including active databases <ref> [WC95] </ref>, data warehousing [HGMW + 95, IK93, ZGMHW95], view maintenance [GM95], and version and configuration management [HKG + 94]. As one example, consider the world-wide web. A user may visit certain (HTML) documents repeatedly and is interested in knowing how each document has changed since the last visit. <p> Of course, if the information we are comparing does have unique identifiers, then our algorithms can take advantage of them to quickly match fragments that have not changed. * Old, New Version Comparison. Although some database systemsparticularly active database systemsbuild change detection facilities into the system itself <ref> [WC95] </ref>, we focus on the problem of detecting changes given old and new versions of the data. <p> In a relational database, deltas usually are represented using delta relations: For a relation R, delta relations inserted (R) and deleted (R) contain the tuples inserted to and deleted from R, while delta relations old-updated (R) and new-updated (R) contain the old and new values of updated tuples <ref> [GHJ + 93, WC95] </ref>. One can contrast this representation with the relational version of an edit script, which would (presumably) be a list of tuple-level inserts, deletes, and updates, possibly based on tuple identifiers. We are interested in a representation comparable to delta relations but for hierarchically structured data. <p> In practice delta relations often are joined with their corresponding relation <ref> [WC95] </ref>, and we are effectively representing this join explicitly. 19 * IDN, indicating that the node corresponds to a node in the original tree. (In Figure 12, IDN annotations appear as blanks.) * UPD (v), indicating that the value of the node is updated to v. * INS (l,v), indicating that
Reference: [WU95] <author> J. Widom and J. Ullman. </author> <title> C 3 : Changes, consistency, and configurations in heterogeneous distributed information systems. Unpublished project description, </title> <note> available through the URL http://www-db.stanford.edu/c3/synopsis.html, 1995. </note>
Reference-contexts: non-document domains. * Further studying the tradeoff between optimality and efficiency to produce a parameterized algorithm A (k) where the parameter k specifies the desired level of optimality. 23 * Designing and implementing query, browsing, and active rule languages for hierarchical data based on our edit scripts and delta trees <ref> [WU95] </ref>. * Improving the implementation of our LaDiff program, and extending it to HTML and SGML docu ments. We also plan to incorporate the diff program in a web browser.
Reference: [WZS95] <author> T-L. Wang, K. Zhang, and D. Shasha. </author> <title> Pattern matching and pattern discovery in scientific, program, and document databases. </title> <booktitle> In SIGMOD Demo, </booktitle> <year> 1995. </year>
Reference-contexts: However, our delete operation is less general than the one in [ZS89], which is more symmetrical with the insert operation. We have added flexibility due to the move operation, although moves have been added to the [ZS89] algorithm in a post-processing step <ref> [WZS95] </ref>. The application domain usually determines which edit operations are more natural. In a general tree structure, the delete operation of [ZS89], which makes the children of the deleted node the children of its parent, is natural.
Reference: [ZGMHW95] <author> Y. Zhuge, H. Garcia-Molina, J. Hammer, and J. Widom. </author> <title> View maintenance in a warehousing environment. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 316-327, </pages> <address> San Jose, California, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: 1 Introduction We study the problem of detecting and representing changes to hierarchically structured information. Detecting changes to data (henceforth referred to as deltas) is a basic function of many important database facilities and applications, including active databases [WC95], data warehousing <ref> [HGMW + 95, IK93, ZGMHW95] </ref>, view maintenance [GM95], and version and configuration management [HKG + 94]. As one example, consider the world-wide web. A user may visit certain (HTML) documents repeatedly and is interested in knowing how each document has changed since the last visit.
Reference: [Zha95] <author> K. Zhang. </author> <type> Personal communication, </type> <month> May </month> <year> 1995. </year>
Reference-contexts: The second difficulty is one of complexity: the only algorithm known to us to compute the best matching as defined above (based on post-processing the output of the algorithm in [ZS89]) runs in time O (n 2 ) where n is the number of tree nodes <ref> [Zha95] </ref>. To solve the first difficulty, we restrict the set of matchings we consider by introducing stronger matching criteria, as described below. These criteria also permit us to design efficient algorithms for matching.
Reference: [ZS89] <author> K. Zhang and D. Shasha. </author> <title> Simple fast algorithms for the editing distance between trees and related problems. </title> <journal> SIAM Journal of Computing, </journal> <volume> 18(6) </volume> <pages> 1245-1262, </pages> <year> 1989. </year> <title> 24 Textual Unit Edit Operation Insert Delete Update Move Sentence Bold font Small font Italic font Footnote, label Paragraph Marginal note Marginal note, label Item Marginal note Marginal note, label Subsection Annotation(ins,del,upd,mov) in heading Section Annotation(ins,del,upd,mov) in heading Table 2: Mark-up conventions used by LaDiff. </title>
Reference-contexts: Our goal is to develop high performance algorithms that exploit features common to many applications and can be used on very large structures. In particular, <ref> [ZS89, SZ90] </ref> present algorithms that always find the most compact deltas, but are expensive to run, especially for large structures. (The running time is at least quadratic in the number of objects in each structure compared. <p> However, there are restrictions on how documents can be compared (on either a word, phrase, sentence, or paragraph basis). Furthermore, these approaches do not generalize to non-document data. The general problem of finding the minimum cost edit distance between ordered trees has been studied in <ref> [ZS89] </ref>. Compared to the algorithm presented there, our algorithm is more restrictive in that we make some assumptions about the nature of the data being represented. Our algorithm always yields correct results, but if the assumptions do not hold it may produce sub-optimal results. <p> In particular, our algorithm runs in time O (ne + e 2 ), where n is the number of tree leaves and e is the weighted edit distance (typically, e t n). The algorithm in <ref> [ZS89] </ref> runs in time O (n 2 log 2 n) for balanced trees (even higher for unbalanced trees). 2 Our work also uses a different set of edit operations than those used in [ZS89]. <p> The algorithm in <ref> [ZS89] </ref> runs in time O (n 2 log 2 n) for balanced trees (even higher for unbalanced trees). 2 Our work also uses a different set of edit operations than those used in [ZS89]. The two sets of edit operations are equivalent in the sense that any state reachable using one set is also reachable using the other. However, our delete operation is less general than the one in [ZS89], which is more symmetrical with the insert operation. <p> Our work also uses a different set of edit operations than those used in <ref> [ZS89] </ref>. The two sets of edit operations are equivalent in the sense that any state reachable using one set is also reachable using the other. However, our delete operation is less general than the one in [ZS89], which is more symmetrical with the insert operation. We have added flexibility due to the move operation, although moves have been added to the [ZS89] algorithm in a post-processing step [WZS95]. The application domain usually determines which edit operations are more natural. <p> However, our delete operation is less general than the one in <ref> [ZS89] </ref>, which is more symmetrical with the insert operation. We have added flexibility due to the move operation, although moves have been added to the [ZS89] algorithm in a post-processing step [WZS95]. The application domain usually determines which edit operations are more natural. In a general tree structure, the delete operation of [ZS89], which makes the children of the deleted node the children of its parent, is natural. <p> We have added flexibility due to the move operation, although moves have been added to the <ref> [ZS89] </ref> algorithm in a post-processing step [WZS95]. The application domain usually determines which edit operations are more natural. In a general tree structure, the delete operation of [ZS89], which makes the children of the deleted node the children of its parent, is natural. However, in an object hierarchy, this may be undesirable due to restrictions on types and composite-object memberships. (For example, an object representing a library may have a number of book objects as subobjects. <p> If a book is deleted, it is unnatural to have the subobjects of book (such as author, title, etc.) become subobjects of the library object.) We believe our approach and that in <ref> [ZS89] </ref> are complementary; the choice of which algorithm to use depends on the domain characteristics. In an application where the amount of data is small (small tree structures), or where we are willing to spend more time (biochemical structures), the more thorough algorithm [ZS89] may be preferred. <p> We believe our approach and that in <ref> [ZS89] </ref> are complementary; the choice of which algorithm to use depends on the domain characteristics. In an application where the amount of data is small (small tree structures), or where we are willing to spend more time (biochemical structures), the more thorough algorithm [ZS89] may be preferred. However, in applications with large amounts of data (object hierarchies, database dumps), or with strict running-time requirements, we would use our algorithm. The efficiency of our method is based on exploiting certain domain characteristics. <p> The second difficulty is one of complexity: the only algorithm known to us to compute the best matching as defined above (based on post-processing the output of the algorithm in <ref> [ZS89] </ref>) runs in time O (n 2 ) where n is the number of tree nodes [Zha95]. To solve the first difficulty, we restrict the set of matchings we consider by introducing stronger matching criteria, as described below. These criteria also permit us to design efficient algorithms for matching.
References-found: 18

