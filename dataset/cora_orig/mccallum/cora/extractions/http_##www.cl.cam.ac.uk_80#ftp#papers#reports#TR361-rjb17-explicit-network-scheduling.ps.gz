URL: http://www.cl.cam.ac.uk:80/ftp/papers/reports/TR361-rjb17-explicit-network-scheduling.ps.gz
Refering-URL: http://www.cl.cam.ac.uk:80/ftp/papers/reports/
Root-URL: 
Title: Explicit Network Scheduling  
Author: Richard John Black 
Degree: A dissertation submitted for the degree of Doctor of Philosophy  
Date: December 1994  
Address: Cambridge  
Affiliation: Churchill College University of  
Abstract-found: 0
Intro-found: 1
Reference: [Anderson90] <author> T.E. Anderson, B.N. Bershad, E.D. Lazowska, and H.M. Levy. </author> <title> Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism. </title> <type> Technical Report 90-04-02, </type> <institution> Department of Computer Science, University of Washington, </institution> <month> April </month> <year> 1990. </year> <month> Revised October </month> <year> 1990. </year> <pages> (pp 28, 48) </pages>
Reference-contexts: 27 * A mechanism for the kernel to indicate which event channels have been active is provided. * There is support for virtualising hardware interrupts for device drivers. * System time is unified with event handling. 3.4.1 Activations The concept of activations is derived from some of the ideas of <ref> [Anderson90] </ref>. When a process is given the CPU after some time without it, the process is upcalled or activated by a special means rather than simply being resumed at the point where it lost the CPU. <p> In this model, the client signals to a blocked server thread that it should wake up and perform an operation. The client thread may or may not block under its own control. In a variant called scheduler activations <ref> [Anderson90] </ref>, the thread blocks but control of the CPU is returned to the process' internal sched-uler. The client may then at some later date block on or poll for the indication from the server that the operation is complete. This model is recommended in [Bershad91] for multiprocessor machines.
Reference: [ANSA89] <institution> Architecture Projects Management Ltd. </institution> <note> ANSA Reference Manual release 01.01, </note> <month> March </month> <year> 1989. </year> <pages> (pp 9, 43, 49) </pages>
Reference-contexts: There is usually no multiplexing of user threads over kernel threads since the user level synchronisation primitives reduce the cost of kernel level scheduling. An exception is in the ANSA Testbench <ref> [ANSA89] </ref>, which is used as one of the available RPC systems; ANSA threads are multiplexed over tasks, with the tasks being implemented using Wanda threads. <p> Interfaces of services within the system, either in a shared library or in another process, are specified with machine-generated interface references which can be passed between processes. A binding function exists for initiating inter-process communication with a service, and a trading <ref> [ANSA89] </ref> function exists for naming interface references with human-readable names, types and properties. 4.1 Language On setting out to design a new operating system the question of which language to use is always a consideration. <p> kernel scheduler keeps a hint of the last process which has been the recipient of an event, and when re-allocating the CPU, it will favour that process if it has CPU allocation remaining in that jubilee. 4.4 IPC Operation 4.4.1 Architecture The architecture of the IPC system follows that of <ref> [ANSA89] </ref> and [Evers94b] and is connection oriented; clients must explicitly bind to servers before operations on interfaces can be invoked. Interface definitions are written in the MIDDL language [Roscoe94b]; the mapping onto the C language is known as MiddlC.
Reference: [ARM91] <institution> Advanced RISC Machines. ARM6 Macrocell Datasheet, </institution> <address> 0.5 edition, </address> <month> November </month> <year> 1991. </year> <title> (p 83) </title>
Reference-contexts: Third, to consider the suitability of Rbufs for I/O channel communication in an event based micro-kernel system. 6.1 Experimental Platform The experimental platform chosen was the ARM processor <ref> [ARM91, ARM92] </ref> and the Fairisle Port Controller version 3 [Hayter94a, Hayter94b]. This was due to the author's detailed knowledge of this hardware gained during the porting of the Wanda micro-kernel to this platform and the writing of the code for the Fairisle ATM switch.
Reference: [ARM92] <institution> Advanced RISC Machines. </institution> <address> ARM610 Datasheet, 1.0 edition, </address> <year> 1992. </year> <title> (p 83) </title>
Reference-contexts: Third, to consider the suitability of Rbufs for I/O channel communication in an event based micro-kernel system. 6.1 Experimental Platform The experimental platform chosen was the ARM processor <ref> [ARM91, ARM92] </ref> and the Fairisle Port Controller version 3 [Hayter94a, Hayter94b]. This was due to the author's detailed knowledge of this hardware gained during the porting of the Wanda micro-kernel to this platform and the writing of the code for the Fairisle ATM switch.
Reference: [Barham95] <author> P. Barham, M. Hayter, D. McAuley, and I. Pratt. </author> <title> Devices on the Deak Area Network. </title> <journal> IEEE Journal on Selected Areas in Communication, </journal> <volume> 13(1), </volume> <month> January </month> <year> 1995. </year> <note> To Appear in the special issue on ATM LANs. (p 2) </note>
Reference-contexts: The observation that bus-based workstations (where data traversed the bus many times) were not ideal led to a prototype second generation multimedia workstation replacing the bus with an ATM based interconnect the Desk Area Network <ref> [Hayter91, Hayter93, Barham95] </ref>. Operating system support for continuous media streams has also been under investigation; the creation of the Pegasus project [Mullender92] was intended to develop such a system.
Reference: [Bershad89] <author> B.N. Bershad, T.E. Anderson, E.D. Lazowska, and H.M. Levy. </author> <title> Lightweight Remote Procedure Call. </title> <type> Technical Report 89-04-02, </type> <institution> Department of Computer Science, University of Washing-ton, </institution> <month> April </month> <year> 1989. </year> <pages> (pp 46, 47, 63) </pages>
Reference-contexts: Other uses of that function within the shared library are not affected. 4.3 IPC Model The mechanism for local (i.e. same machine) RPC has been the subject of a great deal of research and experimentation over the last few years. For the Topaz micro-kernel, <ref> [Bershad89] </ref> reports that almost 95% of RPC is local, so in a highly decomposed (micro-kernel) system its performance can be crucial to the overall performance. 4.3.1 Trust In a conventional monolithic kernel such as Unix, the various different parts make assumptions of trust about others, and user processes make assumptions of <p> The size of the memory is determined at bind time. Of course, although this may be the defined semantics the implementation may differ; all such buffers may be writable by all processes, and some platforms may lack protection hardware. 4.3.2 Migrating model In <ref> [Bershad89] </ref> a migrating model for local RPC is described. In this model (also used by Spring [Hamilton93] and in some versions of Mach [Ford94]) the thread of control which makes the call in a client is transferred via the kernel and up-called into the server process. <p> On reception Wanda's performance relies on two aspects. One is a generalisation of a result noted in <ref> [Bershad89] </ref>, that RPC programmers tend to ensure that interfaces are such that arguments and results fit in a single Ethernet packet. Since Wanda machines are usually used for specific services the sizes of the buffers present in the system may be configured appropriately.
Reference: [Bershad91] <author> B.N. Bershad, T.E. Anderson, E.D. Lazowska, and H.M. Levy. </author> <title> User-Level Interprocess Communication for Shared Memory Multiprocessors. </title> <journal> ACM Transactions on Commputer Systems, </journal> <volume> 9(2) </volume> <pages> 175-198, </pages> <month> May </month> <year> 1991. </year> <title> (p 48) </title>
Reference-contexts: The client may then at some later date block on or poll for the indication from the server that the operation is complete. This model is recommended in <ref> [Bershad91] </ref> for multiprocessor machines. That work also notes that this model is superior when threads are provided at the user level (either over a non threaded or a kernel threaded base) due to the lower synchronisation costs.
Reference: [Birrell87] <author> A.D. Birrell and J.V. Guttag. </author> <title> Synchronization Primitives for a Multiprocessor: A formal specification. </title> <type> Technical Re 112 port 20, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <year> 1987. </year> <pages> (pp 37, 41) </pages>
Reference-contexts: may be overwritten at any time. 36 3.6 Concurrency primitives using events In contrast to many other systems where implementing one style of concurrency primitives over another set can be expensive [Birrell93, Fairbairns93] it is very efficient to implement many schemes over event counts. 3.6.1 SRC threads In SRC threads <ref> [Birrell87] </ref> concurrency is controlled by two primitives. These are mutexes and condition variables. A mutex is held for a short period of time to protect the examination of some state. A thread may then decide it needs to block while waiting for something to happen. <p> In general this is how thread packages are implemented in order to avoid race conditions where the underlying scheduling control primitives are to block oneself or wake a particular thread. Examples include user space Wanda semaphores over the Wanda scheduler system calls, SRC threads over the Taos system calls <ref> [Birrell87] </ref>, Posix threads implemented using Wanda threads [Fairbairns93], and SRC threads over Windows NT primitives [Birrell93].
Reference: [Birrell93] <author> A. Birrell. </author> <title> Taming the Windows NT (TM) Thread Primitives. </title> <institution> A presentation before the Systems Research Group of the University of Cambridge Computer Laboratory, </institution> <month> October </month> <year> 1993. </year> <pages> (pp 37, 41) </pages>
Reference-contexts: Only read and await should be used on incoming events as their value may be overwritten at any time. 36 3.6 Concurrency primitives using events In contrast to many other systems where implementing one style of concurrency primitives over another set can be expensive <ref> [Birrell93, Fairbairns93] </ref> it is very efficient to implement many schemes over event counts. 3.6.1 SRC threads In SRC threads [Birrell87] concurrency is controlled by two primitives. These are mutexes and condition variables. A mutex is held for a short period of time to protect the examination of some state. <p> Examples include user space Wanda semaphores over the Wanda scheduler system calls, SRC threads over the Taos system calls [Birrell87], Posix threads implemented using Wanda threads [Fairbairns93], and SRC threads over Windows NT primitives <ref> [Birrell93] </ref>.
Reference: [Birrell94] <author> A. Birrell, G. Nelson, S. Owicki, and E. Wobber. </author> <title> Network Objects. </title> <type> Technical Report 115, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <month> February </month> <year> 1994. </year> <title> (p 50) </title>
Reference-contexts: These problems would be eliminated if sharing semantics were adopted between client and server with memory being reclaimed by garbage collecting methods as is used in the Network Objects distributed system <ref> [Birrell94] </ref>. In such cases sharing of the memory is reasonable since if one trusts the server or client to be in the same process then it is reasonable to trust it to share correctly the information; in the remote case it is reasonable to trust the stubs.
Reference: [Black94a] <author> R. Black. </author> <title> FDL Cell formats and Meta-Signalling. In ATM Document Collection 3 (The Blue Book), </title> <type> chapter 5. </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> March </month> <year> 1994. </year> <title> (p 98) </title>
Reference-contexts: As described in section 6.1 the theoretical transfer rate is limited by the bus bandwidth rather than the line rate, so the best comparison is with the performance achieved for the identical MSSAR/FDL <ref> [Black94b, Black94a] </ref> protocol on Wanda using identical hardware. Two of the simple test programs on Wanda are a data sink and a data source.
Reference: [Black94b] <author> R. Black. </author> <title> Segmentation and Reassembly. In ATM Document Collection 3 (The Blue Book), </title> <type> chapter 3. </type> <institution> University of Cam-bridge Computer Laboratory, </institution> <month> March </month> <year> 1994. </year> <title> (p 98) </title>
Reference-contexts: As described in section 6.1 the theoretical transfer rate is limited by the bus bandwidth rather than the line rate, so the best comparison is with the performance achieved for the identical MSSAR/FDL <ref> [Black94b, Black94a] </ref> protocol on Wanda using identical hardware. Two of the simple test programs on Wanda are a data sink and a data source.
Reference: [Black94c] <author> R. Black and S. Crosby. </author> <title> Experience and Results from the Implementation of an ATM Socket Family. </title> <booktitle> In USENIX Winter 1994 Conference, </booktitle> <pages> pages 143-152, </pages> <month> January </month> <year> 1994. </year> <pages> (pp 6, 19) </pages>
Reference-contexts: A detailed discussion of multiplexing techniques and the advantages and disadvantages of ATM networks may be found in [McAuley90]. The author's experience of ATM includes the implementation of an ATM protocol stack within Unix <ref> [Black94c] </ref>. 2.1.2 Fairisle The Fairisle project (on which the author was employed for a period of a year before beginning research) has built a switch based ATM network for the local area [Leslie91, Black94d]. <p> This leads to performance loss due to the context switches (dispatching overhead and register file saves and loads) and reconfiguration of device interrupt masks. One discussion of this performance cost can be found in <ref> [Black94c] </ref>. A related cost is due to the effect of live-lock, where excessive data arriving can hinder the progress of requests already in the system. Live-lock in Unix has been reported in [Burrows88] and [Mogul].
Reference: [Black94d] <author> R.J. Black, I.M. Leslie, and D.R. McAuley. </author> <title> Experiences of building an ATM switch for the Local Area. </title> <journal> In Computer Communication Review, </journal> <volume> volume 24, </volume> <pages> pages 158-167. </pages> <publisher> ACM SIG-COMM, </publisher> <month> September </month> <year> 1994. </year> <pages> (pp 6, 19, 96) </pages>
Reference-contexts: The author's experience of ATM includes the implementation of an ATM protocol stack within Unix [Black94c]. 2.1.2 Fairisle The Fairisle project (on which the author was employed for a period of a year before beginning research) has built a switch based ATM network for the local area <ref> [Leslie91, Black94d] </ref>. Since this network was to be used to investigate the management of quality of service in a local area multi-service network, one of the key features of the design was flexibility and programmability. <p> Another problem with giving device interrupts priority over processes is that the interrupt dispatching overhead can consume substantial amounts of the CPU. An extreme example of this is the Fairisle port controller, reported in <ref> [Black94d] </ref>, where an ATM device generates an interrupt for every cell received. The overhead of the interrupt dispatching in the system is such that no process execution occurs once the system is approximately half loaded; the extra CPU resources being lost. <p> This reduces the concurrency overhead. To make comparison with the Wanda performance as realistic as possible the 95 device driver is as close as possible to the Wanda form whose performance is reported in <ref> [Black94d] </ref> (in particular the cell scheduling policy is the same; the FIFO queue for forwarded cells has priority over locally generated cells which in turn has priority over cells to be freed) with the following differences: * The special purpose bank of FIQ registers available to the low level Wanda interrupt
Reference: [Bosch94] <author> P. Bosch. </author> <title> A Cache Odyssey. </title> <type> Master's thesis, </type> <institution> University of Twente, Faculty of Computer Science, </institution> <month> June </month> <year> 1994. </year> <note> Also available as Pegasus report number 94-6. (p 18) </note>
Reference-contexts: These should be of lower priority than the disk read and network threads, whose scheduling is important for observed application jitter, but they must get some processing time otherwise the buffers in the system will become exhausted. This particular concern is examined thoroughly in <ref> [Bosch94] </ref>. In that work (concerned with conventional file I/O) the interruption of disk write requests by disk read requests is recommended. In addition writes are delayed altogether for as long as 1000 seconds or until the buffer cache becomes more than 25% dirty.
Reference: [Brackmo94] <author> L. Brackmo, S. O'Malley, and L. Peterson. </author> <title> TCP Vegas: New Techniques for Congestion Detection and Avoidance. </title> <journal> In Computer Communication Review, </journal> <volume> volume 24, </volume> <pages> pages 24-35. </pages> <publisher> ACM SIGCOMM, </publisher> <month> September </month> <year> 1994. </year> <title> (p 72) </title>
Reference-contexts: Third, the application may in fact be able to make better use of the resources in the network due to application specific knowledge, or by using advanced experimental code. Recent research <ref> [Brackmo94] </ref> shows that improving one's own responsiveness to network behaviour in order to improve ones own performance may in fact have a beneficial effect on others using the network. 5.2.2.2 Trailers Unlike headers, trailers do not usually contain any security information. They usually contain checksum information.
Reference: [Burrows88] <author> M. Burrows. </author> <title> Efficient Data Sharing. </title> <type> Technical Report 153, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> December </month> <year> 1988. </year> <pages> pages 30-31. </pages> <booktitle> Ph.D. Dissertation. </booktitle> <volume> (p 19) 113 </volume>
Reference-contexts: One discussion of this performance cost can be found in [Black94c]. A related cost is due to the effect of live-lock, where excessive data arriving can hinder the progress of requests already in the system. Live-lock in Unix has been reported in <ref> [Burrows88] </ref> and [Mogul]. This particular live-lock problem is now so severe with high performance network devices that some hardware [Rodeheffer94] includes special support which allows the device driver to disable high priority interrupts from the adaptor so that low priority protocol processing can be performed [Burrows94].
Reference: [Burrows94] <author> M. Burrows. </author> <title> The software of the OTTO ATM network inter-face. </title> <type> Personal Communication, </type> <month> October </month> <year> 1994. </year> <title> (p 19) </title>
Reference-contexts: This particular live-lock problem is now so severe with high performance network devices that some hardware [Rodeheffer94] includes special support which allows the device driver to disable high priority interrupts from the adaptor so that low priority protocol processing can be performed <ref> [Burrows94] </ref>. In effect the scheduling of the system has been moved from the scheduler into the device driver code, with the resultant potential for pathological interactions between multiple such device drivers.
Reference: [Cardelli89] <author> L. Cardelli, J. Donahue, L. Glassman, M. Jordan, B. Kalsow, and G. Nelson. </author> <type> Modula-3 Report (revised). Technical Report 52, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <month> November </month> <year> 1989. </year> <title> (p 44) </title>
Reference-contexts: Modula-3 <ref> [Cardelli89] </ref> was rejected due to lack of availability.
Reference: [Carter89] <author> J. Carter and W. Zwaenepoel. </author> <title> Optimistic bulk data transfer protocols. </title> <booktitle> Sigmetrics and Performance, </booktitle> <volume> 17(1) </volume> <pages> 61-69, </pages> <month> May </month> <year> 1989. </year> <title> (p 66) </title>
Reference-contexts: The IP (and UDP/TCP) headers are padded to fill a 48 byte ATM cell so that the user data remains cell-aligned. 5.1.4.2 Optimistic Blast The Optimistic Blast protocol <ref> [Carter89] </ref> tried to avoid data copying by assuming that the transmission medium is likely to be idle.
Reference: [Chen94] <author> J. Chen. </author> <title> Memory Behaviour of an X11 Window System. </title> <booktitle> In USENIX Winter 1994 Conference, </booktitle> <pages> pages 189-199, </pages> <month> January </month> <year> 1994. </year> <title> (p 90) </title>
Reference-contexts: A few researchers have observed performance problems due to cache conflicts in client-server environments although this is not a standard benchmark and therefore not greatly studied. For example, <ref> [Chen94] </ref> presents studies of X11 clients and server for the DECstation 5000/200 running Ultrix 4.2. This problem has tended to be regarded as soluble using shared libraries (which Ultrix lacks) and greater cache associativity.
Reference: [Coulson93] <author> G. Coulson, G. Blair, P. Robin, and D. Shepherd. </author> <title> Extending the Chorus Micro-kernel to support Continuous Media Applications. </title> <booktitle> In Proceedings of the 4th International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pages 49-60, </pages> <month> November </month> <year> 1993. </year> <title> (p 12) </title>
Reference-contexts: Nevertheless it is a seminal work in this field and forms the basis for the lowest levels of the Fawn system presented in this dissertation. 2.3 Related Scheduling Work 2.3.1 Sumo The Sumo project at Lancaster University <ref> [Coulson93] </ref> is addressing multimedia support by modifying the Chorus micro-kernel. This work has the advantage that Chorus already supports Unix applications through the provision of a Unix subsystem.
Reference: [Crosby94] <author> S. Crosby, R. Hayton, and T. Roscoe. </author> <title> MSRPC2 User Manual. In ATM Document Collection 3 (The Blue Book), </title> <type> chapter 16. </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> March </month> <year> 1994. </year> <title> (p 49) </title>
Reference-contexts: The marshalling is procedural and the stubs are generated per-transport so they can take advantage of the local data and call mechanisms. The data representation is based on that used in MSDR <ref> [Crosby94] </ref>. 4.4.2 Calling conventions The calling conventions for MiddlC interfaces are summarised in table 4.1. The C language only supports returning a single value directly so, for operations with more than one result, pointers to the variables to receive the results are passed as additional arguments.
Reference: [DEC91] <institution> Digital Equipment Corporation Workstation Systems Engineering. MAXine System Module Functional Specification Revision 1.2, </institution> <month> February </month> <year> 1991. </year> <title> (p 61) </title>
Reference-contexts: Furthermore, on many modern platforms, many devices (excepting the most expensive and higher bandwidth) are not able to interface well with wide memory busses <ref> [DEC91, DEC92] </ref> and so data is copied again in the device driver into a format which can be accessed by these devices. This means that data is potentially copied in software three times between user space and being acceptable to device hardware.
Reference: [DEC92] <institution> Digital Equipment Corporation Workstation Systems Engineering. Flamingo Macrocoder's Manual, </institution> <month> November </month> <year> 1992. </year> <title> (p 61) </title>
Reference-contexts: Furthermore, on many modern platforms, many devices (excepting the most expensive and higher bandwidth) are not able to interface well with wide memory busses <ref> [DEC91, DEC92] </ref> and so data is copied again in the device driver into a format which can be accessed by these devices. This means that data is potentially copied in software three times between user space and being acceptable to device hardware.
Reference: [DEC93] <institution> Digital Equipment Corporation TURBOchannel Industry Group. </institution> <note> TURBOchannel Specifications Version 3.0, 1993. (p 69) </note>
Reference-contexts: This property is assumed in the Fawn buffer mechanism derived below. On older hardware many devices which used DMA required a single non-interrupted access to a contiguous buffer. On more recent platforms such as the TUR-BOchannel <ref> [DEC93] </ref> the bus architecture requires that a device burst for some maximum period before relinquishing the bus. This is to prevent the cache and write buffer being starved of memory bandwidth and halting the CPU. Devices are expected to have enough internal buffering to weather such gaps.
Reference: [Dixon91] <author> M.J. Dixon. </author> <title> System Support for Multi-Service Traffic. </title> <type> Technical Report 245, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> September </month> <year> 1991. </year> <type> Ph.D. Dissertation. </type> <pages> (pp 9, 16, 17, 18, 62) </pages>
Reference-contexts: The principal distinguishing feature of this system is that it uses the MSNA suite of protocols as its only built-in means of communication (both intra- as well as inter-machine). The original design is presented in <ref> [Dixon91] </ref>, subsequently the networking code was re-written by the author in a similar methodology to the original as a requirement to support the Fairisle network. The I/O scheme of the Wanda micro-kernel is considered in detail in section 5.1.2. <p> as regular drop-outs are very perceptible to the human ear. 3.1.2 Priority in Wanda Using the Wanda system, Dixon found that jitter over a local area connection could be significantly reduced if the Wanda threads running at each end had a higher priority than any other thread in the system <ref> [Dixon91] </ref>. The improvement gained must be weighed against the cost crucial kernel housekeeping threads were no longer guaranteed to run, also the number of streams to which this technique can be applied is clearly limited. <p> enormous, assuming that these protocols could be implemented in this manner at all. 16 Whilst upcalls are a very efficient way of dispatching arriving data, the time for which such a call captures the CPU should be strictly curbed to ensure that effective control of CPU scheduling is not lost. <ref> [Dixon91] </ref> also notes that pervasive use of upcalls can have detrimental effects in certain environments. 3.1.3 Priority between Applications In [Nieh93] a comprehensive study is made of the effects of various scheduling schemes and parameters on a mixture of interactive, multimedia and batch applications. <p> This split solved the problem of high network load causing missed timer 17 interrupts but implementation of this dynamic priority change in timer handling necessitated an (interrupt) context switch. <ref> [Dixon91] </ref> reported that the cost of timer interrupts in the common case was 14s. 1 The cost of split timer interrupts is not reported but a likely estimate is double at 30s or 3% of the machine for his 1ms ticker. 2 Despite using the machine in single application mode it <p> Unfortunately the cost of this page flipping is frequently greater than the cost of the copy. This is especially the case on a machine with a virtually addressed cache or on a multiprocessor; <ref> [Dixon91] </ref> notes that coherence of TLBs in a multiprocessor is usually not addressed at all (unlike the concern for memory coherence), necessitating an inter-processor interrupt whenever page remapping takes place. <p> This can be a major performance penalty for such protocols. 5.1.2 Wanda Buffer management in Wanda picks up many attributes of the Unix system and some ideas from the Topaz system [Thacker87, Schroeder89]. Communication primitives in Wanda are discussed more fully in <ref> [Dixon91] </ref>. Wanda has a set of kernel managed buffers called IOBufs. Each IOBuf is of fixed size; various sized buffers are available. An IOBuf is some multiple of the page size of the machine. 3 Applications may acquire and free IOBufs.
Reference: [Druschel93] <author> P. Druschel and L. Peterson. Fbufs: </author> <title> A High-Bandwidth Cross--Domain Transfer Facility. </title> <booktitle> In Proceedings of the fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 189-202, </pages> <month> December </month> <year> 1993. </year> <title> (p 64) </title>
Reference-contexts: This is a similar problem to priority inversion. 5.1.3 Fbufs Fbufs <ref> [Druschel93] </ref> are another example of operating system research on buffer management. An Fbuf is a page of memory allocated from a reserved area of the virtual address space of the machine which is common across all processes. <p> Another potential optimisation is to declare Fbufs to be volatile; the process 5 This figure is based on a diagram in <ref> [Druschel93] </ref>. 64 which initially created the data retains write access to the Fbufs and so they may conceivably change whilst being read by a receiving process.
Reference: [Druschel94] <author> P. Druschel, L. Peterson, and B. Davie. </author> <title> Experiences with a High-Speed Network Adaptor: A Software Perspective. </title> <journal> In Computer Communication Review, </journal> <volume> volume 24, </volume> <pages> pages 2-13. </pages> <publisher> ACM SIGCOMM, </publisher> <month> September </month> <year> 1994. </year> <pages> (pp 65, 69) </pages>
Reference-contexts: Fbufs provide high performance access to buffer memory for network I/O as exemplified in <ref> [Druschel94] </ref>. However there are a number of disadvantages. First there is no resource control on the number of Fbufs a process may collect as a result of I/O activity. <p> course there are exceptions (e.g. [Greaves94]) but it is reasonable to optimise for the common cases. 7 If an application does not free memory when required within a reasonable length of time then the resource manager may simply kill it. 68 Examples of self-selecting interfaces include the Aurora TURBOchannel inter-face <ref> [Druschel94] </ref> and the Jetstream / Afterburner combination [Edwards94]. In Jetstream the arriving packets enter a special buffer memory based on the arriving VCI. The device driver then reads the headers and instructs a special DMA engine to copy the data to the final location.
Reference: [Edwards94] <author> A. Edwards, G. Watson, J. Lumley, D. Banks, C. Calamvokis, and C. Dalton. </author> <title> User-space protocols deliver high performance to applications on a low-cost Gb/s LAN. </title> <journal> In Computer Communication Review, </journal> <volume> volume 24, </volume> <pages> pages 14-23. </pages> <publisher> ACM SIGCOMM, </publisher> <month> September </month> <year> 1994. </year> <title> (p 69) </title>
Reference-contexts: it is reasonable to optimise for the common cases. 7 If an application does not free memory when required within a reasonable length of time then the resource manager may simply kill it. 68 Examples of self-selecting interfaces include the Aurora TURBOchannel inter-face [Druschel94] and the Jetstream / Afterburner combination <ref> [Edwards94] </ref>. In Jetstream the arriving packets enter a special buffer memory based on the arriving VCI. The device driver then reads the headers and instructs a special DMA engine to copy the data to the final location.
Reference: [Evers94a] <author> D. Evers. </author> <title> Nemesis Structure and Interfaces. Pegasus Project Internal Memorandum, </title> <month> August </month> <year> 1994. </year> <title> (p 101) </title>
Reference-contexts: There are also a number of further research topics which have been raised as a result of this work. 7.1 Operating System Development A large amount of the design presented has already been adopted by the programming team working on the Operating System work package of the Pegasus project <ref> [Evers94a] </ref>. It is hoped that within that context the following can be resolved. 7.1.1 Event value overflow The event system as described relies on monotonically increasing values in order to operate. On a 64-bit architecture (such as the Alpha) this can be easily implemented directly in a single machine word.
Reference: [Evers94b] <author> D.M. Evers. </author> <title> Distributed Computing with Objects. </title> <type> Technical Report 332, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> March </month> <year> 1994. </year> <type> Ph.D. Dissertation. </type> <pages> (pp 49, 53) </pages>
Reference-contexts: keeps a hint of the last process which has been the recipient of an event, and when re-allocating the CPU, it will favour that process if it has CPU allocation remaining in that jubilee. 4.4 IPC Operation 4.4.1 Architecture The architecture of the IPC system follows that of [ANSA89] and <ref> [Evers94b] </ref> and is connection oriented; clients must explicitly bind to servers before operations on interfaces can be invoked. Interface definitions are written in the MIDDL language [Roscoe94b]; the mapping onto the C language is known as MiddlC. <p> The object table returns an interface reference which the server may then publish. The call back is activated when a request from a client occurs. The call back function has the last word in vetting the client, and may create any per-binding state required 10 This name comes from <ref> [Evers94b] </ref>. 53 within the service. It returns the actual closure for the service to the object table which is subsequently used by the server side stubs. All the other work of setting up the IPC channel is done by the object table.
Reference: [Fairbairns93] <author> R. Fairbairns. </author> <title> Experience of implementing POSIX threads on Wanda. </title> <type> Personal communication, </type> <month> March </month> <year> 1993. </year> <pages> (pp 37, 41) </pages>
Reference-contexts: Only read and await should be used on incoming events as their value may be overwritten at any time. 36 3.6 Concurrency primitives using events In contrast to many other systems where implementing one style of concurrency primitives over another set can be expensive <ref> [Birrell93, Fairbairns93] </ref> it is very efficient to implement many schemes over event counts. 3.6.1 SRC threads In SRC threads [Birrell87] concurrency is controlled by two primitives. These are mutexes and condition variables. A mutex is held for a short period of time to protect the examination of some state. <p> Examples include user space Wanda semaphores over the Wanda scheduler system calls, SRC threads over the Taos system calls [Birrell87], Posix threads implemented using Wanda threads <ref> [Fairbairns93] </ref>, and SRC threads over Windows NT primitives [Birrell93].
Reference: [Ford94] <author> B. Ford and J. Lepreau. </author> <title> Evolving Mach 3.0 to a Migrating Thread Model. </title> <booktitle> In USENIX Winter 1994 Conference, </booktitle> <pages> pages 97-114, </pages> <month> January </month> <year> 1994. </year> <title> (p 47) </title>
Reference-contexts: In this model (also used by Spring [Hamilton93] and in some versions of Mach <ref> [Ford94] </ref>) the thread of control which makes the call in a client is transferred via the kernel and up-called into the server process. The client loses its thread until the server returns control.
Reference: [Forum93] <author> The ATM Forum. </author> <title> ATM user-network interface specification Version 3.0. </title> <publisher> Prentice Hall, </publisher> <year> 1993. </year> <title> (p 64) </title>
Reference-contexts: The other aspect is that for cell based networks, the use of the MSSAR protocol [McAuley90] allows the size of the packet to be determined from the header of the first cell; Wanda allocates an IOBuf of sufficient size. Recently, to support AAL5 <ref> [Forum93] </ref>, where this indication is not available, the Wanda MSNA implementation has been enhanced to allow an application to hint to a device driver the expected size of arriving packets. Like Unix, Wanda can experience live-lock problems if data is arriving faster than the application can consume the IOBufs.
Reference: [Fraser92] <author> A. Fraser, C. Kalmanek, A. Kaplan, E. Marshall, and R. Re-strick. </author> <title> Xunet 2: A Nationwide Testbed in High-Speed Networking. </title> <booktitle> In IEEE Infocomm, </booktitle> <pages> pages 582-589, </pages> <month> May </month> <year> 1992. </year> <title> (p 4) </title>
Reference-contexts: During this time Bell Labs has produced four ATM networks: Spider, Datakit, Incon and XUNET <ref> [Fraser92] </ref>. At Cambridge, the Computer Laboratory developed ATDM networks based on slotted rings beginning with the Cambridge Ring [Hopper78]. More recently the Fairisle project has developed a general topology switch based ATM network.
Reference: [Fraser93] <author> S. Fraser. </author> <title> Early Experiments with Asynchronous Time Division Networks. </title> <journal> IEEE Network, </journal> <volume> 7(1) </volume> <pages> 12-26, </pages> <month> January </month> <year> 1993. </year> <title> (p 4) </title>
Reference-contexts: research is considered at the point at which its relation to the equivalent systems proposed in this work is more directly assessable. 2.1 Networking Technology 2.1.1 Asynchronous Transfer Mode Asynchronous Transfer Mode (ATM), which was originally called Asynchronous Time Division Multiplexing (ATDM), has been in use for approximately 25 years <ref> [Fraser93] </ref> as a technique for integrating isochronous and bursty traffic in the same data network.
Reference: [Greaves94] <author> D. Greaves. </author> <title> The Olivetti Research "Yes V2" option module. In ATM Document Collection 3 (The Blue Book), </title> <type> chapter 33. </type> <institution> 115 University of Cambridge Computer Laboratory, </institution> <month> March </month> <year> 1994. </year> <title> (p 68) </title>
Reference-contexts: Otherwise the interface is usually of low bandwidth and requiring software copying of data (e.g. Ethernet); such interfaces are non self-selecting. Of course there are exceptions (e.g. <ref> [Greaves94] </ref>) but it is reasonable to optimise for the common cases. 7 If an application does not free memory when required within a reasonable length of time then the resource manager may simply kill it. 68 Examples of self-selecting interfaces include the Aurora TURBOchannel inter-face [Druschel94] and the Jetstream / Afterburner
Reference: [Hamilton93] <author> G. Hamilton and P. Kougiouris. </author> <title> The Spring nucleus: a mi-crokernel for objects. </title> <type> Technical Report SMLI TR-93-14, </type> <institution> Sun Microsystems Laboratories, </institution> <month> April </month> <year> 1993. </year> <note> Also in USENIX 93. (pp 47, 56) </note>
Reference-contexts: Of course, although this may be the defined semantics the implementation may differ; all such buffers may be writable by all processes, and some platforms may lack protection hardware. 4.3.2 Migrating model In [Bershad89] a migrating model for local RPC is described. In this model (also used by Spring <ref> [Hamilton93] </ref> and in some versions of Mach [Ford94]) the thread of control which makes the call in a client is transferred via the kernel and up-called into the server process. The client loses its thread until the server returns control. <p> All of these rely on the interface references for objects in the system being unguessable. This is because the system does not enforce any special mechanisms on the passing of interfaces between processes. This is in contrast to systems such as Spring <ref> [Hamilton93] </ref> where the passing of doors between processes requires special consideration on the part of the operating system kernel. Even if an unprivileged (chrooted) process had a proxy-binding service interposed between itself and the real binder this does not permit a solution.
Reference: [Hayter91] <author> M. Hayter and D. McAuley. </author> <title> The Desk Area Network. </title> <journal> ACM Operating Systems Review, </journal> <volume> 25(4) </volume> <pages> 14-21, </pages> <month> May </month> <year> 1991. </year> <note> Also available as University of Cambridge Computer Laboratory Technical Report number 228. (p 2) </note>
Reference-contexts: The observation that bus-based workstations (where data traversed the bus many times) were not ideal led to a prototype second generation multimedia workstation replacing the bus with an ATM based interconnect the Desk Area Network <ref> [Hayter91, Hayter93, Barham95] </ref>. Operating system support for continuous media streams has also been under investigation; the creation of the Pegasus project [Mullender92] was intended to develop such a system.
Reference: [Hayter93] <author> M. Hayter. </author> <title> A Workstation Architecture to Support Multimedia. </title> <type> Technical Report 319, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> September </month> <year> 1993. </year> <type> Ph.D. Dissertation. </type> <pages> (pp 2, 74) </pages>
Reference-contexts: The observation that bus-based workstations (where data traversed the bus many times) were not ideal led to a prototype second generation multimedia workstation replacing the bus with an ATM based interconnect the Desk Area Network <ref> [Hayter91, Hayter93, Barham95] </ref>. Operating system support for continuous media streams has also been under investigation; the creation of the Pegasus project [Mullender92] was intended to develop such a system. <p> A device driver process may have specific scheduling requirements in order to meet its quality of service contracts. In particular it is likely to require a non-blocking access method to I/O channels. 73 5.2.5 Streaming Memory In <ref> [Hayter93] </ref> the concept of a stream cache was defined. A stream cache is a special area of the cache on a system which is used directly for I/O without the data actually being represented in the underlying memory. It is particularly suited to the processing of multimedia streams.
Reference: [Hayter94a] <author> M. Hayter and R. Black. </author> <title> Fairisle Port Controller Design and Ideas. In ATM Document Collection 3 (The Blue Book), </title> <type> chapter 23. </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> March </month> <year> 1994. </year> <pages> (pp 8, 83) </pages>
Reference-contexts: Within the Wanda system this FIQ interrupt is never disabled and it interacts with Wanda using conventional interrupts. In this way the Fairisle hardware is presented as a virtual device. The full details of the operation of the Fairisle interface may be found in <ref> [Hayter94a, Hayter94b] </ref>. Since the port controller includes the standard I/O bus for the Arm chip set it is possible to inter-operate with other networks by plugging in the appropriate adaptor (e.g. Ethernet or CFR). <p> Third, to consider the suitability of Rbufs for I/O channel communication in an event based micro-kernel system. 6.1 Experimental Platform The experimental platform chosen was the ARM processor [ARM91, ARM92] and the Fairisle Port Controller version 3 <ref> [Hayter94a, Hayter94b] </ref>. This was due to the author's detailed knowledge of this hardware gained during the porting of the Wanda micro-kernel to this platform and the writing of the code for the Fairisle ATM switch.
Reference: [Hayter94b] <author> M. Hayter and R. Black. </author> <title> FPC3 Xilinx Xi5 Design and Notes. In ATM Document Collection 3 (The Blue Book), </title> <type> chapter 25. </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> March </month> <year> 1994. </year> <pages> (pp 8, 83) </pages>
Reference-contexts: Within the Wanda system this FIQ interrupt is never disabled and it interacts with Wanda using conventional interrupts. In this way the Fairisle hardware is presented as a virtual device. The full details of the operation of the Fairisle interface may be found in <ref> [Hayter94a, Hayter94b] </ref>. Since the port controller includes the standard I/O bus for the Arm chip set it is possible to inter-operate with other networks by plugging in the appropriate adaptor (e.g. Ethernet or CFR). <p> Third, to consider the suitability of Rbufs for I/O channel communication in an event based micro-kernel system. 6.1 Experimental Platform The experimental platform chosen was the ARM processor [ARM91, ARM92] and the Fairisle Port Controller version 3 <ref> [Hayter94a, Hayter94b] </ref>. This was due to the author's detailed knowledge of this hardware gained during the porting of the Wanda micro-kernel to this platform and the writing of the code for the Fairisle ATM switch.
Reference: [Hopper78] <author> A. Hopper. </author> <title> Local Area Computer Communication Networks. </title> <type> Technical Report 7, </type> <institution> University of Cambridge Computer Laboratory, </institution> <year> 1978. </year> <type> Ph.D. Dissertation. </type> <pages> (pp 4, 67) </pages>
Reference-contexts: During this time Bell Labs has produced four ATM networks: Spider, Datakit, Incon and XUNET [Fraser92]. At Cambridge, the Computer Laboratory developed ATDM networks based on slotted rings beginning with the Cambridge Ring <ref> [Hopper78] </ref>. More recently the Fairisle project has developed a general topology switch based ATM network. In Synchronous Transfer Mode (STM) information from multiple circuits is multiplexed together in a deterministic way into different time slots within a larger 4 frame. <p> This implementation suffers from a different problem which is that the bus latency caused by accessing the descriptors used to break the received packet up into the header and data components can cause the Ethernet chip to overrun. 5.1.4.4 The Cambridge Ring The Media Access Protocol on the Cambridge Ring <ref> [Hopper78] </ref> allows a receiver to indicate a Not Selected indication to a transmitter. This allows the construction of a very simple interface which can receive from only a single source at a time. The indication prevents the data being lost; the transmitter will retry that mini-packet.
Reference: [Hopper90] <author> A. Hopper. </author> <title> Pandora an experimental system for multimedia applications. </title> <journal> ACM Operating Systems Review, </journal> <volume> 24(2) </volume> <pages> 19-34, </pages> <month> April </month> <year> 1990. </year> <title> (p 2) </title>
Reference-contexts: Much of this has been practical with the implementation of the Pandora's Box <ref> [Hopper90] </ref>, a continuous media peripheral for a workstation. Such facilities are typically used in a distributed environment [Nicolaou90]. Storage and synchronisation services have been implemented for the Pandora system which used an early ATM network known as the Cambridge Fast Ring [Temple84].
Reference: [Hutchinson91] <author> N. Hutchinson and L. Peterson. </author> <title> The x-Kernel: An Architecture for Implementing Network Protocols. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(1) </volume> <pages> 64-75, </pages> <month> January </month> <year> 1991. </year> <title> (p 9) </title>
Reference-contexts: The I/O scheme of the Wanda micro-kernel is considered in detail in section 5.1.2. Other protocol families such as the internet protocol are provided through user space server processes, as is common on many micro-kernels. 2.2.2 The x-kernel The x-kernel <ref> [Hutchinson91] </ref> is a kernel that provides an explicit architecture for constructing and composing network protocols. A protocol is viewed as a specification of a communication abstraction through which a collection of participants exchange a set of messages. Three primitive objects are provided: protocols, sessions and messages.
Reference: [Hyden94] <author> E. Hyden. </author> <title> Operating System Support for Quality of Service. </title> <type> Technical Report 340, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> February </month> <year> 1994. </year> <type> Ph.D. Dissertation. </type> <pages> (pp 11, 20, 22) 116 </pages>
Reference-contexts: Nemesis system is currently under development at Cambridge; where it is referred to in this work the reader must understand that this refers to the situation at the time of writing (mid 1994); substantial changes in both design and implementation are likely in the future. 2.2.4 Nemo The Nemo system <ref> [Hyden94] </ref> was an early prototype of a system in the Pega-sus Architecture (and has been used as a starting platform for it). This work principally considered the inter-process scheduling required to promote Quality of Service. Hyden considers real-time problems in detail. <p> Of these assumptions, thread independence, constant period, and constant requirements, are considered inappropriate for a network based fluctuating service. Further consideration of the inappropriate application of hard real-time solutions to soft real time systems can be found in <ref> [Hyden94] </ref>. 3.1.7 Earliest Deadline First The EDF algorithm also presented in [Liu73] is a dynamic priority scheduling algorithm which also relies on the assumptions of section 3.1.6. <p> This section considers the lowest (kernel) level scheduling of processes. First it will be constructive to examine this process scheduling within the Nemo and early Nemesis 6 systems, considering some of the infelicities. 6 Mid 1994 3.2.1 Interprocess scheduling in Nemo In the architecture of <ref> [Hyden94] </ref>, system processes which have guaranteed access to the CPU do so by negotiating a certain amount of CPU time (called 7 a slice) in another larger timer period (called 7 an interval). <p> If the client and server have different intervals it is not clear exactly how the server's scheduling parameters should be altered. 7 <ref> [Hyden94] </ref> does not use this terminology; I introduce it here for clarity only. 22 3.2.2 Interprocess scheduling in Nemesis The mid 1994 version of the Nemesis system adopted a particular prototype of Nemo which used differing scheduling algorithms to those described above.
Reference: [ISO90] <institution> International Organisation for Standardization. </institution> <note> Programming languages - C, 1990. Draft international standard ISO/IEC DIS 9899 UDC 681.3.06 : 519.682 : 800.92. (p 44) </note>
Reference-contexts: The C language <ref> [ISO90] </ref> was adopted together with a portable exception mechanism using setjmp. 2 Without compiler support, the possibility of exceptions contributes a certain amount to the costs of service invocation. Their advantage is that they localise the blame for erroneous code; an exception will halt the thread if ignored.
Reference: [Jacobson93] <author> V. Jacobson. </author> <title> The Synchronisation of Periodic Routing Messages. </title> <journal> In Computer Communication Review. ACM SIG-COMM, </journal> <month> September </month> <year> 1993. </year> <title> (p 16) </title>
Reference-contexts: Furthermore in a general purpose operating system it is impossible to reconcile the claims of different competing user processes. Even 15 in a single user, single purpose system the strict use of priority is not always helpful. 3.1.1 Priority in the Internet In <ref> [Jacobson93] </ref> Jacobson reports on the effect of routers prioritising the processing of routeing updates over forwarding duties on the internet. The observation is that the probability of packet loss during this (periodic) processing is much higher. <p> It is important that a very high packet arrival rate does not delay the processing of routeing updates indefinitely. To avoid this, routers give the processing of routeing updates priority over data packet processing. The resultant gap in processing has been measured at over 300ms <ref> [Jacobson93] </ref> for a single router. The effect on a multimedia stream is made worse by the synchronisation of routeing updates which causes multiple routers to cease processing at the same time.
Reference: [Jardetzky92] <author> P.W. Jardetzky. </author> <title> Network File Server Design for Continuous Media. </title> <type> Technical Report 268, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> October </month> <year> 1992. </year> <type> Ph.D. Dissertation. </type> <pages> (pp 18, 63) </pages>
Reference-contexts: Another example of an application where priority caused problems is described in <ref> [Jardetzky92] </ref>. This application used a dedicated Wanda machine as a net-worked continuous media fileserver. Two problems were encountered in the design of this system. Firstly, the problem of selecting the priority for control threads (i.e. the threads handling out of band control via RPC). <p> Since Wanda machines are usually used for specific services the sizes of the buffers present in the system may be configured appropriately. For example, the Pandora video file server <ref> [Jardetzky92] </ref> configured the kernel to have many IOBufs of the 4 The "fat cell" packet format on the Ethernet uses 106 byte headers. 63 same size as video and audio segments.
Reference: [Johnson81] <author> M. Johnson. </author> <title> Exception handling in domain based systems. </title> <type> Technical Report 27, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> September </month> <year> 1981. </year> <type> Ph.D. Dissertation. (p 48) </type>
Reference-contexts: This problem of resource recovery is also found in equivalent capability based systems where services exist independently of processes and are invoked using "enter capabilities". A full discussion of the complex ramifications of this model may be found in <ref> [Johnson81] </ref>. Additionally, and particularly on a multiprocessor system, the cache contents on the migrating processor may be adversely affected.
Reference: [Jones93] <author> A. Jones and A. Hopper. </author> <title> Handling Audio and Video Streams in a Distributed Environment. </title> <booktitle> Proceedings of the fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 231-243, </pages> <month> December </month> <year> 1993. </year> <note> Also available as Olivetti Research Ltd. Technical Report number 93-4. (p 18) </note>
Reference-contexts: Theoretically such (short) sections of the device driver should also change their dynamic interrupt priority to avoid this problem. Although this is a peculiar device similar requirements do occasionally present themselves in the form of cache ECC errors and the like. 3 This list is abridged from <ref> [Jones93] </ref>. 18 * Outgoing data streams have priority over incoming ones. 4 * Commands have priority over audio which in turn has priority over video. * Newer data streams have priority over older ones. * Where a stream is being split (multicast) bottlenecks should not affect upstream nodes. 3.1.5 Priority in
Reference: [Larmouth75] <author> J. Larmouth. </author> <title> Scheduling for a Share of the Machine. </title> <journal> Software Practice and Experience, </journal> <volume> 5 </volume> <pages> 29-49, </pages> <month> January </month> <year> 1975. </year> <note> Also available as University of Cambridge Computer Laboratory Technical Report number 2, October 1974. (p 102) </note>
Reference-contexts: This process, known as the QoS manager, is a topic for further investigation. This system deliberately excludes a prototype for such a process since a static system is easier to analyse. One system for re-negotiation is to include deliberate inflation in the value of CPU resources <ref> [Larmouth75] </ref>. In this system the allocations of processes are regularly downgraded by small amounts. Processes would need to re-negotiate regularly based on observed loss of resource to maintain their allocation.
Reference: [Le*er84] <author> S. Le*er and M. Karels. Trailer Encapsulations. </author> <title> Internet Request for Comment Number 893, </title> <month> April </month> <year> 1984. </year> <title> (p 66) </title>
Reference-contexts: The general idea is that the device driver will arrange for the data to arrive in a manner that will reduce the cost of its presentation to the receiving user process. 65 5.1.4.1 IP Trailers The IP trailers <ref> [Le*er84] </ref> scheme found in some versions of BSD Unix used a set of special Ethernet type codes to indicate that the "headers" of the IP packet 6 had been placed at the end instead of at the start.
Reference: [Le*er89] <author> S. Le*er, M. McKusick, M. Karels, and J. Quarterman. </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year> <pages> (pp 17, 59) </pages>
Reference-contexts: A number of problems with priority scheduling in Wanda arose during this work. It was found necessary to split the clock interrupts into two separate pieces reminiscent of the hardclock versus softclock distinction in Unix <ref> [Le*er89] </ref>. The high priority interrupt (which can interrupt other device drivers) ensures that no time skew occurs. The lower priority interrupt is used to examine the scheduler data structures to determine if any threads need to be awoken. <p> In BSD derived Unix (specifically Ultrix) these are 512, 2048, 4096 and 8192 bytes respectively. For network activity, memory buffers are allocated using Mbufs <ref> [Le*er89] </ref>. Mbufs are a two level hierarchy of linked lists. One list is used to indicate a sequence of packets on some queue, the other to indicate a sequence of mbufs which store the data for one particular packet.
Reference: [Leslie83] <author> I. Leslie. </author> <title> Extending the Local Area Network. </title> <type> Technical Report 43, </type> <institution> University of Cambridge Computer Laboratory, </institution> <year> 1983. </year> <type> Ph.D. Dissertation. (p 5) </type>
Reference-contexts: It is the remapping tables in the switches along the route that represent the state for the circuit. The circuits carried by ATM networks are usually lightweight <ref> [Leslie83] </ref> which means that they do not have any hop by hop error control and may be disbanded by intermediate nodes at any time.
Reference: [Leslie91] <author> I. Leslie and D. McAuley. Fairisle: </author> <title> An ATM Network for the Local Area. </title> <journal> In Computer Communication Review, </journal> <volume> volume 21(4), </volume> <pages> pages 327-336. </pages> <publisher> ACM SIGCOMM, </publisher> <month> September </month> <year> 1991. </year> <pages> (pp 2, 6) </pages>
Reference-contexts: Such facilities are typically used in a distributed environment [Nicolaou90]. Storage and synchronisation services have been implemented for the Pandora system which used an early ATM network known as the Cambridge Fast Ring [Temple84]. The Fairisle project <ref> [Leslie91] </ref> was an investigation of switch based ATM networks. This project designed and constructed a test-bed switched ATM infrastructure in order to investigate the management and behaviour of real traffic streams. <p> The author's experience of ATM includes the implementation of an ATM protocol stack within Unix [Black94c]. 2.1.2 Fairisle The Fairisle project (on which the author was employed for a period of a year before beginning research) has built a switch based ATM network for the local area <ref> [Leslie91, Black94d] </ref>. Since this network was to be used to investigate the management of quality of service in a local area multi-service network, one of the key features of the design was flexibility and programmability.
Reference: [Liu73] <author> C.L. Liu and J. Layland. </author> <title> Scheduling Algorithms for Multipro--gramming in a hard Real-Time Environment. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20(1) </volume> <pages> 46-61, </pages> <month> January </month> <year> 1973. </year> <title> (p 20) </title>
Reference-contexts: That is, the device does not have priority over the computations of the system as a whole. 3.1.6 Periodicity As a result of these problems with priority many hard-real-time control systems use the Rate Monotonic algorithm presented in <ref> [Liu73] </ref>. This provides a method for scheduling a set of tasks based on a static priority calculated from their periods. <p> Of these assumptions, thread independence, constant period, and constant requirements, are considered inappropriate for a network based fluctuating service. Further consideration of the inappropriate application of hard real-time solutions to soft real time systems can be found in [Hyden94]. 3.1.7 Earliest Deadline First The EDF algorithm also presented in <ref> [Liu73] </ref> is a dynamic priority scheduling algorithm which also relies on the assumptions of section 3.1.6. The deadline of 5 Quoted directly from [Liu73]. 20 a task is considered to be the time at which the next request for that task will occur. <p> the inappropriate application of hard real-time solutions to soft real time systems can be found in [Hyden94]. 3.1.7 Earliest Deadline First The EDF algorithm also presented in <ref> [Liu73] </ref> is a dynamic priority scheduling algorithm which also relies on the assumptions of section 3.1.6. The deadline of 5 Quoted directly from [Liu73]. 20 a task is considered to be the time at which the next request for that task will occur. It is shown that this scheme will permit a feasible schedule where the CPU utilisation is less than or equal to 100%.
Reference: [McAuley90] <author> D.R. McAuley. </author> <title> Protocol Design for High Speed Networks. </title> <type> Technical Report 186, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> January </month> <year> 1990. </year> <type> Ph.D. Dissertation. </type> <pages> (pp 6, 9, 64) </pages>
Reference-contexts: A detailed discussion of multiplexing techniques and the advantages and disadvantages of ATM networks may be found in <ref> [McAuley90] </ref>. The author's experience of ATM includes the implementation of an ATM protocol stack within Unix [Black94c]. 2.1.2 Fairisle The Fairisle project (on which the author was employed for a period of a year before beginning research) has built a switch based ATM network for the local area [Leslie91, Black94d]. <p> The kernel implementation is multi-threaded and includes the virtual address system, the 3 A 3064 was used on earlier versions. 4 Mike Roe of the Computer Laboratory assisted in the original port to the Archimedes. 8 IPC system, device drivers, and the Multi-Service Network Architecture proto-col family <ref> [McAuley90] </ref>. The scheduler uses a static priority run-to-completion policy. Synchronisation uses counting semaphores which have separate implementations at user and kernel levels to aid performance. <p> The other aspect is that for cell based networks, the use of the MSSAR protocol <ref> [McAuley90] </ref> allows the size of the packet to be determined from the header of the first cell; Wanda allocates an IOBuf of sufficient size.
Reference: [McAuley94] <author> D. McAuley. </author> <title> The design of the ARX operating system. </title> <type> Personal communication, </type> <month> September </month> <year> 1994. </year> <title> (p 48) </title>
Reference-contexts: After careful consideration of this resource recovery problem, the designers of the ARX operating system <ref> [McAuley94] </ref> prohibited nested RPC by adding the constraint that no thread which had already made a migrating RPC call could make a further such call; equivalently replacing n kernel context switches with n 1 user ones.
Reference: [McCanne93] <author> S. McCanne and V. Jacobson. </author> <title> The BSD Packet Filter: A New Architecture for User-level Packet Capture. </title> <booktitle> In USENIX Winter 1993 Conference, </booktitle> <pages> pages 259-269, </pages> <month> January </month> <year> 1993. </year> <title> (p 69) </title>
Reference-contexts: It has been recent practice in operating systems to support a protocol independent scheme for determining the process for which packets arriving at an interface are destined. This is known as packet filtering [Mogul90] and this technology is now highly advanced <ref> [McCanne93, Yuhara94] </ref>. For non-self-selecting interfaces packet filtering can determine which I/O path the data will travel along as easily as it can determine which process will be the receiver. This property is assumed in the Fawn buffer mechanism derived below.
Reference: [Mills89] <author> D. Mills. </author> <title> Internet Time Synchronisation: The Network Time Protocol. Internet Request for Comment Number 1129, </title> <booktitle> Octo-ber 1989. (p 33) </booktitle>
Reference-contexts: mechanism. * There is no active notification of the fact that time is passing, a process must include regular checks to detect it. * The available time would be a wall clock time and would be subject to adjustments to keep it synchronised with other systems (e.g. by using NTP <ref> [Mills89] </ref>) rather than the time which is being used for local scheduling. Since adjustments may add as much as a 10% skew the locally based clock which is likely to be accurate with respect to instruction execution is more useful to many applications.
Reference: [Mogul] <author> J. Mogul. </author> <title> Livelock in Ultrix 4.2. </title> <type> Internal Technical Report, </type> <institution> Digital Equipment Corporation Western Research Laboratory. (p 19) </institution>
Reference-contexts: One discussion of this performance cost can be found in [Black94c]. A related cost is due to the effect of live-lock, where excessive data arriving can hinder the progress of requests already in the system. Live-lock in Unix has been reported in [Burrows88] and <ref> [Mogul] </ref>. This particular live-lock problem is now so severe with high performance network devices that some hardware [Rodeheffer94] includes special support which allows the device driver to disable high priority interrupts from the adaptor so that low priority protocol processing can be performed [Burrows94].
Reference: [Mogul90] <author> J. Mogul. </author> <title> Efficient Use of Workstations for Passive Monitoring of Local Area Networks. </title> <journal> In Computer Communication Review, </journal> <volume> volume 20. </volume> <booktitle> ACM SIGCOMM, </booktitle> <month> September </month> <year> 1990. </year> <title> (p 69) </title>
Reference-contexts: Knowledgeable applications may make special use of the buffer pools in the special memory. It has been recent practice in operating systems to support a protocol independent scheme for determining the process for which packets arriving at an interface are destined. This is known as packet filtering <ref> [Mogul90] </ref> and this technology is now highly advanced [McCanne93, Yuhara94]. For non-self-selecting interfaces packet filtering can determine which I/O path the data will travel along as easily as it can determine which process will be the receiver. This property is assumed in the Fawn buffer mechanism derived below.
Reference: [Moore94] <author> S. Moore. </author> <title> Multithreaded Processor Design. </title> <type> PhD thesis, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> October </month> <year> 1994. </year> <title> (p 105) </title>
Reference-contexts: In those systems, integrating applications into the kernel has been rarely attempted and when performed 2 requires substantial changes to the application code and / or adaptation layers. 2 Such as MSRPC2 in Wanda and NFS in Unix. 104 7.2.3 Micro-threaded processors The anaconda processor <ref> [Moore94] </ref> is a micro-threaded data-flow / control-flow hybrid. It uses interleaved execution of blocks of code known as micro-threads from different threads. A separate unit known as a matching store performs executability analysis based on availability of previous results.
Reference: [Mullender92] <author> S. Mullender, I. Leslie, and D. McAuley. </author> <title> Pegasus Project Description. </title> <type> Technical Report 92-1, </type> <institution> Pegasus Esprit Project, </institution> <month> September </month> <year> 1992. </year> <note> Also available as University of Cambridge Computer Laboratory Technical Report number 281. (pp 2, 10) </note>
Reference-contexts: Operating system support for continuous media streams has also been under investigation; the creation of the Pegasus project <ref> [Mullender92] </ref> was intended to develop such a system. <p> The x-kernel does, however, presume that all protocols are implemented in the kernel; recently support for device drivers external to the x-kernel has been added to allow the x-kernel to operate as a single Mach server. 2.2.3 Pegasus The Pegasus project <ref> [Mullender92, Mullender94] </ref> is a joint project funded by the European Community Esprit programme involving the University of Cam-bridge Computer Laboratory and the University of Twente Faculty of Computer Science.
Reference: [Mullender94] <author> S. Mullender, I. Leslie, and D. McAuley. </author> <title> Operating-System Support for Distributed Multimedia. </title> <booktitle> In USENIX Summer 1994 Conference, </booktitle> <month> July </month> <year> 1994. </year> <note> (p 10) 118 </note>
Reference-contexts: The x-kernel does, however, presume that all protocols are implemented in the kernel; recently support for device drivers external to the x-kernel has been added to allow the x-kernel to operate as a single Mach server. 2.2.3 Pegasus The Pegasus project <ref> [Mullender92, Mullender94] </ref> is a joint project funded by the European Community Esprit programme involving the University of Cam-bridge Computer Laboratory and the University of Twente Faculty of Computer Science.
Reference: [Nakamura93] <author> A. Nakamura. </author> <title> An investigation of real-time synchronisation. </title> <type> PhD thesis, </type> <institution> University of Cambridge Computer Laboratory, </institution> <year> 1993. </year> <title> (p 15) </title>
Reference-contexts: Simple priority schemes suffer from priority inversion, leading to the priority inheritance protocol, and the priority ceiling protocol [Sha87] which requires static analysis (the determination of the complete call graph at compile time). In fact Namakura argues <ref> [Nakamura93] </ref> that even more complex schemes are required, again requiring static analysis. Static analysis of code, however, is an operation which can only be applied to code with a static call graph. This is most untypical of all but the most esoteric of executives.
Reference: [Needham82] <author> R. Needham and A. Herbert. </author> <title> The Cambridge distributed computing system. </title> <booktitle> International computer science series. </booktitle> <publisher> Addison-Wesley (London), </publisher> <year> 1982. </year> <title> (p 57) </title>
Reference-contexts: A similar data structure was used for support of some atomic operations in the Cambridge File Server <ref> [Needham82] </ref>. Such a server can then send an event to inform the clients to change to the alternate root pointer. Clients acknowledge the change by using an event in the other direction, freeing the server to make subsequent updates. Such a mechanism may be most suitable for name servers.
Reference: [Newman89] <author> P. Newman. </author> <title> Fast Packet Switching for Integrated Services. </title> <type> Technical Report 165, </type> <institution> University of Cambridge Computer Laboratory, </institution> <year> 1989. </year> <type> Ph.D. Dissertation. (p 6) </type>
Reference-contexts: This is shown in figure 2.1. The switch is input buffered. The switch fabrics are available as 4 by 4, 8 by 8, or 16 by 16. These are made up of self routeing round-robin priority 4 by 4 crossbar elements based on the design presented in <ref> [Newman89] </ref> and implemented on a Xilinx 3064. The 16 2 Also known as line cards. 6 by 16 fabric uses 8 of these elements arranged in a delta network using two interconnected PCBs.
Reference: [Nicolaou90] <author> C. Nicolaou. </author> <title> A Distributed Architecture for Multimedia Communication Systems. </title> <type> Technical Report 220, </type> <institution> University of Cam-bridge Computer Laboratory, </institution> <month> December </month> <year> 1990. </year> <type> Ph.D. Dissertation. (p 2) </type>
Reference-contexts: Much of this has been practical with the implementation of the Pandora's Box [Hopper90], a continuous media peripheral for a workstation. Such facilities are typically used in a distributed environment <ref> [Nicolaou90] </ref>. Storage and synchronisation services have been implemented for the Pandora system which used an early ATM network known as the Cambridge Fast Ring [Temple84]. The Fairisle project [Leslie91] was an investigation of switch based ATM networks.
Reference: [Nieh93] <author> J. Nieh, J. Hanko, J. Northcutt, and G. Wall. </author> <title> SVR4 UNIX Scheduler Unacceptable for Multimedia Applications. </title> <booktitle> In Proceedings of the 4th International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pages 35-47, </pages> <month> November </month> <year> 1993. </year> <title> (p 17) </title>
Reference-contexts: way of dispatching arriving data, the time for which such a call captures the CPU should be strictly curbed to ensure that effective control of CPU scheduling is not lost. [Dixon91] also notes that pervasive use of upcalls can have detrimental effects in certain environments. 3.1.3 Priority between Applications In <ref> [Nieh93] </ref> a comprehensive study is made of the effects of various scheduling schemes and parameters on a mixture of interactive, multimedia and batch applications. This work was performed on Solaris 2.2 (an SVR4 Unix). <p> Further, the use of the "real time" priority based scheduler did not lead to any acceptable solution. This is a direct quotation from <ref> [Nieh93] </ref>: Note that the existence of the strict-priority real-time scheduling class in standard SVR4 in no way allows a user to effectively deal with these types of problems.
Reference: [Oikawa93] <author> S. Oikawa and H. Tokuda. </author> <title> User-Level Real-Time Threads: An Approach Towards High Performance Multimedia Threads. </title> <booktitle> In Proceedings of the 4th International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pages 61-71, </pages> <month> November </month> <year> 1993. </year> <title> (p 13) </title>
Reference-contexts: A scheme to compromise between the driver's requirement always to have buffers available and minimising the need to copy is being researched. 2.3.2 Meta-Level Scheduler A variant on the idea of the split level scheduler is proposed in <ref> [Oikawa93] </ref>. In that system a layer known as a Meta-Level Scheduler (MLS) is inserted between kernel functionality and the processes. This layer consists of a page of memory for each process which is used by that process to store its intra-process scheduling requirements.
Reference: [O'Malley90] <author> S. O'Malley, M. Abbott, N. Hutchinson, and L. Peterson. </author> <title> A Transparent Blast Facility. Internetworking: </title> <journal> Research and Experience, </journal> <volume> 1(2) </volume> <pages> 57-75, </pages> <month> December </month> <year> 1990. </year> <title> (p 67) </title>
Reference-contexts: example, this would allow a rogue process on one machine to deliberately attempt to cause burst transfers when a message from a fileserver was expected, in order to gain unauthorised access to data for other processes on that machine. 5.1.4.3 Transparent Blast An improved transparent blast protocol was proposed in <ref> [O'Malley90] </ref>. In this scheme a control packet is sent in advance of the blast. This contains enough information to allow the receiver to reprogram the interface chip in order to put the blast data in the correct place.
Reference: [O'Malley94] <author> S. O'Malley, T. Proebstring, and A. Montz. </author> <title> USC: A Universal Stub Compiler. </title> <journal> In Computer Communication Review, </journal> <volume> volume 24, </volume> <pages> pages 295-306. </pages> <publisher> ACM SIGCOMM, </publisher> <month> September </month> <year> 1994. </year> <title> (p 106) </title>
Reference-contexts: As a result use of types whose size is dependent on the natural sizes of various constructs on a particular platform can be difficult. One possible alternative is a generic stub compiler such as USC <ref> [O'Malley94] </ref> which can interconvert easily in a heterogeneous environment. 7.4 Desk Area Network Within the Desk Area Network operating system project, one of the concerns has been to consider operating system scheduling of the ATM interconnect resources.
Reference: [Owicki89] <author> S. Owicki. </author> <title> Experience with the Firefly Multiprocessor Workstation. </title> <type> Technical Report 51, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <month> September </month> <year> 1989. </year> <note> (p 49) 119 </note>
Reference-contexts: Various examples 48 of similar performance improvements on a multiprocessor machine may be found in <ref> [Owicki89] </ref>. The switching model is used in Fawn.
Reference: [Pike91] <author> R. Pike, D. Presotto, K. Thomson, H. Trickey, T. Duff, and G. Holzmann. </author> <note> Plan 9: The Early Papers. Computing Science Technical Report 158, </note> <institution> AT&T Laboratories, </institution> <month> July </month> <year> 1991. </year> <title> (p 55) </title>
Reference-contexts: Various traders may be mounted at various points in the name space of the process as the process sees fit. This is similar to Plan 9 from Bell Labs <ref> [Pike91] </ref>. 13 Merging of file names provided by separate traders within a single directory (as provided in Plan 9) may be implemented using a proxy trader. 12 Another example is the instantiation muddle in the Unix packet filter code, where the special device open function modifies the minor device number of
Reference: [Pratt94a] <author> I. Pratt. </author> <title> Hardware Support for Operating System Support for Continuous Media. </title> <institution> University of Cambridge Computer Laboratory Ph.D. Research Proposal, </institution> <month> July </month> <year> 1994. </year> <pages> (pp 90, 106) </pages>
Reference-contexts: This study, having both shared libraries and a highly associative cache, shows that further considerations may be necessary. One possibility is to relax the alignment requirements. Another, more interesting approach, of providing Quality of Service support in the cache implementation is proposed in <ref> [Pratt94a] </ref>. Further consideration of this issue is beyond the scope of this dissertation. 6.2.3 Same machine RPC This experiment attempts to measure the cost of invoking a service in another process on the same machine. A testing interface includes an operation called ping which provides a null-RPC service. <p> This concept is taken further and generalised in Pratt's cache system <ref> [Pratt94a] </ref> where cache allocation may be process specific. In such an environment, the Rbuf data area may in fact represent an area of cache rather than an area of memory.
Reference: [Pratt94b] <author> I. Pratt. </author> <title> Internet Connectivity on the Desk Area Network. </title> <type> Personal communication, </type> <month> April </month> <year> 1994. </year> <title> (p 66) </title>
Reference-contexts: This would have avoided the implementation costs in many receivers for whom the trailers protocol was no benefit in any case. This padding scheme is to be used in the network interface for the Desk Area Network <ref> [Pratt94b] </ref> where an internal message may need to be converted into an external IP datagram.
Reference: [Pratt94c] <author> I. Pratt and P. Barham. </author> <title> The ATM Camera V2: AVA200. In ATM Document Collection 3 (The Blue Book), </title> <type> chapter 36. </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> March </month> <year> 1994. </year> <title> (p 73) </title>
Reference-contexts: This may be found in multimedia streams such as audio over ATM, and compressed tiled video <ref> [Pratt94c] </ref>.
Reference: [Reed77] <author> D. Reed and R. Kanodia. </author> <title> Synchronization with eventcounts and sequencers. </title> <type> Technical Report, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1977. </year> <pages> (pp 27, 35) </pages>
Reference-contexts: The recipient has a copy of the event whose value will be updated some time later by the kernel. The relationship between these events and event counts and sequencers <ref> [Reed77] </ref> is discussed in section 3.5 below. This propagation is called an event channel. For each process, the kernel has a protected table of the destinations of the event channels originating at that process. <p> The functions which are provided by the intra-process scheduler are known as the process methods. The interface that was adopted within processes was to extend the use of events already present for interprocess communication, and provide primitives similar to <ref> [Reed77] </ref> namely event counts and sequencers. The events which are used in this way are entirely local to the domain and so are called local events.
Reference: [Rodeheffer94] <author> T. Rodeheffer. </author> <title> The hardware of the OTTO ATM network interface. </title> <type> Personal Communication, </type> <month> January </month> <year> 1994. </year> <title> (p 19) </title>
Reference-contexts: Live-lock in Unix has been reported in [Burrows88] and [Mogul]. This particular live-lock problem is now so severe with high performance network devices that some hardware <ref> [Rodeheffer94] </ref> includes special support which allows the device driver to disable high priority interrupts from the adaptor so that low priority protocol processing can be performed [Burrows94].
Reference: [Roscoe94a] <author> T. Roscoe. </author> <title> Linkage in the Nemesis Single Address Space Operating System. </title> <journal> ACM Operating Systems Review, </journal> <volume> 28(4) </volume> <pages> 48-55, </pages> <month> October </month> <year> 1994. </year> <title> (p 45) </title>
Reference-contexts: Other examples of such functions are ones which create closures for subsequent use. For these stateless functions location in a shared library with early binding (i.e. direct linking with the textual name) is used in Fawn rather than the later binding of <ref> [Roscoe94a] </ref>. A closure is a pair of pointers. One of these pointers points to a table of methods, the other points to the state record on which these methods operate. The state record may contain any private or public state including other closures. [Roscoe94a] gives a full discussion of the use <p> Fawn rather than the later binding of <ref> [Roscoe94a] </ref>. A closure is a pair of pointers. One of these pointers points to a table of methods, the other points to the state record on which these methods operate. The state record may contain any private or public state including other closures. [Roscoe94a] gives a full discussion of the use of closures and shared library modules within the Nemesis operating system. Within the Fawn system a slightly different scheme was used.
Reference: [Roscoe94b] <author> T. Roscoe. </author> <note> The MIDDL Manual, 3rd Edition. available by anonymous ftp from ftp.cl.cam.ac.uk in pegasus/Middl.ps.gz, January 1994. now superseded by the 4th edition. (p 49) </note>
Reference-contexts: Interface definitions are written in the MIDDL language <ref> [Roscoe94b] </ref>; the mapping onto the C language is known as MiddlC. Stubs are generated automatically by a stub compiler 8 whose back end is written in python, making for a quick prototyping language.
Reference: [Saltzer78] <author> J.H. Saltzer. </author> <title> Naming and Binding of Objects, </title> <booktitle> chapter 3A, </booktitle> <pages> pages 99-208. </pages> <booktitle> Number 60 in Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1978. </year> <pages> (pp 15, 43, 45) </pages>
Reference-contexts: Static analysis of code, however, is an operation which can only be applied to code with a static call graph. This is most untypical of all but the most esoteric of executives. In a system using dynamic binding of services, closures <ref> [Saltzer78] </ref> for library routines, and especially RPC (even if restricted to same machine), it simply cannot be applied. Furthermore in a general purpose operating system it is impossible to reconcile the claims of different competing user processes. <p> As a result the sharing of code, and the invocation of services in different processes are both highly relevant. This chapter considers these issues. The system makes considerable use of closures <ref> [Saltzer78] </ref> to access state rather than addresses built into the code. This allows for sharing of code. Inter-process communication uses shared memory for data and events for signalling. <p> A shared library is defined as one consisting of pure code, i.e. it contains exclusively (read-only) fully-resolved text segment or fully-resolved references to other shared libraries. All state manipulated by the library (even if opaque to the client) is passed into functions using closures <ref> [Saltzer78] </ref> except the closure for process and thread specific functions as described in section 3.5. Some library routines may operate entirely without state and have well known names (such as strlen). Other examples of such functions are ones which create closures for subsequent use.
Reference: [Schroeder89] <author> M. Schroeder and M. Burrows. </author> <title> Performance of Firefly RPC. </title> <type> Technical Report 43, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <month> April </month> <year> 1989. </year> <title> (p 62) </title>
Reference-contexts: This can be a major performance penalty for such protocols. 5.1.2 Wanda Buffer management in Wanda picks up many attributes of the Unix system and some ideas from the Topaz system <ref> [Thacker87, Schroeder89] </ref>. Communication primitives in Wanda are discussed more fully in [Dixon91]. Wanda has a set of kernel managed buffers called IOBufs. Each IOBuf is of fixed size; various sized buffers are available.
Reference: [Sha87] <author> L. Sha, R. Rajkumar, and J.P. Lehoczky. </author> <title> Priority Inheritance Protocols. </title> <type> Technical Report CMU-CS-87-181, </type> <institution> Carnegie Mellon Computer Science Department, </institution> <month> December </month> <year> 1987. </year> <note> (p 15) 120 </note>
Reference-contexts: Finally the intra-process synchronisation mechanisms are described. 3.1 Priority First, note that a simple priority scheme is rarely sufficient. Simple priority schemes suffer from priority inversion, leading to the priority inheritance protocol, and the priority ceiling protocol <ref> [Sha87] </ref> which requires static analysis (the determination of the complete call graph at compile time). In fact Namakura argues [Nakamura93] that even more complex schemes are required, again requiring static analysis.
Reference: [Shand92] <author> M. Shand. </author> <title> Measuring System Performance with Repro--grammable Hardware. </title> <type> Technical Report 19, </type> <institution> Digital Equipment Corporation Paris Research Laboratory, </institution> <month> August </month> <year> 1992. </year> <title> (p 87) </title>
Reference-contexts: In comparison, for a more powerful DECstation 5000/200, 3 <ref> [Shand92] </ref> measures the interrupt latency to a kernel device driver on Ultrix 4.2A to be usually between 14s and 21s.
Reference: [Sreenan93] <author> C.J. Sreenan. </author> <title> Synchronisation services for digital continuous media. </title> <type> Technical Report 292, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> March </month> <year> 1993. </year> <type> Ph.D. Dissertation. </type> <pages> (pp 17, 75) </pages>
Reference-contexts: Their solution was to develop a new timesharing class which allocates the CPU more fairly and attempts to ensure that all runnable processes do make steady progress. 3.1.4 Priority within Applications In <ref> [Sreenan93] </ref> Wanda is used as a platform for implementing a local area syn-chronisation service. A number of problems with priority scheduling in Wanda arose during this work. It was found necessary to split the clock interrupts into two separate pieces reminiscent of the hardclock versus softclock distinction in Unix [Le*er89]. <p> This padding could be used on some channels where appropriate to carry additional information. For example the exact time at which the packet arrived or partial checksum information if this is computed by the hardware. <ref> [Sreenan93] </ref> points out that sometimes it is more important to know exactly when something happened than actually getting to process it immediately. 75 5.3.1.3 Control Areas A control area is a circular buffer used in a producer / consumer arrangement.
Reference: [Stroustrup91] <author> B. Stroustrup. </author> <title> The C++ programming language. </title> <publisher> Addison-Wesley, </publisher> <address> second edition, </address> <year> 1991. </year> <title> (p 44) </title>
Reference-contexts: supported is extremely limited, it did not support the platform intended for practical work, and showed no signs of being more available in the future the most recent port took three years despite the authors of the language working for the company producing the new hardware. 1 The C++ language <ref> [Stroustrup91] </ref> was rejected due to problems with the stability of the g++ compiler, and the tendency for the language to hide the performance and memory costs of the underlying operations.
Reference: [Sun94] <author> Re: </author> <title> Sun's Sparc technology business discloses next-generation processor. USENET News article in comp.arch Message-ID: </title> <editor> &lt;35ppf8$bf2@engnews2.Eng.Sun.COM&gt; from M. Tremblay (tremblay@flayout.Eng.Sun.COM), </editor> <month> September </month> <year> 1994. </year> <title> (p 47) </title>
Reference-contexts: Second, the server may not use the upcall solely 7 102 in the kernel and 21 in user space, however this cost does not include the delayed effect of register window traps estimated at 300 cycles each in <ref> [Sun94] </ref>. 47 for performing work for that client; the implicit billing may be highly inaccu-rate. As was noted earlier the use of upcalls can lead to loss of control over and accountability of scheduling.
Reference: [Tanenbaum81] <author> A. Tanenbaum and S. Mullender. </author> <title> An Overview of the Amoeba Distributed Operating System. </title> <journal> ACM Operating Systems Review, </journal> <volume> 15(3) </volume> <pages> 51-64, </pages> <month> July </month> <year> 1981. </year> <title> (p 8) </title>
Reference-contexts: Ethernet or CFR). The Fairisle port controller was used as the experimental platform for the work described in this dissertation and further discussions of its features occur throughout the text. 2.2 Operating System Research 2.2.1 Wanda The Wanda micro-kernel (loosely derived from Amoeba <ref> [Tanenbaum81] </ref>) is a locally developed operating system designed as an aid to networking, multimedia and operating system research. It has been implemented on both uni- and multiprocessors including the VAX Firefly, the 68000, Arm and MIPS R3000.
Reference: [Temple84] <author> S. </author> <title> Temple. The Design of a Ring Communication Network. </title> <type> Technical Report 52, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> January </month> <year> 1984. </year> <type> Ph.D. Dissertation. </type> <pages> (pp 2, 67) </pages>
Reference-contexts: Such facilities are typically used in a distributed environment [Nicolaou90]. Storage and synchronisation services have been implemented for the Pandora system which used an early ATM network known as the Cambridge Fast Ring <ref> [Temple84] </ref>. The Fairisle project [Leslie91] was an investigation of switch based ATM networks. This project designed and constructed a test-bed switched ATM infrastructure in order to investigate the management and behaviour of real traffic streams. <p> This allows the construction of a very simple interface which can receive from only a single source at a time. The indication prevents the data being lost; the transmitter will retry that mini-packet. This corresponds to explicit support for blast protocols in the hardware. The Cambridge Fast Ring <ref> [Temple84] </ref> supported a similar selection and channel mode where bandwidth was reserved for the duration of the burst. 67 5.1.4.5 Discussion In general, attempts to date to make an efficient implementation of Application Data Units have failed.
Reference: [Thacker87] <author> C. Thacker, L. Stewart, and E. Satterthwaite. Firefly: </author> <title> A Multiprocessor Workstation. </title> <type> Technical Report 23, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <month> December </month> <year> 1987. </year> <title> (p 62) </title>
Reference-contexts: This can be a major performance penalty for such protocols. 5.1.2 Wanda Buffer management in Wanda picks up many attributes of the Unix system and some ideas from the Topaz system <ref> [Thacker87, Schroeder89] </ref>. Communication primitives in Wanda are discussed more fully in [Dixon91]. Wanda has a set of kernel managed buffers called IOBufs. Each IOBuf is of fixed size; various sized buffers are available.
Reference: [Trickey93] <author> H. Trickey. </author> <title> Internals of Plan 9 Naming. </title> <type> Personal Communication, </type> <month> September </month> <year> 1993. </year> <title> (p 55) </title>
Reference-contexts: This leads to an inability to export a configured name space from one process to another; their system relies on a per-user configured name space generated from the .profile file. This is likely to be addressed in a forthcoming system named Brazil <ref> [Trickey93] </ref>. 55 4.4.9 Restriction of Name Space In some systems it can be the case that the owner of a process may wish at the time of its creation to restrict the name space which is visible to that process. In Unix this is known as the chroot operation.
Reference: [Yuhara94] <author> M. Yuhara, C. Maeda, B. Bershad, and J. Moss. </author> <title> The MACH Packet Filter: Efficient Packet Demultiplexing for Multiple Endpoints and Large Messages. </title> <booktitle> In USENIX Winter 1994 Conference, </booktitle> <pages> pages 153-165, </pages> <month> January </month> <year> 1994. </year> <note> (p 69) 121 </note>
Reference-contexts: It has been recent practice in operating systems to support a protocol independent scheme for determining the process for which packets arriving at an interface are destined. This is known as packet filtering [Mogul90] and this technology is now highly advanced <ref> [McCanne93, Yuhara94] </ref>. For non-self-selecting interfaces packet filtering can determine which I/O path the data will travel along as easily as it can determine which process will be the receiver. This property is assumed in the Fawn buffer mechanism derived below.
References-found: 96

