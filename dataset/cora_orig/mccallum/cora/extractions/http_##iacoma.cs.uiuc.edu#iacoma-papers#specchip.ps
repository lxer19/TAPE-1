URL: http://iacoma.cs.uiuc.edu/iacoma-papers/specchip.ps
Refering-URL: http://iacoma.cs.uiuc.edu/papers.html
Root-URL: http://www.cs.uiuc.edu
Email: venkat,torrella@cs.uiuc.edu  
Title: Hardware and Software Support for Speculative Execution of Sequential Binaries on a Chip-Multiprocessor 1  
Author: Venkata Krishnan and Josep Torrellas 
Web: http://iacoma.cs.uiuc.edu  
Address: IL 61801  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign,  
Abstract: Chip-multiprocessors (CMP) are a promising approach for exploiting the increasing transistor count on a chip. To allow sequential applications to be executed on this architecture, current proposals incorporate hardware support to exploit speculative parallelism. However, these proposals either require re-compilation of the source program or use substantial hardware that tailors the architecture for speculative execution, thereby resulting in wasted resources when running parallel applications. In this paper, we present a CMP architecture that has hardware and software support for speculative execution of sequential binaries without the need for source re-compilation. The software support enables identification of threads from sequential binaries, while a modest amount of hardware allows register-level communication and enforces true inter-thread memory dependences. We evaluate this architecture and show that it is able to deliver high performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Breach, T. N. Vijaykumar, and G. Sohi. </author> <title> The Anatomy of the Register File in a Multiscalar Processor. </title> <booktitle> In 27th International Symposium on Microarchitecture (MICRO-27), </booktitle> <pages> pages 181-190, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Register values are forwarded from one processor to another with the aid of a ring structure, while recovery from mis-speculation is achieved by maintaining two copies of the registers, along with a set of register masks, in each processing unit <ref> [1] </ref>. Overall, both of these processors have sufficient hardware support that tailors the architecture for speculative execution, thereby enabling them to achieve high performance on existing sequential binaries without the need for re-compilation. <p> We could allow the values to be stored, by using a buffered communication mechanism, rather than using a simple broadcast bus. However, this would require further hardware support in the form of duplicate register sets in each processor to enable recovery from squashes <ref> [1] </ref>. Alternatively, a global register set may be maintained to store the values [9], but at the cost of maintaining a centralized structure. In our approach, we add minimal hardware to support the consumer-initiated form of communication.
Reference: [2] <author> M. Franklin and G. Sohi. ARB: </author> <title> A Hardware Mechanism for Dynamic Memory Disambiguation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 45(5) </volume> <pages> 552-571, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: It must also identify dependence violations that may occur when a speculative thread prematurely accesses a memory location. This would result in the squashing of the violating thread along with its successors. The hardware that is required may be a centralized buffer along the lines of the ARB <ref> [2] </ref>. Alternatively, it may involve a decentralized design, where each processor's primary cache is used to store the speculative data, along with enhancements to the cache coherence protocol to maintain data consistency. We use the latter approach for our hardware.
Reference: [3] <author> S. Gopal, T. N. Vijaykumar, J. Smith, and G. Sohi. </author> <title> Speculative Versioning Cache. </title> <booktitle> In 4th International Symposium on High-Performance Computer Architecture, </booktitle> <pages> pages 195-205, </pages> <month> February </month> <year> 1998. </year>
Reference-contexts: We use the latter approach for our hardware. There has been work done concurrently with ours, such as the Speculative Versioning Cache (SVC) <ref> [3] </ref>, which makes use of a snoopy-bus to maintain data consistency among different processors. Our work differs from SVC in that we use a decentralized approach similar to a directory-based protocol. We call our approach the Memory Disambiguation Table (MDT) (Section 3.2).
Reference: [4] <author> V. Krishnan. </author> <title> A Multithreaded Architecture for Enhancing the Performance of Sequential and Parallel Applications. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> May </month> <year> 1998. </year>
Reference-contexts: Finally, the private X bit is used to avoid the undesirable state where all copies of the register become invalid. This could have occurred when there is a delay in the consumer thread requesting the value. More details may be found in <ref> [4] </ref>. Overall, the extra overhead per register is 3n bits, where n is the number of processors on chip. <p> Maintaining these bits on a cache-line level sometimes results in false sharing and, consequently, leads to unwanted squashing of threads. So, we maintain information at a word level, except the Dirty bit, which is maintained at the line level. More details of the protocol may be found in <ref> [4] </ref>. 3.2.1 Memory Disambiguation Table (MDT) The disambiguating mechanism is performed with the help of the MDT. The MDT maintains entries on a cache line basis. As with the cache lines, we maintain the information on a word basis.
Reference: [5] <author> A. Moshovos, S. Breach, T. N. Vijaykumar, and G. Sohi. </author> <title> Dynamic Speculation and Synchronization of Data Dependences. </title> <booktitle> In 24th International Symposium on Computer Architecture, </booktitle> <pages> pages 181-193, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Overall, the additional overhead added to each cache line is modest. The coherence protocol is similar to a conventional directory-based scheme with sub-blocks. Finally, having a separate dependence-tracking module (MDT) leaves room for further improvements, such as memory dependence prediction <ref> [5] </ref>, thereby disallowing premature loads from occurring. 4 Evaluation Environment For our representative CMP, we consider a chip with four 4-issue dynamic superscalar processors (4x4-issue). This CMP, with hardware support for speculation, is compared to conventional 12-issue and 16-issue dynamic superscalar processors.
Reference: [6] <author> K. Olukotun, B. Nayfeh, L. Hammond, K. Wilson, and K. Chang. </author> <title> The Case for a Single-Chip Multiprocessor. </title> <booktitle> In 7th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 2-11, </pages> <month> Oc-tober </month> <year> 1996. </year>
Reference-contexts: A direct consequence of this, however, is that a large amount of hardware may remain un-utilized when running a parallel application or a multiprogrammed workload. The chip-multiprocessor (CMP) <ref> [6, 12, 13] </ref>, on the other hand, is generic enough and has minimal support for speculative execution. Current proposals support a restricted communication mechanism between processors, which can occur only through memory.
Reference: [7] <author> S. Palacharla, N. Jouppi, and J. Smith. </author> <title> Complexity-Effective Superscalar Processors. </title> <booktitle> In 24th International Symposium on Computer Architecture, </booktitle> <pages> pages 206-218, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: We now consider the timing complexity. Palacharla and Jouppi <ref> [7] </ref> have argued that the register bypass network will dominate the cycle time of future high-issue processors. In fact, they have shown that an 8-issue processor would have almost twice the cycle time of a 4-issue processor with 0:18 technology.
Reference: [8] <author> E. Rotenberg, S. Bennett, and J. Smith. </author> <title> Trace Cache: A Low Latency Approach to High Bandwidth Instruction Fetching. </title> <booktitle> In 29th International Symposium on Microarchitecture (MICRO-29), </booktitle> <pages> pages 24-34, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: For instance, in the Trace processor, additional hardware in the form of a trace cache <ref> [8] </ref> assists in the identification of threads at run-time, while inter-thread register communication is performed with the help of a centralized global register file. In the Multiscalar processor, threads are identified statically by a compiler.
Reference: [9] <author> E. Rotenberg, Q. Jacobson, Y. Sazeides, and J. Smith. </author> <title> Trace Processors. </title> <booktitle> In 30th International Symposium on Microarchi-tecture (MICRO-30), </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: There have been two approaches for configuring multiple processing units on a chip. In one approach, the architecture is fully geared towards exploiting speculative parallelism from sequential applications. Typical examples are the Trace <ref> [9, 10] </ref> and Multiscalar [11] processors. Indeed, these processors can handle sequential binaries without re-compilation of the source. <p> However, this would require further hardware support in the form of duplicate register sets in each processor to enable recovery from squashes [1]. Alternatively, a global register set may be maintained to store the values <ref> [9] </ref>, but at the cost of maintaining a centralized structure. In our approach, we add minimal hardware to support the consumer-initiated form of communication. Specifically, the SS has simple logic that allows a consumer thread to identify the correct producer and get the register value. The logic works as follows. <p> Overall, the extra overhead per register is 3n bits, where n is the number of processors on chip. This is indeed a modest amount of storage overhead when compared to replicating the register sets in each processor [11] or using a centralized global register file <ref> [9] </ref>. 3.2 Memory Disambiguation Unlike register dependences, we do not identify memory dependences in the binary annotation phase and, therefore, assign the full responsibility to hardware. Each processor in the CMP has a private L1 cache. The L2 cache is shared.
Reference: [10] <author> J. Smith and S. Vajapeyam. </author> <title> Trace Processors: Moving to Fourth Generation Microarchitectures. </title> <journal> IEEE Computer, </journal> <volume> 30(9) </volume> <pages> 68-74, </pages> <month> September </month> <year> 1997. </year>
Reference-contexts: There have been two approaches for configuring multiple processing units on a chip. In one approach, the architecture is fully geared towards exploiting speculative parallelism from sequential applications. Typical examples are the Trace <ref> [9, 10] </ref> and Multiscalar [11] processors. Indeed, these processors can handle sequential binaries without re-compilation of the source.
Reference: [11] <author> G. Sohi, S. Breach, and T. N. Vijaykumar. </author> <title> Multiscalar Processors. </title> <booktitle> In 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 414-425, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: There have been two approaches for configuring multiple processing units on a chip. In one approach, the architecture is fully geared towards exploiting speculative parallelism from sequential applications. Typical examples are the Trace [9, 10] and Multiscalar <ref> [11] </ref> processors. Indeed, these processors can handle sequential binaries without re-compilation of the source. <p> The steps involved in the annotation process are illustrated in Figure 1. The approach that we use is similar to that of Multiscalar <ref> [11] </ref> except that we operate on the binary instead of the intermediate code. First, we identify inner loop iterations and annotate their initiation and termination points. Then, we need to identify the register level dependences between these threads. <p> More details may be found in [4]. Overall, the extra overhead per register is 3n bits, where n is the number of processors on chip. This is indeed a modest amount of storage overhead when compared to replicating the register sets in each processor <ref> [11] </ref> or using a centralized global register file [9]. 3.2 Memory Disambiguation Unlike register dependences, we do not identify memory dependences in the binary annotation phase and, therefore, assign the full responsibility to hardware. Each processor in the CMP has a private L1 cache. The L2 cache is shared.
Reference: [12] <author> J. Steffan and T. Mowry. </author> <title> The Potential for Using Thread-Level Data Speculation to Facilitate Automatic Parallelization. </title> <booktitle> In 4th International Symposium on High-Performance Computer Architecture, </booktitle> <pages> pages 2-13, </pages> <month> February </month> <year> 1998. </year>
Reference-contexts: A direct consequence of this, however, is that a large amount of hardware may remain un-utilized when running a parallel application or a multiprogrammed workload. The chip-multiprocessor (CMP) <ref> [6, 12, 13] </ref>, on the other hand, is generic enough and has minimal support for speculative execution. Current proposals support a restricted communication mechanism between processors, which can occur only through memory. <p> Current proposals support a restricted communication mechanism between processors, which can occur only through memory. Such limited hardware may be sufficient when programs are compiled using a compiler that is aware of the speculation hardware <ref> [12] </ref>. However, the need to re-compile the source is a handicap, especially when the source is unavailable. <p> Our approach of exploiting parallelism in binaries without re-compilation limits the performance of the CMP in these applications. Indeed, it has been shown that there is a large scope for improvement even for such inherently sequential applications, when the source code is recompiled with appropriate speculation support <ref> [12] </ref>. For the remaining three applications (ijpeg, mpeg and eqntott ) which have relatively smaller sequential sections, the CMP has a comparable or a higher IPC than the conventional superscalars. We stress that we have made our comparisons solely based on the IPC values, without taking cycle time into consideration.
Reference: [13] <author> J. Tsai and P. Yew. </author> <title> The Superthreaded Architecture: Thread Pipelining with Run-Time Data Dependence Checking and Control Speculation. </title> <booktitle> In PACT '96, </booktitle> <pages> pages 35-46, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: A direct consequence of this, however, is that a large amount of hardware may remain un-utilized when running a parallel application or a multiprogrammed workload. The chip-multiprocessor (CMP) <ref> [6, 12, 13] </ref>, on the other hand, is generic enough and has minimal support for speculative execution. Current proposals support a restricted communication mechanism between processors, which can occur only through memory.
Reference: [14] <author> J. Veenstra and R. Fowler. MINT: </author> <title> A Front End for Efficient Simulation of Shared-Memory Multiprocessors. </title> <booktitle> In MASCOTS'94, </booktitle> <pages> pages 201-207, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: La tencies refer to round trips. Simulation Approach Our simulation environment is built on a modified MINT <ref> [14] </ref> execution-driven simulation environment. MINT captures both application and library code execution and generates events by instrumenting binaries. Our back-end simulator is extremely detailed and performs a cycle-accurate simulation of the architectures and hardware support for speculation described.
References-found: 14

