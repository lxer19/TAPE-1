URL: http://www.cs.columbia.edu/CAVE/papers/nayar/nayar-fang-boult-color_polar_ijcv-96.ps.gz
Refering-URL: http://www.cs.columbia.edu/CAVE/physics-based-vision.html
Root-URL: http://www.cs.columbia.edu
Title: Separation of Reflection Components Using Color and Polarization  
Author: Shree K. Nayar, Xi-Sheng Fang, and Terrance Boult 
Address: New York, N.Y. 10027  
Affiliation: Department of Computer Science Columbia University  
Date: 1996  November 1993  
Note: To Appear: International Journal of Computer Vision,  
Pubnum: CUCS-058-92  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> B. G. Batchelor, D. A. Hill, and D. C. Hodgson, </author> <title> Automated Visual Inspection, </title> <publisher> IFS Publications Ltd., </publisher> <address> Bedford, England, </address> <year> 1985. </year>
Reference-contexts: The above procedure is an old trick that has been extensively used in a variety industrial applications (see <ref> [1] </ref> [14] for examples). Our purpose is to develop a passive technique for specularity removal that does not rely on controlled illumination. To this end, we shall assume the incident light to be unpolarized and return to expression (2).
Reference: [2] <author> R. Bajcsy, S. W. Lee, and A. </author> <title> Leonardis "Color image segmentation with detection of highlights and local illumination induced by interreflections," </title> <booktitle> Proc. of Intl. Conf. on Pattern Recognition (ICPR), </booktitle> <address> Atlantic City, NJ, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Later, an algorithm was proposed that attempts to achieve separation and segmentation simultaneously [11]. 1 These are also referred to as body and surface components (see [19]). 1 Subsequently, Bajcsy et al. <ref> [2] </ref> and Novak and Shafer [16] showed that the color histogram of an object could have additional limbs that correspond to highlights caused by interreflections between surfaces. Lee [21] suggested moving a sensor and applying spectral differencing to color histograms of consecutive images to identify specular points in the scene. <p> Based on this observation, Klinker et al. [11] and Gershon [8] developed algorithms to automatically identify the two limbs of the skewed T and then separate the diffuse and specular components at each object point. Along similar lines, Bajcsy et al. <ref> [2] </ref> observed that the color histogram can include additional limbs that correspond to highlights caused by interreflections. The highlight removal algorithms of Klinker and Gershon can therefore be modified to identify additional limbs and remove specularities due to interreflections.
Reference: [3] <author> P. Beckmann and A. Spizzichino, </author> <title> The Scattering of Electromagnetic Waves from Rough Surfaces, </title> <publisher> Pergamon, </publisher> <address> 1963, New York. </address>
Reference-contexts: In the case of dielectrics (non-conductors), however, the two Fresnel coefficients differ substantially except for near-normal angles of incidence (when is less than 20 5 Surface roughness that is comparable in dimension to the wavelength of light causes partial depolar-ization of incident light waves (see <ref> [3] </ref>). Therefore, removal of specular reflection using polarized incident light is most effective for surfaces with low microscopic roughness. 6 The plane of incidence includes the direction of illumination and the surface normal. 7 There are a few exceptions to this rule.
Reference: [4] <author> M. Born and E. Wolf, </author> <booktitle> Principles of Optics, </booktitle> <address> London:Pergamon, </address> <year> 1965. </year>
Reference-contexts: To overcome this problem, Wolff and Boult [23] use a large set of image points that lie on a pre-segmented (using percentage of polarization) highlight region. They assume that the diffuse component is constant over the entire highlight. In addition, the ratio of the Fresnel coefficients <ref> [4] </ref> is also assumed to be constant over the highlight. Using these assumptions, an estimate for the constant diffuse term is computed. The above polarization based approach suffers from two problems. <p> In this section, we present a brief overview of polarization and discuss the type of surfaces for which it provides useful information. Detailed discussions on the theory of polarization can be found in <ref> [4] </ref>. Polarization methods have been used extensively in the past two decades in the area of remote sensing for segmentation and classification of satellite imagery. A summary of recent results can be found in [7]. <p> To this end, we shall assume the incident light to be unpolarized and return to expression (2). The exact values of I sc and I sv in (2) depend on the material properties and the angle of incidence . These factors are represented by the Fresnel reflection coefficients <ref> [4] </ref>, F ? (; ) and F k (; ), that determine the polarization of reflected light waves in the directions perpendicular and parallel to the plane of incidence 6 , respectively. <p> From I c and I sv , the maximum and minimum values of image brightness are determined as: I min = I c I sv (9) The degree of polarization at a scene point can be estimated as <ref> [4] </ref>: = I max + I min lies between 0 and 1 and can be used during highlight removal to classify points into those that are only diffuse ( ! 0) and those that include a specular component. <p> An average q value is computed for the entire highlight region and used to estimate the incidence angle from Figure 14 (a). Note that each q estimate results in two possible values, on either side of the Brewster angle <ref> [4] </ref> at which q tends to infinity. For the assumed value of 1.7, the Brewster angle is approximately 60 degrees. To resolve this two-fold ambiguity in , we assume the source lies within 120 degrees with respect to the sensor direction.
Reference: [5] <author> T. E. Boult and L. B. Wolff, </author> <title> "Physically based edge labeling," </title> <booktitle> Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), </booktitle> <pages> pp. 656-663, </pages> <address> Maui, Hawaii, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: In the field of machine vision, polarization methods were introduced by Koshikawa [13] who used ellipsometry for shape interpretation and recognition of glossy objects. More recently, Wolff and Boult [23] have used linear polarization for highlight removal and material classification. Boult and Wolff <ref> [5] </ref> have also studied the classification of scene edges based on their polarization characteristics. A polarization filter is placed in front of the sensor. <p> The above expression is general in that it describes the variation of the specular component when the incident light is unpolarized, i.e. includes light waves of all polarizations. 4 Boult and Wolff <ref> [5] </ref> note that this assumption does not hold near the occluding contour of an object. 7 In structured environments, such as industrial assembly lines, the illumination of the scene of interest can be controlled. In such cases, removal of specularities is straightforward. <p> The above formulation of the problem using vectors saves substantial computations compared to the non-linear formulation of the type a + b sin 2 ( ff) used by Boult and Wolff <ref> [5] </ref> that requires the use of iterative non-linear estimation techniques.
Reference: [6] <author> G. Brelstaff and A. Blake, </author> <title> "Detecting Specular Reflections using Lambertian Constraints," </title> <booktitle> Proc. of Intl. Conf. on Computer Vision (ICCV), </booktitle> <pages> pp. 297-302, </pages> <address> Tampa, Florida, </address> <month> December </month> <year> 1992. </year>
Reference-contexts: In this paper, we present an algorithm that separates the diffuse and specular components of brightness from images. Separation of reflection components has been a topic of active research in the past few years. Initial work by Brestaff and Blake <ref> [6] </ref> addressed the problem of detecting specularities in gray-level (black and white) images by invoking the Lambertian constraint. Specularities are detected by identifying rapid brightness variations that violate Lambertian-like behavior. A different approach to the problem is based on color.
Reference: [7] <editor> Polarization and Remote Sensing, edited by W. G. Egan, </editor> <booktitle> SPIE, </booktitle> <volume> Vol. 1747, </volume> <month> July, </month> <year> 1992. </year>
Reference-contexts: Detailed discussions on the theory of polarization can be found in [4]. Polarization methods have been used extensively in the past two decades in the area of remote sensing for segmentation and classification of satellite imagery. A summary of recent results can be found in <ref> [7] </ref>. In the field of machine vision, polarization methods were introduced by Koshikawa [13] who used ellipsometry for shape interpretation and recognition of glossy objects. More recently, Wolff and Boult [23] have used linear polarization for highlight removal and material classification.
Reference: [8] <author> R. </author> <title> Gershon, The Use of Color in Computational Vision, </title> <type> PhD thesis, </type> <institution> University of Toronto, </institution> <year> 1987. </year>
Reference-contexts: Hence, the color of an image point can be viewed as the sum of two vectors with different directions in color space. Using this model, Klinker et al. [11] and Gershon <ref> [8] </ref> independently observed that the color histogram of a surface with uniform diffuse reflectance takes the shape of a "skewed T" or "dog leg" with two limbs. <p> The two vectors will however have the same direction if, for instance, a gray object is illuminated by white light. In such cases, separation of reflection components using color is not feasible. Klinker et al. [11] and Gershon <ref> [8] </ref> used the dichromatic reflectance model to remove highlights from images. They observed that the color histogram of a single object with uniform diffuse color has two limbs forming what is referred to by Klinker as a skewed T (also see [12] for a detailed and insightful discussion). <p> One limb results from diffuse reflections from object points that do not have a specular component, while the second limb corresponds to object points that lie on a highlight region and therefore include a specular component. Based on this observation, Klinker et al. [11] and Gershon <ref> [8] </ref> developed algorithms to automatically identify the two limbs of the skewed T and then separate the diffuse and specular components at each object point. Along similar lines, Bajcsy et al. [2] observed that the color histogram can include additional limbs that correspond to highlights caused by interreflections. <p> Real scenes are complex with objects that may be textured or have patches with different reflectance properties. In either case, the color histogram of the object does not provide neat linear clusters as assumed by Klinker et al. [11] and Gershon <ref> [8] </ref>. In other words, the skewed T would not be recognizable from the histogram. (b) The second assumption is related to the roughness of the surface. A skewed T would result only if all points on the highlight have nearly equal diffuse components, I d 0 .
Reference: [9] <institution> Handbook of Laser Science and Technology, edited by M.J. </institution> <address> Marvin, </address> <publisher> CRC Press Inc., Vol. </publisher> <address> 4, </address> <year> 1988. </year>
Reference-contexts: The parameter is once again the angle of incidence (and reflection since light rays are specularly reflected). The complex index of refraction is determined by the physical properties of the reflecting material. The Fresnel coefficients for a typical metal and a typical dielectric <ref> [9] </ref> [10] are shown in Figure 5. For metals, the Fresnel coefficients are nearly equal except for incidence angles close to grazing (when lies between 70 and 90 degrees). <p> Some special metals, such as Gold, have Fresnel coefficient plots that resemble those of a dielectric (see <ref> [9] </ref>). 8 degrees). It is interesting to note that the effect of varying the filter angle for a metal would be similar to that for a dielectric when the incidence angle is small. <p> As is evident from Figure 14 (a), it is not possible to determine from q without approximating the refractive index . It turns out that a large variety of real-world dielectrics have values between 1.6 and 1.8, including most plastics, ceramics, and other commonplace synthetic materials (see [10], <ref> [9] </ref>). Within this range of values, the q plots do not vary substantially and thus we assume = 1.7. This approximation allows us to determine illumination direction from primary specular highlights. In the case of specular reflection, angle of incidence equals angle of reflection.
Reference: [10] <institution> Handbook of Optics, edited by W.G. Driscoll, McGraw Hill Inc., </institution> <year> 1978. </year>
Reference-contexts: The parameter is once again the angle of incidence (and reflection since light rays are specularly reflected). The complex index of refraction is determined by the physical properties of the reflecting material. The Fresnel coefficients for a typical metal and a typical dielectric [9] <ref> [10] </ref> are shown in Figure 5. For metals, the Fresnel coefficients are nearly equal except for incidence angles close to grazing (when lies between 70 and 90 degrees). <p> The parameters a and b account for the partial polarization of the incident light [23]. (C) The Fresnel coefficients F ? (; ) and F k (; ) are independent of the wavelength of incident light. This assumption is reasonable (see <ref> [10] </ref>) since we are operating in a narrow wavelength range, namely, the visible-light spectrum. Assumptions (B) and (C) result in the Fresnel ratio q being constant for all three color bands. The separation technique is described by focusing on a single image point x. <p> As is evident from Figure 14 (a), it is not possible to determine from q without approximating the refractive index . It turns out that a large variety of real-world dielectrics have values between 1.6 and 1.8, including most plastics, ceramics, and other commonplace synthetic materials (see <ref> [10] </ref>, [9]). Within this range of values, the q plots do not vary substantially and thus we assume = 1.7. This approximation allows us to determine illumination direction from primary specular highlights. In the case of specular reflection, angle of incidence equals angle of reflection.
Reference: [11] <author> G. J. Klinker, S. A. Shafer, and T. Kanade, </author> <title> "The measurement of highlights in color images," </title> <journal> International Journal of Computer Vision, </journal> <volume> Vol. 2, No. 1, </volume> <pages> pp. 7-32, </pages> <year> 1990. </year> <month> 34 </month>
Reference-contexts: Hence, the color of an image point can be viewed as the sum of two vectors with different directions in color space. Using this model, Klinker et al. <ref> [11] </ref> and Gershon [8] independently observed that the color histogram of a surface with uniform diffuse reflectance takes the shape of a "skewed T" or "dog leg" with two limbs. <p> One limb corresponds to purely diffuse points on the surface while the other represents a highlight region. , Klinker et al. <ref> [11] </ref> proposed an algorithm for automatically identifying the two limbs and used the directions of the limbs to separate the diffuse and specular color vectors at each surface point. Later, an algorithm was proposed that attempts to achieve separation and segmentation simultaneously [11]. 1 These are also referred to as body <p> represents a highlight region. , Klinker et al. <ref> [11] </ref> proposed an algorithm for automatically identifying the two limbs and used the directions of the limbs to separate the diffuse and specular color vectors at each surface point. Later, an algorithm was proposed that attempts to achieve separation and segmentation simultaneously [11]. 1 These are also referred to as body and surface components (see [19]). 1 Subsequently, Bajcsy et al. [2] and Novak and Shafer [16] showed that the color histogram of an object could have additional limbs that correspond to highlights caused by interreflections between surfaces. <p> The two vectors will however have the same direction if, for instance, a gray object is illuminated by white light. In such cases, separation of reflection components using color is not feasible. Klinker et al. <ref> [11] </ref> and Gershon [8] used the dichromatic reflectance model to remove highlights from images. <p> One limb results from diffuse reflections from object points that do not have a specular component, while the second limb corresponds to object points that lie on a highlight region and therefore include a specular component. Based on this observation, Klinker et al. <ref> [11] </ref> and Gershon [8] developed algorithms to automatically identify the two limbs of the skewed T and then separate the diffuse and specular components at each object point. <p> Real scenes are complex with objects that may be textured or have patches with different reflectance properties. In either case, the color histogram of the object does not provide neat linear clusters as assumed by Klinker et al. <ref> [11] </ref> and Gershon [8]. In other words, the skewed T would not be recognizable from the histogram. (b) The second assumption is related to the roughness of the surface. A skewed T would result only if all points on the highlight have nearly equal diffuse components, I d 0 . <p> The window includes a highlight that spreads over regions with different diffuse colors. Figure 9 (b) shows the histogram of the window in (R,G,B ) color space. Note that the anatomy of the histogram is very complex and does not lend itself to the skewed T analysis used in <ref> [11] </ref>. Figure 9 (c) shows the cluster obtained in (I min ,I max ) space for the green band of the window. The green band was selected in this example as the average degree of polarization was found to be maximum in this band. <p> A large highlight, for instance, shrinks in size with each iteration. The iterations are discontinued when no new diffuse estimates are obtained. 18 (a) (e) (d) of the image. The anatomy of the histogram is too complex to identify the skewed T used in <ref> [11] </ref>. (c) Cluster in (I min ,I max ) space used by the polarization based proposed in [23].
Reference: [12] <author> G. J. Klinker, </author> <title> A Physical Approach to Color Image Understanding, A K Peters, </title> <type> Wellesley, </type> <institution> Massachusetts, </institution> <year> 1993. </year>
Reference-contexts: Klinker et al. [11] and Gershon [8] used the dichromatic reflectance model to remove highlights from images. They observed that the color histogram of a single object with uniform diffuse color has two limbs forming what is referred to by Klinker as a skewed T (also see <ref> [12] </ref> for a detailed and insightful discussion). One limb results from diffuse reflections from object points that do not have a specular component, while the second limb corresponds to object points that lie on a highlight region and therefore include a specular component.
Reference: [13] <author> K. Koshikawa, </author> <title> "A polarimetric approach to shape understanding," </title> <booktitle> Proc. of Intl. Joint Conf. on Artificial Intelligence (IJCAI), </booktitle> <pages> pp. 493-495, </pages> <year> 1979. </year>
Reference-contexts: Polarization methods have been used extensively in the past two decades in the area of remote sensing for segmentation and classification of satellite imagery. A summary of recent results can be found in [7]. In the field of machine vision, polarization methods were introduced by Koshikawa <ref> [13] </ref> who used ellipsometry for shape interpretation and recognition of glossy objects. More recently, Wolff and Boult [23] have used linear polarization for highlight removal and material classification. Boult and Wolff [5] have also studied the classification of scene edges based on their polarization characteristics.
Reference: [14] <author> S. Mersch, </author> <title> "Polarized Lighting for Machine Vision Applications," </title> <booktitle> Proc. of RI/SME Third Annual Applied Machine Vision Conf., </booktitle> <pages> pp. 40-54, Schaumburg, </pages> <month> Feb. </month> <year> 1984. </year>
Reference-contexts: The above procedure is an old trick that has been extensively used in a variety industrial applications (see [1] <ref> [14] </ref> for examples). Our purpose is to develop a passive technique for specularity removal that does not rely on controlled illumination. To this end, we shall assume the incident light to be unpolarized and return to expression (2).
Reference: [15] <author> S. K. Nayar, K. Ikeuchi, T. Kanade, </author> <title> "Surface Reflection: Physical and Geometrical Perspectives," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 13, No. 7, </volume> <pages> pp. 611-634, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: The paper is concluded with a critique of the algorithm. 3 2 Reflection and Interreflection Mechanisms We begin by describing the mechanisms involved in the processes of reflection and in-terreflection. Nayar et al. <ref> [15] </ref> proposed a reflectance framework that includes three primary components: the diffuse lobe; the specular lobe; and the specular spike. The last component exists only in the case of very smooth surfaces. In general, the two specular components can be combined into a single component.
Reference: [16] <author> C. Novak and S. Shafer, </author> <title> "Anatomy of a Color Histogram," </title> <booktitle> Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), </booktitle> <pages> pp. 599-605, </pages> <year> 1992. </year>
Reference-contexts: Later, an algorithm was proposed that attempts to achieve separation and segmentation simultaneously [11]. 1 These are also referred to as body and surface components (see [19]). 1 Subsequently, Bajcsy et al. [2] and Novak and Shafer <ref> [16] </ref> showed that the color histogram of an object could have additional limbs that correspond to highlights caused by interreflections between surfaces. Lee [21] suggested moving a sensor and applying spectral differencing to color histograms of consecutive images to identify specular points in the scene. <p> In the case of rough surfaces, highlights spread over a wider range of surface normals with different diffuse components and the specular limb of the skewed T does not have a well-defined direction. This last observation was also made by Novak and Shafer <ref> [16] </ref> and Lee [21]. Taking a different approach, Wolff and Boult [23] proposed a polarization based method for separating reflection components from gray-level images. A polarization filter is placed in front of the image sensor and the filter is rotated to obtain a sequence of images. <p> In such cases, the specular limb of the skewed T spreads into a wide cluster in color space that is difficult to separate from the diffuse limb. A detailed discussion on this problem is given by Novak and Shafer <ref> [16] </ref>. 5 Separation of Reflection Components We now present the algorithm for separating reflection components from images. The following assumptions are made: (A) The scene consists of dielectric objects. Hence, specular reflections and interreflec-tions are polarized while diffuse reflections are not.
Reference: [17] <author> M. Oren and S. K. Nayar, </author> <title> "Seeing Beyond Lambert's Law," </title> <booktitle> Proc. Third European Conference on Computer Vision, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 269-280, </pages> <month> May, </month> <year> 1994. </year>
Reference-contexts: For a given scene, a sequence of polarization images can be taken using a color image sensor and the separation algorithm then applied to recover a diffuse image. The diffuse image is invariant to viewing direction only if the scene is Lambertian. However, even for non-Lambertian surfaces (see <ref> [17] </ref>, [24]), diffuse reflection varies gradually with viewing direction in comparison to specular reflections. The diffuse image is therefore valuable for a variety of vision applications. Here, we shall explore other applications of the computed diffuse and specular images.
Reference: [18] <author> Y. Sato and K. </author> <title> Ikeuchi, "Temporal-Color Space Analysis of Reflection," </title> <booktitle> Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), </booktitle> <pages> pp. 570-576, </pages> <year> 1993. </year>
Reference-contexts: Lee [21] suggested moving a sensor and applying spectral differencing to color histograms of consecutive images to identify specular points in the scene. Recently, Sato and Ikeuchi <ref> [18] </ref> used local color signatures generated by actively varying the illumination direction to separate reflection components. This work uses the dichromatic model and singular value decomposition to decompose the color signatures into diffuse and specular signatures. These signatures can then be used to estimate surface orientation and local roughness estimates. <p> In addition, the ratio of the Fresnel coefficients [4] is also assumed to be constant over the highlight. Using these assumptions, an estimate for the constant diffuse term is computed. The above polarization based approach suffers from two problems. First, except 2 Sato and Ikeuchi <ref> [18] </ref> rely solely on local color measurements but require a large number of mea surements obtained by varying illumination direction. 2 for very smooth surfaces, highlights typically include a wide range of surface normals and the underlying diffuse component cannot be assumed constant.
Reference: [19] <author> S. Shafer, </author> <title> "Using color to separate reflection components," </title> <journal> Color Research and Applications, </journal> <volume> Vol. 10, </volume> <pages> pp. 210-218, </pages> <year> 1985. </year>
Reference-contexts: Specularities are detected by identifying rapid brightness variations that violate Lambertian-like behavior. A different approach to the problem is based on color. Most of this work uses the dichromatic reflectance model proposed by Shafer <ref> [19] </ref>. The dichromatic model suggests that, in the case of dielectrics (non-conductors), the diffuse and specular components generally have different spectral distributions. <p> Later, an algorithm was proposed that attempts to achieve separation and segmentation simultaneously [11]. 1 These are also referred to as body and surface components (see <ref> [19] </ref>). 1 Subsequently, Bajcsy et al. [2] and Novak and Shafer [16] showed that the color histogram of an object could have additional limbs that correspond to highlights caused by interreflections between surfaces. <p> Hence, in three-dimensional color space we have the following decomposition: I 0 = I d 0 (14) Shafer <ref> [19] </ref> proposed the Dichromatic Reflectance Model that suggests that for dielectrics, the spectral distribution of the diffuse component is determined by the colorant in the reflecting surface whereas the specular component preserves the spectral distribution of the incident light.
Reference: [20] <author> S. Shafer, T. Kanade, G. J. Klinker, and C. L. Novak, </author> <title> "Physics-based models for early vision by machine," </title> <booktitle> Proc. SPIE Conf. on Perceiving, Measuring and Using Color, </booktitle> <volume> Vol. 1250, </volume> <month> Feb </month> <year> 1993. </year>
Reference-contexts: The above assumption holds well except for very rough surfaces that have wide specular distributions that increase the likelihood of specular components due to both direct illumination and interreflection being dominant 3 A similar decomposition of interreflection mechanisms is presented by Shafer et al. <ref> [20] </ref>. 4 (a) an object with complex surface texture; (b) Image of the object after removal of specular reflections. 5 in any given sensor direction.
Reference: [21] <author> S.W. Lee, </author> <title> Understanding of Surface Reflection in Computer Vision by Color and Multiple Views, </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <year> 1991. </year>
Reference-contexts: Lee <ref> [21] </ref> suggested moving a sensor and applying spectral differencing to color histograms of consecutive images to identify specular points in the scene. Recently, Sato and Ikeuchi [18] used local color signatures generated by actively varying the illumination direction to separate reflection components. <p> In the case of rough surfaces, highlights spread over a wider range of surface normals with different diffuse components and the specular limb of the skewed T does not have a well-defined direction. This last observation was also made by Novak and Shafer [16] and Lee <ref> [21] </ref>. Taking a different approach, Wolff and Boult [23] proposed a polarization based method for separating reflection components from gray-level images. A polarization filter is placed in front of the image sensor and the filter is rotated to obtain a sequence of images.
Reference: [22] <author> K. Torrance and E. </author> <title> Sparrow, "Theory for Off-Specular Reflection from Roughened Surfaces," </title> <journal> Journal of the Optical Society of America, </journal> <volume> No. 57, </volume> <pages> pp. 1105-1114, </pages> <year> 1967. </year>
Reference-contexts: The result is a specular component that spreads around the specular direction, the width of the distribution depending on the roughness of the surface <ref> [22] </ref>. Now let us consider the phenomenon of interreflections. Points in the scene receive light not only from light sources but also from other scene points. Assume that point B reflects in the direction of the sensor, light energy that is received only from point A. <p> In the case of specular reflection, angle of incidence equals angle of reflection. Even in the case of rough surfaces, only those facets on the surface that are oriented so as to satisfy this specular constraint, produce specular reflections in the image <ref> [22] </ref>. Therefore, given , the polar angle s between the source and the sensor, subtended by the scene point, is simply s = 2 . The azimuth angle s of the source is exactly equal to the phase angle ff estimated by the polarization fitting.
Reference: [23] <author> L. B. Wolff and T. E. Boult, </author> <title> "Constraining Object Features using a Polarization Reflectance Model," </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 13, No. 7, </volume> <pages> pp. 635-657, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: This last observation was also made by Novak and Shafer [16] and Lee [21]. Taking a different approach, Wolff and Boult <ref> [23] </ref> proposed a polarization based method for separating reflection components from gray-level images. A polarization filter is placed in front of the image sensor and the filter is rotated to obtain a sequence of images. <p> In general, the diffuse component tends to be unpolarized while the specular component varies with rotation of the polarization filter. This variation in the specular component is significant only in the case of dielectrics. Wolff and Boult <ref> [23] </ref> assume the scene consists of dielectric objects and use the variation in image brightness due to polarization to estimate the diffuse and specular components. Though the specular component varies with the position of the polarization filter, it also includes a constant specular offset that does not vary. <p> Though the specular component varies with the position of the polarization filter, it also includes a constant specular offset that does not vary. This specular offset is not separable from the diffuse component which is also constant with respect to polarization. To overcome this problem, Wolff and Boult <ref> [23] </ref> use a large set of image points that lie on a pre-segmented (using percentage of polarization) highlight region. They assume that the diffuse component is constant over the entire highlight. In addition, the ratio of the Fresnel coefficients [4] is also assumed to be constant over the highlight. <p> A summary of recent results can be found in [7]. In the field of machine vision, polarization methods were introduced by Koshikawa [13] who used ellipsometry for shape interpretation and recognition of glossy objects. More recently, Wolff and Boult <ref> [23] </ref> have used linear polarization for highlight removal and material classification. Boult and Wolff [5] have also studied the classification of scene edges based on their polarization characteristics. A polarization filter is placed in front of the sensor. <p> Wolff and Boult <ref> [23] </ref> have presented a method for computing I d and I s by rotating the polarization filter. From the above discussion, we know that I d and I sc are both constant. <p> As stated earlier, the Fresnel coefficients are determined by the material properties of the scene point as well as the angle of incidence. Neither of these factors are known. To constrain the problem, Wolff and Boult <ref> [23] </ref> use all points (pixels) on a segmented highlight. They assume that both the diffuse component I d as well as the Fresnel ratio q are constant under the highlight region, and estimate them using all points within the highlight region. <p> In the second case, incident light is already partially polarized and the effective Fresnel ratio for the surface point is q = aF ? (; )=bF k (; ). The parameters a and b account for the partial polarization of the incident light <ref> [23] </ref>. (C) The Fresnel coefficients F ? (; ) and F k (; ) are independent of the wavelength of incident light. This assumption is reasonable (see [10]) since we are operating in a narrow wavelength range, namely, the visible-light spectrum. <p> The green band was selected in this example as the average degree of polarization was found to be maximum in this band. The polarization based method for highlight removal proposed in <ref> [23] </ref> is based on the assumption that this cluster in (I min ,I max ) space is linear. As seen in the Figure 9 (c), the cluster does not form a straight line and hence the polarization based method is not viable. <p> The anatomy of the histogram is too complex to identify the skewed T used in [11]. (c) Cluster in (I min ,I max ) space used by the polarization based proposed in <ref> [23] </ref>. This cluster must approximate a single straight line (which it clearly does not) for the method in [23] to work. (d) Separation of diffuse and specular components of the center pixel of the image using the proposed method based on color and polarization. (e) Diffuse image after removal of specular <p> The anatomy of the histogram is too complex to identify the skewed T used in [11]. (c) Cluster in (I min ,I max ) space used by the polarization based proposed in <ref> [23] </ref>. This cluster must approximate a single straight line (which it clearly does not) for the method in [23] to work. (d) Separation of diffuse and specular components of the center pixel of the image using the proposed method based on color and polarization. (e) Diffuse image after removal of specular reflections from the entire image in (a). 19 6 Implementation This section describes the implementation of the separation
Reference: [24] <author> L. B. Wolff, </author> <title> "A Diffuse Reflectance Model for Dielectric Surfaces," </title> <booktitle> Proc. SPIE Conf. on Optics, Illumination, and Image Sensing for Machine Vision, </booktitle> <volume> Vol. 1822, </volume> <pages> pp. 60-73, </pages> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: For a given scene, a sequence of polarization images can be taken using a color image sensor and the separation algorithm then applied to recover a diffuse image. The diffuse image is invariant to viewing direction only if the scene is Lambertian. However, even for non-Lambertian surfaces (see [17], <ref> [24] </ref>), diffuse reflection varies gradually with viewing direction in comparison to specular reflections. The diffuse image is therefore valuable for a variety of vision applications. Here, we shall explore other applications of the computed diffuse and specular images.
Reference: [25] <author> R. J. Woodham, </author> <title> "Photometric Method for Determining Surface Orientation from Multiple Images," </title> <journal> Optical Engineering, </journal> <volume> Vol. 19, No. 1, </volume> <pages> pp. 139-144, </pages> <year> 1980. </year> <month> 35 </month>
Reference-contexts: Here, we use photometric stereo <ref> [25] </ref> to demonstrate this idea. Photometric stereo uses multiple source directions and the known reflectance properties of surfaces in the scene to estimate local surface normals. The separation algorithm is used to overcome two problems.
References-found: 25

