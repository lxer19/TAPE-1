URL: http://www.ai.mit.edu/projects/haystack/papers/kramer-thesis.ps.gz
Refering-URL: http://www.ai.mit.edu/people/las/cv.html
Root-URL: 
Title: Agent Based Personalized Information Retrieval  
Author: by Joshua David Kramer c Joshua David Kramer, Lynn Andrea Stein Arthur C. Smith 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degrees of Master of Engineering in Computer Science and Engineering and Bachelor of Science in Computer Science and Engineering at the  MCMXCVII. All rights reserved. The author hereby grants to MIT permission to reproduce and distribute publicly paper and electronic copies of this thesis document in whole or in part, and to grant others the right to do so. Author  Certified by  Associate Professor Thesis Supervisor Accepted by  Chairman, Department Committee on Graduate Students  
Date: June 1997  June 2, 1997  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> Ohio Environmental Protection Agency. The 1995 Ohio State of the Environment Report. </institution> <note> http://www.fsu.edu/~cpm/segip/states/OH/pop.html. </note>
Reference-contexts: Instead of an information retrieval (IR) system, we would 2 In fact, one can currently go to the Infoseek [7] search engine, enter the query "What is the population of Ohio?" and get back as the best document the 1995 Ohio State of the Environment Report section on population <ref> [1] </ref>. This tells us that the 1990 census reports a population of 10,947,115 people. 11 like an information management (IM) system. We envision the following interaction with a fictional computerized personal information agent called Oren: Lynn: Oren, what information do I have about teaching Java. <p> This is typically used to get information about about the set of documents returned by a query: @RelevantDocs = Haystack.Query ('agent theory'); @DocumentInfo = Haystack.DocumentArray (@RelevantDocs); indexed array). Thus $foo could be a scalar such as 5 or 'hello'. @bar could be an array such as <ref> [1, 2, 'hello', 'world'] </ref>. . A hash table such as %baz is represented via an array of pairs, as in ['name', 'amy', 'age', 20] 44 This simple set of actions is enough to give other agents access to the core function-ality of Haystack.
Reference: [2] <author> R. Armstrong, D. Freitag, T. Joachims, and T. Mitchell. Webwatcher: </author> <title> A Learning Apprentice for the World Wide Web. </title> <booktitle> Proceedings of the 1995 AAAI Spring Symposium on Information Gathering from Heterogeneous, Distributed Environments, </booktitle> <month> March </month> <year> 1995. </year>
Reference-contexts: It is one of the few examples of a tool which uses a model of its user when answering queries. It is also a direction which we hope our own system will take. In some sense we already do this by modeling users through their documents. Letizia [28], WebWatcher <ref> [2] </ref>, and Syskill & Webert [35] all take a personalized approach to managing the wealth of information on the Web. While Web search engines have provided a valuable tool for finding sites in general, there is often a lack of local searching which makes navigating some Web sites difficult. <p> This is typically used to get information about about the set of documents returned by a query: @RelevantDocs = Haystack.Query ('agent theory'); @DocumentInfo = Haystack.DocumentArray (@RelevantDocs); indexed array). Thus $foo could be a scalar such as 5 or 'hello'. @bar could be an array such as <ref> [1, 2, 'hello', 'world'] </ref>. . A hash table such as %baz is represented via an array of pairs, as in ['name', 'amy', 'age', 20] 44 This simple set of actions is enough to give other agents access to the core function-ality of Haystack.
Reference: [3] <author> A. Birrell and B. Nelson. </author> <title> Implementing remote procedure calls. </title> <type> Technical Report CSL-83-7, </type> <institution> Xerox, </institution> <month> October </month> <year> 1983. </year>
Reference-contexts: These additions consist of language primatives which make it simple to specify agent interactions without having worry about the details of the execution. It is comparable to having a built in set of routines for fault tolerant network access and RPC <ref> [3] </ref>. In some respects SodaBotL is similar to an object oriented language, except that instead of objects, it has agents. We mean this in the simplest possible interpretation: Agents make use of other agents, and there is no code which is not part of an agent.
Reference: [4] <author> R. A. Brooks. </author> <title> A Robust Layered Control System for a Mobile Robot. </title> <type> Technical Report 864, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA., </address> <year> 1985. </year>
Reference-contexts: The design of the Room's architecture calls for higher level, more complex, applications (such as an information retrieval agent) to be built on top of the base "reflex" layer. These layers of many agents interacting in interesting ways was largely influence by Brooks' subsumption architecture <ref> [4] </ref> and Minsky's Society of Mind [33]. Coen [5] calls this 2nd tier "intermediate information-level applications." An example of such a higher level system is a system for controlling a slide presentation. The Slide agent is essentially layered on top of the Netscape agent.
Reference: [5] <author> M. Coen. </author> <title> Building Brains for Rooms: Designing Distributed Software Agents. </title> <note> To Appear in AAAI 1997. http://www.ai.mit.edu/projects/hal/brain.ps. </note>
Reference-contexts: Coen <ref> [5] </ref> has made the point that the Intelligent Room is more than a platform for HCI experiments; it is an excellent environment for conducting core AI research as well. <p> There are roughly 20 agents distributed over 10 different workstations with no centralized thread of control. We call this base level control system the ScatterBrain <ref> [5] </ref>. 35 The ScatterBrain represents what are essentially the Room's reflexes a set of basic behaviors that are constantly available. For instance, the LaserPointer agent is always running. <p> These layers of many agents interacting in interesting ways was largely influence by Brooks' subsumption architecture [4] and Minsky's Society of Mind [33]. Coen <ref> [5] </ref> calls this 2nd tier "intermediate information-level applications." An example of such a higher level system is a system for controlling a slide presentation. The Slide agent is essentially layered on top of the Netscape agent.
Reference: [6] <author> M. Coen. SodaBot: </author> <title> A Software Agent Environment and Constuction System. </title> <type> Technical Report 1493, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA., </address> <month> June </month> <year> 1994. </year>
Reference-contexts: AgentTCL [14], and to some extent TeleScript [48], could be used to build a similar infrastructure. Given the functionality gained by building our application in the context of Intelligent Room, SodaBot is the logical choice. 3.1 SodaBot SodaBot <ref> [6] </ref> is a software agent environment developed at the MIT Artificial Intelligence Lab. It is designed to simplify the specification of agent interactions. SodaBot consists of both an agent programming language, SodaBotL, and a runtime environment to support these agents. <p> So, an AP running on a machine named lovebug in the 2 A request is analogous to a C++ method, a procedure which other agents can call. We use the term request synonymously with procedure, function, routine, and method. 3 In the original implementation of SodaBot <ref> [6] </ref>, these were known as Basic Software Agents, or BSAs. 34 AI Lab is canonically known as lovebug@ai.mit.edu. Agents can specify which AP they want other agents to run on when making procedure calls.
Reference: [7] <author> Infoseek Corporation. Infoseek. </author> <note> http://www.infoseek.com. </note>
Reference-contexts: Instead of an information retrieval (IR) system, we would 2 In fact, one can currently go to the Infoseek <ref> [7] </ref> search engine, enter the query "What is the population of Ohio?" and get back as the best document the 1995 Ohio State of the Environment Report section on population [1].
Reference: [8] <author> C. A. DellaFera, M. W. Eichin, R. S. French, D. C. Jedlinksy, J. T. Kohl, and W. E. Sommerfeld. </author> <title> Section E.4.1: </title> <publisher> Zephyr Notification Service. MIT Project Athena, </publisher> <address> Cambridge, MA, </address> <month> December </month> <year> 1987. </year> <month> 69 </month>
Reference-contexts: That is, as other agents are written which are aware of other document interactions (e.g. an email agent), the system can easily make use of them to provide information retrieval. We have briefly experimented with a Zephyr agent to integrate the Zephyr <ref> [8] </ref> instantaneous messaging system with the User agent. Once we had provided the Zephyr agent with access to each incoming message, having the User agent index each message was simple. Unfortunately, we encountered problems with Haystack due to the high rate of archiving.
Reference: [9] <author> D. Dreilinger. SavvySearch. </author> <note> http://guaraldi.cs.colorado.edu:2000/. </note>
Reference-contexts: In many ways we already have IR systems which are ubiquitous for a specific domain, automated, and networked - Web search engines. Systems such as Lycos and AltaVista automatically spider [31] the Web, attempting to find every document on the Web and index it. Furthermore, systems such as SavvySearch <ref> [9] </ref> and the MetaCrawler [40] send queries to multiple Web search engines and aggregate the results to produce a better result set than any individual engine does.
Reference: [10] <author> O. Etzioni and D. S. Weld. </author> <title> A Softbot-Based Interface to the Internet. </title> <journal> CACM, </journal> <month> July </month> <year> 1994. </year>
Reference-contexts: The tendency seems to build an agent which can make use of several resources (often Web based) and tie them together in useful and easy to use ways. The University of Washington's collection of Softbots <ref> [10] </ref> are an example of this approach. They have build up systems for locating users, shopping assistance, travel reservations, and searching the web itself. These are exactly the types of applications which agents are excel at.
Reference: [11] <author> O. Etzioni and D. S. Weld. </author> <title> Intelligent Agents on the Internet: Fact, Fiction, and Forecast. </title> <journal> IEEE Expert, </journal> <month> August </month> <year> 1995. </year>
Reference-contexts: It also builds some background for looking at the other systems described in Section 2.4 2.3.1 Agents Software agents are a recent class of computer programs which have been given many definitions. Qualities ascribed to software agents by Etzioni and Weld <ref> [11] </ref> include being "autonomous, goal-oriented, collaborative, flexible, self-starting, communicative, adaptive, mobile, temporally continuous, and having character." This grab-bag of features describes both a very generic tool as well as a very powerful one.
Reference: [12] <author> L. Foner. Yenta: </author> <title> A Multi-Agent, Referral Based Matchmaking System. </title> <booktitle> In The First International Conference on Autonomous Agents (Agents '97), </booktitle> <address> Marina del Rey, California, </address> <month> February </month> <year> 1997. </year>
Reference-contexts: It uses a nearest neighbor approach to find other users in the system with similar likes. The underlying engine has been adapted for the Web in the form of WebDoggie [32]. An even more general approach is taken in Yenta <ref> [12] </ref> 28 which attempts to play the role of match-maker. Yenta attempts to dynamically cre-ate interest groups by introducing people with similar interests who have never met. Yenta requires users to explicitly list their interests.
Reference: [13] <author> N. Glovert and U. Pfeifer. Sfgate: </author> <title> A Gateway Between the WWW and WAIS. </title> <address> http://ls6.informatik.uni-dortmund.de/ir/projects/SFgate. </address>
Reference-contexts: It is called with two arguments, a query string called the InfoTopic and an optional 3 This is accomplished through the use of a proxy Web server. The Netscape agent has a thread which starts this server. The server is a customized version of SFProxy <ref> [13] </ref>, a proxy server written in Perl. The server outputs information about the pages that browsers request from it.
Reference: [14] <author> R. S. Gray, D. Rus, and D. Kotz. </author> <title> Transportable information agents. </title> <type> Technical Report PCS-TR96-278, </type> <institution> Dartmouth College, Computer Science, </institution> <address> Hanover, NH, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Is SodaBot necessary? Well, it is certainly required for our interactions with the Intelligent Room's existing infrastructure of agents. However, there are several other agent systems which provide similar levels of network accessibility and easy user interaction. AgentTCL <ref> [14] </ref>, and to some extent TeleScript [48], could be used to build a similar infrastructure. Given the functionality gained by building our application in the context of Intelligent Room, SodaBot is the logical choice. 3.1 SodaBot SodaBot [6] is a software agent environment developed at the MIT Artificial Intelligence Lab.
Reference: [15] <author> K. Hammond and J. Kozlovsky. </author> <title> Knowledge-based Information Retrieval for Semi-Structured Text. </title> <booktitle> In Working Notes from AAAI Fall Symposium on AI Applications in Knowledge Navigation and Retrieval, </booktitle> <year> 1995. </year>
Reference-contexts: These are exactly the types of applications which agents are excel at. They make use of a variety of computational resources to either solve high level problems or solve problems more efficiently. The University of Chicago's FaqFinder <ref> [15] </ref> is a system for searching the set of FAQs (Frequently Asked Questions) associated with many Usenet news groups. These documents typically are a list of questions and their answers. For a given news group, they can be very informative.
Reference: [16] <author> W. C. Hill, J. D. Hollan, D. Wroblewski, and T. McCandless. Edit Wear and Read Wear: </author> <title> Their Theory and Generalization. </title> <booktitle> In ACM CHI'92 Human Factors in Computing Systems Proceedings, </booktitle> <pages> pages 3-9. </pages> <publisher> ACM, ACM Press, </publisher> <year> 1992. </year>
Reference: [17] <author> AltaVista Inc. AltaVista. </author> <note> http://www.altavista.digital.com. </note>
Reference-contexts: However its current implementation has limited means for automatically adding documents to the repository. Furthermore, it is limited to textual documents saved in the user's file system. It also lacks the networking and annotating capabilities of our system. Overall, there are relatively few systems for personal information management. AltaVista <ref> [17] </ref> has introduced a personal version of its popular Web search engine. The program is designed to index a user's hard disk and then provide text based querying. Glimpse [30] is designed to provide keyword searches of a user's file-system.
Reference: [18] <author> Lycos Inc. Lycos: </author> <title> Catalog of the Internet. </title> <address> http://www.lycos.com. </address>
Reference-contexts: Given the Web's unstructured nature and enormous size, these search engines have been crucial in making the Web usable. Without any sort of central authority or hierarchy, it is often quite difficult to say where a user should start looking for a document. Hence, Web sites such as Lycos <ref> [18] </ref> and Yahoo [19] each routinely get over 5 million search requests in a day 1 . Given the advertising and licensing revenues these sites generate, Internet search engines are here for the foreseeable future.
Reference: [19] <author> Yahoo! Inc. </author> <note> Yahoo! http://www.yahoo.com. </note>
Reference-contexts: Without any sort of central authority or hierarchy, it is often quite difficult to say where a user should start looking for a document. Hence, Web sites such as Lycos [18] and Yahoo <ref> [19] </ref> each routinely get over 5 million search requests in a day 1 . Given the advertising and licensing revenues these sites generate, Internet search engines are here for the foreseeable future.
Reference: [20] <author> J. Jannotti. </author> <title> Private communication with the author., </title> <booktitle> 1997. </booktitle> <pages> 70 </pages>
Reference-contexts: This can be extended to create an "expert finder" by finding other users with Haystacks which contain many documents on a single topic. The argument has been made that searching other people's Haystacks is no better than effectively searching the entire Web <ref> [20] </ref>. We argue that Haystacks should typically contain documents which cannot be found on the Web or which cannot be indexed by conventional Web search tools. <p> Thus $foo could be a scalar such as 5 or 'hello'. @bar could be an array such as [1, 2, 'hello', 'world']. . A hash table such as %baz is represented via an array of pairs, as in <ref> ['name', 'amy', 'age', 20] </ref> 44 This simple set of actions is enough to give other agents access to the core function-ality of Haystack.
Reference: [21] <author> A. Jennings and H. Higuchii. </author> <title> A Personal News Service based on a User Model Neural Network. </title> <journal> In IEICE Transactions on Information and Systems, </journal> <month> March </month> <year> 1992. </year>
Reference-contexts: We are able to make use of passive observations to determine how useful a document is to the user. While this may not help an individual search, the goal is to build up information of time about which documents best answer which queries. Browse <ref> [21] </ref> is an X windows based system which uses a neural-net to model its users. It uses a binary rating system by asking users to either accept or reject articles. This is not too different from SIFT.
Reference: [22] <author> D. Karger and L. A. Stein. Haystack: </author> <title> Per-User Information Environments. </title> <address> http://www.ai.mit.edu/projects/haystack/karger-stein-9702.html. </address>
Reference-contexts: This is very different from conventional IR systems where the user is normally searching a large unknown body of documents. Karger and Stein <ref> [22] </ref> liken this to searching one's bookshelf versus searching a card catalog at a library. Furthermore, the fact that users have most likely already seen the document they are looking for enables more powerful queries. <p> The ScatterBrain provides the ability to easily build these high level and more complex applications in a multi-modal interactive environment. It is also a natural level at which to integrate our personal IM system into the Room. 3.2 Haystack: Per-User Information Retrieval The Haystack <ref> [22] </ref> information retrieval system is an project of the MIT Laboratory for Computer Science. Its goal, much like our own, is to be a "living" personal information retrieval system deployed on a community wide basis.
Reference: [23] <author> B. Katz. </author> <title> Using English for Indexing and Retrieving. </title> <editor> In P. Winston and S. Shel-lard, editors, </editor> <booktitle> Artificial Intelligence at MIT: Expanding Frontiers, volume 1, </booktitle> <address> Cam-bridge, MA, 1990. </address> <publisher> MIT Press. </publisher>
Reference-contexts: We have leveraged this powerful operating environment by building our personal information management system in it. Providing the Intelligent Room with access to its own information management system is a major contribution of this work. While the Room has an existing interface for using the START <ref> [23] </ref> natural language information retrieval system, it is very limited in its use. All the information in START has to be entered by hand and is generally high level symbolic information, such as statistical summaries. Thus its data set is quite limited. <p> For a given news group, they can be very informative. FaqFinder takes a natural language query and uses the SMART [38] IR system to find relevant FAQs. It then parses the query further and attempts to find a matching question/answer pair. The START <ref> [23] </ref> natural language information retrieval system provides similar functionality for its own limited knowledgebase about Bosnia. Unfortunately, both systems are quite limited in their knowledge and tend to have poor failure modes for dealing with queries they have no answer for.
Reference: [24] <author> H. Kautz, A. Milewski, and B Selman. </author> <title> Agent amplified communication. </title> <booktitle> Proceedings of the 1995 AAAI Spring Symposium on Information Gathering from Heterogeneous Distributed Environments, </booktitle> <month> March </month> <year> 1995. </year>
Reference: [25] <author> H. Kautz, B. Selman, M. Coen, and S. Katchpel. </author> <title> An Experiment in the Design of Software Agents. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, AAAI-94, </booktitle> <address> Seattle, Washington, </address> <year> 1994. </year>
Reference-contexts: Kautz et al.[24] have built such a system based around a similar User agent to our own. They make use of users' email and files to develop profiles which agents share with each other. Given the historical connection of their "visitorbots" <ref> [25] </ref> to our own SodaBot, it is no surprise that they too took advantage of their architecture to build such a system. We hope to more completely integrate the RoomInfo agent and the Intelligent 67 Room.
Reference: [26] <author> K. Lang. Newsweeder: </author> <title> Learning to Filter Netnews. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 331-339, </pages> <address> Tahoe City, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Relevance feedback is an area of research in and of itself. Essentially, queries can be improved by making use of keywords from good documents and removing the keywords from bad ones. Thus, a system such as NewsWeeder <ref> [26] </ref> has users rate each article they read using a scale of 1 to 5 (They point out the importance of making the rating process as simple and unintrusive as possible for the user.) This type of 26 feedback can greatly improve a search, even with just a single iteration [39].
Reference: [27] <author> Y. Lashkari, M. Metral, and P. Maes. </author> <title> Collaborative Interface Agents. </title> <booktitle> In Conference of the American Association for Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The GroupLens [36] project has similar goals but is built on a very open framework. The Agents group of the MIT Media Lab has developed a number of collaborative filtering applications. Maxim <ref> [27] </ref> is a learning collaborative email reader. It is noteworthy for being exceptionally easy to use and thus much more geared toward beginners than Tapestry. FireFly [41] is a collaborative system for recommending new music selections.
Reference: [28] <author> H. Lieberman. Letizia: </author> <title> An Agent That Assists Web Browsing. </title> <booktitle> In Proceedings of the 1995 International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: It is one of the few examples of a tool which uses a model of its user when answering queries. It is also a direction which we hope our own system will take. In some sense we already do this by modeling users through their documents. Letizia <ref> [28] </ref>, WebWatcher [2], and Syskill & Webert [35] all take a personalized approach to managing the wealth of information on the Web.
Reference: [29] <author> D. Maltz. </author> <title> Distributed Iinformation for Collaborative Filtering on Usenet News. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1994. </year> <month> 71 </month>
Reference-contexts: The Tapestry [44] project at Xerox PARC is an excellent implementation of this idea. The Tapestry project focuses on annotating and filtering electronic mail and recent articles on net-news bulletin boards for a fairly small community of users. Several Usenet news reading tools <ref> [29] </ref> were modified to let readers vote on articles they like and dislike, as well as to annotate these documents with their comments.
Reference: [30] <author> U. Manber and S. Wu. Glimpse: </author> <title> A Tool to Search Through Entire File Systems. </title> <type> Technical Report TR93-34, </type> <institution> The University of Arizona, Department of Computer Science, Tuscon, AR, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: Overall, there are relatively few systems for personal information management. AltaVista [17] has introduced a personal version of its popular Web search engine. The program is designed to index a user's hard disk and then provide text based querying. Glimpse <ref> [30] </ref> is designed to provide keyword searches of a user's file-system. It is essentially a more powerful version of UNIX's grep, which itself has been used as a crude tool for searching personal files for certain words.
Reference: [31] <author> M. Mauldin and J. Leavett. </author> <title> Web Agent Related Research at the Center for Machine Translation. </title> <booktitle> Presented at SIGNIDR meeting, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: In many ways we already have IR systems which are ubiquitous for a specific domain, automated, and networked - Web search engines. Systems such as Lycos and AltaVista automatically spider <ref> [31] </ref> the Web, attempting to find every document on the Web and index it. Furthermore, systems such as SavvySearch [9] and the MetaCrawler [40] send queries to multiple Web search engines and aggregate the results to produce a better result set than any individual engine does.
Reference: [32] <author> M. Metral and M. </author> <title> Eng. The WebDoggie Personailzed Document Filtering System. </title> <address> http://webhound.www.media.mit.edu/projects/webhound/www-face. </address>
Reference-contexts: FireFly [41] is a collaborative system for recommending new music selections. It uses a nearest neighbor approach to find other users in the system with similar likes. The underlying engine has been adapted for the Web in the form of WebDoggie <ref> [32] </ref>. An even more general approach is taken in Yenta [12] 28 which attempts to play the role of match-maker. Yenta attempts to dynamically cre-ate interest groups by introducing people with similar interests who have never met. Yenta requires users to explicitly list their interests.
Reference: [33] <author> M. Minsky. </author> <title> The Society of Mind. </title> <publisher> Simon and Schuster, </publisher> <year> 1986. </year>
Reference-contexts: These layers of many agents interacting in interesting ways was largely influence by Brooks' subsumption architecture [4] and Minsky's Society of Mind <ref> [33] </ref>. Coen [5] calls this 2nd tier "intermediate information-level applications." An example of such a higher level system is a system for controlling a slide presentation. The Slide agent is essentially layered on top of the Netscape agent.
Reference: [34] <author> A. Moukas. Amalthaea: </author> <title> Information Discovery and Filtering using a Multiagent Evolving Ecosystem. </title> <journal> International Journal of Applied Artificial Intelligence, </journal> <year> 1997. </year>
Reference-contexts: This work is notable because it describes a generic framework for using genetic algorithms to deploy information agents. The information agents then compete to provide their owner with the best information, regardless of the source. Amalthaea <ref> [34] </ref> is an attempt to bring a large number of these information agents together.
Reference: [35] <author> M. Pazzani, J. Muramatsu, and D. Billsus. Syskill & Webert: </author> <title> Identifying interesting web sites. </title> <booktitle> In Proceedings of AAAI Conference, </booktitle> <year> 1996. </year>
Reference-contexts: It is also a direction which we hope our own system will take. In some sense we already do this by modeling users through their documents. Letizia [28], WebWatcher [2], and Syskill & Webert <ref> [35] </ref> all take a personalized approach to managing the wealth of information on the Web. While Web search engines have provided a valuable tool for finding sites in general, there is often a lack of local searching which makes navigating some Web sites difficult.
Reference: [36] <author> P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl. GroupLens: </author> <title> An Open Architecture for Collaborative Filtering of Netnews. </title> <booktitle> In Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work, </booktitle> <pages> pages 1175-186, </pages> <address> Chapel Hill, NC, 1994. </address> <publisher> ACM. </publisher>
Reference-contexts: The language allows users to specify filtering rules which are applied to the set of messages. One novel idea they describe is to first use binary acceptors to quickly filter articles and then rate the articles with appraisers. The GroupLens <ref> [36] </ref> project has similar goals but is built on a very open framework. The Agents group of the MIT Media Lab has developed a number of collaborative filtering applications. Maxim [27] is a learning collaborative email reader.
Reference: [37] <author> B. J. Rhodes and T. Starner. </author> <title> Remembrance Agent: A continuously running automated information retrieval system. </title> <booktitle> In The Proceedings of The First International Conference on The Practical Application Of Intelligent Agents and Multi Agent Technology, </booktitle> <pages> pages 487-495, </pages> <year> 1996. </year>
Reference-contexts: Amalthaea [34] is an attempt to bring a large number of these information agents together. The goal is to collectively meet a user's information needs instead of building a large, complex, information system. 2.4.4 Personal Information Retrieval Systems The Remembrance Agent <ref> [37] </ref> is the project with the most similar goals to our own augmenting human memory. The system attempts to monitor every document its owner uses and add it to an information retrieval system. <p> As we fill in the gaps in document coverage to capture all of a user's information interactions, we will truly have a novel system. The closest system to our own, the Remembrance Agent <ref> [37] </ref>, certainly has similar intentions. However its strength lies much more in its automated search facilities, not in automatically archiving documents. The Remembrance Agent basically requires users to hand-pick which documents to store in their repository.
Reference: [38] <author> G. Salton. </author> <title> The SMART Retrieval System Experiments in Automatic Document Processing. </title> <publisher> Prentice Hall, </publisher> <year> 1971. </year>
Reference-contexts: These documents typically are a list of questions and their answers. For a given news group, they can be very informative. FaqFinder takes a natural language query and uses the SMART <ref> [38] </ref> IR system to find relevant FAQs. It then parses the query further and attempts to find a matching question/answer pair. The START [23] natural language information retrieval system provides similar functionality for its own limited knowledgebase about Bosnia.
Reference: [39] <author> G. Salton. </author> <title> Automatic Text Processing: The Transformation, Analysis, and Re-trievalof Information by Computer. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> Reading, MA, </address> <year> 1989. </year> <month> 72 </month>
Reference-contexts: So, for us, information retrieval systems are black boxes the datastore for our documents. By all means, they are certainly a powerful abstraction. But, we make no attempt to explore or improve their internal design. We refer the reader to Salton's <ref> [39] </ref> excellent overview of this area for a detailed explanation of IR. Thus, the choice of which IR system to use as our underlying engine is not terrible important, and given our choice of Haystack, actually not our choice to make. <p> [26] has users rate each article they read using a scale of 1 to 5 (They point out the importance of making the rating process as simple and unintrusive as possible for the user.) This type of 26 feedback can greatly improve a search, even with just a single iteration <ref> [39] </ref>. Our framework enables a slightly different sort of feedback. We are able to make use of passive observations to determine how useful a document is to the user.
Reference: [40] <author> E. Selberg and O. Etzioni. </author> <title> Multi-Service Search and Comparison using the MetaCrawler. </title> <booktitle> In Proceedings of the 4th International World Wide Web Conference, </booktitle> <year> 1995. </year>
Reference-contexts: Systems such as Lycos and AltaVista automatically spider [31] the Web, attempting to find every document on the Web and index it. Furthermore, systems such as SavvySearch [9] and the MetaCrawler <ref> [40] </ref> send queries to multiple Web search engines and aggregate the results to produce a better result set than any individual engine does.
Reference: [41] <author> U. Shardanand and P. Maes. </author> <title> Social Information Filtering: Algorithms for Automating "Word of Mouth". </title> <booktitle> In Proceedings of the CHI-95 Conference, </booktitle> <address> Denver, CO, </address> <month> May </month> <year> 1995. </year> <title> ACM, </title> <publisher> ACM Press. </publisher>
Reference-contexts: The Agents group of the MIT Media Lab has developed a number of collaborative filtering applications. Maxim [27] is a learning collaborative email reader. It is noteworthy for being exceptionally easy to use and thus much more geared toward beginners than Tapestry. FireFly <ref> [41] </ref> is a collaborative system for recommending new music selections. It uses a nearest neighbor approach to find other users in the system with similar likes. The underlying engine has been adapted for the Web in the form of WebDoggie [32].
Reference: [42] <author> B. Sheth. </author> <title> A Learning Approach to Personalized Information Filtering. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> Febuary </month> <year> 1994. </year>
Reference-contexts: Unfortunately, both systems are quite limited in their knowledge and tend to have poor failure modes for dealing with queries they have no answer for. Thus, they are only really useful when you already suspect they have the 29 answer to your question. Sheth <ref> [42] </ref> describes Newt, a news reader which makes use of genetic algorithms to develop multiple user profiles. These profiles then compete to yield the best set of keywords to search the news corpus.
Reference: [43] <author> L. A. Stein. </author> <title> In the eye of the beholder. </title> <note> To appear in IEEE Expert Sepcial Issue on Software Agents. </note>
Reference-contexts: Qualities ascribed to software agents by Etzioni and Weld [11] include being "autonomous, goal-oriented, collaborative, flexible, self-starting, communicative, adaptive, mobile, temporally continuous, and having character." This grab-bag of features describes both a very generic tool as well as a very powerful one. Indeed, Stein <ref> [43] </ref> goes as far as to suggest that there isn't a viable definition of agency at all, that it is simply our individual perceptions of what a program is doing for us which make it an agent. Agents are what we make of them.
Reference: [44] <author> D. B. Terry. </author> <title> A Tour Through Tapestry. </title> <booktitle> In Proceedings of ACM Conference on Organizational Computing Systems (COOCS), </booktitle> <address> New York, 1993. </address> <publisher> ACM Press. </publisher>
Reference-contexts: This is an area we are eager to explore. As we build networked personal information management systems, it will be possible to use this collaborative network to enhance the information retrieval process. The Tapestry <ref> [44] </ref> project at Xerox PARC is an excellent implementation of this idea. The Tapestry project focuses on annotating and filtering electronic mail and recent articles on net-news bulletin boards for a fairly small community of users.
Reference: [45] <author> M. Torrance. </author> <booktitle> Advances in Human Computer Interaction: The Intelligent Room. In Working Notes of the CHI '95 Research Symposium, </booktitle> <address> Denver, Colorado, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: It is an environment which is not only aware of what documents are being used in it, but hopefully one which has an idea of its occupants' intentions. This environment is the Intelligent Room <ref> [45] </ref> at the MIT Artificial Intelligence Lab and its system of SodaBot software agents. The Intelligent Room is an experiment in enhanced human computer interaction. The Room is designed as an intelligent conference space void of keyboards and mice, yet fully interactive.
Reference: [46] <author> S. Vinoski. </author> <title> CORBA: Integrating Diverse Applications Within Distributed Heterogeneous Environments. </title> <journal> IEEE Communications Magazine, </journal> <volume> 14(2), </volume> <month> Feburary </month> <year> 1997. </year>
Reference-contexts: For instance, the personal IM system will want to "know" about each document its user accesses. Most applications, and indeed most operating systems, do not provide this level of service. While several standards for exchanging information between applications (CORBA <ref> [46] </ref>, Microsoft's OLE, Apple's OpenDoc, UNIX IPC, etc.) exist, they are certainly not in widespread use. The simple problem is that there is no single universal interface for applications to communicate with each other about their activities. What is missing is an common infrastructure to support these activities.
Reference: [47] <author> L. Wall and R. L. Schwartz. </author> <title> Programming Perl. </title> <publisher> O'Reilly & Associates, Inc., </publisher> <address> Sebastopol, CA, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: Thus only the VCR agent need know the complex set of serial-line instructions for controlling a VCR; other agents can simply use the vcr.play command. SodaBot consists of two distinct components. The agent programming language, SodaBotL, is used to code agents. Its syntax is similar to Perl <ref> [47] </ref>, but SodaBotL has several additions which make it suitable for agent programming. These additions consist of language primatives which make it simple to specify agent interactions without having worry about the details of the execution.
Reference: [48] <author> J. White. </author> <title> Mobile agents white paper. </title> <note> http://www.genmagic.com/agents/Whitepaper/whitepaper.html, 1996. </note>
Reference-contexts: Is SodaBot necessary? Well, it is certainly required for our interactions with the Intelligent Room's existing infrastructure of agents. However, there are several other agent systems which provide similar levels of network accessibility and easy user interaction. AgentTCL [14], and to some extent TeleScript <ref> [48] </ref>, could be used to build a similar infrastructure. Given the functionality gained by building our application in the context of Intelligent Room, SodaBot is the logical choice. 3.1 SodaBot SodaBot [6] is a software agent environment developed at the MIT Artificial Intelligence Lab.
Reference: [49] <author> I. H. Witten, A. Moffat, and T. C. Bell. </author> <title> Managing Gigabytes: Compressing and Indexing Documents and Images. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1994. </year> <month> 73 </month>
Reference-contexts: Haystack is more than an information retrieval system however. In fact, it is designed to be layered on top of more conventional IR systems. The current implementation is essentially a complex set of wrappers built primarily around the MG <ref> [49] </ref> textual IR system. Haystack is trying to provide a usable interface to IR by layering itself between the complex and difficult IR system and its users. For us, Haystack will provide the tools for managing our documents. However, Haystack also in many ways provides us with our inspriration.
Reference: [50] <author> T. Yan and H. Garcia-Molina. </author> <title> SIFT A Tool for Wide-Area Information Dissem--ination. </title> <booktitle> Proceedings of the 1995 USENIX Technical Conference, </booktitle> <pages> pages 177-186, </pages> <year> 1995. </year>
References-found: 50

