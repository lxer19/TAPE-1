URL: http://www.cri.ensmp.fr/doc/A-282.ps.Z
Refering-URL: http://www.cri.ensmp.fr/rapports.html
Root-URL: 
Title: Interprocedural Array Region Analyses  
Author: Beatrice Creusillet, Fran~cois Irigoin 
Address: 35, rue Saint-Honore, F-77305 FONTAINEBLEAU Cedex FRANCE  
Affiliation: Centre de Recherche en Informatique, Ecole des mines de Paris  
Abstract: Many program optimizations require exact knowledge of the sets of array elements that are referenced in or that flow between statements or procedures. Some examples are array privatization, generation of communications in distributed memory machines, or compile-time optimization of cache behavior in hierarchical memory machines. Exact array region analysis is introduced in this article. These regions exactly represent the effects of statements and procedures upon array variables. To represent the flow of these data, we also introduce two new types of array region analyses: IN and OUT regions. The intraprocedural propagation is presented, as well as a general linear framework for interprocedural analyses, which handles array reshapes. The intra- and inter-procedural propagation of array regions is implemented in pips, the interprocedural parallelizer of fortran programs developed at Ecole des mines de Paris. Keywords: interprocedural analysis, array data flow analysis, array re gions, array reshaping.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> American National Standard Institute. </author> <title> Programming Language FORTRAN, ANSI X3.9-1978, </title> <type> ISO 1539-1980, </type> <year> 1983. </year>
Reference-contexts: The other constructs, in particular IF constructs, are not considered here, because it would not provide useful insights to the reader. However, the implementation of array region computation 4 in pips covers the whole fortran standard <ref> [1] </ref>, with a few minor exceptions 2 which can easily be avoided. <p> On the contrary, top-down analyses propagate the solutions toward the leaves of the tree: the solution for the inner nodes are computed from the solutions at the upper level. Interprocedural propagations are performed on the program call graph. This graph is assumed acyclic, according to the fortran standard <ref> [1] </ref> which prohibits recursive function calls. Analyses can be performed bottom-up or top-down.
Reference: 2. <author> Corinne Ancourt and Fran~cois Irigoin. </author> <title> Scanning polyhedra with DO loops. </title> <booktitle> In Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 39-50, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: We then eliminate I#init, because it refers to 1 . We obtain f 1 ==I-1g, which is relative to 2 . The exactness of the operation depends on several factors, such as the combined characteristics of the transformer and the region, and the exactness of the variable elimination <ref> [2, 29] </ref>. When the operation is not exact, it leads to an over-approximation of the target region, which becomes a MAY region. Merging over an iteration space The region corresponding to the body of a loop is a function of the value i of the loop index. <p> The elimination of i from R (i) lbiub is exact according to the conditions of Ancourt or Pugh <ref> [2, 29] </ref> 4 . The first condition ensures that the iteration space can be exactly described by a convex polyhedron over the program variables (here lb i ub) 5 . <p> At Steps 10 and 11, the exactness of the variable elimination is verified with the usual conditions <ref> [2, 29] </ref>. Step 13 is performed using the relations between formal and actual parameters, and between the declarations of global variables in the source and target routines (this gives a translation context system). The variables belonging to the name space of the source routine are then eliminated. <p> The variables belonging to the name space of the source routine are then eliminated. The exactness of this operation depends on the combined characteristics of the translation context system and R, and the exactness of the variable elimination <ref> [2, 29] </ref>. The last step is particularly useful in case of a partial matching between A and B, which is the case when A and B belong to a COMMON that is not similarly declared in the source and target routine.
Reference: 3. <author> Beatrice Apvrille-Creusillet. </author> <title> Regions exactes et privatisation de tableaux (Exact array region analyses and array privatization). </title> <type> Master's thesis, </type> <institution> Universite Paris VI, France, </institution> <month> September </month> <year> 1994. </year> <note> Available via http://www.cri.ensmp.fr/~creusil. 27 </note>
Reference-contexts: In pips [21], the interprocedural parallelizer of fortran programs developed at Ecole des mines de Paris, we have extended Triolet's array regions [33] (which are array element sets described by convex polyhedra) to compute summaries that exactly represent the effects of statements and procedures on sets of array elements <ref> [3] </ref>, whenever possible; whereas the regions originally defined by Triolet were over-approximations of these effects. The resulting exact read and write regions were found necessary by Coelho [10, 11] to efficiently compile hpf. <p> We therefore introduce two new types of exact regions: for any statement or procedure, in regions contain its imported array elements, and out regions represent its set of live array elements. The possible applications are numerous. in and out regions are already used in pips to privatize array sections <ref> [3] </ref>, and we intend to use them for memory allocation when compiling signal processing specifications based on dynamic single assignment. In massively parallel or heterogeneous systems, they can also be used to compute the communications before and after the execution of a piece of code. <p> Its features are described in Table 1, Column 5. For instance, when the original regions are EXACT regions, a first step computes R 1 " R 2 ; the result is a list of regions <ref> [3] </ref>; these regions are then merged using S , an extension of [ to union of lists. 3 The test R 1 [ R 2 R 1 [ R 2 is implemented in pips. 7 Translation from one store to another one The linear constraints defining a region often involve integer <p> To apply one of the preceding operators to two regions, they must be relative to the same store. Let T 1 ! 2 denote the transformation of a region relative to the store 1 into a region relative to the store 2 . This transformation is described in <ref> [3] </ref>. Very briefly, it consists in adding to the predicate of the region, the constraints of the transformer that abstracts the effects of the program between the two stores. The variables of the original store ( 1 ) are then eliminated. <p> represent the sets of array elements that are imported or exported by the corresponding code fragment. in regions contain the locally upward exposed read elements, and are thus different from the usual upward-exposed read references. in and out regions are already used in pips for the privatization of array sections <ref> [3, 13] </ref> even when there are procedure calls. We also provide a general linear framework for the interprocedural propagation of regions, regardless of their type. It handles array reshapes, even in COMMONs that do not have the same data layout, and when arrays do not have the same type.
Reference: 4. <author> V. Balasundaram and K. Kennedy. </author> <title> A technique for summarizing data access and its use in parallelism enhancing transformations. </title> <booktitle> In International Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 41-53, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Many other less recent studies <ref> [9, 19, 4] </ref> have addressed the problem of the interprocedural propagation of array element sets. But they did not provide sufficient symbolic analyses, and did not tackle array reshaping.
Reference: 5. <author> M. Berry, D. Chen, P. Koss, D. Kuck, V. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orzag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, and J. Martin. </author> <title> The PERFECT Club benchmarks : Effective performance evaluation of supercomputers. </title> <type> Technical Report CSRD-827, </type> <institution> CSRD, University of Illinois, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: Examples of other applications are software specification verification or compilation of out-of-core computations [28]. To support the exactness of the analysis, an accurate interprocedural translation is needed. However, by examining the Perfect Club Benchmarks <ref> [5] </ref>, we found out that the existing methods for handling array reshapes were insufficient. <p> Fig. 6. Interprocedural propagation of array regions. 6.2 Array region translation This section describes the translation part of the interprocedural propagation. Because the source and target variables may not have the same declaration (array reshaping), this operation is not straightforward. By examining the Perfect Club benchmarks <ref> [5] </ref>, we found it necessary to handle several non-exclusive cases: 1. Array reshaping due to different dimension declarations. 2. Offsets between the first elements of the source and target arrays due to parameter passing (CALL F (A (1,J)) for instance); 3.
Reference: 6. <author> W. Blume and R. Eigenmann. </author> <title> Performance analysis of parallelizing compilers on the Perfect Benchmarks programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(6) </volume> <pages> 643-656, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: 1 Introduction The efficient compilation of scientific programs for massively parallel machines or hierarchical memory machines requires advanced program optimizations to deal with memory management issues. For instance, Blume and Eigenmann <ref> [6] </ref> have shown that array privatization could greatly enhance the amount of potential parallelism in sequential programs. This technique basically aims at discovering array sections that are used as temporaries in loops, and can thus be replaced by local copies on each processor.
Reference: 7. <author> Thomas Brandes. </author> <title> The importance of direct dependences for automatic paralleliza-tion. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 407-417, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Solving such problems requires a precise intra- and inter-procedural analysis of array data flow, that is to say how individual array element values are defined and used (or flow ) during program execution. A recent type of analysis <ref> [7, 16] </ref> has opened up wide perspectives in this area: It provides an exact analysis of array data flow, originally in monopro-cedural programs with static control. This last constraint has since been partially removed [25, 12], at the expense of accuracy.
Reference: 8. <author> Michael Burke and Ron Cytron. </author> <title> Interprocedural dependence analysis and paral-lelization. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 21(7) </volume> <pages> 162-175, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: , 2 )-W-EXACT-f1&lt;= 1 &lt;=5, 2&lt;= 2 &lt;=10g&gt; &lt;D ( 1 , 2 )-W-EXACT-f1&lt;= 1 &lt;=5, 2 ==1g&gt; 24 7 Related Work The previous work closest to ours are those of Triolet [33], Tang [31], Hall [18], Li [27, 17] and Leservot [23], and the works by Burke and Cytron <ref> [8] </ref> and Maslov [26] for the interprocedural translation. Many other less recent studies [9, 19, 4] have addressed the problem of the interprocedural propagation of array element sets. But they did not provide sufficient symbolic analyses, and did not tackle array reshaping. <p> For each procedure, this method computes in-going effects, which bear some resemblance with in regions, and out-going effects, which are somewhat similar to downward exposed writes, and are thus different from out regions. Burke and Cytron <ref> [8] </ref> They alleviate the memory disambiguation problem by linearizing all array accesses when possible. This is equivalent to using the system S in our method. However, we have seen that this may lead to non linear expressions, that prevent further dependence testing for instance.
Reference: 9. <author> D. Callahan and K. Kennedy. </author> <title> Analysis of interprocedural side effects in a parallel programming environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: Fur--thermore the complexity of the method makes it useless on large programs. Another approach is to compute conservative summaries of the effects of statements and procedure calls on sets of array elements <ref> [33, 9] </ref>. Their relatively weak complexity (in practice) allows the analysis of large programs. But since these analyses are flow insensitive, and since they do not precisely take into account the modifications of the values of integer scalar variables, they are not accurate enough to support powerful optimizations. <p> Many other less recent studies <ref> [9, 19, 4] </ref> have addressed the problem of the interprocedural propagation of array element sets. But they did not provide sufficient symbolic analyses, and did not tackle array reshaping. <p> do not handle global 7! global translation when the COMMON to which the source and target arrays belong, does not have the same data layout in the caller and callee. 25 Li et al.[27, 17] In the Panorama compiler, the representation of array element sets is a list of rsds <ref> [9] </ref> with bounds and step, guarded by predicates derived from IF conditions. Since our regions also include some IF conditions, the advantages of this representation over ours (except the use of lists) is unclear. They also have different types of array element sets.
Reference: 10. <author> Fabien Coelho. </author> <title> Compilation of I/O communications for HPF. </title> <booktitle> In Frontiers'95, </booktitle> <pages> pages 102-109, </pages> <month> February </month> <year> 1995. </year> <note> Available via http://www.cri.ensmp.fr/~coelho. </note>
Reference-contexts: The resulting exact read and write regions were found necessary by Coelho <ref> [10, 11] </ref> to efficiently compile hpf. However, they cannot be used to compute array data flow, and are thus insufficient for optimizations such as array privatization. <p> We define several types of summaries. 26 read and write array regions represent the exact effects of statements and procedures upon array elements whenever possible. Whereas the regions initially defined by Triolet [33] are over-approximations of the effects of procedures. read and write regions are used by Coelho <ref> [10] </ref> to efficiently compile hpf.
Reference: 11. <author> Fabien Coelho and Corinne Ancourt. </author> <title> Optimal compilation of HPF remappings. </title> <type> Technical Report A-277-CRI, </type> <institution> CRI, Ecole des Mines de Paris, </institution> <month> October </month> <year> 1995. </year> <note> To appear in JPDC in 1996. </note>
Reference-contexts: The resulting exact read and write regions were found necessary by Coelho <ref> [10, 11] </ref> to efficiently compile hpf. However, they cannot be used to compute array data flow, and are thus insufficient for optimizations such as array privatization.
Reference: 12. <author> Jean-Fran~cois Collard. </author> <title> Automatic parallelization of while-loops using speculative execution. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 23(2) </volume> <pages> 191-219, </pages> <year> 1995. </year>
Reference-contexts: A recent type of analysis [7, 16] has opened up wide perspectives in this area: It provides an exact analysis of array data flow, originally in monopro-cedural programs with static control. This last constraint has since been partially removed <ref> [25, 12] </ref>, at the expense of accuracy. A partial interprocedural ? E-mail: fcreusillet,irigoing@cri.ensmp.fr extension [23] has also been defined, but only in a static control framework. Fur--thermore the complexity of the method makes it useless on large programs.
Reference: 13. <author> Beatrice Creusillet. </author> <title> Array regions for interprocedural parallelization and array privatization. </title> <type> Report A-279, </type> <institution> CRI, Ecole des Mines de Paris, </institution> <month> November </month> <year> 1995. </year> <note> Available at http://www.cri.ensmp.fr/~creusil. </note>
Reference-contexts: represent the sets of array elements that are imported or exported by the corresponding code fragment. in regions contain the locally upward exposed read elements, and are thus different from the usual upward-exposed read references. in and out regions are already used in pips for the privatization of array sections <ref> [3, 13] </ref> even when there are procedure calls. We also provide a general linear framework for the interprocedural propagation of regions, regardless of their type. It handles array reshapes, even in COMMONs that do not have the same data layout, and when arrays do not have the same type.
Reference: 14. <author> Beatrice Creusillet. </author> <title> IN and OUT array region analyses. </title> <booktitle> In Fifth International Workshop on Compilers for Parallel Computers, </booktitle> <pages> pages 233-246, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: ele ments; the approximation of the region: EXACT when the region exactly represents the requested set of array elements, or MAY or MUST if it is an over- or under-approximation (MUST EXACT MAY); in the rest of the paper, we only 6 consider EXACT and MAY regions; in previous papers <ref> [15, 14] </ref> MUST was unfor-tunately used to mean EXACT. For instance, the region: &lt;A ( 1 , 2 )-W-EXACT-f 1 ==I, 1 == 2 g&gt; where the region parameters 1 and 2 respectively represent the first and second dimensions of A, corresponds to an assignment of the element A (I,I).
Reference: 15. <author> Beatrice Creusillet and Fran~cois Irigoin. </author> <title> Interprocedural array regions analyses. </title> <booktitle> In Languages and Compilers for Parallel Computing, Lecture Notes in Computer Science, </booktitle> <pages> pages 46-60. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: ele ments; the approximation of the region: EXACT when the region exactly represents the requested set of array elements, or MAY or MUST if it is an over- or under-approximation (MUST EXACT MAY); in the rest of the paper, we only 6 consider EXACT and MAY regions; in previous papers <ref> [15, 14] </ref> MUST was unfor-tunately used to mean EXACT. For instance, the region: &lt;A ( 1 , 2 )-W-EXACT-f 1 ==I, 1 == 2 g&gt; where the region parameters 1 and 2 respectively represent the first and second dimensions of A, corresponds to an assignment of the element A (I,I).
Reference: 16. <author> Paul Feautrier. </author> <title> Dataflow analysis of array and scalar references. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(1) </volume> <pages> 23-53, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Solving such problems requires a precise intra- and inter-procedural analysis of array data flow, that is to say how individual array element values are defined and used (or flow ) during program execution. A recent type of analysis <ref> [7, 16] </ref> has opened up wide perspectives in this area: It provides an exact analysis of array data flow, originally in monopro-cedural programs with static control. This last constraint has since been partially removed [25, 12], at the expense of accuracy. <p> The previous sets are exact sets, unless they contain an unknown component. Our regions should be more accurate, because we can keep information about all the variables, even in case of a MAY region. Leservot [23] Leservot has extended Feautrier's array data flow analysis <ref> [16] </ref> to handle static control programs with procedure calls.
Reference: 17. <author> Jungie Gu, Zhiyuan Li, and Gyungho Lee. </author> <title> Symbolic array dataflow analysis for array privatization and program parallelization. </title> <booktitle> In Supercomputing, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: &lt;=N,1<= 2 &lt;=10,1<= 3 &lt;=20, 2 +10 3 &lt;=110g&gt; &lt;D ( 1 , 2 )-W-EXACT-f1&lt;= 1 &lt;=5, 2&lt;= 2 &lt;=10g&gt; &lt;D ( 1 , 2 )-W-EXACT-f1&lt;= 1 &lt;=5, 2 ==1g&gt; 24 7 Related Work The previous work closest to ours are those of Triolet [33], Tang [31], Hall [18], Li <ref> [27, 17] </ref> and Leservot [23], and the works by Burke and Cytron [8] and Maslov [26] for the interprocedural translation. Many other less recent studies [9, 19, 4] have addressed the problem of the interprocedural propagation of array element sets.
Reference: 18. <author> Mary Hall, Brian Murphy, Saman Amarasinghe, Shih-Wei Liao, and Monica Lam. </author> <title> Interprocedural analysis for parallelization. </title> <booktitle> In Languages and Compilers for Parallel Computing, Lecture Notes in Computer Science, </booktitle> <pages> pages 61-80. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: )-W-EXACT-f1&lt;= 1 &lt;=N,1<= 2 &lt;=10,1<= 3 &lt;=20, 2 +10 3 &lt;=110g&gt; &lt;D ( 1 , 2 )-W-EXACT-f1&lt;= 1 &lt;=5, 2&lt;= 2 &lt;=10g&gt; &lt;D ( 1 , 2 )-W-EXACT-f1&lt;= 1 &lt;=5, 2 ==1g&gt; 24 7 Related Work The previous work closest to ours are those of Triolet [33], Tang [31], Hall <ref> [18] </ref>, Li [27, 17] and Leservot [23], and the works by Burke and Cytron [8] and Maslov [26] for the interprocedural translation. Many other less recent studies [9, 19, 4] have addressed the problem of the interprocedural propagation of array element sets.
Reference: 19. <author> Paul Havlak and Ken Kennedy. </author> <title> An implementation of interprocedural bounded regular section analysis. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 350-360, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Many other less recent studies <ref> [9, 19, 4] </ref> have addressed the problem of the interprocedural propagation of array element sets. But they did not provide sufficient symbolic analyses, and did not tackle array reshaping.
Reference: 20. <author> Fran~cois Irigoin. </author> <title> Interprocedural analyses for programming environments. </title> <booktitle> In Workshop on Environments and Tools for Parallel Scientific Computing, </booktitle> <pages> pages 333-350, </pages> <month> September </month> <year> 1992. </year> <month> 28 </month>
Reference-contexts: Furthermore the exponential speed improvement of computers renders these analyses fast enough to perform them on real life programs. 3.2 Transformers and preconditions Two auxiliary analyses are of interest in the remainder of this paper: transformers and preconditions <ref> [20] </ref>. Transformers abstract the effects of instructions upon the values of integer scalar variables by giving an affine approximation of the relations that exist between their values before and after the execution of a statement or procedure call.
References-found: 20

