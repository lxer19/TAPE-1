URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-89-876/CS-TR-89-876.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-89-876/
Root-URL: http://www.cs.wisc.edu
Email: shavlik@cs.wisc.edu  
Title: Acquiring Recursive and Iterative Concepts with Explanation-Based Learning explanation-based generalization, generalizing explanation structures, generalizing to
Author: Jude W. Shavlik 
Note: (Submitted to Machine Learning) Keywords:  
Address: Wisconsin Madison  
Affiliation: Department of Computer Sciences University of  
Abstract: University of Wisconsin Computer Sciences Technical Report 876 (September 1989) Abstract In explanation-based learning, a specific problem's solution is generalized into a form that can be later used to solve conceptually similar problems. Most research in explanation-based learning involves relaxing constraints on the variables in the explanation of a specific example, rather than generalizing the graphical structure of the explanation itself. However, this precludes the acquisition of concepts where an iterative or recursive process is implicitly represented in the explanation by a fixed number of applications. This paper presents an algorithm that generalizes explanation structures and reports empirical results that demonstrate the value of acquiring recursive and iterative concepts. The BAGGER2 algorithm learns recursive and iterative concepts, integrates results from multiple examples, and extracts useful subconcepts during generalization. On problems where learning a recursive rule is not appropriate, the system produces the same result as standard explanation-based methods. Applying the learned recursive rules only requires a minor extension to a PROLOG-like problem solver, namely, the ability to explicitly call a specific rule. Empirical studies demonstrate that generalizing the structure of explanations helps avoid the recently reported negative effects of learning. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ahn, W., Mooney, R. J., Brewer, W. F., & DeJong, G. F. </author> <year> (1987). </year> <title> Schema acquisition from one example: Psychological evidence for explanation-based learning. </title> <booktitle> Proceedings of the Ninth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 50-57). </pages> <address> Seattle, WA: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference-contexts: Even when such a system correctly constructed a concept like the building-a-wagon schema, it could not know that it had generalized properly. The system could not tell which concepts fell within its scope and which did not. Third, there is recent psychological evidence <ref> (Ahn, Mooney, Brewer, & DeJong, 1987) </ref> that people can generalize number on the basis of one example. One may argue that the fault for not properly generalizing lies with the explanation module.
Reference: <author> Anderson, J. R. </author> <year> (1986). </year> <title> Knowledge compilation: The general learning mechanism. </title> <editor> In R. S. Michalski, </editor> <publisher> J. </publisher>
Reference: <editor> G. Carbonell, & T. M. Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach (Vol. 2). </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Andreae, P. M. </author> <year> (1984). </year> <title> Justified generalization: Acquiring procedures from example. </title> <type> Doctoral dissertation, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA. </address>
Reference: <author> Bauer, M. </author> <year> (1979). </year> <title> Programming by examples. </title> <journal> Artificial Intelligence, </journal> <volume> 12, </volume> <pages> 1-21. </pages>
Reference: <author> Biermann, A. W. </author> <year> (1978). </year> <title> The inference of regular LISP programs from examples. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 8, </volume> <pages> 585-600. </pages>
Reference: <author> Cheng, P., & Carbonell, J. G. </author> <year> (1986). </year> <title> The FERMI system: Inducing iterative macro-operators from experience. </title> <booktitle> Proceedings of the Fifth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 490-495). </pages> <address> Philadelphia, PA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Chien, S. A. </author> <year> (1989). </year> <title> Using and refining simplifications: Explanation-based learning of plans in intractable domains. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 590-595). </pages> <address> Detroit, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Clocksin, W. F., & Mellish, C. S. </author> <year> (1984). </year> <title> Programming in PROLOG. Berlin: Springer Verlag. 37 Acquiring Recursive and Iterative Concepts Cohen, </title> <editor> W. W. </editor> <year> (1987). </year> <title> A technique for generalizing number in explanation-based learning. </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning (pp. </booktitle> <pages> 256-269). </pages> <address> Ann Arbor, MI: </address> <publisher> Morgan Kaufmann. </publisher> <editor> 38 Acquiring Recursive and Iterative Concepts Cohen, W. W. </editor> <year> (1989). </year> <title> Solution path caching mechanisms which provably improve performance (Technical Report DCS-TR-254). </title> <address> New Brunswick, NJ: </address> <institution> Rutgers University, Department of Computer Science. </institution>
Reference-contexts: This could be accomplished by reasoning about the semantics of the system's predicate calculus functions and predicates. Properties such as symmetry, transitivity, and reflexivity may help determine constraints on order independence. Programmers use PROLOG's cut operator <ref> (Clocksin & Mellish, 1984) </ref> to indicate where backtracking will be a waste of time, and it may prove fruitful to have a learning system decide where to place cuts in the rules it acquires.
Reference: <author> DeJong, G. F., & Mooney, R. J. </author> <year> (1986). </year> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 145-176. </pages>
Reference: <author> Dietterich, T. G., & Michalski, R. S. </author> <year> (1984). </year> <title> Discovering patterns in sequences of objects. </title> <journal> Artificial Intelligence, </journal> <volume> 25, </volume> <pages> 257-294. </pages>
Reference: <author> Ellman, T. </author> <year> (1985). </year> <title> Generalizing logic circuit designs by analyzing proofs of correctness. </title> <booktitle> Proceedings of the Ninth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 643-646). </pages> <address> Los Angeles, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fikes, R. E., Hart, P. E., & Nilsson, N. J. </author> <year> (1972). </year> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3, </volume> <pages> 251-288. </pages>
Reference: <author> Green, C. C. </author> <year> (1969). </year> <title> Application of theorem proving to problem solving. </title> <booktitle> Proceedings of the First International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 219-239). </pages> <address> Washington, D.C.: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hirsh, H. </author> <year> (1987). </year> <title> Explanation-based generalization in a logic-programming environment. </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 221-227). </pages> <address> Milan, Italy: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Jacobson, N. </author> <year> (1951). </year> <title> Lectures in abstract algebra (Vol. </title> <type> 1). </type> <institution> Princeton, </institution> <address> NJ: </address> <publisher> Von Nostrand. </publisher>
Reference-contexts: EGGS organizes hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 3 The number of different ways to implement an N-input OR gate with binary gates is N ! (N -1)! (2 N - 2)! hhhhhhhhhh <ref> (Jacobson, 1951, page 18) </ref>. 17 Acquiring Recursive and Iterative Concepts its rules according to the number of inputs involved (i.e., in six groups) and only checks possibly relevant rules during problem solving. For EGGS, only the time spent on problems solved by a learned rule is recorded.
Reference: <author> Kedar-Cabelli, S. T. </author> <year> (1986). </year> <title> Purpose-directed analogy: A summary of current research. </title> <editor> In T. </editor> <publisher> M. </publisher>
Reference: <author> Mitchell, J. G. Carbonell, & R. S. Michalski, (Eds.), </author> <title> Machine learning: A guide to current research. </title> <address> Hingham, MA: </address> <publisher> Kluwer. </publisher>
Reference: <author> Kedar-Cabelli, S. T., & McCarty, L. T. </author> <year> (1987). </year> <title> Explanation-based generalization as resolution theorem proving. </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning (pp. </booktitle> <pages> 383-389). </pages> <address> Irvine, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Keller, R. M. </author> <year> (1987). </year> <title> Defining operationality for explanation-based learning. </title> <booktitle> Proceedings of the National Conference on Artificial Intelligence (pp. </booktitle> <pages> 482-487). </pages> <address> Seattle, WA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kodratoff, Y. </author> <year> (1979). </year> <title> A class of functions synthesized from a finite number of examples and a LISP program scheme. </title> <journal> International Journal of Computer and Information Sciences, </journal> <volume> 8, </volume> <pages> 489-521. </pages>
Reference: <author> Korf, R. E. </author> <year> (1985). </year> <title> Depth-first iterative-deepening: An optimal admissible tree search. </title> <journal> Artificial Intelligence, </journal> <volume> 27, </volume> <pages> 97-109. </pages>
Reference-contexts: When facing a new problem, it first tries to apply the rules that involve one action; if this fails, it tries rules involving two actions, and so forth. Shavlik (in press) demonstrates the efficiency of this strategy, which is similar to iterative deepening <ref> (Korf, 1985) </ref>; it works well because the effort required to produce a plan can depend exponentially on the number of actions involved.
Reference: <author> Laird, J. E. , Rosenbloom, P. S., & Newell, A. </author> <year> (1986). </year> <title> Chunking in SOAR: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 11-46. </pages>
Reference-contexts: Standard explanation-based learning algorithms (e.g., Fikes, Hart, & Nilsson, 1972; Hirsh, 1987; Kedar-Cabelli & McCarty, 1987; Mooney & Bennett, 1986) and similar algorithms for chunking <ref> (Laird, Rosenbloom, & Newell, 1986) </ref> cannot treat these cases differently. These methods, possibly after pruning the explanation to eliminate irrelevant parts, replace constants with constrained variables. They cannot significantly augment the explanation during generalization. <p> If they are to scale to larger problems, EBL systems must not expect the explanation module to do more than narrowly explain the solution to the specific problem at hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 The SOAR system <ref> (Laird et al., 1986) </ref> would seem to acquire a number of concepts that together are slightly more general. In addition to a new operator for moving four blocks, the system would acquire new operators for moving three blocks, two blocks, and one block, but not for five or more.
Reference: <author> Manna, Z. </author> <year> (1974). </year> <title> Mathematical theory of computation. New York: McGraw-Hill. 39 Acquiring Recursive and Iterative Concepts McCarthy, </title> <editor> J. </editor> <year> (1963). </year> <title> Situations, actions, and causal laws (Memorandum). </title> <institution> Stanford, CA: Stanford University, Department of Computer Science. </institution> <note> (Reprinted in M. </note> <editor> Minsky, (Ed.), </editor> <booktitle> Semantic information processing., 1968, </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press.) </publisher> <editor> Minton, S. N. </editor> <year> (1988). </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> Proceedings of the Seventh National Conference on Artificial Intelligence (pp. </booktitle> <pages> 564-569). </pages> <address> St. Paul, MN: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: One weakness of systems that generalize explanation structures is that they may fall into infinite loops. Although the halting problem is undecidable in general, one can prove termination in restricted circumstances <ref> (Manna, 1974) </ref>. Systems that generalize number need to incorporate techniques for proving termination. BAGGER2 contains a partial solution to this problem.
Reference: <author> Minton, S. N. </author> <year> (1989). </year> <title> Learning effective search control knowledge: An explanation-based approach. </title> <address> Hingham, MA: </address> <publisher> Kluwer. </publisher>
Reference: <author> Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. </author> <year> (1986). </year> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 47-80. </pages>
Reference-contexts: However, such an approach places a much larger burden on the explanation module, as well as on the domain theory writer. Constructing explanations is a demanding, often intractable, task <ref> (Mitchell et al., 1986) </ref>. Generalization is more focused and less computationally intensive; hence it makes sense to shift as much of the burden of learning onto this module. <p> Both techniques assume that, in the course of solving a problem, the solver interconnects a collection of pieces of general knowledge (e.g., inference rules, rewrite rules, or plan schemata), using unification to insure compatibility. The generalizers then produce an explanation structure <ref> (Mitchell et al., 1986) </ref> from the specific problem's explanation. To build the explanation structure, they first strip away the details of the specific problem and then replace each instantiated rule in the explanation with a copy of the original general rule.
Reference: <author> Mitchell, T. M., Mahadevan, S., & Steinberg, L. I. </author> <year> (1985). </year> <title> LEAP: A learning apprentice for VLSI design. </title> <booktitle> Proceedings of the Ninth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 573-580). </pages> <address> Los Angeles, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A system that possesses the ability to generalize the graphical structure of explanations, adding additional applications of inference rules where appropriate, can learn recursive and iterative concepts from a specific example. This article presents such a system. To see the need for generalizing explanation structures, consider the LEAP system <ref> (Mitchell, Mahadevan, & Steinberg, 1985) </ref>, an early application of explanation-based learning. The system observes an example of using NOR gates to compute the Boolean AND of two OR's, and it discovers that the technique generalizes to computing the Boolean AND of any two inverted Boolean functions.
Reference: <author> Mooney, R. J. </author> <year> (1988). </year> <title> Generalizing the order of operators in macro-operators. </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning (pp. </booktitle> <pages> 270-283). </pages> <address> Ann Arbor, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Mooney, R. J. </author> <year> (1989). </year> <title> The effect of rule use on the utility of explanation-based learning. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 725-730). </pages> <address> Detroit, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Mooney, R. J. </author> <title> (in press). A general explanation-based learning mechanism and its application to narrative understanding. </title> <publisher> London: Pitman. </publisher>
Reference: <author> Mooney, R. J., & Bennett, S. W. </author> <year> (1986). </year> <title> A domain independent explanation-based generalizer. </title> <booktitle> Proceedings of the Fifth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 551-555). </pages> <address> Philadelphia, PA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Prieditis, A. E. </author> <year> (1986). </year> <title> Discovery of algorithms from weak methods. </title> <booktitle> Proceedings of the International Meeting on Advances in Learning (pp. </booktitle> <pages> 37-52). </pages> <address> Les Arcs, Switzerland. </address>
Reference: <author> Rajamoney, S., & DeJong, G. F. </author> <year> (1987). </year> <title> The classification, detection, and handling of imperfect theory problems. </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 205-207). </pages> <address> Milan, Italy: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Riddle, P. J. </author> <year> (1989). </year> <title> Automating shifts of problem representation. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ. </address>
Reference: <author> Sammut, C. B., & Banerji, R. B. </author> <year> (1986). </year> <title> Learning concepts by asking questions. </title> <editor> In R. S. Michalski, </editor> <publisher> J. </publisher>
Reference: <editor> G. Carbonell, & T. M. Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach (Vol. 2). </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Segre, A. M. </author> <year> (1987). </year> <title> On the operationality/generality trade-off in explanation-based learning. </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 242-248). </pages> <address> Milan, Italy: </address> <publisher> Morgan Kaufmann. </publisher> <editor> 40 Acquiring Recursive and Iterative Concepts Shavlik, J. W. (in press). </editor> <title> Extending explanation-based learning by generalizing the structure of explanations. </title> <publisher> London: Pitman. </publisher>
Reference: <author> Shavlik, J.W., & DeJong, G. F. </author> <year> (1985). </year> <title> Building a computer model of learning classical mechanics. </title> <booktitle> Proceedings of the Seventh Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 351-355). </pages> <address> Irvine, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Shavlik, J.W., & DeJong, G. F. </author> <year> (1987). </year> <title> BAGGER: An EBL system that extends and generalizes explanations. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 516-520). </pages> <address> Seattle, WA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Shavlik, J.W., & DeJong, G. F. </author> <title> (in press). Learning in mathematically-based domains: Understanding and generalizing obstacle cancellations. </title> <journal> Artificial Intelligence. </journal>
Reference: <author> Shavlik, J.W., DeJong, G. F., & Ross, B. H. </author> <year> (1987). </year> <title> Acquiring special case schemata in explanation-based learning. </title> <booktitle> Proceedings of the Ninth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 351-355). </pages> <address> Seattle, WA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Shavlik, J. W., & Maclin, R. </author> <year> (1988). </year> <title> An approach to acquiring algorithms by observing expert behavior. </title> <booktitle> Proceedings of the AAAI-88 Workshop on Automating Software Design (pp. </booktitle> <pages> 172-181). </pages> <address> St. Paul, MN. </address>
Reference: <author> Shell, P., & Carbonell, J. G. </author> <year> (1989). </year> <title> Towards a general framework for composing disjunctive and iterative macro-operators. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 596-602). </pages> <address> Detroit, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For instance, if BAGGER2 observes the summation of four numbers it will not produce the efficient result mentioned above; instead it will produce a rule that performs the intermediate summations. One possible extension is to create a library of templates for soluble recurrences, then match them against explanations <ref> (Shell & Carbonell, 1989) </ref>. However, a more direct approach, such as Weld's (1986) aggregation technique, may be more fruitful; aggregation creates a description of a continuous process from a series of discrete events.
Reference: <author> Smith, D. E., & Genesereth, M. R. </author> <year> (1985). </year> <title> Ordering conjunctive queries. </title> <journal> Artificial Intelligence, </journal> <volume> 26, </volume> <pages> 171-215. </pages>
Reference-contexts: A related area of future research involves determining the most efficient ordering of conjunctive goals <ref> (Smith & Genesereth, 1985) </ref> in recursive rules. Consider an acquired iterative rule that builds towers of a desired height, subject to the constraint that no block can be placed upon a narrower block.
Reference: <author> Smith, D. R. </author> <year> (1984). </year> <title> The synthesis of LISP programs from examples: A survey. </title> <editor> In A. Biermann, </editor> <publisher> G. </publisher>
Reference-contexts: The class of recursive concepts this technique recognizes needs to be characterized, and BAGGER2 should be extended to cover a wider range of recursive rule applications. Techniques for detecting recursive patterns developed in automatic programming research may be applicable to this task <ref> (Smith, 1984) </ref>. However, such approaches can introduce backtracking search into the generalization process, thereby leading to problems of intractability. Also, if they allow multiple parses of an explanation, techniques for choosing the best parse may be required.
Reference: <editor> Guiho, and Y. Kodratoff, (Eds.), </editor> <title> Automatic program construction techniques. </title> <address> New York: </address> <publisher> MacMillan. </publisher>
Reference: <author> Summers, P. D. </author> <year> (1977). </year> <title> A methodology for LISP program construction from examples. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 24, </volume> <pages> 161-175. </pages>
Reference: <author> Weld, D. S. </author> <year> (1986). </year> <title> The use of aggregation in casual simulation. </title> <journal> Artificial Intelligence, </journal> <volume> 30, </volume> <pages> 1-34. 41 </pages>
References-found: 48

