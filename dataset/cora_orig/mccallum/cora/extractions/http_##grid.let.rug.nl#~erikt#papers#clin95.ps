URL: http://grid.let.rug.nl/~erikt/papers/clin95.ps
Refering-URL: http://grid.let.rug.nl/~erikt/papers/clin95.html
Root-URL: 
Email: erikt@let.rug.nl  
Title: The Limitations of Modeling Finite State Grammars with Simple Recurrent Networks  
Author: Erik F. Tjong Kim Sang vakgroep Alfa-informatica 
Date: September 5, 1995  
Address: Groningen  
Affiliation: University of  
Abstract: In his book `Mechanisms of Implicit Learning' (1993) Axel Cleeremans describes how finite state grammars can be modeled successfully with connectionist networks namely with Simple Recurrent Networks (SRNs) developed by Jeffrey El-man. However, SRNs cannot be used for modeling arbitrary finite state gram mars. In this paper I describe the limitations of this approach. 
Abstract-found: 1
Intro-found: 1
Reference: [Cle93] <author> Axel Cleeremans. </author> <title> Mechanisms of Implicit Learning. </title> <publisher> The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: One of the three learning techniques behaved surprisingly worse than could be expected from the results reported in the literature. The connectionist Simple Recurrent Networks (SRNs) were developed by Jeffrey Elman to be applied for generating or recognizing sequences [Elm90]. In [CSSM89], [SSCM91] and <ref> [Cle93] </ref>, Axel Cleeremans, David Servan-Schreiber and James McClelland report experiments in which they modeled finite state grammars with SRNs. The experiments were very successful: after a training phase in which the network only received positive examples it modeled the grammar perfectly, accepting all valid strings and rejecting all invalid strings. <p> The experiments were very successful: after a training phase in which the network only received positive examples it modeled the grammar perfectly, accepting all valid strings and rejecting all invalid strings. The results reported in <ref> [Cle93] </ref> motivated me to use SRNs for modeling the phono-tactic structure of Dutch mono-syllabic words. Earlier approaches to this problem which used the statistical Hidden Markov Models and a rule-based learning technique have produced satisfactory results. <p> In this paper I will explain why SRNs performed bad on my problem while their performance was excellent on the problem posed to them in [CSSM89], [SSCM91] and <ref> [Cle93] </ref>. First I will describe the structure of an SRN and give a description of the main experiment described in the literature. <p> To make the SRN model the grammar, we will have to train it. I will not describe the training process here. Interested readers are referred to [Elm90] and <ref> [Cle93] </ref>. Suppose the SRN has been trained to model the grammar and that the training process terminated. Then a parse of the string aab will evolve as follows: 1. (a): start with in 1 =1 and in 2 =0. <p> The SRN accepts a string if at all processing steps the next character is among the possible continuation characters according to the output of the network. 3 The experiments of Cleeremans et al. In experiments described in [CSSM89], [SSCM91] and <ref> [Cle93] </ref>, Axel Cleeremans, David Servan-Schreiber and James McClelland trained a network to recognize strings which were generated using a small grammar that was originally used by [Reb76] (figure 2). <p> While these were non-perfect scores, they indicate that reasonable models for the phonotactic structure of Dutch monosyllabic words can be found. I chose the same network learning parameters as in the experiments of <ref> [Cle93] </ref>: learning rate =0.01 and momentum ff=0.5. The network contained 27 input cells (a-zfl) and also 27 output cells. <p> Because there are more valid continuation tokens in the grammar I am looking for than in the Reber grammar, the output signals of my SRN will be smaller than the SRN modeling the Reber grammar. The output signal threshold of 0.3 used in <ref> [Cle93] </ref> would reject almost all words. Therefore I changed the string score measure used in [Cle93] into: 1. <p> The output signal threshold of 0.3 used in <ref> [Cle93] </ref> would reject almost all words. Therefore I changed the string score measure used in [Cle93] into: 1. The score assigned by an SRN to a character X in a string Y is the value of the output cell which was assigned to X after processing the prefix of Y before X. 2. <p> The performance of the network is not anywhere near the 95-99% range of the Hidden Markov Model on this problem or the 100% performance of the SRN on the Reber grammar reported in <ref> [Cle93] </ref>. 5 The influence of the number of possible continu- ations of a string My three experiments show that SRNs with the configuration I chose are unable to acquire a good model for the phonotactic structure of Dutch monosyllabic words. <p> While my target was rejecting 96% of the random strings the SRNs never were able to reject more than 6%. This performance is a sharp contrast with the performance on grammaticality checking reported in <ref> [Cle93] </ref> in which all non-grammatical strings were rejected by the network. This fact surprised me so I took a closer look at the differences between my experiments and the experiment described in chapter 2 of [Cle93]. <p> This performance is a sharp contrast with the performance on grammaticality checking reported in <ref> [Cle93] </ref> in which all non-grammatical strings were rejected by the network. This fact surprised me so I took a closer look at the differences between my experiments and the experiment described in chapter 2 of [Cle93]. The most obvious difference I was able to find was the maximal number of valid continuations of grammatical strings. In finite state model for the Reber grammar used by Cleeremans et al. (figure 2) the maximum number of valid continuation tokens is two. <p> Some continuation tokens of s occur frequently, like c (23%) and t (24%), but others are very infrequent: f, q, u and w occur less than 1%. The frequency of the continuation tokens will be mirrored by the network output, as in the example from <ref> [Cle93] </ref>. Because the network output contains noise, it will be impossible to distinguish between low frequency continuation tokens and impossible continuation tokens, like b and x in this example. In my experiments I chose the lowest character score in the training data as the string acceptance threshold value. <p> a signals 0.01 and 0.00 are in practice impossible to detect. tokens (left) and one with four continuation tokens (right) 6 Can we scale up the Cleeremans experiment? I decided to test the explanation I have given in the previous section by redoing the experiment described in chapter 2 of <ref> [Cle93] </ref>. Apart from training an SRN to decide on the grammatically of strings according to the Reber grammar shown in figure 2, I have trained SRNs with strings from two alternative grammars. <p> I trained the SRNs in steps of 50 training rounds using learning rate =0.01, momentum ff=0.5 and a network configuration that was similar to the one used in <ref> [Cle93] </ref> (7 input cells, 3 hidden cells and 7 output cells). After each 50-round step I checked if the total sum squared error of the network had changed more than 1%. If this was the fact training was continued otherwise training was stopped. <p> We can conclude that the number of valid continuation tokens influences the difficulty of the problem. [CSSM89], maximum training total sum rejected rejected continuation rounds squared test random tokens needed error words words 2 150 9079 0 299 4 100 13944 0 240 complexity. [SSCM91] and <ref> [Cle93] </ref>, showed that SRNs are capable of acquiring finite state grammars in which a grammatical substring has two valid continuation tokens. <p> This approach was promising after the successful experiments described in <ref> [Cle93] </ref>. However, the unsatisfactory results of my own experiments in which the phonotactic structure of mono-syllabic Dutch words was modeled with SRNs reduced this optimistic view.
Reference: [CSSM89] <author> A. Cleeremans, D. Servan-Schreiber, and J.L. McClelland. </author> <title> Finite state automata and simple recurrent networks. </title> <booktitle> Neural Computation, </booktitle> <pages> pages 372-381, </pages> <year> 1989. </year>
Reference-contexts: One of the three learning techniques behaved surprisingly worse than could be expected from the results reported in the literature. The connectionist Simple Recurrent Networks (SRNs) were developed by Jeffrey Elman to be applied for generating or recognizing sequences [Elm90]. In <ref> [CSSM89] </ref>, [SSCM91] and [Cle93], Axel Cleeremans, David Servan-Schreiber and James McClelland report experiments in which they modeled finite state grammars with SRNs. <p> The SRNs reached the 100% acceptance rate for valid Dutch monosyllabic words but they never rejected more than 6% of the random strings. In this paper I will explain why SRNs performed bad on my problem while their performance was excellent on the problem posed to them in <ref> [CSSM89] </ref>, [SSCM91] and [Cle93]. First I will describe the structure of an SRN and give a description of the main experiment described in the literature. <p> The SRN accepts a string if at all processing steps the next character is among the possible continuation characters according to the output of the network. 3 The experiments of Cleeremans et al. In experiments described in <ref> [CSSM89] </ref>, [SSCM91] and [Cle93], Axel Cleeremans, David Servan-Schreiber and James McClelland trained a network to recognize strings which were generated using a small grammar that was originally used by [Reb76] (figure 2). <p> We can conclude that the number of valid continuation tokens influences the difficulty of the problem. <ref> [CSSM89] </ref>, maximum training total sum rejected rejected continuation rounds squared test random tokens needed error words words 2 150 9079 0 299 4 100 13944 0 240 complexity. [SSCM91] and [Cle93], showed that SRNs are capable of acquiring finite state grammars in which a grammatical substring has two valid continuation tokens.
Reference: [Elm90] <author> Jeffrey L. Elman. </author> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14, </volume> <year> 1990. </year>
Reference-contexts: One of the three learning techniques behaved surprisingly worse than could be expected from the results reported in the literature. The connectionist Simple Recurrent Networks (SRNs) were developed by Jeffrey Elman to be applied for generating or recognizing sequences <ref> [Elm90] </ref>. In [CSSM89], [SSCM91] and [Cle93], Axel Cleeremans, David Servan-Schreiber and James McClelland report experiments in which they modeled finite state grammars with SRNs. <p> However, they cannot perform context sensitive pattern transformations (bA ! ba : replace A by a only if A is preceded by b). For this purpose Jeffrey Elman developed the Simple Recurrent Network (SRN) <ref> [Elm90] </ref>. This network is equal to a feed-forward network expanded with some context cells that are connected to the cells in the hidden layer with forward and backward connections (figure 1). <p> For these two reasons, I will accept that an output signal indicates a valid continuation character if the signal is larger than 0.3. To make the SRN model the grammar, we will have to train it. I will not describe the training process here. Interested readers are referred to <ref> [Elm90] </ref> and [Cle93]. Suppose the SRN has been trained to model the grammar and that the training process terminated. Then a parse of the string aab will evolve as follows: 1. (a): start with in 1 =1 and in 2 =0. <p> The network does not perfectly predict the `correct' continuation but it outputs some average pattern that indicates possible continuation tokens. This network behavior was already recognized in <ref> [Elm90] </ref>. The fact is that in the phonotactic grammars for Dutch the maximal number of valid continuation tokens is much larger than two. For example, according to my training corpus for the plain text experiments the number of tokens which are possible continuations of the string s is 17.
Reference: [Kle56] <author> S.C. Kleene. </author> <title> Representation of events in nerve nets and finite automata. </title> <editor> In C.E. Shannon and J. McCarty, eds. </editor> <booktitle> Automata Studies Annals of Mathematics Studies nr 34. </booktitle> <publisher> Princeton University Press, </publisher> <year> 1956. </year>
Reference-contexts: This problem cannot be solved by changing the configuration or the size of the network. Still, theoretical research has proven that connectionists networks as basic as the McCulloch-Pitts networks can model finite state grammars <ref> [Kle56] </ref>. The SRNs I have used in my experiments should be able to model the finite state grammars shown in figure 4. I believe that it is possible to train SRNs to model those grammars if the training data is adapted.
Reference: [Reb76] <author> A.S. Reber. </author> <title> Implicit learning of synthetic languages: The role of the instructional set. Journal of Experimental Psychology: </title> <booktitle> Human Learning and Memory, </booktitle> <volume> 2, </volume> <year> 1976. </year>
Reference-contexts: In experiments described in [CSSM89], [SSCM91] and [Cle93], Axel Cleeremans, David Servan-Schreiber and James McClelland trained a network to recognize strings which were generated using a small grammar that was originally used by <ref> [Reb76] </ref> (figure 2). They trained an SRN to predict the next character in a sequence of 60,000 strings which were randomly generated by the grammar. 1 This prediction task is non-deterministic and the size of the network was too small to memorize the complete sequence.
Reference: [RHW86] <author> D.E. Rumelhart, G.E. Hinton, and R.J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In David E. Rumelhart and James A. McClelland, </editor> <volume> volume 1. </volume> <publisher> The MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: In the final part of the paper I will give two extensions of the grammar modeled by Cleeremans et al. and I will show that the performance of the SRNs degrades when they are required to learn grammars of increasing complexity. 2 The Simple Recurrent Network Standard feed-forward connectionist networks <ref> [RHW86] </ref> consist of a sequence of layers of cells. Usually three layers of cells are present in the network: the input layer, the output layer and the in-between hidden layer (figure 1). Signals in these networks are represented by numbers between 0 and 1.
Reference: [Spe54] <author> Nederlands-Belgische Spellingscommissie. Woordenlijst der Nederlandse Taal. Staatsdrukkerij, </author> <year> 1954. </year> <note> (Available by anonymous ftp from ftp:// donau.et.tudelft.nl/pub/words/platte lijst.Z). </note>
Reference-contexts: The words were represented in orthographic format (ordinary characters; no phonological representations) and were taken from the Dutch corpus Het groene boekje <ref> [Spe54] </ref>. From this corpus I obtained 3506 monosyllabic words. I divided this set in two corpora: one 3206-word training corpus (training data) and a 300-word test corpus (test data). As an additional test corpus I generated 300 random words (random data) of which 12 words (4.0%) were acceptable.
Reference: [SSCM91] <author> D. Servan-Schreiber, A. Cleeremans, and J.L. McClelland. </author> <title> Graded state machines: The representation of temporal continguincies in simple recurrent networks. </title> <booktitle> Machine Learning, </booktitle> <pages> pages 161-193, </pages> <year> 1991. </year>
Reference-contexts: One of the three learning techniques behaved surprisingly worse than could be expected from the results reported in the literature. The connectionist Simple Recurrent Networks (SRNs) were developed by Jeffrey Elman to be applied for generating or recognizing sequences [Elm90]. In [CSSM89], <ref> [SSCM91] </ref> and [Cle93], Axel Cleeremans, David Servan-Schreiber and James McClelland report experiments in which they modeled finite state grammars with SRNs. <p> The SRNs reached the 100% acceptance rate for valid Dutch monosyllabic words but they never rejected more than 6% of the random strings. In this paper I will explain why SRNs performed bad on my problem while their performance was excellent on the problem posed to them in [CSSM89], <ref> [SSCM91] </ref> and [Cle93]. First I will describe the structure of an SRN and give a description of the main experiment described in the literature. <p> The SRN accepts a string if at all processing steps the next character is among the possible continuation characters according to the output of the network. 3 The experiments of Cleeremans et al. In experiments described in [CSSM89], <ref> [SSCM91] </ref> and [Cle93], Axel Cleeremans, David Servan-Schreiber and James McClelland trained a network to recognize strings which were generated using a small grammar that was originally used by [Reb76] (figure 2). <p> We can conclude that the number of valid continuation tokens influences the difficulty of the problem. [CSSM89], maximum training total sum rejected rejected continuation rounds squared test random tokens needed error words words 2 150 9079 0 299 4 100 13944 0 240 complexity. <ref> [SSCM91] </ref> and [Cle93], showed that SRNs are capable of acquiring finite state grammars in which a grammatical substring has two valid continuation tokens.
Reference: [TKS96] <author> Erik F. Tjong Kim Sang. </author> <title> Machine Learning of Phonotactical Knowledge. </title> <type> PhD thesis, </type> <institution> University of Groningen, </institution> <note> (to appear in 1996). </note>
Reference-contexts: 1 Introduction In my thesis research I am comparing the performance of three different machine learning techniques on the problem of acquiring models for the phonotactic structure of Dutch <ref> [TKS96] </ref>. A good phonological model is able to make the distinction between words that are in a language and words that cannot be part of the language because of their structure (for example bda in English). <p> In an experiment with the statistical learning technique Hidden Markov Models an acceptance rate of 99.3% (test data) and an rejection rate of 95.0% (random data) were achieved for the same data <ref> [TKS96] </ref>. While these were non-perfect scores, they indicate that reasonable models for the phonotactic structure of Dutch monosyllabic words can be found. I chose the same network learning parameters as in the experiments of [Cle93]: learning rate =0.01 and momentum ff=0.5.
References-found: 9

