URL: http://www.cs.colostate.edu/~draper/papers/draper_iuw96.ps.gz
Refering-URL: http://www.cs.colostate.edu/~vision/html/publications.html
Root-URL: 
Email: bdraper@cs.umass.edu  
Title: Learning Grouping Strategies for 2D and 3D Object Recognition  
Author: Bruce A. Draper 
Address: Amherst, MA 01003  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: The Schema Learning System (SLS) automatically assembles task-specific object recognition programs from existing IU algorithms. SLS brings together two emerging technologies image understanding and machine learning to automatically build customized procedures for recognizing and extracting specific object classes in constrained contexts. This paper describes the representations and algorithms underlying SLS, and presents an example of SLS learning to recognize rooftops in aerial images of Ft. Hood. This task is the first of several tasks from the ARPA/ORD sponsored RADIUS project [6] that SLS is intended to learn without human interaction. In later experiments, SLS will be tasked to automatically construct 3D models of buildings and other objects of interest from overlapping aerial images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barto, S. Bradtke and S. Singh. </author> <title> Learning to Act using Real-Time Dynamic Programming, </title> <journal> Artificial Intelligence, </journal> <year> 1995. </year>
Reference: [2] <author> M. Boldt, R. Weiss and E. Riseman. </author> <title> "Token-Based Extraction of Straight Lines," </title> <journal> in IEEE Trans. on Systems, Man and Cybernetics, </journal> <volume> 19(6) </volume> <pages> 1581-1594, </pages> <year> 1989. </year>
Reference-contexts: Madi Das created the neural net C++ object, based on code published in [11]. Bob Collins created the algorithm for computing 3D line segments, as well as constructing the ground truth models. Lionel Gaucher updated the 2D line extraction code of <ref> [2] </ref>, thereby making the Par2Polygon and Corner2Polygon procedures possible. Shashi Buluswar contributed the shadow feature measurement program. Gokhan Kutlu and Robert Heller programmed large parts of ISR3, including SLS's graphics interface. Frank Stolle calculated the ground heights for each image, and Chris Jaynes extracted the camera positions from RCDE.
Reference: [3] <author> R. Collins, A. Hanson, E. Riseman, C. Jaynes, F. Stolle, X. Wang and Y. Cheng. </author> <title> UMass Progress in 3D Building Model Acquisition, </title> <booktitle> ARPA Image Understanding Workshop, </booktitle> <year> 1996. </year>
Reference: [4] <author> B. Draper. </author> <title> Learning Control Strategies for Object Recognition, in Symbolic Visual Learning, </title> <editor> K. Ikeuchi and M. Veloso (eds.), </editor> <publisher> Oxford University Press, </publisher> <address> New York, </address> <note> to appear 1996. </note>
Reference-contexts: Hood, a task that was copied from the RADIUS project task domain. On each trial, the system is given a subimage containing one or sometimes two buildings, and a set of 3D line segments computed as described in <ref> [4] </ref>. SLS is also given a visual procedure library that defines eight levels of representation and nine visual procedures. The levels of representation correspond to images, sets of 3D line segments, parallel line pairs, corners (i.e. vertices of orthogonal lines), line groups and polygons. <p> The 3D line segments were computed off-line as described in <ref> [4] </ref>, and filtered according to the known height of the ground plane. Eight other visual procedures are available. <p> Hood. The training and evaluation was carried out using the ground truth data developed for the (self) evaluation of UMass's hand-crafted building detector and 3D reconstruction system <ref> [4] </ref>. SLS was tested using a leave one out methodology. On each trial, SLS was be trained on data from nine images, and then the control policy it learned would be applied to the tenth image. <p> The UMass terrain reconstruction system [14] constructs dense digital elevation maps (DEMs) accurate to within a meter from pairs of images, even when those images were taken with wide baselines at highly oblique angles. This type of dense, 3D data, in combination with the 3D lines computed in <ref> [4] </ref>, should make it possible to reconstruct highly accurate building models. These procedures, along with additional procedures for fitting planes and complex surfaces to DEM data, should give SLS many alternative strategies for constructing 3D building models.
Reference: [5] <author> D.Gerson and S.Wood, </author> <title> RADIUS Phase II The RADIUS Testbed System, </title> <booktitle> Arpa Image Understanding Workshop, </booktitle> <address> Monterey, CA, </address> <month> November </month> <year> 1994, </year> <pages> pp. 231-237. </pages>
Reference-contexts: Unfortunately, it is not obvious how to divide any given level of representation into a discrete set of states a-priori (although in the past we have learned policies by training decision trees to divide each representation's space of tokens into discrete states <ref> [5] </ref>). As an alternative, we note that Markov Decision Problems can be defined over infinite state spaces.
Reference: [6] <author> A. Huertas, C. Lin and R. Nevatia. </author> <title> Detection of Buildings from Monocular Views Using Perceptual Grouping and Shadows, </title> <booktitle> ARPA Image Understanding Workshop, </booktitle> <address> Washington, DC. </address> <year> 1993. </year>
Reference: [7] <author> R. Mohan and R. Nevatia. </author> <title> Using Perceptual Organization to Extract 3D Structures, </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <year> 1989. </year>
Reference-contexts: This paper presents some early results of a major experiment in using SLS to accomplish RADIUS-project tasks such as building detection and reconstruction. The first of these tasks (described below) is to recognize the image positions of rooftops in aerial photographs. Several other universities have previously addressed this problem <ref> [7, 9] </ref> developing hand-crafted strategies for finding rooftops by grouping line segments, analyzing shadows, and exploiting other 2D image cues. Our goal for SLS is to automatically learn an equivalent (or better) strategy based on the same type of information.
Reference: [8] <author> J.Mundy, R.Welty, L.Quam, T.Strat, W.Bremner, M.Horwedel, D.Hackett and A.Hughes, </author> <title> The RADIUS Common Development Environment, </title> <booktitle> Arpa IUW, </booktitle> <address> San Diego, CA, </address> <month> Jan </month> <year> 1992, </year> <pages> pp. 215-226. </pages>
Reference: [9] <author> Yoh-Han Pao. </author> <title> Adaptive Pattern Recognition and Neural Networks. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: This paper presents some early results of a major experiment in using SLS to accomplish RADIUS-project tasks such as building detection and reconstruction. The first of these tasks (described below) is to recognize the image positions of rooftops in aerial photographs. Several other universities have previously addressed this problem <ref> [7, 9] </ref> developing hand-crafted strategies for finding rooftops by grouping line segments, analyzing shadows, and exploiting other 2D image cues. Our goal for SLS is to automatically learn an equivalent (or better) strategy based on the same type of information.
Reference: [10] <author> G. Reynolds and R. Beveridge, </author> <title> "Searching for Geometric Structure in Images of Natural Scenes", </title> <booktitle> ARPA Image Understanding Workshop, </booktitle> <address> Los Ange-les, CA, </address> <month> Feb. </month> <year> 1987, </year> <pages> pp. 257-271. </pages>
Reference-contexts: Ideally, SLS's library should contain the same subroutines used in other rooftop recognition projects. Unfortunately, SLS's procedures must be executable UNIX modules, while many of the subroutines developed for RADIUS are Lisp functions embedded in RCDE <ref> [10] </ref>. Therefore, a small set of RADIUS-style vision routines (recoded as stand-alone C or C++ modules) have been used for this experiment, many although not all from UMass.
Reference: [11] <author> D. Rumelhart, G. Hinton and R. Williams. </author> <title> Learning Internal Representations by Error Propagation, </title> <booktitle> in Parallel Distributed Processing, </booktitle> <volume> Vol 1, </volume> <editor> Rumelhart and McClellan (eds), </editor> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA. </address>
Reference-contexts: Although the traditional control-theoretic techniques for solving MDPs (i.e. Dynamic Programming) require a more detailed process model than is generally available for IU applications, we believe that recent advances in reinforcement learning [15, 17, 16, 18] and in function approximation (including, but not limited to, backpropagation neural networks <ref> [13, 11] </ref>) make it possible to learn near-optimal control policies for image understanding. In principle, one should be able to transform the task of constructing a new vision application to one of training the system with a set of representative input-output examples relevant for the task. <p> The near-term future goal, however, is to learn control policies for automatically constructing 3D building models. Acknowledgements Many people have contributed their time, effort and code to the Schema Learning System. Madi Das created the neural net C++ object, based on code published in <ref> [11] </ref>. Bob Collins created the algorithm for computing 3D line segments, as well as constructing the ground truth models. Lionel Gaucher updated the 2D line extraction code of [2], thereby making the Par2Polygon and Corner2Polygon procedures possible. Shashi Buluswar contributed the shadow feature measurement program.
Reference: [12] <author> H. Schultz. </author> <title> Terrain Reconstruction from Widely Separated Images, SPIE: Integrated Photogram-metric Techniques with Scene Analysis and Machine Vision II, </title> <address> Orlando, FL, </address> <month> April </month> <year> 1995, </year> <pages> pp. 113-123. </pages>
Reference-contexts: The 3D line segments were computed off-line as described in [4], and filtered according to the known height of the ground plane. Eight other visual procedures are available. The rectilinear line grouping (RLGS) procedure is an updated version of <ref> [12] </ref> that computes relationships between nearby line segments; it was updated to use information about the camera pose (available for all RADIUS images) to remove the effects of perspective distortion from orthogonal and parallel re lations.
Reference: [13] <institution> Learning to Predict by the Method of Temporal Differences, </institution> <note> Machine Learning 3 9-44. </note>
Reference-contexts: Although the traditional control-theoretic techniques for solving MDPs (i.e. Dynamic Programming) require a more detailed process model than is generally available for IU applications, we believe that recent advances in reinforcement learning [15, 17, 16, 18] and in function approximation (including, but not limited to, backpropagation neural networks <ref> [13, 11] </ref>) make it possible to learn near-optimal control policies for image understanding. In principle, one should be able to transform the task of constructing a new vision application to one of training the system with a set of representative input-output examples relevant for the task.
Reference: [14] <author> G. Tesauro. </author> <title> Temporal Difference Learning and TD-Gammon Communications of the ACM, </title> <booktitle> 38(3) </booktitle> <pages> 58-68 </pages>
Reference-contexts: The UMass terrain reconstruction system <ref> [14] </ref> constructs dense digital elevation maps (DEMs) accurate to within a meter from pairs of images, even when those images were taken with wide baselines at highly oblique angles.
Reference: [15] <author> C. Watkins. </author> <title> Learning from Delayed Rewards, </title> <type> Ph.D. thesis, </type> <institution> Cambridge University, </institution> <year> 1989. </year>
Reference-contexts: Although the traditional control-theoretic techniques for solving MDPs (i.e. Dynamic Programming) require a more detailed process model than is generally available for IU applications, we believe that recent advances in reinforcement learning <ref> [15, 17, 16, 18] </ref> and in function approximation (including, but not limited to, backpropagation neural networks [13, 11]) make it possible to learn near-optimal control policies for image understanding. <p> a complete search tree, and using the Q and V functions as heuristics to select which nodes to expand, in a manner similar to A fl search. 3.4 Computing Q and V There are several reinforcement learning algorithms for estimating Q or V without a-priori process models, with TD () <ref> [15] </ref> and Q-Learning [17] being the best known.
Reference: [16] <author> W. Zhang and T. Dietterich. </author> <title> A Reinforcement Learning Approach to Job-Shop Scheduling, </title> <booktitle> Int. Joint Conference on Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: Although the traditional control-theoretic techniques for solving MDPs (i.e. Dynamic Programming) require a more detailed process model than is generally available for IU applications, we believe that recent advances in reinforcement learning <ref> [15, 17, 16, 18] </ref> and in function approximation (including, but not limited to, backpropagation neural networks [13, 11]) make it possible to learn near-optimal control policies for image understanding. <p> Mathematically, this is a clean formulation of the problem. In practice, it only works if we can learn estimate for the Q fl (s; a) or V fl (s) functions over these infinite state spaces from a finite number of samples. Inspired by Tesauro <ref> [16] </ref> and Zhang and Dietterich [18], we use back propagation neural networks to learn approximations to the Q fl (s; a) function for each action, as described below in Section 3.4. <p> These algorithms build successively better approximations of Q and V based on experience gained by running the system; Tesauro <ref> [16] </ref> and Zhang and Dietterich [18] have used these techniques with neural network function approximators to learn Q values for systems with continuous state spaces.
References-found: 16

