URL: ftp://ftp.dcs.exeter.ac.uk/pub/parallel/models/gpoptim.ps.Z
Refering-URL: http://www.dcs.exeter.ac.uk/reports/reports.html
Root-URL: 
Email: Email: steve@dcs.exeter.ac.uk  
Title: GENERAL PURPOSE OPTIMISTIC PARALLEL COMPUTING  
Author: Stephen Turner and Adam Back 
Date: March 31, 1994  
Address: Road, Exeter EX4 4PT England  
Affiliation: Department of Computer Science, University of Exeter, Prince of Wales  
Abstract: In this paper we discuss our research into the use of optimistic methods for general purpose parallel computing. The optimistic execution of a program can allow code to be run in parallel which static program analysis might indicate was sequential. However, this also means that it may do some work which is later found to be wrong because of a causality violation. Optimistic methods use a detection and recovery approach: causality errors are detected, and a roll-back mechanism is invoked to recover. These techniques have been used very successfully in parallel discrete event simulation, but are not as yet widely used in general purpose computing. Our research involves the development of a compiler which converts a conventional object-oriented program into a form which has calls to an optimistic run time system. The generation of time-stamps which allow for loops with an unknown number of iterations is discussed. We also describe some of the portability issues which we have addressed in this project: in particular, our use of p4, a cluster based communications library which provides the basis for portable, heterogeneous parallel computing. We describe our implementation of p4 on the transputer architecture, including some extensions to support the optimistic execution of programs, and also an outline of our work in retargetting the GNU C and C++ compilers for the transputer.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A Back and S J Turner. </author> <title> Portability and parallelism with lightweight p4. </title> <booktitle> In BCS PPSG Conference on General Purpose Parallel Computing, </booktitle> <year> 1993. </year>
Reference-contexts: Then we provide a multiplexor and a demultiplexor process for each virtual channel. The multiplexor for a particular channel will forward all messages destined for the remote processor via the virtual channel. Further details of the implementation of the message passing mechanism may be found in <ref> [1] </ref>. 6.4 Performance 10 the basic Inmos C communications library using virtual channels. These times are obtained with a simple "Ping" application where a message is sent from one transputer to an adjacent transputer and then back to the originator.
Reference: [2] <author> A Back and S J Turner. </author> <title> Time-stamp generation for the parallel execution of program control structures. </title> <type> Technical report, </type> <institution> R289, Department of Computer Science, Exeter University, </institution> <year> 1994. </year>
Reference-contexts: The choice of b is important in this scheme as the efficiency of dynamic allocation compared to the static allocation used for fixed bound loops depends on the choice of b. Further details of our time-stamp mechanism may be found in <ref> [2] </ref>. 6 Portability Issues In this section, we discuss the suitability of p4 as a portable base for our research into the use of general purpose optimistic parallel computing.
Reference: [3] <author> D F Bacon. </author> <title> Optimistic parallelization of communicating sequential processes. </title> <journal> Association of Computing Machinery, </journal> <year> 1991. </year>
Reference-contexts: The aims are to make use of more of the available parallelism than is possible with automatic parallelization schemes based on static program analysis. Some work has been done by Bacon <ref> [3] </ref> on the optimistic execution of CSP (Communicating Sequential Processes) [10], but the use of optimistic execution as a parallelization tool has been largely unexplored. 4 An Example of Parallelization To illustrate these ideas, we present an example which shows the parallelization of an object-oriented program involving matrix multiplication.
Reference: [4] <author> C Berry, A Back, and S J Turner. </author> <title> A GNU CC compiler for the transputer. </title> <type> Technical report, </type> <institution> R295, Department of Computer Science, Exeter University, </institution> <year> 1994. </year>
Reference-contexts: Pseudo-registers 0 to 6 are special purpose registers, such as the frame pointer, etc., whereas those from 7 to 15 are general purpose. Details of the GNU CC abstract machine model for the transputer are given in <ref> [4] </ref>. 7 Conclusions In this paper, we have shown how it is possible to parallelize an object-oriented program using optimistic execution techniques based on the concept of virtual time.
Reference: [5] <author> R Butler and E Lusk. </author> <title> User's guide to the p4 parallel programming system. </title> <type> Technical report, </type> <institution> ANL-92/17, Argonne National Laboratory, </institution> <year> 1992. </year>
Reference-contexts: Further details of our time-stamp mechanism may be found in [2]. 6 Portability Issues In this section, we discuss the suitability of p4 as a portable base for our research into the use of general purpose optimistic parallel computing. The p4 parallel library <ref> [5, 6] </ref>, which originates from the Argonne National Laboratory, provides a portable programming model for a large set of parallel machines. The model combines message passing with shared memory to form a cluster based model of parallel computing.
Reference: [6] <author> R Butler and E Lusk. </author> <title> Monitors, messages, and clusters: the p4 parallel programming system. </title> <type> Technical report, </type> <institution> Argonne National Laboratory, </institution> <year> 1993. </year>
Reference-contexts: Further details of our time-stamp mechanism may be found in [2]. 6 Portability Issues In this section, we discuss the suitability of p4 as a portable base for our research into the use of general purpose optimistic parallel computing. The p4 parallel library <ref> [5, 6] </ref>, which originates from the Argonne National Laboratory, provides a portable programming model for a large set of parallel machines. The model combines message passing with shared memory to form a cluster based model of parallel computing.
Reference: [7] <author> K M Chandy and J Misra. </author> <title> Distributed simulation: A case study in design and verification of distributed programs. </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> SE5(5):440-452, </volume> <year> 1979. </year>
Reference-contexts: This is known as a causality error, from the cause and effect principle: the fact that events in the future cannot affect events in the past. There are two approaches to ensuring that causality is not violated in a parallel discrete event simulation: conservative and optimistic. Conservative approaches <ref> [7] </ref> avoid the possibility 3 of any causality error ever occurring. These approaches rely on some strategy to determine when it is safe to process an event. This will be when all events which could affect the event in question have been processed.
Reference: [8] <author> Richard M Fujimoto. </author> <title> Parallel discrete event simulation. </title> <journal> Communications of the ACM, </journal> <volume> 33(10) </volume> <pages> 30-53, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Thus, the Time Warp mechanism is the inverse of Lamport's algorithm. Although virtual time has been used in distributed database concurrency control [16], its main success has been in parallel discrete event simulation <ref> [8, 13, 19] </ref>. Here, the interactions between the objects of the simulation are modelled by the exchange of time-stamped event messages. The Time Warp mechanism allows different nodes of the parallel computer to execute events out of time-stamp order provided that no causal relation exists between them. <p> The simulation moves forwards in simulation time by jumping from the the time-stamp of one event to the next. This is in contrast to time-driven simulation methods where time moves forward uniformly. The simulation is complete when there are no more events to simulate. In parallel discrete event simulation <ref> [8] </ref>, the physical system is modelled by a set of processes which correspond to the interacting objects in the physical system. The interactions between the physical objects are modelled by the exchange of time-stamped event messages.
Reference: [9] <author> A Gafni. </author> <title> Rollback mechanisms for optimistic distributed simulation systems. </title> <booktitle> In Procedings SCS Distributed Simulation Conference, </booktitle> <pages> pages 61-67, </pages> <year> 1988. </year>
Reference-contexts: An exception is where the methods are read-only and do not affect the state of the object. Such methods may be executed out of time-stamp order using a principle similar to that of lazy cancellation <ref> [9] </ref>. In figure 1, we can see that the Time Warp mechanism would allow the multiplication of A fi B to proceed in parallel with that of C fi D, since these are method invocations on different objects, each with its own local virtual clock.
Reference: [10] <author> C Hoare. </author> <title> Communicating Sequential Processes. </title> <publisher> Prentice Hall, </publisher> <year> 1985. </year>
Reference-contexts: The aims are to make use of more of the available parallelism than is possible with automatic parallelization schemes based on static program analysis. Some work has been done by Bacon [3] on the optimistic execution of CSP (Communicating Sequential Processes) <ref> [10] </ref>, but the use of optimistic execution as a parallelization tool has been largely unexplored. 4 An Example of Parallelization To illustrate these ideas, we present an example which shows the parallelization of an object-oriented program involving matrix multiplication.
Reference: [11] <author> Inmos. </author> <title> ANSI C Toolset User Guide, </title> <year> 1992. </year>
Reference-contexts: The generic Unix implementation of p4 uses sockets for communication. Vendor specific communication libraries are used for communication on parallel machines with specific communication hardware. We have implemented the p4 message passing calls on the transputer using the Inmos VCR <ref> [11] </ref> system, which provides virtual channels which can be placed between processes on any processor in a transputer network, the necessary through routing and multiplexing being performed by the VCR (on the T805, this is performed by software). <p> generated by pattern matching the RTL file produced by the front end against a machine description file which specifies the actual code for each abstract instruction. 11 One of the main considerations in retargetting the GNU compiler is that it should generate code which utilises the standard Inmos C libraries <ref> [11] </ref>. To do this, it is necessary to adopt a stack layout which is compatible with that used by the Inmos compiler.
Reference: [12] <author> David R Jefferson. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: However, if the time-stamps for two events are equivalent, T A = T B , then we know that A and B must be concurrent, that is there is no causal relation between these two events. 2 In 1985, Jefferson <ref> [12] </ref> introduced the idea of virtual time as a new paradigm for parallel computing. In many ways, this is the reverse of Lamport's approach: we assume that every event is labelled with a clock value from some totally ordered time-scale in a manner consistent with causality. <p> These approaches rely on some strategy to determine when it is safe to process an event. This will be when all events which could affect the event in question have been processed. Optimistic methods such as Time Warp <ref> [12] </ref> use a detection and recovery approach: causality errors are detected, and a roll-back mechanism is invoked to recover. A roll-back will be required when a causality violation is detected due to an event message arriving too late (such a message is known as a straggler).
Reference: [13] <author> JPL. </author> <title> Time Warp Operating System User's Manual. </title> <institution> Jet Propulsion Laboratory, </institution> <year> 1991. </year>
Reference-contexts: Thus, the Time Warp mechanism is the inverse of Lamport's algorithm. Although virtual time has been used in distributed database concurrency control [16], its main success has been in parallel discrete event simulation <ref> [8, 13, 19] </ref>. Here, the interactions between the objects of the simulation are modelled by the exchange of time-stamped event messages. The Time Warp mechanism allows different nodes of the parallel computer to execute events out of time-stamp order provided that no causal relation exists between them.
Reference: [14] <author> L Lamport. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: We then describe some of the portability issues which we have addressed in this project and finally present our conclusions. 2 Virtual Time The concept of an artificial time-scale was originally proposed by Lamport <ref> [14] </ref> in 1978 as a way of defining a global ordering of events in a parallel or distributed system.
Reference: [15] <author> T G Lewis and H El-Rewini. </author> <title> Introduction to Parallel Computing. </title> <publisher> Prentice Hall International, </publisher> <year> 1992. </year>
Reference-contexts: Classes can be defined using an inheritance mechanism that supports the development of large programs and the re-use of code. Because of this encapsulation, it seems natural to execute an object-oriented program in parallel by assigning different objects to different processors. Each object would have a server <ref> [15] </ref>, which communicates with other servers by means of message passing. When a method is 1 invoked, a thread is created by the server to execute that method.
Reference: [16] <author> M Livesey. </author> <title> Distributed varimistic concurrency control in a persistent object store. </title> <type> Technical report, </type> <institution> University of St. Andrews, </institution> <year> 1990. </year> <month> 13 </month>
Reference-contexts: When a causality error is detected, a process must be rolled back in virtual time, and then be allowed to continue along new execution paths. Thus, the Time Warp mechanism is the inverse of Lamport's algorithm. Although virtual time has been used in distributed database concurrency control <ref> [16] </ref>, its main success has been in parallel discrete event simulation [8, 13, 19]. Here, the interactions between the objects of the simulation are modelled by the exchange of time-stamped event messages.
Reference: [17] <author> M D May, P W Thompson, and P H Welch. </author> <title> Networks, Routers and Transputers. </title> <publisher> IOS Press, </publisher> <year> 1993. </year>
Reference-contexts: In particular, we would like to be able to transfer our programs, without modification, between transputer systems (both T805 and T9000 <ref> [17] </ref>), networks of workstations, and shared memory multiprocessors. We also wish to be able to develop programs which run on a heterogeneous system involving any or all of the above architectures.
Reference: [18] <author> SUN Microsystems. </author> <title> Network Programming Guide, </title> <year> 1990. </year>
Reference-contexts: To allow messages to be passed between machines of different architectures, p4 uses the XDR (eXternal Data Representation) library. XDR <ref> [18] </ref> provides a standard representation for float, double, int, long into which messages must be translated on send and from which they must be translated on receive.
Reference: [19] <author> M Presley, M Ebling, F Wieland, and D Jefferson. </author> <title> Benchmarking the time warp operating system with a computer network simulation. </title> <booktitle> In Procedings SCS Distributed Simulation Conference, </booktitle> <pages> pages 8-13, </pages> <year> 1989. </year>
Reference-contexts: Thus, the Time Warp mechanism is the inverse of Lamport's algorithm. Although virtual time has been used in distributed database concurrency control [16], its main success has been in parallel discrete event simulation <ref> [8, 13, 19] </ref>. Here, the interactions between the objects of the simulation are modelled by the exchange of time-stamped event messages. The Time Warp mechanism allows different nodes of the parallel computer to execute events out of time-stamp order provided that no causal relation exists between them.
Reference: [20] <author> K M Shea, M H Cheung, and F C M Lau. </author> <title> An efficient multi-priority scheduler for the transputer. </title> <booktitle> In Proc. 15th WoTUG Technical Meeting (Aberdeen), </booktitle> <pages> pages 139-153. </pages> <publisher> IOS Press, </publisher> <year> 1992. </year> <month> 14 </month>
Reference-contexts: A multi-priority scheduler with the capability of pre-emptively descheduling processes has been constructed based on the work of Shea et. al. <ref> [20] </ref>. The library allows processes to be externally suspended, resumed and killed, and also allows control over each process's priority. 6.6 Retargetting the GNU C and C++ compilers We wish to be able to develop programs that are portable across a wide range of parallel architectures.
References-found: 20

