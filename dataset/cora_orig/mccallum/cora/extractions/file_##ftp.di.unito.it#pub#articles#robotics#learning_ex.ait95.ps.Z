URL: file://ftp.di.unito.it/pub/articles/robotics/learning_ex.ait95.ps.Z
Refering-URL: http://www.di.unito.it/WWW/MLgroup/attiliobib.html
Root-URL: 
Title: Learning Controllers from Examples  a motivation for searching alternative, empirical techniques for generating controllers.  
Author: C. Baroglio, A. Giordana, and R. Piola 
Keyword: production of (non-)linear controllers. Two major families are defined: Open Field  
Note: would allow a higher performance. This is  
Address: c.so Svizzera 185, I-10149 Torino, Italy  
Affiliation: Dip. di Informatica, Universita degli Studi  
Email: baroglio|attilio|piola@di.unito.it  
Phone: tel. +39-11-7429214, fax +39-11-751603  
Abstract: Today there is a great interest in discovering methods that allow a faster design and development of real-time control software. Control theory helps when linear controllers have to be developed but it does not support the generation In this paper, it is discussed how Machine Learning has been applied to the Function, and Locally Receptive Field Function Approximators. Three integrated learning algorithms, two of which are original, are described and then tried on two experimental test cases. The first test case is provided by an industrial robot KUKA IR-361 engaged into the "peg-into-hole" task, while the second is a classical prediction task on the Mackey-Glass chaotic series. From the experimental comparison, it appears that both Fuzzy Controllers and RBFNs synthesised from examples are excellent approximators, and that they can be even more accurate than MLPs. of non-linear controllers, which in many cases (such as in compliant motion control)
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Asada. </author> <title> Teaching and learning of compliance using neural nets: Represen tation and generation of nonlinear compliance. </title> <booktitle> In Proceedings of the 1990 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1237 - 1244, </pages> <year> 1990. </year>
Reference-contexts: The selected task, peg-into-hole, consists in learning to insert a peg into a hole, and to recover from error situations, in which, for instance, the peg is stuck midway because of a wrong inclination. This application is particularly interesting because the optimal control is known to be non-linear <ref> [1] </ref>. In our case, both the peg and the hole had a circular section. The diameter of the shamfered peg was 30 [mm], the clearance between the peg and the hole was 0:15 [mm]: The hole was located on a plane surface.
Reference: [2] <author> A.G. Barto, R.S. Sutton, and C.J.C.H. Watkins. </author> <title> Sequential decision problems and neural networks. </title> <booktitle> In Advances in neural information processing system, </booktitle> <volume> volume 2. </volume> <publisher> Morgan Kauffman, </publisher> <address> San mateo, Ca, </address> <year> 1990. </year>
Reference-contexts: Finally, the results are discussed in Section 5. 2 Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics [10, 36, 37], connectionism <ref> [30, 2] </ref>, fuzzy logics [43, 4] and symbolic machine learning [32, 28]. Apart from regression and prediction trees, all the existing approximators can be represented by some multi-layered network, in which nodes (or neurons) computing a simple function (activation function) are connected by means of weighted links.
Reference: [3] <author> H.R. Berenji. </author> <title> Machine learning in fuzzy control. </title> <booktitle> In International Conference on Fuzzy Logic & Neural Networks, </booktitle> <pages> pages 231-234, </pages> <address> Iizuka, Fukuoka, Japan, </address> <year> 1990. </year>
Reference-contexts: In the Fuzzy Controller approach, the most common practice is designing the network layout manually, relying on the domain knowledge of a human expert [24]. Variants of the error gradient descent have been proposed in order to refine the fuzzy sets in a second step <ref> [3] </ref>.
Reference: [4] <author> H.R. Berenji. </author> <title> Fuzzy logic controllers. In R.R. </title> <editor> Yager and L.A. Zadeh, editors, </editor> <title> An Introduction to Fuzzy Logic Applications in Intelligent Systems. </title> <publisher> Kluver Academic Publishers, </publisher> <year> 1992. </year>
Reference-contexts: In the literature, regression has been tackled with different approaches: neural networks [30, 31], prediction trees, statistics [11, 29], regression trees [10], and fuzzy logics <ref> [4] </ref>, and it has been seen either as a supervised or as a reinforcement learning task. <p> Finally, the results are discussed in Section 5. 2 Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics [10, 36, 37], connectionism [30, 2], fuzzy logics <ref> [43, 4] </ref> and symbolic machine learning [32, 28]. Apart from regression and prediction trees, all the existing approximators can be represented by some multi-layered network, in which nodes (or neurons) computing a simple function (activation function) are connected by means of weighted links. <p> We will show how symbolic learning algorithms can be used to automatically build excellent layouts for LRFNs. 2.1 A Fuzzy Controller Architecture Fuzzy controllers are a kind of universal function approximators developed within the fuzzy logic community <ref> [43, 4] </ref> and are representative of the LRFN family. As a matter of fact, Fuzzy Controllers do not correspond to a single architecture but to a wide family that contains the topology of Figure 1b as a special case. <p> As a matter of fact, Fuzzy Controllers do not correspond to a single architecture but to a wide family that contains the topology of Figure 1b as a special case. Nevertheless, in our research, we focused on a specific topology, derived from the one experienced by Berenji <ref> [4] </ref> in control problems similar to the ones tackled in this paper. Figure 2 shows the corresponding network representation. The fuzzy controller is organized as a three-layered network plus an input layer.
Reference: [5] <author> H.R. Berenji and P. Khedkar. </author> <title> Learning and tuning fuzzy controllers through reinforcements. </title> <journal> IEEE Transactions on neural networks, </journal> <volume> 3(5):724 740, </volume> <month> September </month> <year> 1992. </year>
Reference-contexts: A last point requiring some discussion is the need of refining a controller for overcoming the human teacher's skill. Reinforcement Learning (RL) is a promising way to overcome this limitation. Actually, in RL literature we find many techniques for learning in continuous domains <ref> [26, 5, 41, 13] </ref>, in which agents implemented as neural networks are trained. One system that integrates neural and reinforcement learning is Berenji's GARIC [5]. This system uses a fuzzy controller, implemented as a neural net work, which is very similar to those described in Section 2. <p> Reinforcement Learning (RL) is a promising way to overcome this limitation. Actually, in RL literature we find many techniques for learning in continuous domains [26, 5, 41, 13], in which agents implemented as neural networks are trained. One system that integrates neural and reinforcement learning is Berenji's GARIC <ref> [5] </ref>. This system uses a fuzzy controller, implemented as a neural net work, which is very similar to those described in Section 2. It is extremely easy to think to GARIC's variants in which other kinds of LRFN approximators are used instead of fuzzy controllers.
Reference: [6] <author> F. Bergadano, A. Giordana, and L. Saitta. </author> <title> Learning concepts in noisy envi ronment. </title> <journal> IEEE Transaction on Pattern Analysis ans Machine Intelligence, </journal> <pages> pages 555-578, </pages> <year> 1988. </year> <month> 15 </month>
Reference-contexts: An example of this method is described in [32]. In the present case, we used a flexible learner called SMART+ <ref> [6, 9] </ref>, that allows the induction process to be guided by the background knowledge of a domain expert.
Reference: [7] <author> M.R. Berthold. </author> <title> A time delay radial basis function network for phoneme recognition. </title> <booktitle> In IEEE International Conference on Neural Networks, </booktitle> <address> Orlando, Florida, </address> <year> 1994. </year>
Reference-contexts: The complexity of the trees generated by CART and SMART+ was comparable and ranged from 20 to 80 leaves corresponding to a number of neurons in the hidden layer ranging from 60 to 160 (each neuron corresponds to a unidimensional Gaussian). 11 RBFN and Time Delay RBFN <ref> [7] </ref> have been built using the algorithm of Section 3.1 and then have been trained using gradient descent. The complexity of the networks ranged from 30 to 60 neurons in the hidden layer. Finally, experiments were done using the basic MLP for comparison purposes.
Reference: [8] <author> P.P. Bonissone and K.H. Chiang. </author> <title> Fuzzy logic controllers: from development to deployment. </title> <booktitle> In IEEE International Conference on Neural Networks, volume 2, </booktitle> <address> San Francisco, CA, </address> <year> 1993. </year>
Reference-contexts: In fact, a closed region in the input space can be approximated using a hyper-rectangle which, in turn, can be described by a propositional formula (see Section 3.2). This property has already been exploited for manually encoding fuzzy controller's layouts using qualitative domain knowledge <ref> [8] </ref>. We will show how symbolic learning algorithms can be used to automatically build excellent layouts for LRFNs. 2.1 A Fuzzy Controller Architecture Fuzzy controllers are a kind of universal function approximators developed within the fuzzy logic community [43, 4] and are representative of the LRFN family.
Reference: [9] <author> M. Botta and A. Giordana. </author> <title> SMART+: A multi-strategy learning tool. </title> <booktitle> In IJCAI-93, Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, volume 2, </booktitle> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: An example of this method is described in [32]. In the present case, we used a flexible learner called SMART+ <ref> [6, 9] </ref>, that allows the induction process to be guided by the background knowledge of a domain expert.
Reference: [10] <author> L. Breiman, J.H. Friedman, R.A. Ohlsen, and C.J. Stone. </author> <title> Classification And Regression Trees. </title> <publisher> Wadsworth & Brooks, </publisher> <address> Pacific Grove, CA, </address> <year> 1984. </year>
Reference-contexts: In the literature, regression has been tackled with different approaches: neural networks [30, 31], prediction trees, statistics [11, 29], regression trees <ref> [10] </ref>, and fuzzy logics [4], and it has been seen either as a supervised or as a reinforcement learning task. <p> Finally, the results are discussed in Section 5. 2 Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics <ref> [10, 36, 37] </ref>, connectionism [30, 2], fuzzy logics [43, 4] and symbolic machine learning [32, 28]. <p> Here, three alternative procedures to automate the layout construction of a LRFN are reported: (1) the first is based on a variant of the k-means according to the algorithm described in [22, 42]; (2) the second one is based on CART <ref> [10] </ref>, an algorithm for generating Regression Trees; (3) the last technique is based on symbolic learning methods in the line of [32], and allows learning both from data and from background knowledge. <p> A setting of fi &gt; 0:5 or even fi &gt; 1 will result in an initial cluster set that is already providing ambiguous classifications. This is usually not desired. 3.2 Using CART A regression tree <ref> [10] </ref> partitions the domain of a function f (~x) into rectangular regions (see Figure 3) where the value of f (~x) is similar so that it can be approximated by a constant. Therefore f (~x) is approximated by a histogram as accurately as the subdivision of the input domain permits. <p> Therefore f (~x) is approximated by a histogram as accurately as the subdivision of the input domain permits. The algorithm for generating a regression tree (CART) is simple and a detailed description can be found in <ref> [10] </ref>. Given: a learning set f (~x 1 ; y 1 ); : : :; (~x n ; y n )g obtained by sampling the target function f (~x) 1. <p> Obviously, in a learning problem framed in propositional calculus, predicate schemes will not have any variable but only constants to tune. An example of predicate used for learning a controller's layout can be GreaterF orce x (K : <ref> [10; 25; 0:1] </ref>) stating that the force along the X axis be greater than a constant K, ranging from 10 to 25 Newtons, with granularity 0.1. In this case, the learning events are simply described as attribute vectors where F orce x is one of them.
Reference: [11] <author> H. Cramer. </author> <title> Mathematical Methods of Statistics. </title> <publisher> Princeton University Press, </publisher> <year> 1974. </year>
Reference-contexts: In the literature, regression has been tackled with different approaches: neural networks [30, 31], prediction trees, statistics <ref> [11, 29] </ref>, regression trees [10], and fuzzy logics [4], and it has been seen either as a supervised or as a reinforcement learning task.
Reference: [12] <author> R.S. Crowder. </author> <title> Predicting the mackey-glass time series with cascade correlation learning. </title> <editor> In G. Hinton D. Touretzky and T.Sejnovsky, editors, </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School, </booktitle> <pages> pages 117-123. </pages> <institution> Carnegie Mellon University, </institution> <year> 1990. </year>
Reference-contexts: In order to correctly predict the function value 84 steps ahead it is necessary to capture the generative model of the phenomenon. This task was used also by <ref> [12, 15, 16, 18, 21, 22, 33] </ref>, so results can be compared directly. The experiment has been organized as follows. First, a sequence of 1500 time steps has been generated. <p> The results are reported in Table 2. The Non-Dimensional Error Index (NDEI) is defined as the Root Mean Square Error divided by the Standard Deviation of the target series. Comparing the best results obtained in the literature in analogous experiments <ref> [12, 15] </ref>, it appears that both the predictor generated by CART and the one gener 13 ated by SMART+ show excellent performances after training.
Reference: [13] <author> V. Gullapalli. </author> <title> A stochastic reinforcement learning algorithm for learning real valued functions. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 671-692, </pages> <year> 1990. </year>
Reference-contexts: A last point requiring some discussion is the need of refining a controller for overcoming the human teacher's skill. Reinforcement Learning (RL) is a promising way to overcome this limitation. Actually, in RL literature we find many techniques for learning in continuous domains <ref> [26, 5, 41, 13] </ref>, in which agents implemented as neural networks are trained. One system that integrates neural and reinforcement learning is Berenji's GARIC [5]. This system uses a fuzzy controller, implemented as a neural net work, which is very similar to those described in Section 2.
Reference: [14] <author> K. Hornik, M. Stinchcombe, and H. White. </author> <title> Multilayer feed-forward networks are universal approximators. </title> <booktitle> Neural Networks, </booktitle> <volume> 2 </volume> <pages> 359-366, </pages> <year> 1989. </year>
Reference-contexts: Apart from regression and prediction trees, all the existing approximators can be represented by some multi-layered network, in which nodes (or neurons) computing a simple function (activation function) are connected by means of weighted links. As proven in <ref> [14] </ref>, a universal function approximator can be constructed using only three layers of nodes provided the activation function in the hidden layer be non-linear. The differences among the various kinds of approximators (Figure 1) reside in the activation functions and in the learning algorithms.
Reference: [15] <author> J.S.R. Jang. ANFIS: </author> <title> Adaptive-Network-Based Fuzzy Inference System. </title> <journal> IEEE Transactions on Systems, Men and Cybernetics, </journal> <volume> SMC-23(3):665-687, </volume> <month> May/June </month> <year> 1993. </year>
Reference-contexts: In order to correctly predict the function value 84 steps ahead it is necessary to capture the generative model of the phenomenon. This task was used also by <ref> [12, 15, 16, 18, 21, 22, 33] </ref>, so results can be compared directly. The experiment has been organized as follows. First, a sequence of 1500 time steps has been generated. <p> The results are reported in Table 2. The Non-Dimensional Error Index (NDEI) is defined as the Root Mean Square Error divided by the Standard Deviation of the target series. Comparing the best results obtained in the literature in analogous experiments <ref> [12, 15] </ref>, it appears that both the predictor generated by CART and the one gener 13 ated by SMART+ show excellent performances after training.
Reference: [16] <author> R.D. Jones, Y.C. Lee, C.W. Barnes, G.W. Flake, K. Lee, and P.S. Lewis. </author> <title> Function approximation and time series prediction with neural networks. </title> <booktitle> In Proceedings of IEEE International Joint Conference on Neural Networks, </booktitle> <pages> pages I-649-665, </pages> <year> 1990. </year>
Reference-contexts: In order to correctly predict the function value 84 steps ahead it is necessary to capture the generative model of the phenomenon. This task was used also by <ref> [12, 15, 16, 18, 21, 22, 33] </ref>, so results can be compared directly. The experiment has been organized as follows. First, a sequence of 1500 time steps has been generated.
Reference: [17] <author> M. Kaiser, L. Camarinha-Matos, A. Giordana, V. Klingspor, J. del R. Millan, M. Nuttin, and R. </author> <title> Suarez. Robot learning three case studies in robotics and machine learning. </title> <booktitle> In Proceedings of the IVAR '94, </booktitle> <address> Leuven, Belgium, </address> <year> 1994. </year> <note> Also available via anonymous ftp from ftpipr.ira.uka.de. </note>
Reference-contexts: 1 Introduction In this paper, we describe some results of an investigation done in the framework of the EEC project N.7274: B-LEARN II. B-LEARN is a wide-spectrum project, structured into several subprojects related to different applicative fields <ref> [17] </ref>. In the research presented here, we focus on controllers for robots employed in assembly lines, performing tasks (such as cutting and deburring), in which the same oper ation is repeated thousands of times, and information coming from rough sensors only, such as force-torque sensors, is exploited.
Reference: [18] <author> A.S. Lapedes and R.Farber. </author> <title> Nonlinear signal processing using neural net works: Prediction and system modeling. </title> <type> Technical Report LA-UR-87-2662, </type> <institution> Los Alamos National Laboratory, </institution> <year> 1987. </year>
Reference-contexts: In order to correctly predict the function value 84 steps ahead it is necessary to capture the generative model of the phenomenon. This task was used also by <ref> [12, 15, 16, 18, 21, 22, 33] </ref>, so results can be compared directly. The experiment has been organized as follows. First, a sequence of 1500 time steps has been generated.
Reference: [19] <author> J.R. Millan. </author> <title> Learning efficient reactive behavioral sequences from basic re flexes in a goal-directed autonomous robot. </title> <booktitle> In Proceedings of the third International Conference on Simulation of Adaptive Behavior, </booktitle> <year> 1994. </year>
Reference-contexts: On the contrary, changing the amplitude or shifting the position of the activation function in a LRFN will have an effect local to the region it dominates. Locality of LRFNs allows the network layout to be incrementally constructed (see for instance <ref> [19] </ref>) because the knowledge encoded in the other parts of the network is not lost neither dramatically modified. 2. undergeneralization: in a LRFN, it is possible to have large regions of the input space that are not covered by any neuron. <p> Other considerations must, therefore, be taken into account to select one architecture. LRFNs have specific properties that make them particularly suitable for robotic applications, like incrementality in learning (deeply addressed by <ref> [20, 19] </ref>), deriving from the locality property. The possibility of incrementally building the mapping from the input space to the output space is equivalent to split the learning problem into subproblems; thus, different parts of the control function can be learnt during different learning sessions.
Reference: [20] <author> J.R. Millan and Carme Torras. </author> <title> A reinforcement connectionist approach to robot path finding in non-maze-like environments. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 363-395, </pages> <year> 1992. </year>
Reference-contexts: Other considerations must, therefore, be taken into account to select one architecture. LRFNs have specific properties that make them particularly suitable for robotic applications, like incrementality in learning (deeply addressed by <ref> [20, 19] </ref>), deriving from the locality property. The possibility of incrementally building the mapping from the input space to the output space is equivalent to split the learning problem into subproblems; thus, different parts of the control function can be learnt during different learning sessions.
Reference: [21] <author> J. Moody. </author> <title> Fast learning in multi-resolution hierarchies. </title> <editor> In D. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year> <month> 16 </month>
Reference-contexts: In order to correctly predict the function value 84 steps ahead it is necessary to capture the generative model of the phenomenon. This task was used also by <ref> [12, 15, 16, 18, 21, 22, 33] </ref>, so results can be compared directly. The experiment has been organized as follows. First, a sequence of 1500 time steps has been generated.
Reference: [22] <author> J. Moody and C. Darken. </author> <title> Fast learning in networks of locally tuned units. </title> <booktitle> Neural Computations, </booktitle> <volume> 1(2) </volume> <pages> 281-294, </pages> <year> 1989. </year>
Reference-contexts: This can be done, in fact, by dividing the input space into a mosaic of closed regions, approximating the target function with a histogram. In RBFNs literature, this task is usually accomplished using clustering algorithms such as k-means <ref> [22, 42] </ref>. Afterwards, the weights on the links to the output level can be learned either performing a gradient descent of the quadratic error or using algorithms based on pseudo-inverse matrix transformation. <p> Here, three alternative procedures to automate the layout construction of a LRFN are reported: (1) the first is based on a variant of the k-means according to the algorithm described in <ref> [22, 42] </ref>; (2) the second one is based on CART [10], an algorithm for generating Regression Trees; (3) the last technique is based on symbolic learning methods in the line of [32], and allows learning both from data and from background knowledge. <p> In order to correctly predict the function value 84 steps ahead it is necessary to capture the generative model of the phenomenon. This task was used also by <ref> [12, 15, 16, 18, 21, 22, 33] </ref>, so results can be compared directly. The experiment has been organized as follows. First, a sequence of 1500 time steps has been generated. <p> The learning procedure based on modified k-means has not been tried here; nevertheless, by referring to the work by <ref> [22] </ref> we find a NDEI of 0.055 obtained with a training set of 10,000 examples and 1,000 hidden neurons. The method based on SMART+ obtained a better result using a fuzzy controller of 91 rules corresponding to a global number of 305 neurons in the first hidden layer.
Reference: [23] <author> M.T. Musavi, W. Ahmed, K.H. Chan, </author> <title> K.B. Faris, and D.M. Hummels. On the training of radial basis function classifiers. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 595-603, </pages> <year> 1992. </year>
Reference-contexts: Afterwards, the networks can be trained on-line e.g. by error minimization using a gradient descent technique (Section 3.4). 3.1 Using Statistical Clustering The clustering procedure applied for the experiments described in Section 4 is based on work presented in <ref> [23] </ref> and its algorithm is reported in this Section. <p> Differently than the observations documented in <ref> [23] </ref>, for function approximation problems as they are considered here, selecting ff &lt; 1 has proven to provide very satisfactory results, both in terms of network size and final approximation accuracy (see Section 4). The fi parameter, on the other hand, determines the initial size of the clusters.
Reference: [24] <author> M. Nuttin, H. Van Brussel, C. Baroglio, and R. Piola. </author> <title> Fuzzy controller syn thesis in robotic assembly: Procedure and experiments. </title> <booktitle> In FUZZ-IEEE-94: Third IEEE International Conference on Fuzzy Systems, World Congress on Computational Intelligence, </booktitle> <year> 1994. </year>
Reference-contexts: In the Fuzzy Controller approach, the most common practice is designing the network layout manually, relying on the domain knowledge of a human expert <ref> [24] </ref>. Variants of the error gradient descent have been proposed in order to refine the fuzzy sets in a second step [3].
Reference: [25] <author> M. Nuttin, H. Van Brussel, J. Peirs, A. S. Soembagijo, and S. Sonck. </author> <title> Learn ing the peg-into-hole assembly operation with a connectionist reinforcement technique. </title> <booktitle> In Second International CIRP Workshop on Learning in Intelligent Manufacturing Systems, </booktitle> <pages> pages 335-357, </pages> <address> Budapest, Hungary, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: The emphasis will be given to supervised learning, which can also be a basis for reinforcement learning architectures, as shown by a preliminary experiment based on Williams' REINFORCE algorithm <ref> [41, 25] </ref> for learning from continuous reinforcements. The paper is organized as follows. Section 2 performs a comparative analysis of the main methods available for regression, and tries to set a unifying view. <p> Obviously, in a learning problem framed in propositional calculus, predicate schemes will not have any variable but only constants to tune. An example of predicate used for learning a controller's layout can be GreaterF orce x (K : <ref> [10; 25; 0:1] </ref>) stating that the force along the X axis be greater than a constant K, ranging from 10 to 25 Newtons, with granularity 0.1. In this case, the learning events are simply described as attribute vectors where F orce x is one of them.
Reference: [26] <author> J. Peng and R.J. Williams. </author> <title> Efficient learning and planning within the Dyna framework. </title> <booktitle> In Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <address> Honolulu, HI, </address> <month> December </month> <year> 1992. </year>
Reference-contexts: A last point requiring some discussion is the need of refining a controller for overcoming the human teacher's skill. Reinforcement Learning (RL) is a promising way to overcome this limitation. Actually, in RL literature we find many techniques for learning in continuous domains <ref> [26, 5, 41, 13] </ref>, in which agents implemented as neural networks are trained. One system that integrates neural and reinforcement learning is Berenji's GARIC [5]. This system uses a fuzzy controller, implemented as a neural net work, which is very similar to those described in Section 2.
Reference: [27] <author> T. Poggio and F. Girosi. </author> <title> Networks for approximation and learning. </title> <journal> Proceed ings of the IEEE, </journal> <volume> 78(9) </volume> <pages> 1481-1497, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The activation functions can be grouped into two major families: Open Field Functions (OFFs), such as the sigmoid function used in MLPs (Multilayer Perceptrons), and Locally Receptive Field Functions (LRFFs), such as the multidimensional Gaussian functions used in Radial Basis Function Networks <ref> [27] </ref>. The difference is that OFFs split the function domain into two semi-spaces with a hy-perplane, whereas LRFFs have a radial symmetry. Furthermore, in a LRFN each neuron dominates over the others in a closed region of the input space, in which its response is significantly greater than zero.
Reference: [28] <author> J.R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 81 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Finally, the results are discussed in Section 5. 2 Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics [10, 36, 37], connectionism [30, 2], fuzzy logics [43, 4] and symbolic machine learning <ref> [32, 28] </ref>. Apart from regression and prediction trees, all the existing approximators can be represented by some multi-layered network, in which nodes (or neurons) computing a simple function (activation function) are connected by means of weighted links.
Reference: [29] <author> J.R. Quinlan. </author> <title> Combining instance-based and model-based learning. </title> <booktitle> In Pro ceedings of the 10 th machine learning conference, </booktitle> <pages> pages 236-243, </pages> <address> Amherst, MA, </address> <year> 1993. </year>
Reference-contexts: In the literature, regression has been tackled with different approaches: neural networks [30, 31], prediction trees, statistics <ref> [11, 29] </ref>, regression trees [10], and fuzzy logics [4], and it has been seen either as a supervised or as a reinforcement learning task.
Reference: [30] <author> D. E. Rumelhart and J. L. McClelland. </author> <title> Parallel Distributed Processing : Explorations in the Microstructure of Coginition, Parts I & II. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: In the literature, regression has been tackled with different approaches: neural networks <ref> [30, 31] </ref>, prediction trees, statistics [11, 29], regression trees [10], and fuzzy logics [4], and it has been seen either as a supervised or as a reinforcement learning task. <p> Finally, the results are discussed in Section 5. 2 Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics [10, 36, 37], connectionism <ref> [30, 2] </ref>, fuzzy logics [43, 4] and symbolic machine learning [32, 28]. Apart from regression and prediction trees, all the existing approximators can be represented by some multi-layered network, in which nodes (or neurons) computing a simple function (activation function) are connected by means of weighted links.
Reference: [31] <author> D.E. Rumelhart, G.E. Hinton, and R.J. Williams. </author> <title> Learning internal represen tations by error propagation. </title> <type> Technical Report 8506, </type> <institution> Institute for Cognitive Science, La Jolla: University of California, </institution> <address> San Diego, </address> <year> 1985. </year>
Reference-contexts: In the literature, regression has been tackled with different approaches: neural networks <ref> [30, 31] </ref>, prediction trees, statistics [11, 29], regression trees [10], and fuzzy logics [4], and it has been seen either as a supervised or as a reinforcement learning task. <p> Let moreover f (~x) depend upon a set P of tunable parameters. The error gradient descent is performed by iteratively updating each parameter P i 2 P with the following rule <ref> [31] </ref>: P i = @P i @E @y = (Y y) @P i If the update of the parameter P takes place immediately, the learning will be characterized as on-line.
Reference: [32] <author> C. Sammut, S. Hurst, D. Kedzier, and D. Michie. </author> <title> Learning to fly. </title> <editor> In D. Slee man and P. Edwards, editors, </editor> <booktitle> Machine Learning Proceedings of the Ninth International Workshop (ML92), </booktitle> <pages> pages 385-393. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: Finally, the results are discussed in Section 5. 2 Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics [10, 36, 37], connectionism [30, 2], fuzzy logics [43, 4] and symbolic machine learning <ref> [32, 28] </ref>. Apart from regression and prediction trees, all the existing approximators can be represented by some multi-layered network, in which nodes (or neurons) computing a simple function (activation function) are connected by means of weighted links. <p> are reported: (1) the first is based on a variant of the k-means according to the algorithm described in [22, 42]; (2) the second one is based on CART [10], an algorithm for generating Regression Trees; (3) the last technique is based on symbolic learning methods in the line of <ref> [32] </ref>, and allows learning both from data and from background knowledge. <p> In this way, the regression problem becomes a classification problem, being O the 7 set of classes and f fl (~x) the learning set, which can be solved using an algorithm such as C4.5. An example of this method is described in <ref> [32] </ref>. In the present case, we used a flexible learner called SMART+ [6, 9], that allows the induction process to be guided by the background knowledge of a domain expert.
Reference: [33] <author> T.D. Sanger. </author> <title> A tree-structured adaptive network for function approximate in high-dimensional spaces. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 2(2):285 293, </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: In order to correctly predict the function value 84 steps ahead it is necessary to capture the generative model of the phenomenon. This task was used also by <ref> [12, 15, 16, 18, 21, 22, 33] </ref>, so results can be compared directly. The experiment has been organized as follows. First, a sequence of 1500 time steps has been generated.
Reference: [34] <author> J. De Schutter and H. Van Brussel. </author> <title> Compliant robot motion II, a control ap proach based on external control loops. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 7(4), </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: The diameter of the shamfered peg was 30 [mm], the clearance between the peg and the hole was 0:15 [mm]: The hole was located on a plane surface. In the experiments, a PID controller was already available for the robot <ref> [34] </ref>, and the goal was to learn to approximate the behavior of the PID-controller using a set of examples of control behavior.
Reference: [35] <author> J. De Schutter, W. Witvrouw, P. Van De Poel, and H. Bruyninckx. Rosi: </author> <title> a task specification and simulation tool for force sensor based robot control. </title> <booktitle> In 24th International Symposium on Industrial Robots, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: Figure 5c shows the signal after on-line refinement. The signal shown is obtained from the second training example and is the velocity V z . Analogous results were obtained using SMART+. In order to test the learnt controllers "on the field", we used a professional robot simulation package <ref> [35] </ref>. The result is that the learnt behavior is comparable to the one of the teacher in terms of speed of insertion and quality of forces.
Reference: [36] <author> D.F. Specht. </author> <title> Probabilistic neural networks for classification mapping, or as sociative memory. </title> <booktitle> In IEEE International Conference on Neural Networks, </booktitle> <volume> volume 1, </volume> <pages> pages 525-532, </pages> <year> 1988. </year> <month> 17 </month>
Reference-contexts: Finally, the results are discussed in Section 5. 2 Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics <ref> [10, 36, 37] </ref>, connectionism [30, 2], fuzzy logics [43, 4] and symbolic machine learning [32, 28].
Reference: [37] <author> D.F. Specht. </author> <title> Probabilistic neural networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 109-118, </pages> <year> 1990. </year>
Reference-contexts: Finally, the results are discussed in Section 5. 2 Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics <ref> [10, 36, 37] </ref>, connectionism [30, 2], fuzzy logics [43, 4] and symbolic machine learning [32, 28].
Reference: [38] <author> G. Towell and J.W. Shavlik. </author> <title> Extracting refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13(1) </volume> <pages> 71-101, </pages> <year> 1993. </year>
Reference-contexts: In the latter case, learning the mapping from input signals to symbols, and then from symbols to an output signal, must also be taken into account. KBANN has, then, been improved by adding algorithms for turning a MLP back into a propositional theory (see <ref> [38] </ref>) a process we will call "inverse mapping of the network". Inverse mappings can be found also for LRFNs because of the locality property, that allows a discretization of inputs and outputs, and because they maintain their topological structure during learning.
Reference: [39] <author> G.G. Towell, J.W. Shavlik, and M.O. Noordwier. </author> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proceedings of the 8 th National Conference on Artificial Intelligence AAAI'90, </booktitle> <pages> pages 861-866, </pages> <year> 1990. </year>
Reference-contexts: A trained MLP has therefore the tendency to overgeneralize, whereas a LRFN always tends to undergeneralize, in the sense that its output will be null for every situation which is far from the examples processed during the training phase. 3. interpretability: LRFNs (as opposed to MLPs, which, with few exceptions <ref> [39] </ref>, are black-boxes w.r.t. their interpretation) can be given an immediate, symbolic interpretation of the hidden neurons. In fact, a closed region in the input space can be approximated using a hyper-rectangle which, in turn, can be described by a propositional formula (see Section 3.2). <p> In the literature, other methods have been already proposed in order to integrate the symbolic and connectionist paradigms, such as KBANN by Shavlik and 14 Towell <ref> [39] </ref>, who use a propositional theory to initialize a MLP for classification tasks in a domain of Boolean features. The main difference between the approach proposed in this paper and that of Shavlik's stands in the task they tackle.
Reference: [40] <author> A. Waibel, T. Hanazawa, G. Hinton, K. Shikano, and K. Lang. </author> <title> Phoneme recognition using time-delay neural networks. </title> <journal> IEEE Transactions on acoustics, speech and signal processing, </journal> <pages> pages 328-339, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: In fact, they obtained favourable results, w.r.t. the MLPs and TDNNs <ref> [40] </ref>, both on robot traces and on the Mackey-Glass series. It is worth noticing that, considering the aim of robotic applications, the slight differences of performance between OFFNs and LRFNs (though certainly mean ingful from a statistical viewpoint) cannot be decisive when looking for a technique to apply.
Reference: [41] <author> R.J. Williams. </author> <title> Simple statistical gradient-following algorithms for connec tionist reinforcement learning. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 9-44, </pages> <year> 1988. </year>
Reference-contexts: The emphasis will be given to supervised learning, which can also be a basis for reinforcement learning architectures, as shown by a preliminary experiment based on Williams' REINFORCE algorithm <ref> [41, 25] </ref> for learning from continuous reinforcements. The paper is organized as follows. Section 2 performs a comparative analysis of the main methods available for regression, and tries to set a unifying view. <p> A last point requiring some discussion is the need of refining a controller for overcoming the human teacher's skill. Reinforcement Learning (RL) is a promising way to overcome this limitation. Actually, in RL literature we find many techniques for learning in continuous domains <ref> [26, 5, 41, 13] </ref>, in which agents implemented as neural networks are trained. One system that integrates neural and reinforcement learning is Berenji's GARIC [5]. This system uses a fuzzy controller, implemented as a neural net work, which is very similar to those described in Section 2.
Reference: [42] <author> J.G. Wilpon and L.R. Rabiner. </author> <title> A modified k-means clustering algorithm for use in isolated work recognition. </title> <journal> IEEE transactions on acoustics, speech and signal processing, </journal> <volume> ASSP-33:587-594, </volume> <month> Jun </month> <year> 1985. </year>
Reference-contexts: This can be done, in fact, by dividing the input space into a mosaic of closed regions, approximating the target function with a histogram. In RBFNs literature, this task is usually accomplished using clustering algorithms such as k-means <ref> [22, 42] </ref>. Afterwards, the weights on the links to the output level can be learned either performing a gradient descent of the quadratic error or using algorithms based on pseudo-inverse matrix transformation. <p> Here, three alternative procedures to automate the layout construction of a LRFN are reported: (1) the first is based on a variant of the k-means according to the algorithm described in <ref> [22, 42] </ref>; (2) the second one is based on CART [10], an algorithm for generating Regression Trees; (3) the last technique is based on symbolic learning methods in the line of [32], and allows learning both from data and from background knowledge.
Reference: [43] <author> L.A. Zadeh. </author> <title> Knowledge representation in fuzzy logic. In R.R. </title> <editor> Yager and L.A. Zadeh, editors, </editor> <title> An Introduction to Fuzzy Logic Applications in Intelligent Systems. </title> <publisher> Kluver Academic Publishers, </publisher> <year> 1992. </year> <month> 18 </month>
Reference-contexts: Finally, the results are discussed in Section 5. 2 Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics [10, 36, 37], connectionism [30, 2], fuzzy logics <ref> [43, 4] </ref> and symbolic machine learning [32, 28]. Apart from regression and prediction trees, all the existing approximators can be represented by some multi-layered network, in which nodes (or neurons) computing a simple function (activation function) are connected by means of weighted links. <p> We will show how symbolic learning algorithms can be used to automatically build excellent layouts for LRFNs. 2.1 A Fuzzy Controller Architecture Fuzzy controllers are a kind of universal function approximators developed within the fuzzy logic community <ref> [43, 4] </ref> and are representative of the LRFN family. As a matter of fact, Fuzzy Controllers do not correspond to a single architecture but to a wide family that contains the topology of Figure 1b as a special case.
References-found: 43

