URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3295/3295.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: Implementing an Algorithm for Solving Block Hessenberg Systems  
Author: G. W. Stewart 
Date: December, 1993  
Affiliation: University of Maryland College Park Institute for Advanced Computer Studies TR-94-70 Department of Computer Science  
Pubnum: TR-3295  
Abstract: This paper describes the implementation of a recursive descent method for solving block Hessenberg systems. Although the algorithm is conceptually simple, its implementation in C (a natural choice of language given the recursive nature of the algorithm and its data) is nontrivial. Particularly important is the balance between ease of use, computational efficiency, and flexibility. fl This report and the programs it documents are available by anonymous ftp from thales.cs.umd.edu in the directory pub/reports. y Department of Computer Science and Institute for Advanced Computer Studies, University of Mary-land, College Park, MD 20742. This work was supported in part by the National Science Foundation under grant CCR 9115568. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. C. S. Lui and R. R. Muntz. </author> <title> Evaluating bounds on staeady state availability of repairable systems from Markov models. </title> <editor> In W. J. Stewart, editor, </editor> <title> Numerical Solution of Markov Chains, </title> <address> pages 435-454, Amsterdam, 1989. </address> <publisher> North Holland. </publisher>
Reference-contexts: 1. Introduction Block Hessenberg arise in a number of applications, including queueing theory [2, 3] and repairable systems <ref> [1] </ref>. <p> can initialize Q and R ourselves [see (8.1)]. aswfr = make_dhqrdc (m, m, 0); aswfr-&gt;effrnk = 1; for (i=1; i&lt;=m; i++)- aswfr-&gt;q->val [i]<ref> [1] </ref> = 0.; aswfr-&gt;r->val [1][i] = -w [1][i]; - aswfr-&gt;q->val [1][1] = 1.; Next we create a bhtree, complete with patches. BHESS: Solving Block Hessenberg Systems 19 dbx [1] = 1; dbx [i+1] = dbx [i] + m; a = make_bhtree (n, dbx, 1, n, daminit, NULL, 0, NULL); patchgen (a, 1, dammult); The main program ends by computing and printing G. for (i=1; i&lt;=m; i++)- g [i][j] = 0.; for (k=1; k&lt;=a-&gt;aswfr->effrnk; k++)- g [i][j] = g [i][j]
Reference: [2] <author> M. Neuts. </author> <title> Matrix-Geometric Solutions in Stochastic Models. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1981. </year>
Reference-contexts: 1. Introduction Block Hessenberg arise in a number of applications, including queueing theory <ref> [2, 3] </ref> and repairable systems [1].
Reference: [3] <author> M. F. Neuts. </author> <title> Structured Stochastic Matrices of M/G/1 Type and Their Applications. </title> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: 1. Introduction Block Hessenberg arise in a number of applications, including queueing theory <ref> [2, 3] </ref> and repairable systems [1]. <p> Background The problem treated here is called the Odoom-Lloyd dam model. The following sketch is intended to get the reader quickly to the matrix problem that must be solved. For more technical details see the exposition in <ref> [3] </ref>. In this model things happen at discrete points in time called epochs. At the kth epoch, Mother Nature puts r k units of water into a reservoir behind a dam, and at the same time the dam keeper releases one unit of water.
Reference: [4] <author> G. W. Stewart. </author> <title> On the solution of block hessenberg systems. </title> <type> Technical Report CS-TR-2973, </type> <institution> Department of Computer Science, University of Maryland, College Park, </institution> <year> 1992. </year> <note> To appear in Numerical Linear Algebra and Applications.. 22 BHESS: Solving Block Hessenberg Systems </note>
Reference-contexts: The system is solved by recursively dividing it into smaller block Hessenberg systems. The mathematical underpinings of the algorithm as well as its complexity have been treated elsewhere by the author <ref> [4] </ref>. If the matrix A is dense, then the method costs the same as Gaussian elimination. However, if A is sparse, the method can result in considerable savings in both time and memory. <p> However, that would require a complete restructuring of bhess. Whether the savings are worth the trouble is problematical. See the operation counts in <ref> [4] </ref>. One last point. For debugging purposes, it is a good idea to have a problem whose answer can be recognized. It can be shown that if the process is recurrent, then G = (w 1 w 1 : : : w 1 ) T .
Reference: [5] <author> U. von Matt and G. W. Stewart. </author> <title> Rounding errors in solving block hessenberg systems. </title> <institution> Institute for Advanced Computer Studies, Universiyt of Maryland, College Park, MD 20742, </institution> <year> 1994. </year>
Reference-contexts: If the matrix A is dense, then the method costs the same as Gaussian elimination. However, if A is sparse, the method can result in considerable savings in both time and memory. A rounding error analysis <ref> [5] </ref> shows that the method is stable for diagonally dominant matrices, which covers the applications mentioned above. The purpose of this paper is to describe an implementation in C of the algorithm. The details of the implementation have been driven by a number of considerations, not all of them consonant.
References-found: 5

