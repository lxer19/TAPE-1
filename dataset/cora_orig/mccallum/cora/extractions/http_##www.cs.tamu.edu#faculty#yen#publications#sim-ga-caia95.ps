URL: http://www.cs.tamu.edu/faculty/yen/publications/sim-ga-caia95.ps
Refering-URL: http://www.cs.tamu.edu/faculty/yen/publications/index.html
Root-URL: http://www.cs.tamu.edu
Title: A Hybrid Approach to Modeling Metabolic Systems Using Genetic Algorithm and Simplex Method  
Author: John Yen MEMBER, IEEE* James C. Liaoy Bogju Lee* David Randolph* 
Address: College Station, TX 77843-3112 yDepartment  College Station, TX 77843-3122  
Affiliation: Center for Fuzzy Logic and Intelligent Systems Research, Department of Computer Science, Texas A&M University,  of Chemical Engineering, Texas A&M University,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> K. A. Dejong, </author> <title> Analysis of the behavior of a class of genetic adaptive systems, </title> <type> PhD thesis, </type> <institution> Department of Computer and Communication Sciences, University of Michigan, </institution> <year> 1975. </year>
Reference-contexts: To distinguish this modification to simplex from the one developed by Nelder and Mead, we will refer to this method as the probabilistic simplex. IV. Integrating Genetic Algorithms and the Simplex Method While genetic algorithms (GAs) have shown to be effective for solving a wide range of optimization problems <ref> [1] </ref>, its convergence speed is typically much slower than local optimization techniques. It can only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 2 .
Reference: [2] <author> D. E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning, </title> <address> MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: This is achieved by combining Equations 3 and 5 into the following equation: X p = X + ff (X X w ) (6) where ff is a random variable taking its value from the interval <ref> [0, 2] </ref> based on a predetermined probability distribution. A probability distribution used in our application is a triangular probability density function that peaks at 1, and reaches zero probability at 0 and 2 respectively.
Reference: [3] <author> H. Kargupta and R. E. Smith, </author> <title> "System identification with evolving polynomial networks," </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Diego, CA, </address> <month> July </month> <year> 1991. </year>
Reference: [4] <author> K. Kristinnson and G. A. Dumont, </author> <title> "System identification and control using genetic algorithms," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 22, no. 5, </volume> <pages> pp. 1033-1046, </pages> <year> 1992. </year>
Reference: [5] <author> H. Iba, T. Kurita, H. deGaris, and T. Sato, </author> <title> "System identification using structured genetic algorithms," </title> <booktitle> In Proceedings of 5th International Joint Conference on Genetic Algorithms, </booktitle> <year> 1993. </year>
Reference: [6] <author> D. M. Etter, M. J. Hicks, and K. H. Cho, </author> <title> "Recursive adaptive filter design using an adaptive genetic algorithm," </title> <booktitle> In ICASSP 82 : Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 2, </volume> <pages> pp. 635-638, </pages> <address> Paris, France, </address> <month> May </month> <year> 1982. </year>
Reference: [7] <author> S. Uckun, S. Bagchi, and K. Kawamura, </author> <title> "Managing genetic search in job shop scheduling," </title> <journal> IEEE Expert, </journal> <volume> vol. 8, no. 5, </volume> <pages> pp. 15-24, </pages> <year> 1993. </year> <month> 39 </month>
Reference: [8] <author> A. B. Conru, </author> <title> "A genetic approach to the cable harness routing problem," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference: [9] <author> D. P. Kwok and F. Sheng, </author> <title> "Genetic algorithm and simulated annealing for optimal robot arm pid control," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference: [10] <author> D. Park and A. Kandel, </author> <title> "Genetic-based new fuzzy reasoning models with application to fuzzy control," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 24, no. 1, </volume> <pages> pp. 39-47, </pages> <year> 1994. </year>
Reference: [11] <author> T. Smith and K. A. DeJong, </author> <title> "Genetic algorithms applied to the calibration of information driven models of us migration patterns," </title> <booktitle> In Proceedings of 12th annual Pittsburgh Conference on Modeling and Simulation, </booktitle> <pages> pp. 955-959, </pages> <year> 1981. </year>
Reference: [12] <author> D. J. Janson and J. F. Frenzel, </author> <title> "Training product unit neural networks with genetic algorithms," </title> <journal> IEEE Expert, </journal> <volume> vol. 8, no. 5, </volume> <pages> pp. 26-33, </pages> <year> 1993. </year>
Reference: [13] <author> M. F. Bramlette, </author> <title> "Finding maximum flow with random and genetic search," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference: [14] <author> P. S. de Souza and S. N. Talukdar, </author> <title> "Genetic algorithm in asynchronous teams," </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pp. 392-397, </pages> <address> San Diego, CA, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: It can only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 2 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [30, 14, 15, 31, 32, 33, 17, 20] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum. <p> The A-Teams (Asynchronous Teams) methodology describes the first kind of combination by mating the GA with Newton's Method <ref> [14] </ref>. A.3 Hierarchical Hybrids A hierarchical hybrid GA uses a GA and another optimization technique at two different levels of an optimization problem. An example of hierarchical hybrid is the hybrid of the genetic algorithm and the Multivariate Adaptive Regression Splines (MARS) to create the G/SPLINES algorithm [15].
Reference: [15] <author> D. Rogers, "G/SPLINES: </author> <title> A hybrid of Friedman's multivariate adaptive regression splines (MARS) algorithm with Holland's genetic algorithm," </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pp. 384-391, </pages> <address> San Diego, CA, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: It can only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 2 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [30, 14, 15, 31, 32, 33, 17, 20] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum. <p> A.3 Hierarchical Hybrids A hierarchical hybrid GA uses a GA and another optimization technique at two different levels of an optimization problem. An example of hierarchical hybrid is the hybrid of the genetic algorithm and the Multivariate Adaptive Regression Splines (MARS) to create the G/SPLINES algorithm <ref> [15] </ref>.
Reference: [16] <author> K. E. Mathias, L. D. Whitley, C. Stork, and T. Kusuma, </author> <title> "Staged hybrid genetic search for seismic data imaging," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <pages> pp. 356-361, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Although local optimization in a hybrid often results in a faster convergence, it has been shown that too much local optimization can interfere with the search for a global optimum by drawing the genetic algorithm's attention to local optima too quickly, leading to premature convergence <ref> [16] </ref>. Thus, while local optimization might improve the speed of the analysis, it may also reduce 2 The underlying foundation of this search strategy is Holland's Schema Theory [21]. 12 the quality of the final solution found. <p> There are three basic types of pipelining hybrid GA, as shown in the primary search routine. (3) The GA interleaves with another optimization technique. This has often been referred to as staged hybrid in the literature <ref> [16] </ref>. A.2 Asynchronous Hybrids An asynchronous hybrid architecture uses a shared population to allow a GA and other optimization processes to proceed and cooperate asynchronously. One process might work on the problem by itself for several iterations before accessing the shared population again.
Reference: [17] <author> H. Ishibuchi, N. Yamamoto, T. Murata, and H. Tanaka, </author> <title> "Genetic algorithms and neighborhood search algorithms for fuzzy flowshop scheduling problems," </title> <journal> Fuzzy Sets and Systems, </journal> <volume> vol. 67, no. 1, </volume> <pages> pp. 81-100, </pages> <year> 1994. </year>
Reference-contexts: It can only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 2 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [30, 14, 15, 31, 32, 33, 17, 20] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [18] <author> J. Yen, J. C. Liao, D. Randolph, and B. Lee, </author> <title> "A hybrid approach to modeling metabolic systems using genetic algorithm and simplex method," </title> <booktitle> In Proceedings of the 11th IEEE Conference on Artificial Intelligence for Applications (CAIA95), </booktitle> <pages> pp. 277-283, </pages> <address> Los Angeles, CA, </address> <month> Feburary </month> <year> 1995. </year>
Reference-contexts: B.2 Our Simplex-GA Hybrid Approach We developed an alternative simplex-GA hybrid independently by applying a concurrent version of probabilistic simplex operator to top ranking chromosomes <ref> [18] </ref>. Concurrent Simplex A concurrent simplex is very much like the classical simplex methods with one minor difference. Instead of starting with N +1 points in the simplex (where N is the number of variables to be optimized), the variant begins with N + points, where &gt; 1.
Reference: [19] <author> J. A. Nelder and R. Mead, </author> <title> "A simplex method for function minimization," </title> <journal> Computer Journal, </journal> <volume> vol. 7, </volume> <pages> pp. 308-313, </pages> <year> 1965. </year>
Reference-contexts: B.2 Nelder-Mead Simplex Method Nelder and Mead developed a modification to the basic simplex method that allows the procedure to adjust its search step according to the evaluation result of the new point generated <ref> [19] </ref>. This is achieved in three ways.
Reference: [20] <author> D. B. McGarrah and R. S. Judson, </author> <title> "Analysis of the genetic algorithm method of molecular conformation determination," </title> <journal> Journal of Computational Chemistry, </journal> <volume> vol. 14, no. 11, </volume> <pages> pp. 1385-1395, </pages> <year> 1993. </year>
Reference-contexts: It can only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 2 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [30, 14, 15, 31, 32, 33, 17, 20] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [21] <author> J. H. Holland, </author> <booktitle> Adaptation in Natural and Artificial Systems, </booktitle> <address> Ann Arbor, MI: </address> <publisher> University of Michigan Press, </publisher> <year> 1975. </year>
Reference-contexts: Thus, while local optimization might improve the speed of the analysis, it may also reduce 2 The underlying foundation of this search strategy is Holland's Schema Theory <ref> [21] </ref>. 12 the quality of the final solution found. Thus, designing a hybrid approach for an application involves a careful analysis of these tradeoffs.
Reference: [22] <author> Z. Michalewicz, </author> <title> Genetic Algorithms + Data Structures = Evolution Programs, </title> <publisher> Springer Verlag Berlin Heidelberg, </publisher> <year> 1992. </year>
Reference-contexts: We chose the function maximization problems used by Renders and Bersini [30], which are actually instances of a function family introduced by Michalewicz in <ref> [22] </ref>: f (~x) = i=1 i fi x 2 26 27 28 where x i 2 [0; ]. We chose the function maximization problem because there are many (exactly N !) local minima in this function. As m grows, finding maxima of this function becomes more and more difficult.
Reference: [23] <author> C. Z. Janikow and Z. Michalewicz, </author> <title> "An experimental comparison of binary and floating point representation in genetic algorithms," </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pp. 31-36, </pages> <address> San Diego, CA, </address> <month> July </month> <year> 1991. </year>
Reference: [24] <author> J. Kowalik and M. R. Osborne, </author> <title> Methods for Unconstrained Optimization Problems, </title> <address> New York: </address> <publisher> American Elsevier, </publisher> <year> 1968. </year>
Reference: [25] <author> R. W. Daniels, </author> <title> An Introduction to Numerical Methods and Optimization Techniques, </title> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1978. </year>
Reference: [26] <author> H. P. Schwefel, </author> <title> Numerical optimization of computer models, </title> <address> Chichester, NY: </address> <publisher> Wiley, </publisher> <year> 1981. </year>
Reference: [27] <author> M. J. D. Powell, </author> <title> "An effecient method for finding the minimum of a function of several variables without calculating derivatives," </title> <journal> Computer Journal, </journal> <volume> vol. 8, </volume> <pages> pp. 155-162, </pages> <year> 1964. </year>
Reference: [28] <author> R. Hooke and T. A. Jeeves, </author> <title> "Direct search solution of numerical and statistical problems," </title> <journal> Journal of the ACM, </journal> <volume> vol. 8, </volume> <pages> pp. 212-229, </pages> <year> 1961. </year>
Reference: [29] <author> W. Spendley, G. R. Hext, and F. R. Himsworth, </author> <title> "Sequential application of simplex designs in optimization and evolutionary operation," </title> <journal> Technometrics, </journal> <volume> vol. 4, </volume> <pages> pp. 441-461, </pages> <year> 1962. </year> <month> 41 </month>
Reference: [30] <author> J. Renders and H. Bersini, </author> <title> "Hybridizing genetic algorithms with hill-climbing methods for global optimization: Two possible ways," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <pages> pp. 312-317, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: It can only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 2 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [30, 14, 15, 31, 32, 33, 17, 20] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum. <p> The parameters of R-B hybrid are those reported in their paper for a function maximization problem: 0.5 simplex probability, 0.2 crossover probability, and 0.2 average probability <ref> [30] </ref>. <p> VI. Application to a Function Maximization Problem Because of the success of applying our simplex-GA hybrid to the metabolic modeling problem, we decided to further test our hybrid approach using a different problem. We chose the function maximization problems used by Renders and Bersini <ref> [30] </ref>, which are actually instances of a function family introduced by Michalewicz in [22]: f (~x) = i=1 i fi x 2 26 27 28 where x i 2 [0; ]. We chose the function maximization problem because there are many (exactly N !) local minima in this function. <p> As m grows, finding maxima of this function becomes more and more difficult. Renders and Bersini used two instances of this function family to test their hybrid approach by setting N to 10, and m to 10 and 100 respectively <ref> [30] </ref>. These problems are 10-dimensional optimization problems. Theoretical maximum of these two functions are 9.660 (for m=10) and 9.655 (for m=100). We used these two problems to test our hybrid approach (57% simplex-GA) and compare the performance with those of GA, 100% concurrent simplex, and R-B hybrid. <p> For the R-B hybrid, we used the parameters that gave the best performance in their experiments (i.e., 0.2, 0.2, and 0.5 for the crossover probability, the average probability, and the simplex probability, respectively) <ref> [30] </ref>. Figures 15 and 16 plot the average best fitness vs number of trials for the two function maximization problems. Because the performance of the 100% concurrent simplex is much worse than the other three approaches, they are not included in the figures. <p> The performance of real-coded GA was better than that of R-B hybrid. We need to clarify a few differences between the result of our experiments and those reported by Renders and Bersini <ref> [30] </ref>. The GA outperformed the R-B hybrid for both problems in our experiment, but was outperformed by the R-B hybrid in their experiment. One of the differences between the two experiments is the maximum trials allowed.
Reference: [31] <author> D. Ackley, </author> <title> Stochastic Iterated Genetic Hillclimbing, </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1987. </year>
Reference-contexts: It can only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 2 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [30, 14, 15, 31, 32, 33, 17, 20] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [32] <author> G. Dozier, J. Bowen, and D. Bahler, </author> <title> "Solving small and large scale constraint satisfaction problems using a heuristic-based microgenetic algorithm," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: It can only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 2 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [30, 14, 15, 31, 32, 33, 17, 20] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [33] <author> T. Murata and H. Ishibuchi, </author> <title> "Performance evaluation of genetic algorithms for flowshop scheduling problems," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: It can only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 2 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [30, 14, 15, 31, 32, 33, 17, 20] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [34] <author> J. J. Grefenstette, </author> <note> User's Guide to GENESIS Verison 5.0, </note> <year> 1990. </year>
Reference-contexts: We summarize the major differences between these two hybrid simplex-GA approaches in Table 3. V. Application to Metabolic Modeling We have successfully applied our simplex-GA hybrid optimization approach to the metabolic modeling problem described in Section II. We implemented the approach by modifying the code of GENESIS <ref> [34] </ref>. In this section, we describe the design of this application and the empirical results obtained, which is compared with those of original real-coded GA, concurrent simplex, and the R-B hybrid approach.
Reference: [35] <author> M. Caracotsios and W. E. Stewart, </author> <title> DDASAC Double precision Differential Algebraic Sensitivity Analysis Code, </title> <year> 1984. </year>
Reference-contexts: The Fitness Evaluation: To evaluate the fitness of a chromosome, we assign the parameter values in the chromosome to their corresponding parameters. We then evaluate the metabolic model with these parameter assignment by simulating the model using DDASAC (Double precision Differential Algebraic Sensitivity Analysis Code) <ref> [35] </ref> with thirty time steps. Even though the metabolic model consists of forty four state variables, only three of them can actually be observed during experiments (i.e., GLU , P Y R, and ffKET O).
Reference: [36] <author> J. Grefenstette, </author> <title> "GENESIS: A system for using genetic search procedures," </title> <booktitle> In Proceedings of the 1984 Conference of Intelligent Systems and Machines, </booktitle> <pages> pp. 161-165, </pages> <year> 1984. </year> <month> 42 </month>
Reference-contexts: Acknowledgements This research is partially supported by NSF Young Investigator Awards IRI 92-57293 and BCS-9257351. The software package for model simulation DDASAC was originated from M. Caracotsios and W. E. Stewart. The GENESIS implementation of GA was developed by John J. Grefenstette <ref> [36] </ref>.
References-found: 36

