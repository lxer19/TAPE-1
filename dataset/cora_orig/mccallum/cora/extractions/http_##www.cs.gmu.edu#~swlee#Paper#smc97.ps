URL: http://www.cs.gmu.edu/~swlee/Paper/smc97.ps
Refering-URL: http://www.cs.gmu.edu/~swlee/publication~.html
Root-URL: 
Email: -swlee, jwnek-@aic.gmu.edu  
Title: AqBC: A Multistrategy Approach for Constructive Induction  
Author: Seok Won Lee and Janusz Wnek 
Address: M.S. 4A5  4400 University Drive Fairfax, VA 22030-4444  Tysons Corner, VA.  
Affiliation: Laboratory,  George Mason University  Corp.,  
Note: Machine Learning and Inference  Also with Science Applications International  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Bloedorn and R. S. Michalski, </author> <title> Constructive Induction from Data in AQ17-DCI: Further Experiments , Reports of the Machine Learning and Inference Laboratory, </title> <type> MLI 91-12, </type> <institution> George Mason University, Fairfax, VA, </institution> <year> 1991. </year>
Reference-contexts: Multiple engines may also be used to perform additional constructive induction prior to unsupervised classification. For example, AQ17-DCI <ref> [1] </ref> and AQ17-HCI [14] construct new features based on interrelationships among existing ones. Varying the rule learner based on the application may also prove productive. If mathematical formulae are desired instead of conjunctive rules, a system such as ABACUS [3] could be employed in place of AQ15c.
Reference: [2] <author> P. Cheeseman and J. Stutz, </author> <title> Bayesian Classification (AutoClass): Theory and Results , In Advances in Knowledge Discovery and Data Mining. </title> <editor> U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, eds., </editor> <publisher> AAAI Press, </publisher> <address> Menlo Park, </address> <year> 1996. </year>
Reference-contexts: These new concepts expand the knowledge representation space for the supervised inductive learning system. The system employs constructive induction to create and enhance the knowledge representation space with the aid of the unsupervised Bayesian classifier, AutoClass <ref> [2] </ref>. AutoClass provides a maximum posterior probability grouping objects into classes. The constructed classes define abstract concepts, with descriptions learned from class members using the inductive learning system, AQ15c [13]. The abstract concept descriptions are then used to improve and expand the original representation space. <p> The new attributes degree of belief is very high because it is generated from the best model of Bayesian classification. Therefore, this new attribute can potentially reorganize and improve the knowledge representation space. The theory of how Bayesian learning is applied in AutoClass is described in <ref> [2] </ref>, [5]. The AqBC Multistrategy Learning Methodology AqBC is a multistrategy knowledge discovery approach that combines unsupervised Bayesian classification with supervised inductive learning. Figure 3 shows the general structure of the AqBC approach. AqBC can be applied to two different goals.
Reference: [3] <author> B. C . Falkenhainer and R. S. Michalski, </author> <title> Integration Quantitative and Qualitative Discovery in the ABACUS System, </title> <booktitle> In Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. </volume> <editor> III. Y. Kodratoff and R. S . Michalski, eds., </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1990. </year>
Reference-contexts: For example, AQ17-DCI [1] and AQ17-HCI [14] construct new features based on interrelationships among existing ones. Varying the rule learner based on the application may also prove productive. If mathematical formulae are desired instead of conjunctive rules, a system such as ABACUS <ref> [3] </ref> could be employed in place of AQ15c. There are still many challenging real world applications to which this multistrategy approach could be applied for new knowledge discovery. 6. ACKNOWLEDGMENTS The authors thank Dr. Ryszard Michalski for his comments and the AutoClass group for making their software readily available.
Reference: [4] <editor> U. M. Fayyad, G. Piatetsky-Shapiro, P . Smyth, and R. Uthurusamy, eds. </editor> <booktitle> Advances in Knowledge Discovery and Data Mining , The AAAI Press, </booktitle> <address> Menlo Park. </address> <year> 1996. </year>
Reference-contexts: 1. INTRODUCTION The explosive growth of large scale databases far exceeds our ability to analyze them, requiring a new approach for intelligent and automated knowledge discovery <ref> [4] </ref>. We present AqBC [7], a multistrategy knowledge discovery approach to concept learning. AqBC extracts new knowledge, determines meaningful descriptions and applies the newly acquired knowledge in supervised learning. These descriptions and knowledge grow out of patterns identified by AqBC.
Reference: [5] <author> R. Hanson, J. Stutz, and P. Cheeseman, </author> <title> Bayesian Classification Theory, </title> <type> Technical Report FIA-90-12-7-01, </type> <institution> NASA Ames Research Center, </institution> <note> Artificial Intelligence Branch , 1991. </note>
Reference-contexts: The new attributes degree of belief is very high because it is generated from the best model of Bayesian classification. Therefore, this new attribute can potentially reorganize and improve the knowledge representation space. The theory of how Bayesian learning is applied in AutoClass is described in [2], <ref> [5] </ref>. The AqBC Multistrategy Learning Methodology AqBC is a multistrategy knowledge discovery approach that combines unsupervised Bayesian classification with supervised inductive learning. Figure 3 shows the general structure of the AqBC approach. AqBC can be applied to two different goals.
Reference: [6] <author> T. Kohonen, </author> <title> Self Organizing Maps , Springer-Verlag, </title> <address> Heidelberg, </address> <year> 1995. </year>
Reference-contexts: Not only Bayesian classifiers benefit from the use of AQ15c to learn the descriptive representations of the generated classes. In addition to the distance-based clustering methods like K-means centroid & Ward hierarchical clustering , other subsymbolic systems such as SOFMs <ref> [6] </ref> and k-NN methods can be employed as the unsupervised classification engine. Multiple engines may also be used to perform additional constructive induction prior to unsupervised classification. For example, AQ17-DCI [1] and AQ17-HCI [14] construct new features based on interrelationships among existing ones.
Reference: [7] <author> S. W. Lee, </author> <title> Multistrategy Learning: An Empirical Study with AQ + Bayesian Approach, Reports of the Machine Learning and Inference Laboratory, </title> <type> MLI 96-10, </type> <institution> George Mason University, Fairfax, VA, </institution> <year> 1996. </year>
Reference-contexts: 1. INTRODUCTION The explosive growth of large scale databases far exceeds our ability to analyze them, requiring a new approach for intelligent and automated knowledge discovery [4]. We present AqBC <ref> [7] </ref>, a multistrategy knowledge discovery approach to concept learning. AqBC extracts new knowledge, determines meaningful descriptions and applies the newly acquired knowledge in supervised learning. These descriptions and knowledge grow out of patterns identified by AqBC.
Reference: [8] <author> R. S. Michalski, </author> <title> Pattern Recognition as Knowledge-Guided Computer Induction, </title> <type> Technical Report No. 927, </type> <institution> Department of Computer Science, University of Illinois, Urbana-Champaign, </institution> <year> 1978. </year>
Reference-contexts: In this paper, we show that the newly created knowledge facilitates classification and, in turn, problem solving that employs classification or pattern recognition in large databases. 2. THE SIGNIFICANCE OF IMPROVING THE KNOWLEDGE REPRESENTATION SPACE Constructive Induction (CI) is a concept proposed in the field of inductive concept learning <ref> [8] </ref> to solve learning problems in which the original representation space is inadequate for the problem at hand and needs to be improved in order to correctly formulate the knowledge to be learned. In other words, constructive induction hypothesizes new knowledge using a search process.
Reference: [9] <author> R. S. Michalski, </author> <title> A Theory and Methodology of Inductive Learning, </title> <booktitle> Artificial Intelligence . Vol.20, </booktitle> <pages> 111-116, </pages> <year> 1983a. </year>
Reference-contexts: AQBC : A MULTISTRATEGY APPROACH FOR CONSTRUCTIVE INDUCTION-BASED KNOWLEDGE DISCOVERY AQ15c Inductive Learning System AQ15c [13] is a C language reimplementation of AQ15 [11] with significant performance improvement and dynamic allocation of representation spaces. AQ-family of inductive learning programs implements the STAR method of inductive learning <ref> [9] </ref>. AQ15c learns decision rules for a given set of decision classes from examples. When learning rules, AQ15c uses 1) background knowledge in the form of rules (input hypotheses), 2) the definition of descriptors and their types and 3) a rule preference criterion that evaluates competing candidate hypotheses.
Reference: [10] <author> R. S. Michalski and R. E. Stepp, </author> <title> Automated Construction of Classifications: Conceptual Clustering Versus Numerical Taxonomy, </title> <journal> IEEE Transactions on PAMI 5:4, </journal> <pages> 396-410, </pages> <year> 1983b. </year>
Reference-contexts: Another potential experiment would be to use the taxonomy produced via the AqBC method to perform supervised classification with many different decision attributes from the current set rather than just the population attribute. Other future research will focus on developing new strategies combining various statistical and conceptual <ref> [10] </ref> classification methods for constructing better knowledge representation spaces from large data sets. Not only Bayesian classifiers benefit from the use of AQ15c to learn the descriptive representations of the generated classes.
Reference: [11] <author> R. S. Michalski, I. Mozetic, J. Hong, and N. Lavrac, </author> <title> The MultiPurpose Incremental Learning System AQ15 and its Testing Application to Three Medical Domains , In Proceedings of AAAI-86 , 1041-1045, </title> <address> Philadelphia, PA, </address> <year> 1986. </year>
Reference-contexts: AQBC : A MULTISTRATEGY APPROACH FOR CONSTRUCTIVE INDUCTION-BASED KNOWLEDGE DISCOVERY AQ15c Inductive Learning System AQ15c [13] is a C language reimplementation of AQ15 <ref> [11] </ref> with significant performance improvement and dynamic allocation of representation spaces. AQ-family of inductive learning programs implements the STAR method of inductive learning [9]. AQ15c learns decision rules for a given set of decision classes from examples.
Reference: [12] <author> S. B. Thrun, et al. </author> <title> The MONK s problems: A Performance Comparison of Different Learning Algorithms , Carnegie Mellon University, </title> <year> 1991. </year>
Reference-contexts: This way, the hierarchical hypotheses structures discovered from the nested classifications provide valuable information that cannot be obtained from either system alone. The first MONK problem, MONK1, <ref> [12] </ref> and US census data have been used for experimentation. The diagrammatic visualization system, DIAV [15] graphically interprets the knowledge representation spaces and shows the changes in the representation space caused by constructive induction.
Reference: [13] <author> J. Wnek, K. Kaufman, E. Bloedorn, and R. S. Michalski, </author> <title> Inductive Learning System AQ15c: The Method and Users Guide, Reports of the Machine Learning and Inference Laboratory , MLI 95-4, </title> <institution> George Mason University, VA, </institution> <year> 1995. </year>
Reference-contexts: AutoClass provides a maximum posterior probability grouping objects into classes. The constructed classes define abstract concepts, with descriptions learned from class members using the inductive learning system, AQ15c <ref> [13] </ref>. The abstract concept descriptions are then used to improve and expand the original representation space. This expanded representation space serves as a final setting for supervised concept learning of any attribute from the original examples by employing A Q15c. <p> AQBC : A MULTISTRATEGY APPROACH FOR CONSTRUCTIVE INDUCTION-BASED KNOWLEDGE DISCOVERY AQ15c Inductive Learning System AQ15c <ref> [13] </ref> is a C language reimplementation of AQ15 [11] with significant performance improvement and dynamic allocation of representation spaces. AQ-family of inductive learning programs implements the STAR method of inductive learning [9]. AQ15c learns decision rules for a given set of decision classes from examples.
Reference: [14] <author> J. Wnek and R. S. Michalski, </author> <title> Hypothesis-driven Constructive Induction in AQ17-HCI: A method and experiments, </title> <journal> Machine Learning , Vol.14, No.2, </journal> <month> 139-168 , </month> <year> 1994. </year>
Reference-contexts: CI searches for patterns in data, learned hypotheses, and knowledge from experts, using them to create a new knowledge representation space <ref> [14] </ref>. In order to find an appropriate representation space, clustering is an important way of summarizing and explaining data. A clustering system accepts a set of object descriptions (events, observations, facts) and produces a classification scheme over the observations. <p> By not providing the original classifications , the original properties of the testing data set can be preserved and AutoClasss ability to correctly classify previously unseen examples can be verified. The technique of constructing classification labels is based on previous constructive induction methodology <ref> [14] </ref>. The improvement of the knowledge representation space is already demonstrated with the MONK1 problem in the previous section . <p> Multiple engines may also be used to perform additional constructive induction prior to unsupervised classification. For example, AQ17-DCI [1] and AQ17-HCI <ref> [14] </ref> construct new features based on interrelationships among existing ones. Varying the rule learner based on the application may also prove productive. If mathematical formulae are desired instead of conjunctive rules, a system such as ABACUS [3] could be employed in place of AQ15c.
Reference: [15] <author> J. Wnek, </author> <title> DIAV 2.0 User Manual: Specification and Guide through the Diagrammatic Visualization System, Reports of the Machine Learning and Inference Laboratory , MLI 95-4, </title> <institution> George Mason University, Fairfax, VA, </institution> <year> 1995. </year>
Reference-contexts: This way, the hierarchical hypotheses structures discovered from the nested classifications provide valuable information that cannot be obtained from either system alone. The first MONK problem, MONK1, [12] and US census data have been used for experimentation. The diagrammatic visualization system, DIAV <ref> [15] </ref> graphically interprets the knowledge representation spaces and shows the changes in the representation space caused by constructive induction. In this paper, we show that the newly created knowledge facilitates classification and, in turn, problem solving that employs classification or pattern recognition in large databases. 2.
References-found: 15

