URL: http://www.research.digital.com/SRC/personal/Ed_Lee/Papers/sosp97.ps
Refering-URL: http://www.research.digital.com/SRC/personal/Ed_Lee/Petal/petal.html
Root-URL: http://www.research.digital.com
Title: Frangipani: A Scalable Distributed File System  
Author: Chandramohan A. Thekkath Timothy Mann Edward K. Lee 
Address: 130 Lytton Ave, Palo Alto, CA 94301  
Affiliation: Systems Research Center Digital Equipment Corporation  
Abstract: The ideal distributed file system would provide all its users with coherent, shared access to the same set of files,yet would be arbitrarily scalable to provide more storage space and higher performance to a growing user community. It would be highly available in spite of component failures. It would require minimal human administration, and administration would not become more complex as more components were added. Frangipani is a new file system that approximates this ideal, yet was relatively easy to build because of its two-layer structure. The lower layer is Petal (described in an earlier paper), a distributed storage service that provides incrementally scalable, highly available, automatically managed virtual disks. In the upper layer, multiple machines run the same Frangipani file system code on top of a shared Petal virtual disk, using a distributed lock service to ensure coherence. Frangipani is meant to run in a cluster of machines that are under a common administration and can communicate securely. Thus the machines trust one another and the shared virtual disk approach is practical. Of course, a Frangipani file system can be exported to untrusted machines using ordinary network file access protocols. We have implemented Frangipani on a collection of Alphas running DIGITAL Unix 4.0. Initial measurements indicate that Frangipani has excellent single-server performance and scales well as servers are added. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Thomas E. Anderson, Michael D. Dahlin, Jeanna M. Neefe, David A. Patterson, Drew S. Roselli, and Randolph Y. Wang. </author> <title> Serverless network file systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 14(1):4179, </volume> <month> February </month> <year> 1996. </year>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks. <p> Unlike the other log-based file systems cited above, but like the log-structured file systems Zebra [17] and xFS <ref> [1] </ref>, Frangipani keeps multiple logs. 5 Synchronization and Cache Coherence With multiple Frangipani servers all modifying shared on-disk data structures, careful synchronization is needed to give each server a consistent view of the data, and yet allow enough concurrency to scale performance as load is increased or servers are added. <p> We are unable to compare the performance of their system with ours at present, as performance numbers for their file system layer are not available. The xFS file system <ref> [1, 36] </ref> comes closest in spirit to Frangipani. In fact, the goals of the two systems are essentially the same. Both try to distribute the management responsibility for files over multiple machines and to provide good availability and performance. <p> Second, we have addressed file system recovery and reconfiguration. These issues have been left as open problems by the xFS work to date. We would have liked to compare Frangipani's performance with that of xFS, but considerable performance work remains to be completed on the current xFS prototype <ref> [1] </ref>.
Reference: [2] <author> Philip A. Bernstein, Vassos Hadzilacos, and Nathan Good-man. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: In both local Unix file systems and Frangipani, a user can get better consistency semantics by calling fsync at suitable checkpoints. Frangipani's logging is an application of techniques first developed for databases <ref> [2] </ref> and later used in several other log-based file systems [9, 11, 16, 18].
Reference: [3] <author> Anupam Bhide, Elmootazbellah N. Elnozahy, and Stephen P. Morgan. </author> <title> A highly available network file server. </title> <booktitle> In Proceedings of the Winter USENIX Conference, </booktitle> <pages> pages 199205, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Ideally, the protocol should also support failover from one Frangipani server to another. The protocols just mentioned do not support failover directly, but the technique of having a new machine take over the IP address of a failed machine has been used in other systems <ref> [3, 25] </ref> and could be applied here. Apart from security, there is a second reason for using this client/server configuration. Because Frangipani runs in the kernel, it is not quickly portable across different operating systems or even different versions of Unix.
Reference: [4] <author> A. D. Birrell and R. M. Needham. </author> <title> A universal file server. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-6(5):450 453, </volume> <month> September </month> <year> 1980. </year>
Reference-contexts: The earliest example we know of is the Universal File Server <ref> [4] </ref>. However, the storage facility provided by Petal is substantially different from earlier systems, leading to a different higher level structure as well. Section 10 contains detailed comparisons with previous systems. Frangipani has been designed to work with the storage abstraction provided by Petal. <p> Frangipani is simply not targeted for such workloads. 10 Related Work Like Frangipani, the Cambridge (or Universal) File Server takes a two-layered approach to building a file system <ref> [4, 28] </ref>. The split between layers is quite different from ours, however. CFS, the lower layer, provides its clients with two abstractions: files and indices. File systems built above CFS can use these abstractions to implement files and directories.
Reference: [5] <author> Andrew D. Birrell, Andy Hisgen, Charles Jerian, Timothy Mann, and Garret Swart. </author> <title> The Echo distributed file system. </title> <type> Research Report 111, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: We believe the AFS and Frangipani approaches to scaling are complementary; it would make good sense for Frangipani servers to export the file system to wide-area clients using the AFS or DCE/DFS name space and access protocol. Like Frangipani, the Echo file system <ref> [5, 18, 26, 35] </ref> is log-based, replicates data for reliability and access paths for availability, permits volumes to span multiple disks, and provides coherent caching. Echo does not share Frangipani's scalability, however.
Reference: [6] <author> Michael Burrows. </author> <title> Efficient Data Sharing. </title> <type> PhD thesis, </type> <institution> University of Cambridge, </institution> <month> September </month> <year> 1988. </year>
Reference-contexts: With smaller block sizes, throughput is even smaller. We do not have much experience with workloads that exhibit concurrent write sharing. If necessary, we believe it would be straightforward to extend Frangipani to implement byte-range locking <ref> [6] </ref> or block locking instead. This would improve the performance of workloads that read and write different parts of the same file, making it similar to the performance of writing different files in the current system.
Reference: [7] <author> C. Chao, R. English, D. Jacobson, A. Stepanov, and J. Wilkes. Mime: </author> <title> A high performance parallel storage device with strong recovery guarantees. </title> <type> Technical Report HPL-CSP-92-9, </type> <institution> Hewlett-Packard Laboratories, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Unlike a physical disk, a virtual disk provides a sparse 2 64 byte address space, with physical storage allocated only on demand. Petal optionally replicates data for high availability. Petal also provides efficient snapshots <ref> [7, 10] </ref> to support consistent backup. Frangipani inherits much of its scalability, fault tolerance, and easy administration from the underlying storage system, but careful design was required to extend these disk. properties to the file system level.
Reference: [8] <author> Jeffrey S. Chase, Henry M. Levy, Michael J. Feeley, and Edward D. Lazowska. </author> <title> Sharing and protection in a single-address-space operating system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12(4):271307, </volume> <month> November </month> <year> 1994. </year>
Reference-contexts: The general idea is reminiscent of past work on programming computers with large memory address spaces <ref> [8] </ref>. There is so much address space available that it can be parcelled out generously. A Petal virtual disk has 2 64 bytes of address space. Petal commits physical disk space to virtual addresses only when they are written.
Reference: [9] <author> Sailesh Chutani, Owen T. Anderson, Michael L. Kazar, Bruce W. Leverett, W. Anthony Mason, and Robert N. Side-botham. </author> <title> The Episode file system. </title> <booktitle> In Proceedings of the Winter USENIX Conference, </booktitle> <pages> pages 4360, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: In both local Unix file systems and Frangipani, a user can get better consistency semantics by calling fsync at suitable checkpoints. Frangipani's logging is an application of techniques first developed for databases [2] and later used in several other log-based file systems <ref> [9, 11, 16, 18] </ref>. Frangipani is not a log-structured file system [32]; it does not keep all its data in the log, instead maintaining conventional on-disk data structures, with a small log as an adjunct to provide improved performance and failure atomicity.
Reference: [10] <author> Wiebren de Jonge, M. Frans Kaashoek, and Wilson C. Hsieh. </author> <title> The logical disk: A new approach to improving file systems. </title> <booktitle> In Proc. 14th Symp. on Operating Systems Principles, </booktitle> <pages> pages 1528, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Unlike a physical disk, a virtual disk provides a sparse 2 64 byte address space, with physical storage allocated only on demand. Petal optionally replicates data for high availability. Petal also provides efficient snapshots <ref> [7, 10] </ref> to support consistent backup. Frangipani inherits much of its scalability, fault tolerance, and easy administration from the underlying storage system, but careful design was required to extend these disk. properties to the file system level.
Reference: [11] <author> Murthy Devarakonda, Bill Kish, and Ajay Mohindra. </author> <title> Recovery in the Calypso file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 14(3):287310, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks. <p> In both local Unix file systems and Frangipani, a user can get better consistency semantics by calling fsync at suitable checkpoints. Frangipani's logging is an application of techniques first developed for databases [2] and later used in several other log-based file systems <ref> [9, 11, 16, 18] </ref>. Frangipani is not a log-structured file system [32]; it does not keep all its data in the log, instead maintaining conventional on-disk data structures, with a small log as an adjunct to provide improved performance and failure atomicity. <p> At the same time, Spiralog's storage system does not share Petal's scalability or fault tolerance; a Spiralog volume can span only the disks connected to one machine, and becomes unavailable when that machine crashes. Though designed as a cluster file system, Calypso <ref> [11] </ref> is similar to Echo, not to VMS Clusters or Frangipani. Like Echo, Calypso stores its files on multiported disks. One of the machines directly connected to each disk acts as a file server for data stored on that disk; if that machine fails, another takes over.
Reference: [12] <author> Murthy Devarakonda, Ajay Mohindra, Jill Simoneaux, and William H. Tetzlaff. </author> <title> Evaluation of design alternatives for a cluster file system. </title> <booktitle> In Proceedings of the Winter USENIX Conference, </booktitle> <pages> pages 3546, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Other members of the Calypso cluster access the current server as file system clients. Like both Frangipani and Echo, the clients have caches, kept coherent with a multiple-reader/single-writer locking protocol. For comparison purposes, the authors of Calypso also built a file system in the shared-disk style, called PJFS <ref> [12] </ref>. Calypso performed better than PJFS, leading them to abandon the shared-disk approach. PJFS differs from Frangipani in two main respects. First, its lower layer is a centralized disk server, not a distributed virtual disk like Petal. Second, all file server machines in PJFS share a common log.
Reference: [13] <author> Garth A. Gibson, David F. Nagle, Khalil Amiri, Fay W. Chang, Eugene M. Feinberg, Howard Gobioff, Chen Lee, Berend Ozceri, Erik Riedel, David Rochberg, and Jim Ze-lenka. </author> <title> File server scaling with network-attached secure disks. </title> <booktitle> In Proceedings of the ACM International Conference on Measurements and Modeling of Computer Systems (Sigmetrics '97), </booktitle> <pages> pages 272284, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: This does not necessarily mean that the machines must be locked in a room with a private physical network; known cryptographic techniques for secure booting, authentication, and encrypted links could be used instead <ref> [13, 37] </ref>. Also, in many applications, partial solutions may be acceptable; typical existing NFS installations are not secure against network eavesdropping or even data modification by a user who boots a modified kernel on his workstation. <p> Section 10 contains detailed comparisons with previous systems. Frangipani has been designed to work with the storage abstraction provided by Petal. We have not fully considered the design changes needed to exploit alternative storage abstractions like NASD <ref> [13] </ref>. Petal provides highly available storage that can scale in throughput and capacity as resources are added to it. However, Petal has no provision for coordination or sharing the storage among multiple clients. Furthermore, most applications cannot directly use Petal's client interface because it is disk-like and not file-like.
Reference: [14] <author> Andrew C. Goldstein. </author> <title> The design and implementation of a distributed file system. </title> <journal> Digital Technical Journal, </journal> <volume> 1(5):45 55, </volume> <month> September </month> <year> 1987. </year> <institution> Digital Equipment Corporation, </institution> <address> 50 Nagog Park, AK02-3/B3, Acton, MA 01720-9843. </address>
Reference-contexts: There is an internal layering of file service atop disk service, but the Echo implementation requires both layers to run in the same address space on the same machine, and experience with Echo showed the server CPU to be a bottleneck. The VMS Cluster file system <ref> [14] </ref> offloads file system processing to individual machines that are members of a cluster, much as Frangipani does. Each cluster member runs its own instance of the file system code on top of a shared physical disk, with synchronization provided by a distributed lock service.
Reference: [15] <author> Cary Gray and David Cheriton. Leases: </author> <title> An efficient fault-tolerant mechanism for distributed file cache consistency. </title> <booktitle> In Proc. 12th Symp. on Operating Systems Principles, </booktitle> <pages> pages 202210, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: The lock service provides multiple-reader/single-writer locks. Locks are sticky; that is, a client will generally retain a lock until some other client needs a conflicting one. (Recall that the clients of the lock service are the Frangipani servers.) The lock service deals with client failure using leases <ref> [15, 26] </ref>. When a client first contacts the lock service, it obtains a lease. All locks the client acquires are associated with the lease. Each lease has an expiration time, currently set to 30 seconds after its creation or last renewal.
Reference: [16] <author> Robert Hagmann. </author> <title> Reimplementing the Cedar file system using logging and group commit. </title> <booktitle> In Proc. 11th Symp. on Operating Systems Principles, </booktitle> <pages> pages 155162, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: In both local Unix file systems and Frangipani, a user can get better consistency semantics by calling fsync at suitable checkpoints. Frangipani's logging is an application of techniques first developed for databases [2] and later used in several other log-based file systems <ref> [9, 11, 16, 18] </ref>. Frangipani is not a log-structured file system [32]; it does not keep all its data in the log, instead maintaining conventional on-disk data structures, with a small log as an adjunct to provide improved performance and failure atomicity.
Reference: [17] <author> John H. Hartman and John K. Ousterhout. </author> <title> The Zebra striped network file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 13(3):274310, </volume> <month> August </month> <year> 1995. </year>
Reference-contexts: Unlike the other log-based file systems cited above, but like the log-structured file systems Zebra <ref> [17] </ref> and xFS [1], Frangipani keeps multiple logs. 5 Synchronization and Cache Coherence With multiple Frangipani servers all modifying shared on-disk data structures, careful synchronization is needed to give each server a consistent view of the data, and yet allow enough concurrency to scale performance as load is increased or servers
Reference: [18] <author> Andy Hisgen, Andrew Birrell, Charles Jerian, Timothy Mann, and Garret Swart. </author> <title> New-value logging in the Echo replicated file system. </title> <type> Research Report 104, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: In both local Unix file systems and Frangipani, a user can get better consistency semantics by calling fsync at suitable checkpoints. Frangipani's logging is an application of techniques first developed for databases [2] and later used in several other log-based file systems <ref> [9, 11, 16, 18] </ref>. Frangipani is not a log-structured file system [32]; it does not keep all its data in the log, instead maintaining conventional on-disk data structures, with a small log as an adjunct to provide improved performance and failure atomicity. <p> We believe the AFS and Frangipani approaches to scaling are complementary; it would make good sense for Frangipani servers to export the file system to wide-area clients using the AFS or DCE/DFS name space and access protocol. Like Frangipani, the Echo file system <ref> [5, 18, 26, 35] </ref> is log-based, replicates data for reliability and access paths for availability, permits volumes to span multiple disks, and provides coherent caching. Echo does not share Frangipani's scalability, however.
Reference: [19] <author> John H. Howard, Michael L. Kazar, Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Robert N. Side-botham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1):5181, </volume> <month> February </month> <year> 1988. </year>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks. <p> It retains each lock until the dirty blocks it covers are written back to disk. The cache coherence protocol we have just described is similar to protocols used for client file caches in Echo [26], the Andrew File System <ref> [19] </ref>, DCE/DFS [21], and Sprite [30]. The deadlock avoidance technique is similar to Echo's. <p> Frangipani provides a strongly coherent, single system view, using a protocol that maintains more state but eliminates unnecessary accesses to servers. The Andrew File System (AFS) <ref> [19] </ref> and its offshoot DCE/DFS [21] provide better cache performance and coherence than NFS. AFS is designed for a different kind of scalability than Frangipani.
Reference: [20] <author> James E. Johnson and William A. Laing. </author> <title> Overview of the Spiralog file system. </title> <journal> Digital Technical Journal, </journal> <volume> 8(2):514, </volume> <year> 1996. </year> <institution> Digital Equipment Corporation, </institution> <address> 50 Nagog Park, AK02-3/B3, Acton, MA 01720-9843. </address>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks. <p> The Spiralog file system <ref> [20] </ref> also offloads its file system processing to individual cluster members, which run above a shared storage system layer. The interface between layers in Spiralog differs both from the original VMS Cluster file system and from Petal.
Reference: [21] <author> Michael L. Kazar, Bruce W. Leverett, Owen T. Anderson, Vasilis Apostolides, Ben A. Bottos, Sailesh Chutani, Craig F. Everhart, W. Antony Mason, Shu-Tsui Tu, and Edward R. Zayas. </author> <title> DEcorum file system architectural overview. </title> <booktitle> In Proceedings of the Summer USENIX Conference,pages 151164, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks. <p> It retains each lock until the dirty blocks it covers are written back to disk. The cache coherence protocol we have just described is similar to protocols used for client file caches in Echo [26], the Andrew File System [19], DCE/DFS <ref> [21] </ref>, and Sprite [30]. The deadlock avoidance technique is similar to Echo's. <p> Frangipani provides a strongly coherent, single system view, using a protocol that maintains more state but eliminates unnecessary accesses to servers. The Andrew File System (AFS) [19] and its offshoot DCE/DFS <ref> [21] </ref> provide better cache performance and coherence than NFS. AFS is designed for a different kind of scalability than Frangipani.
Reference: [22] <author> Nancy P. Kronenberg, Henry M. Levy, and William D. Strecker. VAXclusters: </author> <title> A closely-coupled distributed system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 4(2):130146, </volume> <month> May </month> <year> 1986. </year>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks.
Reference: [23] <author> Leslie Lamport. </author> <note> The part-time parliament. Research Report 49, </note> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <month> September </month> <year> 1989. </year>
Reference-contexts: To avoid consuming too much memory because of sticky locks, clerks discard locks that have not been used for a long time (1 hour). A small amount of global state information that does not change often is consistently replicated across all lock servers using Lam-port's Paxos algorithm <ref> [23] </ref>. The lock service reuses an implementation of Paxos originally written for Petal. The global state information consists of a list of lock servers, a list of locks that each is responsible for serving, and a list of clerks that have opened but not yet closed each lock table.
Reference: [24] <author> Edward K. Lee and Chandramohan A. Thekkath. </author> <title> Petal: Distributed virtual disks. </title> <booktitle> In Proc. 7th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 8492, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Backups can optionally be kept online, allowing users quick access to accidentally deleted files. 5. The file system tolerates and recovers from machine, network, and disk failures without operator intervention. Frangipani is layered on top of Petal <ref> [24] </ref>, an easy-to-administer distributed storage system that provides virtual disks to its clients. Like a physical disk, a Petal virtual disk provides storage that can be read or written in blocks. <p> Petal can tolerate one or more disk or server failures, as long as a majority of the Petal servers remain up and in communication and at least one copy of each data block remains physically accessible. Additional details on Petal are available in a separate paper <ref> [24] </ref>. The lock service is a general-purpose service that provides multiple-reader/single-writer locks to clients on the network. Its implementation is distributed for fault tolerance and scalable performance. <p> Again, the administrator does not need to touch the other servers. Petal servers can also be added and removed transparently, as described in the Petal paper <ref> [24] </ref>. Lock servers are added and removed in a similar manner. 8 Backup Petal's snapshot feature provides us with a convenient way to make consistent full dumps of a Frangipani file system. Petal allows a client to create an exact copy of a virtual disk at any point in time. <p> Read latency is about 10 ms. (We could have connected the AdvFS file system to a Petal virtual disk to ensure both file systems were using identical storage subsystems. Previous experiments <ref> [24] </ref> have shown that AdvFS would have been about 4% slower if run on Petal. To present AdvFS in the best light, we chose not to do this.) It is not our intention to compare Petal's cost/performance with that of locally attached disks.
Reference: [25] <author> Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Liuba Shrira, and Michael Williams. </author> <title> Replication in the Harp file system. </title> <booktitle> In Proc. 13th Symp. on Operating Systems Principles, </booktitle> <pages> pages 226238, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Ideally, the protocol should also support failover from one Frangipani server to another. The protocols just mentioned do not support failover directly, but the technique of having a new machine take over the IP address of a failed machine has been used in other systems <ref> [3, 25] </ref> and could be applied here. Apart from security, there is a second reason for using this client/server configuration. Because Frangipani runs in the kernel, it is not quickly portable across different operating systems or even different versions of Unix.
Reference: [26] <author> Timothy Mann, Andrew Birrell, Andy Hisgen, Charles Je-rian, and Garret Swart. </author> <title> A coherent distributed file cache with directory write-behind. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12(2):123164, </volume> <month> May </month> <year> 1994. </year>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks. <p> It retains each lock until the dirty blocks it covers are written back to disk. The cache coherence protocol we have just described is similar to protocols used for client file caches in Echo <ref> [26] </ref>, the Andrew File System [19], DCE/DFS [21], and Sprite [30]. The deadlock avoidance technique is similar to Echo's. <p> The lock service provides multiple-reader/single-writer locks. Locks are sticky; that is, a client will generally retain a lock until some other client needs a conflicting one. (Recall that the clients of the lock service are the Frangipani servers.) The lock service deals with client failure using leases <ref> [15, 26] </ref>. When a client first contacts the lock service, it obtains a lease. All locks the client acquires are associated with the lease. Each lease has an expiration time, currently set to 30 seconds after its creation or last renewal. <p> We believe the AFS and Frangipani approaches to scaling are complementary; it would make good sense for Frangipani servers to export the file system to wide-area clients using the AFS or DCE/DFS name space and access protocol. Like Frangipani, the Echo file system <ref> [5, 18, 26, 35] </ref> is log-based, replicates data for reliability and access paths for availability, permits volumes to span multiple disks, and provides coherent caching. Echo does not share Frangipani's scalability, however.
Reference: [27] <author> Marshal Kirk McKusick, William N. Joy, Samuel J. Leffler, and Robert S. Fabry. </author> <title> A fast file system for UNIX. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(3):181197, </volume> <month> August </month> <year> 1984. </year>
Reference-contexts: We used AdvFS for our comparison rather than the more familiar BSD-derived UFS file system <ref> [27] </ref> because AdvFS is significantly faster than UFS. In particular, AdvFS can stripe files across multiple disks, thereby achieving nearly double the throughput of UFS on our test machines. Also, unlike UFS, which synchronously updates metadata, AdvFS uses a write-ahead log like Frangipani.
Reference: [28] <author> James G. Mitchell and Jeremy Dion. </author> <title> A comparison of two network-based file servers. </title> <journal> Communications of the ACM, </journal> <volume> 25(4):233245, </volume> <month> April </month> <year> 1982. </year>
Reference-contexts: Frangipani is simply not targeted for such workloads. 10 Related Work Like Frangipani, the Cambridge (or Universal) File Server takes a two-layered approach to building a file system <ref> [4, 28] </ref>. The split between layers is quite different from ours, however. CFS, the lower layer, provides its clients with two abstractions: files and indices. File systems built above CFS can use these abstractions to implement files and directories.
Reference: [29] <author> Sape J. Mullender and Andrew S. Tanenbaum. </author> <title> Immediate files. </title> <journal> SoftwarePractice and Experience, </journal> <volume> 14(4):365368, </volume> <month> April </month> <year> 1984. </year>
Reference-contexts: Our disk layout policy of using 4 KB blocks can suffer from more fragmentation than a policy that more carefully husbands disk space. Also, allocating 512 bytes per inode is somewhat wasteful of space. We could alleviate these problems by storing small files in the inode itself <ref> [29] </ref>. What we gain with our design is simplicity, which we believe is a reasonable tradeoff for the cost of extra physical disk space. The current scheme limits Frangipani to slightly less than 2 24 (16 million) large files, where a large file is any file bigger than 64 KB.
Reference: [30] <author> Michael N. Nelson, Brent B. Welch, and John K. Ousterhout. </author> <title> Caching in the Sprite network file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1):134154, </volume> <month> February </month> <year> 1988. </year>
Reference-contexts: It retains each lock until the dirty blocks it covers are written back to disk. The cache coherence protocol we have just described is similar to protocols used for client file caches in Echo [26], the Andrew File System [19], DCE/DFS [21], and Sprite <ref> [30] </ref>. The deadlock avoidance technique is similar to Echo's.
Reference: [31] <author> Brian Pawlowski, Chet Juszczak, Peter Staubach, Carl Smith, Diane Lebel, and David Hitz. </author> <title> NFS version 3 design and implementation. </title> <booktitle> In Proceedings of the Summer USENIX Conference, </booktitle> <pages> pages 137152, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks. <p> CFS, the lower layer, provides its clients with two abstractions: files and indices. File systems built above CFS can use these abstractions to implement files and directories. A major difference between CFS and Petal is that in CFS a single machine manages all the storage. NFS <ref> [31, 33] </ref> is not a file system in itself, but simply a remote file access protocol. The NFS protocol provides a weak notion of cache coherence, and its stateless design requires clients to access servers frequently to maintain even this level of coherence.
Reference: [32] <author> Mendel Rosenblum and John K. Ousterhout. </author> <title> The design and implementation of a log-structured file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(1):2652, </volume> <month> February </month> <year> 1992. </year>
Reference-contexts: Frangipani's logging is an application of techniques first developed for databases [2] and later used in several other log-based file systems [9, 11, 16, 18]. Frangipani is not a log-structured file system <ref> [32] </ref>; it does not keep all its data in the log, instead maintaining conventional on-disk data structures, with a small log as an adjunct to provide improved performance and failure atomicity.
Reference: [33] <author> Russel Sandberg, David Goldberg, Steve Kleiman, Dan Walsh, and Bob Lyon. </author> <title> Design and implemention of the Sun network filesystem. </title> <booktitle> In Proceedings of the Summer USENIX Conference, </booktitle> <pages> pages 119130, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks. <p> CFS, the lower layer, provides its clients with two abstractions: files and indices. File systems built above CFS can use these abstractions to implement files and directories. A major difference between CFS and Petal is that in CFS a single machine manages all the storage. NFS <ref> [31, 33] </ref> is not a file system in itself, but simply a remote file access protocol. The NFS protocol provides a weak notion of cache coherence, and its stateless design requires clients to access servers frequently to maintain even this level of coherence.
Reference: [34] <author> Robert A. Shillner and Edward W. Felten. </author> <title> Simplifying distributed file systems using a shared logical disk. </title> <type> Technical Report TR-524-96, </type> <institution> Dept. of Computer Science, Princeton University, </institution> <year> 1996. </year>
Reference-contexts: The machines are assumed to be under a common administration and to be able to communicate securely. There have been many earlier attempts at building distributed file systems that scale well in throughput and capacity <ref> [1, 11, 19, 20, 21, 22, 26, 31, 33, 34] </ref>. One distinguishing feature of Frangipani is that it has a very simple internal structurea set of cooperating machines use a common store and synchronize access to that store with locks. <p> We expect the present Frangipani implementation to have similar problems with such workloads, but as noted in Section 9.4 above, we could adopt byte-range locking instead. Shillner and Felten have built a distributed file system on top of a shared logical disk <ref> [34] </ref>. The layering in their system is similar to ours: In the lower layer, multiple machines cooperate to implement a single logical disk. In the upper layer, multiple independent machines run the same file system code on top of one logical disk, all providing access to the same files.
Reference: [35] <author> Garret Swart, Andrew Birrell, Andy Hisgen, Charles Jerian, and Timothy Mann. </author> <title> Availability in the Echo file system. </title> <type> Research Report 112, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: We believe the AFS and Frangipani approaches to scaling are complementary; it would make good sense for Frangipani servers to export the file system to wide-area clients using the AFS or DCE/DFS name space and access protocol. Like Frangipani, the Echo file system <ref> [5, 18, 26, 35] </ref> is log-based, replicates data for reliability and access paths for availability, permits volumes to span multiple disks, and provides coherent caching. Echo does not share Frangipani's scalability, however.
Reference: [36] <author> Randy Wang, Tom Anderson, and Mike Dahlin. </author> <title> Experience with a distributed file system implementation. </title> <type> Technical report, </type> <institution> University of California, Berkeley, Computer Science Division, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: We are unable to compare the performance of their system with ours at present, as performance numbers for their file system layer are not available. The xFS file system <ref> [1, 36] </ref> comes closest in spirit to Frangipani. In fact, the goals of the two systems are essentially the same. Both try to distribute the management responsibility for files over multiple machines and to provide good availability and performance.
Reference: [37] <author> Edward Wobber, Martin Abadi, Michael Burrows, and Butler Lampson. </author> <title> Authentication in the Taos operating system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12(1):332, </volume> <month> February </month> <year> 1994. </year>
Reference-contexts: This does not necessarily mean that the machines must be locked in a room with a private physical network; known cryptographic techniques for secure booting, authentication, and encrypted links could be used instead <ref> [13, 37] </ref>. Also, in many applications, partial solutions may be acceptable; typical existing NFS installations are not secure against network eavesdropping or even data modification by a user who boots a modified kernel on his workstation.
References-found: 37

