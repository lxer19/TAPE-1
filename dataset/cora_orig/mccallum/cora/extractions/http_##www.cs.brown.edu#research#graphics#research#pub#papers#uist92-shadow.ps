URL: http://www.cs.brown.edu/research/graphics/research/pub/papers/uist92-shadow.ps
Refering-URL: http://www.cs.brown.edu/research/graphics/research/pub/
Root-URL: http://www.cs.brown.edu
Email: fkph,bcz,dcr,dbc,sss,avdg@cs.brown.edu  
Phone: (401) 863-7693  
Title: Interactive Shadows  
Author: Kenneth P. Herndon, Robert C. Zeleznik, Daniel C. Robbins, D. Brookshire Conner, Scott S. Snibbe and Andries van Dam 
Keyword: Direct Manipulation, 3D Widgets, Interactive Systems  
Address: PO Box 1910 Providence, RI 02912  
Affiliation: Brown University  
Abstract: It is often difficult in computer graphics applications to understand spatial relationships between objects in a 3D scene or effect changes to those objects without specialized visualization and manipulation techniques. We present a set of three-dimensional tools (widgets) called shadows that not only provide valuable perceptual cues about the spatial relationships between objects, but also provide a direct manipulation interface to constrained transformation techniques. These shadow widgets provide two advances over previous techniques. First, they provide high correlation between their own geometric feedback and their effects on the objects they control. Second, unlike some other 3D widgets, they do not obscure the objects they control. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Eric A. Bier. </author> <title> Snap-dragging in three dimensions. </title> <editor> In Rich Riesenfeld and Carlo Sequin, editors, </editor> <booktitle> Proceedings of the 1990 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 193-204. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> March </month> <year> 1990. </year>
Reference-contexts: Note that in the mirror view, one can see that the landing gear is aligned with the landing gear bay. We have also used this specific version of the shadow widget to perform object-to-object snapping <ref> [1] </ref> [2], a popular technique for aligning the surfaces of two objects with each other. In our implementation of this technique, we can snap together only points on the visible surfaces of objects.
Reference: [2] <editor> Eric A. Bier and Maureen C. Stone. Snap-dragging. In David C. Evans and Russell J. Athay, editors, </editor> <booktitle> SIGGRAPH '86 Conference Proceedings, </booktitle> <pages> pages 233-240. </pages> <publisher> ACM SIGGRAPH, Addison-Wesley, </publisher> <month> July </month> <year> 1986. </year>
Reference-contexts: Note that in the mirror view, one can see that the landing gear is aligned with the landing gear bay. We have also used this specific version of the shadow widget to perform object-to-object snapping [1] <ref> [2] </ref>, a popular technique for aligning the surfaces of two objects with each other. In our implementation of this technique, we can snap together only points on the visible surfaces of objects.
Reference: [3] <author> Edwin E. Catmull, </author> <title> editor. </title> <booktitle> SIGGRAPH '92 Conference Proceedings. ACM SIGGRAPH, </booktitle> <publisher> Addison-Wesley, </publisher> <month> July </month> <year> 1992. </year>
Reference: [4] <author> Michael Chen, S. Joy Mountford, and Abigail Sellen. </author> <title> A study in interactive 3-D rotation using 2-D control devices. </title> <editor> In John Dill, editor, </editor> <booktitle> SIGGRAPH '88 Conference Proceedings, </booktitle> <pages> pages 121-129. </pages> <publisher> ACM SIGGRAPH, Addison-Wesley, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: These widgets exist within a 3D scene along with the very objects they affect, thus increasing a user's feeling of performing actions directly upon objects and decreasing the distance between goals and actions. However, none of these solutions are perfect for all interaction tasks <ref> [4] </ref> [14]. Adding geometry to a widget sometimes helps communicate the widget's degrees of freedom and intended use, thus allowing a user to more accurately choose the appropriate tool for a task and predict that tool's effects.
Reference: [5] <author> D. Brookshire Conner, Scott S. Snibbe, Kenneth P. Herndon, Daniel C. Robbins, Robert C. Zeleznik, and Andries van Dam. </author> <title> Three-dimensional widgets. </title> <booktitle> In Levoy and Catmull [13], </booktitle> <pages> pages 183-188. </pages>
Reference-contexts: Direct-manipulation techniques, or widgets, that significantly reduce the cognitive load on a user in certain interaction tasks have been implemented in many systems <ref> [5] </ref> [10] [15] [16] [22]. These widgets exist within a 3D scene along with the very objects they affect, thus increasing a user's feeling of performing actions directly upon objects and decreasing the distance between goals and actions. <p> First, users are easily able to transform objects with planar constraints using controls that are readily available and visible at all times. Other solutions to this specific interaction task include widgets known as object handles <ref> [5] </ref> [10] [15] [17] [22]. These handles are useful tools in many situations, but their geometry can sometimes obscure the object of interest. This can make it difficult for users to see the changes they have made to an object.
Reference: [6] <author> C. N. Cooper and R. N. Shepard. </author> <title> Turning something over in the mind. </title> <journal> Scientific American, </journal> <volume> 251(6) </volume> <pages> 106-114, </pages> <year> 1984. </year>
Reference-contexts: While this solution does present a great deal of information at once, it is the user who must combine the separate images into a single, coherent understanding of the model. This is an often difficult task <ref> [6] </ref>; consider combining three adjacent orthographic views and one perspective view, a standard multi-window configuration, to form a mental model of a complex object.
Reference: [7] <author> James D. Foley, Andries van Dam, Steven Feiner, and John F. Hughes. </author> <title> Computer Graphics: </title> <booktitle> Principles and Practice. </booktitle> <publisher> Addison-Wesley, </publisher> <address> 2nd edition, </address> <year> 1990. </year>
Reference-contexts: This ray is intersected with each object in the scene to determine which object was clicked on. The ray intersection test for each object is performed in object space, which requires inversion of the object's transformation matrix, and is impossible for a zero-scaled matrix (see <ref> [7] </ref>, Chapter 15, for more details on ray tracing). The trick of thinly scaling objects relieves us of the computational costs of constructing shadow volumes and intersecting them with the shadow plane, at the expense of some generality (for instance, our shadow widgets can fall only on planar surfaces).
Reference: [8] <author> Tinsley A. Galyean and John F. Hughes. </author> <title> Sculpting: An interactive volumetric modeling technique. </title> <booktitle> In Sederberg [20], </booktitle> <pages> pages 267-274. </pages>
Reference-contexts: This stage metaphor has been implemented in a number of previous systems to give users some sense of a workspace in an otherwise boundless volume <ref> [8] </ref> [15]. Displaying a number of shadow widgets simultaneously in a stage-like configuration like this has two important implications. First, users are easily able to transform objects with planar constraints using controls that are readily available and visible at all times.
Reference: [9] <author> Stanley L. Grotch. </author> <title> Three-dimensional and stereoscopic graphics for scientific data display and analysis. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 3(8) </volume> <pages> 31-43, </pages> <month> November </month> <year> 1983. </year>
Reference-contexts: The bolio system from MIT [23], and Jack, by Phillips and Badler [15], also projected modeling objects onto the walls of the scene to aid visualization. Projections of data points in 3D volumes have also been used in scientific visualization applications to help users understand their data <ref> [9] </ref>. Wanger et al. recently performed user studies to determine which of a number of depth cues, including shadows, most effectively displayed inter-object spatial relationships to a user viewing a scene via a 2D display. Shadows ranked high in these results [25] [26].
Reference: [10] <author> Stephanie Houde. </author> <title> Iterative design of an interface for easy 3D direct manipulation. </title> <booktitle> In Proceedings of ACM CHI'92 Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 135-142, </pages> <year> 1992. </year>
Reference-contexts: Direct-manipulation techniques, or widgets, that significantly reduce the cognitive load on a user in certain interaction tasks have been implemented in many systems [5] <ref> [10] </ref> [15] [16] [22]. These widgets exist within a 3D scene along with the very objects they affect, thus increasing a user's feeling of performing actions directly upon objects and decreasing the distance between goals and actions. However, none of these solutions are perfect for all interaction tasks [4] [14]. <p> First, users are easily able to transform objects with planar constraints using controls that are readily available and visible at all times. Other solutions to this specific interaction task include widgets known as object handles [5] <ref> [10] </ref> [15] [17] [22]. These handles are useful tools in many situations, but their geometry can sometimes obscure the object of interest. This can make it difficult for users to see the changes they have made to an object.
Reference: [11] <author> Edwin L. Hutchins, James D. Hollan, and Donald A. Norman. </author> <title> Direct manipulation interfaces. </title> <booktitle> In Human-Computer Interaction, </booktitle> <volume> volume 1, </volume> <pages> pages 311-338. </pages> <publisher> Laurence Erlbaum Associates, Inc., </publisher> <year> 1985. </year>
Reference-contexts: Thus, there is often a large cognitive distance between a user's intentions and an application's tools; if this distance is too great, the kinesthetic correspondence between user actions and results will be poor and the user's sense of engagement with the application is lessened <ref> [11] </ref>. Direct-manipulation techniques, or widgets, that significantly reduce the cognitive load on a user in certain interaction tasks have been implemented in many systems [5] [10] [15] [16] [22].
Reference: [12] <author> Paul Jerome Kilpatrick. </author> <title> The Use of a Kinesthetic Supplement in an Interactive Graphics System. </title> <type> PhD thesis, </type> <institution> University of North Carolina at Chapel Hill, </institution> <year> 1976. </year>
Reference-contexts: Unfortunately, most implementations of this idea are non-interactive (i.e., users cannot interact directly with the shadows themselves); the shadows are exclusively visualization aids. The GROPE-II system, developed at the University of North Carolina at Chapel Hill in the mid-1970s <ref> [12] </ref>, provided a number of depth cues, including shadows, to help users position and orient a robot's arm and hand in a real environment by interacting with a simulated representation on a vector display. User studies conducted by the author revealed that shadows were the most informative and popular cue.
Reference: [13] <editor> Marc Levoy and Edwin E. Catmull, editors. </editor> <booktitle> Proceedings of the 1992 Symposium on Interactive Three-Dimensional Graphics. ACM SIGGRAPH, </booktitle> <month> March </month> <year> 1992. </year>
Reference: [14] <author> Gregory M. Nielson and Dan R. Olson Jr. </author> <title> Direct manipulation techniques for 3D objects using 2D locator devices. </title> <editor> In Frank Crow and Stephen M. Pizer, editors, </editor> <booktitle> Proceedings of the 1986 Workshop on Interactive 3D Graphics, </booktitle> <pages> pages 175-182. </pages> <publisher> ACM SIGGRAPH and ACM SIGCHI, </publisher> <month> October </month> <year> 1986. </year>
Reference-contexts: These widgets exist within a 3D scene along with the very objects they affect, thus increasing a user's feeling of performing actions directly upon objects and decreasing the distance between goals and actions. However, none of these solutions are perfect for all interaction tasks [4] <ref> [14] </ref>. Adding geometry to a widget sometimes helps communicate the widget's degrees of freedom and intended use, thus allowing a user to more accurately choose the appropriate tool for a task and predict that tool's effects.
Reference: [15] <author> Cary B. Phillips and Norman I. Badler. Jack: </author> <title> a toolkit for manipulating articulated figures. </title> <booktitle> In Proceedings of the ACM SIGGRAPH Symposium on User Interface Software, </booktitle> <pages> pages 221-229, </pages> <year> 1988. </year>
Reference-contexts: Direct-manipulation techniques, or widgets, that significantly reduce the cognitive load on a user in certain interaction tasks have been implemented in many systems [5] [10] <ref> [15] </ref> [16] [22]. These widgets exist within a 3D scene along with the very objects they affect, thus increasing a user's feeling of performing actions directly upon objects and decreasing the distance between goals and actions. However, none of these solutions are perfect for all interaction tasks [4] [14]. <p> User studies conducted by the author revealed that shadows were the most informative and popular cue. The bolio system from MIT [23], and Jack, by Phillips and Badler <ref> [15] </ref>, also projected modeling objects onto the walls of the scene to aid visualization. Projections of data points in 3D volumes have also been used in scientific visualization applications to help users understand their data [9]. <p> This stage metaphor has been implemented in a number of previous systems to give users some sense of a workspace in an otherwise boundless volume [8] <ref> [15] </ref>. Displaying a number of shadow widgets simultaneously in a stage-like configuration like this has two important implications. First, users are easily able to transform objects with planar constraints using controls that are readily available and visible at all times. <p> First, users are easily able to transform objects with planar constraints using controls that are readily available and visible at all times. Other solutions to this specific interaction task include widgets known as object handles [5] [10] <ref> [15] </ref> [17] [22]. These handles are useful tools in many situations, but their geometry can sometimes obscure the object of interest. This can make it difficult for users to see the changes they have made to an object.
Reference: [16] <author> Cary B. Phillips, Norman I. Badler, and John Granieri. </author> <title> Automatic viewing control for 3D direct manipulation. </title> <booktitle> In Levoy and Catmull [13], </booktitle> <pages> pages 71-74. </pages>
Reference-contexts: Direct-manipulation techniques, or widgets, that significantly reduce the cognitive load on a user in certain interaction tasks have been implemented in many systems [5] [10] [15] <ref> [16] </ref> [22]. These widgets exist within a 3D scene along with the very objects they affect, thus increasing a user's feeling of performing actions directly upon objects and decreasing the distance between goals and actions. However, none of these solutions are perfect for all interaction tasks [4] [14].
Reference: [17] <author> Pixar, Inc. RenderMan Showplace. </author> <title> Macintosh application. </title>
Reference-contexts: First, users are easily able to transform objects with planar constraints using controls that are readily available and visible at all times. Other solutions to this specific interaction task include widgets known as object handles [5] [10] [15] <ref> [17] </ref> [22]. These handles are useful tools in many situations, but their geometry can sometimes obscure the object of interest. This can make it difficult for users to see the changes they have made to an object.
Reference: [18] <author> Pierre Poulin and Alain Fournier. </author> <title> Lights from highlights and shadows. </title> <booktitle> In Levoy and Catmull [13], </booktitle> <pages> pages 31-38. </pages>
Reference-contexts: In none of these systems or studies are users allowed to manipulate the shadows themselves the projections are useful visualization aids, but are non-interactive. However, in a recent system, specular highlights and shadows derived from light sources are used to position lights in a 3D scene <ref> [18] </ref>. In this system, light sources are inferred from information provided by user-specified highlights and shadows. 3 Using Shadows as Widgets Projections of objects (or shadows) have been proven to be valuable visualization tools.
Reference: [19] <author> F. Rabb, E. Blood, R. Steiner, and H. Jones. </author> <title> Magnetic position and orientation tracking system. </title> <journal> IEEE Transaction on Aerospace and Electronic Systems, </journal> <volume> 15(5) </volume> <pages> 709-718, </pages> <month> Septem-ber </month> <year> 1979. </year>
Reference-contexts: We hope to explore some of these various uses of alternate embedded views in our own applications. We are also interested in studying the applicability of these techniques in environments that use 6D input devices like a Polhemus 3Space Isotrack <ref> [19] </ref> or VPL DataGlove [28]. Immersive environments with stereoscopic displays are also an interesting avenue of research.
Reference: [20] <editor> Thomas W. Sederberg, editor. </editor> <booktitle> SIGGRAPH '91 Conference Proceedings. ACM SIGGRAPH, </booktitle> <publisher> Addison-Wesley, </publisher> <month> July </month> <year> 1991. </year>
Reference: [21] <author> Scott S. Snibbe, Kenneth P. Herndon, Daniel C. Robbins, D. Brookshire Conner, and Andries van Dam. </author> <title> Using deformations to explore 3D widget design. </title> <booktitle> In Catmull [3], </booktitle> <pages> pages 351-352. </pages> <note> Video paper. </note>
Reference-contexts: However, geometric 3D widgets can still distract a user's attention away from or even obscure the object of interest <ref> [21] </ref>.
Reference: [22] <author> Paul S. Strauss and Rikk Carey. </author> <title> An object-oriented 3D graphics toolkit. </title> <booktitle> In Catmull [3], </booktitle> <pages> pages 341-349. </pages>
Reference-contexts: Direct-manipulation techniques, or widgets, that significantly reduce the cognitive load on a user in certain interaction tasks have been implemented in many systems [5] [10] [15] [16] <ref> [22] </ref>. These widgets exist within a 3D scene along with the very objects they affect, thus increasing a user's feeling of performing actions directly upon objects and decreasing the distance between goals and actions. However, none of these solutions are perfect for all interaction tasks [4] [14]. <p> However, geometric 3D widgets can still distract a user's attention away from or even obscure the object of interest [21]. Alleviating these problems by rendering widgets in wireframe or disclosing their components selectively <ref> [22] </ref>, can make it more difficult to understand the function of a widget or its relation to a 3D object. 2.2 Visualization Techniques The 2D image produced by hardware Z-buffer renderers (the most common style of representation) is often hard to visualize, and a great deal of viewpoint or object manipulation <p> First, users are easily able to transform objects with planar constraints using controls that are readily available and visible at all times. Other solutions to this specific interaction task include widgets known as object handles [5] [10] [15] [17] <ref> [22] </ref>. These handles are useful tools in many situations, but their geometry can sometimes obscure the object of interest. This can make it difficult for users to see the changes they have made to an object.
Reference: [23] <author> David J. Sturman, David Zeltzer, and Steve Pieper. </author> <title> Hands-on interaction with virtual environments. </title> <booktitle> In Proceedings of the ACM SIGGRAPH Symposium on User Interface Software and Technology, </booktitle> <pages> pages 19-24, </pages> <year> 1989. </year>
Reference-contexts: User studies conducted by the author revealed that shadows were the most informative and popular cue. The bolio system from MIT <ref> [23] </ref>, and Jack, by Phillips and Badler [15], also projected modeling objects onto the walls of the scene to aid visualization. Projections of data points in 3D volumes have also been used in scientific visualization applications to help users understand their data [9].
Reference: [24] <author> Mark A. Tarlton and P. Nong Tarlton. </author> <title> A framework for dynamic visual applications. </title> <booktitle> In Levoy and Catmull [13], </booktitle> <pages> pages 161-164. </pages>
Reference-contexts: Also, we would like to exploit the idea that shadow widgets can be regarded as alternative views of a scene that are themselves embedded in the scene. Such embedded or alternate views have been used in other systems, like MCC's Mirage <ref> [24] </ref>, for visualizing slicing planes of scientific data, for drawing floor plans of architectural projects, for displaying hierarchy trees and logical or schematic diagrams of complex objects like electronic assemblies, and for displaying other abstractions of a model.
Reference: [25] <author> Leonard R. Wanger. </author> <title> The effect of shadow quality on the perception of spatial relationships in computer generated imagery. </title> <booktitle> In Levoy and Catmull [13], </booktitle> <pages> pages 39-42. </pages>
Reference-contexts: Wanger et al. recently performed user studies to determine which of a number of depth cues, including shadows, most effectively displayed inter-object spatial relationships to a user viewing a scene via a 2D display. Shadows ranked high in these results <ref> [25] </ref> [26]. In none of these systems or studies are users allowed to manipulate the shadows themselves the projections are useful visualization aids, but are non-interactive. However, in a recent system, specular highlights and shadows derived from light sources are used to position lights in a 3D scene [18]. <p> However, difficulties can arise with certain object-shadow relationships when, for example, the projections of two very differently shaped objects are similar from one point of view (say, a sphere and an hourglass) <ref> [25] </ref>. In these cases, projecting shadows simultaneously onto a number of orthogonal planes can help disambiguate conflicts. Wireframe shadows are similar to the orthogonal views commonly used in industrial design or architectural applications.
Reference: [26] <author> Leonard R. Wanger, James A. Ferwerda, and Donald P. Greenberg. </author> <title> Perceiving spatial relationships in computer-generated images. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 12(3) </volume> <pages> 44-58, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Wanger et al. recently performed user studies to determine which of a number of depth cues, including shadows, most effectively displayed inter-object spatial relationships to a user viewing a scene via a 2D display. Shadows ranked high in these results [25] <ref> [26] </ref>. In none of these systems or studies are users allowed to manipulate the shadows themselves the projections are useful visualization aids, but are non-interactive. However, in a recent system, specular highlights and shadows derived from light sources are used to position lights in a 3D scene [18]. <p> It will also be useful to determine to what extent geometry can be omitted before a 3D object and its shadow no longer appear to be related to one another. Some studies have already been done on this topic <ref> [26] </ref>, but more are needed. 6 Conclusion We have presented a technique called shadows for visualizing and manipulating objects in three-dimensional graphics applications.
Reference: [27] <author> Robert C. Zeleznik, D. Brookshire Conner, Matthias W. Wloka, Daniel G. Aliaga, Nate T. Huang, Phillip M. Hubbard, Brian Knep, Henry Kaufman, John F. Hughes, and Andries van Dam. </author> <title> An object-oriented framework for the integration of interactive animation techniques. </title> <booktitle> In Sederberg [20], </booktitle> <pages> pages 105-112. </pages>
Reference-contexts: This method works best for objects that are completely convex. Objects that have self-obscuring regions may not benefit fully from the use of full-rendered shadow widgets. 4 Implementation Details and Problems We have used our animation, modeling and simulation system, called UGA <ref> [27] </ref>, to implement the shadow widgets described here. This system uses the same scripting language to describe the geometry and behavior of widgets and application objects, and treats both equally as first-class objects.
Reference: [28] <author> Thomas G. Zimmerman, Jaron Lanier, Chuck Blanchard, Steve Bryson, and Young Harvill. </author> <title> A hand gesture interface device. </title> <booktitle> In Proceedings of ACM CHI+GI'87 Conference on Human Factors in Computing Systems and Graphics Interface, </booktitle> <pages> pages 189-192, </pages> <year> 1987. </year>
Reference-contexts: We hope to explore some of these various uses of alternate embedded views in our own applications. We are also interested in studying the applicability of these techniques in environments that use 6D input devices like a Polhemus 3Space Isotrack [19] or VPL DataGlove <ref> [28] </ref>. Immersive environments with stereoscopic displays are also an interesting avenue of research. In such an environment, the shadow widgets are likely to be useful more as constrained manipulation tools than visualization aids because the stereoscopic display itself may be adequate to convey spatial relationships between objects.
References-found: 28

