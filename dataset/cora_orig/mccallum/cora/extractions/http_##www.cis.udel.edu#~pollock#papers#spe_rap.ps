URL: http://www.cis.udel.edu/~pollock/papers/spe_rap.ps
Refering-URL: http://www.cis.udel.edu/~jochen/passages/pubs.htm
Root-URL: http://www.cis.udel.edu
Email: can@cs.appstate.edu pollock@cis.udel.edu  
Phone: (704)262-2359 (302) 831-1953  
Title: The Design and Implementation of RAP: A PDG-based Register Allocator 1  
Author: Cindy Norris Lori L. Pollock 
Note: 1 This work was partially supported by NSF under grant CCR-9625219.  
Address: Boone, NC 28608 Newark, DE 19716  
Affiliation: Mathematical Sciences Computer and Information Sciences Appalachian State University University of Delaware  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Agrawal and J. R. Horgan. </author> <title> Dynamic program slicing. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 246-256, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3]. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing <ref> [33, 1, 17, 22, 21, 30] </ref>, and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
Reference: [2] <author> V. H. Allan, J. Janardhan, R. M. Lee, and M. Srinivas. </author> <title> Enhanced region scheduling on a program dependence graph. </title> <booktitle> In Proceedings of the Twenty-fifth International Symposium on Microarchitecture, </booktitle> <pages> pages 72-80, </pages> <address> Portland, OR, </address> <year> 1992. </year>
Reference-contexts: The PDG provides a natural representation for scheduling across basic block boundaries; several global instruction scheduling methods have been expressed as transformations over the PDG <ref> [6, 19, 2] </ref>. Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3]. <p> The PDG provides a natural representation for scheduling across basic block boundaries; several global instruction scheduling methods have been expressed as transformations over the PDG [6, 19, 2]. Examples include region scheduling [19] and software pipelining <ref> [2] </ref>. In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3].
Reference: [3] <author> F. E. Allen, M. Burke, P. Charles, R. Cytron, and J. Ferrante. </author> <title> An overview of the PTRAN analysis system for multiprocessing. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 617-640, </pages> <year> 1988. </year> <month> 29 </month>
Reference-contexts: Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines <ref> [34, 3] </ref>. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing [33, 1, 17, 22, 21, 30], and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
Reference: [4] <author> R. A. Ballance, A. B. Maccabe, and K. J. Ottenstein. </author> <title> The program dependence web: a representation supporting control-, data-, and demand-driven interpretation of imperative languages. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing [33, 1, 17, 22, 21, 30], and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers <ref> [4] </ref>. By using a common program representation for various optimization analysis and transformation phases, there is a basis for designing cooperative approaches to optimization phases in attempt to improve the overall improvement from optimization.
Reference: [5] <author> W. Baxter and H. R. Bauer, III. </author> <title> The program dependence graph and vectorization. </title> <booktitle> In Proceedings of the Sixteenth Annual ACM SIGACT/SIGPLAN Symposium on Principles of Programming Languages, </booktitle> <address> Austin, TX, </address> <year> 1989. </year>
Reference-contexts: Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines <ref> [32, 5] </ref> and multiprocessor machines [34, 3]. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing [33, 1, 17, 22, 21, 30], and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
Reference: [6] <author> David Bernstein and Michael Rodeh. </author> <title> Global instruction scheduling for superscalar machines. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, CANADA, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: The PDG provides a natural representation for scheduling across basic block boundaries; several global instruction scheduling methods have been expressed as transformations over the PDG <ref> [6, 19, 2] </ref>. Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3].
Reference: [7] <author> Preston Briggs. </author> <title> Register allocation via graph coloring. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Chaitin et al. [13] were the first to apply graph coloring to the problem of register allocation and most recent work also casts register allocation as a graph coloring problem <ref> [10, 14, 11, 8, 7, 12] </ref>. These techniques involve building an interference graph in which nodes of the graph represent live ranges of the virtual registers.
Reference: [8] <author> Preston Briggs, Keith D. Cooper, Ken Kennedy, and Linda Torczon. </author> <title> Coloring heuristics for register allocation. </title> <booktitle> In Proceedings of the ACM SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <month> July </month> <year> 1989. </year>
Reference-contexts: The register allocation of each region is performed in a bottom up pass over the PDG, using an enhanced version of Chaitin's graph coloring algorithm for each region <ref> [13, 8] </ref>. On a top down pass, RAP attempts to move loads and stores out of loops. A third pass over the PDG removes unnecessary loads and stores that were created by the hierarchical register allocation process. <p> Chaitin et al. [13] were the first to apply graph coloring to the problem of register allocation and most recent work also casts register allocation as a graph coloring problem <ref> [10, 14, 11, 8, 7, 12] </ref>. These techniques involve building an interference graph in which nodes of the graph represent live ranges of the virtual registers. <p> GRA is basically an implementation of Chaitin's global register allocator with one exception: the enhancement that separates coloring into a simplify phase and a select phase suggested by Briggs et al. <ref> [8] </ref> has been incorporated. These modifications were made to GRA in order to present a fair comparison with the current version of the prototype implementation of RAP since the Briggs enhancement has been incorporated into RAP.
Reference: [9] <author> Preston Briggs, Keith D. Cooper, and Linda Torczon. </author> <title> R n Programming Environment Newsletter #44. </title> <institution> Department of Computer Science, Rice University, </institution> <month> September </month> <year> 1987. </year>
Reference-contexts: The intermediate code representation is iloc <ref> [9] </ref>. RAP performs register allocation over the PDG representation and generates code with a correct register assignment. Alternatively, RAP can simply output the unallocated iloc code that is then used as input to GRA for experimental comparison. An iloc interpreter counts the number of cycles required to execute the code.
Reference: [10] <author> Preston Briggs, Keith D. Cooper, and Linda Torczon. </author> <title> Rematerialization. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: Chaitin et al. [13] were the first to apply graph coloring to the problem of register allocation and most recent work also casts register allocation as a graph coloring problem <ref> [10, 14, 11, 8, 7, 12] </ref>. These techniques involve building an interference graph in which nodes of the graph represent live ranges of the virtual registers.
Reference: [11] <author> David Callahan and Brian Koblenz. </author> <title> Register allocation via hierarchical graph coloring. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 192-203, </pages> <address> Toronto, CANADA, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: When a variable needs to be spilled within a region, it may be possible to spill the variable only locally, without spilling it throughout the routine. Like other approaches <ref> [11, 20] </ref>, a register allocator based on the PDG can obtain space savings by performing register allocation for code segments separately, which causes smaller interference graphs to be constructed than one interference graph for the whole routine. <p> Chaitin et al. [13] were the first to apply graph coloring to the problem of register allocation and most recent work also casts register allocation as a graph coloring problem <ref> [10, 14, 11, 8, 7, 12] </ref>. These techniques involve building an interference graph in which nodes of the graph represent live ranges of the virtual registers. <p> The two major benefits to this approach are that it allows a variable to be spilled only locally, and it obtains space savings because it constructs smaller interference graphs. Callahan and Koblenz <ref> [11] </ref> presented a hierarchical approach to global register allocation in which they build 6 7 a tree of "tiles" covering the basic blocks of the control flow graph. <p> RAP currently attempts to move spill code out of loop regions, but moving spill code out of any subregion is also likely to reduce the amount of spill code executed. Unlike the hierarchical tile structure of Callahan and Koblenz <ref> [11] </ref>, a region of a PDG may contain multiple exits making spill code placement more difficult. The tile structure allows placement of spill code in the single entry and the single exit of the tile tree.
Reference: [12] <author> G. J. Chaitin. </author> <title> Register allocation and spilling via graph coloring. </title> <booktitle> In SIGPLAN Symposium on Compiler Construction, </booktitle> <address> Boston, </address> <month> June </month> <year> 1982. </year>
Reference-contexts: Chaitin et al. [13] were the first to apply graph coloring to the problem of register allocation and most recent work also casts register allocation as a graph coloring problem <ref> [10, 14, 11, 8, 7, 12] </ref>. These techniques involve building an interference graph in which nodes of the graph represent live ranges of the virtual registers.
Reference: [13] <author> Gregory Chaitin, Marc Auslander, Ashok K. Chandra, John Cocke, Martin E. Hopkins, and Peter W. Markstein. </author> <title> Register allocation via coloring. </title> <journal> Computer Languages, </journal> <volume> 6 </volume> <pages> 47-57, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: The register allocation of each region is performed in a bottom up pass over the PDG, using an enhanced version of Chaitin's graph coloring algorithm for each region <ref> [13, 8] </ref>. On a top down pass, RAP attempts to move loads and stores out of loops. A third pass over the PDG removes unnecessary loads and stores that were created by the hierarchical register allocation process. <p> The goal of register allocation is to map variables in an intermediate language to physical registers in order to minimize the number of accesses to memory during program execution. Chaitin et al. <ref> [13] </ref> were the first to apply graph coloring to the problem of register allocation and most recent work also casts register allocation as a graph coloring problem [10, 14, 11, 8, 7, 12]. <p> Building the Interference Graph. RAP builds the interference graph for a region in two steps. RAP first builds the interference graph for the interferences in the immediate region, without concern for the subregions. Like standard global register allocation techniques <ref> [13] </ref>, RAP visits statements in reverse sequential order 11 and adds an interference between the virtual register defined in the current statement and all virtual registers that are currently live. The PDG does not restrict the statements within a region to a specific sequential order. <p> Coalescing. After a complete interference graph is built for a given region, a coalescing step eliminates copy statements, for example, a = b, by renaming all occurrences of a to b or vice-versa. Standard global register allocation techniques <ref> [13] </ref> perform coalescing over an entire routine. RAP performs coalescing on a region basis. 14 The coalescing for a specific copy statement can be performed safely if the two operands of the copy do not interfere, and if at least one of the operands is not global to the region.
Reference: [14] <author> Frederick Chow and John Hennessy. </author> <title> Register allocation by priority-based coloring. </title> <booktitle> In Proceedings of the SIG-PLAN '84 Symposium on Compiler Construction, </booktitle> <month> June </month> <year> 1984. </year>
Reference-contexts: Chaitin et al. [13] were the first to apply graph coloring to the problem of register allocation and most recent work also casts register allocation as a graph coloring problem <ref> [10, 14, 11, 8, 7, 12] </ref>. These techniques involve building an interference graph in which nodes of the graph represent live ranges of the virtual registers.
Reference: [15] <author> Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <year> 1987. </year>
Reference-contexts: The PDG provides a natural representation for scheduling across basic block boundaries; several global instruction scheduling methods have been expressed as transformations over the PDG [6, 19, 2]. Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations <ref> [15, 29, 24] </ref>, detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3].
Reference: [16] <author> Claude-Nicolas Fiechter. </author> <title> PDG C Compiler. </title> <institution> University of Pittsburgh, </institution> <year> 1992. </year>
Reference-contexts: Variation Used by RAP. The front end for RAP is the pdgcc compiler developed at the University of Pittsburgh <ref> [16] </ref>. The pdgcc compiler accepts C source code as input and outputs the corresponding PDG with attached intermediate code. In contrast to the standard PDG representation, pdgcc creates a region node for each C statement in the source code. <p> These modifications were made to GRA in order to present a fair comparison with the current version of the prototype implementation of RAP since the Briggs enhancement has been incorporated into RAP. The front end for RAP is the pdgcc compiler, developed at the University of Pittsburgh <ref> [16] </ref>, which accepts C source code as input and outputs the corresponding PDG. pdgcc contains an optimizer that performs classic optimizations like dead code elimination and constant folding and propagation.
Reference: [17] <author> J. H. Griffin and K. J. Ottenstein. </author> <title> PROBE: a dependence-based program browser. </title> <type> Technical Report LA-UR-89-1823, </type> <institution> Los Alamos National Laboratory, </institution> <address> Los Alamos, NM, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3]. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing <ref> [33, 1, 17, 22, 21, 30] </ref>, and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
Reference: [18] <author> Stanford SUIF Compiler Group. </author> <title> The SUIF Parallelizing Compiler Guide. </title> <institution> Stanford University, </institution> <year> 1994. </year> <note> Version 1.0. </note>
Reference-contexts: Instead of attempting to identify the possible multiple exits of a region, RAP inserts spill code within the region and attempts to move the spill code out of the region in a later phase. Another project to be considered for the future is porting RAP to the SUIF <ref> [18] </ref> infrastructure environment in order to increase the benchmark suite to larger benchmarks.
Reference: [19] <author> Rajiv Gupta and Mary Lou Soffa. </author> <title> Region scheduling: An approach for detecting and redistributing parallelism. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(4) </volume> <pages> 421-431, </pages> <year> 1990. </year>
Reference-contexts: The PDG provides a natural representation for scheduling across basic block boundaries; several global instruction scheduling methods have been expressed as transformations over the PDG <ref> [6, 19, 2] </ref>. Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3]. <p> The PDG provides a natural representation for scheduling across basic block boundaries; several global instruction scheduling methods have been expressed as transformations over the PDG [6, 19, 2]. Examples include region scheduling <ref> [19] </ref> and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3].
Reference: [20] <author> Rajiv Gupta, Mary Lou Soffa, and Tim Steele. </author> <title> Register allocation via clique separators. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <address> Portland, Oregon, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: When a variable needs to be spilled within a region, it may be possible to spill the variable only locally, without spilling it throughout the routine. Like other approaches <ref> [11, 20] </ref>, a register allocator based on the PDG can obtain space savings by performing register allocation for code segments separately, which causes smaller interference graphs to be constructed than one interference graph for the whole routine.
Reference: [21] <author> S. Horwitz. </author> <title> Identifying the semantic and textual differences between two versions of a program. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 234-245, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3]. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing <ref> [33, 1, 17, 22, 21, 30] </ref>, and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
Reference: [22] <author> S. Horwitz, J. Prins, and T. Reps. </author> <title> Integrating non-interfering versions of programs. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM SIGACT/SIGPLAN Symposium on Principles of Programming Languages, </booktitle> <pages> pages 133-145, </pages> <address> San Diego, CA, </address> <year> 1988. </year>
Reference-contexts: In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3]. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing <ref> [33, 1, 17, 22, 21, 30] </ref>, and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
Reference: [23] <author> Akira Koseki, Hideaki Komatsu, and Yoshiaki Fukazawa. </author> <title> A register allocation technique using guarded pdg. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: In that technique, local allocation precedes probabilistic global allocation performed iteratively from inner to outer loops. Although the register allocator performed very well on the Stanford Benchmarks, this method significantly increases compile time, primarily due to the frequent recomputation of probabilities. Koseki, Komatsu, and Fukazawa <ref> [23] </ref> have developed a register allocation technique that utilizes a guarded PDG inside a compiler that works in a hierarchical manner. The goal of their work is to design a register allocator that attempts to minimize the generated anti-dependences in order to maintain available instruction level parallelism. <p> The goal of their work is to design a register allocator that attempts to minimize the generated anti-dependences in order to maintain available instruction level parallelism. Because a guarded PDG expresses only the innermost loop of a routine, the register allocation technique that is discussed in <ref> [23] </ref> strictly targets innermost loop kernels. They do not describe any provision for a hierarchical register allocation phase.
Reference: [24] <author> D. J. Kuck, R. H. Kuhn, B. Leasure, D. A. Padua, and M. Wolfe. </author> <title> Dependence graphs and compiler optimizations. </title> <booktitle> In Proceedings of the Eighth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-218, </pages> <year> 1981. </year>
Reference-contexts: The PDG provides a natural representation for scheduling across basic block boundaries; several global instruction scheduling methods have been expressed as transformations over the PDG [6, 19, 2]. Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations <ref> [15, 29, 24] </ref>, detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3].
Reference: [25] <author> Cindy Norris. </author> <title> Cooperative Register Allocation and Instruction Scheduling. </title> <type> PhD thesis, </type> <institution> University of Delaware, </institution> <month> May </month> <year> 1995. </year> <month> 30 </month>
Reference-contexts: This paper describes the design and implementation of RAP, a Register Allocator that allocates registers over the PDG representation of a routine in a hierarchical manner <ref> [27, 25] </ref>. The register allocation of each region is performed in a bottom up pass over the PDG, using an enhanced version of Chaitin's graph coloring algorithm for each region [13, 8]. On a top down pass, RAP attempts to move loads and stores out of loops.
Reference: [26] <author> Cindy Norris and Lori L. Pollock. </author> <title> A scheduler-sensitive global register allocator. </title> <booktitle> In Supercomputing '93 Pro--ceedings, </booktitle> <address> Portland, OR, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: By using a common program representation for various optimization analysis and transformation phases, there is a basis for designing cooperative approaches to optimization phases in attempt to improve the overall improvement from optimization. In particular, we have been focusing on the cooperation between instruction scheduling and register allocation <ref> [28, 26] </ref>. We have discovered that cooperation between these 1 phases can produce better final code, and moreover, cooperation is much easier to achieve with a common intermediate program representation shared by the cooperating phases.
Reference: [27] <author> Cindy Norris and Lori L. Pollock. </author> <title> Register allocation over the program dependence graph. </title> <booktitle> In Proceedings of the SIGPLAN '94 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: This paper describes the design and implementation of RAP, a Register Allocator that allocates registers over the PDG representation of a routine in a hierarchical manner <ref> [27, 25] </ref>. The register allocation of each region is performed in a bottom up pass over the PDG, using an enhanced version of Chaitin's graph coloring algorithm for each region [13, 8]. On a top down pass, RAP attempts to move loads and stores out of loops.
Reference: [28] <author> Cindy Norris and Lori L. Pollock. </author> <title> Register allocation sensitive region scheduling. </title> <booktitle> In PACT `95: International Conference on Parallel Architectures and Compilation Techniques, </booktitle> <address> Limassol, Cyprus, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: By using a common program representation for various optimization analysis and transformation phases, there is a basis for designing cooperative approaches to optimization phases in attempt to improve the overall improvement from optimization. In particular, we have been focusing on the cooperation between instruction scheduling and register allocation <ref> [28, 26] </ref>. We have discovered that cooperation between these 1 phases can produce better final code, and moreover, cooperation is much easier to achieve with a common intermediate program representation shared by the cooperating phases. <p> In addition to examining some potential improvements to RAP based on these experimental findings, we are investigating the use of RAP in conjunction with our register allocation sensitive region scheduler (RASER) <ref> [28] </ref> since both operate on the PDG. In a similar vein, we are examining the potential for incorporating the spirit of cooperation into RAP, that is, having RAP make allocation decisions that are sensitive to the goals of the instruction scheduler.
Reference: [29] <author> K. J. Ottenstein. </author> <title> An intermediate program form based on a cyclic data-dependence graph. </title> <type> Technical Report 81-1, </type> <institution> Department of Computer Science, Michigan Tech. University, </institution> <year> 1981. </year>
Reference-contexts: The PDG provides a natural representation for scheduling across basic block boundaries; several global instruction scheduling methods have been expressed as transformations over the PDG [6, 19, 2]. Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations <ref> [15, 29, 24] </ref>, detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3].
Reference: [30] <author> K. J. Ottenstein and L. M. Ottenstein. </author> <title> The program dependence graph in a software development environment. </title> <booktitle> In Proceedings of ACM SIGPLAN/SIGSOFT Symposium on Practical Software Development Environments, </booktitle> <pages> pages 177-184, </pages> <address> Pittsburgh, PA, </address> <month> April </month> <year> 1984. </year>
Reference-contexts: In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3]. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing <ref> [33, 1, 17, 22, 21, 30] </ref>, and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
Reference: [31] <author> Todd A. Proebsting and Charles N. Fischer. </author> <title> Probabilistic register allocation. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 300-310, </pages> <address> San Francisco, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Other efforts directed specifically toward improving the overall allocation by considering both local register needs and global register usage in making register allocation and assignment decisions includes a probabilistic 8 approach designed by Proebsting and Fischer <ref> [31] </ref>. In that technique, local allocation precedes probabilistic global allocation performed iteratively from inner to outer loops. Although the register allocator performed very well on the Stanford Benchmarks, this method significantly increases compile time, primarily due to the frequent recomputation of probabilities.
Reference: [32] <author> J. Warren. </author> <title> A hierarchical basis for reordering transformations. </title> <booktitle> In Proceedings of the Eleventh Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 272-282, </pages> <year> 1984. </year>
Reference-contexts: Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines <ref> [32, 5] </ref> and multiprocessor machines [34, 3]. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing [33, 1, 17, 22, 21, 30], and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
Reference: [33] <author> M. Weiser. </author> <title> Program slicing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-10(4):352-357, </volume> <year> 1984. </year>
Reference-contexts: In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines [34, 3]. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing <ref> [33, 1, 17, 22, 21, 30] </ref>, and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
Reference: [34] <author> M. J. Wolfe. </author> <booktitle> Research Monographs in Parallel and Distributed Computing. </booktitle> <publisher> The MIT Press, </publisher> <year> 1989. </year> <month> 31 </month>
Reference-contexts: Examples include region scheduling [19] and software pipelining [2]. In addition, the PDG has been used for various scalar optimizations [15, 29, 24], detecting and improving parallelization for vector machines [32, 5] and multiprocessor machines <ref> [34, 3] </ref>. Variations of the PDG have also been used for debugging and integrating different versions of a program via program-slicing [33, 1, 17, 22, 21, 30], and to enable translation of imperative programs for data-flow machines and demand-driven graph reducers [4].
References-found: 34

