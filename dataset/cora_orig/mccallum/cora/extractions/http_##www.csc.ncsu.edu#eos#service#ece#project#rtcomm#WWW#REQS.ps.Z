URL: http://www.csc.ncsu.edu/eos/service/ece/project/rtcomm/WWW/REQS.ps.Z
Refering-URL: http://www.csc.ncsu.edu/eos/service/ece/project/rtcomm/WWW/qos.html
Root-URL: http://www.csc.ncsu.edu
Email: email: srampal@vnet.ibm.com  email: reeves@csc.ncsu.edu  email: candice@eos.ncsu.edu  
Title: Dynamic Resource Allocation Based on Measured QoS  
Author: Douglas S. Reeves Ioannis Viniotis 
Keyword: Sanjeev Rampal Network Architecture  
Note: This work was supported by the Air Force Office of Scientific Research Under Grant F49620-92-J-0441.  
Address: Triangle Park, NC 27709  Raleigh, NC 27695  Raleigh, NC 27695  
Affiliation: IBM Research  Department of Computer Science North Carolina State University  Department of Electrical and Computer Engineering North Carolina State University  
Abstract: Technical Report TR 96-2 Center for Advanced Computing and Communication North Carolina State University, Raleigh. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> ATM Forum, </author> <title> "ATM User-Network Interface (UNI) Specification, Version 3.0, </title> ", <publisher> Prentice Hall, </publisher> <month> September </month> <year> 1993. </year>
Reference-contexts: Additionally, efficient use of network resources is desired for providing a cost-effective service. In the context of ATM networks, typical QoS measures include average cell loss probability (CLP), cell transfer delay (CTD) and cell delay variance (CDV) <ref> [1] </ref>. Network resources of interest include bandwidth requirements at each physical link, as well as buffer space and processing capability at each switching node. A major issue for the network service provider is how to satisfy the specified QoS requirements using the network resources as efficiently as possible. <p> The conventional approach for dealing with this problem is to have each user declare in advance the characteristics of their traffic. As an example, the ATM Forum has adopted a standard set of 3 traffic descriptors: peak cell rate, sustainable cell rate and maximum burst size <ref> [1] </ref>. A policing mechanism such as the leaky bucket [1] will ensure that the user's traffic conforms to the declared values for these descriptors. <p> As an example, the ATM Forum has adopted a standard set of 3 traffic descriptors: peak cell rate, sustainable cell rate and maximum burst size <ref> [1] </ref>. A policing mechanism such as the leaky bucket [1] will ensure that the user's traffic conforms to the declared values for these descriptors. Using this information, an appropriate Call Admission Control (CAC) algorithm determines whether the QoS requirements of a new call can be met, without compromising the QoS of calls that have already been admitted. <p> Hence bandwidth re-allocation is continually required during the duration of a session. The algorithm developed in this paper determines a steady state effective bandwidth so that once the algorithm has converged, no bandwidth re-allocation is necessary. In [3], an algorithm for rate allocation for the ABR (Available Bit Rate <ref> [1] </ref>) service is proposed. However, the emphasis there is not to guarantee any QoS measures, since applications which require ABR service are typically non-real-time (like file transfers). The target applications for the algorithm studied in this paper are characterized as real-time variable bit rate (VBR) type and require QoS guarantees.
Reference: [2] <author> P.P. Bhattacharya, L. Georgiadis, P. Tsoucas and I. Viniotis, </author> <title> "Ergodicity and Optimality of an Adaptive Multiobjective Algorithm," </title> <institution> Mathematics of Operations Research, </institution> <month> August, </month> <year> 1993, </year> <month> pp.705-740. </month>
Reference-contexts: In fact both the algorithm studied here and in [10] borrow from well known ideas in control of queueing systems. These algorithms are generically similar to those studied in several earlier papers including those by Bhattacharya et al <ref> [2] </ref> and Karlsson et al [15]. All these approaches are based on basic control theoretic ideas of scaling queuing parameters based on errors in observed performance metrics. The theoretical analysis in [10] and the practical studies presented in this paper seek to apply these ideas towards ATM resource allocation.
Reference: [3] <author> A. Charny, </author> <title> "An Algorithm for Rate Allocation in a Packet-switching Network with Feedback," </title> <type> Tech. Rep. </type> <address> MIT/TR-601, </address> <publisher> MIT, </publisher> <address> Cambridge, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Hence bandwidth re-allocation is continually required during the duration of a session. The algorithm developed in this paper determines a steady state effective bandwidth so that once the algorithm has converged, no bandwidth re-allocation is necessary. In <ref> [3] </ref>, an algorithm for rate allocation for the ABR (Available Bit Rate [1]) service is proposed. However, the emphasis there is not to guarantee any QoS measures, since applications which require ABR service are typically non-real-time (like file transfers).
Reference: [4] <author> D.D. Clark, S. Shenker and L. Zhang, </author> <title> "Supporting real-time applications in an integrated services packet network: architecture and mechanism," </title> <booktitle> Proc. ACM SIGCOMM '92, </booktitle> <address> Aug.1992, pp.14-26. </address>
Reference-contexts: They showed that these algorithms were able to achieve any desired performance vector which was feasible under the class of work-conserving service policies. Clark et al <ref> [4] </ref> developed the FIFO+ queuing discipline, in which the transmission scheduling priority of a packet at a node is dynamically adjusted. This adjustment is based on the queuing delay seen at the previous node.
Reference: [5] <author> K.M. Elsayed and H.G. Perros, </author> <title> "The Superposition of Discrete-Time Markov Renewal Processes with an Application to Statistical Multiplexing of Bursty Traffic Sources," </title> <type> Technical Report TR 94-10, </type> <institution> Dept of Computer Science, North Carolina State University, </institution> <year> 1994. </year>
Reference-contexts: For instance, El-Sayed and Perros <ref> [5] </ref> showed that two sources with the same peak rate, mean rate and mean burst length could experience very different cell losses because of differences in higher order moments of the distribution of burst lengths. * Deriving an accurate CAC algorithm which can be executed on-line without excessive numer ical computation <p> A two-state Markov Modulated Bernoulli Process (MMBP) was used as the traffic source in most experiments. This model has been used extensively in simulation and analytical studies of bursty multimedia traffic <ref> [5] </ref>. The 2 state MMBP is in either of two states S0 or S1. In S0 cells are generated according to a Bernoulli Process with a mean rate of 0 cells/sec, and in S1 with a mean rate 1 cells/sec. <p> The durations of the two states are geometrically distributed with means fl 0 and fl 1 seconds. A measure of the burstiness of the source is the squared coefficient of variation of the inter-arrival times, which can be determined from the above parameters <ref> [5] </ref>. For most experiments, values for these parameters were chosen as 9 0 = 200 cells/sec, 1 = 1000 cells/sec, fl 0 = :02 seconds, fl 1 = :01 seconds. These values reflect typical behavior for voice and video, but scaled down to reduce the simulation time required.
Reference: [6] <author> A.I. Elwalid and D. Mitra, </author> <title> "Effective Bandwidth of General Markovian Traffic Sources and Admission Control of High Speed Networks," </title> <journal> IEEE/ACM Transactions on Networking, Vol.1, </journal> <volume> No.3, </volume> <month> June </month> <year> 1993, </year> <month> pp.329-343. </month>
Reference-contexts: The effectiveness and robustness of the algorithm is demonstrated by varying the measurement frequency, source burstiness, buffer size and CLP specifications. It is shown that this algorithm can yield significant bandwidth savings over popular off-line approaches, such as the "equivalent capacity" method <ref> [6] </ref>. This approach can also be used to derive the minimum requirements for other resources (such as buffer space), and for other QoS measures (such as queuing delay percentiles). This approach dynamically determines the "effective" resource requirement to satisfy a given QoS measure for an arbitrary (stationary) source. <p> This concludes the experimental validation of the proposed algorithm. The next section compares REQS with other methods of bandwidth allocation. 4 Comparison with Other Approaches 4.1 Comparison of Steady State Performance with Equivalent Capacity Formu las The equivalent capacity formula <ref> [6] </ref> is a widely-cited method for estimating the bandwidth needed to achieve specified loss and queuing delays, for certain types of traffic sources (markov-modulated fluids, in which the state durations are exponentially distributed). <p> The queuing system of Figure 1, with REQS as the method of resource allocation, was simulated to find the steady state rate. The equivalent capacity for this same traffic source was calculated using the method of <ref> [6] </ref>, for a target loss rate of 1e-3. These two service rates were then compared. Figure 18 shows how much more bandwidth was required by the equivalent bandwidth formula, than was predicted by REQS (for the same loss rate). This comparison was performed for several buffer sizes.
Reference: [7] <author> S.J. Golestaani, </author> <title> "A Framing Strategy for Congestion Management," </title> <journal> IEEE Journal on Selected Areas in Communications, Vol.9, </journal> <volume> No. 7, </volume> <month> Sept. </month> <year> 1991, </year> <month> pp.1064-1077. </month>
Reference-contexts: We investigate the rate control of a single queue, where the service rate of this queue is synonymous with the term "bandwidth". In case of flow control policies such as Weighted Round Robin [21], Weighted Fair Queuing [18], Stop & Go <ref> [7] </ref> and RCSP [26], the end-to-end bandwidth is simply this rate multiplied by the number of links traversed. <p> This can be applied in different ways in broadband networks some of which are outlined here. 26 Arriving Cells Queue `A' Leaky Bucket `B' 5.1 Control of rate enforcing servers Rate enforcing servers such as WRR [21], Stop&Go <ref> [7] </ref> and such others, require enforcing a deterministic service rate on each session in order to provide end-to-end QoS guarantees. Using this technique, the optimal rate for each bursty session can be dynamically obtained.
Reference: [8] <author> R. Guerin, H. Ahmadi and M. Naghshineh, </author> <title> "Equivalent Capacity and its Application to Bandwidth Allocation in High-Speed Networks," </title> <journal> IEEE Journal on Selected Areas in Communications, Vol.9, </journal> <volume> No.7, </volume> <month> Sep </month> <year> 1991, </year> <pages> pp. 968-981. </pages>
Reference-contexts: rate, mean rate and mean burst length could experience very different cell losses because of differences in higher order moments of the distribution of burst lengths. * Deriving an accurate CAC algorithm which can be executed on-line without excessive numer ical computation is difficult even for simple traffic model approximations <ref> [8] </ref>. * Even if the characteristics of individual traffic sources are known, characterizing aggregations of traffic streams is non-trivial and approximate. This approximation is likely to result in sub-optimal allocation. <p> This adjustment is based on the queuing delay seen at the previous node. They showed that this resulted in improved end-to-end delay performance as compared to static allocation of priorities. However, the improved resource 1 However, performance monitoring modules are already expected to be deployed in ATM switches <ref> [8] </ref>. 3 utilization was obtained at the cost of not being able to guarantee the QoS seen by each user. They claimed that strong guarantees on QoS were not necessary for a type of service referred to as predictive service. <p> For buffer sizes much smaller than the mean burst data length, it is known (e.g. <ref> [8] </ref>) that cell scale congestion during a burst is responsible for losses. The average amount of data in a burst for this source was 10 cells which is twice the buffer size in this case. Hence, the effective rate can be greater than 1000 cells/secs. <p> This comparison was performed for several buffer sizes. The bandwidth savings is always non-negligible. For small buffer sizes, the equivalent capacity formulation overallocates the bandwidth by as much as 75%. Guerin et al. <ref> [8] </ref>. have described a number of situations in which the equivalent capacity formula is either overly optimistic or overly pessimistic. <p> The problem with non-exponentially distributed states for the equivalent capacity formulas has been addressed in [9] so this may not be as serious a problem. However, another problem with the equivalent capacity formulas is that these ignore the potential for statistical multiplexing <ref> [8] </ref>. As a result, these result in overallocation of resources when applied to an aggregation of sources. REQS, on the other hand, can be used to allocate resources for a set of multiplexed sources, to yield an aggregate QoS for the multiplexed sources. <p> When a virtual connection n + 1 seeks admission, we use some conservative measure of the bandwidth requirement of this call in isolation (this could be based on peak bandwidth or equivalent capacity <ref> [8] </ref> for example). Let this bandwidth be c n+1 . The CAC rule is now simply that if C n + c n+1 C l , admit the call else reject it.
Reference: [9] <author> L. Gun, </author> <title> "An Approximation Method for Capturing Complex Traffic Behavior in High Speed Networks," </title> <journal> Performance Evaluation, </journal> <volume> Vol 19, </volume> <year> 1994, </year> <month> pp.5-23. </month>
Reference-contexts: The problem with non-exponentially distributed states for the equivalent capacity formulas has been addressed in <ref> [9] </ref> so this may not be as serious a problem. However, another problem with the equivalent capacity formulas is that these ignore the potential for statistical multiplexing [8]. As a result, these result in overallocation of resources when applied to an aggregation of sources.
Reference: [10] <author> I. Hsu and J. Walrand, </author> <title> "Dynamic Bandwidth Allocation for ATM Switches," </title> <type> Technical Manuscript, </type> <institution> University of California, Berkeley, </institution> <note> submitted for publication to the Journal of Applied Probability, </note> <month> February </month> <year> 1995. </year>
Reference-contexts: However, the effects of these problems can be reduced through engineering solutions. This technique also involves a slight additional cost in implementation since provision must be made for measuring queuing performance on-line. 1 The algorithm studied here is similar in many ways to that analyzed by Hsu <ref> [10] </ref>. In [10] the convergence of the dynamic rate to the true steady state effective rate for the algorithm studied there, is proved theoretically (for markov-modulated fluid type sources). <p> However, the effects of these problems can be reduced through engineering solutions. This technique also involves a slight additional cost in implementation since provision must be made for measuring queuing performance on-line. 1 The algorithm studied here is similar in many ways to that analyzed by Hsu <ref> [10] </ref>. In [10] the convergence of the dynamic rate to the true steady state effective rate for the algorithm studied there, is proved theoretically (for markov-modulated fluid type sources). <p> Further, as we show in later sections, there are some important differences between the algorithm studied here and that analyzed in <ref> [10] </ref> which make this algorithm arguably better suited for practical implmentability. In fact both the algorithm studied here and in [10] borrow from well known ideas in control of queueing systems. <p> Further, as we show in later sections, there are some important differences between the algorithm studied here and that analyzed in <ref> [10] </ref> which make this algorithm arguably better suited for practical implmentability. In fact both the algorithm studied here and in [10] borrow from well known ideas in control of queueing systems. These algorithms are generically similar to those studied in several earlier papers including those by Bhattacharya et al [2] and Karlsson et al [15]. <p> These algorithms are generically similar to those studied in several earlier papers including those by Bhattacharya et al [2] and Karlsson et al [15]. All these approaches are based on basic control theoretic ideas of scaling queuing parameters based on errors in observed performance metrics. The theoretical analysis in <ref> [10] </ref> and the practical studies presented in this paper seek to apply these ideas towards ATM resource allocation. Several other studies which have explored the use of adaptive resource allocation in broadband networks. <p> The reason is that the loss probability over any finite interval will never converge. An algorithm (such as REQS) which tracks the loss probability over the current update interval must necessarily lengthen the update intervals to ensure convergence. As mentioned earlier, Hsu and Walrand <ref> [10] </ref> have independently proposed an iterative algorithm with a similar formulation to ours. Some differences are that Hsu's algorithm uses a fixed update interval, and multiplies the error in the measured CLP by a factor of 1=n, where n represents the iteration. <p> This happens if the update interval is chosen too small, resulting in an excessive number of updates. As we have seen from the simulation results, convergence times vary significantly with the choice of update interval. No technique for selecting a good update interval was suggested in <ref> [10] </ref>. In contrast, the method of adjusting the update interval (during mode 2) proposed in this paper ensures convergence, independent of the source characteristics. We believe our work on the practical behavior of dynamic rate allocation complements the theoretical work of [10]. 5 Applications The queuing model used for analysis of <p> for selecting a good update interval was suggested in <ref> [10] </ref>. In contrast, the method of adjusting the update interval (during mode 2) proposed in this paper ensures convergence, independent of the source characteristics. We believe our work on the practical behavior of dynamic rate allocation complements the theoretical work of [10]. 5 Applications The queuing model used for analysis of the REQS/ algorithm was a simple queue whose service rate could be controlled. The arrival process was arbitrary but all packets (cells) were of the same length.
Reference: [11] <author> M. Izquieredo and D.S. Reeves, </author> <title> "Statistical Characterization of MPEG VBR Video at the Slice Level," </title> <booktitle> Proc of the Conf on Multimedia Computing and Networking, SPIE, </booktitle> <address> San Jose, </address> <month> Feb </month> <year> 1995. </year>
Reference-contexts: Average On and Off times are 30 msec and 60 msec, to approximately model an IBBPBBI-type MPEG-compressed video. The rates in the two states are based on figures for the average amount of data in I and P frames and in B frames, respectively, as presented in <ref> [11] </ref>. The buffer was set to 1000 cells in order to be larger than the average burst length of 840 cells. The target CLP was set to 1e-4. behavior is similar to that in Figure 4.
Reference: [12] <author> S. Jamin, P. Danzig, S. Shenker and L. Zhang, </author> <title> "A Measurement-Based Admission Control Algorithm for Integrated Services Packet Networks," </title> <booktitle> in Proc ACM SIGCOMM '95, </booktitle> <address> Boston, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: They claimed that strong guarantees on QoS were not necessary for a type of service referred to as predictive service. Jamin et al <ref> [12] </ref> extended these notions and tested multimedia applications under predictive service. In [22], Chong et al examine dynamic bandwidth allocation algorithms for MPEG video.
Reference: [13] <author> Y.H. Jeon and I. Viniotis, </author> <title> "Achievable Loss Probabilities and Buffer Allocation Policies in ATM Nodes with Correlated Arrivals," </title> <booktitle> Proc. IEEE Intl Conference on Communications, </booktitle> <address> pp.365-369, </address> <year> 1993. </year>
Reference-contexts: The theoretical analysis in [10] and the practical studies presented in this paper seek to apply these ideas towards ATM resource allocation. Several other studies which have explored the use of adaptive resource allocation in broadband networks. Jeon and Viniotis <ref> [13] </ref> studied algorithms which dynamically vary the scheduling priority of different traffic classes in a multi-class queuing system, in order to meet QoS specifications such as loss probability and average queuing delay. <p> A second alternative substituted measurements of the cumulative loss probability, rather than the current loss probability, in the basic iteration of equation 1. Other dynamic algorithms based on feedback (for example, <ref> [13] </ref>) have also used the error in the cumulative performance measure to adjust the resource allocation. This alternative was investigated experimentally. <p> Figure 19 shows one pair of sample paths of the rate and cumulative loss probability, using this alternative. While the CLP appears to converge, the service rate oscillates, and in fact the magnitude of the oscillations increases. In <ref> [13] </ref> the control parameter (the scheduling priority) was not required to converge to a steady state value, so this was not a problem. Our experimental results indicate this approach will have difficulty converging both the QoS measure and the controlled 25 resource.
Reference: [14] <author> C.R. Kalmanek, H. Kanakia and S. Keshav, </author> <title> "Rate controlled servers for very high-speed networks," </title> <booktitle> Proc IEEE GLOBECOM '90, </booktitle> <address> pp.300.3.1-300.3.9, </address> <month> December </month> <year> 1990. </year>
Reference: [15] <author> J.M. Karlsson, H.G. Perros and I. Viniotis, </author> <title> "Adaptive Polling Schemes for an ATM Bus with Bursty Arrivals," Computer Networks and ISDN Systems, </title> <address> vol.24, </address> <year> 1992, </year> <month> pp.93-103. </month>
Reference-contexts: In fact both the algorithm studied here and in [10] borrow from well known ideas in control of queueing systems. These algorithms are generically similar to those studied in several earlier papers including those by Bhattacharya et al [2] and Karlsson et al <ref> [15] </ref>. All these approaches are based on basic control theoretic ideas of scaling queuing parameters based on errors in observed performance metrics. The theoretical analysis in [10] and the practical studies presented in this paper seek to apply these ideas towards ATM resource allocation.
Reference: [16] <author> R. Nagarajan, J. Kurose and D. Towsley, </author> <title> "Finite-horizon Statistical Quality-of-Service Measures for High-Speed Networks," </title> <type> Technical Manuscript, </type> <institution> University of Massachusetts at Amherst, </institution> <note> to appear in Journal of High Speed Networks. </note>
Reference-contexts: Convergence time increases with lower loss requirement, since the algorithm must estimate the CLP with rarer events. The sharp rise in convergence time for lower loss probabilities indicates convergence may be slow for very low loss requirements, such as 1e-8 or 1e-9. As discussed elsewhere (e.g. <ref> [16] </ref>), a steady state loss probability for very low probability events makes sense only over very long time scales.
Reference: [17] <author> P.M. Morse, </author> <title> Queues, Inventories and Maintenance : The Analysis of Operation Systems with Variable Supply and Demand, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1958. </year>
Reference-contexts: For instance, closed form solutions for the time-dependent queue performance measures such as buffer occupancy are available only for simple queues such as the M=M=1 queue <ref> [17] </ref>. Transient analysis of a queue with variable service rate and bursty input traffic is consequently not expected to yield closed form results. Hence we used simulation to analyze the performance of REQS. 3.1 Simulation Model and Procedure The simulation model was shown earlier in Figure 1. <p> For example, a suggested rule of thumb for the relaxation time of the M=M=1=K queue is 1=( p p ) 2 ) <ref> [17] </ref> (where and are the average arrival and service rates), which suggests that even for an arrival process with very low burstiness, the time required for the queue transients to disappear, could rise exponentially as the utilization is increased. <p> This is strong evidence that the convergence time is reasonable, and depends on the inherent relaxation time of the loss probability of the queue. No closed form solutions are known for describing the transient measures of a queue with bursty arrivals such as MMBP sources. In <ref> [17] </ref>, closed form solutions for the distribution of number of customers in an M=M=1=K system conditioned on the initial number are presented. As a rule of thumb the author suggests a relaxation time of 1=( p p ) 2 for the distribution of the buffer occupancy of such a system.
Reference: [18] <author> A.K. Parekh and R.G. Gallager, </author> <title> "A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks," </title> <booktitle> Proc, IEEE INFOCOM '93, </booktitle> <month> Mar. </month> <year> 1993, </year> <month> pp.521-530. </month>
Reference-contexts: We investigate the rate control of a single queue, where the service rate of this queue is synonymous with the term "bandwidth". In case of flow control policies such as Weighted Round Robin [21], Weighted Fair Queuing <ref> [18] </ref>, Stop & Go [7] and RCSP [26], the end-to-end bandwidth is simply this rate multiplied by the number of links traversed.
Reference: [19] <author> C. Partridge, </author> <title> Gigabit Networking, </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: This does not, however, eliminate the need for guarantees on the end-to-end delay and losses when the video is transmitted across the network. Table 1 lists typical data rates and QoS requirements for voice and video traffic <ref> [19] </ref>. Note that the peak data rate is several times the mean rate which gives some idea of statistical variability of traffic generation rates for such sources. The conventional approach for dealing with this problem is to have each user declare in advance the characteristics of their traffic.
Reference: [20] <author> S. Rampal, </author> <title> "Routing and End-to-end Quality-of-Service in Multimedia Networks," </title> <type> PhD Thesis, </type> <institution> North Carolina State University, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: Clearly, REQS can also be used to control this QoS. This is because this QoS measure also varies monotonically with service rate, as proved in <ref> [20] </ref>. 22 For the case where multiple QoS metrics are specified, REQS can be modified to obtain the minimum bandwidth at which all specified QoS measures can be met. <p> However, the same problems as outlined in Section 5.3 exist and need further study. * In <ref> [20] </ref>, we show a monotonic relation exists between the queuing buffer size and cell losses, similar to Theorem 1. Hence, REQS can be used to adapt the queuing buffer size to achieve a desired cell loss probability. <p> In fact, it can be shown <ref> [20] </ref> that Theorem 1 does not hold for tandem queues. Extensions of this method to tandem queues would be very worthwhile. * Formal proofs of convergence of REQS should be developed.
Reference: [21] <author> S. Rampal, D.S. Reeves, and D.P. Agrawal, </author> <title> "End-to-end QoS guarantees with statistical multiplexing in ATM networks," in Performance Modeling and Evaluation of ATM Networks, D.D. </title> <editor> Kouvatsos ed., </editor> <publisher> Chapman and Hall, </publisher> <year> 1995. </year>
Reference-contexts: We investigate the rate control of a single queue, where the service rate of this queue is synonymous with the term "bandwidth". In case of flow control policies such as Weighted Round Robin <ref> [21] </ref>, Weighted Fair Queuing [18], Stop & Go [7] and RCSP [26], the end-to-end bandwidth is simply this rate multiplied by the number of links traversed. <p> This can be applied in different ways in broadband networks some of which are outlined here. 26 Arriving Cells Queue `A' Leaky Bucket `B' 5.1 Control of rate enforcing servers Rate enforcing servers such as WRR <ref> [21] </ref>, Stop&Go [7] and such others, require enforcing a deterministic service rate on each session in order to provide end-to-end QoS guarantees. Using this technique, the optimal rate for each bursty session can be dynamically obtained.
Reference: [22] <author> S. Chong, S.Q. Li, and J. Ghosh, </author> <title> "Predictive Dynamic Bandwidth Allocation for Efficient Transport of Real-Time VBR Video over ATM," </title> <journal> IEEE J. on Selected Areas in Communication, Vol.13, </journal> <volume> No.1, </volume> <month> Jan </month> <year> 1995, </year> <pages> pp. 12-23. </pages>
Reference-contexts: They claimed that strong guarantees on QoS were not necessary for a type of service referred to as predictive service. Jamin et al [12] extended these notions and tested multimedia applications under predictive service. In <ref> [22] </ref>, Chong et al examine dynamic bandwidth allocation algorithms for MPEG video. They examine two different approaches for predicting the rate required to transmit an MPEG frame based on data from the previous frames (one based on a Recursive Least Squares type prediction and the other using Hopfield Neural networks).
Reference: [23] <author> C.-Y. Wang, D. Logothetis, K. Trivedi and I. Viniotis, </author> <title> "Transient Behavior of ATM Networks under Overloads", </title> <type> Technical Manuscript, </type> <institution> Dept of Computer Science, Duke University, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: This definition of convergence time corresponds to the term `relaxation time" used in transient analysis of queuing and control systems <ref> [23] </ref>. The method of batch means was used to determine convergence time. In each batch, a number (typically 3-5) runs were simulated of the queuing system with the dynamic rate control for sufficiently long times to obtain convergence. <p> The relaxation time of the loss probability can be expected to increase with source burstiness since the loss process will also become more bursty. Such an observation was also made by Wang et al <ref> [23] </ref> in their study of transient analysis of queues with bursty traffic. As source burstiness increases, queue service rates must increase (meaning lower utilization) to achieve a given loss rate. <p> For very small burst lengths, the effect of increase in burstiness is dominant, while for larger bursts, the effect of reduced utilization is dominant. This results in the non-monotonic behavior seen. Analogous non-monotonic behavior was also seen in <ref> [23] </ref>, where the maximum transient overshoot first increased, then decreased as the burstiness of the arrival process was increased. 3.5 Variation of Convergence Time with Peak-to-Mean Ratio In this experiment, the peak-to-mean ratio of the source was varied to see how this affects convergence.
Reference: [24] <author> Q. Wang and V. Frost, </author> <title> "Efficient Estimation of Cell Blocking Probability for ATM Systems, </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> vol.1, </volume> <month> April </month> <year> 1993, </year> <month> pp.230-235. </month>
Reference-contexts: It is possible the convergence time can be reduced using techniques developed for fast simulation of rare events <ref> [24] </ref>. 3.7 Convergence Times at Video Rates An approximate 2 state MMBP model of a compressed video source was constructed and used as a traffic source for one experiment. This was done to get some idea of the performance and robustness of REQS at typical video rates. <p> One way to do this would be to estimate the rate requirement for very low loss probabilities by extrapolation using the rates determined for higher loss rates, or similar approaches based on fast simulation techniques <ref> [24] </ref>. * Theorem 1 is for a single queue only. In fact, it can be shown [20] that Theorem 1 does not hold for tandem queues. Extensions of this method to tandem queues would be very worthwhile. * Formal proofs of convergence of REQS should be developed.
Reference: [25] <author> R.W. Wolff, </author> <title> "Stochastic Modeling and the Theory of Queues," </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference: [26] <author> H. Zhang and D. Ferrari, </author> <title> "Rate-controlled Static Priority Queuing," </title> <booktitle> in Proc IEEE INFOCOM '93, </booktitle> <address> pp.227-236, </address> <month> March </month> <year> 1993. </year> <month> 33 </month>
Reference-contexts: We investigate the rate control of a single queue, where the service rate of this queue is synonymous with the term "bandwidth". In case of flow control policies such as Weighted Round Robin [21], Weighted Fair Queuing [18], Stop & Go [7] and RCSP <ref> [26] </ref>, the end-to-end bandwidth is simply this rate multiplied by the number of links traversed.
References-found: 26

