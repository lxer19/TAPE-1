URL: http://www.hds.utc.fr/~grandval/ICANN97.ps.gz
Refering-URL: http://www.hds.utc.fr/~grandval/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Adaptive Noise Injection for Input Variables Relevance Determination  
Author: Yves Grandvalet and Stephane Canu 
Address: B.P. 20.529, 60205 Compiegne Cedex, France  
Affiliation: Heudiasyc, U.M.R. C.N.R.S. 6599, Universite de Technologie de Compiegne,  
Abstract: In this paper we consider the application of training with noise in multi-layer perceptron to input variables relevance determination. Noise injection is modified in order to penalize irrelevant features. The proposed algorithm is attractive as it requires the tuning of a single parameter. This parameter controls the penalization of the inputs together with the complexity of the model. After the presentation of the method, experimental evidences are given on simulated data sets.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> L. Breiman, J.H. Friedman, R. Olshen, and C.J. Stone. </author> <title> Classification and Regression Trees. </title> <address> Wadswworth, Belmont, CA., </address> <year> 1984. </year>
Reference-contexts: Example 5: Same as example 3, except that the two classes are defined by: P d k=1 x k 0 ) class 1, and class 2 otherwise. Example 6: This is the classical waveform example <ref> [1] </ref>. There are d = 21 input variables, ` = 300 training observations and three classes. Each point x i is a random combination of two out of three basic waveform, with noise added.
Reference: 2. <author> B. Efron and R.J. Tibshirani. </author> <title> An Introduction to the Bootstrap, </title> <booktitle> volume 57 of Monographs on Statistics and Applied Probability. </booktitle> <publisher> Chapman & Hall, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Each point x i is a random combination of two out of three basic waveform, with noise added. We used Friedman's experimental setup except that the parameter 2 was estimated by :632 bootstrap instead of cross-validation (these estimates of the generalization error are described in <ref> [2] </ref>). For all examples, ten independent training samples of size ` with their independent generalization set of size 2000 were generated. The mean error rates on the generalization sets are reported in Table 1. For each example, we used a multi-layer perceptron with a single hidden layer with 10 units.
Reference: 3. <author> J.H. Friedman. </author> <title> Flexible metric nearest neighbor classification. </title> <type> Technical report, </type> <institution> Stanford University, Stanford, </institution> <address> CA., </address> <month> November </month> <year> 1994. </year>
Reference-contexts: As p eff is decreased when 6= 2 I , this bias is increased. It is thus unlikely that adapting should be paid by some significant additional variance. 3 Simulations In this section, we borrowed Friedman's simulated data examples and results from <ref> [3] </ref>. These data were created to test flexible (thus adaptive) metric nearest neighbor classification. We briefly summarize the description of the examples below (see [3] for full details). Example 1: There are d = 10 input variables, ` = 200 training observations and two classes. <p> thus unlikely that adapting should be paid by some significant additional variance. 3 Simulations In this section, we borrowed Friedman's simulated data examples and results from <ref> [3] </ref>. These data were created to test flexible (thus adaptive) metric nearest neighbor classification. We briefly summarize the description of the examples below (see [3] for full details). Example 1: There are d = 10 input variables, ` = 200 training observations and two classes.
Reference: 4. <author> Y. Grandvalet, S. Canu, and S. Boucheron. </author> <title> Noise injection: theoretical prospects. </title> <journal> Neural Computation, </journal> <volume> 9(7), </volume> <year> 1997, </year> <note> to appear. </note>
Reference-contexts: In this case the added "noise" is a means to enhance the training set, by adding examples of inputs transformed under a known in variance group [7]; 2. improve the network robustness regarding inputs inaccuracy [10]; 3. control the complexity of oversized networks <ref> [4] </ref>. Overfitting is avoided by introducing an induction bias. Intuitively, NI can be interpreted as a means to favor solutions such that little changes in x result in little changes in f (x).
Reference: 5. <author> T.J. Hastie and R.J. Tibshirani. </author> <title> Generalized Additive Models, </title> <booktitle> volume 43 of Monographs on Statistics and Applied Probability. </booktitle> <publisher> Chapman & Hall, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: The variance parameter 2 sets the complexity of the network. It is tuned by minimizing an estimate of the generalization error. The noise distribution in NI acts as the kernel function in the Nadaraya-Watson regressor [6]. In kernel smoothing, a key point is the choice of the bandwidth <ref> [5] </ref>. In simple regression (one variable) the bandwidth is defined by the parameter 2 . In multiple regression, the analogous of the bandwidth is the covariance matrix 2 I d . This choice amounts to suppose that all variables have the same degree of relevance. <p> Minimizing C NI with an MLP leads to have this function as target. The number of effective parameters p eff of the Nadaraya-Watson smoother can be analytically computed <ref> [5] </ref>: p eff = P ` ffi P ` j=1 p (x i x j ), where p is the noise distribution, acting here as a kernel. The ratio P ` is a weighted measure of the number of neighbors of x.
Reference: 6. <author> L. Holmstrom and P. Koistinen. </author> <title> Using additive noise in back-propagation training. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 3(1) </volume> <pages> 24-38, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: The variance parameter 2 sets the complexity of the network. It is tuned by minimizing an estimate of the generalization error. The noise distribution in NI acts as the kernel function in the Nadaraya-Watson regressor <ref> [6] </ref>. In kernel smoothing, a key point is the choice of the bandwidth [5]. In simple regression (one variable) the bandwidth is defined by the parameter 2 . In multiple regression, the analogous of the bandwidth is the covariance matrix 2 I d . <p> First, let us recall that for the quadratic or for the cross-entropy loss, C NI (1) is minimized by the Nadaraya-Watson kernel smoother <ref> [6] </ref>. Minimizing C NI with an MLP leads to have this function as target.
Reference: 7. <author> T.K. Leen. </author> <title> From data distribution to regularization in invariant learning. </title> <journal> Neural Computation, </journal> <volume> 7(5) </volume> <pages> 974-981, </pages> <year> 1995. </year>
Reference-contexts: This heuristic may be used for three different purposes, namely: 1. learn invariance. In this case the added "noise" is a means to enhance the training set, by adding examples of inputs transformed under a known in variance group <ref> [7] </ref>; 2. improve the network robustness regarding inputs inaccuracy [10]; 3. control the complexity of oversized networks [4]. Overfitting is avoided by introducing an induction bias. Intuitively, NI can be interpreted as a means to favor solutions such that little changes in x result in little changes in f (x).
Reference: 8. <author> K. Matsuoka. </author> <title> Noise injection into inputs in back-propagation learning. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 22(3) </volume> <pages> 436-440, </pages> <year> 1992. </year>
Reference-contexts: The effects of NI for non-linear perceptrons are then shortly described for the quadratic and cross-entropy loss. 2.1 Linear Perceptron For a linear perceptron f (x) = W x + , trained with the quadratic loss l, NI is asymptotically equivalent to minimizing the following penalized cost <ref> [8] </ref>: C NI (f ) = ` i=1 fl W x i + y i fl + tr (W W T ) ; (2) where is the covariance matrix of the noise .
Reference: 9. <author> R. M. Neal. </author> <title> Bayesian Learning for Neural Networks. </title> <booktitle> Lecture Notes in Statistics. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: If weight decay is used with the intent to determining relevant variables, we have to penalize differently each set of input fan-out weights, i.e. each column W j W . This principle is used in the Bayesian framework by the automatic relevance determination model <ref> [9] </ref>. The priors on W j are set to be N ( 0 ; ! 2 j I N=d ), where ! 2 j are adapted during training.
Reference: 10. <author> A.R. Webb. </author> <title> Functional approximation by feed-forward networks: A least-squares approach to generalization. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(3) </volume> <pages> 363-371, </pages> <year> 1994. </year>
Reference-contexts: This heuristic may be used for three different purposes, namely: 1. learn invariance. In this case the added "noise" is a means to enhance the training set, by adding examples of inputs transformed under a known in variance group [7]; 2. improve the network robustness regarding inputs inaccuracy <ref> [10] </ref>; 3. control the complexity of oversized networks [4]. Overfitting is avoided by introducing an induction bias. Intuitively, NI can be interpreted as a means to favor solutions such that little changes in x result in little changes in f (x).
References-found: 10

