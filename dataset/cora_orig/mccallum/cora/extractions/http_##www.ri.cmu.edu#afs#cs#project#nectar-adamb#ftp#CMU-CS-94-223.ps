URL: http://www.ri.cmu.edu/afs/cs/project/nectar-adamb/ftp/CMU-CS-94-223.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs/project/nectar-adamb/ftp/
Root-URL: 
Title: High-Level Fault Tolerance in Distributed Programs  
Author: Erik Seligman Adam Beguelin 
Note: This research was sponsored by the National Science Foundation and the Defense Advanced Research Projects Agency under Cooperative Agreement NCR-8919038 with the Corporation for National Research Initiatives, and by the Advanced Research Projects Agency under contract number DABT63-93-C-0054. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of NSF, CNRI, ARPA, or the U.S. Government.  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: December 1994  
Pubnum: CMU-CS-94-223  
Abstract: We have been developing high-level checkpoint and restart methods for Dome (Distributed Object Migration Environment), a C++ library of data-parallel objects that are automatically distributed using PVM. There are several levels of programming abstraction at which fault tolerance mechanisms can be designed: high-level, where the checkpoint and restart are built into our C++ objects, but the program structure is severly constrained; high-level with preprocessing, where a preprocessor inserts extra C++ statements into the code to facilitate checkpoint and restart; and low-level, where periodically an interrupt causes a memory image to be written out. Because we consider portability (both of our libraries and of the checkpoints they produce) to be an important goal, we focus on the higher-level checkpointing methods. In addition, we describe an implementation of high-level checkpointing, demonstrate it on multiple architectures, and show that it is efficient enough to provide good expected run times with low overhead, even in the case of frequent failures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adam Beguelin, Erik Seligman, and Michael Starkey. Dome: </author> <title> Distributed object migration environment. </title> <type> Technical Report CMU-CS-94-153, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Thus it is vital that some kind of fault tolerance mechanism be incorporated into any system designed for extended execution on a workstation cluster. Here we discuss the fault tolerance mechanisms we have been building for Dome (Distributed Object Migration Environment <ref> [1] </ref>), an object-oriented library we have developed in which objects, implemented in C++, automatically distribute themselves using PVM [5]. We have been experimenting with fault tolerance at various levels of programming abstraction, and this paper describes the results we have achieved in our initial implementation. <p> From the programmer's point of view, a Dome application is simply a data-parallel program. For a full discussion of Dome, see <ref> [1] </ref>. There are several levels of programming abstraction at which one could implement a fault tolerance package in Dome. At the highest level, we have provided a set of C++ methods which can be called to checkpoint the program's data structures.
Reference: [2] <author> Andrzej Duda. </author> <title> The effects of checkpointing on program execution time. </title> <journal> Information Processing Letters, </journal> <volume> 16 </volume> <pages> 221-229, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: Using this formulation, Duda <ref> [2] </ref> has calculated the expected run time (we ignore the time to detect and recover from a failure, which we are assuming to be negligible for now): t = T fl )(e (fla) 1)) where t = total expected time for a run fl = Poisson parameter, or 1/(mean time between
Reference: [3] <author> Elmootazbella Elnozahy, David Johnson, and Willy Zwaeneopoel. </author> <title> The performance of consistent checkpointing. </title> <booktitle> In Proceedings of the 11th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 39-47. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: Silva,Veer,and Silva [15] have also developed a high-level checkpointing system for distributed programs. Their primary focus was in attempting to minimize the cost of individual checkpoints. Some studies, such as <ref> [3] </ref>, however, have suggested that in general, checkpointing tends to be a cheap operation, and we want to take advantage of this fact to concentrate on other issues.
Reference: [4] <author> Geoffrey C. Fox. </author> <title> What have we learned from using real parallel machines to solve real problems? In Proceedings of the Third Conference on Hypercube Concurrent Computers and Applications, </title> <type> pages 897-955. </type> <institution> Association for Computing Machinery, </institution> <year> 1988. </year>
Reference-contexts: Of course, this is a very limited programming model; in particular, the requirement that the main loop be at the top level might seem extremely restrictive. However, it has been observed <ref> [4] </ref> that a majority of scientific programs are either fully or loosely synchronous (that is, all processes repeatedly execute a section of code and then synchronize), so we believe that a large proportion of them could be adapted to follow this model without too much work.
Reference: [5] <author> A. Geist, A. Beguelin, J. J. Dongarra, W. Jiang, R. Manchek, and V. S. Sunderam. </author> <title> PVM 3 user's guide and reference manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Here we discuss the fault tolerance mechanisms we have been building for Dome (Distributed Object Migration Environment [1]), an object-oriented library we have developed in which objects, implemented in C++, automatically distribute themselves using PVM <ref> [5] </ref>. We have been experimenting with fault tolerance at various levels of programming abstraction, and this paper describes the results we have achieved in our initial implementation. A Dome program is a C++ program that instantiates objects defined in our Dome library.
Reference: [6] <author> Erol Gelenbe. </author> <title> On the optimum checkpoint interval. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 26(2) </volume> <pages> 259-270, </pages> <month> April </month> <year> 1979. </year>
Reference-contexts: For additional mathematical treatments of program run times in the prescence of failures, see <ref> [6] </ref>, [16]. 4 The State of the System Before discussing the details of our implementation, it is also necessary to detail what we mean by the "state" of a computation. In general terms, this consists of the user memory, stack, registers, messages, and the relevant operating system variables.
Reference: [7] <author> Christine Hofmeister and James Purtilo. </author> <title> Dynamic reconfiguration in distributed systems: Adapting software modules for replacement. </title> <type> Technical Report UMIACS-TR-92-120, </type> <institution> University of Maryland, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: We are mainly concerned with using the object-oriented paradigm to maximize the user-transparency of a fully portable checkpoint and restart mechanism for distributed programs. Hofmeister and Purtilo <ref> [7] </ref> have written a preprocessor for saving the state of programs written using their Polylith system.
Reference: [8] <author> Juan Leon, Allan Fisher, and Peter Steenkiste. </author> <title> Fail-safe pvm: A portable package for distributed programming with transparent recovery. </title> <type> Technical Report CMU-CS-93-124, </type> <institution> Carnegie Mellon University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Silva and Silva [14] have designed a system to take into account the latency between failure occurrence and failure detection. Another system being designed by Leon, Fisher, and Steenkiste <ref> [8] </ref> is specifically tailored to checkpoint and restart multicomputer applications written in PVM. All of these systems depend on machine-specific code, and none of them provide checkpoints that are portable between heterogeneous systems. Silva,Veer,and Silva [15] have also developed a high-level checkpointing system for distributed programs. <p> For example, using our high-level checkpoint method for md running on a single process yields a 10KB file, while a low-level method, using the code from <ref> [8] </ref>, gives us a 3.3MB file. Finally, in terms of portability, the high level checkpointing methods have a definite advantage over the low-level ones. The system itself is portable, since the high-level methods use ordinary C++ code and do not require any system-specific details, unlike the low level methods. <p> doing local checkpoints at each process rather than synchronizing for each checkpoint. (In fact, the SPMD model makes optimisitic checkpointing very easy, since each point in the computation has a globally known iteration number even without communication.) It would also be useful to implement a "failure daemon" method as in <ref> [8] </ref> to automatically detect failures and initiate recovery, and to expand our checkpointing system to handle additional issues like file I/O. 8 In general, we have seen that high-level checkpointing can be a useful method for implementing fault tolerance in SPMD parallel programming systems such as Dome.
Reference: [9] <author> Kai Li, Jeffrey Naughton, and James Plank. </author> <title> Real-time, concurrent checkpoint for parallel programs. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 79-88. </pages> <institution> Association for Computing Machinery, </institution> <year> 1990. </year>
Reference: [10] <author> Kai Li, Jeffrey Naughton, and James Plank. </author> <title> Checkpointing multicomputer applications. </title> <booktitle> In Proceedings of the 10th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 2-11. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: Our timings show that even in the case of frequent failures, our checkpointing overhead is low enough to provide a good expected run time for this application. 2 Related Work A number of systems targeted at low-level interrupt-driven checkpointing have been developed recently. Li, Naughton, and Plank ([9], <ref> [10] </ref>, [12]) have concentrated on trying to minimize the overhead of the individual checkpoints by using system-level techniques related to memory protection, and designed special algorithms to take advantage of multicomputer architectures.
Reference: [11] <author> D.D.E. Long, J.L. Carroll, and C.J. Park. </author> <title> A study of the reliability of internet sites. </title> <booktitle> In Proceedings of the 10th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 177-186. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: In an experiment measuring the failure rates of systems on the Internet, Long, Carroll, and Park <ref> [11] </ref> found that depending on the system, the mean time between failures tended to be between 12 and 20 days. If we take 16 days as a rough estimate, a cluster of eight machines is likely to have a failure an average of every 2 days. <p> We would ideally like to run some very large simulations and observe the expected runtimes instead of calculating them, since studies such as <ref> [11] </ref> have suggested that failures may not in fact be a Poisson process. We also might be able to accomplish this by using actual observed failure times to create an accurate simulation.
Reference: [12] <author> James Plank and Kai Li. </author> <title> ickp: A consistent checkpointer for multicomputers. </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <pages> pages 62-66, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: Our timings show that even in the case of frequent failures, our checkpointing overhead is low enough to provide a good expected run time for this application. 2 Related Work A number of systems targeted at low-level interrupt-driven checkpointing have been developed recently. Li, Naughton, and Plank ([9], [10], <ref> [12] </ref>) have concentrated on trying to minimize the overhead of the individual checkpoints by using system-level techniques related to memory protection, and designed special algorithms to take advantage of multicomputer architectures.
Reference: [13] <author> Sheldon Ross. </author> <title> A First Course in Probability. </title> <publisher> Macmillan Publishing Company, </publisher> <year> 1988. </year>
Reference-contexts: occurring in any sufficiently small time interval is proportional to the size of the interval, the probability of more than one failure on a single time interval is much smaller than the chance of one failure, and the probabilities of failures in nonoverlapping intervals are independent, then, as discussed in <ref> [13] </ref>, a Poisson distribution will be an accurate model of the expected number of failures during a computation.
Reference: [14] <author> Luis Silva and Jo~ao Silva. </author> <title> Global checkpointing for distributed programs. </title> <booktitle> In Proceedings of the 11th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 155-162. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: Li, Naughton, and Plank ([9], [10], [12]) have concentrated on trying to minimize the overhead of the individual checkpoints by using system-level techniques related to memory protection, and designed special algorithms to take advantage of multicomputer architectures. Silva and Silva <ref> [14] </ref> have designed a system to take into account the latency between failure occurrence and failure detection. Another system being designed by Leon, Fisher, and Steenkiste [8] is specifically tailored to checkpoint and restart multicomputer applications written in PVM.
Reference: [15] <author> Luis Silva, Bart Veer, and Jo~ao Silva. </author> <title> Checkpointing spmd applications on transputer networks. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <pages> pages 694-701, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Another system being designed by Leon, Fisher, and Steenkiste [8] is specifically tailored to checkpoint and restart multicomputer applications written in PVM. All of these systems depend on machine-specific code, and none of them provide checkpoints that are portable between heterogeneous systems. Silva,Veer,and Silva <ref> [15] </ref> have also developed a high-level checkpointing system for distributed programs. Their primary focus was in attempting to minimize the cost of individual checkpoints.
Reference: [16] <author> John W. Young. </author> <title> A first order approximation to the optimum checkpoint interval. </title> <journal> Communications of the ACM, </journal> <volume> 17(9) </volume> <pages> 530-531, </pages> <month> September </month> <year> 1974. </year> <month> 10 </month>
Reference-contexts: For additional mathematical treatments of program run times in the prescence of failures, see [6], <ref> [16] </ref>. 4 The State of the System Before discussing the details of our implementation, it is also necessary to detail what we mean by the "state" of a computation. In general terms, this consists of the user memory, stack, registers, messages, and the relevant operating system variables.
References-found: 16

