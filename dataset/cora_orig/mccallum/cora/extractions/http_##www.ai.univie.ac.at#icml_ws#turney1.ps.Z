URL: http://www.ai.univie.ac.at/icml_ws/turney1.ps.Z
Refering-URL: http://www.ai.univie.ac.at/icml_ws/program.html
Root-URL: 
Email: peter@ai.iit.nrc.ca  
Title: The Identification of Context-Sensitive Features: A Formal Definition of Context for Concept Learning  
Author: Peter Turney 
Address: Ottawa, Ontario, Canada, K1A 0R6  
Affiliation: Institute for Information Technology National Research Council Canada  
Abstract: A large body of research in machine learning is concerned with supervised learning from examples. The examples are typically represented as vectors in a multi-dimensional feature space (also known as attribute-value descriptions). A teacher partitions a set of training examples into a finite number of classes. The task of the learning algorithm is to induce a concept from the training examples. In this paper, we formally distinguish three types of features: primary, contextual, and irrelevant features. We also formally define what it means for one feature to be context-sensitive to another feature. Context-sensitive features complicate the task of the learner and potentially impair the learners performance. Our formal definitions make it possible for a learner to automatically identify context-sensitive features. After context-sensitive features have been identified, there are several strategies that the learner can employ for managing the features; however, a discussion of these strategies is outside of the scope of this paper. The formal definitions presented here correct a aw in previously proposed definitions. We discuss the relationship between our work and a formal definition of relevance. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bergadano, F., Matwin, S., Michalski, R.S., and Zhang, J. </author> <year> (1992). </year> <title> Learning two-tiered descriptions of exible concepts: The POSEIDON system. </title> <journal> Machine Learning, </journal> <volume> 8, </volume> <pages> 5-43. </pages>
Reference: <author> John, G.H., Kohavi, R., and Peger, K. </author> <year> (1994). </year> <title> Irrelevant features and the subset selection problem, </title> <booktitle> Machine Learning: Proceedings of the Eleventh International Conference, </booktitle> <pages> pp. 121-129, </pages> <address> California: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In other words, they are orthogonal but symmetric. 2 Definition of Relevance We introduced a formal definition of context in our previous work on context-sensitive learning (Turney, 1993a, 1993b), but subsequent work by other researchers <ref> (John et al., 1994) </ref> has exposed a aw in our definition. John et al. (1994) are concerned with defining relevant versus irrelevant features, which is related to the problem of defining contextual features.
Reference: <author> Katz, A.J., Gately, M.T., and Collins, D.R. </author> <year> (1990). </year> <title> Robust classifiers without robust features, </title> <journal> Neural Computation, </journal> <volume> 2, </volume> <pages> 472-479. </pages>
Reference: <author> Michalski, R.S. </author> <year> (1987). </year> <title> How to learn imprecise concepts: A method employing a two-tiered knowledge representation for learning. </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pp. 50-58, </pages> <address> California: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Pratt, L.Y., Mostow, J, and Kamm, C.A. </author> <year> (1991). </year> <title> Direct transfer of learned information among neural networks. </title> <booktitle> Proceedings of the 9th National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> pp. 584-580, </pages> <address> Anaheim, California. </address>
Reference: <author> Turney, P.D. </author> <year> (1993a). </year> <title> Exploiting context when learning to classify. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, ECML-93, </booktitle> <pages> pp. 402-407. </pages> <address> Vienna, Austria: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: A precise definition of context is the first step in the construction of such a system. In Section 2 we present the definition of relevance given by John et al. (1994). Our definitions employ their notation and build on their work. Section 3 reviews our previous definition of context <ref> (Turney, 1993a, 1993b) </ref> and the problem pointed out by the work of John et al. (1994). We introduce new definitions of primary, contextual, and irrelevant features in Section 4. These new definitions are illustrated by a simple example in Section 5. <p> However, the distinctions are closely related. As we discuss below, the primary/contextual distinction and the weakly relevant/strongly relevant distinction are duals. In other words, they are orthogonal but symmetric. 2 Definition of Relevance We introduced a formal definition of context in our previous work on context-sensitive learning <ref> (Turney, 1993a, 1993b) </ref>, but subsequent work by other researchers (John et al., 1994) has exposed a aw in our definition. John et al. (1994) are concerned with defining relevant versus irrelevant features, which is related to the problem of defining contextual features. <p> John et al. (1994) are concerned with defining relevant versus irrelevant features, which is related to the problem of defining contextual features. We will begin by examining the definitions in John et al. (1994), then we will review our earlier definitions <ref> (Turney, 1993a, 1993b) </ref> and discuss the problem exposed by John et al. (1994). Finally, we will present new definitions that correct the problem. The following notation comes from John et al. (1994). Suppose we have an m dimensional feature space , where is the domain of the i-th fea ture. <p> Some (but not all) weakly relevant features may also be discarded. John et al. (1994) have demonstrated that their method of feature subset selection can improve the learners performance. 3 Previous Definition of Context In our previous definition of context <ref> (Turney, 1993a, 1993b) </ref>, we did not consider the possibility of weakly relevant features. In the terminology of John et al. (1994), we defined a primary feature as a feature that is weakly relevant when . We defined a contextual feature as a feature that is strongly relevant, but not primary. <p> Finally, we defined an irrelevant feature as a feature that is neither primary nor contextual. In the light of the definitions given by John et al. (1994), it is easy to see that our definitions <ref> (Turney, 1993a, 1993b) </ref> were awed. By our old definitions, a weakly relevant feature (i.e., a redundant relevant feature) would be (mistakenly) called irrelevant when . John et al. (1994) point out that many earlier definitions of irrelevance share this aw.
Reference: <author> Turney, P.D. </author> <year> (1993b). </year> <title> Robust classification with context-sensitive features. </title> <journal> In Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, IEA/ AIE-93, </journal> <pages> pp. 268-276. </pages> <address> Edinburgh, Scotland: </address> <publisher> Gordon and Breach. </publisher>
Reference: <author> Watrous, R.L. </author> <year> (1991). </year> <title> Context-modulated vowel discrimination using connectionist networks. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 5, </volume> <pages> 341-362. </pages>
Reference: <author> Widmer, G. and Kubat, M. </author> <year> (1992). </year> <title> Learning exible concepts from streams of examples: </title> <booktitle> FLORA2. In Proceedings of the 10th European Conference on Artificial Intelligence (ECAI-92), </booktitle> <address> Vienna. Chichester: </address> <publisher> Wiley and Sons. </publisher>
Reference: <author> Widmer, G. and Kubat, M. </author> <year> (1993). </year> <title> Effective learning in dynamic environments by explicit context tracking. </title> <booktitle> In Proceedings of the European Conference on Machine Learning (ECML-93), </booktitle> <pages> 227-243, </pages> <address> Vienna, Austria. Berlin: </address> <publisher> Springer Verlag. </publisher>
References-found: 10

