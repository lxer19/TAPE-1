URL: http://www.cs.virginia.edu/~xd2a/jpdc97.ps.Z
Refering-URL: http://www.cs.virginia.edu/~xd2a/
Root-URL: http://www.cs.virginia.edu
Title: Coordinating Parallel Processes on Networks of Workstations 1  
Author: Xing Du and Xiaodong Zhang 
Note: 1 This work is supported in part by the National Science Foundation under grants CCR-9102854 and CCR-9400719, by the Air Force Office of Scientific Research under grant AFOSR-95-1-0215, and by the Office of Naval Research under grant ONR-95-1-1239.  
Address: Williamsburg, VA 23187  
Affiliation: Department of Computer Science College of William and Mary  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. H. Arpaci, et al., </author> <title> "The interaction of parallel and sequential workloads on a network of workstations", </title> <booktitle> Proceedings of the 1995 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1995, </year> <pages> pp. 267-278. </pages>
Reference-contexts: The execution times of MG and LU using the self-coordinated scheme increased about 1.7% in comparison with the times of co-scheduling. The slowdown comes from context switch overhead and power preservation precision problem we discussed in the previous subsection. 6 Related work Using direct simulation, Arpaci et al. <ref> [1] </ref> evaluate effects of interactions between parallel jobs and local user jobs. They also study feasibilities of process migrations in order to avoid the interaction.
Reference: [2] <author> M. J. Atallah, et al., </author> <title> "Models and algorithms for co-scheduling compute-intensive tasks on a network of workstations", </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 16, 16, </volume> <year> 1992, </year> <pages> pp. 319-327. </pages>
Reference-contexts: Co-scheduling efforts are made by spinning at the blocking point for a specific period of time through using a revised SVR4-based local scheduler. Atallah et al. <ref> [2] </ref> redefine co-scheduling from an effective speedup perspective. In their study, they first give a concept called "duty cycle", which is defined as the ratio of cycles the workstation commits to local jobs to the number of cycles available for parallel processes.
Reference: [3] <author> D. Bailey et al., </author> <title> "The NAS parallel benchmarks", </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> Vol. 5, No. 3, </volume> <month> Fall, </month> <year> 1991, </year> <pages> pp. 63-73. </pages>
Reference-contexts: We give each type a letter such as A or B for simple reference. A network was used to connect workstations. The context switch cost was assumed as 200 s. We selected four programs from the NAS parallel benchmarks <ref> [3] </ref>: EP (Embarrassing Parallel), MG (Multigrid), IS (Integer Sort), and LU (LU Decomposition) as the example applications. All of them followed the BSP model. However, the four applications were different in the computation size at each iteration and the communication patterns.
Reference: [4] <author> M. Crovella et al., </author> <title> "Multiprogramming on multiprocessors", </title> <booktitle> Proceedings of 3rd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1991, </year> <pages> pp. 590-597. </pages>
Reference-contexts: We focus our research on the approach to keeping both local and parallel jobs together and effectively scheduling them. Co-scheduling is another available technique for parallel process scheduling. It generally results in good parallel program performance, and is widely used to schedule parallel processes involving frequent communication and synchronization <ref> [4] </ref> [8] [10]. This method is particularly effective for parallel applications partitioned into multiple processes of equal size, running on a homogeneous multiprocessor/multicomputer system. Co-scheduling will ensure that no process will wait for a non-scheduled process for synchronization/communication, and will minimize the waiting time at the synchronization points.
Reference: [5] <author> F. Douglis and J. Ousterhout, </author> <title> "Transparent process migration: design alternatives and the Sprite implementation", </title> <journal> Software Practice and Experience Vol. </journal> <volume> 21, No. 8, </volume> <year> 1991, </year> <pages> pp. 757-785. 18 </pages>
Reference-contexts: Regarding the issue of job interactions, there are two basic approaches: avoid interactions by migrating one type of job to a dedicated environment, or go along with interactions but try to effectively schedule jobs. The studies in <ref> [5] </ref> [12] indicate that more than 50% of workstations are idle at any time.
Reference: [6] <author> X. Du, Y. Dong, and X. Zhang, </author> <title> "Characterizing communication interactions of parallel and sequential jobs on networks of workstations", </title> <booktitle> Proceedings of IEEE International Conference on Communications, </booktitle> <month> June </month> <year> 1997, </year> <pages> pp. 1133-1137. </pages>
Reference-contexts: We are studying these variants. Besides computing power, there are some other factors such as memory and I/O capability which need to be modeled and be taken into considerations. We are also investigating the communication interaction between local user jobs and parallel jobs at a lower network level <ref> [6] </ref>, and applying the scheme to wider area NOW scheduling applications. Acknowledgement: We would like to thank our colleagues, Jon Weissman and Neal Wagner for reading the paper and making helpful comments.
Reference: [7] <author> A. C. Dusseau, R. Arpaci, and D. Culler, </author> <title> "Effective distributed scheduling of parallel work-loads", </title> <booktitle> Proceedings of the 1996 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1996, </year> <pages> pp. 25-36. </pages>
Reference-contexts: Co-scheduling will ensure that no process will wait for a non-scheduled process for synchronization/communication, and will minimize the waiting time at the synchronization points. However, the non-dedicated feature of workstations and the low communication bandwidth make the implementation of complete co-scheduling on NOWs expensive and not realistic <ref> [7] </ref>. Using quantified and deterministic system information such as a power weight, and the power preservation in each workstation, we address the three NOW scheduling issues by designing a scheduling scheme, called self-coordinated local scheduling. This scheme coordinates parallel jobs independently in each workstation based on the co-scheduling principle. <p> Predicative co-scheduling uses the recent history of communications among processes to predict coming communication activities of each process. When a process is scheduled on one node, an attempt is made to schedule its correspondents on other nodes for simultaneous execution. Dusseau et al. <ref> [7] </ref> address the scheduling issue from another perspective. In their study, they find that local scheduling is a feasible alternative to co-scheduling for parallel applications with 16 barrier synchronization.
Reference: [8] <author> D. G. Feitelson and L. Rudolph, </author> <title> "Gang scheduling performance benefits for fine-grain synchronization", </title> <journal> Journal of Parallel and Distributed Computing. </journal> <volume> Vol 16, No. 4, </volume> <month> Dec., </month> <year> 1992. </year> <pages> pp. 306-318. </pages>
Reference-contexts: Co-scheduling is another available technique for parallel process scheduling. It generally results in good parallel program performance, and is widely used to schedule parallel processes involving frequent communication and synchronization [4] <ref> [8] </ref> [10]. This method is particularly effective for parallel applications partitioned into multiple processes of equal size, running on a homogeneous multiprocessor/multicomputer system. Co-scheduling will ensure that no process will wait for a non-scheduled process for synchronization/communication, and will minimize the waiting time at the synchronization points.
Reference: [9] <author> B. Goodheart and J. Cox, </author> <title> The magic garden explained: the internals of Unix System V Release 4, </title> <publisher> Prentice-Hall. </publisher> <address> New York. </address> <year> 1994. </year>
Reference-contexts: t s = P ow (i) fi (1 R user (i)) P ow (s) fi (1 R user (s)) = The execution pace in (3.8) can be self-determined, and is workstation computing power dependent rather than application program dependent. 4 Power preservation on SVR4 Unix System V Release 4 (SVR4) <ref> [9] </ref> is a powerful and open operating system. We select SVR4 as the target operating system to discuss how to preserve power and implement the scheme in a commodity operating system. The scheduling policy of SVR4 is time-sharing and priority-based.
Reference: [10] <author> A. Gupta, A. Tucker, and S. Urushibara, </author> <title> "The impact of operating system scheduling policies and synchronization methods on the performance of parallel applications", </title> <booktitle> Proceedings of the 1991 ACM SIGMETRICS Conference, </booktitle> <month> May </month> <year> 1991, </year> <pages> pp. 120-132. </pages>
Reference-contexts: Co-scheduling is another available technique for parallel process scheduling. It generally results in good parallel program performance, and is widely used to schedule parallel processes involving frequent communication and synchronization [4] [8] <ref> [10] </ref>. This method is particularly effective for parallel applications partitioned into multiple processes of equal size, running on a homogeneous multiprocessor/multicomputer system. Co-scheduling will ensure that no process will wait for a non-scheduled process for synchronization/communication, and will minimize the waiting time at the synchronization points.
Reference: [11] <author> P. Krueger and D. Babbar. </author> <title> Stealth: a liberal approach to distributed scheduling for networks of workstations, </title> <type> Technical Report, </type> <institution> OSU-CISRCI/93-TR6. Ohio State University. </institution> <year> 1993. </year>
Reference-contexts: They also study feasibilities of process migrations in order to avoid the interaction. Another proposal for the interaction is discussed in <ref> [11] </ref>, which allows parallel jobs to stay in a workstation, but run at the lowest priority when local user jobs exist. This method avoids the process migration, but does not guarantee the performance of parallel jobs. Several variations of co-scheduling have been proposed to reduce the overhead of co-scheduling.
Reference: [12] <author> D. Nichols, </author> <title> "Using idle workstations in a shared computing environment", </title> <booktitle> Proceedings of the 11th ACM Symposium on Operating Systems Principles, </booktitle> <year> 1987, </year> <pages> pp. 5-12. </pages>
Reference-contexts: Regarding the issue of job interactions, there are two basic approaches: avoid interactions by migrating one type of job to a dedicated environment, or go along with interactions but try to effectively schedule jobs. The studies in [5] <ref> [12] </ref> indicate that more than 50% of workstations are idle at any time. However, in practice, it may be difficult to immediately find a set of suitable workstations to migrate the target processes to there where they can stay for awhile and need not be migrated to other workstations frequently.
Reference: [13] <author> J. Ousterhout, </author> <title> "Scheduling techniques for concurrent systems", </title> <booktitle> Proceedings of the 3rd International Conference on Distributed Computing Systems, </booktitle> <month> October </month> <year> 1982, </year> <pages> pp. 22-30. </pages>
Reference-contexts: In practice, a NOW system is heterogeneous and non-dedicated. These two unique factors make scheduling policies on multiprocessor/multicomputer systems not suitable for NOWs. Since the nature of parallel processing on NOWs does not change, the co-scheduling <ref> [13] </ref> principle is still an important basis for parallel process scheduling on NOWs. Thus, heterogeneity, job interactions and co-scheduling are three major concerns in our design. Many research groups currently are using homogeneous NOWs as experimental platforms. <p> We assumed the system calls were exponentially distributed in the lifetime of each local process. The scheduling policies in the simulator included the SVR4 local scheduling, co-scheduling using the matrix scheme in <ref> [13] </ref>, and the self-coordinated local scheduling scheme based on SVR4 which is discussed in Section 4. 12 5.2 Precision of power preservation Using the simulator, we first studied the effects of the quantum in PJ1 and maxwait in PJ0 on the precision of power preservation of a workstation.
Reference: [14] <author> P. G. Sobalvarro and W. E. Weihl, </author> <title> "Demand-based co-scheduling of parallel jobs on multipro-grammed multiprocessors", </title> <booktitle> Proceedings of the IPPS'95 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <year> 1995, </year> <pages> pp. 63-75. </pages>
Reference-contexts: This method avoids the process migration, but does not guarantee the performance of parallel jobs. Several variations of co-scheduling have been proposed to reduce the overhead of co-scheduling. For example, Sobalvarro and Weihl <ref> [14] </ref> propose a demand-based co-scheduling policy to schedule parallel processes simultaneously only if they communicate. There are two options: dynamic co-scheduling and predictive co-scheduling. When parallel processes are dynamically co-scheduled, an arriving message will cause the targeted process at that node to start running.

References-found: 14

