URL: ftp://ftp.cse.unsw.edu.au/pub/users/andrewt/publications/1996/114.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/publications/1996/SCSE_publications.html
Root-URL: 
Email: (waleed@cse.unsw.edu.au)  
Title: Machine Recognition of Auslan Signs Using PowerGloves: Towards Large-Lexicon Recognition of Sign Language  
Author: Mohammed Waleed Kadous 
Affiliation: Computer Science Engineering, University of New South Wales  
Abstract: Instrumented gloves use a variety of sensors to provide information about the user's hand. They can be used for recognition of gestures; especially well-defined gesture sets such as sign languages. However, recognising gestures is a difficult task, due to intrapersonal and interpersonal variations in performing them. One approach to solving this problem is to use machine learning. In this case, samples of 95 discrete Australian Sign Language (Auslan) signs were collected using a Power-Glove. Two machine learning techniques were applied - instance-based learning (IBL) and decision-tree learning to the data after some simple features were extracted. Accuracy of approximately 80 per cent was achieved using IBL, despite the severe limitations of the glove.
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W., Kibler, D. & Albert, M. K. </author> <year> (1990). </year> <note> Instance-based learning algorithms. Draft submission to Machine Learning. </note>
Reference: <author> Charayaphan, C. & Marble, A. </author> <year> (1992). </year> <title> Image Processing system for interpreting motion in American Sign Language. </title> <journal> Journal of Biomedical Engineering, </journal> <volume> 14, </volume> <pages> 419-425. </pages>
Reference-contexts: Previous work Murakami and Taguchi (Murakami & Taguchi, 1991) tried to recognise ten signs using instrumented gloves and a very large (403-node) recurrent neural net and achieved an accuracy of 96 per cent on a random sample. Charayaphan and Marble <ref> (Charayaphan & Marble, 1992) </ref> tried 31 ASL signs using a video camera, but sampled each sign once and simulated the variation and consistently got 27 out of the 31 correct, with the remaining four sometimes correctly classified.
Reference: <author> Cover, T. M. </author> <year> (1968). </year> <title> Estimation by the nearest neighbour rule. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-14(1), </volume> <pages> 50-55. </pages>
Reference: <author> Cover, T. M. & Hart, P. E. </author> <year> (1967). </year> <title> Nearest neighbour pattern classification. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-13(1), </volume> <pages> 21-27. </pages>
Reference: <author> Johnston, T. </author> <year> (1989). </year> <title> Auslan Dictionary: a Dictionary of the Sign Language of the Australian Deaf Community. </title> <publisher> Deafness Resources Australia Ltd. </publisher>
Reference-contexts: Auslan and other sign languages Auslan <ref> (Johnston, 1989) </ref> is the language used by the Australian Deaf community. It has strong similarities to British Sign Language (BSL) and marginal similarities to American Sign Language (ASL). The language contains approximately four thousand well-defined signs.
Reference: <author> Murakami, K. & Taguchi, H. </author> <year> (1991). </year> <title> Gesture recognition using recurrent neural networks. </title> <booktitle> In CHI '91 Conference Proceedings (pp. </booktitle> <pages> 237-242). </pages> <publisher> ACM. </publisher>
Reference-contexts: For these experiments, we used C4.5 (Quinlan, 1993) as the decision tree builder. Previous work Murakami and Taguchi <ref> (Murakami & Taguchi, 1991) </ref> tried to recognise ten signs using instrumented gloves and a very large (403-node) recurrent neural net and achieved an accuracy of 96 per cent on a random sample.
Reference: <author> Ohira, E., Sagawa, H. & Sakiyama, T. </author> <year> (1995). </year> <title> A Segmentation Method for Sign Language Recognition. </title> <journal> IEICE Transactions on Information and Systems, </journal> <volume> E78-D(1), </volume> <pages> 49-57. </pages>
Reference-contexts: Starner also tried to recognise signs without the use of gloves (Starner & Pentland, 1996), with a corresponding decrease in accuracy (91.9 per cent with strict grammar, 74.5 per cent without). Some work has also been done on the segmentation problem. Using an instrumented glove, Ohira et al. <ref> (Ohira, Sagawa & Sakiyama, 1995) </ref> built a system for segmentation, based on rests in motion and velocity envelopes. This appeared to be accurate. Experimental setup 95 signs found in Auslan were selected on the basis of frequency of occurrence, coverage of handshapes and complexity.
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: There are many variations on this focussed mainly on (a) limiting the instances kept (b) adjusting what is meant by "closest" and (c) exactly how the the classification is made (for example, we might look at the five nearest instances and use a "vote" technique). Decision tree building <ref> (Quinlan, 1993) </ref> works by building a hierarchy of decisions based on attribute values. For instance, we might want to learn when to play and when not to play golf, given weather conditions. We might think that the important attributes are the rain level (qualitatively), the wind level and the temperature. <p> We would give examples to the decision tree builder of what we would do for a given situation, and the decision tree builder might produce a tree as shown in figure 1. For these experiments, we used C4.5 <ref> (Quinlan, 1993) </ref> as the decision tree builder. Previous work Murakami and Taguchi (Murakami & Taguchi, 1991) tried to recognise ten signs using instrumented gloves and a very large (403-node) recurrent neural net and achieved an accuracy of 96 per cent on a random sample.
Reference: <author> Rheingold, H. </author> <year> (1991). </year> <title> Virtual Reality. </title> <publisher> Touchstone Books. </publisher>
Reference-contexts: In these experiments, the segmentation problem, mime aspects of sign language, finger-spelling and spatial pronouns are not handled. We focus on recognising isolated signs. Instrumented gloves Instrumented gloves (Sturman & Zeltzer, 1994; Sturman, 1992) have been used extensively recently, mostly for direct manipulation for virtual environments <ref> (Rheingold, 1991) </ref>. But they may also be used for gesture and sign language recognition. They have several advantages (and some disadvantages) when compared to video methods.
Reference: <author> Starner, T. </author> <year> (1995). </year> <title> Visual recognition of American Sign Language using Hidden Markov Models. </title> <type> Master's thesis, </type> <institution> MIT Media Lab. </institution> <address> URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-316.ps.Z. </address>
Reference: <author> Starner, T. & Pentland, A. </author> <year> (1995). </year> <title> Visual recognition of American Sign Language using Hidden Markov Models. </title> <type> Technical Report TR-306, </type> <institution> Media Lab, MIT. </institution> <address> URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-306.ps.Z. </address>
Reference: <author> Starner, T. & Pentland, A. </author> <year> (1996). </year> <title> Real-Time American Sign Language Recognition from Video Using Hidden Markov Models. </title> <type> Technical Report TR-375, </type> <institution> Media Lab, MIT. </institution> <note> URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-375.ps.Z. Student Chapter of the ACM (1994). Power Glove Serial Interface (2.0 Ed.). Student Chapter of the ACM, UIUC. </note>
Reference-contexts: Starner also tried to recognise signs without the use of gloves <ref> (Starner & Pentland, 1996) </ref>, with a corresponding decrease in accuracy (91.9 per cent with strict grammar, 74.5 per cent without). Some work has also been done on the segmentation problem.
Reference: <author> Sturman, D. J. </author> <year> (1992). </year> <title> Whole Hand Input. </title> <type> PhD thesis, </type> <institution> MIT. </institution> <address> URL: ftp://media.mit.edu/pub/sturman/WholeHandInput/*. </address>
Reference: <author> Sturman, D. J. & Zeltzer, D. </author> <year> (1994). </year> <title> A survey of glove-based input. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 14(1), </volume> <pages> 30-39. </pages>
References-found: 14

