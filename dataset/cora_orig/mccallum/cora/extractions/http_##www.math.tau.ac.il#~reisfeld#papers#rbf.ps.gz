URL: http://www.math.tau.ac.il/~reisfeld/papers/rbf.ps.gz
Refering-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Root-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Title: Image Warping by Radial Basis Functions: Application to Facial Expressions  
Author: Nur Arad, Nira Dyn, Daniel Reisfeld Yehezkel Yeshurun 
Address: Tel-Aviv 69978, Israel.  
Affiliation: School of Mathematical Sciences Tel-Aviv University  
Abstract: The human face is an elastic object. A natural paradigm for representing facial expressions is to form a complete 3D model of facial muscles and tissues. However, determining the actual parameter values for synthesizing and animating facial expressions is tedious; evaluating these parameters for facial expression analysis out of grey-level images is ahead of the state of the art in computer vision. Using only 2D face images and a small number of anchor points, we show that the method of radial basis functions provides a powerful mechanism for processing facial expressions. Although constructed speciocally for facial expressions, our method is applicable to other elastic objects as well. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Beier and S. Neely. </author> <title> Feature-based image metamorphosis. </title> <journal> Computer Graphics, </journal> <volume> 26(2):3542, </volume> <year> 1992. </year>
Reference-contexts: The aOEne transformation can compensate for various viewing conditions, but is not eoeective if the facial expression is modioed. A recent 2D approach <ref> [1] </ref>, which was impressively used in a video clip, ignores the aOEne aspects of the transformation. All these points have motivated us to look for a smooth 2D transformation, which can be used to compensate for changes in facial expressions, based on a relatively small number of anchor points. <p> Moreover, the position of the points may not coincide with the position of physical features that are to be manipulated. Another algorithm that has cumulated in an impressive Michael Jack-son video is the feature based image metamorphosis algorithm <ref> [1] </ref>, where the position of each point is the weighted average of aOEne transformations determined by corresponding line segments in the source and target images.
Reference: [2] <author> F.L. Bookstein. </author> <title> Principal warps: Thin plate splines and the decomposition of deformations. </title> <journal> IEEE Transactions Pattern Analysis and Machine Intelligence, </journal> <volume> 11:567585, </volume> <year> 1989. </year>
Reference-contexts: The computation of the coeOEcients in (5) involves the solution of two square linear systems of size N + 3 (with the same matrix in each case). An algebraic treatment of the mapping (5) is given in <ref> [2] </ref>.
Reference: [3] <author> C. De Boor. </author> <title> On calculating with B-splines. Journal of Approximation Theory, </title> <address> 6:5062, </address> <year> 1972. </year>
Reference-contexts: Another possibility is constructing a pair of R 2 ! R functions where each of these functions is constructed by a tensor product of univariate functions. Such an approach involves tessellations of the plane, and requires a relatively large number of points to be specioed <ref> [3, 6, 13] </ref>. This drawback applies to other tessellation dependent techniques, such as an adaptive meshing technique [30] which uses a facial muscle control model deoned on a mesh. Turning to the family of mappings deoned in the present work, 2D radial basis function transformations overcome the drawbacks previously mentioned.
Reference: [4] <author> H. H. Blthooe and S. Edelman. </author> <title> Psychophysical support for a 2D view interpolation theory of object recognition. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <address> 89:6064, </address> <year> 1992. </year>
Reference-contexts: An alternative approach is not to rely on a 3D model of the face, but rather to use a limited set of anchor points in 2D face images. This approach is attractive from the computational complexity point of view and is supported by psychophysical ondings <ref> [4] </ref>. We have recently demonstrated the applicability of such an approach to face recognition. We have developed a system that automatically detects the most important facial features (eyes and mouth) using generalized symmetry [26, 5].
Reference: [5] <author> Reisfeld D. and Yeshurun Y. </author> <title> Robust detection of facial features by generalized symmetry. </title> <booktitle> In Proceedings of the 11th IAPR International Conference on Pattern Recognition, pages A117120, The Hague, </booktitle> <address> The Netherlands, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: We have recently demonstrated the applicability of such an approach to face recognition. We have developed a system that automatically detects the most important facial features (eyes and mouth) using generalized symmetry <ref> [26, 5] </ref>. We have also shown that normalizing a 2D image of a face using an aOEne transformation determined by the location of the eyes and mouth is an eoeective step towards face recognition [11].
Reference: [6] <author> W. Dahmen and C. A. Micchelli. </author> <title> On linear independence of B-splines I: Triangulations of simploids. </title> <journal> SIAM Journal of Numerical Analysis, </journal> <volume> 19:993 1012, </volume> <year> 1982. </year>
Reference-contexts: Another possibility is constructing a pair of R 2 ! R functions where each of these functions is constructed by a tensor product of univariate functions. Such an approach involves tessellations of the plane, and requires a relatively large number of points to be specioed <ref> [3, 6, 13] </ref>. This drawback applies to other tessellation dependent techniques, such as an adaptive meshing technique [30] which uses a facial muscle control model deoned on a mesh. Turning to the family of mappings deoned in the present work, 2D radial basis function transformations overcome the drawbacks previously mentioned.
Reference: [7] <author> J. Duchon. </author> <title> Splines minimizing rotation-invariant semi-norms in Sobolev spaces. </title> <editor> In C. K. Chui, L. L. Schumaker, and J. D. Ward, editors, </editor> <booktitle> Multi-variate Approximation Theory, </booktitle> <pages> pages 85100. </pages> <address> Birkhuser, Basel, </address> <year> 1979. </year>
Reference-contexts: continuously dioeerentiable, it is customary to use the functional J (f ) = R 2 (f xx ) 2 + 2 (f xy ) 2 + (f yy ) 2 d (x; y) as a measure of the total amount of bending of the surface (x; y; f (x; y)) <ref> [7] </ref>. The functional J is rotation invariant, again reAEecting the fact that the data has no preferred orientations. <p> With this formulation in mind, it is known that the choice g (t) = t 2 log t (with g (0) = 0) provides a uniquely solvable interpolation problem (3) (4) with m = 1, the solution of which minimizes the functional J <ref> [7] </ref>.
Reference: [8] <author> N. Dyn. </author> <title> Interpolation and approximation by radial and related function. </title> <editor> In C.K. Chui, L.L. Schumaker, and J.D. Ward, editors, </editor> <booktitle> Approximation Theory VI, </booktitle> <volume> volume 1, </volume> <pages> pages 211234. </pages> <publisher> Academic Press, </publisher> <year> 1989. </year>
Reference-contexts: Some classes of functions for which a unique solution to (2) exists for any N distinct points x i 2 R d , and are well known in the literature <ref> [8] </ref> are: 1. g (t) = (t 2 + c 2 ) ff ; 0 &lt; ff &lt; 1 (multiquadrics). 2. g (t) = log (t 2 + c 2 ) 1=2 ; c 2 1 (shifted log). 3. g (t) = exp (t 2 =oe 2 ) ; oe &gt;
Reference: [9] <author> N. Dyn, D. Levin, and S. Rippa. </author> <title> Numerical procedures for global surface otting of scattered data by radial functions. </title> <journal> SIAM journal of Scientioc and Statistical Computing, </journal> <volume> 7:639659, </volume> <year> 1986. </year>
Reference-contexts: When using thin-plate spline, an alternative to using look-up tables is to use certain linear combinations of the original basis functions that decay polynomially; i.e., another basis (not necessarily radial) can be constructed using functions f , satisfying f (t) = O (t k ) <ref> [9] </ref>, We, however, were satisoed with look-up tables, and thus did not further pursue this approach. 18 5 Discussion 5.1 Comparison with other Works In the last several years a considerable amount of research has been directed towards image warping in general and animation of facial expressions in particular.
Reference: [10] <author> N. Dyn and G. Wahba. </author> <title> On the estimation of functions of several variables from aggregated data. </title> <journal> SIAM Journal of Numerical Analysis, </journal> <volume> 13(1):134152, </volume> <year> 1982. </year>
Reference-contexts: for i = 1; : : : ; N (8) N X a i q (x i ) = 0 for q (x; y) = 1; x; y; (9) where G is deoned in equation (2), and (G+ I) i is the i'th row of the matrix G + I <ref> [10] </ref>. A similar solution exists for T V . The equations given in (8) are the generalization of the interpolation equations, while those given in (9) guarantee the reproduction of linear polynomials. Some special cases of the functionals (6)(7) are listed below: * N = 3.
Reference: [11] <author> S. Edelman, D. Reisfeld, and Y. Yeshurun. </author> <title> Learning to recognize faces from examples. </title> <booktitle> In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <pages> pages 787791, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: We have also shown that normalizing a 2D image of a face using an aOEne transformation determined by the location of the eyes and mouth is an eoeective step towards face recognition <ref> [11] </ref>. The aOEne transformation can compensate for various viewing conditions, but is not eoeective if the facial expression is modioed. A recent 2D approach [1], which was impressively used in a video clip, ignores the aOEne aspects of the transformation. <p> Using the center of the mouth as the third anchor point improves the quality of the superposition of facial images and is instrumental for face recognition <ref> [11] </ref>. superimposing photographs by chemical means, a similarity transformation (translation, rotation and scaling) is used. A generalization is obtained by using an aOEne transformation (similarity and shear). Notice that the matching at the chin leaves room for improvement. <p> We have held experiments with other base functions such as t ff ; 1 &lt; ff &lt; 2, with comparable success. 5.3 General remarks A major motivation for this work was the successful use of aOEne transformations in face normalization <ref> [11] </ref>. One feature of aOEne mappings is their group structure: The family of aOEne transformations is closed under composition and inversion. This structure is attractive in interactive systems, since the position of the anchor points can be successively tuned. Thus, the onal outcome is memoryless.
Reference: [12] <author> J. D. Foley, A. van Dam, S. K. Feiner, and J. F. Hughes. </author> <title> Computer graphics: </title> <booktitle> principles and practice. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 21, 25, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [12, 17, 32, 31, 23] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse.
Reference: [13] <author> P. Fong and H. P. Seidel. </author> <title> Control points for multivariate B-spline surfaces over arbitrary triangulations. </title> <journal> Computer Graphics Forum, </journal> <volume> 10:309317, </volume> <year> 1991. </year>
Reference-contexts: Another possibility is constructing a pair of R 2 ! R functions where each of these functions is constructed by a tensor product of univariate functions. Such an approach involves tessellations of the plane, and requires a relatively large number of points to be specioed <ref> [3, 6, 13] </ref>. This drawback applies to other tessellation dependent techniques, such as an adaptive meshing technique [30] which uses a facial muscle control model deoned on a mesh. Turning to the family of mappings deoned in the present work, 2D radial basis function transformations overcome the drawbacks previously mentioned.
Reference: [14] <author> C. Frederick and E. L. Schwartz. </author> <title> Conformal image warping. </title> <journal> IEEE Computer Graphics and Applications, </journal> <month> March, </month> <year> 1990:5461, 1990. </year>
Reference-contexts: These techniques may exhibit impressive results, but suoeer from the fundamental drawback that they are object dependent, i.e. a dioeerent model is needed for dioeerent non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed <ref> [27, 19, 14] </ref>. Recently these two approaches have been combined [18], in the sense that an association between mathematical parameters deoning the transformations and real-life facial expressions was established, giving rise to an expression editor. <p> These constraints should rely on the position of few anchor points that can be detected automatically. There are various alternatives for the construction of such a mapping. Functions of a complex variable have been suggested in such a setting <ref> [14] </ref> since R 2 is naturally incorporated into their structure. Analyticity is a pri 20 and target anchor points. Bottom (left to right): thin-plate warp, Gaussian warp, aOEne least-square warp ( = 1).
Reference: [15] <author> F. Galton. </author> <title> Composite portraits, made by combining those of many dioeer-ent persons, into a single, resultant ogure. </title> <journal> journal of the Anthropological Institute, 8:132144, </journal> <volume> 1879. </volume>
Reference-contexts: For the technique to succeed, he carefully aligned the dioeerent images so that the pupils of the eyes coincided. He superimposed photographs of faces of army personnel for a deonite portrait of health; of tuberculosis victims for disease; and of convicted felons for criminality <ref> [15, 16] </ref>. Being a member of the Victorian elite, he was surprised to see that a superimposed photograph of people convicted of murder, manslaughter, or violent robbery tended to look more respectable than the individual ones used to make it.
Reference: [16] <author> F. Galton. </author> <title> Personal identiocation and description ii. </title> <booktitle> Nature, </booktitle> <pages> pages 201203, </pages> <month> 22 Jun 1899. </month>
Reference-contexts: For the technique to succeed, he carefully aligned the dioeerent images so that the pupils of the eyes coincided. He superimposed photographs of faces of army personnel for a deonite portrait of health; of tuberculosis victims for disease; and of convicted felons for criminality <ref> [15, 16] </ref>. Being a member of the Victorian elite, he was surprised to see that a superimposed photograph of people convicted of murder, manslaughter, or violent robbery tended to look more respectable than the individual ones used to make it.
Reference: [17] <author> P. S. Heckbert. </author> <title> Survey of texture mapping. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 6(11):5667, </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 21, 25, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [12, 17, 32, 31, 23] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse. <p> In cases where two anchor points are mapped to the same or almost the same location, the backward transformation is ill-deoned and the forward transformation must be used. Overcoming the resulting aliasing problem is also a standard procedure <ref> [17] </ref>. We have found that, in practice, the two directions are useful. Of the following examples Figures 6 and 7 were obtained using the forward transformation, and the rest were obtained using the backward transformation.
Reference: [18] <author> P. Kalra, A. Magnili, N. Magnenat-Thalmann, and D. Thalmann. </author> <title> Simulation of facial muscle actions based on rational free form deformations. </title> <address> CGF, 11(3):C59 C69, </address> <year> 1992. </year>
Reference-contexts: The second family of techniques model independent simulate deformations without using any information on the object being deformed [27, 19, 14]. Recently these two approaches have been combined <ref> [18] </ref>, in the sense that an association between mathematical parameters deoning the transformations and real-life facial expressions was established, giving rise to an expression editor. Ideally, model dependent warps mimic the real world realistically, however at the present they are much simpler than the real world.
Reference: [19] <author> Z. C. LI, C. Y. Suen, T. D. Bui, and Q. L. Gu. </author> <title> Harmonic models of shape transformations in digital images and patterns. </title> <journal> Journal of Computer Vision, Graphics, and Image Processing, </journal> <volume> 54(3):198209, </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: These techniques may exhibit impressive results, but suoeer from the fundamental drawback that they are object dependent, i.e. a dioeerent model is needed for dioeerent non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed <ref> [27, 19, 14] </ref>. Recently these two approaches have been combined [18], in the sense that an association between mathematical parameters deoning the transformations and real-life facial expressions was established, giving rise to an expression editor.
Reference: [20] <author> W. R. Madych and S. A. Nelson. </author> <title> Multivariate interpolation: a variational theory. </title> <type> Preprint, </type> <year> 1989. </year>
Reference-contexts: and without a polynomial term) minimizes the functional (f; f ), where (f; h) is deoned by (f; h) = R 2 ( ^ f is the fourier transform of f ), and the minimum is taken over all functions f for which the functional (f; f ) is deoned <ref> [20] </ref>.
Reference: [21] <author> N. Magnenat-Thalmann, P. Primeau, and D. Thalmann. </author> <title> Abstract muscle action procedures for face animation. </title> <booktitle> The Visual Computer, </booktitle> <address> 3:290297, </address> <year> 1988. </year>
Reference-contexts: Such applications require realistic reproduction of faces, as opposed to computer vision face recognition and classiocation tasks that do not require full reconstruction. Current approaches for synthesizing facial expressions use 3D face models, which employ a 3D mesh. Some try to simulate muscle action, skin complexion and so on <ref> [30, 21, 25, 28] </ref>, while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry [12, 17, 32, 31, 23]. The two methods can be combined to enhance their respective performance.
Reference: [22] <author> G. A. Miccelli. </author> <title> Interpolation of scattered data: distance matrices and conditionally positive deonite functions. Constructive Approximation, </title> <address> 2:1122, </address> <year> 1986. </year>
Reference-contexts: This method of interpolation reproduces polynomials in m whenever (4) is uniquely solvable. Conditions for the unique solvability of (4) can be found in <ref> [22] </ref>. A large class of radial functions for which (4) is solvable at distinct fx i g has the additional property that the interpolant satisoes some variational 4 principle, namely the interpolant minimizes some functional deoned on a rel-evant space of functions.
Reference: [23] <author> M. Oka, K. Tsutsui, A. Ohba, Y. Kurauchi, and T. Tago. </author> <title> Real-time manipulation of texture mapped surfaces. </title> <journal> Computer Graphics, </journal> <volume> 21(4):181188, </volume> <year> 1987. </year>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 21, 25, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [12, 17, 32, 31, 23] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse.
Reference: [24] <author> F. I. Parke. </author> <title> Parameterized models for facial animation. </title> <journal> IEEE Computer Graphics and Applications, </journal> <pages> pages 6168, </pages> <month> November </month> <year> 1982. </year>
Reference-contexts: From our point of view models and procedures intended at facial animation may be classioed into two families: The orst model dependent, generates facial expressions by orst constructing a mathematical model of the physical face, and then deoning the dynamics which govern the non-rigid motion of the object, e.g. <ref> [24, 28] </ref>. These techniques may exhibit impressive results, but suoeer from the fundamental drawback that they are object dependent, i.e. a dioeerent model is needed for dioeerent non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed [27, 19, 14].
Reference: [25] <author> S. Platt and N. I. Badler. </author> <title> Animating facial expression. </title> <journal> Computer Graphics, </journal> <volume> 15(3):245252, </volume> <year> 1981. </year>
Reference-contexts: Such applications require realistic reproduction of faces, as opposed to computer vision face recognition and classiocation tasks that do not require full reconstruction. Current approaches for synthesizing facial expressions use 3D face models, which employ a 3D mesh. Some try to simulate muscle action, skin complexion and so on <ref> [30, 21, 25, 28] </ref>, while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry [12, 17, 32, 31, 23]. The two methods can be combined to enhance their respective performance.
Reference: [26] <author> D. Reisfeld, H. Wolfson, and Y. Yeshurun. </author> <title> Detection of interest points using symmetry. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 6265, </pages> <address> Osaka, Japan, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: We have recently demonstrated the applicability of such an approach to face recognition. We have developed a system that automatically detects the most important facial features (eyes and mouth) using generalized symmetry <ref> [26, 5] </ref>. We have also shown that normalizing a 2D image of a face using an aOEne transformation determined by the location of the eyes and mouth is an eoeective step towards face recognition [11].
Reference: [27] <author> T. W. </author> <title> Sederberg. Free-form deformation of solid geometric models. </title> <journal> Computer Graphics, </journal> <volume> 20(4):151160, </volume> <year> 1986. </year>
Reference-contexts: These techniques may exhibit impressive results, but suoeer from the fundamental drawback that they are object dependent, i.e. a dioeerent model is needed for dioeerent non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed <ref> [27, 19, 14] </ref>. Recently these two approaches have been combined [18], in the sense that an association between mathematical parameters deoning the transformations and real-life facial expressions was established, giving rise to an expression editor. <p> Another model that deones a transformation by the position of anchor points is the free-form deformation model of Sederberg and Parry <ref> [27] </ref>. In this model the anchors (control points) must lie on a regular grid, thus imposing at least 4 control points in the planar case, but typically many more. Moreover, the position of the points may not coincide with the position of physical features that are to be manipulated.
Reference: [28] <author> D. Terzopolous and K. Waters. </author> <title> Physically based facial modeling, analysis, and animation. journal of Visualization and Animation, </title> <address> 1(2):7380, </address> <year> 1990. </year>
Reference-contexts: Such applications require realistic reproduction of faces, as opposed to computer vision face recognition and classiocation tasks that do not require full reconstruction. Current approaches for synthesizing facial expressions use 3D face models, which employ a 3D mesh. Some try to simulate muscle action, skin complexion and so on <ref> [30, 21, 25, 28] </ref>, while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry [12, 17, 32, 31, 23]. The two methods can be combined to enhance their respective performance. <p> From our point of view models and procedures intended at facial animation may be classioed into two families: The orst model dependent, generates facial expressions by orst constructing a mathematical model of the physical face, and then deoning the dynamics which govern the non-rigid motion of the object, e.g. <ref> [24, 28] </ref>. These techniques may exhibit impressive results, but suoeer from the fundamental drawback that they are object dependent, i.e. a dioeerent model is needed for dioeerent non-rigid objects. The second family of techniques model independent simulate deformations without using any information on the object being deformed [27, 19, 14].
Reference: [29] <author> C. W. A. M. van Overveld. </author> <title> Beyond bump maps: nonlinear mappings for the modeling of geometric details in computer graphics. </title> <booktitle> Computer Aided Design, </booktitle> <address> 24(4):201209, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: This last point may be modioed by using locally supported weight functions. A model-free warping algorithm driven by the position of source and target anchor points is the nonlinear mappings for modeling of geometric details of van Overveld <ref> [29] </ref>. Like our model, the warp is aOEne whenever possible. However, when more than three anchors are used, it is rare that aOEne warping is possible, and a deonition of a generalization of aOEne warping is needed.
Reference: [30] <author> K. Waters and D. Terzopoulos. </author> <title> Modeling and animating faces using scanned data. </title> <journal> The journal Of Visualization and Computer Animation, </journal> <volume> 2(4):123128, </volume> <year> 1991. </year>
Reference-contexts: Such applications require realistic reproduction of faces, as opposed to computer vision face recognition and classiocation tasks that do not require full reconstruction. Current approaches for synthesizing facial expressions use 3D face models, which employ a 3D mesh. Some try to simulate muscle action, skin complexion and so on <ref> [30, 21, 25, 28] </ref>, while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry [12, 17, 32, 31, 23]. The two methods can be combined to enhance their respective performance. <p> Such an approach involves tessellations of the plane, and requires a relatively large number of points to be specioed [3, 6, 13]. This drawback applies to other tessellation dependent techniques, such as an adaptive meshing technique <ref> [30] </ref> which uses a facial muscle control model deoned on a mesh. Turning to the family of mappings deoned in the present work, 2D radial basis function transformations overcome the drawbacks previously mentioned.
Reference: [31] <author> L. Williams. </author> <title> Performance-driven facial animation. </title> <journal> Computer Graphics, </journal> <volume> 24(4):235242, </volume> <year> 1990. </year>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 21, 25, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [12, 17, 32, 31, 23] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse.
Reference: [32] <author> J. F. S. Yau and A. D. Duoey. </author> <title> A texture mapping approach to 3D facial image synthesis. </title> <journal> Computer Graphics Forum, </journal> <volume> 17:129143, </volume> <year> 1988. </year> <month> 26 </month>
Reference-contexts: Some try to simulate muscle action, skin complexion and so on [30, 21, 25, 28], while others employ texture mapping techniques, which transform 2D texture planes onto the manifold determined by the 3D mesh representing face geometry <ref> [12, 17, 32, 31, 23] </ref>. The two methods can be combined to enhance their respective performance. However, determining the actual parameter values for synthesizing and animating facial expressions is a task requiring tedious interactions with a human operator. In the case of facial expression analysis, the situation is even worse.
References-found: 32

