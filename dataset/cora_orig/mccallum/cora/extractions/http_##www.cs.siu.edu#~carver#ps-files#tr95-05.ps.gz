URL: http://www.cs.siu.edu/~carver/ps-files/tr95-05.ps.gz
Refering-URL: http://www.cs.siu.edu/~carver/umass/fac-analysis-umass.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: (carver@cs.siu.edu)  (lesser@cs.umass.edu)  
Title: A Formal Analysis of Solution Quality in FA/C Distributed Sensor Interpretation Systems  
Author: Norman Carver Victor Lesser 
Note: This work was supported in part by the Department of the Navy, Office of the Chief of Naval Research, under contract N00014-92-J-1450. The content of the information does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred.  
Address: Carbondale, IL 62901  Amherst, MA 01003  
Affiliation: Computer Science Department Southern Illinois University  Computer Science Department University of Massachusetts  
Abstract: The functionally-accurate, cooperative (FA/C) distributed problem-solving paradigm is one approach for organizing distributed problem solving among homogeneous, cooperating agents. The idea behind the FA/C model is that agents should produce tentative, partial results based on only local information and then exchange these results, exploiting the constraints that exist among their local subproblems to resolve the uncertainties and global inconsistencies that result from the use of incomplete information. While several FA/C systems have been implemented, there has been little formal analysis of the quality of the solutions that can be produced using the approach or of the conditions that are necessary for the approach to be effective. This paper reports on work we have done to formally analyze the FA/C model in the context of distributed sensor interpretation (SI). Several results are presented that compare the quality of solutions produced by a distributed FA/C system to those produced by an equivalent centralized system, based on particular agent problem-solving and coordination strategies. We first establish that while it is possible for an FA/C system to produce the same solution as a centralized system, this requires the use of interpretation and coordination strategies that are impractical for most SI applications. Because of this we then consider the effect of "approximate" interpretation and coordination strategies, given some assumptions about the characteristics of the domain. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Yaakov Bar-Shalom and Thomas Fortmann, </author> <title> Tracking and Data Association, </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: and each vehicle will produce a "track" of data points that can be of varying, unknown lengths. 5 Because there can be an indeterminate number of instances of any top-level cause, a key problem for SI is what is known in the target tracking literature as the data association problem <ref> [1] </ref>: which target should data be associated with? The data association problem and the possibility of an indeterminate number of top-level causes lead to the problem of correlation ambiguity (it is ambiguous/uncertain which potential explanation hypothesis a data evidence should be associated with) and to a combinatorial explosion of possible explanations
Reference: [2] <author> Norman Carver and Victor Lesser, </author> <title> "A New Framework for Sensor Interpretation: Planning to Resolve Sources of Uncertainty," </title> <booktitle> Proceedings of AAAI-91, </booktitle> <pages> 724-731, </pages> <year> 1991. </year>
Reference-contexts: The paper concludes with a summary of the major results in the paper and our future research plans. 2 Distributed Sensor Interpretation By sensor interpretation, we mean the determination of high-level, conceptual explanations of sensor data. Our model of the interpretation process will be essentially that used in <ref> [2] </ref>: interpretation hypotheses are incrementally constructed via abductive inferences, based on a causal domain model that defines the relationships among the data types and abstraction types. For each type T , the causal model defines the type's support, S T , and its possible explanations, E T . <p> Also, instead of random variables, in SI we talk about data and hypotheses, which can be complex, multi-attribute entities. 3 Approximate Interpretation Strategies To deal with the characteristics discussed in the previous section, SI systems must be constructive <ref> [2, 5] </ref> and they must use approximate, satisficing strategies to determine solutions. <p> The distributed SI model we describe in the next section is based on the RESUN/DRESUN architecture, which provides great flexibility for implementing approximate interpretation strategies <ref> [2, 3] </ref>. <p> Ideally, this would be accomplished with a mechanism that allowed agents to understand where there are constraints among their subproblems, so that information interchange could be highly directed. DRESUN <ref> [2, 3, 4] </ref> provides this capability, and it will form the basis for our model of the capabilities of an FA/C agent. DRESUN agents create symbolic source of uncertainty statements (SOUs) to represent all of the reasons why their hypotheses are uncertain based on their local evidence. <p> It is important to note that while we have shown that a distributed DRESUN system would find an "acceptable" solution, this interpretation may not be identical to that produced by the new versions of the hypothesis (what <ref> [2] </ref> terms extensions). Thus, what we really mean is that a precursor, partial version of each alternative hypothesis would have been created by one or more of the agents.
Reference: [3] <author> Norman Carver, Zarko Cvetanovic, and Victor Lesser, </author> <title> "Sophisticated Cooperation in FA/C Distributed Problem Solving Systems," </title> <booktitle> Proceedings of AAAI-91, </booktitle> <pages> 191-198, </pages> <year> 1991. </year>
Reference-contexts: While several systems that use the FA/C approach have been built (e.g., <ref> [3, 9] </ref>), there has never been any formal analysis of the quality of the solutions that can be produced by the approach or of the effect of domain conditions and coordination strategies on solutions. This paper reports on our efforts in formally characterizing the FA/C paradigm. <p> For example, some architectures allow a wide range of inconsistencies to be resolved using very directed, limited communication of data and hypotheses among the agents <ref> [3, 4] </ref>. <p> We also consider the effect of different coordination strategies, in terms of the completeness with which subproblem (local interpretation) interactions are pursued. The analysis assumes the capabilities of an abstract model of the DRESUN system for distributed SI <ref> [3, 4] </ref>. In particular, we assume that all possible subproblem interactions can be easily identified and that they can be selectively (and incrementally) pursued (see Section 4). Again, there are several alternative strategies that might be used. <p> The distributed SI model we describe in the next section is based on the RESUN/DRESUN architecture, which provides great flexibility for implementing approximate interpretation strategies <ref> [2, 3] </ref>. <p> Ideally, this would be accomplished with a mechanism that allowed agents to understand where there are constraints among their subproblems, so that information interchange could be highly directed. DRESUN <ref> [2, 3, 4] </ref> provides this capability, and it will form the basis for our model of the capabilities of an FA/C agent. DRESUN agents create symbolic source of uncertainty statements (SOUs) to represent all of the reasons why their hypotheses are uncertain based on their local evidence.
Reference: [4] <author> Norman Carver, Victor Lesser, </author> <title> "The DRESUN Testbed for Research in FA/C Distributed Situation Assessment: Extensions to the Model of External Evidence," </title> <booktitle> Proceedings of the International Conference on Multiagent Systems, </booktitle> <month> June, </month> <year> 1995. </year>
Reference-contexts: For example, some architectures allow a wide range of inconsistencies to be resolved using very directed, limited communication of data and hypotheses among the agents <ref> [3, 4] </ref>. <p> We also consider the effect of different coordination strategies, in terms of the completeness with which subproblem (local interpretation) interactions are pursued. The analysis assumes the capabilities of an abstract model of the DRESUN system for distributed SI <ref> [3, 4] </ref>. In particular, we assume that all possible subproblem interactions can be easily identified and that they can be selectively (and incrementally) pursued (see Section 4). Again, there are several alternative strategies that might be used. <p> Ideally, this would be accomplished with a mechanism that allowed agents to understand where there are constraints among their subproblems, so that information interchange could be highly directed. DRESUN <ref> [2, 3, 4] </ref> provides this capability, and it will form the basis for our model of the capabilities of an FA/C agent. DRESUN agents create symbolic source of uncertainty statements (SOUs) to represent all of the reasons why their hypotheses are uncertain based on their local evidence.
Reference: [5] <author> William Clancey, </author> <title> "Heuristic Classification," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 27, </volume> <pages> 289-350, </pages> <year> 1985. </year>
Reference-contexts: Also, instead of random variables, in SI we talk about data and hypotheses, which can be complex, multi-attribute entities. 3 Approximate Interpretation Strategies To deal with the characteristics discussed in the previous section, SI systems must be constructive <ref> [2, 5] </ref> and they must use approximate, satisficing strategies to determine solutions.
Reference: [6] <author> Keith Decker, and Victor Lesser, </author> <title> "An Approach to Analyzing the Need for Meta-Level Communication," </title> <booktitle> Proceedings of IJCAI-93, </booktitle> <pages> 360-366, </pages> <year> 1993. </year>
Reference-contexts: Finally, there are other 1 Distributed sensor interpretation plays an important role in many military situation assessment (decision support) systems. 2 We are pursuing both empirical and analytic approaches to address this issue <ref> [6, 7] </ref>. 1 factors that might prevent effective FA/C problem solving in certain domains, but they are beyond the scope of this paper. 3 The main aspect of FA/C performance that we address is the quality of solutions produced by an FA/C system.
Reference: [7] <author> Keith Decker, and Victor Lesser, </author> <title> "Designing a Family of Coordination Algorithms," </title> <booktitle> Proceedings of the International Conference on Multiagent Systems, </booktitle> <month> June, </month> <year> 1995. </year>
Reference-contexts: Finally, there are other 1 Distributed sensor interpretation plays an important role in many military situation assessment (decision support) systems. 2 We are pursuing both empirical and analytic approaches to address this issue <ref> [6, 7] </ref>. 1 factors that might prevent effective FA/C problem solving in certain domains, but they are beyond the scope of this paper. 3 The main aspect of FA/C performance that we address is the quality of solutions produced by an FA/C system.
Reference: [8] <author> Victor Lesser and Daniel Corkill, </author> <title> "Functionally Accurate, Cooperative Distributed Systems," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 11, no. 1, </volume> <pages> 81-96, </pages> <year> 1981. </year>
Reference-contexts: 1 Introduction In the functionally accurate, cooperative (FA/C) paradigm for distributed problem solving <ref> [8, 10] </ref>, agents need not have all the information necessary to completely and accurately solve their sub-problems. Instead, agents are designed to produce tentative, partial results based on only local information and to then exchange these results with the other agents to resolve local uncertainties and global inconsistencies. <p> This is an important strategy because it can be very efficient when local agent solutions are consistent. In addition, the developers of the FA/C paradigm clearly saw this as a useful coordination strategy. For example, <ref> [8] </ref> refers to consistency checking of the tentative local solutions with results received from other nodes as "an important part of the FA/C approach." Theorem 2: Given a centralized system that uses an arbitrary (possibly approximate) local interpretation strategy and a set of agents A each of which uses this same
Reference: [9] <author> Victor Lesser and Daniel Corkill, </author> <title> "The Distributed Vehicle Monitoring Testbed: A Tool for Investigating Distributed Problem Solving Networks," </title> <journal> AI Magazine, </journal> <volume> vol. 4, no. 3, </volume> <pages> 15-33, </pages> <note> 1983 (also in Blackboard Systems, </note> <editor> Robert Engelmore and Tony Morgan, editors, </editor> <publisher> Addison-Wesley, </publisher> <year> 1988). </year>
Reference-contexts: While several systems that use the FA/C approach have been built (e.g., <ref> [3, 9] </ref>), there has never been any formal analysis of the quality of the solutions that can be produced by the approach or of the effect of domain conditions and coordination strategies on solutions. This paper reports on our efforts in formally characterizing the FA/C paradigm.
Reference: [10] <author> Victor Lesser, </author> <title> "A Retrospective View of FA/C Distributed Problem Solving," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, special issue on Distributed Artificial Intelligence, </journal> <volume> vol. 21, no. 6, </volume> <pages> 1347-1362, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction In the functionally accurate, cooperative (FA/C) paradigm for distributed problem solving <ref> [8, 10] </ref>, agents need not have all the information necessary to completely and accurately solve their sub-problems. Instead, agents are designed to produce tentative, partial results based on only local information and to then exchange these results with the other agents to resolve local uncertainties and global inconsistencies. <p> First, it is important to be clear about what we will and will not consider. <ref> [10] </ref> referred to the issues of solution uncertainty and control uncertainty in FA/C problem solving, and these concepts are useful in delineating the focus of our efforts.
Reference: [11] <author> Ann Nicholson and Michael Brady, </author> <title> "Dynamic Belief Networks for Discrete Monitoring," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, special issue on Knowledge-Based Construction of Probabilistic and Decision Models, </journal> <volume> vol. 24, no. 11, </volume> <pages> 1593-1610, </pages> <year> 1994. </year>
Reference-contexts: probabilities) for the hypotheses, 8 consider only some of the possible composite interpretations (hypothesis combinations), and use 7 The probabilistic belief network community is just starting to become aware of the data association problem and the issues it raises that have not been addressed in the work on diagnosis problems|e.g., <ref> [11] </ref>. 8 We will use the term "belief" to mean the degree-of-belief accorded to a hypothesis or interpretation.
Reference: [12] <author> Judea Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: An interpretation of a data set is an explanation what caused all of the data. In general, an interpretation will be a composite of a set of hypotheses whose types are from a specified subset of the interpretation types (the explanation corpus <ref> [12] </ref>), each of which explains some subset of the data, and which together explain all of the data set. <p> In this paper we are interested in analyzing the quality of the global solutions that can be produced by FA/C distributed interpretation systems. To do this we need some standard for comparison|i.e., the "globally best solution." Usually one would like this to be the most probable 4 explanation (MPE) <ref> [12] </ref> given all of the globally available data. 4 The problem with defining the globally best solution to be the global MPE is that for most real-world SI problems it is impractical to compute the (true) MPE. <p> The complexity of determining the true MPE can be understood by considering the differences between SI problems and the kinds of problems that are typically studied in research on abductive inference and probabilistic network inference (e.g., <ref> [12, 13] </ref>). For simplicity, we will refer to these problems as diagnosis problems. One key difference is that diagnosis problems are propositional while SI is not, in general. In other words, diagnosis problems have a fixed set of causes and possible findings, with fixed relations among them. <p> One key difference is that diagnosis problems are propositional while SI is not, in general. In other words, diagnosis problems have a fixed set of causes and possible findings, with fixed relations among them. The problem of identifying the MPE in such systems has been studied extensively (e.g., <ref> [12, 13] </ref>). By contrast, while SI problems have a fixed set of "top-level" cause types and a fixed set of data types, they can have an indeterminate number of instances of any of the types. <p> This is because incomplete hypothesis construction results in incomplete propagation of the effects of evidence (we are using "evidence propagation" in the same basic sense that <ref> [12] </ref> refers to "belief propagation"). Figure 1 provides an example of this situation. The bottom line is that these approaches will result in SI solutions that are only approximations of the MPE: they may be incomplete or they may not be the most probable composite interpretation. <p> When the MPE can be computed using a local computation, message passing scheme (see the discussion of belief revision in <ref> [12] </ref>) this is not a major issue. However, if the agents require access to all of the possible component hypotheses of the possible interpretations then substantial additional evidence may have to be communicated (beyond that necessary to compute revised hypothesis beliefs). the local solutions GSOUs resolution strategy.
Reference: [13] <author> Yun Peng and James Reggia, </author> <title> Abductive Inference Models for Diagnostic Problem-Solving, </title> <publisher> Springer-Verlag, </publisher> <year> 1990. </year> <month> 25 </month>
Reference-contexts: The complexity of determining the true MPE can be understood by considering the differences between SI problems and the kinds of problems that are typically studied in research on abductive inference and probabilistic network inference (e.g., <ref> [12, 13] </ref>). For simplicity, we will refer to these problems as diagnosis problems. One key difference is that diagnosis problems are propositional while SI is not, in general. In other words, diagnosis problems have a fixed set of causes and possible findings, with fixed relations among them. <p> One key difference is that diagnosis problems are propositional while SI is not, in general. In other words, diagnosis problems have a fixed set of causes and possible findings, with fixed relations among them. The problem of identifying the MPE in such systems has been studied extensively (e.g., <ref> [12, 13] </ref>). By contrast, while SI problems have a fixed set of "top-level" cause types and a fixed set of data types, they can have an indeterminate number of instances of any of the types.
References-found: 13

