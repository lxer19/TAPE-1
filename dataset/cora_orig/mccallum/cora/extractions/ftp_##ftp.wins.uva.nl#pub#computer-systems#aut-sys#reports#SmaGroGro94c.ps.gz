URL: ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/SmaGroGro94c.ps.gz
Refering-URL: http://www.fwi.uva.nl/research/neuro/publications/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email smagt@fwi.uva.nl  
Phone: fax +31-20-525-7490 phone +31-20-525-7524  
Title: Robotic hand-eye coordination using multi-resolution linear perceptron representation  
Author: P. van der Smagt F. van het Groenewoud F. Groen 
Date: December 20, 1993  
Address: Kruislaan 403, 1098 SJ Amsterdam The Netherlands  
Affiliation: Department of Computer Systems University of Amsterdam  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> C. Brice and C. Fennema. </author> <title> Scene analysis using regions. </title> <journal> Artificial Intelligence, </journal> <volume> 1 </volume> <pages> 205-226, </pages> <year> 1970. </year>
Reference-contexts: This process of splitting up will be repeated until for every part of the input space the desired approximation precision is achieved. This process can be compared with the first part of the well-known split and merge process as used in image processing, as first mentioned in <ref> [1] </ref>. A second requirement is that we want to have a very flexible system, able to adjust itself to changes in the system.

Reference: [3] <author> A. Jansen, P. van der Smagt, and F. Groen. </author> <title> High-precision robot control: The nested network. </title> <editor> In I. Aleksander and J. Taylor, editors, </editor> <booktitle> Artificial Neural Networks 2, </booktitle> <pages> pages 583-586. </pages> <publisher> North-Holland/Elsevier Science Publishers, </publisher> <month> September </month> <year> 1992. </year>
Reference-contexts: are expensive to get for a real robot system), whereas global approximations can quickly establish reasonable overall approximations but the final result will be coarse; also, parallel implementation is more cumbersome. 1 In previous work, we have combined global and local representations in a method called the nested network method <ref> [10, 3, 4] </ref>. The approximation starts with a global map in the form of a fast-learning feed-forward network, but as learning proceeds local maps will be built in a tree-like structure where needed.
Reference: [4] <author> A. Jansen, P. van der Smagt, and F. C. A. Groen. </author> <title> Nested networks for robot control. </title> <editor> In A. F. Murray, editor, </editor> <title> Neural Network Applications. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year> <note> In print. </note>
Reference-contexts: are expensive to get for a real robot system), whereas global approximations can quickly establish reasonable overall approximations but the final result will be coarse; also, parallel implementation is more cumbersome. 1 In previous work, we have combined global and local representations in a method called the nested network method <ref> [10, 3, 4] </ref>. The approximation starts with a global map in the form of a fast-learning feed-forward network, but as learning proceeds local maps will be built in a tree-like structure where needed. <p> From the joint and camera information input samples to train the control system can be constructed using an input-adjustment method [7]. 2 The Nested Network Method In a previous publication, the nested network method is described in detail <ref> [4] </ref>. We will highlight the principal components. Methods used for continuous function approximation usually allow their user to specify a `smoothness' parameter. Such a parameter is determined based on a priori knowledge of the function at hand, while overfitting due to noise must be prevented. <p> Conversely, a single feed-forward network exhibits fast learning but will get a lower accuracy (figure 5). 4 Conclusion We presented a method which can represent unknown multi-dimensional functions from samples randomly drawn from its input space. The system builds upon previous research with nested networks <ref> [4] </ref>, and gives equally good results with much lower resources. When compared with feed-forward networks and Kohonen networks for the same task, this method of high-dimensional function approximation is shown to be superior in its economic use of learning samples, i.e., it generalises faster while also allowing very exact representation.
Reference: [5] <author> T. Martinetz, H. Ritter, and K. Schulten. </author> <title> Learning of visuomotor-coordination of a robot arm with redundant degrees of freedom. </title> <editor> In R. Eck-miller, G. Hartmann, and G. Hauske, editors, </editor> <booktitle> Parallel Processing in Neural Systems and Computers, </booktitle> <pages> pages 431-434. </pages> <publisher> Elsevier Science Publishers B.V., </publisher> <year> 1990. </year>
Reference-contexts: Also, unavoidable errors due to discrepancies between the model and the machine must be corrected. Neural adaptive robot controllers that have been previously proposed either suffer from long learning times or from a less precise approximation. For example, Kohonen networks as initially proposed by Ritter et al. <ref> [5, 6, 2] </ref> can get a precision of around 0.5 cm in the end-effector position in a few feedback steps, but need thousands of iterations to attain reasonable results.
Reference: [6] <author> T. Martinetz and K. Schulten. </author> <title> A "neural-gas" network learns topologies. </title> <booktitle> In Proceedings of the 1991 International Conference on Artificial Neural Networks, </booktitle> <volume> volume 1, </volume> <pages> pages 397-402, </pages> <address> Espoo, Finland, </address> <year> 1991. </year>
Reference-contexts: Also, unavoidable errors due to discrepancies between the model and the machine must be corrected. Neural adaptive robot controllers that have been previously proposed either suffer from long learning times or from a less precise approximation. For example, Kohonen networks as initially proposed by Ritter et al. <ref> [5, 6, 2] </ref> can get a precision of around 0.5 cm in the end-effector position in a few feedback steps, but need thousands of iterations to attain reasonable results.
Reference: [7] <author> D. Psaltis, A. Sideris, and A. A. Yamamura. </author> <title> A multilayer neural network controller. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 8(2) </volume> <pages> 17-21, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Note that the value of the 1 is not necessary as network input. From the joint and camera information input samples to train the control system can be constructed using an input-adjustment method <ref> [7] </ref>. 2 The Nested Network Method In a previous publication, the nested network method is described in detail [4]. We will highlight the principal components. Methods used for continuous function approximation usually allow their user to specify a `smoothness' parameter.
Reference: [8] <author> P. van der Smagt. </author> <title> Minimisation methods for training feed-forward networks. Neural Networks, </title> <type> 7, </type> <month> January </month> <year> 1994. </year>
Reference-contexts: The networks are trained with conjugate gradient optimisation <ref> [8] </ref>. The maximum depth that the tree is allowed to grow should, theoretically, be infinity. However, due to the finiteness of computer memory, a value is chosen higher than the maximum depth the tree (i.e., the deepest network node) would reach in a typical run.
Reference: [9] <author> P. van der Smagt, F. Groen, and B. Krose. </author> <title> Robot hand-eye coordination using neural networks. </title> <type> Technical Report TR CS-93-10, </type> <institution> Department of Computer Systems, University of Amsterdam, </institution> <address> Amsterdam, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: The use of a single feed-forward network trained with conjugate gradient back-propagation has been shown to give fast and highly adaptive approximation of inverse kinematics functions, but a large number of feedback steps is needed to get high-precision results <ref> [11, 9] </ref>.
Reference: [10] <author> P. van der Smagt, A. Jansen, and F. C. A. Groen. </author> <title> Interpolative robot control with the nested network approach. </title> <booktitle> In Proceedings of the 1992 IEEE International Symposium on Intelligent Control, </booktitle> <pages> pages 475-480, </pages> <address> Glasgow, Scotland, U.K., </address> <month> 11-13 August </month> <year> 1992. </year>
Reference-contexts: are expensive to get for a real robot system), whereas global approximations can quickly establish reasonable overall approximations but the final result will be coarse; also, parallel implementation is more cumbersome. 1 In previous work, we have combined global and local representations in a method called the nested network method <ref> [10, 3, 4] </ref>. The approximation starts with a global map in the form of a fast-learning feed-forward network, but as learning proceeds local maps will be built in a tree-like structure where needed.
Reference: [11] <author> P. van der Smagt and B. J. A. Krose. </author> <title> A real-time learning neural robot controller. </title> <booktitle> In Proceedings of the 1991 International Conference on Artificial Neural Networks, </booktitle> <pages> pages 351-356. </pages> <publisher> Elsevier Science Publishers, </publisher> <address> Espoo, Finland, </address> <month> June </month> <year> 1991. </year> <month> 8 </month>
Reference-contexts: The use of a single feed-forward network trained with conjugate gradient back-propagation has been shown to give fast and highly adaptive approximation of inverse kinematics functions, but a large number of feedback steps is needed to get high-precision results <ref> [11, 9] </ref>.
References-found: 10

