URL: http://www.mcs.anl.gov/Projects/PRISM/lib/techsrc/wn35.ps
Refering-URL: 
Root-URL: 
Title: A Parallel Implementation of Symmetric Band Reduction Using PLAPACK  
Author: Yuan-Jye J. Wu, Philip A. Alpatov, Christian H. Bischof, and Robert A. van de Geijn 
Abstract: Successive band reduction (SBR) is a two-phase approach for reducing a full symmetric matrix to tridiag-onal (or narrow banded) form. In its simplest case, it consists of a full-to-band reduction followed by a band-to-tridiagonal reduction. Its richness in BLAS-3 operations makes it potentially more efficient on high-performance architectures than the traditional tridi-agonalization method. However, a scalable, portable, general-purpose parallel implementation of SBR is still not available. In this article, we review some existing parallel tridiagonalization routines and describe the implementation of a full-to-band reduction routine using PLAPACK as a first step toward a parallel SBR toolbox. The PLAPACK-based routine turns out to be simple and efficient and, unlike the other existing packages, does not suffer restrictions on physical data layout or algorithmic block size. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Ham-marling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <title> LAPACK Users' Guide, 2nd edition. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1995. </year>
Reference-contexts: 1 Introduction Reducing a full, dense symmetric matrix to tridiag-onal form is one of the key steps in computing eigenval-ues and eigenvectors of a symmetric matrix. Although serial tridiagonalization algorithms and implementations are well studied (e.g., LAPACK <ref> [1] </ref>), a scalable, portable, general-purpose parallel implementation remains a challenge. Existing software packages, like ScaLAPACK [2] or HJS [3], provide tridiagonalization fl This work is part of the PRISM project.
Reference: [2] <author> J. Choi, J. J. Dongarra, and D. W. Walker. </author> <title> The design of a parallel dense linear algebra software library: Reduction to Hessenberg, tridiago-nal, and bidiagonal form. </title> <booktitle> Numerical Algorithms, </booktitle> <volume> 10 </volume> <pages> 379-400, </pages> <year> 1995. </year>
Reference-contexts: Although serial tridiagonalization algorithms and implementations are well studied (e.g., LAPACK [1]), a scalable, portable, general-purpose parallel implementation remains a challenge. Existing software packages, like ScaLAPACK <ref> [2] </ref> or HJS [3], provide tridiagonalization fl This work is part of the PRISM project. It is supported in part by ARPA grant P-95006 and the Mathematical, Information, and Computational Sciences Division subprogram of the Office of Computational and Technology Research, U.S.
Reference: [3] <author> B. Hendrickson, E. Jessup, and C. Smith. </author> <title> A parallel eigensolver for dense symmetric matrices. </title> <institution> Sandia National Laboratory Report, </institution> <year> 1996. </year>
Reference-contexts: Although serial tridiagonalization algorithms and implementations are well studied (e.g., LAPACK [1]), a scalable, portable, general-purpose parallel implementation remains a challenge. Existing software packages, like ScaLAPACK [2] or HJS <ref> [3] </ref>, provide tridiagonalization fl This work is part of the PRISM project. It is supported in part by ARPA grant P-95006 and the Mathematical, Information, and Computational Sciences Division subprogram of the Office of Computational and Technology Research, U.S.
Reference: [4] <author> C. Bischof, M. Marques, and X. Sun. </author> <title> Parallel band reduction and tridiagonalization. </title> <booktitle> Proceedings of Sixth SIAM Conference on Parallel Processing for Scientific Computing, SIAM, </booktitle> <pages> 383-390, </pages> <year> 1993. </year>
Reference-contexts: However, they all impose some constraints either on data layout or on the topology of the processor grid, which may cause difficulties in incorporating them into applications. As an alternative to directly computing the tridi-agonalization, a multistep approach called successive band reduction (SBR) was introduced by Bischof et al. <ref> [4, 5, 6] </ref>. Instead of reducing a full matrix to tridi-agonal form directly, SBR first reduces the original matrix to banded form and then performs a band-to-tridiagonal reduction. This approach increases the potential for utilizing BLAS-3 operations.
Reference: [5] <author> C. Bischof, B. Lang and X. Sun. </author> <title> A framework for symmetric band reduction. </title> <institution> Mathematics and Computer Science Division Preprint ANL/MCS-P586-0496, Argonne National Laboratory, </institution> <year> 1996. </year>
Reference-contexts: However, they all impose some constraints either on data layout or on the topology of the processor grid, which may cause difficulties in incorporating them into applications. As an alternative to directly computing the tridi-agonalization, a multistep approach called successive band reduction (SBR) was introduced by Bischof et al. <ref> [4, 5, 6] </ref>. Instead of reducing a full matrix to tridi-agonal form directly, SBR first reduces the original matrix to banded form and then performs a band-to-tridiagonal reduction. This approach increases the potential for utilizing BLAS-3 operations.
Reference: [6] <author> C. Bischof, B. Lang and X. Sun. </author> <title> The SBR toolbox software for successive band reduction. </title> <institution> Mathematics and Computer Science Division Preprint ANL/MCS-P587-0496, Argonne National Laboratory, </institution> <year> 1996. </year>
Reference-contexts: However, they all impose some constraints either on data layout or on the topology of the processor grid, which may cause difficulties in incorporating them into applications. As an alternative to directly computing the tridi-agonalization, a multistep approach called successive band reduction (SBR) was introduced by Bischof et al. <ref> [4, 5, 6] </ref>. Instead of reducing a full matrix to tridi-agonal form directly, SBR first reduces the original matrix to banded form and then performs a band-to-tridiagonal reduction. This approach increases the potential for utilizing BLAS-3 operations.
Reference: [7] <author> R. van de Geijn et al. </author> <title> Parallel Linear Algebra Package (PLAPACK): Release R0.1 (Beta) Users' Guide. </title> <type> Unpublished manuscript, </type> <year> 1996. </year>
Reference-contexts: Thus, continuing in the previous low-level programming style was impractical because of the excessive amount of work that would be required. Recently, van de Geijn et al. introduced a new parallel library, the Parallel Linear Algebra Package (PLAPACK) <ref> [7] </ref>. One of the goals of PLAPACK is to enable the rapid transformation of matrix algorithms into parallel codes while hiding the complicated local index alignment and data movement issues. Therefore, PLAPACK appeared to be an attractive infrastructure for rapidly prototyping our new approach.
Reference: [8] <author> C. Bischof and C. Van Loan. </author> <title> The WY representation for products of Householder matrices. </title> <note> SIAM J. </note> <institution> Sci. Stat. Comput., 8:s2-s13, </institution> <year> 1987. </year>
Reference-contexts: Accumulating a certain number of Householder transformations into a block update is a common way to enrich BLAS-3 operations. Suppose that we have a sequence of k Householder transformations H i ; i = 1; : : : ; k. For one-sided updates, we can use the WY representation <ref> [8] </ref> of the product of these transformations to achieve one rank-k update instead of a sequence of rank-one updates.
Reference: [9] <author> J. Dongarra, S. Hammarling, and D. Sorensen. </author> <title> Block reduction of matrices to condensed forms for eigenvalue computations. </title> <journal> J. Comp. and Appl. Math., </journal> <volume> 27 </volume> <pages> 215-227, </pages> <year> 1989. </year>
Reference-contexts: 1 : The WY representation, H k H 1 = I + Y k W T can be computed by the following recursion: for i = 2; : : : ; k, W i = [W i1 (I + Y i1 W T For symmetric Householder updates, the YZ representation <ref> [9] </ref> can be employed to perform a rank-2k update.
Reference: [10] <author> C. Bischof, S. Huss-Lederman, X. Sun, A. Tsao, and T. Turnbull. </author> <title> Parallel studies of the invariant subspace decomposition approach for banded symmetric matrices. </title> <booktitle> Proceedings of Seventh SIAM Conference on Parallel Processing for Scientific Computing, SIAM, </booktitle> <pages> 516-521, </pages> <year> 1995. </year>
Reference-contexts: Once the global matrix and vector partitions for PLAPACK are defined, no local indices need to be dealt with. The simplicity of this code also makes it very easy to debug, document, maintain, and extend. In particular, we have added capabilities that are specifically addressed in the PRISM eigensolver <ref> [10] </ref>. For example, if the norm of a vector (or a column of a panel) a in (1) is small enough, we might skip computing the Householder transformation for a and continue the process on the next column in the panel.
References-found: 10

