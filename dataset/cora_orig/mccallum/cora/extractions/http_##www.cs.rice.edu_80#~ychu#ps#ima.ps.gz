URL: http://www.cs.rice.edu:80/~ychu/ps/ima.ps.gz
Refering-URL: http://www.cs.rice.edu:80/~ychu/papers.html
Root-URL: 
Title: DATA PARALLEL PERFORMANCE OPTIMIZATIONS USING ARRAY ALIASING  
Author: Y. CHARLIE HU AND S. LENNART JOHNSSON 
Keyword: Key words. Data parallel programming, array aliasing, hierarchical N -body methods.  
Note: AMS(MOS) subject classifications. 68N15, 68N20, 70-08, 70F10  
Abstract: The array aliasing mechanism provided in the Connection Machine Fortran (CMF) language and run-time system provides a unique way of identifying the memory address spaces local to processors within the global address space of distributed memory architectures, while staying in the data parallel programming paradigm. We show how the array aliasing feature can be used effectively in optimizing communication and computation performance. The constructs we present occur frequently in many scientific and engineering applications, and include various forms of aggregation and array reshaping through array aliasing. The effectiveness of the optimization techniques is demonstrated on an implementation of Anderson's hierarchical O(N ) N -body method. We also suggest a way of implementing the array aliasing feature in HPF by extending the semantics of the RESHAPE intrinsic function of Fortran 90 to include possible aliasing relationship between the parameter and returning arrays. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. R. Anderson. </author> <title> An implementation of the fast multipole method without multi-poles. </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> 13(4) </volume> <pages> 923-947, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: CHARLIE HU AND S. LENNART JOHNSSON * align and operate on nonconforming arrays without growth in mem ory requirements and excessive communication, * enhance arithmetic performance through aggregation. The effectiveness of our techniques is demonstrated on an implementation of Anderson's hierarchical O (N ) N -body method <ref> [1] </ref> for the Connection Machine system CM-5/5E. Of the total execution time, communication accounts for about 10-20% of the total time, with the average efficiency for arithmetic operations about 40% and the total efficiency (including communication) about 35%. Section 2 describes the array aliasing feature of CMF. <p> Hierarchical N -body methods encompass yet another issue, namely, the interaction between two different data structures; one for the discrete particles, one for the discretized fields. We used an implementation of Anderson's hierarchical N -body method <ref> [1] </ref> to eval 1 All the code examples in this paper will be in CMF. DATA PARALLEL OPTIMIZATIONS USING ARRAY ALIASING 5 Fig. 3.1. Recursive domain decompositions, the near-field, and the interactive-field in two dimensions. uate the effectiveness of the techniques we propose. <p> Then, the potential value at ~x is 6 Y. CHARLIE HU AND S. LENNART JOHNSSON approximated by (equation (15) of <ref> [1] </ref>) (~x) i=1 n=0 a ) n+1 P n (~s i ~x p ) g (a~s i )w i (3.2) where P n is the nth Legendre function, K the number of integration points on the sphere, ~s i their location and w i their weights. <p> This approximation is called an outer-sphere approximation. The approximation used to represent potentials inside a given region is (equation (16) of <ref> [1] </ref>) (~x) i=1 n=0 r ) n+1 P n (~s i ~x p ) g (a~s i )w i (3.3) and is called an inner-sphere approximation. The outer-sphere and the inner-sphere approximations define the computational elements in Anderson's hierarchical method.
Reference: [2] <author> J. H. Applegate, M. R. Douglas, Y. Gursel, P. Hunter, C. L. Seitz, and G. J. Sussman. </author> <title> A digital orrery. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-34(9):822-831, </volume> <month> September </month> <year> 1985. </year>
Reference-contexts: Exploiting symmetry in the all-to-all interaction is fairly straightforward based on the linear ordering offered by the space-filling curve. This observation has been made by many others, see for instance <ref> [2] </ref>. The idea of reducing communication by exploiting symmetry is shown in a 2-D example in Figure 5.9. As subdomain 0 traverses subdomains 1-4, the interactions between subdomain 0 and each of the four subdomains will be computed. <p> product (level-1 BLAS) approaches one floating-point operation per memory reference as operand size grows, a matrix-vector multiplication (level-2 BLAS) approaches two floating-point operations per memory ref 2 The 1206 matrices correspond to the 1206 possible relative interactive-field box locations with offsets in [5; 5] fi [5; 5] fi [5; 5]n <ref> [2; 2] </ref> fi [2; 2] fi [2; 2]. 24 Y. CHARLIE HU AND S. LENNART JOHNSSON erence, while a matrix-matrix multiplication (level-3 BLAS) approaches b floating-point operations per memory reference. <p> approaches one floating-point operation per memory reference as operand size grows, a matrix-vector multiplication (level-2 BLAS) approaches two floating-point operations per memory ref 2 The 1206 matrices correspond to the 1206 possible relative interactive-field box locations with offsets in [5; 5] fi [5; 5] fi [5; 5]n <ref> [2; 2] </ref> fi [2; 2] fi [2; 2]. 24 Y. CHARLIE HU AND S. LENNART JOHNSSON erence, while a matrix-matrix multiplication (level-3 BLAS) approaches b floating-point operations per memory reference. Since memory bandwidth on most processor architectures is a limiting factor it is highly desirable to use higher level BLAS whenever possible. <p> operation per memory reference as operand size grows, a matrix-vector multiplication (level-2 BLAS) approaches two floating-point operations per memory ref 2 The 1206 matrices correspond to the 1206 possible relative interactive-field box locations with offsets in [5; 5] fi [5; 5] fi [5; 5]n <ref> [2; 2] </ref> fi [2; 2] fi [2; 2]. 24 Y. CHARLIE HU AND S. LENNART JOHNSSON erence, while a matrix-matrix multiplication (level-3 BLAS) approaches b floating-point operations per memory reference. Since memory bandwidth on most processor architectures is a limiting factor it is highly desirable to use higher level BLAS whenever possible.
Reference: [3] <author> T. Bially. </author> <title> Space-filling curves: Their generation and their application to bandwidth reduction. </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> IT-15:658 - 664, </volume> <month> November </month> <year> 1969. </year>
Reference-contexts: The construction is recursive since after the one-level refinement from (a) to (b), the beginning and ending subdomains denoted by the two black circles are on the same edge as the beginning and ending subdomains before the refinement. finite-state diagrams <ref> [3] </ref> were devised previously. Here we give an elegant recursive algorithm, as illustrated in Figures 5.6 and 5.7. The Hilbert curve can be constructed recursively using self-similar curves as building blocks, and we only need to show one recursion step.
Reference: [4] <author> A. R. Butz. </author> <title> Convergence with hilbert's space filling curve. </title> <journal> J. of Computer and System Sciences, </journal> <volume> 3:128 - 146, </volume> <month> May </month> <year> 1969. </year>
Reference-contexts: The Morton ordering is achieved by constructing keys for sorting the subdomains by interleaving the bits of the subdomains coordinates. The Hilbert ordering traverses only adjacent subdomains and thus gives potentially better locality in computation when used in data partitioning schemes. Complicated algorithms based on bit manipulation <ref> [4] </ref> or DATA PARALLEL OPTIMIZATIONS USING ARRAY ALIASING 19 (a) (b) Fig. 5.6. Recursive construction of Hilbert curve in 2-D using self-similar curves.
Reference: [5] <author> H. Forum. </author> <title> High Performance Fortran; language specification, version 1.0. </title> <journal> Scientific Programming, </journal> <volume> 2(1 - 2):1-170, 1993. DATA PARALLEL OPTIMIZATIONS USING ARRAY ALIASING 33 </volume>
Reference-contexts: 1. Introduction. Data parallel programming provides an effective way to write maintainable, portable, and scalable parallel codes. The proprietary data parallel programming language Connection Machine Fortran (CMF) [10], with many characteristics in common with the emerging data parallel programming language, High Performance Fortran (HPF) <ref> [5] </ref>, has been successfully used in solving many structured and unstructured problems in science and engineering. <p> Thus, for these operations, an inner product (level-1 BLAS) approaches one floating-point operation per memory reference as operand size grows, a matrix-vector multiplication (level-2 BLAS) approaches two floating-point operations per memory ref 2 The 1206 matrices correspond to the 1206 possible relative interactive-field box locations with offsets in <ref> [5; 5] </ref> fi [5; 5] fi [5; 5]n [2; 2] fi [2; 2] fi [2; 2]. 24 Y. CHARLIE HU AND S. LENNART JOHNSSON erence, while a matrix-matrix multiplication (level-3 BLAS) approaches b floating-point operations per memory reference. <p> for these operations, an inner product (level-1 BLAS) approaches one floating-point operation per memory reference as operand size grows, a matrix-vector multiplication (level-2 BLAS) approaches two floating-point operations per memory ref 2 The 1206 matrices correspond to the 1206 possible relative interactive-field box locations with offsets in <ref> [5; 5] </ref> fi [5; 5] fi [5; 5]n [2; 2] fi [2; 2] fi [2; 2]. 24 Y. CHARLIE HU AND S. LENNART JOHNSSON erence, while a matrix-matrix multiplication (level-3 BLAS) approaches b floating-point operations per memory reference. <p> an inner product (level-1 BLAS) approaches one floating-point operation per memory reference as operand size grows, a matrix-vector multiplication (level-2 BLAS) approaches two floating-point operations per memory ref 2 The 1206 matrices correspond to the 1206 possible relative interactive-field box locations with offsets in <ref> [5; 5] </ref> fi [5; 5] fi [5; 5]n [2; 2] fi [2; 2] fi [2; 2]. 24 Y. CHARLIE HU AND S. LENNART JOHNSSON erence, while a matrix-matrix multiplication (level-3 BLAS) approaches b floating-point operations per memory reference.
Reference: [6] <author> L. Greengard and W. D. Gropp. </author> <title> A parallel version of the fast multipole method. </title> <booktitle> In Parallel Processing for Scientific Computing, </booktitle> <pages> pages 213-222. </pages> <publisher> SIAM, </publisher> <year> 1989. </year>
Reference: [7] <author> D. </author> <title> Hilbert. Uber die stetige Abbildung einer Linie auf Flachenstuck. </title> <journal> Math. Annln, </journal> (38):459-460, <volume> 1891. </volume>
Reference-contexts: Hierarchical subdomain orderings, such as Morton [9] or Hilbert <ref> [7] </ref> space filling curves, allow one sorted order to be used for any depth of the hierarchical domain decomposition with the ordering properties preserved from level to level. The Morton ordering is achieved by constructing keys for sorting the subdomains by interleaving the bits of the subdomains coordinates.
Reference: [8] <author> S. L. Johnsson and C.-T. Ho. </author> <title> Spanning graphs for optimum broadcasting and personalized communication in hypercubes. </title> <journal> IEEE Trans. Computers, </journal> <volume> 38(9) </volume> <pages> 1249-1268, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: CHARLIE HU AND S. LENNART JOHNSSON Fig. 5.9. Exploiting symmetry in all-to-all communication. CMF$LAYOUT MASK (:,:,:) DO II = MIN_PTCLPERBOX, MAX_PTCLPERBOX-1 MASK = (II &lt; NUM_PTCLPERBOX) FORALL (I=1:L, J=1:M, K=1:N, MASK (I,J,K)) $ X_4D (II+1,I,J,K) = X (START_PTR (I,J,K)+II) ENDDO 5.4. Exploiting symmetry in all-to-all communication. All-to-all communication <ref> [8] </ref> is a critical operation in several applications, such as the naive (direct) N -body algorithm, but also in molecular dynamics computations where a cut-off radius is used. In such computations, all-to-all interactions take place between all molecules within the cut-off radius of each molecule.
Reference: [9] <author> H. Samet. </author> <title> Design and Analysis of Spatial Data Structures. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Hierarchical subdomain orderings, such as Morton <ref> [9] </ref> or Hilbert [7] space filling curves, allow one sorted order to be used for any depth of the hierarchical domain decomposition with the ordering properties preserved from level to level.
Reference: [10] <institution> Thinking Machines Corp. </institution> <note> CM Fortran Reference Manual, Version 2.1, </note> <year> 1993. </year>
Reference-contexts: 1. Introduction. Data parallel programming provides an effective way to write maintainable, portable, and scalable parallel codes. The proprietary data parallel programming language Connection Machine Fortran (CMF) <ref> [10] </ref>, with many characteristics in common with the emerging data parallel programming language, High Performance Fortran (HPF) [5], has been successfully used in solving many structured and unstructured problems in science and engineering.
Reference: [11] <institution> Thinking Machines Corp. CMSSL for CM Fortran, </institution> <note> Version 3.1, </note> <year> 1993. </year>
Reference-contexts: With respect to the second case, level-1 BLAS can be aggregated into level-3 BLAS, that can be further aggregated into multiple-instance level-3 BLAS. Multiple-instance BLAS is supported in the Connection Machine Scientific Software Library, CMSSL <ref> [11] </ref>. The aggregation from level-1 to level-2 BLAS is made in the problem formulation, while the aggregation into multiple-instance level-3 BLAS is carried out either through aliasing alone, or aliasing in combination with copying of some local arrays.
Reference: [12] <institution> Thinking Machines Corp. </institution> <note> CM Fortran Libraries Reference Manual, version 2.2, </note> <year> 1994. </year>
Reference-contexts: The subgrid equivalencing feature in CMF provides a means of managing memory accesses similar to that of the EQUIVALENCE statement in Fortran 77. In CMF, the array alias variable is declared to have type array descriptor, and the aliasing is created by calling the CMF utility library procedures <ref> [12] </ref>. The aliased array is then passed to a subroutine in which it is declared to be an array with the desired new type, shape, or layout. The following 4 Y. CHARLIE HU AND S.
Reference: [13] <author> F. Zhao. </author> <title> An O(N) algorithm for three-dimensional N-body simulations. </title> <type> Technical Report AI Memo 995, </type> <institution> MIT, Artificial Intelligence Laboratory, </institution> <month> October </month> <year> 1987. </year>
References-found: 13

