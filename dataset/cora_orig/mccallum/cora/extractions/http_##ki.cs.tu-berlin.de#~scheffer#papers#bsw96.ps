URL: http://ki.cs.tu-berlin.de/~scheffer/papers/bsw96.ps
Refering-URL: http://ki.cs.tu-berlin.de/~scheffer/publications.html
Root-URL: 
Title: A Concept Formation Based Algorithmic Model for Skill Acquisition  
Author: Linda Briesemeister Tobias Scheffer Fritz Wysotzki 
Date: October 9, 1996  
Address: FR 5-8, Franklinstr. 28/29, D-10587 Berlin  
Affiliation: Technische Universitat Berlin, Artificial Intelligence Group,  
Abstract: We present an algorithmic model for acquisition of cognitive skills that is based on machine learning and problem solving algorithms. The principle is to use a problem solving approach for new problems that are not covered by the routine knowledge obtained from generalizing previous samples, and to use a machine learning algorithm to generalize these samples to an abstraction of the state space. We show the admissibility of our approach, discuss complexity results and present empirical results for Rubik's cube and a maze problem. 
Abstract-found: 1
Intro-found: 1
Reference: [And93] <author> J.R. Anderson. </author> <title> Rules of the Mind. </title> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction The problem of skill acquisition has been approached from various perspectives, ranging from a psychological, e.g. <ref> [And93] </ref> to a machine learning point of view, e.g. [MC68, BSA83]. While most work on skill acquisition in machine learning focuses on control skills, e.g. [ML892, DBS93], this paper mainly deals with cognitive skills. Known models for cognitive skills include Soar [LNR87] and Act-R [And93]. <p> perspectives, ranging from a psychological, e.g. <ref> [And93] </ref> to a machine learning point of view, e.g. [MC68, BSA83]. While most work on skill acquisition in machine learning focuses on control skills, e.g. [ML892, DBS93], this paper mainly deals with cognitive skills. Known models for cognitive skills include Soar [LNR87] and Act-R [And93].
Reference: [BSA83] <author> A. B. Barto, R. S. Sutton, and C. W. Anderson. </author> <title> Neuronlike adaptive elements that can solve difficult learning control problems. </title> <journal> In IEEE Transactions on Systems, Man, and Cybernetics, </journal> <year> 1983. </year>
Reference-contexts: 1 Introduction The problem of skill acquisition has been approached from various perspectives, ranging from a psychological, e.g. [And93] to a machine learning point of view, e.g. <ref> [MC68, BSA83] </ref>. While most work on skill acquisition in machine learning focuses on control skills, e.g. [ML892, DBS93], this paper mainly deals with cognitive skills. Known models for cognitive skills include Soar [LNR87] and Act-R [And93].
Reference: [DBS93] <author> T. Dean, K. Basye, and J. Shewchuk. </author> <title> Reinforcement learning for planning and control. </title> <editor> In S. Minton, editor, </editor> <title> Machine Learning Methods for Planning, </title> <year> 1993. </year>
Reference-contexts: 1 Introduction The problem of skill acquisition has been approached from various perspectives, ranging from a psychological, e.g. [And93] to a machine learning point of view, e.g. [MC68, BSA83]. While most work on skill acquisition in machine learning focuses on control skills, e.g. <ref> [ML892, DBS93] </ref>, this paper mainly deals with cognitive skills. Known models for cognitive skills include Soar [LNR87] and Act-R [And93].
Reference: [FHN72] <author> R. E. Fikes, P. E. Hart, and N. J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 251-288, </pages> <year> 1972. </year>
Reference-contexts: The main problem of problem solving is the high computational complexity; various approaches to speeding up this process by incorporating some kind of learning algorithm are known: Strips learns macro operators <ref> [FHN72] </ref> that perform "large steps" in the search space, other systems learn evaluation functions, operator strengths, and operator-selection and rejection rules (e. g. Lex [MUB83], Soar [LNR87], Prodigy [Min90]). Concept formation is studied most intensively in both, psychology and artificial intelligence.
Reference: [Gel77] <author> D. Gelperin. </author> <title> On the optimality of A*. </title> <journal> Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 69-76, </pages> <year> 1977. </year>
Reference-contexts: The process of problem solving, e.g. [Nil71], means finding an operator sequence, that maps an initial state to one desired goal state. A number of algorithms with well-defined properties (admissibility, optimality) are known, that can solve this problem, e.g. branch and bound algorithms [NKK84] or A fl <ref> [Nil71, Gel77] </ref>.
Reference: [Hau89] <author> D. Haussler. </author> <title> Learning conjunctive concepts in structural domains. </title> <journal> Machine Learning, </journal> <volume> 4(1) </volume> <pages> 7-40, </pages> <year> 1989. </year>
Reference-contexts: Chunking is a bottom- up learning mechanism based on abstraction from those part of some situation, that are not involved in the focused mental process. From a theoretical point of view, this operational definition is less precise and formal than mathematical models of generalization <ref> [Hau89, Plo70, Sch95a] </ref>. In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation [HMS66] and machine learning, e.g. [UW81], it is often performed by specializing the most general or generalizing the most special hypothesis.
Reference: [HMS66] <author> E. B. Hunt, J. Marin, and P. T. Stone. </author> <title> Experiments in Induction. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: From a theoretical point of view, this operational definition is less precise and formal than mathematical models of generalization [Hau89, Plo70, Sch95a]. In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation <ref> [HMS66] </ref> and machine learning, e.g. [UW81], it is often performed by specializing the most general or generalizing the most special hypothesis.
Reference: [LNR87] <author> J.E. Laird, A. Newell, </author> <title> and P.S. Rosenbloom. Soar: An architecture for general intel-ligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: While most work on skill acquisition in machine learning focuses on control skills, e.g. [ML892, DBS93], this paper mainly deals with cognitive skills. Known models for cognitive skills include Soar <ref> [LNR87] </ref> and Act-R [And93]. <p> Lex [MUB83], Soar <ref> [LNR87] </ref>, Prodigy [Min90]). Concept formation is studied most intensively in both, psychology and artificial intelligence. The objective of concept formation is to find a description of some target concept, that generalizes a set of given positive examples, but does not cover any of the negative examples.
Reference: [LRN86] <author> J.E. Laird, P.S. Rosenbloom, and A. Newell. </author> <title> Chunking in soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 11-46, </pages> <year> 1986. </year>
Reference-contexts: The objective of concept formation is to find a description of some target concept, that generalizes a set of given positive examples, but does not cover any of the negative examples. Many psychological models of learning are based on chunking of production rules, e.g. <ref> [LRN86] </ref>. Chunking is a bottom- up learning mechanism based on abstraction from those part of some situation, that are not involved in the focused mental process. From a theoretical point of view, this operational definition is less precise and formal than mathematical models of generalization [Hau89, Plo70, Sch95a].
Reference: [MC68] <author> D. Michie and A. Chambers. </author> <title> Boxes: An experiment in adaptive control. </title> <booktitle> In Machine Intelligence 2, </booktitle> <year> 1968. </year>
Reference-contexts: 1 Introduction The problem of skill acquisition has been approached from various perspectives, ranging from a psychological, e.g. [And93] to a machine learning point of view, e.g. <ref> [MC68, BSA83] </ref>. While most work on skill acquisition in machine learning focuses on control skills, e.g. [ML892, DBS93], this paper mainly deals with cognitive skills. Known models for cognitive skills include Soar [LNR87] and Act-R [And93].
Reference: [Min90] <author> S. N. Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 363-392, </pages> <year> 1990. </year>
Reference-contexts: Lex [MUB83], Soar [LNR87], Prodigy <ref> [Min90] </ref>). Concept formation is studied most intensively in both, psychology and artificial intelligence. The objective of concept formation is to find a description of some target concept, that generalizes a set of given positive examples, but does not cover any of the negative examples.
Reference: [ML892] <editor> Machine learning. </editor> <volume> vol. </volume> <pages> 8(3-4): </pages> <note> Special issue on reinforcement learning, </note> <year> 1992. </year>
Reference-contexts: 1 Introduction The problem of skill acquisition has been approached from various perspectives, ranging from a psychological, e.g. [And93] to a machine learning point of view, e.g. [MC68, BSA83]. While most work on skill acquisition in machine learning focuses on control skills, e.g. <ref> [ML892, DBS93] </ref>, this paper mainly deals with cognitive skills. Known models for cognitive skills include Soar [LNR87] and Act-R [And93].
Reference: [MMHL86] <author> R. S Michalski, I. Mozetic, J. Hong, and N. Lavrac. </author> <title> The multi-purpose incremental learning system aq15 and its testing application to three medical domains. </title> <booktitle> Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1041-1045, </pages> <year> 1986. </year>
Reference-contexts: In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation [HMS66] and machine learning, e.g. [UW81], it is often performed by specializing the most general or generalizing the most special hypothesis. A number of decision tree [UW81, Qui86, MW92] and rule extraction algorithms <ref> [MMHL86, Sch95b] </ref> perform this task efficiently, if the examples are described propositionally, i.e. in terms of attribute vectors. Propositional concept formation is well understood, a comprising theory is available [Val84]. Muller and Wysotzki [MW95] propose an approach to combining problem solving and concept formation in the context of skill acquisition.
Reference: [MUB83] <author> T. M. Mitchell, P. E. Utgoff, and R. B. Banerji. </author> <title> Learning by experimentation: Acquiring and refining problem-solving heuristics. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine learning: An artificial intelligence approach, </booktitle> <volume> volume 1. </volume> <publisher> Morgan Kaufmann, </publisher> <year> 1983. </year>
Reference-contexts: Lex <ref> [MUB83] </ref>, Soar [LNR87], Prodigy [Min90]). Concept formation is studied most intensively in both, psychology and artificial intelligence. The objective of concept formation is to find a description of some target concept, that generalizes a set of given positive examples, but does not cover any of the negative examples.
Reference: [MW92] <author> Wolfgang Muller and Fritz Wysotzki. </author> <title> Automatic construction of decision trees for classification. </title> <journal> Annalen fur operations Research, </journal> <year> 1992. </year>
Reference-contexts: In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation [HMS66] and machine learning, e.g. [UW81], it is often performed by specializing the most general or generalizing the most special hypothesis. A number of decision tree <ref> [UW81, Qui86, MW92] </ref> and rule extraction algorithms [MMHL86, Sch95b] perform this task efficiently, if the examples are described propositionally, i.e. in terms of attribute vectors. Propositional concept formation is well understood, a comprising theory is available [Val84].
Reference: [MW95] <author> Wolfgang Muller and Fritz Wysotzki. </author> <title> Automatic synthesis of control programs by combination of learning and problem solving methods (extended abstract). </title> <editor> In Nada Lavrac and Stefan Wrobel, editors, </editor> <booktitle> Machine Learning: ECML-95 (Proc. European Conf. on Machine Learning, 1995), Lecture Notes in Artificial Intelligence 912, </booktitle> <pages> pages 323 - 326, </pages> <address> Berlin, Heidelberg, New York, 1995. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: A number of decision tree [UW81, Qui86, MW92] and rule extraction algorithms [MMHL86, Sch95b] perform this task efficiently, if the examples are described propositionally, i.e. in terms of attribute vectors. Propositional concept formation is well understood, a comprising theory is available [Val84]. Muller and Wysotzki <ref> [MW95] </ref> propose an approach to combining problem solving and concept formation in the context of skill acquisition.
Reference: [Nil71] <author> N. Nilsson. </author> <booktitle> Problem Solving in Artificial Intelligence. </booktitle> <publisher> McGraw Hill, </publisher> <year> 1971. </year>
Reference-contexts: Our work is based on combining problem solving in the sense of artificial intelligence with machine learning. The process of problem solving, e.g. <ref> [Nil71] </ref>, means finding an operator sequence, that maps an initial state to one desired goal state. A number of algorithms with well-defined properties (admissibility, optimality) are known, that can solve this problem, e.g. branch and bound algorithms [NKK84] or A fl [Nil71, Gel77]. <p> The process of problem solving, e.g. [Nil71], means finding an operator sequence, that maps an initial state to one desired goal state. A number of algorithms with well-defined properties (admissibility, optimality) are known, that can solve this problem, e.g. branch and bound algorithms [NKK84] or A fl <ref> [Nil71, Gel77] </ref>. <p> It has been implemented in LISP and reimplemented in C++. As problem solver, the A* algorithm <ref> [Nil71] </ref> is used. This algorithm finds an optimal solution, if a solution exists. As incremental learner, the Cal2 learning algorithm [UW81], pp. 25 has been chosen. It induces classification rules which are expressed in form of a decision tree.
Reference: [NKK84] <author> D. S. Nau, V. Kumar, and L. Kanal. </author> <title> General branch and bound and its relation to A* and AO*. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 29-58, </pages> <year> 1984. </year>
Reference-contexts: The process of problem solving, e.g. [Nil71], means finding an operator sequence, that maps an initial state to one desired goal state. A number of algorithms with well-defined properties (admissibility, optimality) are known, that can solve this problem, e.g. branch and bound algorithms <ref> [NKK84] </ref> or A fl [Nil71, Gel77].
Reference: [Plo70] <author> G. D. Plotkin. </author> <title> A note on inductive generalization. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 5, </volume> <pages> pages 153-163, </pages> <year> 1970. </year>
Reference-contexts: Chunking is a bottom- up learning mechanism based on abstraction from those part of some situation, that are not involved in the focused mental process. From a theoretical point of view, this operational definition is less precise and formal than mathematical models of generalization <ref> [Hau89, Plo70, Sch95a] </ref>. In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation [HMS66] and machine learning, e.g. [UW81], it is often performed by specializing the most general or generalizing the most special hypothesis.
Reference: [Qui86] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1), </volume> <year> 1986. </year>
Reference-contexts: In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation [HMS66] and machine learning, e.g. [UW81], it is often performed by specializing the most general or generalizing the most special hypothesis. A number of decision tree <ref> [UW81, Qui86, MW92] </ref> and rule extraction algorithms [MMHL86, Sch95b] perform this task efficiently, if the examples are described propositionally, i.e. in terms of attribute vectors. Propositional concept formation is well understood, a comprising theory is available [Val84].
Reference: [Sch95a] <editor> T. Scheffer. Beschreibungsunabhangiges Lernen und Generalisieren. In K. Morik and J. Hermann, editors, </editor> <booktitle> Beitrage zur Fachtagung Maschinelles Lernen, </booktitle> <year> 1995. </year>
Reference-contexts: Chunking is a bottom- up learning mechanism based on abstraction from those part of some situation, that are not involved in the focused mental process. From a theoretical point of view, this operational definition is less precise and formal than mathematical models of generalization <ref> [Hau89, Plo70, Sch95a] </ref>. In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation [HMS66] and machine learning, e.g. [UW81], it is often performed by specializing the most general or generalizing the most special hypothesis.
Reference: [Sch95b] <author> T. Scheffer. </author> <title> Learning rules with nested exceptions. </title> <booktitle> In Proc. International Workshop on Artificial Intelligence Techniques, </booktitle> <address> Brno, Czech Republic, </address> <year> 1995. </year>
Reference-contexts: In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation [HMS66] and machine learning, e.g. [UW81], it is often performed by specializing the most general or generalizing the most special hypothesis. A number of decision tree [UW81, Qui86, MW92] and rule extraction algorithms <ref> [MMHL86, Sch95b] </ref> perform this task efficiently, if the examples are described propositionally, i.e. in terms of attribute vectors. Propositional concept formation is well understood, a comprising theory is available [Val84]. Muller and Wysotzki [MW95] propose an approach to combining problem solving and concept formation in the context of skill acquisition.
Reference: [UW81] <editor> S. Unger and F. Wysotzki. Lernfahige Klassifizierungssysteme. </editor> <publisher> Akademie Verlag Berlin, </publisher> <year> 1981. </year>
Reference-contexts: From a theoretical point of view, this operational definition is less precise and formal than mathematical models of generalization [Hau89, Plo70, Sch95a]. In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation [HMS66] and machine learning, e.g. <ref> [UW81] </ref>, it is often performed by specializing the most general or generalizing the most special hypothesis. A number of decision tree [UW81, Qui86, MW92] and rule extraction algorithms [MMHL86, Sch95b] perform this task efficiently, if the examples are described propositionally, i.e. in terms of attribute vectors. <p> In fl e-mail: xantippe@cs.tu-berlin.de y e-mail: scheffer@cs.tu-berlin.de other psychological models of concept formation [HMS66] and machine learning, e.g. [UW81], it is often performed by specializing the most general or generalizing the most special hypothesis. A number of decision tree <ref> [UW81, Qui86, MW92] </ref> and rule extraction algorithms [MMHL86, Sch95b] perform this task efficiently, if the examples are described propositionally, i.e. in terms of attribute vectors. Propositional concept formation is well understood, a comprising theory is available [Val84]. <p> It has been implemented in LISP and reimplemented in C++. As problem solver, the A* algorithm [Nil71] is used. This algorithm finds an optimal solution, if a solution exists. As incremental learner, the Cal2 learning algorithm <ref> [UW81] </ref>, pp. 25 has been chosen. It induces classification rules which are expressed in form of a decision tree. As it operates on discrete valued attributes, our system can only solve problems in a discrete problem space. Cal2 requires disjoint classes.
Reference: [Val84] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: A number of decision tree [UW81, Qui86, MW92] and rule extraction algorithms [MMHL86, Sch95b] perform this task efficiently, if the examples are described propositionally, i.e. in terms of attribute vectors. Propositional concept formation is well understood, a comprising theory is available <ref> [Val84] </ref>. Muller and Wysotzki [MW95] propose an approach to combining problem solving and concept formation in the context of skill acquisition.
References-found: 24

