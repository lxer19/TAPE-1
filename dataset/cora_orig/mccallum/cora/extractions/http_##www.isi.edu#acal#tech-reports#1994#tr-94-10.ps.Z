URL: http://www.isi.edu/acal/tech-reports/1994/tr-94-10.ps.Z
Refering-URL: http://www.isi.edu/acal/tech-reports/index.html
Root-URL: http://www.isi.edu
Title: Co-Synthesis of Instruction Sets  
Author: and Microarchitectures Ing-Jer Huang 
Keyword: application specific instruction set processor, instruction set design, resource allocation, code generation  
Note: August 1994  
Address: ACAL-TR-94-10  
Affiliation: Advanced Computer Architecture Laboratory  
Abstract: The design of an instruction set processor includes several related design tasks: instruction set design, microarchitecture design, and code generation. Although there have been automatic approaches for each individual task, the investigation of the interaction between these tasks still primarily relies on designers experience and ingenuity. It is thus the goal of this research to develop formal models and algorithms to investigate such interaction systematically. This dissertation presents a two-phase co-synthesis approach to the problem. In the architectural level, given a set of application benchmarks and a pipeline structure, the ASIA (Automatic Synthesis of Instruction set Architecture) design automation system generates an instruction set and allocates hardware resources which best fit the applications, and, at the same time, maps the applications to assembly code with the synthesized instruction set. This approach formulates the co-design problem as a modified scheduling/allocation problem. A simulated annealing algorithm is used to solve the problem. Following ASIA, the microarchitectural-level design automation system PIPER accepts the instruction set architecture specification and generates a pipelined microarchitecture which implements the instruction set, and a reordering table which guides the compiler backend (reorderer). This approach relies on an extended taxonomy of inter-instruction dependencies and the associated hardware/software resolutions. The techniques are demonstrated with both illustrative and practical experiments. The results show that the techniques are capable of synthesizing instruction set processors that are as good as or better than the manually-designed instruction set architecture VLSI-BAM in application-specific environments, based on a design metric consisting of the instruction set size, cycle count and hardware resources. In addition, these techniques can be used to characterize architectural properties of application benchmarks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Alauddin Alomary, et al., PEAS-I: </editor> <title> A Hardware/Software Co-design System for ASIPs, </title> <booktitle> Proc. of EURO-DAC, </booktitle> <year> 1993 </year>
Reference-contexts: T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc. K. & S. [50], Praet et al. [68], PEAS-I <ref> [1] </ref> ASIA PIPER HARDWARE Architectural model ++ ++ ++ ++ ++ ++ Control path - -- Data path ++/x ++ - - - -- Chip area - Cycle count --/x - - - -- Cycle time Power dissipation INTERFACE Instruction semantics -- ++ ++ - -- ++ Instruction format -- ++
Reference: [2] <editor> Alauddin Alomary, et al., </editor> <title> An ASIP Instruction Set Optimization Algorithm with Functional Module Sharing Constraint, </title> <booktitle> Proc. of the International Conference on Computer-Aided Designs, </booktitle> <month> Nov. </month> <year> 1993 </year>
Reference-contexts: The design problem is then expressed as selecting the best implementation methods for BRTLs and XRTLs such that performance/cost is optimized for the given application. A formal definition of the problem and its branch-and-bound solver are given in <ref> [2] </ref>. 29 Like most of the related work, our approach synthesizes instructions from the given application, instead of customizing from a super set. <p> or constraint to the design automation system --: primary output of the design automation system -: secondary output, or side-effect of the primary output of the design automation system Design Objects & Metrics Instruction Set Synthesis * Code Generation m-architecture Synthesis Combined Approaches Haney [29], Bose [4], Bennett [5], PEAS <ref> [2] </ref>, Holmer [36] Cattell [10], Graham [28], Giegerich [26], C. & L. [13], S. T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc.
Reference: [3] <author> Alfred V. Aho, Ravi Sethi and Jeffrey D. Ullman, </author> <booktitle> Compilers: Principles, Techniques, and Tools, </booktitle> <address> Adison-Wesley, </address> <year> 1985 </year>
Reference: [4] <author> Pradip Bose and Edward S. Davidson, </author> <title> Design of Instruction Set Architectures for Support of High-Level Languages, </title> <booktitle> Proc. of the 11th Annual International Symposium on Computer Architecture, </booktitle> <year> 1984 </year>
Reference-contexts: Instructions were not restricted to single-cycle instructions since multi-cycle instructions can be supported through micro-programming (firmware). Without knowing the decode/control complexity, the focus was mainly in directly supporting high level languages or increasing the code density. The results were CISC-like instructions. These studies include Haneys [29], Boses <ref> [4] </ref> and Bennetts [6] work. These techniques are not suitable for designing instruction sets for modern pipelined processors. Sato et al. [72] proposed an integrated design framework for application specific instruction set processors. This framework generates profiling information from a given set of application benchmarks and their expected data. <p> +: secondary input specification or constraint to the design automation system --: primary output of the design automation system -: secondary output, or side-effect of the primary output of the design automation system Design Objects & Metrics Instruction Set Synthesis * Code Generation m-architecture Synthesis Combined Approaches Haney [29], Bose <ref> [4] </ref>, Bennett [5], PEAS [2], Holmer [36] Cattell [10], Graham [28], Giegerich [26], C. & L. [13], S. T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc.
Reference: [5] <author> J. P. Bennett, </author> <title> Automated Design of an Instruction Set for BCPL, </title> <type> Technical Report 93, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <year> 1986 </year>
Reference-contexts: The design space of this approach is constrained by the given instruction set specification. On the other hand, design automation systems such as <ref> [5] </ref> and [36] address the instruction set design phase in Figure 1.2. These systems accept a set of application benchmarks, a given microarchitecture and instruction format constraints, and produce a best instruction set according to the given objective function. <p> input specification or constraint to the design automation system --: primary output of the design automation system -: secondary output, or side-effect of the primary output of the design automation system Design Objects & Metrics Instruction Set Synthesis * Code Generation m-architecture Synthesis Combined Approaches Haney [29], Bose [4], Bennett <ref> [5] </ref>, PEAS [2], Holmer [36] Cattell [10], Graham [28], Giegerich [26], C. & L. [13], S. T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc.
Reference: [6] <author> J. P. Bennett, </author> <title> A Methodology for Automated Design of Computer Instruction Sets, </title> <type> Ph.D. thesis, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <year> 1988. </year> <note> Also available as Technical Report 129 </note>
Reference-contexts: Without knowing the decode/control complexity, the focus was mainly in directly supporting high level languages or increasing the code density. The results were CISC-like instructions. These studies include Haneys [29], Boses [4] and Bennetts <ref> [6] </ref> work. These techniques are not suitable for designing instruction sets for modern pipelined processors. Sato et al. [72] proposed an integrated design framework for application specific instruction set processors. This framework generates profiling information from a given set of application benchmarks and their expected data.
Reference: [7] <author> Mauricio Breternitz Jr. and John Paul Shen, </author> <title> Architecture Synthesis of High-Performance Application-Specific Processors, </title> <booktitle> Proceedings Design Automation Conference, </booktitle> <year> 1990 </year>
Reference-contexts: Two branches of CAD tool development are related to instruction set processor design. High level (behavioral) synthesis for instruction set processors corresponds to the microarchitecture design phase in generates the microarchitecture implementation at the register transfer level (RTL). <ref> [7] </ref> 5 and [15] are examples of such an approach. The design space of this approach is constrained by the given instruction set specification. On the other hand, design automation systems such as [5] and [36] address the instruction set design phase in Figure 1.2. <p> Therefore, it can be concluded that these techniques are not suitable for synthesis of pipelined instruction set processors. ASPD uses a VLIW-based architecture as the hardware template, and applies percolation scheduling and pipeline scheduling to explore the fine grain parallelism <ref> [7] </ref>. The system performs the design task in two phases: specification optimization and implementation optimization. In the first phase the above scheduling algorithms are used to generate the application micro-code. The VLIW template is customized in the second phase. <p> T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD <ref> [7] </ref>, etc. <p> Third, The number of dependencies to be resolved grows fast when the instruction initiation latency is decreased. This is because that the higher the degree of pipelin *. Synthesized by ASPD <ref> [7] </ref> 149 ing, the larger the number of pipeline stages; the larger the number of pipeline stages, the more interactions between stages. Fourth, adopting more hardware resolutions does not necessarily reduce the number of reordering constraints.
Reference: [8] <author> Bill Bush, et al., </author> <title> The Berkeley Abstract Machine Instruction Manual, </title> <type> Internal Technical Report, </type> <institution> Advanced Computer Architecture Laboratory, University of Southern California, </institution> <year> 1990 </year>
Reference-contexts: The width of the instruction word and field types is specified by the designer. Table 4.1 lists the specification of some instruction field types and their bit widths, taken from the BAM instruction set <ref> [8] </ref>. Each instruction has one opcode field, but the use of other fields is constrained only by the total number of bits needed by the operations in the instruction.
Reference: [9] <author> William Bush et al., </author> <title> An Advanced Silicon Compiler in Prolog, </title> <booktitle> Proceedings International Conference on Computer Aided Design, </booktitle> <year> 1987 </year>
Reference: [10] <author> R. G. G. Cattell, </author> <title> Automatic Derivation of Code Generators from Machine Description, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 2, No. 2, </volume> <month> April </month> <year> 1980 </year>
Reference-contexts: design automation system --: primary output of the design automation system -: secondary output, or side-effect of the primary output of the design automation system Design Objects & Metrics Instruction Set Synthesis * Code Generation m-architecture Synthesis Combined Approaches Haney [29], Bose [4], Bennett [5], PEAS [2], Holmer [36] Cattell <ref> [10] </ref>, Graham [28], Giegerich [26], C. & L. [13], S. T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc.
Reference: [11] <author> Mike Carlton, </author> <title> Source codes of the Aquarius Prolog Compiler (Back-end), </title> <institution> University of California, Berkeley, </institution> <year> 1991 </year>
Reference: [12] <author> Albert E. Casavant, </author> <title> MIST-A Design Aid for Programmable Pipelined Processors, </title> <booktitle> Proc. of the 31st Design Automation Conference, </booktitle> <month> June </month> <year> 1994 </year> <month> 162 </month>
Reference: [13] <author> Wei-Kai Cheng and Youn-Long Lin, </author> <title> Code Generation for a DSP Processor, </title> <booktitle> to appear in Proc. of Intl Symposium on High Level Synthesis, </booktitle> <month> May </month> <year> 1994 </year>
Reference-contexts: design automation system -: secondary output, or side-effect of the primary output of the design automation system Design Objects & Metrics Instruction Set Synthesis * Code Generation m-architecture Synthesis Combined Approaches Haney [29], Bose [4], Bennett [5], PEAS [2], Holmer [36] Cattell [10], Graham [28], Giegerich [26], C. & L. <ref> [13] </ref>, S. T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc.
Reference: [14] <author> Gino Cheng et al., </author> <title> Advanced Design Automation System for Microprocessors, </title>
Reference: [15] <author> Richard Cloutier and Donald Thomas, </author> <title> Synthesis of Pipelined Instruction Set Processors, </title> <booktitle> Proc. of the 30th Design Automation Conference, </booktitle> <year> 1993 </year>
Reference-contexts: Two branches of CAD tool development are related to instruction set processor design. High level (behavioral) synthesis for instruction set processors corresponds to the microarchitecture design phase in generates the microarchitecture implementation at the register transfer level (RTL). [7] 5 and <ref> [15] </ref> are examples of such an approach. The design space of this approach is constrained by the given instruction set specification. On the other hand, design automation systems such as [5] and [36] address the instruction set design phase in Figure 1.2.
Reference: [16] <author> M. Corazao, et al., </author> <title> Instruction Set Mapping for Performance Optimization, </title> <booktitle> Proc. of ICCAD, </booktitle> <month> Nov. </month> <year> 1993 </year>
Reference: [17] <author> H. J. Curnow and B. A. Wichmann, </author> <title> A Synthetic Benchmark, </title> <journal> The Computer J., </journal> <volume> 19:1, </volume> <year> 1976 </year>
Reference-contexts: This is shown in Figure 1.2. For example, such a design example can be found in [25]. Several benchmark sets such as SPEC [73], Livermore Loops [58], Whestone <ref> [17] </ref> and the Prolog benchmark suite [30] have been proposed to evaluate computer ISAs. Therefore, when designing a good instruction set processor, features in the instruction set, microarchitecture and the compiler backend are chosen under cost constraints.
Reference: [18] <author> Subrata Dasgupta, </author> <title> Computer Architecture A Modern Synthesis, Volume 1, </title> <publisher> John Wiley & Sons, </publisher> <year> 1989 </year>
Reference: [19] <author> Subrata Dasgupta, </author> <title> Computer Architecture A Modern Synthesis, Volume 2, </title> <publisher> John Wiley & Sons, </publisher> <year> 1989 </year>
Reference-contexts: Microarchi-tectures and instruction sets are interdependent entities in the following senses. 1. The term microarchitecture is used by some to denote a class of micro-programmed hardware organization, for example in <ref> [19] </ref>, whereas some others, for example in [32], use it in a more general sense such as the one employed in this text. Computing System Environment: applications, technology, etc. Physical Micro-Arch Machine Instruction Set Software 2 1.
Reference: [20] <author> Subrata Dasgupta, </author> <booktitle> Design Theory and Computer Science, </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1991 </year>
Reference: [21] <editor> Alvin Despain et al., Aquarius, </editor> <booktitle> Computer Architecture News, </booktitle> <month> March, </month> <year> 1987 </year>
Reference: [22] <author> Alvin Despain, </author> <title> The Design System (ASP) of the Aquarius Project, </title> <booktitle> Proceedings of the Second International Workshop on VLSI Design, </booktitle> <month> December, </month> <year> 1988 </year>
Reference-contexts: The new ADAS is an extension over the original ADAS [69], which was an improvement of the ASP design automation system <ref> [22] </ref>. 33 ADAS spans many levels of design abstraction: architectural, microarchitectural (behavioral), logic and circuit, and physical (geometric) domains. Figure 3.1 shows the hierarchy of the new ADAS and corresponding design tools. The dashed line shows the design entry point of the original ADAS.
Reference: [23] <author> Srinivas Devadas and Richard Newton, </author> <title> Algorithms for Hardware Allocation in Data Path Synthesis, </title> <journal> IEEE Trans. on Computer-Aided Design, </journal> <volume> Vol. 8, No. 7, </volume> <month> July </month> <year> 1989 </year>
Reference-contexts: This is similar to the problem formulation in <ref> [23] </ref>. For each time step, the required hardware resources are the total of the resources consumed by each MOP scheduled into the time step, minus the resources that are shared. The sharing of resources in a time step is due to the operand encoding.
Reference: [24] <author> J. A. Fisher, </author> <title> Trace Scheduling: A Technique for Global Microcode Compaction, </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. 30, No. 7, </volume> <year> 1981 </year>
Reference: [25] <author> D. Gifford and A. Spector, </author> <title> Case Study: </title> <journal> IMBs system360-370 Architecture,, Communications of the ACM, </journal> <volume> 30(4) </volume> <pages> 292-307, </pages> <month> April </month> <year> 1987 </year>
Reference-contexts: This is shown in Figure 1.2. For example, such a design example can be found in <ref> [25] </ref>. Several benchmark sets such as SPEC [73], Livermore Loops [58], Whestone [17] and the Prolog benchmark suite [30] have been proposed to evaluate computer ISAs. Therefore, when designing a good instruction set processor, features in the instruction set, microarchitecture and the compiler backend are chosen under cost constraints.
Reference: [26] <author> Robert Giegerich, </author> <title> A Formal Framework for the Derivation of Machine-Specific Optimizers, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 25 No. 3, </volume> <month> July </month> <year> 1983 </year>
Reference-contexts: The machine-dependent information is usually kept in tabular formats. The machine-dependent information is derived from a machine description. Cattells and Grahams works focus on the generation of code-generators [10][28], while Giegerichs work is on the derivation of machine-specific opti-mizers <ref> [26] </ref>. They derive their machine-dependent tables from instruction set semantics which describes the instruction formats, addressing modes, and operations. However, the micro-architectural features such as pipeline configuration are not considered in these systems. <p> primary output of the design automation system -: secondary output, or side-effect of the primary output of the design automation system Design Objects & Metrics Instruction Set Synthesis * Code Generation m-architecture Synthesis Combined Approaches Haney [29], Bose [4], Bennett [5], PEAS [2], Holmer [36] Cattell [10], Graham [28], Giegerich <ref> [26] </ref>, C. & L. [13], S. T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc.
Reference: [27] <author> Gert Goossens, Jan Rabaey, Joos Vandewalle and Hugo De Man, </author> <title> An Efficient Microcode Compiler for Application Specific DSP Processors, </title> <journal> IEEE Trans. on Computer-Aided Design, </journal> <volume> Vol. 9, No. 9, </volume> <month> September </month> <year> 1990 </year> <month> 163 </month>
Reference-contexts: These two systems do not work with applications which exhibit loop carried dependencies. PLS and CATHEDRAL II are capable of working on applications with LCDs by means of an iterative folding algorithm [46] and loop folding algorithm <ref> [27] </ref>, respectively. Both systems adopt an iterative approach to find the MAL. This MAL then serves as the upper bound of the performance of the synthesized designs. The major application domain of the above synthesis systems is digital signal processors (DSP).
Reference: [28] <author> S. L. Graham, </author> <title> Table-Driven Code Generation, </title> <booktitle> IEEE Computer, </booktitle> <month> August </month> <year> 1980 </year>
Reference-contexts: system --: primary output of the design automation system -: secondary output, or side-effect of the primary output of the design automation system Design Objects & Metrics Instruction Set Synthesis * Code Generation m-architecture Synthesis Combined Approaches Haney [29], Bose [4], Bennett [5], PEAS [2], Holmer [36] Cattell [10], Graham <ref> [28] </ref>, Giegerich [26], C. & L. [13], S. T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc.
Reference: [29] <author> F. M. Haney, </author> <title> ISDS-A program that designs computer instruction sets, </title> <booktitle> Fall Joint Computer Conference, </booktitle> <year> 1969 </year>
Reference-contexts: Instructions were not restricted to single-cycle instructions since multi-cycle instructions can be supported through micro-programming (firmware). Without knowing the decode/control complexity, the focus was mainly in directly supporting high level languages or increasing the code density. The results were CISC-like instructions. These studies include Haneys <ref> [29] </ref>, Boses [4] and Bennetts [6] work. These techniques are not suitable for designing instruction sets for modern pipelined processors. Sato et al. [72] proposed an integrated design framework for application specific instruction set processors. <p> automation system +: secondary input specification or constraint to the design automation system --: primary output of the design automation system -: secondary output, or side-effect of the primary output of the design automation system Design Objects & Metrics Instruction Set Synthesis * Code Generation m-architecture Synthesis Combined Approaches Haney <ref> [29] </ref>, Bose [4], Bennett [5], PEAS [2], Holmer [36] Cattell [10], Graham [28], Giegerich [26], C. & L. [13], S. T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc.
Reference: [30] <author> R. Haygood, </author> <title> A Prolog Benchmark Suite for Aquarius, </title> <type> Technical Report, </type> <institution> UCB/ CSD 89/509, University of California, Berkeley, </institution> <year> 1989 </year>
Reference-contexts: This is shown in Figure 1.2. For example, such a design example can be found in [25]. Several benchmark sets such as SPEC [73], Livermore Loops [58], Whestone [17] and the Prolog benchmark suite <ref> [30] </ref> have been proposed to evaluate computer ISAs. Therefore, when designing a good instruction set processor, features in the instruction set, microarchitecture and the compiler backend are chosen under cost constraints. These design options have to be tuned toward the representative application benchmarks and the intended application environment. <p> Four benchmarks were selected from the Prolog Benchmark suite <ref> [30] </ref>. The benchmarks con3 and nreverse are pro grams for list manipulation. The benchmark query is a program for database query. The benchmark circuit maps boolean equations into logic gates. <p> The number of movements tried at each temperature point is 5*(# of MOPs). The next temperature is 90% of the current temperature. The experiments were conducted on a HP 750 workstation with 256M memory. Four symbolic applications were selected from the Prolog benchmark suite <ref> [30] </ref>. hanoi_8 is the hanoi problem solver. con3 concatenates two strings into one string. 3.
Reference: [31] <author> John Hennessy and Thomas Gross, </author> <title> Postpass Code Optimization of Pipeline Constraints, </title> <booktitle> ACM Tran. on Programming Languages and Systems, </booktitle> <month> July </month> <year> 1983, </year> <pages> pp. 422-448 </pages>
Reference-contexts: For example, a straightforward implementation of the reor-derer (compiler back-end) described in <ref> [31] </ref> has time and space complexities proportional to the size of the reorder table (the number of reorder constraints).
Reference: [32] <author> John L. Hennessy and David A. Patterson, </author> <title> Computer Architecture A Quantitative Approach, </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990, </year> <pages> pp. 257-278 </pages>
Reference-contexts: Microarchi-tectures and instruction sets are interdependent entities in the following senses. 1. The term microarchitecture is used by some to denote a class of micro-programmed hardware organization, for example in [19], whereas some others, for example in <ref> [32] </ref>, use it in a more general sense such as the one employed in this text. Computing System Environment: applications, technology, etc. Physical Micro-Arch Machine Instruction Set Software 2 1. <p> A delay load refers to the load instruction whose data to be loaded is not ready for the following instruction in the pipeline <ref> [32] </ref>. 26 or jump is decoded, regardless whether the succeeding instructions are dependent instructions or not. This approach leaves no room for compilers to utilize the ushed (idle) cycles.
Reference: [33] <author> John Hennessy, Norman Jouppi, Steven Prezybylski, Christopher Rowen, and Thomas Gross, </author> <title> Design of a High Performance VLSI Processor, </title> <booktitle> Third Caltech Conference on VLSI, </booktitle> <pages> page 33, </pages> <year> 1983 </year>
Reference: [34] <author> John L. Hennessy and David A. Patterson, </author> <title> Computer Architecture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann publishers, </publisher> <year> 1990 </year>
Reference: [35] <author> Bruce Holmer, et al., </author> <title> Fast Prolog with an Extended General Purpose Architecture, </title> <booktitle> Proc. of 27th International Symposium on Computer Architecture, </booktitle> <year> 1990 </year>
Reference-contexts: The supported MOPs describe the functionality sup ported in the microarchitecture, and the connectivity among modules in the data path. For example, the first two columns of Table 4.2 list some of the MOPs supported in the VLSI-BAM microprocessor <ref> [35] </ref> and their corresponding MOP type IDs. The pipeline configuration IF-ID-R-A/M-W in Figure 4.3 (c) can be derived by eliminating the MOPs rmd, mrd and mrad from Table 4.2. *. The operator ^ appends a tag to a value before the value is sent to a destination. . <p> For example, multiple-word memory access with a single address is a way to increase memory data bandwidth while consuming limited addressing bandwidth. This feature has been proved as an effective way to increase performance of Prolog applications <ref> [35] </ref>. (2) The complication between data and control dependencies have not been considered yet. For example, the value of the program counter may be stored into a general purpose register for further data manipulation, e.g. addition.
Reference: [36] <author> Bruce Holmer, </author> <title> Automatic Design of Computer Instruction Sets, </title> <type> Ph.D. thesis, </type> <institution> Univ. of California, Berkeley, </institution> <year> 1992 </year>
Reference-contexts: The design space of this approach is constrained by the given instruction set specification. On the other hand, design automation systems such as [5] and <ref> [36] </ref> address the instruction set design phase in Figure 1.2. These systems accept a set of application benchmarks, a given microarchitecture and instruction format constraints, and produce a best instruction set according to the given objective function. <p> On the other hand, Sato et al. generate instruction sets by customizing a super set, whereas we synthesize the instruction sets directly in order to find new and useful instructions for the given application domain. Unlike previous approaches, Holmer <ref> [36] </ref> focused on generating instruction sets which closely couple to the underlying micro-architecture. As pipelined micro-architecture proved its superiority in 1980s, Holmer adopted the modern pipeline control model (data stationary control) and simple, parameterized data path as the underlying micro-architecture model. <p> Techniques in high level synthesis, such as scheduling and allocation, become attractive alternatives to code generation for these DSP cases. 2.6 Combined Approaches The need to closely examine the problems of MS, ISS and ISM for instruction set processors has been noted by researchers, e.g., <ref> [36] </ref> and [66]. The most common way to solve the problems is the use of current tools with some iterative approaches. In Kitabatake and Shirais approach [50], the application is translated to an intermediate representation which is simulated. <p> to the design automation system --: primary output of the design automation system -: secondary output, or side-effect of the primary output of the design automation system Design Objects & Metrics Instruction Set Synthesis * Code Generation m-architecture Synthesis Combined Approaches Haney [29], Bose [4], Bennett [5], PEAS [2], Holmer <ref> [36] </ref> Cattell [10], Graham [28], Giegerich [26], C. & L. [13], S. T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc. <p> An objective function is thus required to balance the tradeoff between performance and cost. The techniques used in step 1 and 2 are based on the idea of state-pairs described by Holmer in <ref> [36] </ref> and thus will not be further discussed in this dissertation. Interested readers may refer to his dissertation for more information. <p> An interesting objective function suitable for our purpose is the following equation. Objective = (100/P)ln (C) + S EQ 1 This is an integral form, derived by Holmer in <ref> [36] </ref>, of the statement a new instruction will be accepted if it provides a P% performance improvement, which tries to balance the instruction set size with the performance gain. Other types of objective functions can be used with the design system as well. <p> register-file read port) + C 4 (# of register-file write ports) + C 5 (# of memory ports) + C 6 (# of functional units) EQ 5 k (S) = C 7 ln (S) EQ 6 The natural logarithmic form of EQ 3 (EQ 6) is suggested by Holmer in <ref> [36] </ref> as a way to balance the tradeoff between the instruction set size and the execution time (static code size). <p> The application benchmark con3 listed in Figure 8.1 on page 123 is used to customized the instruction set. 8.3.1 Complete segments for Prolog To ensure completeness of the synthesized instruction set, special code segments, which were used by Holmer in Table 8.3 of his dissertation <ref> [36] </ref> for the same purpose, are included in the given application. The special code segments contain a subset of the VLSI-BAM instruction set which is known to be complete for Prolog execution. The complete segments are given in Figure 8.3, with each segment separated by the predicate label. <p> Qualitative comparison, such as the input/out behavior, problem formulation, machine model, has been given in Section 2.3 on page 21, Section 2.6 on page 27 and Section 2.7 on page 29. In this section, quantitative comparison is performed for ASIA and Holmers work <ref> [36] </ref> since they are the closest approaches among related work. Algorithm speed. Holmers approach generates instructions by executing the simulator of the microarchitecture. The execution of the simulator is one of the major overhead of his approach. <p> According to previous paragraph, each iteration of ASIA running under hardware resource constraints is about seven times faster. Therefore, the co-synthesis approach 6. The largest experiment conducted by Holmer is the 279 segments in page 160 of <ref> [36] </ref>. The average size of the segments is 3.29. His algorithm processed the 279*3.29 (918) cycles of instructions with more than one week of computation (according to a private conversation with Holmer). <p> As for ASIA, due to the lack of profiling tools, precise cycle counts can be obtained only for small benchmarks whose profiles can be manually derived. 7. See paragraph 5 in page 167 of <ref> [36] </ref>. 8. using the same data path as VLSI-BAM except no support for double word memory access and three way branch 141 According to Figure 8.4 on page 134 (b), the cycle counts (normalized to VLSI-BAMs) of instruction sets synthesized by ASIA for the string concatenation program range from 0.85 (with
Reference: [37] <author> Bruce Holmer and Alvin Despain, </author> <title> Viewing Instruction Set Design as an Optimization Problem, </title> <booktitle> Proc. of Micro-24, </booktitle> <year> 1991 </year>
Reference: [38] <author> Bruce Holmer and Barry Pangrle, </author> <title> Hardware/Software Codesign Using Automated Instruction Set Design & Processor Synthesis, </title> <booktitle> Proc. of Hardware/Software Codesign Workshop, </booktitle> <year> 1993 </year>
Reference-contexts: However, due to the lack of reference, we are not sure how such interactions are handled in this approach. Holmer and Pangrle propose the iteration between the instruction set design tool Alchemy and a high level synthesis tool SandS <ref> [38] </ref>. An initial data path model and its timing parameters are given to Alchemy which generates the initial instruction set from the model. The generated instruction set specification is then taken by SandS which 28 synthesizes both the detailed data path and control path, considering pipelining.
Reference: [39] <author> Ing-Jer Huang and Alvin Despain, </author> <title> High Level Synthesis of Pipelined Instruction Set Processors and Back-End Compilers, </title> <booktitle> Proc. of the 29th DAC, </booktitle> <year> 1992 </year>
Reference: [40] <author> Ing-Jer Huang and Alvin Despain, </author> <title> An Extended Classification of Inter-instruction Dependency and Its Application in Automatic Synthesis of Pipelined Processors, </title> <booktitle> Proc. of the 26th International Symposium on Microarchitectures, </booktitle> <month> Nov. </month> <year> 1993 </year>
Reference: [41] <author> Ing-Jer Huang and Alvin Despain, </author> <title> Hardware/Software Resolution of Pipeline Hazards in Instruction Set Processors, </title> <booktitle> Proc. of the International Conference on Computer-Aided Design, </booktitle> <month> Nov. </month> <year> 1993 </year> <month> 164 </month>
Reference: [42] <author> Ing-Jer Huang, Bruce Holmer and Alvin Despain, </author> <title> ASIA: Automatic Synthesis of Instruction-set Architectures, </title> <booktitle> Proc. of SASIMI Workshop, </booktitle> <address> Nara, Japan, </address> <month> Oct. </month> <year> 1993 </year>
Reference: [43] <author> Ing-Jer Huang and Alvin Despain, </author> <title> Synthesis of Application Specific Instruction Sets, </title> <journal> accepted for the IEEE Trans. on CAD, </journal> <year> 1994 </year>
Reference: [44] <author> Ing-Jer Huang and Alvin Despain, </author> <title> Synthesis of Instruction Sets for Pipelined Microprocessors, </title> <booktitle> Proc. of the 31st Design Automation Conference, </booktitle> <month> June </month> <year> 1994 </year>
Reference-contexts: This action is adopted because we observed in our early experiments with the prototype <ref> [44] </ref> of the algorithm that the simulated annealing process sometimes was not able to reach an equivalent or better state after it jumped out of a local best state. 5.3 Extension for Microarchitecture Design The previous formulation can be extended to synthesize the microarchitecture at the same time, with the introduction
Reference: [45] <author> Ing-Jer Huang and Alvin Despain, </author> <title> Generating Instruction Sets and Microarchi-tectures from Applications, </title> <booktitle> accepted to the International Conference on Computer-Aided Design, </booktitle> <month> April </month> <year> 1994 </year>
Reference: [46] <author> Cheng-Tsung Hwang et al., </author> <title> Scheduling for Functional Pipelining and Loop Winding, </title> <booktitle> Proc. 28th DAC, </booktitle> <year> 1991 </year>
Reference-contexts: These two systems do not work with applications which exhibit loop carried dependencies. PLS and CATHEDRAL II are capable of working on applications with LCDs by means of an iterative folding algorithm <ref> [46] </ref> and loop folding algorithm [27], respectively. Both systems adopt an iterative approach to find the MAL. This MAL then serves as the upper bound of the performance of the synthesized designs. The major application domain of the above synthesis systems is digital signal processors (DSP). <p> T. & D. [75] SEHWA [62], HAL [61], PLS <ref> [46] </ref>, ASPD [7], etc.
Reference: [47] <author> Masaharu Imai, Alauddin Alomary et al., </author> <title> An Integer Programming Approach to Instruction Implementation Method Selection Problem, </title> <booktitle> Proc. of Euro-DAC, </booktitle> <year> 1992 </year>
Reference: [48] <author> Mike Johnson, </author> <title> Superscalar Microprocessor Design, </title> <publisher> Prentice Hall, </publisher> <year> 1991 </year>
Reference: [49] <author> Gerry Kane, </author> <title> MIPS RISC Architecture, </title> <publisher> Prentice-Hall, </publisher> <year> 1989 </year>
Reference-contexts: The limitation of these techniques is that they are still subject to the constraint of MAL. Pipelined instruction set processors with instruction initiation latencies less than MAL are impossible. For example, the MIPS R2000 <ref> [49] </ref> has MAL of two. If it were synthesized with these techniques, it would have instruction initiation latency of two, instead of one as in the manually designed one. Therefore, it can be concluded that these techniques are not suitable for synthesis of pipelined instruction set processors.
Reference: [50] <author> Hironobu Kitabatake and Katsuhiko Shirai, </author> <title> Functional Design of a Special Purpose Processor Based on High Level Specification Description, </title> <journal> IEICE Trans. Fundamentals, </journal> <volume> Vol. E75-A, No. 10, </volume> <month> Oct. </month> <year> 1992 </year>
Reference-contexts: The most common way to solve the problems is the use of current tools with some iterative approaches. In Kitabatake and Shirais approach <ref> [50] </ref>, the application is translated to an intermediate representation which is simulated. The operation frequencies and graph structure patterns are reported to the designer who then selects the desired patterns. The selected patterns define the instruction set and data path. <p> T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc. K. & S. <ref> [50] </ref>, Praet et al. [68], PEAS-I [1] ASIA PIPER HARDWARE Architectural model ++ ++ ++ ++ ++ ++ Control path - -- Data path ++/x ++ - - - -- Chip area - Cycle count --/x - - - -- Cycle time Power dissipation INTERFACE Instruction semantics -- ++ ++ -
Reference: [51] <author> Peter M. Kogge, </author> <title> The Architecture of Pipelined Computers, </title> <publisher> McGraw-Hill Book Company, </publisher> <year> 1981 </year>
Reference-contexts: As shown in to issue an iteration every three cycles as shown in Figure 2.1 (b). The length of the longest inter-iteration dependency is called minimal achievable latency (MAL) <ref> [51] </ref>, which has been used by several pipeline synthesis systems as the lower bound of the instruction initiation latency. 2.4.2 Synthesis approaches for instruction set processors In the pursuit of high performance in digital circuit designs, many high level synthesis systems focus on automating the design of pipeline structures. <p> Data path for the instructions add and inc. Register file ALU (a). Data path for the instruction add. MUX constant 1 57 placements have to be computed by other instructions which proceed the memory related instructions. The pipeline is controlled in a data stationary fashion <ref> [51] </ref>. In the data stationary control, the opcode ows through the pipeline in synchronization with the data being processed in the data path. Figure 4.4 shows the relationship between the control path with data stationary model and the data path. <p> This model is similar to the 1. The stage latency is the number of clock cycles that an instruction spends in one pipeline stage before it advances to the next stage. 89 pipelined SISD machine model defined by Kogge in <ref> [51] </ref>, with the extension that the execution phase of instructions allows multiple register accesses and ALU operations. These operations may span multiple pipeline stages. For simplicity, we assume a pipelined machine with one-cycle stage latency throughout this section. <p> Please note that our definition of inter-instruction dependency is different from the definition in <ref> [51] </ref> in that our dependency is defined based on the access of a single register, as opposed to a set of registers. In [51], for every instruction, a domain and a range are defined as the set of registers that the instruction reads and writes, respectively. <p> Please note that our definition of inter-instruction dependency is different from the definition in <ref> [51] </ref> in that our dependency is defined based on the access of a single register, as opposed to a set of registers. In [51], for every instruction, a domain and a range are defined as the set of registers that the instruction reads and writes, respectively. A pair of instructions exhibits an inter-instruction dependency as long as their domains or ranges have some overlap.
Reference: [52] <author> Vipin Kumar, </author> <title> Algorithms for Constraint Satisfaction Problems: A Survey, </title> <journal> AI Magazine, </journal> <month> spring, </month> <year> 1992 </year>
Reference: [53] <author> Anshul Kumar and Shashi Kumar, </author> <title> Automatic Synthesis of Microprogrammed Control Units from Behavior Descriptions, </title> <booktitle> Proc. of 26th DAC, </booktitle> <year> 1989 </year>
Reference: [54] <author> Tsing-Fa Lee, et al., </author> <title> An Effective Methodology for Functional Pipelining, </title> <booktitle> Proc. of ICCAD, </booktitle> <year> 1992 </year>
Reference: [55] <author> Thomas Lengauer, </author> <title> Combinatorial Algorithms for Integrated Circuit Layout, </title> <publisher> John Wiley & Sons, </publisher> <address> England, </address> <year> 1990 </year>
Reference-contexts: A time step is then randomly chosen from the selected basic block, and one move operator is randomly selected and applied to the time step. 5.2.4 Temperature and cooling schedule A proper initial temperature should accept virtually any transition (see page 154 of <ref> [55] </ref>). Several trial runs may be required to set the initial temperature. A simple heuristic to select the initial temperature is to start with a given temperature and see if all transitions are accepted in this temperature.
Reference: [56] <author> Clifford Liem, Trevor May, Pierre Paulin, </author> <title> Instruction-Set Matching and Selection for DSP and ASIP Code Generation, </title> <booktitle> Proc. of EDAC, </booktitle> <year> 1994 </year> <month> 165 </month>
Reference: [57] <author> Shi-Zheng Lin, Cheng-Tsung Hwang and Yu-Chin Hsu, </author> <title> Efficient Microcode Arrangement and Controller Synthesis for Application Specific Integrated Circuits, </title> <booktitle> Proc. of ICCAD, </booktitle> <year> 1991 </year>
Reference: [58] <author> F. M. McMahon, </author> <title> The Livermore FORTRAN Kernels: A Computer Test of Numerical Performance Range, </title> <type> Tech. Rep. </type> <institution> UCRL-55745, Lawrence Livermore National Laboratory, Univ. of California, Livermore, </institution> <month> December </month> <year> 1986 </year>
Reference-contexts: This is shown in Figure 1.2. For example, such a design example can be found in [25]. Several benchmark sets such as SPEC [73], Livermore Loops <ref> [58] </ref>, Whestone [17] and the Prolog benchmark suite [30] have been proposed to evaluate computer ISAs. Therefore, when designing a good instruction set processor, features in the instruction set, microarchitecture and the compiler backend are chosen under cost constraints.
Reference: [59] <author> Michael C. McFarland, Alice C. Parker and Raul Camponsano, </author> <title> The High-Level Synthesis of Digital Systems, </title> <journal> Proc. of the IEEE, </journal> <volume> Vol. 78, No. 2, </volume> <month> February </month> <year> 1990 </year>
Reference: [60] <editor> Glenford J. Myers, </editor> <booktitle> Advances in Computer Architecture, </booktitle> <publisher> John Wiley & Sons, </publisher> <year> 1982 </year>
Reference: [61] <author> Pierre G. Paulin and John P. Knight, </author> <title> Force-Directed Scheduling for the Behavioral Synthesis of ASICs, </title> <journal> IEEE Trans. on Computer-Aided Design, </journal> <volume> vol. 8, No. 6, </volume> <month> June </month> <year> 1989 </year>
Reference-contexts: Several pipeline scheduling algorithms have been developed. These algorithms differ in their application scope and achieved performance. SEHWA uses two algorithms: feasible scheduling and maximal scheduling [64]. HAL applies a modified force-directed scheduling algorithm to achieve better quality of pipeline scheduling and allocation at the cost of higher complexity <ref> [61] </ref>. These two systems do not work with applications which exhibit loop carried dependencies. PLS and CATHEDRAL II are capable of working on applications with LCDs by means of an iterative folding algorithm [46] and loop folding algorithm [27], respectively. Both systems adopt an iterative approach to find the MAL. <p> T. & D. [75] SEHWA [62], HAL <ref> [61] </ref>, PLS [46], ASPD [7], etc.
Reference: [62] <author> Nohbyung Park and Alice C. Parker, Sehwa: </author> <title> A Software Package for Synthesis of Pipelines from Behavioral Specifications, </title> <journal> Trans. on CAD, </journal> <volume> Vol 7. No. 3, </volume> <month> March </month> <year> 1988 </year>
Reference-contexts: T. & D. [75] SEHWA <ref> [62] </ref>, HAL [61], PLS [46], ASPD [7], etc.
Reference: [63] <author> Christos H. Papadimitriou and Kenneth Steiglitz, </author> <title> Combinatorial Optimization: Algorithms and Complexity, </title> <publisher> Prentice-Hall, </publisher> <year> 1982 </year>
Reference: [64] <author> Nohbyung Park, Rajiv Jain and Alice C. Parker, </author> <title> Data Path Synthesis of Pipelined Designs: </title> <booktitle> Theoretical Foundations, in Progress in Computer-Aided VLSI Design, </booktitle> <volume> Vol. 3, </volume> <pages> pages 119-156, </pages> <publisher> Ablex Publishing, </publisher> <year> 1990 </year>
Reference-contexts: Several pipeline scheduling algorithms have been developed. These algorithms differ in their application scope and achieved performance. SEHWA uses two algorithms: feasible scheduling and maximal scheduling <ref> [64] </ref>. HAL applies a modified force-directed scheduling algorithm to achieve better quality of pipeline scheduling and allocation at the cost of higher complexity [61]. These two systems do not work with applications which exhibit loop carried dependencies.
Reference: [65] <author> J. H. Patel and E. S. Davidson, </author> <title> Improving the Throughput of a Pipeline by Insertion of Delay, </title> <journal> IEEE/ACM 3rd Ann. Symp. Computer Arch., IEEE No. </journal> <volume> 76CH0143-5C, </volume> <year> 1976 </year>
Reference-contexts: The advantage of forwarding is that as soon as the current datum of register X is forwarded to next stage, X is free for more data. This is 94 analogous to adding extra latches (delays) in a pipeline in order to improve the system throughput <ref> [65] </ref>. Duplicate registers release the burden of temporary registers. In Figure 6.3 (a), a temporary register T connects two sources S 1 and S 2 and two destinations D 1 and D 2 . There are four possible connection patterns.
Reference: [66] <author> Pierre Paulin, Clifford Liem, Trevor May, Shailesh Sutarwala, </author> <title> DSP Design Tool Requirements for Embedded Systems: A Telecommunications Industrial Perspective, </title> <note> to appear in Journal of VLSI Signal Processing, </note> <year> 1994 </year>
Reference-contexts: Techniques in high level synthesis, such as scheduling and allocation, become attractive alternatives to code generation for these DSP cases. 2.6 Combined Approaches The need to closely examine the problems of MS, ISS and ISM for instruction set processors has been noted by researchers, e.g., [36] and <ref> [66] </ref>. The most common way to solve the problems is the use of current tools with some iterative approaches. In Kitabatake and Shirais approach [50], the application is translated to an intermediate representation which is simulated. <p> Software related to the architecture and microarchitecture design of processors includes instruction-level simulators, microarchitecture simulators, code generators, reorderers 1 , peephole optimizers, etc. It is desirable to generate these software tools automatically when designing new processors since software develop ment usually takes equal or more time than hardware development <ref> [66] </ref>. Redesign based on feedback information. One of the advantages of integrated design automation systems is that design information generated by one tool can be easily used by other tools to improve design quality.
Reference: [67] <author> J. Pendleton, et. al., </author> <title> A 32-bit Microprocessor for Smalltalk, </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> SC-21(5):741-749, </volume> <month> October </month> <year> 1986 </year>
Reference-contexts: This pipeline configuration supports single-cycle instructions 1 which are typical of modern RISC-style processors. Multiple-cycle instructions can be accommodated with some modification to the linear pipeline such as the insertion of internal opcodes <ref> [67] </ref>. In order to manage the complexity of this research, general multiple-cycle instruc tions are not considered at this moment. However, multiple-cycle arithmetic/logic opera tions, memory access, and change of control ow (branch/jump/call) are supported by specifying the delay cycles as design parameters. 1.
Reference: [68] <author> Johan Van Praet, Gert Goossens, Dirk Lanneer, Hugo De Man, </author> <title> Instruction Set Definition and Instruction Selection for ASIPs, </title> <booktitle> to appear in Proc. of Intl Symposium on High Level Synthesis, </booktitle> <month> May </month> <year> 1994 </year>
Reference-contexts: Once the hardware details are obtained, the data path model for Alchemy is updated, and the design process repeats until the design objective is satisfied. Praet, et al. uses a similar iterative scheme but the interaction is performed by the designer at a finer level <ref> [68] </ref>. This approach is intended for DSP processors with non-pipelined data path. The application is first analyzed for the types of operations and frequent common patterns. The initial data path is constructed by selecting modules from a cell library, based on the analysis results. <p> T. & D. [75] SEHWA [62], HAL [61], PLS [46], ASPD [7], etc. K. & S. [50], Praet et al. <ref> [68] </ref>, PEAS-I [1] ASIA PIPER HARDWARE Architectural model ++ ++ ++ ++ ++ ++ Control path - -- Data path ++/x ++ - - - -- Chip area - Cycle count --/x - - - -- Cycle time Power dissipation INTERFACE Instruction semantics -- ++ ++ - -- ++ Instruction format
Reference: [69] <author> Iksoo Pyo, et al., </author> <title> Application-Driven Design Automation for Microprocessor Design, </title> <booktitle> Proc. of the 29th DAC, </booktitle> <year> 1992 </year> <month> 166 </month>
Reference-contexts: In addition, ADAS also generates the application-specific instruction set, assembly code of the given application benchmarks and the reordering table which serves as the interface to the compiler backend reorderer. The new ADAS is an extension over the original ADAS <ref> [69] </ref>, which was an improvement of the ASP design automation system [22]. 33 ADAS spans many levels of design abstraction: architectural, microarchitectural (behavioral), logic and circuit, and physical (geometric) domains. Figure 3.1 shows the hierarchy of the new ADAS and corresponding design tools. <p> FIPER takes as input an instruction set architecture specification in Prolog, and transforms it into a finite state machine by scheduling and allocation processes. The output of FIPER is fed to PIPER for pipeline synthesis <ref> [69] </ref>. 35 In ADAS, there is also a simulation pass which runs parallel with the synthesis pass. A set of application benchmarks are provided for simulation at major design domains to verify the correctness and performance of the design. <p> It was built on six boards. While it is still widely in service, its parts become obsolete and raise a difficult maintenance problem. There fore, a customized single-chip re-implementation is desirable. The ADAS design auto mation system <ref> [69] </ref> was used to generate a gate-array implementation from the instruction set specification. PIPER is the high level synthesis tool of ADAS, and was used to explore possible pipeline implementations of TDY-43. Table 8.22 shows some results of TDY-43.
Reference: [70] <author> Peter Van Roy and Alvin Despain, </author> <title> HIgh-performance Logic Programming with the Aquarius Prolog Compiler, </title> <journal> Computer, </journal> <volume> 25(1) </volume> <pages> 54-68, </pages> <month> January </month> <year> 1992 </year>
Reference-contexts: The purpose is to explore the variation of their architectural properties of several different application benchmarks by comparing performance and cost of their corresponding instruction sets. Source-level (Prolog) application benchmarks are used for the experiments. They are compiled to assembly code by the Aquarius Prolog compiler <ref> [70] </ref>. A preprocessor maps the .r files of the assembly code to dependency graphs of micro-operations, which are the input to the synthesis algorithm described in Section 5.2 on page 73.
Reference: [71] <author> D. E. Thomas et al., </author> <title> The System Architects Workbench, </title> <booktitle> Proc. of the 25th Design Automation Conference, </booktitle> <year> 1988 </year>
Reference-contexts: This MAL then serves as the upper bound of the performance of the synthesized designs. The major application domain of the above synthesis systems is digital signal processors (DSP). The System Architects Workbench (SAW) synthesizes both un-pipelined and pipelined processors <ref> [71] </ref>. The possible biases of the designers coding style in the instruction set specification are eliminated with a set of transformation rules to be selected by the user. The optimized specification is fed to a architectural partitioning 25 phase to determine the feasible hardware allocation.
Reference: [72] <author> Jun Sato, et al., </author> <title> An Integrated Design Environment for Application Specific Integrated Processor, </title> <booktitle> Proc. of ICCD, </booktitle> <year> 1991 </year>
Reference-contexts: The results were CISC-like instructions. These studies include Haneys [29], Boses [4] and Bennetts [6] work. These techniques are not suitable for designing instruction sets for modern pipelined processors. Sato et al. <ref> [72] </ref> proposed an integrated design framework for application specific instruction set processors. This framework generates profiling information from a given set of application benchmarks and their expected data.
Reference: [73] <institution> SPEC Benchmark Suite Release 1.0, </institution> <month> October 2, </month> <year> 1989 </year>
Reference-contexts: This is shown in Figure 1.2. For example, such a design example can be found in [25]. Several benchmark sets such as SPEC <ref> [73] </ref>, Livermore Loops [58], Whestone [17] and the Prolog benchmark suite [30] have been proposed to evaluate computer ISAs. Therefore, when designing a good instruction set processor, features in the instruction set, microarchitecture and the compiler backend are chosen under cost constraints.
Reference: [74] <author> Ching-Long Su and Alvin Despain, </author> <title> An Instruction Scheduler and Register Allocator for Prolog Parallel Microprocessors, </title> <booktitle> Proc. of International Computer Symposium, </booktitle> <year> 1992 </year>
Reference: [75] <author> Ching-Long Su, Chi-Ying Tsui and Alvin Despain, </author> <title> Low Power Architecture Design and Compilation Techniques for High Performance Processors, </title> <booktitle> Proced-ings of the IEEE COMPCON, </booktitle> <month> Febuary </month> <year> 1994 </year>
Reference-contexts: Although there has been some work such as <ref> [75] </ref>, further investigation is necessary to incorporate the power issue into synthesis. (3) Another missing link is the construction of the compiler backend: code generator and peephole optimizer. A new instruction set processor is of little use unless there is a compiler back-end for it. <p> T. & D. <ref> [75] </ref> SEHWA [62], HAL [61], PLS [46], ASPD [7], etc.
Reference: [76] <author> R. M. Tomasulo, </author> <title> An Efficient Algorithm for Exploiting Multiple Arithmetic Units, </title> <institution> IBM J. Res. Dev., </institution> <month> January </month> <year> 1967, </year> <pages> pp. 25-33. </pages>
Reference-contexts: In the following section, we will present hardware and software resolutions for pipeline hazards caused by forward and backward dependencies. 6.2 Hardware/software Resolutions for Pipeline Hazards The most powerful and practical way of resolving data dependent pipeline hazards is a data-ow like approach, such as Tomasulos approach <ref> [76] </ref>. Data are assigned tags, and a data ow engine, such as the reservation station and its supporting circuitry in Tomasulos approach, is used to track the relationships among data. In this paper, we consider an alternative approach employing relatively simple hardware and software techniques.
Reference: [77] <author> Jean-Paul Tremblay and Paul G. Sorenson, </author> <title> The Theory and Practice of Compiler Writing, </title> <publisher> McGraw-Hill Book Company, </publisher> <year> 1985 </year>
Reference: [78] <institution> Programming Manual for the Teledyne TDY-43 Computer, Teledyne Systems Company, </institution> <year> 1988 </year>
Reference-contexts: development systems where lots of applications are constantly 151 compiled during the life time of the machines, thus making software cost less affordable as shown in our a=0.4 case. 8.4.3 The TDY-43 processor The TDY-43 processor was designed about twenty years ago, and was used for aviation control in helicopters <ref> [78] </ref>. It has 256 instructions supporting fix-point, frac tional, and twos complement operations on nine registers, a wide variety of addressing modes, and some external I/O controls. It was built on six boards. While it is still widely in service, its parts become obsolete and raise a difficult maintenance problem.
Reference: [79] <author> Peter L. Van Roy, </author> <title> Can Logic Programming Execute as Fast as Imperative Programming, </title> <type> Ph.D. thesis, Technical Report UCB/CSD 90/600, </type> <institution> Univ. of Califor-nia, Berkeley, </institution> <year> 1990 </year>
Reference-contexts: This translation is performed in two steps. First, the application, written in a high level language, is translated into an intermediate representation by the compiler of the high level language (in our current environment, the Aquarius Prolog Compiler <ref> [79] </ref>). Second, a retargetable 87 MOP mapper, consulting the given architectural template specified with the language described in Section 4.2.1 on page 59, transforms the intermediate repre sentation into the dependency graphs of MOPs. 2. A preprocessor generates a simple-minded schedule for the MOPs.
Reference: [80] <author> D. F. Wong, H. W. Leong and C. L. Liu, </author> <title> Simulated Annealing for VLSI Design, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988 </year>
References-found: 80

