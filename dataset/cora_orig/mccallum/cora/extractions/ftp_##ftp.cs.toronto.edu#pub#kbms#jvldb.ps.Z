URL: ftp://ftp.cs.toronto.edu/pub/kbms/jvldb.ps.Z
Refering-URL: ftp://ftp.cs.toronto.edu/pub/kbms/readme.html
Root-URL: 
Title: Building Knowledge Base Management Systems  
Author: John Mylopoulos, Vinay Chaudhri, Dimitris Plexousakis Adel Shrufi and Thodoros Topaloglou 
Keyword: Knowledge bases, knowledge base management systems, knowledge representation, storage management, query processing, concurrency control, constraint enforcement, rule management  
Address: Toronto, 6 King's College Road, Toronto, Canada,  
Note: Authors' full address:  
Affiliation: University of Toronto  Department of Computer Science, University of  
Pubnum: M5S 1A4.  
Date: May 8, 1995  
Abstract: Advanced applications in fields such as CAD, Software Engineering, Real-Time Process Control, Corporate Repositories and Digital Libraries require the construction, efficient access and management of large, shared knowledge bases. Such knowledge bases cannot be built using existing tools such as expert system shells, because these do not scale up; nor can they be built in terms of existing database technology because such technology does not support the rich representational structure and inference mechanisms required for knowledge based systems. This paper proposes a generic architecture for a knowledge base management system intended for such applications. The architecture assumes an object-oriented knowledge representation language with an as-sertional sublanguage used to express constraints and rules. It also provides for general-purpose deductive inference and special-purpose temporal reasoning. Results reported in the paper address several knowledge base management issues. For storage management, a new method is proposed for generating a logical schema for a given knowledge base. Query processing algorithms are offered for semantic and physical query optimization, along with an enhanced cost model for query cost estimation. On concurrency control, the paper describes a novel concurrency control policy which takes advantage of knowledge base structure and is shown to outperform two-phase locking for highly structured knowledge bases and update-intensive transactions. Finally, algorithms for compilation and efficient processing of constraints and rules during knowledge base operations are described. The paper describes original results, including novel data structures and algorithms, as well as preliminary performance evaluation data. Based on these results, we conclude that knowledge base management systems which can accommodate large knowledge bases are feasible. fl Results reported in this paper are based on research conducted within the project titled "A Telos Knowledge Base Management System", funded by the Province of Ontario through the Information Technology Research Center; additional funding for the project has been received from the Department of Computer Science of the University of Toronto and the National Science and Engineering Research Council of Canada. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agrawal, R., Carey, M. J., and Livny, M. </author> <year> (1987). </year> <title> Concurrency Control Performance Modeling: Alternatives and Implications. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(4) </volume> <pages> 609-654. </pages>
Reference-contexts: Our performance model is similar to that presented in <ref> (Agrawal, Carey and Livny, 1987) </ref> and has four components: a source, which generates transactions, a transaction manager, which models the execution behavior of transactions, a concurrency control manager, which implements the details of a particular algorithm; and a resource manager, which models the CPU and I/O resources of the database.
Reference: <author> Aho, A. V., Hopcroft, J. E., and Ullman, J. D. </author> <year> (1987). </year> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley Publishing Company. </publisher>
Reference-contexts: The dominator information is maintained using and incremental algorithm (Carroll, 1988). The information on strongly connected components is computed at compile time in time O (m) <ref> (Aho, Hopcroft and Ullman, 1987) </ref>, where m is the number of edges in the graph. We developed a new algorithm for incrementally maintaining information on strongly connected components as the knowledge base evolves (Chaudhri, 1995) as algorithm for this purpose was not available.
Reference: <author> Allen, J. </author> <year> (1983). </year> <title> Maintaining Knowledge about Temporal Intervals. </title> <journal> Communications of the ACM, </journal> <volume> 26(11) </volume> <pages> 832-843. </pages>
Reference-contexts: Both history and belief time are represented by means of time intervals. The model of time adopted is a modification of Allen's framework <ref> (Allen, 1983) </ref>. Seven exclusive temporal relations (e.g, equal, meet, before, after, during, start, end) together with their inverses are used to characterize the possible positions of two intervals on a linear time line. Temporal relationships participate in the expression of deductive rules and integrity constraints in the assertion language. <p> Temporal Simplification The objective of temporal simplification rules is to simplify a conjunction of temporal relationships into a single temporal relationship. In its full generality this task is intractable <ref> (Allen, 1983) </ref>. In our method, however, we require that at least one of the temporal variables in each temporal relation should be instantiated, and with this condition the simplification can be performed efficiently. In fact only a table lookup is required.
Reference: <author> Attardi, G. and Simi, M. </author> <year> (1981). </year> <title> Semantics of Inheritance and Attributions in the Description System OMEGA. </title> <type> Technical Report S-81-16, </type> <institution> Universita Di Pisa. </institution> <note> Also MIT AI memo 642, </note> <year> 1981. </year>
Reference-contexts: A proposition can be represented by a 3-tuple 2 (e.g. [Martin,age,35]). Propositions (individuals and attributes) are organized along three dimensions, referred to in the literature as attribution <ref> (Attardi and Simi, 1981) </ref>, classification and generalization (Brodie, Mylopoulos and Schmidt, 1984). Structured objects consist of collections of (possibly multi-valued) attributes that have a common proposition as a source, thus adding a simple form of aggregation.
Reference: <author> Bernstein, P. A., Hadzilacos, V., and Goodman, N. </author> <year> (1987). </year> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Welssley Publishing Company. </publisher>
Reference-contexts: The rest of the discussion in this section focuses on locking rules. A detailed description of the DDG algorithm appears elsewhere (Chaudhri, 1995). A transaction may lock a node in shared or exclusive mode <ref> (Bernstein, Hadzilacos and Goodman, 1987) </ref>.
Reference: <author> Bertino, E. and Kim, W. </author> <year> (1989). </year> <title> Indexing Techniques for Queries on Nested Objects. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 1(2) </volume> <pages> 196-214. </pages>
Reference-contexts: To make the two-way access efficient we assume that that two copies of a TJI are stored. Each copy is clustered on one of the object identifiers of the two classes. A series of TJIs can be used to form the temporal equivalent of the multi-join index <ref> (Bertino and Kim, 1989) </ref>. 5 Query Processing For the Telos KBMS, queries are specified through an ASK operation (Mylopoulos et al., 1990), that has the following structure: ASK x 1 =S 1 ; :::; x n =S n : W AS OF t 2 x 1 ; :::; x n are
Reference: <author> Biliris, A. </author> <year> (1992). </year> <title> The Performance of Three Database Storage Structures for Managing Large Objects. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data. </booktitle>
Reference: <author> Bocca, J. </author> <year> (1986). </year> <title> On Evaluation Strategy of EDUCE. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 368-378. </pages>
Reference-contexts: Specifically, this section compares the join index strategy to the sort-merge and nested-loop strategies. The sort-merge strategy represents the traditional database approach in computing large joins. The nested-loop strategy represents the traditional AI approach in query processing where processing is done in a tuple-oriented fashion <ref> (Bocca, 1986) </ref>. Our key conclusion is that our choice of using the join index for evaluating joins performs better than the sort-merge and nested-loop methods. In our test knowledge base, the total number of classes is 40.
Reference: <editor> Brodie, M., Mylopoulos, J., and Schmidt, J., editors (1984). </editor> <booktitle> On Conceptual Modeling: Perspectives from Artificial Intelligence, Databases and Programming Languages. </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: A proposition can be represented by a 3-tuple 2 (e.g. [Martin,age,35]). Propositions (individuals and attributes) are organized along three dimensions, referred to in the literature as attribution (Attardi and Simi, 1981), classification and generalization <ref> (Brodie, Mylopoulos and Schmidt, 1984) </ref>. Structured objects consist of collections of (possibly multi-valued) attributes that have a common proposition as a source, thus adding a simple form of aggregation.
Reference: <author> Bry, F., Decker, H., and Manthey, R. </author> <year> (1988). </year> <title> A Uniform Approach to Constraint Satisfaction and Constraint Satisfiability in Deductive Databases. </title> <booktitle> In 1st Int. Conference on Extending Data Base Technology, </booktitle> <pages> pages 488-505, </pages> <address> Venice, Italy. </address>
Reference-contexts: sequence of updates that change the KB so that constraints are satisfied in the resulting state. 33 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982), (Ceri and Widom, 1990),(Ling and Lee, 1992), (Gupta et al., 1994), ), deductive (e.g. (Decker, 1986), <ref> (Bry, Decker and Manthey, 1988) </ref>, (Kuchenhoff, 1991)), object-oriented (Jeusfeld and Jarke, 1991) and temporal databases (Chomicki, 1992), have appeared in the recent literature. A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). <p> Transaction modification is less flexible than constraint simplification since each transaction has to be modified for each relevant constraint. Most promising, as a basis for enforcing more expressive constraints such as the ones expressible in the assertion language of Telos, are the compilation method of <ref> (Bry, Decker and Manthey, 1988) </ref> and the historical knowledge minimization techniques of (Hulsmann and Saake, 1990) and (Chomicki, 1992). <p> if there exists a literal L ( ; ; ; ) in I such that L unifies with the complement of U and the intersections t 1 fl T and t 2 fl T 0 are non-empty. 13 A formula is rectified if no two quantifiers introduce the same variable <ref> (Bry, Decker and Manthey, 1988) </ref>. 14 This class of constraints is equivalent to both the restricted quantification form of (Bry, Decker and Manthey, 1988) and the range form of (Jeusfeld and Jarke, 1991). 15 A set of rules is stratified if whenever a negated literal P occurs in the body of <p> complement of U and the intersections t 1 fl T and t 2 fl T 0 are non-empty. 13 A formula is rectified if no two quantifiers introduce the same variable <ref> (Bry, Decker and Manthey, 1988) </ref>. 14 This class of constraints is equivalent to both the restricted quantification form of (Bry, Decker and Manthey, 1988) and the range form of (Jeusfeld and Jarke, 1991). 15 A set of rules is stratified if whenever a negated literal P occurs in the body of a rule with head Q, there is no derivation path for P in which Q occurs in the body <p> A dual approach to constraint enforcement, based on compiling constraints into transaction specifications, is a topic of current research (Plexousakis and Mylopoulos, 1995). Finally, a more fine grained approach to integrity violation needs to be devised, possibly adopting ideas of finite constraint satisfiability <ref> (Bry, Decker and Manthey, 1988) </ref>. In addition, we are working towards benchmarks for knowledge based systems, so that we can have a standard method to evaluate the algorithms developed for such systems.
Reference: <author> Buchanan, B. G. and Wilkins, D. C., </author> <title> editors (1993). Readings in Knowledge Acquisition and Learning. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA. </address>
Reference: <author> Carey, M., DeWitt, D., Richardson, J., and Shekita, E. </author> <year> (1986). </year> <title> Object and File Management in the EXODUS Extensible Database System. </title> <booktitle> In Proceedings of the 12th International Conference on Very Large Data Bases, </booktitle> <pages> pages 91-100. </pages>
Reference: <author> Carroll, M. D. </author> <year> (1988). </year> <title> Data Flow Analysis via Dominator and Attribute Updates. </title> <type> Technical Report LCSR-TR-111, </type> <institution> Rutgers University. </institution>
Reference-contexts: Using this information, the dominator of the set of nodes in the transaction can be computed in time linear in the length of a transaction using the nearest common ancestor algorithm (Schieber and Vishkin, 1988). The dominator information is maintained using and incremental algorithm <ref> (Carroll, 1988) </ref>. The information on strongly connected components is computed at compile time in time O (m) (Aho, Hopcroft and Ullman, 1987), where m is the number of edges in the graph.
Reference: <author> Ceri, S. and Widom, J. </author> <year> (1990). </year> <title> Deriving Production Rules for Constraint Maintenance. </title> <booktitle> In Proceedings of the 16th Int. Conference in Very Large Databases, </booktitle> <pages> pages 566-577. </pages>
Reference-contexts: all constraints are found to be satisfied. 12 12 A finer grained approach could initiate a sequence of updates that change the KB so that constraints are satisfied in the resulting state. 33 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982), <ref> (Ceri and Widom, 1990) </ref>,(Ling and Lee, 1992), (Gupta et al., 1994), ), deductive (e.g. (Decker, 1986), (Bry, Decker and Manthey, 1988), (Kuchenhoff, 1991)), object-oriented (Jeusfeld and Jarke, 1991) and temporal databases (Chomicki, 1992), have appeared in the recent literature.
Reference: <author> Chakravarthy, V., Grant, J., and Minker, J. </author> <year> (1988). </year> <title> Foundations of Semantic Query Optimization for Deductive Databases. </title> <editor> In Minker, J., editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, </booktitle> <pages> pages 243-273. </pages> <publisher> Morgan-Kaufmann. </publisher>
Reference: <author> Chaudhri, V. K. </author> <year> (1995). </year> <title> Transaction Synchronization in Knowledge Bases: Concepts, Realization and Quantitative Evaluation. </title> <type> PhD thesis, </type> <institution> University of Toronto, Toronto. </institution>
Reference-contexts: It should be noted that we varied these parameters and the relative performance of the strategies remained unaffected. Also, the number of classes chosen was deemed reasonably large in view of statistics empirically observed in real knowledge bases <ref> (Chaudhri, 1995) </ref>. The cardinalities of the classes and the primitive attributes were chosen randomly within reasonable ranges as in (Ioannidis, Ramakrishnan and Winger, 1993). This has thus ensured that the generation of data is not biased towards a particular strategy. <p> Locking rules specify how each transaction should acquire locks. Maintenance rules specify additional operations that must be executed by transactions to keep the structure rooted and connected. The rest of the discussion in this section focuses on locking rules. A detailed description of the DDG algorithm appears elsewhere <ref> (Chaudhri, 1995) </ref>. A transaction may lock a node in shared or exclusive mode (Bernstein, Hadzilacos and Goodman, 1987). <p> The information on strongly connected components is computed at compile time in time O (m) (Aho, Hopcroft and Ullman, 1987), where m is the number of edges in the graph. We developed a new algorithm for incrementally maintaining information on strongly connected components as the knowledge base evolves <ref> (Chaudhri, 1995) </ref> as algorithm for this purpose was not available. Let us describe the order in which a transaction acquires and releases locks. A transaction always begins by locking the dominator of all the nodes that it might access. <p> It is difficult to comment on this aspect in the absence of a specific knowledge base and its workload. In general, if the database is highly structured <ref> (Chaudhri, 1995) </ref> the locality of changes is almost assured, and the incremental algorithms, and therefore, the results presented in this section will scale up to larger problems The present section has presented an overview of the results based on the second author's doctoral dissertation (Chaudhri, 1995) which have also been published <p> if the database is highly structured <ref> (Chaudhri, 1995) </ref> the locality of changes is almost assured, and the incremental algorithms, and therefore, the results presented in this section will scale up to larger problems The present section has presented an overview of the results based on the second author's doctoral dissertation (Chaudhri, 1995) which have also been published as conference length papers (Chaudhri, Hadzilacos and Mylopoulos, 1992; Chaudhri et al., 1994; Chaudhri and Hadzilacos, 1995; Chaudhri and Mylopoulos, 1995). 7 Integrity Constraint and Rule Management Integrity constraints specify the valid states of a knowledge base (static constraints) as well as the allowable
Reference: <author> Chaudhri, V. K. and Hadzilacos, V. </author> <year> (1995). </year> <title> Safe Locking Policies for Dynamic Databases. </title> <booktitle> In Fourteenth ACM Symposium on Principles of Database Systems. </booktitle>
Reference-contexts: It should be noted that we varied these parameters and the relative performance of the strategies remained unaffected. Also, the number of classes chosen was deemed reasonably large in view of statistics empirically observed in real knowledge bases <ref> (Chaudhri, 1995) </ref>. The cardinalities of the classes and the primitive attributes were chosen randomly within reasonable ranges as in (Ioannidis, Ramakrishnan and Winger, 1993). This has thus ensured that the generation of data is not biased towards a particular strategy. <p> Locking rules specify how each transaction should acquire locks. Maintenance rules specify additional operations that must be executed by transactions to keep the structure rooted and connected. The rest of the discussion in this section focuses on locking rules. A detailed description of the DDG algorithm appears elsewhere <ref> (Chaudhri, 1995) </ref>. A transaction may lock a node in shared or exclusive mode (Bernstein, Hadzilacos and Goodman, 1987). <p> The information on strongly connected components is computed at compile time in time O (m) (Aho, Hopcroft and Ullman, 1987), where m is the number of edges in the graph. We developed a new algorithm for incrementally maintaining information on strongly connected components as the knowledge base evolves <ref> (Chaudhri, 1995) </ref> as algorithm for this purpose was not available. Let us describe the order in which a transaction acquires and releases locks. A transaction always begins by locking the dominator of all the nodes that it might access. <p> It is difficult to comment on this aspect in the absence of a specific knowledge base and its workload. In general, if the database is highly structured <ref> (Chaudhri, 1995) </ref> the locality of changes is almost assured, and the incremental algorithms, and therefore, the results presented in this section will scale up to larger problems The present section has presented an overview of the results based on the second author's doctoral dissertation (Chaudhri, 1995) which have also been published <p> if the database is highly structured <ref> (Chaudhri, 1995) </ref> the locality of changes is almost assured, and the incremental algorithms, and therefore, the results presented in this section will scale up to larger problems The present section has presented an overview of the results based on the second author's doctoral dissertation (Chaudhri, 1995) which have also been published as conference length papers (Chaudhri, Hadzilacos and Mylopoulos, 1992; Chaudhri et al., 1994; Chaudhri and Hadzilacos, 1995; Chaudhri and Mylopoulos, 1995). 7 Integrity Constraint and Rule Management Integrity constraints specify the valid states of a knowledge base (static constraints) as well as the allowable
Reference: <author> Chaudhri, V. K., Hadzilacos, V., and Mylopoulos, J. </author> <year> (1992). </year> <title> Concurrency Control for Knowledge Bases. </title> <booktitle> In Proceedings of the Third International Conference on Knowledge Representation and Reasoning, </booktitle> <pages> pages 762-773. </pages>
Reference-contexts: This suggests that if a knowledge base contains very large cycles which need to be locked as one node, concurrency will be reduced. We have a version of the DDG policy (called, DDG 0 policy) that does permit concurrency within cycles <ref> (Chaudhri, Hadzilacos and Mylopoulos, 1992) </ref>. We adopted the above version, because the transactions in knowledge bases tend to access all the nodes on a cycle together, and therefore, the cycles are a natural unit of locking.
Reference: <author> Chaudhri, V. K., Hadzilacos, V., Mylopoulos, J., and Sevcik, K. </author> <year> (1994). </year> <title> Quantitative Evaluation of a Transaction Facility for a Knowledge Base Management System. </title> <booktitle> In Proceedings of the Third International Conference on Knowledge Management, </booktitle> <pages> pages 122-131, </pages> <address> Gaithersberg, MD. </address> <note> 45 Chaudhri, </note> <author> V. K. and Mylopoulos, J. </author> <year> (1995). </year> <title> Efficient Algorithms and Performance Results for Multi-User Knowledge Bases. </title> <booktitle> In Proceedings of the 1995 International Joint Conference on Artificial Intelligence, page To Appear, </booktitle> <address> Montreal. </address>
Reference-contexts: More details about the model and the simulations are available elsewhere <ref> (Chaudhri et al., 1994) </ref>. The primary performance metric adopted for the simulation is the response time of transactions in each class.
Reference: <author> Chomicki, J. </author> <year> (1992). </year> <title> History-less Checking of Dynamic Integrity Constraints. </title> <booktitle> In 8th Int. Conference on Data Engineering, </booktitle> <pages> pages 557-564, </pages> <month> Phoenix,AZ. </month>
Reference-contexts: state. 33 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982), (Ceri and Widom, 1990),(Ling and Lee, 1992), (Gupta et al., 1994), ), deductive (e.g. (Decker, 1986), (Bry, Decker and Manthey, 1988), (Kuchenhoff, 1991)), object-oriented (Jeusfeld and Jarke, 1991) and temporal databases <ref> (Chomicki, 1992) </ref>, have appeared in the recent literature. A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). <p> Most promising, as a basis for enforcing more expressive constraints such as the ones expressible in the assertion language of Telos, are the compilation method of (Bry, Decker and Manthey, 1988) and the historical knowledge minimization techniques of (Hulsmann and Saake, 1990) and <ref> (Chomicki, 1992) </ref>. The former method, extended with the ability to deal with object identity, aggregation and classification, has been used in the integrity subsystem of the deductive object base ConceptBase (Jeusfeld and Jarke, 1991) (also based on a version of Telos).
Reference: <author> Copeland, G. and Khoshafian, S. </author> <year> (1985). </year> <title> A Decomposition Storage Model. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 268-279. </pages>
Reference-contexts: A more general model that does not make this assumption is available elsewhere (Topaloglou, 1993). rds (DSM) = k=0 h X b j )N (2) Note that equations 1 and 2 modify <ref> (Copeland and Khoshafian, 1985) </ref> formulas for NSM and DSM storage, taking into account attributes defined over isA hierarchies. In the CDM, the degree of decomposition depends on the average number of attributes with complex domains and the access frequency of the attributes. <p> With this change, the expression for the storage cost of CDM is as follows: rds (CDM) = (1 d) fl (rds (N SM ) + cor (N SM )) + d fl rds (DSM ) (3) The estimates of space costs suggested by the above formulae confirm the claim of <ref> (Copeland and Khoshafian, 1985) </ref> that DSM requires 2 to 4 times more data storage than NSM. As expected, CDM's storage costs fall between those of the other two schemes.
Reference: <author> Dechter, R., Meiri, I., and Pearl, J. </author> <year> (1989). </year> <title> Temporal Constraint Networks. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Representation and Reasoning, </booktitle> <pages> pages 83-93. </pages>
Reference-contexts: The testing of the temporal condition in the schema query is formulated as a CSP with integer order constraints which is solved in polynomial time <ref> (Dechter, Meiri and Pearl, 1989) </ref>. For the last step, we need to index the rules and the constraints on their history and belief time.
Reference: <author> Decker, H. </author> <year> (1986). </year> <title> Integrity Enforcement in Deductive Databases. </title> <booktitle> In Expert Database Systems, 1st Int. </booktitle> <pages> Conference , pages 271-285. </pages>
Reference-contexts: initiate a sequence of updates that change the KB so that constraints are satisfied in the resulting state. 33 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982), (Ceri and Widom, 1990),(Ling and Lee, 1992), (Gupta et al., 1994), ), deductive (e.g. <ref> (Decker, 1986) </ref>, (Bry, Decker and Manthey, 1988), (Kuchenhoff, 1991)), object-oriented (Jeusfeld and Jarke, 1991) and temporal databases (Chomicki, 1992), have appeared in the recent literature. A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). <p> Each C i is a Telos class and the meaning of each restricted quantification is that the variable bound by the quantifier ranges over the extension of the class instead of the entire domain. Any constraint in this form is range-restricted <ref> (Decker, 1986) </ref>. 14 The typed quantifications 8x=C F and 9x=C F are short forms for the formulae: 8x 8t instanceOf (x; C; t) ^ instanceOf (t; TimeInterval; Alltime) ) F , 9x 9t instanceOf (x; C; t) ^ instanceOf (t; TimeInterval; Alltime) ^ F The introduction of temporal variables and their
Reference: <author> Eswaran, K., Gray, J. N., Lorie, R. A., and Traiger, I. L. </author> <year> (1976). </year> <title> The Notions of Consistency and Predicate Locks in Database Systems. </title> <journal> Communications of the ACM, </journal> <volume> 19(9) </volume> <pages> 624-633. </pages>
Reference-contexts: The best known locking algorithm, two phase locking (2PL) <ref> (Eswaran et al., 1976) </ref>, works along the following lines. Associated with each data item is a distinct "lock". A transaction must acquire a lock on a data item before accessing it.
Reference: <author> Findler, N., </author> <title> editor (1979). Associative Networks. </title> <publisher> Academic Press. </publisher>
Reference-contexts: Section 8 summarizes the results of this work and outlines open problems for further research. 2 Overview of Telos The representational framework of Telos (Mylopoulos et al., 1990) constitutes a generalization of graph-theoretic data structures used in semantic networks <ref> (Findler, 1979) </ref>, semantic data models (Hull and King, 1987) and object-oriented representations (Zdonik and Maier, 1989). Telos treats attributes as first-class citizens, supports a powerful classification (or instantiation) mechanism which enhances extensibility and offers special representational and inferential mechanisms for temporal knowledge.
Reference: <author> Finkelstein, S., Schkolnick, M., and Tiberio, P. </author> <year> (1988). </year> <title> Physical Database Design for Relational Databases. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 13(1) </volume> <pages> 91-128. </pages>
Reference: <author> Frank, M., Omiecinski, E., and Navathe, S. </author> <year> (1992). </year> <title> Adaptive and Automated Index Selection in RDBMS. </title> <booktitle> In Proceedings of International Conference on Extending Database Technology, </booktitle> <pages> pages 277-292. </pages>
Reference: <author> Frenkel, K. A. </author> <year> (1991). </year> <title> The Human Genome Project and Informatics. </title> <journal> Communications of the ACM, </journal> <volume> 34(11) </volume> <pages> 41-51. </pages>
Reference-contexts: functions (what does it mean when alarm 692 goes off) and diagnostic knowledge used by plant operators to determine the nature of an emergency (Mylopoulos et al., 1992); * "grand challenges", such as information system support for environmental global change research (Stonebraker and Dozier, 1991) and the human GENOME project <ref> (Frenkel, 1991) </ref>; * knowledge sharing applications that involve construction of generic knowledge bases that include thousands of concept descriptions and are used as references in the construction of knowledge based systems (Neches et al., 1991).
Reference: <author> Gupta, A., Sagiv, Y., Ullman, J., and Widom, J. </author> <year> (1994). </year> <title> Constraint Checking with Partial Information. </title> <booktitle> In ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems , pages 45-55. </booktitle>
Reference-contexts: 12 12 A finer grained approach could initiate a sequence of updates that change the KB so that constraints are satisfied in the resulting state. 33 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982), (Ceri and Widom, 1990),(Ling and Lee, 1992), <ref> (Gupta et al., 1994) </ref>, ), deductive (e.g. (Decker, 1986), (Bry, Decker and Manthey, 1988), (Kuchenhoff, 1991)), object-oriented (Jeusfeld and Jarke, 1991) and temporal databases (Chomicki, 1992), have appeared in the recent literature.
Reference: <author> Guttman, A. </author> <year> (1984). </year> <title> R-Trees: A Dynamic Index Structure For Spatial Searching. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 47-57. </pages>
Reference-contexts: With these indices it is possible to perform selection using keys and time simultaneously. Since the index entries are no longer points, it is assumed that they are implemented as spatial access meth 14 ods <ref> (Guttman, 1984) </ref>. Moreover, the indices are hierarchical in the sense that one index stores information for all the instances of a class (including inherited ones). This choice is consistent with a previous study (Kim, Kim and Dale, 1989) which shows that a hierarchical index always outperforms the simple class index. <p> For the last step, we need to index the rules and the constraints on their history and belief time. In the two dimensional space that history and belief time define, each rule or constraint is viewed as a rectangular area; We use an R-tree based spatial access method <ref> (Guttman, 1984) </ref> to assist the temporal selection with logarithmic complexity. 5.1.2 Syntactic Simplification Syntactic simplification exploits the properties of the structural features of Telos (i.e., isA, instanceOf and proposition relationships). Also, subexpressions within the query expression that are always true, always false, or inconsistent are detected.
Reference: <author> Hull, R. and King, R. </author> <year> (1987). </year> <title> Semantic Database Modeling: Survey, Applications and Research Issues. </title> <journal> ACM Computing Surveys, </journal> <volume> 19(3). </volume>
Reference-contexts: Section 8 summarizes the results of this work and outlines open problems for further research. 2 Overview of Telos The representational framework of Telos (Mylopoulos et al., 1990) constitutes a generalization of graph-theoretic data structures used in semantic networks (Findler, 1979), semantic data models <ref> (Hull and King, 1987) </ref> and object-oriented representations (Zdonik and Maier, 1989). Telos treats attributes as first-class citizens, supports a powerful classification (or instantiation) mechanism which enhances extensibility and offers special representational and inferential mechanisms for temporal knowledge.
Reference: <author> Hulsmann, K. and Saake, G. </author> <year> (1990). </year> <title> Representation of the Historical Information Necessary for Temporal Integrity Monitoring. </title> <booktitle> In 2nd Int. Conference on Extending Data Base Technology, </booktitle> <pages> pages 378-392, </pages> <address> Venice, Italy. </address>
Reference-contexts: Most promising, as a basis for enforcing more expressive constraints such as the ones expressible in the assertion language of Telos, are the compilation method of (Bry, Decker and Manthey, 1988) and the historical knowledge minimization techniques of <ref> (Hulsmann and Saake, 1990) </ref> and (Chomicki, 1992). The former method, extended with the ability to deal with object identity, aggregation and classification, has been used in the integrity subsystem of the deductive object base ConceptBase (Jeusfeld and Jarke, 1991) (also based on a version of Telos).
Reference: <author> Ibaraki, T. and Katoh, N. </author> <year> (1983). </year> <title> On-Line Computation of Transitive Closures of Graphs. </title> <journal> Information Processing Letters, </journal> <volume> 16(3) </volume> <pages> 95-97. </pages>
Reference: <author> Ioannidis, Y., Ramakrishnan, R., and Winger, L. </author> <year> (1993). </year> <title> Transitivie Closure Algorithms based on Graph Traversal. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 18(3) </volume> <pages> 512-576. </pages>
Reference-contexts: Also, the number of classes chosen was deemed reasonably large in view of statistics empirically observed in real knowledge bases (Chaudhri, 1995). The cardinalities of the classes and the primitive attributes were chosen randomly within reasonable ranges as in <ref> (Ioannidis, Ramakrishnan and Winger, 1993) </ref>. This has thus ensured that the generation of data is not biased towards a particular strategy. For the above knowledge base, random queries were generated with path expressions that had a given fanout and depth of query graph (QG).
Reference: <author> Ioannidis, Y. E. and Kang, Y. C. </author> <year> (1991). </year> <title> Left-Deep vs. Bushy Trees: An Analysis of Strategy Spaces and its Implications for Query Optimization. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 168-177. </pages>
Reference-contexts: The costs of the primitive operations that were shown in the previous section are given in Table 2. For our KBMS, we have adopted a heuristic search method based upon the enumeration of the most promising execution plan based on the selectivity of classes. Exploring randomized algorithms <ref> (Ioannidis and Kang, 1991) </ref> is a topic for future research. 5.2.5 Performance Analysis In this section, our goal is to quantitatively evaluate the proposed join-index-based query processing methods. Specifically, this section compares the join index strategy to the sort-merge and nested-loop strategies.
Reference: <author> Ishikawa, H., Suzuki, F., Kozakura, F., Makinouchi, A., Miyagishima, M., Izumida, Y., Aoshima, M., and Yamane, Y. </author> <year> (1993). </year> <title> The Model, Language, and Implementation of an Object-Oriented Multimedia Knowledge Base Management System . ACM Transactions on Database Systems, </title> <booktitle> 18(1) </booktitle> <pages> 1-50. </pages>
Reference: <author> Italiano, G. </author> <year> (1988). </year> <title> Finding Paths and Deleting Edges in Directed Acyclic Graphs. </title> <journal> Information Processing Letters, </journal> <volume> 28(1) </volume> <pages> 5-11. </pages>
Reference: <author> Jarke, M. and Koch, J. </author> <year> (1984). </year> <title> Query Optimization in Database Systems. </title> <journal> Computing Surveys, </journal> <volume> 16(2) </volume> <pages> 111-143. </pages>
Reference: <author> Jarke, M. and Koubarakis, M. </author> <year> (1989). </year> <title> Query Optimization in KBMS: Overview, Research Issues, and Concepts for a Telos Implementation. </title> <type> Technical Report KRR-TR-89-6, </type> <institution> Dept. of Computer Science, University of Toronto. </institution>
Reference-contexts: In the following, we summarize the three steps in semantic optimization. More details can be found elsewhere (Topaloglou, Illarramendi and Sbattella, 1992). 16 5.1.1 Temporal Simplification Temporal simplification attempts to identify those parts of a knowledge base that are relevant to a query from a temporal viewpoint <ref> (Jarke and Koubarakis, 1989) </ref>. Temporal simplification involves the following three steps: 1. Check for inconsistent or redundant temporal constraints in the query expression; 2.
Reference: <author> Jeusfeld, M. and Jarke, M. </author> <year> (1991). </year> <title> From Relational to Object-Oriented Integrity Simplification. </title> <booktitle> In 2nd Int. Conference on Deductive and Object-Oriented Databases, </booktitle> <pages> pages 460-477, </pages> <address> Munich, Germany. </address>
Reference-contexts: that constraints are satisfied in the resulting state. 33 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982), (Ceri and Widom, 1990),(Ling and Lee, 1992), (Gupta et al., 1994), ), deductive (e.g. (Decker, 1986), (Bry, Decker and Manthey, 1988), (Kuchenhoff, 1991)), object-oriented <ref> (Jeusfeld and Jarke, 1991) </ref> and temporal databases (Chomicki, 1992), have appeared in the recent literature. A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). <p> The former method, extended with the ability to deal with object identity, aggregation and classification, has been used in the integrity subsystem of the deductive object base ConceptBase <ref> (Jeusfeld and Jarke, 1991) </ref> (also based on a version of Telos). However, this method does not deal with temporal or dynamic constraints. Historical knowledge minimization techniques assume a formulation of constraints in temporal logic and attempt to minimize the historical information required in order to verify the constraints. <p> The definition of relevance found in <ref> (Jeusfeld and Jarke, 1991) </ref> is not sufficient in the presence of time. The following definition provides sufficient conditions for "relevance" of a constraint to an update, by considering the relationships of the time intervals participating in the literals of the constraint and the update. <p> and t 2 fl T 0 are non-empty. 13 A formula is rectified if no two quantifiers introduce the same variable (Bry, Decker and Manthey, 1988). 14 This class of constraints is equivalent to both the restricted quantification form of (Bry, Decker and Manthey, 1988) and the range form of <ref> (Jeusfeld and Jarke, 1991) </ref>. 15 A set of rules is stratified if whenever a negated literal P occurs in the body of a rule with head Q, there is no derivation path for P in which Q occurs in the body of a rule. 35 Similar to the above definition, we
Reference: <author> Khoshafian, S. and Copeland, G. </author> <year> (1986). </year> <title> Object identity. </title> <booktitle> In Proceedings of OOPSLA-86, </booktitle> <pages> pages 406-416, </pages> <address> Portland, Oregon. </address>
Reference-contexts: Updating the value of an attribute: First, the relevant storage record is located by accessing an index. Then, the block which contains that record is written and the attribute's index is updated. For the DSM, as with the CDM, this requires on average three writes <ref> (Khoshafian and Copeland, 1986) </ref>. Appropriate buffering policy may further minimize that cost. The graph of Figure 5 (b) shows the cost for the token insertion case.
Reference: <author> Kim, W., Kim, K.-C., and Dale, A. </author> <year> (1989). </year> <title> Indexing Techniques for Object-Oriented Databases. In Object-Oriented Concepts, Databases and Applications. </title> <publisher> ACM Press. </publisher>
Reference-contexts: Moreover, the indices are hierarchical in the sense that one index stores information for all the instances of a class (including inherited ones). This choice is consistent with a previous study <ref> (Kim, Kim and Dale, 1989) </ref> which shows that a hierarchical index always outperforms the simple class index. The simple temporal index (STI) is used on attributes with primitive domains. <p> To make the two-way access efficient we assume that that two copies of a TJI are stored. Each copy is clustered on one of the object identifiers of the two classes. A series of TJIs can be used to form the temporal equivalent of the multi-join index <ref> (Bertino and Kim, 1989) </ref>. 5 Query Processing For the Telos KBMS, queries are specified through an ASK operation (Mylopoulos et al., 1990), that has the following structure: ASK x 1 =S 1 ; :::; x n =S n : W AS OF t 2 x 1 ; :::; x n are
Reference: <author> Kuchenhoff, V. </author> <year> (1991). </year> <title> On the Efficient Computation of the Difference Between Consecutive Database States. </title> <booktitle> In 2nd International Conference on Deductive and Object-Oriented Databases, </booktitle> <pages> pages 478-502, </pages> <address> Munich, Germany. </address>
Reference-contexts: the KB so that constraints are satisfied in the resulting state. 33 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982), (Ceri and Widom, 1990),(Ling and Lee, 1992), (Gupta et al., 1994), ), deductive (e.g. (Decker, 1986), (Bry, Decker and Manthey, 1988), <ref> (Kuchenhoff, 1991) </ref>), object-oriented (Jeusfeld and Jarke, 1991) and temporal databases (Chomicki, 1992), have appeared in the recent literature. A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). <p> Moreover, issues such as the efficient storage and access of the dependence graph and storage and indexing of rules and constraints are currently under investigation. The performance of the compilation method needs to be assessed and compared to methods that interleave compilation and evaluation, e.g. <ref> (Kuchenhoff, 1991) </ref>. A dual approach to constraint enforcement, based on compiling constraints into transaction specifications, is a topic of current research (Plexousakis and Mylopoulos, 1995). Finally, a more fine grained approach to integrity violation needs to be devised, possibly adopting ideas of finite constraint satisfiability (Bry, Decker and Manthey, 1988).
Reference: <author> Law, A. M. and Kelton, W. D. </author> <year> (1991). </year> <title> Simulation Modeling and Analysis. </title> <address> McGraw-Hill New York, NY. </address>
Reference-contexts: We employ a batch means method for the statistical data analysis of our results, and run each simulation long enough to obtain sufficiently tight confidence intervals (90% confidence level, within 5% of the mean) <ref> (Law and Kelton, 1991) </ref>. Performance of the DDG policy was studied on a knowledge base under development for industrial process control.
Reference: <author> Lengauer, T. and Tarjan, R. E. </author> <year> (1979). </year> <title> A Fast Dominator Algorithm for Finding Dominators in a Flow Graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 1(1) </volume> <pages> 121-141. </pages>
Reference-contexts: To enforce the locking rules, we need information on the dominator relationships and the strongly connected components within the knowledge base graph. In our implementation, the dominator tree of the knowledge base is computed at compile time using a bit vector algorithm <ref> (Lengauer and Tarjan, 1979) </ref>. Using this information, the dominator of the set of nodes in the transaction can be computed in time linear in the length of a transaction using the nearest common ancestor algorithm (Schieber and Vishkin, 1988). The dominator information is maintained using and incremental algorithm (Carroll, 1988).
Reference: <author> Ling, T. and Lee, S. </author> <year> (1992). </year> <title> Integrity Checking for Transactions in Relational Databases. </title> <booktitle> In International Computer Science Conference, </booktitle> <pages> pages 245-251. </pages>
Reference: <author> Lipeck, U. </author> <year> (1990). </year> <title> Transformation of Dynamic Integrity Constraints into Transaction Specifications. </title> <journal> Theoretical Computer Science, </journal> <volume> 76 </volume> <pages> 115-142. </pages>
Reference-contexts: A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). Along the same lines, a transaction modification technique for temporal constraints has been proposed in <ref> (Lipeck, 1990) </ref>, but does not account for implicit updates. A transaction modification method for temporal constraints and implicit updates appears in (Plexousakis, 1995). Transaction modification is less flexible than constraint simplification since each transaction has to be modified for each relevant constraint.
Reference: <author> Livny, M. </author> <year> (1986). </year> <title> DeNeT User's Guide (Version 1.5). </title> <type> Technical report, </type> <institution> University of Wisconsin. </institution>
Reference-contexts: These entries are created when the transaction begins execution and are incrementally updated as the transaction progresses and as changes in the underlying structure of the graph occur. 6.3 Performance Results The DDG policy has been implemented in the DeNet <ref> (Livny, 1986) </ref> simulation environment.
Reference: <author> Lockemann, P. C., Nagel, H.-H., and Walter, I. M. </author> <year> (1991). </year> <title> Databases for Knowledge Bases: empirical study of a knowledge base management system for a semantic network. </title> <journal> Data & Knowledge Engineering, </journal> <volume> 7 </volume> <pages> 115-154. </pages>
Reference: <author> Mylopoulos, J., Borgida, A., Jarke, M., and Koubarakis, M. </author> <year> (1990). </year> <title> Telos: A Language for Representing Knowledge About Information Systems. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 8(4) </volume> <pages> 325-362. </pages>
Reference-contexts: Moreover, the system supports reasoning mechanisms including deductive inference, constraint enforcement and temporal reasoning. The representation language adopted for the KBMS design is Telos <ref> (Mylopoulos et al., 1990) </ref>. The term "knowledge base" is used throughout the paper, instead of "database", mostly for historical reasons. <p> The methodology used to evaluate the proposed research results varies with the results being evaluated. Section 8 summarizes the results of this work and outlines open problems for further research. 2 Overview of Telos The representational framework of Telos <ref> (Mylopoulos et al., 1990) </ref> constitutes a generalization of graph-theoretic data structures used in semantic networks (Findler, 1979), semantic data models (Hull and King, 1987) and object-oriented representations (Zdonik and Maier, 1989). <p> This section introduces the core features of Telos which are divided into structural, temporal and assertional features. A more comprehensive description of the language can be found elsewhere <ref> (Mylopoulos et al., 1990) </ref>. 2.1 Structural Component A Telos knowledge base consists of structured objects built out of two kinds of primitive units, individuals and attributes. <p> The definitions of other functions can be found elsewhere <ref> (Mylopoulos et al., 1990) </ref>. The terms of the language include variables, constants (including conventional dates) and the result of applying functions to terms. <p> These services are interfaced with the logical layer through the knowledge representation language interpreter or compiler and a session manager. The logical layer maintains information on class definitions, including rules and constraints, and supports primitive knowledge base operations such as TELL and ASK <ref> (Mylopoulos et al., 1990) </ref>. <p> Each copy is clustered on one of the object identifiers of the two classes. A series of TJIs can be used to form the temporal equivalent of the multi-join index (Bertino and Kim, 1989). 5 Query Processing For the Telos KBMS, queries are specified through an ASK operation <ref> (Mylopoulos et al., 1990) </ref>, that has the following structure: ASK x 1 =S 1 ; :::; x n =S n : W AS OF t 2 x 1 ; :::; x n are assumed to be target variables for which the query processor needs to determine values; S 1 ; :::;
Reference: <author> Mylopoulos, J., Kramer, B., Wang, H., Benjamin, M., Chou, Q. B., and Mensah, S. </author> <year> (1992). </year> <title> Expert System Applications in Process Control. </title> <booktitle> In Proceedings of the International Symposium on Artificial Intelligence in Materials Processing Applications, </booktitle> <address> Edmonton. </address>
Reference-contexts: them; for an industrial process, such knowledge includes a plant schematic, knowledge about plant components (pipes, valves, boilers, etc.) and their operational characteristics, knowledge about hardwired functions (what does it mean when alarm 692 goes off) and diagnostic knowledge used by plant operators to determine the nature of an emergency <ref> (Mylopoulos et al., 1992) </ref>; * "grand challenges", such as information system support for environmental global change research (Stonebraker and Dozier, 1991) and the human GENOME project (Frenkel, 1991); * knowledge sharing applications that involve construction of generic knowledge bases that include thousands of concept descriptions and are used as references in <p> This suggests that if a knowledge base contains very large cycles which need to be locked as one node, concurrency will be reduced. We have a version of the DDG policy (called, DDG 0 policy) that does permit concurrency within cycles <ref> (Chaudhri, Hadzilacos and Mylopoulos, 1992) </ref>. We adopted the above version, because the transactions in knowledge bases tend to access all the nodes on a cycle together, and therefore, the cycles are a natural unit of locking.
Reference: <author> Neches, R., Fikes, R., Finin, T., Gruber, T., Patil, R., Senator, T., and Swartout, W. </author> <year> (1991). </year> <title> Enabling Technology for Knowledge Sharing. </title> <journal> AI Magazine, </journal> <volume> 12(3) </volume> <pages> 36-56. </pages>
Reference-contexts: such as information system support for environmental global change research (Stonebraker and Dozier, 1991) and the human GENOME project (Frenkel, 1991); * knowledge sharing applications that involve construction of generic knowledge bases that include thousands of concept descriptions and are used as references in the construction of knowledge based systems <ref> (Neches et al., 1991) </ref>. Such knowledge bases may be built in terms of existing knowledge representation systems (expert system shells, for instance) or AI languages such as Lisp or Prolog.
Reference: <author> Nicolas, J.-M. </author> <year> (1982). </year> <title> Logic for Improving Integrity Checking in Relational Databases. </title> <journal> Acta Informatica, </journal> <volume> 18 </volume> <pages> 227-253. </pages>
Reference-contexts: committed until all constraints are found to be satisfied. 12 12 A finer grained approach could initiate a sequence of updates that change the KB so that constraints are satisfied in the resulting state. 33 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. <ref> (Nicolas, 1982) </ref>, (Ceri and Widom, 1990),(Ling and Lee, 1992), (Gupta et al., 1994), ), deductive (e.g. (Decker, 1986), (Bry, Decker and Manthey, 1988), (Kuchenhoff, 1991)), object-oriented (Jeusfeld and Jarke, 1991) and temporal databases (Chomicki, 1992), have appeared in the recent literature.
Reference: <author> Paul, H.-B., Schek, H.-J., Scholl, M., Weikum, G., and Deppish, U. </author> <year> (1987). </year> <title> Architecture and Implementation of a Darmstadt Database Kernel System. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 196-207, </pages> <address> San Francisco, CA. </address>
Reference: <author> Plexousakis, D. </author> <year> (1993a). </year> <title> Integrity Constraint and Rule Maintenance in Temporal Deductive Knowledge Bases. </title> <booktitle> In Proceedings of the 19th International Conference on Very Large Data Bases, </booktitle> <pages> pages 146-157, </pages> <address> Dublin, Ireland. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Integrity constraints are used to express general, complex semantic relationships that cannot be built-into the data structures used to represent knowledge. Such relationships may refer to state transitions or histories <ref> (Plexousakis, 1993a) </ref>. <p> The compilation scheme allows for dynamic insertion or removal of integrity constraints and deductive rules without having to recompile the entire knowledge base. We describe the method in more detail in <ref> (Plexousakis, 1993a) </ref> . 7.2 A Constraint Enforcement Algorithm Our constraint enforcement method operates in two phases: compilation and evaluation. <p> Experiments with randomly generated dependence graphs have shown that, on the average, the execution time of computing single-source implicit updates is sub-linear in jEj <ref> (Plexousakis, 1993a) </ref>. 7.2.3 Evaluation Phase In this section we describe the evaluation phase of our algorithm. We first discuss how the dependence graph generated in the compilation phase is used to check the integrity constraints at the time of update.
Reference: <author> Plexousakis, D. </author> <year> (1993b). </year> <title> Semantical and Ontological Consideration in Telos: a Language for Knowledge Representation. </title> <journal> Computational Intelligence, </journal> <volume> 9(1) </volume> <pages> 41-72. </pages>
Reference-contexts: In addition, there have been formal accounts of the semantics of the language based on an axiomatic approach (Stanley, 1986) or 2 a possible-worlds model <ref> (Plexousakis, 1993b) </ref>. This section introduces the core features of Telos which are divided into structural, temporal and assertional features.
Reference: <author> Plexousakis, D. </author> <year> (1995). </year> <title> On the Efficient Enforcement of Integrity Constraints in Temporal Deductive Knowledge Bases. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Toronto. Forthcoming. </institution>
Reference-contexts: Along the same lines, a transaction modification technique for temporal constraints has been proposed in (Lipeck, 1990), but does not account for implicit updates. A transaction modification method for temporal constraints and implicit updates appears in <ref> (Plexousakis, 1995) </ref>. Transaction modification is less flexible than constraint simplification since each transaction has to be modified for each relevant constraint. <p> Detailed proofs can be found elsewhere <ref> (Plexousakis, 1995) </ref>. Theorem 7.1 The simplification rules PF1-PF6 are sound. Temporal simplification (rule PF6) is also complete. <p> There can be cycles among deductive rule nodes in the graph. This happens when R contains mutually recursive rules. There are no trivial cycles in the graph and it has the following property <ref> (Plexousakis, 1995) </ref>: Theorem 7.2 For any Telos knowledge base, dependence graph construction yields a graph that may contain cycles of length at most equal to the number of deductive rules participating in the same recursive scheme. <p> The time complexity for computing implicit updates caused by an explicit update matching some node in the graph is O (jEj), and O (jV R j fl jEj) for computing the transitive 41 closure of the entire graph by solving jV R j single-source problems <ref> (Plexousakis, 1995) </ref>. Experiments with randomly generated dependence graphs have shown that, on the average, the execution time of computing single-source implicit updates is sub-linear in jEj (Plexousakis, 1993a). 7.2.3 Evaluation Phase In this section we describe the evaluation phase of our algorithm. <p> Rule deletion requires worst-case time of O (jV R j fl jEj). An analytical model giving more precise characterizations of the cost of updates of rules and constraints can be found elsewhere <ref> (Plexousakis, 1995) </ref>. In addition to updating the dependence graph, we also need to incrementally compute its transitive closure. Incremental transitive closure algorithms available in literature can deal only with directed acyclic graphs (Ibaraki and Katoh, 1983; Italiano, 1988). <p> Incremental transitive closure algorithms available in literature can deal only with directed acyclic graphs (Ibaraki and Katoh, 1983; Italiano, 1988). In our research we have developed an algorithm that incrementally computes transitive closure for general graphs <ref> (Plexousakis, 1995) </ref>. Our preliminary experiments with randomly generated sparse cyclic graphs have shown that this algorithm can efficiently update the transitive closure of a dependence graph. <p> The performance of the compilation method needs to be assessed and compared to methods that interleave compilation and evaluation, e.g. (Kuchenhoff, 1991). A dual approach to constraint enforcement, based on compiling constraints into transaction specifications, is a topic of current research <ref> (Plexousakis and Mylopoulos, 1995) </ref>. Finally, a more fine grained approach to integrity violation needs to be devised, possibly adopting ideas of finite constraint satisfiability (Bry, Decker and Manthey, 1988).
Reference: <author> Plexousakis, D. and Mylopoulos, J. </author> <year> (1995). </year> <title> Accommodating Integrity Constraints During Database Design. </title> <note> Submitted for Publication. 47 Qaddah, </note> <author> G., Henschen, L., and Kim, J. </author> <year> (1991). </year> <title> Efficient Algorithms for the Instantiated Transitive Closure Queries. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(3) </volume> <pages> 296-309. </pages>
Reference-contexts: Along the same lines, a transaction modification technique for temporal constraints has been proposed in (Lipeck, 1990), but does not account for implicit updates. A transaction modification method for temporal constraints and implicit updates appears in <ref> (Plexousakis, 1995) </ref>. Transaction modification is less flexible than constraint simplification since each transaction has to be modified for each relevant constraint. <p> Detailed proofs can be found elsewhere <ref> (Plexousakis, 1995) </ref>. Theorem 7.1 The simplification rules PF1-PF6 are sound. Temporal simplification (rule PF6) is also complete. <p> There can be cycles among deductive rule nodes in the graph. This happens when R contains mutually recursive rules. There are no trivial cycles in the graph and it has the following property <ref> (Plexousakis, 1995) </ref>: Theorem 7.2 For any Telos knowledge base, dependence graph construction yields a graph that may contain cycles of length at most equal to the number of deductive rules participating in the same recursive scheme. <p> The time complexity for computing implicit updates caused by an explicit update matching some node in the graph is O (jEj), and O (jV R j fl jEj) for computing the transitive 41 closure of the entire graph by solving jV R j single-source problems <ref> (Plexousakis, 1995) </ref>. Experiments with randomly generated dependence graphs have shown that, on the average, the execution time of computing single-source implicit updates is sub-linear in jEj (Plexousakis, 1993a). 7.2.3 Evaluation Phase In this section we describe the evaluation phase of our algorithm. <p> Rule deletion requires worst-case time of O (jV R j fl jEj). An analytical model giving more precise characterizations of the cost of updates of rules and constraints can be found elsewhere <ref> (Plexousakis, 1995) </ref>. In addition to updating the dependence graph, we also need to incrementally compute its transitive closure. Incremental transitive closure algorithms available in literature can deal only with directed acyclic graphs (Ibaraki and Katoh, 1983; Italiano, 1988). <p> Incremental transitive closure algorithms available in literature can deal only with directed acyclic graphs (Ibaraki and Katoh, 1983; Italiano, 1988). In our research we have developed an algorithm that incrementally computes transitive closure for general graphs <ref> (Plexousakis, 1995) </ref>. Our preliminary experiments with randomly generated sparse cyclic graphs have shown that this algorithm can efficiently update the transitive closure of a dependence graph. <p> The performance of the compilation method needs to be assessed and compared to methods that interleave compilation and evaluation, e.g. (Kuchenhoff, 1991). A dual approach to constraint enforcement, based on compiling constraints into transaction specifications, is a topic of current research <ref> (Plexousakis and Mylopoulos, 1995) </ref>. Finally, a more fine grained approach to integrity violation needs to be devised, possibly adopting ideas of finite constraint satisfiability (Bry, Decker and Manthey, 1988).
Reference: <author> Schieber, B. and Vishkin, U. </author> <year> (1988). </year> <title> On Finding Lowest Common Ancestors: Simplification and Paralleliza-tion. </title> <journal> SIAM Journal of Computing, </journal> <volume> 17(6) </volume> <pages> 1253-1262. </pages>
Reference-contexts: Using this information, the dominator of the set of nodes in the transaction can be computed in time linear in the length of a transaction using the nearest common ancestor algorithm <ref> (Schieber and Vishkin, 1988) </ref>. The dominator information is maintained using and incremental algorithm (Carroll, 1988). The information on strongly connected components is computed at compile time in time O (m) (Aho, Hopcroft and Ullman, 1987), where m is the number of edges in the graph.
Reference: <author> Selinger, G., Astrahan, M., Chamberlin, D., Lorie, R., and Price, T. </author> <year> (1979). </year> <title> Access Path Selection in a Relational Database Management System. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 23-34. </pages>
Reference-contexts: In general, a query is subjected to four phases of processing: parsing, optimization, code generation and execution <ref> (Selinger et al., 1979) </ref>. The focus of this section is on the optimization phase. Query optimization for knowledge bases is hard for several reasons. First, the representation formalism adopted for the knowledge bases is more expressive given a query language with temporal, spatial, class- and meta-class-related expressions. <p> For a query with n classes, there are n (n 1) parameterized trees generated, in the worst case. Unfortunately, the substitution of the primitive operations on the parameterized tree implies a O (2 n1 ) size of the execution space that obviates the enumeration of all possible executions <ref> (Selinger et al., 1979) </ref>. 22 In order to pick an execution tree with an optimal cost, we need a cost function that is used to compute the cost of access plan corresponding to each execution tree.
Reference: <author> Shrufi, A. </author> <year> (1994). </year> <title> Performance of Clustering Policies in Object Bases. </title> <booktitle> In Proceedings of the Third Conference on Information and Knowledge Management, </booktitle> <pages> pages 80-87. </pages>
Reference-contexts: Soundness and completeness of the simplification method have been proven and preliminary performance results have been established. Clearly, the design and performance analysis of the proposed architecture is not complete. In particular, work is in progress on the physical design of the KBMS <ref> (Shrufi, 1994) </ref>, exploring the use of existing database storage kernels. A thorough experimental performance analysis is planned to validate the cost function of our storage and query model. The study of semantic criteria for reducing the search space when an access is planned is an issue that requires further research.
Reference: <author> Silberschatz, A. and Kedem, Z. M. </author> <year> (1980). </year> <title> Consistency in Hierarchical Database Systems. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 27(1) </volume> <pages> 72-80. </pages>
Reference: <author> Snodgrass, R. </author> <year> (1987). </year> <title> The Temporal Query Language TQuel. </title> <journal> ACM Transcactions on Database Systems, </journal> <volume> 12(2) </volume> <pages> 247-298. </pages>
Reference-contexts: The second query retrieves all employees who worked for the database group of IBM in 1990 according to what the system 15 currently believes. The first query is a temporal query and the second is a historical query <ref> (Snodgrass, 1987) </ref>. Q1. ASK e=Employee : Exist t 1 ; t 2 =TimeInterval (e [t 1 ]:salary e [t 2 ]:salary 5000) and (t 1 before t 2 ) ON 1988 Q2.
Reference: <author> Stanley, M. </author> <year> (1986). </year> <title> CML: A Knowledge Representation Language with Application to Requirements Modeling. </title> <type> Technical report, </type> <institution> University of Toronto, Toronto. </institution>
Reference-contexts: Telos treats attributes as first-class citizens, supports a powerful classification (or instantiation) mechanism which enhances extensibility and offers special representational and inferential mechanisms for temporal knowledge. In addition, there have been formal accounts of the semantics of the language based on an axiomatic approach <ref> (Stanley, 1986) </ref> or 2 a possible-worlds model (Plexousakis, 1993b). This section introduces the core features of Telos which are divided into structural, temporal and assertional features.
Reference: <author> Steinbrunn, M., Moerkotte, G., and Kemper, A. </author> <year> (1993). </year> <title> Optimizing Join Orders. </title> <type> Technical Report MIP-9307, </type> <institution> Universitat Passsu, Fakulat fur Mathematik and Informatik. </institution>
Reference-contexts: Second, it has been argued that the space of left-deep trees covers the space containing the the execution strategies that incur the least cost, where cost is typically measured in terms of disk I/O required by the strategy <ref> (Steinbrunn, Moerkotte and Kemper, 1993) </ref>. Third, in the controlled decomposition model adopted here, the left-deep trees better utilize the join index relations that are available. The number of all possible P O trees for a query graph with n nodes is at most n (n 1).
Reference: <author> Stickel, M. </author> <year> (1985). </year> <title> Automated Deduction by Theory Resolution. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 455-458, </pages> <address> Los Angeles, CA. </address>
Reference-contexts: Second, we have reformulated the known techniques for syntactic simplification (Jarke and Koch, 1984; Chakravarthy, Grant and Minker, 1988) to exploit the properties of a knowledge base, such as generalization and aggregation. Finally, we have advanced the semantic transformation techniques by using theory resolution <ref> (Stickel, 1985) </ref> and specialized reasoners. In the following, we summarize the three steps in semantic optimization. <p> proceeds as follows: It takes as input the set of relevant deductive rules and integrity constraints, called the rule base, which is returned from the temporal simplification algorithm, and the query form which is returned from the syntactic simplification algorithm and applies the transformation to the query using theory resolution <ref> (Stickel, 1985) </ref>. There are some unique features of this algorithm. First, it uses the reduced size rule base that is produced by the temporal simplification and is specific to the query being optimized; consequently, it reduces the search space for the resolution based transformations.
Reference: <author> Stonebraker, M. </author> <year> (1975). </year> <title> Implementation of Integrity Constraints and Views by Query Modification. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 65-78. </pages>
Reference-contexts: A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in <ref> (Stonebraker, 1975) </ref> and (Wallace, 1991). Along the same lines, a transaction modification technique for temporal constraints has been proposed in (Lipeck, 1990), but does not account for implicit updates. A transaction modification method for temporal constraints and implicit updates appears in (Plexousakis, 1995).
Reference: <author> Stonebraker, M. and Dozier, J. </author> <year> (1991). </year> <title> An Overview of the SEQUOIA 2000 Project. </title> <type> Technical Report SEQUOIA-TR-91/5, </type> <institution> University of California, Berkeley. </institution>
Reference-contexts: boilers, etc.) and their operational characteristics, knowledge about hardwired functions (what does it mean when alarm 692 goes off) and diagnostic knowledge used by plant operators to determine the nature of an emergency (Mylopoulos et al., 1992); * "grand challenges", such as information system support for environmental global change research <ref> (Stonebraker and Dozier, 1991) </ref> and the human GENOME project (Frenkel, 1991); * knowledge sharing applications that involve construction of generic knowledge bases that include thousands of concept descriptions and are used as references in the construction of knowledge based systems (Neches et al., 1991).
Reference: <author> Tay, Y. C. </author> <year> (1987). </year> <title> Locking Performance in Centralized Databases. </title> <publisher> Academic Press, London. </publisher>
Reference-contexts: It has been shown that the performance results of a 2PL algorithm on a knowledge base of size of D entities with N active transactions are indicative of its performance on another knowledge base of size bD entities with bN active transactions, where b &gt; 0 <ref> (Tay, 1987) </ref>. In a similar fashion we expect that our results are representative of the relative performance of 2PL and the DDG policy on knowledge bases that are larger and have greater number of active transactions.
Reference: <author> Topaloglou, T. </author> <year> (1993). </year> <title> Storage Management for Knowledge Bases. </title> <booktitle> In Proceedings of Second International Conference on Information and Knowledge Management (CIKM'93). </booktitle>
Reference-contexts: C3. A token is stored as a tuple in the relation corresponding to the most general class of which the token is an instance. Object identifiers are assigned to each tuple using a hierarchical scheme (see <ref> (Topaloglou, 1993) </ref>). C4. <p> A more general model that does not make this assumption is available elsewhere <ref> (Topaloglou, 1993) </ref>. rds (DSM) = k=0 h X b j )N (2) Note that equations 1 and 2 modify (Copeland and Khoshafian, 1985) formulas for NSM and DSM storage, taking into account attributes defined over isA hierarchies. <p> Therefore, in Equation 1, the term kl is dropped when computing the storage cost, and a correction cor (N SM ) is applied to take into account the cost of storage of the instances (A more detailed analysis appears elsewhere <ref> (Topaloglou, 1993) </ref>.) With this change, the expression for the storage cost of CDM is as follows: rds (CDM) = (1 d) fl (rds (N SM ) + cor (N SM )) + d fl rds (DSM ) (3) The estimates of space costs suggested by the above formulae confirm the claim <p> The cost in CDM is the weighted sum of the costs of the NSM and DSM models. Experimental results have shown that CDM's cost can be as low as 1/4 of DSM costs <ref> (Topaloglou, 1993) </ref>. 4. Updating the value of an attribute: First, the relevant storage record is located by accessing an index. Then, the block which contains that record is written and the attribute's index is updated. <p> Given an object identifier, RAI determines the location of its components on disk. Due to space limitations, only a brief discussion of STI and TJI is presented here. The interested reader can find more details about the functionality and the performance of the above indices elsewhere <ref> (Topaloglou, 1993) </ref>. The STI and TJI are generalizations of non-temporal indices where, in contrast to the traditional hkey; valuei pair, each entry is a triplet hkey; value; timei, where time is the history time during which the entry is true.
Reference: <author> Topaloglou, T., Illarramendi, A., and Sbattella, L. </author> <year> (1992). </year> <title> Query Optimization for KBMSs: Temporal, Syntactic and Semantic Transformation. </title> <booktitle> In Proceedings of the International Conference on Data Engineering, </booktitle> <pages> pages 310-319. </pages>
Reference-contexts: Finally, we have advanced the semantic transformation techniques by using theory resolution (Stickel, 1985) and specialized reasoners. In the following, we summarize the three steps in semantic optimization. More details can be found elsewhere <ref> (Topaloglou, Illarramendi and Sbattella, 1992) </ref>. 16 5.1.1 Temporal Simplification Temporal simplification attempts to identify those parts of a knowledge base that are relevant to a query from a temporal viewpoint (Jarke and Koubarakis, 1989). Temporal simplification involves the following three steps: 1. <p> Theory resolution is, in general, more efficient than classical resolution because it decreases the length of refutations and the size of the search space. Finally, our semantic transformation algorithm has been shown to be sound <ref> (Topaloglou, Illarramendi and Sbattella, 1992) </ref>. 5.2 Physical Query Optimization The task of physical query optimizer is to take the simplified query as generated by the semantic optimization phase and generate an optimal execution strategy.
Reference: <author> Ullman, J. </author> <year> (1988). </year> <title> Principles of Data Base and Knowledge Base Systems, volume 1. </title> <publisher> Addison Wesley. </publisher>
Reference-contexts: Their general form is: DR 8x 1 =C 1 : : : 8x n =C n (F ) A) where F is subject to the same restrictions as above and A is an atom of the assertion language. In addition deductive rules are assumed to be stratified 15 <ref> (Ullman, 1988) </ref>. Let us now introduce some terminology that we will use in the rest of the section. Definition 7.1 An update is an instantiated literal. A positive literal is considered as an insertion, whereas a negative literal is considered as a deletion.
Reference: <author> Valduriez, P. </author> <year> (1987). </year> <title> Join Indices. </title> <journal> ACM Transaction on Database Systems, </journal> <volume> 12(2) </volume> <pages> 218-246. </pages>
Reference-contexts: In this section we propose an algorithm called, Controlled Decomposition Method (CDM), that combines the advantages of both the NSM and DSM and also takes into account temporal knowledge. As far as access methods are concerned, the most promising solution for knowledge bases is the join index <ref> (Valduriez, 1987) </ref>. The join index is used, as part of the data storage, by the DSM. Once again, however, this index cannot be adopted as it is because it offers no provisions for dealing with temporal attributes.
Reference: <author> Valduriez, P., Khoshafian, S., and Copeland, G. </author> <year> (1986). </year> <title> Implementation Techniques of Complex Objects. </title> <booktitle> In Proceedings of the 12th International Conference on Very Large Data Bases, </booktitle> <pages> pages 101-109, </pages> <address> Kyoto, Japan. </address>
Reference: <author> Vilain, M., Kautz, H., and van Beek, P. </author> <year> (1989). </year> <title> Constraint Propagation Algorithms for Temporal Reasoning: </title> <note> a Revised Report. In Weld, </note> <editor> D. and de Kleer, J., editors, </editor> <booktitle> Readings in Qualitative Reasoning about Physical Systems, </booktitle> <pages> pages 373-381. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The first step is formulated as a constraint satisfaction problem (CSP) on the temporal relations of the query formula. These relations are interval constraints which belong in the pointsable class and therefore the CSP is solved in polynomial time <ref> (Vilain, Kautz and van Beek, 1989) </ref>.
Reference: <author> Wallace, M. </author> <year> (1991). </year> <title> Compiling Integrity Checking into Update Procedures. </title> <booktitle> In Proceedings of the 12th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 903-908. </pages>
Reference-contexts: A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and <ref> (Wallace, 1991) </ref>. Along the same lines, a transaction modification technique for temporal constraints has been proposed in (Lipeck, 1990), but does not account for implicit updates. A transaction modification method for temporal constraints and implicit updates appears in (Plexousakis, 1995).
Reference: <author> Yannakakis, M. </author> <year> (1982). </year> <title> A Theory of Safe Locking Policies in Database Systems. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 29(3) </volume> <pages> 718-740. </pages>
Reference: <author> Yao, S. </author> <year> (1977). </year> <title> Approximating Block Accesses in Database Organizations. </title> <journal> Communications of ACM, </journal> <volume> 20(4) </volume> <pages> 260-261. </pages>
Reference-contexts: ; j C j) Legend: R C storage relation for class C P qualification predicate selectivity of a predicate I C a index relation for class C, attr. a B storage capacity of a page L C list of OIDs of class C Yao (K; M; N ) Yao's formula <ref> (Yao, 1977) </ref> LP Index pages at leaf level V C;i unique instances of C in the r a avg. number of historical values domain of ith attribute associated with each occurrence of attr. a h tree height of an index tree M R C number of pages for storage relation R
Reference: <author> Zdonik, S. B. and Maier, D., </author> <title> editors (1989). Readings in Object-Oriented Databases. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA. </address> <month> 49 </month>
Reference-contexts: 8 summarizes the results of this work and outlines open problems for further research. 2 Overview of Telos The representational framework of Telos (Mylopoulos et al., 1990) constitutes a generalization of graph-theoretic data structures used in semantic networks (Findler, 1979), semantic data models (Hull and King, 1987) and object-oriented representations <ref> (Zdonik and Maier, 1989) </ref>. Telos treats attributes as first-class citizens, supports a powerful classification (or instantiation) mechanism which enhances extensibility and offers special representational and inferential mechanisms for temporal knowledge.
References-found: 79

