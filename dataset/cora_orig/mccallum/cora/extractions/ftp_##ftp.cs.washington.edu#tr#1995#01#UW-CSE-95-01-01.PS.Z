URL: ftp://ftp.cs.washington.edu/tr/1995/01/UW-CSE-95-01-01.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-date.html
Root-URL: http://www.cs.washington.edu
Title: TRIBORS: A Triplet-Based Object Recognition System  
Author: Kari Pulli 
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. O. Binford, </author> <title> "Survey of Model-Based Image Analysis", </title> <journal> International Journal of Robotics Research, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 18-64, </pages> <year> 1982. </year>
Reference-contexts: 1 Introduction Model-based object recognition <ref> [1] </ref> is a subfield of Computer Vision that attempts to deduce the identities and location of objects using sensor information. Typically, the sensor information comes in the form of a digitized camera image, where the data describes the intensity or color variations of the reflected light.
Reference: [2] <author> R. C. Bolles, R. A. Cain, </author> <title> "Recognizing and Locating Partially Visible Objects: The Local-Feature-Focus Method", </title> <journal> International Journal of Robotics Research, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 57-82, </pages> <year> 1982. </year>
Reference-contexts: The mapping of model and object features is a combinatorial problem and is usually approached by applying some search method [10]. The Random Sample Consensus (RANSAC) [9] avoids the combinatorics of an exhaustive search by using a randomized hypothesis-verification method. The related Local Feature Focus (LFF) method <ref> [2] </ref> tries to constrain the large search space by concentrating on small clusters of key features. The 3DPO system [13] implements the same ideas in 3D using range data. <p> Often only a few matched features are enough to fully constrain the pose of the whole object, and hence also the locations of all the other features. This is the idea behind the Local Feature Focus (LFF) method of Bolles and Cain <ref> [2] </ref>. The method uses only small sets of features that are spatially close to each other for overcoming a common problem in object recognition: occlusion.
Reference: [3] <author> K. L. Boyer, A. C. </author> <title> Kak "Structural Stereopsis for 3-D Vision", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 10, no. 2, </volume> <pages> pp. 144-166, </pages> <year> 1988. </year>
Reference-contexts: There are two related methods for evaluating the partial or final matches. One of them is based on information theory <ref> [3] </ref> [25], while the other is based on probability theory [4]. Our approach is the probabilistic one and is related to the PREMIO system of Camps [4].
Reference: [4] <author> O. I. Camps, PREMIO: </author> <title> The Use of Prediction in a CAD-Model-Based Vision System, </title> <type> PhD thesis, </type> <institution> Univ. of Washington, </institution> <address> Seattle, </address> <year> 1992. </year>
Reference-contexts: There are two related methods for evaluating the partial or final matches. One of them is based on information theory [3] [25], while the other is based on probability theory <ref> [4] </ref>. Our approach is the probabilistic one and is related to the PREMIO system of Camps [4]. PREMIO (Prediction in Matching Images to Objects) constructs view-dependent probability models that incorporate the errors due to the interplay of surface reflectance properties, lighting conditions, and image processing operators. <p> There are two related methods for evaluating the partial or final matches. One of them is based on information theory [3] [25], while the other is based on probability theory <ref> [4] </ref>. Our approach is the probabilistic one and is related to the PREMIO system of Camps [4]. PREMIO (Prediction in Matching Images to Objects) constructs view-dependent probability models that incorporate the errors due to the interplay of surface reflectance properties, lighting conditions, and image processing operators. The matching method used in PREMIO is an iterative-deepening A* search guided by probability information about feature attributes.
Reference: [5] <author> J. Canny, </author> <title> "A computational approach to edge detection", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. PAMI-6, no.6, </volume> <pages> pp. 679-698, </pages> <year> 1986. </year>
Reference-contexts: Edge detection. We use the Canny edge detector <ref> [5] </ref> for extracting the edges from the images. The idea behind this detector is to first calculate the gradients of the intensities within the image and then to link together pixels with high gradient values. The same programs are used for both the synthesized and the real images. Line detection.
Reference: [6] <author> M. Dhome, M. Richetin, J-T Lapreste, G. Rives, </author> <title> "Determination of the Attitude of 3-D Objects from a Single Perspective View", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 11, no. 12, </volume> <pages> pp. 1265-1278, </pages> <year> 1989. </year>
Reference-contexts: On the other hand, this general characterization means that the triples cannot be matched in isolation, but only in context of several other triples, whose interrelationships are known. Since three line matches are enough in most cases to constrain the view point to a unique solution <ref> [6] </ref>, 2 we chose to concentrate more on individual line triplets rather than tracking their relationships. Our triplets are not constrained to be joint, and their appearance is not constrained in any way. <p> The next step is to obtain an initial estimate for the pose of the object. Dhome et al. <ref> [6] </ref> have developed a method that analytically derives the possible 3D poses from matched triplets of image lines by solving the inverse perspective equations.
Reference: [7] <author> A. Etemadi, J-P Schmidt, G. Matas, J. Illingworth, J. Kittler, </author> <title> "Low-level Grouping of Straight Line Segments", </title> <booktitle> Proc. of the IEE Image Processing Conference, </booktitle> <year> 1991. </year>
Reference-contexts: The same programs are used for both the synthesized and the real images. Line detection. The edge pixels obtained using the Canny edge detector are input to the Object Recognition Toolkit (ORT) <ref> [7] </ref> [8] which extracts straight lines and circular arcs from the edgel chains. ORT also provides for grouping of the line segments according to parallel, collinear, intersecting, etc. relationships. Pose estimation.
Reference: [8] <author> A. Etemadi, </author> <title> "Robust Segmentation of Edge Data", </title> <booktitle> Proc. of the IEE Image Processing Conference, </booktitle> <year> 1992. </year>
Reference-contexts: The same programs are used for both the synthesized and the real images. Line detection. The edge pixels obtained using the Canny edge detector are input to the Object Recognition Toolkit (ORT) [7] <ref> [8] </ref> which extracts straight lines and circular arcs from the edgel chains. ORT also provides for grouping of the line segments according to parallel, collinear, intersecting, etc. relationships. Pose estimation. We use only one algorithm for obtaining both the initial estimate for the pose and for the refined pose estimate.
Reference: [9] <author> M. A. Fischler, R. C. Bolles, </author> <title> "Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography", </title> <journal> Communications of ACM, </journal> <volume> 24(6), </volume> <pages> pp. 381-395, </pages> <year> 1981. </year> <month> 20 </month>
Reference-contexts: The correspondence problem can be tackled by studying the the interrelationships of features (see Vosselman [25] for a good description of relational matching). The mapping of model and object features is a combinatorial problem and is usually approached by applying some search method [10]. The Random Sample Consensus (RANSAC) <ref> [9] </ref> avoids the combinatorics of an exhaustive search by using a randomized hypothesis-verification method. The related Local Feature Focus (LFF) method [2] tries to constrain the large search space by concentrating on small clusters of key features. The 3DPO system [13] implements the same ideas in 3D using range data.
Reference: [10] <author> W. E. L. </author> <title> Grimson, "The Combinatorics of Object Recognition in Cluttered Environments using Constrained Search", </title> <booktitle> Proc. International Conference on Computer Vision, </booktitle> <pages> pp. 218-227, </pages> <year> 1988. </year>
Reference-contexts: The correspondence problem can be tackled by studying the the interrelationships of features (see Vosselman [25] for a good description of relational matching). The mapping of model and object features is a combinatorial problem and is usually approached by applying some search method <ref> [10] </ref>. The Random Sample Consensus (RANSAC) [9] avoids the combinatorics of an exhaustive search by using a randomized hypothesis-verification method. The related Local Feature Focus (LFF) method [2] tries to constrain the large search space by concentrating on small clusters of key features.
Reference: [11] <author> R. M. Haralick, L. G. Shapiro, </author> <title> Computer and Robot Vision, </title> <journal> vol. </journal> <volume> 2, </volume> <publisher> Addison-Wesley, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: ORT also provides for grouping of the line segments according to parallel, collinear, intersecting, etc. relationships. Pose estimation. We use only one algorithm for obtaining both the initial estimate for the pose and for the refined pose estimate. The exterior orientation algorithm, implemented by Ken Thornton and described in <ref> [11] </ref>, needs as its input a set of 3D-point-to-2D-point (model-to-image) correspondences and a starting guess for the viewing parameters 5 . There are several ways of obtaining point correspondences from line correspondences. The simplest way is to match the end points of the lines.
Reference: [12] <author> J. Henikoff, L. G. Shapiro, </author> <title> "Representative Patterns for Model-Based Matching", </title> <journal> Pattern Recognition, </journal> <volume> vol. 26, no. 7, </volume> <pages> pp. 1087-1098, </pages> <year> 1993. </year>
Reference-contexts: The 3DPO system [13] implements the same ideas in 3D using range data. Other techniques for making the expensive search more intelligent include finding viewpoint invariant features [15] [24] or perceptual groupings [19] <ref> [12] </ref> that can be used to constrain the possible mappings. There are two related methods for evaluating the partial or final matches. One of them is based on information theory [3] [25], while the other is based on probability theory [4]. <p> Triplet matching does not remove the need for searching, but it guarantees that the search space will never grow very large, since the depth of the search tree is limited to three, the number of features needed to constrain the object pose. 3 2.2 Representative patterns Henikoff and Shapiro <ref> [12] </ref> have presented a matching method based on based on representative patterns, a collection of edge chains consisting of sets of linked line segments. The building blocks of the edge chains are ordered sets of three lines called triples.
Reference: [13] <author> P. Horaud, R. C. Bolles, "3DPO: </author> <title> A System for Matching 3-D Objects in Range Data", </title> <editor> in A. P. Pentland, editor, </editor> <booktitle> From Pixels to Predicates, </booktitle> <pages> pp. 359-370, </pages> <publisher> Ablex Publishing Corporation, </publisher> <address> New Jersey, </address> <year> 1986. </year>
Reference-contexts: The Random Sample Consensus (RANSAC) [9] avoids the combinatorics of an exhaustive search by using a randomized hypothesis-verification method. The related Local Feature Focus (LFF) method [2] tries to constrain the large search space by concentrating on small clusters of key features. The 3DPO system <ref> [13] </ref> implements the same ideas in 3D using range data. Other techniques for making the expensive search more intelligent include finding viewpoint invariant features [15] [24] or perceptual groupings [19] [12] that can be used to constrain the possible mappings.
Reference: [14] <author> R. Horaud, </author> <title> "New Methods for Matching 3-D Objects with Single Perspective Views", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. PAMI-9, no.3, </volume> <pages> pp. 401-412, </pages> <year> 1987. </year>
Reference-contexts: Many other methods require a rough initial guess for the pose in order to converge to a solution. For example Lowe [19] [20] gave an iterative algorithm based on Newton's method that can be used for obtaining poses of parameterized 3D objects. Other methods are described in [16] and <ref> [14] </ref>. For our purposes we could use any of those methods, since the general viewing direction is assumed to be known by the choice of the probability model (there is a one-to-one correspondence between probability models and view classes).
Reference: [15] <author> Y. Lamdan, J. T. Schwartz, H. J. Wolfson, </author> <title> "Affine invariant model-based object recognition", </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> vol. 6, no. 5, </volume> <pages> pp. 578-89, </pages> <year> 1990. </year>
Reference-contexts: The 3DPO system [13] implements the same ideas in 3D using range data. Other techniques for making the expensive search more intelligent include finding viewpoint invariant features <ref> [15] </ref> [24] or perceptual groupings [19] [12] that can be used to constrain the possible mappings. There are two related methods for evaluating the partial or final matches. One of them is based on information theory [3] [25], while the other is based on probability theory [4].
Reference: [16] <author> C-N Lee, </author> <title> "Exterior Orientation from Line-to-Line Correspondences A Bayesian Approach", </title> <year> 1992. </year>
Reference-contexts: Many other methods require a rough initial guess for the pose in order to converge to a solution. For example Lowe [19] [20] gave an iterative algorithm based on Newton's method that can be used for obtaining poses of parameterized 3D objects. Other methods are described in <ref> [16] </ref> and [14]. For our purposes we could use any of those methods, since the general viewing direction is assumed to be known by the choice of the probability model (there is a one-to-one correspondence between probability models and view classes).
Reference: [17] <author> Y. Liu, T. S. Huang, O. D. Faugeras, </author> <title> "Determination of Camera Location from 2-D to 3-D Line and Point Correspondences", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 12, no. 1, </volume> <pages> pp. 28-37, </pages> <year> 1990. </year>
Reference: [18] <author> P. P. Loutrel, </author> <title> "A solution to the hidden-line problem for computer-drawn polyhedra", </title> <journal> IEEE Trans. on Computers, </journal> <volume> 19(3), </volume> <pages> pp. 205-210, </pages> <year> 1970. </year>
Reference-contexts: The verification starts with the creation of a wireframe image of the object model so that the pose of the wireframe equals the initial pose estimate. The visibility of the edges of the wireframe can be determined by a hidden line detection algorithm <ref> [18] </ref>. Our system implements a quick version of that algorithm which removes most of the hidden lines. Once the visible edges and their locations have been predicted we search for image lines that would match them.
Reference: [19] <author> D. G. Lowe, </author> <title> "Three-Dimensional Object Recognition from Single Two-Dimensional Images", </title> <journal> Artificial Intelligence, </journal> <volume> 31, </volume> <pages> pp. 355-395, </pages> <year> 1987. </year>
Reference-contexts: The 3DPO system [13] implements the same ideas in 3D using range data. Other techniques for making the expensive search more intelligent include finding viewpoint invariant features [15] [24] or perceptual groupings <ref> [19] </ref> [12] that can be used to constrain the possible mappings. There are two related methods for evaluating the partial or final matches. One of them is based on information theory [3] [25], while the other is based on probability theory [4]. <p> Many other methods require a rough initial guess for the pose in order to converge to a solution. For example Lowe <ref> [19] </ref> [20] gave an iterative algorithm based on Newton's method that can be used for obtaining poses of parameterized 3D objects. Other methods are described in [16] and [14].
Reference: [20] <author> D. G. Lowe, </author> <title> "Fitting Parameterized Three-Dimensional Models to Images", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 13, no. 5, </volume> <pages> pp. 441-450, </pages> <year> 1991. </year>
Reference-contexts: Many other methods require a rough initial guess for the pose in order to converge to a solution. For example Lowe [19] <ref> [20] </ref> gave an iterative algorithm based on Newton's method that can be used for obtaining poses of parameterized 3D objects. Other methods are described in [16] and [14].
Reference: [21] <author> T. M. Mitchell, R. Keller, S. Kedar-Cabelli, </author> <title> "Explanation-Based Generalization: A Unifying View", </title> <journal> Machine Learning 1, </journal> <volume> 1, </volume> <year> 1986. </year>
Reference-contexts: This formulation enables us to look at the creation of probability models as an instance of explanation-based learning problem. Explanation-based learning <ref> [21] </ref> [22] enables an intelligent and economical use of training examples by using prior information. The method iterates over three steps: explanation, analysis, and refinement. Explanation.
Reference: [22] <author> T. M. Mitchell, </author> <title> Essentials of Machine Learning, </title> <note> to appear. </note>
Reference-contexts: This formulation enables us to look at the creation of probability models as an instance of explanation-based learning problem. Explanation-based learning [21] <ref> [22] </ref> enables an intelligent and economical use of training examples by using prior information. The method iterates over three steps: explanation, analysis, and refinement. Explanation.
Reference: [23] <author> K. B. Thornton, L. G. Shapiro, </author> <title> "Image Matching for View Class Construction", </title> <booktitle> Proc. of the Sixth Israeli Conf. on Artificial Intelligence, Vision, and Pattern Recognition, </booktitle> <pages> pp. 220-229, </pages> <year> 1989. </year>
Reference-contexts: Small changes in view point, however, do not normally change the appearance very much. From this fact arises the idea of view classes <ref> [23] </ref>.
Reference: [24] <author> F. C. D. Tsai, </author> <title> "Geometric Hashing with Line Features", </title> <journal> Pattern Recognition, </journal> <volume> vol. 27, no. 3, </volume> <pages> pp. 377-389, </pages> <year> 1994. </year>
Reference-contexts: The 3DPO system [13] implements the same ideas in 3D using range data. Other techniques for making the expensive search more intelligent include finding viewpoint invariant features [15] <ref> [24] </ref> or perceptual groupings [19] [12] that can be used to constrain the possible mappings. There are two related methods for evaluating the partial or final matches. One of them is based on information theory [3] [25], while the other is based on probability theory [4]. <p> It is possible that some faces or edges of an object are visible, or partially or totally occluded, depending on the exact view and the threshold *. The determination of the correct view class could be done by geometric hashing <ref> [24] </ref> where some salient features vote for the directions where they can be observed, or the application can be one where only a couple of different view classes are possible. For example, an assembly part coming on a conveyer belt could have only a limited number of stable orientations.
Reference: [25] <author> G. Vosselman, </author> <title> Relational Matching, </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1992. </year> <month> 21 </month>
Reference-contexts: The correspondence problem can be tackled by studying the the interrelationships of features (see Vosselman <ref> [25] </ref> for a good description of relational matching). The mapping of model and object features is a combinatorial problem and is usually approached by applying some search method [10]. The Random Sample Consensus (RANSAC) [9] avoids the combinatorics of an exhaustive search by using a randomized hypothesis-verification method. <p> There are two related methods for evaluating the partial or final matches. One of them is based on information theory [3] <ref> [25] </ref>, while the other is based on probability theory [4]. Our approach is the probabilistic one and is related to the PREMIO system of Camps [4].
References-found: 25

