URL: ftp://ftp.cs.colorado.edu/users/alw/papers/CU-CS-840-97.ps
Refering-URL: http://www.cs.colorado.edu/users/alw/RecentPubs.html
Root-URL: http://www.cs.colorado.edu
Email: jcook@cs.nmsu.edu alw@cs.colorado.edu  
Title: Software Process Validation: Quantitatively Measuring the Correspondence of a Process to a Model  
Author: Jonathan E. Cook Alexander L. Wolf 
Address: Las Cruces, NM 88003 USA Boulder, CO 80309 USA  
Affiliation: Department of Computer Science Department of Computer Science New Mexico State University University of Colorado  
Abstract: University of Colorado Department of Computer Science Technical Report CU-CS-840-97 May 1997 ABSTRACT To a great extent, the usefulness of a formal model of a software process lies in its ability to accurately predict the behavior of the executing process. Similarly, the usefulness of an executing process lies largely in its ability to fulfill the requirements embodied in a formal model of the process. When process models and process executions diverge, something significant is happening. We have developed techniques for uncovering and measuring the discrepancies between models and executions, which we call process validation. Process validation takes a process execution and a process model, and measures the level of correspondence between the two. Our metrics our tailorable and give process engineers control over determining the severity of different types of discrepancies. The techniques provide detailed information once a high-level measurement indicates the presence of a problem. We have applied our process validation methods in an industrial case study, of which a portion is described in this paper. This work was supported in part by the National Science Foundation under grant CCR-93-02739 and by the Air Force Material Command, Rome Laboratory, and the Defense Advanced Research Projects Agency under Contract Number F30602-94-C-0253. The content of the information does not necessarily reflect the position or the policy of the Government and no official endorsement should be inferred. c fl 1997 Jonathan E. Cook and Alexander L. Wolf
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho and T.G. Peterson. </author> <title> A minimum distance error-correcting parser for context-free languages. </title> <journal> SIAM Journal on Computing, </journal> <volume> 1(4) </volume> <pages> 305-312, </pages> <month> December </month> <year> 1972. </year>
Reference-contexts: By applying various mathematical transformations, this method becomes a family of metrics. String distance metrics have been used in applications as varied as DNA/RNA matching [44], substring matching [30, 40], spelling error correction [17], syntax error correction <ref> [1, 23, 39] </ref>, and even the well-known UNIX tool for comparing text files, diff. <p> A minimal correction is desired to allow the compiler to process as much of the program as possible, and thus this problem is similar the one we face in process validation. Compiler research has produced several methods of interest here. * Aho and Peterson <ref> [1] </ref> show a cubic algorithm for performing globally minimum cost error correction in terms of token insertion and deletion. They do not expect their algorithm to be used, however, because of its high cost.
Reference: [2] <author> G.S. Avrunin, U.A. Buy, J.C. Corbett, L.K. Dillon, and J.C. Wileden. </author> <title> Automated Analysis of Concurrent Systems with the Constrained Expression Toolset. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(11) </volume> <pages> 1204-1222, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: The use of events to characterize behavior is already widely accepted in other areas of software engineering, such as program visualization [34], concurrent-system analysis <ref> [2] </ref>, and distributed debugging [5, 14]. The "instant" of an event is relative to the time granularity that is needed or desired; thus, certain activities that are of short duration relative to the time granularity are represented as a single event. <p> If models do not have regularity in the state space, they admit that their techniques will not provide much leverage. Another example of a technique to search for a behavior is found in the Constrained Expressions framework <ref> [2, 16] </ref>. This is a method that, given a model, a current simulation state of that model, and a desired event, can answer the question: "Can this event be produced in the future?". The model is stated as a system of event sequences, specified by extended regular expressions.
Reference: [3] <author> S. Bandinelli, A. Fuggetta, and C. Ghezzi. </author> <title> Software Process Model Evolution in the SPADE Environe-ment. </title> <journal> IEEE Transactions on Software Engineering, </journal> 19(12) 1128-1144, December 1993. 
Reference-contexts: Even if one could completely enforce a process, there still remains the issue of managing change in a process, which might also lead to a discrepancy between the model and the execution. There has, in fact, been considerable work that addresses process evolution <ref> [3, 29] </ref>. Commensurate with the historical approach mentioned above, that work is concerned more with the problem of effecting changes to a process model used for automation, than it is with the problem of uncovering inconsistencies between the model and the execution.
Reference: [4] <author> S. Bandinelli, A. Fuggetta, C. Ghezzi, and L. Lavazza. SPADE: </author> <title> An Environment for Software Process Analysis, Design, </title> <editor> and Enactment. In A. Finkelstein, J. Kramer, and B. Nuseibeh, editors, </editor> <booktitle> Software Process Modeling and Technology, </booktitle> <pages> pages 223-248. </pages> <publisher> Wiley, </publisher> <year> 1994. </year>
Reference-contexts: These include models based on state machines (e.g., Statemate [28]), Petri nets (e.g., SLANG <ref> [4] </ref> and FUNSOFT Nets [27]), procedural languages (e.g., APPL/A [43]), and rule-based languages (e.g., Oz [6]). We assume that a model described in any such formalism induces one or more event streams, and thus it has places in its behavioral description where events can be recognized.
Reference: [5] <author> P. Bates. </author> <title> Debugging Heterogenous Systems Using Event-Based Models of Behavior. </title> <booktitle> In Proceedings of a Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 11-22. </pages> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: The use of events to characterize behavior is already widely accepted in other areas of software engineering, such as program visualization [34], concurrent-system analysis [2], and distributed debugging <ref> [5, 14] </ref>. The "instant" of an event is relative to the time granularity that is needed or desired; thus, certain activities that are of short duration relative to the time granularity are represented as a single event. <p> In using event-based data to compare an execution with a formal model, the our work also relates to that of distributed debugging and history checking. * Bates <ref> [5] </ref> uses "event-based behavioral abstraction" to characterize the behavior of programs. He attempts to match the event data to a model based on regular expressions.
Reference: [6] <author> I.S. Ben-Shaul and G.E. Kaiser. </author> <title> A Paradigm for Decentralized Process Modeling and its Realization in the OZ Environment. </title> <booktitle> In Proceedings of the 16th International Conference on Software Engineering, </booktitle> <pages> pages 179-188. </pages> <publisher> IEEE Computer Society, </publisher> <month> May </month> <year> 1994. </year>
Reference-contexts: These include models based on state machines (e.g., Statemate [28]), Petri nets (e.g., SLANG [4] and FUNSOFT Nets [27]), procedural languages (e.g., APPL/A [43]), and rule-based languages (e.g., Oz <ref> [6] </ref>). We assume that a model described in any such formalism induces one or more event streams, and thus it has places in its behavioral description where events can be recognized. We call these places 2 event sites.
Reference: [7] <author> I. Bhandari, M. Halliday, E. Tarver, D. Brown, J. Chaar, and R. Chillarege. </author> <title> A Case Study of Software Process Improvement During Development. </title> <journal> IEEE Transactions on Software Engineering, </journal> 19(12) 1157-1170, December 1993. 
Reference-contexts: to suggestions about where in the process some adjustments might be useful. 8 Related Work There is related work in the area of process improvement that uses data to characterize processes, but none that uses data in a process validation activity. * Chmura et al. [9] and Bhandari et al. <ref> [7] </ref> try to deduce problems in the process by looking at defect data in the products. Specifically, they statistically analyze change data and effort data to determine the behavior of the process.
Reference: [8] <author> J.R. Burch, E.M. Clarke, K.L. McMillan, D.L. Dill, and L.J. Hwang. </author> <title> Symbolic Model Checking: 10 20 States and Beyond. </title> <journal> Information and Computation, </journal> <volume> 98 </volume> <pages> 141-170, </pages> <year> 1992. </year>
Reference-contexts: In one example, Burch et al. <ref> [8] </ref> describe a model checker based on binary decision diagrams that is able to check models with 10 20 states, where previous work had only handled 10 8 states.
Reference: [9] <author> L.J. Chmura, A.F. Norcio, and T.J. Wicinski. </author> <title> Evaluating Software Design Processes by Analyzing Change Data Over Time. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(7) </volume> <pages> 729-739, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Indeed, our results led to suggestions about where in the process some adjustments might be useful. 8 Related Work There is related work in the area of process improvement that uses data to characterize processes, but none that uses data in a process validation activity. * Chmura et al. <ref> [9] </ref> and Bhandari et al. [7] try to deduce problems in the process by looking at defect data in the products. Specifically, they statistically analyze change data and effort data to determine the behavior of the process.
Reference: [10] <author> J.E. Cook. </author> <title> Process Discovery and Validation through Event-Data Analysis. </title> <type> Technical Report CU-CS-817-96, </type> <institution> University of Colorado, University of Colorado, Boulder, Colorado, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: We have studied our pruning methods extensively, but detailed discussion is beyond the scope of this paper. We refer the reader elsewhere for more information <ref> [10] </ref>. 7 Using Validation in an Industrial Case Study We recently performed a case study of an industrial software process [11]. The goal of the study was to statistically identify process behaviors that correlated with successful and unsuccessful exe 16 cutions of the process. <p> The metrics are independent of any specific behavioral process modeling paradigm, and thus has wide applicability. The process validation techniques have been implemented as part of the Balboa process data analysis framework <ref> [10] </ref>. The current implementation works with finite state machine models of processes. The user interface for selecting execution streams and process models, and for viewing the results of a process validation, is shown in Figure 7.
Reference: [11] <author> J.E. Cook, L.G. Votta, and A.L. Wolf. </author> <title> A Methodology for Cost-Effective Analysis of In-Place Software Processes. </title> <type> Technical Report CU-CS-825-97, </type> <institution> University of Colorado, University of Colorado, Boulder, Colorado, </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: We have studied our pruning methods extensively, but detailed discussion is beyond the scope of this paper. We refer the reader elsewhere for more information [10]. 7 Using Validation in an Industrial Case Study We recently performed a case study of an industrial software process <ref> [11] </ref>. The goal of the study was to statistically identify process behaviors that correlated with successful and unsuccessful exe 16 cutions of the process. One component of that study involved the use of our validation techniques.
Reference: [12] <author> J.E. Cook and A.L. Wolf. </author> <title> Toward Metrics for Process Validation. </title> <booktitle> In Proceedings of the Third International Conference on the Software Process, </booktitle> <pages> pages 33-44. </pages> <publisher> IEEE Computer Society, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: We have developed techniques for detecting and characterizing differences between a formal model of a process and the actual execution of the process. We refer to this activity as process validation <ref> [12] </ref>. The techniques are neutral with respect to the correctness of the model ("Does our model reflect what we actually do?") and the correctness of the execution ("Do we follow our model?").
Reference: [13] <author> G. Cugola, E. Di Nitto, A. Fuggetta, and C. Ghezzi. </author> <title> A Framework for Formalizing Inconsistencies and Deviations in Human-Centered Systems. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 5(3) </volume> <pages> 191-230, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution. Moreover, deviations from the process are naturally to be expected <ref> [13, 19, 26] </ref>. Even if one could completely enforce a process, there still remains the issue of managing change in a process, which might also lead to a discrepancy between the model and the execution. There has, in fact, been considerable work that addresses process evolution [3, 29]. <p> The effort here is to predict how well a specific process will fit into an environment, rather than whether or not the model is followed once it is deployed. 18 * Cugola et al. <ref> [13] </ref> define a formal framework for reasoning about inconsistencies and deviations in a process. Their approach is directed towards processes that are controlled by a process support system using an enacted model. Their goal is to enable these systems to allow, coordinate, and resolve deviations from the model.
Reference: [14] <author> J. Cuny, G. Forman, A. Hough, J. Kundu, C. Lin, L. Snyder, and D. Stemple. </author> <title> The Adriane Debugger: Scalable Application of Event-Based Abstraction. </title> <booktitle> In Proceedings of the ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 85-95. </pages> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: The use of events to characterize behavior is already widely accepted in other areas of software engineering, such as program visualization [34], concurrent-system analysis [2], and distributed debugging <ref> [5, 14] </ref>. The "instant" of an event is relative to the time granularity that is needed or desired; thus, certain activities that are of short duration relative to the time granularity are represented as a single event. <p> He attempts to match the event data to a model based on regular expressions. However, he only marks the points at which the data and model did not match, rather than attempting to provide aggregate measures of disparity. * Cuny et al. <ref> [14] </ref> builds on the work of Bates, attempting to deal with large amounts of event data by providing query mechanisms for event relationships.
Reference: [15] <author> J.L. Devore. </author> <title> Probability and Statistics for Engineering and the Sciences. </title> <address> Brooks/Cole, Pacific Grove, California, </address> <note> 3rd edition, </note> <year> 1991. </year>
Reference-contexts: Thus, one might pick the standard statistical correlation rules of thumb <ref> [15] </ref> and say that any measurement less than 0:2 is a strong correspondence, less than 0:5 is a moderate correspondence, and greater than 0:5 is a weak correspondence. 3 4.3 Non-linear String Distance Metric A characteristic of the SSD metric is that it is focused narrowly on the cost of individual
Reference: [16] <author> L.K. Dillon, G.S. Avrunin, and J.C. Wileden. </author> <title> Constrained Expressions: Toward Broad Applicability of Analysis Methods for Distributed Software Systems. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(3) </volume> <pages> 374-402, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: If models do not have regularity in the state space, they admit that their techniques will not provide much leverage. Another example of a technique to search for a behavior is found in the Constrained Expressions framework <ref> [2, 16] </ref>. This is a method that, given a model, a current simulation state of that model, and a desired event, can answer the question: "Can this event be produced in the future?". The model is stated as a system of event sequences, specified by extended regular expressions.
Reference: [17] <author> M.W. Du and S.C. Chang. </author> <title> A model and a fast algorithm for multiple errors spelling correction. </title> <journal> Acta Informatica, </journal> <volume> 29 </volume> <pages> 281-302, </pages> <year> 1992. </year> <month> 21 </month>
Reference-contexts: By applying various mathematical transformations, this method becomes a family of metrics. String distance metrics have been used in applications as varied as DNA/RNA matching [44], substring matching [30, 40], spelling error correction <ref> [17] </ref>, syntax error correction [1, 23, 39], and even the well-known UNIX tool for comparing text files, diff.
Reference: [18] <author> Z. K. F. Eckert and G. J. Nutt. </author> <title> Trace extrapolation for parallel programs on shared memory multipro-cessors. </title> <type> Technical Report TR CU-CS-804-96, </type> <institution> Department of Computer Science, University of Colorado, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: For example, points in a model where one can fix the execution stream and ignore previous behavior could help reduce the search cost in a large model. This is similar to the concept of trace change points <ref> [18] </ref>. * Developing improved techniques for visualizing the results of validation. For example, overlaying the differences onto the process model rather than onto the model event stream may help a process engineer better understand the problems in the process. * Investigating other analyses for process executions and process models.
Reference: [19] <author> C.A. Ellis, K. Keddara, and G. Rosenberg. </author> <title> Dynamic Change within Workflow Systems. </title> <booktitle> In Proceedings of the Conference on Organizational Computing Systems, </booktitle> <pages> pages 10-21. </pages> <publisher> ACM SIGOIS, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution. Moreover, deviations from the process are naturally to be expected <ref> [13, 19, 26] </ref>. Even if one could completely enforce a process, there still remains the issue of managing change in a process, which might also lead to a discrepancy between the model and the execution. There has, in fact, been considerable work that addresses process evolution [3, 29].
Reference: [20] <author> D. Eppstein. </author> <title> Sequence comparison with mixed convex and concave costs. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 85-101, </pages> <year> 1990. </year>
Reference-contexts: For simple operation and symbol weightings, equivalent to our SSD metric, their algorithms operate in O (M N ) time. However, dealing with multi-symbol blocks (or gaps), as our NSD metric requires, complicates matters significantly. In general, for both string-to-string comparisons <ref> [20] </ref> and string-to-regular-expression comparisons [36], arbitrary cost functions for blocks require at least O (M N max (M; N )), or cubic time. 7 The regular expression algorithm takes advantage of the simplicity of its modeling paradigm.
Reference: [21] <author> M. Felder, D. Mandrioli, and A. Morzenti. </author> <title> Proving Properties of Real-time Systems Through Logical Specifications and Petri Net Models. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 20(2) </volume> <pages> 127-141, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: They assume that there is some problem somewhere in the event stream and that one is trying to locate that problem. * Felder et al. <ref> [21, 22] </ref> describe a method and tool by which one can compare an execution history against a temporal logic specification to decide the correctness of that execution with respect to the model.
Reference: [22] <author> M. Felder and A. Morzenti. </author> <title> Validating Real-time Systems by History-checking TRIO Specifications. </title> <booktitle> In Proceedings of the 14th International Conference on Software Engineering, </booktitle> <pages> pages 199-211. </pages> <publisher> IEEE Computer Society, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: They assume that there is some problem somewhere in the event stream and that one is trying to locate that problem. * Felder et al. <ref> [21, 22] </ref> describe a method and tool by which one can compare an execution history against a temporal logic specification to decide the correctness of that execution with respect to the model. <p> For example, time-oriented metrics, perhaps derived from the area of real-time analysis <ref> [22, 41] </ref>, would be a useful extension to execution stream analysis. Methods for measuring the efficiency of a process would be another useful analysis method. Both would help in the optimization of a process that has already been behaviorally validated.
Reference: [23] <author> C.N. Fischer and J. Mauney. </author> <title> A simple, fast, and effective LL(1) error repair algorithm. </title> <journal> Acta Informat-ica, </journal> <volume> 29 </volume> <pages> 109-120, </pages> <year> 1992. </year>
Reference-contexts: By applying various mathematical transformations, this method becomes a family of metrics. String distance metrics have been used in applications as varied as DNA/RNA matching [44], substring matching [30, 40], spelling error correction [17], syntax error correction <ref> [1, 23, 39] </ref>, and even the well-known UNIX tool for comparing text files, diff. <p> This method is based on the ideas of minimum distance corrections, but makes the assumption that one never needs to back up in the input stream to find a good correction. * Fischer and Mauney <ref> [23] </ref> describe a method for locally least cost error correction. They are also biased towards insertions, but include deletions. Their method uses a local search with a priority queue to find a locally minimum cost fix. They show that their method is fast enough to reasonably implement in a compiler.
Reference: [24] <author> P.K. Garg and M. Jazayeri. </author> <title> Process-Centered Software Engineering Environments: A Grand Tour. </title> <editor> In A. Fuggetta and A.L. Wolf, editors, </editor> <booktitle> Software Process, number 4 in Trends in Software, </booktitle> <pages> pages 25-52. </pages> <publisher> Wiley, </publisher> <address> London, </address> <year> 1996. </year>
Reference-contexts: 1 Introduction Whenever a model of a system is created, the question arises as to whether that model faithfully captures the system. In software process research, where the model is typically embedded and executed within an automated software engineering environment <ref> [24] </ref>, this question is avoided; the model and process are necessarily in agreement because the model becomes the process. When applied in software process practice, however, this approach suffers from a fundamental flaw. In particular, it assumes that virtually the entire process is executed within the context of the environment.
Reference: [25] <author> P.K. Garg, M. Jazayeri, </author> <title> and M.L. Creech. A Meta-Process for Software Reuse, Process Discovery, and Evolution. </title> <booktitle> In Proceedings of the 6th International Workshop on Software Reuse, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: Specifically, they statistically analyze change data and effort data to determine the behavior of the process. For example, they can see ripple effects from interface changes and high percentages of fix-on-fix changes. * Garg et al. <ref> [25] </ref> employ a manual process history analysis in the context of a meta-process for creating and validating domain-specific process models and software toolkits. * Perez et al. [37] propose methods for evaluating the congruence of process models.
Reference: [26] <author> J. Grudin. </author> <title> Groupware and Cooperative Work: Problems and Prospects. </title> <editor> In B. Laurel, editor, </editor> <booktitle> The Art of Human Computer Interface Design. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution. Moreover, deviations from the process are naturally to be expected <ref> [13, 19, 26] </ref>. Even if one could completely enforce a process, there still remains the issue of managing change in a process, which might also lead to a discrepancy between the model and the execution. There has, in fact, been considerable work that addresses process evolution [3, 29].
Reference: [27] <author> V. Gruhn and R. Jegelka. </author> <title> An Evaluation of FUNSOFT Nets. </title> <booktitle> In Proceedings of the Second European Workshop on Software Process Technology, number 635 in Lecture Notes in Computer Science, </booktitle> <pages> pages 196-214. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1992. </year>
Reference-contexts: These include models based on state machines (e.g., Statemate [28]), Petri nets (e.g., SLANG [4] and FUNSOFT Nets <ref> [27] </ref>), procedural languages (e.g., APPL/A [43]), and rule-based languages (e.g., Oz [6]). We assume that a model described in any such formalism induces one or more event streams, and thus it has places in its behavioral description where events can be recognized. We call these places 2 event sites.
Reference: [28] <author> D. Harel, H. Lachover, A. Naamad, A. Pnueli, M. Politi, R. Sherman, and A. Shtul-Trauring. STATE-MATE: </author> <title> A Working Environment for the Development of Complex Reactive Systems. </title> <booktitle> In Proceedings of the 10th International Conference on Software Engineering, </booktitle> <pages> pages 396-406. </pages> <publisher> IEEE Computer Society, </publisher> <month> April </month> <year> 1988. </year>
Reference-contexts: These include models based on state machines (e.g., Statemate <ref> [28] </ref>), Petri nets (e.g., SLANG [4] and FUNSOFT Nets [27]), procedural languages (e.g., APPL/A [43]), and rule-based languages (e.g., Oz [6]).
Reference: [29] <author> M.L. Jaccheri and R. Conradi. </author> <title> Techniques for Process Model Evolution in EPOS. </title> <journal> IEEE Transactions on Software Engineering, </journal> 19(12) 1145-1156, December 1993. 
Reference-contexts: Even if one could completely enforce a process, there still remains the issue of managing change in a process, which might also lead to a discrepancy between the model and the execution. There has, in fact, been considerable work that addresses process evolution <ref> [3, 29] </ref>. Commensurate with the historical approach mentioned above, that work is concerned more with the problem of effecting changes to a process model used for automation, than it is with the problem of uncovering inconsistencies between the model and the execution.
Reference: [30] <author> R.L. Kashyap and B.J. Oommen. </author> <title> The noisy substring matching problem. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 9(3) </volume> <pages> 365-370, </pages> <year> 1983. </year>
Reference-contexts: A string distance metric counts the number of token insertions, deletions, and substitutions needed to transform one string into the other. By applying various mathematical transformations, this method becomes a family of metrics. String distance metrics have been used in applications as varied as DNA/RNA matching [44], substring matching <ref> [30, 40] </ref>, spelling error correction [17], syntax error correction [1, 23, 39], and even the well-known UNIX tool for comparing text files, diff.
Reference: [31] <author> M.I. Kellner, P.H. Feiler, A. Finkelstein, T. Katayama, L.J. Osterweil, M.H. Penedo, and H.D. Rombach. </author> <title> Software Process Modeling Example Problem. </title> <booktitle> In Proceedings of the 6th International Software Process Workshop, </booktitle> <pages> pages 19-29, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: In Section 7 we show how they contribute detailed and important information to an understanding of deviations in an industrial process. 5 Example Use of the Metrics To illustrate the three metrics introduced above, we use the Test Unit task from the ISPW 6/7 process problem <ref> [31] </ref>. This is a simple and small process fragment, but it should give the reader a feeling for how the metrics are applied to a process. In this task, a developer and a tester are involved in testing a module that has undergone some change.
Reference: [32] <author> J.R. Knight and E.W. Myers. </author> <title> Approximate regular expression pattern matching with concave gap penalties. </title> <journal> Algorithmica, </journal> <volume> 14 </volume> <pages> 85-121, </pages> <year> 1995. </year>
Reference-contexts: The issue is that while they leverage system transformations to gain speed and scalability, the transformations make the system inherently uninspectable. 6.1.3 Regular Expression Matching Myers, Miller, and Knight <ref> [32, 36] </ref> describe algorithms for approximately matching a string to a regular expression, using the insertion, deletion, and substitution operations. These methods build on the dynamic programming techniques of string-to-string comparison algorithms, and extend this to regular expressions. <p> In general, constructs used in process modeling languages are not reducible to regular expressions. More powerful, yet still restricted constructs have been looked at. Context free languages, for example, are thought to have high-order polynomial time algorithms for solving approximate matching <ref> [32] </ref>. In general, these super-quadratic to cubic techniques, while providing optimal answers, are impractical.
Reference: [33] <author> J.B. Kruskal. </author> <title> An Overview of Sequence Comparison. </title> <editor> In D. Sankoff and J.B. Kruskal, editors, </editor> <title> Time Warps, String Edits, and Macromolecules: </title> <booktitle> The Theory and Practice of Sequence Comparison, </booktitle> <pages> pages 1-44. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1983. </year>
Reference-contexts: We call these two event streams the execution event stream and the model event stream, respectively. There are several methods for performing a measurement such as this, but one that seems most applicable is the string distance metric <ref> [33] </ref>. A string distance metric counts the number of token insertions, deletions, and substitutions needed to transform one string into the other. By applying various mathematical transformations, this method becomes a family of metrics. <p> Given two strings, one of length M and the other of length N , the minimum total cost of operations can be computed in O (M N ) time using a well-known dynamic program <ref> [33] </ref>. In some applications of this method, such as DNA/RNA sequencing or text recognition, token substitution in the string distance metric makes sense. For process validation, however, it is not clear that a substituted event should contribute in any way to the measure of the correspondence.
Reference: [34] <author> R.J. LeBlanc and A.D. Robbins. </author> <title> Event-Driven Monitoring of Distributed Programs. </title> <booktitle> In Proceedings of the Fifth International Conference on Distributed Computing Systems, </booktitle> <pages> pages 515-522. </pages> <publisher> IEEE Computer Society, </publisher> <month> May </month> <year> 1985. </year> <month> 22 </month>
Reference-contexts: The use of events to characterize behavior is already widely accepted in other areas of software engineering, such as program visualization <ref> [34] </ref>, concurrent-system analysis [2], and distributed debugging [5, 14]. The "instant" of an event is relative to the time granularity that is needed or desired; thus, certain activities that are of short duration relative to the time granularity are represented as a single event.
Reference: [35] <author> S.Y. Lu and K.S. Fu. </author> <title> Error-correcting tree automata for syntactic pattern recognition. </title> <journal> IEEE Transac--tions on Computers, </journal> <volume> C-27:1040-1053, </volume> <month> November </month> <year> 1978. </year>
Reference-contexts: In general, string distance metrics have become the standard method in any domain requiring symbolic sequence comparison. 1 String distance metrics are also generalizable to tree and graph distance measurements <ref> [35] </ref>, although we do not take advantage of these extensions here. Other methods that could be used to quantify the difference between two event streams do not offer the versatility of string distance metrics.
Reference: [36] <author> E.W. Myers and W. Miller. </author> <title> Approximate matching of regular expressions. </title> <journal> Bulletin of Mathematical Biology, </journal> <volume> 51(1) </volume> <pages> 5-37, </pages> <year> 1989. </year>
Reference-contexts: The issue is that while they leverage system transformations to gain speed and scalability, the transformations make the system inherently uninspectable. 6.1.3 Regular Expression Matching Myers, Miller, and Knight <ref> [32, 36] </ref> describe algorithms for approximately matching a string to a regular expression, using the insertion, deletion, and substitution operations. These methods build on the dynamic programming techniques of string-to-string comparison algorithms, and extend this to regular expressions. <p> For simple operation and symbol weightings, equivalent to our SSD metric, their algorithms operate in O (M N ) time. However, dealing with multi-symbol blocks (or gaps), as our NSD metric requires, complicates matters significantly. In general, for both string-to-string comparisons [20] and string-to-regular-expression comparisons <ref> [36] </ref>, arbitrary cost functions for blocks require at least O (M N max (M; N )), or cubic time. 7 The regular expression algorithm takes advantage of the simplicity of its modeling paradigm. In general, constructs used in process modeling languages are not reducible to regular expressions.
Reference: [37] <author> G. Perez, K. El Emam, and N.H. Madhavji. </author> <title> A System for Evaluating the Congruence of Software Process Models. </title> <type> Technical Report SE-94-7, </type> <institution> McGill University, Montreal, Canada, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: For example, they can see ripple effects from interface changes and high percentages of fix-on-fix changes. * Garg et al. [25] employ a manual process history analysis in the context of a meta-process for creating and validating domain-specific process models and software toolkits. * Perez et al. <ref> [37] </ref> propose methods for evaluating the congruence of process models. Congruence is a measure of how well an environment can accommodate a given process model, based on the tools and activities already in that environment.
Reference: [38] <editor> E. Rich. </editor> <booktitle> Artificial Intelligence. McGraw-Hill Series in Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: Pruning discards portions of the state space that look unpromising. By pruning, one cannot guarantee a lowest cost goal. But in some domains, such as game playing, "smart" pruning has negligible effects on the outcome of the search while dramatically reducing search costs <ref> [38] </ref>. Pruning takes many forms and can use vastly different methods and heuristics. One heuristic that we employ is to discard any newly generated state that has an estimated cost higher than some threshold relative to the current best-looking state. We refer to this as cost pruning.
Reference: [39] <author> J. Rohrich. </author> <title> Methods for the automatic construction of error correcting parsers. </title> <journal> Acta Informatica, </journal> <volume> 13 </volume> <pages> 115-139, </pages> <year> 1980. </year>
Reference-contexts: By applying various mathematical transformations, this method becomes a family of metrics. String distance metrics have been used in applications as varied as DNA/RNA matching [44], substring matching [30, 40], spelling error correction [17], syntax error correction <ref> [1, 23, 39] </ref>, and even the well-known UNIX tool for comparing text files, diff. <p> They do not expect their algorithm to be used, however, because of its high cost. Rather, they propose it as a baseline for other methods to compare against. * Rohrich <ref> [39] </ref> describes an error correction method biased towards insertion of symbols, arguing that as little of the program text should be skipped (deleted) as possible.
Reference: [40] <author> M. Schneider, H. Lim, and W. Schoaff. </author> <title> The utilization of fuzzy sets in the recognition of imperfect strings. </title> <journal> Fuzzy Sets and Systems, </journal> <volume> 49 </volume> <pages> 331-337, </pages> <year> 1992. </year>
Reference-contexts: A string distance metric counts the number of token insertions, deletions, and substitutions needed to transform one string into the other. By applying various mathematical transformations, this method becomes a family of metrics. String distance metrics have been used in applications as varied as DNA/RNA matching [44], substring matching <ref> [30, 40] </ref>, spelling error correction [17], syntax error correction [1, 23, 39], and even the well-known UNIX tool for comparing text files, diff.
Reference: [41] <author> R.L. Schwartz, P.M. Melliar-Smith, and F.H. Vogt. </author> <title> An Interval Logic for Higher-level Temporal Reasoning. </title> <booktitle> In Proceedings of the Second ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 173-186. </pages> <institution> Association for Computer Machinery, </institution> <month> August </month> <year> 1983. </year>
Reference-contexts: For example, time-oriented metrics, perhaps derived from the area of real-time analysis <ref> [22, 41] </ref>, would be a useful extension to execution stream analysis. Methods for measuring the efficiency of a process would be another useful analysis method. Both would help in the optimization of a process that has already been behaviorally validated.
Reference: [42] <author> S.M. Sutton, Jr. </author> <title> Accommodating Manual Activities in Automated Process Programs. </title> <booktitle> In Proceedings of the 7th International Software Process Workshop, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: In particular, it assumes that virtually the entire process is executed within the context of the environment. In fact, critical aspects of the process occur off the computer and, therefore, not under the watchful eye of the environment <ref> [42, 45, 46] </ref>. That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution. Moreover, deviations from the process are naturally to be expected [13, 19, 26].
Reference: [43] <author> S.M. Sutton, Jr., D. Heimbigner, and L.J. Osterweil. APPL/A: </author> <title> A Language for Software Process Programming. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <volume> 4(3) </volume> <pages> 221-286, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: These include models based on state machines (e.g., Statemate [28]), Petri nets (e.g., SLANG [4] and FUNSOFT Nets [27]), procedural languages (e.g., APPL/A <ref> [43] </ref>), and rule-based languages (e.g., Oz [6]). We assume that a model described in any such formalism induces one or more event streams, and thus it has places in its behavioral description where events can be recognized. We call these places 2 event sites.
Reference: [44] <author> M.S. Waterman. </author> <title> General methods of sequence comparison. </title> <journal> Bulletin of Mathematical Biology, </journal> <volume> 46 </volume> <pages> 473-501, </pages> <year> 1984. </year>
Reference-contexts: A string distance metric counts the number of token insertions, deletions, and substitutions needed to transform one string into the other. By applying various mathematical transformations, this method becomes a family of metrics. String distance metrics have been used in applications as varied as DNA/RNA matching <ref> [44] </ref>, substring matching [30, 40], spelling error correction [17], syntax error correction [1, 23, 39], and even the well-known UNIX tool for comparing text files, diff.
Reference: [45] <author> A.L. Wolf and D.S. Rosenblum. </author> <title> A Study in Software Process Data Capture and Analysis. </title> <booktitle> In Proceedings of the Second International Conference on the Software Process, </booktitle> <pages> pages 115-124. </pages> <publisher> IEEE Computer Society, </publisher> <month> February </month> <year> 1993. </year>
Reference-contexts: In particular, it assumes that virtually the entire process is executed within the context of the environment. In fact, critical aspects of the process occur off the computer and, therefore, not under the watchful eye of the environment <ref> [42, 45, 46] </ref>. That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution. Moreover, deviations from the process are naturally to be expected [13, 19, 26]. <p> This does not mean that other aspects of a process are not worthy of study; it is just that the issues we have chosen to investigate are those having to do with behavior rather than structure. 2.1 Events Following Wolf and Rosenblum <ref> [45] </ref>, we use an event-based model of process actions, where an event is used to characterize the dynamic behavior of a process in terms of identifiable, instantaneous actions, such as invoking a development tool or deciding upon the next activity to be performed.
Reference: [46] <editor> A.L. Wolf and D.S. Rosenblum. </editor> <booktitle> Process-centered Environments (Only) Support Environment-centered Processes. In Proceedings of the 8th International Software Process Workshop, </booktitle> <pages> pages 148-149, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: In particular, it assumes that virtually the entire process is executed within the context of the environment. In fact, critical aspects of the process occur off the computer and, therefore, not under the watchful eye of the environment <ref> [42, 45, 46] </ref>. That being the case, there is no effective way to enforce the process using this approach nor to guarantee the mutual consistency of a process model and a process execution. Moreover, deviations from the process are naturally to be expected [13, 19, 26].
References-found: 46

