URL: ftp://ftpipr.ira.uka.de/pub/conferences/EWLR-4/PROCEEDINGS/ewlr4_kaiser.ps.gz
Refering-URL: http://wwwipr.ira.uka.de/~kaiser/events/ewlr4program.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-Mail: kaiser@ira.uka.de  
Title: TEACHING BASIC MOBILITY SKILLS TO MOBILE ROBOTS  
Author: MICHAEL KAISER, MICHAEL DECK, R UDIGER DILLMANN 
Keyword: Key Words. Machine Learning, Robotics, Man-Machine Systems, Programming Support  
Address: D-76128 Karl-sruhe, Germany.  
Affiliation: Institute for Real-Time Computer Systems Robotics, University of Karlsruhe,  
Abstract: Reactive control of a mobile robot requires to map the robot's perceptions into actions by means of a strategy that is goal-oriented. To explicitely encode this strategy is not an easy task. Specifically, it cannot be assumed that users of future service robots will be able to perform this kind of low-level robot programming. What is sought is a method that allows to intuitively program the robot without requiring knowledge about the robot's hardware, its sensor system, or the actual relationship between both. In this paper, we present such a method that builds basic mobility skills from human demonstrations, i.e., manual operation of the robot only. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Asada, H. and B.-H. </author> <title> Yang (1989). Skill acquisition from human experts through pattern processing of teaching data. </title> <booktitle> In: Proceedings of the 1989 IEEE International Conference on Robotics and Automation. </booktitle>
Reference-contexts: Also, the specification of the functional form of the skill by the user, which reduces skill learning to the identification of numerical parameters <ref> (Asada and Yang, 1989) </ref>, is not an appropriate solution.
Reference: <author> Asada, H. and S. </author> <title> Liu (1991). Transfer of human skills to neural net robot controllers. </title> <booktitle> In: Proceedings of the 1991 IEEE International Conference on Robotics and Automation. </booktitle>
Reference: <author> Baroglio, C., A. Giordana, M. Kaiser, M. Nuttin and R. </author> <month> Pi-ola </month> <year> (1996). </year> <title> Learning controllers for industrial robots. </title> <booktitle> Machine Learning. </booktitle>
Reference-contexts: I.e., by checking the activation of the individual clusters available in such a network, it is possible to easily distinguish if the network is recalling an example it has seen before, or if it is generalizing. For building C s and r s ; the clustering algorithm described in <ref> (Baroglio et al., 1996) </ref> is applied to generate the initial network. Afterwards, the resulting networks are trained via gradient descent.
Reference: <author> Barto, A. G., R. S. Sutton and C. W. </author> <title> Anderson (1983). Neuronlike elements that can solve difficult learning control problems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics pp. </journal> <pages> 835-846. </pages>
Reference: <author> Deck, M. </author> <year> (1995). </year> <title> Interaktive Akquisition von Elemen-tarfahigkeiten fur mobile Roboter. </title> <type> Master's thesis. </type> <institution> Universitat Karlsruhe, Fakultat fur Informatik, Insti-tut fur Prozerechentechnik und Robotik. </institution>
Reference-contexts: Otherwise, a new unlabelled region covering the current state is inserted, thereby excluding a part of the old region from the error or the termination criterion. 7 EXPERIMENTS For the evaluation of the described method, several skills were taught to PRIAMOS (for a more thorough evaluation, see <ref> (Deck, 1995) </ref>).
Reference: <author> Dillmann, R., M. Kaiser and A. </author> <month> Ude </month> <year> (1995a). </year> <title> Acquisition of elementary robot skills from human demonstration. </title> <booktitle> In: International Symposium on Intelligent Robotics Systems. </booktitle> <address> Pisa, Italy. </address>
Reference-contexts: Based on knowledge of relevant actions, such a dependency can be used to identify relevant perceptions <ref> (Dillmann et al., 1995a) </ref>, if sufficiently many samples have been taken during the demonstration. This is however not the case if mobility skills are being demonstrated that use PRIAMOS' ultrasonic sensors (see section 3).
Reference: <author> Dillmann, R., M. Kaiser, F. Wallner and P. </author> <month> Weckesser </month> <year> (1995b). </year> <title> PRIAMOS: An advanced mobile system for service, inspection, and surveillance tasks. In: Mod-elling and Planning for Sensor Based Intelligent Robot Systems (T. </title> <editor> Kanade H. Bunke, H. Noltemeier, Ed.). </editor> <publisher> World Scientific. </publisher>
Reference-contexts: Especially w.r.t. several of the learning techniques, the descriptions will be rather brief, however, references to the original publications will be given. The testbed for the work described here has been the mobile robot PRIAMOS <ref> (Dillmann et al., 1995b) </ref>. 2 ACQUIRING ELEMENTARY SKILLS FROM HUMAN DEMONSTRATIONS "Skill" denotes the learned power of doing a thing competently.
Reference: <author> Elfes, A. </author> <year> (1989). </year> <title> Using occupancy grids for mobile robot perception and navigation. </title> <journal> IEEE Computer pp. </journal> <pages> 46-57. </pages>
Reference: <author> Gullapalli, V. </author> <year> (1990). </year> <title> A stochastic reinforcement learning algorithm for learning real valued functions. </title> <booktitle> Neural Networks 3, </booktitle> <pages> 671-692. </pages>
Reference: <author> Gullapalli, V., J. A. Franklin and H. </author> <month> Benbrahim </month> <year> (1994). </year> <title> Acquiring robot skills via reinforcement learning. </title> <journal> IEEE Control Systems Magazine 14(1), </journal> <volume> 13 - 24. Harnad, </volume> <month> Stevan </month> <year> (1990). </year> <title> The symbol grounding problem. </title> <journal> Physica D 42, </journal> <pages> 335-346. </pages>
Reference: <author> Hirai, S., H. Noguchi and K. </author> <title> Iwata (1995). Transplantation of human skillful motion to manipulators in insertion of deformable tubes. </title> <booktitle> In: IEEE Internation Conference on Robotics and Automation. Nagoya, Japan. </booktitle> <pages> pp. </pages> <year> 1900 </year> <month> - </month> <year> 1905. </year>
Reference: <author> Kaiser, M., A. Retey and R. </author> <month> Dillmann </month> <year> (1995a). </year> <title> Designing neural networks for adaptive control. </title> <booktitle> In: IEEE International Conference on Decision and Control (34th CDC). </booktitle>
Reference-contexts: The actual mechanism used for this adaptation depends on the representation of the functions as well as on the information contained in the feedback <ref> (Kaiser et al., 1995a) </ref>. the exploratory element. The minimum feedback that is assumed to be available in the context of learning from human demonstrations is an evaluation of the performance of the robot after the application of an individual skill.
Reference: <author> Kaiser, M., A. Retey and R. </author> <month> Dillmann </month> <year> (1995b). </year> <title> Robot skill acquisition via human demonstration. </title> <booktitle> In: Proceedings of the International Conference on Advanced Robotics (ICAR '95). </booktitle>
Reference-contexts: known in advance, p is determined based on the demonstration data. d o ; d r ; and p must also be considered while generating the training data. 3 WHAT IS SPECIAL ABOUT BASIC MOBILITY SKILLS? During the demonstration of manipulation skills, usually a force/torque sensor provides the robot's perceptions <ref> (Kaiser et al., 1995b) </ref>. Such a sensor is able to deliver information at a rate of at least 30 [Hz]; such that a demonstration of 20 seconds length results in more than 600 single training samples.
Reference: <author> Kaiser, M. and R. </author> <month> Dillmann </month> <year> (1995). </year> <title> Hierarchical learning of efficient skill application for autonomous robots. </title> <booktitle> In: International Symposium on Intelligent Robotics Systems. </booktitle> <address> Pisa, Italy. </address>
Reference-contexts: Reinforcement learning can only be successfully applied in the real world if the learning system is provided with hints about the strategy. These hints can be obtained from user demonstrations <ref> (Kaiser and Dillmann, 1995) </ref>. Consequently, a human demonstration is used to initially build the skill and to setup the online adaptation mechanism. The adaptation 1 Both expressions denote the same thing.
Reference: <author> Kaiser, M., H. Friedrich and R. </author> <month> Dillmann </month> <year> (1995c). </year> <title> Obtaining good performance from a bad teacher. </title> <booktitle> In: International Conference on Machine Learning, Workshop on Programming by Demonstration. </booktitle> <address> Tahoe City, Cal-ifornia. </address>
Reference-contexts: In the ideal case, these data represent the skill to be acquired perfectly. In reality, however, this will seldom be the case. Several sources of suboptimality exist that result in disturbances, the most prominent being <ref> (Kaiser et al., 1995c) </ref> 1. the existence of incorrect actions that must be corrected at a later instance and 2. the human tendency to perform "bang-bang" instead of smooth control. The effect of these suboptimalities cannot be neglected.
Reference: <author> Kaiser, M., V. Klingspor, J. del R. Millan, M. Accame, F. Wallner and R. </author> <month> Dillmann </month> <year> (1995d). </year> <title> Using machine learning techniques in real-world mobile robots. </title> <journal> IEEE Expert. </journal>
Reference-contexts: available for planning: Only if the robot is able to associate a symbolic operator with a sequence of actions that are possibly dependent on its perceptions, i.e., only if the robot can operationalize the operator by applying a particular skill, using this op erator on the planning level makes sense <ref> (Kaiser et al., 1995d) </ref>. This is obviously related to the problem of symbol grounding (Harnad, 1990). elementary skills. To realize such elementary skills requires to map the robot's perceptions into actions by means of a strategy that is goal-oriented. Several possibilities to encode such a strategy exist (Fig. 1).
Reference: <author> Koeppe, R. and G. </author> <month> Hirzinger </month> <year> (1995). </year> <title> Learning compliant motions by task-demonstration in virtual environments. </title> <booktitle> In: Fourth Int. Symp. on Experimental Robotics. </booktitle>
Reference: <author> Kwok, T.-Y. and D.-Y. </author> <title> Yeung (1995). Constructive feedfor-ward neural networks for regression problems: A survey. </title> <type> Technical Report HKUST-CS95-43. </type> <institution> Hong Kong University of Science and Technology, Department of Computer Science. </institution>
Reference: <author> Liu, S. and H. </author> <month> Asada </month> <year> (1993). </year> <title> Teaching and learning of de-burring robots using neural networks. </title> <booktitle> In: Proceedings of the IEEE International Conference on Robotics and Automation. </booktitle> <address> Atlanta, Georgia. </address>
Reference: <author> Millan, J. del R. </author> <year> (1996). </year> <title> Rapid, safe, and incremental learning of navigation strategies. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics. </journal>
Reference: <author> Millan, J. del R. and C. </author> <month> Torras </month> <year> (1992). </year> <title> A reinforcement connectionist approach to robot path finding in non-maze-like environments. </title> <journal> Machine Learning 8, </journal> <volume> 363 - 395. </volume>
Reference: <author> Moody, J. and C. </author> <month> Darken </month> <year> (1988). </year> <title> Learning with localized receptive fields. </title> <booktitle> In: Proceedings of the Connectionist Models Summer School (T. </booktitle> <editor> Sejnowski D. Touretzky, G. Hinton, </editor> <address> Ed.). </address> <institution> Carnegie Mellon University. </institution>
Reference-contexts: In B-Learn II, the investigation of several function approximation techniques (Nut-tin et al., 1994; Kaiser et al., 1995a; Baroglio et al., 1996; Millan, 1996) lead to the selection of neural networks based on local receptive fields <ref> (Moody and Darken, 1988) </ref>, such as Radial-Basis Function Networks (RBFs) (Poggio and Girosi, 1990).
Reference: <author> Musavi, M.T., W. Ahmed, K.H. Chan, </author> <title> K.B. Faris and D.M. Hummels (1992). On the training of radial basis function classifiers. </title> <booktitle> Neural Networks 5, </booktitle> <volume> 595 - 603. </volume>
Reference: <author> Nuttin, M., A. Giordana, M. Kaiser and R. </author> <title> Suarez (1994). B-Learn II - D 203. B-Learn II ESPRIT BRA Project No. </title> <type> 7274. </type>
Reference: <author> Poggio, T. and F. </author> <title> Girosi (1990). Networks for approximation and learning. </title> <booktitle> Proceedings of the IEEE 78(9), </booktitle> <pages> 1481-1497. </pages>
Reference-contexts: In B-Learn II, the investigation of several function approximation techniques (Nut-tin et al., 1994; Kaiser et al., 1995a; Baroglio et al., 1996; Millan, 1996) lead to the selection of neural networks based on local receptive fields (Moody and Darken, 1988), such as Radial-Basis Function Networks (RBFs) <ref> (Poggio and Girosi, 1990) </ref>. Such networks can be built from training data (Moody and Darken, 1988; Musavi et al., 1992; Baroglio et al., 1996; Kwok and Yeung, 1995), which is extremly important in a setting that asks for automation of the learning phase.
Reference: <author> Pomerleau, D. A. </author> <year> (1991). </year> <title> Efficient training of artificial neural networks for autonomous navigation. </title> <booktitle> Neural Computation 3, </booktitle> <volume> 88 - 97. </volume>
Reference-contexts: In robotics, these approaches are mostly related to manipulation skills (Asada and Liu, 1991; Hirai et al., 1995; Koeppe and Hirzinger, 1995). The acquisition of basic mobility skills from human demonstrations has, for instance, been described by Pomerleau <ref> (Pomerleau, 1991) </ref> and Reignier (Reignier et al., 1995). If only an evaluation of the robot's performance is available, learning from examples is replaced by learning from reward and punishment (reinforcement learning, (Thorndike, 1911; Barto et al., 1983)).
Reference: <author> Reignier, P. </author> <year> (1993). </year> <title> Fuzzy logic techniques for mobile robot obstacle avoidance. </title> <booktitle> In: International Symposium on Intelligent Robotic Systems. </booktitle> <address> Zakopane, Poland. </address>
Reference: <author> Reignier, P., V. Hansen and J.L. </author> <title> Crowley (1995). Incremental supervised learning for mobile robot reactive control. </title> <booktitle> In: Intelligent Autonomous Systems 4 (IAS-4). </booktitle> <publisher> IOS Press. </publisher> <pages> pp. 287 - 294. </pages>
Reference-contexts: In robotics, these approaches are mostly related to manipulation skills (Asada and Liu, 1991; Hirai et al., 1995; Koeppe and Hirzinger, 1995). The acquisition of basic mobility skills from human demonstrations has, for instance, been described by Pomerleau (Pomerleau, 1991) and Reignier <ref> (Reignier et al., 1995) </ref>. If only an evaluation of the robot's performance is available, learning from examples is replaced by learning from reward and punishment (reinforcement learning, (Thorndike, 1911; Barto et al., 1983)).
Reference: <author> Song, K.-T. and J.-C. </author> <title> Tai (1992). Fuzzy navigation of a mobile robot. </title> <booktitle> In: Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems. </booktitle> <address> Raleigh, NC. </address>
Reference: <author> Thorndike, E. L. </author> <year> (1911). </year> <title> Animal Intelligence. </title> <publisher> Macmillan, </publisher> <address> New York. </address>
Reference: <author> Thrun, S. B. </author> <year> (1992). </year> <title> COLUMBUS: An autonomously exploring mobile robot. </title> <booktitle> In: Advances in Neural Information Processing Systems 5 (NIPS-5). </booktitle>
Reference: <author> Urbancic, T. and I. </author> <title> Bratko (1994). Reconstructing human skill with machine learning. </title> <booktitle> In: Proceedings of the ECAI '94. </booktitle> <address> Amsterdam. </address>
Reference: <author> Wallner, F. and R. </author> <month> Dillmann </month> <year> (1994). </year> <title> Efficient mapping of dynamic environment by use of sonar and active stereo-vision. </title> <booktitle> In: International Symposium on Intelligent Robotic Systems `94, </booktitle> <address> Grenoble. </address>
Reference-contexts: 1 INTRODUCTION Despite the diversity of mobile robot applications, and of the environment they are usually operating in, two characteristic modes of operation can always be distinguished (see also <ref> (Wallner and Dill-mann, 1994) </ref>): Model-based operation, including path planning and execution on the base of an a-priori given and possibly continuously refined geometrical world model.
Reference: <author> Wallner, F., T.C. Luth and F. </author> <month> Langiniuex </month> <year> (1992). </year> <title> Fast local path planning for a local robot. </title> <booktitle> In: Proc. of the Second International Conference on Automation, Robotics, and Computer Vision. </booktitle> <address> Singapore. </address>
References-found: 34

