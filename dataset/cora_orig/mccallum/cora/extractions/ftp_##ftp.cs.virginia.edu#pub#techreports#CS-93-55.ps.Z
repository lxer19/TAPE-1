URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-93-55.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A Thesis  The Design and Evaluation of an Off-Host Communications Protocol Architecture  
Author: Jeffrey R. Michel 
Degree: Presented to the Faculty of the  In Partial Fulfillment of the Requirements for the Degree Master of Science (Computer Science)  
Date: August 1993  
Note: by  
Affiliation: School of Engineering and Applied Science University of Virginia  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. J. Accetta, R. V. Baron, W. Bolosky, D. B. Golub, R. F. Rashid, A. Tevanian Jr., and M. W. Young, </author> <title> Mach: A New Kernel Foundation of UNIX Development, </title> <booktitle> Proceedings of the Summer 1985 USENIX Conference, </booktitle> <month> July </month> <year> 1986, </year> <pages> pp. 93-113. </pages>
Reference-contexts: In such cases it may be necessary to place the protocol processor device driver in a protected operating system kernel. An alternative to this approach, employed in operating systems such as Mach <ref> [1] </ref>, allows device drivers to run securely at the user level. Such drivers run as privileged server processes as discussed in section 1.3.1.
Reference: [2] <institution> American National Standards Institute/Institute of Electrical and Electronics Engineers, VMEbus Specification Manual, STD 1014-1987, VMEbus International Trade Association, Scottsdale, Arizona, </institution> <year> 1987. </year>
Reference-contexts: The bus and motherboard architecture also forced certain other design constraints. Since the host motherboard resides in the first slot of the VME backplane, it is required by the VMEbus specification to act as the bus arbiter <ref> [2] </ref>. This constrained our bus arbitration policy since the Sun 4300 motherboard supports only a fixed-priority arbitration policy [45]. In addition, the board supports only a Release On Request (ROR) bus release strategy.
Reference: [3] <author> B. Beach, UltraNet: </author> <title> An Architecture for Gigabit Networking, </title> <booktitle> Proceedings of the 15th Conference on Local Computer Networks, </booktitle> <address> Minneapolis, Minnesota, </address> <month> September 30-October 3, </month> <year> 1990, </year> <pages> pp. 232-248. </pages>
Reference-contexts: They expect a higher rate with a full hierarchical-bus implementation of their architecture. 3.6. Beach Beach presents the design of UltraNet, a commercial architecture aimed at providing near-gigabit data transfer between supercomputers over gigabit links <ref> [3] </ref>. To achieve such high performance, UltraNet architects use an off-host firmware implementation of a modified TP4 and employ up to two general-purpose processors and a small amount of custom VLSI support. The network layer of this architecture is null.
Reference: [4] <author> A. G. Bell and G. Borriello, </author> <title> A Single Chip NMOS Ethernet Controller, </title> <booktitle> Proceedings of the IEEE International Solid-State Circuits Conference, </booktitle> <month> February </month> <year> 1983, </year> <pages> pp. 70-71. </pages>
Reference: [5] <author> P. L. Borrill, </author> <title> 32-Bit BusesAn Objective Comparison, </title> <booktitle> Proceedings, </booktitle> <address> BUSCON 1986 West, San Jose, California, </address> <year> 1986, </year> <pages> pp. 138-145. </pages>
Reference-contexts: Another important issue affecting the bus transfer rate is the access or cycle time of the memory or registers on the slave side of the bus transaction. Some measurements of VMEbus throughput <ref> [5] </ref> have indicated that, for block mode transfers involving infinitely fast memory, the VMEbus can support a throughput of 223.2 Mbps; however, with block mode and a memory having a 150-ns access time, peak VME-bus throughput drops to only 108.8 Mbps.
Reference: [6] <author> T. Braun and M. Zitterbart, </author> <title> A Parallel Implementation of XTP on Transputers, </title> <booktitle> Proceedings of the 16th Conference on Local Computer Networks, </booktitle> <address> Minneapolis, Minne-sota, </address> <month> October </month> <year> 1991, </year> <pages> pp. 321-329. </pages>
Reference: [7] <author> T. Braun, B. Stiller, and M. Zitterbart, </author> <title> XTP and VMTP on Multiprocessor Architectures, </title> <booktitle> Proceedings of the International Workshop on Advanced Communications and Applications for High-Speed Networks, </booktitle> <address> Munich, Germany, </address> <month> March </month> <year> 1992, </year> <pages> pp. 67-76. </pages>
Reference: [8] <author> D. R. Cheriton, VMTP: </author> <title> A Versatile Message Transaction Protocol, </title> <type> Technical Report RFC 1045, </type> <institution> Defense Advanced Research Projects Agency, </institution> <month> February </month> <year> 1988. </year>
Reference-contexts: Kanakia and Cheriton Convinced that conventional transport protocols were too slow without hardware implementation, Kanakia and Cheriton designed the VMP 2 Network Adapter Board (NAB) [27]. The NAB is an off-host protocol processor board designed to implement Cheritons VMTP transport protocol <ref> [8] </ref>. In their design, VMTP runs directly above the raw data link, i.e., the network layer of their protocol architecture is null. Like XTP, VMTP is a simplified, lightweight protocol, designed to allow VLSI support.
Reference: [9] <author> G. Chesson, </author> <title> The Protocol Engine Project, Unix Review, </title> <month> September </month> <year> 1987. </year>
Reference-contexts: This research is not surveyed here because it is largely concerned with issues intrinsic to parallel host computers rather than with the off-host design issues presented in chapter two. 3.2. Chesson A pioneering effort in the development of off-host protocol architectures was Greg Chessons Protocol Engine project <ref> [9] </ref>. The goal of this project was to develop the Protocol Engine, a custom VLSI protocol processor for the Xpress Transfer Protocol (XTP). XTP possesses two unique architectural features relevant to off-host protocol processing.
Reference: [10] <author> G. Chesson, </author> <title> XTP/PE Design Considerations, </title> <editor> H. Rudin and R. Williamson, Ed., </editor> <title> Protocols for High-Speed Networks, </title> <publisher> Elsevier Science Publishers B. V., North Hol-land, </publisher> <year> 1989, </year> <pages> pp. 27-33. </pages>
Reference-contexts: First, 39 it is a transfer layer 1 protocol spanning both the transport and network layers of the ISO OSI reference model. Second, XTP was designed as part of the Protocol Engine project to readily facilitate its VLSI implementation. The design of the protocol processor is discussed in <ref> [10] </ref> and [44]. The most distinguishing feature of the Protocol Engine is its VLSI-intensive approach; in choosing an ASIC chipset implementation for the common-case processing of XTP, the Protocol Engine designers hoped to maximize the parallelism possible in protocol processing.
Reference: [11] <author> E. C. Cooper, P. A. Steenkiste, R. D. Sansom, and B. D. Zill, </author> <title> Protocol Implementation on the Nectar Communication Processor, </title> <booktitle> Proceedings, SIGCOMM 90, </booktitle> <address> Phila-delphia, PA, </address> <month> September </month> <year> 1990, </year> <pages> pp. 135-144. </pages>
Reference: [12] <author> P. Coquet, </author> <title> GAM-T-103 Reference Model for Military Real-Time Local-Area Networks (MRT-LAN), </title> <booktitle> Proceedings of the IFIP Workshop on Protocols for High-Speed Networks, </booktitle> <address> Zrich, </address> <month> May </month> <year> 1989. </year> <month> 120 </month>
Reference-contexts: A more general-purpose control processor handles complex XTP processing tasks such as network level route management and connection setup. Such are operations that do not occur in the common case of protocol processing. 1. The term transfer layer originates with the protocol hierarchy of the GAM-T-103 reference model <ref> [12] </ref>. 40 To communicate with the host, the Protocol Engine includes a host port. Its circuitry transfers data buffers between host and protocol processor memory using high-speed DMA (its transfer rate was projected to be 200 Mbps).
Reference: [13] <author> B. J. Dempsey, J. C. Fenton, J. R. Michel, A. S. Waterman, and A. C. Weaver, </author> <title> Tutorial on UVA SAFENET Lightweight Communications Architecture, </title> <institution> Computer Science Technical Report Number TR-93-01, University of Virginia, </institution> <month> January </month> <year> 1993. </year>
Reference: [14] <author> B. J. Dempsey, J. C. Fenton, J. R. Michel, A. S. Waterman, and A. C. Weaver, </author> <title> Ada Binding Reference ManualSAFENET Lightweight Application Services, </title> <institution> Computer Science Technical Report TR-93-02, University of Virginia, </institution> <month> January </month> <year> 1993. </year>
Reference: [15] <author> B. J. Dempsey, J. C. Fenton, J. R. Michel, A. S. Waterman, and A. C. Weaver, </author> <title> SAFENET Internals, </title> <institution> Computer Science Technical Report Number TR-93-05, University of Virginia, </institution> <month> January </month> <year> 1993. </year>
Reference: [16] <author> C. Diot and M. N. X. Dang, </author> <title> A High-Performance Implementation of OSI Transport Protocol Class 4; Evaluation and Perspectives, </title> <booktitle> Proceedings of the 15th Conference on Local Computer Networks, </booktitle> <address> Minneapolis, Minnesota, </address> <month> October </month> <year> 1990, </year> <pages> pp. 223-230. </pages>
Reference: [17] <author> C. Diot and V. Roca, </author> <title> XTP/KRM Implementation on a Transputer Network, </title> <booktitle> Proceedings of the 16th Conference on Local Computer Networks, </booktitle> <address> Minneapolis, Minne-sota, </address> <month> October </month> <year> 1991, </year> <pages> pp. 310-320. </pages>
Reference: [18] <author> R. Duncan, Ed., </author> <title> The MS-DOS Encyclopedia, </title> <publisher> Microsoft Press, </publisher> <address> Redmond, Washing-ton, </address> <year> 1988. </year>
Reference-contexts: Another component of the communications architecture which may reside at the user level is the protocol processor device driver. For host operating systems such as MS-DOS <ref> [18] </ref> in which secure access to shared resources is not a concern, the protocol processor device driver may safely run at the user level.
Reference: [19] <author> I. Erickson, </author> <title> Protocol Controller Chip Manages X.25 Interface, </title> <booktitle> Computer Design, </booktitle> <volume> Vol. 24, </volume> <month> September 1, </month> <year> 1985, </year> <pages> pp. 78-81. </pages>
Reference: [20] <author> D. Giarrizzo, M. Kaiserswerth, T. Wicki, and R. C. Williamson, </author> <title> High-Speed Parallel Protocol Implementation, </title> <editor> H. Rudin and R. Williamson, Ed., </editor> <title> Protocols for High-Speed Networks, </title> <publisher> Elsevier Science Publishers B. V., North Holland, </publisher> <year> 1989, </year> <month> pp.165-180. </month>
Reference: [21] <author> D. T. Green and D. T. Marlow, </author> <title> SAFENET - LAN for Navy Mission Critical Systems, </title> <booktitle> Proceedings of the 14th Conference on Local Computer Networks, </booktitle> <address> Minneap-olis, Minnesota, </address> <month> October </month> <year> 1989, </year> <pages> pp. 340-346. </pages>
Reference: [22] <author> A. N. Habermann, </author> <title> Synchronization of Communicating Processes, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 15, No. 3, </volume> <month> March </month> <year> 1972, </year> <pages> pp. 171-176. </pages>
Reference: [23] <author> B. Heinrichs, </author> <title> XTP Specification and Parallel Implementation, </title> <booktitle> Proceedings of the International Workshop on Advanced Communications and Applications for High-Speed Networks, </booktitle> <address> Munich, Germany, </address> <month> March </month> <year> 1992, </year> <pages> pp. 77-84. </pages>
Reference: [24] <author> International Organization for Standardization, </author> <title> Information Processing Systems Open Systems InterconnectionBasic Reference Model, Draft International Standard 7498, </title> <month> October </month> <year> 1984. </year>
Reference-contexts: These communications protocols are quite numerous and have perform varying services. To organize this complexity, they are structured into protocol hierarchies consisting of multiple layers of functionality. For the purposes of our discussion, we shall use the hierarchical organization of the ISO/OSI reference model <ref> [24] </ref> to refer to the protocol layers and to imply the functionality supported at each.
Reference: [25] <author> N. Jain, M. Schwartz, and T. R. Bashkow, </author> <title> Transport Protocol Processing at BGPS Rates, </title> <booktitle> Proceedings, SIGCOMM 90, ACM, </booktitle> <address> New York, </address> <year> 1990, </year> <pages> pp. 188-199. 121 </pages>
Reference: [26] <author> D. Julin, </author> <title> MACH Networking Group, Network Server Design, </title> <type> Technical Report, </type> <institution> Carnegie Mellon University, </institution> <month> September </month> <year> 1989. </year>
Reference-contexts: In such a situation, an application process desiring network service acts as a client, sending a request message for protocol service to the server via interprocess communication. The server process later sends a reply message to the client when it has completed the request <ref> [26] </ref>. Access to the shared resources is restricted to the server process, which, like the kernel, has a protected address space. This approach has the benefit of providing secure access to shared resources without adding to the complexity of the operating system kernel.
Reference: [27] <author> H. Kanakia, D. R. Cheriton, </author> <title> The VMP Network Adapter Board (NAB): High-Performance Network Communication for Multiprocessors, </title> <booktitle> Proceedings of the SIG-COMM 88 Symposium on Communications Architectures and Protocols, </booktitle> <month> August </month> <year> 1988, </year> <pages> pp. 175-187. </pages>
Reference-contexts: Similarly, a transport and network protocol processor can deliver to the host only those TSDUs which the host desires to receive, thus shielding it from an accidental or malicious barrage of TSDU arrivals. Such a feature has been referred to as a network firewall <ref> [27] </ref>. 1.4.2. Protocol Benefits A communications protocol can receive the following benefits when run on protocol processor hardware: Dedicated processing cycles. When run on the host, a communications protocol must contend with application processes for processor cycles, thereby losing potential CPU cycles and incurring overhead from scheduling and context swaps. <p> The literature provides no details of the command and status streams between the protocol processor and a user-level application. 3.3. Kanakia and Cheriton Convinced that conventional transport protocols were too slow without hardware implementation, Kanakia and Cheriton designed the VMP 2 Network Adapter Board (NAB) <ref> [27] </ref>. The NAB is an off-host protocol processor board designed to implement Cheritons VMTP transport protocol [8]. In their design, VMTP runs directly above the raw data link, i.e., the network layer of their protocol architecture is null. <p> Background Performance estimations have been used by others to predict the performance of their designs. In a previous work on off-host protocol processing, Kanakia and Cheriton estimate the performance of their proposed Network Adapter Board <ref> [27] </ref>. Their analysis takes into account such factors as bus transfer time, network transfer time, and memory access time in order to predict the request-response delay of their device. The approach is quite informal, and it takes into account factors above and below the level of their transport protocol (VMTP).
Reference: [28] <author> A. S. Krishnakumar and K. Sabnani, </author> <title> VLSI Implementations of Communication Pro-tocolsA Survey, </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> Vol. 7, No. 7, </volume> <month> September </month> <year> 1989, </year> <pages> pp. 1082-1090. </pages>
Reference-contexts: The goal of this hardware has been twofold: (1) to perform protocol operations at generally higher rates of speed, and (2) to lower the burden of protocol processing on the host CPU <ref> [28] </ref>. 6 The trend has been for an increasing amount of higher-layer protocol functionality to be performed in special-purpose hardware without the involvement of the host CPU. Following this trend, we investigate the implementation options for protocols at the network and transport layers.
Reference: [29] <author> L. Lamport, </author> <title> Synchronization of Independent Processes, </title> <journal> Acta Informatica, </journal> <volume> Vol. 7, No. 1, </volume> <year> 1976, </year> <pages> pp. 15-34. </pages>
Reference: [30] <author> S. J. Lefer, M. K. McKusick, M. J. Karels, and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: The protocol software may be loosely integrated into the kernel as a device driver accessed through the operating systems I/O system calls [37], or it may be tightly integrated into the kernel and accessed with its own set of networking system calls <ref> [30] </ref>. Such calls are more sophisticated than subprogram calls; hence, they may result in a significant overhead. In addition, if the kernel resides in a protected address space, the cost of some means of accessing protocol data residing in the calling process address space must be incurred. <p> Such processes may send and receive application service data units (ASDUs) located in the memory of their address space. Applications transfer these ASDUs by invoking communication primitives from an Application Program Interface (API). An example of such an API is the socket interface of BSD UNIX <ref> [30] </ref>. At least part of the API imple User Level Kernel Level Protocol-Processor Level Network-Interface Level Bus Level Bus Level 21 mentation must reside at the user level so that it may be accessed by applications; however, much of the API implementation may also occur at the kernel level. <p> Such protocols may be in the form of library code linked with the code of an application, or the protocols may run as server processes. 2.3.2. Kernel Level In operating systems such as UNIX <ref> [30] </ref> which provide the secure management of shared resources for multiple user processes, host memory is divided into protected address spaces. <p> For short messages, however, a mechanism employ 28 ing the call-by-value mechanism may prove to have higher performance since such a method avoids the overhead of shared memory creation. 2.4.1.3. User-Level Interrupts Some operating systems such as UNIX <ref> [30] </ref> allow kernel software to interrupt a user process in order to notify it of the occurrence of an asynchronous event such as the arrival of protocol processor status. This information may be sent by a kernel-level device driver to an application process or a protocol server.
Reference: [31] <author> R. A. MacClean and S. E. Barvick, </author> <title> An Outboard Processor for High Performance Implementation of Transport Layer Protocols, </title> <booktitle> Proceedings, GLOBECOM 91, </booktitle> <year> 1991, </year> <pages> pp. 1728-1732. </pages>
Reference-contexts: MacLean and Barvick MacLean and Barvick developed an off-host Protocol Accelerator (PA) board whose goal is to eliminate the bottlenecks in transport protocol processing. The PA approach is to use two general-purpose microprocessors and additional custom hardware to execute a modified TCP <ref> [31] </ref>. Their communications architecture has a null network layer and serves a UNIX host computer containing a 25-Mhz Motorola MC68030 CPU. A VME backplane contains the PA board along with the host processor board and a 4-Mbyte host memory board.
Reference: [32] <author> MIL-STD-2204: </author> <title> Survivable Adaptable Fiber Optic Embedded Network (SAFENET), </title> <institution> United States Department of Defense, </institution> <month> September, </month> <year> 1992. </year>
Reference: [33] <author> R. J. Mitchell, E. T. Saulnier, and M. C. Orlovsky, </author> <title> A Partitioned Implementation of the Xpress Transfer Protocol (Part I), </title> <booktitle> Proceedings of the 16th Conference on Local Computer Networks, </booktitle> <address> Minneapolis, Minnesota, </address> <month> October </month> <year> 1991, </year> <pages> pp. 301-309. </pages>
Reference: [34] <author> R. J. Mitchell, E. T. Saulnier, </author> <title> Experience with an XTP Implementation for Embedded Systems, </title> <booktitle> Proceedings of the 17th Conference on Local Computer Networks, </booktitle> <address> Minneapolis, Minnesota, </address> <month> September </month> <year> 1992, </year> <pages> pp. 586-592. </pages>
Reference: [35] <author> A. N. Netravali, W. D. Roome, K. Sabnani, </author> <title> Design and Implementation of a High-Speed Transport Protocol, </title> <journal> IEEE Transactions on Communications, </journal> <volume> Vol. 38, No. 11, </volume> <month> November </month> <year> 1990, </year> <pages> pp. 2010-2024. </pages>
Reference-contexts: Netravali et al. Netravali et al. developed an communications architecture in which their SNR protocol runs off-host and in parallel on a set of loosely-integrated, dedicated processing nodes <ref> [35] </ref>. They use a protocol architecture with a null network layer. A novel aspect of their architecture is that, to minimize bus contention, their planned design connects protocol processing nodes via a hierarchy of buses, each of which may be mastered independently.
Reference: [36] <author> J. L. Paige, </author> <title> SAFENET - A Navy Approach to Computer Networking, </title> <booktitle> Proceedings of the 15th Conference on Local Computer Networks, </booktitle> <address> Minneapolis, Minnesota, Sep-tember 30-October 3, </address> <year> 1990, </year> <pages> pp. 268-273. </pages>
Reference: [37] <author> D. M. Ritchie, </author> <title> A Stream Input-Output System, </title> <journal> AT&T Bell Laboratories Technical Journal, </journal> <volume> Vol. 63, No. 8, </volume> <month> October </month> <year> 1984, </year> <pages> pp. 1897-1910. </pages>
Reference-contexts: In this kernelized scenario, application programs typically request protocol services from the kernel through system calls. The protocol software may be loosely integrated into the kernel as a device driver accessed through the operating systems I/O system calls <ref> [37] </ref>, or it may be tightly integrated into the kernel and accessed with its own set of networking system calls [30]. Such calls are more sophisticated than subprogram calls; hence, they may result in a significant overhead.
Reference: [38] <author> E. T. Saulnier and R. J. Mitchell, </author> <title> A Multi-Processor Partitioning of XTP, </title> <booktitle> Proceedings of the International Workshop on Advanced Communications and Applications for High-Speed Networks, </booktitle> <address> Munich, Germany, </address> <month> March </month> <year> 1992, </year> <pages> pp. 85-92. 122 </pages>
Reference: [39] <author> M. Siegel, M. Williams, and G. Rler, </author> <title> Overcoming Bottlenecks in High-Speed Transport Systems, </title> <booktitle> Proceedings of the 16th Conference on Local Computer Networks, </booktitle> <address> Minneapolis, Minnesota, </address> <month> October </month> <year> 1991, </year> <pages> pp. 399-407. </pages>
Reference-contexts: Data are transferred between the host and protocol processor using a DMA controller built into the 80960 microprocessor. 3.9. Siegel et al. Siegel et al. develop an architecture which seeks to overcome the bottlenecks in transport protocol processing <ref> [39] </ref>. They approach the problem at two ends by employing (1) a simplified version of TP4 and (2) an off-host architecture in which TP4 runs in parallel on a set of general-purpose processors aided by custom VLSI.
Reference: [40] <author> A. Silberschatz, </author> <title> Communications and Synchronization in Distributed Programs, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-5, No. 6, </volume> <month> November </month> <year> 1979, </year> <pages> pp. 542-546. </pages>
Reference: [41] <author> R. Simoncic, A. C. Weaver, and M. A. Colvin, </author> <title> Experience with the Xpress Transfer Protocol, </title> <booktitle> Proceedings of the 15th Conference on Local Computer Networks, </booktitle> <address> Minne-apolis, Minnesota, </address> <month> September 30-October 3, </month> <year> 1990, </year> <pages> pp. 123-131. </pages>
Reference-contexts: Furthermore, there is seldom any address space partitioning between user processes and the operating system. In this environment, a protocol implementation may acceptably be in the form of library code linked with the code of an application program <ref> [41] </ref>. This approach has the benefit of avoiding operating system security concerns and complex address space issues. As a result, the protocol implementation is likely simpler and its performance is typically higher than that of other approaches.
Reference: [42] <author> M. Stark, A. Kornhauser, and D. Van-Mierop, </author> <title> A High Functionality VLSI LAN Controller for CSMA/CD Networks, </title> <booktitle> Proceedings of the IEEE Compcon Spring, </booktitle> <month> February 28-March 3, </month> <year> 1983, </year> <pages> pp. 510-517. </pages>
Reference: [43] <author> P. Steenkiste, </author> <title> Analyzing Communication Latency Using the Nectar Communication Processor, </title> <booktitle> Proceedings of SIGCOMM 92, </booktitle> <year> 1992, </year> <pages> pp. 199-209. </pages>
Reference: [44] <author> W. T. Strayer, B. J. Dempsey, and A. C. Weaver, XTP: </author> <title> The Xpress Transfer Protocol, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: Second, XTP was designed as part of the Protocol Engine project to readily facilitate its VLSI implementation. The design of the protocol processor is discussed in [10] and <ref> [44] </ref>. The most distinguishing feature of the Protocol Engine is its VLSI-intensive approach; in choosing an ASIC chipset implementation for the common-case processing of XTP, the Protocol Engine designers hoped to maximize the parallelism possible in protocol processing. <p> End-to-end latency measures half the round-trip time of an entire ASDU sent between two Ada applications. For the throughput measurements, the communication primitives were performed asynchronously, and XTPs rate control features and NOCHECK option <ref> [44] </ref> were used to provide maximum performance. RATE was set to 1.5 MB/s and BURST was set to 10 KB/burst. For the latency measurements, NOCHECK was set, but rate control was unused. The minimum latency occurred at a message size of one byte and was 5.1 ms.
Reference: [45] <author> Sun Microsystems, Inc. </author> <title> Sun 4300 CPU Board Hardware Reference Manual, Part No: </title> <address> 800-3081-05, Mountain View, California, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: Since the host motherboard resides in the first slot of the VME backplane, it is required by the VMEbus specification to act as the bus arbiter [2]. This constrained our bus arbitration policy since the Sun 4300 motherboard supports only a fixed-priority arbitration policy <ref> [45] </ref>. In addition, the board supports only a Release On Request (ROR) bus release strategy. A very significant restriction imposed by the motherboard is that only a restricted region of its virtual address space is addressable on the VMEbus. The effect of this restriction is discussed in section 4.5.3.2.
Reference: [46] <author> Sun Microsystems, Inc., </author> <title> Writing Device Drivers, Part No: </title> <address> 800-3851-10, Mountain View, California, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: The iodone () routine acts to release the exclusive access to the block acquired by the physio () operation <ref> [46] </ref>. These two routines, as can be seen from the profiles, form the largest proportion of the hosts execution time spent on processing sending and receiving operations on short ASDUs.
Reference: [47] <author> A. S. Waterman, </author> <title> A Comparison of Off-Host vs. In-Kernel Communications Architecture, M.S. </title> <type> Thesis, </type> <institution> Department of Computer Science, University of Virginia (in preparation). </institution>
Reference-contexts: Some facets of this evaluation require comparison with the behavior an in-host architecture. For this purpose we compare our work with an in-kernel implementation of XTP <ref> [47] </ref>. This in-kernel approach features a somewhat different API, but the XTP layer and below consists of essentially the same protocol software. Other evaluations consider aspects of our off-host communications architecture which are readily observable from the design presented in chapter four or its analysis covered in chapter five. 7.2.1. <p> Similar 107 benefits also occur with respect to interrupts; each sending or receiving operation incurs exactly one host interrupt. Results from <ref> [47] </ref> show that 26 interrupts can result for a single 64-KB receiving operation. Thus the off-host architecture incurs 96% fewer interrupts in such cases. Obviously our design is quite successful in acting as a firewall. <p> To compare the host load of our off-host architecture with that of the in-kernel approach, we compare the load for transmitting operations of both short and long ASDUs. Estimates in <ref> [47] </ref> show that a 64-KB sending operation takes 66 ms of host CPU time for the in-kernel approach, whereas chapter five shows that a similar call using the off-host architecture requires only 21 ms. Relative to in-kernel operation, the off-host approach reduces host load by a factor of 68%.
Reference: [48] <author> R. W. Watson and S. A. Mamrak, </author> <title> Gaining Efficiency in Transport Services by Appropriate Design and Implementation Choices, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 5, No. 2, </volume> <month> May </month> <year> 1987, </year> <pages> pp. 97-120. </pages>
Reference-contexts: One method of optimizing this path is through the placement of the network interface on the same circuit board as the protocol processor device. Ideal operating system environment. It has been recognized that an operating system environment can place severe restrictions on a protocols performance and proper implementation <ref> [48] </ref>. The timer, buffer, and lightweight process management services provided by the host operating system may be relatively inefficient for protocol tasks. In addition, the host operating system may impose security restrictions and other overhead which can hinder protocol performance.
Reference: [49] <author> C. M. Woodside and R. G. Franks, </author> <title> Alternative Software Architectures for Parallel Protocol Execution with Synchronous IPC, </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> Vol. 1, No. 2, </volume> <month> April </month> <year> 1993, </year> <pages> pp. 178-186. </pages>
Reference: [50] <author> M. Zitterbart, </author> <title> A Multiprocessor Architecture for High-Speed Network Interconnections, </title> <booktitle> Proceedings, IEEE INFOCOM 89, </booktitle> <year> 1989, </year> <pages> pp. 212-218. </pages>
Reference: [51] <author> M. Zitterbart, </author> <title> High-Speed Protocol Implementations Based on a Multiprocessor Architecture, </title> <editor> H. Rudin and R. Williamson, Ed., </editor> <title> Protocols for High-Speed Networks, </title> <publisher> Elsevier Science Publishers B. V., North Holland, </publisher> <year> 1989, </year> <pages> pp. 151-163. 123 </pages>
Reference: [52] <author> M. Zitterbart, </author> <title> High-Speed Transport Components, </title> <journal> IEEE Network Magazine, </journal> <volume> Vol. 5, No. 1, </volume> <month> January </month> <year> 1991, </year> <pages> pp. 54-63. 124 </pages>
Reference-contexts: Other projects only went through initial design and unit testing phases; such work provides only estimates of performance. Off-host communications architectures have many similarities to parallel protocol implementations. To this end we wish to recognize the fine body of work on parallel implementations of network and transport protocols [6][7][16][17][20][23][25][49][50][51] <ref> [52] </ref>. This research is not surveyed here because it is largely concerned with issues intrinsic to parallel host computers rather than with the off-host design issues presented in chapter two. 3.2. Chesson A pioneering effort in the development of off-host protocol architectures was Greg Chessons Protocol Engine project [9].
References-found: 52

