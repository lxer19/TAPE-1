URL: ftp://ftp.cs.sandia.gov/pub/papers/wehart/opt/thesis.ps.gz
Refering-URL: http://www.ing.unlp.edu.ar/cetad/mos/memetic_home.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Adaptive Global Optimization with Local Search  
Author: William Eugene Hart Professor Paul R. Kube Professor Christos H. Papadimitriou Professor J. Benjamin Rosen Professor Halbert L. White, Jr. 
Degree: A dissertation submitted in partial satisfaction of the requirements for the degree Doctor of Philosophy in Computer Science Engineering by  Committee in charge: Professor Richard K. Belew, Chair Professor Philip E. Gill  
Date: 1994  
Affiliation: UNIVERSITY OF CALIFORNIA, SAN DIEGO  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> David H. Ackley. </author> <title> A Connectionist Machine for Genetic Hillclimbing. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1987. </year>
Reference-contexts: These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems [49]. Muhlenbein [60, 61, 62], Ackley <ref> [1] </ref>, and McInerney [56] have developed application-independent versions of the GA for optimization with local search. In most of these applications, the performance of the GA is substantially improved when the local search technique is employed. <p> Optimizing functions defined on R n also enables us to make comparisons with algorithms developed in the global optimization literature. Most problems in the testbeds used to evaluate GAs and global optimization algorithms are defined on R n <ref> [1, 21, 31, 91] </ref>. Thus, I evaluate GA-LS hybrids on problems for which we can 42 directly compare my results to other global optimization and evolutionary methods. The experiments in Chapter V and VI perform optimization on three global optimization test functions on R n . <p> If the parents of the i-th individual are p 1 and p 2 , then we can modify the local search frequency of the i-th individual as follows where 2 <ref> [0; 1] </ref>. This method approximates the complete method of calculating redundancy by assuming that (N 1) other solutions have the same difference 65 as the parents of the current individual. <p> If F 0 is the F statistic of the parents of the i-th individual, then the modified local search frequency for the local approximate method is 8 &gt; : otherwise where 2 <ref> [0; 1] </ref>.
Reference: [2] <author> David H. Ackley. </author> <title> A case for Lamarackian evolution. </title> <booktitle> In To appear in Proceedings of the Third Conf. on Artificial Life, </booktitle> <year> 1993. </year>
Reference-contexts: The most common way of structuring the selection mechanism uses a toroidal two dimensional grid like the one in Figure II.4 <ref> [2, 12, 56, 87] </ref>. Every element of the population is 22 Figure II.4: The two dimensional grid used by GSGAs to define population subsets. assigned to a location on the grid. The grid locations are not necessarily related to the individuals' solutions.
Reference: [3] <author> David H. Ackley and Michael L. Littman. </author> <title> A video presentation of "learning from natural selection in an artificial environment". </title> <editor> In Chris G. Langton, Charles Taylor, J. Doyne Farmer, and Steen Rasmussen, editors, </editor> <booktitle> Video Proceedings of the Second Conference on Artificial Life, </booktitle> <pages> pages 487-509. </pages> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: In this case, the optimal solutions are not biologically plausible. This phenomenon was observed in Ackley and Littman's artificial life model <ref> [3] </ref>. Nowak and May observe similar phenomena in the context of game theory [69]. The second difference concerns the manner in which the rate of evolution is measured in natural systems and in GA-LS hybrids. There are three ways the cost of GA-LS hybrids can be evaluated.
Reference: [4] <author> Thomas Back and Frank Hoffmeister. </author> <title> Extended selection mechanisms in genetic algorithms. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 92-99. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The exemplars of evolutionary search algorithms are genetic algorithms, evolutionary strategie and evolutionary programming [5, 22, 31]. The design and motivation for these algorithms are different, but they incorporate the same basic adaptive components <ref> [4, 41] </ref>. These methods use a collection of solutions (population of individuals) that are updated iteratively using selection mechanisms and genetic operators. The general process of each iteration (generation) is described in figure II.3. The selection mechanism performs a competition to select a subset of the solutions for further processing.
Reference: [5] <editor> Thomas Back, Frank Hoffmeister, and Hans-Paul Schwefel. </editor> <title> A survey of evolution strategies. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 2-9. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Research on evolutionary search algorithms incorporates elements of both biological evolution and global optimization. These algorithms are inspired by biological evolutionary mechanisms and are often used to perform global optimization. The exemplars of evolutionary search algorithms are genetic algorithms, evolutionary strategie and evolutionary programming <ref> [5, 22, 31] </ref>. The design and motivation for these algorithms are different, but they incorporate the same basic adaptive components [4, 41]. These methods use a collection of solutions (population of individuals) that are updated iteratively using selection mechanisms and genetic operators.
Reference: [6] <author> Richard K. Belew. </author> <title> Evolution, learning, and culture: Computational metaphors for adaptive algorithms. </title> <journal> Complex Systems, </journal> <volume> 4(1) </volume> <pages> 11-49, </pages> <year> 1990. </year>
Reference-contexts: Alternatively, local search can be applied to solutions in each iteration of the GA. This type of GA-LS hybrid is particularly interesting because the global and local search methods can influence each other's behavior. An important example of this phenomenon is the Baldwin effect <ref> [6, 40] </ref> in which learning in natural systems speeds up the rate of evolutionary change. Similar effects have been observed by a number of authors using GA-LS hybrids [7, 40, 50]. The research in this dissertation examines the second type of GA-LS hybrid. <p> Conversely, this research on artificial methods of adaptive search may have implications for models of evolution and learning in natural systems. The superior performance of the GA-LS hybrids when compared with the 116 GA appears to provide confirmation of the "Baldwin Effect" <ref> [6, 40] </ref>. The experiments in Chapters V and VII indicate that learning can improve the efficiency of the GA. Consequently, GA-LS hybrids run for fewer generations than the GA.
Reference: [7] <author> Richard K. Belew, John McInerny, and Nicol N. Schraudolph. </author> <title> Evolving networks: Using the genetic algorithm with connectionist learning. </title> <editor> In Chris G. Langton, Charles Taylor, J. Doyne Farmer, and Steen Rasmussen, editors, </editor> <booktitle> Proceedings of the Second Conference on Artificial Life, </booktitle> <pages> pages 511-548. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: An important example of this phenomenon is the Baldwin effect [6, 40] in which learning in natural systems speeds up the rate of evolutionary change. Similar effects have been observed by a number of authors using GA-LS hybrids <ref> [7, 40, 50] </ref>. The research in this dissertation examines the second type of GA-LS hybrid. I.C Genetic Algorithms with Local Search Previous experimental results confirm that GA-LS hybrids not only find better solutions than the GA, but also optimize more efficiently [7, 61]. <p> The research in this dissertation examines the second type of GA-LS hybrid. I.C Genetic Algorithms with Local Search Previous experimental results confirm that GA-LS hybrids not only find better solutions than the GA, but also optimize more efficiently <ref> [7, 61] </ref>. It is noteworthy that these results examine a limited number of algorithmic combinations of the GA with local search. I believe that important algorithmic combinations have been overlooked and that the standard GA-LS hybrids of the GA and local search should be reconsidered. <p> Similarly, models of learning are often equated with techniques for local optimization [81]. Research on the interaction between evolution and learning has naturally led computer scientists to consider interactions between evolutionary algorithms and local optimization <ref> [7] </ref>. The following framework is used to describe the range of interactions between the GA and local search algorithms. Let G be the space of genotypes, and let Ph be the space of phenotypes. Genotypes are mapped to phenotypes via a maturation function, ffi : G ! Ph. <p> Non-Lamarckian local search is typically used to determine the fitness associated with g. II.D Related Work GAs have been combined with local search methods for a number of different applications. The problem of finding the optimal parameters for a neural network <ref> [7, 50, 68] </ref> comes closest to the models of learning and evolution. GA-LS hybrids have been applied to combinatorial graph problems like the traveling salesman problem [9, 63, 95] and the graph partitioning problem [96]. <p> Some authors did stop their local search after a fixed time limit or after a fixed number of iterations of their local search algorithm. Finally, most authors used Lamarckian local search techniques. Belew et al. <ref> [7] </ref> and Judson et al. [49] make a clear distinction between mutation and local search in their experiments, and were able to compare the performance of Lamar-ckian and non-Lamarckian local search. They found that Lamarckian local search outperforms non-Lamarckian local search. <p> The neural network problem is the six-bit symmetry problem, which has been previously optimized with GA-LS hybrids by Belew, McInerney and Schrau-dolph <ref> [7] </ref>. The first molecular structural problem is the problem of solving for a molecule's conformation. This problem has been explored by a number of different authors [49, 55] and there are experiments with GA-LS hybrids for which a comparison is possible. <p> In theory, the global minimum of the search space is desired. In practice, minimization is usually performed using local search techniques that can only guarantee solutions which are locally optimal. Belew, McInerney and Schraudolph <ref> [7] </ref> use GA-LS hybrids to minimize J (w) for the six-bit symmetry problem. In the six-bit symmetry problem, patterns are classified as one if the left three bits are mirror images of the right three bits. Thus 110011 is classified as one, while 101110 is classified as zero.
Reference: [8] <author> C.G.E. Boender and A.H.G. Rinnooy Kan. </author> <title> Bayesian stopping rules for multi-start global optimization methods. </title> <journal> Mathematical Programming, </journal> <volume> 37 </volume> <pages> 59-80, </pages> <year> 1987. </year>
Reference-contexts: Blind random search methods are relatively inefficient, but they are often amenable to analysis <ref> [8, 18] </ref>.
Reference: [9] <author> Heinrich Braun. </author> <title> On solving the travelling salesman problems by genetic algorithms. </title> <editor> In Hans-Paul Schwefel and Reinhard Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 129-133. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year> <pages> 127 128 </pages>
Reference-contexts: The problem of finding the optimal parameters for a neural network [7, 50, 68] comes closest to the models of learning and evolution. GA-LS hybrids have been applied to combinatorial graph problems like the traveling salesman problem <ref> [9, 63, 95] </ref> and the graph partitioning problem [96]. These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems [49].
Reference: [10] <author> Matthew Clark, Richard D. Cramer, III, and Nicole Van Opdenbosch. </author> <title> Validation of the general purpose Tripos 5.2 force field. </title> <journal> Journal of Computational Chemistry, </journal> <volume> 10(8) </volume> <pages> 982-1012, </pages> <year> 1989. </year>
Reference-contexts: For example, we could define V as V = V bond + V angle + V torsion + V nonbond + V electrostatic A detailed description of these terms is given in Le Grand and Merz [54]. Clark, Cramer and Van Opdenbosch <ref> [10] </ref> describe many of the "standard" force fields. In-tramolecular forces are modeled by the terms for bond stretching, bond torsion and angle valence.
Reference: [11] <author> N.E. Collins, R.W. Eglese, and B.L. Golden. </author> <title> Simulated annealing an annotated bibliography. </title> <journal> American Journal of Mathematics and Management Sciences, </journal> <volume> 8(3 </volume> & 4):209-307, 1988. 
Reference-contexts: Simulated annealing (SA) is a method of optimization inspired by an analogy between a physical annealing process for obtaining low energy states and the process of solving for minimal solutions to discrete optimization problems <ref> [11, 51] </ref>. SA sequentially generates random deviates of the current solution that are accepted if a probabilistic test is passed. Suppose x 0 is the current solution and let x 00 be the new deviate. If f (x 00 )f (x 0 ) &lt; 0, the new deviate is accepted.
Reference: [12] <author> Robert J. Collins and David R. Jefferson. </author> <title> Selection in massively parallel genetic algorithms. </title> <booktitle> In Proceedings of the 4th International Conference on Genetic Algorithms, </booktitle> <pages> pages 249-256, </pages> <year> 1991. </year>
Reference-contexts: The most common way of structuring the selection mechanism uses a toroidal two dimensional grid like the one in Figure II.4 <ref> [2, 12, 56, 87] </ref>. Every element of the population is 22 Figure II.4: The two dimensional grid used by GSGAs to define population subsets. assigned to a location on the grid. The grid locations are not necessarily related to the individuals' solutions. <p> Two general methods of local selection have been used to perform selection in GSGAs: (1) fixed size neighborhoods have been used to define the set of neighboring individuals [14, 35], and (2) random walks have been used to stochastically sample the locations of neighboring individuals <ref> [12, 56] </ref>. Figure II.4 illustrates the fixed size neighborhoods that could be used to perform selection. Proportional selection is applied to the solutions in each of these neighborhoods. <p> GSGAs are implemented by assigning one individual per processor. Selection and recombination is limited to a small number of individuals on neighboring processors, typically forming a two dimensional grid of individuals (see Spiessens and Manderick [87], Collins and Jefferson <ref> [12] </ref> and McInerney [56]). Gordon and Whitley [35] have recently argued that the algorithmic nature of these parallel algorithms may be of interest, independent from their implementation on a particular architecture.
Reference: [13] <author> J.S. Cramer. </author> <title> The Logit Model: An introduction for economists. </title> <editor> Edward Arnold, </editor> <year> 1991. </year>
Reference-contexts: A common error function is the squared error E (a; b) = ka bk 2 : Examples of parametric models are linear models [19], logit models <ref> [13] </ref> and neural networks [81]. Both random local search and conjugate gradient methods can be used to minimize J (w), since gradient information is typically available for this function. An alternative method of minimizing J (w) is stochastic approximation.
Reference: [14] <author> Yuval Davidor, Takeshi Yamada, and Ryohei Nakano. </author> <title> The ECOlogical framework II: Improving GA performance at virtually zero cost. </title> <editor> In Stephanie Forrest, editor, </editor> <booktitle> Proceedings of the Fifth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 171-176. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: When local selection is performed, it is performed in the population grid. Two general methods of local selection have been used to perform selection in GSGAs: (1) fixed size neighborhoods have been used to define the set of neighboring individuals <ref> [14, 35] </ref>, and (2) random walks have been used to stochastically sample the locations of neighboring individuals [12, 56]. Figure II.4 illustrates the fixed size neighborhoods that could be used to perform selection. Proportional selection is applied to the solutions in each of these neighborhoods. <p> Gordon and Whitley [35] have recently argued that the algorithmic nature of GSGAs may be of interest, independent from their implementation on a particular architecture. They experimentally compare GSGAs to panmictic GAs and observe that the GSGAs provide superior performance. This philosophy is echoed by Davidor, Yamada and Nakano <ref> [14] </ref> in their motivation for the ECO framework. The ECO framework provides a serial design for implementing a geographically structured GA. Finally, we note that our definition of GSGAs includes GAs which structure the selection at a fine granularity. <p> They experimentally compare the performance of several classic, island-model and geographically structured GAs that are executed on a sequential architecture. They observed that both IMGAs and GSGAs provide performance that is superior to the performance of a classic GA. This philosophy is echoed by Davidor, Yamada and Nakano <ref> [14] </ref> in their motivation for the ECO framework. The ECO framework provides a serial design for implementing a geographically structured GA. I am interested in the algorithmic nature of the GSGA, but wish to paral-lelize it on MIMD architectures. This particular parallel design is motivated by two 81 observations.
Reference: [15] <author> Lawrence Davis. </author> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: For example, if the binary string is decoded into a vector of integers or floating point values, then crossover is often applied only between the integer or floating point values on the binary string <ref> [15] </ref>. II.C.2 Panmictic and Geographically Structured Genetic Algorithms GAs can be distinguished by the manner in which the selection mechanism and genetic operators are applied to the population. Panmictic GAs use selection mechanisms (like proportional selection) that use global information about the entire population to perform a global selection.
Reference: [16] <author> Kenneth A. De Jong. </author> <title> An analysis of the behavior of a class of genetic adaptive systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: Figure IV.3: The Rastrigin function. 45 IV.C Optimization Methods IV.C.1 Floating Point GA I use a GA with a floating point encoding in the experiments. GAs have traditionally used binary encodings of real numbers to perform optimization on R n <ref> [16] </ref>. While binary encodings have been used to successfully solve optimization problems, special manipulation of this encoding is often necessary to increase the efficiency of the algorithm [83, 100]. There is evidence that optimization on R n can and should be performed with real parameters.
Reference: [17] <author> C.C.Y. Dorea. </author> <title> Limiting distribution for random optimization methods. </title> <journal> SIAM Journal of Control and Optimization, </journal> <volume> 24(1) </volume> <pages> 76-82, </pages> <year> 1986. </year>
Reference-contexts: Variants of these algorithms that use a fixed, non-uniform distribution over the search domain are also blind random search techniques. Also included is the probabilistic multistart algorithm (described in Chapter III) and the algorithm described in Dorea <ref> [17] </ref> for which new samples are generated by adding a random deviate (from a fixed distribution) to the previous sample. Blind random search methods are relatively inefficient, but they are often amenable to analysis [8, 18].
Reference: [18] <author> C.C.Y. Dorea. </author> <title> Stopping rules for a random optimization method. </title> <journal> SIAM Journal of Control and Optimization, </journal> <volume> 28(4) </volume> <pages> 841-850, </pages> <year> 1990. </year>
Reference-contexts: Blind random search methods are relatively inefficient, but they are often amenable to analysis <ref> [8, 18] </ref>.
Reference: [19] <author> Richard O. Duda and Peter E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley and Sons, </publisher> <year> 1973. </year>
Reference-contexts: The first is the non-derivative method proposed by Solis and Wets [84]. Next, conjugate gradient methods [26, 74] are used to minimize continuous functions using gradient information. Finally, stochastic approximation is used in pattern recognition methods 10 to find the optimal weights for parametric models of data <ref> [19] </ref>. II.A.1 Random Local Search Solis and Wets [84] propose several random local search methods for performing local search on smooth functions without derivative information. Their "Algorithm 1" uses normally distributed steps to generate new points in the search space. <p> A common error function is the squared error E (a; b) = ka bk 2 : Examples of parametric models are linear models <ref> [19] </ref>, logit models [13] and neural networks [81]. Both random local search and conjugate gradient methods can be used to minimize J (w), since gradient information is typically available for this function. An alternative method of minimizing J (w) is stochastic approximation.
Reference: [20] <author> I. Fiodorova. </author> <title> Search for the global optimum of multiextremal problems. </title> <booktitle> In Optimal Decision Theory 4, </booktitle> <pages> pages 93-100, </pages> <institution> Lithuanian SSR Acad. of Sci., 1978. Inst. of Math. and Cybern. </institution>
Reference-contexts: Trajectory methods modify the trajectory of the local search routine so it passes through all of 16 the local optima. For example, the method proposed by Fiodorova <ref> [20] </ref> is composed of three subalgorithms that are used to (1) descend toward a local minimum, (2) ascend from a minimum up to a saddle point, and (3) pass through a saddle point. Using these subalgorithms, new local minima are identified from searches originating from previously identified local minima.
Reference: [21] <author> Christodoulos A. Floudas and Panos M. Pardalos. </author> <title> A Collection of Test Problems for Constrained Global Optimization Algorithms, </title> <booktitle> volume 455 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Optimizing functions defined on R n also enables us to make comparisons with algorithms developed in the global optimization literature. Most problems in the testbeds used to evaluate GAs and global optimization algorithms are defined on R n <ref> [1, 21, 31, 91] </ref>. Thus, I evaluate GA-LS hybrids on problems for which we can 42 directly compare my results to other global optimization and evolutionary methods. The experiments in Chapter V and VI perform optimization on three global optimization test functions on R n .
Reference: [22] <author> David R. Fogel. </author> <title> An introduction to simulated evolutionary optimization. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(1) </volume> <pages> 3-14, </pages> <year> 1994. </year>
Reference-contexts: Research on evolutionary search algorithms incorporates elements of both biological evolution and global optimization. These algorithms are inspired by biological evolutionary mechanisms and are often used to perform global optimization. The exemplars of evolutionary search algorithms are genetic algorithms, evolutionary strategie and evolutionary programming <ref> [5, 22, 31] </ref>. The design and motivation for these algorithms are different, but they incorporate the same basic adaptive components [4, 41]. These methods use a collection of solutions (population of individuals) that are updated iteratively using selection mechanisms and genetic operators.
Reference: [23] <editor> Stephanie Forrest and Melanie Mitchell. </editor> <title> The performance of genetic algorithms on Walsh polynomials: Some anomalous results and their explanations. </title> <booktitle> In Proceedings of the 4th conference on Genetic Algorithms, </booktitle> <month> June </month> <year> 1991. </year> <month> 129 </month>
Reference-contexts: As was noted earlier, this element is missing from current computational analyses of the GA. Some experimental analyses have examined the performance of GAs on classes of functions that are motivated by an analysis of the role of the crossover operator. Forrest and Mitchell <ref> [23] </ref> and Mitchell, Holland and Forrest [58] have examined the performance of the GA on a subclass of Walsh polynomials. These analyses have yet to make definite predictions of the performance of GAs, but have provided much insight into the way the genetic operators perform search.
Reference: [24] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability A guide to the theory of NP-completeness. W.H. </title> <publisher> Freeman and Co., </publisher> <year> 1979. </year>
Reference-contexts: IV.A.1 Complexity Analysis Consider F, the class of all deterministic pseudo-boolean functions f such that f : B l ! Z, where B = f0; 1g. We can formalize the problem that the GA 1 The reader is referred to Gary and Johnson <ref> [24] </ref> for an excellent discussion of the complexity differences between P and N P , and to Gill [25] for an exposition of probabilistic computation. 38 attempts to solve as a combinatorial optimization problem DGA-MAX (following the format of Papadimitriou and Steiglitz [72]): Definition 1 DGA-MAX The Genetic Algorithm combinatorial maximization <p> space B l 2) an encoding of a TM M f , which defines a function f : B l ! Z In order to determine the complexity of DGA-MAX, we need to define a version of this problem as a formal language (using the format of Gary and John-son <ref> [24] </ref>). Definition 2 DGA-MAX INSTANCE: a string encoding integers l, and , and a TM M f that computes a function f : B l ! Z in polynomial time. <p> There are a number of performance guarantees defined in the literature. We consider the the absolute and asymptotic performance ratios to analyze the difficulty of DGA-MAX. We take the following definitions from Gary and Johnson <ref> [24] </ref>. Let the ratio R A (I) = Opt (I)=A (I).
Reference: [25] <author> John Gill. </author> <title> Computational complexity of probabilistic Turing machines. </title> <journal> SIAM Journal of Computation, </journal> <volume> 6(4) </volume> <pages> 675-695, </pages> <year> 1977. </year>
Reference-contexts: We can formalize the problem that the GA 1 The reader is referred to Gary and Johnson [24] for an excellent discussion of the complexity differences between P and N P , and to Gill <ref> [25] </ref> for an exposition of probabilistic computation. 38 attempts to solve as a combinatorial optimization problem DGA-MAX (following the format of Papadimitriou and Steiglitz [72]): Definition 1 DGA-MAX The Genetic Algorithm combinatorial maximization problem that (1) uses a deterministic fitness function f and (2) assigns the fitness of the maximally fit <p> Since the GA is nondeterministic, it could be the case that its nondeterminism allows it to efficiently solve either of the versions of DGA-MAX. For example, it is known that there are languages that can be solved more efficiently by probabilistic TMs than by deterministic TMs <ref> [25] </ref>. The following corollary demonstrates that even though GAs are stochastic, they still require super-polynomial time to solve DGA-MAX unless RP = N P . Corollary 3 If RP 6= N P , then DGA-MAX is not in RP.
Reference: [26] <author> Philip E. Gill, Walter Murray, and Margaret H. Wright. </author> <title> Practical optimization. </title> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: II.A Local Search Methods of local search have gained attention in both theoretical computer science and numerical optimization. An important distinction among local search methods concerns whether they minimize in the presence of constraints that restrict the domain of the search <ref> [26] </ref>. This dissertation examines methods for unconstrained 8 9 optimization. Theoretical computer science is primarily interested in local search methods over discrete spaces. <p> Three methods of local search will be used throughout this dissertation. The first is the non-derivative method proposed by Solis and Wets [84]. Next, conjugate gradient methods <ref> [26, 74] </ref> are used to minimize continuous functions using gradient information. Finally, stochastic approximation is used in pattern recognition methods 10 to find the optimal weights for parametric models of data [19]. <p> Hence, O (n) line searches are needed [74]. Because it uses gradient information, conjugate gradient has well-defined stopping criterion. The conjugate gradient method uses gradient information do terminate when the algorithm has reached a critical point of the objective function <ref> [26, 74] </ref>.
Reference: [27] <author> David Goldberg. </author> <title> The theory of virtual alphabets. </title> <editor> In Hans-Paul Schwefel and Reinhard Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 13-22. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: While binary encodings have been used to successfully solve optimization problems, special manipulation of this encoding is often necessary to increase the efficiency of the algorithm [83, 100]. There is evidence that optimization on R n can and should be performed with real parameters. Goldberg <ref> [27] </ref> provides formal arguments that floating point GAs manipulate virtual alphabets, a type of schema that is appropriate in R n .
Reference: [28] <editor> David E Goldberg and Kalyanmoy Deb. </editor> <title> A comparative analysis of selection schemes used in genetic algorithms. </title> <editor> In Gregory J.E. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 301-315. </pages> <address> Morgan-Kauffmann, </address> <year> 1991. </year>
Reference-contexts: However, I will follow this restriction, since it will allow me to make direct comparisons with the experiments using fixed frequency local search. The value p i can be calculated using any of a number of selection strategies that have been proposed for the GA <ref> [28] </ref>. For example, we can use an elitist method which always performs local search on the individual with the best fitness. To insure that P i p i = N , the frequency of the remaining individuals are reduced.
Reference: [29] <author> David E. Goldberg and J. Richardson. </author> <title> Genetic algorithms with sharing for multimodal function optimization. </title> <booktitle> In Genetic algorithms and their applications: Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 41-49, </pages> <year> 1987. </year>
Reference-contexts: Thus F i measures the average number of individuals that are identical to the i-th individual. Second, note that the complete method is closely related to the the method of fitness sharing proposed by Goldberg and Richardson <ref> [29] </ref>. Fitness sharing is a method of inducing niche behavior in GAs that enables the GA to converge to a population that is distributed over several local optima.
Reference: [30] <author> D.E. Goldberg. </author> <title> Genetic algorithms and Walsh functions: Part I, a gentle introduction. </title> <journal> Complex Systems, </journal> <volume> 3 </volume> <pages> 129-152, </pages> <year> 1989. </year>
Reference-contexts: In particular, much research has been done examining how crossover composes and disrupts patterns in binary strings, based on their contribution to the total fitness of the individual <ref> [30, 85, 86, 97] </ref>. This research has motivated the use of modified crossover operators that restrict the distribution of crossover points. <p> Related analysis with 36 37 Walsh functions has also proven very rewarding. Walsh functions can be used to analyze the effectiveness of genetic operators, as well as analyze the difficulty of the function being optimized <ref> [31, 30] </ref>. While these analyses provide some understanding of how GAs perform their search, they have not been able to identify the class of functions that GAs efficiently optimize. Any discussion of the computational complexity of the GA must be relative to a specific class of functions.
Reference: [31] <author> D.E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley Publishing Co., Inc., </publisher> <year> 1989. </year>
Reference-contexts: Research on evolutionary search algorithms incorporates elements of both biological evolution and global optimization. These algorithms are inspired by biological evolutionary mechanisms and are often used to perform global optimization. The exemplars of evolutionary search algorithms are genetic algorithms, evolutionary strategie and evolutionary programming <ref> [5, 22, 31] </ref>. The design and motivation for these algorithms are different, but they incorporate the same basic adaptive components [4, 41]. These methods use a collection of solutions (population of individuals) that are updated iteratively using selection mechanisms and genetic operators. <p> Evolutionary strategie also uses recombination, so it may be interesting to use local search with this algorithm. II.C.1 Genetic Algorithms The GA was initially described using populations of binary strings in f0; 1g n , which are evaluated by the objective function (fitness function) <ref> [42, 31, 57] </ref>. When searching spaces other than f0; 1g n , the objective function decodes the binary string and performs the function evaluation. <p> Related analysis with 36 37 Walsh functions has also proven very rewarding. Walsh functions can be used to analyze the effectiveness of genetic operators, as well as analyze the difficulty of the function being optimized <ref> [31, 30] </ref>. While these analyses provide some understanding of how GAs perform their search, they have not been able to identify the class of functions that GAs efficiently optimize. Any discussion of the computational complexity of the GA must be relative to a specific class of functions. <p> Optimizing functions defined on R n also enables us to make comparisons with algorithms developed in the global optimization literature. Most problems in the testbeds used to evaluate GAs and global optimization algorithms are defined on R n <ref> [1, 21, 31, 91] </ref>. Thus, I evaluate GA-LS hybrids on problems for which we can 42 directly compare my results to other global optimization and evolutionary methods. The experiments in Chapter V and VI perform optimization on three global optimization test functions on R n .
Reference: [32] <author> S. Gomez and A. V. Levy. </author> <title> The tunneling method for solving the constrained global optimization problem with several non-connected feasible regions, </title> <booktitle> pages 34-47. Lecture Notes in Mathematics. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1982. </year>
Reference-contexts: Using these subalgorithms, new local minima are identified from searches originating from previously identified local minima. Penalty methods modify the objective function with penalty terms that make the local search procedure avoid the local minima that it has previously searched. The tunneling method described by Gomez and Levy <ref> [32] </ref> uses two phases: local minimization and tunneling. The local minimization phase finds a local minimum x 0 . The tunneling phase minimizes a modified objective function to find a point x 00 such that f (x 00 ) &lt; f (x 0 ).
Reference: [33] <author> P. J. Goodford. </author> <title> A computational procedure for determining energetically favorable binding sites on biologically important molecules. </title> <journal> J. Med. Chem., </journal> <volume> 28 </volume> <pages> 849-857, </pages> <year> 1985. </year>
Reference-contexts: Evaluations of the docking conformations were performed using the Autodock software developed by Olson et al. [70]. The conformation energy was 111 evaluated using molecular affinity potentials, as described by Goodford <ref> [33] </ref>. The macromolecule is imbeded in a three-dimensional grid, and the energy of interaction is calculated for different atom types at every location of the grid. These energies are stored in tables that are used to rapidly compute the energy of a given conformation.
Reference: [34] <author> David S. Goodsell and Arthur J. Olson. </author> <title> Automated docking of substrates to protiens by simulated annealing. Protiens: Structure, Function and Genetics, </title> <booktitle> 8 </booktitle> <pages> 195-202, </pages> <year> 1990. </year>
Reference-contexts: This problem has been explored by a number of different authors [49, 55] and there are experiments with GA-LS hybrids for which a comparison is possible. The second molecular structural problem is the problem of docking drug candidates to a target macromolecule <ref> [34] </ref>, which is an important problem in automated drug design. The drug docking results with GA-LS hybrids are compared with simulated annealing, the optimization method used by Goodwell and Olsen [34]. VII.A Neural Networks Neural networks are simple parametric models that are thought to loosely model biological nervous systems [80]. <p> The second molecular structural problem is the problem of docking drug candidates to a target macromolecule <ref> [34] </ref>, which is an important problem in automated drug design. The drug docking results with GA-LS hybrids are compared with simulated annealing, the optimization method used by Goodwell and Olsen [34]. VII.A Neural Networks Neural networks are simple parametric models that are thought to loosely model biological nervous systems [80]. <p> Manual methods of docking have been widely used [88]. They use sophisticated energy evaluations, but only allow the user to examine a limit number of docking conformations. The docking method described by Goodsell and Olsen <ref> [34] </ref> examines a large number of docking conformations automatically. This method uses simulated annealing (SA) to search the conformation space (see Section II.B.3) and performs rapid energy evaluations using molecular affinity potentials.
Reference: [35] <author> V. Scott Gordon and Darrell Whitley. </author> <title> Serial and parallel genetic algorithms as function optimizers. </title> <editor> In Stephanie Forrest, editor, </editor> <booktitle> Proceedings of the Fifth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 177-183. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: I propose and analyze a MIMD design for geographically structured genetic algorithms (GSGAs). The SIMD GAs examined by McInerney and others are called GSGAs because they spatially structure the adaptive search performed by the GA. Gordon and Whitley <ref> [35] </ref> have recently argued that the algorithmic nature of GSGAs may be of interest independent of their implementation on a particular architecture and observe that their performance is competitive with other parallel GAs. 1 An analytic and experimental analysis of MIMD GSGAs demonstrates that they scale well for large problems. <p> When local selection is performed, it is performed in the population grid. Two general methods of local selection have been used to perform selection in GSGAs: (1) fixed size neighborhoods have been used to define the set of neighboring individuals <ref> [14, 35] </ref>, and (2) random walks have been used to stochastically sample the locations of neighboring individuals [12, 56]. Figure II.4 illustrates the fixed size neighborhoods that could be used to perform selection. Proportional selection is applied to the solutions in each of these neighborhoods. <p> He observes that selection using random walks gave very good results in his experiments. He notes that this method enabled good solutions to diffuse through the population, while strongly encouraging the formation of demes. Gordon and Whitley <ref> [35] </ref> have recently argued that the algorithmic nature of GSGAs may be of interest, independent from their implementation on a particular architecture. They experimentally compare GSGAs to panmictic GAs and observe that the GSGAs provide superior performance. <p> GSGAs are implemented by assigning one individual per processor. Selection and recombination is limited to a small number of individuals on neighboring processors, typically forming a two dimensional grid of individuals (see Spiessens and Manderick [87], Collins and Jefferson [12] and McInerney [56]). Gordon and Whitley <ref> [35] </ref> have recently argued that the algorithmic nature of these parallel algorithms may be of interest, independent from their implementation on a particular architecture. They experimentally compare the performance of several classic, island-model and geographically structured GAs that are executed on a sequential architecture. <p> When N x is one, the population consists of a simple array, and communication is minimal since neighboring processors only need to communicate the neighborhood of a single individual. However, results reported by Gordon and Whitely <ref> [35] </ref> and others indicate that GSGAs using this type of structured population are less likely to find optimal solutions than GSGAs that use populations structured on a 2D grid. 89 VI.D Complexity Analysis II The complexity analysis in the previous section assumes that the application of genetic operators introduces variability that <p> I expect that these MIMD GSGAs will be competitive with other MIMD GAs, such as the IMGA. Gordon and Whitley <ref> [35] </ref> show sequential simulations of parallel GAs in which the performance of GSGAs was competitive with other parallel GAs. They note that their simulations used a simple GSGA, and they expect GSGAs to perform very well when more sophisticated methods are employed.
Reference: [36] <author> William E. Hart and Richard K. Belew. </author> <title> Optimizing an arbitrary function is hard for the genetic algorithm. </title> <booktitle> In Proceedings of the 4th conference on Genetic Algorithms, </booktitle> <pages> pages 190-195, </pages> <month> June </month> <year> 1991. </year> <month> 130 </month>
Reference-contexts: The assumptions that can be made about the class of functions are often critical to establishing interesting complexity bounds. To illustrate the importance of selecting an appropriate class of functions, I summarize the analysis in Hart and Belew <ref> [36] </ref> that considers the GA's computational complexity for a very broad class of functions. I assume that the reader is familiar with formal language theory and follow the notational conventions of Hopcroft and Ullman [43].
Reference: [37] <author> William E. Hart and Richard K. Belew. </author> <title> Optimization with genetic algorithm hybrids that use local search. In Plastic Individuals in Evolving Populations, </title> <note> 1994. (to appear). </note>
Reference-contexts: Figures V.3b, V.4b and V.5b compare the performance of MC, MS-SW and the three GA-SW hybrids with different frequencies of local search. 1 The results reported here are an extension of those reported in Hart and Belew <ref> [37] </ref>. 54 (b) Figure V.3: Log-performance on the Griewank function using (a) conjugate gradient and (b) Solis-Wets. 55 (b) Figure V.4: Log-performance on the modified Griewank function using (a) conjugate gradient and (b) Solis-Wets. 56 (b) Figure V.5: Performance on the Rastrigin function using (a) conjugate gradient and (b) Solis-Wets. 57
Reference: [38] <author> Daniel L. Hartl. </author> <title> A primer on population genetics. </title> <publisher> Sinauer Associates, </publisher> <year> 1981. </year>
Reference-contexts: These results suggest that the fitness of the entire population may be improved even when only a fraction of the population is applying learning methods. The distribution-based methods of adapting the local search frequency are reminiscent of the effects of inbreeding depression <ref> [38] </ref>, and may be useful for studying the effects of inbreeding on learning in natural systems. Inbreeding depression refers to the detrimental effects of inbreeding, which is indicated by a high F statistic for an individual. Now consider a GA-LS hybrid as a model of natural evolution and learning. <p> We generalize the definition of the F statistic to allow for other distance measures between two chromosomes. As a consequence, the generalized F statistic can be computed for chromosomes on any space for which a distance metric is available. A.A Formalism Hartl <ref> [38] </ref> defines the inbreeding coefficient of an individual (relative to the total population) to be F IT = H T where 122 123 * H T the expected heterozygosity of an individual in an equivalent random mating total population * H I the heterozygosity of an individual H I can be
Reference: [39] <author> John Hertz, Anders Krogh, and Richard G. Palmer. </author> <title> Introduction to the Theory of Neural Computation. </title> <booktitle> Lecture Notes Volume 1, Sante Fe Institute, Studies in the Sciences of Complexity. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: Thus, Equation II.1 becomes w t+1 = w t + w t 104 Batch BP can be viewed as a simple gradient descent procedure. Unlike BP, the gradient calculation in BP is a reliable estimate of the current descent direction. Hertz, Krogh and Palmer <ref> [39] </ref> note that the relative performance of BP and batch BP is problem dependent, though BP seems superior in many cases. Table VII.1 compares the performance of MC, MS, GA and GA-LS hybrids for the three local search methods. The GA-LS hybrids are compared for three fixed frequencies.
Reference: [40] <author> Geoffrey E. Hinton and Steven J. Nowlan. </author> <title> How learning can guide evolution. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 495-502, </pages> <year> 1987. </year>
Reference-contexts: Alternatively, local search can be applied to solutions in each iteration of the GA. This type of GA-LS hybrid is particularly interesting because the global and local search methods can influence each other's behavior. An important example of this phenomenon is the Baldwin effect <ref> [6, 40] </ref> in which learning in natural systems speeds up the rate of evolutionary change. Similar effects have been observed by a number of authors using GA-LS hybrids [7, 40, 50]. The research in this dissertation examines the second type of GA-LS hybrid. <p> An important example of this phenomenon is the Baldwin effect [6, 40] in which learning in natural systems speeds up the rate of evolutionary change. Similar effects have been observed by a number of authors using GA-LS hybrids <ref> [7, 40, 50] </ref>. The research in this dissertation examines the second type of GA-LS hybrid. I.C Genetic Algorithms with Local Search Previous experimental results confirm that GA-LS hybrids not only find better solutions than the GA, but also optimize more efficiently [7, 61]. <p> Conversely, this research on artificial methods of adaptive search may have implications for models of evolution and learning in natural systems. The superior performance of the GA-LS hybrids when compared with the 116 GA appears to provide confirmation of the "Baldwin Effect" <ref> [6, 40] </ref>. The experiments in Chapters V and VII indicate that learning can improve the efficiency of the GA. Consequently, GA-LS hybrids run for fewer generations than the GA. <p> This is the most common method used in computational contexts. Second, the cost of the local search can be ignored completely, and the number of generations of the GA is used to measure the cost of the search. This measure has been used by Hinton and Nowlan <ref> [40] </ref> and Nolfi, Elman and Parisi [68]. Finally, the cost of each generation can be equated with the length of the longest local search performed in the population.
Reference: [41] <author> Frank Hoffmeister and Thomas Back. </author> <title> Genetic algorithms and evolutionary strategies: Similarities and differences. </title> <editor> In Hans-Paul Schwefel and Rein-hard Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 455-469. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: The exemplars of evolutionary search algorithms are genetic algorithms, evolutionary strategie and evolutionary programming [5, 22, 31]. The design and motivation for these algorithms are different, but they incorporate the same basic adaptive components <ref> [4, 41] </ref>. These methods use a collection of solutions (population of individuals) that are updated iteratively using selection mechanisms and genetic operators. The general process of each iteration (generation) is described in figure II.3. The selection mechanism performs a competition to select a subset of the solutions for further processing.
Reference: [42] <author> John H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The University of Michigan Press, </publisher> <year> 1976. </year>
Reference-contexts: Evolutionary strategie also uses recombination, so it may be interesting to use local search with this algorithm. II.C.1 Genetic Algorithms The GA was initially described using populations of binary strings in f0; 1g n , which are evaluated by the objective function (fitness function) <ref> [42, 31, 57] </ref>. When searching spaces other than f0; 1g n , the objective function decodes the binary string and performs the function evaluation. <p> When searching spaces other than f0; 1g n , the objective function decodes the binary string and performs the function evaluation. Holland <ref> [42] </ref> proposed a selection mechanism that stochastically selects individuals with probability p i = P This selection mechanism is called proportional selection, since the number of copies of an individual will be in proportion to the its fraction of the population's total fitness. <p> Finally, I motivate the use of GAs with a floating point representation and describe the genetic operators used with the floating point GA. IV.A Worst-Case Analysis There have been many attempts to analyze the computational behavior of the GA, with Holland's schema theorem <ref> [42] </ref> central to much of this analysis. Using it, we can justify how and why certain bit patterns (schemata) will be propagated from one generation to the next. This can be used to analyze the effectiveness of different genetic operators (see for example Syswerda [89]).
Reference: [43] <author> John E. Hopcroft and Jeffrey D. Ullman. </author> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison-Wesley Pub. Co., </publisher> <year> 1979. </year>
Reference-contexts: I assume that the reader is familiar with formal language theory and follow the notational conventions of Hopcroft and Ullman <ref> [43] </ref>. Recall that P refers to the class of formal languages that can be recognized by a deterministic Turing machine (TM) in polynomial time. Additionally, both N P and RP refer to the classes of formal languages that can be recognized by nondeterministic TMs in polynomial time.
Reference: [44] <author> Lester Ingber. </author> <title> Very fast simulated re-annealing. </title> <journal> Mathematical and Computer Modelling, </journal> <volume> 12(8) </volume> <pages> 967-973, </pages> <year> 1989. </year>
Reference-contexts: As the temperature decreases, the search becomes increasingly localized. At very low temperatures, the search is often localized to a single basin of attraction for which there is a low probability of escaping in the near term. For this reason, simulated re-annealing has been proposed <ref> [44, 45] </ref>. This variant treats simulated annealing more like a local search technique, using multiple starts to perform the global search. II.C Evolutionary Search Evolutionary search algorithms, called competitive search by Torn and Zilinskas [91], represent an important class of adaptive search algorithms.
Reference: [45] <author> Lester Ingber and Bruce Rosen. </author> <title> Genetic algorithms and very fast simulated reannealing a comparison. </title> <journal> Mathematical and Computer Modelling, </journal> <volume> 16(11) </volume> <pages> 87-100, </pages> <year> 1992. </year>
Reference-contexts: As the temperature decreases, the search becomes increasingly localized. At very low temperatures, the search is often localized to a single basin of attraction for which there is a low probability of escaping in the near term. For this reason, simulated re-annealing has been proposed <ref> [44, 45] </ref>. This variant treats simulated annealing more like a local search technique, using multiple starts to perform the global search. II.C Evolutionary Search Evolutionary search algorithms, called competitive search by Torn and Zilinskas [91], represent an important class of adaptive search algorithms.
Reference: [46] <author> Cezary Z. Janikow and Zbigniew Michalewicz. </author> <title> An experimental comparison of binary and floating point representations in genetic algorithms. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 31-36. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: There is evidence that optimization on R n can and should be performed with real parameters. Goldberg [27] provides formal arguments that floating point GAs manipulate virtual alphabets, a type of schema that is appropriate in R n . Wright [103] and Janikow and Michalewicz <ref> [46] </ref> suggests that floating point GAs can be more efficient, provide increase precision, and allow for genetic operators that are more appropriate for a continuous domain. In the experiments, the panmictic GAs use proportional selection, while the GSGAs use local proportional selection with minimal NEWS neighborhoods.
Reference: [47] <author> David S. Johnson. </author> <title> Local optimization and the traveling salesman problem. In M.S. </title> <editor> Paterson, editor, </editor> <booktitle> Automata, Languages and Programming 17th International Colloquium, </booktitle> <pages> pages 446-461, </pages> <address> New York, </address> <month> July </month> <year> 1990. </year> <journal> Springer-Verlag. </journal> <volume> Volume #443. </volume>
Reference-contexts: Johnson, Papadimitriou and Yannakakis [48] observe that "One of the few general approaches to difficult combinatorial optimization problems that has met with empirical success is local (or neighborhood) search." For example, local search methods have proven very successful for the celebrated Traveling Salesman problem <ref> [47] </ref>. A number of authors have performed general analyses of local search methods over discrete spaces. Tovey [92, 93] models the expected performance of local search algorithms that optimize real valued functions defined on f0; 1g n .
Reference: [48] <author> David S. Johnson, Christos H. Papadimitriou, and Mihalis Yannakakis. </author> <title> How easy is local search? Journal of computer and system sciences, </title> <booktitle> 37(1) </booktitle> <pages> 79-100, </pages> <month> Aug </month> <year> 1988. </year>
Reference-contexts: This dissertation examines methods for unconstrained 8 9 optimization. Theoretical computer science is primarily interested in local search methods over discrete spaces. Johnson, Papadimitriou and Yannakakis <ref> [48] </ref> observe that "One of the few general approaches to difficult combinatorial optimization problems that has met with empirical success is local (or neighborhood) search." For example, local search methods have proven very successful for the celebrated Traveling Salesman problem [47]. <p> A number of authors have performed general analyses of local search methods over discrete spaces. Tovey [92, 93] models the expected performance of local search algorithms that optimize real valued functions defined on f0; 1g n . Johnson, Papadimitriou and Yannakakis <ref> [48] </ref> introduce the complexity class PLS (Polynomial Local Search). Members of PLS are problems for which a local minimum can be found using a polynomial-time local algorithm that finds a solution with better cost, or identifies the current solution as a local optimum.
Reference: [49] <author> R.S. Judson, M.E. Colvin, J.C. Meza, A. Huffer, and D. Gutierrez. </author> <title> Do intelligent configuration search techniques outperform random search for large molecules? International Journal of Quantum Chemistry, </title> <address> pages 277-290, </address> <year> 1992. </year> <month> 131 </month>
Reference-contexts: These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems <ref> [49] </ref>. Muhlenbein [60, 61, 62], Ackley [1], and McInerney [56] have developed application-independent versions of the GA for optimization with local search. In most of these applications, the performance of the GA is substantially improved when the local search technique is employed. <p> Some authors did stop their local search after a fixed time limit or after a fixed number of iterations of their local search algorithm. Finally, most authors used Lamarckian local search techniques. Belew et al. [7] and Judson et al. <ref> [49] </ref> make a clear distinction between mutation and local search in their experiments, and were able to compare the performance of Lamar-ckian and non-Lamarckian local search. They found that Lamarckian local search outperforms non-Lamarckian local search. <p> The neural network problem is the six-bit symmetry problem, which has been previously optimized with GA-LS hybrids by Belew, McInerney and Schrau-dolph [7]. The first molecular structural problem is the problem of solving for a molecule's conformation. This problem has been explored by a number of different authors <ref> [49, 55] </ref> and there are experiments with GA-LS hybrids for which a comparison is possible. The second molecular structural problem is the problem of docking drug candidates to a target macromolecule [34], which is an important problem in automated drug design. <p> I consider a simple two dimensional conformation problem that is examined in Judson et al. <ref> [49] </ref>. This conformation problem concerns a molecule composed of a chain of identical atoms that are connected with rigid rods of length one. <p> The global minima of this function are approximately located on a hexagonal grid with unit spacing. Figure VII.2b is an example of a global minimum. When minimizing a 19-atom molecule, the global minima are known to have a value of -45.3 <ref> [49] </ref>. VII.B.2 Parametrization The distance terms r ij can be parameterized in two ways: (1) using the coordinates of the atoms, and (2) using the bond angles and bond lengths. Figure VII.3 illustrates the relation of these parameters to the structure of a simple molecule. <p> Finally, 110 the GA-LS hybrids are significantly better than MC, MS and GA. These results are not directly comparable to those of Judson et al. <ref> [49] </ref> since they report the final results after 10 7 function evaluations. However, they report that the best solution found with their GA-CG hybrids is -44.3. After 150,000 function evaluations, the best solution found by these methods was -44.2. <p> The F statistic is zero if the distance between the chromosomes is equal to H T Appendix B Analytic Gradients for the 2D Conformation Problem This appendix describes the equations used to analytically calculate the derivative for the simple conformation problem consider by Judson et al. <ref> [49] </ref>. f (ff) = i&lt;j 4 * r fl ! 12 r ij 3 where r ij is the interatom distance r ij = (x i x j ) 2 + (y i y j ) 2 : The angles ff are used to calculate the coordinates x and y.
Reference: [50] <author> Ron Keesing and David G. Stork. </author> <title> Evolution and learning in neural networks: The number and distribution of learning trials affect the rate of evolution. </title> <editor> In Richard P. Lippmann, John E. Moody, and David S. Touretzky, editors, </editor> <booktitle> NIPS 3, </booktitle> <pages> pages 804-810. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: An important example of this phenomenon is the Baldwin effect [6, 40] in which learning in natural systems speeds up the rate of evolutionary change. Similar effects have been observed by a number of authors using GA-LS hybrids <ref> [7, 40, 50] </ref>. The research in this dissertation examines the second type of GA-LS hybrid. I.C Genetic Algorithms with Local Search Previous experimental results confirm that GA-LS hybrids not only find better solutions than the GA, but also optimize more efficiently [7, 61]. <p> Non-Lamarckian local search is typically used to determine the fitness associated with g. II.D Related Work GAs have been combined with local search methods for a number of different applications. The problem of finding the optimal parameters for a neural network <ref> [7, 50, 68] </ref> comes closest to the models of learning and evolution. GA-LS hybrids have been applied to combinatorial graph problems like the traveling salesman problem [9, 63, 95] and the graph partitioning problem [96].
Reference: [51] <author> S. Kirkpatrick, C.D. Gelatt, Jr., </author> <title> and M.P. Vecchi. Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220 </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference-contexts: Simulated annealing (SA) is a method of optimization inspired by an analogy between a physical annealing process for obtaining low energy states and the process of solving for minimal solutions to discrete optimization problems <ref> [11, 51] </ref>. SA sequentially generates random deviates of the current solution that are accepted if a probabilistic test is passed. Suppose x 0 is the current solution and let x 00 be the new deviate. If f (x 00 )f (x 0 ) &lt; 0, the new deviate is accepted.
Reference: [52] <author> Scott R. Kohn and Scott B. Baden. </author> <title> A robust parallel programming model for dynamic non-uniform scientific computations. </title> <booktitle> In Proceedings of the 1994 Scalable High Performance Computing Conference, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: VI.E Methods To validate the theoretical analysis of the GSGA, I implemented an GSGA and evaluated its performance on the Intel Paragon at the San Diego Supercomputer Center. The GSGA was implemented using the MP++ and LPARX routines described in Kohn and Baden <ref> [52] </ref>. The LPARX routines were used to implement the inter-process communication in the globally synchronous GSGA, and were modified to perform inter-process communication in the locally synchronous and asynchronous GSGAs. The parallel GSGAs were evaluated using the Rastrigin function. GSGAs with floating point encoding were used in the experiments.
Reference: [53] <author> Clyde P. Kruskal and Alan Weiss. </author> <title> Allocating independent subtasks on parallel processors. </title> <booktitle> In ICCP 1984, </booktitle> <pages> pages 236-240, </pages> <year> 1984. </year> <note> Extended Abstract. </note>
Reference-contexts: large, we can approximate Y by a 91 normal random variable, Y 0 , with mean and standard deviation , where = P (T f + T gen + T ls ) = T ls (1 )P : Applying the approximation to Y 0 n:n used in Kruskal and Weiss <ref> [53] </ref>, we have E (T 1 kT flop P (T f + T gen + T ls ) + kT flop T ls q comm (VI:5) To analyze A 3 , we compare the maximum length of each process independently.
Reference: [54] <author> Scott M. Le Grand and Kenneth M. Merz, Jr. </author> <title> The application of the genetic algorithm to the minimization of potential energy functions. </title> <journal> Journal of Global Optimization, </journal> <volume> 3 </volume> <pages> 49-66, </pages> <year> 1993. </year>
Reference-contexts: For example, we could define V as V = V bond + V angle + V torsion + V nonbond + V electrostatic A detailed description of these terms is given in Le Grand and Merz <ref> [54] </ref>. Clark, Cramer and Van Opdenbosch [10] describe many of the "standard" force fields. In-tramolecular forces are modeled by the terms for bond stretching, bond torsion and angle valence. <p> The bond torsion (dihedral) term measures the energy related to the stresses put on double bonds. This energy is often quite specific to the type of bond that is modeled. Le Grand and Merz <ref> [54] </ref> distinguish the angle valence energy from other 106 torsion energies V angle = 1 K ijk ( ijk 0 ) 2 where ijk is the angle between the bond linking the i-th and j-th atoms and the bond linking the j-th and k-th atoms.
Reference: [55] <author> R.S. Maier, J.B. Rosen, and G.L. Xue. </author> <title> A discrete-continuous algorithm for molecular energy minimization. </title> <type> Unpublished manuscript, </type> <month> Mar </month> <year> 1992. </year>
Reference-contexts: The neural network problem is the six-bit symmetry problem, which has been previously optimized with GA-LS hybrids by Belew, McInerney and Schrau-dolph [7]. The first molecular structural problem is the problem of solving for a molecule's conformation. This problem has been explored by a number of different authors <ref> [49, 55] </ref> and there are experiments with GA-LS hybrids for which a comparison is possible. The second molecular structural problem is the problem of docking drug candidates to a target macromolecule [34], which is an important problem in automated drug design.
Reference: [56] <author> John M.N. McInerny. </author> <title> Biologically Influenced Algorithms and Parallelism in Non-Linear Optimization. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> San Diego, </address> <year> 1992. </year>
Reference-contexts: My thesis is that selectively applying local search can improve the efficiency of each iteration of the GA while preserving the benefits of the hybridization. I.D Parallel Genetic Algorithms with Local Search Research on GA-LS hybrids has been performed on both sequential and parallel architectures (see McInerney <ref> [56] </ref> for a review of parallel GAs). Parallel GAs have been motivated by the need to process large populations when solving high dimensional problems. They are also important when solving problems for which the objective function is expensive to evaluate. <p> They are also important when solving problems for which the objective function is expensive to evaluate. Most of the research on parallel GA-LS hybrids has been performed with coarse-grained MIMD architectures. These computers offer parallelism among a lim 6 ited number of processors that run asynchronously. McInerney <ref> [56] </ref> has also analyzed GA-LS hybrids on a fine-grained SIMD architecture, the CM-200. This computer offers parallelism among a very large number of processors that execute each instruction synchronously. Asynchronism is particularly important because GA-LS hybrids are naturally asynchronous. <p> The most common way of structuring the selection mechanism uses a toroidal two dimensional grid like the one in Figure II.4 <ref> [2, 12, 56, 87] </ref>. Every element of the population is 22 Figure II.4: The two dimensional grid used by GSGAs to define population subsets. assigned to a location on the grid. The grid locations are not necessarily related to the individuals' solutions. <p> Two general methods of local selection have been used to perform selection in GSGAs: (1) fixed size neighborhoods have been used to define the set of neighboring individuals [14, 35], and (2) random walks have been used to stochastically sample the locations of neighboring individuals <ref> [12, 56] </ref>. Figure II.4 illustrates the fixed size neighborhoods that could be used to perform selection. Proportional selection is applied to the solutions in each of these neighborhoods. <p> For example, two individuals will be selected if crossover is used. The new individual generated from a genetic operator is assigned to the grid location at which selection is performed. The early motivation for GSGAs came from SIMD designs for GAs (see Chapter VI). McInerney <ref> [56] </ref> describes a SIMD GSGA and analyzes the effect of different methods of local selection. <p> These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems [49]. Muhlenbein [60, 61, 62], Ackley [1], and McInerney <ref> [56] </ref> have developed application-independent versions of the GA for optimization with local search. In most of these applications, the performance of the GA is substantially improved when the local search technique is employed. There are a number of common elements to the use of local search in these applications. <p> GSGAs are implemented by assigning one individual per processor. Selection and recombination is limited to a small number of individuals on neighboring processors, typically forming a two dimensional grid of individuals (see Spiessens and Manderick [87], Collins and Jefferson [12] and McInerney <ref> [56] </ref>). Gordon and Whitley [35] have recently argued that the algorithmic nature of these parallel algorithms may be of interest, independent from their implementation on a particular architecture. They experimentally compare the performance of several classic, island-model and geographically structured GAs that are executed on a sequential architecture.
Reference: [57] <author> Zbigniew Michalewicz. </author> <title> Genetic algorithms + data structures = evolution programs. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Evolutionary strategie also uses recombination, so it may be interesting to use local search with this algorithm. II.C.1 Genetic Algorithms The GA was initially described using populations of binary strings in f0; 1g n , which are evaluated by the objective function (fitness function) <ref> [42, 31, 57] </ref>. When searching spaces other than f0; 1g n , the objective function decodes the binary string and performs the function evaluation.
Reference: [58] <author> Melanie Mitchell, Stephani Forrest, and John H. Holland. </author> <title> The royal road for genetic algorithms: Fitness landscapes and GA performance. In Toward a practice of autonomous systems. </title> <booktitle> Proceedings of the First European Conference on Artificial Life, </booktitle> <pages> pages 245-54. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Some experimental analyses have examined the performance of GAs on classes of functions that are motivated by an analysis of the role of the crossover operator. Forrest and Mitchell [23] and Mitchell, Holland and Forrest <ref> [58] </ref> have examined the performance of the GA on a subclass of Walsh polynomials. These analyses have yet to make definite predictions of the performance of GAs, but have provided much insight into the way the genetic operators perform search.
Reference: [59] <author> David J. Montana and Lawrence Davis. </author> <title> Training feedforward neural networks using genetic algorithms. </title> <booktitle> In IJCAI 1989, </booktitle> <pages> pages 762-767, </pages> <year> 1989. </year>
Reference-contexts: The results for the adaptive methods indicate that the methods using the L 2 metric have this property. Finally, we note that our analysis of GA-LS hybrids may explain the performance that other researchers have observed in their GA-LS hybrids. Davis <ref> [59] </ref> and Muhlenbein [61] have observed that local search is not needed in the initial stages of the optimization. Our analysis suggests that local search is probably useful for their problems, but is best used with a low frequency.
Reference: [60] <author> H. Muhlenbein, M. Gorges-Schleuter, and O. Kramer. </author> <title> Evolution algorithms in combinatorial optimization. </title> <journal> Parallel Computing, </journal> <volume> 7 </volume> <pages> 65-85, </pages> <year> 1988. </year>
Reference-contexts: These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems [49]. Muhlenbein <ref> [60, 61, 62] </ref>, Ackley [1], and McInerney [56] have developed application-independent versions of the GA for optimization with local search. In most of these applications, the performance of the GA is substantially improved when the local search technique is employed.
Reference: [61] <author> H. Muhlenbein, M. Schomisch, and J. Born. </author> <title> The parallel genetic algorithm as function optimizer. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 271-278. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The research in this dissertation examines the second type of GA-LS hybrid. I.C Genetic Algorithms with Local Search Previous experimental results confirm that GA-LS hybrids not only find better solutions than the GA, but also optimize more efficiently <ref> [7, 61] </ref>. It is noteworthy that these results examine a limited number of algorithmic combinations of the GA with local search. I believe that important algorithmic combinations have been overlooked and that the standard GA-LS hybrids of the GA and local search should be reconsidered. <p> These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems [49]. Muhlenbein <ref> [60, 61, 62] </ref>, Ackley [1], and McInerney [56] have developed application-independent versions of the GA for optimization with local search. In most of these applications, the performance of the GA is substantially improved when the local search technique is employed. <p> Figure IV.2 shows a one-dimensional slice of this function. IV.B.3 Rastrigin The Rastrigin function f (x) = x 2 2 cos (18x 1 ) cos (18x 2 ) was proposed in Rastrigin [75]. Muhlenbein, Schomisch and Born <ref> [61] </ref> describe a modified version of this function f (x) = 10n + i=1 x 2 which generalizes Rastrigin's function to an arbitrary number of dimensions. Following Muhlenbein, Schomisch and Born, I optimize this function in 20 dimensions, over the domain [5:12; 5:12] 20 . <p> The results for the adaptive methods indicate that the methods using the L 2 metric have this property. Finally, we note that our analysis of GA-LS hybrids may explain the performance that other researchers have observed in their GA-LS hybrids. Davis [59] and Muhlenbein <ref> [61] </ref> have observed that local search is not needed in the initial stages of the optimization. Our analysis suggests that local search is probably useful for their problems, but is best used with a low frequency.
Reference: [62] <author> H. Muhlenbein, M. Schomisch, and J. Born. </author> <title> The parallel genetic algorithm as function optimizer. </title> <journal> Parallel Computing, </journal> <volume> 17 </volume> <pages> 619-632, </pages> <year> 1991. </year> <month> 132 </month>
Reference-contexts: These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems [49]. Muhlenbein <ref> [60, 61, 62] </ref>, Ackley [1], and McInerney [56] have developed application-independent versions of the GA for optimization with local search. In most of these applications, the performance of the GA is substantially improved when the local search technique is employed. <p> There are a number of common elements to the use of local search in these applications. First, most authors apply the local search to each individual in every generation. A notable exception is work by Muhlenbein et al. <ref> [62] </ref> who only perform local search if the GA is either not increasing fast enough or if the GA is converging to a solution. Second, most authors apply the local search operator until a local minima 27 was found.
Reference: [63] <author> Heinz Muhlenbein. </author> <title> Evolution in time and space the parallel genetic algorithm. </title> <editor> In Gregory J.E. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 316-337. </pages> <address> Morgan-Kauffmann, </address> <year> 1991. </year>
Reference-contexts: The ECO framework provides a serial design for implementing a geographically structured GA. Finally, we note that our definition of GSGAs includes GAs which structure the selection at a fine granularity. A number of GAs have been proposed whose competitive selection is intermediate between GSGAs and panmictic GAs. Muhlenbein <ref> [63] </ref> makes a similar distinction and describes a GA which uses a set of independent subpopulations and structures the inter-population communication with a ladder structure. These subpopulations are typically small, so they perform a localized search of the function. <p> The problem of finding the optimal parameters for a neural network [7, 50, 68] comes closest to the models of learning and evolution. GA-LS hybrids have been applied to combinatorial graph problems like the traveling salesman problem <ref> [9, 63, 95] </ref> and the graph partitioning problem [96]. These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems [49]. <p> The classic GA uses a single population of individuals that are panmictically recombined. IMGAs are typically implemented by independently running a classic GA on each processor, with individuals migrated between the subpopulations (see Muhlenbein <ref> [63] </ref>). GSGAs are implemented by assigning one individual per processor. Selection and recombination is limited to a small number of individuals on neighboring processors, typically forming a two dimensional grid of individuals (see Spiessens and Manderick [87], Collins and Jefferson [12] and McInerney [56]).
Reference: [64] <author> Peter Neuhaus. </author> <title> Solving the mapping-problem experiences with a genetic algorithm. </title> <editor> In Hans-Paul Schwefel and Reinhard Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 170-175. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem <ref> [64] </ref> and molecular conformation problems [49]. Muhlenbein [60, 61, 62], Ackley [1], and McInerney [56] have developed application-independent versions of the GA for optimization with local search. In most of these applications, the performance of the GA is substantially improved when the local search technique is employed.
Reference: [65] <author> Harald Niederreiter. </author> <title> A quasi-Monte Carlo method for the approximate computation of the extreme values of a function. </title> <editor> In Paul Erdos, editor, </editor> <booktitle> Studies in Pure Mathematics, </booktitle> <pages> pages 523-529. </pages> <publisher> Birkhauser Verlag, </publisher> <year> 1983. </year>
Reference-contexts: II.B.1 Methods with Guaranteed Accuracy The covering methods use a global search strategy that excludes regions of the search space based on estimates of how much the function can vary over small regions. For example, quasi-Monte Carlo methods <ref> [65, 66, 67] </ref> deterministically generate a sequence of points that are uniformly spread across the search space. The accuracy 15 of the estimated global optimum is computed using measures of the uniformity of the sequence of points.
Reference: [66] <author> Harald Niederreiter. </author> <title> Quasi-Monte Carlo methods for global optimization. </title> <editor> In W. Grossmann, G. Pflug, I. Vincze, and W. Wertz, editors, </editor> <booktitle> Proceedings of the 4th Pannonian Symposium on Mathematical Statistics, </booktitle> <pages> pages 251-267. </pages> <address> Bad Tatzmannsdorf, Austria, </address> <year> 1983. </year>
Reference-contexts: II.B.1 Methods with Guaranteed Accuracy The covering methods use a global search strategy that excludes regions of the search space based on estimates of how much the function can vary over small regions. For example, quasi-Monte Carlo methods <ref> [65, 66, 67] </ref> deterministically generate a sequence of points that are uniformly spread across the search space. The accuracy 15 of the estimated global optimum is computed using measures of the uniformity of the sequence of points.
Reference: [67] <author> Harald Niederreiter and Paul Peart. </author> <title> Localization of search in quasi-Monte Carlo methods for global optimization. </title> <journal> SIAM Journal of Scientific and Statistical Computing, </journal> <volume> 7(2) </volume> <pages> 660-664, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: II.B.1 Methods with Guaranteed Accuracy The covering methods use a global search strategy that excludes regions of the search space based on estimates of how much the function can vary over small regions. For example, quasi-Monte Carlo methods <ref> [65, 66, 67] </ref> deterministically generate a sequence of points that are uniformly spread across the search space. The accuracy 15 of the estimated global optimum is computed using measures of the uniformity of the sequence of points.
Reference: [68] <author> Stefano Nolfi, Jeffrey L. Elman, and Domenico Parisi. </author> <title> Learning and evolution in neural networks. </title> <type> Technical Report CRL 9019, </type> <institution> Center for Research in Language, University of California, </institution> <address> San Diego, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Non-Lamarckian local search is typically used to determine the fitness associated with g. II.D Related Work GAs have been combined with local search methods for a number of different applications. The problem of finding the optimal parameters for a neural network <ref> [7, 50, 68] </ref> comes closest to the models of learning and evolution. GA-LS hybrids have been applied to combinatorial graph problems like the traveling salesman problem [9, 63, 95] and the graph partitioning problem [96]. <p> Second, the cost of the local search can be ignored completely, and the number of generations of the GA is used to measure the cost of the search. This measure has been used by Hinton and Nowlan [40] and Nolfi, Elman and Parisi <ref> [68] </ref>. Finally, the cost of each generation can be equated with the length of the longest local search performed in the population.
Reference: [69] <author> M. A. Nowak and R. M. </author> <month> May. </month> <title> The spatial dilemas of evolution. </title> <journal> Intl. Journal of Bifurcation and Chaos in Applied Sciences and Engineering, </journal> <volume> 3(1) </volume> <pages> 35-78, </pages> <year> 1993. </year>
Reference-contexts: In this case, the optimal solutions are not biologically plausible. This phenomenon was observed in Ackley and Littman's artificial life model [3]. Nowak and May observe similar phenomena in the context of game theory <ref> [69] </ref>. The second difference concerns the manner in which the rate of evolution is measured in natural systems and in GA-LS hybrids. There are three ways the cost of GA-LS hybrids can be evaluated.
Reference: [70] <author> Arthur J. Olson, David S. Goodsell, Garrett M. Morris, and Ruth Huey. </author> <title> Autodock User Guide. </title> <institution> Scripps Research Institute, Department of Molecular Biology, </institution> <year> 1994. </year>
Reference-contexts: The experiments in this section compare the performance of the GA and GA-LS hybrids to SA on a docking problem that models the docking of an inhibitor for HIV protease. Evaluations of the docking conformations were performed using the Autodock software developed by Olson et al. <ref> [70] </ref>. The conformation energy was 111 evaluated using molecular affinity potentials, as described by Goodford [33]. The macromolecule is imbeded in a three-dimensional grid, and the energy of interaction is calculated for different atom types at every location of the grid.
Reference: [71] <author> Christos H. Papadimitriou, Alejandro A. Schaffer, and Mihalis Yannakakis. </author> <title> On the complexity of local search. </title> <booktitle> In Proceedings of the Twenty Second Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 438-45, </pages> <year> 1990. </year>
Reference-contexts: Members of PLS are problems for which a local minimum can be found using a polynomial-time local algorithm that finds a solution with better cost, or identifies the current solution as a local optimum. Papadimitriou, Schaffer and Yannankakis <ref> [71] </ref> use this class of problems to show how local search is the main underlying method used to solve seeming unrelated problems in computer science. The field of applied mathematics is primarily interested in local search methods used for minimizing continuous functions on compact spaces.
Reference: [72] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization Algorithms and Complexity. </title> <publisher> Prentice Hall, Inc., </publisher> <year> 1982. </year>
Reference-contexts: The reader is referred to Gary and Johnson [24] for an excellent discussion of the complexity differences between P and N P , and to Gill [25] for an exposition of probabilistic computation. 38 attempts to solve as a combinatorial optimization problem DGA-MAX (following the format of Papadimitriou and Steiglitz <ref> [72] </ref>): Definition 1 DGA-MAX The Genetic Algorithm combinatorial maximization problem that (1) uses a deterministic fitness function f and (2) assigns the fitness of the maximally fit individual in a population to the fitness of the population itself. <p> Given a TM that solves the optimization version, we can clearly solve the formal language version. However, it is unknown whether the opposite is true (see Papadimitriou and Steiglitz <ref> [72] </ref> for further details). Thus, the optimization version is at least as difficult as the formal language version of DGA-MAX. Hart and Belew prove the following. Proposition 1 DGA-MAX is NP-complete.
Reference: [73] <author> A.T. Phillips and J.B. Rosen. </author> <title> A computation comparison of two methods for constrained global optimization. </title> <type> Unpublished manuscript, </type> <year> 1992. </year>
Reference-contexts: It is unclear whether the relatively poor performance on these types of functions results from inadequate stopping criteria or from a bias in the clustering methods towards larger clusters. These techniques have been successfully applied to problems with as many as 40 dimensions <ref> [73] </ref>. Random Search In Torn and Zilinskas, the category of random search methods is a collection of techniques that use randomization and which do not fit nicely into any of the other categories.
Reference: [74] <author> William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vet-terling. </author> <title> Numerical Recipies in C The Art of Scientific Computing. </title> <publisher> Cambridge University Press, </publisher> <year> 1990. </year>
Reference-contexts: Three methods of local search will be used throughout this dissertation. The first is the non-derivative method proposed by Solis and Wets [84]. Next, conjugate gradient methods <ref> [26, 74] </ref> are used to minimize continuous functions using gradient information. Finally, stochastic approximation is used in pattern recognition methods 10 to find the optimal weights for parametric models of data [19]. <p> II.A.2 Conjugate Gradient Several classes of local search algorithms have been defined for algorithms that use gradient information. Among them, conjugate gradient methods provide an efficient use of the gradient information while only requiring O (n) storage <ref> [74] </ref>. Conjugate gradient methods are motivated by an analysis of the steepest descent method. The steepest descent method iteratively performs line searches in 11 Figure II.1: Performance of the steepest descent method on a narrow valley. the local downhill gradient direction 5 f (x). <p> For quadratic functions, using conju 12 gate search directions guarantees that subsequent line searches preserve the previous minimizations. Hence, O (n) line searches are needed <ref> [74] </ref>. Because it uses gradient information, conjugate gradient has well-defined stopping criterion. The conjugate gradient method uses gradient information do terminate when the algorithm has reached a critical point of the objective function [26, 74]. <p> Hence, O (n) line searches are needed [74]. Because it uses gradient information, conjugate gradient has well-defined stopping criterion. The conjugate gradient method uses gradient information do terminate when the algorithm has reached a critical point of the objective function <ref> [26, 74] </ref>.
Reference: [75] <author> L. A. Rastrigin. </author> <title> Systems of extremal control. </title> <publisher> Nauka, </publisher> <year> 1974. </year> <month> 133 </month>
Reference-contexts: I optimize this function over the domain [600:0; 600:0] 10 , and use = 0:1. Figure IV.2 shows a one-dimensional slice of this function. IV.B.3 Rastrigin The Rastrigin function f (x) = x 2 2 cos (18x 1 ) cos (18x 2 ) was proposed in Rastrigin <ref> [75] </ref>. Muhlenbein, Schomisch and Born [61] describe a modified version of this function f (x) = 10n + i=1 x 2 which generalizes Rastrigin's function to an arbitrary number of dimensions. Following Muhlenbein, Schomisch and Born, I optimize this function in 20 dimensions, over the domain [5:12; 5:12] 20 .
Reference: [76] <author> A.H.G. Rinnooy Kan, C.G.E. Boender, and G.Th. Timmer. </author> <title> A stochastic approach to global optimization. </title> <editor> In K. Schittkowski, editor, </editor> <booktitle> Computational Mathematical Programming. NATO ASI Series, </booktitle> <address> Bol. F15, </address> <year> 1985. </year>
Reference-contexts: While covering methods have provable convergence properties, they generally require the user to estimate properties like the Lipschitz constant. Unfortunately, these properties can be difficult to estimate, so the utility of these algorithms is unclear in many practical applications <ref> [76] </ref>. II.B.2 Indirect Methods Indirect methods use local information like function evaluations to build a model of either the function or its levels sets. This model is then used to guide the selection of new samples.
Reference: [77] <author> A.H.G. Rinnooy Kan and G.T. Timmer. </author> <title> Stochastic global optimization methods part I: Clustering methods. </title> <journal> Mathematical Programming, </journal> <volume> 39 </volume> <pages> 27-56, </pages> <year> 1987. </year>
Reference-contexts: Torn and Zilinskas [91] describe a number of clustering algorithms that have been used with these methods, including standard hierarchical methods. Clustering methods are amenable to analysis because they use uniformly distributed samples. Rinnooy Kan and Timmer <ref> [77, 78] </ref> describe a clustering method and describe conditions for which any local minima will be found within a finite number of iterations with probability one. 17 One drawback of cluster methods is that they tend to perform poorly on functions with many local minima.
Reference: [78] <author> A.H.G. Rinnooy Kan and G.T. Timmer. </author> <title> Stochastic global optimization methods part II: Multi level methods. </title> <journal> Mathematical Programming, </journal> <volume> 39 </volume> <pages> 57-78, </pages> <year> 1987. </year>
Reference-contexts: Torn and Zilinskas [91] describe a number of clustering algorithms that have been used with these methods, including standard hierarchical methods. Clustering methods are amenable to analysis because they use uniformly distributed samples. Rinnooy Kan and Timmer <ref> [77, 78] </ref> describe a clustering method and describe conditions for which any local minima will be found within a finite number of iterations with probability one. 17 One drawback of cluster methods is that they tend to perform poorly on functions with many local minima.
Reference: [79] <author> Gunter Rudolph. </author> <title> Convergence analysis of canonical genetic algorithms. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(1) </volume> <pages> 96-101, </pages> <year> 1994. </year>
Reference-contexts: Local search is another genetic operator that is sometimes employed with GAs to refine solutions in their local neighborhood. Using these genetic operators, evolutionary search algorithms perform a 20 global search. Global convergence is not guaranteed for all evolutionary algorithms <ref> [79] </ref>, but experiments with these algorithms indicate that they often converge to regions of the search space that contain near-optimal solutions. Global convergence is guaranteed for the type of GAs used in this dissertation.
Reference: [80] <author> David E. Rumelhart, Geoffrey E. Hinton, and James L. McClelland. </author> <title> A general framework for parallel distributed processing. </title> <editor> In David E. Rumelhart and James L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 45-76. </pages> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: The drug docking results with GA-LS hybrids are compared with simulated annealing, the optimization method used by Goodwell and Olsen [34]. VII.A Neural Networks Neural networks are simple parametric models that are thought to loosely model biological nervous systems <ref> [80] </ref>. While there are a variety of types of neural networks, I have examined feedforward neural networks, which perform a deterministic mapping from a set of inputs to a set of outputs [81]. Figure VII.1 illustrates a multilayer feedforward neural network.
Reference: [81] <author> David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In David E. Rumelhart and James L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 318-362. </pages> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: A common error function is the squared error E (a; b) = ka bk 2 : Examples of parametric models are linear models [19], logit models [13] and neural networks <ref> [81] </ref>. Both random local search and conjugate gradient methods can be used to minimize J (w), since gradient information is typically available for this function. An alternative method of minimizing J (w) is stochastic approximation. <p> To use information from a single sample, suppose that (x i ; y i ) is randomly selected from the data set. The following learning rule is described in White [99] and 13 Rumelhart, Hinton and Williams <ref> [81] </ref>: w t+1 = w t + w t (II.1) where t is the so called learning rate, which controls the step size of this method. <p> The use of local search with GAs is also inspired by biological models of learning and evolution. We have noted that evolutionary algorithms like the GA take many cues from mechanisms observed in natural evolution. Similarly, models of learning are often equated with techniques for local optimization <ref> [81] </ref>. Research on the interaction between evolution and learning has naturally led computer scientists to consider interactions between evolutionary algorithms and local optimization [7]. The following framework is used to describe the range of interactions between the GA and local search algorithms. <p> While there are a variety of types of neural networks, I have examined feedforward neural networks, which perform a deterministic mapping from a set of inputs to a set of outputs <ref> [81] </ref>. Figure VII.1 illustrates a multilayer feedforward neural network. Each node 101 102 Figure VII.1: Multilayer feedforward neural network with one hidden layer. in the network computes a weighted sum of the node's inputs that is passed into a logistic function. <p> A common error function is the squared error E (a; b) = ka bk 2 When using a smooth error function like this, the gradient of J (w) is computed for feedforward neural networks by back-propagating the errors on the outputs through every layer of the network <ref> [81] </ref>. The weight vector for neural networks is typically large. Therefore, solving neural network problems involves the minimization of an error criterion over a high dimensional search space that has a large number of local minima. In theory, the global minimum of the search space is desired.
Reference: [82] <author> J. David Schaffer, Richard A. Caruana, Larry J. Eshelman, and Rajarshi Das. </author> <title> A study of control parameters affecting online performance of genetic algorithms for function optimization. </title> <editor> In J. David Schaffer, editor, </editor> <booktitle> Proceedings of the Third Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 51-60. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Since I am primarily interested in GA-LS hybrids, the experiments use Cauchy deviates to search the domain with global samples. I use C (0; 1) Cauchy deviates with the floating point GA. Unless otherwise specified, the mutation rate is determined by operationalizing the analysis in Schaffer et al. <ref> [82] </ref> that examines the interaction between population size, mutation rate and the length of the genome.
Reference: [83] <author> Nicol N. Schraudolph and Richard K. Belew. </author> <title> Dynamic parameter encoding for genetic algorithms. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 9-21, </pages> <year> 1992. </year>
Reference-contexts: GAs have traditionally used binary encodings of real numbers to perform optimization on R n [16]. While binary encodings have been used to successfully solve optimization problems, special manipulation of this encoding is often necessary to increase the efficiency of the algorithm <ref> [83, 100] </ref>. There is evidence that optimization on R n can and should be performed with real parameters. Goldberg [27] provides formal arguments that floating point GAs manipulate virtual alphabets, a type of schema that is appropriate in R n .
Reference: [84] <author> F.J. Solis and R.J-B. Wets. </author> <title> Minimization by random search techniques. </title> <journal> Mathematical Operations Research, </journal> <volume> 6 </volume> <pages> 19-30, </pages> <year> 1981. </year>
Reference-contexts: However, derivative information requires additional calculations, and these algorithms do not always generated good solutions fast enough to compensate for the additional expense. Three methods of local search will be used throughout this dissertation. The first is the non-derivative method proposed by Solis and Wets <ref> [84] </ref>. Next, conjugate gradient methods [26, 74] are used to minimize continuous functions using gradient information. Finally, stochastic approximation is used in pattern recognition methods 10 to find the optimal weights for parametric models of data [19]. II.A.1 Random Local Search Solis and Wets [84] propose several random local search methods <p> method proposed by Solis and Wets <ref> [84] </ref>. Next, conjugate gradient methods [26, 74] are used to minimize continuous functions using gradient information. Finally, stochastic approximation is used in pattern recognition methods 10 to find the optimal weights for parametric models of data [19]. II.A.1 Random Local Search Solis and Wets [84] propose several random local search methods for performing local search on smooth functions without derivative information. Their "Algorithm 1" uses normally distributed steps to generate new points in the search space. A new point is generated by adding zero mean normal deviates to every dimension of the current point. <p> The deterministic complexity analysis can be extended to include expensive genetic operators by applying a fixed-cost local search to a fixed fraction of the population. An example of a fixed-cost local search is a random local search method, like the one described by Solis and Wets <ref> [84] </ref>, which is terminated after a fixed number of function evaluations. Using local search in this manner, the deterministic computational complexity is a simple extension of our previous analysis.
Reference: [85] <author> William M. Spears and Kenneth A. De Jong. </author> <title> An analysis of multi-point crossover. </title> <editor> In Gregory J.E. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 301-315. </pages> <address> Morgan-Kauffmann, </address> <year> 1991. </year>
Reference-contexts: In particular, much research has been done examining how crossover composes and disrupts patterns in binary strings, based on their contribution to the total fitness of the individual <ref> [30, 85, 86, 97] </ref>. This research has motivated the use of modified crossover operators that restrict the distribution of crossover points.
Reference: [86] <author> William M. Spears and Kenneth A. De Jong. </author> <title> On the virtues of parametrized uniform crossover. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 230-236. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: In particular, much research has been done examining how crossover composes and disrupts patterns in binary strings, based on their contribution to the total fitness of the individual <ref> [30, 85, 86, 97] </ref>. This research has motivated the use of modified crossover operators that restrict the distribution of crossover points.
Reference: [87] <author> Piet Spiessens and Bernard Manderick. </author> <title> A massively parallel genetic algorithm: Implementation and first analysis. </title> <booktitle> In Proceedings of the 4th International Conference on Genetic Algorithms, </booktitle> <pages> pages 279-285, </pages> <year> 1991. </year> <month> 134 </month>
Reference-contexts: The most common way of structuring the selection mechanism uses a toroidal two dimensional grid like the one in Figure II.4 <ref> [2, 12, 56, 87] </ref>. Every element of the population is 22 Figure II.4: The two dimensional grid used by GSGAs to define population subsets. assigned to a location on the grid. The grid locations are not necessarily related to the individuals' solutions. <p> GSGAs are implemented by assigning one individual per processor. Selection and recombination is limited to a small number of individuals on neighboring processors, typically forming a two dimensional grid of individuals (see Spiessens and Manderick <ref> [87] </ref>, Collins and Jefferson [12] and McInerney [56]). Gordon and Whitley [35] have recently argued that the algorithmic nature of these parallel algorithms may be of interest, independent from their implementation on a particular architecture. <p> Given a neighborhood size s and a problem representation length , the time complexity needed to perform selection and apply the crossover and mutation operators is O (s + ) when using local tournament selection, and O (s log s + ) when using local proportional or rank selection <ref> [87] </ref>. Let T f is the time to perform a single function evaluation, which is problem dependent, and let T flop is the time needed to perform a single floating point operation.
Reference: [88] <author> N. J. Stedmann, G. M. Morris, and P. J. Atkinson. </author> <title> Bibliography of theoretical calculations in molecular pharmacology. </title> <journal> J. Mol. Graphics, </journal> <volume> 5 </volume> <pages> 211-222, </pages> <year> 1987. </year>
Reference-contexts: VII.C Drug Docking One of the key elements of computer aided drug design is the docking of potential drug candidates to a target macromolecule. Manual methods of docking have been widely used <ref> [88] </ref>. They use sophisticated energy evaluations, but only allow the user to examine a limit number of docking conformations. The docking method described by Goodsell and Olsen [34] examines a large number of docking conformations automatically.
Reference: [89] <author> Gilbert Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9, </pages> <year> 1989. </year>
Reference-contexts: Using it, we can justify how and why certain bit patterns (schemata) will be propagated from one generation to the next. This can be used to analyze the effectiveness of different genetic operators (see for example Syswerda <ref> [89] </ref>). Related analysis with 36 37 Walsh functions has also proven very rewarding. Walsh functions can be used to analyze the effectiveness of genetic operators, as well as analyze the difficulty of the function being optimized [31, 30].
Reference: [90] <author> Larry E. Toothaker. </author> <title> Multiple Comparisons for Researchers. </title> <publisher> Sages Publications, </publisher> <year> 1991. </year>
Reference-contexts: In this instance, there are three samples that have 50 measurements each. Multiple comparisons are performed with the GH procedure, which compares samples with unequal variances <ref> [90] </ref>. This method tests multiple null hypotheses which state that the means of each pair of samples are identical. The confidence of this test applies to all of the hypothesis tests considered collectively.
Reference: [91] <author> Aimo Torn and Antanas Zilinskas. </author> <title> Global Optimization, </title> <booktitle> volume 350 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Consequently, global optimization methods have been developed to perform a sophisticated search across multiple local minima. Global optimization is an inherently difficult problem since no general criterion exists for determining whether the global optimum has been reached. I.B Adaptive Global Optimization Torn and Zilinskas <ref> [91] </ref> observe that two competing goals govern the design of global optimization methods. Global reliability is needed to ensure that every part of the domain is searched enough to provide a reliable estimate of the global optimum. <p> Because my interest concerns adaptive global search methods that use local search, I pay close attention to the role of local search techniques in these global optimization algorithms. Figure II.2 shows the classification of global optimization methods proposed by Torn and Zilinskas <ref> [91] </ref> (our category labels). II.B.1 Methods with Guaranteed Accuracy The covering methods use a global search strategy that excludes regions of the search space based on estimates of how much the function can vary over small regions. <p> The modified objective function is designed such that a local search procedure can be used to search for x 00 starting from x 0 . Torn and Zilinskas <ref> [91] </ref> note that the implementation of generalized descent techniques is similar to a multistart procedure using non-local optimization techniques (see below). Clustering Methods Clustering methods are among the most efficient algorithms proposed for global optimization. These methods are composed of several steps. <p> A variety of methods can be used to perform each of these steps. Concentrating the samples is typically performed by refining the samples with a few steps of local search and retaining a fraction of the best samples. Torn and Zilinskas <ref> [91] </ref> describe a number of clustering algorithms that have been used with these methods, including standard hierarchical methods. Clustering methods are amenable to analysis because they use uniformly distributed samples. <p> For this reason, simulated re-annealing has been proposed [44, 45]. This variant treats simulated annealing more like a local search technique, using multiple starts to perform the global search. II.C Evolutionary Search Evolutionary search algorithms, called competitive search by Torn and Zilinskas <ref> [91] </ref>, represent an important class of adaptive search algorithms. <p> Optimizing functions defined on R n also enables us to make comparisons with algorithms developed in the global optimization literature. Most problems in the testbeds used to evaluate GAs and global optimization algorithms are defined on R n <ref> [1, 21, 31, 91] </ref>. Thus, I evaluate GA-LS hybrids on problems for which we can 42 directly compare my results to other global optimization and evolutionary methods. The experiments in Chapter V and VI perform optimization on three global optimization test functions on R n . <p> IV.B.1 Griewank The Griewank function f (x) = i=1 i =4000 + 1 i=1 p with dimension n = 10 is one of the most difficult global optimization test functions <ref> [91] </ref>. Figure IV.1 shows a one-dimensional slice of this function, which has been smoothed a bit to remove some of the local minima. The Griewank function contains some 500 local minima in [600:0; 600:0] 10 , which are concentrated around the global optimum at the origin. <p> The second is the time needed to find an *- accurate solution. To account for variations in processing speed between computers, the CPU time is normalized by the time needed to evaluate Shekel's function 1000 times <ref> [91] </ref>. Shekel's function is a standard global optimization test function. The third approach is to compare the performance of the methods after a fixed number of function evaluations. This is particular useful if complete optimization is prohibitively expensive. This last approach is used in the experiments.
Reference: [92] <author> Craig A. Tovey. </author> <title> Hill climbing with multiple local optima. </title> <journal> SIAM Journal of Algorithms and Discrete Mathematics, </journal> <volume> 6(3) </volume> <pages> 384-393, </pages> <year> 1985. </year>
Reference-contexts: A number of authors have performed general analyses of local search methods over discrete spaces. Tovey <ref> [92, 93] </ref> models the expected performance of local search algorithms that optimize real valued functions defined on f0; 1g n . Johnson, Papadimitriou and Yannakakis [48] introduce the complexity class PLS (Polynomial Local Search).
Reference: [93] <author> Craig A. Tovey. </author> <title> Low order polynomial bounds on the expected performance of local imporvement algorithms. </title> <journal> Mathematical Programming, </journal> <volume> 35 </volume> <pages> 193-224, </pages> <year> 1986. </year>
Reference-contexts: A number of authors have performed general analyses of local search methods over discrete spaces. Tovey <ref> [92, 93] </ref> models the expected performance of local search algorithms that optimize real valued functions defined on f0; 1g n . Johnson, Papadimitriou and Yannakakis [48] introduce the complexity class PLS (Polynomial Local Search).
Reference: [94] <author> J. F. Traub, G. W. Wasilkowski, and H. Wozniakowski. </author> <title> Information-Based Complexity. </title> <publisher> Academic Press, Inc., </publisher> <year> 1988. </year>
Reference-contexts: III.B Complexity Analysis In computational analysis, the fundamental tradeoff is between computational expense and the performance measure for the problem at hand. In the following analysis, I equate computational expense with the amount of time an algorithm uses. The following complexity analysis considers algorithms that use randomization information <ref> [94] </ref>. The analysis examines the complexity for the worst possible set of randomization information, except that a ffi probability of finding a solution with accuracy greater than * is given. This complexity analysis concerns the time complexity of the algorithms, and the space complexity of the algorithms is ignored.
Reference: [95] <author> Nico L.J. Ulder, Emile H.L. Aarts, Hans-Jurgen Bandelt, Peter J.M. van Laarhoven, and Erwin Pesch. </author> <title> Genetic local search algorithms for the traveling salesman problem. </title> <editor> In Hans-Paul Schwefel and Reinhard Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 109-116. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: The problem of finding the optimal parameters for a neural network [7, 50, 68] comes closest to the models of learning and evolution. GA-LS hybrids have been applied to combinatorial graph problems like the traveling salesman problem <ref> [9, 63, 95] </ref> and the graph partitioning problem [96]. These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems [49].
Reference: [96] <author> Gregor von Laszewski. </author> <title> Intelligent structural operators for the k-way graph partitioning problem. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 45-52. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The problem of finding the optimal parameters for a neural network [7, 50, 68] comes closest to the models of learning and evolution. GA-LS hybrids have been applied to combinatorial graph problems like the traveling salesman problem [9, 63, 95] and the graph partitioning problem <ref> [96] </ref>. These problems lend themselves to the use of local search operators because there are a number of very good heuristics for the local improvement of a solution. Other applications include the mapping problem [64] and molecular conformation problems [49].
Reference: [97] <author> Michael D. Vose and Gunar E. Liepens. </author> <title> Schema disruption. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 237-242. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: In particular, much research has been done examining how crossover composes and disrupts patterns in binary strings, based on their contribution to the total fitness of the individual <ref> [30, 85, 86, 97] </ref>. This research has motivated the use of modified crossover operators that restrict the distribution of crossover points.
Reference: [98] <author> E.D. Weinberger. </author> <title> Fourier and Taylor serics on fitness landscapes. </title> <journal> Biological Cybernetics, </journal> <volume> 65 </volume> <pages> 321-330, </pages> <year> 1991. </year>
Reference-contexts: I claim that it is easier to analyze experimental results when optimizing these functions, particularly when optimizing with local search methods. In discrete spaces, the neighborhood structure used to search the domain space can have a tremendous influence on the performance of local optimization methods. For example, Wein-berger <ref> [98] </ref> provides a formalism for computing something like the Fourier analysis, but over discrete spaces. Analyses like this indicate how discrete problems vary across their domains. Unfortunately, the results of this analysis appear very specific to the topological structure of the discrete space.
Reference: [99] <author> Halbert White. </author> <title> Learning in artificial neural networks: A statistical perspective. </title> <journal> Neural Computation, </journal> <volume> 1(4) </volume> <pages> 425-464, </pages> <year> 1989. </year>
Reference-contexts: In particular, it makes updates to the current solution using randomly selected samples. To use information from a single sample, suppose that (x i ; y i ) is randomly selected from the data set. The following learning rule is described in White <ref> [99] </ref> and 13 Rumelhart, Hinton and Williams [81]: w t+1 = w t + w t (II.1) where t is the so called learning rate, which controls the step size of this method. <p> White <ref> [99] </ref> summarizes analyses of stochastic approximation methods which show conditions under which w t converges to the optimum with probability one. <p> For a deterministic algorithm, the estimates of the global optimum, x n , converge if lim n!1 x n = x fl . Natural generalizations of convergence can be defined for stochastic algorithms <ref> [99] </ref>. Unfortunately, convergence is typically provided in a limit that is 14 I. Methods with guaranteed accuracy A. Covering methods II. Indirect methods A. Methods approximating the level sets B. Methods approximating the function III. Direct Methods A. Clustering methods B. Generalized descent methods C.
Reference: [100] <author> D. Whitley, K. Mathias, and P. Fitzhorn. </author> <title> Delta coding: An iterative search strategy for genetic algorithms. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 77-84. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: GAs have traditionally used binary encodings of real numbers to perform optimization on R n [16]. While binary encodings have been used to successfully solve optimization problems, special manipulation of this encoding is often necessary to increase the efficiency of the algorithm <ref> [83, 100] </ref>. There is evidence that optimization on R n can and should be performed with real parameters. Goldberg [27] provides formal arguments that floating point GAs manipulate virtual alphabets, a type of schema that is appropriate in R n .
Reference: [101] <author> Darrell Whitley. </author> <title> Cellular genetic algorithms. </title> <editor> In Stephanie Forrest, editor, </editor> <booktitle> Proceedings of the Fifth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> page 658. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1993. </year> <month> 135 </month>
Reference-contexts: These architectures typically have on the order of 2 10 or more simple processors, and are often described as massively parallel. These parallel GAs have also been called massively parallel GAs and fine grain GAs. Whitley <ref> [101] </ref> has identified a subset of these parallel GAs, cellular GAs, which can be equated with finite cellular automaton.
Reference: [102] <author> Darrell Whitley, Stephen Dominic, and Rajarshi Das. </author> <title> Genetic reinforcement learning with multilayer neural networks. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth Intl. Conf. on Genetic Algorithms, </booktitle> <pages> pages 562-569. </pages> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Muhlenbein [63] makes a similar distinction and describes a GA which uses a set of independent subpopulations and structures the inter-population communication with a ladder structure. These subpopulations are typically small, so they perform a localized search of the function. For example, Whitely <ref> [102] </ref> illustrates how a small 24 population can perform a locallized search in the context of neural network optimization problems. Inter-population communication enables populations to combine disparate solutions and enables them to perform a global search.
Reference: [103] <author> Alden H. Wright. </author> <title> Genetic algorithms for real parameter optimization. </title> <editor> In Gre-gory J.E. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 205-218. </pages> <address> Morgan-Kauffmann, </address> <year> 1991. </year>
Reference-contexts: There is evidence that optimization on R n can and should be performed with real parameters. Goldberg [27] provides formal arguments that floating point GAs manipulate virtual alphabets, a type of schema that is appropriate in R n . Wright <ref> [103] </ref> and Janikow and Michalewicz [46] suggests that floating point GAs can be more efficient, provide increase precision, and allow for genetic operators that are more appropriate for a continuous domain.
References-found: 103

