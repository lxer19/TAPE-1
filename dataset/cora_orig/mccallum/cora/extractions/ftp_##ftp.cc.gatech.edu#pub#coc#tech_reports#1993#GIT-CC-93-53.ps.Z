URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1993/GIT-CC-93-53.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.93.html
Root-URL: 
Email: (bodhi@cc.gatech.edu)  (eisen@cc.gatech.edu)  (kaushik@cc.gatech.edu)  
Title: A Machine Independent Interface for Lightweight Threads  
Author: Bodhisattwa Mukherjee Greg Eisenhauer Kaushik Ghosh 
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Web: GIT-CC-93/53  
Abstract: Recently, lightweight thread libraries have become a common entity to support concurrent programming on shared memory multiprocessors. However, the disparity between primitives offered by operating systems creates a challenge for those who wish to create portable lightweight thread packages. What should be the interface between the machine-independent and machine-dependent parts of the thread library? We have implemented a portable lightweight thread library on top of Unix on a KSR-1 supercomputer, BBN Butterfly multiprocessor, SGI multiprocessor, Sequent multiprocessor and Sun 3/4 family of uniprocessors. This paper first compares the nature and performance of the OS primitives offered by these machines. We then present a procedure-level abstraction that is efficiently implementable on all the architectures and is a sufficient base upon which a user-level thread package can be built. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jr. A. Tevanian. </author> <title> Architecture-Independent Virtual Memory Management for Parallel and Distributed Environments. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie-Mellon University, </institution> <month> December </month> <year> 1987. </year> <note> Also as Technical Report CMU-CS-88-106. </note>
Reference-contexts: For example, in Sequent/DYNIX, a user may explicitly specify a data item to be shared among a group of processes using the "shared" keyword. Similarly, some operating systems implement process groups that inherently share an address space. A few operating systems <ref> [8, 1] </ref> also support dynamic address space sharing using sophisticated address mapping techniques. Depending on the amount of static data sharing, we have classified the process model in three categories (Figure 3): Fully shared data segments. In this model, a group of related processes share one data segment.
Reference: [2] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. Sched-uler activations: </author> <title> Effective kernel support for the user-level management of parallelism. </title> <journal> Transactions on Computer Systems, ACM, </journal> <volume> 10(1) </volume> <pages> 53-79, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: Parallelism expressed using such heavyweight processes must be coarse-grained and is often not suitable for high performance parallel programs. Hence, in many contemporary operating system kernels, address space and threads are decoupled so that a single address space can have multiple execution threads <ref> [2, 4] </ref>. Threads are an emerging model for expressing concurrency within Unix processes [7]. In multiprocessors, threads are primarily used to simultaneously utilize all the available processors. Threads are even useful on a uniprocessor system for mapping asynchronous behavior into equivalent synchronous behavior [7, 4]. <p> Recently, thread libraries have become a common element of new languages and operating systems for shared memory multiprocessor and uniprocessors to support concurrent programming. Mach Cthreads [6, 16], the University of Washington threads <ref> [15, 2] </ref>, POSIX Pthreads [7], SunOS LWP and threads [12, 13, 20], are a few popular lightweight thread implementations. <p> An application level scheduler schedules lightweight threads on top of kernel supported threads (let be the mapping function), which in turn are scheduled by a kernel scheduler () on the available physical processors (referred to as two-level scheduling) <ref> [2, 3] </ref>. Figure 2 illustrates such a computation model where kernel-level active entities form a cluster of virtual processors for user-level threads. If both and map 1:1, it results in a true parallelism. The implementation of a lightweight thread library depends on the kernel scheduler ().
Reference: [3] <author> Thomas E. Anderson, Edward D. Lazowska, and Henry M. Levy. </author> <title> The performance implications of thread management alternatives for shared-memory multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(12) </volume> <pages> 1631-1644, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Though such kernel-level threads offer a general programming interface to an application, they are expensive and therefore are not used in fine-grained parallel programs [4, 17]. Unlike kernel-level threads, user-level threads (also known as lightweight threads) are managed by runtime library routines linked into each application <ref> [3, 6] </ref>. They are efficient because thread management operations do not need to cross the kernel protection boundary. Furthermore, lightweight threads enable an application program to use a thread management system which is most appropriate to the problem domain. <p> An application level scheduler schedules lightweight threads on top of kernel supported threads (let be the mapping function), which in turn are scheduled by a kernel scheduler () on the available physical processors (referred to as two-level scheduling) <ref> [2, 3] </ref>. Figure 2 illustrates such a computation model where kernel-level active entities form a cluster of virtual processors for user-level threads. If both and map 1:1, it results in a true parallelism. The implementation of a lightweight thread library depends on the kernel scheduler ().
Reference: [4] <author> Brian N. Bershad. </author> <title> High performance cross-address space communication. </title> <type> Technical Report 90-06-02, </type> <institution> Dept. of Computer Science and Eng., University of Washington, </institution> <month> June </month> <year> 1990. </year> <type> Ph.D. dissertation. </type>
Reference-contexts: Parallelism expressed using such heavyweight processes must be coarse-grained and is often not suitable for high performance parallel programs. Hence, in many contemporary operating system kernels, address space and threads are decoupled so that a single address space can have multiple execution threads <ref> [2, 4] </ref>. Threads are an emerging model for expressing concurrency within Unix processes [7]. In multiprocessors, threads are primarily used to simultaneously utilize all the available processors. Threads are even useful on a uniprocessor system for mapping asynchronous behavior into equivalent synchronous behavior [7, 4]. <p> Threads are an emerging model for expressing concurrency within Unix processes [7]. In multiprocessors, threads are primarily used to simultaneously utilize all the available processors. Threads are even useful on a uniprocessor system for mapping asynchronous behavior into equivalent synchronous behavior <ref> [7, 4] </ref>. Though such kernel-level threads offer a general programming interface to an application, they are expensive and therefore are not used in fine-grained parallel programs [4, 17]. Unlike kernel-level threads, user-level threads (also known as lightweight threads) are managed by runtime library routines linked into each application [3, 6]. <p> Threads are even useful on a uniprocessor system for mapping asynchronous behavior into equivalent synchronous behavior [7, 4]. Though such kernel-level threads offer a general programming interface to an application, they are expensive and therefore are not used in fine-grained parallel programs <ref> [4, 17] </ref>. Unlike kernel-level threads, user-level threads (also known as lightweight threads) are managed by runtime library routines linked into each application [3, 6]. They are efficient because thread management operations do not need to cross the kernel protection boundary.
Reference: [5] <author> David. L. Black. </author> <title> Scheduling support for concurrency and parallelism in the mach operating system. </title> <booktitle> IEEE Computer, </booktitle> <month> May </month> <year> 1990. </year> <note> Also as CMU Technical Report CMU-CS-90-125, </note> <month> April </month> <year> 1990. </year>
Reference-contexts: BBN Butterfly multiprocessors run a version of Unix which supports a few Mach <ref> [5, 10] </ref> features. Table 1 compares the cost of a few basic operations of these Unix implementations.
Reference: [6] <author> E. Cooper and R. Draves. </author> <title> C threads. </title> <type> Technical Report CMU-CS-88-154, </type> <institution> Dept. of Computer Science, Carnegie Mellon University, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: Though such kernel-level threads offer a general programming interface to an application, they are expensive and therefore are not used in fine-grained parallel programs [4, 17]. Unlike kernel-level threads, user-level threads (also known as lightweight threads) are managed by runtime library routines linked into each application <ref> [3, 6] </ref>. They are efficient because thread management operations do not need to cross the kernel protection boundary. Furthermore, lightweight threads enable an application program to use a thread management system which is most appropriate to the problem domain. <p> Furthermore, lightweight threads enable an application program to use a thread management system which is most appropriate to the problem domain. Recently, thread libraries have become a common element of new languages and operating systems for shared memory multiprocessor and uniprocessors to support concurrent programming. Mach Cthreads <ref> [6, 16] </ref>, the University of Washington threads [15, 2], POSIX Pthreads [7], SunOS LWP and threads [12, 13, 20], are a few popular lightweight thread implementations.
Reference: [7] <editor> POSIX P1003.4a IEEE Draft. </editor> <title> Threads Extension for Portable Operating Systems. </title>
Reference-contexts: Hence, in many contemporary operating system kernels, address space and threads are decoupled so that a single address space can have multiple execution threads [2, 4]. Threads are an emerging model for expressing concurrency within Unix processes <ref> [7] </ref>. In multiprocessors, threads are primarily used to simultaneously utilize all the available processors. Threads are even useful on a uniprocessor system for mapping asynchronous behavior into equivalent synchronous behavior [7, 4]. <p> Threads are an emerging model for expressing concurrency within Unix processes [7]. In multiprocessors, threads are primarily used to simultaneously utilize all the available processors. Threads are even useful on a uniprocessor system for mapping asynchronous behavior into equivalent synchronous behavior <ref> [7, 4] </ref>. Though such kernel-level threads offer a general programming interface to an application, they are expensive and therefore are not used in fine-grained parallel programs [4, 17]. Unlike kernel-level threads, user-level threads (also known as lightweight threads) are managed by runtime library routines linked into each application [3, 6]. <p> Recently, thread libraries have become a common element of new languages and operating systems for shared memory multiprocessor and uniprocessors to support concurrent programming. Mach Cthreads [6, 16], the University of Washington threads [15, 2], POSIX Pthreads <ref> [7] </ref>, SunOS LWP and threads [12, 13, 20], are a few popular lightweight thread implementations.
Reference: [8] <author> R. Fitzgerald and R. Rashid. </author> <title> The integration of virtual memory management and inter-process communication in accent. </title> <journal> ACM Transactions on Computer Systems, </journal> <month> May </month> <year> 1986. </year>
Reference-contexts: For example, in Sequent/DYNIX, a user may explicitly specify a data item to be shared among a group of processes using the "shared" keyword. Similarly, some operating systems implement process groups that inherently share an address space. A few operating systems <ref> [8, 1] </ref> also support dynamic address space sharing using sophisticated address mapping techniques. Depending on the amount of static data sharing, we have classified the process model in three categories (Figure 3): Fully shared data segments. In this model, a group of related processes share one data segment.
Reference: [9] <author> Kaushik Ghosh, Bodhisattwa Mukherjee, and Karsten Schwan. </author> <title> Experimentation with configurable, lightweight threads on a ksr multiprocessor. </title> <type> Technical Report GIT-CC-93/37, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1993. </year>
Reference-contexts: Access to non-local memory results in the corresponding cache line being migrated to the local cache, so that future accesses to that memory element are relatively cheap <ref> [9, 18] </ref>. At the lowest level, the parallel programming model offered by the KSR's OSF Unix operating system is one of kernel-level threads which offer constructs for thread fork, thread synchronization, shared memory between threads, etc..
Reference: [10] <author> D. Golub, R. Dean, A. Forin, and R. Rashid. </author> <title> Unix as an application program. </title> <booktitle> In Proceedings of the Summer Usenix Technical Conference, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: BBN Butterfly multiprocessors run a version of Unix which supports a few Mach <ref> [5, 10] </ref> features. Table 1 compares the cost of a few basic operations of these Unix implementations.
Reference: [11] <author> A. Gupta, A. Tucker, and S. Urushibara. </author> <title> The impact of operating systems scheduling policies and synchronization methods of the performance of parallel applications. </title> <booktitle> In Proc. 1991 ACM SIGMETRICS Conf. on Meas. and Mod. of Comp. Sys., </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: Figure 2 illustrates such a computation model where kernel-level active entities form a cluster of virtual processors for user-level threads. If both and map 1:1, it results in a true parallelism. The implementation of a lightweight thread library depends on the kernel scheduler (). Earlier research in scheduling <ref> [14, 22, 11] </ref> has compared the performance of applications under "processor partitioning" scheme 5 vs. "time sharing" scheme 6 , and has observed that processor partitioning considerably improves application performance.
Reference: [12] <author> Sun Microsystem Inc. </author> <title> Sun OS 4.0 Reference Manual, </title> <month> November </month> <year> 1987. </year> <note> Section 3L. </note>
Reference-contexts: Recently, thread libraries have become a common element of new languages and operating systems for shared memory multiprocessor and uniprocessors to support concurrent programming. Mach Cthreads [6, 16], the University of Washington threads [15, 2], POSIX Pthreads [7], SunOS LWP and threads <ref> [12, 13, 20] </ref>, are a few popular lightweight thread implementations.
Reference: [13] <author> J. Kepecs. </author> <title> Lightweight processes for unix implementation and application. </title> <booktitle> In Proc. 1985 USENIX Summer Conference, </booktitle> <pages> pages 299-308, </pages> <year> 1985. </year>
Reference-contexts: Recently, thread libraries have become a common element of new languages and operating systems for shared memory multiprocessor and uniprocessors to support concurrent programming. Mach Cthreads [6, 16], the University of Washington threads [15, 2], POSIX Pthreads [7], SunOS LWP and threads <ref> [12, 13, 20] </ref>, are a few popular lightweight thread implementations.
Reference: [14] <author> S. Leutenegger and M. Vernon. </author> <title> The performance of multiprogrammed multiprocessor scheduling policies. </title> <booktitle> In Proceedings of the 1990 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Figure 2 illustrates such a computation model where kernel-level active entities form a cluster of virtual processors for user-level threads. If both and map 1:1, it results in a true parallelism. The implementation of a lightweight thread library depends on the kernel scheduler (). Earlier research in scheduling <ref> [14, 22, 11] </ref> has compared the performance of applications under "processor partitioning" scheme 5 vs. "time sharing" scheme 6 , and has observed that processor partitioning considerably improves application performance.
Reference: [15] <author> P. McJones and G. Swart. </author> <title> Evolving the unix system interface to support multithreaded programs. </title> <booktitle> In Proc. USENIX Winter Conference, </booktitle> <pages> pages 393-404, </pages> <year> 1989. </year>
Reference-contexts: Recently, thread libraries have become a common element of new languages and operating systems for shared memory multiprocessor and uniprocessors to support concurrent programming. Mach Cthreads [6, 16], the University of Washington threads <ref> [15, 2] </ref>, POSIX Pthreads [7], SunOS LWP and threads [12, 13, 20], are a few popular lightweight thread implementations.
Reference: [16] <author> Bodhisattwa Mukherjee. </author> <title> A portable and reconfigurable threads package. </title> <booktitle> In Proceedings of Sun User Group Technical Conference, </booktitle> <pages> pages 101-112, </pages> <month> June </month> <year> 1991. </year> <note> TR# GIT-ICS-91/02. </note>
Reference-contexts: Furthermore, lightweight threads enable an application program to use a thread management system which is most appropriate to the problem domain. Recently, thread libraries have become a common element of new languages and operating systems for shared memory multiprocessor and uniprocessors to support concurrent programming. Mach Cthreads <ref> [6, 16] </ref>, the University of Washington threads [15, 2], POSIX Pthreads [7], SunOS LWP and threads [12, 13, 20], are a few popular lightweight thread implementations. <p> Mach Cthreads [6, 16], the University of Washington threads [15, 2], POSIX Pthreads [7], SunOS LWP and threads [12, 13, 20], are a few popular lightweight thread implementations. We have implemented a portable user-level thread package 1 <ref> [16] </ref> on several multiprocessor platforms such as BBN Butterfly parallel processor, Kendall Square Research parallel processor, Sequent Symmetry multiprocessor, Silicon Graphics multiprocessor and on several uniprocessors such as Sun 3 and Sun 4 families.
Reference: [17] <author> Bodhisattwa Mukherjee and Karsten Schwan. </author> <title> A survey of multiprocessor operating system kernels. </title> <type> Technical Report GIT-CC-92/05, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: Threads are even useful on a uniprocessor system for mapping asynchronous behavior into equivalent synchronous behavior [7, 4]. Though such kernel-level threads offer a general programming interface to an application, they are expensive and therefore are not used in fine-grained parallel programs <ref> [4, 17] </ref>. Unlike kernel-level threads, user-level threads (also known as lightweight threads) are managed by runtime library routines linked into each application [3, 6]. They are efficient because thread management operations do not need to cross the kernel protection boundary.
Reference: [18] <author> Bodhisattwa Mukherjee and Karsten Schwan. </author> <title> Experimentation with a reconfigurable micro-kernel. </title> <booktitle> In Proc. of the USENIX Symposium on Microkernels and Other Kernel Architectures, </booktitle> <pages> pages 45-60, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Access to non-local memory results in the corresponding cache line being migrated to the local cache, so that future accesses to that memory element are relatively cheap <ref> [9, 18] </ref>. At the lowest level, the parallel programming model offered by the KSR's OSF Unix operating system is one of kernel-level threads which offer constructs for thread fork, thread synchronization, shared memory between threads, etc..
Reference: [19] <author> J. Ousterhout. </author> <title> Scheduling techniques for concurrent systems. </title> <booktitle> In Proceedings of Distributed Computing Systems Conference, </booktitle> <pages> pages 22-30, </pages> <year> 1982. </year>
Reference: [20] <author> M. Powell, S. Kleiman, S. Barton, D. Shah, D. Stein, and M. Weeks. </author> <title> Sunos multi-thread architecture. </title> <booktitle> In Proc. USENIX winter conference, </booktitle> <pages> pages 1-14, </pages> <year> 1991. </year>
Reference-contexts: Recently, thread libraries have become a common element of new languages and operating systems for shared memory multiprocessor and uniprocessors to support concurrent programming. Mach Cthreads [6, 16], the University of Washington threads [15, 2], POSIX Pthreads [7], SunOS LWP and threads <ref> [12, 13, 20] </ref>, are a few popular lightweight thread implementations.
Reference: [21] <author> R. Vaswani and J. Zahorjan. </author> <title> The implications of cache affinity on processor scheduling for multiprogrammed, shared memory multiprocessors. </title> <booktitle> In Proceedings of the thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 26-40, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Thread context switches add to the overhead of parallel applications. Apart from the primary effect of saving and restoring context, there is also the secondary effect of destroying cache footprints <ref> [21] </ref>. A few popular classes of applications (e.g. interactive, real-time) often use temporal information to make scheduling decisions. Such information is obtained by accessing the hardware provided "timer". For such applications, the cost of generating/handling timer interrupts plays a vital role in application performance. Dynamic operation costs.
Reference: [22] <author> J. Zahorjan and C. McCann. </author> <title> Processor scheduling in shared memory multiprocessors. </title> <booktitle> In Proceedings of the 1990 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 214-225, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Figure 2 illustrates such a computation model where kernel-level active entities form a cluster of virtual processors for user-level threads. If both and map 1:1, it results in a true parallelism. The implementation of a lightweight thread library depends on the kernel scheduler (). Earlier research in scheduling <ref> [14, 22, 11] </ref> has compared the performance of applications under "processor partitioning" scheme 5 vs. "time sharing" scheme 6 , and has observed that processor partitioning considerably improves application performance.
Reference: [23] <author> Hongyi Zhou and Karsten Schwan. </author> <title> Dynamic scheduling for hard real-time systems: Toward real-time threads. </title> <booktitle> In Proceedings of Joint IEEE Workshop on Real-Time Operating Systems and Software and IFAC Workshop on Real-Time Programming, </booktitle> <address> Atlanta, GA, </address> <pages> pages 13-21. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1991. </year> <journal> Also in IEEE Real-Time Systems Newsletter, </journal> <volume> Vol. 7, No. 4, </volume> <month> Fall </month> <year> 1991, </year> <pages> pp. 14-22. </pages>
Reference-contexts: Hence, the hardware library should provide these inexpensive hardware-implemented synchronization primitives to the user: hw-test-and-set (lock hw-lock); Timer access. It is important to have support for (timer) interrupts to develop preemptible thread libraries <ref> [23] </ref>. Most operating systems support an expensive interface to the timer interrupts and interrupt handling capabilities (e.g., the UNIX "signal" mechanism). These primitives are often so expensive (Table 2) that they are practically unusable in a lightweight thread implementation.
References-found: 23

