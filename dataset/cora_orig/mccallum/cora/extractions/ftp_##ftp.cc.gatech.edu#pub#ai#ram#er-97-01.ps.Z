URL: ftp://ftp.cc.gatech.edu/pub/ai/ram/er-97-01.ps.Z
Refering-URL: http://www.cs.gatech.edu/people/home/markd/abstracts/icml-97.abstract.html
Root-URL: 
Email: markd@cc.gatech.edu  ashwin@cc.gatech.edu  
Title: Efficient Feature Selection in Conceptual Clustering  
Author: Mark Devaney Ashwin Ram 
Address: Atlanta, GA 30332-0280  Atlanta, GA 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  College of Computing Georgia Institute of Technology  
Note: Machine Learning: Proceedings of the Fourteenth International Conference, Nashville, TN, July 1997 (to appear).  
Abstract: Feature selection has proven to be a valuable technique in supervised learning for improving predictive accuracy while reducing the number of attributes considered in a task. We investigate the potential for similar benefits in an unsupervised learning task, conceptual clustering. The issues raised in feature selection by the absence of class labels are discussed and an implementation of a sequential feature selection algorithm based on an existing conceptual clustering system is described. Additionally, we present a second implementation which employs a technique for improving the efficiency of the search for an optimal description and compare the performance of both algorithms.
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. </author> <year> (1988). </year> <title> Text file heart-disease.names, location: </title> <publisher> ftp.ics.uci.edu/pub/ machine-learning-databases/heart-disease/. </publisher>
Reference-contexts: The data set is interesting in the context of feature selection research because most of the attributes are considered irrelevant and the majority of published experiments use only a subset of fourteen attributes <ref> (Aha, 1988) </ref>. The LED data contains 24 1 Donated by V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D. <p> After training, the concepts produced by each of the algorithms were evaluated by measuring the accuracy of predicting the class label of the previously-unseen testing instances. As in evaluations conducted with the heart disease database by other researchers <ref> (Aha, 1988) </ref>, accuracy was measured by treating the output of the classifier as a binary indicator of the presence of heart disease (values of 1-4 were treated as identical). The performance task in the LED domain was to predict the class value (1-10).
Reference: <author> Aha, D., & Bankert, R. </author> <year> (1994). </year> <title> Feature selection for case-based classification of cloud types: An empirical comparison. </title> <editor> In D.W. Aha (Ed.) </editor> <booktitle> Case-based reasoning: Papers from the 1994 Workshop. </booktitle> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Aha, D., & Bankert, R. </author> <year> (1995). </year> <title> A comparative evaluation of sequential feature selection algorithms. </title> <booktitle> Proceedings of the Fifth International Workshop on Artificial Intelligence and Statistics, </booktitle> <address> Ft. Lauderdale, FL: </address> <note> Unpublished. </note>
Reference-contexts: For this reason, the majority of real-world data sets used in inductive learning research have been constructed by domain experts and contain only those attributes which are expected to be relevant to the classification problem. However, there are areas <ref> (e.g., the cloud data described in Aha & Bankert, 1995, 1994) </ref> in which sufficient domain knowledge to select only relevant attributes does not exist, and in such cases the data must be described by all attributes that are considered potentially relevant. <p> The process involves an algorithm to control the exploration of the space of potential subsets, an evaluation function to judge the quality of each of these subsets according to some metric, and the ultimate performance function with which the learner is evaluated <ref> (Aha & Bankert, 1995) </ref>. Since the space of all feature subsets of a attributes has size 2 a , feature selection algorithms typically use some form of non-exhaustive search.
Reference: <author> Almuallim, H., & Dietterich, T.G. </author> <year> (1991). </year> <title> Learning with many irrelevant features. </title> <booktitle> Ninth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 547-552). </pages> <publisher> MIT Press. </publisher>
Reference-contexts: In supervised learning, wrapper models typically measure subset quality by evaluating predictive accuracy of the class labels. Similarly, while filter models do not explicitly measure accuracy of predicting the class label they evaluate subsets on their ability to determine the class label. The algorithms FOCUS <ref> (Almuallim & Dietterich, 1991) </ref> and Relief (Kira & Rendell, 1992) are examples of such methods. The ultimate performance function in supervised concept learning is typically the accuracy of the learner in predicting the class labels of a previously-unseen set of testing instances.
Reference: <author> Caruana, R., & Freitag, D. </author> <year> (1994). </year> <title> Greedy attribute selection. </title> <booktitle> Machine Learning : Proceedings of the Eleventh International Conference, </booktitle> <address> San Francisco, CA: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: Experimental evidence suggests that this technique greatly reduces the time required to search the space of potential descriptors without sacrificing the ultimate performance of the concepts. As more complex data is explored, techniques for improving search performance such as attribute-incrementation or caching <ref> (Caruana & Freitag, 1994) </ref> become increasingly important.
Reference: <author> Devaney, M. & Ram, A. </author> <year> (1996). </year> <title> Dynamically adjusting concepts to accommodate changing contexts. </title> <editor> In M. Ku--bat & G. Widmer, Eds., </editor> <booktitle> Proceedings of the Workshop on Learning in Context-Sensitive Domains. </booktitle>
Reference-contexts: In an attempt to improve the efficiency of the feature subset search, we employ a technique we refer to as attribute-incremental concept formation. An attribute-incremental learner adds (or removes) attributes to an existing concept structure rather than instances. Our previous research <ref> (Devaney & Ram, 1996) </ref> has suggested that it is usually much more efficient to retain and modify an existing concept structure when making relatively minor modifications to the data that comprise it rather than throwing it away and beginning anew from scratch as COBWEB is forced to do.
Reference: <author> Doak, J. </author> <year> (1992). </year> <title> An Evaluation of Feature Selection Methods and Their Application to Computer Security (Tech. </title> <type> Rep. </type> <institution> CSE-92-18). Davis: University of California. </institution>
Reference-contexts: The complexity of sequential algorithms is O (a 2 ) and in data sets with large attribute sets even sequential selection algorithms can require a great deal of processing time <ref> (Doak, 1992) </ref>. The search through description space is guided by an evaluation function which measures the quality of each attribute subset. John, Kohavi, and Pfleger (1994) distinguish two types of evaluation functions, filter models and wrapper models. <p> Filter models employ some measure of an intrinsic property of the data <ref> (Doak, 1992) </ref> that is presumed to affect the ultimate performance of the classifier but is not a direct measure of this performance. In supervised learning, wrapper models typically measure subset quality by evaluating predictive accuracy of the class labels.
Reference: <author> Fisher, D. H. </author> <year> (1987). </year> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 139-172. </pages>
Reference: <author> Gennari, J. H. </author> <year> (1990). </year> <title> An experimental study of concept formation (Tech. </title> <type> Rep. 90-06). </type> <institution> Irvine: University of Cali-fornia, Department of Information and Computer Science. </institution>
Reference: <author> Gennari, J. H. </author> <year> (1991). </year> <title> Concept formation and attention. </title> <booktitle> Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 724-728). </pages> <address> Irvine, CA: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: It has also been shown that focusing on relevant attributes also increases the efficiency of a classifier by reducing the number of attributes considered during classification <ref> (Gennari, 1991) </ref>. We intend to further research these claims using 2 Running in single-user mode on a SUN Sparc10 workstation more real and artificial data sets which exhibit the traits feature selection is designed to take advantage of.
Reference: <author> Gluck, M. A., & Corter, J. E. </author> <year> (1985). </year> <title> Information, uncertainty, and the utility of categories. </title> <booktitle> Proceedings of the Seventh Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 283-287). </pages> <address> Irvine, CA: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> John, G.H., Kohavi, R., & Pfleger, K. </author> <year> (1994). </year> <title> Irrelevant features and the subset selection problem. </title> <booktitle> Machine Learning : Proceedings of the Eleventh International Conference, </booktitle> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kira, K., & Rendell, L. </author> <year> (1992). </year> <title> The feature selection problem: Traditional methods and a new algorithm. </title> <booktitle> Tenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 129-134). </pages> <publisher> MIT Press. </publisher>
Reference-contexts: Similarly, while filter models do not explicitly measure accuracy of predicting the class label they evaluate subsets on their ability to determine the class label. The algorithms FOCUS (Almuallim & Dietterich, 1991) and Relief <ref> (Kira & Rendell, 1992) </ref> are examples of such methods. The ultimate performance function in supervised concept learning is typically the accuracy of the learner in predicting the class labels of a previously-unseen set of testing instances.
Reference: <author> Kohavi, R. & John, G. H. </author> <year> (1997), </year> <title> Wrappers for Feature Subset Selection. </title> <journal> Artificial Intelligence Journal. Forthcoming. </journal>
Reference-contexts: The search through description space is guided by an evaluation function which measures the quality of each attribute subset. John, Kohavi, and Pfleger (1994) distinguish two types of evaluation functions, filter models and wrapper models. Wrapper models employ feedback from the performance function <ref> (Kohavi & John, 1997) </ref>, typically the classifier itself; measuring the performance of a feature subset by its classification accuracy on an internal testing set or by cross-validation on the training data.
Reference: <author> Merz, C.J., & Murphy, P.M. </author> <year> (1996). </year> <note> UCI Repository of machine learning databases [http://www.ics.uci.edu/ mlearn/MLRepository.html]. </note> <institution> Irvine, CA: University of California, Department of Information and Computer Science. </institution>
Reference-contexts: As an additional interesting baseline we also compare with COBWEB (no feature selection) but using only the attributes defined as relevant. Evaluations were conducted using one real and one artificial data set, both from the UCI Machine Learning Database <ref> (Merz & Murphy, 1996) </ref>. The real data was the Cleveland Clinic Heart-Disease database 1 and the artificial data was based on the LED data set generator.
References-found: 15

