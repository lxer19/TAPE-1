URL: ftp://ftp.aifb.uni-karlsruhe.de/pub/ren/ecaiA.ps.gz
Refering-URL: http://www.aifb.uni-karlsruhe.de/WBS/KDDproject/KDDproject.html
Root-URL: 
Title: Using a Data Metric for Preprocessing Advice for Data Mining Applications  
Author: Robert Engels and Christiane Theusinger 
Abstract: This paper describes research that is performed in the course of a project where a methodology for providing user support for KDD processes plays a central role. Although methodologically we aim at supporting the whole process of applying inductive learning techniques, the current paper fo-cussus on a part of this process. The main issue in this paper is the support of data preprocessing for KDD. We give some insights in the metadata we calculate from a dataset as part of the method for user support. DCT (Data Char-acteristion Tool) is implemented in a software environment (Clementine). Some examples are given that resulted from running the UGM/DCT (User Guidance Module combined with DCT) on the data. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> MLT Consortium, </author> <title> `Final public report', </title> <type> Technical report, </type> <year> (1993). </year> <title> Esprit II Project 2154. </title>
Reference-contexts: Such an approach can also be found in statistics, as described in [6] and projects like StatLOG project [9], and the MLT-approach <ref> [1] </ref> where the CONSULTANT [2] played an advisory role. A very important contribution of that research is that it notifies the importance for a support in defining application processes where statistical and inductive techniques are involved. An issue related to that of algorithm selection is that of data preprocessing. <p> can interpret the near zero values of the g-function as an indication for the fact that there is no high probability to find the joint distribution of the classes and attributes. 6 Conclusions Beginning with ideas from the knowledge acquisition field and statistical principles and guided by projects as MLT <ref> [1] </ref> and StatLOG [9] we finally came up with a framework for User Guidance Modelling (UGM: [3], [5]) that recollects a top down (problem definition etc.) and bottom up (data characteristics) process. The results of DCT are used for initiation or support of preprocessing of the data.
Reference: [2] <author> S. Craw, D. Sleeman, N. Granger, M. Rissakis, and S. Sharma, </author> <title> `Consultant: Providing advice for the machine learning toolbox', in Research and Development in Expert Systems, </title> <editor> eds., M.A. Bramer and R.W. </editor> <booktitle> Milne, </booktitle> <pages> pp. 5-23, </pages> <year> (1992). </year>
Reference-contexts: Such an approach can also be found in statistics, as described in [6] and projects like StatLOG project [9], and the MLT-approach [1] where the CONSULTANT <ref> [2] </ref> played an advisory role. A very important contribution of that research is that it notifies the importance for a support in defining application processes where statistical and inductive techniques are involved. An issue related to that of algorithm selection is that of data preprocessing.
Reference: [3] <author> R. Engels, </author> <title> `Planning tasks for knowledge discovery in databases; performing task-oriented user-guidance.', </title> <booktitle> in Proceedings of the 2nd Int. Conference on Knowledge Discovery and Data Mining, </booktitle> <editor> eds., E. Simounis, J. Han, and U. </editor> <booktitle> Fayyad, </booktitle> <pages> pp. 170-175, </pages> <address> Portland, Oregon, </address> <month> August 2-4, </month> <year> (1996). </year> <month> AAAI-Press. </month>
Reference-contexts: Support for data preprocessing is provided as part of a more general architecture for user support that is described in several papers (UGM approach: <ref> [3] </ref>, [5]). As part of the project, the UGM approach is implemented on top of Clementine (ISL) and has the advantage that it supports generation of KDD processes besides docu-mention and reuse aspects of KDD projects. <p> there is no high probability to find the joint distribution of the classes and attributes. 6 Conclusions Beginning with ideas from the knowledge acquisition field and statistical principles and guided by projects as MLT [1] and StatLOG [9] we finally came up with a framework for User Guidance Modelling (UGM: <ref> [3] </ref>, [5]) that recollects a top down (problem definition etc.) and bottom up (data characteristics) process. The results of DCT are used for initiation or support of preprocessing of the data. Several techniques from the field of statistics as well as information theory are implemented in our UGM prototype.
Reference: [4] <author> R. Engels, B. Evans, J. Herrmann, and F. Verdenius, eds. </author> <title> Workshop on Machine Learning Application in the real world; Methodological Aspects and Implications (at the ICML-97), Nashville, </title> <booktitle> TN, July 12th, 1997. at: 14th International Conference on Machine Learning. </booktitle>
Reference-contexts: The setting in which algorithms are immediately tested on (clean) datasets clearly is too academic and not realistic in real world applications (a finding that is also repeated at workshops on this topic and in literature, see e.g. <ref> [4] </ref>, [11]). Several experiences show that up to three quarters of the time might be used for transforming the data at hand in a format appropriate for learning and that this process has significant influence on the final generated models.
Reference: [5] <author> R. Engels, G. Lindner, and R. Studer, </author> <title> `A guided tour through the data mining jungle', </title> <booktitle> in Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining, </booktitle> <editor> ed., D.Pregibon D. Heckerman, H.Manilla, </editor> <address> Newport Beach, CA, August 14 -17, (1997). </address> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA. </address>
Reference-contexts: Support for data preprocessing is provided as part of a more general architecture for user support that is described in several papers (UGM approach: [3], <ref> [5] </ref>). As part of the project, the UGM approach is implemented on top of Clementine (ISL) and has the advantage that it supports generation of KDD processes besides docu-mention and reuse aspects of KDD projects. <p> is no high probability to find the joint distribution of the classes and attributes. 6 Conclusions Beginning with ideas from the knowledge acquisition field and statistical principles and guided by projects as MLT [1] and StatLOG [9] we finally came up with a framework for User Guidance Modelling (UGM: [3], <ref> [5] </ref>) that recollects a top down (problem definition etc.) and bottom up (data characteristics) process. The results of DCT are used for initiation or support of preprocessing of the data. Several techniques from the field of statistics as well as information theory are implemented in our UGM prototype.
Reference: [6] <author> D.J. </author> <title> Hand, `Deconstructing statistical questions', </title> <journal> Journal of the Royal Statistical Society, </journal> <pages> 317-356, </pages> <year> (1994). </year>
Reference-contexts: It was only natural that from such experiences and the fact that many algorithms are in principle applicable in various situations, the idea arose to partially automate the support of algorithm selection. Such an approach can also be found in statistics, as described in <ref> [6] </ref> and projects like StatLOG project [9], and the MLT-approach [1] where the CONSULTANT [2] played an advisory role. A very important contribution of that research is that it notifies the importance for a support in defining application processes where statistical and inductive techniques are involved.
Reference: [7] <author> N. Henze and Th. Wagner, </author> <title> `A new approach to the bhep tests for multivariate normality', </title> <journal> Journal of Multivariate Analysis, </journal> <volume> 62(1), </volume> <year> (1997). </year>
Reference-contexts: Another problem is that in the above mentioned case kurtosis and skewness tests do not deliver information on why the assumption of normal distribution is rejected. A robust test on normal distribution is provided by the BHEP-test 2 , and is for this purpose implemented 2 See <ref> [7] </ref> for a thorough description of the BHEP-test. Machine Learning and Data Mining 431 R. Engels and Ch. Theusinger in our system.
Reference: [8] <author> W.R. Klecka, </author> <title> `Discriminant analysis', Sage University Paper Series on Quantitive Applications in the Social Sciences, </title> <address> 07-019, (1980). Beverly Hills and London: </address> <publisher> Sage Pubns. </publisher>
Reference-contexts: Dispersion parameters that are calculated include standard deviation (sensitive to extreme values), quartiles deviation (less sensitive to extreme values) and median deviation. 3.2 Assumption Testing An appropriate technique for prediction of complexity of a domain and relevance of independent variables is discriminant analysis (see <ref> [8] </ref> for a good introduction). Discriminant Analysis has as one of its purposes to provide one or more mathematical equations in order to separate a data space. This set of equations can be used in order to classify as well.
Reference: [9] <editor> D. Michie, D.J. Spiegelhalter, and C.C. Taylor, </editor> <title> Machine Learning, Neural and Statistical Classification, </title> <publisher> Ellis Hor-wood, </publisher> <year> 1994. </year>
Reference-contexts: Such an approach can also be found in statistics, as described in [6] and projects like StatLOG project <ref> [9] </ref>, and the MLT-approach [1] where the CONSULTANT [2] played an advisory role. A very important contribution of that research is that it notifies the importance for a support in defining application processes where statistical and inductive techniques are involved. <p> When a large number of variables is symbolic one would rather concentrate on information theoretical characteristics (as in <ref> [9] </ref>). We concentrate on the opposite case, in which many independent variables are numeric. The next measurements that are calculated are location and dispersion parameters that are only computable as single dimensional measurements. <p> near zero values of the g-function as an indication for the fact that there is no high probability to find the joint distribution of the classes and attributes. 6 Conclusions Beginning with ideas from the knowledge acquisition field and statistical principles and guided by projects as MLT [1] and StatLOG <ref> [9] </ref> we finally came up with a framework for User Guidance Modelling (UGM: [3], [5]) that recollects a top down (problem definition etc.) and bottom up (data characteristics) process. The results of DCT are used for initiation or support of preprocessing of the data.
Reference: [10] <author> J. Stoer and R. </author> <title> Bulirsch, Numerische Mathematik 2, </title> <publisher> Springer Verlag, </publisher> <address> 3 edn., </address> <year> 1990. </year>
Reference-contexts: Since our restriction is that we aim at applying the chosen techniques on real world datasets, we have chosen the so called QR-algorithm <ref> [10] </ref>, since this algorithm is resistant against non symmetric covariance matrices, whereas other algorithms (like the JACOBI algorithm) are only able to calculate valid eigenvalue iff the covariance matrices are symmetric.
Reference: [11] <author> F. Verdenius, </author> <title> `Applications of inductive learning techniques: A survey in the netherlands', </title> <journal> AI communications, </journal> <volume> 10(1), </volume> <year> (1997). </year> <title> Machine Learning and Data Mining 434 R. Engels and Ch. </title> <publisher> Theusinger </publisher>
Reference-contexts: The setting in which algorithms are immediately tested on (clean) datasets clearly is too academic and not realistic in real world applications (a finding that is also repeated at workshops on this topic and in literature, see e.g. [4], <ref> [11] </ref>). Several experiences show that up to three quarters of the time might be used for transforming the data at hand in a format appropriate for learning and that this process has significant influence on the final generated models.
References-found: 11

