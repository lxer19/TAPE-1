URL: http://polaris.cs.uiuc.edu/reports/1465.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Scalable Shared-Memory Architectures Introduction to the Minitrack processors want to access memory, they want to
Author: Josep Torrellas 
Note: Unfortunately, not only do  the program  Another  from those of busses to crossbars.  
Date: 1 Background  [7, 1].  
Address: IL 61801, USA  
Affiliation: Center for Supercomputing Research and Development and Computer Science Department University of Illinois at Urbana-Champaign,  
Abstract: Shared-memory multiprocessing is emerging as a popular approach to increase computing power, over that of sequential computing, while maintaining programmability. What makes the base shared-memory paradigm attractive is the simplicity of the programming model: all memory is in a pool and is globally shared. Furthermore, architectures that do not require a broadcast channel for interprocessor communication can potentially scale to many processors and therefore provide large-scale computing power. Such systems are loosely termed "scalable". There are many hardware and software research issues in scalable shared-memory multiprocessors. One of the most important ones is how to handle the increasing speed mismatch between fast processors and slow, far-off memory systems. Indeed, data needs to be fetched and returned to memory, and the processor may have to remain idle during this transfer. This problem is partially eliminated with the presence of caches or local memories, which try to keep the working set close to the processor. Alternative or complementary approaches to caches are prefetch-ing [5, 9] and multithreading [2]. Prefetching consists of fetching instructions or data before they are needed while overlapping the accesses with other computation. Both hardware and software approaches are possible. Multithreading consists of switching processes when an instruction or memory access by a process would stall the processor. When the process is finally re-scheduled, the offending condition that forced the switch is likely to have disappeared. For example, if the offending condition is a remote memory read, the data is likely to be in the cache when the process is re-scheduled. While communication resulting from the sharing of data (also called true sharing) is unavoidable, other non-essential sources of communication slow the machine further. Such sources are false sharing [10] and process migration [11]. The former can appear when the unit of coherence is larger than a single word; the latter is often necessary if we want to keep the machine load-balanced. These are also active areas of research. In addition to the mostly hardware research issues that we mentioned, there are countless software issues that need to be explored in these architectures. Examples are task scheduling issues, operating systems issues, and many compiler/language issues. The shared-memory paradigm is attractive because it simplifies the development of complex software systems. For instance, there are several robust commercial multiprocessor operating systems and parallelizing compilers. Last, but not least, there is the active field of application design for these machines. Many of the efforts done by developers of applications for these machines result in feedback for the architecture and system designers. Overall, the field of scalable shared-memory architectures is one of the most exciting and vast areas 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Adve and M. Hill. </author> <title> Weak Ordering ANew Definition. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 1-13, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: There are many hardware solutions [3] (variations of directory-based schemes), compiler solutions [6], and operating system-based approaches [4]. Memory consistency models focus on how the overlapping of memory accesses from different processors to the same set of variables affects the sequence of operations seen by the program <ref> [7, 1] </ref>. While communication resulting from the sharing of data (also called true sharing) is unavoidable, other non-essential sources of communication slow the machine further. Such sources are false sharing [10] and process migration [11].
Reference: [2] <author> A. Agarwal. </author> <title> Performance Tradeoffs in Multithreaded Processors. </title> <journal> In IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> volume 3, </volume> <pages> pages 525-539, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: This problem is partially eliminated with the presence of caches or local memories, which try to keep the working set close to the processor. Alternative or complementary approaches to caches are prefetch-ing [5, 9] and multithreading <ref> [2] </ref>. Prefetching consists of fetching instructions or data before they are needed while overlapping the accesses with other computation. Both hardware and software approaches are possible. Multithreading consists of switching processes when an instruction or memory access by a process would stall the processor.
Reference: [3] <author> A. Agarwal, R. Simoni, J. Hennessy, and M. Horowitz. </author> <title> An Evaluation of Directory Schemes for Cache Coherence. </title> <booktitle> In Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 280-289, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: This gives rise to the synchronization problem [8]. Furthermore, given that, for performance reasons, data is usually allowed to replicate in the memory hierarchy, the popular problems of data coherence and memory consistency appear. Data coherence has been studied from many different angles. There are many hardware solutions <ref> [3] </ref> (variations of directory-based schemes), compiler solutions [6], and operating system-based approaches [4]. Memory consistency models focus on how the overlapping of memory accesses from different processors to the same set of variables affects the sequence of operations seen by the program [7, 1].
Reference: [4] <author> W. Bolosky, R. Fitzgerald, and M. Scott. </author> <title> Simple but Effective Techniques for NUMA Memory Management. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 19-31, </pages> <month> Decem-ber </month> <year> 1989. </year>
Reference-contexts: Data coherence has been studied from many different angles. There are many hardware solutions [3] (variations of directory-based schemes), compiler solutions [6], and operating system-based approaches <ref> [4] </ref>. Memory consistency models focus on how the overlapping of memory accesses from different processors to the same set of variables affects the sequence of operations seen by the program [7, 1].
Reference: [5] <author> T. F. Chen and J. L. Baer. </author> <title> A Performance Study of Software and Hardware Data Prefetching Schemes. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 223-232, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: This problem is partially eliminated with the presence of caches or local memories, which try to keep the working set close to the processor. Alternative or complementary approaches to caches are prefetch-ing <ref> [5, 9] </ref> and multithreading [2]. Prefetching consists of fetching instructions or data before they are needed while overlapping the accesses with other computation. Both hardware and software approaches are possible. Multithreading consists of switching processes when an instruction or memory access by a process would stall the processor.
Reference: [6] <author> H. Cheong and A. V. Veidenbaum. </author> <title> Compiler-Directed Cache Management in Multiprocessors. </title> <booktitle> In IEEE Computer, </booktitle> <pages> pages 39-47, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Furthermore, given that, for performance reasons, data is usually allowed to replicate in the memory hierarchy, the popular problems of data coherence and memory consistency appear. Data coherence has been studied from many different angles. There are many hardware solutions [3] (variations of directory-based schemes), compiler solutions <ref> [6] </ref>, and operating system-based approaches [4]. Memory consistency models focus on how the overlapping of memory accesses from different processors to the same set of variables affects the sequence of operations seen by the program [7, 1].
Reference: [7] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory Consistency and Event Ordering in Scalable Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: There are many hardware solutions [3] (variations of directory-based schemes), compiler solutions [6], and operating system-based approaches [4]. Memory consistency models focus on how the overlapping of memory accesses from different processors to the same set of variables affects the sequence of operations seen by the program <ref> [7, 1] </ref>. While communication resulting from the sharing of data (also called true sharing) is unavoidable, other non-essential sources of communication slow the machine further. Such sources are false sharing [10] and process migration [11].
Reference: [8] <author> J. R. Goodman, M. K. Vernon, and P. J. Woest. </author> <title> Efficient synchronization primitives for large-scale cache-coherent multiprocessors. </title> <booktitle> In Proceedings of the 3rd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 64-73, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Unfortunately, not only do processors want to access memory, they want to communicate with each other as well. This gives rise to the synchronization problem <ref> [8] </ref>. Furthermore, given that, for performance reasons, data is usually allowed to replicate in the memory hierarchy, the popular problems of data coherence and memory consistency appear. Data coherence has been studied from many different angles.
Reference: [9] <author> T. Mowry, M. Lam, and A. Gupta. </author> <title> Design and Evaluation of a Compiler Algorithm for Prefetching. </title> <booktitle> In Proceedings of the 5th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 62-73, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: This problem is partially eliminated with the presence of caches or local memories, which try to keep the working set close to the processor. Alternative or complementary approaches to caches are prefetch-ing <ref> [5, 9] </ref> and multithreading [2]. Prefetching consists of fetching instructions or data before they are needed while overlapping the accesses with other computation. Both hardware and software approaches are possible. Multithreading consists of switching processes when an instruction or memory access by a process would stall the processor.
Reference: [10] <author> J. Torrellas, M. S. Lam, and J. L. Hennessy. </author> <title> False Sharing and Spatial Locality in Multiprocessor Caches. </title> <journal> In IEEE Trans. on Computers, </journal> <pages> pages 651-663, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: While communication resulting from the sharing of data (also called true sharing) is unavoidable, other non-essential sources of communication slow the machine further. Such sources are false sharing <ref> [10] </ref> and process migration [11]. The former can appear when the unit of coherence is larger than a single word; the latter is often necessary if we want to keep the machine load-balanced. These are also active areas of research.
Reference: [11] <author> J. Torrellas, A. Tucker, and A. Gupta. </author> <title> Evaluating the Performance of Cache-Affinity Scheduling in Shared-Memory Multiprocessors. </title> <journal> In IEEE Transactions on Parallel and Distributed Systems. </journal> <note> To appear 1994. A short version appeared in ACM Sigmetrics 1993. </note>
Reference-contexts: While communication resulting from the sharing of data (also called true sharing) is unavoidable, other non-essential sources of communication slow the machine further. Such sources are false sharing [10] and process migration <ref> [11] </ref>. The former can appear when the unit of coherence is larger than a single word; the latter is often necessary if we want to keep the machine load-balanced. These are also active areas of research.
References-found: 11

