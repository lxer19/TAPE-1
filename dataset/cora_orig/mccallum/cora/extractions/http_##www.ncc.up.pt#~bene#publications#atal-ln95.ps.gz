URL: http://www.ncc.up.pt/~bene/publications/atal-ln95.ps.gz
Refering-URL: http://www.fe.up.pt/~eol/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Abstract: . 
Abstract-found: 1
Intro-found: 1
Reference: <institution> shared propositions local consistency shared propositions global consistency </institution>
Reference: 1. <author> M. Barbuceanu and M. S. Fox, </author> <title> The Architecture of an Agent Building Shell, </title> <booktitle> Intelligent Agents Volume II Proceedings of the 1995 Workshop on Agent Theories, Architectures, and Languages (ATAL-95), </booktitle> <editor> Edited by M. Wooldridge and J. P. Muller and M. Tambe, Springer-Verlag, </editor> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <year> 1996, </year> <note> In this volume. </note>
Reference-contexts: Within the DAI community different approaches to these questions have been developed. It is the case of <ref> [1] </ref> where a credibility/deniability model is used to perform conflict management, or [2], where agents engage in collaborative negotiations to solve their conflicting perspectives.
Reference: 2. <author> J. Chu-Caroll and S. Carberry, </author> <title> Conflict Detection and Resolution in Collaborative Planning, </title> <booktitle> Intelligent Agents Volume II Proceedings of the 1995 Workshop on Agent Theories, Architectures, and Languages (ATAL-95), </booktitle> <editor> Edited by M. Wooldridge and J. P. Muller and M. Tambe, Springer-Verlag, </editor> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <year> 1996, </year> <note> In this volume. </note>
Reference-contexts: Within the DAI community different approaches to these questions have been developed. It is the case of [1] where a credibility/deniability model is used to perform conflict management, or <ref> [2] </ref>, where agents engage in collaborative negotiations to solve their conflicting perspectives.
Reference: 3. <author> C. Beckstein, R. Fughe and G. Kraetzschmar, </author> <title> Supporting Assumption-Based Reasoning in a Distributed Environment, </title> <booktitle> Proceedings of the 12 International Workshop on Distributed Artificial Intelligence, </booktitle> <address> Hidden Valley, Pennsylvania, </address> <year> 1993. </year>
Reference-contexts: By communicating the already detected contradictions to all the relevant recipients the system avoids exploring invalid search space areas. Whenever agents detect inconsistent situations, they exchange the corresponding nogoods, if they believe the nogoods are relevant to each other <ref> [3] </ref>. So, every time a contradiction is detected by one agent it is thoroughly inspected to determine the set of agents to whom it may be relevant.
Reference: 4. <author> A. Callatay, </author> <booktitle> Natural and Artificial Intelligence, </booktitle> <publisher> North Holland, Elsevier Publishers, </publisher> <year> 1992. </year>
Reference-contexts: From the many challenging aspects that arise within this framework, a crucial one emerges: how to incorporate dynamic and conflicting agent beliefs? Since Aristotle, it has been known that man does not reason with absolute knowledge, but with beliefs <ref> [4] </ref>. Beliefs are dynamic and provide a crucial adaptative be-haviour to world changes. Intelligent systems that portray such human-like behaviour are called or .
Reference: 5. <author> M. R. Cravo and J. P. Martins, </author> <title> A Unified Approach to Default Reasoning and Belief Revision, </title> <booktitle> Proc. of the 6 Portuguese Conference on AI, EPIA93, Lecture Notes in Artificial Intelligence, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Implementing efficient systems that are capable of changing what they believe is addressed by belief revision systems <ref> [5] </ref>. From the belief revision point of view, a knowledge based system with belief revision capabilities, or simply, a belief revision system, has two main units: (i) the truth maintenance system (TMS) module and (ii) the problem solver unit.
Reference: 6. <author> E. Davis, </author> <title> Constraint Propagation with Interval Labels, </title> <journal> Artificial Intelligence, </journal> <volume> 32, </volume> <year> 1987. </year>
Reference-contexts: To prevent the inference process from searching a large or infinite space, it must generally give up some degree of completeness. The designer must manage this tradeoff so that the knowledge base produces useful information in reasonable time <ref> [6] </ref>. The agents' domain knowledge was divided into sub-domains of expertise. Each sub-domain corresponds to specific sets of rules. Dependencies between the rules of different sub-domains can occur. The necessary mapping between the sub-domains and the groups of rules is static, and is contained in the agents self models.
Reference: 7. <author> J. Doyle, </author> <title> A Truth Maintenance System, </title> <booktitle> Artificial Intelligence 12, </booktitle> <year> 1979. </year>
Reference-contexts: Typically, the problem solver/TMS relationship is a master/slave one. Two broad categories, single context TMSs and multiple context TMSs, result from two distinct ways of recording the dependencies between beliefs [13]: in justification based TMSs (JTMSs) each belief is associated with the beliefs that immediately caused it <ref> [7] </ref>; whereas in an assumption based TMS (ATMS) each belief is associated with the smallest sets of assumptions from which it can be deduced ( ) [8]. The ATMS only deals with propositions (usually substituted by arbitrary identifiers called nodes) and their dependencies.
Reference: 8. <author> J. de Kleer, </author> <title> An Assumption-based TMS, </title> <journal> Artificial Intelligence, </journal> <volume> 28 (2), </volume> <year> 1986. </year>
Reference-contexts: ways of recording the dependencies between beliefs [13]: in justification based TMSs (JTMSs) each belief is associated with the beliefs that immediately caused it [7]; whereas in an assumption based TMS (ATMS) each belief is associated with the smallest sets of assumptions from which it can be deduced ( ) <ref> [8] </ref>. The ATMS only deals with propositions (usually substituted by arbitrary identifiers called nodes) and their dependencies. For each proposition there will be a node and for each dependency a justification which describes how the node was inferred from other nodes.

Reference: 10. <author> B. Malheiro, N. Jennings and E. Oliveira, </author> <title> Belief Revision in Multi-Agent Systems, </title> <booktitle> Proc. of the 11 European Conference on Artificial Intelligence, </booktitle> <address> Amsterdam, Holland, </address> <year> 1994. </year>
Reference-contexts: new assumption node whenever the problem solver chooses to believe in a new proposition; (ii) create a new inferred node when the problem solver infers a new proposition; and (iii) add a new justification to an existing node whenever the problem solver finds a new way of inferring the node <ref> [10] </ref>. Upon the reception of a justification, the ATMS invokes a label updating algorithm that will assign a unique belief status to every node according to the justifications provided so far. <p> The former is implemented as an assumption based belief revision system and contains expertise on specific domains. The latter is the interface between the agent and the rest of the community and provides the necessary facilities for establishing, maintaining and monitoring cooperation <ref> [10] </ref>. Finally, an User Interface Agent was designed to provide the user/system interaction. The social activities are upheld by the inter-agent cooperation.
Reference: 11. <author> J. P. Martins, </author> <title> The Truth, The Whole Truth, and Nothing But The Truth, </title> <journal> AI Magazine, Special Issue, </journal> <year> 1990. </year>
Reference-contexts: To keep track of an agent's changing beliefs, researchers have devised a number of different types of Truth Maintenance Systems (TMS) <ref> [11] </ref>. Such ISEP, Rua de S. Tome, P-4200 Porto, Email: FEUP, Rua dos Bragas, P-4099 Porto CODEX, Email: Portugal Multi-agent architectures are well suited for complex inherently distributed problem solving domains.
Reference: 12. <author> C. Mason and R. Johnson, DATMS: </author> <title> A Framework for Distributed Assumption Based Reasoning, </title> <booktitle> in Distributed Artificial Intelligence Vol II, </booktitle> <editor> Edited by L. Gasser and M. N. Huhns, </editor> <year> 1989. </year>
Reference-contexts: In the first case the agents exhibit and , whilst in the second case there is only and [9]. Instead of adopting the standard communication of nodes plus their respective labels ([3], [9], <ref> [12] </ref>), our agents use a reduced data exchange format: nodes plus their associated belief status. In DiBeRT the consistency level of the shared propositions can be selected by the user at startup.
Reference: 13. <author> C. Mason, ROO: </author> <title> A Distributed AI Toolkit For Belief Based Reasoning Agents, </title> <booktitle> Proc. of the 2 International Working Conference on Cooperating Knowledge Based Systems, </booktitle> <address> Keele, UK, </address> <year> 1994. </year>
Reference-contexts: Typically, the problem solver/TMS relationship is a master/slave one. Two broad categories, single context TMSs and multiple context TMSs, result from two distinct ways of recording the dependencies between beliefs <ref> [13] </ref>: in justification based TMSs (JTMSs) each belief is associated with the beliefs that immediately caused it [7]; whereas in an assumption based TMS (ATMS) each belief is associated with the smallest sets of assumptions from which it can be deduced ( ) [8].
Reference: 14. <author> C. Mason, </author> <title> Introspection as Control in Result-Sharing Assumption-Based Reasoning Agents, </title> <booktitle> in Proc. of the 13 International DAI Workshop, </booktitle> <address> Seattle, USA, </address> <year> 1994. </year>
Reference-contexts: local consistency local well- foundedness local consistency private beliefs shared beliefs shared internal endogenous problem at hand is also decisive: while, in critical time response problems, direct message passing is adopted and communication is reduced to its minimum, since an arriving message may trigger a whole set of computations, in <ref> [14] </ref> it is shown how, in a specific domain problem, broadcasting can be an essential feature to achieve a better solution quality.
Reference: 15. <author> J. R. Searle, </author> <title> Speech Acts: An Essay in the Philosophy of Language, </title> <publisher> Cambridge University Press, </publisher> <year> 1969. </year>
Reference-contexts: Once the community has been launched the agents self and acquaintances models are kept static. This cooperation activity is supported through asynchronous selective communication (direct message passing). The used protocol is based on the speech act theory <ref> [15] </ref>. The path from the monolithic to the distributed framework has to be carefully undertaken. In a social context, issues like the desirable levels of consistency and the adequate amount of inter-agent communication have to be discussed prior to the implementation.
Reference: 16. <editor> T. Wittig (Editor), ARCHON: </editor> <title> An Architecture for Cooperative Multi-Agent Systems, </title> <publisher> Ellis Horwood, </publisher> <year> 1992. </year> <title> This article was processed using the LT E X macro package with LLNCS style </title>
Reference-contexts: The cooperation layer has the following components <ref> [16] </ref>: (i) a cooperation module responsible for engaging in cooperative actions; (ii) a communications module which sends/receives messages between the agents; (iii) a self model which represents information about the underlying domain level system; and (iv) an acquaintances model which represents the relevant information about the other community members with which
References-found: 16

