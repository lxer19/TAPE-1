URL: http://http.cs.berkeley.edu/~camillo/paperlinks/pami.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~camillo/
Root-URL: 
Title: Structure and Motion from Line Segments in Multiple Images  
Author: Camillo J. Taylor, David J. Kriegman 
Abstract: This paper presents a new method for recovering the three dimensional structure of a scene composed of straight line segments using the image data obtained from a moving camera. The recovery algorithm is formulated in terms of an objective function which measures the total squared distance in the image plane between the observed edge segments and the projections (perspective) of the reconstructed lines. This objective function is minimized with respect to the line parameters and the camera positions to obtain an estimate for the structure of the scene. The effectiveness of this approach is demonstrated quantitatively through extensive simulations and qualitatively with actual image sequences. The implementation is being made publicly available. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Ullman, </author> <title> The Interpretation of Visual Motion, </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1979. </year>
Reference: [2] <author> H.C. Longuet-Higgins, </author> <title> "A computer algorithm for reconstructing a scene from two projections", </title> <journal> Nature, </journal> <volume> vol. 293, </volume> <pages> pp. 133-135, </pages> <year> 1981. </year>
Reference: [3] <author> J. Weng, T.S. Huang, and N. Ahuja, </author> <title> "Motion and structure from two perspective views: Algorithms, error analysis, and error estimation", </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> vol. 11, no. 5, </volume> <pages> pp. 451-476, </pages> <month> May 89. </month>
Reference: [4] <author> X. Hu and N. Ahuja, </author> <title> "Motion and structure estimation using long sequence motion models", </title> <journal> Image and Vision Computing, </journal> <volume> vol. 11, no. 9, </volume> <pages> pp. 549-570, </pages> <month> November </month> <year> 1993. </year>
Reference: [5] <author> B.K.P. Horn, </author> <title> "Relative orientation", </title> <journal> Int. J. Computer Vision, </journal> <volume> vol. 4, </volume> <pages> pp. 59-78, </pages> <year> 1990. </year>
Reference-contexts: If this local minimum satisfies certain conditions it will be returned as the final answer, otherwise, the algorithm tries again with a new set of random initial estimates. This is the same technique that Horn employed to recover the relative orientation of two cameras from point correspondences <ref> [5] </ref>. The first stage of the global minimization process involves generating a set of random initial estimates for the camera orientations, R j .
Reference: [6] <author> J. Weng, T. S. Huang, and N. Ahuja, </author> <title> Motion and Structure from Image Sequences, </title> <booktitle> Springer Series on Information Sciences. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1993. </year>
Reference: [7] <author> James L. Crowley, Patrick Stelmaszyk, Thomas Skordas, and Pierre Puget, </author> <title> "Measurement and integration of 3-D structures by tracking edge lines", </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 8, no. 1, </volume> <pages> pp. 29-52, </pages> <month> July </month> <year> 1992. </year>
Reference: [8] <author> Olivier D. Faugeras, Francis Lustaman, and Giorgio Toscani, </author> <title> "Motion and structure from point and line matches", </title> <booktitle> in International Conference on Computer Vision, </booktitle> <month> June </month> <year> 1987, </year> <pages> pp. 25-33. </pages>
Reference-contexts: Although the projection of the recovered line onto the image plane has infinite extent, only the portion nearest to the observed image edge contributes to the error measure. This can be contrasted with other approaches where the observed edge is treated as though it were infinite <ref> [8] </ref>. It should also be noted that in this formulation of the error function, the contributions from various edges are explicitly weighted by their lengths, l. This is a desirable property since longer edges can be localized more accurately in the image than shorter ones. <p> The WLHA88 algorithm also requires a minimum of thirteen line correspondences in three frames while the TK93 algorithm only requires 6 line correspondences in three images to produce a result. This is the minimum number of correspondences required to solve this particular structure from motion problem <ref> [8] </ref>. VI. Conclusion This paper presented a novel algorithm for recovering the structure of a constellation of straight line features and the motion of an observer from a set of edge correspondences derived from an image sequence.
Reference: [9] <author> J. L. Jezouin and N. Ayache, </author> <title> "3d structure from a monocular sequence of images", </title> <booktitle> in International Conference on Computer Vision. IEEE, </booktitle> <month> December </month> <year> 1990, </year> <note> p. 441. </note>
Reference: [10] <author> T. Vieville and O. Faugeras, </author> <title> "Feed-forward recovery of motion and structure from a sequence of 2d-lines matches", </title> <booktitle> in International Conference on Computer Vision. IEEE, </booktitle> <month> December </month> <year> 1990, </year> <note> p. 517. </note>
Reference: [11] <author> Carlo Tomasi and Takeo Kanade, </author> <title> "Shape and motion from image streams under orthography: a factorization method", </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 137-154, </pages> <month> November </month> <year> 1992. </year>
Reference: [12] <author> Richard Szeliski and Sing Bing Kang, </author> <title> "Recovering 3D shape and motion from image streams using non-linear least squares", </title> <journal> Journal of Visual Communication and Image Representation, </journal> <volume> vol. 5, no. 1, </volume> <pages> pp. 10-28, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: On every iteration of the optimization algorithm, the objective function was minimized with respect to each set of parameters independently as described in [28] in order to reduce the computational complexity of the overall procedure. More recently, Szeliski and Kang <ref> [12] </ref> have published work which indicates that a more direct approach to the optimization problem can actually yield a performance improvement.
Reference: [13] <author> T. Vieville, </author> <title> "Estimation of 3d-motion and structure from tracking 2d-lines in a sequence of images", </title> <booktitle> in European Conference on Computer Vision, </booktitle> <month> April </month> <year> 1990, </year> <note> p. 281. </note>
Reference: [14] <author> B. Giai-Checa and T. Vieville, </author> <title> "3d-vision for active visual loops using locally rectilinear edges", </title> <booktitle> in Proceedings of the 1992 IEEE Int. Symp. on Intelligent Control, </booktitle> <month> August </month> <year> 1992, </year> <note> p. 341. </note>
Reference: [15] <author> Nassir Navab, Rachid Deriche, and Olivier D. Faugeras, </author> <title> "Recovering 3d motion and structure from stereo and 2d token tracking", </title> <booktitle> in International Conference on Computer Vision. IEEE, </booktitle> <month> December </month> <year> 1990, </year> <note> p. 513. </note>
Reference: [16] <author> J. Weng, Y. Liu, T. S. Huang, and N. Ahuja, </author> <title> "Estimating motion/structure from line correspondences: A robust linear algorithm and uniqueness theorems", </title> <booktitle> in Proc. IEEE Conf. on Comp. Vision and Patt. </booktitle> <address> Recog., </address> <year> 1988, </year> <pages> pp. 387-392. </pages>
Reference-contexts: These experiments qualitatively demonstrate that the method can be used to successfully reconstruct a variety of scenes. Section V presents the results from a series of simulation experiments that compare the proposed algorithm to the three frame linear method presented in <ref> [16] </ref>. A. Simulation Experiments In all of the simulation experiments a similar arrangement of camera positions and straight line features was used. The cameras were arranged in a circular stereo configuration as shown in Fig. 4. <p> Comparison with Linear Algorithm A series of simulation experiments were carried out in order to compare the algorithm presented in this paper to the three frame linear techniques proposed in <ref> [16] </ref>, [29], [17]. We chose to implement the algorithm described in [16] because it was considered to be one of the best linear structure from motion methods. These experiments simulated a trinocular stereo configuration viewing a set of three rotated cubes (a total of 36 line segments). <p> Comparison with Linear Algorithm A series of simulation experiments were carried out in order to compare the algorithm presented in this paper to the three frame linear techniques proposed in <ref> [16] </ref>, [29], [17]. We chose to implement the algorithm described in [16] because it was considered to be one of the best linear structure from motion methods. These experiments simulated a trinocular stereo configuration viewing a set of three rotated cubes (a total of 36 line segments). <p> One further improvement would be to explicitly satisfy the inequality constraints imposed by T-junctions as is done in Sugihara's work on line drawing interpretation [30]. Implementation: The implementation of this algorithm, our implementation of the algorithm presented in <ref> [16] </ref>, and the data sets used during our experiments are available for noncommercial use. They can be accessed via anonymous ftp at daneel.eng.yale.edu or by contacting either of the authors. Acknowledgments: We would like to thank P. Anandan for his contributions to this research.
Reference: [17] <author> M. E. Spetsakis and J. Aloimonos, </author> <title> "Structure from motion using line correspondences", </title> <journal> Int. J. Computer Vision, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 171-184, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Comparison with Linear Algorithm A series of simulation experiments were carried out in order to compare the algorithm presented in this paper to the three frame linear techniques proposed in [16], [29], <ref> [17] </ref>. We chose to implement the algorithm described in [16] because it was considered to be one of the best linear structure from motion methods. These experiments simulated a trinocular stereo configuration viewing a set of three rotated cubes (a total of 36 line segments).
Reference: [18] <author> Minas Spetsakis, </author> <title> "A linear algorithm for point and line based structure from motion", </title> <booktitle> CVGIP:Image Understanding, </booktitle> <volume> vol. 56, no. 2, </volume> <month> September </month> <year> 1992. </year>
Reference: [19] <author> Olivier Faugeras, </author> <title> Three-Dimensional Computer Vision, </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference: [20] <author> C.J. Taylor, D.J. Kriegman, and P. Anandan, </author> <title> "Structure and motion in two dimensions from multiple images: A least squares approach", </title> <booktitle> in IEEE Workshop on Visual Motion, </booktitle> <month> Oct. </month> <year> 1991, </year> <pages> pp. 242-248. </pages>
Reference-contexts: The final results produced after this stage are generally twice as accurate as the estimates provided by stage C. In an earlier version of this work <ref> [20] </ref> the unknown parameters were divided into two sets: the structural parameters ^ v i ; d i and the camera position parameters R j ; t j .
Reference: [21] <author> John Canny, </author> <title> "A computational approach to edge detection", </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <pages> pp. 679-98, </pages> <month> Nov. </month> <year> 1986. </year>
Reference-contexts: Images were digitized to 464 by 572 pixels using a CCD camera with an 8 mm lens. In each of these experiments the image edges were obtained using a variation of the Canny edge detector <ref> [21] </ref>. The line correspondences were determined manually, and initial estimates for the camera orientations were obtained by taking eyeball estimates. The intrinsic parameters (aspect ratio, camera center and quadratic radial distortion) of the camera system were obtained from a set of calibration images.
Reference: [22] <author> John Craig, </author> <title> Introduction to Robotics: Mechanics and Control, </title> <publisher> Addison-Wesley, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: the edge segment to the predicted edge, and are given by: h 1 = m 2 y m x x 2 + m y y 2 + m z q x + m 2 (5) 3 To represent the coordinates of a vector, we follow the notation established by Craig <ref> [22] </ref>; the leading superscript indicates the frame in which the coordinates are expressed.
Reference: [23] <author> G.H. Golub and C.F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> The Johns Hopkins University Press, </publisher> <year> 1983. </year>
Reference: [24] <author> Yuncan Liu, Thomas S. Huang, and O. D. Faugeras, </author> <title> "Determination of camera location from 2D to 3D line and point correspondences", </title> <booktitle> in Proc. IEEE Conf. on Comp. Vision and Patt. </booktitle> <address> Recog., </address> <year> 1988, </year> <pages> pp. 82-88. </pages>
Reference-contexts: Other researchers have used the constraints described in equations (8) and (9) to recover the position of an observer with respect to a known constellation of straight line features from image data. Liu, Huang and Faugeras <ref> [24] </ref> presented an algorithm that solves for the camera orientation first and then the camera translation. Kumar and Han-son [25] proposed a related technique that solves for the rotational and translational parameters simultaneously.
Reference: [25] <author> Rakesh Kumar and Allen R. Hanson, </author> <title> "Robust estimation of camera location and orientation from noisy data having outliers", </title> <booktitle> in Proceedings of the Workshop on the Interpretation of 3D Scenes, </booktitle> <month> November </month> <year> 1989, </year> <pages> pp. 52-60. </pages>
Reference-contexts: Liu, Huang and Faugeras [24] presented an algorithm that solves for the camera orientation first and then the camera translation. Kumar and Han-son <ref> [25] </ref> proposed a related technique that solves for the rotational and translational parameters simultaneously. In this case, these constraints are being used to estimate both the camera positions and the structure of the scene.
Reference: [26] <author> Camillo J. Taylor and David J. Kriegman, </author> <title> "Minimization on the lie group SO(3) and related manifolds", </title> <type> Tech. Rep. 9405, </type> <institution> Center for Systems Science, Dept. of Electrical Engineering, Yale University, </institution> <address> New Haven, CT, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: Once we have initial estimates for R j , ^ v i , ^ d i and t j , the main objective function O given in (1) can be minimized directly using the technique described in <ref> [26] </ref> to obtain the final estimate for the structure of the scene and the positions of the camera. This minimization involves a total of 4n+6 (m1)1 independent parameters. The optimization method used at this stage is very similar to the approach advanced by Steven Smith in his dissertation [27].
Reference: [27] <author> Steven Smith, </author> <title> Geometric Optimization Methods for Adaptive Filtering, </title> <type> PhD thesis, </type> <institution> Harvard University, Division of Applied Sciences, </institution> <address> Cambridge MA, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: This minimization involves a total of 4n+6 (m1)1 independent parameters. The optimization method used at this stage is very similar to the approach advanced by Steven Smith in his dissertation <ref> [27] </ref>. Smith showed how to carry out a version of the Newton minimization algorithm on Riemannian manifolds and proved that this method shared the quadratic convergence properties of its Euclidean counterpart. The final results produced after this stage are generally twice as accurate as the estimates provided by stage C.
Reference: [28] <author> Morris M. Thompson, </author> <title> Manual of Photogrammetry, </title> <journal> American Society of Photogrammetry, </journal> <year> 1966. </year>
Reference-contexts: On every iteration of the optimization algorithm, the objective function was minimized with respect to each set of parameters independently as described in <ref> [28] </ref> in order to reduce the computational complexity of the overall procedure. More recently, Szeliski and Kang [12] have published work which indicates that a more direct approach to the optimization problem can actually yield a performance improvement.
Reference: [29] <author> Yuncan Liu and Thomas S. Huang, </author> <title> "A linear algorithm for motion estimation using straight line correspondences", </title> <journal> Comp. Vision, Graphics, and Image Proc., </journal> <volume> vol. 44, no. 1, </volume> <pages> pp. 35-57, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Comparison with Linear Algorithm A series of simulation experiments were carried out in order to compare the algorithm presented in this paper to the three frame linear techniques proposed in [16], <ref> [29] </ref>, [17]. We chose to implement the algorithm described in [16] because it was considered to be one of the best linear structure from motion methods. These experiments simulated a trinocular stereo configuration viewing a set of three rotated cubes (a total of 36 line segments).

References-found: 29

