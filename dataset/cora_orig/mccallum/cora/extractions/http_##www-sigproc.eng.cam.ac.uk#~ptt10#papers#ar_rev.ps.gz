URL: http://www-sigproc.eng.cam.ac.uk/~ptt10/papers/ar_rev.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Signal Processing and Communications Reversible Jump Sampler for Autoregressive Time Series, Employing Full Conditionals to
Author: Paul T. Troughton and Simon J. Godsill 
Keyword: Markov chain Monte Carlo, reversible jump, autoregressive time series, model selection, Bayesian model averaging  
Note: A  Work supported by the Engineering and Physical Sciences Research Council  Correspondence to: Signal Processing and Communications  
Address: Cambridge  Paul Troughton Trumpington Street, Cambridge, CB2 1PZ, U.K.  
Affiliation: Department of Engineering, University of  Laboratory, Engineering Department,  
Pubnum: Laboratory  
Email: email: ptt10@cam.ac.uk  
Phone: Tel: [+44] 1223 3 32767 Fax: [+44] 1223 3 32662  
Web: http://www-sigproc.eng.cam.ac.uk/~ptt10  
Date: November 1997  
Abstract: Technical Report CUED/F-INFENG/TR. 304 We use reversible jump Markov chain Monte Carlo (MCMC) methods (Green 1995) to address the problem of model order uncertainty in au-toregressive (AR) time series within a Bayesian framework. Efficient model jumping is achieved by proposing model space moves from the full conditional density for the AR parameters, which is obtained analytically. This is compared with an alternative method, for which the moves are cheaper to compute, in which proposals are made only for the new parameters in each move. Results are presented for both synthetic and audio time series. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Besag, J. </author> <year> (1989). </year> <title> A candidate's formula | a curious result in Bayesian prediction. </title> <type> Biometrika 76(1) 183. </type>
Reference-contexts: T a I k 0 (19) e C T y [1:::k 0 ] (20) Rather than drawing a value of a (k 0 ) , then simply substituting equation (18) and the likelihood and priors into equation (17), which could lead to numerical problems, we can use the `Candidate's Identity' <ref> (Besag 1989) </ref>: p (k; a (k) j y; 2 e ) a ; 2 = p (k j y; 2 e ) (21) to simplify equation (17) in this case to: A (k; a (k) ) ! (k 0 ; a (k 0 ) ) = min 1; a ; 2
Reference: <author> Box, G. E. P., Jenkins, G. M. & Reinsel, G. C. </author> <year> (1994). </year> <title> Time Series Analysis: Forecasting and Control. </title> <publisher> Holden-Day 3rd edn. </publisher>
Reference-contexts: are formed by partitioning y into, respectively, the first k values and the remainder, and A and Y (k) take appropriate forms. 1 Poles are the inverse of the roots of the characteristic equation. 2.2 Prior distributions 3 Since the excitation sequence is Gaussian, the (approximate) likelihood takes the form <ref> (Box, Jenkins & Reinsel 1994, xA7.4) </ref>: p (y j k; a (k) ; 2 e ) (4) e I n e (5) e ) n e 2 2 e where n e is the length of e and y 1 . 2.2 Prior distributions We choose simple conjugate prior distributions for
Reference: <author> George, E. I. & McCulloch, R. E. </author> <year> (1993). </year> <title> Variable selection via Gibbs sampling. </title> <journal> Journal of the American Statistical Association 88(423) 881-889. </journal>
Reference-contexts: While Barbieri & O'Hagan (1996) also use reversible jump MCMC for AR model sampling, Barnett et al. (1996) and Huerta & West (1997) use stochastic search variable selection approaches, which avoid changing the dimension of the parameter vector by including all possible parameters at every iteration <ref> (George & McCulloch 1993) </ref>. 2 Modelling framework 2.1 Autoregressive time series model We model the signal fy t g as: y t = e t + i=1 (k) where e t ~ N e t j 0; 2 is the excitation sequence and a (k) is the AR parameter vector for
Reference: <author> Godsill, S. J. </author> <year> (1997). </year> <title> Some new relationships between MCMC model uncertainty methods and implications for the development of new methods. </title> <type> Tech. Rep. </type> <institution> CUED/F-INFENG/TR.305 Department of Engineering, University of Cambridge. </institution> <note> URL: http://www.sigproc.eng.cam.ac.uk/~sjg/papers/97/model.ps.gz Green, </note> <author> P. J. </author> <year> (1995). </year> <title> Reversible jump Markov chain Monte Carlo computation and Bayesian model determination. </title> <type> Biometrika 82(4) 711-732. </type>
Reference-contexts: the acceptance probability takes different forms for `birth' (k 0 &gt; k) and `death' (k 0 &lt; k) moves: 2 `Birth' move In this case, we are proposing a (k 0 ) = a (k) where a u are the n new parameters drawn from the full conditional posterior density <ref> (Troughton & Godsill 1997) </ref>: a u ~ q (a u j k 0 ; a (k) ; y; 2 e ) / N a u j a u ; C a u (26) where C 1 e Y (k 0 ) T u + 2 a u = 2 u y
Reference: <author> Hastings, W. K. </author> <year> (1970). </year> <title> Monte Carlo sampling methods using Markov chains and their applications. </title> <type> Biometrika 57(1) 97-109. </type>
Reference-contexts: for the parameters is then: p (k; a (k) ; 2 e j y) / p (y j k; a (k) ; 2 | -z - Likelihood p (k) p (a (k) j 2 a ) p ( 2 | -z - Priors (12) 3 Reversible jump MCMC Metropolis-Hastings algorithms <ref> (Hastings 1970) </ref> developed from molecular simulations as means to produce a Markov chain which converges to a required equilibrium distribution p (), without the need to sample directly from any inconvenient density. <p> Reversible jump MCMC (Green 1995) is a generalisation which introduces moves between parameter spaces of different dimensionality, whilst retaining detailed balance <ref> (Hastings 1970) </ref>, which is required for convergence, within each type of move.
Reference: <author> Huerta, G. & West, M. </author> <year> (1997). </year> <title> Priors and component structures in autoregressive time series models. </title> <type> Tech. rep. </type> <institution> Institute of Statistics & Decision Sciences, Duke University. </institution>
Reference-contexts: Previous work on MCMC autoregressive model selection has parameterised the model using partial correlation coefficients (Barnett, Kohn & Sheather 1996, Barbieri & O'Hagan 1996) or pole positions 1 <ref> (Huerta & West 1997) </ref>. These have a simple physical interpretation for certain types of signal, and allow stationarity to be enforced in a straightforward manner. We use the AR parameters, a, directly.
Reference: <author> Johnson, N. L. & Kotz, S. </author> <year> (1970). </year> <title> Distributions in Statistics: Continuous Univariate Distributions. </title> <publisher> Wiley. </publisher>
Reference: <author> Stark, J. A., Fitzgerald, W. J. & Hladky, S. B. </author> <year> (1997). </year> <title> Multiple-order Markov chain Monte Carlo sampling methods with application to a changepoint model. </title> <type> Tech. Rep. </type> <institution> CUED/F-INFENG/TR.302 Department of Engineering, University of Cambridge. </institution>
Reference: <author> Troughton, P. T. & Godsill, S. J. </author> <year> (1997). </year> <title> Bayesian model selection for time series using Markov chain Monte Carlo. </title> <booktitle> Proceedings of IEEE ICASSP-97 V 3733-3736. </booktitle>
Reference-contexts: the acceptance probability takes different forms for `birth' (k 0 &gt; k) and `death' (k 0 &lt; k) moves: 2 `Birth' move In this case, we are proposing a (k 0 ) = a (k) where a u are the n new parameters drawn from the full conditional posterior density <ref> (Troughton & Godsill 1997) </ref>: a u ~ q (a u j k 0 ; a (k) ; y; 2 e ) / N a u j a u ; C a u (26) where C 1 e Y (k 0 ) T u + 2 a u = 2 u y
References-found: 9

