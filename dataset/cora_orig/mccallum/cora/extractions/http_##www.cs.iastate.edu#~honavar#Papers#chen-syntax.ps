URL: http://www.cs.iastate.edu/~honavar/Papers/chen-syntax.ps
Refering-URL: http://www.cs.iastate.edu/~honavar/honavar.html
Root-URL: 
Email: chen@cs.iastate.edu, honavar@cs.iastate.edu  
Title: A Neural Network Architecture for Syntax Analysis  
Author: Chun-Hsien Chen Vasant Honavar 
Address: Ames, Iowa 50011-1040 U.S.A  
Affiliation: Artificial Intelligence Research Group Department of Computer Science Iowa State University  
Abstract-found: 0
Intro-found: 1
Reference: <author> Aho, A. V., Sethi, R. and Ullman, J. D., </author> <booktitle> Compilers: Principles, techniques, and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference: <author> Aho, A. V. and Ullman, J. D., </author> <title> Principles of Compiler Design, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1977. </year>
Reference: <author> Allen, R. B., </author> <title> Connectionist Language Users, </title> <journal> Connection Science, </journal> <volume> vol. 2, no. 4, </volume> <editor> p. </editor> <volume> 279, </volume> <year> 1990. </year>
Reference: <author> Arbib, M., </author> <title> Schema Theory: Cooperative Computation for Brain Theory and Distributed AI, in Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, Honavar, </title> <editor> V. and Uhr, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 51-74, </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year> <note> 49 Berg, </note> <author> G., </author> <title> A Connectionist Parser with Recursive Sentence Structure and Lexical Disambiguation, </title> <booktitle> Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 32-37, </pages> <publisher> MIT Press, </publisher> <address> Massachusetts, </address> <year> 1992. </year>
Reference: <author> Bookman, L. A., </author> <title> A Framework for Integrating Relational and Associational Knowledge for Comprehension, in Computational Architectures Integrating Neural and Symbolic Processes : A Perspective on the State of the Art, Sun, </title> <editor> R. and Bookman, L. (Ed.), </editor> <volume> Chapter 9, </volume> <pages> pp. 283-318, </pages> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1995. </year>
Reference: <author> Chapman, N. P., </author> <title> LR Parsing : Theory and Practice, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1987. </year>
Reference: <author> Chen, C. and Honavar, V., </author> <title> Neural Network Automata, </title> <booktitle> Proceedings of World Congress on Neural Networks, </booktitle> <volume> vol. 4, </volume> <pages> pp. 470-477, </pages> <address> San Diego, CA, </address> <month> June </month> <year> 1994. </year>
Reference: <author> Chen, C. and Honavar, V., </author> <title> A Neural Architecture for Content as well as Address-Based Storage and Recall: </title> <journal> Theory and Applications, Connection Science, </journal> <volume> vol. 7, no. 3 & 4, </volume> <pages> pp. 281-300, </pages> <year> 1995. </year>
Reference: <author> Chen, C. and Honavar, V., </author> <title> A Neural Network Architecture for High-Speed Database Query Processing System, </title> <journal> Microcomputer Applications, </journal> <volume> vol. 15, no. 1, </volume> <pages> pp. 7-13, </pages> <year> 1996. </year>
Reference: <author> Das, S., Giles, C. L. and Sun, G. Z., </author> <title> Using Prior Knowledge in a NNDPA to Learn Context-Free Languages, </title> <booktitle> in Advances in Neural Information Processing Systems 5, </booktitle> <editor> Hanson, S. J., Cowan, J. D. and Giles, C. L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 65-72, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: <author> Dolan, C. P. and Smolensky, P., </author> <title> Tensor Product Production System: A Modular Architecture and Representation, </title> <journal> Connection Science, </journal> <volume> 1, </volume> <pages> pp. 53-58, </pages> <year> 1989. </year>
Reference: <author> Dyer, M. G., </author> <title> Connectionist Natural Language Processing: A Status Report, in Computational Architectures Integrating Neural and Symbolic Processes : A Perspective on the State of the Art, Sun, </title> <editor> R. and Bookman, L. (Ed.), </editor> <volume> Chapter 12, </volume> <pages> pp. 389-429, </pages> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1995. </year>
Reference: <author> Elman, J. L., </author> <title> Finding Structure in Time, </title> <journal> Cognitive Science, </journal> <volume> vol. 14., </volume> <pages> pp. 179-211, </pages> <year> 1990. </year>
Reference: <author> Fanty, M. A., </author> <title> Context-free Parsing with Connectionist Networks, </title> <booktitle> Proceedings of AIP Neural Networks for Computing, Conference No. </booktitle> <volume> 151, </volume> <pages> pp. 140-145, </pages> <address> Snowbird, UT, </address> <year> 1986. </year>
Reference: <author> Frasconi, P., Gori, M., Maggini, M. and Soda, G., </author> <title> Unified Integration of Explicit Rules and Learning by Example in Recurrent Networks, </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <year> 1993. </year>
Reference: <author> Giles, C. L., Horne, B. W. and Lin, T., </author> <title> Learning a Class of Large Finite State Machines With a Recurrent Neural Network, </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 8, no. 9, </volume> <pages> pp. 1359-1365, </pages> <year> 1995. </year>
Reference: <author> Giles, C. L., Miller, C. B., Chen, D., Sun, G. Z. and Lee, Y. C., </author> <title> Learning and Extracting Finite State Automata with Second-Order Recurrent Neural Networks, </title> <journal> Neural Computation, </journal> <volume> vol. 4., no. 3., </volume> <editor> p. </editor> <volume> 380, </volume> <year> 1992. </year>
Reference: <author> Goldfarb, L. and Nigam, S., </author> <title> The Unified Learning Paradigm: A Foundation for AI, in Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, Honavar, </title> <editor> V. and Uhr, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 533-559, </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference: <editor> Goonatilake, S. and Khebbal, S. (Ed.), </editor> <title> Intelligent Hybrid Systems, </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1995. </year>
Reference: <author> Gowda, S. M. et al., </author> <title> Design and Characterization of Analog VLSI Neural Network Modules, </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 28, no. 3, </volume> <pages> pp. 301-313, </pages> <year> 1993. </year>
Reference: <author> Graf, H. P. and Henderson, D., </author> <title> A Reconfigurable CMOS Neural Network, </title> <booktitle> ISSCC Dig. Tech. Papers, </booktitle> <pages> pp. 144-145, </pages> <address> San Francisco, CA, </address> <year> 1990. </year>
Reference: <author> Grant, D. et al., </author> <title> Design, Implementation and Evaluation of a High-Speed Integrated Hamming Neural Classifier, </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 29, no. 9, </volume> <pages> pp. 1154-1157, </pages> <month> September </month> <year> 1994. </year>
Reference: <author> Grosspietsch, K. E., </author> <title> Intelligent Systems by Means of Associative Processing, in Fuzzy, Holographic, </title> <booktitle> and Parallel Intelligence, Soucek, B. and the IRIS Group (Ed.), </booktitle> <pages> pp. 179-214, </pages> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1992. </year> <note> 51 Gupta, </note> <author> A., </author> <title> Parallelism in Production Systems, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie--Mellon University, Pittsburgh, </institution> <month> March </month> <year> 1986. </year>
Reference: <author> Hamilton, A. et al., </author> <title> Integrated Pulse Stream Neural Networks: Results, Issues, and Pointers, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 385-393, </pages> <month> May </month> <year> 1992. </year>
Reference: <author> Hassoun, M., </author> <title> Fundamentals of Artificial Neural Networks, </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1995. </year>
Reference: <editor> Hendler, J., </editor> <booktitle> Beyond the Fifth Generation: Parallel AI Research in Japan, IEEE Expert, </booktitle> <pages> pp. 2-7, </pages> <month> Feb. </month> <year> 1994. </year>
Reference: <author> Hester, K. A. et al., </author> <title> The Predictive RAAM: A RAAM That Can Learn to Distinguish Sequences from a Continuous Input Stream, </title> <booktitle> Proceedings of World Congress on Neural Networks, </booktitle> <volume> vol. 4, </volume> <pages> pp. 97-103, </pages> <address> San Diego, CA, </address> <month> June </month> <year> 1994. </year>
Reference: <author> Hinton, G. E., </author> <title> Implementing Semantic Networks in Parallel Hardware, in Parallel Models of Associative Memory, </title> <editor> Hinton, G. E. and Anderson, </editor> <publisher> J. </publisher>
Reference: <editor> A. (updated Ed.), </editor> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1989. </year>
Reference: <author> Honavar, V., </author> <title> Toward Learning Systems That Integrate Different Strategies and Representations, in Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, Honavar, </title> <editor> V. and Uhr, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 615-644, </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference: <author> Honavar, V., </author> <title> Symbolic Artificial Intelligence and Numeric Artificial Neural Networks: Toward A Resolution of the Dichotomy, in Computational Architectures Integrating Symbolic and Neural Processes, Sun, </title> <editor> R. and Bookman, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 351-388, </pages> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1995. </year>
Reference: <author> Honavar, V. and Uhr, L., </author> <title> Coordination and Control structures and Processes: Possibilities for Connectionist Networks, </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence 2: </journal> <pages> 277-302, </pages> <year> 1990. </year>
Reference: <author> Honavar, V. and Uhr, L. (Ed.), </author> <title> Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, </title> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference: <author> Honavar, V. and Uhr, L., </author> <title> Integrating Symbol Processing Systems and Con--nectionist Networks, in Intelligent Hybrid Systems, </title> <editor> Goonatilake, S. and Khebbal, S. </editor> <publisher> (Ed.), </publisher> <pages> pp. 177-208, </pages> <publisher> Wiley, </publisher> <address> London, </address> <year> 1995. </year>
Reference: <author> Hopcroft, J. E. and Ullman, J. D., </author> <title> Introduction to Automata Theory, Languages, and Computation, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1979. </year>
Reference: <author> Horne, B., Hush, D. R. and Abdallah, C., </author> <title> The State Space Recurrent Neural Network with Application to Regular Grammatical Inference, </title> <type> UNM Tech. Rep. </type> <institution> No. EECE 92-002, Department of Electrical and Computer Engineering, University of New Mexico, </institution> <address> Albuquerque, NM, </address> <year> 1992. </year>
Reference: <author> Howe, D. B. and Asanovic, K., </author> <title> SPACE: </title> <booktitle> Symbolic Processing in Associative Computing Elements, in VLSI for Neural Networks and Artificial Intelligence, </booktitle> <editor> Delgado-Frias, J. G. </editor> <publisher> (Ed.), </publisher> <pages> pp. 243-252, </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <note> 1994 Jain, </note> <author> A. N., Waibel, A. and Touretzky, D. S., </author> <title> PARSEC: A Structured Connectionist Parsing System for Spoken Language, </title> <booktitle> IEEE Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pp. 205-208, </pages> <address> San Francisco, CA, </address> <month> March </month> <year> 1992. </year>
Reference: <author> Kleene, S. C., </author> <title> Representation of Events in Nerve Nets and Finite Automata, in Automata Studies, </title> <editor> Shannon, C. E. and McCarthy, J. </editor> <publisher> (Ed.), </publisher> <pages> pp. 3-42, </pages> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1956. </year>
Reference: <author> Kogge, P., Oldfield, J., Brule, M. and Stormon, C., </author> <title> VLSI and Rule-based Systems, </title> <booktitle> in VLSI for Artificial Intelligence, </booktitle> <editor> Delgado-Frias, J. G. and Moore, W. R. </editor> <publisher> (Ed.), </publisher> <pages> pp. 95-108, </pages> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1989. </year>
Reference: <author> Kumar, R., NCMOS: </author> <title> A High Performance CMOS Logic, </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 29, no. 5, </volume> <pages> pp. 631-633, </pages> <year> 1994. </year>
Reference: <author> Lacher, R. C. and Nguyen, K. D., </author> <title> Hierarchical Architectures for Reasoning, in Computational Architectures Integrating Neural and Symbolic Processes : A Perspective on the State of the Art, Sun, </title> <editor> R. and Bookman, L. (Ed.), </editor> <volume> Chapter 4, </volume> <pages> pp. 117-150, </pages> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1995. </year>
Reference: <author> Langley, P., </author> <title> Elements of Machine Learning, </title> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, CA, </address> <year> 1995. </year>
Reference: <author> Lavington, S. H., Wang, C. J., Kasabov, N. and Lin, S., </author> <title> Hardware Support for Data Parallelism in Production Systems, </title> <booktitle> in VLSI for Neural Networks and Artificial Intelligence, </booktitle> <editor> Delgado-Frias, J. G. </editor> <publisher> (Ed.), </publisher> <pages> pp. 231-242, </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1994. </year>
Reference: <author> Levine, D. and Aparicio IV, M. (Ed.), </author> <title> Neural Networks for Knowledge Representation and Inference, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1994. </year>
Reference: <author> Lont, J. B. and Guggenbuhl, W., </author> <title> Analog CMOS Implementation of a Multilayer Perceptron with Nonlinear Synapses, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 457-465, </pages> <year> 1992. </year>
Reference: <author> Lu, F. and Samueli, H., </author> <title> A 200-MHz CMOS Pipelined Multiplier-Accumulator Using a Quasi-Domino Dynamic Full-Adder Cell Design, </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 28, no. 2, </volume> <pages> pp. 123-132, </pages> <year> 1993. </year>
Reference: <author> MacLennan, B. J., </author> <booktitle> Principles of Programming Languages : Design, Evaluation, and Implementation, 2nd edition, </booktitle> <address> CBS College Publishing, New York, NY, </address> <year> 1987. </year>
Reference: <author> Masa, P., Hoen, K. and Wallinga, H., </author> <title> 70 Input, 20 Nanosecond Pattern Classifier, </title> <booktitle> IEEE International Joint Conference on Neural Networks, </booktitle> <volume> vol. </volume> <pages> 3, </pages> <address> Orlando, FL, </address> <year> 1994. </year>
Reference: <author> Massengill, L. W. and Mundie, D. B., </author> <title> An Analog Neural Network Hardware Implementation Using Charge-Injection Multipliers and Neuron-Specific Gain Control, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 354-362, </pages> <month> May </month> <year> 1992. </year>
Reference: <author> McCulloch, W. S. and Pitts, W., </author> <title> A Logical Calculus of Ideas Immanent in Nervous Activity, </title> <journal> Bulletin of Mathematical Biophysics, </journal> <volume> vol. 5, </volume> <pages> pp. 115-133, </pages> <year> 1943. </year>
Reference: <author> McGregor, D., McInnes, S. and Henning, M., </author> <title> An Architecture for Associative Processing of Large Knowledge Bases (LKBs), </title> <journal> Computer Journal, </journal> <volume> vol. 30, no. 5, </volume> <pages> pp. 404-412, </pages> <month> October </month> <year> 1987. </year> <note> 54 Miclet, </note> <author> L., </author> <title> Structural Methods in Pattern Recognition, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986. </year> <title> Miikkulainen, R, Subsymbolic Parsing of Embedded Structures, in Computational Architectures Integrating Neural and Symbolic Processes : A Perspective on the State of the Art, Sun, </title> <editor> R. and Bookman, L. (Ed.), </editor> <volume> Chapter 5, </volume> <pages> pp. 153-186, </pages> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1995. </year>
Reference: <author> Minsky, M., </author> <title> Computation: Finite and Infinite Machines, </title> <publisher> Prentice Hall, </publisher> <address> En-glewood Cliffs, NJ, </address> <year> 1967. </year>
Reference: <author> Minsky, M. and Papert, S., </author> <title> Perceptrons: An Introduction to Computational Geometry, </title> <publisher> MIT Press, </publisher> <address> Massachusetts, </address> <year> 1969. </year>
Reference: <author> Mjolsness, E., </author> <title> Connectionist Grammars for High-Level Vision, in Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, Honavar, </title> <editor> V. and Uhr, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 423-451, </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference: <author> Moon, G. et al., </author> <title> VLSI Implementation of Synaptic Weighting and Summing in Pulse Coded Neural-Type Cells, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 394-403, </pages> <month> May </month> <year> 1992. </year>
Reference: <author> Mozer, M. C. and Bachrach, J., </author> <title> Discovering the Structure of a Reactive Environment by Exploration, </title> <journal> Neural Computation, </journal> <volume> vol. 2., no. 4., </volume> <editor> p. </editor> <volume> 447, </volume> <year> 1990. </year>
Reference: <author> Mozer, M. C. and Das, S., </author> <title> A Connectionist Symbol Manipulator that Discovers the Structure of Context-Free Languages, </title> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <address> p. 863, </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: <author> Naganuma, J., Ogura, T., Yamada, S. I. and Kimura, T., </author> <title> High-Speed CAM-Based Architecture for a Prolog Machine (ASCA), </title> <journal> IEEE transactions on Computers, </journal> <volume> vol. 37, no. 11, </volume> <pages> pp. 1375-1383, </pages> <month> November </month> <year> 1988. </year>
Reference: <author> Ng, Y. H., Glover, R. J. and Chng, C. L., </author> <title> Unify with active Memory, </title> <booktitle> in VLSI for Artificial Intelligence, </booktitle> <editor> Delgado-Frias, J. G. and Moore, W. R. </editor> <publisher> (Ed.), </publisher> <pages> pp. 109-118, </pages> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1989. </year> <note> 55 Noda, </note> <author> I. and Nagao, M., </author> <title> A Learning Method for Recurrent Neural Networks Based on Minimization of Finite Automata, </title> <booktitle> Proceedings of International Joint Conference on Neural Networks, </booktitle> <volume> vol. 1, </volume> <pages> pp. 27-32, </pages> <publisher> IEEE Press, </publisher> <address> Piscataway, NJ, </address> <year> 1992. </year>
Reference: <author> Norman, D. A., </author> <title> Reflections on Cognition and Parallel Distributed Processing, in Parallel Distributed Processing, </title> <editor> McClelland, J., Rumelhard, D. and the PDP Research Group (Ed.), </editor> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference: <author> Omlin, C. and Giles, C. L., </author> <title> Extraction and Insertion of Symbolic Information in Recurrent Neural Networks, in Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, Honavar, </title> <editor> V. and Uhr, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 271-299, </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference: <author> Omlin, C. and Giles, C. L., </author> <title> Stable Encoding of Large Finite-State Automata in Recurrent Neural Networks with Sigmoid Discriminants, </title> <journal> Neural Computation, </journal> <volume> vol. 8, no. 4, </volume> <pages> pp. 675-696, </pages> <month> May </month> <year> 1996. </year>
Reference: <author> Parekh, R. G. and Honavar, V., </author> <title> Automata Induction, Grammar Inference, and Language Acquisition, </title> <booktitle> in Handbook of Natural Language Processing, </booktitle> <editor> Moisl, H., Dale, R. and Somers, H. (Ed.), </editor> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1997a. </year>
Reference: <author> Parekh, R. G., Nichitiu, C., and Honavar, V., </author> <title> A Polynomial Time Incremental Algorithm for Regular Grammar Inference, </title> <type> Technical Report ISU-CS-TR 97-03, </type> <institution> Department of Computer Science, Iowa State University, </institution> <year> 1997. </year>
Reference: <author> Parekh, R. G. and Honavar, V., </author> <title> Learning Regular Languages from Simple Examples, </title> <type> Technical Report ISU-CS-TR 97-06, </type> <institution> Department of Computer Science, Iowa State University, </institution> <year> 1997b. </year>
Reference: <author> Peter, R., </author> <title> Recursive Functions in Computer Theory, </title> <publisher> Halsted Press, </publisher> <address> New York, </address> <year> 1981. </year>
Reference: <author> Pinkas, G., </author> <title> A Fault-Tolerant Connectionist Architecture for Construction of Logic Proofs, in Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, Honavar, </title> <editor> V. and Uhr, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 321-340, </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year> <note> 56 Pollack, </note> <author> J. B., </author> <title> On Connectionist Models of Language Processing, </title> <type> Ph.D. </type> <institution> Dis--sertation, Computer Science Department, University of Illinois, Urbana-Champaign, IL, </institution> <year> 1987. </year>
Reference: <author> Pollack, J. B., </author> <title> Recursive Distributed Representations, </title> <booktitle> Artificial Intelligence 46, </booktitle> <pages> pp. 77-105, </pages> <year> 1990. </year>
Reference: <author> Popescu, I., </author> <title> Hierarchical Neural Networks for Rules Control in Knowledge-Based Expert Systems, </title> <booktitle> Neural, Parallel & Scientific Computations 3, </booktitle> <pages> pp. 379-392, </pages> <year> 1995. </year>
Reference: <author> Ripley, B. D., </author> <title> Pattern Recognition and Neural Networks, </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1996. </year>
Reference: <author> Robinson, I., </author> <title> The Pattern Addressable Memory: Hardware for Associative Processing, </title> <booktitle> in VLSI for Artificial Intelligence, </booktitle> <editor> Delgado-Frias, J. G. and Moore, W. R. </editor> <publisher> (Ed.), </publisher> <pages> pp. 119-129, </pages> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1989. </year>
Reference: <author> Robinson, M. E. et al., </author> <title> A Modular CMOS Design of a Hamming Network, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 444-456, </pages> <year> 1992. </year>
Reference: <author> Rodohan, D. and Glover, R., </author> <title> A Distributed Parallel Associative Processor (DPAP) for the Execution of Logic Programs, </title> <booktitle> in VLSI for Neural Networks and Artificial Intelligence, </booktitle> <editor> Delgado-Frias, J. G. </editor> <publisher> (Ed.), </publisher> <pages> pp. 265-273, </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <note> 1994 Rogers, </note> <author> Jr., H., </author> <title> Theory of Recursive Functions and Effective Computability, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference: <author> Sanfeliu, A. and Alquezar, R., </author> <title> Understanding Neural Networks for Grammatical Inference and Recognition, in Advances in Structural and Syntactic Pattern Recognition, Bunke, </title> <editor> H. (Ed.), </editor> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1992. </year>
Reference: <author> Schneider, W., </author> <title> Connectionism: Is it a Paradigm Shift for Psychology?, Behavior Research Methods, Instruments, </title> <journal> and Computers, </journal> <volume> 19, </volume> <pages> pp. 73-83, </pages> <year> 1987. </year>
Reference: <author> Schulenburg, D., </author> <title> Sentence Processing with Realistic Feedback, </title> <booktitle> IEEE/INNS International Joint Conference on Neural Networks, </booktitle> <volume> vol. IV, </volume> <pages> pp. 661-666, </pages> <address> Baltimore, MD, </address> <year> 1992. </year> <note> 57 Selman, </note> <author> B. and Hirst, G., </author> <title> A Rule-based Connectionist Parsing System, </title> <booktitle> Pro--ceedings of the Seventh Annual Conference of the Cognitive Science Society, </booktitle> <address> Irvine, CA, </address> <year> 1985. </year>
Reference: <author> Sequin, C. H. and Clay, R. D., </author> <title> Fault Tolerance in Artificial Neural Networks, </title> <booktitle> Proc. IJCNN, </booktitle> <volume> vol. 1, </volume> <pages> pp. 703-708, </pages> <address> San Diego, </address> <year> 1990. </year>
Reference: <author> Servan-Schreiber, D., Cleeremans, A. and McClelland, J. L., </author> <title> Graded State Machines: The Representation of Temporal Contingencies in Simple Recurrent Neural Networks, in Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, Honavar, </title> <editor> V. and Uhr, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 241-269, </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference: <author> Shastri, L. and Ajjanagadde, V., </author> <title> Connectionist System for Rule Based Reasoning with Multi-Place Predicates and Variables, </title> <type> Tech. Rep. </type> <institution> MS-CIS-8906, Computer and Information Science Dept., University of Pennsyl-vania, </institution> <address> Philadelphia, PA, </address> <year> 1989. </year>
Reference: <author> Shavlik, J. W., </author> <title> A Framework for Combining Symbolic and Neural Learning, in Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, Honavar, </title> <editor> V. and Uhr, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 561-580, </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference: <author> Siegelman, H. T. and Sontag, E. D., </author> <title> Turing-Computability with Neural Nets, </title> <journal> Applied Mathematics Letters, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 77-80, </pages> <year> 1991. </year>
Reference: <author> Sippu, S. and Soisalon-Soininen, E., </author> <title> Parsing Theory, vol. II : LR(k) nad LL(k) Parsing, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference: <author> Soucek, B. </author> <title> and the IRIS Group (Ed.), </title> <booktitle> Neural and Intelligent Systems Integrations: Fifth and Sixth Generation Integrated Reasoning Information Systems, </booktitle> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1991. </year>
Reference: <author> Sun, G. Z., Giles, C. L., Chen, H. H. and Lee, Y. C., </author> <title> The Neural Network Pushdown Automation: Model, Stack and Learning Simulations, </title> <institution> UMIA CS-TR-93-77, University of Maryland, College Park, MD, </institution> <month> August </month> <year> 1993. </year>
Reference: <author> Sun, R., </author> <title> Logics and Variables in Connectionist Models: A Brief Overview, in Artificial Intelligence and Neural Networks: Steps Toward Principled 58 Integration, Honavar, </title> <editor> V. and Uhr, L. </editor> <publisher> (Ed.), </publisher> <pages> pp. 301-320, </pages> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference: <author> Sun, R. and Bookman, L. (Ed.), </author> <title> Computational Architectures Integrating Symbolic and Neural Processes, </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1995. </year>
Reference: <author> Swaminathan, G., Srinivasan, S., Mitra, S., Minnix, J., Johnson, B. and I~nigo, R., </author> <title> Fault Tolerance of Neural Networks, </title> <booktitle> Proc. of IJCNN, </booktitle> <volume> vol 2, </volume> <pages> pp. 699-702, </pages> <address> Washington DC, </address> <year> 1990. </year>
Reference: <author> Thurber, K. J. and Wald, L. D., </author> <title> Associative and Parallel Processors, </title> <journal> Computing Surveys, </journal> <volume> vol. 7, no. 4, </volume> <pages> pp. 215-255, </pages> <year> 1975. </year>
Reference: <author> Uchimura, K. et al., </author> <title> An 8G Connection-per-second 54mW Digital Neural Network with Low-power Chain-Reaction Architecture, </title> <booktitle> ISSCC Dig. Tech. Papers, </booktitle> <pages> pp. 134-135, </pages> <address> San Francisco, CA, </address> <year> 1992. </year>
Reference: <author> Uhr, L. and Honavar, V., </author> <title> Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, in Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, Honavar, </title> <editor> V. and Uhr, L. (Ed.), pp. xvii-xxxii. </editor> <publisher> Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference: <author> Van der Velde, F., </author> <title> Symbol Manipulation with Neural Networks: Production of a Context-free Language Using a Modifiable Working Memory, </title> <journal> Connection Science, </journal> <volume> vol. 7, no. 3 & 4, </volume> <pages> pp. 247-280, </pages> <year> 1995. </year>
Reference: <author> Watanabe, T. et al., </author> <title> A Single 1.5-V Digital Chip for a 10 6 Synapse Neural Network, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 387-393, </pages> <month> May </month> <year> 1993. </year>
Reference: <author> Watrous, R. L. and Kuhn, G. M., </author> <title> Induction of Finite-State Languages Using Second-Order Recurrent Neural Networks, </title> <journal> Neural Computation, </journal> <volume> vol. 4, No. 3, </volume> <editor> p. </editor> <volume> 406, </volume> <year> 1992. </year>
Reference: <author> Williams, R. J. and Zipser, D., </author> <title> A Learning Algorithm for Continually Running Fully Recurrent Neural Networks, </title> <journal> Neural Computation, </journal> <volume> vol. 1, </volume> <pages> pp. 270-280, </pages> <year> 1989. </year>
Reference: <author> Wood, D., </author> <title> Theory of Computation, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1987. </year> <note> 59 Zeng, </note> <author> Z., Goodman, R. M. and Smyth, P., </author> <title> Discrete Recurrent Neural Net--works for Grammatical Inference, </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 5, no. 2, </volume> <pages> pp. 320-330, </pages> <month> March </month> <year> 1994. </year> <month> 60 </month>
References-found: 95

