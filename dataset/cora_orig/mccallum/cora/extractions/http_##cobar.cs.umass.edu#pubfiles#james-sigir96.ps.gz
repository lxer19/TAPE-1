URL: http://cobar.cs.umass.edu/pubfiles/james-sigir96.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: allan@cs.umass.edu  
Title: Incremental Relevance Feedback for Information Filtering  
Author: James Allan 
Address: Amherst, MA 01003-4610 USA  
Affiliation: Center for Intelligent Information Retrieval Department of Computer Science, University of Massachusetts  
Abstract: We use data from the TREC routing experiments to explore how relevance feedback can be applied incrementally|using a few judged documents each time|to achieve results that are as good as if the feedback occurred in one pass. We show that relatively few judgments are needed to get high-quality results. We also demonstrate methods that reduce the amount of information archived from past judged documents without adversely affecting effectiveness. A novel simulation shows that such techniques are useful for handling long-standing queries with drifting notions of relevance. 
Abstract-found: 1
Intro-found: 1
Reference: [ABC + 95] <author> James Allan, Lisa Ballesteros, James P. Callan, W. Bruce Croft, and Zhihong Lu. </author> <title> Recent experiments with INQUERY. </title> <booktitle> In Fourth Text REtrieval Conference (TREC-4), </booktitle> <year> 1995. </year> <month> Forthcoming. </month>
Reference-contexts: Note that this feedback scheme is not the best known approach. In particular, all query structure is ignored (the queries are a weighted sum of words), no dynamic feedback optimization <ref> [BS95, ABC + 95] </ref> is done, and only terms are added. However, this simpler approach is fast, reasonably effective, and easy to understand, so it provides an excellent approximation for these experiments.
Reference: [Boo88] <author> A. Bookstein. </author> <title> Set oriented retrieval. </title> <booktitle> In Proceedings of the 11th international conference on research and development in information retrieval, </booktitle> <pages> pages 583-596, </pages> <address> Grenoble, France, </address> <month> June </month> <year> 1988. </year> <institution> Presses Universitaires de Grenoble. </institution>
Reference: [BR93] <author> Carla E. Brodley and Edwina L. Rissland. </author> <title> Measuring concept change. </title> <booktitle> In AAAI Spring Symposium: Training issues in incremental learning, </booktitle> <pages> pages 98-107, </pages> <year> 1993. </year>
Reference: [BS95] <author> Chris Buckley and Gerard Salton. </author> <title> Optimization of relevance feedback weights. </title> <editor> In Edward A. Fox, Peter Ingwersen, and Raya Fidel, editors, </editor> <booktitle> Proceedings of the 18th annual international ACM SIGIR conference on research and development 8 in information retrieval, </booktitle> <pages> pages 351-357, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Note that this feedback scheme is not the best known approach. In particular, all query structure is ignored (the queries are a weighted sum of words), no dynamic feedback optimization <ref> [BS95, ABC + 95] </ref> is done, and only terms are added. However, this simpler approach is fast, reasonably effective, and easy to understand, so it provides an excellent approximation for these experiments.
Reference: [BSA94] <author> Chris Buckley, Gerard Salton, and James Allan. </author> <title> The effect of adding relevance information in a relevance feedback environment. </title> <editor> In W. Bruce Croft and C. J. van Rijsbergen, editors, </editor> <booktitle> Proceedings of the seventeenth annual international ACM-SIGIR conference on research and development in information retrieval, </booktitle> <pages> pages 293-300, </pages> <address> Dublin, Ireland, June 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference: [Cal96] <author> James P. Callan. </author> <title> Document filtering with inference networks. </title> <booktitle> In Proceedings of the 19th annual international ACM SIGIR conference on research and development in information retrieval, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: A retrieval system monitors the stream of documents and when it finds one that matches a user's query, the document 1 is saved. This part of the retrieval problem is handled by various existing filtering engines, both in the research community (e.g., SIFT [YGM95] and InRoute <ref> [Cal96] </ref>) and the commercial setting (e.g., Logicon [Yoc85]). When documents have been selected, the user reads them and has the opportunity to mark them as relevant or not. These judgments are combined with the query to generate a new query|perhaps after several judgments have been made, perhaps after every one.
Reference: [CCW95] <author> W.B. Croft, R. Cook, and D. Wilder. </author> <title> Providing government information on the internet: Experiences with THOMAS. </title> <booktitle> In Digital Libraries Conference, </booktitle> <address> Austin, Texas, </address> <month> June </month> <year> 1995. </year>
Reference: [Har96] <author> Donna Harman. </author> <booktitle> Overview of the fourth Text REtrieval Conference (TREC-4). In Fourth Text REtrieval Conference (TREC-4), </booktitle> <year> 1996. </year> <month> Forthcoming. </month>
Reference: [IJA92] <author> IJsbrand Jan Aalbersberg. </author> <title> Incremental relevance feedback. </title> <booktitle> In Proceedings of the fifteenth annual international ACM SIGIR conference on research and development in information retrieval, </booktitle> <pages> pages 11-22, </pages> <year> 1992. </year>
Reference-contexts: In the area of text classification, efforts have been made to reduce the amount of training needed to build a reasonable classifier.[LG94] Aalbersberg's work on incremental feedback <ref> [IJA92] </ref> is very similar to one of the cases of this study (saving all context from past judgments), though he is concerned with a static collection and the interactive setting.
Reference: [LG94] <author> David D. Lewis and William A. Gale. </author> <title> A sequential algorithm for training text classifiers. </title> <editor> In W. Bruce Croft and C. J. van Rijsbergen, editors, </editor> <booktitle> Proceedings of the seventeenth annual international ACM-SIGIR conference on research and development in information retrieval, </booktitle> <pages> pages 3-12, </pages> <address> Dublin, Ireland, June 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference: [Sal71] <author> Gerard Salton, </author> <title> editor. The SMART retrieval system: experiments in automatic document processing. </title> <booktitle> Prentice-Hall Series in Automatic Computation, </booktitle> <address> Englewood Cliffs, New Jersey, </address> <year> 1971. </year> <month> Chapters 14-17. </month>
Reference: [Tur90] <author> Howard R. </author> <title> Turtle. Inference networks for document retrieval. </title> <type> PhD thesis, </type> <institution> University of Mas-sachusetts, Amherst, </institution> <month> October </month> <year> 1990. </year>
Reference: [YGM95] <author> T. Yan and H. Garcia-Molina. </author> <title> SIFT A tool for wide-area information dissemination. </title> <booktitle> In Proc. USENIX Winter 1995 Technical Conference, </booktitle> <address> New Orleans, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: A retrieval system monitors the stream of documents and when it finds one that matches a user's query, the document 1 is saved. This part of the retrieval problem is handled by various existing filtering engines, both in the research community (e.g., SIFT <ref> [YGM95] </ref> and InRoute [Cal96]) and the commercial setting (e.g., Logicon [Yoc85]). When documents have been selected, the user reads them and has the opportunity to mark them as relevant or not.
Reference: [Yoc85] <author> J. A. Yochum. </author> <title> A high-speed text scanning algorithm utilizing least frequent trigraphs. </title> <booktitle> In Proceedings of the IEEE International Symposium on New Directions in Computing, </booktitle> <pages> pages 114-121, </pages> <address> Trondheim, Norway, </address> <year> 1985. </year> <journal> IEEE. </journal> <volume> 9 </volume>
Reference-contexts: This part of the retrieval problem is handled by various existing filtering engines, both in the research community (e.g., SIFT [YGM95] and InRoute [Cal96]) and the commercial setting (e.g., Logicon <ref> [Yoc85] </ref>). When documents have been selected, the user reads them and has the opportunity to mark them as relevant or not. These judgments are combined with the query to generate a new query|perhaps after several judgments have been made, perhaps after every one.
References-found: 14

