URL: ftp://ftp.cs.washington.edu/tr/PRE-1991/UW-CSE-90-09-04.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: Dynamic Node Reconfiguration in a Parallel-Distributed Environment  
Author: Michael J. Feeley, Brian N. Bershad, Jeffrey S. Chase, and Henry M. Levy 
Note: Appears in the Proceedings of the Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP) SIGPLAN NOTICES, Volume 26, Number  
Date: 90-09-04  7, July 1991  
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering University of Washington  
Pubnum: Technical Report  
Abstract: Idle workstations in a network represent a significant computing potential. In particular, their processing power can be used by parallel-distributed programs that treat the network as a loosely-coupled multiprocessor. But the set of machines free to participate in load sharing changes over time as users come and go from their workstations. To make full use of the available resources, parallel-distributed applications in the network must reconfigure to adapt to these changes as they run. This paper describes a node reconfiguration facility for Amber, an object-based parallel programming system for networks of multiprocessors. We describe system support that allows a parallel Amber application to adapt to changing network conditions by expanding to make use of new nodes as they become idle, and by contracting as nodes become busy. A key characteristic of Amber's node reconfiguration is that it is handled at the user level in the Amber runtime system; it does not depend on a kernel-level process migration facility. Our experiments with Amber show that node reconfiguration can be implemented easily and efficiently in a runtime library. 
Abstract-found: 1
Intro-found: 1
Reference: [Anderson et al. 90] <author> Anderson, R. J., Beame, P., and Ruzzo, W. L. </author> <title> Low overhead parallel schedules for task graphs. </title> <booktitle> In Proceedings of the 2nd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 66-75, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Amber has been used to experiment with a number of parallel-distributed applications, including iterative point-update (e.g., the Game of Life), jigsaw puzzle [Green & Juels 86], graph search, mesh-based dynamic programming <ref> [Anderson et al. 90] </ref>, simulation, and an n-body gravitational interaction. This section describes those aspects of Amber that are relevant to our approach to node reconfiguration.
Reference: [Arnould et al. 89] <author> Arnould, E. A., Bitz, F. J., Cooper, E. C., Kung, H. T., Sansom, R. D., and Steenkiste, P. A. </author> <title> The design of Nectar: A network backplane for heterogeneous mul-ticomputers. </title> <booktitle> 3rd Symposium on Architectural Support for Programming Languages and Operating Systems, Computer Architecture News, </booktitle> <volume> 17(2) </volume> <pages> 205-216, </pages> <month> April </month> <year> 1989. </year>
Reference: [Bennett et al. 90a] <author> Bennett, J. K., Carter, J. B., and Zwaenepoel, W. </author> <title> Adaptive software cache management for distributed shared memory architectures. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 125-134, </pages> <month> May </month> <year> 1990. </year>
Reference: [Bennett et al. 90b] <author> Bennett, J. K., Carter, J. B., and Zwaenepoel, W. Munin: </author> <title> Distributed shared memory based on type-specific memory coherence. </title> <booktitle> In Proceedings of the 2nd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 168-176, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: This eliminates the false sharing inherent in page-based distributed memory systems, and it allows coherence and distribution policies to be selected on an object basis according to how objects are used <ref> [Bennett et al. 90b] </ref>. The maximum parallelism available to an Amber program is determined by its decomposition into objects and threads, and the assignment of objects to nodes determines the distribution of load.
Reference: [Chase et al. 89] <author> Chase, J. S., Amador, F. G., La-zowska, E. D., Levy, H. M., and Littlefield, R. J. </author> <title> The Amber system: Parallel programming on a network of multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 147-158, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Supporting dynamic node reconfiguration allows programmers to use idle workstations according to the needs of their programs, rather than the working hours of their colleagues. In this paper we describe the design, implementation, performance, and impact of dynamic node reconfiguration in Amber <ref> [Chase et al. 89] </ref>.
Reference: [Douglis & Ousterhout 87] <author> Douglis, F. and Ouster-hout, J. </author> <title> Process migration in the Sprite operating system. </title> <booktitle> In Proceedings of the 7th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 18-25, </pages> <month> Septem-ber </month> <year> 1987. </year>
Reference: [Eager et al. 86] <author> Eager, D. L., Lazowska, E. D., and Zahorjan, J. </author> <title> Adaptive load sharing in homogeneous distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-12(5):662-675, </volume> <month> May </month> <year> 1986. </year>
Reference: [Faust 90] <author> Faust, K. </author> <title> An empirical comparison of object mobility mechanisms. </title> <type> Master's thesis, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: In Section 6 we describe the system's performance. We present our conclusions in Section 7. 2 Amber Overview Amber is an object-oriented parallel-distributed programming system that supports threads, a distributed shared object space, object migration, and object replication <ref> [Faust 90] </ref>, for programs written in a variant of C++. Amber was designed to explore the use of a distributed object model as a tool for structuring parallel programs to run efficiently on a network of DEC Firefly shared-memory multiprocessor workstations [Thacker et al. 88].
Reference: [Fowler 85] <author> Fowler, R. J. </author> <title> Decentralized Object Find--ing Using Forwarding Addresses. </title> <type> PhD dissertation, </type> <institution> University of Washington, Decem-ber 1985. Department of Computer Science technical report 85-12-1. </institution>
Reference-contexts: The runtime system handles the failure by querying the NodeSet object for the new binding, updating its local cache of bindings, and retrying the call. 5.3 Locating Remote Objects Amber's scheme for finding remote objects is based on forwarding addresses <ref> [Fowler 85] </ref>. Each time an object moves off of a node it leaves behind the node number of its destination as a forwarding address. The forwarding address may be out of date if the object moves frequently.
Reference: [Green & Juels 86] <author> Green, P. and Juels, R. </author> <title> The jigsaw puzzle: A distributed performance test. </title> <booktitle> In Proceedings of the 6th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 288-295, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: Amber has been used to experiment with a number of parallel-distributed applications, including iterative point-update (e.g., the Game of Life), jigsaw puzzle <ref> [Green & Juels 86] </ref>, graph search, mesh-based dynamic programming [Anderson et al. 90], simulation, and an n-body gravitational interaction. This section describes those aspects of Amber that are relevant to our approach to node reconfiguration.
Reference: [Jul et al. 88] <author> Jul, E., Levy, H., Hutchinson, N., and Black, A. </author> <title> Fine-grained mobility in the Emerald system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 109-133, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Amber can globally bind objects to virtual addresses in this fashion because each program executes in a private (but distributed) object space; one Amber program cannot name or use objects created by another program. This sets Amber apart from other location-independent object systems, such as Emerald <ref> [Jul et al. 88] </ref>, which provide a single global object space shared by multiple programs. 3 Reconfiguration in Amber A running parallel-distributed program can respond to three types of node reconfiguration: the node set can shrink in size, stay the same size but change member ship, or grow.
Reference: [Koeman 90] <author> Koeman, S. </author> <title> Dynamic load balancing in a distributed-parallel object-oriented environment. </title> <type> Master's thesis, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: The program mer can control object location using explicit object mobility primitives, or by selecting an adaptive "off the shelf" object placement policy implemented with additional runtime support layered on the base system <ref> [Koeman 90] </ref>. These features are particularly useful for preventing load imbalances over a changing node set; objects can be migrated to balance the load. An Amber program runs as a collection of processes distributed across a set of network nodes, some of which may be shared-memory multiprocessors.
Reference: [Li & Hudak 89] <author> Li, K. and Hudak, P. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference: [Litzkow et al. 88] <author> Litzkow, M. J., Livny, M., and Mutka, M. W. </author> <title> Condor ahunter of idle workstations. </title> <booktitle> In 8th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 104-111. </pages> <publisher> IEEE Computer Society, </publisher> <month> June </month> <year> 1988. </year>
Reference: [Powell & Miller 83] <author> Powell, M. L. and Miller, B. P. </author> <title> Process migration in DEMOS/MP. </title> <booktitle> In Proceedings of the 9th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 110-119. </pages> <address> ACM/SIGOPS, </address> <month> October </month> <year> 1983. </year>
Reference: [Thacker et al. 88] <author> Thacker, C. P., Stewart, L. C., and Satterthwaite, Jr., E. H. Firefly: </author> <title> A multiprocessor workstation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(8) </volume> <pages> 909-920, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Amber was designed to explore the use of a distributed object model as a tool for structuring parallel programs to run efficiently on a network of DEC Firefly shared-memory multiprocessor workstations <ref> [Thacker et al. 88] </ref>. Programs are explicitly decomposed into objects and threads distributed among the nodes participating in the application.
Reference: [Theimer & Lantz 88] <author> Theimer, M. M. and Lantz, K. A. </author> <title> Finding idle machines in a workstation-based distributed system. </title> <booktitle> In 8th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 112-122. </pages> <publisher> IEEE Computer Society, </publisher> <month> June </month> <year> 1988. </year>
Reference: [Theimer et al. 85] <author> Theimer, M. M., Lantz, K. A., and Cheriton, D. R. </author> <title> Preemptable remote execution facilities for the V-system. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 2-12. </pages> <address> ACM/SIGOPS, </address> <month> December </month> <year> 1985. </year>
Reference-contexts: A final problem with the kernel-level approach is that it transfers the complete contents of a migrating address space, thereby needlessly moving data that is replicated and can be found elsewhere. Although system-level optimizations such as aggressive pre-copying <ref> [Theimer et al. 85] </ref>, or lazy on-demand copying [Zayas 87], can reduce the latency of migration, the most effective optimization no copying - can only be implemented with information kept at the user-level. 5 Implementation This section describes the implementation of node reconfiguration support in the Amber runtime system.
Reference: [Zayas 87] <author> Zayas, E. R. </author> <title> Attacking the process migration bottleneck. </title> <booktitle> In Proceedings of the 11th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 13-24, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: A final problem with the kernel-level approach is that it transfers the complete contents of a migrating address space, thereby needlessly moving data that is replicated and can be found elsewhere. Although system-level optimizations such as aggressive pre-copying [Theimer et al. 85], or lazy on-demand copying <ref> [Zayas 87] </ref>, can reduce the latency of migration, the most effective optimization no copying - can only be implemented with information kept at the user-level. 5 Implementation This section describes the implementation of node reconfiguration support in the Amber runtime system.
References-found: 19

