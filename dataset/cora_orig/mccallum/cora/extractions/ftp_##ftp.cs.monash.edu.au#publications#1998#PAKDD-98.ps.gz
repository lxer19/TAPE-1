URL: ftp://ftp.cs.monash.edu.au/publications/1998/PAKDD-98.ps.gz
Refering-URL: http://www.cs.monash.edu.au/cgi-bin/publications_search/?0++C%20S%20Wallace+
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: jono@ultimode.com, rohan@ultimode.com, csw@cs.monash.edu.au  
Phone: 1  2  
Title: Minimum Message Length Segmentation  
Author: Jonathan J. Oliver Rohan A. Baxter and Chris S. Wallace 
Address: Australia  2560 Bancroft Way #213, Berkeley, CA 94704, USA  
Affiliation: Dept. Computer Science, Monash University, Clayton Vic.,  Ultimode Systems,  
Abstract: The segmentation problem arises in many applications in data mining, A.I. and statistics, including segmenting time series, decision tree algorithms and image processing. In this paper, we consider a range of criteria which may be applied to determine if some data should be segmented into two or regions. We develop a information theoretic criterion (MML) for the segmentation of univariate data with Gaussian errors. We perform simulations comparing segmentation methods (MML, AIC, MDL and BIC) and conclude that the MML criterion is the preferred criterion. We then apply the segmentation method to financial time series data.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> H. Akaike. </author> <title> Information theory and an extension of the maximum likelihood principle. In B.N. </title> <editor> Petrov and F. Csaki, editors, </editor> <booktitle> Proc. of the 2nd International Symposium on Information Theory, </booktitle> <pages> pages 267-281, </pages> <year> 1973. </year>
Reference-contexts: However, choosing a segmentation model to maximize the likelihood results in a model with homogeneous regions containing only one datum each. Therefore, heuristics for solving the segmentation problem usually involve `penalizing' a segmentation for its model complexity. A number of methods which penalize model complexity are available including AIC <ref> [1, 7] </ref>, BIC [13, 6], Minimum Description Length (MDL) [12] and Minimum Message Length (MML) [17, 18]. In this paper, we extend the MML approach to segmentation offered by Baxter and Oliver [2], to the multiple cutpoint case, and apply the approach to time series problems.
Reference: 2. <author> R.A. Baxter and J.J. Oliver. </author> <title> The kindest cut: minimum message length segmentation. </title> <editor> In S. Arikawa and A. Sharma, editors, </editor> <booktitle> Lecture Notes in Artificial Intelligence 1160, Algorithmic Learning Theory, ALT-96, </booktitle> <pages> pages 83-90, </pages> <year> 1996. </year>
Reference-contexts: A number of methods which penalize model complexity are available including AIC [1, 7], BIC [13, 6], Minimum Description Length (MDL) [12] and Minimum Message Length (MML) [17, 18]. In this paper, we extend the MML approach to segmentation offered by Baxter and Oliver <ref> [2] </ref>, to the multiple cutpoint case, and apply the approach to time series problems. This paper is organised as follows: Section 2 defines the segmentation problem we address here. Section 3 describes a previous MDL approach [4, 10, 11], and describes a shortcoming of this approach.
Reference: 3. <author> J.H. Conway and N.J.A Sloane. </author> <title> Sphere Packings, Lattices and Groups. </title> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1988. </year>
Reference: 4. <author> B. Dom. </author> <title> MDL estimation with Small Sample Sizes including an application to the problem of segmenting binary strings using bernoulli models. </title> <type> Technical Report RJ 9997 (89085) 12/15/95, </type> <institution> IBM Research Division, Almaden Research Center, 650 Harry Rd, </institution> <address> San Jose, CA, 95120-6099, </address> <year> 1995. </year>
Reference-contexts: This paper is organised as follows: Section 2 defines the segmentation problem we address here. Section 3 describes a previous MDL approach <ref> [4, 10, 11] </ref>, and describes a shortcoming of this approach. Section 4 gives an MML approach to segmentation. The MML method proposed here differs from the MDL approach by optimising the code for the region boundary and including coding penalties for stating the parameters of each region. <p> This approximation is unsuited to cutpoint-like parameters. A number of authors <ref> [4, 10, 11] </ref> have given terms 3 to describe the cost of stating a cutpoint in a message. <p> If we wish to state C cutpoints, then this will require a codeword of length: DescriptionLength (C cutpoints) = log C Dom <ref> [4] </ref> requires that C &lt; n 2 , otherwise the complexity of the term decreases for increasing C, which is counter to prior beliefs about segmentation models in most applications. 3 We note that these authors used this penalty measure in different, but related contexts and that our use of it
Reference: 5. <author> G. Koop and S.M. Potter. </author> <title> Bayes Factors and nonlinearity: Evidence from economic time series. </title> <note> UCLA Working Paper, August 1995, submitted to Journal of Econometrics. </note>
Reference-contexts: The segmentation problem arises in applications that partition data in areas such as data mining, A.I. and statistics. The segmentation problem arise in applications such as segmenting time series <ref> [14, 16, 5] </ref>, decision tree algorithms [11, 10], and image processing [7, 6]. 1.1 The Problem Considered Here, we consider a univariate problem, where the segment boundarys are defined by cut-points. We assume that the data in each segment is defined by a Gaussian distribution.
Reference: 6. <author> Mengxiang Li. </author> <title> Minimum description length based 2-D shape description. </title> <booktitle> In IEEE 4th Int. Conf. on Computer Vision, </booktitle> <pages> pages 512-517, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: The segmentation problem arises in applications that partition data in areas such as data mining, A.I. and statistics. The segmentation problem arise in applications such as segmenting time series [14, 16, 5], decision tree algorithms [11, 10], and image processing <ref> [7, 6] </ref>. 1.1 The Problem Considered Here, we consider a univariate problem, where the segment boundarys are defined by cut-points. We assume that the data in each segment is defined by a Gaussian distribution. Figure 1 gives an example of the type of data we might consider. <p> Therefore, heuristics for solving the segmentation problem usually involve `penalizing' a segmentation for its model complexity. A number of methods which penalize model complexity are available including AIC [1, 7], BIC <ref> [13, 6] </ref>, Minimum Description Length (MDL) [12] and Minimum Message Length (MML) [17, 18]. In this paper, we extend the MML approach to segmentation offered by Baxter and Oliver [2], to the multiple cutpoint case, and apply the approach to time series problems. <p> d + 2 C X L j + C (6) 5 Simulation Results We ran simulations comparing the following criteria: (i) MML, using Equation (6) of this paper. (ii) AIC, using log f (yj) + number params [7]. (iii) BIC, using log f (yj) + number params 2 log n <ref> [6] </ref>. (iv) MDL, using log f (yj) + continuous params 2 log n + log n 5.1 The Search Method It is impractical to consider every possible segmentation of data once we consider multiple cutpoints. We therefore used the following search method.
Reference: 7. <author> Z. Liang, R.J. Jaszczak, and R.E. Coleman. </author> <title> Parameter estimation of finite mixtures using the EM algorithm and information criteria with applications to medical image processing. </title> <journal> IEEE Trans. on Nuclear Science, </journal> <volume> 39(4) </volume> <pages> 1126-1133, </pages> <year> 1992. </year>
Reference-contexts: The segmentation problem arises in applications that partition data in areas such as data mining, A.I. and statistics. The segmentation problem arise in applications such as segmenting time series [14, 16, 5], decision tree algorithms [11, 10], and image processing <ref> [7, 6] </ref>. 1.1 The Problem Considered Here, we consider a univariate problem, where the segment boundarys are defined by cut-points. We assume that the data in each segment is defined by a Gaussian distribution. Figure 1 gives an example of the type of data we might consider. <p> However, choosing a segmentation model to maximize the likelihood results in a model with homogeneous regions containing only one datum each. Therefore, heuristics for solving the segmentation problem usually involve `penalizing' a segmentation for its model complexity. A number of methods which penalize model complexity are available including AIC <ref> [1, 7] </ref>, BIC [13, 6], Minimum Description Length (MDL) [12] and Minimum Message Length (MML) [17, 18]. In this paper, we extend the MML approach to segmentation offered by Baxter and Oliver [2], to the multiple cutpoint case, and apply the approach to time series problems. <p> j ; j ) C log 1=R + 0:5 j=0 log C! j=1 d + 2 C X L j + C (6) 5 Simulation Results We ran simulations comparing the following criteria: (i) MML, using Equation (6) of this paper. (ii) AIC, using log f (yj) + number params <ref> [7] </ref>. (iii) BIC, using log f (yj) + number params 2 log n [6]. (iv) MDL, using log f (yj) + continuous params 2 log n + log n 5.1 The Search Method It is impractical to consider every possible segmentation of data once we consider multiple cutpoints.
Reference: 8. <author> J.J. Oliver and D.J. </author> <title> Hand. Introduction to minimum encoding inference. </title> <type> Technical report TR 4-94, </type> <institution> Dept. of Statistics, Open University, Walton Hall, Milton Keynes, MK7 6AA, UK, </institution> <year> 1994. </year> <note> Available on the WWW from http://www.cs.monash.edu.au/ ~ jono. </note>
Reference-contexts: The range of x i is assumed to be known by the receiver a priori. 4.1 Minimum Message Length Formulas Wallace and Freeman [18] showed that under some fairly general conditions (a locally flat prior and quadratic log-likelihood function) the expected message length (taking the expectation over coding schemes <ref> [8, Section 3.3.1] </ref>) for sending y and parameters is: E (M essLen (y; )) = log h () log f (yj) + 0:5 log det (F ()) + d log d + 2 where h () is the assumed known prior density on , d is the dimension of , f
Reference: 9. <author> J.J. Oliver, Baxter R.A., and Wallace C.S. </author> <title> Unsupervised Learning using MML. </title> <booktitle> In Machine Learning: Proc. of the Thirteenth International Conference (ICML 96), </booktitle> <pages> pages 364-372. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, CA, </address> <year> 1996. </year> <note> Available on the WWW from http://www.cs.monash.edu.au/ ~ jono. </note>
Reference-contexts: We choose a non-informative (improper) prior based on the population variance of y i <ref> [17, 9] </ref>: h (c 0 ; 0 ) = 2 2 where pop is the standard deviation of the y i .
Reference: 10. <author> B. Pfahringer. </author> <title> Compression-based discretization of continuous attributes. </title> <booktitle> In Machine Learning: Proc. of the Twelfth International Workshop, </booktitle> <pages> pages 456-463, </pages> <year> 1995. </year>
Reference-contexts: The segmentation problem arises in applications that partition data in areas such as data mining, A.I. and statistics. The segmentation problem arise in applications such as segmenting time series [14, 16, 5], decision tree algorithms <ref> [11, 10] </ref>, and image processing [7, 6]. 1.1 The Problem Considered Here, we consider a univariate problem, where the segment boundarys are defined by cut-points. We assume that the data in each segment is defined by a Gaussian distribution. <p> This paper is organised as follows: Section 2 defines the segmentation problem we address here. Section 3 describes a previous MDL approach <ref> [4, 10, 11] </ref>, and describes a shortcoming of this approach. Section 4 gives an MML approach to segmentation. The MML method proposed here differs from the MDL approach by optimising the code for the region boundary and including coding penalties for stating the parameters of each region. <p> This approximation is unsuited to cutpoint-like parameters. A number of authors <ref> [4, 10, 11] </ref> have given terms 3 to describe the cost of stating a cutpoint in a message.
Reference: 11. <author> J.R. Quinlan. </author> <title> Improved use of continuous attributes in C4.5. </title> <journal> Journal of Artificial Intelligence, </journal> <volume> 4 </volume> <pages> 77-90, </pages> <year> 1996. </year>
Reference-contexts: The segmentation problem arises in applications that partition data in areas such as data mining, A.I. and statistics. The segmentation problem arise in applications such as segmenting time series [14, 16, 5], decision tree algorithms <ref> [11, 10] </ref>, and image processing [7, 6]. 1.1 The Problem Considered Here, we consider a univariate problem, where the segment boundarys are defined by cut-points. We assume that the data in each segment is defined by a Gaussian distribution. <p> This paper is organised as follows: Section 2 defines the segmentation problem we address here. Section 3 describes a previous MDL approach <ref> [4, 10, 11] </ref>, and describes a shortcoming of this approach. Section 4 gives an MML approach to segmentation. The MML method proposed here differs from the MDL approach by optimising the code for the region boundary and including coding penalties for stating the parameters of each region. <p> This approximation is unsuited to cutpoint-like parameters. A number of authors <ref> [4, 10, 11] </ref> have given terms 3 to describe the cost of stating a cutpoint in a message.
Reference: 12. <author> J. Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: Therefore, heuristics for solving the segmentation problem usually involve `penalizing' a segmentation for its model complexity. A number of methods which penalize model complexity are available including AIC [1, 7], BIC [13, 6], Minimum Description Length (MDL) <ref> [12] </ref> and Minimum Message Length (MML) [17, 18]. In this paper, we extend the MML approach to segmentation offered by Baxter and Oliver [2], to the multiple cutpoint case, and apply the approach to time series problems. <p> number of cutpoints, (ii) the segment boundaries, fv 1 ; : : : : v C g, (iii) the means, fc 0 ; : : : ; c C g, and (iv) the standard deviations, f 0 ; : : : ; C g. 3 The Straightforward MDL Approach Rissanen <ref> [12] </ref> proposed the straight forward Minimum Description Length (MDL) criterion, which given data y and parameters approximates the length as: DescriptionLength (y; ) = log f (yj) + number params 2 where f (yj) is the Gaussian likelihood function, log f (yj) approximates the length of describing the data, and number
Reference: 13. <author> G. Schwarz. </author> <title> Estimating dimension of a model. </title> <journal> Ann. Stat., </journal> <volume> 6 </volume> <pages> 461-464, </pages> <year> 1978. </year>
Reference-contexts: Therefore, heuristics for solving the segmentation problem usually involve `penalizing' a segmentation for its model complexity. A number of methods which penalize model complexity are available including AIC [1, 7], BIC <ref> [13, 6] </ref>, Minimum Description Length (MDL) [12] and Minimum Message Length (MML) [17, 18]. In this paper, we extend the MML approach to segmentation offered by Baxter and Oliver [2], to the multiple cutpoint case, and apply the approach to time series problems.
Reference: 14. <author> S.L. Sclove. </author> <title> On segmentation of time series. </title> <editor> In S. Karlin, T. Amemiya, and L. Goodman, editors, </editor> <title> Studies in econometrics, time series, </title> <journal> and multivariate statistics, </journal> <pages> pages 311-330. </pages> <publisher> Academic Press, </publisher> <year> 1983. </year>
Reference-contexts: The segmentation problem arises in applications that partition data in areas such as data mining, A.I. and statistics. The segmentation problem arise in applications such as segmenting time series <ref> [14, 16, 5] </ref>, decision tree algorithms [11, 10], and image processing [7, 6]. 1.1 The Problem Considered Here, we consider a univariate problem, where the segment boundarys are defined by cut-points. We assume that the data in each segment is defined by a Gaussian distribution. <p> We argue that these objections are false. Data such as that in Figure 1 might be the number of eye movements per 5 second intervals for a sleeping person, and a doctor may be interested in how many phases of sleep there were, and when they were <ref> [14] </ref>. A different practical example where this model seems plausible is the incidence of tooth cavities. Previously dentists entertained the burst-remission theory, and dentists spent considerable effort looking for factors that induced remission (i.e., segments with lower means). <p> This may be a reasonable method for segmenting data from examples such as: (i) economic time series, (ii) electrocardiogram measurements and (iii) eye movement measurements from a sleeping person. We segmented the quarterly gross national product (GNP) for the United States from 1947 - 1966 <ref> [14] </ref>. Figure 2 6 shows the preferred MML segmentation for this data.
Reference: 15. <author> C.W. Therrien. </author> <title> Decision, estimation, and classification : an introduction to pattern recognition and related topics. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Figure 2 6 shows the preferred MML segmentation for this data. The BIC and MDL criteria also preferred this segmentation, while the AIC criterion preferred a segmentation with 7 segments. 5 The Kullback-Liebler distance (given for example in <ref> [15, Chp. 9] </ref>) between a true distribution N ( t ; 2 t ) and a fitted distribution N ( f ; 2 f ) is f 2 + 1 f t + ( t f ) 2 ): 6 The units in the figure are billions of (non constant) dollars.
Reference: 16. <author> H. Tong. </author> <title> Non-linear time series : a dynamical system approach. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1990. </year>
Reference-contexts: The segmentation problem arises in applications that partition data in areas such as data mining, A.I. and statistics. The segmentation problem arise in applications such as segmenting time series <ref> [14, 16, 5] </ref>, decision tree algorithms [11, 10], and image processing [7, 6]. 1.1 The Problem Considered Here, we consider a univariate problem, where the segment boundarys are defined by cut-points. We assume that the data in each segment is defined by a Gaussian distribution. <p> Previously dentists entertained the burst-remission theory, and dentists spent considerable effort looking for factors that induced remission (i.e., segments with lower means). However, it appears that the data was consistent with the assumption that it was a random walk (i.e. that there was only one segment). Tong <ref> [16] </ref> has written a comprehensive book about non linear time series (including segmentation models). We consider such problems in Section 6. 1.3 Related Work The fit of a segmentation model to data can be expressed precisely using maximum likelihood estimation.
Reference: 17. <author> C.S. Wallace and D.M. Boulton. </author> <title> An information measure for classification. </title> <journal> Computer Journal, </journal> <volume> 11 </volume> <pages> 185-194, </pages> <year> 1968. </year>
Reference-contexts: Therefore, heuristics for solving the segmentation problem usually involve `penalizing' a segmentation for its model complexity. A number of methods which penalize model complexity are available including AIC [1, 7], BIC [13, 6], Minimum Description Length (MDL) [12] and Minimum Message Length (MML) <ref> [17, 18] </ref>. In this paper, we extend the MML approach to segmentation offered by Baxter and Oliver [2], to the multiple cutpoint case, and apply the approach to time series problems. This paper is organised as follows: Section 2 defines the segmentation problem we address here. <p> We choose a non-informative (improper) prior based on the population variance of y i <ref> [17, 9] </ref>: h (c 0 ; 0 ) = 2 2 where pop is the standard deviation of the y i .
Reference: 18. <author> C.S. Wallace and P.R. Freeman. </author> <title> Estimation and inference by compact coding. </title> <journal> Journal of the Royal Statistical Society (Series B), </journal> <volume> 49 </volume> <pages> 240-252, </pages> <year> 1987. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Therefore, heuristics for solving the segmentation problem usually involve `penalizing' a segmentation for its model complexity. A number of methods which penalize model complexity are available including AIC [1, 7], BIC [13, 6], Minimum Description Length (MDL) [12] and Minimum Message Length (MML) <ref> [17, 18] </ref>. In this paper, we extend the MML approach to segmentation offered by Baxter and Oliver [2], to the multiple cutpoint case, and apply the approach to time series problems. This paper is organised as follows: Section 2 defines the segmentation problem we address here. <p> Since the x i are evenly spaced, one can work out the number of x i in any region from knowing the size of the region. The range of x i is assumed to be known by the receiver a priori. 4.1 Minimum Message Length Formulas Wallace and Freeman <ref> [18] </ref> showed that under some fairly general conditions (a locally flat prior and quadratic log-likelihood function) the expected message length (taking the expectation over coding schemes [8, Section 3.3.1]) for sending y and parameters is: E (M essLen (y; )) = log h () log f (yj) + 0:5 log det
References-found: 18

