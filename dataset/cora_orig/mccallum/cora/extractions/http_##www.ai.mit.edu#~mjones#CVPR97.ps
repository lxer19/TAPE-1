URL: http://www.ai.mit.edu/~mjones/CVPR97.ps
Refering-URL: http://www.ai.mit.edu/~mjones/mjones.html
Root-URL: 
Email: vetter@mpik-tueb.mpg.de mjones@ai.mit.edu tp@ai.mit.edu  
Title: A Bootstrapping Algorithm for Learning Linear Models of Object Classes  
Author: Thomas Vetter Michael J. Jones and Tomaso Poggio 
Address: Cambridge, MA 02139 Max-Plack-Institut fur biologische Kybernetik 72076 Tubingen, Germany  
Affiliation: Center for Biological and Computational Learning Massachusetts Institute of Technology,  
Abstract: Flexible models of object classes, based on linear combinations of prototypical images, are capable of matching novel images of the same class and have been shown to be a powerful tool to solve several fundamental vision tasks such as recognition, synthesis and correspondence. The key problem in creating a specific flexible model is the computation of pixelwise correspondence between the prototypes, a task done until now in a semiautomatic way. In this paper we describe an algorithm that automatically bootstraps the correspondence between the prototypes. The algorithm which can be used for 2D images as well as for 3D models is shown to synthesize successfully a flexible model of frontal face images and a flexible model of handwritten digits. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.R. Bergen and R. Hingorani. </author> <title> Hierarchical motion-based frame rate conversion. </title> <type> Technical re-port, </type> <institution> David Sarnoff Research Center, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: We have mostly used the multiresolution, laplacian-based, optical flow algorithm described in <ref> [1] </ref>. combination of image 1 and image 2 (in correspondence), the goal is to find the correspondence between image 1 (or image 2) and the novel image 3.
Reference: [2] <author> D. Beymer, A. Shashua, and T. Poggio. </author> <title> Example based image analysis and synthesis. </title> <journal> A.I. </journal> <volume> Memo 1431, </volume> <publisher> MIT, </publisher> <year> 1993. </year>
Reference-contexts: In this paper we describe a bootstrapping technique that seems capable of computing correspondence between prototypical images in cases in which standard optical flow algorithms fail. 1.2 Past work The "linear class" idea of [19] and [24] together with the image representation used by <ref> [2] </ref> (see [3] for a review) is the main motivation behind the work of this and previous papers.
Reference: [3] <author> David Beymer and Tomaso Poggio. </author> <title> Image repre-sentations for visual learning. </title> <booktitle> Science, </booktitle> <address> 272:19051909, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: In this paper we describe a bootstrapping technique that seems capable of computing correspondence between prototypical images in cases in which standard optical flow algorithms fail. 1.2 Past work The "linear class" idea of [19] and [24] together with the image representation used by [2] (see <ref> [3] </ref> for a review) is the main motivation behind the work of this and previous papers.
Reference: [4] <author> Andrew Blake and Michael Isard. </author> <title> 3d position, attitude and shape input using video tracking of hands and lips. </title> <booktitle> Computer Graphics Proceedings, </booktitle> <pages> pages 185-192, </pages> <year> 1994. </year>
Reference-contexts: The work of Taylor and coworkers et. al. ([6]; [7]; [8]; [9]; [10]; [11]; [15]) on active shape models is probably the closest to ours. Many other flexible models have been proposed, such as the model of Blake and Issard <ref> [4] </ref>. 2 Linear models In this section we formally specify the linear object class model and describe the matching algorithm used to analyze a novel image in terms of a flexible model. 2.1 Formal specification To write the linear object class model mathematically, we must first introduce some notation, which we
Reference: [5] <author> Chang Seok Choi, Toru Okazaki, Hiroshi Harashima, and Tsuyoshi Takebe. </author> <title> A system of an-alyzing and synthesizing facial images. </title> <journal> IEEE, </journal> <pages> pages 2665-2668, </pages> <year> 1991. </year>
Reference: [6] <author> T.F. Cootes and C.J. Taylor. </author> <title> Active shape models - 'smart snakes'. </title> <booktitle> British Machine Vision Conference, </booktitle> <pages> pages 266-275, </pages> <year> 1992. </year>
Reference: [7] <author> T.F. Cootes and C.J. Taylor. </author> <title> Using grey-level models to improve active shape model search. </title> <booktitle> International Conference on Pattern Recognition, </booktitle> <pages> pages 63-67, </pages> <year> 1994. </year>
Reference-contexts: Choi et. al. (1991) were perhaps the first (see also [18]) to suggest a model which represented face images with separate shape and texture components, using a 3D model to provide correspondences between example face images. The work of Taylor and coworkers et. al. ([6]; <ref> [7] </ref>; [8]; [9]; [10]; [11]; [15]) on active shape models is probably the closest to ours.
Reference: [8] <author> T.F. Cootes, C.J. Taylor, D.H. Cooper, and J. Graham. </author> <title> Training models of shape from sets of examples. </title> <booktitle> British Machine Vision Conference, </booktitle> <pages> pages 9-18, </pages> <year> 1992. </year>
Reference-contexts: Choi et. al. (1991) were perhaps the first (see also [18]) to suggest a model which represented face images with separate shape and texture components, using a 3D model to provide correspondences between example face images. The work of Taylor and coworkers et. al. ([6]; [7]; <ref> [8] </ref>; [9]; [10]; [11]; [15]) on active shape models is probably the closest to ours.
Reference: [9] <author> T.F. Cootes, C.J. Taylor, and A. Lanitis. </author> <title> Multiresolution search with active shape models. </title> <booktitle> International Conference on Pattern Recognition, </booktitle> <pages> pages 610-612, </pages> <year> 1994. </year>
Reference-contexts: Choi et. al. (1991) were perhaps the first (see also [18]) to suggest a model which represented face images with separate shape and texture components, using a 3D model to provide correspondences between example face images. The work of Taylor and coworkers et. al. ([6]; [7]; [8]; <ref> [9] </ref>; [10]; [11]; [15]) on active shape models is probably the closest to ours.
Reference: [10] <author> T.F. Cootes, C.J. Taylor, A. Lanitis, D.H. Cooper, and J. Graham. </author> <title> Building and using flex-ible models incorporating grey-level information. </title> <booktitle> In ICCV, </booktitle> <pages> pages 242-246, </pages> <address> Berlin, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Choi et. al. (1991) were perhaps the first (see also [18]) to suggest a model which represented face images with separate shape and texture components, using a 3D model to provide correspondences between example face images. The work of Taylor and coworkers et. al. ([6]; [7]; [8]; [9]; <ref> [10] </ref>; [11]; [15]) on active shape models is probably the closest to ours.
Reference: [11] <author> A. Hill, T.F. Cootes, and C.J. Taylor. </author> <title> A generic system for image interpretation using flexible templates. </title> <booktitle> British Machine Vision Conference, </booktitle> <pages> pages 276-285, </pages> <year> 1992. </year>
Reference-contexts: Choi et. al. (1991) were perhaps the first (see also [18]) to suggest a model which represented face images with separate shape and texture components, using a 3D model to provide correspondences between example face images. The work of Taylor and coworkers et. al. ([6]; [7]; [8]; [9]; [10]; <ref> [11] </ref>; [15]) on active shape models is probably the closest to ours.
Reference: [12] <author> Michael Jones and Tomaso Poggio. </author> <title> Model-based matching of line drawings by linear combinations of prototypes. </title> <booktitle> In Proceedings of the Fifth International Conference on Computer Vision, </booktitle> <pages> pages 531-536, </pages> <year> 1995. </year>
Reference: [13] <author> Michael Jones and Tomaso Poggio. </author> <title> Model-based matching by linear combinations of prototypes. A.i. memo, </title> <publisher> MIT, </publisher> <year> 1996. </year>
Reference-contexts: models In this section we formally specify the linear object class model and describe the matching algorithm used to analyze a novel image in terms of a flexible model. 2.1 Formal specification To write the linear object class model mathematically, we must first introduce some notation, which we summarize from <ref> [13] </ref>. An image I is viewed as a mapping I : R 2 ! I such that I (x; y) is the intensity value of point (x; y) in the image. Here we are only considering grey level images.
Reference: [14] <author> M. Kirby and L. Sirovich. </author> <title> The application of the karhunen-loeve procedure for the characterization of human faces. </title> <journal> IEEE, </journal> <volume> 12(1) </volume> <pages> 103-108, </pages> <month> January </month> <year> 1990. </year>
Reference: [15] <author> A. Lanitis, C.J. Taylor, and T.F. Cootes. </author> <title> A uni-fied approach to coding and interpreting face im-ages. </title> <booktitle> In ICCV, </booktitle> <pages> pages 368-373, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The work of Taylor and coworkers et. al. ([6]; [7]; [8]; [9]; [10]; [11]; <ref> [15] </ref>) on active shape models is probably the closest to ours.
Reference: [16] <author> Steve Lines. </author> <title> The Photorealistic Synthesis of Novel Views from Example Images. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1996. </year>
Reference-contexts: In our past papers we computed correspondence between the prototypes with automatic techniques such as optical flow. Some- times, however, we were forced to use interactive techniques requiring the user to specify at least some of the correspondences (see for instance <ref> [16] </ref>). An automatic technique that could set prototypes in correspondence would be therefore desirable even if very slow. In addition, any claim of biological plausibility would require the demonstration of such a technique.
Reference: [17] <author> Tomaso Poggio and David Beymer. </author> <title> Learning to see. </title> <journal> IEEE Spectrum, </journal> <pages> pages 60-69, </pages> <year> 1996. </year>
Reference-contexts: At the very heart of our flexible models is an image representation in terms of which a linear combination of images makes sense. For a set of images to behave as vectors, they must be in pixelwise correspondence (see <ref> [17] </ref>).
Reference: [18] <author> Tomaso Poggio and Roberto Brunelli. </author> <title> A novel ap-proach to graphics. </title> <journal> A.I. </journal> <volume> Memo 1354, </volume> <publisher> MIT, </publisher> <year> 1992. </year>
Reference-contexts: Recently we have become aware of several papers dealing with various forms of the idea of linear combination of prototypical images. Choi et. al. (1991) were perhaps the first (see also <ref> [18] </ref>) to suggest a model which represented face images with separate shape and texture components, using a 3D model to provide correspondences between example face images.
Reference: [19] <author> Tomaso Poggio and Thomas Vetter. </author> <title> Recognition and structure from one 2d model view: Observations on prototypes, object classes and symme-tries. </title> <journal> A.I. </journal> <volume> Memo 1347, </volume> <publisher> MIT, </publisher> <year> 1992. </year>
Reference-contexts: In addition, any claim of biological plausibility would require the demonstration of such a technique. In this paper we describe a bootstrapping technique that seems capable of computing correspondence between prototypical images in cases in which standard optical flow algorithms fail. 1.2 Past work The "linear class" idea of <ref> [19] </ref> and [24] together with the image representation used by [2] (see [3] for a review) is the main motivation behind the work of this and previous papers.
Reference: [20] <author> Amnon Shashua. </author> <title> Projective structure from two uncalibrated images: Structure from motion and recognition. </title> <journal> A.I. </journal> <volume> Memo 1363, </volume> <publisher> MIT, </publisher> <year> 1992. </year>
Reference-contexts: Poggio and Vetter introduced the idea of linear combinations of views to define and model classes of objects, trying to extend the results of [23] and <ref> [20] </ref> who showed that linear combinations of three views of a single object may be used to obtain any other views of the object (barring self-occlusion and assuming orthographic projection).
Reference: [21] <author> N. Troje and H.H. Bulthoff. </author> <title> Face recognition un-der varying pose: The role of texture and shape. </title> <journal> Vision Research, </journal> <volume> 36(12) </volume> <pages> 1761-1771, </pages> <year> 1995. </year>
Reference-contexts: One class was frontal views of human faces and the second was handwritten digits. 4.1 Face images 4.1.1 Data set 130 frontal images of caucasian faces were used in our experiments. The images were originally rendered for psychophysical experiments <ref> [21] </ref> under ambient illumination conditions from a data base of three-dimensional human head models recorded with a laser scanner (Cyberware T M ). All faces were without makeup, accessories, and facial hair. Additionally, the head hair was removed digitally (but with manual editing), via a vertical cut behind the ears.
Reference: [22] <author> M.A. Turk and A.P Pentland. </author> <title> Face recognition using eigenfaces. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 586591, </pages> <year> 1991. </year>
Reference-contexts: Additional support is provided by ATR Audio and Visual Perception Research Laboratories, Sumitomo Metal Industries, Kodak, Daimler-Benz and Siemens AG. between example images and should not be confused with techniques which use linear combinations of images such as the so-called eigenfaces technique ([14]; <ref> [22] </ref>). In our approach, the correspondences between a reference image and the other example images are obtained in a preprocessing phase. Once the correspondences are computed, an image is represented as a shape vector and a texture vector.
Reference: [23] <author> S. Ullman and R. Basri. </author> <title> Recognition by lin-ear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 992-1006, </pages> <year> 1991. </year>
Reference-contexts: Poggio and Vetter introduced the idea of linear combinations of views to define and model classes of objects, trying to extend the results of <ref> [23] </ref> and [20] who showed that linear combinations of three views of a single object may be used to obtain any other views of the object (barring self-occlusion and assuming orthographic projection).
Reference: [24] <author> Thomas Vetter and Tomaso Poggio. </author> <title> Linear object classes and image synthesis from a single example image. </title> <journal> A.I. </journal> <volume> Memo 1531, </volume> <publisher> MIT, </publisher> <year> 1995. </year>
Reference-contexts: In this paper we describe a bootstrapping technique that seems capable of computing correspondence between prototypical images in cases in which standard optical flow algorithms fail. 1.2 Past work The "linear class" idea of [19] and <ref> [24] </ref> together with the image representation used by [2] (see [3] for a review) is the main motivation behind the work of this and previous papers.
Reference: [25] <author> Paul Viola. </author> <title> Alignment by maximization of mu-tual information. MIT A.I. </title> <type> Technical Report 1548, </type> <institution> MIT, </institution> <year> 1995. </year>
Reference-contexts: So far we have used the L 2 norm for convenience but other norms may be more appropriate (e.g. robust statistics). In order to minimize the error function any minimization algorithm could be used. We have chosen to use the stochastic gradient descent algorithm <ref> [25] </ref> because it is fast and can escape from local minima. 2.3 Optical Flow For some prototypes, the pixelwise correspondences from the reference image to the prototype can be found accurately by an optical flow algorithm.
References-found: 25

