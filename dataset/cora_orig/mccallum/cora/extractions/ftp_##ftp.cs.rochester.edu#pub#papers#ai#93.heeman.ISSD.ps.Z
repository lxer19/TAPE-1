URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/93.heeman.ISSD.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/heeman/papers.html
Root-URL: 
Title: REPAIRING CONVERSATIONAL MISUNDERSTANDINGS AND NON-UNDERSTANDINGS  
Author: Graeme Hirst, Susan McRoy, Peter Heeman, Philip Edmonds, and Diane Horton 
Address: Toronto, Ontario M5S 1A4 Canada  
Affiliation: Department of Computer Science University of Toronto  
Abstract: Participants in a discourse sometimes fail to understand one another, but, when aware of the problem, collaborate upon or negotiate the meaning of a problematic utterance. To address nonunderstanding, we have developed two plan-based models of collaboration in identifying the correct referent of a description: one covers situations where both conversants know of the referent, and the other covers situations, such as direction-giving, where the recipient does not. In the models, conversants use the mechanisms of refashioning, suggestion, and elaboration, to collaboratively refine a referring expression until it is successful. To address misunderstanding, we have developed a model that combines intentional and social accounts of discourse to support the negotiation of meaning. The approach extends intentional accounts by using expectations deriving from social conventions in order to guide interpretation. Reflecting the inherent symmetry of the negotiation of meaning, all our models can act as both speaker and hearer, and can play both the role of the conversant who is not understood or misunderstood and the role of the conversant who fails to understand. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Appelt, Douglas E. </author> <title> Some pragmatic issues in the planning of definite and indefinite noun phrases. </title> <booktitle> Proceedings of the 23rd annual meeting of the Association for Computational Linguistics, </booktitle> <address> Chicago, </address> <year> 1985, </year> <pages> 198-203. </pages>
Reference-contexts: The first condition, originally described by Appelt <ref> [1] </ref>, is important because the success of the referring action depends on the hearer formulating a useful identification plan. We take the referring expression plan itself to be the identification plan. The mental actions in the intermediate plans encode only useful descriptions.
Reference: [2] <author> Appelt, Douglas E. </author> <title> Planning English referring expressions. </title> <journal> Artificial Intelligence, </journal> <volume> 26(1), </volume> <year> 1985, </year> <pages> 1-33. </pages>
Reference-contexts: In the rest of this section, we give a brief overview of the model; details may be found in references [20, 21]. 3.3 Plans for referring We extend the earlier approaches of Cohen [9] and Ap-pelt <ref> [2] </ref> in planning not only the occurrence of a referring expression but also, at the same level, its content.
Reference: [3] <author> Appelt, Douglas E. and Pollack, Martha E. </author> <title> Weighted abduction for plan ascription. </title> <booktitle> User Modeling and User-Adapted Interaction, </booktitle> <pages> 2(1-2), </pages> <year> 1992, </year> <pages> 1-25. </pages>
Reference-contexts: Although techniques have been developed to handle situations in which agents' plan libraries differ in some respects, e.g., Pollack [34], Calistri-Yeh [5], most current schemes have no mechanism for detecting discrepancies in, or for revising, the plans inferred. Appelt and Pollack <ref> [3] </ref> suggested the use of weighted abduction to model the nonmonotonic aspects of plan inference. Although the weighted axioms they define provide limited coverage, the method itself is interesting.
Reference: [4] <author> Blum-Kulka, S. and Weizman, E. </author> <title> The inevitability of misunderstandings: Discourse ambiguities. Text, </title> <type> 8(3), </type> <year> 1988, </year> <pages> 219-241. </pages>
Reference-contexts: The participant might then attempt to change the other's interpretation. For example, he might restate his message, or explicitly tell the other that she has misunderstood; or he might do nothing (cf <ref> [4] </ref>), perhaps in order to avoid social awkwardness.
Reference: [5] <author> Calistri-Yeh, Randall J. </author> <title> Utilizing user models to handle ambiguity and misconceptions in robust plan recognition. User Modelling and User-Adapted Interaction, </title> <type> 1(4), </type> <year> 1991, </year> <pages> 289-322. </pages>
Reference-contexts: Alternatively, the conversation might break down, leading one participant or the other to 1 Misunderstanding should not be confused with misconception. A misconception is an error in the prior knowledge of an participant. McCoy [26], Calistri-Yeh <ref> [5] </ref>, Pollack [33, 34], and others have studied the problem of how one participant can, in conversation, determine the misconceptions of another in order to correct them. determine that a misunderstanding has occurred. <p> Unfortunately, most existing plan recognition schemes cannot be employed as the foundation of a model of these sorts of miscommunication. Although techniques have been developed to handle situations in which agents' plan libraries differ in some respects, e.g., Pollack [34], Calistri-Yeh <ref> [5] </ref>, most current schemes have no mechanism for detecting discrepancies in, or for revising, the plans inferred. Appelt and Pollack [3] suggested the use of weighted abduction to model the nonmonotonic aspects of plan inference. Although the weighted axioms they define provide limited coverage, the method itself is interesting.
Reference: [6] <author> Clark, Herbert H. </author> <title> Arenas of language use. </title> <institution> The University of Chicago Press, Chicago, and Center for the Study of Language and Information, Stanford, </institution> <year> 1993. </year>
Reference-contexts: In an important series of experiments, Clark and his colleaguesespecially Wilkes-Gibbshave shown that conversants will often engage in a kind of negotiation in order for one of them to understand a reference that the other wishes to make <ref> [6, 8] </ref>. In their fundamental experiment, Clark and Wilkes-Gibbs gave pairs of subjects each a copy of a set of hard-to-describe tangram figures. The subjects' task was to arrange their sets in the same order, and to do so by conversation alone; neither could see the other's set.
Reference: [7] <author> Clark, Herbert H. and Marshall, Catherine R. </author> <title> Definite reference and mutual knowledge. </title> <booktitle> In [23], 10-62 and [6], </booktitle> <pages> 9-59. </pages>
Reference-contexts: Constraints on these actions express the conditions under which they can be used; for instance, that it be mutually believed that the object has a certain attribute <ref> [7, 31, 30] </ref>. These speech actions are the building blocks that referring expressions are made from.
Reference: [8] <author> Clark, Herbert H. and Wilkes-Gibbs, Deanna. </author> <title> Referring as a collaborative process. </title> <journal> Cognition, </journal> <volume> 22, </volume> <year> 1986, </year> <pages> 1-39. </pages> <note> Reprinted in [10],463-493 and in [6], 107-143. </note>
Reference-contexts: In an important series of experiments, Clark and his colleaguesespecially Wilkes-Gibbshave shown that conversants will often engage in a kind of negotiation in order for one of them to understand a reference that the other wishes to make <ref> [6, 8] </ref>. In their fundamental experiment, Clark and Wilkes-Gibbs gave pairs of subjects each a copy of a set of hard-to-describe tangram figures. The subjects' task was to arrange their sets in the same order, and to do so by conversation alone; neither could see the other's set.
Reference: [9] <author> Cohen, Philip R. </author> <year> 1981. </year> <title> The need for referent identification as a planned action. </title> <booktitle> Proceedings of the 7th International Joint Conference on Artificial Intelligence (IJCAI-81), </booktitle> <address> Vancouver, </address> <year> 1981, </year> <pages> 31-36. </pages>
Reference-contexts: In the rest of this section, we give a brief overview of the model; details may be found in references [20, 21]. 3.3 Plans for referring We extend the earlier approaches of Cohen <ref> [9] </ref> and Ap-pelt [2] in planning not only the occurrence of a referring expression but also, at the same level, its content.
Reference: [10] <author> Cohen, Philip R.; Morgan, Jerry; and Pollack, Martha E. </author> <title> (editors). Intentions in communication. </title> <address> Cambridge, MA, </address> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference: [11] <author> Coulthard, Malcolm and Brazil, David. Exchangestructure. In Coulthard, Malcolm and Montgomery, Martin (editors), </author> <title> Studies in discourse analysis. </title> <publisher> Routledge & Kegan Paul, </publisher> <address> London, </address> <year> 1984, </year> <pages> 82-106. </pages>
Reference-contexts: Consider Example 5 from Coulthard and Brazil <ref> [11] </ref>. In this example, B has responded to line 1 with an acknowledgement, interpreting line 1 as an inform. Example 5 1 A: So the meeting's on Friday. 2 B: Thanks. 3 A: No, I'm asking you.
Reference: [12] <author> Dale, Robert. </author> <title> Cooking up referring expressions. </title> <booktitle> Proceedings of the 27th annual meeting of the Association for Computational Linguistics, </booktitle> <address> Vancouver, </address> <year> 1989, </year> <pages> 68-75. </pages>
Reference-contexts: Acting as the mortar are intermediate plans that encode the knowledge of how a description can allow a hearer to identify an object, and these ensure that the referring expression includes sufficient descriptors that the hearer can (in the speaker's opinion) identify the referent (cf Dale <ref> [12] </ref>, Reiter [37]). The intermediate plans do this by having mental actions as steps in their decomposition. These mental actions determine which objects could be believed to be the referent of the referring expression.
Reference: [13] <author> Davis, J. R. </author> <title> Back Seat Driver: Voice assisted automobile navigation. </title> <type> PhD thesis, </type> <institution> MassachusettsInstitute of Technology, </institution> <year> 1989. </year>
Reference-contexts: Salience, for our purposes in direction-giving, is primarily visual prominence, but can also involve identi-fiability, familiarity, and functional importance [14, 25]. One approach is to encode the salient properties in a static hierarchy as Davis <ref> [13] </ref>, and Reiter and Dale [38] have done. But, ideally, salience should depend on the context surrounding the referent. For example, the height of a tall building would normally be salient, but not if it were surrounded by other tall buildings.
Reference: [14] <author> Devlin, A. S. </author> <title> The `small town' cognitive map: Adjusting to a new environment. </title> <editor> In Moore, G. and Golledge, R. (editors), </editor> <title> Environmental knowing: Theories, research and methods. </title> <editor> Dowden, Hutchinson and Ross, Stroudsburg, </editor> <address> PA. </address>
Reference-contexts: Now, the confidence value of each attribute is equivalent to its salience within the context of the referring expression. Salience, for our purposes in direction-giving, is primarily visual prominence, but can also involve identi-fiability, familiarity, and functional importance <ref> [14, 25] </ref>. One approach is to encode the salient properties in a static hierarchy as Davis [13], and Reiter and Dale [38] have done. But, ideally, salience should depend on the context surrounding the referent.
Reference: [15] <author> Edmonds, Philip Glenny. </author> <title> A computational model of collaboration on reference in direction-giving dialogues. </title> <type> MSc thesis, </type> <note> to be published as a technical report, </note> <institution> Department of Computer Science, University of Toronto, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: Nevertheless, people are, in general, quite successful in their use of language. That's because they have strategies fl This paper summarizes work reported in greater detail in references <ref> [15, 20, 21, 22, 27, 28] </ref>. y Susan McRoy is now at the Department of Electrical Engineering and Computer Science, University of Wisconsin-Milwaukee, Milwaukee, WI 53201, U.S.A. z Peter Heeman is now at the Department of Computer Science, University of Rochester, Rochester, NY 14627, U.S.A. for coping with their linguistic limitations. <p> In this dialogue, B has not understood the reference to the intersection at Lowell Street, and so suggests that the intersection might be marked. A replies with an elaboration of the initial expression. Edmonds <ref> [15] </ref> has presented a computational model of this type of collaboration that draws from Heeman and Hirst's model. The domain is that of giving directions for someone unfamiliar with an area to get to a particular place. In this section, we give an overview of Edmonds's model.
Reference: [16] <author> Eller, Rhonda and Carberry, Sandra. </author> <title> A meta-rule approach to flexible plan recognition in dialogue. </title> <booktitle> User Modeling and User-Adapted Interaction, </booktitle> <pages> 2(1-2), </pages> <year> 1992, </year> <pages> 27-53. </pages>
Reference-contexts: Appelt and Pollack [3] suggested the use of weighted abduction to model the nonmonotonic aspects of plan inference. Although the weighted axioms they define provide limited coverage, the method itself is interesting. Eller and Carberry <ref> [16] </ref> proposed another mechanism that performs detection and revision, based on the insight that dialogues requiring plan inference revision are analogous to semantically or syntactically ill-formed input.
Reference: [17] <author> Garfinkel, Harold. </author> <title> Studies in Ethnomethodology. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1967. </year> <note> (Reprinted by Polity Press, </note> <institution> Cam-bridge, </institution> <address> England, </address> <year> 1984.) </year>
Reference-contexts: However, there is another way to address misunderstanding that avoids this unconstrained inference of goals: use expectations deriving from social conventions (rather than intention) to guide interpretation. In sociological accounts provided by Ethnomethodol-ogy, both coherent discourse interactions and repairs of misunderstandings are normal activities guided by social conventions <ref> [17, 40] </ref>. There are conventions regarding the expected range of responses to every action, for example. People then can assume that others are behaving as expected, unless they have reason to believe otherwise. In this way, the conventions give speakers a guide to possible interpretations.
Reference: [18] <author> Goodman, Bradley A. </author> <title> Repairing reference identification failures by relaxation. </title> <booktitle> Proceedings of the 23rd annual meeting of the Association for Computational Linguistics, </booktitle> <address> Chicago, </address> <year> 1985, </year> <pages> 204-217. </pages>
Reference-contexts: If the speaker of the refashioning is the person who initiated the referring expression, then this choice is obviously pre-determined. Otherwise, the speaker must choose a possible candidate. Goodman <ref> [18] </ref> has addressed this problem for the case of when the referring expression overconstrains the choice of referent. He uses heuristics to relax the constraints of the description and to pick one that nearly fits it.
Reference: [19] <author> Hayes, Philip J. </author> <title> A representation for robot plans. </title> <booktitle> Proceedings of the 4th International Joint Conference on Artificial Intelligence (IJCAI-75), Tblisi, </booktitle> <pages> 181-188. </pages>
Reference-contexts: The second step is to refashion the referring expression so that it identifies the candidate chosen in the first step. This is done by using plan repair techniques <ref> [19, 45, 46] </ref>. Our technique is to identify a part of the plan that includes the constraint in error, to construct a replacement for it, and then to substitute the replacement into the old plan.
Reference: [20] <author> Heeman, Peter A. </author> <title> A computational model of collaboration on referring expressions. </title> <type> MSc thesis, </type> <note> published as technical report CSRI-251, </note> <institution> Department of Computer Science, University of Toronto. </institution>
Reference-contexts: Nevertheless, people are, in general, quite successful in their use of language. That's because they have strategies fl This paper summarizes work reported in greater detail in references <ref> [15, 20, 21, 22, 27, 28] </ref>. y Susan McRoy is now at the Department of Electrical Engineering and Computer Science, University of Wisconsin-Milwaukee, Milwaukee, WI 53201, U.S.A. z Peter Heeman is now at the Department of Computer Science, University of Rochester, Rochester, NY 14627, U.S.A. for coping with their linguistic limitations. <p> The system then switches back to the role of hearer and waits for a response from the other copy. In the rest of this section, we give a brief overview of the model; details may be found in references <ref> [20, 21] </ref>. 3.3 Plans for referring We extend the earlier approaches of Cohen [9] and Ap-pelt [2] in planning not only the occurrence of a referring expression but also, at the same level, its content. <p> He uses heuristics to relax the constraints of the description and to pick one that nearly fits it. This problem is beyond the scope of this research, and so we simply choose one of the referents arbitrarily (but see Heeman <ref> [20] </ref> for how a simplified version of Goodman's algorithm that only relaxes a single constraint can be incorporated into the planning paradigm). The second step is to refashion the referring expression so that it identifies the candidate chosen in the first step.
Reference: [21] <author> Heeman, Peter A. and Hirst, Graeme. </author> <title> Collaborating on referring expressions. </title> <address> MS, </address> <year> 1993, </year> <note> submitted for publication (available on request from the authors). </note>
Reference-contexts: Nevertheless, people are, in general, quite successful in their use of language. That's because they have strategies fl This paper summarizes work reported in greater detail in references <ref> [15, 20, 21, 22, 27, 28] </ref>. y Susan McRoy is now at the Department of Electrical Engineering and Computer Science, University of Wisconsin-Milwaukee, Milwaukee, WI 53201, U.S.A. z Peter Heeman is now at the Department of Computer Science, University of Rochester, Rochester, NY 14627, U.S.A. for coping with their linguistic limitations. <p> The system then switches back to the role of hearer and waits for a response from the other copy. In the rest of this section, we give a brief overview of the model; details may be found in references <ref> [20, 21] </ref>. 3.3 Plans for referring We extend the earlier approaches of Cohen [9] and Ap-pelt [2] in planning not only the occurrence of a referring expression but also, at the same level, its content.
Reference: [22] <author> Horton, Diane and Hirst, Graeme. </author> <title> Discrepancies in discourse models and miscommunication in conversation. </title> <booktitle> In Working notes of the AAAI fall symposium: Discoursestructure in natural language understanding and generation, </booktitle> <year> 1991, </year> <pages> 31-32. </pages>
Reference-contexts: Nevertheless, people are, in general, quite successful in their use of language. That's because they have strategies fl This paper summarizes work reported in greater detail in references <ref> [15, 20, 21, 22, 27, 28] </ref>. y Susan McRoy is now at the Department of Electrical Engineering and Computer Science, University of Wisconsin-Milwaukee, Milwaukee, WI 53201, U.S.A. z Peter Heeman is now at the Department of Computer Science, University of Rochester, Rochester, NY 14627, U.S.A. for coping with their linguistic limitations. <p> We have characterized the types of discourse-model discrepancy that can arise, and for most, have constructed or found natural instances of examples <ref> [22] </ref>. In example 7, in which the conversants are planning a party, B misunderstands A's ellipsis in line 7, (as do you want to ask Karin to come to the party? instead of do you want to ask Karin for the recipe?) and thinks that a topic shift has occurred.
Reference: [23] <editor> Joshi, Aravind K.; Webber, Bonnie L., and Sag, Ivan (editors). </editor> <booktitle> Elements of discourse understanding. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1981. </year>
Reference: [24] <author> Lambert, Lynn and Carberry, Sandra. </author> <title> A tripartite plan-based model for dialogue. </title> <booktitle> Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Berkeley, </address> <year> 1991, </year> <pages> 47-54. </pages>
Reference-contexts: However, a speaker sometimes has to refer to an object that is not previously known to the hearer. One particular situation in which this arises is in giving directions. For example, the speaker might give a direction like the following: from the first two (cf Lambert and Carberry <ref> [24] </ref>). Example 3 1 A: Go straight ahead until you get to a funny-looking building. The recipient has to understand the reference well enough that when he later reaches the building, he will recognize it as the intended referent.
Reference: [25] <author> Lynch, K. </author> <title> The image of the city. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Now, the confidence value of each attribute is equivalent to its salience within the context of the referring expression. Salience, for our purposes in direction-giving, is primarily visual prominence, but can also involve identi-fiability, familiarity, and functional importance <ref> [14, 25] </ref>. One approach is to encode the salient properties in a static hierarchy as Davis [13], and Reiter and Dale [38] have done. But, ideally, salience should depend on the context surrounding the referent.
Reference: [26] <author> McCoy, Kathleen Filliben. </author> <title> Generating context-sensitive responses to object misconceptions. </title> <journal> Artificial Intelligence, </journal> <volume> 41(2), </volume> <month> December </month> <year> 1989, </year> <pages> 157-195. </pages>
Reference-contexts: Alternatively, the conversation might break down, leading one participant or the other to 1 Misunderstanding should not be confused with misconception. A misconception is an error in the prior knowledge of an participant. McCoy <ref> [26] </ref>, Calistri-Yeh [5], Pollack [33, 34], and others have studied the problem of how one participant can, in conversation, determine the misconceptions of another in order to correct them. determine that a misunderstanding has occurred.
Reference: [27] <author> McRoy, Susan W. </author> <title> Abductive interpretation and reinterpreta-tion of natural language utterances. </title> <type> PhD thesis, </type> <note> published as technical report CSRI-288, </note> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1993. </year>
Reference-contexts: Nevertheless, people are, in general, quite successful in their use of language. That's because they have strategies fl This paper summarizes work reported in greater detail in references <ref> [15, 20, 21, 22, 27, 28] </ref>. y Susan McRoy is now at the Department of Electrical Engineering and Computer Science, University of Wisconsin-Milwaukee, Milwaukee, WI 53201, U.S.A. z Peter Heeman is now at the Department of Computer Science, University of Rochester, Rochester, NY 14627, U.S.A. for coping with their linguistic limitations. <p> What these accounts lack that computational accounts provide is an explanation of how people can identify the convention that is relevant, especially when there is no pre-existing expectation. 5.3 A synthesis In our work (described more fully in references <ref> [27, 28] </ref>) we have developed a model of interaction that addresses the possibility that the participants might differ about the speech act that is performed by some utterance, without requiring extended reasoning about the speaker's goals.
Reference: [28] <author> McRoy, Susan W. and Hirst, Graeme. </author> <title> Abductive explanation of dialogue misunderstandings. </title> <booktitle> Proceedings of the 6th conference of the European chapter of the Association for Computational Linguistics, </booktitle> <address> Utrecht, The Netherlands, </address> <year> 1993, </year> <pages> 277-286. </pages>
Reference-contexts: Nevertheless, people are, in general, quite successful in their use of language. That's because they have strategies fl This paper summarizes work reported in greater detail in references <ref> [15, 20, 21, 22, 27, 28] </ref>. y Susan McRoy is now at the Department of Electrical Engineering and Computer Science, University of Wisconsin-Milwaukee, Milwaukee, WI 53201, U.S.A. z Peter Heeman is now at the Department of Computer Science, University of Rochester, Rochester, NY 14627, U.S.A. for coping with their linguistic limitations. <p> What these accounts lack that computational accounts provide is an explanation of how people can identify the convention that is relevant, especially when there is no pre-existing expectation. 5.3 A synthesis In our work (described more fully in references <ref> [27, 28] </ref>) we have developed a model of interaction that addresses the possibility that the participants might differ about the speech act that is performed by some utterance, without requiring extended reasoning about the speaker's goals.
Reference: [29] <author> McRoy, Susan W. and Hirst, Graeme. </author> <title> Misunderstanding and the negotiation of meaning. </title> <booktitle> Working notes of the AAAI fall symposium: Human-computer collaboration: Reconciling theory, synthesizing practice, </booktitle> <address> Raleigh, NC, </address> <month> November </month> <year> 1993. </year>
Reference: [30] <author> Nadathur, Gopalan and Joshi, Aravind K. </author> <title> Mutual beliefs in conversational systems: Their role in referring expressions. </title> <booktitle> Proceedings of the 8th International Joint Conference on Artificial Intelligence (IJCAI-83), </booktitle> <address> Karlsruhe, </address> <year> 1983, </year> <pages> 603-605. </pages>
Reference-contexts: Constraints on these actions express the conditions under which they can be used; for instance, that it be mutually believed that the object has a certain attribute <ref> [7, 31, 30] </ref>. These speech actions are the building blocks that referring expressions are made from.
Reference: [31] <author> Perrault, C. Raymond and Cohen, Philip R. </author> <title> It's for your own good: A note on inaccurate reference. </title> <booktitle> In [23], </booktitle> <pages> 217-230. </pages>
Reference-contexts: Constraints on these actions express the conditions under which they can be used; for instance, that it be mutually believed that the object has a certain attribute <ref> [7, 31, 30] </ref>. These speech actions are the building blocks that referring expressions are made from.
Reference: [32] <author> Perrault, C. Raymond. </author> <title> An application of default logic to speech act theory. </title> <booktitle> In [10], </booktitle> <pages> 161-186. </pages>
Reference-contexts: And, s may perform a fourth-turn repair. 9 A related concern is how an agent's beliefs might change after an utterance has been understood as an act of a particular type. Although we have nothing new to add here, Perrault <ref> [32] </ref> shows how default logic might be used to address this problem. 5.5 Example We have implemented the model in Prolog and the Theorist [35, 44] framework for abduction with prioritized defaults.
Reference: [33] <author> Pollack, Martha E. </author> <title> A model of plan inference that distinguishes between the beliefs of actors and observers. </title> <booktitle> Proceedings of the 24th annual meeting of the Association for Computational Linguistics, </booktitle> <address> New York, </address> <year> 1986, </year> <pages> 207-214. </pages>
Reference-contexts: Alternatively, the conversation might break down, leading one participant or the other to 1 Misunderstanding should not be confused with misconception. A misconception is an error in the prior knowledge of an participant. McCoy [26], Calistri-Yeh [5], Pollack <ref> [33, 34] </ref>, and others have studied the problem of how one participant can, in conversation, determine the misconceptions of another in order to correct them. determine that a misunderstanding has occurred.
Reference: [34] <author> Pollack, Martha E. </author> <title> Plans as complex mental attitudes. </title> <booktitle> In [10], </booktitle> <pages> 77-103. </pages>
Reference-contexts: Alternatively, the conversation might break down, leading one participant or the other to 1 Misunderstanding should not be confused with misconception. A misconception is an error in the prior knowledge of an participant. McCoy [26], Calistri-Yeh [5], Pollack <ref> [33, 34] </ref>, and others have studied the problem of how one participant can, in conversation, determine the misconceptions of another in order to correct them. determine that a misunderstanding has occurred. <p> These mental actions determine which objects could be believed to be the referent of the referring expression. The mental actions are performed on the potential referents, and the constraints are evaluated, and so the referent can be determined in a manner analogous to constraint satisfaction. Following Pollack <ref> [34] </ref>, our plan inference process can infer plans in which, in the hearer's view, either a constraint does not hold or a mental action is not executable. <p> Unfortunately, most existing plan recognition schemes cannot be employed as the foundation of a model of these sorts of miscommunication. Although techniques have been developed to handle situations in which agents' plan libraries differ in some respects, e.g., Pollack <ref> [34] </ref>, Calistri-Yeh [5], most current schemes have no mechanism for detecting discrepancies in, or for revising, the plans inferred. Appelt and Pollack [3] suggested the use of weighted abduction to model the nonmonotonic aspects of plan inference.
Reference: [35] <author> Poole, David; Goebel, Randy; and Aleliunas, Romas. </author> <title> Theorist: A logical reasoning system for defaults and diagnosis. </title> <editor> In: Cercone, Nick and McCalla, Gordon, editors, </editor> <booktitle> The knowledge frontier: Essays in the representation of knowledge, </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987, </year> <pages> 331-352. </pages>
Reference-contexts: They filter these expectations by considering the consistency of the Gricean intentions that they have expressed. By contrast, previous models of discourse attempt to eliminate interpretations by using some (necessarily incomplete) set of felicity conditions. * An axiomatization in Prioritized Theorist <ref> [35] </ref>. Theorist is a declarative framework for default and abductive reasoning. <p> Although we have nothing new to add here, Perrault [32] shows how default logic might be used to address this problem. 5.5 Example We have implemented the model in Prolog and the Theorist <ref> [35, 44] </ref> framework for abduction with prioritized defaults.
Reference: [36] <author> Psathas, George. </author> <title> The structure of direction-giving in interaction. </title> <editor> In Boden, Deirdre and Zimmerman, Don H. (editors), </editor> <title> Talk and social structure: Studies in ethnomethodology and conversation analysis. </title> <publisher> Polity Press, </publisher> <address> Cambridge, England, </address> <year> 1991, </year> <pages> 195-216. </pages>
Reference-contexts: Although this type of reference is different from the kind of referring action that Heeman and Hirst modelled, conversants can nevertheless collaborate to achieve an understanding of them. This can be seen in the following portion of a telephone conversation recorded by Psathas <ref> [36, p. 196] </ref>. Example 4 1 A: Ya just stay on 2A, until ya get to Lowell Street. 2 B: Is it marked? 3 A: Yeah, I think there's a street sign there, it's an intersection with lights. 4 B: Okay.
Reference: [37] <author> Reiter, Ehud. </author> <title> The computational complexity of avoiding conversational implicature. </title> <booktitle> Proceedings of the 28th annual meeting of the Association for Computational Linguistics, </booktitle> <address> Pittsburgh, </address> <year> 1990, </year> <pages> 97-104. </pages>
Reference-contexts: Acting as the mortar are intermediate plans that encode the knowledge of how a description can allow a hearer to identify an object, and these ensure that the referring expression includes sufficient descriptors that the hearer can (in the speaker's opinion) identify the referent (cf Dale [12], Reiter <ref> [37] </ref>). The intermediate plans do this by having mental actions as steps in their decomposition. These mental actions determine which objects could be believed to be the referent of the referring expression.
Reference: [38] <author> Reiter, Ehud and Dale, Robert. </author> <title> A fast algorithm for the generation of referring expressions. </title> <booktitle> Proceedings of the 14th International Conference on Computational Linguistics (COLING-92), </booktitle> <address> Nantes, </address> <year> 1992, </year> <pages> 232-238. </pages>
Reference-contexts: Salience, for our purposes in direction-giving, is primarily visual prominence, but can also involve identi-fiability, familiarity, and functional importance [14, 25]. One approach is to encode the salient properties in a static hierarchy as Davis [13], and Reiter and Dale <ref> [38] </ref> have done. But, ideally, salience should depend on the context surrounding the referent. For example, the height of a tall building would normally be salient, but not if it were surrounded by other tall buildings.
Reference: [39] <author> Schegloff, Emanuel A. </author> <title> Some sources of misunderstanding in talk-in-interaction. </title> <journal> Linguistics, </journal> <volume> 25, </volume> <year> 1987, </year> <pages> 201-218. </pages>
Reference-contexts: If a conversant hears an utterance that seems inconsistent with her expectations (perhaps because she has misunderstood some previous utterance) and the inconsistency leads her to reinterpret an earlier utterance and produce a new response to it, this is a fourth-turn (or fourth-position) repair <ref> [39] </ref>. Such repairs not only display the alternative interpretations, but also indicate some of the information that may underlie a participant's decision to favor one of them over another. Consider the fragment of conversation between a mother and her child (named Russ), shown in Example 6 [43].
Reference: [40] <author> Schegloff, Emanuel A. </author> <title> Repair after next turn: The last structurally provided defense of intersubjectivity in conversation. </title> <journal> American Journal of Sociology, </journal> <volume> 97(5), </volume> <year> 1992, </year> <pages> 1295-1345. </pages>
Reference-contexts: However, there is another way to address misunderstanding that avoids this unconstrained inference of goals: use expectations deriving from social conventions (rather than intention) to guide interpretation. In sociological accounts provided by Ethnomethodol-ogy, both coherent discourse interactions and repairs of misunderstandings are normal activities guided by social conventions <ref> [17, 40] </ref>. There are conventions regarding the expected range of responses to every action, for example. People then can assume that others are behaving as expected, unless they have reason to believe otherwise. In this way, the conventions give speakers a guide to possible interpretations.
Reference: [41] <author> Schegloff, Emanuel A.; Jefferson, Gail; and Sacks, Harvey. </author> <title> The preference for self-correction in the organization of repair in conversation. </title> <booktitle> Language, </booktitle> <volume> 53, </volume> <year> 1977, </year> <pages> 361-382. </pages>
Reference-contexts: Russ recovers by reinterpreting line 1 as an indirect request, which his line 4 attempts to satisfy. This example also demonstrates agents' reluctance to repair the problems in the utterances of others <ref> [41] </ref>; although Mother might have produced a third-turn repair at line 3, the manifestation of a misunderstanding provided her with an expectable option that allowed her to avoid having to produce an explicit repair. 5.2 The need for both intentional and social information Any dialogue system must account for the detection
Reference: [42] <author> Svartvik, Jan and Quirk, Randolph. </author> <title> A corpus of English conversation. Lund Studies in English 56. </title> <institution> C.W.K. Gleerup, Lund, </institution> <year> 1980. </year>
Reference-contexts: A then accepts the refashioned referring expression in line 3. This kind of reference negotiation is not found only in laboratory settings. A particularly clear instance can be seen in the following example from the London-Lund Corpus of English conversation <ref> [42, S.2.4a:1-8] </ref>, in which the conversants collaborate simultaneously on the phrases that weird creature and over there.
Reference: [43] <author> Terasaki, A. </author> <title> Pre-announcement sequences in conversation. </title> <institution> Social Science Working Paper 99, School of Social Science, University of California, Irvine. </institution> <year> 1976. </year>
Reference-contexts: Such repairs not only display the alternative interpretations, but also indicate some of the information that may underlie a participant's decision to favor one of them over another. Consider the fragment of conversation between a mother and her child (named Russ), shown in Example 6 <ref> [43] </ref>. Example 6 1 Mother: Do you know who's going to that meeting? 2 Russ: Who? 3 Mother: I don't know. 4 Russ: Oh. Probably Mrs McOwen and probably Mrs Cadry and some of the teachers.
Reference: [44] <author> Van Arragon, Paul. </author> <title> Nested default reasoning for user modeling. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Waterloo, Waterloo, </institution> <address> Ontario, </address> <year> 1990. </year> <note> Published by the department as Research Report CS-90-25. </note>
Reference-contexts: Although we have nothing new to add here, Perrault [32] shows how default logic might be used to address this problem. 5.5 Example We have implemented the model in Prolog and the Theorist <ref> [35, 44] </ref> framework for abduction with prioritized defaults.
Reference: [45] <author> Wilensky, Robert. </author> <title> A model for planning in complex situations. </title> <journal> Cognition and Brain Theory, </journal> <volume> 4, </volume> <year> 1981. </year>
Reference-contexts: The second step is to refashion the referring expression so that it identifies the candidate chosen in the first step. This is done by using plan repair techniques <ref> [19, 45, 46] </ref>. Our technique is to identify a part of the plan that includes the constraint in error, to construct a replacement for it, and then to substitute the replacement into the old plan.
Reference: [46] <author> Wilkens, David E. </author> <title> Recovering from execution errors in SIPE. </title> <journal> Computational Intelligence, </journal> <volume> 1, </volume> <year> 1985, </year> <pages> 33-45. </pages>
Reference-contexts: The second step is to refashion the referring expression so that it identifies the candidate chosen in the first step. This is done by using plan repair techniques <ref> [19, 45, 46] </ref>. Our technique is to identify a part of the plan that includes the constraint in error, to construct a replacement for it, and then to substitute the replacement into the old plan.
References-found: 46

