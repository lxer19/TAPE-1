URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/jass/www/papers/super96.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/jass/www/papers.html
Root-URL: 
Email: jass@cs.cmu.edu  
Title: Impact of Job Mix on Optimizations for Space Sharing Schedulers  
Author: Jaspal Subhlok Thomas Gross and Takashi Suzuoka 
Keyword: backfilling, job characteristics, job scheduling, scheduling optimizations, space sharing, space slicing, supercomputer workloads  
Note: Appears in Proceedings of Supercomputing '96 Further information and copies available from: http://www.cs.cmu.edu/fx  
Web: http://www.cs.cmu.edu/jass  
Address: Pittsburgh, PA 15213  Pittsburgh, PA 15213  8092 Zuerich, Switzerland  1, Komukai, Toshiba-Cho, Saiwai-Ku, Kawasaki 210, Japan  
Affiliation: School of Computer Science, Carnegie Mellon University,  School of Computer Science, Carnegie Mellon University,  Institut fuer Computersysteme, ETH Zuerich,  Toshiba Corporation,  
Abstract: Modern parallel systems with N nodes can concurrently service multiple jobs requesting a total of up to to N nodes. One of the challenges for the operating system is to give reasonable service to a diverse group of jobs. A sequence of large jobs, each requiring over half of the available nodes, can reduce the machine utilization by up to 50%, but scheduling a long running job on the idle nodes may block the stream of large jobs. Various policies have been proposed for scheduling parallel computers, but as the users of current supercomputers know, these policies are far from perfect. This paper reports on the measurement of the usage of a 512-node IBM SP2 at Cornell Theory Center, a 96-node Intel Paragon at ETH Zurich, and a 512-node Cray T3D at Pittsburgh Supercomputing Center. We discuss the characteristics of the different workloads and examine their impact on job scheduling. We specifically show how two simple scheduling optimizations based on reordering the waiting queue can be used effectively to improve scheduling performance on real workloads. Supercomputer workloads from different installations exhibit some common characteristics, but they also differ in important ways We demonstrate how this knowledge can be exploited in the design and tuning of schedulers. 
Abstract-found: 1
Intro-found: 1
Reference: [CT94] <author> P. Chuang and N. Tzeng. </author> <title> Allocating precise submeshes in mesh connected systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 5(2):211217, </volume> <month> Feb. </month> <year> 1994. </year> <month> 17 </month>
Reference-contexts: The dominant use of power-of-2 numbers of nodes is useful information, because several scheduling techniques discussed in the literature make the assumption that jobs must execute on a power-of-2 number of nodes <ref> [LC91, CT94, DB93] </ref>. These techniques may be broadly applicable but they must allow for node numbers that are not powers of 2.
Reference: [DB93] <author> J. Ding and L. Bhuyan. </author> <title> An adaptive submesh allocation strategy for two-dimensional mesh connected systems. </title> <booktitle> In Proc. International Conference on Parallel Processing, pages 193200, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: The dominant use of power-of-2 numbers of nodes is useful information, because several scheduling techniques discussed in the literature make the assumption that jobs must execute on a power-of-2 number of nodes <ref> [LC91, CT94, DB93] </ref>. These techniques may be broadly applicable but they must allow for node numbers that are not powers of 2.
Reference: [Fei94] <author> D. Feitelson. </author> <title> A survey of scheduling in multiprogrammed parallel systems. </title> <type> Technical Report Research Report RC 19790(87657), </type> <institution> IBM T. J. Watson Research Center, </institution> <year> 1994. </year>
Reference-contexts: Large commercial parallel systems support dynamic partitions and time sharing, although not all sites choose to operate their system that way; instead, space sharing is the preeminent approach used today. Most commercial systems can support a variety of scheduling policies <ref> [Fei94] </ref> and they typically allow the system manager to tune a scheduling policy with a set of parameters. However, our experience shows that the actual scheduling policies used are not always the best way to use a machine.
Reference: [FN95] <author> D. Feitelson and B. Nitzberg. </author> <title> Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/860. </title> <booktitle> In Proc. IPPS'95 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 215227, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: We would like to point out that a full understanding of the usage of each of these parallel machines requires a detailed study (see, e.g., <ref> [FN95, HSO96, Hot96, WLF + 96] </ref>). However, the purpose of this section is to focus on those aspects of supercomputer usage that reveal patterns across multiple installations, with the objective of employing this commonality of behavior to select, develop, and validate scheduling algorithms and optimizations. <p> On the Paragon and the T3D, machine usage by jobs using 4 or fewer nodes is negligible, while it is around 11 percent for the SP2 2 . Similar results are reported for the usage of an Intel iPSC 860 machine at NASA <ref> [FN95] </ref>. The general conclusion is that a significant number of jobs may use only a few nodes, but these jobs consume a relatively small part of the compute resources.
Reference: [Hot96] <author> S. Hotovy. </author> <title> Workload evolution on the Cornell Theory Center IBM SP2. </title> <booktitle> In IPPS '96 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 272273, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: We would like to point out that a full understanding of the usage of each of these parallel machines requires a detailed study (see, e.g., <ref> [FN95, HSO96, Hot96, WLF + 96] </ref>). However, the purpose of this section is to focus on those aspects of supercomputer usage that reveal patterns across multiple installations, with the objective of employing this commonality of behavior to select, develop, and validate scheduling algorithms and optimizations.
Reference: [HSO96] <author> S. Hotovy, D. Schneider, and T. O'Donnell. </author> <title> Analysis of the Early workload on the Cornell Theory Center IBM SP2. </title> <booktitle> In Proc. SIGMETRICS' 96, </booktitle> <pages> pages 272273, </pages> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year> <note> Full version available as CTC Technical Report No. 234 at http://www.tc.cornell.edu/Research/tech.rep.html. </note>
Reference-contexts: We would like to point out that a full understanding of the usage of each of these parallel machines requires a detailed study (see, e.g., <ref> [FN95, HSO96, Hot96, WLF + 96] </ref>). However, the purpose of this section is to focus on those aspects of supercomputer usage that reveal patterns across multiple installations, with the objective of employing this commonality of behavior to select, develop, and validate scheduling algorithms and optimizations.
Reference: [IBM95] <institution> IBM. IBM LoadLeveler Adminstration Guide, </institution> <month> August </month> <year> 1995. </year>
Reference: [Int94] <author> Intel. </author> <title> Paragon User's Guide, </title> <month> June </month> <year> 1994. </year>
Reference: [LC91] <author> K. Li and K. Cheng. </author> <title> Job scheduling in a partitionable mesh using a two-dimensional buddy system partitioning scheme. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 2(4):pp. 413422, </volume> <year> 1991. </year>
Reference-contexts: The dominant use of power-of-2 numbers of nodes is useful information, because several scheduling techniques discussed in the literature make the assumption that jobs must execute on a power-of-2 number of nodes <ref> [LC91, CT94, DB93] </ref>. These techniques may be broadly applicable but they must allow for node numbers that are not powers of 2. <p> This optimization can also improve the utilization of the machine when there is a large waiting queue, as smaller jobs are more likely to fit together on the machine. Note that this optimization is different from the sorting algorithm that places the larger jobs in front <ref> [LC91] </ref>. Our workloads exhibit a large number of small jobs in the job mix. Hence we expect sorting of job queue to improve the overall throughput and turnaround time.
Reference: [LHR95] <author> D. Lifka, M. Henderson, and K. Rayl. </author> <title> Users guide to the Argonne SP scheduling system. </title> <type> Technical Report ANL/MCS-TM-201, </type> <institution> Mathematics and Computer Science Division, </institution> <year> 1995. </year>
Reference-contexts: This technique is called backfilling. It has been in use at the IBM SP2 installation 13 at the Argonne National Laboratory <ref> [LHR95] </ref> and is being installed with a new scheduler on the IBM SP2 at the Cornell Theory Center. Backfilling assumes that the execution times of jobs are known ahead of time.
Reference: [LLNW94] <author> W. Liu, V. Lo, B. Nitzberg, and K. Windisch. </author> <title> Non-contiguous processor allocation algorithms for distributed memory multicomputers. </title> <booktitle> In Supercomputing '94, </booktitle> <pages> pages 227236, </pages> <address> Washington, D.C, </address> <month> Nov </month> <year> 1994. </year>
Reference: [Ous82] <author> J. Ousterhout. </author> <title> Scheduling techniques for concurrent systems. </title> <booktitle> In Proc. 3rd International Conference on Distributed Computing systems, </booktitle> <pages> pages 2230, </pages> <year> 1982. </year>
Reference: [SCZL96] <author> J. Skovira, W. Chan, H. Zhou, and D. Lifka. </author> <title> The EASY - LoadLeveler API project. </title> <booktitle> In IPPS '96 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: IBM SP2 at Cornell Theory Center was primarily using LoadLeveler for scheduling for the duration in which the data was collected, although it has since been replaced by EASY-LL sched-uler <ref> [SCZL96] </ref>. The Intel Paragon at ETH primarily uses NQS for scheduling. The usage presented only represents the jobs scheduled by NQS and LoadLeveler respectively, since the usage data is obtained from the scheduler logs. <p> However, in related work we have observed that reasonable approximations to the actual execution time can be effective in obtaining the benefits of backfilling. On a practical note, preliminary experience with EASY-LL scheduler <ref> [SCZL96] </ref> at Cornell Theory Center has been very positive, in part because the workload appears to adapt to make the best use of backfilling. 5.4 Relationship between job mix and optimization We first analyze the impact of the two scheduling optimizations on the IBM SP2.
Reference: [WLF + 96] <author> K. Windisch, V. Lo, D. Feitelson, B. Nitzberg, and R. Moore. </author> <title> A comparison of workload traces from two production parallel machines. </title> <type> Technical Report CIS-TR-96-06, </type> <institution> University of Oregon, </institution> <month> April </month> <year> 1996. </year> <month> 18 </month>
Reference-contexts: We would like to point out that a full understanding of the usage of each of these parallel machines requires a detailed study (see, e.g., <ref> [FN95, HSO96, Hot96, WLF + 96] </ref>). However, the purpose of this section is to focus on those aspects of supercomputer usage that reveal patterns across multiple installations, with the objective of employing this commonality of behavior to select, develop, and validate scheduling algorithms and optimizations.
References-found: 14

