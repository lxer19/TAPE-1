URL: http://www.cs.unm.edu/~bap/papers/nips91-descent.ps.gz
Refering-URL: http://www.cs.unm.edu/~bap/publications.html
Root-URL: http://www.cs.unm.edu
Email: pearlmutter-barak@yale.edu  
Title: Gradient Descent: Second-Order Momentum and Saturating Error  
Author: Barak Pearlmutter 
Keyword: p  
Address: P.O. Box 11A Yale Station New Haven, CT 06520-7447  
Affiliation: Department of Psychology  
Note: To appear in the proceedings of NIPS*4, Morgan Kaufmann 1992.  
Abstract: 4 max = min where min and max are the minimum and maximum eigenvalues of the Hessian matrix of E with respect to w. It was recently shown that adding a momentum term w(t) = jdE=dw(t) + ffw(t 1) improves this to max = min , although only in the batch case. Here we show that second-order momentum, w(t) = jdE=dw(t) + ffw(t 1) + fiw(t 2), can lower this no further. We then regard gradient descent with momentum as a dynamic system and explore a nonquadratic error surface, showing that saturation of the error accounts for a variety of effects observed in simulations and justifies some popular heuristics.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Thomas Alexander. </author> <title> Adaptive Signal Processing. </title> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: and observe some effect not predicted by theory; and account for these effects by analyzing gradient descent with momentum on a saturating error surface. 1.1 SIMPLE GRADIENT DESCENT First, let us review the bounds on the convergence rate of simple gradient descent without momentum to a minimum of quadratic form <ref> [11, 1] </ref>. Let w fl be the minimum of E, the error, H = d 2 E=dw 2 (w fl ), and i , v i be the eigenvalues and eigenvectors of H.
Reference: [2] <author> H. S. Dabis and T. J. Moir. </author> <title> Least mean squares as a control system. </title> <journal> International Journal of Control, </journal> <volume> 54(2) </volume> <pages> 321-335, </pages> <year> 1991. </year>
Reference-contexts: Adjusting the momentum feels easier to practitioners than adjusting the learning rate, as too high a value leads to small oscillations rather than divergence, and techniques from control theory can be applied to the problem <ref> [2] </ref>.
Reference: [3] <author> Yan Fang and Terrence J. Sejnowski. </author> <title> Faster learning for dynamic recurrent backpropagation. </title> <journal> Neural Computation, </journal> <volume> 2(3) </volume> <pages> 270-273, </pages> <year> 1990. </year>
Reference-contexts: Finding these optimal values in practice is beyond the scope of this paper, but some techniques for achieving nearly optimal learning rates are available <ref> [4, 10, 8, 7, 3] </ref>. Adjusting the momentum feels easier to practitioners than adjusting the learning rate, as too high a value leads to small oscillations rather than divergence, and techniques from control theory can be applied to the problem [2].
Reference: [4] <author> Robert A. Jacobs. </author> <title> Increased rates of convergence through learning rate adaptation. </title> <booktitle> Neural Networks, </booktitle> <volume> 1(4) </volume> <pages> 295-307, </pages> <year> 1988. </year>
Reference-contexts: Finding these optimal values in practice is beyond the scope of this paper, but some techniques for achieving nearly optimal learning rates are available <ref> [4, 10, 8, 7, 3] </ref>. Adjusting the momentum feels easier to practitioners than adjusting the learning rate, as too high a value leads to small oscillations rather than divergence, and techniques from control theory can be applied to the problem [2].
Reference: [5] <author> David E. Rumelhart, Geoffrey E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart, J. L. McClelland, and the PDP research group., editors, </editor> <booktitle> Parallel distributed processing: Explorations in the microstructure of cognition, Volume 1: Foundations. </booktitle> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: (3) where we use s = min = max for the inverse eigenvalues spread of H and O is read "asymptotically converges to zero more slowly than." 1.2 FIRST-ORDER MOMENTUM Sometimes a momentum term is used, the weight update (1) being modified to incorporate a momentum term ff &lt; 1 <ref> [5, equation 16] </ref>, w (t) = j dw The Momentum LMS algorithm, MLMS, has been analyzed by Shynk and Roy [6], who have shown that the momentum term can not speed convergence in the online, or stochastic gradient, case.
Reference: [6] <author> J. J. Shynk and S. Roy. </author> <title> The LMS algorithm with momentum updating. </title> <booktitle> In Proceedings of the IEEE International Symposium on Circuits and Systems, </booktitle> <pages> pages 2651-2654, </pages> <month> June 6-9 </month> <year> 1988. </year>
Reference-contexts: "asymptotically converges to zero more slowly than." 1.2 FIRST-ORDER MOMENTUM Sometimes a momentum term is used, the weight update (1) being modified to incorporate a momentum term ff &lt; 1 [5, equation 16], w (t) = j dw The Momentum LMS algorithm, MLMS, has been analyzed by Shynk and Roy <ref> [6] </ref>, who have shown that the momentum term can not speed convergence in the online, or stochastic gradient, case.
Reference: [7] <author> F. M. Silva and L. B. Almeida. </author> <title> Acceleration techniques for the backpropagation algorithm. </title> <editor> In L. B. Almeida and C. J. Wellekens, editors, </editor> <booktitle> Proceedings of the 1990 EURASIP Workshop on Neural Networks. </booktitle> <publisher> Springer-Verlag, </publisher> <month> February </month> <year> 1990. </year> <booktitle> (Lecture Notes in Computer Science series). </booktitle>
Reference-contexts: Finding these optimal values in practice is beyond the scope of this paper, but some techniques for achieving nearly optimal learning rates are available <ref> [4, 10, 8, 7, 3] </ref>. Adjusting the momentum feels easier to practitioners than adjusting the learning rate, as too high a value leads to small oscillations rather than divergence, and techniques from control theory can be applied to the problem [2].
Reference: [8] <author> Tom Tollenaere. SuperSAB: </author> <title> Fast adaptive back propagation with good scaling properties. </title> <booktitle> Neural Networks, </booktitle> <volume> 3(5) </volume> <pages> 561-573, </pages> <year> 1990. </year>
Reference-contexts: Finding these optimal values in practice is beyond the scope of this paper, but some techniques for achieving nearly optimal learning rates are available <ref> [4, 10, 8, 7, 3] </ref>. Adjusting the momentum feels easier to practitioners than adjusting the learning rate, as too high a value leads to small oscillations rather than divergence, and techniques from control theory can be applied to the problem [2].
Reference: [9] <author> Mehmet Ali Tugay and Yalcin Tanik. </author> <title> Properties of the momentum LMS algorithm. </title> <booktitle> Signal Processing, </booktitle> <volume> 18(2) </volume> <pages> 117-127, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: In the batch case, which we consider here, Tugay and Tanik <ref> [9] </ref> have shown that momentum is stable when ff &lt; 1 and 0 &lt; j &lt; 2 (ff + 1)= max (5) which speeds convergence to E E fl O exp ((4 s + O (s)) t) (6) ff fl = p (1 2s) 2 1 = 1 4 s +
Reference: [10] <author> T. P. Vogl, J. K. Mangis, A. K. Zigler, W. T. Zink, and D. L. Alkon. </author> <title> Accelerating the convergence of the back-propagation method. </title> <journal> Biological Cybernetics, </journal> <volume> 59 </volume> <pages> 257-263, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Finding these optimal values in practice is beyond the scope of this paper, but some techniques for achieving nearly optimal learning rates are available <ref> [4, 10, 8, 7, 3] </ref>. Adjusting the momentum feels easier to practitioners than adjusting the learning rate, as too high a value leads to small oscillations rather than divergence, and techniques from control theory can be applied to the problem [2].
Reference: [11] <author> B. Widrow, J. M. McCool, M. G. Larimore, and C. R. Johnson, Jr. </author> <title> Stational and nonstationary learning characteristics of the LMS adaptive filter. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 64 </volume> <pages> 1151-1162, </pages> <year> 1979. </year>
Reference-contexts: and observe some effect not predicted by theory; and account for these effects by analyzing gradient descent with momentum on a saturating error surface. 1.1 SIMPLE GRADIENT DESCENT First, let us review the bounds on the convergence rate of simple gradient descent without momentum to a minimum of quadratic form <ref> [11, 1] </ref>. Let w fl be the minimum of E, the error, H = d 2 E=dw 2 (w fl ), and i , v i be the eigenvalues and eigenvectors of H.
References-found: 11

