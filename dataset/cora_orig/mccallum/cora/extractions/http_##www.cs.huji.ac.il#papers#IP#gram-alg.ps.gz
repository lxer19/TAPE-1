URL: http://www.cs.huji.ac.il/papers/IP/gram-alg.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Title: Linear and Incremental Acquisition of Invariant Shape Models from Image Sequences  
Author: Daphna Weinshall Carlo Tomasi 
Address: 91904 Jerusalem ISRAEL  Ithaca, NY 14853 USA  
Affiliation: Department of Computer Science The Hebrew University of Jerusalem  Department of Computer Science Cornell University  
Abstract: We show how to automatically acquire similarity-invariant shape representations of objects from noisy image sequences under weak perspective. The proposed method is linear and incremental, requiring no more than pseudo-inverse. It is based on the observation that the trajectories that points on the object form in weak-perspective image sequences are linear combinations of three of the trajectories themselves, and that the coefficients of the linear combinations represent shape in an affine-invariant basis. A nonlinear but numerically sound preprocessing stage is added to improve the accuracy of the results even further. Experiments show that attention to noise and computational techniques improve the shape results substantially with respect to previous methods proposed for ideal images.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Aloimonos. </author> <title> Perspective approximations. </title> <journal> Image and Vision Computing, </journal> <volume> 8(3) </volume> <pages> 179-192, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: For this purpose, three-dimensional object representations have been proposed [34] that are invariant with respect to similarity transformations, that is, rotations, translations, and isotropic scaling. These are exactly the transformations that occur in the weak perspective projection model <ref> [1] </ref>, where images are scaled orthographic projections of rotated and translated objects. Because of its linearity, weak perspective strikes a good balance between mathematical tractability and model generality. In this paper, we propose a method for acquiring a similarity-invariant representation from a sequence of images of the objects themselves.
Reference: [2] <author> R. C. Bolles, H. H. Baker, and D. H. Marimont. </author> <title> Epipolar-plane image analysis: An approach to determining structure from motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(1) </volume> <pages> 7-55, </pages> <year> 1987. </year>
Reference-contexts: To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, [28, 32, 23, 18, 27, 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, <ref> [2, 21] </ref> recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem under orthographic projection, and [26, 13] propose multiframe solutions under perspective projection.
Reference: [3] <author> T.J. Broida, S. Chandrashekhar, and R. Chellappa. </author> <title> Recursive 3-d motion estimation from a monocular image sequence. </title> <journal> IEEE Transactions on Aerospace and Electronic Systems, </journal> <volume> 26(4) </volume> <pages> 639-656, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: For instance, [28, 32, 23, 18, 27, 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, <ref> [17, 14, 3, 6, 11] </ref> consider restricted or partially known motion, [30] solves the complete multiframe problem under orthographic projection, and [26, 13] propose multiframe solutions under perspective projection.
Reference: [4] <author> H. H. Bulthoff and S. Edelman. </author> <title> Psychophysical support for a 2D interpolation theory of object recognition. </title> <booktitle> Proceedings of the National Academy of Science, </booktitle> <volume> 89 </volume> <pages> 60-64, </pages> <year> 1992. </year>
Reference-contexts: We also see an average lower discrimination ratio for images used for model acquisition than for other images. This replicates the performance of human subjects in similar recognition tasks <ref> [4] </ref>.
Reference: [5] <author> S. Chandrasekaran and I. Ipsen. </author> <title> On rank-revealing QR factorizations. </title> <institution> Research report YALEU/DCS/RR-880, Yale University, Computer Science, </institution> <month> December </month> <year> 1991. </year> <title> short version in IEEE Trans. </title> <journal> on Pattern Anal. Machine Intel., </journal> <volume> 17(5), </volume> <pages> 512-517, </pages> <year> 1995 </year> <month> 21 </month>
Reference-contexts: brings a well conditioned submatrix in front of ^ Q ^ R. (See [10] for more details, as well as for definitions and algorithms for singular value decomposition and QR factorization.) Although heuristic in nature, this procedure has proven to work well in all the cases we considered (see also <ref> [5] </ref> for a discussion of possible alternatives).
Reference: [6] <author> C. H. Debrunner and N. Ahuja. </author> <title> A direct data approximation based motion estimation algorithm. </title> <booktitle> In Proceedings of the 10th International Conference on Pattern Recognition, </booktitle> <pages> pages 384-389, </pages> <address> Atlantic City, NJ, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: For instance, [28, 32, 23, 18, 27, 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, <ref> [17, 14, 3, 6, 11] </ref> consider restricted or partially known motion, [30] solves the complete multiframe problem under orthographic projection, and [26, 13] propose multiframe solutions under perspective projection.
Reference: [7] <author> O. Faugeras. </author> <booktitle> What can be seen in three dimensions with an uncalibrated stereo rig? In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <pages> pages 563-578, </pages> <address> Santa Margherita Ligure, Italy, 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In this paper, we show that this is indeed the case. (We assume weak perspective projection; A few recent papers described structure from motion algorithms without camera calibration and with perspective projection <ref> [7, 22] </ref>.) Specifically, we compute a similarity-invariant representation of shape both linearly and incrementally from a sequence of weak perspective images. This is a very important gain.
Reference: [8] <author> C. Fuh and P. Maragos. </author> <title> Motion displacement estimation using and affine model for matching. </title> <journal> Optical Engineering, </journal> <volume> 30(7) </volume> <pages> 881-887, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: In a sequence of images, feature points can be extracted and tracked with one of the methods described in <ref> [24, 29, 8] </ref> (see the experiments in section 5 below).
Reference: [9] <author> W. E. L. Grimson, D. P. Huttenlocher, and D. W. Jacobs. </author> <title> A study of affine matching with bounded sensor error. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Computer Vision - ECCV92, </booktitle> <pages> pages 291-306, </pages> <address> Berlin, May 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Automatic acquisition from images avoids the tedious and error prone process of typing three-dimensional coordinates of points on the objects, and makes expensive three-dimensional sensors such as laser rangefinders unnecessary. However, model recognition techniques such as geometric hashing have been shown <ref> [9] </ref> to produce false positive fl This work was done at IBM T.J. Watson Research Center, Yorktown Heights, NY. y This work was supported by Grant No. IRI-9201751 from the NSF. 1 short version in IEEE Trans. on Pattern Anal.
Reference: [10] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, Md, </address> <year> 1989. </year>
Reference-contexts: Then, the definition (8) of the Gramian can be rewritten as G = P T Suppose now that T is the Cholesky factor of the Gramian G. We recall <ref> [10] </ref> that the Cholesky factor of a symmetric positive definite matrix G is the unique upper triangular matrix T with positive diagonal entries such that G = T T T : (10) Eq. (9) and Eq. (10) are formally similar factorizations of G. <p> The size of this largest perturbation turns out to be equal to the condition number of W b , that is, to the ratio between its largest and smallest singular values <ref> [10] </ref>. The problem of selecting three columns W b of W that are as good as possible in this sense is known as the subset selection problem in the numerical analysis literature [10]. In the following, we summarize the solution to this problem proposed in [10]: 1. compute the singular value <p> condition number of W b , that is, to the ratio between its largest and smallest singular values <ref> [10] </ref>. The problem of selecting three columns W b of W that are as good as possible in this sense is known as the subset selection problem in the numerical analysis literature [10]. In the following, we summarize the solution to this problem proposed in [10]: 1. compute the singular value decomposition of W , W = U V T ; 2. apply QR factorization with column pivoting to the right factor V T : V T = ^ Q ^ R T <p> largest and smallest singular values <ref> [10] </ref>. The problem of selecting three columns W b of W that are as good as possible in this sense is known as the subset selection problem in the numerical analysis literature [10]. In the following, we summarize the solution to this problem proposed in [10]: 1. compute the singular value decomposition of W , W = U V T ; 2. apply QR factorization with column pivoting to the right factor V T : V T = ^ Q ^ R T : The first three columns of the permutation matrix are all zero, except <p> The row subscripts of those three nonzero entries are the desired subscripts i, j, k. The rationale of this procedure is that singular value decomposition preconditions the shape matrix, and then QR factorization with column pivoting brings a well conditioned submatrix in front of ^ Q ^ R. (See <ref> [10] </ref> for more details, as well as for definitions and algorithms for singular value decomposition and QR factorization.) Although heuristic in nature, this procedure has proven to work well in all the cases we considered (see also [5] for a discussion of possible alternatives).
Reference: [11] <author> B. K. P. Horn, H. M. Hilden, and S. Negahdaripour. </author> <title> Closed-form solution of absolute orientation using orthonormal matrices. </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 5(7) </volume> <pages> 1127-1135, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: For instance, [28, 32, 23, 18, 27, 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, <ref> [17, 14, 3, 6, 11] </ref> consider restricted or partially known motion, [30] solves the complete multiframe problem under orthographic projection, and [26, 13] propose multiframe solutions under perspective projection. <p> In [16], it is suggested to pick an object point as the reference origin. In [30], the centroid of all the points is used instead (this is the optimal translation in a least-square sense <ref> [11] </ref>). In practice, our experiments show that there is little difference between these two choices. Let now t be a 2M -dimensional vector that collects the two coordinates of the projection of the reference point in each frame. <p> The known coordinates of the basis points in system M and in the orthonormal system defined in Section 3.4 can be used to compute the transformation between the two coordinates system, e.g., using the method described in <ref> [11] </ref>. This transformation gives the pose of the camera in frame m. Alternatively, it is possible to compute pose directly from the image measurements, using Eq. (5). <p> For comparison, we received the 3D coordinates of the points in the first frame as ground truth. We used the algorithm described in <ref> [11] </ref> to compute the optimal similarity transformation between the invariant depth map representation computed by our algorithm (step 5), and the given data in the coordinate system of the first frame.
Reference: [12] <author> B. K. P. Horn. </author> <title> Relative orientation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4(1) </volume> <pages> 59-78, </pages> <year> 1990. </year>
Reference-contexts: Three results were reported in [25] and copied to Table 1: column "Rot." depth computation with their algorithm, which assumes perspective projection and rotational motion only; column "2-frm" - depth computation using the algorithm described in <ref> [12] </ref>, which uses 2-frames only; and column "2-frm, Ave." depth computation using the 2-frames algorithm, where the depth estimates were averages over six pairs of frames. Table 1 summarized these results, as well as the results using our affine algorithm (column "Aff.
Reference: [13] <author> D. J. Heeger and A. Jepson. </author> <title> Visual perception of three-dimensional motion. </title> <type> Technical Report 124, </type> <institution> MIT Media Laboratory, </institution> <address> Cambridge, Ma, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem under orthographic projection, and <ref> [26, 13] </ref> propose multiframe solutions under perspective projection. Conceivably, one could use one of these algorithms to determine the complete three-dimensional shape and pose of the object in an Euclidean reference system, and process the results to achieve similarity invariance.
Reference: [14] <author> R. Jain. </author> <title> Direct computation of the focus of expansion. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <volume> 5 </volume> <pages> 58-63, </pages> <year> 1983. </year>
Reference-contexts: For instance, [28, 32, 23, 18, 27, 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, <ref> [17, 14, 3, 6, 11] </ref> consider restricted or partially known motion, [30] solves the complete multiframe problem under orthographic projection, and [26, 13] propose multiframe solutions under perspective projection.
Reference: [15] <author> R. Kumar and A. R. Hanson. </author> <title> Sensitivity of the pose refinement problem to accurate estimation of camera parameters. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 365-369, </pages> <address> Osaka, Japan, 1990. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: The depth values of the points in the first frame ranged from 550 to 700 mms, therefore weak perspective provided a good approximation to this sequence. (See a more detailed description of the sequence in [25] Fig. 5, or <ref> [15] </ref> Fig. 2.) We compared the relative errors of our algorithm to the errors reported in [25]. <p> Moreover, a wide-lens camera was used, causing distortions at the periphery which were not compensated for. (See a more detailed description of a similar sequence in [25] Fig. 4, or <ref> [15] </ref> Fig. 3.) Table 2 summarizes the results of our invariant algorithm for the last 8 points.
Reference: [16] <author> J. J. Koenderink and A. J. van Doorn. </author> <title> Affine structure from motion. </title> <journal> Journal of the Optical Society of America, </journal> <volume> 8(2) </volume> <pages> 377-385, </pages> <year> 1991. </year>
Reference-contexts: To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, <ref> [28, 32, 23, 18, 27, 16] </ref> identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem <p> In <ref> [16] </ref>, it is suggested to pick an object point as the reference origin. In [30], the centroid of all the points is used instead (this is the optimal translation in a least-square sense [11]). In practice, our experiments show that there is little difference between these two choices. <p> Specifically, the basis is made by three of the object points themselves, that is, by the vectors from the reference origin to the three points, assumed not to be coplanar with the origin. This basis is no more orthonormal. The new coordinates were called affine in <ref> [16] </ref>. If now the object undergoes some affine transformation, so do the basis points, and the affine coordinates of the N object points do not change. The choice of the three basis points can be important.
Reference: [17] <author> D. T. Lawton. </author> <title> Processing translational motion sequences. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 22 </volume> <pages> 116-144, </pages> <year> 1983. </year>
Reference-contexts: For instance, [28, 32, 23, 18, 27, 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, <ref> [17, 14, 3, 6, 11] </ref> consider restricted or partially known motion, [30] solves the complete multiframe problem under orthographic projection, and [26, 13] propose multiframe solutions under perspective projection.
Reference: [18] <author> H. C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <month> September </month> <year> 1981. </year>
Reference-contexts: To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, <ref> [28, 32, 23, 18, 27, 16] </ref> identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem
Reference: [19] <author> Y. Lamdan, J. T. Schwartz, and H. J. Wolfson. </author> <title> Affine invariant model-based object recognition. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 6 </volume> <pages> 578-589, </pages> <year> 1990. </year>
Reference: [20] <author> P. S. Maybeck. </author> <title> Stochastic Models, Estimation, and Control. </title> <publisher> Academic Press, </publisher> <address> Orlando, Fl, </address> <year> 1979. </year> <title> short version in IEEE Trans. </title> <journal> on Pattern Anal. Machine Intel., </journal> <volume> 17(5), </volume> <pages> 512-517, </pages> <year> 1995 </year> <month> 22 </month>
Reference-contexts: It is well known from the literature of Kalman filtering that linear systems can be solved incrementally (see for instance <ref> [20] </ref>) one row at a time. <p> For added efficiency, this pair of equations can be manipulated into the following update rule for A <ref> [20] </ref>: A + = A + 1 + w T b A : Note that the computation of A requires at least two frames. short version in IEEE Trans. on Pattern Anal.
Reference: [21] <author> L. Matthies, T. Kanade, and R. Szeliski. </author> <title> Kalman filter-based algorithms for estimating depth from image sequences. </title> <journal> International Journal of Computer Vision, </journal> <volume> 3(3) </volume> <pages> 209-236, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, [28, 32, 23, 18, 27, 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, <ref> [2, 21] </ref> recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem under orthographic projection, and [26, 13] propose multiframe solutions under perspective projection.
Reference: [22] <author> R. Mohr, , L. Quan, F. Veillon, and B. Boufama. </author> <title> Relative 3D reconstruction using multiple uncalibrated images. </title> <institution> RT 84-IMAG-12 LIFIA, Institut IMAG, University of Grenoble, France, </institution> <year> 1992. </year>
Reference-contexts: In this paper, we show that this is indeed the case. (We assume weak perspective projection; A few recent papers described structure from motion algorithms without camera calibration and with perspective projection <ref> [7, 22] </ref>.) Specifically, we compute a similarity-invariant representation of shape both linearly and incrementally from a sequence of weak perspective images. This is a very important gain.
Reference: [23] <author> J. W. Roach and J. K. Aggarwal. </author> <title> Computer tracking of objects moving in space. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-1(2):127-135, </volume> <month> April </month> <year> 1979. </year>
Reference-contexts: To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, <ref> [28, 32, 23, 18, 27, 16] </ref> identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem
Reference: [24] <author> J. Rehg and A. Witkin. </author> <title> Visual tracking with deformation models. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 844-850, </pages> <address> Sacramento, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: In a sequence of images, feature points can be extracted and tracked with one of the methods described in <ref> [24, 29, 8] </ref> (see the experiments in section 5 below).
Reference: [25] <author> H. S. Sawhney, J. Oliensis, and A. R. Hanson. </author> <title> Description and reconstruction from image trajectories of rotational motion. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 494-498, </pages> <address> Osaka, Japan, 1990. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: The depth values of the points in the first frame ranged from 550 to 700 mms, therefore weak perspective provided a good approximation to this sequence. (See a more detailed description of the sequence in <ref> [25] </ref> Fig. 5, or [15] Fig. 2.) We compared the relative errors of our algorithm to the errors reported in [25]. Three results were reported in [25] and copied to Table 1: column "Rot." depth computation with their algorithm, which assumes perspective projection and rotational motion only; column "2-frm" - depth <p> points in the first frame ranged from 550 to 700 mms, therefore weak perspective provided a good approximation to this sequence. (See a more detailed description of the sequence in <ref> [25] </ref> Fig. 5, or [15] Fig. 2.) We compared the relative errors of our algorithm to the errors reported in [25]. Three results were reported in [25] and copied to Table 1: column "Rot." depth computation with their algorithm, which assumes perspective projection and rotational motion only; column "2-frm" - depth computation using the algorithm described in [12], which uses 2-frames only; and column "2-frm, Ave." depth computation using the 2-frames <p> from 550 to 700 mms, therefore weak perspective provided a good approximation to this sequence. (See a more detailed description of the sequence in <ref> [25] </ref> Fig. 5, or [15] Fig. 2.) We compared the relative errors of our algorithm to the errors reported in [25]. Three results were reported in [25] and copied to Table 1: column "Rot." depth computation with their algorithm, which assumes perspective projection and rotational motion only; column "2-frm" - depth computation using the algorithm described in [12], which uses 2-frames only; and column "2-frm, Ave." depth computation using the 2-frames algorithm, where the depth estimates were <p> Moreover, a wide-lens camera was used, causing distortions at the periphery which were not compensated for. (See a more detailed description of a similar sequence in <ref> [25] </ref> Fig. 4, or [15] Fig. 3.) Table 2 summarizes the results of our invariant algorithm for the last 8 points. <p> Under these conditions, which lend themselves favorably to the weak perspective approximation, our algorithm clearly performs very well. The excellent results of all the algorithms with the box sequence are due in part to the reliable data, which was obtained by the particular tracking method described in <ref> [25] </ref>. Given this reliable correspondence, our algorithm gave the best results, although it relies on the weak perspective approximation. <p> Note, however, that even algorithms which use the perspective projection model do not necessarily perform better with such sequences (compare with the results for a similar sequence reported in <ref> [25] </ref>). In this last sequence, the computation of invariant shape using 8 frames or 16 frames lead to rather similar results for the affine shape matrix and the Gramian matrix.
Reference: [26] <author> M. E. Spetsakis and J. Y. Aloimonos. </author> <title> Optimal motion estimation. </title> <booktitle> In Proceedings of the IEEE Workshop on Visual Motion, </booktitle> <pages> pages 229-237, </pages> <address> Irvine, California, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem under orthographic projection, and <ref> [26, 13] </ref> propose multiframe solutions under perspective projection. Conceivably, one could use one of these algorithms to determine the complete three-dimensional shape and pose of the object in an Euclidean reference system, and process the results to achieve similarity invariance.
Reference: [27] <author> R. Y. Tsai and T. S. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects with curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-6(1):13-27, </volume> <month> January </month> <year> 1984. </year>
Reference-contexts: To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, <ref> [28, 32, 23, 18, 27, 16] </ref> identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem
Reference: [28] <author> E. H. Thompson. </author> <title> A rational algebraic formulation of the problem of relative orientation. </title> <journal> Photogrammetric Record, </journal> <volume> 3(14) </volume> <pages> 152-159, </pages> <year> 1959. </year>
Reference-contexts: To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, <ref> [28, 32, 23, 18, 27, 16] </ref> identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem
Reference: [29] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams: a factorization method - 3. detection and tracking of point features. </title> <type> Technical Report CMU-CS-91-132, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: In a sequence of images, feature points can be extracted and tracked with one of the methods described in <ref> [24, 29, 8] </ref> (see the experiments in section 5 below). <p> The ratio between the value of the criterion applied to the actual sequence over that for the random sequence was used as a performance measure: if the ratio is very small, the algorithm discriminates well between the "true" object and other "false" comparison objects. The tracker described in <ref> [29] </ref> was used to both select and track features from frame to frame. Only those features that were visible throughout the thirty frames were used in these experiments. Ninety points on the ball satisfied this requirement. Fig. 2a shows the trajectories of those 90 points.
Reference: [30] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: For instance, [28, 32, 23, 18, 27, 16] identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, <ref> [30] </ref> solves the complete multiframe problem under orthographic projection, and [26, 13] propose multiframe solutions under perspective projection. Conceivably, one could use one of these algorithms to determine the complete three-dimensional shape and pose of the object in an Euclidean reference system, and process the results to achieve similarity invariance. <p> In [16], it is suggested to pick an object point as the reference origin. In <ref> [30] </ref>, the centroid of all the points is used instead (this is the optimal translation in a least-square sense [11]). In practice, our experiments show that there is little difference between these two choices. <p> This transformation gives the pose of the camera in frame m. Alternatively, it is possible to compute pose directly from the image measurements, using Eq. (5). Tomasi & kanade <ref> [30] </ref> described a relatively simple non-linear method, which computes pose from the Singular Value Decomposition of the centered measurement matrix W . short version in IEEE Trans. on Pattern Anal. <p> The only advantage for the simultaneous analysis of more than five points was the availability of a better (more independent) basis. A comparison with a SVD based algorithm for the computation of the decomposition in Eq. (7), which was described in <ref> [30] </ref>, showed a comparable average performance of both our simple linear algorithm and the SVD based algorithm. In our simulations of a recognition operator (Fig. 4), we see a marked difference between interpolation and extrapolation.
Reference: [31] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 992-1006, </pages> <year> 1991. </year>
Reference-contexts: This result is closely related to, but different from, the statement that any image in the sequence is a linear combination of three of its images <ref> [31] </ref>. In this paper, we also show that the optional addition of a nonlinear but numerically sound stage, which selects the most suitable basis trajectories, improves the accuracy of the representation even further. <p> The coefficients (A) of the linear combinations are the three-dimensional coordinates of the corresponding points in space in the affine three-dimensional basis of the points themselves. Notice the analogy and difference between this result and the statement, made in <ref> [31] </ref>, that under weak perspective any image of an object is a linear combination of three of its views. We are saying that any trajectory is a linear combination of three trajectories, while they are saying that any snapshot is a linear combination of three snapshots.
Reference: [32] <author> S. Ullman. </author> <title> The Interpretation of Visual Motion. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1979. </year>
Reference-contexts: To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, <ref> [28, 32, 23, 18, 27, 16] </ref> identify the minimum number of points necessary to recover motion and structure from two or three frames, [2, 21] recover depth from many frames when motion is known, [17, 14, 3, 6, 11] consider restricted or partially known motion, [30] solves the complete multiframe problem
Reference: [33] <author> S. Ullman. </author> <title> Maximizing rigidity: the incremental recovery of 3D structure from rigid and rubbery motion. </title> <journal> Perception, </journal> <volume> 13 </volume> <pages> 255-274, </pages> <year> 1984. </year>
Reference-contexts: Unlike most algorithms, our algorithm computes shape without computing explicit depth or the transformation between images. Depth can be optionally obtained by computing the square root of a 3 fi 3 matrix. Like <ref> [33] </ref> and unlike most algorithms, it can be implemented in an incremental way, updating the results with additional data without storing all the previous data.
Reference: [34] <author> D. Weinshall. </author> <title> Model-based invariants for 3D vision. </title> <journal> International Journal on Computer Vision, </journal> <volume> 10(1) </volume> <pages> 27-42, </pages> <year> 1993. </year>
Reference-contexts: The recognition process is greatly simplified if the quality of the match can be determined without camera calibration, namely, without having to compute the pose of each candidate object in the reference system of the camera. For this purpose, three-dimensional object representations have been proposed <ref> [34] </ref> that are invariant with respect to similarity transformations, that is, rotations, translations, and isotropic scaling. These are exactly the transformations that occur in the weak perspective projection model [1], where images are scaled orthographic projections of rotated and translated objects. <p> be computed explicitly in order to compute a similarity-invariant representation. 3 Review of the Similarity-Invariant Representation Starting with Eq. (3) as a multiframe imaging model, we now describe how to define a shape repre sentation that is invariant with respect to similarity transformations, that is, rigid transformations and isotropic scalings <ref> [34] </ref>. Specifically, we work towards similarity invariance in three steps: 1. invariance to translation (Section 3.1); 2. invariance to affine transformations (Section 3.2); short version in IEEE Trans. on Pattern Anal. Machine Intel., 17 (5), 512-517, 1995 4 3. invariance to similarity transformations (Section 3.3). <p> Machine Intel., 17 (5), 512-517, 1995 6 coordinates would not be invariant with respect to rotation and scaling. Instead, we introduce the Gramian matrix of the three basis points, defined as follows <ref> [34] </ref>: G = 6 p T i p j p T p T j p j p T p T k p j p T 3 5 : (8) In Section 4.2 we normalize G to make it invariant to scaling. <p> During acquisition of the shape representation, on the other hand, G is the unknown, and Eq. (11) can be solved for G. In this section, we review the use of G for recognition (as discussed at length in <ref> [34] </ref>). We discuss its computation, the major point of the present paper, in Section 4. Essentially, the recognition scheme checks the residues between the left- and the righthand sides of the equations in (11). The residues, however, must be properly normalized to make the matching criterion independent of scale. <p> Essentially, the recognition scheme checks the residues between the left- and the righthand sides of the equations in (11). The residues, however, must be properly normalized to make the matching criterion independent of scale. The most straightforward definition of matching measure for the three basis points is the following <ref> [34] </ref>: g (x m ; y m ) = m G 1 y m j + jx T m G 1 y m j m G 1 x m j + jy T : (12) The function (12) is a quadratic image invariant that can be used to check the basis
References-found: 34

