URL: http://www.cs.columbia.edu/pdis_lab/papers/learning/kdd93/k.ps.Z
Refering-URL: http://www.cs.columbia.edu/pdis_lab/
Root-URL: 
Email: pkc@cs.columbia.edu and sal@cs.columbia.edu  
Title: Toward Parallel and Distributed Learning by Meta-Learning  
Author: Philip K. Chan and Salvatore J. Stolfo 
Keyword: machine learning, inductive learning, meta-learning, parallel and distributed processing, and large databases.  
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Abstract: Much of the research in inductive learning concentrates on problems with relatively small amounts of data. With the coming age of very large network computing, it is likely that orders of magnitude more data in databases will be available for various learning problems of real world importance. Learning techniques are central to knowledge discovery and the approach proposed in this paper may substantially increase the amount of data a knowledge discovery system can handle effectively. Meta-learning is proposed as a general technique to integrating a number of distinct learning processes. This paper details several meta-learning strategies for integrating independently learned classifiers by the same learner in a parallel and distributed computing environment. Our strategies are particularly suited for massive amounts of data that main-memory-based learning algorithms cannot efficiently handle. The strategies are also independent of the particular learning algorithm used and the underlying parallel and distributed platform. Preliminary experiments using different data sets and algorithms demonstrate encouraging results: parallel learning by meta-learning can achieve comparable prediction accuracy in less space and time than purely serial learning. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA, </address> <year> 1984. </year>
Reference-contexts: We also note that once an arbiter tree is computed, its application in a parallel environment can be done efficiently according to the scheme proposed in [18]. 4 Experiments Four inductive learning algorithms were used in our experiments. ID3 [15] and CART <ref> [1] </ref> were obtained from NASA Ames Research Center in the IND package [2]. They are both decision tree learning algorithms. WPEBLS is the weighted version of PEBLS [8], which is a memory-based learning algorithm. BAYES is a simple Bayesian learner based on conditional probabilities, which is described in [7].
Reference: [2] <author> W. Buntine and R. Caruana. </author> <title> Introduction to IND and Recursive Partitioning. </title> <institution> NASA Ames Research Center, </institution> <year> 1991. </year>
Reference-contexts: ID3 [15] and CART [1] were obtained from NASA Ames Research Center in the IND package <ref> [2] </ref>. They are both decision tree learning algorithms. WPEBLS is the weighted version of PEBLS [8], which is a memory-based learning algorithm. BAYES is a simple Bayesian learner based on conditional probabilities, which is described in [7]. The latter two algorithms were reimplemented in C.
Reference: [3] <author> J. Catlett. </author> <title> Megainduction: A test flight. </title> <booktitle> In Proc. Eighth Intl. Work. Machine Learning, </booktitle> <pages> pages 596-599, </pages> <year> 1991. </year>
Reference-contexts: Wirth and Catlett [21] show that the window-ing technique does not significantly improve speed on reliable data. On the contrary, for noisy data, windowing considerably slows down the computation. Catlett <ref> [3] </ref> demonstrates that larger amounts of data improves accuracy, but he projects that ID3 [15] on modern machines will take several months to learn from a million records in the flight data set obtained from NASA.
Reference: [4] <author> P. Chan and S. Stolfo. </author> <title> Experiments on multi-strategy learning by meta-learning. </title> <note> Submitted to CIKM93, </note> <year> 1993. </year>
Reference-contexts: We are not aware of any work in the literature on this approach beyond what was first reported in [18] in the domain of speech recognition. Work on using meta-learning for combining different learning systems is reported elsewhere <ref> [4, 6] </ref> and is further discussed at the end of this paper. In the next section we will discuss our approach on the how to use meta-learning for parallel learning using only one learning algorithm. 3 Parallel Learning The objective here is to speed up the learning process by divide-and-conquer. <p> Mitchell [12] refers to this phenomenon as inductive bias. We postulate that by combining the different results intelligently through meta-learning, higher accuracy can be obtained. We call this approach multistrategy hypothesis boosting. Preliminary results reported in <ref> [4] </ref> are encouraging. Zhang et al.'s [24] and Wolpert's [22] work is in this direction. Silver et al.'s [17] and Holder's [10] work also employs multiple learners, but no learning is involved at the meta level.
Reference: [5] <author> P. Chan and S. Stolfo. </author> <title> Meta-learning for multi-strategy and parallel learning. </title> <booktitle> In Proc. Second Intl. Work. on Multistrategy Learning, </booktitle> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: Work in progress In addition to applying meta-learning to combining results from a set of parallel or distributed learning processes, meta-learning can also be used to coalesce the results from multiple different inductive learning algorithms applied to the same set of data to improve accuracy <ref> [5] </ref>. The premise is that different algorithms have different representations and search heuristics, different search spaces are being explored and hence potentially diversed results can be obtained from different algorithms. Mitchell [12] refers to this phenomenon as inductive bias.
Reference: [6] <author> P. Chan and S. Stolfo. </author> <title> Toward multistrategy parallel and distributed learning in sequence analysis. </title> <booktitle> In Proc. First Intl. Conf. Intel. Sys. Mol. Biol., </booktitle> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: We are not aware of any work in the literature on this approach beyond what was first reported in [18] in the domain of speech recognition. Work on using meta-learning for combining different learning systems is reported elsewhere <ref> [4, 6] </ref> and is further discussed at the end of this paper. In the next section we will discuss our approach on the how to use meta-learning for parallel learning using only one learning algorithm. 3 Parallel Learning The objective here is to speed up the learning process by divide-and-conquer. <p> Since the ultimate goal of this work is to improve both the accuracy and efficiency of machine learning, we have been working on combining ideas in parallel learning, described in this paper, with those in multistrategy hypothesis boosting. We call this approach multistrategy parallel learning. Preliminary results reported in <ref> [6] </ref> are encouraging. To our knowledge, not much work in this direction has been attempted by others. 7 Concluding Remarks Several meta-learning schemes for parallel learning are presented in this paper. In particular, schemes for building arbiter trees are detailed.
Reference: [7] <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 261-285, </pages> <year> 1987. </year>
Reference-contexts: They are both decision tree learning algorithms. WPEBLS is the weighted version of PEBLS [8], which is a memory-based learning algorithm. BAYES is a simple Bayesian learner based on conditional probabilities, which is described in <ref> [7] </ref>. The latter two algorithms were reimplemented in C. Two data sets, obtained from the UCI Machine Learning Database, were used in our studies. The secondary protein structure data set (SS) [13], courtesy of Qian and Sejnowski, contains sequences of amino acids and the secondary structures at the corresponding positions.
Reference: [8] <author> S. Cost and S. Salzberg. </author> <title> A weighted nearest neighbor algorithm for learning with symbolic features. </title> <journal> Machine Learning, </journal> <volume> 10 </volume> <pages> 57-78, </pages> <year> 1993. </year>
Reference-contexts: ID3 [15] and CART [1] were obtained from NASA Ames Research Center in the IND package [2]. They are both decision tree learning algorithms. WPEBLS is the weighted version of PEBLS <ref> [8] </ref>, which is a memory-based learning algorithm. BAYES is a simple Bayesian learner based on conditional probabilities, which is described in [7]. The latter two algorithms were reimplemented in C. Two data sets, obtained from the UCI Machine Learning Database, were used in our studies.
Reference: [9] <author> Y. Freund. </author> <title> Boosting a weak learning algorithm by majority. </title> <booktitle> In Proc. 3rd Work. Comp. Learning Theory, </booktitle> <pages> pages 202-216, </pages> <year> 1990. </year>
Reference-contexts: We use three distribution as well, but the first two are independent and are available simultaneously. The third distribution, for the arbiter, however, depends on the first two. Fre-und <ref> [9] </ref> has a similar approach, but with potentially many more distributions. Again, the distributions can only be generated iteratively.
Reference: [10] <author> L. Holder. </author> <title> Selection of learning methods using an adaptive model of knowledge utility. </title> <booktitle> In Proc. MSL-91, </booktitle> <pages> pages 247-254, </pages> <year> 1991. </year>
Reference-contexts: We postulate that by combining the different results intelligently through meta-learning, higher accuracy can be obtained. We call this approach multistrategy hypothesis boosting. Preliminary results reported in [4] are encouraging. Zhang et al.'s [24] and Wolpert's [22] work is in this direction. Silver et al.'s [17] and Holder's <ref> [10] </ref> work also employs multiple learners, but no learning is involved at the meta level.
Reference: [11] <author> C. Matheus, P. Chan, and G. Piatesky-Shapiro. </author> <title> Systems for knowledge discovery in databases. </title> <journal> IEEE Trans. Know. Data. Eng., </journal> <note> 1993. To appear. </note>
Reference-contexts: With the coming age of very large network computing, it is likely that orders of magnitude more data in databases will be available for various learning problems of real world importance. The Grand Challenges of HPCC [20] are perhaps the best examples. Learning techniques are central to knowledge discovery <ref> [11] </ref> and the approach proposed here may substantially increase the amount of data a Knowledge Discovery system can handle effectively. Quinlan [14] approached the problem of efficiently applying learning systems to data that are substantially larger than available main memory with a windowing technique.
Reference: [12] <author> T. M. Mitchell. </author> <title> The need for biases in learning generalizaions. </title> <type> Technical Report CBM-TR-117, </type> <institution> Dept. Comp. Sci., Rutgers Univ., </institution> <year> 1980. </year>
Reference-contexts: The premise is that different algorithms have different representations and search heuristics, different search spaces are being explored and hence potentially diversed results can be obtained from different algorithms. Mitchell <ref> [12] </ref> refers to this phenomenon as inductive bias. We postulate that by combining the different results intelligently through meta-learning, higher accuracy can be obtained. We call this approach multistrategy hypothesis boosting. Preliminary results reported in [4] are encouraging. Zhang et al.'s [24] and Wolpert's [22] work is in this direction.
Reference: [13] <author> N. Qian and T. Sejnowski. </author> <title> Predicting the secondary structure of globular proteins using neural network models. </title> <journal> J. Mol. Biol., </journal> <volume> 202 </volume> <pages> 865-884, </pages> <year> 1988. </year>
Reference-contexts: BAYES is a simple Bayesian learner based on conditional probabilities, which is described in [7]. The latter two algorithms were reimplemented in C. Two data sets, obtained from the UCI Machine Learning Database, were used in our studies. The secondary protein structure data set (SS) <ref> [13] </ref>, courtesy of Qian and Sejnowski, contains sequences of amino acids and the secondary structures at the corresponding positions. There are three structures (three classes) and 20 amino acids (21 attributes because of a spacer) in the data. <p> There are three structures (three classes) and 20 amino acids (21 attributes because of a spacer) in the data. The amino acid sequences were split into shorter sequences of length 13 according to a windowing technique used in <ref> [13] </ref>. The sequences were then divided into a training and test set, which are disjoint, according to the distribution described in [13]. The training set has 18105 instances and the test set has 3520. <p> The amino acid sequences were split into shorter sequences of length 13 according to a windowing technique used in <ref> [13] </ref>. The sequences were then divided into a training and test set, which are disjoint, according to the distribution described in [13]. The training set has 18105 instances and the test set has 3520. The DNA splice junction data set (SJ) [19], courtesy of Tow-ell, Shavlik and Noordewier, contains sequences of nucleotides and the type of splice junction, if any, (three classes) at the center of each sequence.
Reference: [14] <author> J. R. Quinlan. </author> <title> Induction over large data bases. </title> <type> Technical Report STAN-CS-79-739, </type> <institution> Comp. Sci. Dept., Stanford Univ., </institution> <year> 1979. </year>
Reference-contexts: The Grand Challenges of HPCC [20] are perhaps the best examples. Learning techniques are central to knowledge discovery [11] and the approach proposed here may substantially increase the amount of data a Knowledge Discovery system can handle effectively. Quinlan <ref> [14] </ref> approached the problem of efficiently applying learning systems to data that are substantially larger than available main memory with a windowing technique. A learning algorithm is applied to a small subset of training data, called a window, and the learned concept is tested on the remaining training data.
Reference: [15] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Wirth and Catlett [21] show that the window-ing technique does not significantly improve speed on reliable data. On the contrary, for noisy data, windowing considerably slows down the computation. Catlett [3] demonstrates that larger amounts of data improves accuracy, but he projects that ID3 <ref> [15] </ref> on modern machines will take several months to learn from a million records in the flight data set obtained from NASA. He proposes some improvements to the ID3 algorithm particularly for handling attributes with real numbers, but the processing time is still prohibitive due to the algorithm's complexity. <p> We also note that once an arbiter tree is computed, its application in a parallel environment can be done efficiently according to the scheme proposed in [18]. 4 Experiments Four inductive learning algorithms were used in our experiments. ID3 <ref> [15] </ref> and CART [1] were obtained from NASA Ames Research Center in the IND package [2]. They are both decision tree learning algorithms. WPEBLS is the weighted version of PEBLS [8], which is a memory-based learning algorithm. <p> However, according to the theoretical analysis, significant speed-up can be obtained when the maximum arbiter training set size is fixed to the subset size (see Section 3.3; ID3 and CART is O (nl) <ref> [15] </ref>, where l is the number of leaves, and assuming l is proportional to p n, the complexity becomes O (n n); WPEBLS is O (n 2 ); BAYES is O (n)).
Reference: [16] <author> R. Schapire. </author> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 197-226, </pages> <year> 1990. </year>
Reference-contexts: This and the aforementioned strategies and issues are the subject matter of ongoing experimentation. Schapire's hypothesis boosting Our ideas are related to using meta-learning to improve accuracy. The most notable work in this area is due to Schapire <ref> [16] </ref>, which he refers to as hypothesis boosting. Based on an initial learned hypothesis for some concept derived from a random distribution of training data, Schapire's scheme iteratively generates two additional distributions of examples.
Reference: [17] <author> B. Silver, W. Frawley, G. Iba, J. Vittal, and K. Bradford. ILS: </author> <title> A framework for multi-paradigmatic learning. </title> <booktitle> In Proc. Seventh Intl. Conf. Machine Learning, </booktitle> <pages> pages 348-356, </pages> <year> 1990. </year>
Reference-contexts: We postulate that by combining the different results intelligently through meta-learning, higher accuracy can be obtained. We call this approach multistrategy hypothesis boosting. Preliminary results reported in [4] are encouraging. Zhang et al.'s [24] and Wolpert's [22] work is in this direction. Silver et al.'s <ref> [17] </ref> and Holder's [10] work also employs multiple learners, but no learning is involved at the meta level.
Reference: [18] <author> S. Stolfo, Z. Galil, K. McKeown, and R. Mills. </author> <title> Speech recognition in parallel. </title> <booktitle> In Proc. Speech Nat. Lang. Work., </booktitle> <pages> pages 353-373. DARPA, </pages> <year> 1989. </year>
Reference-contexts: This involves applying the same algorithm on different subsets of the data in parallel and the use of meta-learning to combine the partial results. We are not aware of any work in the literature on this approach beyond what was first reported in <ref> [18] </ref> in the domain of speech recognition. Work on using meta-learning for combining different learning systems is reported elsewhere [4, 6] and is further discussed at the end of this paper. <p> We also note that once an arbiter tree is computed, its application in a parallel environment can be done efficiently according to the scheme proposed in <ref> [18] </ref>. 4 Experiments Four inductive learning algorithms were used in our experiments. ID3 [15] and CART [1] were obtained from NASA Ames Research Center in the IND package [2]. They are both decision tree learning algorithms. WPEBLS is the weighted version of PEBLS [8], which is a memory-based learning algorithm.
Reference: [19] <author> G. Towell, J. Shavlik, and M. Noordewier. </author> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proc. AAAI-90, </booktitle> <pages> pages 861-866, </pages> <year> 1990. </year>
Reference-contexts: The sequences were then divided into a training and test set, which are disjoint, according to the distribution described in [13]. The training set has 18105 instances and the test set has 3520. The DNA splice junction data set (SJ) <ref> [19] </ref>, courtesy of Tow-ell, Shavlik and Noordewier, contains sequences of nucleotides and the type of splice junction, if any, (three classes) at the center of each sequence. Each sequence has 60 nucleotides with 8 different values each (four base ones plus four combinations).
Reference: [20] <author> B. Wah et al. </author> <title> High performance computing and communications for grand challenge applications: Computer vision, speech and natural language processing, </title> <journal> and artificial intelligence. IEEE Trans. Know. Data. Eng., </journal> <volume> 5(1) </volume> <pages> 138-154, </pages> <year> 1993. </year>
Reference-contexts: With the coming age of very large network computing, it is likely that orders of magnitude more data in databases will be available for various learning problems of real world importance. The Grand Challenges of HPCC <ref> [20] </ref> are perhaps the best examples. Learning techniques are central to knowledge discovery [11] and the approach proposed here may substantially increase the amount of data a Knowledge Discovery system can handle effectively.
Reference: [21] <author> J. Wirth and J. Catlett. </author> <title> Experiments on the costs and benefits of windowing in ID3. </title> <booktitle> In Proc. Fifth Intl. Conf. Machine Learning, </booktitle> <pages> pages 87-99, </pages> <year> 1988. </year>
Reference-contexts: This is repeated on a new window of the same size with some of the incorrectly classified data replacing some of the data in the old window until all the data are correctly classified. Wirth and Catlett <ref> [21] </ref> show that the window-ing technique does not significantly improve speed on reliable data. On the contrary, for noisy data, windowing considerably slows down the computation.
Reference: [22] <author> D. Wolpert. </author> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 241-259, </pages> <year> 1992. </year>
Reference-contexts: Mitchell [12] refers to this phenomenon as inductive bias. We postulate that by combining the different results intelligently through meta-learning, higher accuracy can be obtained. We call this approach multistrategy hypothesis boosting. Preliminary results reported in [4] are encouraging. Zhang et al.'s [24] and Wolpert's <ref> [22] </ref> work is in this direction. Silver et al.'s [17] and Holder's [10] work also employs multiple learners, but no learning is involved at the meta level.
Reference: [23] <author> X. Zhang, M. Mckenna, J. Mesirov, and D. Waltz. </author> <title> An efficient implementation of the backpropagation algorithm on the connection machine CM-2. </title> <type> Technical Report RL89-1, </type> <institution> Thinking Machines Corp., </institution> <year> 1989. </year>
Reference-contexts: One approach to this problem is to parallelize the learning algorithms and apply the parallelized algorithm to the entire data set (presumably utilizing multiple I/O channels to handle the I/O bottleneck). Zhang et al.'s work <ref> [23] </ref> on parallelizing the backpropagation algorithm on a Connection Machine is one example. This approach requires optimizing the code for a particular algorithm on a specific architecture.
Reference: [24] <author> X. Zhang, J. Mesirov, and D. Waltz. </author> <title> A hybrid system for protein secondary structure prediction. </title> <journal> J. Mol. Biol., </journal> <volume> 225 </volume> <pages> 1049-1063, </pages> <year> 1992. </year>
Reference-contexts: Mitchell [12] refers to this phenomenon as inductive bias. We postulate that by combining the different results intelligently through meta-learning, higher accuracy can be obtained. We call this approach multistrategy hypothesis boosting. Preliminary results reported in [4] are encouraging. Zhang et al.'s <ref> [24] </ref> and Wolpert's [22] work is in this direction. Silver et al.'s [17] and Holder's [10] work also employs multiple learners, but no learning is involved at the meta level.
References-found: 24

