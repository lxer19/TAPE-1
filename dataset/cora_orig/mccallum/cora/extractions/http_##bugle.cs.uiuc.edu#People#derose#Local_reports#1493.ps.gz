URL: http://bugle.cs.uiuc.edu/People/derose/Local_reports/1493.ps.gz
Refering-URL: http://bugle.cs.uiuc.edu/People/derose/falcon_publications.html
Root-URL: http://www.cs.uiuc.edu
Title: COMPILER TECHNIQUES FOR MATLAB PROGRAMS  
Author: BY LUIZ ANT ONIO DE ROSE Bach., Universidade de Braslia, 
Degree: 1992 THESIS Submitted in partial fullfilment of the requirements for the degree of Doctor of Philosophy in Computer Science in the Graduate College of the  
Date: 1982  
Address: Braslia,  1996 Urbana, Illinois  
Affiliation: M.Stat., Universidade de  M.S., University of Illinois at Urbana-Champaign,  University of Illinois at Urbana-Champaign,  
Abstract-found: 0
Intro-found: 1
Reference: [AALL93] <author> Saman P. Amarasinghe, Jennifer M. Anderson, Monica S. Lam, and Amy W. Lim. </author> <title> An Overview of a Compiler for Scalable Parallel Machines. </title> <editor> In Utpal Baner-jee, David Gelernter, Alex Nicolau, and David Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 253-272. </pages> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> vol. 768, </volume> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1993. </year> <booktitle> 6th International Workshop, </booktitle> <address> Portland, Oregon. </address>
Reference-contexts: Several approaches to facilitate the development and maintenance of programs for high-performance computers are currently under study. One approach is the automatic translation of conventional programming languages, notably Fortran, into parallel form. Po-laris [BEF + 94] and Parafrase-2 [PGH + 89], developed at Illinois, and SUIF <ref> [AALL93] </ref>, a compiler developed at Stanford, are examples of this first approach. Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran [Hig93] and pC++ [BBG + 93].
Reference: [ABB + 92] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Green-baum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <title> LA-PACK User's Guide. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <year> 1992. </year>
Reference-contexts: Moreover, at this point, all necessary attributes for the code generation have been already filled by the static and dynamic inference phases. To maintain compatibility with the MATLAB interpreter, whenever possible 7 the compiler generates function calls from the same libraries used by MATLAB (i.e., LINPACK [DMBS79], LAPACK <ref> [ABB + 92] </ref>, EISPACK [SBD + 76]). 7 The information on which library function is being used by the interpreter is not always available.
Reference: [ASU85] <author> A. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: One of our main objectives in this thesis is to evaluate the effectiveness of the inference mechanisms for detecting intrinsic type, rank, and shape on MATLAB programs. We make use in this work of data-flow analysis as described by Aho, Sethi, and Ullman in <ref> [ASU85] </ref>, and type inference techniques developed for SETL [Sch75] and APL [Bud88, Chi86]. We extend these techniques where necessary to deal with peculiarities of the MAT-LAB language and to improve accuracy and performance. <p> Examples of these techniques are: a structural inference mechanism, a symbolic dimension propagation analysis, and a value propagation analysis. 8 A forward/backward traversal scheme for type inference is described in <ref> [ASU85] </ref>. In this scheme, type inference is performed with data-flow analysis on a flow graph of the program. The in and out set of variables for each block of the program are mapped onto sets of possible types. <p> These properties are used by the compiler to generate the Fortran 90 declarations and to optimize the output code. The MATLAB compiler was structured in a conventional way <ref> [ASU85] </ref> with a series of different passes, as shown in Figure 3.1. This section discusses the main issues and the overall strategy adopted for each of the phases of the compiler. 3.2.1 Structure of a MATLAB Program MATLAB is a procedural language. <p> Similarly, the term M-file will refer to M-file functions and not to script files. 3.2.2 Scanner, Parser, and the Symbol Table Generation Initially, a LALR (1) grammar <ref> [ASU85] </ref> was defined for MATLAB, as there is no publicly available grammar for the MATLAB language. The compiler accepts as input a MATLAB script (from here on referred to as main program), that may contain several M-file calls. <p> These two steps are similar to scanning and parsing for conventional compilers, described in the literature <ref> [ASU85] </ref>. The main problem during this phase, as described in Section 4.1, is addressed by the symbol table manager with the differentiations between variables and functions. By the end of this phase, the symbol table manager will have created a list containing all the M-files invoked by the main program. <p> The generation of executable code is performed by traversing once more the AST in lexicographic order. This pass is straightforward because our output language is a high-level language and, therefore, we do not deal with most of the issues of code generation <ref> [ASU85] </ref>. Moreover, at this point, all necessary attributes for the code generation have been already filled by the static and dynamic inference phases.
Reference: [BBC + 93] <author> Richard Barrett, Michael Berry, Tony Chan, James Demmel, June Donato, Jack Dongarra, Victor Eijkhout, Roldan Pozo, Charles Romine, and Henk van der Vorst. </author> <title> Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods. </title> <publisher> SIAM, </publisher> <year> 1993. </year>
Reference-contexts: By performing these less expensive tests, MATLAB is able to improve its performance using specialized functions. Consider, for example, the solve operation: z = M n b; that appears in the preconditioned conjugate gradient (CG) <ref> [BBC + 93] </ref>, presented in Figure 5.8 (Statement S10). In this case, M is a matrix and b is a rowVector. The general method for the solution of a linear system requires O (n 3 ) operations. <p> This solve operation using a diagonal matrix occurs normally in practice, as for example in the CG algorithm using a diagonal preconditioner <ref> [BBC + 93] </ref>. <p> Poisson equation (Ga) 40 fi 40 48 c Two body problem using 4th order Runge-Kutta (RK) 3200 steps 66 c Two body problem using Euler-Cromer method (EC) 6240 steps 26 c Incomplete Cholesky Factorization (IC) 400 fi 400 33 d Generation of a 3D-Surface (3D) 51fi31fi21 28 d Source: a: <ref> [BBC + 93] </ref> b: [Mat92c] c: [Gar94] d: Colleagues fl A stiffness matrix from the Harwell-Boeing Test Set (BCSSTK06) was used as input data for these programs. Table 7.1: Test programs. A brief description of the test programs is presented in Table 7.1.
Reference: [BBG + 93] <author> Francois Bodin, Peter Beckman, Dennis Gannon, Srinivas Narayana, and Shelby Yang. </author> <title> Distributed pC++: Basic Ideas for an Object Parallel Language. </title> <booktitle> In OON-SKI'93 Proceedings of the First Annual Object-Oriented Numerics Conference, </booktitle> <pages> pages 1-24, </pages> <month> April </month> <year> 1993. </year> <month> 101 </month>
Reference-contexts: Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran [Hig93] and pC++ <ref> [BBG + 93] </ref>. A third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel.
Reference: [BE94] <author> William Blume and Rudolf Eigenmann. </author> <title> The Range Test: A Dependence Test for Symbolic, Non-linear Expressions. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <pages> pages 528-537, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: This algorithm is similar to the range propagation algorithm used by Blume and Eigenmann for the Range Test <ref> [BE94] </ref>. Since all matrices in MATLAB have lower dimensions set to 1, our problem is simplified to determining whether the maximum value that an array index will reach is larger than the corresponding dimension in the previous assignment of the variable.
Reference: [BEF + 94] <author> William Blume, Rudolf Eigenmann, Keith Faigin, John Grout, Jay Hoeflinger, David Padua, Paul Petersen, Bill Pottenger, Lawrence Rauchwerger, Peng Tu, and Stephen Weatherford. </author> <title> Polaris: Improving the Effectiveness of Parallelizing Compilers. </title> <editor> In K. Pingali, U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 141-154. </pages> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> vol. 892, </volume> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1994. </year> <booktitle> 7th International Workshop, </booktitle> <address> Ithaca, NY, USA. </address>
Reference-contexts: Several approaches to facilitate the development and maintenance of programs for high-performance computers are currently under study. One approach is the automatic translation of conventional programming languages, notably Fortran, into parallel form. Po-laris <ref> [BEF + 94] </ref> and Parafrase-2 [PGH + 89], developed at Illinois, and SUIF [AALL93], a compiler developed at Stanford, are examples of this first approach. Another approach is to extend conventional languages with simple annotations and parallel constructs.
Reference: [Bud88] <author> Timothy Budd. </author> <title> An APL Compiler. </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: In this way, the execution could be made more efficient by eliminating the need for some or all of the run-time bookkeeping operations. A study of the effectiveness of this type of approach on APL programs is presented in <ref> [Bud88] </ref>. When the bulk of the computations is done by the high-level array functions, the inefficiency of the interpreter is less of a problem. This is because these high-level functions are not interpreted and the bookkeeping operations need to be performed only when the function is invoked and/or returns. <p> We make use in this work of data-flow analysis as described by Aho, Sethi, and Ullman in [ASU85], and type inference techniques developed for SETL [Sch75] and APL <ref> [Bud88, Chi86] </ref>. We extend these techniques where necessary to deal with peculiarities of the MAT-LAB language and to improve accuracy and performance. <p> A few compilers for APL have been developed in the past. These compilers are also based on forward/backward dataflow analysis. Budd <ref> [Bud88] </ref> and Ching [Chi86] have independently developed compilers for APL. Budd's compiler translates APL programs into C, while Ching's compiler produces IBM System/370 assembly code directly. <p> Finally, APL's syntax is much simpler than MATLAB. The syntax for APL expressions is so regular that it can almost be recognized by a finite state automaton <ref> [Bud88] </ref>. Additionally, all functions in APL, including user defined functions, are limited to either zero, one, or two arguments. This limitation facilitates the translation process.
Reference: [CFR + 91] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Ken-neth Zadeck. </author> <title> Efficiently Computing Static Single Assignment Form and the Control Dependence Graph. </title> <journal> ACM Transactions on Programming Language and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Our inference algorithms are applied to a Static Single Assignment (SSA) <ref> [CFR + 91] </ref> 17 S1: load %(V) S1: load %(V 1 ) S2: n = length (V); S2: n 1 = length (V 1 ); S3: T = 0; S3: T 1 = 0; P1: T 4 = (T 2 ,T 1 ); S6: end S6: end S7: AVG = T <p> Hence, in situations like this, we use the standard approach and transform indexed assignments of the form A (R) = RHS; where R is an arbitrary range, into A i+1 = ff (A i , R, RHS); The ff function we use is similar to the "Update" function described in <ref> [CFR + 91] </ref>, but extended for assignments to a matrix range. In the case of MATLAB, an ff function may return an array with dimensions larger than that of the parameter array.
Reference: [Chi86] <author> Wai-Mee Ching. </author> <title> Program Analysis and Code Generation in an APL/370 Compiler. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 30:6:594-602, </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: We make use in this work of data-flow analysis as described by Aho, Sethi, and Ullman in [ASU85], and type inference techniques developed for SETL [Sch75] and APL <ref> [Bud88, Chi86] </ref>. We extend these techniques where necessary to deal with peculiarities of the MAT-LAB language and to improve accuracy and performance. <p> A few compilers for APL have been developed in the past. These compilers are also based on forward/backward dataflow analysis. Budd [Bud88] and Ching <ref> [Chi86] </ref> have independently developed compilers for APL. Budd's compiler translates APL programs into C, while Ching's compiler produces IBM System/370 assembly code directly.
Reference: [Coo88] <author> Grant O. Cook Jr. </author> <title> ALPAL A Tool for the Development of Large-Scale Simulation Codes. </title> <type> Technical report, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> August </month> <year> 1988. </year> <note> Technical Report UCID-21482. </note>
Reference-contexts: Examples include High Performance Fortran [Hig93] and pC++ [BBG + 93]. A third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel. Examples of this approach are //ELL-PACK [HRC + 90], developed at Purdue, ALPAL <ref> [Coo88] </ref>, developed at Lawrence Livermore Laboratories, and EXTENT [DGK + 94], developed at Ohio State University.
Reference: [DGG + 94] <author> L. DeRose, K. Gallivan, E. Gallopoulos, B. Marsolf, and D. Padua. </author> <title> An Environment for the Rapid Prototyping and Development of Numerical Programs and Libraries for Scientific Computation. </title> <editor> In F. Makedon, editor, </editor> <booktitle> Proc. of the DAGS'94 Symposium: Parallel Computation and Problem Solving Environments, </booktitle> <pages> pages 11-25, </pages> <institution> Dartmouth College, </institution> <month> July </month> <year> 1994. </year> <month> 102 </month>
Reference-contexts: This environment supports the development of high-performance numerical programs and libraries by combining the transformation and analysis techniques used in restructuring compilers with the algebraic techniques used by developers to express and manipulate their algorithms in an intuitively useful manner <ref> [DGG + 94] </ref>. The development process using FALCON starts with a simple prototype of the algorithm and then continues with a sequence of automatic and interactive transformations until an effective program or routine is obtained.
Reference: [DGG + 95a] <author> L. DeRose, K. Gallivan, E. Gallopoulos, B. Marsolf, and D. Padua. </author> <title> FALCON: A MATLAB Interactive Restructuring Compiler. </title> <editor> In C.-H. Huang, P. Sadayappan, U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 269-288. </pages> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> vol. 1033, </volume> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1995. </year> <booktitle> 8th International Workshop, </booktitle> <address> Columbus, Ohio. </address>
Reference-contexts: Examples of this approach are //ELL-PACK [HRC + 90], developed at Purdue, ALPAL [Coo88], developed at Lawrence Livermore Laboratories, and EXTENT [DGK + 94], developed at Ohio State University. We addressed the problem of development of software for scientific computation on high-performance computers by designing FALCON <ref> [DGG + 95b, DGG + 95a] </ref>, a development environment that combines the three approaches described above. 1 1.1 High-Level Approach for Software Development for Scientific Computation We believe that the development process should use a very high-level language that should be as close as possible to the mathematical description of the
Reference: [DGG + 95b] <author> L. DeRose, K. Gallivan, E. Gallopoulos, B. Marsolf, and D. Padua. </author> <title> FALCON: An Environment for the Development of Scientific Libraries and Applications. </title> <booktitle> In Proc. of the KBUP95: First international workshop on Knowledge-Based systems for the (re)Use of Program libraries, </booktitle> <institution> Sophia Antipolis, France, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: Examples of this approach are //ELL-PACK [HRC + 90], developed at Purdue, ALPAL [Coo88], developed at Lawrence Livermore Laboratories, and EXTENT [DGK + 94], developed at Ohio State University. We addressed the problem of development of software for scientific computation on high-performance computers by designing FALCON <ref> [DGG + 95b, DGG + 95a] </ref>, a development environment that combines the three approaches described above. 1 1.1 High-Level Approach for Software Development for Scientific Computation We believe that the development process should use a very high-level language that should be as close as possible to the mathematical description of the
Reference: [DGK + 94] <author> D. L. Dai, S. K. S. Gupta, S. D. Kaushik, J. H. Lu, R. V. Singh, C.-H. Huang, P. Sadayappan, and R. W. Johnson. </author> <title> EXTENT: A Portable Programming Environment for Designing and Implementing High-Performance Block-Recursive Algorithms. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <pages> pages 49-58, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: A third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel. Examples of this approach are //ELL-PACK [HRC + 90], developed at Purdue, ALPAL [Coo88], developed at Lawrence Livermore Laboratories, and EXTENT <ref> [DGK + 94] </ref>, developed at Ohio State University.
Reference: [DJK93] <author> Peter Drakenberg, Peter Jacobson, and Bo Kagstrom. </author> <title> A CONLAB Compiler for a Distributed Memory Multicomputer. </title> <booktitle> In Proceedings of the 6th SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> Norfolk Va, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: It uses a subset of the MATLAB language, with extensions for expressing parallelism, synchronization, and communication. A translator from CONLAB to C was developed by Drakenberg et.al. <ref> [DJK93] </ref>. However, some simplifications and modifications 10 have been made to the source language to allow efficient C code to be produced, such as the exclusion of all primitives for synchronization and communication, except for message passing.
Reference: [DMBS79] <author> J. J. Dongarra, C. B. Moler, J. R. Bunch, and G. W. Stewart. </author> <title> LINPACK User's Guide. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <year> 1979. </year>
Reference-contexts: Moreover, at this point, all necessary attributes for the code generation have been already filled by the static and dynamic inference phases. To maintain compatibility with the MATLAB interpreter, whenever possible 7 the compiler generates function calls from the same libraries used by MATLAB (i.e., LINPACK <ref> [DMBS79] </ref>, LAPACK [ABB + 92], EISPACK [SBD + 76]). 7 The information on which library function is being used by the interpreter is not always available.
Reference: [DPar] <author> Luiz DeRose and David Padua. </author> <title> A MATLAB to Fortran 90 Translator and its Effectiveness. </title> <booktitle> In Proceedings of the 10th ACM International Conference on Supercomputing, to appear. </booktitle>
Reference-contexts: However, for some applications and algorithms, such functions are not sufficient and the program needs to execute a significant number of loops and scalar operations. In some experiments we have conducted <ref> [DPar] </ref>, it was observed that interpreting programs executing mainly loops and scalar operations could be up to three orders of magnitude slower than 3 executing their compiled versions. 1.3 Compiling MATLAB One important aspect of FALCON's design was the selection of its input language.
Reference: [Gar94] <author> Alejandro L. Garcia. </author> <title> Numerical Methods for Physics. </title> <publisher> Prentice Hall, </publisher> <year> 1994. </year> <month> 103 </month>
Reference-contexts: 48 c Two body problem using 4th order Runge-Kutta (RK) 3200 steps 66 c Two body problem using Euler-Cromer method (EC) 6240 steps 26 c Incomplete Cholesky Factorization (IC) 400 fi 400 33 d Generation of a 3D-Surface (3D) 51fi31fi21 28 d Source: a: [BBC + 93] b: [Mat92c] c: <ref> [Gar94] </ref> d: Colleagues fl A stiffness matrix from the Harwell-Boeing Test Set (BCSSTK06) was used as input data for these programs. Table 7.1: Test programs. A brief description of the test programs is presented in Table 7.1.
Reference: [GHR94] <author> E. Gallopoulos, E. Houstis, and J. R. Rice. </author> <title> Computer as Thinker/Doer: Problem-Solving Environments for Computational Science. </title> <journal> IEEE Computational Science & Engineering, </journal> <volume> 1(2) </volume> <pages> 11-23, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: One reason is the interactive nature of the language, which facilitates debugging and analysis. A second reason is that interactive array languages are usually contained within problem-solving environments which include easy-to-use facilities for displaying results both graphically and in tabular form <ref> [GHR94] </ref>. Third, in these languages it is not necessary to specify the dimension, rank, or intrinsic type of elements of arrays. While some researchers may consider that lack of typing increases the probability of error, in practice programmers find that this is a convenient feature.
Reference: [GMBW95] <author> K. Gallivan, B. Marsolf, A. Bik, and H. Wijshoff. </author> <title> The Generation of Optimized Codes using Nonzero Structure Analysis. </title> <type> Technical Report 1451, </type> <institution> Center for Supercomputing Research and Development, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: The support of global variables and the reminder of the input/output constructions is straightforward, and should be available in a second version of the compiler. Support for sparse computation requires more research. This issue is being addressed for the FALCON system in the work by Gallivan et. al. <ref> [GMBW95] </ref>. 3.2 Phases of the MATLAB Compiler The main challenge of the MATLAB compiler is to perform inference on the input program to determine the variable properties: intrinsic type, rank, shape, and structure.
Reference: [GMW79] <author> Michael J. Gordon, Arthur J. Milner, and Christopher P. Wadsworth. </author> <title> Edinburgh LCF, </title> <booktitle> volume 78 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1979. </year>
Reference-contexts: mechanism are discussed in Chapter 5; the dynamic phase and its algorithms are discussed in Chapter 6; experimental results are presented in Chapter 7; and, finally, our conclusions are presented in Chapter 8. 6 Chapter 2 RELATED WORK There are many examples of typeless programming languages, including APL, MATLAB, ML <ref> [GMW79] </ref>, Haskell [HWA + 88], Lisp [MAE + 65], and Smalltalk [GR83]. These languages can be divided in two classes: the statically typed languages (e.g., ML and Haskell) and the dynamically typed languages (e.g., Lisp, Smalltalk, APL, and MATLAB). <p> Thus, the type-checker may sometimes find a more generic type assignment than expected. A classical example is the language ML, a meta-language for theorem proving, where the main motivation for strict type-checking is to ensure that every computed value of type theorem is indeed a theorem <ref> [GMW79] </ref>. To facilitate type inferencing, several restrictions are imposed to the language. For example, ML does not allow expressions with mixed types. Thus, a function definition fun successor (n) = n+1; will be considered a function that takes an integer as argument (n) and returns another 7 integer.
Reference: [GP92] <author> Milind Girkar and Constantine D. Polychronopoulos. </author> <title> Automatic Extraction of Functional Parallelism from Ordinary Programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2), </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: One important characteristic of M-file functions in MATLAB is that they are side-effect free. This functionality can be used to facilitate the exploitation of functional parallelism <ref> [GP92] </ref> and loop parallelism. To avoid confusion, from here on when the term function is used alone in the text, it will refer to M-file functions and built-in functions only, and not to script files.
Reference: [GR83] <author> A. Goldeberg and D. Robson. </author> <title> Smalltalk-80: The Language and Its Implementation. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1983. </year>
Reference-contexts: algorithms are discussed in Chapter 6; experimental results are presented in Chapter 7; and, finally, our conclusions are presented in Chapter 8. 6 Chapter 2 RELATED WORK There are many examples of typeless programming languages, including APL, MATLAB, ML [GMW79], Haskell [HWA + 88], Lisp [MAE + 65], and Smalltalk <ref> [GR83] </ref>. These languages can be divided in two classes: the statically typed languages (e.g., ML and Haskell) and the dynamically typed languages (e.g., Lisp, Smalltalk, APL, and MATLAB). Statically typed languages include type constraints as part of their language definition.
Reference: [GR84] <author> L. Gilman and A. Rose. </author> <title> APL : An Interactive Approach. </title> <publisher> Wiley, </publisher> <year> 1984. </year>
Reference-contexts: The prototype and intermediate versions of the code are represented in an interactive array language. 1.2 Issues on the Utilization of Interactive Array Lan guages Interactive array languages, such as APL <ref> [GR84, Pom83] </ref>, and MATLAB [Mat92a] are powerful programming tools for the development of programs for numerical computation. Many computational scientists consider it easier to prototype algorithms and applications using 2 array languages instead of conventional languages such as Fortran and C.
Reference: [Hig93] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <month> May </month> <year> 1993. </year> <note> Version 1.0. </note>
Reference-contexts: Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran <ref> [Hig93] </ref> and pC++ [BBG + 93]. A third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel.
Reference: [HRC + 90] <author> E. N. Houstis, J. R. Rice, N. P. Chrisochoides, H. C. Karathanasis, P. N. Pa-pachiou, M. K. Samartzis, E. A. Vavalis, Ko Yang Wang, and S. Weerawarana. </author> <title> //ELLPACK: A Numerical Simulation Programming Environment for Parallel MIMD Machines. </title> <booktitle> In Proceedings 1990 International Conference on Supercomputing, </booktitle> <pages> pages 96-107, </pages> <year> 1990. </year>
Reference-contexts: Examples include High Performance Fortran [Hig93] and pC++ [BBG + 93]. A third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel. Examples of this approach are //ELL-PACK <ref> [HRC + 90] </ref>, developed at Purdue, ALPAL [Coo88], developed at Lawrence Livermore Laboratories, and EXTENT [DGK + 94], developed at Ohio State University.
Reference: [HWA + 88] <author> P. Hudak, P. Wadler, Arvind, B. Boutel, J. Fairbairn, J. Fasel, J. Hughes, T. Johnsson, D. Kieburtz, S. P. Jones, R. Nikhil, M. Reeve, D. Wise, and 104 J. Young. </author> <title> Report on the Functional Programming Language Haskell. </title> <type> Technical report, </type> <institution> Yale University, </institution> <month> December </month> <year> 1988. </year> <note> Technical Report DCS/RR-666. </note>
Reference-contexts: discussed in Chapter 5; the dynamic phase and its algorithms are discussed in Chapter 6; experimental results are presented in Chapter 7; and, finally, our conclusions are presented in Chapter 8. 6 Chapter 2 RELATED WORK There are many examples of typeless programming languages, including APL, MATLAB, ML [GMW79], Haskell <ref> [HWA + 88] </ref>, Lisp [MAE + 65], and Smalltalk [GR83]. These languages can be divided in two classes: the statically typed languages (e.g., ML and Haskell) and the dynamically typed languages (e.g., Lisp, Smalltalk, APL, and MATLAB). Statically typed languages include type constraints as part of their language definition.
Reference: [JKR92] <author> Peter Jacobson, Bo Kagstrom, and Mikael Rannar. </author> <title> Algorithm Development for Distributed Memory Multicomputers Using CONLAB. </title> <journal> Scientific Programming, </journal> <volume> 1 </volume> <pages> 185-203, </pages> <year> 1992. </year>
Reference-contexts: We make use of some of the techniques developed for these two languages (SETL and APL) and extend them, with techniques originally developed for Fortran, to analyze array accesses and to represent the gathered information in a compact form [TP95]. 2.3 Compilation of MATLAB and MATLAB-like Lan guages CONLAB <ref> [JKR92] </ref> is an interactive environment for developing algorithms for parallel computer architectures. It uses a subset of the MATLAB language, with extensions for expressing parallelism, synchronization, and communication. A translator from CONLAB to C was developed by Drakenberg et.al. [DJK93].
Reference: [Joh] <author> Steve Johnson. </author> <title> Yacc: Yet Another Compiler-Compiler. Unix Programmer's Manual Supplementary Documents. </title>
Reference-contexts: The lexical analyzer, which is generated by lex [LS], reads and converts the main program into a stream of tokens that are processed by a syntax analyzer, which is generated by yacc <ref> [Joh] </ref>, 15 according to the grammar rules, producing a parse tree and a symbol table. These two steps are similar to scanning and parsing for conventional compilers, described in the literature [ASU85].
Reference: [Ker95] <author> Yaron Keren. MATCOM: </author> <title> A MATLAB to C++ Translator and Support Libraries. </title> <institution> Technion, Israel Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: Some sort of type inference system is alluded to by the authors in their papers, but it is not described. A simple approach for the compilation of MATLAB was taken by <ref> [Ker95] </ref> to translate MATLAB into C++. In this work, a matrix class was created to take care of all type and shape inference decisions during run-time. This class is then utilized by the generated C++.
Reference: [LS] <author> M. Lesk and E. Schmidt. </author> <title> Lex A Lexical Analyzer Generator. Unix Programmer's Manual Supplementary Documents. </title>
Reference-contexts: The compiler accepts as input a MATLAB script (from here on referred to as main program), that may contain several M-file calls. The lexical analyzer, which is generated by lex <ref> [LS] </ref>, reads and converts the main program into a stream of tokens that are processed by a syntax analyzer, which is generated by yacc [Joh], 15 according to the grammar rules, producing a parse tree and a symbol table.
Reference: [MAE + 65] <author> J. McCarthy, P. W. Abrahams, D. J. Edwards, T. P. Hart, and M. I. Levin. </author> <title> Lisp 1.5 Programmer's Manual. </title> <publisher> The MIT Press, </publisher> <address> 2nd edition, </address> <year> 1965. </year>
Reference-contexts: the dynamic phase and its algorithms are discussed in Chapter 6; experimental results are presented in Chapter 7; and, finally, our conclusions are presented in Chapter 8. 6 Chapter 2 RELATED WORK There are many examples of typeless programming languages, including APL, MATLAB, ML [GMW79], Haskell [HWA + 88], Lisp <ref> [MAE + 65] </ref>, and Smalltalk [GR83]. These languages can be divided in two classes: the statically typed languages (e.g., ML and Haskell) and the dynamically typed languages (e.g., Lisp, Smalltalk, APL, and MATLAB). Statically typed languages include type constraints as part of their language definition.
Reference: [Mat92a] <author> The Math Works, Inc. </author> <title> MATLAB, High-Performance Numeric Computation and Visualization Software. User's Guide, </title> <year> 1992. </year>
Reference-contexts: The prototype and intermediate versions of the code are represented in an interactive array language. 1.2 Issues on the Utilization of Interactive Array Lan guages Interactive array languages, such as APL [GR84, Pom83], and MATLAB <ref> [Mat92a] </ref> are powerful programming tools for the development of programs for numerical computation. Many computational scientists consider it easier to prototype algorithms and applications using 2 array languages instead of conventional languages such as Fortran and C. <p> This section discusses the main issues and the overall strategy adopted for each of the phases of the compiler. 3.2.1 Structure of a MATLAB Program MATLAB is a procedural language. Its current version works with essentially one kind of data structure: a rectangular numerical matrix <ref> [Mat92a] </ref>. A MATLAB program consists of one or more Fortran-like statements which may include function calls. There are two types of functions in MATLAB: intrinsic or built-in functions, and M-files.
Reference: [Mat92b] <author> The Math Works, Inc. </author> <title> MATLAB, High-Performance Numeric Computation and Visualization Software. Reference Guide, </title> <year> 1992. </year>
Reference-contexts: For example, the linear equation A fi x = b (3:1) can be solved in MATLAB using the simple statement: x = A n b; When executing this statement, MATLAB performs the following tests <ref> [Mat92b] </ref> to choose the best method to solve the linear system: * If A is a triangular matrix, or a permutation of a triangular matrix, then x is computed by a permuted back-substitution algorithm. * If A is symmetric, or Hermitian, and has positive diagonal elements, then a Cholesky factorization is
Reference: [Mat92c] <author> John H. Mathews. </author> <title> Numerical Methods for Mathematics, </title> <booktitle> Science and Engineering. </booktitle> <publisher> Prentice Hall, </publisher> <address> 2nd edition, </address> <year> 1992. </year>
Reference-contexts: fi 40 48 c Two body problem using 4th order Runge-Kutta (RK) 3200 steps 66 c Two body problem using Euler-Cromer method (EC) 6240 steps 26 c Incomplete Cholesky Factorization (IC) 400 fi 400 33 d Generation of a 3D-Surface (3D) 51fi31fi21 28 d Source: a: [BBC + 93] b: <ref> [Mat92c] </ref> c: [Gar94] d: Colleagues fl A stiffness matrix from the Harwell-Boeing Test Set (BCSSTK06) was used as input data for these programs. Table 7.1: Test programs. A brief description of the test programs is presented in Table 7.1. <p> the Simpson's rule to numerically approximate the value of the definite integral: Z 6 13 fl (x x 2 )e 2 dx: (7:2) This is a memory-intensive program because the adaptive quadrature method adjusts the integration interval to smaller subintervals, when some portions of the curve have large functional variation <ref> [Mat92c] </ref>. This refinement in the integration process requires data movements and dynamic reallocation of an array as new subintervals are gener ated. CN: is a numeric approximation method for the solution of parabolic differential equations (the heat equation).
Reference: [Mat95] <institution> The Math Works, Inc. MATLAB Compiler, </institution> <year> 1995. </year>
Reference-contexts: This class is then utilized by the generated C++. So, effectively, the control structure is compiled, but all the mathematical operations are still interpreted within this matrix class. Recently, MathWorks released MCC, a MATLAB Compiler <ref> [Mat95] </ref> that translates MAT-LAB programs into C for stand-alone external applications, or into C MEX-files which are called within the MATLAB environment. MEX-files are MATLAB-callable C or Fortran dynamically linked subroutines that are built with a special interface module. From [Mat95], it appears that MCC performs only simple inference and relies <p> Recently, MathWorks released MCC, a MATLAB Compiler <ref> [Mat95] </ref> that translates MAT-LAB programs into C for stand-alone external applications, or into C MEX-files which are called within the MATLAB environment. MEX-files are MATLAB-callable C or Fortran dynamically linked subroutines that are built with a special interface module. From [Mat95], it appears that MCC performs only simple inference and relies upon user provided flags, pragmas, and assertions 1 to optimize the generated C code. <p> The inefficiency results because the same activation of the built-in may result in different intrinsic types, depending on the value of the parameters. The simplest approach for these kinds of functions, as used by MathWorks in their compiler <ref> [Mat95] </ref>, is to assume that the output of these built-ins will always be of type complex. However, this automatic promotion of intrinsic type may affect the performance of the code. <p> The MathWorks 85 86 compiler does not perform use-coverage analysis and, as mentioned before, simplifies the handling of multi-typed built-ins by considering that they always return complex output. Moreover, as described in <ref> [Mat95] </ref>, the code generated by MCC cannot handle complex values nor perform subscript checking. To solve these problems, the code generated by MCC calls MATLAB using "callback functions" provided in their library.
Reference: [McK76] <author> W. M. McKeeman. </author> <title> Compiler Construction. In Compiler Construction, An Advanced Course. </title> <publisher> Springer-Verlag, </publisher> <year> 1976. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Volume 21. </volume> <pages> 105 </pages>
Reference-contexts: Therefore, the same variable in an M-file may have different properties in different activations of the M-file, depending on the properties of the actual input parameters. 3.2.4 The Intermediate Representation After the inline of the M-files, the parse tree is transformed into an abstract syntax tree (AST) <ref> [McK76] </ref>, which has an intermediate representation more suitable for the generation of the output code.
Reference: [Pac93] <author> Pacific-Sierra Research Corporation. </author> <title> VAST-90 Fortran 90 Language System: User guide, </title> <address> 2.1 edition, </address> <year> 1993. </year>
Reference-contexts: the square root is complex. 79 for j = 1:n r = sqrt (L (j,j) - s); if (r &lt;= 0) Error = j; L (j,j) = 1; else L (j,j) = r; ... the Fortran 90 programs were first translated to Fortran 77 with the use of VAST 90 <ref> [Pac93] </ref>, and then compiled with the Sun Fortran 77 compiler using the optimization flag "O3". The C-MEX-files generated by the MathWorks MATLAB to C Compiler (MCC) were compiled on the SPARCstation with the GNU C compiler using the optimization flag "O3".
Reference: [PGH + 89] <author> Constantine Polychronopoulos, Milind Girkar, Mohammad Reza Haghighat, Chia-Ling Lee, Bruce Leung, and Dale Schouten. </author> <title> Parafrase-2: A New Generation Parallelizing Compiler. </title> <booktitle> In Proceedings of 1989 Int'l. Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <booktitle> volume II, </booktitle> <pages> pages 39-48, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Several approaches to facilitate the development and maintenance of programs for high-performance computers are currently under study. One approach is the automatic translation of conventional programming languages, notably Fortran, into parallel form. Po-laris [BEF + 94] and Parafrase-2 <ref> [PGH + 89] </ref>, developed at Illinois, and SUIF [AALL93], a compiler developed at Stanford, are examples of this first approach. Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions.
Reference: [Pom83] <author> S. Pommier. </author> <title> An Introduction to APL. </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: The prototype and intermediate versions of the code are represented in an interactive array language. 1.2 Issues on the Utilization of Interactive Array Lan guages Interactive array languages, such as APL <ref> [GR84, Pom83] </ref>, and MATLAB [Mat92a] are powerful programming tools for the development of programs for numerical computation. Many computational scientists consider it easier to prototype algorithms and applications using 2 array languages instead of conventional languages such as Fortran and C.
Reference: [SBD + 76] <author> B. T. Smith, J. M. Boyle, J. J. Dongarra, B. S. Garbow, Y. Ikebe, V. C. Klema, and C. B. Moler. </author> <title> Matrix Eigensystem Routines - EISPACK Guide, </title> <booktitle> volume 6 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> second edition, </address> <year> 1976. </year>
Reference-contexts: To maintain compatibility with the MATLAB interpreter, whenever possible 7 the compiler generates function calls from the same libraries used by MATLAB (i.e., LINPACK [DMBS79], LAPACK [ABB + 92], EISPACK <ref> [SBD + 76] </ref>). 7 The information on which library function is being used by the interpreter is not always available.
Reference: [Sch75] <author> J. T. Schwartz. </author> <title> Automatic Data Structure Choice in a Language of a Very High Level. </title> <journal> Communications of the ACM, </journal> <volume> 18 </volume> <pages> 722-728, </pages> <year> 1975. </year>
Reference-contexts: We make use in this work of data-flow analysis as described by Aho, Sethi, and Ullman in [ASU85], and type inference techniques developed for SETL <ref> [Sch75] </ref> and APL [Bud88, Chi86]. We extend these techniques where necessary to deal with peculiarities of the MAT-LAB language and to improve accuracy and performance. <p> SETL is a set-theoretically oriented language of very high-level. A SETL program may be considered to represent an algorithm before it is codified into a language of lower-level <ref> [Sch75] </ref>. It treats types in a fully dynamic way, with no type declarations. However, the types of the objects that appear in SETL programs can be deduced with the use of an appropriate global analysis [Sch75]. <p> be considered to represent an algorithm before it is codified into a language of lower-level <ref> [Sch75] </ref>. It treats types in a fully dynamic way, with no type declarations. However, the types of the objects that appear in SETL programs can be deduced with the use of an appropriate global analysis [Sch75]. For this type inference, a type algebra that operates on the structural type of SETL objects is used. This algebra is implemented using tables whose entries describe the action, on the symbolic entities of the algebra, of each of the primitives of the language to be analyzed [Sch75]. 2.2 Compilation <p> global analysis <ref> [Sch75] </ref>. For this type inference, a type algebra that operates on the structural type of SETL objects is used. This algebra is implemented using tables whose entries describe the action, on the symbolic entities of the algebra, of each of the primitives of the language to be analyzed [Sch75]. 2.2 Compilation of APL APL is similar to MATLAB in that it can be executed interactively, is usually interpreted, and operates on aggregate data structures. A few compilers for APL have been developed in the past. These compilers are also based on forward/backward dataflow analysis. <p> presentation, the intrinsic type inference, and shape and rank inference are discussed separately, despite the fact that they are applied by a single compiler pass. 5.1 Intrinsic Type Inference The static mechanism for intrinsic type inference propagates intrinsic types through expressions using a type algebra similar to that described in <ref> [Sch75] </ref> for SETL. For the case of logical operators, the output is always considered to be of intrinsic type logical. For the other operators and built-in functions, this algebra operates on the intrinsic type of MATLAB objects and is implemented using tables for all operations.
Reference: [TP95] <author> Peng Tu and David Padua. </author> <title> Gated SSA-Based Demand-Driven Symbolic Analysis for Parallelizing Compilers. </title> <booktitle> In Proceedings of the 9th ACM International Conference on Supercomputing, </booktitle> <pages> pages 414-423, </pages> <address> Barcelona, Spain, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: We make use of some of the techniques developed for these two languages (SETL and APL) and extend them, with techniques originally developed for Fortran, to analyze array accesses and to represent the gathered information in a compact form <ref> [TP95] </ref>. 2.3 Compilation of MATLAB and MATLAB-like Lan guages CONLAB [JKR92] is an interactive environment for developing algorithms for parallel computer architectures. It uses a subset of the MATLAB language, with extensions for expressing parallelism, synchronization, and communication. A translator from CONLAB to C was developed by Drakenberg et.al. [DJK93]. <p> This information is obtained by tracing the indices of the array to their earliest definitions in the AST representation of the program, following an on-demand approach similar to that introduced in <ref> [TP95] </ref>. In some situations (such as non-scalar indices or indirections), this symbolic inference is unable to determine the maximum value. In this case, the compiler sets the corresponding information as unknown, and dynamic allocation is required. Algorithm: Symbolic Dimension Propagation. Input: An AST representation of a MATLAB program.

References-found: 44

