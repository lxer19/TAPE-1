URL: http://www.aic.nrl.navy.mil/~aha/papers/ijcai93-workshop.ps
Refering-URL: http://www.aic.nrl.navy.mil/~aha/pub-details.html
Root-URL: 
Email: aha@aic.nrl.navy.mil  
Title: Learning Singly-Recursive Relations from Small Datasets  
Author: David W. Aha Charles X. Ling Stan Matwin Stephane Lapointe 
Address: Washington, DC 20375  
Affiliation: Center for Applied Research in AI Naval Research Laboratory  
Abstract: The inductive logic programming system LOPSTER was created to demonstrate the advantage of basing induction on logical implication rather than -subsumption. LOPSTER's sub-unification procedures allow it to induce recursive relations using a minimum number of examples, whereas inductive logic programming algorithms based on -subsumption require many more examples to solve induction tasks. However, LOPSTER's input examples must be carefully chosen; they must be along the same inverse resolution path. We hypothesize that an extension of LOPSTER can efficiently induce recursive relations without this requirement. We introduce a generalization of LOPSTER named CRUSTACEAN that has this capability and empirically evaluate its ability to induce recursive relations. 
Abstract-found: 1
Intro-found: 1
Reference: <author> De Raedt, L., & Bruynooghe, M. </author> <year> (1989). </year> <title> Constructive induction by analogy: A method to learn how to learn? In Proceedings of the Fourth European Working Session on Learning (pp. </title> <address> 189-200). Montpellier, France: </address> <publisher> Pitman. </publisher>
Reference: <author> Idestam-Almquist, P. </author> <year> (1993). </year> <title> Generalization under implication by recursive anti-unification. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning (pp. </booktitle> <pages> 151-158). </pages> <address> Amherst, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kietz, J-U., & Wrobel, S. </author> <year> (1991). </year> <title> Controlling the complexity of learning in logic through syntactic and task-oriented models. </title> <editor> In S. Muggleton (Ed.), </editor> <booktitle> Inductive Logic Programming. </booktitle> <address> London, UK: </address> <publisher> Academic Press. </publisher>
Reference: <author> Lapointe, S. </author> <year> (1992). </year> <title> Induction of recursive logic programs. </title> <type> Unpublished master's thesis, </type> <institution> University of Ottawa, </institution> <address> Ottawa, Canada. </address>
Reference-contexts: Some ILP systems employ strong learning biases (e.g., Kietz & Wrobel, 1991; De Raedt & Bruynooghe, 1989; Silverstein & Pazzani, 1991). However, only LOPSTER has demonstrated a consistent ability to induce relations when given only a small number of examples <ref> (Lapointe & Matwin, 1992) </ref>. This is because 1. <p> Section 3 describes a generalization of LOPSTER that does not a priori require the user to know either the base or recursive clauses. 3 CRUSTACEAN: Removing the Constraint This section introduces CRUSTACEAN, a generalization of LOPSTER <ref> (Lapointe & Matwin, 1992) </ref>. CRUSTACEAN inputs a set of (positive) examples of a predicate, a set of negative examples, and a set of constants. <p> If that base clause does not resolve with any of the negative examples, then a recursive clause is induced for each highest-summed match among lists of generating terms using the same procedure as used in LOPSTER (see <ref> (Lapointe & Matwin, 1992) </ref> for details). A recursive definition is saved for each pairing of the base 8 Also, lists of generating terms at depth=0 are ignored during matching. <p> The relations used in the experiments were previously used to test LOPSTER <ref> (Lapointe & Matwin, 1992) </ref>. However, the positive examples used here were modified so as to not be on the same inverse resolution path. 10 The positive examples, negative examples, and target relation for each experiment are summarized in Table 2. <p> of (a,[c,a]) + split ([x,y],[x],[y]) + last of (b,[x,y,b]) + split ([1,2,3,4],[1,3],[2,4]) last of ([x,y],[x]) split ([x,y],[x,y],A) last of (A,[A]). split ([a],[],[a]) last of (A,[B,CjD]) :- last of (A,[CjD]). split ([],[],[a]) split ([a],[],[]) split ([],[],[]). split ([A,BjC],[AjD],[BjE]) :- split (C,D,E). 6 Conclusion This paper introduces CRUSTACEAN, a generalization of LOPSTER <ref> (Lapointe & Matwin, 1992) </ref> that removes its requirement that the input examples must be on the same inverse resolution path.
Reference: <author> Lapointe, S., & Matwin, S. </author> <year> (1992). </year> <title> Sub-unification: A tool for efficient induction of recursive programs. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning (pp. </booktitle> <pages> 273-281). </pages> <address> Aberdeen, Scotland: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Some ILP systems employ strong learning biases (e.g., Kietz & Wrobel, 1991; De Raedt & Bruynooghe, 1989; Silverstein & Pazzani, 1991). However, only LOPSTER has demonstrated a consistent ability to induce relations when given only a small number of examples <ref> (Lapointe & Matwin, 1992) </ref>. This is because 1. <p> Section 3 describes a generalization of LOPSTER that does not a priori require the user to know either the base or recursive clauses. 3 CRUSTACEAN: Removing the Constraint This section introduces CRUSTACEAN, a generalization of LOPSTER <ref> (Lapointe & Matwin, 1992) </ref>. CRUSTACEAN inputs a set of (positive) examples of a predicate, a set of negative examples, and a set of constants. <p> If that base clause does not resolve with any of the negative examples, then a recursive clause is induced for each highest-summed match among lists of generating terms using the same procedure as used in LOPSTER (see <ref> (Lapointe & Matwin, 1992) </ref> for details). A recursive definition is saved for each pairing of the base 8 Also, lists of generating terms at depth=0 are ignored during matching. <p> The relations used in the experiments were previously used to test LOPSTER <ref> (Lapointe & Matwin, 1992) </ref>. However, the positive examples used here were modified so as to not be on the same inverse resolution path. 10 The positive examples, negative examples, and target relation for each experiment are summarized in Table 2. <p> of (a,[c,a]) + split ([x,y],[x],[y]) + last of (b,[x,y,b]) + split ([1,2,3,4],[1,3],[2,4]) last of ([x,y],[x]) split ([x,y],[x,y],A) last of (A,[A]). split ([a],[],[a]) last of (A,[B,CjD]) :- last of (A,[CjD]). split ([],[],[a]) split ([a],[],[]) split ([],[],[]). split ([A,BjC],[AjD],[BjE]) :- split (C,D,E). 6 Conclusion This paper introduces CRUSTACEAN, a generalization of LOPSTER <ref> (Lapointe & Matwin, 1992) </ref> that removes its requirement that the input examples must be on the same inverse resolution path.
Reference: <author> Lapointe, S., Ling, X. C., & Matwin, S. </author> <year> (1993). </year> <title> Constructive inductive logic programming. </title> <booktitle> To appear in Proceedings of the Thirteenth International Joint Conference 11 on Artificial Intelligence. </booktitle> <address> Chambery, France: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For example, we purposely provided short (positive) examples to CRUSTACEAN to reduce cpu times. Future research goals include improving efficiency. One way to do this is to further restrict CRUSTACEAN's hypothesis language. We have not yet extended CRUSTACEAN to induce left-recursive relations or for induction tasks requiring predicate invention <ref> (Lapointe, Ling, & Matwin, 1993) </ref>.
Reference: <author> Ling, X. C. </author> <year> (1991). </year> <title> Inductive learning from good examples. </title> <booktitle> In Proceedings of the Twelvth International Conference on Artificial Intelligence (pp. </booktitle> <pages> 751-756). </pages> <address> Sydney, Australia: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: 1 Introduction Several well-known inductive logic programming (ILP) algorithms are based on - subsumption (e.g., Muggleton & Feng, 1990; Quinlan, 1991; Pazzani & Kibler, 1992). When inducing recursive clauses, the input examples to these algorithms must include at least two basic representative sets <ref> (Ling, 1991) </ref>. However, if the user knows what inputs form basic representative sets for the target relation, then the user must already know the target relation's definition (i.e., represented by pairing two clauses that define the target relation, namely a base clause and a recursive clause).
Reference: <author> Muggleton, S. </author> <year> (1992). </year> <title> Inverting implication. </title> <booktitle> In Proceedings of the First European Workshop on Inductive Logic Programming. </booktitle> <address> Vienna, Austria: </address> <note> Unpublished. </note>
Reference: <author> Muggleton, S., & Feng, C. </author> <year> (1990). </year> <title> Efficient induction of logic programs. </title> <booktitle> Proceedings of the First International Workshop on Algorithmic Learning Theory (pp. </booktitle> <pages> 368-381). </pages> <address> Tokyo, Japan: </address> <booktitle> Japanese Society for Artificial Intelligence. </booktitle>
Reference-contexts: The inverse resolution chain for these clauses is shown in Figure 1. 2.1.1 Logical implication rather than fi-subsumption Most ILP systems are based on -subsumption; they typically induce clauses by computing relative least general generalizations (rlggs) (e.g., GOLEM <ref> (Muggleton & Feng, 1990) </ref>) or by incrementally extending clauses as directed by information gain evaluations (e.g., FOIL (Quinlan, 1991)). These approaches assume that a clause participates only once during the inverse resolution proof of other clauses. <p> two pairings of sets of generating lists above, and the matched generating lists with the highest summed depths for the latter pair is [ [empty,pair (2)] at depth=2 [empty,pair (2)] at depth=3] If any acceptable matches are found, then a base clause is induced by computing the least general generalization <ref> (Muggleton & Feng, 1990) </ref> of the corresponding jP j lists of subterm combinations.
Reference: <author> Pazzani, M., & Kibler, D. </author> <year> (1992). </year> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 57-94. </pages>
Reference-contexts: Therefore, users of such ILP systems often provide substantially more inputs to their systems. For example, Quinlan (1991) provided 70 positive and 10K negatives examples to FOIL to induce the append relation. 5 Systems such as FOCL <ref> (Pazzani & Kibler, 1992) </ref> that allow background knowledge to be encoded as rules (i.e., rather than requiring that all such knowledge be encoded as facts) cannot completely solve this problem.
Reference: <author> Quinlan, J. R. </author> <year> (1991). </year> <title> Determinate literals in inductive logic programming. </title> <booktitle> In Proceedings of the Twelvth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 746-750). </pages> <address> Sydney, Australia: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: these clauses is shown in Figure 1. 2.1.1 Logical implication rather than fi-subsumption Most ILP systems are based on -subsumption; they typically induce clauses by computing relative least general generalizations (rlggs) (e.g., GOLEM (Muggleton & Feng, 1990)) or by incrementally extending clauses as directed by information gain evaluations (e.g., FOIL <ref> (Quinlan, 1991) </ref>). These approaches assume that a clause participates only once during the inverse resolution proof of other clauses. Therefore, they are not tuned to inducing recursive relations even though such relations are prevalent in logic programs written in PROLOG.
Reference: <author> Silverstein, G., & Pazzani, M. J. </author> <year> (1991). </year> <title> Relational cliches: Constraining constructive induction during relational learning. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning (pp. </booktitle> <pages> 432-436). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher> <pages> 12 </pages>
References-found: 12

