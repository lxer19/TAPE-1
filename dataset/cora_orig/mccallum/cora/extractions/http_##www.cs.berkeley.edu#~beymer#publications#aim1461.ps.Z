URL: http://www.cs.berkeley.edu/~beymer/publications/aim1461.ps.Z
Refering-URL: http://www.cs.berkeley.edu/~beymer/publications.html
Root-URL: 
Email: email: beymer@ai.mit.edu  
Title: Face Recognition Under Varying Pose  
Author: David J. Beymer 
Note: Copyright c Massachusetts Institute of Technology, 1993  
Date: 1461 December, 1993  89  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Memo No.  C.B.C.L. Paper No.  
Abstract: Researchers in computer vision and pattern recognition have worked on automatic techniques for recognizing human faces for the last 20 years. While some systems, especially template-based ones, have been quite successful on expressionless, frontal views of faces with controlled lighting, not much work has taken face recognizers beyond these narrow imaging conditions. Our goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face rotations in depth. Building on successful template-based systems (especially Brunelli and Poggio[7]), our basic approach is to represent faces with templates from multiple model views that cover different poses from the viewing sphere. To recognize a novel view, the recognizer locates the eyes and nose features, uses these locations to geometrically register the input with model views, and then uses correlation on model templates to find the best match in the data base of people. Our system has achieved a recognition rate of 98% on a data base of 62 people containing 10 testing and 15 modelling views per person. This report describes research done at the Artificial Intelligence Laboratory and within the Center for Biological and Computational Learning. This research is sponsored by grants from the Office of Naval Research under contracts N00014-91-J-1270 and N00014-92-J-1879; by a grant from the National Science Foundation under contract ASC-9217041. Support for the A.I. Laboratory's artificial intelligence research is provided by ONR contract N00014-91-J-4038. The author is supported by a Howard Hughes Doctoral Fellowship from the Hughes Aircraft Company. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Shigeru Akamatsu, Tsutomu Sasaki, Hideo Fuka-machi, Nobuhiko Masui, and Yasuhito Suenaga. </author> <title> An accurate and robust face identification scheme. </title> <booktitle> In Proceedings Int. Conf. on Pattern Recognition, </booktitle> <volume> volume 2, </volume> <pages> pages 217-220, </pages> <address> The Hague, The Nether-lands, </address> <year> 1992. </year>
Reference: [2] <author> A. Azarbayejani, T. Starner, B. Horowitz, and A. Pentland. </author> <title> Visually controlled graphics. </title> <type> Technical Report No. 180, </type> <institution> MIT Media Lab, Vision and Modeling Group, </institution> <year> 1992. </year>
Reference-contexts: As opposed to the model-based and template-based approaches, this approach does not find features with semantic content as, say, an eye, nose or mouth detector does. Instead, the features are defined by the local grey level structure of the image, such as corners (Azarbaye-jani, et al. <ref> [2] </ref>), symmetry (Reisfeld and Yeshurun [33]), or the "end-inhibition" features of Manjunath, Shekhar, Chellappa, and von der Malsburg [29], which are ex 1 tracted from a wavelet decomposition of the image. 1.2.2 Face recognition While the earliest work in automatic face recognition dates back two decades (Kanade [22]), the topic has
Reference: [3] <author> Robert J. Baron. </author> <title> Mechanisms of human facial recognition. </title> <journal> International Journal of Man Machine Studies, </journal> <volume> 15 </volume> <pages> 137-178, </pages> <year> 1981. </year>
Reference-contexts: Terzopoulos and Waters [38] have used the active contour model of snakes to track facial features in image sequences. In the pictorial approach, a pixel-based representation of facial features is matched against the image. This representation may be templates of the major facial features (Bichsel [6], Baron <ref> [3] </ref>, Burt [8], Poggio and Brunelli [7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers [40]). For the template-based systems, correlation on preprocessed versions of the image is the typical matching metric. <p> In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron <ref> [3] </ref>, Brunelli and Poggio [7], Gilbert and Yang [18], Burt [8], Bichsel [6]). Template images need not be taken from the original grey levels; some systems use the gradient magnitude or gradient vector field in order to get invariance to lighting. <p> Systems that include rejection also report the false access rate, usually defined as the fraction of false accepts on test images of faces not in the library. Some recent systems have been quite successful, achieving high recognition rates and using relatively large data bases of people. For example, Baron <ref> [3] </ref> reached an impressive 100% recognition rate on a library of 42 people and a false access rate of 0% on 108 images. Brunelli and Poggio's system [7] achieved a recognition rate of 100% on frontal views of 47 people. <p> Using fewer exemplars decreases the running time but also reduces system flexibility and recognition performance. 4 Face recognition using multiple views As mentioned in the introduction, template-based face recognizers have been quite successful on frontal views of the face (Baron <ref> [3] </ref>, Turk and Pentland [39], Brunelli and Poggio [7]). Our goal is to extend template-based systems to handle varying pose, notably facial rotations in depth. Our approach is view-based, representing faces with templates from many images that cover the viewing sphere.
Reference: [4] <author> Alan Bennett and Ian Craw. </author> <title> Finding image features using deformable templates and detailed prior statistical knowledge. </title> <booktitle> In Proc. British Machine Vision Conference, </booktitle> <pages> pages 233-239, </pages> <year> 1991. </year>
Reference-contexts: An energy functional is defined that attracts portions of the model to preprocessed versions of the image peaks, valleys, edges and model fitting is performed by minimizing this functional. A related model-based approach fits a global head model constructed from tens of feature locations (Bennett and Craw <ref> [4] </ref>, Craw, Tock, and Bennett [14], Cootes, et al.[12]) to the image by varying individual feature locations. Terzopoulos and Waters [38] have used the active contour model of snakes to track facial features in image sequences.
Reference: [5] <author> J.R. Bergen and R. Hingorani. </author> <title> Hierarchical motion-based frame rate conversion. </title> <type> Technical report, </type> <institution> David Sarnoff Research Center, Princeton, </institution> <address> New Jersey, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: First, the optical flow is measured between the input features and the template using the hierarchical gradient-based scheme of Bergen and Hingorani <ref> [5] </ref>. This finds a flow field between the input feature and template, which can be interpreted as a dense set of correspondences. The input feature, as shown in figure 4, is then graphically warped using the flow field to make the input feature mimic the appearance of the template. <p> The second part of the geometrical alignment step attempts to compensate for any small remaining geometrical differences due to rotation, scale, or expression. A dense set of pixelwise correspondence between the affine transformed input and the model is computed using optical flow <ref> [5] </ref>. Given this dense set of correspondences, the affine transformed input can be brought into pixel-level correspondence with the model by applying a 2D warp operation driven by the optical flow (also see Shashua [36]).
Reference: [6] <author> Martin Bichsel. </author> <title> Strategies of Robust Object Recognition for the Automatic Identification of Human Faces. </title> <type> PhD thesis, </type> <institution> ETH, </institution> <address> Zurich, </address> <year> 1991. </year>
Reference-contexts: Terzopoulos and Waters [38] have used the active contour model of snakes to track facial features in image sequences. In the pictorial approach, a pixel-based representation of facial features is matched against the image. This representation may be templates of the major facial features (Bichsel <ref> [6] </ref>, Baron [3], Burt [8], Poggio and Brunelli [7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers [40]). For the template-based systems, correlation on preprocessed versions of the image is the typical matching metric. <p> In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron [3], Brunelli and Poggio [7], Gilbert and Yang [18], Burt [8], Bichsel <ref> [6] </ref>). Template images need not be taken from the original grey levels; some systems use the gradient magnitude or gradient vector field in order to get invariance to lighting. <p> Needless to say, these recognition statistics are meaningful only if the library of model faces is sufficiently large. While there is no consensus on the sufficient size of the model database, some of the more recent approaches ([26], <ref> [6] </ref>, [28]) have used libraries on the order of 70 people or more. 1.3 Our view-based recognizer As discussed in the previous section, not much work has taken face recognizers beyond the narrow imaging conditions of expressionless, frontal views of faces with controlled lighting.
Reference: [7] <author> Roberto Brunelli and Tomaso Poggio. </author> <title> Face recognition: Features versus templates. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(10) </volume> <pages> 1042-1052, </pages> <year> 1993. </year>
Reference-contexts: In the pictorial approach, a pixel-based representation of facial features is matched against the image. This representation may be templates of the major facial features (Bichsel [6], Baron [3], Burt [8], Poggio and Brunelli <ref> [7] </ref>) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers [40]). For the template-based systems, correlation on preprocessed versions of the image is the typical matching metric. The neural network approaches construct a network where implicit feature templates are "learned" from positive and negative examples. <p> There have been several feature geometry approaches, beginning with the seminal work of Kanade [22], and including Kaya and Kobayashi [23], Craw and Cameron [13], Wong, Law, and Tsang [42], Brunelli and Poggio <ref> [7] </ref>, and Chen and Huang [10]. These feature-based systems begin by locating a set of facial features, including such features as the corners of the eyes and mouth, sides of the face and nose, nostrils, the contour along the chin, etc. <p> In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron [3], Brunelli and Poggio <ref> [7] </ref>, Gilbert and Yang [18], Burt [8], Bichsel [6]). Template images need not be taken from the original grey levels; some systems use the gradient magnitude or gradient vector field in order to get invariance to lighting. <p> Some recent systems have been quite successful, achieving high recognition rates and using relatively large data bases of people. For example, Baron [3] reached an impressive 100% recognition rate on a library of 42 people and a false access rate of 0% on 108 images. Brunelli and Poggio's system <ref> [7] </ref> achieved a recognition rate of 100% on frontal views of 47 people. <p> Using fewer exemplars decreases the running time but also reduces system flexibility and recognition performance. 4 Face recognition using multiple views As mentioned in the introduction, template-based face recognizers have been quite successful on frontal views of the face (Baron [3], Turk and Pentland [39], Brunelli and Poggio <ref> [7] </ref>). Our goal is to extend template-based systems to handle varying pose, notably facial rotations in depth. Our approach is view-based, representing faces with templates from many images that cover the viewing sphere. <p> Best performance was had from dx+dy, mag, and lap, with dx+dy yielding the best recognition rate at 98.7%. Preprocessing with the gradient magnitude performs nearly as well, a result in agreement with the preprocessing experiments of Brunelli and Pogggio <ref> [7] </ref>. Given that using the original grey levels produces the lower rate of 94.5%, our results indicate that preprocessing the image with a differential operator gives the system a performance advantage.
Reference: [8] <author> Peter J. Burt. </author> <title> Multiresolution techniques for image representation, analysis, and 'smart' transmission. </title> <booktitle> In SPIE Vol. 1199, Visual Communications and Image Processing IV, </booktitle> <pages> pages 2-15, </pages> <year> 1989. </year>
Reference-contexts: Terzopoulos and Waters [38] have used the active contour model of snakes to track facial features in image sequences. In the pictorial approach, a pixel-based representation of facial features is matched against the image. This representation may be templates of the major facial features (Bichsel [6], Baron [3], Burt <ref> [8] </ref>, Poggio and Brunelli [7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers [40]). For the template-based systems, correlation on preprocessed versions of the image is the typical matching metric. <p> In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron [3], Brunelli and Poggio [7], Gilbert and Yang [18], Burt <ref> [8] </ref>, Bichsel [6]). Template images need not be taken from the original grey levels; some systems use the gradient magnitude or gradient vector field in order to get invariance to lighting.
Reference: [9] <author> Scott R. Cannon, Gregory W. Jones, Robert Camp-bell, and Neil W. Morgan. </author> <title> A computer vision system for identification of individuals. </title> <booktitle> In Proc. IECON, </booktitle> <pages> pages 347-351, </pages> <address> Milwaukee, WI, </address> <year> 1986. </year>
Reference: [10] <author> Chin-Wen Chen and Chung-Lin Huang. </author> <title> Human face recognition from a single front view. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <volume> 6(4) </volume> <pages> 571-593, </pages> <year> 1992. </year>
Reference-contexts: There have been several feature geometry approaches, beginning with the seminal work of Kanade [22], and including Kaya and Kobayashi [23], Craw and Cameron [13], Wong, Law, and Tsang [42], Brunelli and Poggio [7], and Chen and Huang <ref> [10] </ref>. These feature-based systems begin by locating a set of facial features, including such features as the corners of the eyes and mouth, sides of the face and nose, nostrils, the contour along the chin, etc.
Reference: [11] <author> Yong-Qing Cheng, Ke Liu, Jing-Yu Yang, and Hua-Feng Wang. </author> <title> A robust algebraic method for human face recognition. </title> <booktitle> In Proceedings Int. Conf. on Pattern Recognition, </booktitle> <volume> volume 2, </volume> <pages> pages 221-224, </pages> <address> The Hague, The Netherlands, </address> <year> 1992. </year>
Reference: [12] <author> T.F. Cootes, C.J. Taylor, A. Lanitis, D.H. Cooper, and J. Graham. </author> <title> Building and using flexible models incorporating grey-level information. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 242-246, </pages> <address> Berlin, </address> <month> May </month> <year> 1993. </year>
Reference: [13] <author> Ian Craw and Peter Cameron. </author> <title> Face recognition by computer. </title> <editor> In David Hogg and Roger Boyle, editors, </editor> <booktitle> Proc. British Machine Vision Conference, </booktitle> <pages> pages 498-507. </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: There have been several feature geometry approaches, beginning with the seminal work of Kanade [22], and including Kaya and Kobayashi [23], Craw and Cameron <ref> [13] </ref>, Wong, Law, and Tsang [42], Brunelli and Poggio [7], and Chen and Huang [10]. These feature-based systems begin by locating a set of facial features, including such features as the corners of the eyes and mouth, sides of the face and nose, nostrils, the contour along the chin, etc. <p> Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich [24], Turk and Pentland [39], Akamatsu, et al.[1], Craw and Cameron <ref> [13] </ref>, Dalla Serra and Brunelli [34]). It can be read as an suboptimal pictorial approach, reducing the dimensionality of the input space from the number of pixels in the templates to the number of eigenpictures, or "eigenfaces", used in the representation.
Reference: [14] <author> Ian Craw, David Tock, and Alan Bennett. </author> <title> Finding face features. </title> <booktitle> In Proceedings of the European Conference on Computer Vision, </booktitle> <pages> pages 92-96, </pages> <year> 1992. </year>
Reference-contexts: A related model-based approach fits a global head model constructed from tens of feature locations (Bennett and Craw [4], Craw, Tock, and Bennett <ref> [14] </ref>, Cootes, et al.[12]) to the image by varying individual feature locations. Terzopoulos and Waters [38] have used the active contour model of snakes to track facial features in image sequences. In the pictorial approach, a pixel-based representation of facial features is matched against the image.
Reference: [15] <author> Shimon Edelman, Daniel Reisfeld, and Yechezkel Yeshurun. </author> <title> Learning to recognize faces from examples. </title> <booktitle> In Proceedings of the European Conference on Computer Vision, </booktitle> <pages> pages 787-791, </pages> <year> 1992. </year>
Reference-contexts: Examples include autocorrelation (Kurita, Otsu and Sato [26]), Singular Value Decomposition (Cheng, et al.[11] and Hong [20]), and vector quantization (Ramsay, et al.[32]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen [25], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun <ref> [15] </ref>, Weng, Ahuja, and Huang [41], Fuchs and Haken [17], Stonham [37]). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. <p> Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level images. [41] uses directional edge maps, [37] uses a thresholded binary image, and <ref> [15] </ref> uses Gaussian units applied to the grey level image. Hybrid representations that combine the geometrical and pictorial approaches have been explored, such as Cannon et al.[9], whose feature vector face representation includes geometrical and template-based information.
Reference: [16] <author> Michael K. Fleming and Garrison W. Cottrell. </author> <title> Categorization of faces using unsupervised feature extraction. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <volume> volume 2, </volume> <pages> pages 65-70, </pages> <year> 1990. </year>
Reference-contexts: Examples include autocorrelation (Kurita, Otsu and Sato [26]), Singular Value Decomposition (Cheng, et al.[11] and Hong [20]), and vector quantization (Ramsay, et al.[32]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen [25], Fleming and Cottrell <ref> [16] </ref>, Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang [41], Fuchs and Haken [17], Stonham [37]). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level <p> faces (Kohonen [25], Fleming and Cottrell <ref> [16] </ref>, Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang [41], Fuchs and Haken [17], Stonham [37]). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level images. [41] uses directional edge maps, [37] uses a thresholded binary image, and [15] uses Gaussian units applied to the grey level image.
Reference: [17] <author> A. Fuchs and H. Haken. </author> <title> Pattern recognition and associative memory as dynamical processes in a syn-ergetic system; I. translational invariance, selective attention, and decomposition of scenes. </title> <journal> Biological Cybernetics, </journal> <volume> 60 </volume> <pages> 17-22, </pages> <year> 1988. </year>
Reference-contexts: (Kurita, Otsu and Sato [26]), Singular Value Decomposition (Cheng, et al.[11] and Hong [20]), and vector quantization (Ramsay, et al.[32]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen [25], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang [41], Fuchs and Haken <ref> [17] </ref>, Stonham [37]). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level images. [41] uses directional edge maps, [37] uses a thresholded binary image, and [15] <p> (Kohonen [25], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang [41], Fuchs and Haken <ref> [17] </ref>, Stonham [37]). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level images. [41] uses directional edge maps, [37] uses a thresholded binary image, and [15] uses Gaussian units applied to the grey level image.
Reference: [18] <author> Jeffrey M. Gilbert and Woody Yang. </author> <title> A real-time face recognition system using custom VLSI hardware. </title> <booktitle> In IEEE Workshop on Computer Architectures for Machine Perception, </booktitle> <pages> pages 58-66, </pages> <month> Decem-ber </month> <year> 1993. </year>
Reference-contexts: In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron [3], Brunelli and Poggio [7], Gilbert and Yang <ref> [18] </ref>, Burt [8], Bichsel [6]). Template images need not be taken from the original grey levels; some systems use the gradient magnitude or gradient vector field in order to get invariance to lighting. <p> On our unoptimized CM-5 implementation, it takes about 10 seconds for the template-based recognizer to run since we can distribute the data base so that each processor compares the input against one person. Specialized hardware, for example correlation chips <ref> [18] </ref>, can be used to further speed up the computation. 5 Conclusion In this paper we presented a view-based approach for recognizing faces under varying pose.
Reference: [19] <author> Peter W. Hallinan. </author> <title> Recognizing human eyes. </title> <booktitle> In SPIE Vol. 1570, Geometric Methods in Computer Vision, </booktitle> <pages> pages 214-226, </pages> <year> 1991. </year>
Reference-contexts: In one parameterized model approach, deformable template models of individual facial features are fit to the image by minimizing an energy functional (Yuille, Hallinan, and Cohen [43], Hallinan <ref> [19] </ref>, Shackleton and Welsh [35], Huang and Chen [21]). These deformable models are hand constructed from parameterized curves that outline subfeatures such as the iris or a lip.
Reference: [20] <author> Zi-Quan Hong. </author> <title> Algebraic feature extraction of image for recognition. </title> <journal> Pattern Recognition, </journal> <volume> 24(3) </volume> <pages> 211-219, </pages> <year> 1991. </year>
Reference-contexts: Besides principal components analysis, other analysis techniques have been applied to images of faces, generating a new, more compact representation than the original image space. Examples include autocorrelation (Kurita, Otsu and Sato [26]), Singular Value Decomposition (Cheng, et al.[11] and Hong <ref> [20] </ref>), and vector quantization (Ramsay, et al.[32]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen [25], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang [41], Fuchs and Haken [17], Stonham [37]).
Reference: [21] <author> Chung-Lin Huang and Chin-Wen Chen. </author> <title> Human facial feature extraction for face interpretation and recognition. </title> <journal> Pattern Recognition, </journal> <volume> 25(12) </volume> <pages> 1435-1444, </pages> <year> 1992. </year>
Reference-contexts: In one parameterized model approach, deformable template models of individual facial features are fit to the image by minimizing an energy functional (Yuille, Hallinan, and Cohen [43], Hallinan [19], Shackleton and Welsh [35], Huang and Chen <ref> [21] </ref>). These deformable models are hand constructed from parameterized curves that outline subfeatures such as the iris or a lip. An energy functional is defined that attracts portions of the model to preprocessed versions of the image peaks, valleys, edges and model fitting is performed by minimizing this functional.
Reference: [22] <author> Takeo Kanade. </author> <title> Picture processing by computer complex and recognition of human faces. </title> <type> Technical report, </type> <institution> Kyoto University, Dept. of Information Science, </institution> <year> 1973. </year>
Reference-contexts: (Azarbaye-jani, et al. [2]), symmetry (Reisfeld and Yeshurun [33]), or the "end-inhibition" features of Manjunath, Shekhar, Chellappa, and von der Malsburg [29], which are ex 1 tracted from a wavelet decomposition of the image. 1.2.2 Face recognition While the earliest work in automatic face recognition dates back two decades (Kanade <ref> [22] </ref>), the topic has seen renewed interest in the last few years. Most face recognition systems operate on intensity images of frontal or nearly frontal views of a face, and practically all of them follow the same basic recognition technique. <p> There are two main approaches to input representation, a geometrical approach that uses the spatial configuration of facial features, and a more pictorial approach that uses an image-based representation. There have been several feature geometry approaches, beginning with the seminal work of Kanade <ref> [22] </ref>, and including Kaya and Kobayashi [23], Craw and Cameron [13], Wong, Law, and Tsang [42], Brunelli and Poggio [7], and Chen and Huang [10].
Reference: [23] <author> Y. Kaya and K. Kobayashi. </author> <title> A basic study on human face recognition. </title> <editor> In Satosi Watanabe, editor, </editor> <booktitle> Frontiers of Pattern Recognition, </booktitle> <pages> pages 265-289. </pages> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1972. </year> <month> 9 </month>
Reference-contexts: There are two main approaches to input representation, a geometrical approach that uses the spatial configuration of facial features, and a more pictorial approach that uses an image-based representation. There have been several feature geometry approaches, beginning with the seminal work of Kanade [22], and including Kaya and Kobayashi <ref> [23] </ref>, Craw and Cameron [13], Wong, Law, and Tsang [42], Brunelli and Poggio [7], and Chen and Huang [10].
Reference: [24] <author> M. Kirby and L. Sirovich. </author> <title> Application of the Karhunen-Loeve procedure for the characterization of human faces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(1) </volume> <pages> 103-108, </pages> <year> 1990. </year>
Reference-contexts: An input face is then recognized by comparing it to all of the model templates, typically using correlation as an image distance metric. Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich <ref> [24] </ref>, Turk and Pentland [39], Akamatsu, et al.[1], Craw and Cameron [13], Dalla Serra and Brunelli [34]).
Reference: [25] <author> T. Kohonen. </author> <title> Self-organization and Associative Memory. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference-contexts: Examples include autocorrelation (Kurita, Otsu and Sato [26]), Singular Value Decomposition (Cheng, et al.[11] and Hong [20]), and vector quantization (Ramsay, et al.[32]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen <ref> [25] </ref>, Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang [41], Fuchs and Haken [17], Stonham [37]). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using <p> for faces (Kohonen <ref> [25] </ref>, Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang [41], Fuchs and Haken [17], Stonham [37]). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level images. [41] uses directional edge maps, [37] uses a thresholded binary image, and [15] uses Gaussian units applied to the grey level image.
Reference: [26] <author> T. Kurita, N. Otsu, and T. Sato. </author> <title> A face recognition method using higher order local autocorrelation and multivariate analysis. </title> <booktitle> In Proceedings Int. Conf. on Pattern Recognition, </booktitle> <volume> volume 2, </volume> <pages> pages 213-216, </pages> <address> The Hague, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: This forms the representation onto which all faces are projected and distance measurements are performed. Besides principal components analysis, other analysis techniques have been applied to images of faces, generating a new, more compact representation than the original image space. Examples include autocorrelation (Kurita, Otsu and Sato <ref> [26] </ref>), Singular Value Decomposition (Cheng, et al.[11] and Hong [20]), and vector quantization (Ramsay, et al.[32]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen [25], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang [41], Fuchs and Haken [17], Stonham [37]). <p> To provide shift invariance, some systems preprocess images using the Fourier transform magnitude (Akamatsu, et al.[1]) or autocorrelation (Kurita, Otsu and Sato <ref> [26] </ref>). By finding at least two facial features usually the eyes in existing systems the face can be normalized for translation, scale, and image-plane rotation. In feature geometry approaches, distances in the feature vector are normalized for scale by dividing by a given distance such as the interocular distance. <p> By tackling changes in pose and lighting with the invariant representations and normalization techniques described above, current systems treat face recognition mostly as a rigid, 2D problem. There are exceptions, however, as some systems have employed multiple views ([1], <ref> [26] </ref>) and flexible matching strategies ([28], [27]) to deal with some degree of expression and out-of-plane rotations. What distinguishes our approach from these techniques, which will be explained in section 1.3, will be a wider allowed variation in viewpoint.
Reference: [27] <author> Martin Lades, Jan C. Vorbruggen, Joachim Buh-mann, Jorg Lange, Christoph v.d. Malsburg, Rolf P. Wurtz, and Wolfgang Konen. </author> <title> Distortion invariant object recognition in the dynamic link architecture. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(3), </volume> <month> March </month> <year> 1993. </year>
Reference-contexts: By tackling changes in pose and lighting with the invariant representations and normalization techniques described above, current systems treat face recognition mostly as a rigid, 2D problem. There are exceptions, however, as some systems have employed multiple views ([1], [26]) and flexible matching strategies ([28], <ref> [27] </ref>) to deal with some degree of expression and out-of-plane rotations. What distinguishes our approach from these techniques, which will be explained in section 1.3, will be a wider allowed variation in viewpoint.
Reference: [28] <author> B.S. Manjunath, R. Chellappa, and C. von der Malsburg. </author> <title> A feature based approach to face recognition. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 373-378, </pages> <year> 1992. </year>
Reference-contexts: Hybrid representations that combine the geometrical and pictorial approaches have been explored, such as Cannon et al.[9], whose feature vector face representation includes geometrical and template-based information. In another hybrid approach, Lades et al.[27] and Manjunath, Chellappa, and von der Malsburg <ref> [28] </ref> represent faces as elastic graphs of local textural features. Invariance to imaging conditions The wide variation in face appearance under changes in pose, lighting, and expression makes face recognition a difficult task. <p> Needless to say, these recognition statistics are meaningful only if the library of model faces is sufficiently large. While there is no consensus on the sufficient size of the model database, some of the more recent approaches ([26], [6], <ref> [28] </ref>) have used libraries on the order of 70 people or more. 1.3 Our view-based recognizer As discussed in the previous section, not much work has taken face recognizers beyond the narrow imaging conditions of expressionless, frontal views of faces with controlled lighting.
Reference: [29] <author> B.S. Manjunath, Chandra Shekhar, R. Chellappa, and C. von der Malsburg. </author> <title> A robust method for detecting image features with application to face recognition and motion correspondence. </title> <booktitle> In Proceedings Int. Conf. on Pattern Recognition, </booktitle> <volume> volume 2, </volume> <pages> pages 208-212, </pages> <address> The Hague, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: Instead, the features are defined by the local grey level structure of the image, such as corners (Azarbaye-jani, et al. [2]), symmetry (Reisfeld and Yeshurun [33]), or the "end-inhibition" features of Manjunath, Shekhar, Chellappa, and von der Malsburg <ref> [29] </ref>, which are ex 1 tracted from a wavelet decomposition of the image. 1.2.2 Face recognition While the earliest work in automatic face recognition dates back two decades (Kanade [22]), the topic has seen renewed interest in the last few years.
Reference: [30] <author> T. Poggio. </author> <title> 3D object recognition and prototypes: one 2D view may be sufficient. </title> <type> Technical Report 9107-02, I.R.S.T., </type> <institution> Povo, Italy, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: The key to making this work will be an example-based learning system that uses multiple images of prototype faces undergoing changes in pose to "learn" what it means to rotate a face 8 (see Poggio <ref> [30] </ref>, Poggio and Vetter [31]). The system will apply this knowledge to synthesize new "virtual" views of the person's face. Overall, we have demonstrated in this paper that template-based face recognition systems can be extended in a straightforward way to deal with the problem of varying pose.
Reference: [31] <author> Tomaso Poggio and Thomas Vetter. </author> <title> Recognition and structure from one 2D model view: Observations on prototypes, object classes, and symmetries. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1347, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: The key to making this work will be an example-based learning system that uses multiple images of prototype faces undergoing changes in pose to "learn" what it means to rotate a face 8 (see Poggio [30], Poggio and Vetter <ref> [31] </ref>). The system will apply this knowledge to synthesize new "virtual" views of the person's face. Overall, we have demonstrated in this paper that template-based face recognition systems can be extended in a straightforward way to deal with the problem of varying pose.
Reference: [32] <author> C.S. Ramsay, K. Sutherland, D. Renshaw, and P.B. Denyer. </author> <title> A comparison of vector quantization code-book generation algorithms applied to automatic face recognition. </title> <editor> In David Hogg and Roger Boyle, editors, </editor> <booktitle> Proc. British Machine Vision Conference, </booktitle> <pages> pages 508-517. </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference: [33] <author> Daniel Reisfeld and Yehezkel Yeshurun. </author> <title> Robust detection of facial features by generalized symmetry. </title> <booktitle> In Proceedings Int. Conf. on Pattern Recognition, </booktitle> <volume> volume 1, </volume> <pages> pages 117-120, </pages> <address> The Hague, The Nether-lands, </address> <year> 1992. </year>
Reference-contexts: Instead, the features are defined by the local grey level structure of the image, such as corners (Azarbaye-jani, et al. [2]), symmetry (Reisfeld and Yeshurun <ref> [33] </ref>), or the "end-inhibition" features of Manjunath, Shekhar, Chellappa, and von der Malsburg [29], which are ex 1 tracted from a wavelet decomposition of the image. 1.2.2 Face recognition While the earliest work in automatic face recognition dates back two decades (Kanade [22]), the topic has seen renewed interest in the
Reference: [34] <author> M. Dalla Serra and R. Brunelli. </author> <title> On the use of the Karhunen-Loeve expansion for face recognition. </title> <type> Technical Report 9206-04, I.R.S.T., </type> <year> 1992. </year>
Reference-contexts: Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich [24], Turk and Pentland [39], Akamatsu, et al.[1], Craw and Cameron [13], Dalla Serra and Brunelli <ref> [34] </ref>). It can be read as an suboptimal pictorial approach, reducing the dimensionality of the input space from the number of pixels in the templates to the number of eigenpictures, or "eigenfaces", used in the representation.
Reference: [35] <author> M.A. Shackleton and W.J. Welsh. </author> <title> Classification of facial features for recognition. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 573-579, </pages> <address> Lahaina, Maui, Hawaii, </address> <year> 1991. </year>
Reference-contexts: In one parameterized model approach, deformable template models of individual facial features are fit to the image by minimizing an energy functional (Yuille, Hallinan, and Cohen [43], Hallinan [19], Shackleton and Welsh <ref> [35] </ref>, Huang and Chen [21]). These deformable models are hand constructed from parameterized curves that outline subfeatures such as the iris or a lip.
Reference: [36] <author> A. Shashua. </author> <title> Correspondence and affine shape from two orthographic views: Motion and Recognition. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1327, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <month> De-cember </month> <year> 1991. </year>
Reference-contexts: Given this dense set of correspondences, the affine transformed input can be brought into pixel-level correspondence with the model by applying a 2D warp operation driven by the optical flow (also see Shashua <ref> [36] </ref>). Basically, pixels in the affine transformed input are "pushed" along the flow vectors to their corresponding pixels in the model. In figure 9, we first compute optical flow between the affine transformed input (left, from figure 8) and the model image (middle, from figure 6).
Reference: [37] <author> T.J. Stonham. </author> <title> Practical face recognition and verification with WISARD. </title> <editor> In M. Jeeves, F. Newcombe, and A. Young, editors, </editor> <booktitle> Aspects of Face Processing, </booktitle> <pages> pages 426-441. </pages> <publisher> Martinus Nijhoff Publishers, </publisher> <address> Dor-drecht, </address> <year> 1986. </year>
Reference-contexts: and Sato [26]), Singular Value Decomposition (Cheng, et al.[11] and Hong [20]), and vector quantization (Ramsay, et al.[32]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen [25], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang [41], Fuchs and Haken [17], Stonham <ref> [37] </ref>). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level images. [41] uses directional edge maps, [37] uses a thresholded binary image, and [15] uses Gaussian <p> Ahuja, and Huang [41], Fuchs and Haken [17], Stonham <ref> [37] </ref>). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level images. [41] uses directional edge maps, [37] uses a thresholded binary image, and [15] uses Gaussian units applied to the grey level image. Hybrid representations that combine the geometrical and pictorial approaches have been explored, such as Cannon et al.[9], whose feature vector face representation includes geometrical and template-based information.
Reference: [38] <author> Demetri Terzopoulos and Keith Waters. </author> <title> Analysis of facial images using physical and anatomical models. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 727-732, </pages> <address> Osaka, Japan, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: A related model-based approach fits a global head model constructed from tens of feature locations (Bennett and Craw [4], Craw, Tock, and Bennett [14], Cootes, et al.[12]) to the image by varying individual feature locations. Terzopoulos and Waters <ref> [38] </ref> have used the active contour model of snakes to track facial features in image sequences. In the pictorial approach, a pixel-based representation of facial features is matched against the image.
Reference: [39] <author> Matthew Turk and Alex Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1) </volume> <pages> 71-86, </pages> <year> 1991. </year>
Reference-contexts: An input face is then recognized by comparing it to all of the model templates, typically using correlation as an image distance metric. Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich [24], Turk and Pentland <ref> [39] </ref>, Akamatsu, et al.[1], Craw and Cameron [13], Dalla Serra and Brunelli [34]). It can be read as an suboptimal pictorial approach, reducing the dimensionality of the input space from the number of pixels in the templates to the number of eigenpictures, or "eigenfaces", used in the representation. <p> Brunelli and Poggio's system [7] achieved a recognition rate of 100% on frontal views of 47 people. Cannon, et al.[9] report a 96% recognition rate on a library of 50, and Turk and Pentland <ref> [39] </ref> report a 96% recognition rate when their system, which uses a library of only 16 people, is tested under varying lighting conditions. Needless to say, these recognition statistics are meaningful only if the library of model faces is sufficiently large. <p> Using fewer exemplars decreases the running time but also reduces system flexibility and recognition performance. 4 Face recognition using multiple views As mentioned in the introduction, template-based face recognizers have been quite successful on frontal views of the face (Baron [3], Turk and Pentland <ref> [39] </ref>, Brunelli and Poggio [7]). Our goal is to extend template-based systems to handle varying pose, notably facial rotations in depth. Our approach is view-based, representing faces with templates from many images that cover the viewing sphere.
Reference: [40] <author> J.M. Vincent, J.B. Waite, and D.J. Myers. </author> <title> Location of feature points in images using neural networks. </title> <journal> BT Technology Journal, </journal> <volume> 10(3) </volume> <pages> 7-15, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In the pictorial approach, a pixel-based representation of facial features is matched against the image. This representation may be templates of the major facial features (Bichsel [6], Baron [3], Burt [8], Poggio and Brunelli [7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers <ref> [40] </ref>). For the template-based systems, correlation on preprocessed versions of the image is the typical matching metric. The neural network approaches construct a network where implicit feature templates are "learned" from positive and negative examples.
Reference: [41] <author> John J. Weng, N. Ahuja, and T.S. Huang. </author> <title> Learning recognition and segmentation of 3-D objects from 2-D images. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 121-128, </pages> <address> Berlin, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Examples include autocorrelation (Kurita, Otsu and Sato [26]), Singular Value Decomposition (Cheng, et al.[11] and Hong [20]), and vector quantization (Ramsay, et al.[32]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen [25], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang <ref> [41] </ref>, Fuchs and Haken [17], Stonham [37]). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level images. [41] uses directional edge maps, [37] uses a thresholded <p> Reisfeld, and Yeshurun [15], Weng, Ahuja, and Huang <ref> [41] </ref>, Fuchs and Haken [17], Stonham [37]). Since the networks used in connectionist approaches are just classifiers, these approaches are similar to the ones described above. Different pixel-based representations have been used, with [25], [16], [17] using the original grey level images. [41] uses directional edge maps, [37] uses a thresholded binary image, and [15] uses Gaussian units applied to the grey level image. Hybrid representations that combine the geometrical and pictorial approaches have been explored, such as Cannon et al.[9], whose feature vector face representation includes geometrical and template-based information.
Reference: [42] <author> K.H. Wong, Hudson H.M. Law, and P.W.M. Tsang. </author> <title> A system for recognizing human faces. </title> <booktitle> In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 1638-1642, </pages> <year> 1989. </year>
Reference-contexts: There have been several feature geometry approaches, beginning with the seminal work of Kanade [22], and including Kaya and Kobayashi [23], Craw and Cameron [13], Wong, Law, and Tsang <ref> [42] </ref>, Brunelli and Poggio [7], and Chen and Huang [10]. These feature-based systems begin by locating a set of facial features, including such features as the corners of the eyes and mouth, sides of the face and nose, nostrils, the contour along the chin, etc.

References-found: 42

