URL: http://ftp.cs.indiana.edu/pub/liu/Psr-IFIP97.ps.Z
Refering-URL: http://www.cs.indiana.edu/hyplan/liu.html
Root-URL: http://www.cs.indiana.edu
Email: Email: liu@cs.indiana.edu,  
Phone: Tel: (812)855-4373, Fax: (812)855-4829  
Title: Principled strength reduction  
Author: Yanhong A. Liu 
Address: 201E Lindley Hall, Bloomington, IN 47405, U.S.A.  
Affiliation: Computer Science Department, Indiana University  
Abstract: This paper presents a principled approach for optimizing iterative (or recursive) programs. The approach formulates a loop body as a function f and a change operation , incrementalizes f with respect to , and adopts an incrementalized loop body to form a new loop that is more efficient. Three general optimizations are performed as part of the adoption; they systematically handle initializations, termination conditions, and final return values on exits of loops. These optimizations are either omitted, or done in implicit, limited, or ad hoc ways in previous methods. The new approach generalizes classical loop optimization techniques, notably strength reduction, in optimizing compilers, and it unifies and systematizes various optimization strategies in transformational programming. Such principled strength reduction performs drastic program efficiency improvement via incrementalization and appreciably reduces code size via associated optimizations. We give examples where this approach can systematically produce strength-reduced programs while no previous method can. Keywords program optimization, incrementalization, strength reduction, caching intermediate results, maintaining auxiliary information, initialization, termination condition, loop optimization, iteration, recursion 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aho, A. V., Sethi, R. & Ullman, J. D. </author> <year> (1986). </year> <title> Compilers, Principles, Techniques, and Tools, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts. </address>
Reference: <author> Allen, F. E. </author> <year> (1969). </year> <title> Program optimization, </title> <booktitle> Annual Review of Automatic Programming, </booktitle> <volume> Vol. 5, </volume> <publisher> Pergamon Press, </publisher> <address> New York, </address> <pages> pp. 239-307. </pages>
Reference: <author> Allen, F. E., Cocke, J. & Kennedy, K. </author> <year> (1981). </year> <title> Reduction of operator strength, </title> <editor> in S. S. Muchnick & N. D. Jones (eds), </editor> <title> Program Flow Analysis, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <note> chapter 3, pp. 79-101. Related work and conclusion 23 Banerjee, </note> <author> U. </author> <year> (1990). </year> <title> Unimodular transformations of double loops, </title> <booktitle> Proceedings of the Workshop on Advances in Languages and Compilers for Parallel Processing, </booktitle> <pages> pp. 192-219. </pages>
Reference-contexts: 1 = ~g 0 (i; cdr (l); 2nd ( ~r 1 )) in if arc (i; car (l)) then &lt; max (1st (v 1 ); 1+1st ( ~r 1 )); ~r 1 &gt; else &lt; 1st (v 1 ); ~r 1 &gt; (33) 7 RELATED WORK AND CONCLUSION Strength reduction <ref> (Allen et al. 1981, Cocke & Kennedy 1977) </ref> is a classical compiler optimization technique that can be traced back to recursive address calculation for early ALGOL 60 compilers (Grau et al. 1967, Gries 1971). <p> Our method is general; it exploits program semantics to reduce computation strength, utilizes program analyses to guarantee correctness and efficiency, and is not limited to particular term structures. In fact, we can reduce the computation strength for a loop body as a whole. In particular, eliminating induction variables <ref> (Allen et al. 1981) </ref> is a special case of one of our optimizations. Optimal code motion (Steffen, Knoop & Ruthing 1990) is a principled method for optimal placement of computations within a program with respect to the Herbrand interpretation.
Reference: <author> Bauer, F. L., Moller, B., Partsch, H. & Pepper, P. </author> <year> (1989). </year> <title> Formal program construction by transformations|Computer-aided, </title> <journal> intuition-guided programming, IEEE Transactions on Software Engineering 15(2): </journal> <pages> 165-180. </pages>
Reference-contexts: As discussed in a previous paper (Liu et al. 1996), its underlying principle is essentially incrementalization. But their work stresses mental tools for programming, rather than mechanical assistance, so no systematic procedures were proposed for automatic or semi-automatic uses. Transforming recursive functions in CIP <ref> (Bauer, Moller, Partsch & Pepper 1989, Broy 1984, Partsch 1990) </ref> uses a collection of optimization strategies, including memoization, tabulation, relocation, precomputation, differencing, etc.
Reference: <author> Bird, R. S. </author> <year> (1984). </year> <title> The promotion and accumulation strategies in transformational programming, </title> <journal> ACM Transactions on Programming Languages and Systems 6(4): </journal> <pages> 487-504. </pages>
Reference-contexts: case, we obtain a simpler program: f fib (x) = if x 1 then &lt; 1; 1 &gt; else let ~r = f fib (x 1) in &lt; 1st (~r)+2nd (~r); 1st (~r) &gt; Bird's path sequence problem generalizes Dijkstra's longest up sequence problem and the longest common subsequence problem <ref> (Bird 1984) </ref>. Given a directed acyclic graph, as a predicate arc, and a string l whose elements are vertices in the graph, the function llp below computes the length of the longest subsequence in l that forms a path in the graph (Bird 1984): llp (l) = if null (l) then <p> sequence problem and the longest common subsequence problem <ref> (Bird 1984) </ref>. Given a directed acyclic graph, as a predicate arc, and a string l whose elements are vertices in the graph, the function llp below computes the length of the longest subsequence in l that forms a path in the graph (Bird 1984): llp (l) = if null (l) then 0 else max (llp (cdr (l)); 1+g (car (l); cdr (l))) g (n; l) = if null (l) then 0 else if arc (n; car (l)) then max (g (n; cdr (l)); 1+g (car (l); cdr (l))) else g (n; cdr (l)) <p> (n; l) = if null (l) then 0 else if arc (n; car (l)) then max (g (n; cdr (l)); 1+g (car (l); cdr (l))) else g (n; cdr (l)) (31) This program is improved from exponential time to square time in (Liu et al. 1996) (and also incorrectly in <ref> (Bird 1984) </ref>, but corrected in (Bird 1985)), and the resulting program is llp (l) = 1st ( f llp (l)), where f llp is e llp (l) = if null (l) then &lt; 0 &gt; else if null (cdr (l)) then &lt;1; &lt;0 &gt;&gt; else let ~r = e llp (cdr <p> Other work on transformational programming for improving program efficiency, including the extension technique (Dershowitz 1983), the promotion and accumulation strategies <ref> (Bird 1984, Bird 1985) </ref>, and finite differencing of functional programs in KIDS (Smith 1990), can also be further automated with principled strength reduction. Principled strength reduction improves over previous approaches for program efficiency improvement. It systematically handles program constructs and operations that were not handled systematically before.
Reference: <author> Bird, R. S. </author> <year> (1985). </year> <title> Addendum: The promotion and accumulation strategies in transformational programming, </title> <journal> ACM Transactions on Programming Languages and Systems 7(3): </journal> <pages> 490-492. </pages>
Reference-contexts: (l) then 0 else if arc (n; car (l)) then max (g (n; cdr (l)); 1+g (car (l); cdr (l))) else g (n; cdr (l)) (31) This program is improved from exponential time to square time in (Liu et al. 1996) (and also incorrectly in (Bird 1984), but corrected in <ref> (Bird 1985) </ref>), and the resulting program is llp (l) = 1st ( f llp (l)), where f llp is e llp (l) = if null (l) then &lt; 0 &gt; else if null (cdr (l)) then &lt;1; &lt;0 &gt;&gt; else let ~r = e llp (cdr (l)) in let v 2
Reference: <author> Broy, M. </author> <year> (1984). </year> <title> Algebraic methods for program construction: The project CIP, </title> <editor> in P. Pepper (ed.), </editor> <title> Program Transformation and Programming Environments, </title> <publisher> Springer-Verlag, Berlin, </publisher> <pages> pp. 199-222. </pages>
Reference: <author> Cai, J. & Paige, R. (1988/89). </author> <title> Program derivation by fixed point computation, </title> <booktitle> Science of Computer Programming 11: </booktitle> <pages> 197-261. </pages>
Reference: <author> Cocke, J. & Kennedy, K. </author> <year> (1977). </year> <title> An algorithm for reduction of operator strength, </title> <booktitle> Communications of the ACM 20(11): </booktitle> <pages> 850-856. </pages>
Reference: <author> Cocke, J. & Schwartz, J. T. </author> <year> (1970). </year> <title> Programming Languages and Their Compilers; Preliminary Notes, </title> <type> Technical report, </type> <institution> Courant Institute of Mathematical Sciences, New York University. </institution>
Reference: <author> Constable, R. L. et al. </author> <year> (1986). </year> <title> Implementing Mathematics with the Nuprl Proof Development System, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey. </address>
Reference-contexts: The strength-reduced program was manually discovered and proved correct using Nuprl <ref> (Constable et al. 1986) </ref>. As discussed above, the optimizations used in (O'Leary et al. 1994) either incurred extra levels of proofs or were not handled formally. Another drawback is that there was no formal treatment of cost.
Reference: <author> Dershowitz, N. </author> <year> (1983). </year> <title> The Evolution of Programs, </title> <booktitle> Vol. 5 of Progress in Computer Science, </booktitle> <publisher> Birkhauser, </publisher> <address> Boston. </address>
Reference-contexts: We have showed through the presentation how our method is used to systematically derive a strength-reduced program, which automates and simplifies the VLSI circuit design process. Many similar programs, such as various versions of real/integer division/square-root algorithms <ref> (Dershowitz 1983) </ref>, can also be derived using our method. 6.2 Minimum-sum section problem This example is taken from (Gries 1984). Given an array a [1::n] of numbers, where n 1. A minimum-sum section of a is a non-empty sequence of adjacent elements whose sum is a minimum. <p> Other work on transformational programming for improving program efficiency, including the extension technique <ref> (Dershowitz 1983) </ref>, the promotion and accumulation strategies (Bird 1984, Bird 1985), and finite differencing of functional programs in KIDS (Smith 1990), can also be further automated with principled strength reduction. Principled strength reduction improves over previous approaches for program efficiency improvement.
Reference: <author> Dijkstra, E. W. </author> <year> (1976). </year> <title> A Discipline of Programming, </title> <booktitle> Prentice-Hall Series in Automatic Computation, </booktitle> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey. </address>
Reference-contexts: In general, they apply only to programs written in very-high-level languages like SETL; our method applies also to lower-level languages. Maintaining and strengthening loop invariants has been advocated by Dijkstra, Gries, and others <ref> (Dijkstra 1976, Gries 1981, Gries 1984, Reynolds 1981) </ref> for almost two decades as a standard strategy for developing loops. As discussed in a previous paper (Liu et al. 1996), its underlying principle is essentially incrementalization.
Reference: <author> Flores, I. </author> <year> (1963). </year> <title> The Logic of Computer Arithmetic, </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, New Jersey. </address>
Reference: <author> Fong, A. C. </author> <year> (1977). </year> <title> Generalized common subexpressions in very high level languages, </title> <booktitle> Conference Record of the 4th Annual ACM Symposium on POPL, </booktitle> <address> Los Angeles, California, </address> <pages> pp. 48-57. </pages>
Reference-contexts: In fact, their method would not perform any strength reduction on the square root example (Knoop 1994). Of course, the complexity of our algorithm is larger. We plan to further study the complexity issues. Inductively computable constructs in very-high-level languages <ref> (Fong 1977, Fong 1979, Fong & Ullman 1976) </ref> generalize conventional strength reduction and the elimination of induction variables to set-based languages.
Reference: <author> Fong, A. C. </author> <year> (1979). </year> <title> Inductively computable constructs in very high level languages, </title> <booktitle> Conference Record of the 6th Annual ACM Symposium on POPL, </booktitle> <address> San Antonio, Texas, </address> <pages> pp. 21-28. </pages>
Reference: <author> Fong, A. C. & Ullman, J. D. </author> <year> (1976). </year> <title> Inductive variables in very high level languages, </title> <booktitle> Conference Record of the 3rd Annual ACM Symposium on POPL, Atlanta, Georgia, </booktitle> <pages> pp. 104-112. </pages>
Reference: <author> Garey, M. R. & Johnson, D. S. </author> <year> (1979). </year> <title> Computers and Intractability: A Guid to the Theory of NP-Completeness, </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York. </address> <note> 24 Principled strength reduction Grau, </note> <author> A. A., Hill, U. & Langmaac, H. </author> <year> (1967). </year> <title> Translation of ALGOL 60, Vol. 1 of Handbook for automatic computation, </title> <publisher> Springer, </publisher> <address> Berlin. </address>
Reference-contexts: Yet, the number of additional copy statements and the number of additional temporary variables can sometimes be reduced substantially by carefully ordering the assignment statements. The problem of minimizing the number S of additional copy statements is NP-complete <ref> (Garey & Johnson 1979, Sethi 1973) </ref>, but good heuristics exist (Sethi 1973). We can use an algorithm that easily decides an appropriate order of assignments when no additional temporary variables or copy statements are needed and reduces the problem to the problem of minimizing S otherwise.
Reference: <author> Greibach, S. A. </author> <year> (1975). </year> <title> Theory of Program Structures: Schemes, Semantics, Verification, </title> <booktitle> Vol. 36 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: If the recursion is not linear, then there is no direct correspondence of it to an iteration. In fact, it is known that the while scheme is equivalent to flow chart, which is strictly less expressive than the recursive scheme <ref> (Greibach 1975) </ref>. Simple heuristics exist for recognizing how recursions proceed on the argument, e.g., for an integer argument, a change operation may be x 0 = x+1; for a list argument, a change operation may be x 0 = cons (y; x). Section 6 gives examples with non-linear recursions.
Reference: <author> Gries, D. </author> <year> (1971). </year> <title> Compiler Construction for Digital Computers, </title> <publisher> John Wiley & Sons, </publisher> <address> New York. </address>
Reference: <author> Gries, D. </author> <year> (1981). </year> <booktitle> The Science of Programming, </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: <author> Gries, D. </author> <year> (1984). </year> <title> A note on a standard strategy for developing loop invariants and loops, </title> <booktitle> Science of Computer Programming 2: </booktitle> <pages> 207-214. </pages>
Reference-contexts: Many similar programs, such as various versions of real/integer division/square-root algorithms (Dershowitz 1983), can also be derived using our method. 6.2 Minimum-sum section problem This example is taken from <ref> (Gries 1984) </ref>. Given an array a [1::n] of numbers, where n 1. A minimum-sum section of a is a non-empty sequence of adjacent elements whose sum is a minimum. A naive algorithm takes O (n 3 ) time to compute such a minimum.
Reference: <author> Joshi, S. M. & Dhamdhere, D. M. </author> <year> (1982a). </year> <title> A composite hoisting-strength reuction transformation for global program optimization|part I, </title> <journal> International Journal of Computer Mathematics 11: </journal> <pages> 21-41. </pages>
Reference-contexts: As discussed in (Steffen et al. 1991), it is syntactic (ignoring semantic equivalences between syntactically different terms), locally updating (thus not guaranteeing safety or speedup), and structurally restricted (only working on induction variables and region constants). Composite hoisting-strength reduction <ref> (Joshi & Dhamdhere 1982a, Joshi & Dhamdhere 1982b) </ref> is also syntactic and locally updating. Although it can handle more program terms, these terms are still of limited structures.
Reference: <author> Joshi, S. M. & Dhamdhere, D. M. </author> <year> (1982b). </year> <title> A composite hoisting-strength reuction transformation for global program optimization|part II, </title> <journal> International Journal of Computer Mathematics 11: </journal> <pages> 111-126. </pages>
Reference: <author> Knoop, J. </author> <year> (1994). </year> <note> Private comminication. </note>
Reference-contexts: Our method is also a principled approach, based on the idea of incrementalization. It exploits properties of more primitive operators, data structures, and conditionals, and thus is a more comprehensive exploration of availability. In fact, their method would not perform any strength reduction on the square root example <ref> (Knoop 1994) </ref>. Of course, the complexity of our algorithm is larger. We plan to further study the complexity issues. Inductively computable constructs in very-high-level languages (Fong 1977, Fong 1979, Fong & Ullman 1976) generalize conventional strength reduction and the elimination of induction variables to set-based languages.
Reference: <author> Liu, Y. A. </author> <year> (1995). </year> <title> CACHET: An interactive, incremental-attribution-based program transformation system for deriving incremental programs, </title> <booktitle> Proceedings of the 10th Knowledge-Based Software Engineering Conference, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <address> Boston, Massachusetts, </address> <pages> pp. 19-26. </pages>
Reference-contexts: Third, used off-line on paper, it supports a general methodology for systematic program efficiency improvement, which is one of the most important issues in program development and maintenance. A prototype implementation for semiautomatic use is under development <ref> (Liu 1995) </ref>.
Reference: <author> Liu, Y. A. </author> <year> (1996). </year> <title> Incremental Computation: A Semantics-Based Systematic Transformational Approach, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, New York. </address>
Reference-contexts: We have previously proposed a general systematic approach to incremen-talization <ref> (Liu 1996, Liu, Stoller & Teitelbaum 1996) </ref>. <p> change operation , the approach aims to obtain an incremental program that computes f (x y) efficiently by making use of f (x) (Liu & Teitelbaum 1995b), the intermediate results computed in computing f (x) (Liu & Teitelbaum 1995a), and auxiliary information about f (x) that can be inexpensively maintained <ref> (Liu et al. 1996) </ref>. Since every non-trivial computation proceeds by iteration (or recursion), the approach can be used for achieving efficient computation by computing each iteration using an appropriate incremental program. <p> Section 4 describes optimizations in adopting incremental programs to form more efficient iterations. Section 5 discusses extensions and applications of the approach. Section 6 gives examples. Finally, Section 7 discusses related work and concludes. 2 PRELIMINARIES Our incrementalization method <ref> (Liu 1996, Liu et al. 1996) </ref> has been described using a first-order, call-by-value functional programming language. <p> Of course, maintaining additional information takes extra space. Our primary goal is to improve the asymptotic running time of the incremental computation. We attempt to save space by maintaining only information useful for achieving this. Given a program f and an operation , we can use the approach in <ref> (Liu 1996, Liu et al. 1996) </ref> to derive (i) a program ~ f (x) that extends f (x) to return also useful additional information about x, (ii) a program ~ f 0 (x; y; ~r) that incrementally computes ~ f (x y) when ~r = ~ f (x), and (iii) a <p> using the approach in (Liu 1996, Liu et al. 1996, Liu & Teitelbaum 1995a, Liu & Teitelbaum 1995b), we can derive an incremental program that computes f (x y) incrementally by using the return value (Liu & Teitelbaum 1995b), the intermediate results (Liu & Teitelbaum 1995a), and certain auxiliary information <ref> (Liu et al. 1996) </ref> of f (x), i.e., we obtain a program ~ f that computes f (x) and necessary additional information, a program ~ f 0 that incrementally computes f (x y) and maintains the additional information, and a constant-time projection function that projects the value of f out of <p> Thus, we consider only the function update in component 2. Incrementalizing update under , as done in <ref> (Liu et al. 1996) </ref>, we obtain the functions g update and g update 0 , explained below, and the projection function = 1st. g update (n; m; i) = let p = n m 2 in if p &gt; 0 then let u = 2 i in &lt; m + u; <p> but it is not used separately, and thus is not maintained. fl Such additional values are returned only in branches where they are computed; in other branches, they could be denoted using a placeholder , which can be safely eliminated when they are at the rightmost positions of a tuple <ref> (Liu et al. 1996, Liu & Teitelbaum 1995a) </ref>. A principled approach 9 Function g update 0 ( ~r 1 ) uses the extended return value of g update (n; m; i) to compute g update (hn; m; ii hi). <p> As discussed above, the optimizations used in (O'Leary et al. 1994) either incurred extra levels of proofs or were not handled formally. Another drawback is that there was no formal treatment of cost. As mentioned in <ref> (Liu et al. 1996) </ref>, the final program in (O'Leary et al. 1994) contains an unnecessary shift. We have showed through the presentation how our method is used to systematically derive a strength-reduced program, which automates and simplifies the VLSI circuit design process. <p> (cdr (l)); 1+g (car (l); cdr (l))) g (n; l) = if null (l) then 0 else if arc (n; car (l)) then max (g (n; cdr (l)); 1+g (car (l); cdr (l))) else g (n; cdr (l)) (31) This program is improved from exponential time to square time in <ref> (Liu et al. 1996) </ref> (and also incorrectly in (Bird 1984), but corrected in (Bird 1985)), and the resulting program is llp (l) = 1st ( f llp (l)), where f llp is e llp (l) = if null (l) then &lt; 0 &gt; else if null (cdr (l)) then &lt;1; &lt;0 <p> Maintaining and strengthening loop invariants has been advocated by Dijkstra, Gries, and others (Dijkstra 1976, Gries 1981, Gries 1984, Reynolds 1981) for almost two decades as a standard strategy for developing loops. As discussed in a previous paper <ref> (Liu et al. 1996) </ref>, its underlying principle is essentially incrementalization. But their work stresses mental tools for programming, rather than mechanical assistance, so no systematic procedures were proposed for automatic or semi-automatic uses.
Reference: <author> Liu, Y. A. & Stoller, S. D. </author> <year> (1997). </year> <title> Loop optimization for aggregate array computations, </title> <type> Technical Report TR 477, </type> <institution> Computer Science Department, Indiana University, Bloomington, Indiana. </institution>
Reference-contexts: In particular, we show that different ways of writing the original programs result in different optimized programs. We also show that the general principles underlying our approach apply to programs that use arrays, though detailed analyses and transformations for arrays are worked out elsewhere <ref> (Liu & Stoller 1997) </ref>. 6.1 Non-restoring binary integer square root The running example is taken from VLSI circuit design (O'Leary et al. 1994), which transforms the original specification into a strength reduced version and further into a hardware implementation. <p> We have studied automatic techniques for incrementalizing array computations <ref> (Liu & Stoller 1997) </ref>, and they can be applied in obtaining the program on the right of (27) from that on the left and obtaining the program in the middle of (28) from that on the left.
Reference: <author> Liu, Y. A., Stoller, S. D. & Teitelbaum, T. </author> <year> (1996). </year> <title> Discovering auxiliary information for incremental computation, </title> <booktitle> Conference Record of the 23rd Annual ACM Symposium on POPL, </booktitle> <address> St. Petersburg Beach, Florida, </address> <pages> pp. 157-170. </pages>
Reference-contexts: We have previously proposed a general systematic approach to incremen-talization <ref> (Liu 1996, Liu, Stoller & Teitelbaum 1996) </ref>. <p> change operation , the approach aims to obtain an incremental program that computes f (x y) efficiently by making use of f (x) (Liu & Teitelbaum 1995b), the intermediate results computed in computing f (x) (Liu & Teitelbaum 1995a), and auxiliary information about f (x) that can be inexpensively maintained <ref> (Liu et al. 1996) </ref>. Since every non-trivial computation proceeds by iteration (or recursion), the approach can be used for achieving efficient computation by computing each iteration using an appropriate incremental program. <p> Section 4 describes optimizations in adopting incremental programs to form more efficient iterations. Section 5 discusses extensions and applications of the approach. Section 6 gives examples. Finally, Section 7 discusses related work and concludes. 2 PRELIMINARIES Our incrementalization method <ref> (Liu 1996, Liu et al. 1996) </ref> has been described using a first-order, call-by-value functional programming language. <p> Of course, maintaining additional information takes extra space. Our primary goal is to improve the asymptotic running time of the incremental computation. We attempt to save space by maintaining only information useful for achieving this. Given a program f and an operation , we can use the approach in <ref> (Liu 1996, Liu et al. 1996) </ref> to derive (i) a program ~ f (x) that extends f (x) to return also useful additional information about x, (ii) a program ~ f 0 (x; y; ~r) that incrementally computes ~ f (x y) when ~r = ~ f (x), and (iii) a <p> using the approach in (Liu 1996, Liu et al. 1996, Liu & Teitelbaum 1995a, Liu & Teitelbaum 1995b), we can derive an incremental program that computes f (x y) incrementally by using the return value (Liu & Teitelbaum 1995b), the intermediate results (Liu & Teitelbaum 1995a), and certain auxiliary information <ref> (Liu et al. 1996) </ref> of f (x), i.e., we obtain a program ~ f that computes f (x) and necessary additional information, a program ~ f 0 that incrementally computes f (x y) and maintains the additional information, and a constant-time projection function that projects the value of f out of <p> Thus, we consider only the function update in component 2. Incrementalizing update under , as done in <ref> (Liu et al. 1996) </ref>, we obtain the functions g update and g update 0 , explained below, and the projection function = 1st. g update (n; m; i) = let p = n m 2 in if p &gt; 0 then let u = 2 i in &lt; m + u; <p> but it is not used separately, and thus is not maintained. fl Such additional values are returned only in branches where they are computed; in other branches, they could be denoted using a placeholder , which can be safely eliminated when they are at the rightmost positions of a tuple <ref> (Liu et al. 1996, Liu & Teitelbaum 1995a) </ref>. A principled approach 9 Function g update 0 ( ~r 1 ) uses the extended return value of g update (n; m; i) to compute g update (hn; m; ii hi). <p> As discussed above, the optimizations used in (O'Leary et al. 1994) either incurred extra levels of proofs or were not handled formally. Another drawback is that there was no formal treatment of cost. As mentioned in <ref> (Liu et al. 1996) </ref>, the final program in (O'Leary et al. 1994) contains an unnecessary shift. We have showed through the presentation how our method is used to systematically derive a strength-reduced program, which automates and simplifies the VLSI circuit design process. <p> (cdr (l)); 1+g (car (l); cdr (l))) g (n; l) = if null (l) then 0 else if arc (n; car (l)) then max (g (n; cdr (l)); 1+g (car (l); cdr (l))) else g (n; cdr (l)) (31) This program is improved from exponential time to square time in <ref> (Liu et al. 1996) </ref> (and also incorrectly in (Bird 1984), but corrected in (Bird 1985)), and the resulting program is llp (l) = 1st ( f llp (l)), where f llp is e llp (l) = if null (l) then &lt; 0 &gt; else if null (cdr (l)) then &lt;1; &lt;0 <p> Maintaining and strengthening loop invariants has been advocated by Dijkstra, Gries, and others (Dijkstra 1976, Gries 1981, Gries 1984, Reynolds 1981) for almost two decades as a standard strategy for developing loops. As discussed in a previous paper <ref> (Liu et al. 1996) </ref>, its underlying principle is essentially incrementalization. But their work stresses mental tools for programming, rather than mechanical assistance, so no systematic procedures were proposed for automatic or semi-automatic uses.
Reference: <author> Liu, Y. A. & Teitelbaum, T. </author> <year> (1995a). </year> <title> Caching intermediate results for program improvement, </title> <booktitle> Proceedings of the ACM SIGPLAN Symposium on PEPM, </booktitle> <address> La Jolla, California, </address> <pages> pp. 190-201. </pages>
Reference-contexts: Given a program f and an input change operation , the approach aims to obtain an incremental program that computes f (x y) efficiently by making use of f (x) (Liu & Teitelbaum 1995b), the intermediate results computed in computing f (x) <ref> (Liu & Teitelbaum 1995a) </ref>, and auxiliary information about f (x) that can be inexpensively maintained (Liu et al. 1996). Since every non-trivial computation proceeds by iteration (or recursion), the approach can be used for achieving efficient computation by computing each iteration using an appropriate incremental program. <p> program f and an input change operation , using the approach in (Liu 1996, Liu et al. 1996, Liu & Teitelbaum 1995a, Liu & Teitelbaum 1995b), we can derive an incremental program that computes f (x y) incrementally by using the return value (Liu & Teitelbaum 1995b), the intermediate results <ref> (Liu & Teitelbaum 1995a) </ref>, and certain auxiliary information (Liu et al. 1996) of f (x), i.e., we obtain a program ~ f that computes f (x) and necessary additional information, a program ~ f 0 that incrementally computes f (x y) and maintains the additional information, and a constant-time projection function <p> In other words, such folding can be done if the final return value can be computed using one more iteration based on the maintained additional information. The backward dependence analysis needed for this optimization can use the one developed in <ref> (Liu & Teitelbaum 1995a) </ref>. Example For the running example, the value that is needed on exit of the loop, i.e., the value of m, is the first component computed by g update 1 . Analyze (21). <p> The latter is a problem that needs further study. 20 Principled strength reduction 6.3 Fibonacci function and path sequence problem The Fibonacci function f ib is improved from an exponential time program to a linear time program f ib (x) = 1st ( f f ib (x)) in <ref> (Liu & Teitelbaum 1995a) </ref>, by considering f ib as a function f , x 0 = x + 1 as an operation , and using the derived constant time function f 0 to form a new recursion: fib (x) = if x 1 then 1 else fib (x 1) + fib
Reference: <author> Liu, Y. A. & Teitelbaum, T. </author> <year> (1995b). </year> <title> Systematic derivation of incremental programs, </title> <booktitle> Science of Computer Programming 24(1): </booktitle> <pages> 1-39. </pages>
Reference-contexts: We have previously proposed a general systematic approach to incremen-talization (Liu 1996, Liu, Stoller & Teitelbaum 1996). Given a program f and an input change operation , the approach aims to obtain an incremental program that computes f (x y) efficiently by making use of f (x) <ref> (Liu & Teitelbaum 1995b) </ref>, the intermediate results computed in computing f (x) (Liu & Teitelbaum 1995a), and auxiliary information about f (x) that can be inexpensively maintained (Liu et al. 1996). <p> Note that some of the parameters of f 0 may be dead and eliminated <ref> (Liu & Teitelbaum 1995b) </ref>. A principled approach 5 cmp (x) = 1st (gcmp (x)): For x of length n, gcmp (x) takes time O (n); cmp (x) takes time O (n). If gcmp (x) = ~r; then gcmp 0 (y; ~r) = gcmp (cons (y; x)). <p> 3.2 Step 2: Incrementalization Given a functional program f and an input change operation , using the approach in (Liu 1996, Liu et al. 1996, Liu & Teitelbaum 1995a, Liu & Teitelbaum 1995b), we can derive an incremental program that computes f (x y) incrementally by using the return value <ref> (Liu & Teitelbaum 1995b) </ref>, the intermediate results (Liu & Teitelbaum 1995a), and certain auxiliary information (Liu et al. 1996) of f (x), i.e., we obtain a program ~ f that computes f (x) and necessary additional information, a program ~ f 0 that incrementally computes f (x y) and maintains the
Reference: <author> O'Leary, J., Leeser, M., Hickey, J. & Aagaard, M. </author> <year> (1994). </year> <title> Non-restoring integer square root: A case study in design by principled optimization, </title> <editor> in R. Kumar & T. Kropf (eds), </editor> <booktitle> Proceedings of the 2nd International Conference on Theorem Provers in Circuit Design: Theory, Practice, and Experience, Vol. 901 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, Berlin, </publisher> <pages> pp. 52-71. </pages>
Reference: <author> Paige, B. & Schwartz, J. T. </author> <year> (1977). </year> <title> Expression continuity and the formal dif Related work and conclusion 25 ferentiation of algorithms, </title> <booktitle> Conference Record of the 4th Annual ACM Symposium on POPL, </booktitle> <pages> pp. 58-71. </pages>
Reference-contexts: Of course, the complexity of our algorithm is larger. We plan to further study the complexity issues. Inductively computable constructs in very-high-level languages (Fong 1977, Fong 1979, Fong & Ullman 1976) generalize conventional strength reduction and the elimination of induction variables to set-based languages. Finite differencing <ref> (Paige & Schwartz 1977, Paige 1983, Paige & Koenig 1982) </ref> and fixed point recomputation (Cai & Paige 1988/89) systematically 22 Principled strength reduction reduce strength of programs that use fixed point iteration and set-theoretic notations as the initial program specification.
Reference: <author> Paige, R. </author> <year> (1983). </year> <title> Transformational programming|Applications to algorithms and systems, </title> <booktitle> Conference Record of the 10th Annual ACM Symposium on POPL, </booktitle> <pages> pp. 73-87. </pages>
Reference: <author> Paige, R. & Koenig, S. </author> <year> (1982). </year> <title> Finite differencing of computable expressions, </title> <journal> ACM Transactions on Programming Languages and Systems 4(3): </journal> <pages> 402-454. </pages>
Reference: <author> Partsch, H. A. </author> <year> (1990). </year> <title> Specification and Transformation of Programs|A Formal Approach to Software Development, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Reynolds, J. C. </author> <year> (1981). </year> <title> The Craft of Programming, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey. </address>
Reference: <author> Sethi, R. </author> <year> (1973). </year> <title> A note on implementing parallel assignment instructions, </title> <booktitle> Information Processing Letter 2: </booktitle> <pages> 91-95. </pages>
Reference-contexts: Yet, the number of additional copy statements and the number of additional temporary variables can sometimes be reduced substantially by carefully ordering the assignment statements. The problem of minimizing the number S of additional copy statements is NP-complete (Garey & Johnson 1979, Sethi 1973), but good heuristics exist <ref> (Sethi 1973) </ref>. We can use an algorithm that easily decides an appropriate order of assignments when no additional temporary variables or copy statements are needed and reduces the problem to the problem of minimizing S otherwise.
Reference: <author> Smith, D. R. </author> <year> (1990). </year> <title> KIDS: A semiautomatic program development system, </title> <journal> IEEE Transactions on Software Engineering 16(9): </journal> <pages> 1024-1043. </pages>
Reference-contexts: Other work on transformational programming for improving program efficiency, including the extension technique (Dershowitz 1983), the promotion and accumulation strategies (Bird 1984, Bird 1985), and finite differencing of functional programs in KIDS <ref> (Smith 1990) </ref>, can also be further automated with principled strength reduction. Principled strength reduction improves over previous approaches for program efficiency improvement. It systematically handles program constructs and operations that were not handled systematically before. Also, it systematically handles initializations and termination conditions, which are often particularly error-prone.
Reference: <author> Steffen, B., Knoop, J. & Ruthing, O. </author> <year> (1990). </year> <title> The value flow graph: A program representation for optimal program transformation, </title> <booktitle> Proceedings of the 3rd ESOP, Vol. 432 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, Berlin, </publisher> <pages> pp. 389-405. </pages>
Reference-contexts: In fact, we can reduce the computation strength for a loop body as a whole. In particular, eliminating induction variables (Allen et al. 1981) is a special case of one of our optimizations. Optimal code motion <ref> (Steffen, Knoop & Ruthing 1990) </ref> is a principled method for optimal placement of computations within a program with respect to the Herbrand interpretation.
Reference: <author> Steffen, B., Knoop, J. & Ruthing, O. </author> <year> (1991). </year> <title> Efficient code motion and an adaption to strength reduction, </title> <booktitle> Proceedings of the 4th International Joint Conference on TAPSOFT, Vol. 494 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, Berlin, </publisher> <pages> pp. 394-415. </pages>
Reference-contexts: As discussed in <ref> (Steffen et al. 1991) </ref>, it is syntactic (ignoring semantic equivalences between syntactically different terms), locally updating (thus not guaranteeing safety or speedup), and structurally restricted (only working on induction variables and region constants). Composite hoisting-strength reduction (Joshi & Dhamdhere 1982a, Joshi & Dhamdhere 1982b) is also syntactic and locally updating. <p> Optimal code motion (Steffen, Knoop & Ruthing 1990) is a principled method for optimal placement of computations within a program with respect to the Herbrand interpretation. It is adopted for strength reduction by exploring the additional availability obtained from properties, such as distributivity, of numeric operators <ref> (Steffen et al. 1991) </ref>, and it improves over conventional methods. Our method is also a principled approach, based on the idea of incrementalization. It exploits properties of more primitive operators, data structures, and conditionals, and thus is a more comprehensive exploration of availability.
Reference: <author> Wolf, M. & Lam, M. </author> <year> (1991a). </year> <title> A data locality optimizing algorithm, </title> <booktitle> Proceedings of the ACM SIGPLAN '91 Conference on PLDI, </booktitle> <pages> pp. 30-44. </pages>

References-found: 42

