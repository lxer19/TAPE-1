URL: http://www.cs.gatech.edu/fac/rama/students/gukal/recovery.ps.Z
Refering-URL: http://www.cs.gatech.edu/fac/rama/students/gukal/index.html
Root-URL: 
Email: e-mail: gukal@cc.gatech.edu  
Phone: Phone: (404) 853-9390 Fax: (404) 853-9378  
Title: Fast Recovery in Transient-Versioned Databases  
Author: Sreenivas Gukal Edward Omiecinski Umakishore Ramachandran 
Address: Atlanta, GA 30332  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: Transient versioning methods, which maintain prior record versions temporarily, have been proposed to support long-running queries without affecting concurrent transactions. This paper presents a log-based recovery method that exploits the transient versions maintained for queries to reduce recovery overheads. Undo log records are avoided by using the prior versions as "before" values for undoing purposes. This reduces the log storage overhead for recovery by nearly 50%. A "lazy-undo" approach that uses the prior versions is devised for faster transaction aborts. In log-based methods, data I/O is the dominant crash recovery cost. This cost is avoided by only collecting the necessary log records during recovery. The data I/O for recovery is combined with normal transaction processing after recovery, thereby reducing crash recovery times by an order of magnitude. We also show that transient versions may be maintained just for recovery with very little storage overhead. 
Abstract-found: 1
Intro-found: 1
Reference: [Baye 80] <author> Bayer, R., Heller, H., Reiser, A. </author> <title> Parallelism and Recovery in Database Systems, </title> <journal> ACM Transactions on Database Systems, </journal> <month> June </month> <year> 1980. </year>
Reference-contexts: required and the pseudo code for the three passes are given in [Moha 92a]. 1 Pages with uncommitted updates are allowed to migrate to the disk. 2 Transaction commits do not force any data pages to the disk. 3 3 Transient Versioning Transient versioning originated from using shadowing for recovery <ref> [Baye 80] </ref>. In a shadowing environment all updates are done only to the shadow pages. Since the prior versions of the pages are maintained for recovery purposes, readers may be allowed to access them. The earlier approaches ([Baye 80], [Chan 82]) did versioning at page-level.
Reference: [Bern 87] <author> Bernstein, P.A., Hadzilacos, V., Goodman, N. </author> <title> Concurrency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley Pub. Co., </publisher> <year> 1987. </year>
Reference-contexts: Note that the entries in the undo-list do not contain the before values of the records. Hence, this "lazy-undo" method has minimal space overhead while providing comparable performance as the "no-undo" algorithms described in <ref> [Bern 87] </ref>. A compensation log record (CLR) is written for every update that is undone. The CLR contains the entry (record identifier and LSN) from the undo-list and the identifier of the aborted transaction. 4.2.2 Checkpoints Checkpointing is done to limit the amount of work during crash recovery.
Reference: [Bobe 92] <author> Bober, P., Carey, M. </author> <title> On Mixing Queries and Transactions via Multiversion Locking, </title> <booktitle> Proc. 8th International Conference on Data Engineering, </booktitle> <month> February </month> <year> 1992. </year>
Reference-contexts: In a shadowing environment all updates are done only to the shadow pages. Since the prior versions of the pages are maintained for recovery purposes, readers may be allowed to access them. The earlier approaches ([Baye 80], [Chan 82]) did versioning at page-level. The recent methods ([Moha 92b], <ref> [Bobe 92] </ref>, [Guka 95]) implement record-level versioning. Each record is allowed to have several committed versions and at most one uncommitted version. Transactions use two-phase locking or a variation for concurrency control. When a transaction first requests to update a record, a new version of the record is created. <p> Since the prior versions are transient, the free space overhead is minimum. When the space in a data page is not sufficient, the prior versions on the page are moved to a version pool <ref> [Bobe 92] </ref> or overflow pages [Guka 95]. The TV recovery method can be used for any record-level transient-versioning database that satisfies two requirements: 1. The last committed versions of the records are always in the data pages.
Reference: [Chan 82] <author> Chan, A., et al, </author> <title> The Implementation of an Integrated Concurrency Control and Recovery Scheme, </title> <booktitle> ACM SIGMOD International Conference on Management of Data, </booktitle> <month> June </month> <year> 1982. </year>
Reference-contexts: In a shadowing environment all updates are done only to the shadow pages. Since the prior versions of the pages are maintained for recovery purposes, readers may be allowed to access them. The earlier approaches ([Baye 80], <ref> [Chan 82] </ref>) did versioning at page-level. The recent methods ([Moha 92b], [Bobe 92], [Guka 95]) implement record-level versioning. Each record is allowed to have several committed versions and at most one uncommitted version. Transactions use two-phase locking or a variation for concurrency control.
Reference: [Crus 84] <author> Crus, R. </author> <title> Data Recovery in IBM Database 2, </title> <journal> IBM Systems Journal, </journal> <volume> Vol. 23, No. 2, </volume> <year> 1984. </year>
Reference-contexts: Usually new transactions are allowed even before the recovery is completed. Methods like ([Gray 81a], <ref> [Crus 84] </ref>, [Moha 92a]) partially recover the state of the database first, and allow normal processing on that part of the database that has been recovered while continuing with the recovery. In TVR, the state of the database is unknown during the first (analysis) pass.
Reference: [Dewi 92] <author> DeWitt, D., Gray, J. </author> <title> Parallel Database Systems: The Future of High Performance Database Systems, </title> <journal> Communications of the ACM, </journal> <month> June </month> <year> 1992. </year>
Reference-contexts: 1 Introduction One of the important concurrency control problems in high-performance database systems <ref> [Dewi 92] </ref> is to prevent the execution of queries (read-only transactions) from affecting concurrent update transactions. Long-running queries lock the data items for a long time and may starve transactions trying to update the same data items.
Reference: [Gray 78] <author> Gray, J.N. </author> <title> Notes on Database Operating Systems, </title> <editor> In R.Bayer, R.M.Graham and G.Seegmuller (Eds.) </editor> <booktitle> Lecture Notes in Computer Science, </booktitle> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: The prior versions are transient; they are removed when queries no longer need them. This paper presents a log-based Transient-Versioning Recovery (TVR) method that uses the transient prior versions maintained to support queries, to reduce recovery overheads during normal processing and to speed up crash recovery. In log-based recovery <ref> [Gray 78] </ref>, every update generates "undo" and "redo" log records. TVR avoids writing the undo log records by utilizing the prior versions for undoing purposes. This reduces both the log size and the log scanning time during recovery.
Reference: [Gray 81a] <author> Gray, J.N., McJones, P., Lindsay, B.G., Blasgen, M.W., Lorie, R.A., Price, T.G., Put-zolu, F., Traiger, </author> <title> I.L. The Recovery Manager of System R Database Manager, </title> <journal> ACM Computing Surveys, </journal> <month> June </month> <year> 1981. </year> <month> 22 </month>
Reference: [Guka 95] <author> Gukal, S., Omiecinski, E., Ramachandran, U., </author> <title> An Efficient Transient Versioning Method, </title> <booktitle> To appear in the Thirteenth British National Conference On Databases, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Since the prior versions of the pages are maintained for recovery purposes, readers may be allowed to access them. The earlier approaches ([Baye 80], [Chan 82]) did versioning at page-level. The recent methods ([Moha 92b], [Bobe 92], <ref> [Guka 95] </ref>) implement record-level versioning. Each record is allowed to have several committed versions and at most one uncommitted version. Transactions use two-phase locking or a variation for concurrency control. When a transaction first requests to update a record, a new version of the record is created. <p> Since the prior versions are transient, the free space overhead is minimum. When the space in a data page is not sufficient, the prior versions on the page are moved to a version pool [Bobe 92] or overflow pages <ref> [Guka 95] </ref>. The TV recovery method can be used for any record-level transient-versioning database that satisfies two requirements: 1. The last committed versions of the records are always in the data pages. In case a data page has insufficient space, any earlier versions are moved out. 2.
Reference: [Jhin 92] <author> Jhingran, A., Khedkar, P. </author> <title> Analysis of Recovery in a Database System Using a Write-Ahead Log Protocol, </title> <type> ACM-SIGMOD, </type> <month> June </month> <year> 1992. </year>
Reference-contexts: scan time * Avoided Performed with log scan in redo pass Data page I/O * Avoided during recovery Data pages loaded when Undo Pass time some transaction needs them or by LPP Log application * Avoided during recovery Undo done during time normal processing For example, the analytical study in <ref> [Jhin 92] </ref> shows that the most significant overhead during recovery in ARIES is the data page I/O time, which is an order of magnitude larger than the other overheads. TVR avoids this overhead during recovery, thereby reducing the crash recovery time by a factor of 10. <p> The break down of the recovery times for both the methods for the 30% updates case is listed in Table 5. The data page I/O time in ARIES is an order of magnitude larger than the other overheads (as analytically shown in <ref> [Jhin 92] </ref>). By avoiding data page I/O during recovery, TVR drastically reduces the recovery time. 5.4 Database Availability During Recovery Table 6 lists the number of data pages not available during each of the passes for the two methods.
Reference: [LiSc 83] <author> Liskov, B., Scheifler, R. </author> <title> Guardians and Actions: Linguistic Support for Robust, Distributed Programs, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 5, No. 3, </volume> <month> July </month> <year> 1983. </year>
Reference-contexts: However, if the transaction aborts during such an operation, the operation should be undone. Such operations are called "Top Actions" <ref> [LiSc 83] </ref>. In our method, each top action is assigned unique identifier which is noted in all the log records generated by that top action. When a top action is started, a beginTA log record is written.
Reference: [Moha 92a] <author> Mohan, C., Haderle, D., Lindsay, B., Pirahesh, H., Schwarz, P. </author> <title> ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging, </title> <booktitle> ACM Transaction on Database Systems, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: Data I/O for recovery is combined with page accesses during transaction processing after recovery. By avoiding any data I/O during recovery, crash recovery times are significantly reduced. We present simulation experiments which compare the performance and overheads of the TVR method with those of ARIES <ref> [Moha 92a] </ref>, an efficient and complete log-based recovery scheme. The results show that TVR, * reduces disk overhead for recovery by about 50% and * speeds up crash recovery by an order of magnitude by incurring small storage and processing overheads for a short duration after recovery. <p> The log records are written to an append-only log on the disk to ensure proper transaction recovery. The crash recovery process utilizes the log records to support the atomicity and durability properties of the transactions. ARIES <ref> [Moha 92a] </ref> is one of the efficient and complete log-based recovery schemes. It has also been implemented to varying degrees in a variety of database management systems. TVR method is based on ARIES. <p> Transaction aborts and partial rollbacks are supported. When any update is undone, a Compensation Log Record (CLR) is written to describe the undo action. The CLRs are redo-only log records and are essential in supporting logical undo and page-oriented redo. A detailed discussion of CLRs is presented in <ref> [Moha 92a] </ref>. Checkpointing is done periodically to limit the amount of work during crash recovery. A checkpoint record contains information about the list of active transactions and the list of dirty pages in the main memory. <p> In the undo pass, all updates belonging to the transactions in progress at the time of the crash are undone in reverse chronological order. The data structures required and the pseudo code for the three passes are given in <ref> [Moha 92a] </ref>. 1 Pages with uncommitted updates are allowed to migrate to the disk. 2 Transaction commits do not force any data pages to the disk. 3 3 Transient Versioning Transient versioning originated from using shadowing for recovery [Baye 80]. <p> Usually new transactions are allowed even before the recovery is completed. Methods like ([Gray 81a], [Crus 84], <ref> [Moha 92a] </ref>) partially recover the state of the database first, and allow normal processing on that part of the database that has been recovered while continuing with the recovery. In TVR, the state of the database is unknown during the first (analysis) pass. <p> Storage (both main memory and disk) overheads 2. Processing overhead * During crash recovery 1. Recovery time 2. Database availability during recovery. Simulation experiments are used to evaluate the TV recovery method in comparison with ARIES <ref> [Moha 92a] </ref> for all the above metrics. The first subsection describes the simulation model and parameters used. The results of the experiments are presented in the next four subsections. 14 5.1 Simulation Model & Parameters The simulation model is shown in Figure 3.
Reference: [Moha 92b] <author> Mohan, C., Pirahesh, H., Lorie, R. </author> <title> Efficient and Flexible Methods for Transient Ver-sioning of Records to Avoid Locking by Read-Only Transactions, </title> <booktitle> ACM SIGMOD Int. Conf. on Mgmt. of Data, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: In case a data page has insufficient space, any earlier versions are moved out. 2. On crash recovery, only the last committed versions of the records need to be restored. Transient-versioning is also implemented in commercial systems. Mohan et. al. <ref> [Moha 92b] </ref> mention that Prime and Oracle support transient versioning in their products.
Reference: [Moha 93] <author> Mohan, C. </author> <title> A Cost-Effective Method for Providing Improved Data Availability During DBMS Restart Recovery After a Failure, </title> <booktitle> Proc. 19th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: In TVR, only the pages requiring redo are not available during the second pass. The number of pages is further reduced by keeping track of the dirty pages in the main memory. The ARIES numbers are calculated based on <ref> [Moha 93] </ref>. ARIES repeats history during crash recovery. First, all the lost updates including the updates by aborted transactions are redone. The updates by aborted transactions are then undone. All the pages requiring redo and undo are not available during second pass.
Reference: [Pira 90] <author> Pirahesh, H., Mohan, C., Cheng, J., Liu, T.S., Selinger, P. </author> <title> Parallelism in Relational Database Systems: </title> <booktitle> Architectural Issues and Design Approaches, IEEE 2nd Int'l Symp. on Databases in Parallel and Distributed Systems, </booktitle> <month> July </month> <year> 1990. </year>
Reference-contexts: Long-running queries lock the data items for a long time and may starve transactions trying to update the same data items. Transient-versioning algorithms have been proposed as an elegant way to support queries without affecting transactions <ref> [Pira 90] </ref>. These algorithms maintain prior versions of updated data items. Queries can read the prior versions, while transactions use the current versions. The prior versions are transient; they are removed when queries no longer need them.
Reference: [RaRe 91] <author> Raghavan, A., Rengarajan, </author> <title> T.K. Database Availability for Transaction Processing, </title> <journal> Digital Technical Journal, </journal> <volume> Vol.3 No. 1, </volume> <month> Winter </month> <year> 1991. </year>
Reference-contexts: On crash recovery, only the last committed versions of the records need to be restored. Transient-versioning is also implemented in commercial systems. Mohan et. al. [Moha 92b] mention that Prime and Oracle support transient versioning in their products. Raghavan and Rengarajan <ref> [RaRe 91] </ref> provide a brief description of a transient-versioning scheme implemented by DEC. 4 Design of the Recovery Method The main goals of the recovery method are to use the transient versions to * minimize the overheads during normal transaction processing and * reduce the crash recovery time by avoiding data
Reference: [Schw 84] <author> Schwarz, P. </author> <title> Transactions on Typed Objects, </title> <type> Ph.D. Dissertation, Tech. Rep. </type> <institution> CMU-CS-84-166, Carnegie Mellon Univ., </institution> <month> December </month> <year> 1984. </year>
Reference-contexts: One way of doing this is to write a log record whenever a page is read from the disk or a dirty page is written back to the disk <ref> [Schw 84] </ref>. However, writing the I/O log records significantly increases the size of the append-only log on the disk, and hence the log scan time during recovery. The solution we devised avoids this overhead while achieving the 6 same effect.
Reference: [Schw 90] <author> Schwetman, H. </author> <title> CSIM Users Guide, </title> <month> March </month> <year> 1990. </year> <month> 23 </month>
Reference-contexts: The same sets of transactions are used for all methods. For each set of input parameters, the system is simulated on a number of transaction sets until the 90% confidence interval for the transaction throughput is within a few percent. The simulator is written in CSIM <ref> [Schw 90] </ref>, a process-oriented simulation package. 16 Table 4: Pages whose records have prior versions Percentage of Number of pages whose records have prior versions updates 1 Record 2 Records 3 Records 4 Records 10 140 2 0 0 30 414 11 0 0 50 657 29 1 0 5.2 Normal
References-found: 18

