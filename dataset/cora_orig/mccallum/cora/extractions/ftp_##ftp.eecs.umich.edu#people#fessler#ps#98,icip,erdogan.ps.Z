URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/98,icip,erdogan.ps.Z
Refering-URL: http://www.eecs.umich.edu/~fessler/papers/conf.html
Root-URL: http://www.eecs.umich.edu
Email: email: erdogan@umich.edu  
Title: Accelerated Monotonic Algorithms for Transmission Tomography  
Author: Hakan Erdoffgan and Jeffrey A. Fessler 
Address: Ann Arbor, MI 48109  
Affiliation: 4415 EECS Dept., Univeristy of Michigan,  
Note: ICIP 1998, to appear 1  
Abstract: We present a framework for designing fast and monotonic algorithms for transmission tomography penalized-likelihood image reconstruction. The new algorithms are based on paraboloidal surrogate functions for the log-likelihood. Due to the form of the log-likelihood function, it is possible to find low curvature surrogate functions that guarantee monotonicity. Unlike previous methods, the proposed surrogate functions lead to monotonic algorithms even for the nonconvex log- likelihood that arises due to background events such as scatter and random coincidences. The gradient and the curvature of the likelihood terms are evaluated only once per iteration. Since the problem is simplified, the CPU time per iteration is less than that of current algorithms which directly minimize the objective, yet the convergence rate is comparable. The simplicity, monotonicity and speed of the new algorithms are quite attractive. The convergence rates of the algorithms are demonstrated using real PET transmission scans. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. C. Huang, E. J. Hoffman, M. E. Phelps, and D. E. Kuhl, </author> <title> Quantitation in positron emission computed tomography: 2 Effects of inaccurate attenuation correction, </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> vol. 3, no. 6, </volume> <pages> pp. 804814, </pages> <month> December </month> <year> 1979. </year>
Reference-contexts: 1 Introduction Emission tomography systems require attenuation correction for quantitatively accurate image reconstruction. Transmission scans are performed to estimate the attenuation maps for correction. The accuracy of this correction is very important in emission tomography <ref> [1] </ref>. Statistical methods provide a valuable tool to reconstruct attenuation maps in photon limited tomography applications. Penalized likelihood is an appealing reconstruction method since it provides an easy means to regularize the problem.
Reference: [2] <author> J. A. Fessler, </author> <title> Hybrid Poisson/polynomial objective functions for tomographic image reconstruction from transmission scans, </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 4, no. 10, </volume> <pages> pp. 143950, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Penalized likelihood is an appealing reconstruction method since it provides an easy means to regularize the problem. Using the Poisson log-likelihood eliminates the negative bias which occurs in the weighted least squares and conventional methods <ref> [2] </ref>. However, up to now, no practically realizable monotonic (or convergent) algorithm has been found which would optimize the penalized likelihood problem when the objective is not convex. The objective is not convex when there are background counts in the data. <p> The projection space was 160 radial bins and 192 angles, and the reconstructed images were 128 fi 128 with 4.5 mm. pixels. The system matrix fa ij g was computed by using 6 mm. wide strip integrals with 3 mm. spacing, which roughly approximates the system geometry <ref> [2] </ref>. <p> The simplicity in part is due to the additive form of (1), which is a direct consequence of independent measurements. Since this algorithm is simple, it might replace the use of FBP in the clinic. In our opinion, the PS,O,CD algorithm supersedes all of our previous methods <ref> [2, 8] </ref>, and is our recommended algorithm for penalized-likelihood transmission tomography. The PS,P,CD algorithm is a faster but nonmonotonic alternative which can be used for noncritical applications.
Reference: [3] <author> P. J. Huber, </author> <title> Robust statistics, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: To obtain the paraboloid, we find 1-D parabolic functions that are tangent to and lie above each of the terms in the log-likelihood, similar to Huber's method for robust linear regression <ref> [3] </ref>. 2 The Problem The measurements in a photon limited application such as PET and SPECT are well-modeled as Poisson random variables. <p> We use one iteration of coordinate descent algorithm to decrease the surrogate function, and this results in a simple monotonic algorithm. For the penalty part, we use Huber's iterative method <ref> [3, 4] </ref> (see also [7]). Since the likelihood part is quadratic, this coordinate descent method is guaran teed to decrease the surrogate function. <p> To prove monotonicity, k () have to be symmetric, differentiable, convex and ! (0) should be finite and nonzero and ! (t) should be non-increasing for t 0 <ref> [3] </ref>. This is an update that monotonically decreases the value of OE (; n ) and consequently the value of (). One iteration is finished when all pixels are updated via (14) in a sequential order. We call this method the Paraboloidal Surrogates Coordinate Descent (PSCD) method.
Reference: [4] <author> J. A. Fessler, </author> <title> Grouped coordinate descent algorithms for robust edge-preserving image restoration, </title> <booktitle> in Proc. SPIE 3071, Im. Recon. and Restor. II, </booktitle> <pages> pp. 18494, </pages> <year> 1997. </year>
Reference-contexts: i ): (2) Penalized likelihood image reconstruction formulation is given below: ^ = arg min (); () = L () + fiR (): (3) 2 Erdo ffgan and Fessler: Accelerated Monotonic Algorithms The roughness penalty included in the objective func tion (in a very general form) can be given by <ref> [4] </ref>: R () = k=1 where k are potential functions penalizing the deviations from the set of equations C 0 for k = 1 : : : K where K is number of such equations. <p> The fi in equation (3) is a parameter which controls the level of smoothness in the final reconstructed image. For more explanation of the penalty function, see <ref> [4] </ref>. The objective function defined in (3) is not convex when there are nonzero background counts (r i 6= 0) in the data. In this realistic case, there is no guarantee that there is a single global minimum. <p> We use one iteration of coordinate descent algorithm to decrease the surrogate function, and this results in a simple monotonic algorithm. For the penalty part, we use Huber's iterative method <ref> [3, 4] </ref> (see also [7]). Since the likelihood part is quadratic, this coordinate descent method is guaran teed to decrease the surrogate function.
Reference: [5] <author> K. Lange and R. Carson, </author> <title> EM reconstruction algorithms for emission and transmission tomography, </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> vol. 8, no. 2, </volume> <pages> pp. 306316, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: n ) = ( n ) 3: OE (; n ) () for 0: A function which satisfies these criteria can be easily shown to satisfy the following monotonicity condition: () ( n ) OE (; n ) OE ( n ; n ); 8 0: (5) The EM algorithm <ref> [5] </ref> provides a statistical method for constructing surrogate functions OE (; n ) satisfying the above conditions. However, in the transmission tomography problem, the EM surrogate is difficult to minimize and leads to slow convergence. In this paper, we construct a simpler surrogate using ordinary calculus rather than statistical techniques.
Reference: [6] <author> P. G. Ciarlet, </author> <title> Introduction to numerical linear algebra and optimisation, </title> <address> Cambridge, Cambridge, </address> <year> 1982. </year>
Reference-contexts: The following two choices for curvatures do ensure monotonicity. 3.1.1 Maximum Curvature A simple choice for c i (l n i ) that ensures monotonicity (7) is the maximum second derivative in the feasible region (from mean value theorem, see for example <ref> [6] </ref>, page 228). The feasible region for the projections is [0; 1) due to the nonnegativity constraint. Hence, c i (l n l2 [0;1) is guaranteed to satisfy (7).
Reference: [7] <author> H. Erdoigan and J. A. Fessler, </author> <title> Fast monotonic algorithms for transmission tomography, </title> <journal> IEEE Tr. Med. </journal> <note> Im., 1998. Submitted. </note>
Reference-contexts: The feasible region for the projections is [0; 1) due to the nonnegativity constraint. Hence, c i (l n l2 [0;1) is guaranteed to satisfy (7). We show in <ref> [7] </ref> that the closed form expression for c i (l n i ) is: i ) = h i (0) + y i r i (11) ICIP 1998, to appear 3 where [x] + = x for x &gt; 0 and zero otherwise. <p> However, this maximum curvature choice for c i (l n i ) is very conservative and results in slow convergence. It is intuitive that smaller c i (l n i ) values will lead to faster convergence, as analyzed in <ref> [7] </ref>. This is due to the fact that smaller curvatures mean wider paraboloids and longer step sizes. <p> By exploiting the properties of the marginal negative log-likelihood functions for each projection (h i ) in trans mission tomography, we show in <ref> [7] </ref> that the paraboloid with the following curvature satisfies the optimality condition: c i (l n 8 &gt; &gt; : 2 i ) + _ h i (l n i ) i ) 2 + i &gt; 0; h i (0) + i = 0: There are some numerical issues with <p> optimality condition: c i (l n 8 &gt; &gt; : 2 i ) + _ h i (l n i ) i ) 2 + i &gt; 0; h i (0) + i = 0: There are some numerical issues with the computation of these curvatures which are addressed in <ref> [7] </ref>. Next, we consider a set of fixed curvatures which have some computational advantages. 3.1.3 Nonmonotonic Precomputed Curvature By relaxing the monotonicity requirement, we can develop faster yet almost always monotonic algorithms. <p> We use one iteration of coordinate descent algorithm to decrease the surrogate function, and this results in a simple monotonic algorithm. For the penalty part, we use Huber's iterative method [3, 4] (see also <ref> [7] </ref>). Since the likelihood part is quadratic, this coordinate descent method is guaran teed to decrease the surrogate function. <p> One iteration is finished when all pixels are updated via (14) in a sequential order. We call this method the Paraboloidal Surrogates Coordinate Descent (PSCD) method. A coarse outline of the algorithm is given in Table 1. For computational considerations and the detailed algorithm flow table, see <ref> [7] </ref>. 4 Results To assess the effectiveness and speed of the new PS algorithms, we present results using real PET data.
Reference: [8] <author> J. A. Fessler, E. P. Ficaro, N. H. Clinthorne, and K. Lange, </author> <title> Grouped-coordinate ascent algorithms for penalized-likelihood transmission image reconstruction, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 16, no. 2, </volume> <pages> pp. 16675, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: h i log y i r i = (y i r i ) 2 =y i : (13) These curvatures c i in (13) are close approximations to the second derivative of h i functions at the projection values A ^ where ^ is the solution to the penalized-likelihood problem <ref> [8] </ref>. <p> The simplicity in part is due to the additive form of (1), which is a direct consequence of independent measurements. Since this algorithm is simple, it might replace the use of FBP in the clinic. In our opinion, the PS,O,CD algorithm supersedes all of our previous methods <ref> [2, 8] </ref>, and is our recommended algorithm for penalized-likelihood transmission tomography. The PS,P,CD algorithm is a faster but nonmonotonic alternative which can be used for noncritical applications.
Reference: [9] <author> K. Lange, </author> <title> Convergence of EM image reconstruction algorithms with Gibbs smoothing, </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 9, no. 4, </volume> <pages> pp. 439446, </pages> <month> December </month> <year> 1990. </year> <title> Corrections, </title> <month> June </month> <year> 1991. </year>
Reference-contexts: end Update _q i := _q i + a ij c i (^ j ^ old j ) Update ^ l i := ^ l i + _q i _ h i end Table 1: Coarse outline of PSCD algorithm. with the edge-preserving nonquadratic potential function that was introduced in <ref> [9] </ref> (x) = ffi 2 [jx=ffij log (1 + jx=ffij)] : Fig. 1 shows that the proposed PSCD algorithms increased the penalized-likelihood almost as fast as the coordinate descent algorithm (CD) [10] applied to the original objective per iteration. It shows that the surrogate paraboloids closely approximate the original log-likelihood.
Reference: [10] <author> C. A. Bouman and K. Sauer, </author> <title> A unified approach to statistical tomography using coordinate descent optimization, </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 5, no. 3, </volume> <pages> pp. 48092, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: i end Table 1: Coarse outline of PSCD algorithm. with the edge-preserving nonquadratic potential function that was introduced in [9] (x) = ffi 2 [jx=ffij log (1 + jx=ffij)] : Fig. 1 shows that the proposed PSCD algorithms increased the penalized-likelihood almost as fast as the coordinate descent algorithm (CD) <ref> [10] </ref> applied to the original objective per iteration. It shows that the surrogate paraboloids closely approximate the original log-likelihood. More importantly, in Fig. 2 the PSCD algorithms are seen to be much faster than coordinate descent in terms of the actual CPU time.
Reference: [11] <author> C. Zhu, R. H. Byrd, P. Lu, and J. Nocedal, L-BFGS-B: </author> <title> Fortran subroutine for large-scale bound contrained optimization, </title> <type> Technical Report ?, Dept. </type> <institution> EECS, Northwestern Univ., </institution> <month> July </month> <year> 1996. </year>
Reference-contexts: However, these c i (l n i )'s are much larger than the optimal curvatures, so more iterations are required for PS,M,CD than PS,O,CD to converge. We also compared the PSCD algorithms to the general purpose constrained Quasi-Newton algorithm (LBFGS) <ref> [11] </ref>, and the functional substitution coordinate descent (FSCD) [12, 13] algorithm in Figures 1 and 2. Although the LBFGS algorithm takes about 25% less CPU time (0.88 seconds) per iteration than PSCD algorithms, it did not converge as fast as the proposed algorithms.
Reference: [12] <author> J. Zheng, S. Saquib, K. Sauer, and C. Bouman, </author> <title> Functional substitution methods in optimization for Bayesian tomography, </title> <journal> IEEE Tr. Im. Proc., </journal> <month> March </month> <year> 1997. </year> <note> Submitted to IEEE Tr. Image Proc. </note>
Reference-contexts: However, these c i (l n i )'s are much larger than the optimal curvatures, so more iterations are required for PS,M,CD than PS,O,CD to converge. We also compared the PSCD algorithms to the general purpose constrained Quasi-Newton algorithm (LBFGS) [11], and the functional substitution coordinate descent (FSCD) <ref> [12, 13] </ref> algorithm in Figures 1 and 2. Although the LBFGS algorithm takes about 25% less CPU time (0.88 seconds) per iteration than PSCD algorithms, it did not converge as fast as the proposed algorithms.
Reference: [13] <author> S. Saquib, J. Zheng, C. A. Bouman, and K. D. Sauer, </author> <title> Provably convergent coordinate descent in statistical tomo-graphic reconstruction, </title> <booktitle> in Proc. IEEE Intl. Conf. on Image Processing, </booktitle> <year> 1996. </year>
Reference-contexts: However, these c i (l n i )'s are much larger than the optimal curvatures, so more iterations are required for PS,M,CD than PS,O,CD to converge. We also compared the PSCD algorithms to the general purpose constrained Quasi-Newton algorithm (LBFGS) [11], and the functional substitution coordinate descent (FSCD) <ref> [12, 13] </ref> algorithm in Figures 1 and 2. Although the LBFGS algorithm takes about 25% less CPU time (0.88 seconds) per iteration than PSCD algorithms, it did not converge as fast as the proposed algorithms.
Reference: [14] <author> J. A. Fessler and A. O. Hero, </author> <title> Space-alternating generalized expectation-maximization algorithm, </title> <journal> IEEE Tr. Sig. Proc., </journal> <volume> vol. 42, no. 10, </volume> <pages> pp. 266477, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: The algorithms are monotonic even with the nonconvex objective function. In the strictly convex case, the proposed algorithms are guaranteed to converge to the global minimum by a proof similar to that in <ref> [14] </ref>. The algorithms we introduced are simple, easy to understand, fast and monotonic. The simplicity in part is due to the additive form of (1), which is a direct consequence of independent measurements. Since this algorithm is simple, it might replace the use of FBP in the clinic.
References-found: 14

