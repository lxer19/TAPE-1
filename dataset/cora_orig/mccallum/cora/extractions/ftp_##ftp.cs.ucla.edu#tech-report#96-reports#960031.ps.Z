URL: ftp://ftp.cs.ucla.edu/tech-report/96-reports/960031.ps.Z
Refering-URL: http://ficus-www.cs.ucla.edu/ficus-members/ratner/research.html
Root-URL: http://www.cs.ucla.edu
Title: Peer Replication with Selective Control  
Author: David Ratner Gerald J. Popek Peter Reiher 
Address: Los Angeles  
Affiliation: Department of Computer Science University of California,  
Abstract: Peer-to-peer optimistic replication strategies provide improved functionality over traditional client-server models by enabling any-to-any communication. This is especially useful in environments with common network partitions, such as mobile environments, in which communicating with a closely connected peer can be cheaper than communicating with a distant, weakly connected server. However, most peer solutions require full replication, meaning that all replicas store the entire replication unit, whether it be a volume or a database. Such strategies are clearly inefficient and not cost effective. Users are forced to both store more data than they require and spend time and money maintaining consistency on that data, potentially making peer solutions unusable in practice. We have developed a set of algorithms that implement selective replication, allowing individual portions of the replication unit to be replicated independently. We have implemented our solution in Ficus and allow files from the volume to be selectively replicated without storing the entire volume. We present a description of the algorithms and their implementation in the Ficus file system, as well as a performance analysis. We argue that these methods permit the practical use of peer optimistic replication. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. E. Anderson, M. D. Dahlin, J. M. Neefe, D. A. Patterson, D. S. Roselli, and R. Y. Wang. </author> <title> Serverless network file systems. </title> <booktitle> In Proceedings of the 15th Symposium on Operating Systems Principles, </booktitle> <pages> pages 109-126, </pages> <address> Copper Mountain Resort, Colorado, </address> <month> Dec. </month> <year> 1995. </year> <journal> ACM. </journal> <volume> 13 </volume>
Reference-contexts: First, peer functionality is important, evidenced by the rise of mobile use. Mobility by its very nature requires peer capabilities; for example, mobile workgroups. A number of research projects are investigating peer usage, such as xFS in the NOW project <ref> [1] </ref> and the Bayou system [24]. Second, we expected that 1 modifying a fundamentally client-server design to in-corporate a rich communications structure would require such basic structural changes as to imply effectively starting from scratch. Adding selective control to a peer model ought to better preserve the underlying framework.
Reference: [2] <author> M. J. Fischer and A. Michael. </author> <title> Sacrificing serializabil--ity to attain high availability of data in an unreliable network. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Database Systems, </booktitle> <month> Mar. </month> <year> 1982. </year>
Reference-contexts: There are two basic deletion issues, the potential loss of updates and the create/delete ambiguity <ref> [2] </ref>. Both of these are examined below. Potential loss of updates: Replica deletions should only affect storage locations, not the file's existence or physical data. However, data can be inadvertently lost when the replica being deleted contains the most recent version. <p> First and foremost, one must guard against premature garbage collection. Garbage collecting before all participants realize the process has started generates create/delete ambiguities <ref> [2, 5] </ref> between the informed and uninformed replicas. Nevertheless, since the data being garbage collected occupies otherwise usable disk space, every effort should be made to garbage collect quickly.
Reference: [3] <author> A. Goel. </author> <title> View consistency for optiimistic replication. </title> <type> Master's thesis, </type> <institution> University of California, </institution> <address> Los Angeles, </address> <month> Feb. </month> <year> 1996. </year> <note> Available as UCLA technical report CSD-960011. </note>
Reference-contexts: Bayou provides session guarantees [23] to improve the perceived consistency by users. Additionally, Bayou establishes strong guarantees about its data| writes can be classified either as committed or tentative. Ficus is working on similar methods of providing stronger consistency guarantees to users <ref> [3] </ref>. However, Bayou does not support any form of selective replication, so the databases (the Bayou replication unit) must be fully replicated at all storage sites.
Reference: [4] <author> R. G. Guy, J. S. Heidemann, W. Mak, T. W. Page, Jr., G. J. Popek, and D. Rothmeier. </author> <title> Implementation of the Ficus replicated file system. </title> <booktitle> In USENIX Conference Proceedings, </booktitle> <pages> pages 63-71. </pages> <publisher> USENIX, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The need for optimistic replication in environments with variable, sporadic, unpredictable, or weak connectivity is already well known <ref> [4, 6, 7, 9, 20, 24] </ref>. Replication provides both improved performance and reliability through the creation of multiple replicas of important data objects; optimism allows replicas to be independently updated, and guarantees that concurrent fl This work was sponsored by the Advanced Research Projects Agency under contract N00174-91-C-0107. <p> Each volume replica stores just the files from the volume that it deems important; additionally, this set can be dynamically modified with simple tools. Incorporating this control into the peer model required extensive algorithmic modifications, which will be explained in the Ficus <ref> [4, 14] </ref> context. Finally, we discovered that the flexibility could be added with little or no performance impact. The next section provides a brief overview of Ficus and optimistic peer replication. Section 3 describes the overall selective replication design; data consistency maintenance is discussed immediately following. <p> However, allowing partitioned updates provides the potential for concurrent updates and resulting conflicts, so optimistic schemes must reliably detect these conflicts after the fact. Once detected, conflict resolution must occur before normal file activity on conflicted files resumes. Ficus <ref> [4, 14] </ref> is one system that supports optimistic replication. With a peer-to-peer model that allows any two replicas to synchronize with each other, and with the work reported in this paper, Ficus supports peer-based, file-level selective replication. Each file can reside at an arbitrary number of volume fragments. <p> Additionally, the status vectors for each file need to be compared to gossip about status changes. The comparison is performed using the method described in Section 3.2. Finally, the "standard" reconciliation actions must be performed, such as version-vector comparisons, update propagation, and conflict-detection, discussed in <ref> [4, 14, 18] </ref>. 4.1.5 Optimization opportunities The multi-ring topology is clearly not ideal in all environments. A single ring is formed with all replicas as members, instead of, for example, utilizing the natural clusters formed by geographic location. <p> Additionally, files may temporarily have no local links while still being globally accessible: new links could exist at other replicas, waiting to be propagated from informed to uninformed sites. The Ficus no lost updates semantics <ref> [4] </ref> require that the latest data version must be preserved as long as the data is globally accessible. Therefore, consensus that no links exist must be reached globally before garbage collection can properly occur. Selective replication only adds more complexity. <p> Some of the benchmarks (mab and ls) were even faster with selective replication, due to minor artifacts of the implementation. We actually expect the ls benchmark to be faster, because it does 7 A description of the volume mounting procedure is in <ref> [4] </ref>. 8 Attribute caching was removed by modifying nfs getattr cache. and Ficus where all data is stored and accessed remotely. Elapsed time is indicated by total height, system time by the black bar within. Each data point is the mean of at least 6 runs.
Reference: [5] <author> R. G. Guy, G. J. Popek, and T. W. Page, Jr. </author> <title> Consistency algorithms for optimistic replication. </title> <booktitle> In Proceedings of the First International Conference on Network Protocols. IEEE, </booktitle> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: As part of reconciliation, Ficus contains a distributed algorithm to perform garbage collection|the deal-location of resources held by unnamed file system objects <ref> [5] </ref>. While a relatively simple process in a centralized system, dynamic naming and potentially long-term communication barriers make garbage collection more difficult in partially replicated, distributed systems. <p> Ficus uses a fully distributed, two-phase, coordinator-free algorithm to ensure that all replicas are knowledgeable about the garbage collection process and can eventually complete it, although any set of participants may never be present simultaneously <ref> [5] </ref>. Ficus is implemented in SunOS 4.1.1, and supports the research of approximately a dozen people. We have over 256 man-months experience with the system and selective replication control. All Ficus development occurs under Ficus. 3 Selective Replication Design This section describes the overall selective replication design. <p> We therefore allow users to bypass reverse reconciliation. Create/delete ambiguity: In the absence of additional information, object deletion (i.e., replica deletion) at one site is indistinguishable from object creation at another. Guy <ref> [5] </ref> describes a solution for resolving the create/delete ambiguity in the garbage collection of distributed file system objects. We adopt Guy's solution here. <p> First and foremost, one must guard against premature garbage collection. Garbage collecting before all participants realize the process has started generates create/delete ambiguities <ref> [2, 5] </ref> between the informed and uninformed replicas. Nevertheless, since the data being garbage collected occupies otherwise usable disk space, every effort should be made to garbage collect quickly. <p> with regard to its own participation in the distributed algorithm. 4.2.2 Garbage collection solution We utilize a two-phase, coordinator-free, distributed solution to the problem of garbage collecting in a rep 6 This is different from dynamic creation and deletion of new volume replicas, which can be trivially handled. licated graph <ref> [5] </ref>, and augment the solution for selective replication. Basically, the algorithm is a distributed implementation of a two-phase commit protocol among multiple participants, and verifies that no member completes before all members know that completion is imminent. <p> Any site with no local links for a file initiates garbage collection; the algorithm either stops when a new link is discovered or reaches consensus that no links exist globally, completing garbage collection. The solution in <ref> [5] </ref> assumes full replication. To support selective replication, the solution must be substantially extended to execute only between data-storing replicas of the file. As explained above, the set of data-storing replicas is dynamic and not necessarily known upon garbage collection initiation.
Reference: [6] <author> J. S. Heidemann, T. W. Page, Jr., R. G. Guy, and G. J. Popek. </author> <title> Primarily disconnected operation: Experiences with Ficus. </title> <booktitle> In Proceedings of the Second Workshop on Management of Replicated Data, </booktitle> <pages> pages 2-5. </pages> <publisher> IEEE, </publisher> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction The need for optimistic replication in environments with variable, sporadic, unpredictable, or weak connectivity is already well known <ref> [4, 6, 7, 9, 20, 24] </ref>. Replication provides both improved performance and reliability through the creation of multiple replicas of important data objects; optimism allows replicas to be independently updated, and guarantees that concurrent fl This work was sponsored by the Advanced Research Projects Agency under contract N00174-91-C-0107. <p> Specifically, (95 + 20N) bytes are transferred for each file, which includes both Unix and Ficus attributes. This constitutes a 4N-byte increase above VFicus. Additionally, we employ a time-based optimization, reducing the number of files which must be analyzed <ref> [6, 17] </ref>. If the file is deemed unchanged since the last time the two replicas communicated, only 63 bytes are transferred. <p> Coda has greatly optimized the communications and synchronization between client and server, especially in environments with weak connectivity [10, 12]. Some of the same ideas can and have been applied in Ficus <ref> [6] </ref>; however, more research is required in optimizing communication protocols for weak connectivity in peer models. The Little Work project [7] is similar to Coda, but modifies only the clients, leaving the AFS [8] servers unaltered.
Reference: [7] <author> P. Honeyman, L. Huston, J. Rees, and D. Bachmann. </author> <title> The Little Work project. </title> <booktitle> In Proceedings of the Third Workshop on Workstation Operating Systems, </booktitle> <pages> pages 11-14. </pages> <publisher> IEEE, </publisher> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction The need for optimistic replication in environments with variable, sporadic, unpredictable, or weak connectivity is already well known <ref> [4, 6, 7, 9, 20, 24] </ref>. Replication provides both improved performance and reliability through the creation of multiple replicas of important data objects; optimism allows replicas to be independently updated, and guarantees that concurrent fl This work was sponsored by the Advanced Research Projects Agency under contract N00174-91-C-0107. <p> Some of the same ideas can and have been applied in Ficus [6]; however, more research is required in optimizing communication protocols for weak connectivity in peer models. The Little Work project <ref> [7] </ref> is similar to Coda, but modifies only the clients, leaving the AFS [8] servers unaltered. Congestion caused by client's slow links is reduced in a variety of ways, including client-side modifications of AFS, its underlying RPC, and other congestion avoidance and control methods.
Reference: [8] <author> J. Howard, M. Kazar, S. Menees, D. Nichols, M. Satya-narayanan, R. Sidebotham, and M. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: Some of the same ideas can and have been applied in Ficus [6]; however, more research is required in optimizing communication protocols for weak connectivity in peer models. The Little Work project [7] is similar to Coda, but modifies only the clients, leaving the AFS <ref> [8] </ref> servers unaltered. Congestion caused by client's slow links is reduced in a variety of ways, including client-side modifications of AFS, its underlying RPC, and other congestion avoidance and control methods. However, again clients cannot intercommunicate, hindering the usability of the system.
Reference: [9] <author> J. J. Kistler and M. Satyanarayanan. </author> <title> Disconnected operation in the Coda file system. </title> <type> Technical Report CMU-CS-91-166, </type> <institution> Carnegie-Mellon University, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The need for optimistic replication in environments with variable, sporadic, unpredictable, or weak connectivity is already well known <ref> [4, 6, 7, 9, 20, 24] </ref>. Replication provides both improved performance and reliability through the creation of multiple replicas of important data objects; optimism allows replicas to be independently updated, and guarantees that concurrent fl This work was sponsored by the Advanced Research Projects Agency under contract N00174-91-C-0107. <p> Additional experience, however, is required. 6 Related Work A number of other replication services exist, each with different design choices, assumptions, and levels of service. We will discuss each system briefly. The Coda file system <ref> [9, 20] </ref> is an optimistically replicated file system constructed on a client-server model, as opposed to the peer architecture proposed by Ficus. 12 As such, Coda trivially provides selective-replication control at the clients, but not at the replicated servers, which are, by definition, peers.
Reference: [10] <author> J. J. Kistler and M. Satyanarayanan. </author> <title> Disconnected operation in the Coda file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(1) </volume> <pages> 3-25, </pages> <year> 1992. </year>
Reference-contexts: This restriction dramatically simplifies the algorithms needed to manage consistency, at the cost of limiting the system's utility for mobile workgroups. Coda has greatly optimized the communications and synchronization between client and server, especially in environments with weak connectivity <ref> [10, 12] </ref>. Some of the same ideas can and have been applied in Ficus [6]; however, more research is required in optimizing communication protocols for weak connectivity in peer models. The Little Work project [7] is similar to Coda, but modifies only the clients, leaving the AFS [8] servers unaltered. <p> However, again clients cannot intercommunicate, hindering the usability of the system. Additionally, the method used to populate the client with the necessary data is suboptimal compared to other strategies <ref> [10, 11] </ref>. The Bayou system [24] is also a replicated storage system, but based on the peer-to-peer architecture. Like Ficus, Bayou provides support for application-dependent resolution of conflicts. However, unlike Ficus, Bayou does not attempt to provide transparent conflict detection.
Reference: [11] <author> G. H. Kuenning. </author> <title> Design of the SEER predictive caching system. </title> <booktitle> In Proceedings of the Workshop on Mobile Computing Systems and Applications, </booktitle> <address> Santa Cruz, CA, </address> <month> Dec. </month> <year> 1994. </year>
Reference-contexts: However, again clients cannot intercommunicate, hindering the usability of the system. Additionally, the method used to populate the client with the necessary data is suboptimal compared to other strategies <ref> [10, 11] </ref>. The Bayou system [24] is also a replicated storage system, but based on the peer-to-peer architecture. Like Ficus, Bayou provides support for application-dependent resolution of conflicts. However, unlike Ficus, Bayou does not attempt to provide transparent conflict detection.
Reference: [12] <author> L. B. Mummert, M. R. Ebling, and M. Satyanara-yanan. </author> <title> Exploiting weak connectivity for mobile file access. </title> <booktitle> In Proceedings of the 15th Symposium on Operating Systems Principles, </booktitle> <pages> pages 143-155, </pages> <address> Copper Mountain Resort, Colorado, </address> <month> Dec. </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: This restriction dramatically simplifies the algorithms needed to manage consistency, at the cost of limiting the system's utility for mobile workgroups. Coda has greatly optimized the communications and synchronization between client and server, especially in environments with weak connectivity <ref> [10, 12] </ref>. Some of the same ideas can and have been applied in Ficus [6]; however, more research is required in optimizing communication protocols for weak connectivity in peer models. The Little Work project [7] is similar to Coda, but modifies only the clients, leaving the AFS [8] servers unaltered.
Reference: [13] <author> J. K. Ousterhout. </author> <title> Why aren't operating systems getting faster as fast as hardware? In USENIX Conference Proceedings, </title> <booktitle> pages 247-256. USENIX, </booktitle> <month> June </month> <year> 1990. </year>
Reference: [14] <author> T. W. Page, Jr., R. G. Guy, G. J. Popek, J. S. Heidemann, W. Mak, and D. Rothmeier. </author> <title> Management of replicated volume location data in the Ficus replicated file system. </title> <booktitle> In USENIX Conference Proceedings, </booktitle> <pages> pages 17-29. </pages> <publisher> USENIX, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: Each volume replica stores just the files from the volume that it deems important; additionally, this set can be dynamically modified with simple tools. Incorporating this control into the peer model required extensive algorithmic modifications, which will be explained in the Ficus <ref> [4, 14] </ref> context. Finally, we discovered that the flexibility could be added with little or no performance impact. The next section provides a brief overview of Ficus and optimistic peer replication. Section 3 describes the overall selective replication design; data consistency maintenance is discussed immediately following. <p> However, allowing partitioned updates provides the potential for concurrent updates and resulting conflicts, so optimistic schemes must reliably detect these conflicts after the fact. Once detected, conflict resolution must occur before normal file activity on conflicted files resumes. Ficus <ref> [4, 14] </ref> is one system that supports optimistic replication. With a peer-to-peer model that allows any two replicas to synchronize with each other, and with the work reported in this paper, Ficus supports peer-based, file-level selective replication. Each file can reside at an arbitrary number of volume fragments. <p> Additionally, the status vectors for each file need to be compared to gossip about status changes. The comparison is performed using the method described in Section 3.2. Finally, the "standard" reconciliation actions must be performed, such as version-vector comparisons, update propagation, and conflict-detection, discussed in <ref> [4, 14, 18] </ref>. 4.1.5 Optimization opportunities The multi-ring topology is clearly not ideal in all environments. A single ring is formed with all replicas as members, instead of, for example, utilizing the natural clusters formed by geographic location.
Reference: [15] <author> D. S. Parker, Jr., G. Popek, G. Rudisin, A. Stoughton, B. J. Walker, E. Walton, J. M. Chow, D. Edwards, S. Kiser, and C. Kline. </author> <title> Detection of mutual inconsistency in distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 9(3) </volume> <pages> 240-247, </pages> <month> May </month> <year> 1983. </year>
Reference-contexts: While the reconciliation algorithms are topology independent, the actual topology can affect both the number of messages exchanged between all replicas and the time required to reach resolution. Updates are tracked using version vectors <ref> [15] </ref>. A version vector is a vector of counters, with one counter per replica. Each counter i tracks the total number of known updates generated by replica i.
Reference: [16] <author> G. Popek, B. Walker, J. Chow, D. Edwards, C. Kline, G. Rudisin, and G. Thiel. </author> <title> LOCUS: A network transparent, high reliability distributed system. </title> <booktitle> In Proceedings of the Eighth Symposium on Operating Systems Principles, </booktitle> <pages> pages 169-177. </pages> <publisher> ACM, </publisher> <month> Dec. </month> <year> 1981. </year>
Reference-contexts: In addition, Deceit cannot tolerate long-term network partitions; instead, only a related failure known as a virtual partition [22], which eventually corrects itself, is tolerated. The university LOCUS operating system <ref> [16, 25] </ref> provides volumes and allows selective replication within the volume. However, the approach taken toward replication is not strictly optimistic.
Reference: [17] <author> D. H. Ratner. </author> <title> Selective replication: Fine-grain control of replicated files. </title> <type> Master's thesis, </type> <institution> University of Cali-fornia, </institution> <address> Los Angeles, </address> <month> Mar. </month> <year> 1995. </year> <note> Available as UCLA technical report CSD-950007. </note>
Reference-contexts: Since consistency would be maintained optimistically, there are still scenarios where the attribute-only replicas are inconsistent; we therefore treat the replicas like a cache, and resort to a multi-level polling and cache-replacement solution if the cache is invalid <ref> [17] </ref>. Treating the attribute-only replicas like a cache means that there is zero overhead or performance impact on reconciliation. 3.5 Replication controls A volume-based replication service has a single policy with regard to file creation|all files are rep licated at all volume replicas, known as full replication. <p> The first-group is easily and optimistically calculated using local information (the status vector). Re-reconciling files as a member of other groups is not required for correctness, though doing so may propag ate information more quickly <ref> [17] </ref>. 4.1.4 Reconciliation details One replica pulls data from another, and in doing so learns all relevant knowledge stored at the source. A pull-based strategy is more general than a two-way communication model and provides support for predominantly one-way transport mechanisms such as floppy disks. <p> When one replica pulls a group of files from another, it detects and resolves possible discrepancies in group membership (caused by incomplete local information). The discrepancies (discussed more fully in <ref> [17] </ref>) could be caused by: * New file replicas (file creation or remote file replica addition) expected to be stored at the other replica * Files which have completed one of the two create/delete resolution algorithms (garbage collection and dropping-notification), and therefore no longer exist at one of the replicas Distinguishing <p> However, since garbage collection itself requires verifying that each participant has performed a specific action, the classification already exists, and the push mechanism can be easily implemented. Specific details on building the participant set, reaching consensus, and pushing data between replicas can be found in <ref> [17] </ref>. 5 Performance Evaluation This section describes the measurements, experiments, and benchmarks used to evaluate selective replication, as well as the results and conclusions which can be drawn from them. <p> Specifically, (95 + 20N) bytes are transferred for each file, which includes both Unix and Ficus attributes. This constitutes a 4N-byte increase above VFicus. Additionally, we employ a time-based optimization, reducing the number of files which must be analyzed <ref> [6, 17] </ref>. If the file is deemed unchanged since the last time the two replicas communicated, only 63 bytes are transferred.
Reference: [18] <author> P. Reiher, J. S. Heidemann, D. Ratner, G. Skinner, and G. J. Popek. </author> <title> Resolving file conflicts in the Ficus file system. </title> <booktitle> In USENIX Conference Proceedings, </booktitle> <pages> pages 183-195. </pages> <publisher> USENIX, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Additionally, the status vectors for each file need to be compared to gossip about status changes. The comparison is performed using the method described in Section 3.2. Finally, the "standard" reconciliation actions must be performed, such as version-vector comparisons, update propagation, and conflict-detection, discussed in <ref> [4, 14, 18] </ref>. 4.1.5 Optimization opportunities The multi-ring topology is clearly not ideal in all environments. A single ring is formed with all replicas as members, instead of, for example, utilizing the natural clusters formed by geographic location.
Reference: [19] <author> M. Satyanarayanan, J. H. Howard, D. A. Nichols, R. N. Sidebotham, A. Z. Spector, and M. J. West. </author> <title> The ITC distributed file system: </title> <booktitle> Principles and design. In Proceedings of the Tenth Symposium on Operating Systems Principles, </booktitle> <pages> pages 35-50. </pages> <publisher> ACM, </publisher> <month> Dec. </month> <year> 1985. </year>
Reference-contexts: Additionally, Ficus provides transparent access to remote replicas; users need not store a particular file or volume in order to access it. Ficus maintains data consistency with two separate 1 A volume is smaller than a file system but larger than a directory <ref> [19] </ref>. For example, a user's home directory and all subdirectories might constitute a volume. mechanisms. At update time, update notification messages are sent to all accessible replicas in a "one-time, best-effort" manner.
Reference: [20] <author> M. Satyanarayanan, J. J. Kistler, P. Kumar, M. E. Okasaki, E. H. Siegel, and D. C. Steere. Coda: </author> <title> A highly available file system for a distributed workstation environment. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(4) </volume> <pages> 447-459, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The need for optimistic replication in environments with variable, sporadic, unpredictable, or weak connectivity is already well known <ref> [4, 6, 7, 9, 20, 24] </ref>. Replication provides both improved performance and reliability through the creation of multiple replicas of important data objects; optimism allows replicas to be independently updated, and guarantees that concurrent fl This work was sponsored by the Advanced Research Projects Agency under contract N00174-91-C-0107. <p> Additional experience, however, is required. 6 Related Work A number of other replication services exist, each with different design choices, assumptions, and levels of service. We will discuss each system briefly. The Coda file system <ref> [9, 20] </ref> is an optimistically replicated file system constructed on a client-server model, as opposed to the peer architecture proposed by Ficus. 12 As such, Coda trivially provides selective-replication control at the clients, but not at the replicated servers, which are, by definition, peers.
Reference: [21] <author> A. Siegel. </author> <title> Performance in Flexible Distributed File Systems. </title> <type> Ph.D. dissertation, </type> <institution> Cornell, </institution> <month> Feb. </month> <year> 1992. </year> <note> Also available as Cornell technical report TR 92-1266. </note>
Reference-contexts: Ficus is working on similar methods of providing stronger consistency guarantees to users [3]. However, Bayou does not support any form of selective replication, so the databases (the Bayou replication unit) must be fully replicated at all storage sites. The Deceit file system <ref> [22, 21] </ref>, places all files into one "volume" and allows each individual file to be replicated independently with varying numbers of replicas. In this sense it provides selective replication.
Reference: [22] <author> A. Siegel, K. Birman, and K. Marzullo. Deceit: </author> <title> A flexible distributed file system. </title> <booktitle> In USENIX Conference Proceedings, </booktitle> <pages> pages 51-61. </pages> <publisher> USENIX, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Ficus is working on similar methods of providing stronger consistency guarantees to users [3]. However, Bayou does not support any form of selective replication, so the databases (the Bayou replication unit) must be fully replicated at all storage sites. The Deceit file system <ref> [22, 21] </ref>, places all files into one "volume" and allows each individual file to be replicated independently with varying numbers of replicas. In this sense it provides selective replication. <p> In this sense it provides selective replication. However, Deceit employs a conservative approach to replication, namely a writer-token mechanism, and as such cannot provide the high availability offered by optimistic mechanisms. In addition, Deceit cannot tolerate long-term network partitions; instead, only a related failure known as a virtual partition <ref> [22] </ref>, which eventually corrects itself, is tolerated. The university LOCUS operating system [16, 25] provides volumes and allows selective replication within the volume. However, the approach taken toward replication is not strictly optimistic.
Reference: [23] <author> D. Terry, A. Demers, K. Petersen, M. Spreitzer, M. Theimer, and B. Welch. </author> <title> Session guarantees for weakly consistent replicated data. </title> <booktitle> In Proceedings of the Third International Conference on Parallel and Distributed Information Systems, </booktitle> <pages> pages 140-149, </pages> <month> sep </month> <year> 1994. </year>
Reference-contexts: Like Ficus, Bayou provides support for application-dependent resolution of conflicts. However, unlike Ficus, Bayou does not attempt to provide transparent conflict detection. Applications must specify a condition that determines when a conflicting access has been made, and must specify the particular resolution process. Bayou provides session guarantees <ref> [23] </ref> to improve the perceived consistency by users. Additionally, Bayou establishes strong guarantees about its data| writes can be classified either as committed or tentative. Ficus is working on similar methods of providing stronger consistency guarantees to users [3].
Reference: [24] <author> D. B. Terry, M. M. Theimer, K. Petersen, A. J. De-mers, M. J. Spreitzer, and C. H. Hauser. </author> <title> Managing update conflicts in bayou, a weakly connected replicated storage system. </title> <booktitle> In Proceedings of the 15th Symposium on Operating Systems Principles, </booktitle> <pages> pages 172-183, </pages> <address> Copper Mountain Resort, Colorado, </address> <month> Dec. </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: 1 Introduction The need for optimistic replication in environments with variable, sporadic, unpredictable, or weak connectivity is already well known <ref> [4, 6, 7, 9, 20, 24] </ref>. Replication provides both improved performance and reliability through the creation of multiple replicas of important data objects; optimism allows replicas to be independently updated, and guarantees that concurrent fl This work was sponsored by the Advanced Research Projects Agency under contract N00174-91-C-0107. <p> First, peer functionality is important, evidenced by the rise of mobile use. Mobility by its very nature requires peer capabilities; for example, mobile workgroups. A number of research projects are investigating peer usage, such as xFS in the NOW project [1] and the Bayou system <ref> [24] </ref>. Second, we expected that 1 modifying a fundamentally client-server design to in-corporate a rich communications structure would require such basic structural changes as to imply effectively starting from scratch. Adding selective control to a peer model ought to better preserve the underlying framework. We call our solution selective replication. <p> However, again clients cannot intercommunicate, hindering the usability of the system. Additionally, the method used to populate the client with the necessary data is suboptimal compared to other strategies [10, 11]. The Bayou system <ref> [24] </ref> is also a replicated storage system, but based on the peer-to-peer architecture. Like Ficus, Bayou provides support for application-dependent resolution of conflicts. However, unlike Ficus, Bayou does not attempt to provide transparent conflict detection.
Reference: [25] <author> B. Walker, G. Popek, R. English, C. Kline, and G. Thiel. </author> <title> The LOCUS distributed operating system. </title> <booktitle> In Proceedings of the Ninth Symposium on Operating Systems Principles, </booktitle> <pages> pages 49-70. </pages> <publisher> ACM, </publisher> <month> Oct. </month> <year> 1983. </year>
Reference-contexts: In addition, Deceit cannot tolerate long-term network partitions; instead, only a related failure known as a virtual partition [22], which eventually corrects itself, is tolerated. The university LOCUS operating system <ref> [16, 25] </ref> provides volumes and allows selective replication within the volume. However, the approach taken toward replication is not strictly optimistic.
Reference: [26] <author> B. Welch and J. Ousterhout. </author> <title> Prefix tables: A simple mechanism for locating files in a distributed system. </title> <booktitle> Sixth International Conference on Distributed Computing Systems, </booktitle> <pages> pages 184-189, </pages> <month> May 19-23, </month> <year> 1986. </year> <month> 14 </month>
Reference-contexts: To store the invited talk (talk.tex) and the week's mail (Mail), the professor must store the intermediate directories (Reports, Current, Personal). However, there is no need for any files under Src, Misc, or Old, so these subtrees are not stored locally. A common alternate solution employs "prefix pointers" <ref> [26] </ref>, a second directory structure used to connect the user's disconnected namespace. While prefix-pointer solutions avoid storing intermediate directories, they must maintain an independent directory structure and integrate it into the user's namespace. Full back-storing avoids the complexity of dual directory structures, and is therefore simpler to implement.
References-found: 26

