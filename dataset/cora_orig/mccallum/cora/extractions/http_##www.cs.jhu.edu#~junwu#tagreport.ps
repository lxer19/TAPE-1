URL: http://www.cs.jhu.edu/~junwu/tagreport.ps
Refering-URL: http://www.cs.jhu.edu/~junwu/
Root-URL: http://www.cs.jhu.edu
Title: Using Multiple Taggers to Improve English Part-of-Speech Tagging by Error Learning  
Author: Jun Wu Advisor: Prof. Eric Brill 
Date: May 8, 1997  
Address: 3400 N. Charles Street Baltimore, MD 21211  
Affiliation: Department of Computer Science Johns Hopkins University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Eric Brill, </author> <title> A simple rule-based part of speech tagger, </title> <booktitle> Proc. of the 3rd conf. on Applied Natural Language Processing, </booktitle> <pages> pp. 152-155, </pages> <address> Trento, Italy, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction There are various approaches to Part-of-Speech tagging, and their results are all around 96-97% <ref> [1, 2, 3, 6] </ref>. It is really difficult to make further improvement on this level by using one approach alone. However, the errors produced by different taggers are not fully overlapped, so combining several taggers together and using different ones in different cases may improve the tagging result. <p> The reason may be that the information of t i+1 i1 is already used in trigram model. 7 3 Combining Rule-Based Tagger with Stochastic One 3.1 Rule-Based Tagger and Trigram Tagger It is reasonable to suggest that rule-based tagger <ref> [1, 2] </ref> and stochastic one have better complementary effect since they use information in different ways. Both taggers were trained on the training set, and both achieved an accuracy of 96.4% on the test set. The complementary rate of rule-based tagger vs trigram tagger is 38.8% and vice versa.
Reference: [2] <author> Eric Brill, </author> <title> Some advances in transformation-based part of speech tagging, </title> <booktitle> Proc. of 12th National Conf on AI, Vol.1, </booktitle> <address> pp.722-727, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction There are various approaches to Part-of-Speech tagging, and their results are all around 96-97% <ref> [1, 2, 3, 6] </ref>. It is really difficult to make further improvement on this level by using one approach alone. However, the errors produced by different taggers are not fully overlapped, so combining several taggers together and using different ones in different cases may improve the tagging result. <p> The reason may be that the information of t i+1 i1 is already used in trigram model. 7 3 Combining Rule-Based Tagger with Stochastic One 3.1 Rule-Based Tagger and Trigram Tagger It is reasonable to suggest that rule-based tagger <ref> [1, 2] </ref> and stochastic one have better complementary effect since they use information in different ways. Both taggers were trained on the training set, and both achieved an accuracy of 96.4% on the test set. The complementary rate of rule-based tagger vs trigram tagger is 38.8% and vice versa.
Reference: [3] <author> Eugene Charniak et al, </author> <title> Equations for part-of-speech tagging, Statistically based NLP, </title> <booktitle> Proc. of 11th National Conf. on AI, </booktitle> <address> pp.784-789, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction There are various approaches to Part-of-Speech tagging, and their results are all around 96-97% <ref> [1, 2, 3, 6] </ref>. It is really difficult to make further improvement on this level by using one approach alone. However, the errors produced by different taggers are not fully overlapped, so combining several taggers together and using different ones in different cases may improve the tagging result.
Reference: [4] <author> Frederick Jelinek, </author> <title> Self-organized language model for speech recognition, Readings in SR, </title> <editor> A. Waibel and K.F. Lee eds, pp450-506, </editor> <publisher> Morgan-Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: We use interpolation <ref> [4] </ref> for both bigram and trigram models for dealing with unseen events. The interpolation parameters are trained by Brown corpus and applied to both Brown and WSJ corpus. (Back-off method [5] provides the same results.) 2.2 Combining Taggers Table 3 gives the number of common errors of some tagger pairs.
Reference: [5] <author> S. Katz, </author> <title> Estimation of probabilities from sparse data for the language model component of a speech recognizer, </title> <journal> IEEE, Trans on ASSP Vol.35, No.3, </journal> <volume> pp400-401, </volume> <month> March, </month> <year> 1987. </year>
Reference-contexts: We use interpolation [4] for both bigram and trigram models for dealing with unseen events. The interpolation parameters are trained by Brown corpus and applied to both Brown and WSJ corpus. (Back-off method <ref> [5] </ref> provides the same results.) 2.2 Combining Taggers Table 3 gives the number of common errors of some tagger pairs. Table 4 and table 5 give the complementary rates of taggers in row vs. taggers in column.
Reference: [6] <author> Adwait Ratnaparkhi, </author> <title> A maximum entropy model for part-of-speech tagging, </title> <booktitle> Proc. of Empirical methods in Natural Language Processing Conf. </booktitle> <institution> pp133-142, Univ. of Pennsylvania, </institution> <year> 1996. </year> <month> 17 </month>
Reference-contexts: 1 Introduction There are various approaches to Part-of-Speech tagging, and their results are all around 96-97% <ref> [1, 2, 3, 6] </ref>. It is really difficult to make further improvement on this level by using one approach alone. However, the errors produced by different taggers are not fully overlapped, so combining several taggers together and using different ones in different cases may improve the tagging result.
References-found: 6

