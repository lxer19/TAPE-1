URL: http://www.cs.wustl.edu/cs/techreports/1994/wucs-94-24.ps.Z
Refering-URL: http://www.cs.wustl.edu/cs/cs/publications.html
Root-URL: 
Title: Performance Comparison of Asynchronous Adders  
Author: Mark A. Franklin and Tienyo Pan 
Address: St. Louis, MO 63130  
Affiliation: Computer and Communication Research Center Washington University  
Abstract: In asynchronous systems, average function delays principally govern overall throughput. This paper compares the performance of six adder designs with respect to their average delays. Our results show that asynchronous adders (32 or 64-bits) with a hybrid structure (e.g., carry-select adders) run 20-40% faster than simple ripple-carry adders. Hybrid adders also outperform high-cost, strictly synchronous conditional-sum adders. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O.J. Bedrij. </author> <title> Carry-Select Adder. </title> <journal> IRE Trans. Electronic Computers, </journal> <volume> 11 </volume> <pages> 340-346, </pages> <month> June </month> <year> 1962. </year>
Reference-contexts: Sklan-sky [15] developed a strictly synchronous technique (conditional sum) which has O (log n) maximum delay, and Winograd [19] showed that with this technique the lower bound (on maximum delay) on addition is achievable. Other adder designs also have O (log n) maximum delays <ref> [18, 1, 10] </ref>. Ling also proposed a high-performance adder that employs wired-OR circuits [17]. Compared with the studies of maximum delays which have been motivated by the requirements of clocked system design, research on average delays which affect the performance of asynchronous systems has been less extensive. <p> The fastest way to collect this information is by utilizing a tree structure which yields an O (log n) delay. Most high-speed adders, such as carry-lookahead [18], conditional-sum [15], carry-skip [10], and carry-select <ref> [1] </ref>, are forms of tree structures. The main drawback associated with such structures is the O (n log n) size required. Hybrid structures are midway between serial and tree structures both in terms of worst case delay and size.
Reference: [2] <author> B.E. Briley. </author> <title> Some New Results on Average Worst Case Carry. </title> <journal> IEEE Trans. Computers, </journal> <volume> 22 </volume> <pages> 459-463, </pages> <month> May </month> <year> 1973. </year>
Reference-contexts: Burks, Goldstine, and von Neumann [3] have showed that for a ripple-carry addition of two n-bit operands chosen at random, the mean of the longest carry sequence is bounded from above by log 2 n. Briley <ref> [2] </ref> further tightened this bound to log 2 n 0:5. In this work only nonzero carry propagation is considered, however, when dealing with asynchronous self-timing addition, propagations of both zero and nonzero carries must be considered. <p> Table 1: Average and Maximum delays of DCVSL cells (1:2 technology) Function Boolean function Delay (ns) name Average maximum Carry ab + bc + ca 1.44 1.62 Sum a b c 1.49 1.56 Bypass g + pc 1.15 1.33 Multiplexor sa + sb 1.23 1.31 Propagate <ref> [2] </ref> (a 1 + b 1 ) (a 0 + b 0 ) 1.23 1.32 Propagate [3] (a 2 + b 2 ) propagate [2] 1.36 1.69 Propagate [4] (a 3 + b 3 ) propagate [3] 1.43 2.08 Generate [2] a 1 b 1 + (a 1 + b 1 <p> ab + bc + ca 1.44 1.62 Sum a b c 1.49 1.56 Bypass g + pc 1.15 1.33 Multiplexor sa + sb 1.23 1.31 Propagate <ref> [2] </ref> (a 1 + b 1 ) (a 0 + b 0 ) 1.23 1.32 Propagate [3] (a 2 + b 2 ) propagate [2] 1.36 1.69 Propagate [4] (a 3 + b 3 ) propagate [3] 1.43 2.08 Generate [2] a 1 b 1 + (a 1 + b 1 ) a 0 b 0 1.52 1.77 Generate [3] a 2 b 2 + (a 2 + b 2 ) generate [2] 1.59 2.22 <p> pc 1.15 1.33 Multiplexor sa + sb 1.23 1.31 Propagate <ref> [2] </ref> (a 1 + b 1 ) (a 0 + b 0 ) 1.23 1.32 Propagate [3] (a 2 + b 2 ) propagate [2] 1.36 1.69 Propagate [4] (a 3 + b 3 ) propagate [3] 1.43 2.08 Generate [2] a 1 b 1 + (a 1 + b 1 ) a 0 b 0 1.52 1.77 Generate [3] a 2 b 2 + (a 2 + b 2 ) generate [2] 1.59 2.22 Generate [4] a 3 b 3 + (a 3 + b 3 ) generate [3] 1.16 <p> ) propagate <ref> [2] </ref> 1.36 1.69 Propagate [4] (a 3 + b 3 ) propagate [3] 1.43 2.08 Generate [2] a 1 b 1 + (a 1 + b 1 ) a 0 b 0 1.52 1.77 Generate [3] a 2 b 2 + (a 2 + b 2 ) generate [2] 1.59 2.22 Generate [4] a 3 b 3 + (a 3 + b 3 ) generate [3] 1.16 2.27 exactly log 2 n levels. This is the reason that RCA and CSA have parallel curves, and the RCA curve is higher.
Reference: [3] <author> A.W. Burks, H.H. Goldstine, and J. von Neumann. </author> <title> Preliminary Discussion of the Logical Design of an Electronic Computing Instrument. </title> <booktitle> In Papers of John von Neumann on Computing and Computer Theory, </booktitle> <pages> pages 97-142. </pages> <publisher> The MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: However, since each digit with the "a = b" condition terminates the carry chain, the worst case is unlikely to happen. Burks, Goldstine, and von Neumann <ref> [3] </ref> have showed that for a ripple-carry addition of two n-bit operands chosen at random, the mean of the longest carry sequence is bounded from above by log 2 n. Briley [2] further tightened this bound to log 2 n 0:5. <p> Boolean function Delay (ns) name Average maximum Carry ab + bc + ca 1.44 1.62 Sum a b c 1.49 1.56 Bypass g + pc 1.15 1.33 Multiplexor sa + sb 1.23 1.31 Propagate [2] (a 1 + b 1 ) (a 0 + b 0 ) 1.23 1.32 Propagate <ref> [3] </ref> (a 2 + b 2 ) propagate [2] 1.36 1.69 Propagate [4] (a 3 + b 3 ) propagate [3] 1.43 2.08 Generate [2] a 1 b 1 + (a 1 + b 1 ) a 0 b 0 1.52 1.77 Generate [3] a 2 b 2 + (a 2 <p> 1.56 Bypass g + pc 1.15 1.33 Multiplexor sa + sb 1.23 1.31 Propagate [2] (a 1 + b 1 ) (a 0 + b 0 ) 1.23 1.32 Propagate <ref> [3] </ref> (a 2 + b 2 ) propagate [2] 1.36 1.69 Propagate [4] (a 3 + b 3 ) propagate [3] 1.43 2.08 Generate [2] a 1 b 1 + (a 1 + b 1 ) a 0 b 0 1.52 1.77 Generate [3] a 2 b 2 + (a 2 + b 2 ) generate [2] 1.59 2.22 Generate [4] a 3 b 3 + (a 3 + b 3 <p> + b 0 ) 1.23 1.32 Propagate <ref> [3] </ref> (a 2 + b 2 ) propagate [2] 1.36 1.69 Propagate [4] (a 3 + b 3 ) propagate [3] 1.43 2.08 Generate [2] a 1 b 1 + (a 1 + b 1 ) a 0 b 0 1.52 1.77 Generate [3] a 2 b 2 + (a 2 + b 2 ) generate [2] 1.59 2.22 Generate [4] a 3 b 3 + (a 3 + b 3 ) generate [3] 1.16 2.27 exactly log 2 n levels. <p> Generate [2] a 1 b 1 + (a 1 + b 1 ) a 0 b 0 1.52 1.77 Generate <ref> [3] </ref> a 2 b 2 + (a 2 + b 2 ) generate [2] 1.59 2.22 Generate [4] a 3 b 3 + (a 3 + b 3 ) generate [3] 1.16 2.27 exactly log 2 n levels. This is the reason that RCA and CSA have parallel curves, and the RCA curve is higher. Completion detection conditional sum adder (CDA) has the best performance among the six due to its O (log 2 log 2 n) average delay.
Reference: [4] <author> M.A. Franklin and T. Pan. </author> <title> Clocked and asynchronous instruction pipelines. </title> <booktitle> In Proc. 26th ACM/IEEE Symp. on Microarchitecture, </booktitle> <address> Austin, TX, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: Our research focuses on issues of speed. An analytical model that compares the speeds of clocked and asynchronous systems based on a pipelined architecture has been proposed by the authors <ref> [4] </ref>. This model can be simplified and described as follows: Cycle time = t comp + t sync (1) For both clocked and asynchronous systems, a processing cycle Cycle time, consists of the computation time, t comp , and the synchronization time, t sync . <p> ca 1.44 1.62 Sum a b c 1.49 1.56 Bypass g + pc 1.15 1.33 Multiplexor sa + sb 1.23 1.31 Propagate [2] (a 1 + b 1 ) (a 0 + b 0 ) 1.23 1.32 Propagate [3] (a 2 + b 2 ) propagate [2] 1.36 1.69 Propagate <ref> [4] </ref> (a 3 + b 3 ) propagate [3] 1.43 2.08 Generate [2] a 1 b 1 + (a 1 + b 1 ) a 0 b 0 1.52 1.77 Generate [3] a 2 b 2 + (a 2 + b 2 ) generate [2] 1.59 2.22 Generate [4] a 3 <p> 1.69 Propagate <ref> [4] </ref> (a 3 + b 3 ) propagate [3] 1.43 2.08 Generate [2] a 1 b 1 + (a 1 + b 1 ) a 0 b 0 1.52 1.77 Generate [3] a 2 b 2 + (a 2 + b 2 ) generate [2] 1.59 2.22 Generate [4] a 3 b 3 + (a 3 + b 3 ) generate [3] 1.16 2.27 exactly log 2 n levels. This is the reason that RCA and CSA have parallel curves, and the RCA curve is higher. <p> This speed is worse than its asynchronous counterpart. However, this comparison only includes instruction-dependent and data-dependent parameters. Environmental parameters and synchronization times need to be considered to gain a more accurate comparison of the two design methodologies <ref> [4] </ref>. In addition, power issues may well be an important factor in determining the suitability of asynchronous versus clocked processor designs. 6 Conclusions In this paper, six adder designs are studied, and their influence on asynchronous system performance are compared.
Reference: [5] <author> J.D. Garside. </author> <title> A CMOS VLSI Implementation of an Asynchronous ALU. </title> <booktitle> In Proc. IFIP Conf. on Asynchronous Design Methodologies, </booktitle> <address> Manchester, Eng-land, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: Asynchronous techniques permit one to focus on the functional and logical sequencing aspects of design and not on such global issues thus making the design task more manageable. Third, asynchronous systems require less power than clocked systems since unused modules in asynchronous systems do not require charging/discharging <ref> [5] </ref>. Finally, the clock period in a clocked system is generally based on the worst case time for component functional units. In asynchronous systems, however, average function delays may govern overall throughput rates thus potentially resulting in higher performance. <p> Average RCA delay is larger than log 2 n according to Hendrickson's result [6], but CSA delay is 2 The assumption of random operand selections is for the simplicity and generality of our models. At least one study <ref> [5] </ref> has indicated that carry chain distributions produced by real code has a somewhat higher mean than that obtained from a random model.
Reference: [6] <author> H.C. Hendrickson. </author> <title> Fast High-Accuracy Binary Parallel Addition. </title> <journal> IRE Trans. Electronic Computers, </journal> <volume> 9 </volume> <pages> 465-469, </pages> <month> December </month> <year> 1960. </year>
Reference-contexts: Briley [2] further tightened this bound to log 2 n 0:5. In this work only nonzero carry propagation is considered, however, when dealing with asynchronous self-timing addition, propagations of both zero and nonzero carries must be considered. Reitwiesner [14] and Hendrickson <ref> [6] </ref> deal with both zero and nonzero carries and develop a more accurate model for the asynchronous ripple-carry addition. Hendrickson also shows (experimentally) that the average length of the longest carry sequence can be approximated by log 2 (5n=4). <p> Figures 5 shows the simulated average delays of the six adder designs. Ripple-carry adder (RCA) and conditional-sum adder (CSA) both have O (log 2 n) delays. Average RCA delay is larger than log 2 n according to Hendrickson's result <ref> [6] </ref>, but CSA delay is 2 The assumption of random operand selections is for the simplicity and generality of our models. At least one study [5] has indicated that carry chain distributions produced by real code has a somewhat higher mean than that obtained from a random model.
Reference: [7] <author> J.L. Hennessy and D.A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Palo Alto, CA, </address> <year> 1990. </year>
Reference-contexts: In general, more frequently used modules have greater influences on overall performance. Statistics presented in <ref> [7] </ref> show that in a prototypical RISC machine (DLX), 72% of the instructions perform additions (or subtractions) in the data path. In addition to ADD/SUB instructions (24%), branch (17%) and memory-access (31%) instructions which require calculations of target addresses or effective addresses also use adders. <p> In this case the block carry output is equal to the block carry input. Finally, the (P,G) = (0,1) state is not allowed. When the number of bits for each block are properly adjusted, the maximum delays of hybrid adders are O ( p n) <ref> [7] </ref> while their sizes remain O (n). Although many adder designs have been originally proposed with tree structures, they are often implemented as hybrid structures since for practical values of n, the O ( p n) delay is comparable to O (log n). <p> type (%) IF ID EX MA WB branch 20 3/10 Add 0 0 0 Add/Sub 25 3/10 3 Add 3 3 logical 25 3/10 3 3 3 3 memory 30 3/10 3 Add 10 3 ciated with each instruction type are found in Table 4 along with their execution probabilities <ref> [7] </ref>. Delays associated with all stages are 3 ns, except when a cache access is involved. In this case the time is 10 ns. Delay distributions of the adders (ADD) are obtained from second level adder simulations (Tables 2 and 3).
Reference: [8] <author> K. Hwang. </author> <title> Computer Arithmetic: </title> <booktitle> Principles, Architecture, and Design. </booktitle> <publisher> Wiley, </publisher> <year> 1979. </year>
Reference-contexts: The overall sum is obtained by continuing this process through a full log 2 n levels. CSA has a tree structure and takes a constant amount of time to complete (O (log 2 n)). Since conditional-sum adders are considered one of the fastest adders (for clocked design) <ref> [8, 17] </ref>, it is chosen in this paper to roughly represent the performance of clocked adders. 3. Completion detection conditional sum adder (CDA) is a modified form of CSA [11].
Reference: [9] <author> Z. Kohavi. </author> <title> Switching and Finite Automata Theory. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: In addition to ADD/SUB instructions (24%), branch (17%) and memory-access (31%) instructions which require calculations of target addresses or effective addresses also use adders. Thus, performance of asynchronous RISC processors is significantly influenced by the adder speed. Addition can be implemented using iterative networks <ref> [9] </ref> with breakable carry chains. That is, in any digit position i, if the two operand bits a i 6= b i , the carry output of this digit is propagated from its carry input.
Reference: [10] <author> M. Lehman and N. Burla. </author> <title> Skip Techniques for High-Speed Carry-Propagation in Binary Arithmetic Units. </title> <journal> IRE Trans. Electronic Computers, </journal> <volume> 10 </volume> <pages> 691-698, </pages> <month> De-cember </month> <year> 1961. </year>
Reference-contexts: Sklan-sky [15] developed a strictly synchronous technique (conditional sum) which has O (log n) maximum delay, and Winograd [19] showed that with this technique the lower bound (on maximum delay) on addition is achievable. Other adder designs also have O (log n) maximum delays <ref> [18, 1, 10] </ref>. Ling also proposed a high-performance adder that employs wired-OR circuits [17]. Compared with the studies of maximum delays which have been motivated by the requirements of clocked system design, research on average delays which affect the performance of asynchronous systems has been less extensive. <p> The fastest way to collect this information is by utilizing a tree structure which yields an O (log n) delay. Most high-speed adders, such as carry-lookahead [18], conditional-sum [15], carry-skip <ref> [10] </ref>, and carry-select [1], are forms of tree structures. The main drawback associated with such structures is the O (n log n) size required. Hybrid structures are midway between serial and tree structures both in terms of worst case delay and size.
Reference: [11] <author> N.M. Martin and S.P. Hufnagel. </author> <title> Conditional-Sum Early Completion Adder Logic. </title> <journal> IEEE Trans. on Com-put., </journal> <volume> C-29(8):753-756, </volume> <month> August </month> <year> 1980. </year>
Reference-contexts: Since conditional-sum adders are considered one of the fastest adders (for clocked design) [8, 17], it is chosen in this paper to roughly represent the performance of clocked adders. 3. Completion detection conditional sum adder (CDA) is a modified form of CSA <ref> [11] </ref>. The modification gives the adder more of an asyn-chronous flavor by providing detection logic indicating the availability of true sum at each level. When the true sum is available, it is latched and the computation is completed. Thus, the full tree delay is often avoided.
Reference: [12] <author> C. Mead and L. Conway. </author> <title> Introduction to VLSI Systems, chapter 7. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1980. </year>
Reference-contexts: Naturally, the potential advantages associated with asynchronous design are subject to a host of qualifications, and are the subject of research and debate. The principal drawbacks associated with asynchronous designs are three fold. First, if dual-rail encoding is employed to generate completion signals <ref> [12, 13] </ref>, increased chip area is needed to implement the complementary logic, completion detectors, and the routing of differential input and output lines. Second, completion detection and handshaking requirements add extra overhead to asynchronous systems computation delays. These are analogous to the clocking overheads associated with synchronous systems.
Reference: [13] <author> T.H. Meng. </author> <title> Synchronization Design for Digital Systems. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1991. </year>
Reference-contexts: Naturally, the potential advantages associated with asynchronous design are subject to a host of qualifications, and are the subject of research and debate. The principal drawbacks associated with asynchronous designs are three fold. First, if dual-rail encoding is employed to generate completion signals <ref> [12, 13] </ref>, increased chip area is needed to implement the complementary logic, completion detectors, and the routing of differential input and output lines. Second, completion detection and handshaking requirements add extra overhead to asynchronous systems computation delays. These are analogous to the clocking overheads associated with synchronous systems. <p> A completion signal may be produced from the two complementary outputs. Other logic functions (cells) required by the adders can be formed in a similar fashion and all of the cells may be precharged and requested concurrently. DCVSL details may be found in <ref> [13] </ref>. Finding the average delay of an adder requires a large number of test operands. The most straightforward way to do this is to perform a VLSI circuit layout, and then simulate the circuit a large number of times with different operand values.
Reference: [14] <author> G.W. Reitwiesner. </author> <title> The Determination of Carry-Propagation Length for Binary Addition. </title> <journal> IRE Trans. Electronic Computers, </journal> <volume> 9 </volume> <pages> 35-38, </pages> <month> March </month> <year> 1960. </year>
Reference-contexts: Briley [2] further tightened this bound to log 2 n 0:5. In this work only nonzero carry propagation is considered, however, when dealing with asynchronous self-timing addition, propagations of both zero and nonzero carries must be considered. Reitwiesner <ref> [14] </ref> and Hendrickson [6] deal with both zero and nonzero carries and develop a more accurate model for the asynchronous ripple-carry addition. Hendrickson also shows (experimentally) that the average length of the longest carry sequence can be approximated by log 2 (5n=4).
Reference: [15] <author> J. Sklansky. </author> <title> Conditional-Sum Addition Logic. </title> <journal> IRE Trans. Electronic Computers, </journal> <volume> 9 </volume> <pages> 226-231, </pages> <month> June </month> <year> 1960. </year>
Reference-contexts: The O (n) maximum delay for ripple-carry addition makes this design impractical in high performance clocked systems, and consequently much of the work on adders used in this environment have focused on techniques to reduce this maximum delay. Sklan-sky <ref> [15] </ref> developed a strictly synchronous technique (conditional sum) which has O (log n) maximum delay, and Winograd [19] showed that with this technique the lower bound (on maximum delay) on addition is achievable. Other adder designs also have O (log n) maximum delays [18, 1, 10]. <p> The fastest way to collect this information is by utilizing a tree structure which yields an O (log n) delay. Most high-speed adders, such as carry-lookahead [18], conditional-sum <ref> [15] </ref>, carry-skip [10], and carry-select [1], are forms of tree structures. The main drawback associated with such structures is the O (n log n) size required. Hybrid structures are midway between serial and tree structures both in terms of worst case delay and size.
Reference: [16] <author> D.F. Wann and M.A. Franklin. </author> <title> Asynchronous and Clocked Control Structures for VLSI Based Interconnection Networks. </title> <journal> IEEE Trans. Comput., </journal> <pages> pages 284-293, </pages> <month> March </month> <year> 1983. </year>
Reference-contexts: First, as clocked systems increase in size, clock skew increases and inevitably limits clock rate. The equivalent delay is not present in asynchronous systems (although other delays are present) <ref> [16] </ref>. Second, hierarchical, modular design techniques are generally ill suited to handling global design constraints such as clock distribution. Asynchronous techniques permit one to focus on the functional and logical sequencing aspects of design and not on such global issues thus making the design task more manageable.
Reference: [17] <author> S. Waser and M. Flynn. </author> <title> Introduction to Arithmetic for Digital System Designers. </title> <publisher> CBS College Pub., </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Other adder designs also have O (log n) maximum delays [18, 1, 10]. Ling also proposed a high-performance adder that employs wired-OR circuits <ref> [17] </ref>. Compared with the studies of maximum delays which have been motivated by the requirements of clocked system design, research on average delays which affect the performance of asynchronous systems has been less extensive. This paper studies several design alternatives for adders operating in an asynchronous environment. <p> The overall sum is obtained by continuing this process through a full log 2 n levels. CSA has a tree structure and takes a constant amount of time to complete (O (log 2 n)). Since conditional-sum adders are considered one of the fastest adders (for clocked design) <ref> [8, 17] </ref>, it is chosen in this paper to roughly represent the performance of clocked adders. 3. Completion detection conditional sum adder (CDA) is a modified form of CSA [11].
Reference: [18] <author> A. Weinberger and J.L. Smith. </author> <title> A Logic for High-Speed Addition. </title> <editor> In E.E. Swartzlander, editor, </editor> <booktitle> Computer Arithmetic, </booktitle> <pages> pages 47-56. </pages> <note> Dowden, </note> <author> Hutchinson and Ross, </author> <year> 1980. </year>
Reference-contexts: Sklan-sky [15] developed a strictly synchronous technique (conditional sum) which has O (log n) maximum delay, and Winograd [19] showed that with this technique the lower bound (on maximum delay) on addition is achievable. Other adder designs also have O (log n) maximum delays <ref> [18, 1, 10] </ref>. Ling also proposed a high-performance adder that employs wired-OR circuits [17]. Compared with the studies of maximum delays which have been motivated by the requirements of clocked system design, research on average delays which affect the performance of asynchronous systems has been less extensive. <p> The fastest way to collect this information is by utilizing a tree structure which yields an O (log n) delay. Most high-speed adders, such as carry-lookahead <ref> [18] </ref>, conditional-sum [15], carry-skip [10], and carry-select [1], are forms of tree structures. The main drawback associated with such structures is the O (n log n) size required. Hybrid structures are midway between serial and tree structures both in terms of worst case delay and size.
Reference: [19] <author> S. Winograd. </author> <title> On the Time Required to Perform Addition. </title> <journal> JACM, </journal> <volume> 12(2) </volume> <pages> 277-285, </pages> <month> April </month> <year> 1965. </year>
Reference-contexts: Sklan-sky [15] developed a strictly synchronous technique (conditional sum) which has O (log n) maximum delay, and Winograd <ref> [19] </ref> showed that with this technique the lower bound (on maximum delay) on addition is achievable. Other adder designs also have O (log n) maximum delays [18, 1, 10]. Ling also proposed a high-performance adder that employs wired-OR circuits [17].
References-found: 19

