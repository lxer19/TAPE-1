URL: http://www.cs.utexas.edu/users/cpg/pub/94-AIRTC.ps.gz
Refering-URL: http://www.cs.utexas.edu/users/cpg/pub/abs.html
Root-URL: 
Title: ACHIEVING HIGH PERFORMANCE SONAR-BASED WALL-FOLLOWING  
Author: Carlos Puchol 
Keyword: Robotics, Navigation, Mapping, Real-Time Control  
Address: Austin, TX 78712-1188. USA  
Affiliation: Department of Computer Sciences The University of Texas at Austin  
Abstract: In this paper we develop a technique to achieve robust high performance real-time wall-following behavior of a mobile robot in an indoor office environment, more specifically, in a corridor environment. The mobile robot achieves increasingly better performance by learning the environment's (most important) features in successive runs through it. This allows the robot to perform the task repeatedly, reliably, increasing the speed at which it is done after every step, without losing accuracy. We are basing our approach in the Spatial Semantic Hierarchy [Kuipers et. al. 1993]. 
Abstract-found: 1
Intro-found: 1
Reference: [Kuipers et. al. 1993] <author> Kuipers, B. J., Froom, R., Lee, W-Y., and Pierce, D. </author> <title> The Semantic Hierarchy Approach to Robot Learning. </title> <editor> In Connell, J. and Mahadevan, S. (Eds.) </editor> <title> Robot Learning. </title> <publisher> Kluwer Academic, </publisher> <year> 1993. </year>
Reference-contexts: To be able to achieve high performance, we decompose the problem and map it into the layers of the Spatial Semantic Hierarchy (SSH) <ref> [Kuipers et. al. 1993] </ref>. By using the word track, we are introducing the problem as one of maintaining some measure associated with the object, while the subject or the object, or both are in motion.
Reference: [Leonard et. al. 1992] <author> Leonard, J., and Durrant-Whyte, H. </author> <title> Directed Sonar Sensing for Mobile Robot Navigation. </title> <publisher> Kluwer Academic, </publisher> <year> 1992. </year>
Reference-contexts: Objects, like tables and chairs are placed in the environment. However we rely on the 2-D assumption, i.e. the three dimensional geometry of the environment is orthogonal to the plane of the sensory horizon of the robot <ref> [Leonard et. al. 1992] </ref>. Another assumption that we impose in the environment is that the features in it are stationary while the robot is performing the exploration. Again, our goal is to establish a performance measure of the behavior in the restricted, known environment described above. <p> The base has its own 68HC11-based microcontroller board, which communicates with the 68000 board through a serial channel. The Sonar Sensor Model The sonar sensor model used is a simplification of the theoretical model introduced in <ref> [Leonard et. al. 1992] </ref> for our task and environment conditions. <p> Initially, the robot is left in the corridor, without any knowledge of what its position is with respect to the environment. 1 The definition of strong returns and weak returns can be found in <ref> [Leonard et. al. 1992] </ref> as well. Fundamentally, the later can be due to specularities, in a short-range sensing mode. <p> To do this, we have implemented a discrete PD regulator to locate the body of the vehicle as parallel as possible to the wall. Achieving High Performance Behavior As pointed out in <ref> [Leonard et. al. 1992] </ref>, navigating at higher speeds always demands some degree of anticipation and capacity of reaction. We argue that the rate at which the sonar observations with appropriate filtering can be taken using the low-cost off-the-shelf technology currently available (e.g. <p> These features in the system practically limit our speed to about 180mm=s. At higher speeds and using a direct control algorithm, the behavior of the robot becomes unstable. Were we to discern the regions of constant depth as defined in <ref> [Leonard et. al. 1992] </ref> with our current hardware, the robot would have to perform many slight rotations to achieve a similar degree of resolution, which would take a significant amount of time, severely limiting our speed.
References-found: 2

