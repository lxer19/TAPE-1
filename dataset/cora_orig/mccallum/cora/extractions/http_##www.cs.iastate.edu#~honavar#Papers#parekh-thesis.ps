URL: http://www.cs.iastate.edu/~honavar/Papers/parekh-thesis.ps
Refering-URL: http://www.cs.iastate.edu/~honavar/homepage.html
Root-URL: http://www.cs.iastate.edu
Title: Constructive learning: Inducing grammars and neural networks  
Author: by Rajesh Girish Parekh Major Professor: Vasant G. Honavar 
Degree: A dissertation submitted to the graduate faculty in partial fulfillment of the requirements for the degree of DOCTOR OF PHILOSOPHY Major: Computer Science  
Note: Copyright c Rajesh Girish Parekh, 1998. All rights reserved.  
Date: 1998  
Address: Ames, Iowa  
Affiliation: Iowa State University  
Abstract-found: 0
Intro-found: 1
Reference: [Ang78] <author> D. Angluin. </author> <title> On the complexity of minimum inference of regular sets. </title> <journal> Information and Control, </journal> <volume> 39(3) </volume> <pages> 337-350, </pages> <year> 1978. </year>
Reference-contexts: However, Angluin showed that even if a vanishingly small fraction of the strings from the complete labeled sample is missing then the problem of finding the smallest consistent DFA is NP-hard <ref> [Ang78] </ref>. Oncina and Garc ia recently proposed the regular positive and negative inference (RPNI) algorithm that in polynomial time identifies a DFA consistent with a given sample S [OG92].
Reference: [Ang81] <author> D. Angluin. </author> <title> A note on the number of queries needed to identify regular languages. </title> <journal> Information and Control, </journal> <volume> 51 </volume> <pages> 76-87, </pages> <year> 1981. </year>
Reference-contexts: complete set of examples that contains a representative string for each live state of the target DFA (see section 3.3.6) and a knowledgeable teacher 1 Note that a FSA is either a DFA or a NFA 11 to answer membership queries it is possible to exactly learn the target DFA <ref> [Ang81] </ref>. Later, Angluin refined this idea to design an algorithm L fl that infers the target DFA with the help of a minimally adequate teacher [Ang87]. A minimally adequate teacher (MAT) is one who is knowledgeable about the target concept and is able to answer the learner's queries. <p> Given A, a finite set of strings P is said to be live complete if for every live state q i of A there exists a string ff 2 P 23 such that ffi fl (q 0 ; ff) = q i <ref> [Ang81] </ref>. For example, P = f; a; b; aag is a live complete set for the DFA in Fig. 3.1. Any superset of a live complete set is also live complete. <p> It is difficult to perform an analysis of the average case performance of the algorithm. Angluin proposed an algorithm (ID) to infer the target grammar from a live complete set of examples (which can be constructed from a structurally complete set) using a polynomial number of membership queries <ref> [Ang81] </ref>. Our approach offers an alternative to the ID procedure when a structurally complete set of sam 39 ples is available. <p> Angluin's ID algorithm presents a framework for learning the target DFA from a live complete set of examples (see section 3.3.6) and membership queries <ref> [Ang81] </ref>. In many practical learning scenarios, a structurally complete set or a live complete set might not be available to the learner at the outset. <p> Section 5.2 briefly reviews the ID algorithm. The interested reader is referred to <ref> [Ang81] </ref> for a complete description of the algorithm and its correctness proof. Section 5.3 describes IID together with its correctness proof and an analysis of its time and space complexities. <p> The number of membership queries posed by the learner is at most O (jjN jP j). Further, the time and space complexities of the algorithm are polynomial in jj, N , and jP j <ref> [Ang81] </ref>. 5.3 IID An Incremental Extension of ID We now present an incremental version of the ID algorithm. As stated earlier, this algorithm does not require that the live complete set of examples be available to the learner at the start. Instead the learner is intermittently presented with labeled examples. <p> Given a live complete set of examples, ID outputs a canonical representation of the target DFA A <ref> [Ang81] </ref>. From above we know that at k = l the current model (M t ) of the target automaton maintained by IID is identical to one arrived at by ID.
Reference: [Ang87] <author> D. Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Information and Computation, </journal> <volume> 75 </volume> <pages> 87-106, </pages> <year> 1987. </year>
Reference-contexts: Later, Angluin refined this idea to design an algorithm L fl that infers the target DFA with the help of a minimally adequate teacher <ref> [Ang87] </ref>. A minimally adequate teacher (MAT) is one who is knowledgeable about the target concept and is able to answer the learner's queries. The L fl algorithm allows the learner to pose two types of queries viz. membership and equivalence queries. <p> Given its efficiency and guaranteed consistency with all examples, our algorithm can provide an effective tool for agent learning, especially in an interactive setting. The L fl algorithm for learning the target DFA is based on membership and equivalence queries <ref> [Ang87] </ref>. The equivalence queries can be replaced by a polynomial number of calls to an oracle that supplies labeled examples to give an efficient PAC algorithm for learning DFA from labeled examples and membership queries. <p> We define PAC learning of DFA more formally in section 6.2. Angluin's L fl algorithm <ref> [Ang87] </ref> that learns DFA in polynomial time using membership and equivalence queries can be recast under the PAC framework to learn by posing membership queries alone. However, the approximate learnability 56 of DFA from labeled examples alone remains a hard problem [PW89, KV89].
Reference: [BF72] <author> A. Biermann and J. Feldman. </author> <title> A survey of results in grammatical inference. </title> <editor> In S. Watanabe, editor, </editor> <booktitle> Frontiers of Pattern Recognition, </booktitle> <pages> pages 31-54. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: Grammar inference is the process of learning a target grammar from a set of labeled examples <ref> [BF72, FB75, MQ86, Lan95] </ref>. It finds applications in syntactic pattern recognition [Fu82], intelligent autonomous agents [CM96], and language acquisition [FLSW90]. <p> Finally, we conclude in chapter 11 with a summary of the research contributions of this dissertation and highlight some interesting directions for future research. 7 PART I LEARNING DETERMINISTIC FINITE AUTOMATA 8 2 INTRODUCTION TO REGULAR GRAMMAR INFERENCE Regular Grammar Inference <ref> [BF72, FB75, MQ86, Lan95, PH98a] </ref> is defined as the process of learning the rules of a target regular grammar from a set of labeled examples.
Reference: [BH69] <author> A. E. Bryson and Y. C. Ho. </author> <title> Applied Optimal Control. </title> <publisher> Blaisdell, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: Several researchers actively searched for suitable training algorithms for multi-layer networks of neurons. Early learning algorithms for training such networks were proposed independently by Dreyfus [Dre62], Bryson and Ho <ref> [BH69] </ref>, and Werbos [Wer74]. These algorithms use a gradient descent approach for training the multi-layer networks of neurons. The backpropagation learning algorithm proposed by Rumelhart et al [RHW86] made the gradient decent based approach popular in the neural networks community.
Reference: [BL91] <author> E. Baum and K. Lang. </author> <title> Constructing hidden units using examples and queries. </title> <editor> In R. Lippmann, J. Moody, and D. Touretzky, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 3, </volume> <pages> pages 904-910, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Their approach starts with an initial network representing the domain theory and modifies this theory by training a single hidden layer of TLUs using the labeled training data. The resultant network topology is depicted in Fig. 10.1. Their method uses the hyperplane detection from examples (HDE) algorithm <ref> [BL91] </ref> to construct the hidden layer. The HDE algorithm divides the feature space with hyperplanes. Each hyperplane is constructed by randomly selecting two points that belong to different output classes and localizing a suitable split between them. This process is repeated until a fixed number of hyperplanes is constructed.
Reference: [Bur94] <author> N. Burgess. </author> <title> A constructive algorithm that converges for real-valued input patterns. </title> <journal> International Journal of Neural Systems, </journal> <volume> 5(1) </volume> <pages> 59-66, </pages> <year> 1994. </year>
Reference-contexts: Note that the performance of this algorithm is heavily dependent on the initial temperature. This difficulty can be overcome to a significant extent if at the end of each epoch the initial temperature T 0 is set to the average net input over that particular epoch <ref> [Bur94] </ref>. <p> These include, among others, the tower , pyramid [Gal90], tiling [MN89], upstart [Fre90b], perceptron cascade <ref> [Bur94] </ref>, and sequential [MGR90]. With the exception of the upstart and the perceptron cascade algorithms all the constructive learning algorithms require the input attributes to be either binary or bipolar valued. <p> Additionally, practical classification tasks often involve patterns with real-valued attributes. The extensions of constructive learning algorithms to handle patterns with real-valued attributes have only been studied only for the upstart [ST91] and the perceptron cascade <ref> [Bur94] </ref> algorithms. For each of the constructive learning algorithms mentioned above we have designed provably correct extensions to handle tasks involving multiple output categories and real-valued pattern attributes (see [PYH95, YPH96, PYH97b, PYH97a]). <p> A number of algorithms that incrementally construct networks of threshold neurons for 2-category pattern classification tasks have been proposed in the literature. These include the tower , pyramid [Gal90], tiling [MN89], upstart [Fre90b], perceptron cascade <ref> [Bur94] </ref>, and sequential [MGR90]. <p> Several quantization algorithms have been proposed in the literature [DKS95, YH96]. We will study a novel adaptive vector quantization technique in chapter 10. Extensions of constructive learning algorithms to handle patterns with real-valued attributes have only been studied for the upstart and perceptron cascade algorithms (see <ref> [ST91, Bur94] </ref>). In this chapter, we present a general framework for the design of constructive learning algorithms that are capable of handling real-valued attributes. <p> Thus, the classification of pattern ^ X q remains unchanged. This proves the convergence of the upstart algorithm when the outputs are computed according to the WTA strategy. 8.5 Perceptron Cascade Algorithm The perceptron cascade algorithm <ref> [Bur94] </ref> draws on the ideas used in the upstart algorithm and constructs a neural network that is topologically similar to the one built by the cascade correlation algorithm [FL90] (see chapter 7). However, unlike the cascade correlation algorithm the perceptron cascade algorithm uses TLUs. <p> The initial temperature T 0 was set to 1.0 and was dynamically updated at the end of each epoch to match the average net input of the neuron (s) during the entire epoch <ref> [Bur94] </ref>. 25 runs were conducted for each experimental set up. <p> As we saw in chapter 8, constructive learning algorithms enjoy several advantages over the traditional algorithms for learning in multi-layer feed-forward networks. Several constructive learning algorithms have been proposed in the literature | tower , pyramid [Gal90], tiling [MN89], upstart [Fre90b], perceptron cascade <ref> [Bur94] </ref>, and sequential [MGR90]. <p> The learning rate was set to 1. The temperature T 0 was initialized to 1 and was dynamically updated at the end of each epoch to match the average net input of the neuron (s) during the entire epoch <ref> [Bur94] </ref>. The pruning option (see chapter 9) was turned on in experiments involving the MTiling , Tiling-Pyramid , and Tiling-Cascade algorithms. For the experiments with the MCascade and Tiling-Cascade algorithms the training set computed for each daughter neuron was balanced if necessary (see section 8.8.2).
Reference: [CG88] <author> G. Carpenter and S. Grossberg. </author> <title> The art of adaptive pattern recognition by a self-organizing neural network. </title> <booktitle> Computer, </booktitle> <month> (March): </month> <pages> 77-88, </pages> <year> 1988. </year>
Reference-contexts: This results in the development of networks where each neuron specializes on subsets of training patterns that share similar characteristics. Kohonen's self organizing maps (SOM) [Koh88] and Carpenter and Grossberg's adaptive resonance theory networks (ART) <ref> [CG88] </ref> are examples of neural networks that use competitive learning. * Feedback Learning: Here the weights of the network are modified based on the feedback received by the learner from its environment. In supervised learning schemes the feedback is available instantly.
Reference: [Cho56] <author> N. Chomsky. </author> <title> Three models for the description of language. </title> <journal> PGIT, </journal> <volume> 2(3) </volume> <pages> 113-124, </pages> <year> 1956. </year> <month> 217 </month>
Reference-contexts: It finds applications in syntactic pattern recognition [Fu82], intelligent autonomous agents [CM96], and language acquisition [FLSW90]. Regular grammars represent the simplest class in the Chomsky hierarchy of formal language grammars <ref> [Cho56, HU79] </ref> and describe the class of languages (regular languages) that can be generated (and recognized) by DFA. Since regular grammars represent a widely used subset of formal grammars, considerable research has focused on regular grammar inference (or equivalently, identification of the corresponding DFA).
Reference: [CLR91] <author> T. Cormen, C. Leiserson, and Rivest R. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: The interested reader is referred to <ref> [CLR91] </ref> for a detailed description of convex hulls and related topics in computational geometry. 131 In effect, the pattern X p has been excluded from the remaining patterns in the training set.
Reference: [CM96] <author> D. Carmel and S. Markovitch. </author> <title> Learning models of intelligent agents. </title> <booktitle> In Proceedings of the AAAI-96 (vol. 1), </booktitle> <address> Portland, OR, </address> <pages> pages 62-67, </pages> <publisher> AAAI Press/MIT Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: Grammar inference is the process of learning a target grammar from a set of labeled examples [BF72, FB75, MQ86, Lan95]. It finds applications in syntactic pattern recognition [Fu82], intelligent autonomous agents <ref> [CM96] </ref>, and language acquisition [FLSW90]. Regular grammars represent the simplest class in the Chomsky hierarchy of formal language grammars [Cho56, HU79] and describe the class of languages (regular languages) that can be generated (and recognized) by DFA. <p> Their simplicity and ease of understanding makes them a widely used class of grammars for modeling several practical grammar inference tasks. Regular grammar inference has been applied in fields such as syntactic pattern recognition, intelligent autonomous agents, language acquisition, computational biology, speech recognition, and the like (see <ref> [GT78, Fu82, MQ86, FLSW90, CM96] </ref>). Regular grammar inference is a difficult problem to solve. It has been actively investigated for over two decades. While there do exist several practically useful heuristic solutions to the problem, we have not yet discovered an efficient general algorithm for learning the target regular grammar. <p> The algorithm is guaranteed to converge to the target DFA and has polynomial time and space complexities. One practical application of incremental learning of DFA is in modeling the behavior of intelligent autonomous agents <ref> [CM96] </ref>. The behavior of agents such as robots can be modeled using a DFA. Incremental approaches to learning DFA provide these agents with a framework to learn from experience in unfamiliar environments.
Reference: [CPY + 95] <author> C-H. Chen, R. Parekh, J. Yang, K. Balakrishnan, and V. Honavar. </author> <title> Analysis of decision boundaries generated by constructive neural network learning algorithms. </title> <booktitle> In Proceedings of WCNN'95 (vol. 1), </booktitle> <address> Washington D.C., </address> <pages> pages 628-635, </pages> <publisher> Lawrence Erlbaum Associates/INNS Press, </publisher> <address> Mahwah, NJ, </address> <year> 1995. </year>
Reference-contexts: The interested reader is referred to <ref> [CPY + 95] </ref> for an analysis (in geometrical terms) of the decision boundaries generated by some of these constructive learning algorithms.
Reference: [Cra96] <author> M. Craven. </author> <title> Extracting Comprehensible Models from Trained Neural Networks. </title> <type> PhD dissertation, </type> <institution> University of Wisconsin, Madison, WI, </institution> <year> 1996. </year>
Reference-contexts: Of late there is significant interest in the study of efficient techniques for knowledge extraction from trained neural networks. The interested reader is referred to <ref> [TS93, Fu93, Cra96] </ref> for additional details. * The types of domain theory rules that can be incorporated into the network are limited to propositional rules. Further, there is no mechanism for handling uncertainty in rules.
Reference: [Day90] <author> J. Dayhoff. </author> <title> Neural Network Architectures: An Introduction. </title> <publisher> Van Nostrand Rein-hold, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: These differ chiefly in terms of the choice of the mathematical functions implemented by the individual neurons (processing units), the network topology (fixed or dynamic), the network architecture (number of layers and neurons), the network interconnections (connectivity among the existing neurons), and the training methodology (one-shot or iterative) <ref> [Day90, Gal93, MMR97] </ref>. Traditional ANN algorithms such as backpropagation [RHW86], although successful on several pattern classification tasks, suffer from drawbacks such as restriction to an a-priori fixed network topology, use of the expensive gradient descent based error backpropagation training rule, and susceptibility to local minima. <p> Q-learning is a widely used algorithm for reinforcement learning [Wat89, WD92]. 89 7.2.4 Applications ANN have been successfully applied to problems in the areas of pattern classification, clustering, vector quantization, pattern association, function approximation, optimization, control, and search <ref> [Day90, Gal93, MMR97] </ref>. In this dissertation we focus exclusively on the use of neural networks for pattern classification. Pattern classification involves assigning patterns to one of several a-priori fixed classes. <p> Backpropagation networks thus cannot use threshold neurons. Instead they use neurons implementing the sigmoid activation function. The interested reader is referred to [RHW86] or any popular textbook on neural network learning (such as <ref> [Day90, Gal93, MMR97] </ref>) for a derivation of the backpropagation weight update rule. The backpropagation algorithm and its extensions have been successfully used in several practical applications. However, the backpropagation like training algorithms suffer from the following important drawbacks: * A-priori fixed network topology.
Reference: [DDG96] <author> F. Denis, C. D'Halluin, and R. Gilleron. </author> <title> PAC learning with simple examples. </title> <booktitle> STACS'96 Proceedings of the 13 th Annual Symposium on the Theoretical Aspects of Computer Science, </booktitle> <pages> pages 231-242, </pages> <year> 1996. </year>
Reference-contexts: Thus, this model is quite general. Recently, this learning model was extended to a framework where a teacher might intelligently choose examples based on the knowledge of the target concept <ref> [DDG96] </ref>. This is called the PAC learning with simple examples (PACS learning) model. We answer the above open research question in the affirmative by proving that DFA are efficiently learnable from simple examples. <p> Denis et al proposed a model of learning from simple examples where a knowledgeable teacher might choose the examples based on the knowledge of the target concept <ref> [DDG96] </ref>. This model is known as the PACS learning model. In this chapter, we present a method for efficient PAC learning of DFA from simple examples thereby answering Pitt's open research question in the affirmative. <p> string r 2 fl , the universal distribution based on the knowledge of r, m r , is defined as is defined as m r (ff) = r 2 K (ffjr) where r is a constant such that r P ff2 fl 2 K (ffjr) = 1 (i.e., r 1) <ref> [DDG96] </ref>. Further, m r is such that 2 K (ffjr) m r (ff) 2 K (ffjr) where is a constant. <p> Denis et al proposed the PACS learning model for learning from simple examples where a teacher might use knowledge of the target concept in selecting representative examples <ref> [DDG96] </ref>. Under this model, examples with low conditional Kolmogorov complexity given a representation r of the target concept are called simple examples. <p> The Occam's Razor theorem proved by Denis et al states that if there exists a representative set of simple examples for each 70 concept in a concept class then the concept class is PACS learnable <ref> [DDG96] </ref>. We now demonstrate that the class of DFA is efficiently learnable under the PACS model. Lemma 6.3 proves that for any DFA A with standard encoding r there exists a characteristic set of simple examples S r sim;rep . <p> Thus 8ff 2 S c , K (ffjr) lg (3jjN 2 ) lg (jrj) where is a constant We define the set S c to be the characteristic set of simple examples S r sim;rep for the DFA A. This proves the lemma. 2 Lemma 6.4 (Due to <ref> [DDG96] </ref>) Suppose that a sample S is drawn according to m r . For an integer l jrj, and 0 &lt; ffi 1, if jSj = O (l lg ( 1 ffi )) then with probability greater than 1 ffi, S r sim S.
Reference: [DG97] <author> F. Denis and R. Gilleron. </author> <title> PAC learning under helpful distributions. </title> <booktitle> In Proceedings of the Eighth International Workshop on Algorithmic Learning Theory (ALT'97), Sendai, Japan, Lecture Notes in Artificial Intelligence 1316, </booktitle> <pages> pages 132-145, </pages> <year> 1997. </year>
Reference-contexts: This opens up a number of interesting possibilities for learning under simple distributions. In a recent paper Denis and Gilleron have proposed a new model of learning under helpful distributions <ref> [DG97] </ref>. A helpful distribution is one in which examples belonging to the charac 80 teristic set for the concept (if there exists one) are assigned non-zero probability. A systematic characterization of the class of helpful distributions would perhaps give us a more practical framework for learning from simple examples. <p> The universal distribution is not computable. The applicability of the PACS model under some efficiently computable approximation of the universal distribution needs to be explored further. A systematic characterization of the framework for learning under helpful distributions (due to <ref> [DG97] </ref>) might give us a more practical framework for learning from simple examples. In applications such as natural language learning it is not inconceivable that a teacher might provide simpler examples of the target concept first before providing the more complex ones.
Reference: [DH73] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: Note that the first component of the weight vector is the threshold term. Several iterative algorithms are available for finding such a ^ W, if one exists <ref> [Ros58, MP69, Nil65, DH73] </ref>. Most of these are variants of the perceptron weight update rule: W W + (C p O p )X p where &gt; 0 is the learning rate The perceptron weight update rule is guaranteed to find a separating hyperplane if one exists.
Reference: [DKS95] <author> J. Dougherty, R. Kohavi, and M. Sahami. </author> <title> Supervised and unsupervised discretiza-tion of continuous features. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <address> San Francisco, CA, </address> <pages> pages 194-202, </pages> <year> 1995. </year> <month> 218 </month>
Reference-contexts: The original constructive learning algorithm can then be applied using the quantized representations of the pattern vectors. Several quantization algorithms have been proposed in the literature <ref> [DKS95, YH96] </ref>. We will study a novel adaptive vector quantization technique in chapter 10. Extensions of constructive learning algorithms to handle patterns with real-valued attributes have only been studied for the upstart and perceptron cascade algorithms (see [ST91, Bur94]). <p> Discretization methods have been extensively studied in conjunction with many different machine learning algorithms. A detailed survey of discretization algorithms appears in <ref> [DKS95] </ref>.
Reference: [DMV94] <author> P. Dupont, L. Miclet, and E. Vidal. </author> <title> What is the search space of the regular inference? In Proceedings of the Second International Colloquium on Grammatical Inference (ICGI'94), </title> <booktitle> Alicante, Spain, </booktitle> <pages> pages 25-37, </pages> <year> 1994. </year>
Reference-contexts: Further, given a canonical DFA A and a set S + that is structurally complete with respect to A (see section 3.3.5), the lattice (S + ) derived from P T A (S + ) is guaranteed to contain A <ref> [PC78, PH93, DMV94] </ref>. 3.3.4 Sub-automaton A sub-automaton A x for a DFA A (ignoring its dead state d 0 and its associated transitions) is a quintuple A x = (Q x ; ffi x ; ; q 0 ; F x ) where Q x Q, q 0 2 Q x <p> then the set S + is said to be structurally complete with respect to A if S + covers each transition of A (except the transitions associated with the dead state d 0 ) and uses every element of the set of final states of A as an accepting state <ref> [PC78, PH93, DMV94] </ref>. <p> This requires that each transition and each accepting state of the target DFA must be covered by the strings in the structurally complete set <ref> [PH93, DMV94, PH96] </ref>. 26 We present an improved learning algorithm based on the version space representation of the lattice of FSA [PH93, PH96]. The version space implicitly represents the entire lattice using two sets of FSA called S and G respectively. <p> Proof: The proof of this theorem is originally due to Pao and Carr [PC78] and has been reworked in [PH93]. It was also independently proven by Miclet (see <ref> [DMV94] </ref>). 2 Theorem 4.2 The following invariance condition holds at all times during the execution of the algorithm. 9 fi 2 G and 9 ff 2 S such that ff t A t fi Proof: We prove this theorem by induction.
Reference: [DR95] <author> S. Donoho and L. Rendell. </author> <title> Representing and restructuring domain theories: A constructive induction approach. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 411-446, </pages> <year> 1995. </year>
Reference-contexts: Theory refinement systems can be broadly classified into the following three categories: * Purely symbolic approaches These methods use symbolic inductive learning algorithms (such as decision tree induction) for theory revision. Examples of such systems include RTLS [Gin90], EITHER [OM94], PTR [KFS94], and TGCI <ref> [DR95] </ref>. The EITHER system starts with the 171 given domain knowledge and a set of training examples. It divides the examples into two subsets depending on whether or not the rules in the domain theory are able to correctly classify them.
Reference: [Dre62] <author> S. Dreyfus. </author> <title> The numerical solution of variational problems. </title> <journal> Journal of Mathematical Analysis and Applications, </journal> <volume> 5(1) </volume> <pages> 30-45, </pages> <year> 1962. </year>
Reference-contexts: Several researchers actively searched for suitable training algorithms for multi-layer networks of neurons. Early learning algorithms for training such networks were proposed independently by Dreyfus <ref> [Dre62] </ref>, Bryson and Ho [BH69], and Werbos [Wer74]. These algorithms use a gradient descent approach for training the multi-layer networks of neurons. The backpropagation learning algorithm proposed by Rumelhart et al [RHW86] made the gradient decent based approach popular in the neural networks community.
Reference: [Dup96a] <author> P. Dupont. </author> <title> Incremental regular inference. </title> <editor> In L. Miclet and C. Higuera, editors, </editor> <booktitle> Proceedings of the Third ICGI-96, Montpellier, France, Lecture Notes in Artificial Intelligence 1147, </booktitle> <pages> pages 222-237, </pages> <year> 1996. </year>
Reference-contexts: The current hypothesis along with the next labeled example should be sufficient to guarantee that the modified hypothesis is consistent with the new example as well as all the examples seen previously. Dupont proposed an incremental version of the RPNI algorithm for regular grammar inference <ref> [Dup96a] </ref>. This algorithm is also based on the idea of a lattice of finite state automata constructed from a set of positive examples. <p> Two prominent incremental algorithms for learning DFA are due to Porat and Feld-man [PF91] and Dupont <ref> [Dup96a] </ref> respectively. Porat and Feldman's algorithm learns the target DFA in the limit from a complete ordered sample. A complete ordered sample includes all the strings in fl in strict lexicographic order. The algorithm uses only finite working storage. <p> RPNI2 extends the RPNI algorithm to an incremental setting where the characteristic set of examples might not be available to the learner at the start <ref> [Dup96a] </ref>. The operation of RPNI2 is summarized as follows: The initially available set of positive examples is mapped to a lattice of FSA. An ordered search of the lattice is conducted using the initial set of negative examples. <p> We are exploring the possibility of learning in an environment where the learner does not have access to a teacher. The algorithms due to Dupont <ref> [Dup96a] </ref> and Porat & Feldman [PF91] operate in this framework. Some open problems include whether the limitations of these algorithms (e.g., the need to store all the examples, the requirement of complete lexicographic ordering of examples, etc.) can be overcome without sacrificing efficiency and guaranteed convergence to the target. <p> Incremental algorithms are guaranteed to converge to the target DFA in the limit. However, these approaches have certain restrictions. RPNI2 requires the learner to store all the examples <ref> [Dup96a] </ref>, Porat and Feldman's algorithm mandates a complete ordered presentation of the labeled examples [PF91], and the IID algorithm described in chapter 5 is based on the availability of a knowledgeable teacher to answer membership queries [PNH97]. It is thus natural to ask whether DFA can be learned approximately. <p> Further, if the sample is a characteristic set for the target DFA then the algorithm is guaranteed to return a canonical representation of the target DFA. Our description of the RPNI algorithm is based on the explanation given in <ref> [Dup96a] </ref>. A labeled sample S = S + [ S is provided as input to the algorithm. It constructs a prefix tree automaton P T A (S + ) and numbers its states in the standard order (see section 3.3.2). <p> This recursive merging of states can go on for at most N 1 steps and the resulting automaton M ^ is guaranteed to be a DFA <ref> [Dup96a] </ref>. Note that since ~ t ^ we know by the grammar covers relation that if M ~ accepts a negative example in S then so would M ^ . <p> In the RPNI2 learning algorithm for incremental learning of the target DFA the learner maintains a hypothesis that is consistent with all labeled examples seen thus far and modifies it whenever a new inconsistent example is observed <ref> [Dup96a] </ref>. The convergence of this algorithm relies on the fact that sooner or later, the set of labeled examples seen by the learner will include a characteristic set.
Reference: [Dup96b] <author> P. </author> <type> Dupont. </type> <institution> Utilisation et Apprentissage de Modeles de Language pour la Reconnaissance de la Parole Continue. </institution> <type> PhD dissertation, </type> <institution> Ecole Normale Superieure des Telecommunications, Paris, France, </institution> <year> 1996. </year>
Reference-contexts: Further, if S is a superset of a characteristic set for the target DFA (see section 3.3.7) then the DFA output by the RPNI algorithm is guaranteed to be equivalent to the target <ref> [OG92, Dup96b] </ref>. A set of labeled examples that satisfy certain properties is one form of additional information that makes the DFA learning problem tractable. Additionally, one may assume the existence of a knowledgeable teacher who responds to queries posed by the learner.
Reference: [Fah88] <author> S. E. Fahlman. </author> <title> An empirical study of learning speed in backpropagation networks. </title> <type> Technical Report CMU-CS-88-162, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1988. </year>
Reference-contexts: Fig. 7.5 shows the various stages in the execution of the cascade correlation algorithm. The solid lines indicate the network's weights that are being trained and the dotted lines indicate the weights that remain frozen. Fahlman and Lebiere propose using the Quickprop learning algorithm <ref> [Fah88] </ref> to accelerate the learning process. The algorithm's performance can be further improved by training a pool of 4 or 8 neurons each time a new hidden neuron is to be added and selecting from 98 this pool a neuron that maximizes the correlation with the network's residual error.
Reference: [FB75] <author> K. S. Fu and T. L. Booth. </author> <title> Grammatical inference: Introduction and survey (part 1). </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 5 </volume> <pages> 85-111, </pages> <year> 1975. </year>
Reference-contexts: Grammar inference is the process of learning a target grammar from a set of labeled examples <ref> [BF72, FB75, MQ86, Lan95] </ref>. It finds applications in syntactic pattern recognition [Fu82], intelligent autonomous agents [CM96], and language acquisition [FLSW90]. <p> Finally, we conclude in chapter 11 with a summary of the research contributions of this dissertation and highlight some interesting directions for future research. 7 PART I LEARNING DETERMINISTIC FINITE AUTOMATA 8 2 INTRODUCTION TO REGULAR GRAMMAR INFERENCE Regular Grammar Inference <ref> [BF72, FB75, MQ86, Lan95, PH98a] </ref> is defined as the process of learning the rules of a target regular grammar from a set of labeled examples.
Reference: [FL90] <author> S. E. Fahlman and C. Lebiere. </author> <title> The cascade correlation learning algorithm. </title> <editor> In D.S. Touretzky, editor, </editor> <booktitle> Neural Information Processing Systems 2, </booktitle> <pages> pages 524-532. </pages> <address> Morgan-Kauffman, San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: A fixed learning rate of 1 is typically gives satisfactory performance across a variety of datasets. * They provide a natural framework for incorporation of problem specific domain knowl edge into the initial network configuration. The cascade correlation learning algorithm due to Fahlman and Lebiere <ref> [FL90] </ref> differs from other constructive neural network learning algorithms in that it is based on gradient ascent training of neurons that implement a continuous differentiable activation function such as the sigmoid. As the name suggests, cascade correlation features cascade architecture development and correlation based training. <p> of the upstart algorithm when the outputs are computed according to the WTA strategy. 8.5 Perceptron Cascade Algorithm The perceptron cascade algorithm [Bur94] draws on the ideas used in the upstart algorithm and constructs a neural network that is topologically similar to the one built by the cascade correlation algorithm <ref> [FL90] </ref> (see chapter 7). However, unlike the cascade correlation algorithm the perceptron cascade algorithm uses TLUs. Initially an output neuron is trained using the algorithm A.
Reference: [FLSW90] <author> J. A. Feldman, G. Lakoff, A. Stolcke, and S. H. Weber. </author> <title> Miniature language acquisition: A touchtone for cognitive science. </title> <type> Technical Report TR-90-009, </type> <institution> International Computer Science Institute, Berkeley, California, </institution> <year> 1990. </year> <month> 219 </month>
Reference-contexts: Grammar inference is the process of learning a target grammar from a set of labeled examples [BF72, FB75, MQ86, Lan95]. It finds applications in syntactic pattern recognition [Fu82], intelligent autonomous agents [CM96], and language acquisition <ref> [FLSW90] </ref>. Regular grammars represent the simplest class in the Chomsky hierarchy of formal language grammars [Cho56, HU79] and describe the class of languages (regular languages) that can be generated (and recognized) by DFA. <p> Their simplicity and ease of understanding makes them a widely used class of grammars for modeling several practical grammar inference tasks. Regular grammar inference has been applied in fields such as syntactic pattern recognition, intelligent autonomous agents, language acquisition, computational biology, speech recognition, and the like (see <ref> [GT78, Fu82, MQ86, FLSW90, CM96] </ref>). Regular grammar inference is a difficult problem to solve. It has been actively investigated for over two decades. While there do exist several practically useful heuristic solutions to the problem, we have not yet discovered an efficient general algorithm for learning the target regular grammar.
Reference: [FO93] <author> J. Fletcher and Z. Obradovic. </author> <title> Combining prior symbolic knowledge and constructive neural network learning. </title> <booktitle> Connection Science, </booktitle> <address> 5(3,4):365-375, </address> <year> 1993. </year>
Reference-contexts: In section 10.4 we present the results of our experiments with the Financial Advisor Rule Base <ref> [LS89, FO93] </ref> and two datasets from the Human Genome Project (ribosome binding sites and DNA promoter sequences). <p> We conclude in section 10.5 with a summary and outline some promising directions for future research. 10.2 Related Work Fletcher and Obradovic <ref> [FO93] </ref> designed a constructive learning method for dynamically adding neurons to the initial knowledge based network. Their approach starts with an initial network representing the domain theory and modifies this theory by training a single hidden layer of TLUs using the labeled training data. <p> This procedure is based on the rules-to-networks algorithm of Towell and Shavlik <ref> [TSN90, FO93] </ref>. It involves rewriting the knowledge rules into a format that highlights the hierarchical structure of the domain theory. In particular, the disjuncts are expressed as a set of rules that each have only one antecedent. <p> The financial advisor rule base is shown in Table 10.6. A set of 5500 labeled examples (500 for training and 5000 for testing) were randomly generated as is the case for the experiments performed by Fletcher and Obradovic <ref> [FO93] </ref>. Each of the 5500 examples are correctly classified by the rules of the financial advisor rule base. We used the hybrid Tiling-Pyramid constructive learning algorithm (described in section 10.3.2.2) to augment the initial domain knowledge. The hybrid network was trained using the thermal perceptron algorithm [Fre92]. <p> Incomplete domain knowledge was modeled by pruning certain rules and their antecedents from the original rule base (as described in <ref> [FO93] </ref>). For example, if sav adeq was selected as the pruning point, then the rules for sav adeq, dep sav adeq, and assets hi are eliminated from the rule base. In other words rules 2, 3, 6, and 7 are pruned. <p> Further, rule 1 is modified to read "if (inc adeq) then invest stocks". The initial network is constructed from this modified rule base and is then augmented using constructive learning. Our experiments follow those performed by Fletcher and Obradovic <ref> [FO93] </ref>. In Table 10.3 we summarize the average generalization (on the 5000 test patterns) and the average network size over 25 runs for 6 different pruning points. The generalization accuracy of the corresponding network prior to theory refinement (i.e., based on rules alone) is also reported. <p> Since the generalization accuracy of the network without the assets hi rule is already significantly high, constructive theory refinement understandably does not improve the generalization any further. In Table 10.4 we present the 187 results for the experiments with HDE that were reported by Fletcher and Obradovic 4 <ref> [FO93] </ref>. These results demonstrate that the performance of the hybrid Tiling-Pyramid algorithm com pares favorably with that of the HDE algorithm on the financial advisor rule base in terms of both the generalization accuracy and the final size of the trained network. Table 10.3 Financial Advisor Rule Base (Tiling-Pyramid). <p> Our method embeds the original domain theory into an initial neural network and then refines the theory by dynamically adding new TLUs to the network. This approach is similar to the one taken by Fletcher and Obradovic in their algorithm for connectionist theory refinement <ref> [FO93] </ref>. The main difference being that our approach allows potentially any constructive neural network learning algorithm to be used for theory refinement whereas Fletcher and Obradovic's approach is based on the specific HDE learning algorithm for training a single hidden layer of TLUs.
Reference: [FPSS96] <author> U. Fayyad, G. Piatetsky-Shapiro, and P. Smyth. </author> <title> Advances in Knowledge Discovery and Data Mining. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: Inductive learning systems have been successfully used in a variety of application domains including autonomously steering a vehicle on public highways [Pom89], automatically learning users' preferences and assisting them in coping with the information overload [Mae95], and discovering interesting new rules from large databases <ref> [FPSS96] </ref>. The goal of a typical inductive learning system is to construct a concise model that correctly explains the observed examples. We specifically study inductive learning systems for pattern classification tasks where the system learns to classify examples into one of M output categories (where M 2). <p> Algorithms that are able to learn efficiently in environments where no teacher is available are of considerable interest. 11.2.3 Knowledge Extraction from Constructive Neural Networks The field of knowledge discovery and data mining seeks to use machine learning techniques to extract interesting rules from large databases <ref> [FPSS96] </ref>. In these applications it is vital that the learned model be comprehensible to a human. Neural network models have been shown 196 to have better generalization capability on several domains than some of the symbolic or rule based machine learning approaches.
Reference: [Fre90a] <author> M. Frean. </author> <title> Small Nets and Short Paths: Optimizing Neural Computation. </title> <type> PhD dissertation, </type> <institution> Center for Cognitive Science, Edinburgh University, Edinburgh, Scot-land, </institution> <year> 1990. </year>
Reference-contexts: In the case of non-linearly separable datasets, the perceptron algorithm behaves poorly i.e., the classification accuracy on the training set can fluctuate wildly from one training epoch to next. Several modifications to the perceptron weight update rule e.g., pocket algorithm with ratchet modification [Gal90], thermal perceptron algorithm <ref> [Fre90a, Fre92] </ref>, Loss minimization algorithm [Hry92], and the barycentric correction procedure [Pou95] are proposed to find a reasonably good weight vector that correctly classifies a large fraction of the training set 91 S when S is not linearly separable and to converge to zero classification errors when S is linearly separable. <p> Given enough training time, the algorithm is guaranteed 92 to find a weight setting W pocket that will correctly classify as large a subset of the training set as possible [Gal90, Gal93]. 7.3.2 Thermal Perceptron Learning Algorithm The rationale behind the thermal perceptron algorithm <ref> [Fre90a] </ref> is to control the weight updates during learning and prevent drastic weight changes in response to patterns that might be outliers. The standard perceptron algorithm treats all misclassifications the same irrespective of the magnitude of the error.
Reference: [Fre90b] <author> M. Frean. </author> <title> The upstart algorithm: A method for constructing and training feedfor-ward neural networks. </title> <journal> Neural Computation, </journal> <volume> 2 </volume> <pages> 198-209, </pages> <year> 1990. </year>
Reference-contexts: These include, among others, the tower , pyramid [Gal90], tiling [MN89], upstart <ref> [Fre90b] </ref>, perceptron cascade [Bur94], and sequential [MGR90]. With the exception of the upstart and the perceptron cascade algorithms all the constructive learning algorithms require the input attributes to be either binary or bipolar valued. <p> A number of algorithms that incrementally construct networks of threshold neurons for 2-category pattern classification tasks have been proposed in the literature. These include the tower , pyramid [Gal90], tiling [MN89], upstart <ref> [Fre90b] </ref>, perceptron cascade [Bur94], and sequential [MGR90]. <p> The convergence proof (for both the independent and WTA output strategies) follows directly from the convergence proof of the tower algorithm. 2 8.4 Upstart Algorithm The 2-category upstart algorithm <ref> [Fre90b] </ref> constructs a binary tree of threshold neurons. A simple extension of this idea to deal with M output categories would be to construct M 116 Network. 117 independent binary trees (one for each output class). This approach fails to exploit the interrelationships that might exist between the different outputs. <p> This approach fails to exploit the interrelationships that might exist between the different outputs. We therefore follow an alternative approach using a single hidden layer instead of a binary tree <ref> [Fre90b] </ref>. Since the original upstart algorithm was designed for binary valued patterns and used binary TLUs, we will present our extension of this algorithm to M classes under the same binary valued framework 2 . <p> As we saw in chapter 8, constructive learning algorithms enjoy several advantages over the traditional algorithms for learning in multi-layer feed-forward networks. Several constructive learning algorithms have been proposed in the literature | tower , pyramid [Gal90], tiling [MN89], upstart <ref> [Fre90b] </ref>, perceptron cascade [Bur94], and sequential [MGR90]. <p> It first translates the initial domain theory to an appropriate neural network architecture and then refines the domain theory by using backpropagation training on the network (just as in the case of KBANN). Further, it augments the network topology by adding new neurons using the upstart learning algorithm <ref> [Fre90b] </ref>. Apart from the fact that RAPTURE is designed for probabilistic rule bases, it differs from our approach of using a constructive learning algorithm to augment the initial network topology in the following manner: RAPTURE uses backpropagation based training in addition to 175 constructive learning.
Reference: [Fre92] <author> M. Frean. </author> <title> A thermal perceptron learning rule. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 946-957, </pages> <year> 1992. </year>
Reference-contexts: In the case of non-linearly separable datasets, the perceptron algorithm behaves poorly i.e., the classification accuracy on the training set can fluctuate wildly from one training epoch to next. Several modifications to the perceptron weight update rule e.g., pocket algorithm with ratchet modification [Gal90], thermal perceptron algorithm <ref> [Fre90a, Fre92] </ref>, Loss minimization algorithm [Hry92], and the barycentric correction procedure [Pou95] are proposed to find a reasonably good weight vector that correctly classifies a large fraction of the training set 91 S when S is not linearly separable and to converge to zero classification errors when S is linearly separable. <p> Algorithms such as the pocket algorithm with ratchet modification [Gal90], the thermal perceptron algorithm <ref> [Fre92] </ref>, and the 156 barycentric correction procedure [Pou95] are commonly used for training individual TLUs (or groups of TLUs) in constructive learning algorithms. We denote such a suitable TLU training algorithm by A. <p> Each of the 5500 examples are correctly classified by the rules of the financial advisor rule base. We used the hybrid Tiling-Pyramid constructive learning algorithm (described in section 10.3.2.2) to augment the initial domain knowledge. The hybrid network was trained using the thermal perceptron algorithm <ref> [Fre92] </ref>. Each TLU was trained for 500 epochs with the initial weights chosen randomly between in the range [1::1], the learning rate held constant at 1 and the initial temperature T 0 set to 1.0.
Reference: [Fu82] <author> K. Fu. </author> <title> Syntactic Pattern Recognition and Applications. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: Grammar inference is the process of learning a target grammar from a set of labeled examples [BF72, FB75, MQ86, Lan95]. It finds applications in syntactic pattern recognition <ref> [Fu82] </ref>, intelligent autonomous agents [CM96], and language acquisition [FLSW90]. Regular grammars represent the simplest class in the Chomsky hierarchy of formal language grammars [Cho56, HU79] and describe the class of languages (regular languages) that can be generated (and recognized) by DFA. <p> Their simplicity and ease of understanding makes them a widely used class of grammars for modeling several practical grammar inference tasks. Regular grammar inference has been applied in fields such as syntactic pattern recognition, intelligent autonomous agents, language acquisition, computational biology, speech recognition, and the like (see <ref> [GT78, Fu82, MQ86, FLSW90, CM96] </ref>). Regular grammar inference is a difficult problem to solve. It has been actively investigated for over two decades. While there do exist several practically useful heuristic solutions to the problem, we have not yet discovered an efficient general algorithm for learning the target regular grammar. <p> This search could perhaps generate more informative queries or possibly use the results of a polynomial number of queries posed simultaneously to speed up learning. An extension of the proposed approach for learning regular tree and attributed grammars <ref> [Fu82] </ref> also merits further investigation. 40 5 AN INCREMENTAL ALGORITHM FOR LEARNING DFA FROM LABELED EXAMPLES AND MEMBERSHIP QUERIES 5.1 Introduction In chapter 4 we studied a version space based approach for learning the target DFA from a structurally complete set of examples and membership queries.
Reference: [Fu89] <author> L. M. Fu. </author> <title> Integration of neural heuristics into knowledge-based inference. </title> <journal> Connection Science, </journal> <volume> 1 </volume> <pages> 325-340, </pages> <year> 1989. </year>
Reference-contexts: Their rules-to-network algorithm constructs an AND-OR graph representation of the initial domain knowledge and translates this graph to an appropriate neural network topology. KBANN then uses the standard backpropagation learning algorithm [RHW86] to refine the do 172 main knowledge. The approaches described by Fu <ref> [Fu89] </ref> and Katz [Kat89] are similar to the KBANN algorithm. Unlike the symbolic and ILP based methods for theory refinement, the connectionist approaches require that the domain knowledge be translated into an appropriate initial neural network topology.
Reference: [Fu93] <author> L. M. Fu. </author> <title> Knowledge-based connectionism for revising domain theories. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 23(1) </volume> <pages> 173-182, </pages> <year> 1993. </year>
Reference-contexts: Of late there is significant interest in the study of efficient techniques for knowledge extraction from trained neural networks. The interested reader is referred to <ref> [TS93, Fu93, Cra96] </ref> for additional details. * The types of domain theory rules that can be incorporated into the network are limited to propositional rules. Further, there is no mechanism for handling uncertainty in rules.
Reference: [Gal90] <author> S. Gallant. </author> <title> Perceptron based learning algorithms. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 1(2) </volume> <pages> 179-191, </pages> <year> 1990. </year>
Reference-contexts: In the case of non-linearly separable datasets, the perceptron algorithm behaves poorly i.e., the classification accuracy on the training set can fluctuate wildly from one training epoch to next. Several modifications to the perceptron weight update rule e.g., pocket algorithm with ratchet modification <ref> [Gal90] </ref>, thermal perceptron algorithm [Fre90a, Fre92], Loss minimization algorithm [Hry92], and the barycentric correction procedure [Pou95] are proposed to find a reasonably good weight vector that correctly classifies a large fraction of the training set 91 S when S is not linearly separable and to converge to zero classification errors when <p> Given enough training time, the algorithm is guaranteed 92 to find a weight setting W pocket that will correctly classify as large a subset of the training set as possible <ref> [Gal90, Gal93] </ref>. 7.3.2 Thermal Perceptron Learning Algorithm The rationale behind the thermal perceptron algorithm [Fre90a] is to control the weight updates during learning and prevent drastic weight changes in response to patterns that might be outliers. <p> These include, among others, the tower , pyramid <ref> [Gal90] </ref>, tiling [MN89], upstart [Fre90b], perceptron cascade [Bur94], and sequential [MGR90]. With the exception of the upstart and the perceptron cascade algorithms all the constructive learning algorithms require the input attributes to be either binary or bipolar valued. <p> A number of algorithms that incrementally construct networks of threshold neurons for 2-category pattern classification tasks have been proposed in the literature. These include the tower , pyramid <ref> [Gal90] </ref>, tiling [MN89], upstart [Fre90b], perceptron cascade [Bur94], and sequential [MGR90]. <p> Section 8.8 presents preliminary results of experiments involving several artificial and real world classification tasks. Section 8.9 concludes with a summary and a discussion of future research directions. 8.2 Tower Algorithm The 2-category tower algorithm <ref> [Gal90] </ref> constructs a tower of TLUs. The bottom-most neuron receives inputs from each of the N input neurons. The tower is built by successively adding neurons to the network and training them using A until the desired classification accuracy is achieved. <p> Thus, O L = O L1 = C q i.e., the classification of previously correctly classified patterns remains unchanged. We have thus proved the convergence of the tower algorithm when the outputs are computed according to the WTA strategy. 8.3 Pyramid Algorithm The 2-category pyramid algorithm <ref> [Gal90] </ref> constructs a network in a manner similar to the tower algorithm, except that each newly added neuron receives input from each of the N input neurons as well as the outputs of all the neurons in each of the preceding layers. <p> The performance of constructive learning algorithms in this setting of lifelong learning merits further study. 155 9 PRUNING STRATEGIES FOR THE MTILING CONSTRUCTIVE LEARNING ALGORITHM 9.1 Introduction Constructive neural network learning algorithms offer an interesting paradigm for incremental construction of near-minimal architectures for pattern classification problems <ref> [Gal90, Hon90, Gal93, HU93] </ref>. As we saw in chapter 8, constructive learning algorithms enjoy several advantages over the traditional algorithms for learning in multi-layer feed-forward networks. <p> As we saw in chapter 8, constructive learning algorithms enjoy several advantages over the traditional algorithms for learning in multi-layer feed-forward networks. Several constructive learning algorithms have been proposed in the literature | tower , pyramid <ref> [Gal90] </ref>, tiling [MN89], upstart [Fre90b], perceptron cascade [Bur94], and sequential [MGR90]. <p> Algorithms such as the pocket algorithm with ratchet modification <ref> [Gal90] </ref>, the thermal perceptron algorithm [Fre92], and the 156 barycentric correction procedure [Pou95] are commonly used for training individual TLUs (or groups of TLUs) in constructive learning algorithms. We denote such a suitable TLU training algorithm by A. <p> This process is repeated until a fixed number of hyperplanes is constructed. Fletcher and Obradovic's algorithm maps these hyperplanes to a set of TLUs and then then trains the final output unit using the pocket algorithm with ratchet modification algorithm <ref> [Gal90] </ref>. 174 Our approach is similar to the one taken by Fletcher and Obradovic. Instead of constructing a single hidden layer we allow the constructive learning algorithm to build a network of one or more hidden layers (if necessary) above the initial network representing the domain theory (see Fig. 10.2). <p> if (assets income * 10) then assets hi 8 if (income 25000 + dep * 4000) then dep inc adeq 9 if (debt pmt &lt; income * 0.3) then debt lo 180 Network. 181 used a novel hybrid algorithm that combines the features of the tiling [MN89] and the pyramid <ref> [Gal90] </ref> learning algorithms. In chapter 8 we described provably correct extensions of several constructive learning algorithms to handle multiple output classes and patterns with real-valued attributes.
Reference: [Gal93] <author> S. Gallant. </author> <title> Neural Network Learning and Expert Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: These differ chiefly in terms of the choice of the mathematical functions implemented by the individual neurons (processing units), the network topology (fixed or dynamic), the network architecture (number of layers and neurons), the network interconnections (connectivity among the existing neurons), and the training methodology (one-shot or iterative) <ref> [Day90, Gal93, MMR97] </ref>. Traditional ANN algorithms such as backpropagation [RHW86], although successful on several pattern classification tasks, suffer from drawbacks such as restriction to an a-priori fixed network topology, use of the expensive gradient descent based error backpropagation training rule, and susceptibility to local minima. <p> Constructive (or generative) neural network learning algorithms offer an attractive frame 6 work for automatic construction of near-minimal networks for pattern classification and inductive knowledge acquisition systems <ref> [Hon90, HU93, Gal93] </ref>. Most constructive learning algorithms are based on simple TLUs that implement a hard-limiting function of their inputs. These algorithms start out by training a single TLU using some variant of the perceptron learning rule [Ros58]. <p> Q-learning is a widely used algorithm for reinforcement learning [Wat89, WD92]. 89 7.2.4 Applications ANN have been successfully applied to problems in the areas of pattern classification, clustering, vector quantization, pattern association, function approximation, optimization, control, and search <ref> [Day90, Gal93, MMR97] </ref>. In this dissertation we focus exclusively on the use of neural networks for pattern classification. Pattern classification involves assigning patterns to one of several a-priori fixed classes. <p> Given enough training time, the algorithm is guaranteed 92 to find a weight setting W pocket that will correctly classify as large a subset of the training set as possible <ref> [Gal90, Gal93] </ref>. 7.3.2 Thermal Perceptron Learning Algorithm The rationale behind the thermal perceptron algorithm [Fre90a] is to control the weight updates during learning and prevent drastic weight changes in response to patterns that might be outliers. <p> WTA training offers a potential advantage over independent training in that pattern classes that are only pairwise separable from each other can be correctly classified using WTA training while in independent training only pattern classes that are independently separable from all the other classes can be correctly classified <ref> [Gal93] </ref>. 7.4 Multi-Layer Networks A single layer of TLUs is incapable of correctly classifying pattern sets that are not linearly separable. <p> Backpropagation networks thus cannot use threshold neurons. Instead they use neurons implementing the sigmoid activation function. The interested reader is referred to [RHW86] or any popular textbook on neural network learning (such as <ref> [Day90, Gal93, MMR97] </ref>) for a derivation of the backpropagation weight update rule. The backpropagation algorithm and its extensions have been successfully used in several practical applications. However, the backpropagation like training algorithms suffer from the following important drawbacks: * A-priori fixed network topology. <p> error minimization by gradient descent, they are susceptible to local minima which prevent the network from converging to the desired solution. 7.4.2 Constructive Learning Algorithms Constructive (or generative) neural network learning algorithms offer an attractive framework for automatic construction of near-minimal networks for pattern classification and inductive knowledge acquisition systems <ref> [Hon90, HU93, Gal93] </ref>. Most constructive learning algorithms are based on simple threshold logic units (TLUs) that implement a hard-limiting function of their inputs. These algorithms start out by training a single TLU (using some variant of the perceptron learning rule [Ros58]) to learn to classify the set of training patterns. <p> correctly classifying patterns belonging to multi 106 ple output classes that are only pairwise separable from each other whereas the traditional method of computing the output of each neuron independently succeeds in correctly classifying all patterns only if the patterns belong to classes that are independently separable from each other <ref> [Gal93] </ref>. It is thus of interest to apply the WTA strategy for computing the outputs in constructive learning algorithms. For details on the adaptation of the TLU training algorithms to the WTA strategy see [YPH98a]. <p> The performance of constructive learning algorithms in this setting of lifelong learning merits further study. 155 9 PRUNING STRATEGIES FOR THE MTILING CONSTRUCTIVE LEARNING ALGORITHM 9.1 Introduction Constructive neural network learning algorithms offer an interesting paradigm for incremental construction of near-minimal architectures for pattern classification problems <ref> [Gal90, Hon90, Gal93, HU93] </ref>. As we saw in chapter 8, constructive learning algorithms enjoy several advantages over the traditional algorithms for learning in multi-layer feed-forward networks.
Reference: [GD + 93] <author> A. Guerin-Dugue et al. </author> <title> Deliverable R1-B1-P Task B1: Databases. Technical report, Elena-NervesII "Enhanced Learning for Evolutive Neural Architecture", ESPRIT-Basic Research Project Number 6891, </title> <booktitle> 1993. </booktitle> <pages> 220 </pages>
Reference-contexts: Datasets We have used an extensive cross section of artificial and real world datasets for our experiments with constructive neural network learning algorithms. These datasets are available either at the UCI Machine Learning Repository [MA94], the ELENA Classification Database <ref> [GD + 93] </ref>, the CMU Connectionist Benchmark 1 , or are artificial datasets generated by us at Iowa State University. Table B.1 summarizes the characteristics of the datasets. Train and Test denote the size of the training and test sets respectively.
Reference: [Gin90] <author> A. Ginsberg. </author> <title> Theory reduction, theory revision, </title> <booktitle> and retranslation. In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 777-782, </pages> <publisher> AAAI/MIT Press, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: Theory refinement systems can be broadly classified into the following three categories: * Purely symbolic approaches These methods use symbolic inductive learning algorithms (such as decision tree induction) for theory revision. Examples of such systems include RTLS <ref> [Gin90] </ref>, EITHER [OM94], PTR [KFS94], and TGCI [DR95]. The EITHER system starts with the 171 given domain knowledge and a set of training examples. It divides the examples into two subsets depending on whether or not the rules in the domain theory are able to correctly classify them.
Reference: [GJ79] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: They have also shown that the problem of identifying a largest linearly separable subset S sep of S is NP-complete. It is widely conjectured that no polynomial time algorithms exist for NP-complete problems <ref> [GJ79] </ref>. Thus, we rely on heuristic algorithms (such as the pocket algorithm with ratchet modification ) to correctly classify as large a subset of training patterns as possible within the given constraints like limited training time.
Reference: [GM93] <author> S. Goldman and H. Mathias. </author> <title> Teaching a smarter learner. </title> <booktitle> In Proceedings of the Workshop on Computational Learning Theory (COLT'93), </booktitle> <pages> pages 67-76, </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Further, we demonstrate how the model of learning from simple examples naturally extends the model of learning concepts from representative examples [Gol78] and the polynomial teachability model <ref> [GM93] </ref> to a probabilistic framework. This chapter is organized as follows: Section 6.2 briefly introduces some of the concepts that are used in the results described in this chapter. This includes a discussion of the PAC learning model, Kolmogorov complexity, and the universal distribution. <p> Thus, the class of DFA is efficiently PAC learnable under the PACS model. 2 6.6 Relating the PACS Model with other Learning Models In this section we analyze the PACS model in relation with Gold's model of polynomial identifiability from characteristic samples [Gol78] and Goldman and Mathias' polynomial teach-ability model <ref> [GM93] </ref> and explain how the PACS learning model naturally extends these two models to a probabilistic framework. <p> any arbitrary set of examples but a special set that enables the learning algorithm to correctly infer the target concept in polynomial time (see the RPNI algorithm in section 6.3). 6.6.2 Polynomial Teachability of Concept Classes Goldman and Mathias developed a teacher-student based model for efficient learning of target concepts <ref> [GM93] </ref>. Their model takes into account the quantity of information that a good teacher must provide to the student (or learner) during learning. <p> Without the restrictive assumption that teacher's computations be performed in polynomial time, the concept class is said to be semi-polynomially T/L teachable. Goldman and Mathias prove that this model avoids collusion <ref> [GM93] </ref>. When this model is adapted to the framework of learning DFA the length of the examples seen by the learner 77 must be included as a parameter in the model.
Reference: [Gol78] <author> E. M. Gold. </author> <title> Complexity of automaton identification from given data. </title> <journal> Information and Control, </journal> <volume> 37(3) </volume> <pages> 302-320, </pages> <year> 1978. </year>
Reference-contexts: The problem of learning the target DFA from an arbitrary set of labeled examples is known to be hard to solve <ref> [Gol78] </ref>. Efficient algorithms for learning DFA assume that some additional information is available to the learner. The learner might be provided with a representative set of labeled examples. Further, the availability of a knowledgeable teacher might facilitate learning by allowing the learner to pose queries about the target DFA. <p> On the other hand, negative results abound in the literature. Under the standard complexity theoretic assumption P 6= N P , it is known that no efficient algorithm exists for exactly learning a target regular grammar from an arbitrary set of labeled examples <ref> [Gol78] </ref>. Further, it has also been demonstrated that approximate learning of DFA under the PAC learning model is a hard problem [PW89, KV89]. These challenges make the regular grammar inference problem an attractive one. <p> Gold showed that the problem of identifying the minimum state DFA consistent with a presentation S comprising of a finite non-empty set of positive examples S + and possibly a finite non-empty set of negative examples S is N P -hard <ref> [Gol78] </ref>. <p> Further, we demonstrate how the model of learning from simple examples naturally extends the model of learning concepts from representative examples <ref> [Gol78] </ref> and the polynomial teachability model [GM93] to a probabilistic framework. This chapter is organized as follows: Section 6.2 briefly introduces some of the concepts that are used in the results described in this chapter. This includes a discussion of the PAC learning model, Kolmogorov complexity, and the universal distribution. <p> Thus, the class of DFA is efficiently PAC learnable under the PACS model. 2 6.6 Relating the PACS Model with other Learning Models In this section we analyze the PACS model in relation with Gold's model of polynomial identifiability from characteristic samples <ref> [Gol78] </ref> and Goldman and Mathias' polynomial teach-ability model [GM93] and explain how the PACS learning model naturally extends these two models to a probabilistic framework. <p> Using the above definition Gold's result can be restated as follows: 76 Theorem 6.4 (due to Gold <ref> [Gol78] </ref>) The class of DFA is polynomially identifiable from characteristic samples. The problem of identifying a minimum state DFA that is consistent with an arbitrary labeled sample S = S + [ S is known to be NP-complete [Gol78]. <p> result can be restated as follows: 76 Theorem 6.4 (due to Gold <ref> [Gol78] </ref>) The class of DFA is polynomially identifiable from characteristic samples. The problem of identifying a minimum state DFA that is consistent with an arbitrary labeled sample S = S + [ S is known to be NP-complete [Gol78].
Reference: [GT78] <author> R.C. Gonzales and M.G. Thomason. </author> <title> Syntactic Pattern Recognition An Introduction. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1978. </year>
Reference-contexts: Their simplicity and ease of understanding makes them a widely used class of grammars for modeling several practical grammar inference tasks. Regular grammar inference has been applied in fields such as syntactic pattern recognition, intelligent autonomous agents, language acquisition, computational biology, speech recognition, and the like (see <ref> [GT78, Fu82, MQ86, FLSW90, CM96] </ref>). Regular grammar inference is a difficult problem to solve. It has been actively investigated for over two decades. While there do exist several practically useful heuristic solutions to the problem, we have not yet discovered an efficient general algorithm for learning the target regular grammar.
Reference: [Heb49] <author> D. Hebb. </author> <title> The Organization of Behavior. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1949. </year>
Reference-contexts: Perhaps the earliest learning algorithm which is still widely used is the Hebbian learning rule <ref> [Heb49] </ref>. It states that connection weights between neurons that are simultaneously on or simultaneously off on similar inputs are reinforced. Rosenblatt proposed a simple iterative strategy called the perceptron learning rule for training the weights of threshold neurons [Ros58]. <p> The following three weight update strategies are prominently used in neural network learning algorithms: 88 * Correlation Learning: It is based on the Hebbian learning rule <ref> [Heb49] </ref> which states that the strength of the connection between two neurons must be gradually reinforced when the neurons have similar outputs in response to similar inputs. * Competitive Learning: When an input pattern is presented to the network the neurons engage in a competitive process that involves self-excitation and mutual
Reference: [Hig96] <author> Colin de la Higuera. </author> <title> Characteristic sets for polynomial grammatical inference. </title> <editor> In L. Miclet and C. Higuera, editors, </editor> <booktitle> Proceedings of the Third ICGI-96, Montpellier, France, Lecture Notes in Artificial Intelligence 1147, </booktitle> <pages> pages 59-71, </pages> <year> 1996. </year>
Reference-contexts: Definition 6.2 (due to <ref> [Hig96] </ref>) C is polynomially identifiable from characteristic samples iff there exist two polynomials p 1 () and p 2 () and an algorithm A such that 1. <p> A scenario in which the teacher constructs a very small teaching set whose examples are unreasonably long is clearly undesirable and must be avoided. This is explained more formally in the following definition. Definition 6.3 (due to <ref> [Hig96] </ref>) A concept class C is semi-polynomially T/L teachable iff there exist polynomials p 1 (), p 2 (), and p 3 (), a teacher T , and a learner L, such that for any adversary ADV and any concept c with representation r that is selected by ADV , after <p> More specifically, by identifying the characteristic set with the teaching sample it was shown that a concept class is polynomially identifiable from characteristic samples iff it is semi-polynomially T/L teachable <ref> [Hig96] </ref>. We now show how the PACS model for learning from simple examples extends the above two models to a probabilistic setting. 78 Lemma 6.5 Let c 2 C be a concept with corresponding representation r 2 R. <p> Very strong negative results in grammar inference were proved recently when it was demonstrated that the classes of context free grammars, linear grammars, simple deterministic grammars, and non-deterministic finite state automata are not learnable under Gold's model for polynomial identification from characteristic samples <ref> [Hig96] </ref>. We proved that any concept learnable under Gold's model is also learnable under the PACS model. The converse of this 195 theorem remains an open problem.
Reference: [Hir90] <author> H. Hirsh. </author> <title> Incremental Version Space Merging: A General Framework for Concept Learning. </title> <publisher> Kluwer Academic, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: The search is continued until no further elimination of elements of 41 fi 0 is possible using safe queries. When an additional positive example is provided the current version space fi i is extended using a technique called incremental version space merging <ref> [Hir90] </ref> to give the modified version space fi i+1 . The set S i+1 = S i [ fsg, where s is the new positive example provided to the learner, is guaranteed to be structurally complete with respect to a sub-automaton A i+1 of the target DFA.
Reference: [Hon90] <author> V. Honavar. </author> <title> Generative Learning Structures and Processes for Generalized Connectionist Networks. </title> <type> PhD dissertation, </type> <institution> University of Wisconsin, Madison, WI, </institution> <year> 1990. </year>
Reference-contexts: Constructive (or generative) neural network learning algorithms offer an attractive frame 6 work for automatic construction of near-minimal networks for pattern classification and inductive knowledge acquisition systems <ref> [Hon90, HU93, Gal93] </ref>. Most constructive learning algorithms are based on simple TLUs that implement a hard-limiting function of their inputs. These algorithms start out by training a single TLU using some variant of the perceptron learning rule [Ros58]. <p> error minimization by gradient descent, they are susceptible to local minima which prevent the network from converging to the desired solution. 7.4.2 Constructive Learning Algorithms Constructive (or generative) neural network learning algorithms offer an attractive framework for automatic construction of near-minimal networks for pattern classification and inductive knowledge acquisition systems <ref> [Hon90, HU93, Gal93] </ref>. Most constructive learning algorithms are based on simple threshold logic units (TLUs) that implement a hard-limiting function of their inputs. These algorithms start out by training a single TLU (using some variant of the perceptron learning rule [Ros58]) to learn to classify the set of training patterns. <p> The focus of this chapter is on learning algorithms that incrementally construct networks of threshold logic units (see chapter 7) to correctly classify a given (typically non-linearly separable) pattern set. Some of the motivations for studying such algorithms <ref> [Hon90, HU93] </ref> include: * Limitations of learning by weight modification alone within an a-priori fixed network topology: Weight modification algorithms typically search for a solution weight vector that satisfies some desired performance criterion (e.g., classification error). <p> The performance of constructive learning algorithms in this setting of lifelong learning merits further study. 155 9 PRUNING STRATEGIES FOR THE MTILING CONSTRUCTIVE LEARNING ALGORITHM 9.1 Introduction Constructive neural network learning algorithms offer an interesting paradigm for incremental construction of near-minimal architectures for pattern classification problems <ref> [Gal90, Hon90, Gal93, HU93] </ref>. As we saw in chapter 8, constructive learning algorithms enjoy several advantages over the traditional algorithms for learning in multi-layer feed-forward networks.
Reference: [Hon94] <author> V. Honavar. </author> <title> Toward learning systems that integrate multiple strategies and representations. </title> <editor> In V. Honavar and L. Uhr, editors, </editor> <booktitle> Artificial Intelligence and Neural Networks: Steps Toward Principled Integration, </booktitle> <pages> pages 615-644. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: 1 INTRODUCTION The ability to learn is one of the central characteristics of intelligent entities. Machine Learning concerns the design and analysis of computational processes that learn from experience <ref> [Hon94, Lan95, RN95, Mit97] </ref>. A typical machine learning system is characterized by its ability to interact with its environment, observe the effects of its own actions, and improve its performance over time.
Reference: [Hry92] <author> T. Hrycej. </author> <title> Modular Learning in Neural Networks. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1992. </year> <month> 221 </month>
Reference-contexts: Several modifications to the perceptron weight update rule e.g., pocket algorithm with ratchet modification [Gal90], thermal perceptron algorithm [Fre90a, Fre92], Loss minimization algorithm <ref> [Hry92] </ref>, and the barycentric correction procedure [Pou95] are proposed to find a reasonably good weight vector that correctly classifies a large fraction of the training set 91 S when S is not linearly separable and to converge to zero classification errors when S is linearly separable.
Reference: [HU79] <author> J. Hopcroft and J. Ullman. </author> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1979. </year>
Reference-contexts: However, decision problems such as whether or not a string is in the language of an unrestricted grammar are unsolvable <ref> [HU79, Mar91] </ref>. Owing to such inherent difficulties there exists no algorithm for identifying a suitable hypothesis for the concept describing palindromes in the space of unrestricted grammars. To make learning tractable, practical inductive learning systems have several biases built into them [Mit80, Mit97]. <p> It finds applications in syntactic pattern recognition [Fu82], intelligent autonomous agents [CM96], and language acquisition [FLSW90]. Regular grammars represent the simplest class in the Chomsky hierarchy of formal language grammars <ref> [Cho56, HU79] </ref> and describe the class of languages (regular languages) that can be generated (and recognized) by DFA. Since regular grammars represent a widely used subset of formal grammars, considerable research has focused on regular grammar inference (or equivalently, identification of the corresponding DFA). <p> More importantly, decision problems such as the equivalence of two DFA, minimization of a DFA, determining if the language of a DFA is a superset/subset of the language of another, and such can be solved using efficient (i.e., polynomial time) algorithms <ref> [HU79, Mar91] </ref>. Thus, DFA is the popular representation choice for regular grammars in the area of regular grammar inference. <p> An example sub-automaton of the DFA in Fig. 3.1 is shown in Fig. 3.4. The interested reader is referred to <ref> [HU79, LP81, Mar91] </ref> for a detailed description of the theory of finite state automata, regular grammars, and languages. 22 3.3.5 Structurally Complete Sample Given a regular grammar G, a structurally complete set of examples S + is one that covers each production rule of G at least once. <p> Some of the elements in the lattice represent NFA. Pao and Carr's algorithm requires that NFA be converted to equivalent DFA and then used for generating the query string. However, the algorithm for converting NFA to DFA has exponential time complexity in the worst case <ref> [HU79] </ref>. 1 Note that Pao and Carr define a structurally complete set as one that covers all the transitions of the target DFA. <p> The process of converting a NFA to an equivalent DFA has exponential time complexity in the worst case <ref> [HU79] </ref>. Our method restricts the search to DFA alone thereby circumventing the problem. 3. Partial inference using the version space. The properties of the version space allow the algorithm to make partial inferences even 38 before the algorithm has converged to the target DFA.
Reference: [HU93] <author> V. Honavar and L. Uhr. </author> <title> Generative learning structures and processes for connectionist networks. </title> <journal> Information Sciences, </journal> <volume> 70 </volume> <pages> 75-108, </pages> <year> 1993. </year>
Reference-contexts: Constructive (or generative) neural network learning algorithms offer an attractive frame 6 work for automatic construction of near-minimal networks for pattern classification and inductive knowledge acquisition systems <ref> [Hon90, HU93, Gal93] </ref>. Most constructive learning algorithms are based on simple TLUs that implement a hard-limiting function of their inputs. These algorithms start out by training a single TLU using some variant of the perceptron learning rule [Ros58]. <p> error minimization by gradient descent, they are susceptible to local minima which prevent the network from converging to the desired solution. 7.4.2 Constructive Learning Algorithms Constructive (or generative) neural network learning algorithms offer an attractive framework for automatic construction of near-minimal networks for pattern classification and inductive knowledge acquisition systems <ref> [Hon90, HU93, Gal93] </ref>. Most constructive learning algorithms are based on simple threshold logic units (TLUs) that implement a hard-limiting function of their inputs. These algorithms start out by training a single TLU (using some variant of the perceptron learning rule [Ros58]) to learn to classify the set of training patterns. <p> The focus of this chapter is on learning algorithms that incrementally construct networks of threshold logic units (see chapter 7) to correctly classify a given (typically non-linearly separable) pattern set. Some of the motivations for studying such algorithms <ref> [Hon90, HU93] </ref> include: * Limitations of learning by weight modification alone within an a-priori fixed network topology: Weight modification algorithms typically search for a solution weight vector that satisfies some desired performance criterion (e.g., classification error). <p> The performance of constructive learning algorithms in this setting of lifelong learning merits further study. 155 9 PRUNING STRATEGIES FOR THE MTILING CONSTRUCTIVE LEARNING ALGORITHM 9.1 Introduction Constructive neural network learning algorithms offer an interesting paradigm for incremental construction of near-minimal architectures for pattern classification problems <ref> [Gal90, Hon90, Gal93, HU93] </ref>. As we saw in chapter 8, constructive learning algorithms enjoy several advantages over the traditional algorithms for learning in multi-layer feed-forward networks.
Reference: [Kat89] <author> B. F. Katz. EBL and SBL: </author> <title> A neural network synthesis. </title> <booktitle> In Proceedings of the Eleventh Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 683-689, </pages> <year> 1989. </year>
Reference-contexts: Their rules-to-network algorithm constructs an AND-OR graph representation of the initial domain knowledge and translates this graph to an appropriate neural network topology. KBANN then uses the standard backpropagation learning algorithm [RHW86] to refine the do 172 main knowledge. The approaches described by Fu [Fu89] and Katz <ref> [Kat89] </ref> are similar to the KBANN algorithm. Unlike the symbolic and ILP based methods for theory refinement, the connectionist approaches require that the domain knowledge be translated into an appropriate initial neural network topology.
Reference: [KFS94] <author> M. Kopel, R. Feldman, and A. Serge. </author> <title> Bias-driven revision of logical domain theories. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 159-208, </pages> <year> 1994. </year>
Reference-contexts: Theory refinement systems can be broadly classified into the following three categories: * Purely symbolic approaches These methods use symbolic inductive learning algorithms (such as decision tree induction) for theory revision. Examples of such systems include RTLS [Gin90], EITHER [OM94], PTR <ref> [KFS94] </ref>, and TGCI [DR95]. The EITHER system starts with the 171 given domain knowledge and a set of training examples. It divides the examples into two subsets depending on whether or not the rules in the domain theory are able to correctly classify them.
Reference: [Koh88] <author> T. Kohonen. </author> <title> Self-Organization and Associative Memory. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: This results in the development of networks where each neuron specializes on subsets of training patterns that share similar characteristics. Kohonen's self organizing maps (SOM) <ref> [Koh88] </ref> and Carpenter and Grossberg's adaptive resonance theory networks (ART) [CG88] are examples of neural networks that use competitive learning. * Feedback Learning: Here the weights of the network are modified based on the feedback received by the learner from its environment.
Reference: [Koh89] <author> T Kohonen. </author> <title> Self-Organization and Associative Memory. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: It partitions the N -dimensional instance space into connected regions called Voronoi regions [OBS92] and represents each region using a discrete valued code book vector. The learning vector quantizer (LVQ) algorithm is one method for performing vector quantization <ref> [Koh89] </ref>. LVQ trains a single layer of k neurons each of which is assigned an arbitrarily chosen class label. The parameter k is chosen heuristically.
Reference: [KV89] <author> M. Kearns and L. G. Valiant. </author> <title> Cryptographic limitations on learning boolean formulae and finite automata. </title> <booktitle> In Proceedings of the 21 st Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 433-444, </pages> <year> 1989. </year>
Reference-contexts: Further, it has also been demonstrated that approximate learning of DFA under the PAC learning model is a hard problem <ref> [PW89, KV89] </ref>. These challenges make the regular grammar inference problem an attractive one. An understanding of the issues and pitfalls of learning regular grammars might provide insights into the problem of learning more general classes of grammars in the formal language hierarchy. <p> Kearns and Valiant showed that an efficient algorithm for learning DFA would entail efficient algorithms for solving problems such as breaking the RSA cryptosystem, factoring Blum integers, and detecting quadratic residues <ref> [KV89] </ref>. Under cryptographic assumptions it is known that these problems are known to be hard to solve. Thus, they showed that DFA learning is a hard problem. The PAC model's requirement of learnability under all conceivable distributions is often considered too stringent for practical learning scenarios. <p> We describe this algorithm, prove its convergence, and analyze its time and space complexities in chapter 5. 16 2.5.3 Learning DFA from Simple Examples In chapter 6 we address the issue of PAC learning of DFA. PAC learning of DFA is known to be a hard problem <ref> [PW89, KV89] </ref>. An interesting open research question (due to [Pit89]) is whether DFA can be learned approximately under restricted classes of distributions. Li and Vitanyi proposed a model for PAC learning with simple examples wherein the examples are drawn according to the Solomonoff-Levin universal distribution (universal distribution). <p> Angluin's L fl algorithm [Ang87] that learns DFA in polynomial time using membership and equivalence queries can be recast under the PAC framework to learn by posing membership queries alone. However, the approximate learnability 56 of DFA from labeled examples alone remains a hard problem <ref> [PW89, KV89] </ref>. The PAC model's requirement of learnability under all conceivable distributions is often considered too stringent. Pitt's seminal paper identified the following open research problem: "Are DFA's PAC-identifiable if examples are drawn from the uniform distribution, or some other known simple distribution?" [Pit89]. <p> Some of the negative results in approximate identification of DFA are derived by showing that an efficient algorithm for learning DFA would entail algorithms for solving known hard problems such as learning boolean formulae [PW88] and breaking the RSA cryptosystem <ref> [KV89] </ref>. It would be interesting to explore the implications of our results on efficient learning of DFA from simple examples on these problems. 81 PART II CONSTRUCTIVE NEURAL NETWORKS 82 7 INTRODUCTION TO ARTIFICIAL NEURAL NETWORKS Artificial Neural Networks (ANN) are biologically inspired models of computation.
Reference: [KV94] <author> M. Kearns and U. Vazirani. </author> <title> An Introduction to Computational Learning Theory. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: In addition, theoretical results on learnability have shown that certain concept classes can be efficiently learned provided the hypothesis space is restricted to a set of compact representations <ref> [Nat91, KV94] </ref>. <p> Valiant's distribution-independent model of learning, also called the probably approximately correct (PAC) learning model [Val84], is a widely used framework for approximate learning of concept classes. PAC learning models natural learning in that it is fast (learning takes place in polynomial time) and it suffices to learn approximately <ref> [KV94] </ref>. When adapted to the problem of learning DFA, the goal of a PAC learning algorithm is to obtain in polynomial time, with high probability, a DFA that is approximately correct when compared to the target DFA. We define PAC learning of DFA more formally in section 6.2. <p> In addition, theoretical results on learnability have shown that certain concept classes can be efficiently learned provided the hypothesis space is restricted to a set of compact representations <ref> [Nat91, KV94] </ref>. Constructive learning algorithms offer the following advantages over the conventional backpropagation style learning algorithms: * They obviate the need for an ad-hoc, a-priori choice of the network topology. Instead, 97 an appropriate network topology is dynamically determined during training.
Reference: [Lan92] <author> K. J. Lang. </author> <title> Random DFAs can be approximately learned from sparse uniform sample. </title> <booktitle> In Proceedings of the 5th ACM workshop on Computational Learning Theory, </booktitle> <pages> pages 45-52, </pages> <year> 1992. </year>
Reference-contexts: Using a variant of Trakhtenbrot and Barzdin's algorithm, Lang empirically demonstrated that random DFA are approximately learnable from a sparse uniform sample <ref> [Lan92] </ref>.
Reference: [Lan95] <author> P. Langley. </author> <title> Elements of Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, CA, </address> <year> 1995. </year>
Reference-contexts: 1 INTRODUCTION The ability to learn is one of the central characteristics of intelligent entities. Machine Learning concerns the design and analysis of computational processes that learn from experience <ref> [Hon94, Lan95, RN95, Mit97] </ref>. A typical machine learning system is characterized by its ability to interact with its environment, observe the effects of its own actions, and improve its performance over time. <p> Grammar inference is the process of learning a target grammar from a set of labeled examples <ref> [BF72, FB75, MQ86, Lan95] </ref>. It finds applications in syntactic pattern recognition [Fu82], intelligent autonomous agents [CM96], and language acquisition [FLSW90]. <p> Finally, we conclude in chapter 11 with a summary of the research contributions of this dissertation and highlight some interesting directions for future research. 7 PART I LEARNING DETERMINISTIC FINITE AUTOMATA 8 2 INTRODUCTION TO REGULAR GRAMMAR INFERENCE Regular Grammar Inference <ref> [BF72, FB75, MQ86, Lan95, PH98a] </ref> is defined as the process of learning the rules of a target regular grammar from a set of labeled examples.
Reference: [LP81] <author> H. R. Lewis and C. H. Papadimitriou. </author> <title> Elements of the Theory of Computation. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year> <month> 222 </month>
Reference-contexts: An example sub-automaton of the DFA in Fig. 3.1 is shown in Fig. 3.4. The interested reader is referred to <ref> [HU79, LP81, Mar91] </ref> for a detailed description of the theory of finite state automata, regular grammars, and languages. 22 3.3.5 Structurally Complete Sample Given a regular grammar G, a structurally complete set of examples S + is one that covers each production rule of G at least once.
Reference: [LS89] <author> G. F. Luger and W. A. Stubblefield. </author> <booktitle> Artificial Intelligence and the Design of Expert Systems. </booktitle> <publisher> Benjamin Cummings, </publisher> <address> Redwood City, CA, </address> <year> 1989. </year>
Reference-contexts: In section 10.4 we present the results of our experiments with the Financial Advisor Rule Base <ref> [LS89, FO93] </ref> and two datasets from the Human Genome Project (ribosome binding sites and DNA promoter sequences). <p> Note that this TLU implements the rule "if a 4b &gt; 6 then c". Using the approach outlined above, the initial neural network topology corresponding to the simple financial advisor rule base (due to <ref> [LS89] </ref>) of Fig. 10.6 is shown in Fig. 10.7. Each TLU in the network computes a bipolar hardlimiting function (i.e., the TLU's outputs are 1 and 1) of the weighted sum of its inputs. The neurons in the first hidden layer encode the rules 6-9 of the rule base.
Reference: [LV91] <author> M. Li and P. Vitanyi. </author> <title> Learning simple concepts under simple distributions. </title> <journal> SIAM Journal of Computing, </journal> <volume> 20 </volume> <pages> 911-935, </pages> <year> 1991. </year>
Reference-contexts: ff0g; f1; 4g; f2; 3; 5gg baa ff0g; f1; 3; 4; 5g; f2gg ff0g; f1; 3; 4; 5g; f2gg a 65 6.4 Learning Simple DFA under the Simple PAC model Li and Vitanyi proposed the simple PAC learning model where the class of probability distributions is restricted to simple distributions <ref> [LV91] </ref>. A distribution is simple if it is multiplicatively dominated by some enumerable distribution. All computable distributions including the distributions that we commonly use in statistics such as the uniform distribution, normal distribution, geometric distribution, and Poisson distribution are simple. Simple distributions thus include a broad range of distributions. <p> Further, the simple distribution independent learning theorem due to Li and Vitany i says that that a concept class is learnable under universal distribution m iff it is learnable under the entire class of simple distributions provided the training examples are drawn according to the universal distribution <ref> [LV91] </ref>. Thus, the simple PAC learning model is sufficiently general. Concept classes such as log n-term DNF and simple k-reversible DFA are learnable under the simple PAC model whereas their PAC learnability in the standard sense is unknown [LV91]. <p> distributions provided the training examples are drawn according to the universal distribution <ref> [LV91] </ref>. Thus, the simple PAC learning model is sufficiently general. Concept classes such as log n-term DNF and simple k-reversible DFA are learnable under the simple PAC model whereas their PAC learnability in the standard sense is unknown [LV91]. We show that the class of simple DFA is polynomially learnable under the simple PAC learning model. A DFA with low Kolmogorov complexity is called a simple DFA. <p> Li and Vitany i have shown that a concept class is efficiently learnable under the universal distribution if and only if it is efficiently learnable under each simple distribution provided the sampling is done according to the universal distribution <ref> [LV91] </ref>. This raises the possibility of using sampling under the universal distribution to learn under all computable distributions. However, the universal distribution is not computable. Whether one can instead get by with a polynomially computable approximation of the universal distribution remains an open question. <p> However, the universal distribution is not computable. Whether one can instead get by with a polynomially computable approximation of the universal distribution remains an open question. It is known that the universal distribution for the class of polynomially-time bounded simple distributions is computable in exponential time <ref> [LV91] </ref>. This opens up a number of interesting possibilities for learning under simple distributions. In a recent paper Denis and Gilleron have proposed a new model of learning under helpful distributions [DG97].
Reference: [LV93] <author> M. Li and P. Vitanyi. </author> <title> An Introduction to Kolmogorov Complexity and its Applications. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: The Coding Theorem due independently to Schnorr, Levin, and Chaitin <ref> [LV93, LV97] </ref> states that 9 2 N such that 8ff m M (ff) 2 K (ff) : Intuitively this means that if there are several programs for a string ff on some machine M then there is a short program for ff on the universal Turning machine (i.e., ff has a <p> Further, m r is such that 2 K (ffjr) m r (ff) 2 K (ffjr) where is a constant. The interested reader is referred to <ref> [LV93, LV97] </ref> for a thorough treatment of Kolmogorov complexity, universal distribution, and related topics. 6.3 The RPNI Algorithm The regular positive and negative inference (RPNI) algorithm [OG92] is a polynomial time algorithm for identification of a DFA consistent with a given set S = S + [ S .
Reference: [LV97] <author> M. Li and P. Vitanyi. </author> <title> An Introduction to Kolmogorov Complexity and its Applications, 2 nd edition. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1997. </year>
Reference-contexts: The Coding Theorem due independently to Schnorr, Levin, and Chaitin <ref> [LV93, LV97] </ref> states that 9 2 N such that 8ff m M (ff) 2 K (ff) : Intuitively this means that if there are several programs for a string ff on some machine M then there is a short program for ff on the universal Turning machine (i.e., ff has a <p> Further, m r is such that 2 K (ffjr) m r (ff) 2 K (ffjr) where is a constant. The interested reader is referred to <ref> [LV93, LV97] </ref> for a thorough treatment of Kolmogorov complexity, universal distribution, and related topics. 6.3 The RPNI Algorithm The regular positive and negative inference (RPNI) algorithm [OG92] is a polynomial time algorithm for identification of a DFA consistent with a given set S = S + [ S .
Reference: [MA94] <author> P. Murphy and D. Aha. </author> <title> UCI repository of machine learning databases. </title> <institution> Department of Information and Computer Science, University of California, </institution> <address> Irvine, CA, </address> <year> 1994. </year>
Reference-contexts: Datasets We have used an extensive cross section of artificial and real world datasets for our experiments with constructive neural network learning algorithms. These datasets are available either at the UCI Machine Learning Repository <ref> [MA94] </ref>, the ELENA Classification Database [GD + 93], the CMU Connectionist Benchmark 1 , or are artificial datasets generated by us at Iowa State University. Table B.1 summarizes the characteristics of the datasets. Train and Test denote the size of the training and test sets respectively.
Reference: [Mae95] <author> P. Maes. </author> <title> Agents that reduce work and information overload. </title> <journal> Communications of the ACM, </journal> <volume> 38(11) </volume> <pages> 108-114, </pages> <year> 1995. </year>
Reference-contexts: Inductive learning systems have been successfully used in a variety of application domains including autonomously steering a vehicle on public highways [Pom89], automatically learning users' preferences and assisting them in coping with the information overload <ref> [Mae95] </ref>, and discovering interesting new rules from large databases [FPSS96]. The goal of a typical inductive learning system is to construct a concise model that correctly explains the observed examples. <p> notion of simplicity that is implicit in these scenarios with Kolmogorov complexity that provides a measure of intrinsic complexity of an object. 11.2.2 Modeling the Behavior of Intelligent Autonomous Agents Intelligent autonomous agents have been successfully applied in several domains such as personalized e-mail filtering, news weeding, electronic commerce, etc. <ref> [Mae95] </ref>. It is of interest to design a formal framework to model agent behavior. Regular grammars can be used to capture the behavior of intelligent agents like robots navigating in a finite world.
Reference: [Mar91] <author> J. C. Martin. </author> <title> Introduction to Languages and The Theory of Computation. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: However, decision problems such as whether or not a string is in the language of an unrestricted grammar are unsolvable <ref> [HU79, Mar91] </ref>. Owing to such inherent difficulties there exists no algorithm for identifying a suitable hypothesis for the concept describing palindromes in the space of unrestricted grammars. To make learning tractable, practical inductive learning systems have several biases built into them [Mit80, Mit97]. <p> More importantly, decision problems such as the equivalence of two DFA, minimization of a DFA, determining if the language of a DFA is a superset/subset of the language of another, and such can be solved using efficient (i.e., polynomial time) algorithms <ref> [HU79, Mar91] </ref>. Thus, DFA is the popular representation choice for regular grammars in the area of regular grammar inference. <p> An example sub-automaton of the DFA in Fig. 3.1 is shown in Fig. 3.4. The interested reader is referred to <ref> [HU79, LP81, Mar91] </ref> for a detailed description of the theory of finite state automata, regular grammars, and languages. 22 3.3.5 Structurally Complete Sample Given a regular grammar G, a structurally complete set of examples S + is one that covers each production rule of G at least once.
Reference: [MGR90] <author> M. Marchand, M. Golea, and P. Rujan. </author> <title> A convergence theorem for sequential learning in two-layer perceptrons. </title> <journal> Europhysics Letters, </journal> <volume> 11(6) </volume> <pages> 487-492, </pages> <year> 1990. </year>
Reference-contexts: These include, among others, the tower , pyramid [Gal90], tiling [MN89], upstart [Fre90b], perceptron cascade [Bur94], and sequential <ref> [MGR90] </ref>. With the exception of the upstart and the perceptron cascade algorithms all the constructive learning algorithms require the input attributes to be either binary or bipolar valued. <p> A number of algorithms that incrementally construct networks of threshold neurons for 2-category pattern classification tasks have been proposed in the literature. These include the tower , pyramid [Gal90], tiling [MN89], upstart [Fre90b], perceptron cascade [Bur94], and sequential <ref> [MGR90] </ref>. <p> have shown that if the output of the master neurons is computed according to the WTA strategy there is a weight setting for a newly added group of master neurons which will reduce the number of misclassifications by at least one. 137 8.7 Sequential Learning Algorithm The sequential learning algorithm <ref> [MGR90] </ref> offers an alternative method for network construction where instead of training neurons to correctly classify a maximal subset of the training patterns, the idea is to train hidden neurons to sequentially exclude patterns belonging to one class from the remaining patterns. <p> Theorem 8.7 (Sequential Learning Theorem 8 ) The internal representation of the training patterns that are excluded sequentially by the neu 8 A version of the sequential learning theorem for two category pattern classification was originally proposed by <ref> [MGR90] </ref>. 140 rons in the single hidden layer is linearly separable. Proof: Let X p be a pattern belonging to j (1 j M ) and excluded by neuron L 1 k (1 k U L1 ). <p> As we saw in chapter 8, constructive learning algorithms enjoy several advantages over the traditional algorithms for learning in multi-layer feed-forward networks. Several constructive learning algorithms have been proposed in the literature | tower , pyramid [Gal90], tiling [MN89], upstart [Fre90b], perceptron cascade [Bur94], and sequential <ref> [MGR90] </ref>.
Reference: [Mit80] <author> T. Mitchell. </author> <title> The need for biases in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Rutgers University, </institution> <address> New Brunswick, NJ, </address> <year> 1980. </year>
Reference-contexts: Owing to such inherent difficulties there exists no algorithm for identifying a suitable hypothesis for the concept describing palindromes in the space of unrestricted grammars. To make learning tractable, practical inductive learning systems have several biases built into them <ref> [Mit80, Mit97] </ref>. A language bias enables the system to focus on only one suitably chosen hypothesis description language. A strong language bias thus restricts the hypothesis class that would be considered by the system.
Reference: [Mit82] <author> T. Mitchell. </author> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18 </volume> <pages> 203-226, </pages> <year> 1982. </year>
Reference-contexts: The efficiency of the algorithm thus relies on the fact that the size of these sets at any time is substantially smaller than the size of the entire lattice. The proposed algorithm uses an efficient bidirectional search strategy inspired by Mitchell's version space algorithm <ref> [Mit82] </ref>. Further, we formulate the search procedure such that the problem of converting NFA to DFA is totally avoided. Thus, our approach overcomes both the limitations encountered in Pao and Carr's algorithm. <p> Fig. 4.4 depicts a typical bidirectional search of the lattice. In order to guarantee convergence to the target DFA the version space must satisfy the following properties at all times <ref> [Mit82] </ref>: 1. The elements of S must be maximally special in the sense that 8 i 2 S; 6 9 j 2 S such that j t i .
Reference: [Mit97] <author> T. Mitchell. </author> <title> Machine Learning. </title> <publisher> McGraw Hill, </publisher> <address> New York, </address> <year> 1997. </year>
Reference-contexts: 1 INTRODUCTION The ability to learn is one of the central characteristics of intelligent entities. Machine Learning concerns the design and analysis of computational processes that learn from experience <ref> [Hon94, Lan95, RN95, Mit97] </ref>. A typical machine learning system is characterized by its ability to interact with its environment, observe the effects of its own actions, and improve its performance over time. <p> Owing to such inherent difficulties there exists no algorithm for identifying a suitable hypothesis for the concept describing palindromes in the space of unrestricted grammars. To make learning tractable, practical inductive learning systems have several biases built into them <ref> [Mit80, Mit97] </ref>. A language bias enables the system to focus on only one suitably chosen hypothesis description language. A strong language bias thus restricts the hypothesis class that would be considered by the system.
Reference: [MM94] <author> J. Mahoney and R. Mooney. </author> <title> Comparing methods for refining certainty-factor rule-bases. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pages 173-180, </pages> <year> 1994. </year> <month> 223 </month>
Reference-contexts: RAPTURE is a system for refining domain theories that contains probabilistic rules represented in the certainty-factor format <ref> [MM94] </ref>. It first translates the initial domain theory to an appropriate neural network architecture and then refines the domain theory by using backpropagation training on the network (just as in the case of KBANN). Further, it augments the network topology by adding new neurons using the upstart learning algorithm [Fre90b].
Reference: [MMR97] <author> K. Mehrotra, C. Mohan, and S. Ranka. </author> <title> Elements of Artificial Neural Networks. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1997. </year>
Reference-contexts: These differ chiefly in terms of the choice of the mathematical functions implemented by the individual neurons (processing units), the network topology (fixed or dynamic), the network architecture (number of layers and neurons), the network interconnections (connectivity among the existing neurons), and the training methodology (one-shot or iterative) <ref> [Day90, Gal93, MMR97] </ref>. Traditional ANN algorithms such as backpropagation [RHW86], although successful on several pattern classification tasks, suffer from drawbacks such as restriction to an a-priori fixed network topology, use of the expensive gradient descent based error backpropagation training rule, and susceptibility to local minima. <p> Q-learning is a widely used algorithm for reinforcement learning [Wat89, WD92]. 89 7.2.4 Applications ANN have been successfully applied to problems in the areas of pattern classification, clustering, vector quantization, pattern association, function approximation, optimization, control, and search <ref> [Day90, Gal93, MMR97] </ref>. In this dissertation we focus exclusively on the use of neural networks for pattern classification. Pattern classification involves assigning patterns to one of several a-priori fixed classes. <p> Backpropagation networks thus cannot use threshold neurons. Instead they use neurons implementing the sigmoid activation function. The interested reader is referred to [RHW86] or any popular textbook on neural network learning (such as <ref> [Day90, Gal93, MMR97] </ref>) for a derivation of the backpropagation weight update rule. The backpropagation algorithm and its extensions have been successfully used in several practical applications. However, the backpropagation like training algorithms suffer from the following important drawbacks: * A-priori fixed network topology.
Reference: [MN89] <author> M. Mezard and J. Nadal. </author> <title> Learning feed-forward networks: The tiling algorithm. </title> <journal> J. Phys. A: Math. Gen., </journal> <volume> 22 </volume> <pages> 2191-2203, </pages> <year> 1989. </year>
Reference-contexts: These include, among others, the tower , pyramid [Gal90], tiling <ref> [MN89] </ref>, upstart [Fre90b], perceptron cascade [Bur94], and sequential [MGR90]. With the exception of the upstart and the perceptron cascade algorithms all the constructive learning algorithms require the input attributes to be either binary or bipolar valued. <p> A number of algorithms that incrementally construct networks of threshold neurons for 2-category pattern classification tasks have been proposed in the literature. These include the tower , pyramid [Gal90], tiling <ref> [MN89] </ref>, upstart [Fre90b], perceptron cascade [Bur94], and sequential [MGR90]. <p> The convergence proof for the perceptron cascade algorithm (both in the case of the independent and WTA output strategies) thus follows directly from the proof of the upstart algorithm. 2 127 8.6 Tiling Algorithm The tiling algorithm <ref> [MN89] </ref> constructs a strictly layered network of threshold neurons. The bottom-most layer receives inputs from each of the N input neurons. The neurons in each subsequent layer receive inputs from those in the layer immediately below itself. Each layer maintains a master neuron. <p> The faithfulness criterion states that no two training examples belonging to different classes should produce identical output at any given layer. Faithfulness is clearly a necessary condition for convergence in strictly layered networks <ref> [MN89] </ref>. The proposed extension to multiple output classes involves constructing layers with M master neurons (one for each of the output classes) 6 . Unlike the other algorithms seen before, it is not necessary to preprocess the dataset using projection or normalization. <p> As we saw in chapter 8, constructive learning algorithms enjoy several advantages over the traditional algorithms for learning in multi-layer feed-forward networks. Several constructive learning algorithms have been proposed in the literature | tower , pyramid [Gal90], tiling <ref> [MN89] </ref>, upstart [Fre90b], perceptron cascade [Bur94], and sequential [MGR90]. <p> dep sav adeq 7 if (assets income * 10) then assets hi 8 if (income 25000 + dep * 4000) then dep inc adeq 9 if (debt pmt &lt; income * 0.3) then debt lo 180 Network. 181 used a novel hybrid algorithm that combines the features of the tiling <ref> [MN89] </ref> and the pyramid [Gal90] learning algorithms. In chapter 8 we described provably correct extensions of several constructive learning algorithms to handle multiple output classes and patterns with real-valued attributes.
Reference: [MP43] <author> W. S. Mcculloch and W. Pitts. </author> <title> A logical calculus of ideas immanent in nervous activity. </title> <journal> Bulletin of Mathematical Biophysics, </journal> <volume> 5 </volume> <pages> 115-133, </pages> <year> 1943. </year>
Reference-contexts: Further, the capabilities of the current ANN are considerably limited as compared to capabilities of the brain. 7.1 A Brief History The history of ANN traces back to McCulloch and Pitts' mathematical model of a biological neuron <ref> [MP43] </ref>. Perhaps the earliest learning algorithm which is still widely used is the Hebbian learning rule [Heb49]. It states that connection weights between neurons that are simultaneously on or simultaneously off on similar inputs are reinforced.
Reference: [MP69] <author> M. Minsky and S. Papert. </author> <title> Perceptrons: An Introduction to Computational Geometry. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1969. </year>
Reference-contexts: A language bias enables the system to focus on only one suitably chosen hypothesis description language. A strong language bias thus restricts the hypothesis class that would be considered by the system. For example, the language bias of perceptrons limits them to a hypothesis class of linear discriminant functions <ref> [MP69] </ref>. Since the size of the chosen hypothesis class could be very large or even infinite, a search bias is designed to specify how the system would search the elements of the class to determine a suitable hypothesis and which hypothesis it would prefer among a set of suitable hypotheses. <p> It acts as a binary classifier giving an output of 1 for patterns on one side of the hyperplane and and output of -1 for patterns on the other side. The simplicity of this rule was also its nemesis. Minsky and Pappert demonstrated the limits of the single perceptrons <ref> [MP69] </ref>. In particular, they showed that there are certain datasets (such as the XOR) that cannot be separated by a linear hyperplane. The perceptron algorithm obviously fails in these situations. <p> Note that the first component of the weight vector is the threshold term. Several iterative algorithms are available for finding such a ^ W, if one exists <ref> [Ros58, MP69, Nil65, DH73] </ref>. Most of these are variants of the perceptron weight update rule: W W + (C p O p )X p where &gt; 0 is the learning rate The perceptron weight update rule is guaranteed to find a separating hyperplane if one exists.
Reference: [MQ86] <author> L. Miclet and J. Quinqueton. </author> <title> Learning from examples in sequences and grammatical inference. </title> <editor> In G. Ferrate et al, editor, </editor> <booktitle> Syntactic and Structural Pattern Recognition, </booktitle> <pages> pages 153-171. </pages> <booktitle> NATO ASI Series Vol. </booktitle> <address> F45, </address> <year> 1986. </year>
Reference-contexts: Grammar inference is the process of learning a target grammar from a set of labeled examples <ref> [BF72, FB75, MQ86, Lan95] </ref>. It finds applications in syntactic pattern recognition [Fu82], intelligent autonomous agents [CM96], and language acquisition [FLSW90]. <p> Finally, we conclude in chapter 11 with a summary of the research contributions of this dissertation and highlight some interesting directions for future research. 7 PART I LEARNING DETERMINISTIC FINITE AUTOMATA 8 2 INTRODUCTION TO REGULAR GRAMMAR INFERENCE Regular Grammar Inference <ref> [BF72, FB75, MQ86, Lan95, PH98a] </ref> is defined as the process of learning the rules of a target regular grammar from a set of labeled examples. <p> Their simplicity and ease of understanding makes them a widely used class of grammars for modeling several practical grammar inference tasks. Regular grammar inference has been applied in fields such as syntactic pattern recognition, intelligent autonomous agents, language acquisition, computational biology, speech recognition, and the like (see <ref> [GT78, Fu82, MQ86, FLSW90, CM96] </ref>). Regular grammar inference is a difficult problem to solve. It has been actively investigated for over two decades. While there do exist several practically useful heuristic solutions to the problem, we have not yet discovered an efficient general algorithm for learning the target regular grammar.
Reference: [MSTG89] <author> R. Mooney, J. Shavlik, G. Towell, and Alan Gove. </author> <title> An experimental comparison of symbolic and connectionist learning algorithms. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 775-780. </pages> <publisher> Morgan Kauffman, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: It is likely that these datasets contain a set of carefully engineered features that were selected by experts to work well with the algorithms existing at that time <ref> [MSTG89] </ref>. These inherent limitations of the datasets result in the scenario where it is not possible to improve the generalization on a particular dataset beyond what is achieved by a single layer network. 2.
Reference: [Mug92] <author> S. Muggleton. </author> <title> Inductive Logic Programming. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1992. </year>
Reference-contexts: It then uses the standard decision tree learning algorithm ID3 [Qui86] to invent new rules that correctly classify some of the previously misclassified training examples. * ILP based methods Inductive Logic Programming (ILP) is an area of artificial intelligence research that combines techniques from machine learning with logic programming <ref> [Mug92] </ref>. It uses computational logic as the knowledge representation mechanism and extends the theory and practice of logic to the inductive (rather than the traditional deductive) model of inference.
Reference: [Nat91] <author> B. K. Natarajan. </author> <title> Machine Learning: A Theoretical Approach. </title> <publisher> Morgan Kauffman, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: In addition, theoretical results on learnability have shown that certain concept classes can be efficiently learned provided the hypothesis space is restricted to a set of compact representations <ref> [Nat91, KV94] </ref>. <p> In addition, theoretical results on learnability have shown that certain concept classes can be efficiently learned provided the hypothesis space is restricted to a set of compact representations <ref> [Nat91, KV94] </ref>. Constructive learning algorithms offer the following advantages over the conventional backpropagation style learning algorithms: * They obviate the need for an ad-hoc, a-priori choice of the network topology. Instead, 97 an appropriate network topology is dynamically determined during training.
Reference: [Nil65] <author> N.J. Nilsson. </author> <title> The Mathematical Foundations of Learning Machines. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1965. </year>
Reference-contexts: Note that the first component of the weight vector is the threshold term. Several iterative algorithms are available for finding such a ^ W, if one exists <ref> [Ros58, MP69, Nil65, DH73] </ref>. Most of these are variants of the perceptron weight update rule: W W + (C p O p )X p where &gt; 0 is the learning rate The perceptron weight update rule is guaranteed to find a separating hyperplane if one exists.
Reference: [OBS92] <author> A. Okabe, B. Boots, and K Sugihara. </author> <title> Spatial tessellations : concepts and applications of Voronoi diagrams. </title> <publisher> Wiley and Sons, </publisher> <address> Chichester, England, </address> <year> 1992. </year>
Reference-contexts: Vector Quantization on the other hand is a method of instance based discretization. It partitions the N -dimensional instance space into connected regions called Voronoi regions <ref> [OBS92] </ref> and represents each region using a discrete valued code book vector. The learning vector quantizer (LVQ) algorithm is one method for performing vector quantization [Koh89]. LVQ trains a single layer of k neurons each of which is assigned an arbitrarily chosen class label. The parameter k is chosen heuristically.
Reference: [OG92] <author> J. Oncina and P. Garca. </author> <title> Inferring regular languages in polynomial update time. </title> <editor> In N. Perez et al, editor, </editor> <booktitle> Pattern Recognition and Image Analysis, </booktitle> <pages> pages 49-61, </pages> <publisher> World Scientific, </publisher> <address> New Jersey, </address> <year> 1992. </year> <month> 224 </month>
Reference-contexts: Oncina and Garc ia recently proposed the regular positive and negative inference (RPNI) algorithm that in polynomial time identifies a DFA consistent with a given sample S <ref> [OG92] </ref>. Further, if S is a superset of a characteristic set for the target DFA (see section 3.3.7) then the DFA output by the RPNI algorithm is guaranteed to be equivalent to the target [OG92, Dup96b]. <p> Further, if S is a superset of a characteristic set for the target DFA (see section 3.3.7) then the DFA output by the RPNI algorithm is guaranteed to be equivalent to the target <ref> [OG92, Dup96b] </ref>. A set of labeled examples that satisfy certain properties is one form of additional information that makes the DFA learning problem tractable. Additionally, one may assume the existence of a knowledgeable teacher who responds to queries posed by the learner. <p> Let L de note the language of G (and equivalently the language of A). A sample S = S + [ S is said to be characteristic with respect to a regular language L if it satisfies the following two conditions <ref> [OG92] </ref>: 1. 8ff 2 N (L); if ff 2 L then ff 2 S + else 9fi 2 fl such that fffi 2 S + 2. 8ff 2 S p (L); 8fi 2 N (L); if L ff 6= L fi then 9fl 2 fl such that (fffl 2 S + <p> The algorithm is guaranteed to converge to the target DFA in the limit. The regular positive and negative inference (RPNI) is a polynomial time algorithm for learning a DFA that is consistent with a given set of positive and negative examples <ref> [OG92] </ref> (see section 6.3 for more information). The algorithm maps the set of positive examples to a lattice of finite state automata and uses the information from the set of negative examples to conduct an ordered search through the lattice. <p> The interested reader is referred to [LV93, LV97] for a thorough treatment of Kolmogorov complexity, universal distribution, and related topics. 6.3 The RPNI Algorithm The regular positive and negative inference (RPNI) algorithm <ref> [OG92] </ref> is a polynomial time algorithm for identification of a DFA consistent with a given set S = S + [ S . Further, if the sample is a characteristic set for the target DFA then the algorithm is guaranteed to return a canonical representation of the target DFA.
Reference: [OM94] <author> D. Ourston and R. J. Mooney. </author> <title> Theory refinement: Combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66 </volume> <pages> 273-310, </pages> <year> 1994. </year>
Reference-contexts: Theory refinement systems can be broadly classified into the following three categories: * Purely symbolic approaches These methods use symbolic inductive learning algorithms (such as decision tree induction) for theory revision. Examples of such systems include RTLS [Gin90], EITHER <ref> [OM94] </ref>, PTR [KFS94], and TGCI [DR95]. The EITHER system starts with the 171 given domain knowledge and a set of training examples. It divides the examples into two subsets depending on whether or not the rules in the domain theory are able to correctly classify them.
Reference: [OS95] <author> D. W. Opitz and J. W. Shavlik. </author> <title> Dynamically adding symbolically meaningful nodes to knowledge-based neural networks. </title> <journal> Knowledge-Based Systems, </journal> <volume> 8(6) </volume> <pages> 301-311, </pages> <year> 1995. </year>
Reference-contexts: Opitz and Shavlik have extensively studied connectionist theory refinement systems that overcome the fixed topology limitation of the KBANN algorithm <ref> [OS95, OS97] </ref>. They have focussed on the design of systems that use abundant computational resources to yield theory revision systems with improved generalization performance. <p> Opitz and Shavlik have extensively studied connectionist theory refinement systems that overcome the fixed topology limitation of the KBANN algorithm [OS95, OS97]. They have focussed on the design of systems that use abundant computational resources to yield theory revision systems with improved generalization performance. The TopGen algorithm <ref> [OS95] </ref> searches through the space of possible expansions of a KBANN network to determine the expansion that has the best generalization accuracy on the cross-validation set. <p> These algorithms use the available computing resources to search the space of network topologies in a bid to identify an expansion of the KBANN that generalizes well on test data. Results of experiments with TopGen and REGENT demonstrated a significant performance improvement over the standard KBANN algorithm <ref> [OS95, OS97] </ref>. We have presented an approach for constructive learning in knowledge based neural networks. Our method embeds the original domain theory into an initial neural network and then refines the theory by dynamically adding new TLUs to the network.
Reference: [OS97] <author> D. W. Opitz and J. W. Shavlik. </author> <title> Connectionist theory refinement: Genetically searching the space of network topologies. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 6 </volume> <pages> 177-209, </pages> <year> 1997. </year>
Reference-contexts: Opitz and Shavlik have extensively studied connectionist theory refinement systems that overcome the fixed topology limitation of the KBANN algorithm <ref> [OS95, OS97] </ref>. They have focussed on the design of systems that use abundant computational resources to yield theory revision systems with improved generalization performance. <p> These networks are trained and placed on the queue. The best network on the queue after a prespecified number of epochs is returned. The REGENT algorithm broadens the space of networks searched by TopGen by performing a genetic search in the space of all neural network architectures <ref> [OS97] </ref>. REGENT first creates a diversified population of networks from the initial KBANN. The network's error on a cross-validation set is selected as its measure of fitness. During each generation of the genetic evolution a subset of the population is selected for reproduction. <p> We construct a single network of TLUs as against a population of networks constructed by TopGen and REGENT. The impact of this is on the training time of knowledge based networks. TopGen and REGENT have reportedly taken several days to search 500 networks and report the best <ref> [OS97] </ref>. On the other hand our approach requires only a few minutes of CPU time for training. Related to this issue of training time is TopGen and REGENT's use of the expensive backpropagation style training as opposed to the simple perceptron type weight update rule used in our approach. <p> When compared with the training times for TopGen and REGENT (which are reported to be several days of CPU time <ref> [OS97] </ref>) we see that our method offers a significant advantage over TopGen and REGENT. It must be kept in mind of course that TopGen and REGENT were designed to take advantage of the available computing resources and come up with hypotheses that have good generalization performance. <p> These algorithms use the available computing resources to search the space of network topologies in a bid to identify an expansion of the KBANN that generalizes well on test data. Results of experiments with TopGen and REGENT demonstrated a significant performance improvement over the standard KBANN algorithm <ref> [OS95, OS97] </ref>. We have presented an approach for constructive learning in knowledge based neural networks. Our method embeds the original domain theory into an initial neural network and then refines the theory by dynamically adding new TLUs to the network.
Reference: [PC78] <author> T. Pao and J. Carr. </author> <title> A solution of the syntactic induction-inference problem for regular languages. </title> <journal> Computer Languages, </journal> <volume> 3 </volume> <pages> 53-64, </pages> <year> 1978. </year>
Reference-contexts: Pao and Carr proposed a framework for learning the target DFA from a structurally complete set of positive examples that in essence describes all the transitions and the accepting states of the target DFA (see section 3.3.5) <ref> [PC78] </ref>. Additionally, their algorithm assumes the availability of a knowledgeable teacher capable of answering membership queries. Their algorithm maps the structurally complete set of examples to an ordered lattice of finite state automata (FSA) 1 . This lattice is guaranteed to contain the target DFA. <p> The algorithm searches for the target DFA with the help of membership queries. A membership query is posed to ask the teacher whether an example string belongs to the language of the target DFA or not. Under this framework, the target DFA is shown to be exactly identifiable <ref> [PC78] </ref>. <p> The set of all quotient automata obtained by systematically merging the states of A represents a lattice of FSA <ref> [PC78] </ref>. This lattice is ordered by the grammar cover relation . <p> Further, given a canonical DFA A and a set S + that is structurally complete with respect to A (see section 3.3.5), the lattice (S + ) derived from P T A (S + ) is guaranteed to contain A <ref> [PC78, PH93, DMV94] </ref>. 3.3.4 Sub-automaton A sub-automaton A x for a DFA A (ignoring its dead state d 0 and its associated transitions) is a quintuple A x = (Q x ; ffi x ; ; q 0 ; F x ) where Q x Q, q 0 2 Q x <p> then the set S + is said to be structurally complete with respect to A if S + covers each transition of A (except the transitions associated with the dead state d 0 ) and uses every element of the set of final states of A as an accepting state <ref> [PC78, PH93, DMV94] </ref>. <p> We will assume that the learner is provided with a structurally complete set of examples and is allowed access to a knowledgeable teacher who answers membership queries. The problem of learning the target DFA under this framework was originally studied by Pao and Carr <ref> [PC78] </ref>. Their algorithm maps the structurally complete set of examples to a lattice of finite state automata. The lattice represents the entire search space and is guaranteed to contain a representation of the target DFA 1 . The learner uses membership queries to search the lattice for the target. <p> Proof: The proof of this theorem is originally due to Pao and Carr <ref> [PC78] </ref> and has been reworked in [PH93]. <p> It implicitly represents all elements of the hypothesis space that are consistent with data observed by the learner. An efficient bidirectional search strategy is used to identify the target DFA. Our algorithm has the following advantages when compared to the approach suggested by Pao and Carr <ref> [PC78] </ref>: 1. Implicit representation of the hypothesis space. Pao and Carr's algorithm explicitly constructs the entire lattice . Even for moderately small structurally complete sets of examples the size of the lattice is prohibitively large for explicit enumeration. 2. Restricting the search to DFA alone.
Reference: [PF91] <author> S. Porat and J. Feldman. </author> <title> Learning automata from ordered examples. </title> <journal> Machine Learning, </journal> <volume> 7 </volume> <pages> 109-138, </pages> <year> 1991. </year>
Reference-contexts: representation of the target is modified, it stays consistent with all the previous examples. 13 Porat and Feldman have proposed an incremental algorithm for inference of regular grammars from a complete ordered sample (one that includes all the strings over the alphabet of the DFA up to a certain length) <ref> [PF91] </ref>. The algorithm maintains a current hypothesis that is consistent with all the examples seen thus far. If this hypothesis is inconsistent with the next labeled example then it is modified appropriately to ensure consistency with the new example and also with all the previous examples. <p> Two prominent incremental algorithms for learning DFA are due to Porat and Feld-man <ref> [PF91] </ref> and Dupont [Dup96a] respectively. Porat and Feldman's algorithm learns the target DFA in the limit from a complete ordered sample. A complete ordered sample includes all the strings in fl in strict lexicographic order. The algorithm uses only finite working storage. <p> We are exploring the possibility of learning in an environment where the learner does not have access to a teacher. The algorithms due to Dupont [Dup96a] and Porat & Feldman <ref> [PF91] </ref> operate in this framework. Some open problems include whether the limitations of these algorithms (e.g., the need to store all the examples, the requirement of complete lexicographic ordering of examples, etc.) can be overcome without sacrificing efficiency and guaranteed convergence to the target. <p> Incremental algorithms are guaranteed to converge to the target DFA in the limit. However, these approaches have certain restrictions. RPNI2 requires the learner to store all the examples [Dup96a], Porat and Feldman's algorithm mandates a complete ordered presentation of the labeled examples <ref> [PF91] </ref>, and the IID algorithm described in chapter 5 is based on the availability of a knowledgeable teacher to answer membership queries [PNH97]. It is thus natural to ask whether DFA can be learned approximately.
Reference: [PH93] <author> R. G. Parekh and V. G. Honavar. </author> <title> Efficient learning of regular languages using teacher supplied positive examples and learner generated queries. </title> <booktitle> In Proceedings of the Fifth UNB Conference on AI, Fredricton, Canada, </booktitle> <pages> pages 195-203, </pages> <year> 1993. </year>
Reference-contexts: The size of the lattice is prohibitively large even when the structurally complete set contains only a few short strings. Thus, explicit enumeration of the hypothesis space is not practical. We propose the use of a version space for compactly representing 15 the hypothesis space <ref> [PH93, PH96] </ref>. The version space implicitly represents the entire lattice using two sets of DFA called S and G respectively. S is initialized to the most special DFA called the prefix tree automaton obtained from the structurally complete set of examples. <p> Further, given a canonical DFA A and a set S + that is structurally complete with respect to A (see section 3.3.5), the lattice (S + ) derived from P T A (S + ) is guaranteed to contain A <ref> [PC78, PH93, DMV94] </ref>. 3.3.4 Sub-automaton A sub-automaton A x for a DFA A (ignoring its dead state d 0 and its associated transitions) is a quintuple A x = (Q x ; ffi x ; ; q 0 ; F x ) where Q x Q, q 0 2 Q x <p> then the set S + is said to be structurally complete with respect to A if S + covers each transition of A (except the transitions associated with the dead state d 0 ) and uses every element of the set of final states of A as an accepting state <ref> [PC78, PH93, DMV94] </ref>. <p> This requires that each transition and each accepting state of the target DFA must be covered by the strings in the structurally complete set <ref> [PH93, DMV94, PH96] </ref>. 26 We present an improved learning algorithm based on the version space representation of the lattice of FSA [PH93, PH96]. The version space implicitly represents the entire lattice using two sets of FSA called S and G respectively. <p> This requires that each transition and each accepting state of the target DFA must be covered by the strings in the structurally complete set [PH93, DMV94, PH96]. 26 We present an improved learning algorithm based on the version space representation of the lattice of FSA <ref> [PH93, PH96] </ref>. The version space implicitly represents the entire lattice using two sets of FSA called S and G respectively. The operations on the version space take time polynomial in the size of the S and G sets. <p> Proof: The proof of this theorem is originally due to Pao and Carr [PC78] and has been reworked in <ref> [PH93] </ref>. It was also independently proven by Miclet (see [DMV94]). 2 Theorem 4.2 The following invariance condition holds at all times during the execution of the algorithm. 9 fi 2 G and 9 ff 2 S such that ff t A t fi Proof: We prove this theorem by induction.
Reference: [PH96] <author> R. G. Parekh and V. G. Honavar. </author> <title> An incremental interactive algorithm for regular grammar inference. </title> <editor> In L. Miclet and C. Higuera, editors, </editor> <booktitle> Proceedings of the Third ICGI-96, Montpellier, France, Lecture Notes in Artificial Intelligence 1147, </booktitle> <pages> pages 238-250, </pages> <year> 1996. </year>
Reference-contexts: The size of the lattice is prohibitively large even when the structurally complete set contains only a few short strings. Thus, explicit enumeration of the hypothesis space is not practical. We propose the use of a version space for compactly representing 15 the hypothesis space <ref> [PH93, PH96] </ref>. The version space implicitly represents the entire lattice using two sets of DFA called S and G respectively. S is initialized to the most special DFA called the prefix tree automaton obtained from the structurally complete set of examples. <p> This requires that each transition and each accepting state of the target DFA must be covered by the strings in the structurally complete set <ref> [PH93, DMV94, PH96] </ref>. 26 We present an improved learning algorithm based on the version space representation of the lattice of FSA [PH93, PH96]. The version space implicitly represents the entire lattice using two sets of FSA called S and G respectively. <p> This requires that each transition and each accepting state of the target DFA must be covered by the strings in the structurally complete set [PH93, DMV94, PH96]. 26 We present an improved learning algorithm based on the version space representation of the lattice of FSA <ref> [PH93, PH96] </ref>. The version space implicitly represents the entire lattice using two sets of FSA called S and G respectively. The operations on the version space take time polynomial in the size of the S and G sets. <p> In such scenarios, an online or incremental model of learning that is guaranteed to eventually converge to the target DFA in the limit is of interest. An incremental extension of the version space based learning algorithm of chapter 4 was described in <ref> [PH96] </ref>. The algorithm assumes that positive examples needed to construct a structurally complete set are intermittently presented to the learner. The learner constructs an initial version space representation of the lattice from the set of positive examples S 0 available to it at the start.
Reference: [PH97] <author> R. G. Parekh and V. G. Honavar. </author> <title> Learning DFA from simple examples. </title> <booktitle> In Proceedings of the Eighth International Workshop on Algorithmic Learning Theory (ALT'97), Sendai, Japan, Lecture Notes in Artificial Intelligence 1316, </booktitle> <pages> pages 116-131, </pages> <year> 1997. </year> <title> Also presented at the Workshop on Grammar Inference, Automata Induction, and Language Acquisition (ICML'97), </title> <address> Nashville, TN, </address> <year> 1997. </year> <month> 225 </month>
Reference-contexts: Further, we demonstrate that it is possible to efficiently learn the entire class of DFA under the PACS learning model <ref> [PH97] </ref>.
Reference: [PH98a] <author> R. G. Parekh and V. G. Honavar. </author> <title> Grammar inference, automata induction, and language acquisition. </title> <editor> In Dale, Moisl, and Somers, editors, </editor> <booktitle> Handbook of Natural Language Processing. </booktitle> <publisher> Marcel Dekker, </publisher> <year> 1998. </year> <note> (To appear). </note>
Reference-contexts: Finally, we conclude in chapter 11 with a summary of the research contributions of this dissertation and highlight some interesting directions for future research. 7 PART I LEARNING DETERMINISTIC FINITE AUTOMATA 8 2 INTRODUCTION TO REGULAR GRAMMAR INFERENCE Regular Grammar Inference <ref> [BF72, FB75, MQ86, Lan95, PH98a] </ref> is defined as the process of learning the rules of a target regular grammar from a set of labeled examples.
Reference: [PH98b] <author> R. G. Parekh and V. G. Honavar. </author> <title> Constructive theory refinement in knowledge based neural networks. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks'98, </booktitle> <address> Anchorage, AK, </address> <year> 1998. </year> <note> (To appear). </note>
Reference-contexts: New rules can be incorporated and inaccuracies in the existing rules (if 101 any) can be corrected by dynamically adding new neurons to the neural network representing the domain theory. In chapter 10 we describe a constructive learning based approach to connectionist theory refinement <ref> [PH98b] </ref>. Specifically, we use a novel hybrid Tiling-Pyramid algorithm to augment the original network topology.
Reference: [Pit89] <author> L. Pitt. </author> <title> Inductive inference, DFAs and computational complexity. In Analogical and Inductive Inference, </title> <booktitle> Lecture Notes in Artificial Intelligence 397, </booktitle> <pages> pages 18-44. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Pitt's seminal paper surveyed several approaches to approximate learning of DFA and identified the following open research problem: "Are DFA PAC-identifiable if examples are drawn from the uniform distribution or some other known simple distribution? " <ref> [Pit89] </ref>. Using a variant of Trakhtenbrot and Barzdin's algorithm, Lang empirically demonstrated that random DFA are approximately learnable from a sparse uniform sample [Lan92]. <p> PAC learning of DFA is known to be a hard problem [PW89, KV89]. An interesting open research question (due to <ref> [Pit89] </ref>) is whether DFA can be learned approximately under restricted classes of distributions. Li and Vitanyi proposed a model for PAC learning with simple examples wherein the examples are drawn according to the Solomonoff-Levin universal distribution (universal distribution). This model is referred to as the simple PAC learning model. <p> The PAC model's requirement of learnability under all conceivable distributions is often considered too stringent. Pitt's seminal paper identified the following open research problem: "Are DFA's PAC-identifiable if examples are drawn from the uniform distribution, or some other known simple distribution?" <ref> [Pit89] </ref>. Several efforts have been made to study the learn-ability of concept classes under restricted classes of distributions. Li and Vitanyi proposed a model for PAC learning with simple examples called the simple PAC model wherein the class of distributions is restricted to simple distributions (see section 6.4). <p> Assume that there is an unknown and arbitrary but fixed distribution D according to which the examples of the target concept are drawn. In the context of learning DFA, D is restricted to a probability distribution on strings of fl of length at most m. Definition 6.1 (due to <ref> [Pit89] </ref>) DFAs are PAC-identifiable iff there exists a (possibly randomized) algorithm A such that on input of any parameters * and ffi, for any DFA M of size N , for any number m, and for any probability distribution D on strings of fl of length at most m, if A
Reference: [PK92] <author> M. Pazzani and D. Kibler. </author> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 57-94, </pages> <year> 1992. </year>
Reference-contexts: It uses computational logic as the knowledge representation mechanism and extends the theory and practice of logic to the inductive (rather than the traditional deductive) model of inference. Theory refinement systems such as FOCL <ref> [PK92] </ref> and FORTE [RM95] use first-order logic as the representation scheme in theory revision and thus are said to belong to the class of ILP based techniques. FORTE (First-Order Revision of Theories from Examples) uses a hill-climbing search for refining first-order Horn-clause theories.
Reference: [PNH97] <author> R. G. Parekh, C. Nichitiu, and V. G. Honavar. </author> <title> A polynomial time incremental algorithm for regular grammar inference. </title> <type> Technical Report ISU-CS-TR97-03, </type> <institution> Iowa State University, Ames, Iowa, </institution> <year> 1997. </year>
Reference-contexts: In this chapter we present an extension of ID to an incremental setting. The proposed algorithm IID (incremental ID) is a polynomial time interactive algorithm for learning the 42 target DFA from labeled examples and membership queries <ref> [PNH97] </ref>. IID overcomes the limitations of the version space based incremental algorithm in that it runs in polynomial time and does not require either the knowledge of a bound on the number of states of the target DFA or the presentation of examples in increasing order by length. <p> RPNI2 requires the learner to store all the examples [Dup96a], Porat and Feldman's algorithm mandates a complete ordered presentation of the labeled examples [PF91], and the IID algorithm described in chapter 5 is based on the availability of a knowledgeable teacher to answer membership queries <ref> [PNH97] </ref>. It is thus natural to ask whether DFA can be learned approximately. Valiant's distribution-independent model of learning, also called the probably approximately correct (PAC) learning model [Val84], is a widely used framework for approximate learning of concept classes.
Reference: [Pom89] <author> D. Pomerleau. Alvinn: </author> <title> An autonomous land vehicle in a neural network. </title> <type> Technical Report CMU-CS-89-107, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1989. </year>
Reference-contexts: Inductive learning systems have been successfully used in a variety of application domains including autonomously steering a vehicle on public highways <ref> [Pom89] </ref>, automatically learning users' preferences and assisting them in coping with the information overload [Mae95], and discovering interesting new rules from large databases [FPSS96]. The goal of a typical inductive learning system is to construct a concise model that correctly explains the observed examples.
Reference: [Pou95] <author> H. Poulard. </author> <title> Barycentric correction procedure: A fast method of learning threshold units. </title> <booktitle> In Proceedings of WCNN'95 (vol. 1), </booktitle> <address> Washington D.C., </address> <pages> pages 710-713, </pages> <year> 1995. </year>
Reference-contexts: Several modifications to the perceptron weight update rule e.g., pocket algorithm with ratchet modification [Gal90], thermal perceptron algorithm [Fre90a, Fre92], Loss minimization algorithm [Hry92], and the barycentric correction procedure <ref> [Pou95] </ref> are proposed to find a reasonably good weight vector that correctly classifies a large fraction of the training set 91 S when S is not linearly separable and to converge to zero classification errors when S is linearly separable. <p> A variant of the barycentric correction procedure can be used to efficiently exclude patterns as desired by the sequential learning algorithm <ref> [Pou95] </ref>. 8.1.1 Multi-Category Pattern Classification Pattern classification tasks often require assigning patterns to one of M (M &gt; 2) classes. <p> Recently, Poulard has shown that a variation of the barycentric correction procedure can be used effectively in sequential learning to exclude as many patterns belonging to a single class as possible <ref> [Pou95] </ref>. The extension of the sequential learning algorithm to multiple output categories follows the same principles as the original version. Using a simple modification of the barycentric correction procedure , hidden neurons can be trained to exclude patterns belonging to one of the M classes from the remaining patterns. <p> Algorithms such as the pocket algorithm with ratchet modification [Gal90], the thermal perceptron algorithm [Fre92], and the 156 barycentric correction procedure <ref> [Pou95] </ref> are commonly used for training individual TLUs (or groups of TLUs) in constructive learning algorithms. We denote such a suitable TLU training algorithm by A.
Reference: [PW88] <author> L. Pitt and M. K. Warmuth. </author> <title> Reductions among prediction problems: on the difficulty of predicting automata. </title> <booktitle> In Proceedings of the 3 rd IEEE Conference on Structure in Complexity Theory, </booktitle> <pages> pages 60-69, </pages> <year> 1988. </year>
Reference-contexts: theoretic assumption P 6= N P , Pitt and Warmuth showed that there exists no polynomial time algorithm which when presented with a set of labeled examples corresponding to a DFA with N states is guaranteed to produce a DFA that is at most polynomially larger than the target DFA <ref> [PW88] </ref>. Efficient learning algorithms for exact identification of DFA assume that some additional 10 information is provided to the learner. <p> Some of the negative results in approximate identification of DFA are derived by showing that an efficient algorithm for learning DFA would entail algorithms for solving known hard problems such as learning boolean formulae <ref> [PW88] </ref> and breaking the RSA cryptosystem [KV89].
Reference: [PW89] <author> L. Pitt and M. K. Warmuth. </author> <title> The minimum consistency dfa problem cannot be approximated within any polynomial. </title> <booktitle> In Proceedings of the 21 st ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 421-432, </pages> <year> 1989. </year> <month> 226 </month>
Reference-contexts: Further, it has also been demonstrated that approximate learning of DFA under the PAC learning model is a hard problem <ref> [PW89, KV89] </ref>. These challenges make the regular grammar inference problem an attractive one. An understanding of the issues and pitfalls of learning regular grammars might provide insights into the problem of learning more general classes of grammars in the formal language hierarchy. <p> Even approximate learnability of DFA was proven to be a hard problem. Pitt and Warmuth showed that the problem of polynomially approximate predictability of the class of DFA is hard <ref> [PW89] </ref>. Using prediction preserving reductions they showed that if DFA are polynomially approximately predictable then so are other known hard to predict concept classes such as boolean formulas. <p> We describe this algorithm, prove its convergence, and analyze its time and space complexities in chapter 5. 16 2.5.3 Learning DFA from Simple Examples In chapter 6 we address the issue of PAC learning of DFA. PAC learning of DFA is known to be a hard problem <ref> [PW89, KV89] </ref>. An interesting open research question (due to [Pit89]) is whether DFA can be learned approximately under restricted classes of distributions. Li and Vitanyi proposed a model for PAC learning with simple examples wherein the examples are drawn according to the Solomonoff-Levin universal distribution (universal distribution). <p> Angluin's L fl algorithm [Ang87] that learns DFA in polynomial time using membership and equivalence queries can be recast under the PAC framework to learn by posing membership queries alone. However, the approximate learnability 56 of DFA from labeled examples alone remains a hard problem <ref> [PW89, KV89] </ref>. The PAC model's requirement of learnability under all conceivable distributions is often considered too stringent. Pitt's seminal paper identified the following open research problem: "Are DFA's PAC-identifiable if examples are drawn from the uniform distribution, or some other known simple distribution?" [Pit89].
Reference: [PYH95] <author> R. Parekh, J. Yang, and V. Honavar. </author> <title> Constructive neural network learning algorithms for multi-category classification. </title> <type> Technical Report ISU-CS-TR95-15a, </type> <institution> Iowa State University, Ames, IA, </institution> <year> 1995. </year>
Reference-contexts: For each of the constructive learning algorithms mentioned above we have designed provably correct extensions to handle tasks involving multiple output categories and real-valued pattern attributes (see <ref> [PYH95, YPH96, PYH97b, PYH97a] </ref>). The convergence proofs for these algorithms outline a general framework for proving the convergence of constructive learning algorithms. Experiments on several artificial and real world datasets have demonstrated the practical applicability of these constructive learning algorithms. <p> In other cases, only some preliminary ideas (not supported by detailed theoretical or experimental analysis) for possible multi-category extensions of 2-category algorithms are available in the literature. A preliminary analysis of the extension of constructive learning algorithms to handle multi-category classification tasks is presented in <ref> [PYH95] </ref>. For pattern sets that involve multiple output classes, training can be performed either independently or by means of the winner-take-all (WTA) strategy. In the former, each output neuron is trained independently of the others using one of the TLU weight training algorithms mentioned earlier. <p> Against this background, the focus of this chapter is on provably convergent multi-category learning algorithms for construction of networks of threshold neurons for pattern classification tasks with real-valued attributes. These results are based on the work described earlier in <ref> [PYH95, YPH96, PYH97b, PYH97a] </ref>. The remainder of this chapter is organized as follows: Sections 8.2 through 8.7 explore the multi-category versions of the tower , pyramid , upstart , perceptron cascade , tiling and sequential learning algorithms respectively.
Reference: [PYH97a] <author> R. G. Parekh, J. Yang, and V. G. Honavar. </author> <title> Constructive neural network learning algorithms for multi-category real-valued pattern classification. </title> <type> Technical Report ISU-CS-TR97-06, </type> <institution> Iowa State University, Ames, IA, </institution> <year> 1997. </year> <note> (Submitted for review to the IEEE Transactions on Neural Networks). </note>
Reference-contexts: For each of the constructive learning algorithms mentioned above we have designed provably correct extensions to handle tasks involving multiple output categories and real-valued pattern attributes (see <ref> [PYH95, YPH96, PYH97b, PYH97a] </ref>). The convergence proofs for these algorithms outline a general framework for proving the convergence of constructive learning algorithms. Experiments on several artificial and real world datasets have demonstrated the practical applicability of these constructive learning algorithms. <p> Against this background, the focus of this chapter is on provably convergent multi-category learning algorithms for construction of networks of threshold neurons for pattern classification tasks with real-valued attributes. These results are based on the work described earlier in <ref> [PYH95, YPH96, PYH97b, PYH97a] </ref>. The remainder of this chapter is organized as follows: Sections 8.2 through 8.7 explore the multi-category versions of the tower , pyramid , upstart , perceptron cascade , tiling and sequential learning algorithms respectively.
Reference: [PYH97b] <author> R. G. Parekh, J. Yang, and V. G. Honavar. </author> <title> Mupstart a constructive neural network learning algorithm for multi-category pattern classification. </title> <booktitle> In Proceedings of the IEEE/INNS International Conference on Neural Networks, ICNN'97, </booktitle> <pages> pages 1924-1929, </pages> <year> 1997. </year>
Reference-contexts: For each of the constructive learning algorithms mentioned above we have designed provably correct extensions to handle tasks involving multiple output categories and real-valued pattern attributes (see <ref> [PYH95, YPH96, PYH97b, PYH97a] </ref>). The convergence proofs for these algorithms outline a general framework for proving the convergence of constructive learning algorithms. Experiments on several artificial and real world datasets have demonstrated the practical applicability of these constructive learning algorithms. <p> Against this background, the focus of this chapter is on provably convergent multi-category learning algorithms for construction of networks of threshold neurons for pattern classification tasks with real-valued attributes. These results are based on the work described earlier in <ref> [PYH95, YPH96, PYH97b, PYH97a] </ref>. The remainder of this chapter is organized as follows: Sections 8.2 through 8.7 explore the multi-category versions of the tower , pyramid , upstart , perceptron cascade , tiling and sequential learning algorithms respectively. <p> a X daughter or a Y daughter, a pair of X and Y daughters must be added at each time. 3 An extension of the upstart algorithm to handle patterns with real-valued attributes using stereographic projection was originally proposed in [ST91]. 4 An earlier version of this algorithm appeared in <ref> [PYH97b] </ref>. 118 Algorithm MUpstart (Multi-Category Real-Valued Upstart Algorithm) Input: A training set S Output: A trained upstart network begin 1) Train a single layer network with M output neurons using the algorithm A 2) Let L = 2 designate the above layer (it is the network's output layer) and H =
Reference: [PYH97c] <author> R. G. Parekh, J. Yang, and V. G. Honavar. </author> <title> Pruning strategies for constructive neural network learning algorithms. </title> <booktitle> In Proceedings of the IEEE/INNS International Conference on Neural Networks, ICNN'97, </booktitle> <pages> pages 1960-1965, </pages> <year> 1997. </year>
Reference-contexts: Network pruning involves elimination of connection elements (i.e., weights or neurons) that are deemed unnecessary in that their elimination does not degrade the network's performance. In <ref> [PYH97c] </ref> we described the application of three simple neuron pruning strategies to the MTiling networks. Experimental results demonstrate a significant reduction in the network size without compromising the network's convergence properties or the generalization performance.
Reference: [PYH98] <author> R. G. Parekh, J. Yang, and V. G. Honavar. </author> <title> An experimental comparison of constructive neural network learning algorithms, </title> <note> 1998. (In preparation). </note>
Reference-contexts: We present a more systematic comparison of the performance of different constructive learning algorithms in appendix B. This is the subject of <ref> [PYH98] </ref>. In what follows, we explore some practical 142 issues that arise in the application of constructive learning algorithms and present the results of a few experiments designed to address the following key issues. 1.
Reference: [Qui86] <author> R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: It divides the examples into two subsets depending on whether or not the rules in the domain theory are able to correctly classify them. It then uses the standard decision tree learning algorithm ID3 <ref> [Qui86] </ref> to invent new rules that correctly classify some of the previously misclassified training examples. * ILP based methods Inductive Logic Programming (ILP) is an area of artificial intelligence research that combines techniques from machine learning with logic programming [Mug92].
Reference: [Ree93] <author> R. Reed. </author> <title> Pruning algorithms | a survey. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 4(5) </volume> <pages> 740-747, </pages> <year> 1993. </year>
Reference-contexts: Section 9.3 presents the results of experiments with pruning using several artificial and real-world datasets. Finally, section 9.4 concludes with an analysis of the 157 experiments with pruning and suggests directions for future research. 9.2 Pruning Strategies An excellent survey of neural network pruning strategies appears in <ref> [Ree93] </ref>. It outlines two types of pruning techniques for feed forward neural networks trained using the backpropagation algorithm | sensitivity calculations and penalty terms. The former investigates the sensitivity of the error function (or the objective function that is minimized) to the removal of a network element.
Reference: [RHW86] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. In Parallel Distributed Processing: Explorations into the Microstructure of Cognition, </title> <booktitle> volume 1 (Foundations). </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: Traditional ANN algorithms such as backpropagation <ref> [RHW86] </ref>, although successful on several pattern classification tasks, suffer from drawbacks such as restriction to an a-priori fixed network topology, use of the expensive gradient descent based error backpropagation training rule, and susceptibility to local minima. <p> Early learning algorithms for training such networks were proposed independently by Dreyfus [Dre62], Bryson and Ho [BH69], and Werbos [Wer74]. These algorithms use a gradient descent approach for training the multi-layer networks of neurons. The backpropagation learning algorithm proposed by Rumelhart et al <ref> [RHW86] </ref> made the gradient decent based approach popular in the neural networks community. The success of the backpropaga 84 tion algorithm rekindled the excitement among researchers and led to fervent activity in both the theory and applications of neural networks. <p> Backpropagation networks thus cannot use threshold neurons. Instead they use neurons implementing the sigmoid activation function. The interested reader is referred to <ref> [RHW86] </ref> or any popular textbook on neural network learning (such as [Day90, Gal93, MMR97]) for a derivation of the backpropagation weight update rule. The backpropagation algorithm and its extensions have been successfully used in several practical applications. <p> Their rules-to-network algorithm constructs an AND-OR graph representation of the initial domain knowledge and translates this graph to an appropriate neural network topology. KBANN then uses the standard backpropagation learning algorithm <ref> [RHW86] </ref> to refine the do 172 main knowledge. The approaches described by Fu [Fu89] and Katz [Kat89] are similar to the KBANN algorithm. Unlike the symbolic and ILP based methods for theory refinement, the connectionist approaches require that the domain knowledge be translated into an appropriate initial neural network topology.
Reference: [Rip96] <author> B. Ripley. </author> <title> Pattern Recognition and Neural Networks. </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1996. </year> <month> 227 </month>
Reference-contexts: A variety of feature subset selection algorithms have been proposed in the literature on pattern recognition <ref> [Rip96] </ref>. The effectiveness of genetic algorithms for feature subset selection has been demonstrated by [YH97]. <p> However, these systems generalize from the labeled examples without knowing anything about why some particular example was assigned a given class label. Further, it is well known that the choice of the attributes to represent the examples can have a significant impact on the performance of the learning system <ref> [Rip96] </ref>. The presence of domain specific knowledge (domain theories) about the concept being learned can potentially enhance the performance of the inductive learning system. <p> The effectiveness of using an appropriate feature subset selection mechanism in culling unwanted input attributes and thereby simplifying the task of several inductive learning algorithms is well known <ref> [Rip96] </ref>. Experimental results have shown that using GA based feature subset selection algorithm significantly boosts the performance of the DistAl constructive learning algorithm [YH97]. 3. Over-fitting of the training set: Constructive learning algorithms allow the network to train until all training patterns are correctly classified.
Reference: [RM95] <author> B. Richards and R. Mooney. </author> <title> Automated refinement of first-order horn-clause domain theories. </title> <journal> Machine Learning, </journal> <volume> 19 </volume> <pages> 95-131, </pages> <year> 1995. </year>
Reference-contexts: It uses computational logic as the knowledge representation mechanism and extends the theory and practice of logic to the inductive (rather than the traditional deductive) model of inference. Theory refinement systems such as FOCL [PK92] and FORTE <ref> [RM95] </ref> use first-order logic as the representation scheme in theory revision and thus are said to belong to the class of ILP based techniques. FORTE (First-Order Revision of Theories from Examples) uses a hill-climbing search for refining first-order Horn-clause theories.
Reference: [RN95] <author> S. Russell and P. Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: 1 INTRODUCTION The ability to learn is one of the central characteristics of intelligent entities. Machine Learning concerns the design and analysis of computational processes that learn from experience <ref> [Hon94, Lan95, RN95, Mit97] </ref>. A typical machine learning system is characterized by its ability to interact with its environment, observe the effects of its own actions, and improve its performance over time.
Reference: [Ros58] <author> F. Rosenblatt. </author> <title> The perceptron: A probabilistic model for information storage and organization in the brain. </title> <journal> Psychological Review, </journal> <volume> 65 </volume> <pages> 386-408, </pages> <year> 1958. </year>
Reference-contexts: Most constructive learning algorithms are based on simple TLUs that implement a hard-limiting function of their inputs. These algorithms start out by training a single TLU using some variant of the perceptron learning rule <ref> [Ros58] </ref>. If the TLU is not successful in correctly classifying all the training patterns then an additional TLU (or a group of TLUs) is added and trained to correct some of the errors made by the network. <p> It states that connection weights between neurons that are simultaneously on or simultaneously off on similar inputs are reinforced. Rosenblatt proposed a simple iterative strategy called the perceptron learning rule for training the weights of threshold neurons <ref> [Ros58] </ref>. The perceptron algorithm attempts to find a separating linear hyperplane that partitions the pattern space into two half-planes. It acts as a binary classifier giving an output of 1 for patterns on one side of the hyperplane and and output of -1 for patterns on the other side. <p> Note that the first component of the weight vector is the threshold term. Several iterative algorithms are available for finding such a ^ W, if one exists <ref> [Ros58, MP69, Nil65, DH73] </ref>. Most of these are variants of the perceptron weight update rule: W W + (C p O p )X p where &gt; 0 is the learning rate The perceptron weight update rule is guaranteed to find a separating hyperplane if one exists. <p> Most constructive learning algorithms are based on simple threshold logic units (TLUs) that implement a hard-limiting function of their inputs. These algorithms start out by training a single TLU (using some variant of the perceptron learning rule <ref> [Ros58] </ref>) to learn to classify the set of training patterns. If the unit is not successful in correctly classifying all patterns, an additional TLU (or a group of TLUs) is added and trained to correct some of the errors made by the network.
Reference: [RS93] <author> R. L. Rivest and R. E. Schapire. </author> <title> Inference of finite automata using homing sequences. </title> <journal> Information and Computation, </journal> <volume> 103(2) </volume> <pages> 299-347, </pages> <year> 1993. </year>
Reference-contexts: However, the robot has no way of knowing where it started from or of retracing its steps to the start state. The robot has to continue from its current state and explore the environment further. Rivest and Schapire proposed a learning method based on homing sequences <ref> [RS93] </ref>.
Reference: [SRK95] <author> K-Y. Siu, V. Roychowdhury, and T. Kailath. </author> <title> Discrete Neural Computation A Theoretical Foundation. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: Siu et al have established the necessary and sufficient conditions for a training set S to be non-linearly separable <ref> [SRK95] </ref>. They have also shown that the problem of identifying a largest linearly separable subset S sep of S is NP-complete. It is widely conjectured that no polynomial time algorithms exist for NP-complete problems [GJ79]. <p> Finding an optimal weight setting for each added neuron such that the classification error is maximally reduced when the the data is non-separable is an NP-hard problem <ref> [SRK95] </ref>. Thus, practical algorithms for training threshold neurons are heuristic in nature. This makes it important to study the convergence of the proposed constructive algorithms in practice. We trained constructive networks on several non linearly separable datasets that require highly nonlinear decision surfaces. 2.
Reference: [ST91] <author> J. Saffery and C. Thornton. </author> <title> Using stereographic projection as a preprocessing technique for upstart. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <pages> pages II 441-446, </pages> <publisher> IEEE Press, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Additionally, practical classification tasks often involve patterns with real-valued attributes. The extensions of constructive learning algorithms to handle patterns with real-valued attributes have only been studied only for the upstart <ref> [ST91] </ref> and the perceptron cascade [Bur94] algorithms. For each of the constructive learning algorithms mentioned above we have designed provably correct extensions to handle tasks involving multiple output categories and real-valued pattern attributes (see [PYH95, YPH96, PYH97b, PYH97a]). <p> Several quantization algorithms have been proposed in the literature [DKS95, YH96]. We will study a novel adaptive vector quantization technique in chapter 10. Extensions of constructive learning algorithms to handle patterns with real-valued attributes have only been studied for the upstart and perceptron cascade algorithms (see <ref> [ST91, Bur94] </ref>). In this chapter, we present a general framework for the design of constructive learning algorithms that are capable of handling real-valued attributes. <p> straightforward with the only change being that instead of adding a X daughter or a Y daughter, a pair of X and Y daughters must be added at each time. 3 An extension of the upstart algorithm to handle patterns with real-valued attributes using stereographic projection was originally proposed in <ref> [ST91] </ref>. 4 An earlier version of this algorithm appeared in [PYH97b]. 118 Algorithm MUpstart (Multi-Category Real-Valued Upstart Algorithm) Input: A training set S Output: A trained upstart network begin 1) Train a single layer network with M output neurons using the algorithm A 2) Let L = 2 designate the above
Reference: [TB73] <author> B. Trakhtenbrot and Ya. Barzdin. </author> <title> Finite Automata: Behavior and Synthesis. </title> <publisher> North Holland Publishing Company, </publisher> <address> Amsterdam, </address> <year> 1973. </year>
Reference-contexts: Trakhtenbrot and Barzdin described a polynomial time algorithm for constructing the smallest DFA consistent with a complete labeled sample i.e., a sample that includes all strings up to a particular length and the corresponding label that states whether the string is accepted by the target DFA or not <ref> [TB73] </ref>. Thus, their algorithm computes, in polynomial time, the smallest DFA that correctly accepts all the positive examples and correctly rejects all the negative examples of the complete labeled sample.
Reference: [Thr95] <author> S. Thrun. </author> <title> Lifelong learning: A case study. </title> <type> Technical Report CMU-CS-95-208, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1995. </year>
Reference-contexts: constructive learning algorithms proposed in this chapter with the DistAl, the cascade correlation algorithm, and the backpropagation learning algorithm would be useful in gaining a better understanding of the advantages and dis advantages of each approach. * Recent research has focussed on the use of neural networks for lifelong learning <ref> [Thr95] </ref> where networks are trained to learn multiple classification tasks one after the other. A goal of the multi-task learning system is to exploit (if possible) the prior knowledge acquired while learning the earlier tasks to make the learning of the later and possibly more difficult tasks easier. <p> It is worth exploring different methods for extracting the refined rules from the trained neural networks. 11.2.4 Constructive Neural Networks in a Lifelong Learning Framework Recent research has focussed on the use of neural networks for lifelong learning <ref> [Thr95] </ref> where networks are trained to learn multiple classification tasks one after the other. It is desirable to allow the network to exploit the knowledge acquired while learning one task to simplify the learning of a related (possibly more complicated) task.
Reference: [TS93] <author> G. Towell and J. Shavlik. </author> <title> Extracting rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13 </volume> <pages> 71-101, </pages> <year> 1993. </year>
Reference-contexts: Of late there is significant interest in the study of efficient techniques for knowledge extraction from trained neural networks. The interested reader is referred to <ref> [TS93, Fu93, Cra96] </ref> for additional details. * The types of domain theory rules that can be incorporated into the network are limited to propositional rules. Further, there is no mechanism for handling uncertainty in rules.
Reference: [TS94] <author> G. Towell and J. Shavlik. </author> <booktitle> Knowledge-based artificial neural networks. Artificial Intelligence, </booktitle> <address> 70(1-2):119-165, </address> <year> 1994. </year>
Reference-contexts: This domain knowledge is then refined by training the neural network on a set of labeled examples. Towell and Shavlik proposed the KBANN (knowledge based artificial neural network) learning algorithm for connectionist theory refinement <ref> [TSN90, TS94] </ref>. Their rules-to-network algorithm constructs an AND-OR graph representation of the initial domain knowledge and translates this graph to an appropriate neural network topology. KBANN then uses the standard backpropagation learning algorithm [RHW86] to refine the do 172 main knowledge. <p> This additional step is of merit as it allows KBANN to generalize better than systems that train from examples alone. In experiments involving datasets from the Human Genome Project 1 , KBANN outperformed symbolic theory refinement systems (such as EITHER) and other learning algorithms such as backpropagation and ID3 <ref> [TS94] </ref>. KBANN is limited by the fact that it does not modify the network's topology and theory refinement is conducted solely by updating the connection weights. This prevents the incorporation of new rules and also restricts the algorithm's ability to compensate for inaccuracies in the domain theory. <p> The KBANN learning algorithm is demonstrated to perform better than several other machine learning algorithms on domains 4 Note that the standard deviations for the results with these experiments were not available. 188 such as the promoter and the splice-junction datasets <ref> [TSN90, TS94] </ref>. However, KBANN is limited by the fact that it does not modify the network topology. The TopGen and REGENT learning algorithms were designed to add new neurons to the KBANN network thereby extending the realm of network topologies considered by KBANN.
Reference: [TSN90] <author> G. G. Towell, J. W. Shavlik, and M. O. Noordwier. </author> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 861-866, </pages> <year> 1990. </year> <month> 228 </month>
Reference-contexts: This domain knowledge is then refined by training the neural network on a set of labeled examples. Towell and Shavlik proposed the KBANN (knowledge based artificial neural network) learning algorithm for connectionist theory refinement <ref> [TSN90, TS94] </ref>. Their rules-to-network algorithm constructs an AND-OR graph representation of the initial domain knowledge and translates this graph to an appropriate neural network topology. KBANN then uses the standard backpropagation learning algorithm [RHW86] to refine the do 172 main knowledge. <p> This procedure is based on the rules-to-networks algorithm of Towell and Shavlik <ref> [TSN90, FO93] </ref>. It involves rewriting the knowledge rules into a format that highlights the hierarchical structure of the domain theory. In particular, the disjuncts are expressed as a set of rules that each have only one antecedent. <p> The KBANN learning algorithm is demonstrated to perform better than several other machine learning algorithms on domains 4 Note that the standard deviations for the results with these experiments were not available. 188 such as the promoter and the splice-junction datasets <ref> [TSN90, TS94] </ref>. However, KBANN is limited by the fact that it does not modify the network topology. The TopGen and REGENT learning algorithms were designed to add new neurons to the KBANN network thereby extending the realm of network topologies considered by KBANN.
Reference: [Val84] <author> L. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: Also, it requires a consistency check with all the previous examples each time the current representation of the target is modified. 2.4 Approximate Identification of DFA Valiant's distribution independent model of learning (also called the PAC model) <ref> [Val84] </ref> is widely used for approximate learning of concept classes. When adapted to the problem of learning DFA, the goal of a PAC learning algorithm is to obtain in polynomial time, with high probability, a DFA that is a good approximation of the target DFA. <p> It is thus natural to ask whether DFA can be learned approximately. Valiant's distribution-independent model of learning, also called the probably approximately correct (PAC) learning model <ref> [Val84] </ref>, is a widely used framework for approximate learning of concept classes. PAC learning models natural learning in that it is fast (learning takes place in polynomial time) and it suffices to learn approximately [KV94].
Reference: [VB87] <author> K. Vanlehn and W. Ball. </author> <title> A version space approach to learning context-free grammars. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 39-74, </pages> <year> 1987. </year>
Reference-contexts: The explicit enumeration of the hypothesis space as in Pao and Carr's algorithm does not permit the learner to make such partial inferences without actually testing whether or not each FSA in the hypothesis space accepts the example. VanLehn and Ball <ref> [VB87] </ref> have proposed a version space based approach to learning context free grammars from a set of positive and negative examples. Their algorithm returns a set of grammars consistent with the given sample set. Their algorithm is also based on a lattice of partitions.
Reference: [Wat89] <author> C. J. Watkins. </author> <title> Learning from Delayed Rewards. </title> <type> PhD dissertation, </type> <institution> King's College, </institution> <address> Cambridge, UK, </address> <year> 1989. </year>
Reference-contexts: This would enable the learner to determine an appropriate sequence of steps that would maximize its reward. Q-learning is a widely used algorithm for reinforcement learning <ref> [Wat89, WD92] </ref>. 89 7.2.4 Applications ANN have been successfully applied to problems in the areas of pattern classification, clustering, vector quantization, pattern association, function approximation, optimization, control, and search [Day90, Gal93, MMR97]. In this dissertation we focus exclusively on the use of neural networks for pattern classification.
Reference: [WD92] <author> C. J. Watkins and P. </author> <title> Dayan. </title> <journal> Q-learning. Machine Learning, </journal> <volume> 8(3) </volume> <pages> 279-292, </pages> <year> 1992. </year>
Reference-contexts: This would enable the learner to determine an appropriate sequence of steps that would maximize its reward. Q-learning is a widely used algorithm for reinforcement learning <ref> [Wat89, WD92] </ref>. 89 7.2.4 Applications ANN have been successfully applied to problems in the areas of pattern classification, clustering, vector quantization, pattern association, function approximation, optimization, control, and search [Day90, Gal93, MMR97]. In this dissertation we focus exclusively on the use of neural networks for pattern classification.
Reference: [Wer74] <author> P. J. Werbos. </author> <title> Beyond Regression: New Tools for Prediction and Analysis in Behavioral Sciences. </title> <type> PhD dissertation, </type> <institution> Harvard University, </institution> <year> 1974. </year>
Reference-contexts: Several researchers actively searched for suitable training algorithms for multi-layer networks of neurons. Early learning algorithms for training such networks were proposed independently by Dreyfus [Dre62], Bryson and Ho [BH69], and Werbos <ref> [Wer74] </ref>. These algorithms use a gradient descent approach for training the multi-layer networks of neurons. The backpropagation learning algorithm proposed by Rumelhart et al [RHW86] made the gradient decent based approach popular in the neural networks community.
Reference: [YH96] <author> J. Yang and V. Honavar. </author> <title> A simple randomized quantization algorithm for neural network pattern classifiers. </title> <booktitle> In Proceedings of the World Congress on Neural Networks'96, </booktitle> <address> San Diego, CA, </address> <pages> pages 223-228, </pages> <year> 1996. </year>
Reference-contexts: The original constructive learning algorithm can then be applied using the quantized representations of the pattern vectors. Several quantization algorithms have been proposed in the literature <ref> [DKS95, YH96] </ref>. We will study a novel adaptive vector quantization technique in chapter 10. Extensions of constructive learning algorithms to handle patterns with real-valued attributes have only been studied for the upstart and perceptron cascade algorithms (see [ST91, Bur94]). <p> Among these we have already seen the benefits of normalization. Another method of handling pattern sets with real-valued outputs is quantization of the training patterns. Preliminary results of applying quantization 153 are presented in <ref> [YH96] </ref>. In chapter 10 we describe a novel adaptive vector quantization scheme based on the MTiling algorithm. * Constructive neural network learning algorithms provide a natural framework for incorporating domain specific prior knowledge in the network topology. <p> Discretization methods have been extensively studied in conjunction with many different machine learning algorithms. A detailed survey of discretization algorithms appears in [DKS95]. Yang and Honavar's experiments with a simple randomized quantization algorithm and an entropy based quantization algorithm (see <ref> [YH96] </ref>) demonstrated the effec 2 Note that the tiling and sequential learning algorithms do not require any such preprocessing. 182 tiveness of quantization in cutting down on the training time and improving the generalization performance of single layer networks of TLUs. <p> Note that the quantized outputs are a faithful representation of the training patterns which is an important feature of any good quantization algorithm <ref> [YH96] </ref>. Thus, the MTiling algorithm can be used as an efficient adaptive vector quantization algorithm.
Reference: [YH97] <author> J. Yang and V. Honavar. </author> <title> Feature subset selection using a genetic algorithm. </title> <booktitle> In Proceedings of the Genetic Programming'97, </booktitle> <address> Stanford, CA, </address> <pages> pages 380-385, </pages> <year> 1997. </year>
Reference-contexts: A variety of feature subset selection algorithms have been proposed in the literature on pattern recognition [Rip96]. The effectiveness of genetic algorithms for feature subset selection has been demonstrated by <ref> [YH97] </ref>. Against this background, exploration of constructive learning algorithms augmented with suitable feature subset selection techniques might be of interest. * The results of a more extensive experimental comparison of the different constructive learning algorithms is presented in appendix B. <p> Experimental results have shown that using GA based feature subset selection algorithm significantly boosts the performance of the DistAl constructive learning algorithm <ref> [YH97] </ref>. 3. Over-fitting of the training set: Constructive learning algorithms allow the network to train until all training patterns are correctly classified.
Reference: [YH98] <author> J. Yang and V. Honavar. </author> <title> Experiments with the cascade-correlation algorithm. Microcomputer Applications, </title> <note> 1998. (To appear). </note>
Reference-contexts: For an experimental study of the cascade correlation algorithm see <ref> [YH98] </ref>. Though the cascade correlation algorithm is considerably faster than the backpropagation algorithm, it still uses an expensive weight update scheme.
Reference: [YPH96] <author> J. Yang, R. Parekh, and V. Honavar. </author> <title> MTiling a constructive neural network learning algorithm for multi-category pattern classification. </title> <booktitle> In Proceedings of the World Congress on Neural Networks'96, </booktitle> <address> San Diego, CA, </address> <pages> pages 182-187, </pages> <year> 1996. </year>
Reference-contexts: For each of the constructive learning algorithms mentioned above we have designed provably correct extensions to handle tasks involving multiple output categories and real-valued pattern attributes (see <ref> [PYH95, YPH96, PYH97b, PYH97a] </ref>). The convergence proofs for these algorithms outline a general framework for proving the convergence of constructive learning algorithms. Experiments on several artificial and real world datasets have demonstrated the practical applicability of these constructive learning algorithms. <p> Against this background, the focus of this chapter is on provably convergent multi-category learning algorithms for construction of networks of threshold neurons for pattern classification tasks with real-valued attributes. These results are based on the work described earlier in <ref> [PYH95, YPH96, PYH97b, PYH97a] </ref>. The remainder of this chapter is organized as follows: Sections 8.2 through 8.7 explore the multi-category versions of the tower , pyramid , upstart , perceptron cascade , tiling and sequential learning algorithms respectively. <p> We designate this output vector &lt; O 1 ; O 2 ; : : : ; O M+K &gt; as a prototype p =&lt; p p p p 6 An earlier version of this algorithm appeared in <ref> [YPH96] </ref>. 128 Algorithm MTiling (Multi-Category Real-Valued Tiling Algorithm) Input: A training set S Output: A trained tiling network begin 1) Train a single layer network with M output neurons using the algorithm A (Note that these M neurons are designated as the master neurons) 2) Let L = 1 denote the
Reference: [YPH98a] <author> J. Yang, R. Parekh, and V. Honavar. </author> <title> Comparison of performance of variants of single-layer perceptron algorithms on non-separable datasets. (Submitted for review to the Journal of Artificial Neural Networks), </title> <year> 1998. </year>
Reference-contexts: We briefly summarize the pocket algorithm with ratchet modification , the thermal perceptron algorithm , and the barycentric correction procedure . The interested reader is referred to <ref> [YPH98a] </ref> for a detailed description of these algorithms and an empirical comparison of their performance on several artificial and real world datasets. 7.3.1 Pocket Algorithm with Ratchet Modification The pocket algorithm with ratchet modification essentially uses the perceptron weight update rule. <p> It is thus of interest to apply the WTA strategy for computing the outputs in constructive learning algorithms. For details on the adaptation of the TLU training algorithms to the WTA strategy see <ref> [YPH98a] </ref>. In this chapter we present the multi-category versions of the popular constructive learning algorithms. 8.1.2 Real-Valued Attributes Practical classification tasks often involve patterns with real-valued attributes. <p> Detailed theoretical and experimental analysis of the performance of single threshold neuron training algorithms is in progress <ref> [YPH98a] </ref>. We expect this analysis to lead to the design of improved and possibly hybrid weight modification schemes that can dynamically adapt to the situation faced by the particular constructive algorithm on a given dataset. <p> We repeated the above experiments using the barycentric correction procedure instead of the thermal perceptron algorithm for training the individual TLUs. Since the extension of the barycentric correction procedure to WTA based output computation is extremely slow (see <ref> [YPH98a] </ref>) we performed these experiments using the independent output computation strategy. These results are summarized in Table 9.2.
Reference: [YPH98b] <author> J. Yang, R. Parekh, and V. Honavar. </author> <title> DistAl: An inter-pattern distance-based constructive learning algorithm. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks'98, </booktitle> <address> Anchorage, AK, </address> <year> 1998. </year> <note> (To appear). </note>
Reference-contexts: Yang et al have recently proposed an efficient inter-pattern distance based constructive learning algorithm DistAl <ref> [YPH98b] </ref>. Unlike the algorithms described in this chapter, DistAl does not use the perceptron style 154 iterative weight update procedure.
References-found: 131

