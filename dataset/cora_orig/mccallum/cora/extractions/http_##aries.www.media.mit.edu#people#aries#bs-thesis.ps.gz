URL: http://aries.www.media.mit.edu/people/aries/bs-thesis.ps.gz
Refering-URL: http://aries.www.media.mit.edu/people/aries/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Algorithms for Pinball Simulation, Ball Tracking and Learning Flipper Control  
Author: by Michael Patrick Johnson c Michael Patrick Johnson, MCMXCIII. Christopher G. Atkeson Leonard A. Gould 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Bachelor of Science in Computer Science and Engineering at the  All rights reserved. The author hereby grants to MIT permission to reproduce and to distribute copies of this thesis document in whole or in part, and to grant others the right to do so. Author  Certified by  Associate Professor  Thesis Supervisor Accepted by  Chairman, Department Committee on Undergraduate Theses  
Date: May 1993  May 17, 1993  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY  Department of Electrical Engineering and Computer Science  of Brain and Cognitive Sciences  
Abstract-found: 0
Intro-found: 1
Reference: [ Foley et al., 1990 ] <author> James D. Foley, A. van Dam, S. Feiner, and J. Hughes. </author> <title> Computer Graphics: Priciples and Practice. </title> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Reading, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: Then we reflect the velocity vector of the ball through the normal and reverse its direction. A description of how to do this reflection can be found in <ref> [ Foley et al., 1990 ] </ref> , pp. 730-731.
Reference: [ Hoeffding, 1963 ] <author> Wassily Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <year> 1963. </year>
Reference-contexts: The useful fact is that the interval gets smaller as n, the number of samples, increases. Hoeffding has a strong formula for finding these intervals <ref> [ Hoeffding, 1963 ] </ref> . We refer you to Appendix B for the actual calculation of the intervals using the Hoeffding formula as described by [ Maron, 1993 ] . The Hoeffding Race Figure 6-3 shows a set of minicontrollers from the same partition of input space. <p> There are two problems with this formula for our purposes. First, be need to know the a priori true mean and 74 standard deviation of the random variables, which we do not; indeed, this is what we are searching for. Instead, we use the following formula from <ref> [ Hoeffding, 1963 ] </ref> : Pr fm n tg e B 2 (B.3) where B is the maximum range of the random variable. Clearly as B ! 1, then the right hand side becomes unity, a trivial upper bound, since probabilities are by definition bounded above by unity.
Reference: [ Kernighan and Ritchie, 1988 ] <author> Brian W. Kernighan and Dennis M. Ritchie. </author> <title> The C Programming Language. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1988. </year>
Reference-contexts: If the flipper's length is l, then l sin ( _ dt 2 ) &lt; ball radius must hold. The flipper update can be done before or after the ball update. 3.4 Implementation and Possible Improvements The above operations were implemented in C <ref> [ Kernighan and Ritchie, 1988 ] </ref> and using the Xlib library. Our implementation redraws the ball every n integration steps, where n can be specified.
Reference: [ Maron, 1993 ] <author> Oded Maron. </author> <title> Finding good models fast using Hoeffding Races. </title> <note> In preparation, </note> <year> 1993. </year>
Reference-contexts: Function Attempt the end, and never stand to doubt; Nothing's so hard, but search will find it out. | Robert Herrick, "Seek and Find", 1591 This chapter will describe two methods used for optimizing the action function described in the previous chapter | stochastic hill-climbing tournament and Hoeffding Relay Race <ref> [ Maron, 1993 ] </ref> . Before describing these particular algorithms, we describe the paradigm and simplifications we use for both methods. 6.1 Description of the Optimization Paradigm In order to optimize an action function efficiently, we need to make several constraints and assumptions. <p> The algorithm we describe in this section uses a modified version of the Hoeffding Race optimization method described by Oded Maron <ref> [ Maron, 1993 ] </ref> . It also incorporates several other important ideas in order to 57 Trial Generation Pop. <p> Hoeffding has a strong formula for finding these intervals [ Hoeffding, 1963 ] . We refer you to Appendix B for the actual calculation of the intervals using the Hoeffding formula as described by <ref> [ Maron, 1993 ] </ref> . The Hoeffding Race Figure 6-3 shows a set of minicontrollers from the same partition of input space. We assume that each minicontroller has run some (perhaps different) number of times, and we have calculated their sample mean and c confidence interval.
Reference: [ Moore and Atkeson, 1992 ] <author> A. W. Moore and C. G. Atkeson. </author> <title> Memory-based Reinforcement Learning: Memory-based Reinforcement Learning: Converging with Less Data and Less Real Time. </title> <note> In preparation, </note> <year> 1992. </year>
Reference-contexts: This type of technique has proven useful in control of stochastic Markov systems, where optimal solutions are found with various dynamic programming algorithms 13 that try to learn the state transition table from samples of the system <ref> [ Moore and Atkeson, 1992 ] </ref> . Stefan Schaal [ Schaal, 1993 ] has also been investigating this type of directed random search technique for control of a juggling robot. <p> Since there is a stochastic element involved, the exact same input and control may lead to a different next controller. It would be interesting to pretend that this is a Markov process and use a dynamic programming solution. Research by <ref> [ Moore and Atkeson, 1992 ] </ref> has shown that this works for similar problems. (This is the subject of future research plans. <p> considerably, though. 7.2 Future Research Directions It is interesting that Moore and Atkeson got away with quantizing a continuous control problem with limited actuation (keeping an inverted pendulum upright on a wagon), pretending that it was a stochastic Markov process, then using dynamic programming to find a good control policy <ref> [ Moore and Atkeson, 1992 ] </ref> . The reason this is interesting, as he mentions, is that there is hidden state in the representation. That is, a given quantized chunk of state space actually covers a range of continuous values that are hidden from the controller. <p> This leads to the idea that we used in this thesis | using linear controllers in a variable partitioning of state space. Indeed, this is a simpler version of Moore's current research <ref> [ Moore and Atkeson, 1992 ] </ref> , using local linear optimal controllers in variable partitions of state-space. Applying this kind of idea to our problem, we identify each of the minicontrollers as a state in a Markov process.
Reference: [ Press et al., 1988 ] <author> William H. Press, Brian P. Flannery, Saul A. Teukolksy, and William T. Vetterling. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference-contexts: That is, given a time-sequence of n (x,y,t) ball location coordinates, we do a least squares fit through each of the two sequences (x i , t i ) and (y i , t i ). Since GLS is described extremely well in Numerical Recipes in C <ref> [ Press et al., 1988 ] </ref> , we omit the details. This direct use of GLS tends to be noisy since we often only look at a small part of the parabola, and there are not enough points to make a good fit for the quadratic coefficient. <p> To make the prediction better for smaller sections, the gravity constant of the pinball table is assumed fixed and calculated in advance. We can have the GLS fix this parameter at the given value and give us the best values for the other two parameters. Numerical Recipes <ref> [ Press et al., 1988 ] </ref> talks about this option in the GLS section also. <p> The algorithm as described allows us to jump anywhere in the minicontroller space every time. This kind of idea is called simulated annealing. A good discussion can be found in Numerical Recipes <ref> [ Press et al., 1988 ] </ref> . Since it takes so long to run few generations, we have no need for such a parameter currently. 6.2.3 Results Running the tournament for only five or six generations takes a long time.
Reference: [ Rogalski, 1992 ] <author> Grzegorz Rogalski. Robo-Pinball: </author> <title> Interfacing a Computer and a Vision System with a Pinball Machine. </title> <type> S.B. Thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: present and discuss human player data gathered on our implementation of a pinball simulation in Chapter 2 1.1.2 A Real Pinball Machine Grzegorz Rogalski, an undergraduate at MIT who also worked with Chris Atkeson in the AI Lab, investigated the problem of pinball control on a home-made, simplified pinball machine <ref> [ Rogalski, 1992 ] </ref> . Part of his work involved designing and building a board that the ball could successfully be tracked on with a vision system (i.e. painted flat black) and allowing the computer to actuate the flippers.
Reference: [ Schaal, 1993 ] <author> Stefan Schaal. </author> <title> Mit artifical intelligence lab, 1993. </title> <type> Personal communication. 77 </type>
Reference-contexts: This type of technique has proven useful in control of stochastic Markov systems, where optimal solutions are found with various dynamic programming algorithms 13 that try to learn the state transition table from samples of the system [ Moore and Atkeson, 1992 ] . Stefan Schaal <ref> [ Schaal, 1993 ] </ref> has also been investigating this type of directed random search technique for control of a juggling robot.
References-found: 8

