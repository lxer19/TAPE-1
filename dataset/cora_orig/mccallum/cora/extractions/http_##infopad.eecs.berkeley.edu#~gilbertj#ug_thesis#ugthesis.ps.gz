URL: http://infopad.eecs.berkeley.edu/~gilbertj/ug_thesis/ugthesis.ps.gz
Refering-URL: http://infopad.eecs.berkeley.edu/~gilbertj/ug_thesis/index.html
Root-URL: 
Title: A Real-Time Face Recognition System Using Custom VLSI Hardware  
Author: Jeffrey Michael Gilbert 
Degree: A Thesis presented by  to Computer Science in partial fulfillment of the honors requirements for the degree of Bachelor of Arts  
Date: April 12, 1993  
Address: Cambridge, Massachusetts  
Affiliation: Harvard College  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Armengou, David Montal. </author> <title> "Parallel Algorithms for Face Recognition. A Feature Based Approach." </title> <institution> Ecole National Superieure des Telecommunications, Paris. </institution>
Reference-contexts: These parameters can be compared to a database to perform recognition. This system runs on a Sun SparcStation but does not achieve real-time performance. High performance super-computers have been used to achieve real-time recognition using feature-based algorithms. Armengou <ref> [1] </ref> describes an implementation of an algorithm developed by Manjunath [10] ported to a massively parallel computer. The system uses wavelets to generate feature graphs which are compared to perform recognition.
Reference: [2] <author> Baron, Robert J. </author> <title> "Mechanisms of human facial recognition". </title> <journal> International Journal of Man-Machine Studies (1981) 15, </journal> <pages> 137-178. </pages>
Reference-contexts: The templates in the database are considered one at a time as if they were from the target image, and compared to the rest of the database. This cross 3 I've adopted Baron's terminology of recognized, mistakenly recognized, and missed images <ref> [2] </ref>. 39 validation provides examples of what are good and bad matches. If the "target" is matched with another image of the same person, the correlation scores are considered to be an example of a good match.
Reference: [3] <author> R. Brunelli. </author> <title> "Edge Projections for Facial Feature Extraction." </title> <type> Technical Report 9009-12, I.R.S.T, </type> <month> Sept </month> <year> 1990 </year>
Reference-contexts: The eye location mechanism could be improved by augmenting the existing highlight and blob detection with other systems such as edge projection <ref> [3] </ref> or motion detection [13]. It may be possible to use the correlator chip to aid in the motion detection, as correlation is commonly used for motion estimation. 5.1.2 Hardware System Research There are also some modifications which could be made to the hardware system.
Reference: [4] <author> R. Brunelli and T. Poggio. </author> <title> "Face Recognition: Features versus Templates." </title> <type> Technical Report 9110-04, I.R.S.T, </type> <year> 1991. </year>
Reference-contexts: Brunelli and Poggio <ref> [4] </ref> have developed the template-based recognition algorithm on which this thesis is based in part. Their system uses eye-location via hierarchical correlation with an "average" eye template to guide automated template extraction. The extracted templates are compared to a database by normalized correlation. <p> Thus the system is based on acquire and track. 2.1.2 Template Extraction Once the eyes are located, templates of the face, eyes, nose, and mouth are extracted as described by Brunelli and Poggio <ref> [4] </ref>. The inter-ocular distance is 28 taken as a scaling factor and the inter-ocular axis is normalized to be horizontal. The four regions of the image are determined by fixed ratios and offsets relative to the eyes.
Reference: [5] <author> Burt, Peter J. </author> <title> "Smart Sensing within a Pyramid Vision Machine". </title> <booktitle> Proceedings of the IEEE, 1988, </booktitle> <volume> vol 76, no 8, </volume> <pages> pp. 1006-1015. </pages>
Reference-contexts: This sort of hierarchical correlation affords a significant speedup. 2 Multi-resolution image processing is used in many systems, in particular Burt's pyramid vision system <ref> [5] </ref>. 36 In addition to the hierarchical mode just described, which delivers accurate results in less time than brute force correlation, the real-time system software offers less accurate modes which are significantly faster. These modes are typically required only if the VLSI correlation accelerator is not being used. <p> a coprocessor and interface it to the main processor in such a way as to achieve maximum performance given the constraints of the IBM PC ISA bus 5 . 4 Peter Burt also used an IBM PC as a host for much of his work with the Pyramid Vision Machine <ref> [5] </ref>. 5 The ISA (Industry Standard Architecture) bus is the standard expansion bus in non-EISA, IBM PC compatible computers. 44 3.1 Bottlenecks Table II Correlation Benchmarks (C Compilers set to optimize for speed) One 68x68 Template Template Set 500 Sets (Brute Force) 486/DX2 IBM PC: Naive C Code Better C Code
Reference: [6] <author> Chiang, Alice M. </author> <title> US patent NO. 5,030,953, entitled "Charge Domain Block Matching Processor." </title>
Reference-contexts: Operating at the ISA-specified bus speed of 4 MHZ results in a computation rate of 600 million operations per second. Most machines, however, average only 2.5 MHZ, producing a computation rate of 375 million operations per second. The correlation architecture employed is described by Chiang <ref> [6] </ref>. One template is broadcast while the other is shifted through the array of 25 processing elements (PE). (See Figure 17). Each PE accumulates the absolute difference of its two inputs at every clock. Four 64-entry shift registers maintain proper pipelining of the shifted 68x68 template.
Reference: [7] <author> Factor, Jason. </author> <title> Person correspondence with Jason and his girlfriend. </title>
Reference-contexts: The motion film industry also has a need for real-time face recognition systems. After a large amount of footage is filmed, it has to be classified, frame by frame, noting which actors and actresses are present in each scene <ref> [7] </ref>. Currently, this task is tediously performed by hand, wasting valuable man-power. An inexpensive, near real-time or real-time system could greatly aid in this task. The system could provide at least initial frame by frame identification which could then be verified by hand.
Reference: [8] <author> P. W. Hallinan. </author> <title> "Recognizing Human Eyes," </title> <booktitle> SPIE Proceedings, </booktitle> <volume> vol. 1570, </volume> <booktitle> Geometric Method in Computer Vision, </booktitle> <pages> 214-226, </pages> <year> 1991. </year>
Reference-contexts: Each of these methods has its merits and shortcomings. The robust eye location work of Peter Hallinan <ref> [8, 9] </ref> is also described in this section, as the eye location algorithm in the real-time system is a variant of this work. 1.2.1 Parameter-based recognition Parameter-based face recognition reduces facial images to a relatively small number of parameters which are compared to similar parameters stored in a database. <p> variation, and 64% correct averaged over size variation. (This implies 4%, 15%, and 36% misidentification rates.) When a rejection threshold is applied to remove all mistaken recognitions, the recognition rate drops to 81%, 61%, and 40% respectively. 1.2.4 Robust Eye Location Since the eye location (and characterization) work of Hallinan <ref> [8, 9] </ref> is the basis of much of the eye-locator in the real-time system presented in this thesis, his work is described here. Hallinan's system is designed to perform eye location in a quite visually complex scene consisting of any number of eyes in a wide range of scales.
Reference: [9] <author> Peter Hallinan. </author> <note> Talk given to Computer Science 283. Spring 1992. 86 </note>
Reference-contexts: Each of these methods has its merits and shortcomings. The robust eye location work of Peter Hallinan <ref> [8, 9] </ref> is also described in this section, as the eye location algorithm in the real-time system is a variant of this work. 1.2.1 Parameter-based recognition Parameter-based face recognition reduces facial images to a relatively small number of parameters which are compared to similar parameters stored in a database. <p> variation, and 64% correct averaged over size variation. (This implies 4%, 15%, and 36% misidentification rates.) When a rejection threshold is applied to remove all mistaken recognitions, the recognition rate drops to 81%, 61%, and 40% respectively. 1.2.4 Robust Eye Location Since the eye location (and characterization) work of Hallinan <ref> [8, 9] </ref> is the basis of much of the eye-locator in the real-time system presented in this thesis, his work is described here. Hallinan's system is designed to perform eye location in a quite visually complex scene consisting of any number of eyes in a wide range of scales.
Reference: [10] <author> Manjunath, R.Chellappa, C.von der Malsburg, </author> <title> "A feature Based Approach to Face Recognition", </title> <note> SRC-UMD CAR-TR-604 January, </note> <year> 1992. </year>
Reference-contexts: These parameters can be compared to a database to perform recognition. This system runs on a Sun SparcStation but does not achieve real-time performance. High performance super-computers have been used to achieve real-time recognition using feature-based algorithms. Armengou [1] describes an implementation of an algorithm developed by Manjunath <ref> [10] </ref> ported to a massively parallel computer. The system uses wavelets to generate feature graphs which are compared to perform recognition.
Reference: [11] <author> Mumford, </author> <title> David. </title> <journal> "Parameterizing Exemplars of Categories" Journal of Cognitive Neuroscience, 1991, </journal> <volume> Vol 3, No. 1, </volume> <pages> p. 87-88. </pages>
Reference-contexts: Parameter-based recognition employs an efficient representation of salient features of an individual <ref> [11] </ref>. However, it can also require expensive preprocessing to extract the salient parameters, and careful selection of parameters which unambiguously describe an individual's face. Various metrics can be used as parameters to describe facial images.
Reference: [12] <author> Shepherd, John and Hadyn Ellis. </author> <title> "Face Recognition and Recall Using Computer-Interactive Methods with Eye Witnesses." Chapter 6 in Processing Images of Faces. Edited by Vicki Bruce and Mike Burton. </title> <publisher> Ablex Publishing Corporation, </publisher> <address> New Jersey, </address> <year> 1992. </year>
Reference-contexts: Criminal investigators could also benefit from a face recognition system. Computerized mug-shot albums could be quickly consulted to match the image of a criminal taken by a security camera, such as those in banks. Face recognition systems can also aid in eye-witness testimonials <ref> [12] </ref>. 9 1.2 Previous work Much of the previous work in face recognition can be classified by three basic approaches. The first approach is to compare a number of feature parameters describing the face, such as eye shape, facial curvature, and nose location.
Reference: [13] <author> Turk, M. and A. Pentland. </author> <title> "Eigenfaces for Recognition," </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> Vol. 3, No. 1, </volume> <pages> p. 71-86, </pages> <year> 1991. </year>
Reference-contexts: Brunelli and Poggio also developed a feature-based system for comparison, which was only able to achieve 12 a recognition rate of 78% over the same database. 1.2.3 Eigenface-based recognition The "eigenface" approach, developed by Matthew Turk and Alex Pentland <ref> [13] </ref>, combines many aspects of parameter- and template-based recognitions. In their system, an image is characterized by its projection onto a small set of eigenfaces. These eigenfaces are generated using principal component analysis to extract salient "features" of the input database. <p> Summing absolute differences is similar to true multiplicative correlation if the mean and variance of the two input templates are normalized (See Equation ?). The global normalization performs this task. 1 This approach is used by Turk and Pentland <ref> [13] </ref>. 33 Equation (2) Multiplicative correlation vs sum of absolute diffs. 34 Summing absolute differences has certain advantages over multiplicative correlation. First, and most importantly, it is possible to implement an absolute value unit in VLSI far more compactly than a multiplier or look-up table. <p> The eye location mechanism could be improved by augmenting the existing highlight and blob detection with other systems such as edge projection [3] or motion detection <ref> [13] </ref>. It may be possible to use the correlator chip to aid in the motion detection, as correlation is commonly used for motion estimation. 5.1.2 Hardware System Research There are also some modifications which could be made to the hardware system.
Reference: [14] <author> Yang, Woodward. </author> <title> "The Architecture and Design of CCD Processors for Computer Vision," </title> <type> Ph.D. Thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> 6 August </month> <year> 1990. </year>
Reference: [15] <author> Alan L. Yuille. </author> <title> "Deformable Templates for Face Recognition". </title> <journal> Journal of Cognitive Neuroscience, 1991, </journal> <volume> Vol 3, No. 1, </volume> <pages> p. 59-70. </pages>
Reference-contexts: However, it can also require expensive preprocessing to extract the salient parameters, and careful selection of parameters which unambiguously describe an individual's face. Various metrics can be used as parameters to describe facial images. Yuille et al. <ref> [15, 16] </ref> describe the use of deformable templates to extract parameters that 10 can be used for recognition. The deformable template approach works by fitting models of facial features such as the eyes and mouth to the image data.
Reference: [16] <author> Alan L. Yuille, Peter W. Hallinan, and David S. Cohen. </author> <title> "Feature Extraction from Faces Using Deformable Templates". </title> <journal> International Journal of Computer Vision, 8:2, </journal> <volume> p. </volume> <pages> 99-111. </pages> <year> 1992. </year>
Reference-contexts: However, it can also require expensive preprocessing to extract the salient parameters, and careful selection of parameters which unambiguously describe an individual's face. Various metrics can be used as parameters to describe facial images. Yuille et al. <ref> [15, 16] </ref> describe the use of deformable templates to extract parameters that 10 can be used for recognition. The deformable template approach works by fitting models of facial features such as the eyes and mouth to the image data.
References-found: 16

