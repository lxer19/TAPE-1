URL: http://www.cs.brown.edu/people/mcc/structure/papers/TR-noise.ps
Refering-URL: http://www.cs.brown.edu/people/mcc/structure/
Root-URL: http://www.cs.brown.edu/
Email: E-mail: trobina@vision.ee.ethz.ch  
Title: Error Model of a Coded-Light Range Sensor  
Author: Marjan Trobina 
Address: CH-8092 Z urich  
Affiliation: Communication Technology Laboratory Image Science Group ETH-Zentrum,  
Date: September 21, 1995  
Pubnum: BIWI-TR-164  
Abstract-found: 0
Intro-found: 1
Reference: <author> M.D. Altschuler, B.R. Altschuler, and J. </author> <month> Taboada </month> <year> (1979). </year> <title> Measuring surfaces space-coded by a laser-projected dot matrix. In Imaging Applications for Automated Industrial Inspection. </title> <booktitle> SPIE Vol. </booktitle> <pages> 182. </pages>
Reference-contexts: A further development of this technique used color encoding of projection directions ( Boyer and Kak, 1987 ) . A very robust encoding technique is the so called time-space encoding of projection directions. The first realization of this technique was published in <ref> ( Altschuler et al., 1979 ) </ref> . They projected a time encoded matrix of laser dots. This basic technique has been improved in ( Wahl, 1984 ) and independently in ( Inokuchi et al., 1984 ) .
Reference: <author> P. J. </author> <month> Besl </month> <year> (1988). </year> <title> Active, optical range imaging sensors. </title> <journal> Machine Vision and Applications, </journal> <volume> Vol. 1,pp. </volume> <pages> 127-152. </pages>
Reference-contexts: Experimental results are given in section 8. Conclusions make up section 9. 2 Related Work There are very many techniques to acquire three-dimensional information about scenes. Good papers that survey different techniques are ( Jarvis, 1983 ) and <ref> ( Besl, 1988 ) </ref> . The papers describing the different techniques usually concentrate on the measurement principle.
Reference: <author> H.A. </author> <title> Beyer (1992). Geometric and Radiometric Analysis of a CCD-Camera Based Photogrammetric Close-Range System. </title> <type> PhD thesis, </type> <institution> Institute of Geodesy and Photogrammetrie, ETH Z urich, </institution> <note> Mitteilungen Nr. 51. </note>
Reference-contexts: They model both camera and projector, using the standard photogrammetric central projection model including lens distortion parameters as it is normally used to calibrate a set of cameras as in <ref> ( Beyer, 1992 ) </ref> . This is possible by using a projector which can be programmed to project stripes in two orthogonal directions. Thus they can project cross-like features into object space, whose image coordinates are given a-priori. <p> The noise along stripe profiles can be attributed mainly to non-idealities of the frame grabber which uses the Phase Locked Loop synchronization mode (PLL). High frequency noise is overlaid with a low frequency noise which is probably also due to the synchronization. Similar noise behavior was reported by in <ref> ( Beyer, 1992 ) </ref> where the low frequency noise could be modeled. In our case low frequency noise changes from column to column (see figure 7) and thus it is not possible to model it. The noise amplitude edge corresponds well to the findings in ( Beyer, 1992 ) . <p> behavior was reported by in <ref> ( Beyer, 1992 ) </ref> where the low frequency noise could be modeled. In our case low frequency noise changes from column to column (see figure 7) and thus it is not possible to model it. The noise amplitude edge corresponds well to the findings in ( Beyer, 1992 ) . It could be decreased by using pixel-clock synchronization or even better by using a digital camera. Both was not possible with the hardware available. For a detailed analysis of error sources related to the synchronization mode see ( Beyer, 1992 ) . columns, starting in the <p> amplitude edge corresponds well to the findings in <ref> ( Beyer, 1992 ) </ref> . It could be decreased by using pixel-clock synchronization or even better by using a digital camera. Both was not possible with the hardware available. For a detailed analysis of error sources related to the synchronization mode see ( Beyer, 1992 ) . columns, starting in the middle of the 690x574 image and going towards the left image border. The increasing noise going from the image center to the image border may be explained by lens distortion. <p> In 21 the following we use the definitions which are used in photogrammetry; e.g. in <ref> ( Beyer, 1992 ) </ref> .
Reference: <author> K.L. Boyer and A.C. </author> <title> Kak (1987). Color-encoded structured light for rapid active ranging. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 9,pp. </volume> <pages> 14-28. </pages>
Reference-contexts: In order to achieve independence of different surface reflectance properties a black and a white reference pattern can be used. The disadvantage here is that only a few directions can be reliably differentiated. A further development of this technique used color encoding of projection directions <ref> ( Boyer and Kak, 1987 ) </ref> . A very robust encoding technique is the so called time-space encoding of projection directions. The first realization of this technique was published in ( Altschuler et al., 1979 ) . They projected a time encoded matrix of laser dots.
Reference: <author> G. Danuser and O. </author> <title> K ubler (1991). Calibration of cmo-stereo-microscopes in a micro robot system. In Commission V Symposium, From Pixels to Sequences. </title> <booktitle> International Society for Photogrammetry and Remote Sensing. </booktitle>
Reference-contexts: As already mentioned in the beginning of section 7, 16 a set of check points is introduced as additional unknowns in order to get their covariance matrices. Here are some important requirements for the calibration standard taken from <ref> ( Danuser and K ubler, 1991 ) </ref> . * The control points have to be regularly distributed in 3-D workspace. * The images of the control points have to have a good contrast and an extent of at least 10 pixels.
Reference: <author> O. </author> <title> Faugeras (1993). Three-Dimensional Computer Vision: A Geometric Viewpoint. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: Thus, we cannot introduce the lens distortion parameters in the projector model. Consequently, we also prefer to use a simple linear model for the camera as proposed by Faugeras <ref> ( Faugeras, 1993 ) </ref> . Apart from using different models, we use the same framework for estimation of model parameters and covariance matrices. 3 Measurement Principle Our measurement principle is based on active triangulation. <p> This makes it possible to use a linear camera model as well as a linear projector model. 200 (b), 138 (c), and 68 (d). 4 Camera Model In this work a pinhole camera model as proposed in <ref> ( Faugeras, 1993 ) </ref> is used. This camera model is based on projective geometry which is elaborated in the book by Faugeras. The main advantage of using projective (also called homogeneous) coordinates is that of having a linear camera model. <p> The exact form of ~ P for the camera in arbitrary position and orientation can be found in <ref> ( Faugeras, 1993 ) </ref> . Let us assume for a moment that ~ P is known (how to estimate ~ P will be shown in section 7). In this case different useful pieces of information can be computed from ~ P; e.g the intrinsic and extrinsic camera parameters. <p> In this case different useful pieces of information can be computed from ~ P; e.g the intrinsic and extrinsic camera parameters. Again, the interested reader can refer to <ref> ( Faugeras, 1993 ) </ref> . Specifically for this work it is important to recapitulate how one can compute the camera center O c from ~ P. As it is shown in ( Faugeras, 1993 ) , O c can be computed by solving the following equation system. ~ P O c <p> Again, the interested reader can refer to <ref> ( Faugeras, 1993 ) </ref> . Specifically for this work it is important to recapitulate how one can compute the camera center O c from ~ P. As it is shown in ( Faugeras, 1993 ) , O c can be computed by solving the following equation system. ~ P O c # If we write the 3x4 matrix ~ P as [P ~ p] where P is a 3x3 matrix and ~ p a 3x1 vector, we can compute the equation of <p> Because of the projectivity these parameters are defined only up to a scale factor, thus an additional constraint must be found. For the discussion about possible constraints see <ref> ( Faugeras, 1993 ) </ref> . We use the constraint that the norm of the first three elements of the third row of P has to be equal to 1 as proposed by Faugeras ( Faugeras, 1993 ) . Thus, 11 unknowns of the camera model remain. 2. <p> For the discussion about possible constraints see <ref> ( Faugeras, 1993 ) </ref> . We use the constraint that the norm of the first three elements of the third row of P has to be equal to 1 as proposed by Faugeras ( Faugeras, 1993 ) . Thus, 11 unknowns of the camera model remain. 2. <p> The initial solution X 0 is provided independently from the actual least squares estimation. Approximate values of camera matrix P are computed using equation 11 as it is done in <ref> ( Faugeras, 1993 ) </ref> . Similarly, equation 12 is used to get an initial solution for projector matrix Q. Initial values for 3-D coordinates of check points are available from the calibration standard.
Reference: <author> A. </author> <title> Gr un (March 1984). Adaptive Least Squares Correlation. Concept and First Results . Technical report, Internal Report prepared for Helava Associates, </title> <publisher> Inc., </publisher> <address> Columbus, Ohio. </address>
Reference-contexts: In this case they can be measured very accurately using least squares template matching as in <ref> ( Gr un, 1984 ) </ref> . * Highly accurate 3-D coordinates of control points as well as their errors have to be available. of camera, projector, and workspace in the range-sensor-plane (RSP), (right) position of the RSP and the workspace projected onto the XY plane of the world coordinate system. <p> Thus, matrix K co XY Z only plays a role for 3-D coordinates of control points. Image coordinates of centers of white squares are measured using least squares template matching as in <ref> ( Gr un, 1984 ) </ref> . Figure 12 shows images of our calibration standard at two different heights along the Z-axis of the world coordinate system.
Reference: <author> R.M. Haralick and L.G. </author> <title> Shapiro (1991). Glossary of computer vision terms. </title> <journal> Pattern Recognition, </journal> <volume> Vol. 24,No. 1,pp. </volume> <month> 69-93. </month> <title> 30 P. H ebert (May 1994). From Points to Shape Recovery: Reliable Geometric Primitive Extraction. </title> <type> PhD thesis, </type> <institution> Universit e Laval, Qu ebec, Canada. </institution>
Reference-contexts: When the question of calibration and achievable accuracy is addressed, the accuracy is given mostly only by magnitude, either as absolute value as in ( Rioux, 1984 ) or as relative accuracy ( Stahs 1 Rangel is defined in <ref> ( Haralick and Shapiro, 1991 ) </ref> as the range data element produced by a range sensor. It is a pair whose first member is an image position and whose second member is the range value. 2 and Wahl, 1990 ) . <p> From this follows an important consequence related to range images. Usually they contain at the position of every pixel the orthogonal distance between the image plane and the ranged surface patch corresponding to the pixel <ref> ( Haralick and Shapiro, 1991 ) </ref> . Instead, we propose to store the Euclidean distance between the measured point and the camera's optical center O c at corresponding image point m.
Reference: <author> S. Inokuchi, K. Sato, and F. </author> <title> Matsuda (1984). Range-imaging system for 3-d object recognition. </title> <booktitle> In International Conference on Pattern Recognition, </booktitle> <pages> pp. 806-808. </pages> <address> Montreal, Canada. </address>
Reference-contexts: The first realization of this technique was published in ( Altschuler et al., 1979 ) . They projected a time encoded matrix of laser dots. This basic technique has been improved in ( Wahl, 1984 ) and independently in <ref> ( Inokuchi et al., 1984 ) </ref> . They achieve the time-space encoding of stripes by projecting a sequence of n stripe patterns onto the scene (see figure 1).
Reference: <author> R.A. </author> <title> Jarvis (March 1983). A perspective on range finding techniques for computer vision. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 5,No. 2,pp. </volume> <pages> 122-139. </pages>
Reference-contexts: Experimental results are given in section 8. Conclusions make up section 9. 2 Related Work There are very many techniques to acquire three-dimensional information about scenes. Good papers that survey different techniques are <ref> ( Jarvis, 1983 ) </ref> and ( Besl, 1988 ) . The papers describing the different techniques usually concentrate on the measurement principle.
Reference: <author> W. </author> <month> Riechmann (March </month> <year> 1995). </year> <title> Fast object recording by means of structured light and photogrammetric techniques. </title> <editor> In E. Baltsavias, H. Beyer, and H.-G. Maas, editors, </editor> <booktitle> From Pixels to Sequences, </booktitle> <pages> pp. 195-200. </pages> <booktitle> ISPRS Intercommission Workshop, </booktitle> <address> Z urich, Switzerland. </address>
Reference-contexts: Strutz ( Strutz, 1993 ) established the noise model for the coded-light range sensor based on a commercial stripe projector, which was further developed in <ref> ( Riechmann, 1995 ) </ref> . They model both camera and projector, using the standard photogrammetric central projection model including lens distortion parameters as it is normally used to calibrate a set of cameras as in ( Beyer, 1992 ) .
Reference: <author> M. </author> <month> Rioux </month> <year> (1984). </year> <title> Laser range finder based on synchronized scanners. </title> <journal> Applied Optics, </journal> <volume> Vol. 23,No. 21,pp. </volume> <pages> 3837-3844. </pages>
Reference-contexts: The papers describing the different techniques usually concentrate on the measurement principle. When the question of calibration and achievable accuracy is addressed, the accuracy is given mostly only by magnitude, either as absolute value as in <ref> ( Rioux, 1984 ) </ref> or as relative accuracy ( Stahs 1 Rangel is defined in ( Haralick and Shapiro, 1991 ) as the range data element produced by a range sensor. <p> In other words, the covariance matrix of the measurements is not known in most cases. An exception is the work in ( H ebert, 1994 ) where an empirical noise model has been built for the laser range sensor designed in <ref> ( Rioux, 1984 ) </ref> . He measured the covariance matrices experimentally depending on the angle between measured surface and optical axis, and on distance between the measured point and the sensor. The covariance matrices were stored in a 2-dimensional table, entries being indexed by angle and distance.
Reference: <author> Y. </author> <title> Sato (1990). Range finding systems for 3-d object recognition. </title> <journal> Journal of Information Science and Engineering, </journal> <volume> Vol. 6,pp. </volume> <pages> 285-310. </pages>
Reference-contexts: With the availability of fast and cheap range sensors like the ones developed in ( Stahs and Wahl, 1990 ) and <ref> ( Sato, 1990 ) </ref> the range of possible applications is ever growing. Up to now, speed and robustness have had a priority over measurement accuracy.
Reference: <author> H.H. </author> <month> Schmid (June </month> <year> 1977). </year> <title> Ein allgemeiner Ausgleichungs-Algorithmus f ur die numerische Auswertung in der Photogrammetrie. </title> <type> Technical report, </type> <institution> Institute of Geodesy and Photogrammetrie, ETH Z urich, </institution> <note> Mitteilungen Nr. 22. </note>
Reference: <author> T. </author> <title> Stahs and F.M. Wahl (1990). Fast and robust range data acquisition in a low-cost environment. </title> <editor> In A. Gruen and E. Baltsavias, editors, </editor> <booktitle> Close-Range Photogrammetry Meets Machine Vision, </booktitle> <pages> pp. 496-503. </pages> <booktitle> ISPRS Commision V Symposium, </booktitle> <address> Z urich, Switzerland. </address>
Reference-contexts: With the availability of fast and cheap range sensors like the ones developed in <ref> ( Stahs and Wahl, 1990 ) </ref> and ( Sato, 1990 ) the range of possible applications is ever growing. Up to now, speed and robustness have had a priority over measurement accuracy.
Reference: <author> T. </author> <month> Strutz (July </month> <year> 1993). </year> <title> Ein genaues optisches Triangulationsverfahren zur Oberfl achenvermessung. </title> <type> PhD thesis, </type> <institution> TU Magdeburg, Germany. </institution>
Reference-contexts: Extraction of eigenvalues and eigenvectors allowed to extract the error ellipsoids for every angle/distance combination. The covariance matrices were determined by the statistics of 100 repeated measurements, therefore the errors of the sensor model were not considered in computing the covariance matrices. Strutz <ref> ( Strutz, 1993 ) </ref> established the noise model for the coded-light range sensor based on a commercial stripe projector, which was further developed in ( Riechmann, 1995 ) . <p> To our knowledge, the influence of the errors in model parameters on range data accuracy was only considered in <ref> ( Strutz, 1993 ) </ref> . The covariance matrix of the range measurements was represented as an error ellipsoid whose axis lengths and orientations are given. It was explained why the error ellipsoid orientation almost coincides with the projector's axis.
Reference: <author> F. </author> <title> Wahl (1984). A coded light approach for 3-dimensional (3d) vision. </title> <type> Research Report RZ 1452, </type> <institution> IBM. </institution>
Reference-contexts: A very robust encoding technique is the so called time-space encoding of projection directions. The first realization of this technique was published in ( Altschuler et al., 1979 ) . They projected a time encoded matrix of laser dots. This basic technique has been improved in <ref> ( Wahl, 1984 ) </ref> and independently in ( Inokuchi et al., 1984 ) . They achieve the time-space encoding of stripes by projecting a sequence of n stripe patterns onto the scene (see figure 1).
Reference: <editor> H. Wolf (1992). Bedienunganleitung: Linienprojektor LCD-320. ABW Au-tomatisierung und Bildverarbeitung Dr. </editor> <publisher> Wolf. </publisher>
Reference-contexts: They achieve the time-space encoding of stripes by projecting a sequence of n stripe patterns onto the scene (see figure 1). In our system, the stripe patterns are generated by a computer controlled transparent Liquid Crystal Display (LCD) projector, which is commercially available <ref> ( Wolf, 1992 ) </ref> . The patterns allow the distinction of 2 n different projection directions indicated by the s coordinate (see figure 1). Each direction can be described uniquely by a characteristic n-bit code.
Reference: <author> Q.-Z. </author> <title> Ye (1988). Range Cameras Based on Structured Light. </title> <type> PhD thesis, </type> <institution> Dept. of Electrical Engineering, Link oping University, Link oping, Sweden. </institution> <month> 31 </month>
Reference-contexts: A similar method was already described in <ref> ( Ye, 1988 ) </ref> where the use of normal and inverse stripe patterns was proposed. In this case, the position of the stripe edge P is computed as the intersection between the line AB and the line EF , see figure 4 (b).
References-found: 19

