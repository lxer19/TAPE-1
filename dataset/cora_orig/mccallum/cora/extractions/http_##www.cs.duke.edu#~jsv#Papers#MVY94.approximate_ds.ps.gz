URL: http://www.cs.duke.edu/~jsv/Papers/MVY94.approximate_ds.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node76.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Chapter 1 Approximate Data Structures with Applications (Extended Abstract)  
Author: Yossi Matias Jeffrey Scott Vitter Neal E. Young 
Abstract: In this paper we introduce the notion of approximate data structures, in which a small amount of error is tolerated in the output. Approximate data structures trade error of approximation for faster operation, leading to theoretical and practical speedups for a wide variety of algorithms. We give approximate variants of the van Emde Boas data structure, which support the same dynamic operations as the standard van Emde Boas data structure [28, 20], except that answers to queries are approximate. The variants support all operations in constant time provided the error of approximation is 1=polylog(n), and in O(log log n) time provided the error is 1=polynomial(n), for n elements in the data structure. We consider the tolerance of prototypical algorithms to approximate data structures. We study in particular Prim's minimum spanning tree algorithm, Di-jkstra's single-source shortest paths algorithm, and an on-line variant of Graham's convex hull algorithm. To obtain output which approximates the desired output with the error of approximation tending to zero, Prim's algorithm requires only linear time, Dijkstra's algorithm requires O(m log log n) time, and the on-line variant of Graham's algorithm requires constant amortized time per operation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1974. </year>
Reference-contexts: For the additively approximate variant, the function f preserves the order of any two elements differing additively by at least some . Let the elements be taken from a universe <ref> [1; U ] </ref>. <p> Arguably, our algorithm is simpler and more practical. 4 Model of computation The model of computation assumed in this paper is a modernized version of the random access machine (ram). Many ram models of a similar nature have been defined in the literature, dating back to the early 1960s <ref> [1] </ref>. Our ram model is a realistic variant of the logarithmic-cost ram [1]: the model assumes constant-time exact binary integer arithmetic (+, , fi, div), bitwise operations (left-shift, right-shift, bitwise-xor, bitwise-and), and addressing operations on words of size b. Put another way, the word size of the ram is b. <p> Many ram models of a similar nature have been defined in the literature, dating back to the early 1960s <ref> [1] </ref>. Our ram model is a realistic variant of the logarithmic-cost ram [1]: the model assumes constant-time exact binary integer arithmetic (+, , fi, div), bitwise operations (left-shift, right-shift, bitwise-xor, bitwise-and), and addressing operations on words of size b. Put another way, the word size of the ram is b. <p> The lemma below assumes a logarithmic word-size ram. The notion of equivalence between data structures is that, given one of the data structures, the other can be simulated with constant-time overhead per operation. Lemma 5.1. The problem of representing a multiplicatively (1 + *)-approximate veb on universe <ref> [1; U ] </ref> is equivalent to the problem of representing an exact veb on universe f0; 1; :::; O (log 1+* U )g.
Reference: [2] <author> J. L. Bentley, M. G. Faust, and F. P. Preparata. </author> <title> Approximation algorithms for convex hulls. </title> <journal> Communications of the ACM, </journal> <volume> 25(1) </volume> <pages> 64-68, </pages> <year> 1982. </year>
Reference-contexts: We adapt Graham's scan to obtain our on-line algorithm, as sketched below. As an invariant, we have a set of points that are in the intermediate convex hull, stored in an approximate veb according to their angular coordinates. The universe is <ref> [0; 2] </ref> with a additive error, which can be interpreted as the perturbation error of points in their angular coordinate, without changing their values in the distance coordinates. This results in point displacements of at most (1 + ) times the diameter of the convex hull. <p> Shamos (see, e.g., [26]) gave an on-line algorithm for (exact) convex hull that takes O (log n) amortized time per update step. Preparata [24] gave a real-time on-line (exact) convex hull algorithm with O (log n)-time worst-case time per update step. Bentley, Faust, and Preparata <ref> [2] </ref> give an O (n + 1=)-time algorithm that finds a (1 + )- approximate convex hull. Their result was superseded by the result of Bern et al. mentioned above.
Reference: [3] <author> M. W. Bern, H. J. Karloff, P. Raghavan, and B. Schieber. </author> <title> Fast geometric approximation techniques and geometric embedding problems. </title> <journal> Theoretical Computer Science, </journal> <volume> 106 </volume> <pages> 265-281, </pages> <year> 1992. </year>
Reference-contexts: Such errors has been studied, for example, in the context of computational geometry [8, 9, 13, 14, 21, 22, 23]. We discuss this further in Section 6. Approximate sorting. Bern, Karloff, Raghavan, and Schieber <ref> [3] </ref> introduced approximate sorting and applied it to several geometric problems. Their results include an O ((n log log n)=*)-time algorithm that finds a (1 +*)- approximate Euclidean minimum spanning tree. They also gave an O (n)-time algorithm that finds a (1 + )- approximate convex hull for any 1/polynomial. <p> If the sweeping algorithm of Chew and Fortune [4] can be shown to be appropriately robust then the use of the van Emde Boas priority queue there can be replaced by an approximate variant; an improved running time may imply better performance for algorithms described in <ref> [3] </ref>.
Reference: [4] <author> L. P. Chew and S. Fortune. </author> <title> Sorting helps for Voronoi diagrams. </title> <booktitle> In 13th Symp. on Mathematical Programming, </booktitle> <address> Japan, </address> <year> 1988. </year>
Reference-contexts: If the sweeping algorithm of Chew and Fortune <ref> [4] </ref> can be shown to be appropriately robust then the use of the van Emde Boas priority queue there can be replaced by an approximate variant; an improved running time may imply better performance for algorithms described in [3].
Reference: [5] <author> M. Dietzfelbinger, J. Gil, Y. Matias, and N. Pippenger. </author> <title> Polynomial Hash Functions are Reliable. </title> <booktitle> Proc. of 19th International Colloquium on Automata Languages and Programming, </booktitle> <publisher> Springer LNCS 623, </publisher> <pages> 235-246, </pages> <year> 1992. </year>
Reference-contexts: The overhead incurred by using dynamic hashing is constant per memory access with high probability <ref> [6, 5] </ref>. Thus, if the data structures are implemented to use nearly linear space, the times given per operation hold only with high probability. 1.1 Description of the data structure. <p> In either case, all dictionary operations require only constant time. In the former case, the time is constant with high probability <ref> [6, 5] </ref>; in the latter case, a well-known trick is required to instantiate the dictionary in constant time. Each instance of our data structure will have a doubly-linked list of element/datum pairs. The list is ordered by the ordering induced by the elements.
Reference: [6] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> A New Universal Class of Hash Functions and Dynamic Hashing in Real Time, </title> <booktitle> In Proc. of 17th International Colloquium on Automata Languages and Programming, </booktitle> <publisher> Springer LNCS 443: </publisher> <pages> 6-19, </pages> <year> 1990. </year>
Reference-contexts: The overhead incurred by using dynamic hashing is constant per memory access with high probability <ref> [6, 5] </ref>. Thus, if the data structures are implemented to use nearly linear space, the times given per operation hold only with high probability. 1.1 Description of the data structure. <p> In either case, all dictionary operations require only constant time. In the former case, the time is constant with high probability <ref> [6, 5] </ref>; in the latter case, a well-known trick is required to instantiate the dictionary in constant time. Each instance of our data structure will have a doubly-linked list of element/datum pairs. The list is ordered by the ordering induced by the elements.
Reference: [7] <author> E. W. Dijkstra. </author> <title> A note on two problems in connexion with graphs. </title> <journal> Numerische Mathematik, </journal> <volume> 1 </volume> <pages> 269-271, </pages> <year> 1959. </year>
Reference-contexts: The proofs are simple and are given in the full paper. 2.1 Minimum spanning trees. For the minimum spanning tree problem, we show the following result about the performance of Prim's algorithm <ref> [16, 25, 7] </ref> when our approximate veb data structure is used to implement the priority queue: Theorem 2.1.
Reference: [8] <author> S. Fortune. </author> <title> Stable maintenance of point-set triangulation in two dimensions. </title> <booktitle> In Proc. of the 30th IEEE Annual Symp. on Foundation of Computer Science, </booktitle> <year> 1989. </year>
Reference-contexts: Finite precision arithmetic. The sensitivity of algorithms to approximate data structures is related in spirit to the challenging problems that arise from various types of error in numeric computations. Such errors has been studied, for example, in the context of computational geometry <ref> [8, 9, 13, 14, 21, 22, 23] </ref>. We discuss this further in Section 6. Approximate sorting. Bern, Karloff, Raghavan, and Schieber [3] introduced approximate sorting and applied it to several geometric problems. <p> Of particular interest were algorithms in computational geometry. Frameworks such as the "epsilon geometry" of Guibas, Salesin and Stolfi [14] may be therefore relevant in our context. The "robust algorithms" described by Fortune and Milenkovic <ref> [8, 9, 21, 22, 23] </ref> are natural candidates for approximate data structures. Expanding the range of applications of approximate data structures is a fruitful area for further research. Other possible candidates include algorithms in computational geometry that use the well-known sweeping technique, provided that they are appropriately robust.
Reference: [9] <author> S. Fortune and V. Milenkovic. </author> <title> Numerical stability of algorithms for line arrangements. </title> <booktitle> In Proc. of the 7th Annual Symposium on Computational Geometry, </booktitle> <pages> pages 334-341, </pages> <year> 1991. </year>
Reference-contexts: Finite precision arithmetic. The sensitivity of algorithms to approximate data structures is related in spirit to the challenging problems that arise from various types of error in numeric computations. Such errors has been studied, for example, in the context of computational geometry <ref> [8, 9, 13, 14, 21, 22, 23] </ref>. We discuss this further in Section 6. Approximate sorting. Bern, Karloff, Raghavan, and Schieber [3] introduced approximate sorting and applied it to several geometric problems. <p> Of particular interest were algorithms in computational geometry. Frameworks such as the "epsilon geometry" of Guibas, Salesin and Stolfi [14] may be therefore relevant in our context. The "robust algorithms" described by Fortune and Milenkovic <ref> [8, 9, 21, 22, 23] </ref> are natural candidates for approximate data structures. Expanding the range of applications of approximate data structures is a fruitful area for further research. Other possible candidates include algorithms in computational geometry that use the well-known sweeping technique, provided that they are appropriately robust. <p> Other possible candidates include algorithms in computational geometry that use the well-known sweeping technique, provided that they are appropriately robust. For instance, in the sweeping algorithm for the line arrangement problem with approximate arithmetic, pre 8 Matias, Vitter, & Young sented by Fortune and Milenkovic <ref> [9] </ref>, the priority queue can be replaced by an approximate priority queue with minor adjustments, to obtain an output with similar accuracy.
Reference: [10] <author> M. L. Fredman and D. E. Willard. </author> <title> Blasting through the information theoretic barrier with fusion trees. </title> <booktitle> In Proc. of the 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 1-7, </pages> <year> 1990. </year>
Reference-contexts: Exploiting the power of RAM. Fredman and Willard have considered a number of data structures taking advantage of arithmetic and bitwise operations on words of size O (log U ). In <ref> [10] </ref>, they presented the fusion tree data structure. Briefly, fusion trees implement the veb data type in time O (log n= log log n).
Reference: [11] <author> M. L. Fredman and D. E. Willard. </author> <title> Trans-dichotomous algorithms for minimum spanning trees and shortest paths. </title> <booktitle> In Proc. of the 31st IEEE Annual Symp. on Foundation of Computer Science, </booktitle> <pages> pages 719-725, </pages> <year> 1990. </year>
Reference-contexts: In [10], they presented the fusion tree data structure. Briefly, fusion trees implement the veb data type in time O (log n= log log n). They also presented an atomic heap data structure <ref> [11] </ref> based on their fusion tree and used it to obtain a linear-time minimum spanning tree algorithm and an O (m + n log n= log log n)-time single-source shortest paths algorithm. Willard [29] also considered similar applications to related geometric and searching problems.
Reference: [12] <author> R. L. Graham. </author> <title> An efficient algorithm for determining the convex hull of a finite planar set. </title> <journal> Information Processing Letters, </journal> <volume> 1 </volume> <pages> 132-133, </pages> <year> 1972. </year>
Reference-contexts: We show the following result about the Graham scan algorithm <ref> [12] </ref> when run using our approximate veb data structure: Theorem 2.3. <p> Given a new point, its successor and predecessor in the veb are found, and the operations required to check the convex hull and, if necessary, to correct it are carried on, as in Graham's algorithm <ref> [12] </ref>. These operations may include the insertion of the new point into the veb (if the point is on the convex hull) and the possible deletion of other points. <p> Their result was superseded by the result of Bern et al. mentioned above. Janardan [15] gave an algorithm maintaining a fully dynamic (1 + )-approximate convex hull (allowing deletion of points) in O (log (n)=) time per request. Our on-line approximation algorithm is based on Graham's scan algorithm <ref> [12] </ref> and can be viewed as a combination of the algorithms by Shamos and by Bentley et al., with the replacement of an exact veb data structure by an approximate variant. Computation with large words. Kirkpatrick and Reich [17] considered exact sorting with large words, giving upper and lower bounds.
Reference: [13] <author> D. H. Greene and F. F. Yao. </author> <title> Finite-resolution computational geometry. </title> <booktitle> Proc. of the 27th IEEE Annual Symp. on Foundation of Computer Science, </booktitle> <pages> pages 143-152, </pages> <year> 1986. </year>
Reference-contexts: Finite precision arithmetic. The sensitivity of algorithms to approximate data structures is related in spirit to the challenging problems that arise from various types of error in numeric computations. Such errors has been studied, for example, in the context of computational geometry <ref> [8, 9, 13, 14, 21, 22, 23] </ref>. We discuss this further in Section 6. Approximate sorting. Bern, Karloff, Raghavan, and Schieber [3] introduced approximate sorting and applied it to several geometric problems.
Reference: [14] <author> L. I. Guibas, D. Salesin, and J. Stolfi. </author> <title> Epsilon geometry: Building robust algorithms from imprecise computations. </title> <booktitle> In Proc. of the 5th Annual Symposium on Computational Geometry, </booktitle> <pages> pages 208-217, </pages> <year> 1989. </year>
Reference-contexts: Finite precision arithmetic. The sensitivity of algorithms to approximate data structures is related in spirit to the challenging problems that arise from various types of error in numeric computations. Such errors has been studied, for example, in the context of computational geometry <ref> [8, 9, 13, 14, 21, 22, 23] </ref>. We discuss this further in Section 6. Approximate sorting. Bern, Karloff, Raghavan, and Schieber [3] introduced approximate sorting and applied it to several geometric problems. <p> In recent years there has been an increasing interest in studying the effect of such errors on algorithms. Of particular interest were algorithms in computational geometry. Frameworks such as the "epsilon geometry" of Guibas, Salesin and Stolfi <ref> [14] </ref> may be therefore relevant in our context. The "robust algorithms" described by Fortune and Milenkovic [8, 9, 21, 22, 23] are natural candidates for approximate data structures. Expanding the range of applications of approximate data structures is a fruitful area for further research.
Reference: [15] <author> R. Janardan. </author> <title> On maintaining the width and diameter of a planar point-set online. </title> <booktitle> In Proc. 2nd International Symposium on Algorithms, volume 557 of Lecture Notes in Computer Science, </booktitle> <pages> pages 137-149. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year> <note> To appear in International Journal of Computational Geometry & Applications. </note>
Reference-contexts: Bentley, Faust, and Preparata [2] give an O (n + 1=)-time algorithm that finds a (1 + )- approximate convex hull. Their result was superseded by the result of Bern et al. mentioned above. Janardan <ref> [15] </ref> gave an algorithm maintaining a fully dynamic (1 + )-approximate convex hull (allowing deletion of points) in O (log (n)=) time per request.
Reference: [16] <editor> V. Jarn ik. O jistem problemu minimalmn im. Praca Moravske Pr irodovedecke Spolecnosti, </editor> <volume> 6 </volume> <pages> 57-63, </pages> <year> 1930. </year> <note> (In Czech). </note>
Reference-contexts: The proofs are simple and are given in the full paper. 2.1 Minimum spanning trees. For the minimum spanning tree problem, we show the following result about the performance of Prim's algorithm <ref> [16, 25, 7] </ref> when our approximate veb data structure is used to implement the priority queue: Theorem 2.1.
Reference: [17] <author> D. Kirkpatrick and S. Reisch. </author> <title> Upper bounds for sorting integers on random access machines. </title> <journal> Theoretical Computer Science, </journal> <volume> 28 </volume> <pages> 263-276, </pages> <year> 1984. </year>
Reference-contexts: Our on-line approximation algorithm is based on Graham's scan algorithm [12] and can be viewed as a combination of the algorithms by Shamos and by Bentley et al., with the replacement of an exact veb data structure by an approximate variant. Computation with large words. Kirkpatrick and Reich <ref> [17] </ref> considered exact sorting with large words, giving upper and lower bounds.
Reference: [18] <author> P. N. Klein and R. E. Tarjan. </author> <title> A linear-time algorithm for minimum spanning tree. </title> <type> Personal communication, </type> <month> August, </month> <year> 1993. </year>
Reference-contexts: On the other hand, they are more complicated and involve larger constants. Subsequent to our work Klein and Tarjan recently announced a randomized minimum spanning tree algorithm that requires only expected linear time <ref> [18] </ref>. Arguably, our algorithm is simpler and more practical. 4 Model of computation The model of computation assumed in this paper is a modernized version of the random access machine (ram).
Reference: [19] <author> Y. Matias, J. S. Vitter, and W.-C. Ni. </author> <title> Dynamic generation of random variates. </title> <booktitle> In Proc. of the Fourth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 361-370, </pages> <year> 1993. </year>
Reference-contexts: Since each point can only be deleted once from the convex hull, the amortized number of veb operations per point is constant. 3 Related work Our work was inspired by and improves upon data structures developed for use in dynamic random variate generation by Matias, Vitter, and Ni <ref> [19] </ref>. Approximation techniques such as rounding and bucketing have been widely used in algorithm design. 4 Matias, Vitter, & Young This is the first work we know of that gives a general-purpose approximate data structure. Finite precision arithmetic.
Reference: [20] <author> K. Mehlhorn. </author> <title> Data Structures and Algorithms. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, </address> <year> 1984. </year>
Reference-contexts: 1 Introduction The van Emde Boas data structure (veb) <ref> [28, 20] </ref> represents an ordered multiset of integers. The data fl AT&T Bell Laboratories, 600 Mountain Avenue, Murray Hill, NJ 07974. Email: matias@research.att.com. y Department of Computer Science, Duke University, Box 90129, Durham, N.C. 27708-0129. Part of this research was done while the author was at Brown University.
Reference: [21] <author> V. Milenkovic. </author> <title> Verifiable Implementations of Geometric Algorithms using Finite Precision Arithmetic. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <year> 1988. </year>
Reference-contexts: Finite precision arithmetic. The sensitivity of algorithms to approximate data structures is related in spirit to the challenging problems that arise from various types of error in numeric computations. Such errors has been studied, for example, in the context of computational geometry <ref> [8, 9, 13, 14, 21, 22, 23] </ref>. We discuss this further in Section 6. Approximate sorting. Bern, Karloff, Raghavan, and Schieber [3] introduced approximate sorting and applied it to several geometric problems. <p> Of particular interest were algorithms in computational geometry. Frameworks such as the "epsilon geometry" of Guibas, Salesin and Stolfi [14] may be therefore relevant in our context. The "robust algorithms" described by Fortune and Milenkovic <ref> [8, 9, 21, 22, 23] </ref> are natural candidates for approximate data structures. Expanding the range of applications of approximate data structures is a fruitful area for further research. Other possible candidates include algorithms in computational geometry that use the well-known sweeping technique, provided that they are appropriately robust.
Reference: [22] <author> V. Milenkovic. </author> <title> Calculating approximate curve arrangements using rounded arithmetic. </title> <booktitle> In Proc. of the 5th Annual Symposium on Computational Geometry, </booktitle> <pages> pages 197-207, </pages> <year> 1989. </year>
Reference-contexts: Finite precision arithmetic. The sensitivity of algorithms to approximate data structures is related in spirit to the challenging problems that arise from various types of error in numeric computations. Such errors has been studied, for example, in the context of computational geometry <ref> [8, 9, 13, 14, 21, 22, 23] </ref>. We discuss this further in Section 6. Approximate sorting. Bern, Karloff, Raghavan, and Schieber [3] introduced approximate sorting and applied it to several geometric problems. <p> Of particular interest were algorithms in computational geometry. Frameworks such as the "epsilon geometry" of Guibas, Salesin and Stolfi [14] may be therefore relevant in our context. The "robust algorithms" described by Fortune and Milenkovic <ref> [8, 9, 21, 22, 23] </ref> are natural candidates for approximate data structures. Expanding the range of applications of approximate data structures is a fruitful area for further research. Other possible candidates include algorithms in computational geometry that use the well-known sweeping technique, provided that they are appropriately robust.
Reference: [23] <author> V. Milenkovic. </author> <title> Double precision geometry: A general technique for calculating line and segment intersections using rounded arithmetic. </title> <booktitle> In Proc. of the 30th IEEE Annual Symp. on Foundation of Computer Science, </booktitle> <year> 1989. </year>
Reference-contexts: Finite precision arithmetic. The sensitivity of algorithms to approximate data structures is related in spirit to the challenging problems that arise from various types of error in numeric computations. Such errors has been studied, for example, in the context of computational geometry <ref> [8, 9, 13, 14, 21, 22, 23] </ref>. We discuss this further in Section 6. Approximate sorting. Bern, Karloff, Raghavan, and Schieber [3] introduced approximate sorting and applied it to several geometric problems. <p> Of particular interest were algorithms in computational geometry. Frameworks such as the "epsilon geometry" of Guibas, Salesin and Stolfi [14] may be therefore relevant in our context. The "robust algorithms" described by Fortune and Milenkovic <ref> [8, 9, 21, 22, 23] </ref> are natural candidates for approximate data structures. Expanding the range of applications of approximate data structures is a fruitful area for further research. Other possible candidates include algorithms in computational geometry that use the well-known sweeping technique, provided that they are appropriately robust.
Reference: [24] <author> F. P. Preparata. </author> <title> An optimal real-time algorithm for planar convex hulls. </title> <journal> Communications of the ACM, </journal> <volume> 22(7) </volume> <pages> 402-405, </pages> <year> 1979. </year>
Reference-contexts: Sorting requires precomputation, so is not applicable to such problems. Convex hull algorithms. There are several relevant works for the on-line convex hull problem. Shamos (see, e.g., [26]) gave an on-line algorithm for (exact) convex hull that takes O (log n) amortized time per update step. Preparata <ref> [24] </ref> gave a real-time on-line (exact) convex hull algorithm with O (log n)-time worst-case time per update step. Bentley, Faust, and Preparata [2] give an O (n + 1=)-time algorithm that finds a (1 + )- approximate convex hull.
Reference: [25] <author> R. C. Prim. </author> <title> Shortest connection networks and some generalizations. </title> <journal> Bell System Tech. J., </journal> <volume> 36 </volume> <pages> 1389-1401, </pages> <year> 1957. </year>
Reference-contexts: The proofs are simple and are given in the full paper. 2.1 Minimum spanning trees. For the minimum spanning tree problem, we show the following result about the performance of Prim's algorithm <ref> [16, 25, 7] </ref> when our approximate veb data structure is used to implement the priority queue: Theorem 2.1.
Reference: [26] <author> F. P. Preparata and M. I. Shamos. </author> <title> Computational Geometry, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Sorting requires precomputation, so is not applicable to such problems. Convex hull algorithms. There are several relevant works for the on-line convex hull problem. Shamos (see, e.g., <ref> [26] </ref>) gave an on-line algorithm for (exact) convex hull that takes O (log n) amortized time per update step. Preparata [24] gave a real-time on-line (exact) convex hull algorithm with O (log n)-time worst-case time per update step.
Reference: [27] <author> R. E. Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1983. </year>
Reference-contexts: Approximate data structures can be "plugged in" to such algorithms without modifying the algorithm. 2.2 Shortest paths. For the single-source shortest paths problem, we get the following result by using an approximate veb data structure as a priority queue in Dijkstra's algorithm (see, e.g., <ref> [27, Thm 7.6] </ref>): Theorem 2.2. <p> Again, this speed-up can be obtained with no adaptation of the original algorithm. Analysis. The proof of Theorem 2.2 follows the proof of the exact shortest paths algorithm (see, e.g., <ref> [27, Thm 7.6] </ref>). The crux of the proof is an inductive claim, saying that any vertex w that becomes labeled during or after the scanning of a vertex v also satisfies dist (w) dist (v), where dist (w) is a so-called tentative distance from the source to w.
Reference: [28] <author> P. van Emde Boas, R. Kaas, and E. Zijlstra. </author> <title> Design and implementation of an efficient priority queue. </title> <journal> Math. Systems Theory, </journal> <volume> 10 </volume> <pages> 99-127, </pages> <year> 1977. </year>
Reference-contexts: 1 Introduction The van Emde Boas data structure (veb) <ref> [28, 20] </ref> represents an ordered multiset of integers. The data fl AT&T Bell Laboratories, 600 Mountain Avenue, Murray Hill, NJ 07974. Email: matias@research.att.com. y Department of Computer Science, Duke University, Box 90129, Durham, N.C. 27708-0129. Part of this research was done while the author was at Brown University.
Reference: [29] <author> D. E. Willard. </author> <title> Applications of the fusion tree method to computational geometry and searching. </title> <booktitle> In Proc. of the Third Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1992. </year>
Reference-contexts: They also presented an atomic heap data structure [11] based on their fusion tree and used it to obtain a linear-time minimum spanning tree algorithm and an O (m + n log n= log log n)-time single-source shortest paths algorithm. Willard <ref> [29] </ref> also considered similar applications to related geometric and searching problems. Generally, these works assume a machine model similar to ours and demonstrate remarkable theoretical consequences of the model. On the other hand, they are more complicated and involve larger constants.
References-found: 29

