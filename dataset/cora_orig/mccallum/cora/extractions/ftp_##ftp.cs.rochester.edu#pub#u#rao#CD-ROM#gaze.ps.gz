URL: ftp://ftp.cs.rochester.edu/pub/u/rao/CD-ROM/gaze.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/rao/papers.html
Root-URL: 
Title: Top-Down Gaze Targeting for Space-Variant Active Vision  
Author: Rajesh P.N. Rao 
Address: Rochester, NY 14627-0226, USA  
Affiliation: Department of Computer Science University of Rochester  
Abstract: In this paper, we describe the use of iconic scene descriptions for top-down foveal targeting. These descriptions take the form of a vector of responses of a bank of steerable filters at multiple scales and orientations. Such a representation has a number of useful properties such as rotation and scale invariance, partial view-insensitivity and tolerance to occlusions. Top-down control of gaze for uniform resolution sensors is achieved by the process of backpro-jection which matches vectors of a previously foveated point to instances of the point in other possibly transformed images. The multiscale structure of representation can be exploited to extend this procedure to the space-variant case.
Abstract-found: 1
Intro-found: 1
Reference: [ Adelson and Bergen, 1985 ] <author> Edward H. Adelson and James Bergen. </author> <title> Spatiotemporal energy models for the perception of motion. </title> <journal> J. Opt. Soc. Am., </journal> <volume> 2(2) </volume> <pages> 284-299, </pages> <year> 1985. </year>
Reference-contexts: [ Horn and Schunck, 1981 ] Variations Shape from Shading [ Ikeuchi and Horn, 1981 ] Filters at Brightness Edge [ Horn, 1971 ] Single Scale Detection [ Binford, 1981 ] Curved Line [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow <ref> [ Adelson and Bergen, 1985 ] </ref> , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ]
Reference: [ Ballard and Rao, 1994 ] <author> Dana H. Ballard and Ra-jesh P.N. Rao. </author> <title> Seeing behind occlusions. </title> <booktitle> In Proceedings of the Third European Conference on Computer Vision (ECCV), </booktitle> <address> Stockholm, Sweden, </address> <pages> pages 274-285, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: A similar process is done to the incoming image. The two masked images are now in the same coordinate system and can be compared as in the backprojection algorithm. The interested reader is referred to <ref> [ Ballard and Rao, 1994 ] </ref> for further details. 5 Top-Down Gaze Targeting 5.1 Gaze Targeting Using Uniform Resolution Sensors The backprojection algorithm can be directly used for foveal targeting if one is using a standard uniform resolution sensor. This is illustrated in the following simulated targeting experiment.
Reference: [ Ballard and Wixson, 1993 ] <author> Dana H. Ballard and Lam-bert E. Wixson. </author> <title> Object recognition using steerable filters at multiple scales. </title> <booktitle> In Proceedings of the IEEE Workshop on Qualitative Vision, </booktitle> <year> 1993. </year>
Reference-contexts: Recent work has shown such a representation to be useful for classical vision tasks such as texture segmentation [ Malik and Perona, 1989 ] , stereo matching [ Kass, 1983; Jones and Malik, 1992 ] and object recognition <ref> [ Ballard and Wixson, 1993 ] </ref> . 1 Our use of the term iconic is akin to its use by Nakayama [ Nakayama, 1990 ] to describe small visual templates which constitute visual memory. <p> 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ] Correspondence [ Jones and Malik, 1992 ] Object <ref> [ Ballard and Wixson, 1993 ] </ref> , [ Wiskott and von der Malsburg, 1992 ] Recognition [ Lades et al., 1991 ] Table 1: The trend from variational methods towards the use of spatiotemporal filters for solving problems in computer vision. 3.1 Linear Steerable Spatial Filters Steerable filters [ Freeman and <p> the response vectors after normalization (positive responses are represented by upward bars proportional to the response magnitude and negative ones by proportional downward bars with the nine smallest scale responses at the beginning and the nine largest ones at the end). 4 Backprojection The normalized multiscale filter responses, or "zip-codes" <ref> [ Ballard and Wixson, 1993 ] </ref> , form an almost unique description of the photometric distribution near a particular point.
Reference: [ Ballard et al., 1994 ] <author> Dana H. Ballard, Rajesh P.N. Rao, and Garbis Salgian. </author> <title> Multiscale spatial filters for visual tasks and object recognition. </title> <booktitle> In Proceedings of the Second International Workshop on Visual Form, </booktitle> <address> Capri, Italy, </address> <month> May </month> <year> 1994. </year>
Reference: [ Binford, 1981 ] <author> Thomas O. Binford. </author> <title> Inferring surfaces from images. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 205-244, </pages> <year> 1981. </year>
Reference-contexts: Computing Problem Being References Methodology Solved Calculus of Optic Flow [ Horn and Schunck, 1981 ] Variations Shape from Shading [ Ikeuchi and Horn, 1981 ] Filters at Brightness Edge [ Horn, 1971 ] Single Scale Detection <ref> [ Binford, 1981 ] </ref> Curved Line [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] ,
Reference: [ Campbell and Robson, 1968 ] <author> F.W. Campbell and J.G. Robson. </author> <title> Application of Fourier analysis to the visibility of gratings. </title> <journal> J. Physiol. (Lond.), </journal> <volume> 197 </volume> <pages> 551-566, </pages> <year> 1968. </year>
Reference-contexts: This observation agrees with the current neurophysiological understanding of the primate visual system in terms of "spatial frequency channels" <ref> [ Campbell and Robson, 1968; Valois and Valois, 1988 ] </ref> . In addition to the useful properties listed above, the Gaussian derivatives also have the property that they approximately function as "matched filters" to some of the most significant elementary visual stimuli.
Reference: [ Canny, 1986 ] <author> J.F. Canny. </author> <title> A computational approach to edge detection. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 679-698, </pages> <month> November </month> <year> 1986. </year>
Reference: [ Carpenter, 1988 ] <author> Roger H.S. Carpenter. </author> <title> Movements of the Eyes. </title> <address> London: Pion, </address> <year> 1988. </year>
Reference-contexts: The human eye differs from current electronic cameras in having a central region termed the fovea with much better resolution than peripheral regions. This circularly symmetric area centralis is characterized by a greater density of receptors and a disproportionate representation in the optic nerve <ref> [ Carpenter, 1988 ] </ref> . On the other hand, the peripheral region displays a gradual logarithmic falloff in resolution as one moves radially outward; it is however more sensitive to light intensity and movement.
Reference: [ Cohen, 1981 ] <author> Karen M. Cohen. </author> <title> The development of strategies of visual search. In Eye Movements: </title> <journal> Cognition and Visual Perception, </journal> <pages> pages 271-288. </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1981. </year>
Reference-contexts: Such tasks are better facilitated by top-down cues that selectively pick out candidates for the next fixation in order to speed up the search process; for example, it is well known that humans have the ability to use information from the low-resolution periphery in guiding visual search <ref> [ Cohen, 1981 ] </ref> . Swain et al. [ 1992 ] explored the use of color histograms for top-down foveal guidance in environments suited for color discrimination. The more difficult case of using top-down cues from general gray-scale images has however remained relatively unexplored.
Reference: [ Coombs and Brown, 1992 ] <author> D.J. Coombs and C.M. Brown. </author> <title> Real-time smooth pursuit tracking for a moving binocular head. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 23-38, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: One interpretation of the Nakayama-Shimojo result is that depth cues play a crucial role in segmenting positive occluders from the object of interest. This observation forms the inspiration for our solution. The occluder can be detected by a method such as zero disparity filtering <ref> [ Coombs and Brown, 1992 ] </ref> which is a way of creating a filter that only passes image energy in the horopter.
Reference: [ Debusschere et al., 1989 ] <author> I. Debusschere, E. Bronkaers, C. Claeys, G. Kreider, J. Van der Speigel, P. Bellutti, G. Soncini, P. Dario, F. Fantini, and G. </author> <title> Sandini. A 2D retinal CCD sensor for fast 2D shape recognition and tracking. </title> <booktitle> In Proceedings of the 5th International Conference on Solid-State Sensors and Transducers, </booktitle> <address> Montreux, </address> <year> 1989. </year>
Reference-contexts: Active vision researchers have implemented log-polar mappings at both the sensor and image processing levels. For instance, one of the first log-polar sensors to be designed was the Retina CCD imaging chip <ref> [ Debusschere et al., 1989 ] </ref> . The Retina implements the log-polar mapping by using 30 concentric circles with 64 receptor cells per circle along with 102 additional receptors at the center. The constant number of receptors per circle yields the required non-uniform sampling of the visual field.
Reference: [ Freeman and Adelson, 1991 ] <author> William T. Freeman and Edward H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: This historic trend is depicted in Table 1. We focus on an important class of linear spatial filters called steerable filters <ref> [ Freeman and Adelson, 1991 ] </ref> . The iconic representation formed from these filters compromises on the ideal of strict view invariance. Instead, image features are judged useful even if they are only relatively insensitive to variations in view. <p> ] Object [ Ballard and Wixson, 1993 ] , [ Wiskott and von der Malsburg, 1992 ] Recognition [ Lades et al., 1991 ] Table 1: The trend from variational methods towards the use of spatiotemporal filters for solving problems in computer vision. 3.1 Linear Steerable Spatial Filters Steerable filters <ref> [ Freeman and Adelson, 1991 ] </ref> are a set of oriented basis filters with the important property that the response of a filter at an arbitrary orientation can be synthesized from linear combinations of the basis filters. <p> The different order Gaussian filters can be steered to arbitrary orientations by using different interpolation functions, as shown by Freeman and Adelson <ref> [ Freeman and Adelson, 1991 ] </ref> . The number of the interpolation functions that are needed for steering is one more than the filter order.
Reference: [ Gabor, 1946 ] <author> D. </author> <title> Gabor. </title> <journal> Theory of communication. J IEE, </journal> <volume> 93 </volume> <pages> 429-459, </pages> <year> 1946. </year>
Reference-contexts: The fact that the responses from filters of higher order will tend be highly correlated supports the rationale behind using filters of order only upto three in our representation. * Besides the Gaussian derivative model, a number of other functions such as Gabor functions <ref> [ Gabor, 1946 ] </ref> or difference of offset Gaussians have been proposed as models of cortical receptive field profiles.
Reference: [ Heeger, 1987 ] <author> D. Heeger. </author> <title> Optic flow using spatiotempo-ral filters. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 279-302, </pages> <year> 1987. </year>
Reference-contexts: Shape from Shading [ Ikeuchi and Horn, 1981 ] Filters at Brightness Edge [ Horn, 1971 ] Single Scale Detection [ Binford, 1981 ] Curved Line [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , <ref> [ Heeger, 1987 ] </ref> , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ] Correspondence [ Jones and Malik, 1992 ]
Reference: [ Horn and Schunck, 1981 ] <author> Berthold K.P. Horn and Brain G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: The following section describes photometric features that are tolerant to modest variations in view and are applicable to general gray-scale images. These are the different order derivatives of Gaussians which form a set of steerable spatial filters. Computing Problem Being References Methodology Solved Calculus of Optic Flow <ref> [ Horn and Schunck, 1981 ] </ref> Variations Shape from Shading [ Ikeuchi and Horn, 1981 ] Filters at Brightness Edge [ Horn, 1971 ] Single Scale Detection [ Binford, 1981 ] Curved Line [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [
Reference: [ Horn, 1971 ] <author> Berthold K.P. Horn. </author> <title> The Binford-Horn linefinder. </title> <type> AI Technical Report 285, </type> <institution> MIT AI Lab, </institution> <year> 1971. </year>
Reference-contexts: These are the different order derivatives of Gaussians which form a set of steerable spatial filters. Computing Problem Being References Methodology Solved Calculus of Optic Flow [ Horn and Schunck, 1981 ] Variations Shape from Shading [ Ikeuchi and Horn, 1981 ] Filters at Brightness Edge <ref> [ Horn, 1971 ] </ref> Single Scale Detection [ Binford, 1981 ] Curved Line [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape
Reference: [ Ikeuchi and Horn, 1981 ] <author> Katsushi Ikeuchi and Berthold K.P. Horn. </author> <title> Numerical shape from shading and occluding boundaries. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 141-184, </pages> <year> 1981. </year>
Reference-contexts: These are the different order derivatives of Gaussians which form a set of steerable spatial filters. Computing Problem Being References Methodology Solved Calculus of Optic Flow [ Horn and Schunck, 1981 ] Variations Shape from Shading <ref> [ Ikeuchi and Horn, 1981 ] </ref> Filters at Brightness Edge [ Horn, 1971 ] Single Scale Detection [ Binford, 1981 ] Curved Line [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ]
Reference: [ Jones and Malik, 1992 ] <author> David G. Jones and Jitendra Malik. </author> <title> A computational framework for determining stereo correspondence from a set of linear spatial filters. </title> <booktitle> In Proceedings of the Second European Conference on Computer Vision, </booktitle> <year> 1992. </year>
Reference-contexts: Recent work has shown such a representation to be useful for classical vision tasks such as texture segmentation [ Malik and Perona, 1989 ] , stereo matching <ref> [ Kass, 1983; Jones and Malik, 1992 ] </ref> and object recognition [ Ballard and Wixson, 1993 ] . 1 Our use of the term iconic is akin to its use by Nakayama [ Nakayama, 1990 ] to describe small visual templates which constitute visual memory. <p> and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ] Correspondence <ref> [ Jones and Malik, 1992 ] </ref> Object [ Ballard and Wixson, 1993 ] , [ Wiskott and von der Malsburg, 1992 ] Recognition [ Lades et al., 1991 ] Table 1: The trend from variational methods towards the use of spatiotemporal filters for solving problems in computer vision. 3.1 Linear Steerable <p> As a consequence the image intensities near every point can be reconstructed by appropriately combining the responses and filter functions. As the functions are not orthogonal, a pseudo-inverse must be used for this purpose <ref> [ Jones and Malik, 1992 ] </ref> . This ability to reconstruct the local intensities allows the stored prototype to be made comparable to the occluded image responses. For every point, the reconstructed image intensities are appropriately masked using the occluding template T (x; y).
Reference: [ Kass, 1983 ] <author> Michael Kass. </author> <title> Computing visual correspondence. </title> <booktitle> In Image Understanding Workshop, </booktitle> <pages> pages 54-60, </pages> <year> 1983. </year>
Reference-contexts: Recent work has shown such a representation to be useful for classical vision tasks such as texture segmentation [ Malik and Perona, 1989 ] , stereo matching <ref> [ Kass, 1983; Jones and Malik, 1992 ] </ref> and object recognition [ Ballard and Wixson, 1993 ] . 1 Our use of the term iconic is akin to its use by Nakayama [ Nakayama, 1990 ] to describe small visual templates which constitute visual memory. <p> at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo <ref> [ Kass, 1983 ] </ref> Correspondence [ Jones and Malik, 1992 ] Object [ Ballard and Wixson, 1993 ] , [ Wiskott and von der Malsburg, 1992 ] Recognition [ Lades et al., 1991 ] Table 1: The trend from variational methods towards the use of spatiotemporal filters for solving problems in
Reference: [ Kass, 1988 ] <author> Michael Kass. </author> <title> Linear image features in stereopsis. </title> <journal> International Journal of Computer Vision, </journal> <pages> pages 357-368, </pages> <year> 1988. </year>
Reference: [ Knuttson and Granlund, 1983 ] <author> H. Knuttson and G.H. Granlund. </author> <title> Texture analysis using two-dimensional quadrature filters. </title> <booktitle> In IEEE Workshop on Computer Architecture for Pattern Analysis and Image Database Management, </booktitle> <pages> pages 206-213, </pages> <year> 1983. </year>
Reference-contexts: [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture <ref> [ Knuttson and Granlund, 1983 ] </ref> Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ] Correspondence [ Jones and Malik, 1992 ] Object [ Ballard and Wixson, 1993 ] , [ Wiskott and von der Malsburg, 1992 ] Recognition [ Lades et al., 1991 ] Table 1: The
Reference: [ Koenderink and van Doorn, 1987 ] <author> J.J. Koenderink and A.J. van Doorn. </author> <title> Representation of local geometry in the visual system. </title> <journal> Biological Cybernetics, </journal> <volume> 55 </volume> <pages> 367-375, </pages> <year> 1987. </year>
Reference: [ Koenderink, 1988 ] <author> J.J. Koenderink. </author> <title> Operational significance of receptive field assemblies. </title> <journal> Biological Cybernetics, </journal> <volume> 58 </volume> <pages> 163-171, </pages> <year> 1988. </year>
Reference-contexts: The Gaussian derivative model has a number of interesting mathematical properties <ref> [ Koen-derink and van Doorn, 1987; Koenderink, 1988 ] </ref> that help justify some of the choices made in our representation: * The responses obtained by applying the different order Gaussian filters at a point characterize an image patch centered at that point and form the terms of a truncated Taylor series <p> series expansion of of the retinal illuminance function blurred to degree dependent on the width of the Gaussian. * Mixed partial derivatives, which were incidently found by Young to be conspicuously absent among primate receptive field profiles, are in fact unnecessary since the other oriented filters yield a complete basis <ref> [ Koenderink, 1988 ] </ref> . * The filters are not orthogonal functions: the correlation between filters of orders n and n + 2 equals (2n + 1)=(2n + 3).
Reference: [ Lades et al., 1991 ] <author> M. Lades, J.C. Vorbruggen, J. Buh-mann, J. Lange, C. von der Malsburg, R.P. Wurtz, and W. Konen. </author> <title> Distortion invariant object recognition in the dynamic link architecture. </title> <type> Technical report, </type> <institution> Inst. fur Neuroinformatik, </institution> <address> Ruhr-Universitat Bochum, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ] Correspondence [ Jones and Malik, 1992 ] Object [ Ballard and Wixson, 1993 ] , [ Wiskott and von der Malsburg, 1992 ] Recognition <ref> [ Lades et al., 1991 ] </ref> Table 1: The trend from variational methods towards the use of spatiotemporal filters for solving problems in computer vision. 3.1 Linear Steerable Spatial Filters Steerable filters [ Freeman and Adelson, 1991 ] are a set of oriented basis filters with the important property that the
Reference: [ Malik and Gigus, 1991 ] <author> Jitendra Malik and Ziv Gigus. </author> <title> A model for curvilinear segregation. </title> <institution> Invest. Ophthal-mol. Vis. Sci. (Supplement), 32(4):715, </institution> <year> 1991. </year>
Reference-contexts: Computing Problem Being References Methodology Solved Calculus of Optic Flow [ Horn and Schunck, 1981 ] Variations Shape from Shading [ Ikeuchi and Horn, 1981 ] Filters at Brightness Edge [ Horn, 1971 ] Single Scale Detection [ Binford, 1981 ] Curved Line [ Parent and Zucker, 1989 ] Grouping <ref> [ Malik and Gigus, 1991 ] </ref> Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [
Reference: [ Malik and Perona, 1989 ] <author> Jitendra Malik and Pietro Perona. </author> <title> A computational model of texture segmentation. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 326-332, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: In this paper, we propose the use of an iconic 1 representation, consisting of a vector of responses of linear spatial filters at different scales and orientations, for top-down gaze targeting. Recent work has shown such a representation to be useful for classical vision tasks such as texture segmentation <ref> [ Malik and Perona, 1989 ] </ref> , stereo matching [ Kass, 1983; Jones and Malik, 1992 ] and object recognition [ Ballard and Wixson, 1993 ] . 1 Our use of the term iconic is akin to its use by Nakayama [ Nakayama, 1990 ] to describe small visual templates which <p> [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation <ref> [ Malik and Perona, 1989 ] </ref> Stereo [ Kass, 1983 ] Correspondence [ Jones and Malik, 1992 ] Object [ Ballard and Wixson, 1993 ] , [ Wiskott and von der Malsburg, 1992 ] Recognition [ Lades et al., 1991 ] Table 1: The trend from variational methods towards the use <p> The different responses at different scales are sensitive to the width of the templates, so the responses, to be comparable across scales, have to be normalized. The easiest way to do this, as shown for example in <ref> [ Malik and Perona, 1989 ] </ref> , is to divide by the filter energy defined as: e i = G 0 The normalized response of a set of filters to the area surrounding a specific point in the image can now be defined as the vector r = r i;j;s ;
Reference: [ Mel, 1994 ] <author> B. </author> <title> Mel. Object classification with high-dimensional vectors. </title> <booktitle> Presentation at Telluride Workshop on Neuromorphic Engineering, </booktitle> <address> Telluride, Col-orado, </address> <month> July </month> <year> 1994. </year>
Reference: [ Murase and Nayar, 1993 ] <author> Hiroshi Murase and Shree K. Nayar. </author> <title> Learning and recognition of 3d objects from appearance. </title> <booktitle> In IEEE Workshop on Qualitative Vision, </booktitle> <pages> pages 39-50, </pages> <year> 1993. </year>
Reference: [ Murray et al., 1993 ] <author> D.W. Murray, K.J. Bradshaw, P.F. McLauchlan, </author> <title> I.D. Reid, and P.M. Sharkey. Driving saccade to pursuit using image motion. </title> <note> Submitted to IJCV, </note> <month> November </month> <year> 1993. </year>
Reference-contexts: Active vision systems equipped with space-variant sensors will also require mechanisms for gaze targeting in order to fully exploit the advantages of space-variant sensing. Recent work has examined the use of bottom-up cues such as motion for initiation of "capture saccades" <ref> [ Murray et al., 1993 ] </ref> . Such cues however serve primarily as alerting cues and are as such not directly applicable to tasks such as visual search for particular objects in large areas.
Reference: [ Nakayama and Shimojo, 1990 ] <author> K. Nakayama and S. Shimojo. </author> <title> Towards a neural understanding of visual surface representation. </title> <booktitle> Cold Spring Harbor Symp. on Quantitative Biology, </booktitle> <volume> Vol. </volume> <month> 55, </month> <title> The Brain, edited by T. Sejnowski, E.R. </title> <type> Kandel, C.F. </type> <institution> Stevens, and J.D. Watson, </institution> <year> 1990. </year>
Reference: [ Nakayama, 1990 ] <author> K. Nakayama. </author> <title> The iconic bottleneck and the tenuous link between early visual processing and perception. </title> <editor> In Colin Blakemore, editor, </editor> <booktitle> Vision : coding and efficiency, </booktitle> <pages> pages 411-422. </pages> <address> New York : Cambridge University Press, </address> <year> 1990. </year>
Reference-contexts: useful for classical vision tasks such as texture segmentation [ Malik and Perona, 1989 ] , stereo matching [ Kass, 1983; Jones and Malik, 1992 ] and object recognition [ Ballard and Wixson, 1993 ] . 1 Our use of the term iconic is akin to its use by Nakayama <ref> [ Nakayama, 1990 ] </ref> to describe small visual templates which constitute visual memory. Our work [ Rao and Ballard, 1994; Ballard et al., 1994; Ballard and Rao, 1994 ] has indicated that such a representation can be the centerpiece of an active vision system as well.
Reference: [ Parent and Zucker, 1989 ] <author> Pierre Parent and Steven Zucker. </author> <title> Trace inference, curvature consistency, and curve detection. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 11(8) </volume> <pages> 823-839, </pages> <year> 1989. </year>
Reference-contexts: Computing Problem Being References Methodology Solved Calculus of Optic Flow [ Horn and Schunck, 1981 ] Variations Shape from Shading [ Ikeuchi and Horn, 1981 ] Filters at Brightness Edge [ Horn, 1971 ] Single Scale Detection [ Binford, 1981 ] Curved Line <ref> [ Parent and Zucker, 1989 ] </ref> Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [
Reference: [ Pentland, 1988 ] <author> Alex P. Pentland. </author> <title> Shape information from shading: A theory of human perception. </title> <booktitle> In Proceedings of the 2nd International Conference on Computer Vision, </booktitle> <address> Tampa, FL, </address> <month> Dec. </month> <pages> 3-8, pages 404-412, </pages> <year> 1988. </year>
Reference-contexts: ] Single Scale Detection [ Binford, 1981 ] Curved Line [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading <ref> [ Pentland, 1988 ] </ref> , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ] Correspondence [ Jones and Malik, 1992 ] Object [ Ballard and Wixson, 1993 ] , [ Wiskott and von der Malsburg, 1992 ]
Reference: [ Pentland, 1990 ] <author> Alex P. Pentland. </author> <title> From 2-D images to 3-D models. </title> <booktitle> In K.N. Leibovic, editor, Science of Vision, </booktitle> <pages> pages 422-438. </pages> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Binford, 1981 ] Curved Line [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , [ Weber and Malik, 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , <ref> [ Pentland, 1990 ] </ref> Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ] Correspondence [ Jones and Malik, 1992 ] Object [ Ballard and Wixson, 1993 ] , [ Wiskott and von der Malsburg, 1992 ] Recognition [ Lades et al.,
Reference: [ Rao and Ballard, 1994 ] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> Iconic representations for active vision. </title> <note> Submitted, </note> <month> August </month> <year> 1994. </year>
Reference: [ Swain and Ballard, 1991 ] <author> Michael J. Swain and Dana H. Ballard. </author> <title> Color indexing. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7 </volume> <pages> 11-32, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: The iconic representation formed from these filters compromises on the ideal of strict view invariance. Instead, image features are judged useful even if they are only relatively insensitive to variations in view. One example of such a feature is image color as a measure of surface albedo <ref> [ Swain, 1990; Swain and Ballard, 1991 ] </ref> . The following section describes photometric features that are tolerant to modest variations in view and are applicable to general gray-scale images. These are the different order derivatives of Gaussians which form a set of steerable spatial filters.
Reference: [ Swain et al., 1992 ] <author> M.J. Swain, R.E. Kahn, and D.H. Ballard. </author> <title> Low resolution cues for guiding saccadic eye movements. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <year> 1992. </year>
Reference: [ Swain, 1990 ] <author> Michael J. Swain. </author> <title> Color indexing. </title> <type> Technical Report 360, </type> <institution> University of Rochester Computer Science Dept., </institution> <year> 1990. </year>
Reference-contexts: The iconic representation formed from these filters compromises on the ideal of strict view invariance. Instead, image features are judged useful even if they are only relatively insensitive to variations in view. One example of such a feature is image color as a measure of surface albedo <ref> [ Swain, 1990; Swain and Ballard, 1991 ] </ref> . The following section describes photometric features that are tolerant to modest variations in view and are applicable to general gray-scale images. These are the different order derivatives of Gaussians which form a set of steerable spatial filters.
Reference: [ Tistarelli and Sandini, 1992 ] <author> Massimo Tistarelli and Giulio Sandini. </author> <title> Dynamic aspects in active vision. Computer Vision, Graphics, </title> <booktitle> and Image Processing: Image Understanding, </booktitle> <volume> 56(1) </volume> <pages> 108-129, </pages> <year> 1992. </year>
Reference-contexts: all local geometrical properties are preserved, which in turn implies that all local image processing operations such as filtering and optic flow remain unaffected. * It effectively separates rotations () from scale changes (r). * Some visual routines such as computation of time-to-impact become greatly simplified in the log-polar case <ref> [ Tistarelli and Sandini, 1992 ] </ref> . * The mapping is shape-invariant i.e. if an object that is currently being fixated upon approaches the sensor, its shape remains unchanged.
Reference: [ Tsotsos, 1989 ] <author> J.K. Tsotsos. </author> <title> The complexity of perceptual search tasks. </title> <booktitle> In Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: Second, a strategy such as that used by Murase and Nayar [ 1993 ] for scale normalization by sub-sampling or oversampling the image of an object to a canonical size can be adopted but this assumes segmentation into object and background regions, an assumption that is questionable for general cases <ref> [ Tsotsos, 1989 ] </ref> . However, there exists a more feasible but nevertheless effective strategy for handling scale changes that exploits the multiscale structure of response vectors.
Reference: [ Valois and Valois, 1988 ] <author> Russell L. De Valois and Karen K. De Valois. </author> <title> Spatial vision. </title> <publisher> New York : Oxford University Press, </publisher> <year> 1988. </year>
Reference-contexts: This observation agrees with the current neurophysiological understanding of the primate visual system in terms of "spatial frequency channels" <ref> [ Campbell and Robson, 1968; Valois and Valois, 1988 ] </ref> . In addition to the useful properties listed above, the Gaussian derivatives also have the property that they approximately function as "matched filters" to some of the most significant elementary visual stimuli.
Reference: [ Viola, 1993 ] <author> Paul Viola. </author> <title> Feature-based recognition of objects. </title> <booktitle> In AAAI Fall Symposium on Learning and Computer Vision, </booktitle> <year> 1993. </year>
Reference: [ Weber and Malik, 1992 ] <author> Joseph W. Weber and Jiten-dra Malik. </author> <title> Robust computation of optical flow in a multi-scale differential framework. </title> <type> Technical Report 709, </type> <institution> Dept. of Electrical Engineering and Computer Science, University of California at Berkeley, </institution> <month> Novem-ber </month> <year> 1992. </year>
Reference-contexts: and Horn, 1981 ] Filters at Brightness Edge [ Horn, 1971 ] Single Scale Detection [ Binford, 1981 ] Curved Line [ Parent and Zucker, 1989 ] Grouping [ Malik and Gigus, 1991 ] Filters at Optic Flow [ Adelson and Bergen, 1985 ] , [ Heeger, 1987 ] , <ref> [ Weber and Malik, 1992 ] </ref> Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ] Correspondence [ Jones and Malik, 1992 ] Object [ Ballard and Wixson,
Reference: [ Weiman and Chaikin, 1979 ] <author> C.F.R. Weiman and G. Chaikin. </author> <title> Logarithmic spiral grids for image processing and display. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 11 </volume> <pages> 197-226, </pages> <year> 1979. </year>
Reference-contexts: The log-polar mapping <ref> [ Weiman and Chaikin, 1979 ] </ref> transforms a polar data space by taking the logarithm of each point's coordinates.
Reference: [ Wiskott and von der Malsburg, 1992 ] <author> L. Wiskott and C. von der Malsburg. </author> <title> A neural system for the recognition of partially occluded objects in cluttered scenes. </title> <type> Technical report, </type> <institution> Inst. fur Neuroinformatik, </institution> <address> Ruhr-Universitat Bochum, </address> <year> 1992. </year>
Reference-contexts: 1992 ] Multiple Scales Shape from Shading [ Pentland, 1988 ] , [ Pentland, 1990 ] Texture [ Knuttson and Granlund, 1983 ] Segmentation [ Malik and Perona, 1989 ] Stereo [ Kass, 1983 ] Correspondence [ Jones and Malik, 1992 ] Object [ Ballard and Wixson, 1993 ] , <ref> [ Wiskott and von der Malsburg, 1992 ] </ref> Recognition [ Lades et al., 1991 ] Table 1: The trend from variational methods towards the use of spatiotemporal filters for solving problems in computer vision. 3.1 Linear Steerable Spatial Filters Steerable filters [ Freeman and Adelson, 1991 ] are a set of

References-found: 45

