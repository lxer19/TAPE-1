URL: http://www.cs.nmsu.edu/lldap/download/isca.ps.Z
Refering-URL: http://www.cs.nmsu.edu/lldap/pub_lp/isca.html
Root-URL: http://www.cs.nmsu.edu
Email: fepontell,guptag@cs.nmsu.edu  
Title: Incremental Exploitation of Parallelism in Prolog  
Author: Enrico Pontelli Gopal Gupta 
Keyword: Prolog, And-parallelism, Or-parallelism, Optimizations  
Address: Box 30001,  Las Cruces, NM 88003  
Affiliation: Laboratory for Logic, Databases, and Advanced Programming New Mexico State University  Dept. CS  
Abstract: In this paper we discuss the problems encountered in exploiting all forms of parallelism| or-parallelism, independent and-parallelism, and dependent and parallelism|from Prolog programs. We also present our solutions to these problems. We describe a parallel Prolog engine that we have developed, called &ACE, that exploits independent and-parallelism. We discuss how or-parallelism and dependent and-parallelism can be incrementally incorporated in &ACE. We also present an efficient technique for exploiting data-parallelism in Prolog. We present performance figures for our parallel implementation done on a Sequent Symmetry and Sun Sparc multiprocessors. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K.A.M. Ali and R. Karlsson. </author> <title> The Muse Or-parallel Prolog Model and its Performance. </title> <booktitle> In 1990 N. American Conf. on Logic Prog. </booktitle> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: the environment representation techniques developed for or-parallelism to the case of and- and or-parallel system is not straightforward and must be appropriately modified in order to take into account this "layered" approach to parallelism. 4.2.1 Stack-Copying One of the most successful approaches adopted for implementing or-parallelism is the stack-copying approach <ref> [1] </ref>, adopted in the Muse system. The idea is relatively simple: whenever a computing agent A steals one alternative from a choice point (created by B) to explore it independently, then it creates a complete copy of the environments allocated in B. <p> Note that to implement stack copying the address space has to be mapped in a special way so that pointers in the stacks being copied can be relocated without changing their meaning <ref> [1, 9] </ref>. The generalization of the stack copying mechanism to the case of and- and or-parallelism presents some new problems.
Reference: [2] <author> V. Santos Costa, D.H.D. Warren, and R. Yang. Andorra-I: </author> <title> A Parallel Prolog System that Transparently Exploits both And- and Or-parallelism. </title> <booktitle> In Proc. 3rd ACM SIGPLAN PPoPP, </booktitle> <year> 1990. </year>
Reference-contexts: An arbitrary intermixing between two parallel computations may lead to a time-dependent and incorrect behaviour. In the literature very few solutions have been proposed to this problem. The solutions that have been proposed range from the use of locks during binding creation <ref> [2] </ref> to the introduction of "invalid" entries on the heap to avoid ahead of time accesses of variables that are being bound [19]. The solution we propose is arguably superior to all these, in terms of efficiency and overhead.
Reference: [3] <author> S. Debray and M. Jain. </author> <title> A Simple Program Transformation for Parallelism. </title> <booktitle> In Proc. of the 1994 Symposium on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: We also discussed techniques that allow MIMD parallelism to be more efficiently realized as SPMD parallelism. We also presented performance data for the system that we have developed and that realizes some of the techniques discussed in this paper. 8 But compile-time transformation have been suggested <ref> [3] </ref> that would easily improve our results and bring them at par to those of dedicated SPMD systems. 13 No. of Agents 1.00 3.00 5.00 7.00 2.00 4.00 6.00 8.00 10.00 Map (LPCO) Matrix Mult. (LPCO) MatrixMult (no LPCO) Map (no LPCO) Speedup Speedups on Backward Execution No. of Agents 1.00
Reference: [4] <author> D. </author> <title> DeGroot. Restricted AND-Parallelism. </title> <booktitle> In Int'l Conf. on 5th Generation Computer Systems, </booktitle> <pages> pages 471-478. </pages> <address> Tokyo, </address> <month> Nov. </month> <year> 1984. </year>
Reference-contexts: Foundations of much of the work described in this section were laid down in <ref> [4] </ref>, however, the specific implementation described is that of the &ACE system [8]. 2.1 Independent And-parallelism Conventionally, an and-parallel Prolog system works by executing a program that has been annotated with parallel conjunctions. These parallel conjunction annotations are either inserted by a parallelizing compiler [11] or hand-coded by the programmer. <p> Parallel conjunctions may also be conditional, which means that the goals in the conjunction are executed in parallel only if the condition, i.e., the expression upon which the conjunction is conditioned, evaluates to true (e.g., Conditional Graph Expressions <ref> [4, 11] </ref>). <p> described above has been implemented quite efficiently by the authors in the &ACE system [8]. &ACE implementation itself is inspired by the RAPWAM [12] 5 . &ACE is an extension to the sequential WAM (Warren Abstract Machine [21]) for and-parallel execution of Prolog programs with and-parallel annotation (such as CGEs <ref> [4] </ref>). The current implementation of &ACE is running on both Sequent Symmetry and Sun Sparc multiprocessors. The results obtained with this system, even though the system is still in its early stages of development, are quite impressive.
Reference: [5] <author> G. Gupta E. Pontelli. </author> <title> Dependent And Parallelism in Logic Programming. </title> <type> Technical report, </type> <institution> Laboratory for Logic, DB, and Advanced Programming, </institution> <year> 1995. </year> <type> Internal Report. </type>
Reference-contexts: boyer No. of Agents 1.00 3.00 5.00 7.00 9.00 Speedup No. of Agents 1.00 3.00 5.00 7.00 9.00 Speedup Fig (i) Fig (ii) simulator of instruction for the same binding operation, and adding a simple run-time test which allows to select the sequence that most appropriately will avoid time-dependent behaviour <ref> [5] </ref>. <p> literature dealing with dependent and-parallelism [19, 17] can be simply distinguished depending on the way in which the role of producer/consumers is computed and handled. 7 A careful study of the characteristics of a dependent and-parallel model leads to the identification of some basic operations that need to be implemented <ref> [5] </ref>: (i) creation of a parallel conjunction; (ii) remote set-up of a parallel subgoal; (iii) access/binding of a shared variable; and, (iv) producer/consumer detection. Our intuition, similar to the one for or-parallelism [6], is that at least one of this operation cannot be performed in constant time [5]. 3.2 A New <p> to be implemented <ref> [5] </ref>: (i) creation of a parallel conjunction; (ii) remote set-up of a parallel subgoal; (iii) access/binding of a shared variable; and, (iv) producer/consumer detection. Our intuition, similar to the one for or-parallelism [6], is that at least one of this operation cannot be performed in constant time [5]. 3.2 A New Model for Dependent And-parallelism From the discussion in the previous section, we can formulate the following criteria for an ideal dependent and-parallel model: operations (i) through (iv) above should all be realized in constant time.
Reference: [6] <author> G. Gupta. </author> <title> Multiprocessor Execution of Logic Programs. </title> <publisher> Kluwer Academic Press, </publisher> <year> 1994. </year>
Reference-contexts: Our intuition, similar to the one for or-parallelism <ref> [6] </ref>, is that at least one of this operation cannot be performed in constant time [5]. 3.2 A New Model for Dependent And-parallelism From the discussion in the previous section, we can formulate the following criteria for an ideal dependent and-parallel model: operations (i) through (iv) above should all be realized <p> In the literature a wide range of environment representation schemes to support implicit exploitation of or-parallelism have been proposed. The proliferation in the number of schemes is due to the considerable degree of freedom available in the design of models for or-parallelism. In <ref> [6] </ref> three criteria for classifying or-parallel models are proposed, based on analyzing the main steps that each model needs to implement (environment creation, variable access, and task switching). In [6] it is shown that at least one of the three operations will be a 8 non constant-time operation; furthermore, the fact <p> In <ref> [6] </ref> three criteria for classifying or-parallel models are proposed, based on analyzing the main steps that each model needs to implement (environment creation, variable access, and task switching). In [6] it is shown that at least one of the three operations will be a 8 non constant-time operation; furthermore, the fact that task switching (i.e., moving from one point of the computation tree to the other) is the only operation whose frequency can be controlled by the run-time system (e.g.,
Reference: [7] <author> G. Gupta, V. Santos Costa, and E. Pontelli. </author> <title> Shared Paged Binding Arrays: A Universal Data-structure for Parallel Logic Programming. </title> <booktitle> Proc. NSF/ICOT Workshop on Parallel Logic Programming and its Environments, </booktitle> <institution> CIS-94-04, University of Oregon, </institution> <month> Mar. </month> <year> 1994. </year> <month> 14 </month>
Reference: [8] <author> G. Gupta, M. Hermenegildo, and E. Pontelli. </author> <title> &ACE: A High-performance Parallel Prolog System. </title> <booktitle> In IPPS 95. IEEE Computer Society, </booktitle> <address> Santa Barbara, CA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Foundations of much of the work described in this section were laid down in [4], however, the specific implementation described is that of the &ACE system <ref> [8] </ref>. 2.1 Independent And-parallelism Conventionally, an and-parallel Prolog system works by executing a program that has been annotated with parallel conjunctions. These parallel conjunction annotations are either inserted by a parallelizing compiler [11] or hand-coded by the programmer. <p> a subgoal p, an untried alternative is picked from it and then all the subgoals to the right of p in the parallel conjunction are restarted (in parallel). 2.2 &ACE Independent and-parallelism with the backtracking semantics described above has been implemented quite efficiently by the authors in the &ACE system <ref> [8] </ref>. &ACE implementation itself is inspired by the RAPWAM [12] 5 . &ACE is an extension to the sequential WAM (Warren Abstract Machine [21]) for and-parallel execution of Prolog programs with and-parallel annotation (such as CGEs [4]).
Reference: [9] <author> G. Gupta, M. Hermenegildo, E. Pontelli, and V. Santos Costa. </author> <title> ACE: And/Or-parallel Copying-based Execution of Logic Programs. </title> <booktitle> In Proc. ICLP'94, </booktitle> <pages> pages 93-109. </pages> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The requirement of and- and or-parallelism, in terms of environment representation, are antithetical. This problem has been tackled in the ACE system <ref> [9] </ref> and in the SPBA model [7]|although the solution proposed can be virtually applied to almost any system combining and- and or-Parallelism. The idea is to create a layering in the exploitation of the different forms of parallelism. <p> Note that to implement stack copying the address space has to be mapped in a special way so that pointers in the stacks being copied can be relocated without changing their meaning <ref> [1, 9] </ref>. The generalization of the stack copying mechanism to the case of and- and or-parallelism presents some new problems. <p> Furthermore, and-parallelism leads to the loss of the correspondence between physical position of the computations on the stack and logical sequence of execution. A solution to these problems has been proposed in the ACE system <ref> [9] </ref>. Each processor in the ACE system is basically an and-parallel engine, capable of carrying on its own computation and interacting with a certain number of other processors (those belonging to its own team). <p> Different approaches to incremental copying have been studied and heuristics to choose the most appropriate in each situation have been developed. The interested reader is referred to <ref> [9] </ref> for a detailed discussion of this topic. 10 B C Team A Team B Team A Team B (i) C A Copied Part A Choice Point Parallel Call Completed Goal ACE is currently under development as a collaborative project between New Mexico State University and the Universidad Politecnica de Madrid.
Reference: [10] <author> Seif Haridi and Sverker Janson. </author> <title> Kernel Andorra Prolog and its Computation Model. </title> <booktitle> In Proc. 7th Int'l Conf. on Logic Prog. </booktitle> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Nevertheless only very few researchers have tackled the more complex problem of integrating the different forms of parallelism in a unique framework. Some recent proposals (e.g., <ref> [10] </ref>) have attempted to reach this goal, but the results are still not well-established and the approaches are based on the development of a new language, with a less intuitive operational semantics than 3 A computing agent is basically a Prolog engine extended with mechanisms required for inter-agent synchronization and scheduling.
Reference: [11] <author> M. Hermenegildo and K. Greene. </author> <title> &-Prolog and its Performance: Exploiting Independent And-Parallelism. </title> <booktitle> In 1990 Int'l Conf. on Logic Prog., </booktitle> <pages> pages 253-268. </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: These parallel conjunction annotations are either inserted by a parallelizing compiler <ref> [11] </ref> or hand-coded by the programmer. Execution of all goals in a parallel conjunction is started in parallel when control reaches that parallel conjunction. <p> Parallel conjunctions may also be conditional, which means that the goals in the conjunction are executed in parallel only if the condition, i.e., the expression upon which the conjunction is conditioned, evaluates to true (e.g., Conditional Graph Expressions <ref> [4, 11] </ref>). <p> In an and-parallel system we must ensure that the backtracking semantics is such that all solutions are reported. One such backtracking semantics has been proposed by Hermenegildo and Nasr <ref> [11] </ref>: consider the subgoals shown below, where `,' is used between sequential subgoals (because of data-dependencies) and `&' for parallel subgoals (no data-dependencies): a, b, (c & d & e), g, h. <p> Note that for the compiler, quicksort, and boyer benchmarks, the speedup curve flattens out because at some point all available parallelism is exhausted.(e.g., in the case of 5 Other implementations based on the principles of RAPWAM have also been proposed in the past, like &-Prolog <ref> [11] </ref> and DDAS [19]. 5 Goals &ACE agents executed 1 3 5 10 matrix mult (30) 5214 1768 (2.95) 1059 (4.92) 534 (9.76) quick sort (10) 1536 632 (2.43) 455 (3.38) 373 (4.12) takeuchi (14) 1811 586 (3.09) 368 (4.92) 200 (9.06) hanoi (11) 1671 550 (3.04) 336 (4.97) 180 (9.28)
Reference: [12] <author> M. V. Hermenegildo. </author> <title> An Abstract Machine Based Execution Model for Computer Architecture Design and Efficient Implementation of Logic Programs in Parallel. </title> <type> PhD thesis, </type> <institution> Dept. of Electrical and Computer Engineering (Dept. of Computer Science TR-86-20), University of Texas at Austin, Austin, Texas 78712, </institution> <month> August </month> <year> 1986. </year>
Reference-contexts: it and then all the subgoals to the right of p in the parallel conjunction are restarted (in parallel). 2.2 &ACE Independent and-parallelism with the backtracking semantics described above has been implemented quite efficiently by the authors in the &ACE system [8]. &ACE implementation itself is inspired by the RAPWAM <ref> [12] </ref> 5 . &ACE is an extension to the sequential WAM (Warren Abstract Machine [21]) for and-parallel execution of Prolog programs with and-parallel annotation (such as CGEs [4]). The current implementation of &ACE is running on both Sequent Symmetry and Sun Sparc multiprocessors.
Reference: [13] <author> H. Millroth J. Bevemyr, T. Lindgren. Reform Pro-log: </author> <title> the Language and its Implementation. </title> <booktitle> In Proc. of the 10th Int'l Conference on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Visiting and managing this structure is definitely simpler and more efficient. Systems targeted to the exploitation of this form of data parallelism in Prolog programs have been designed 12 P (X1) P (X3) map (Y1) map (Y3) P (X1) P (X2) P (X3) P (X4) and implemented <ref> [13] </ref> with very good results.
Reference: [14] <editor> L. Kanal and C.B. Suttner, editors. </editor> <booktitle> Proceedings of the Workshop on Parallel Processing for AI. </booktitle> <institution> Technische Universitat Munchen, Institut fur Infor-matik, </institution> <year> 1992. </year>
Reference-contexts: There are parallelizing compilers and other tools available for parallel numerical processing that programmers can use without being experts on parallel processing. However, the same is not true of parallel processing of Symbolic and Artificial Intelligence (AI) applications. There has been some work <ref> [14, 20] </ref>, but there are still no systems that are general enough and that programmers can use without being experts on parallel processing. In this paper we deal with systems that represent a step towards the goal of building a general automatic tool for parallelizing symbolic and AI applications.
Reference: [15] <author> L. Lamport. </author> <title> The Parallel Execution of DO-loops. </title> <journal> Communications of the ACM, </journal> <volume> 17 </volume> <pages> 83-93, </pages> <year> 1974. </year>
Reference-contexts: 1 Introduction Parallel processing of numerical problems has been an active area of research for almost two decades now <ref> [15, 22] </ref>. There are parallelizing compilers and other tools available for parallel numerical processing that programmers can use without being experts on parallel processing. However, the same is not true of parallel processing of Symbolic and Artificial Intelligence (AI) applications.
Reference: [16] <author> E. Lusk and al. </author> <title> The Aurora Or-parallel Prolog System. </title> <journal> New Generation Computing, 7(2,3), </journal> <volume> '90. </volume>
Reference-contexts: Using this criteria we have designed a new implementation scheme for dependent and-parallelism, based on a generalization of the concept of the Binding Arrays <ref> [16] </ref> used for or-parallelism. In this model, a table is associated with each subgoal, which represents that subgoal's "view" of the shared variables during the execution. Every shared variable will have one location in each of these tables, as shown in figure 3. <p> and-parallel system &ACE; table 2 shows some preliminary results obtained on a generate & test benchmark (generation is non-deterministic and test contains and-parallelism). 4.2.2 Binding Arrays The other most significant approach taken to solve the environment representation problem in or-parallelism is the Binding Arrays method adopted in the Aurora system <ref> [16] </ref>. The idea is to associate with each agent (processor) a private array in which bindings for variables can be stored. Each variable for which binding conflicts between parallel threads are possible is translated into an index in the binding array.
Reference: [17] <author> M. Carro M. Hermenegildo, D. Cabeza. </author> <title> Using Attributed Variables in the Implementation of Parallel and Concurrent Logic Programming Systems. </title> <booktitle> In Proc. of the International Conference on Logic Programming, </booktitle> <year> 1995. </year>
Reference-contexts: A consumer becomes a producer for a variable when the designated producer finishes execution without binding the shared variable and the consumer in question is the leftmost among all potential consumers of the shared variable. The (few) models presented in the literature dealing with dependent and-parallelism <ref> [19, 17] </ref> can be simply distinguished depending on the way in which the role of producer/consumers is computed and handled. 7 A careful study of the characteristics of a dependent and-parallel model leads to the identification of some basic operations that need to be implemented [5]: (i) creation of a parallel
Reference: [18] <author> E. Pontelli, G. Gupta, and D. Tang. </author> <title> Determinacy Driven Optimizations of Parallel Prolog Implementations. </title> <booktitle> In Proc. of the Int'l Conference on Logic Programming 95. </booktitle> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: Nevertheless, these systems are capable only of this specific form of parallelism (i.e., anything that does not fit in the mold of data-parallelism cannot be executed in parallel; so from the point of view of their usability as general parallel systems they have severe limitations <ref> [18] </ref>). Comparable results can be obtained by applying some optimization techniques to an ordinary and-parallel system. We have developed one such optimization scheme, named Last Parallel Call Optimization (LPCO) 7 .
Reference: [19] <author> K. Shen. </author> <title> Studies in And/Or Parallelism in Prolog. </title> <type> PhD thesis, </type> <institution> U. of Cambridge, </institution> <year> 1992. </year>
Reference-contexts: Note that for the compiler, quicksort, and boyer benchmarks, the speedup curve flattens out because at some point all available parallelism is exhausted.(e.g., in the case of 5 Other implementations based on the principles of RAPWAM have also been proposed in the past, like &-Prolog [11] and DDAS <ref> [19] </ref>. 5 Goals &ACE agents executed 1 3 5 10 matrix mult (30) 5214 1768 (2.95) 1059 (4.92) 534 (9.76) quick sort (10) 1536 632 (2.43) 455 (3.38) 373 (4.12) takeuchi (14) 1811 586 (3.09) 368 (4.92) 200 (9.06) hanoi (11) 1671 550 (3.04) 336 (4.97) 180 (9.28) pderiv 5375 1840 <p> In the literature very few solutions have been proposed to this problem. The solutions that have been proposed range from the use of locks during binding creation [2] to the introduction of "invalid" entries on the heap to avoid ahead of time accesses of variables that are being bound <ref> [19] </ref>. The solution we propose is arguably superior to all these, in terms of efficiency and overhead. <p> A consumer becomes a producer for a variable when the designated producer finishes execution without binding the shared variable and the consumer in question is the leftmost among all potential consumers of the shared variable. The (few) models presented in the literature dealing with dependent and-parallelism <ref> [19, 17] </ref> can be simply distinguished depending on the way in which the role of producer/consumers is computed and handled. 7 A careful study of the characteristics of a dependent and-parallel model leads to the identification of some basic operations that need to be implemented [5]: (i) creation of a parallel
Reference: [20] <editor> L.N. Kanal V. Kumar, P.S. Gopalakrishnan, editor. </editor> <booktitle> Parallel Algorithms for Machine Intelligence and Vision. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: There are parallelizing compilers and other tools available for parallel numerical processing that programmers can use without being experts on parallel processing. However, the same is not true of parallel processing of Symbolic and Artificial Intelligence (AI) applications. There has been some work <ref> [14, 20] </ref>, but there are still no systems that are general enough and that programmers can use without being experts on parallel processing. In this paper we deal with systems that represent a step towards the goal of building a general automatic tool for parallelizing symbolic and AI applications.
Reference: [21] <author> D. H. D. Warren. </author> <title> An Abstract Prolog Instruction Set. </title> <type> Technical Report 309, </type> <institution> SRI International, </institution> <year> 1983. </year>
Reference-contexts: conjunction are restarted (in parallel). 2.2 &ACE Independent and-parallelism with the backtracking semantics described above has been implemented quite efficiently by the authors in the &ACE system [8]. &ACE implementation itself is inspired by the RAPWAM [12] 5 . &ACE is an extension to the sequential WAM (Warren Abstract Machine <ref> [21] </ref>) for and-parallel execution of Prolog programs with and-parallel annotation (such as CGEs [4]). The current implementation of &ACE is running on both Sequent Symmetry and Sun Sparc multiprocessors. The results obtained with this system, even though the system is still in its early stages of development, are quite impressive.
Reference: [22] <author> H. Zima and B. Chapman. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction Parallel processing of numerical problems has been an active area of research for almost two decades now <ref> [15, 22] </ref>. There are parallelizing compilers and other tools available for parallel numerical processing that programmers can use without being experts on parallel processing. However, the same is not true of parallel processing of Symbolic and Artificial Intelligence (AI) applications.
References-found: 22

