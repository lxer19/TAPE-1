URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P316.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts92.htm
Root-URL: http://www.mcs.anl.gov
Title: A Globally and Superlinearly Convergent Potential Reduction Interior Point Method for Convex Programming  
Author: R. D. C. Monteiro S. J. Wright 
Date: July 15, 1992  
Abstract: We consider an interior point algorithm for convex programming in which the steps are generated by using a primal-dual affine scaling technique. A "local" variant of the algorithm is shown to have superlinear convergence with q-order up to (but not including) 2. The technique is embedded in a potential reduction algorithm and the resulting method is shown to be globally and superlinearly convergent. An important feature of the convergence analysis is its use of a novel strict interiority condition, which generalizes the usual conical neighborhood of the central path. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. V. Burke and M. C. Ferris, </author> <title> Weak sharp minima in mathematical programming, </title> <type> Research Report 1050, </type> <institution> iComputer Sciences Department, University of Wisconsin, Wisconsin, Madison, </institution> <year> 1991. </year> <note> SIAM Journal on Control and Optimization, to appear. </note>
Reference-contexts: We say that (J; L) is a partition of f1; : : : ; ng if J [ L = f1; : : : ; ng and J " L = ;. Finally, we define some problem-dependent notation: For * 2 <ref> [0; 1] </ref>, let F * = f (x; y; s) feasible j x T s *g: Clearly, F 0 is just the set of all primal-dual solutions of (1),(2) and F 1 is the set of all primal-dual feasible points. <p> We also define a projection operator by (x; y; z) 4 with a slight abuse of notation, X * = (F * ) for * 2 <ref> [0; 1] </ref>. Note that X 0 is the solution set for (1). <p> Two important situations in which the implication (12) holds are stated in the next two lemmas. Lemma 2.6 Suppose that Assumptions 1, 2 and 3 hold. Then Assumption 5 holds if problem (1) has a weak sharp minimum in the sense of Burke and Ferris <ref> [1] </ref>, that is, if there exists a constant &gt; 0 such that kx P (x)k [f (x) f (P (x))] ; Proof. <p> Then, there exist a constant C 5 independent of ffi, j and fl such that for all ff 2 <ref> [0; 1] </ref>, j (x i + ffx i )s i (ff) (1 ff)x i s i j C 5 ff 2 (x T s) 23ffi 16 and fi fi fi nC 5 ff 2 (x T s) 23ffi Proof. We first note that (57) follows immediately from (56). <p> N 4 (ffi; j; fl) then (x + ffx; y + ffy; s (ff)) 2 N 4 (ffi; j; fl) for all " fl ffij 4 (x T s) 14ffi # Moreover, we have that (x + ffx) T s (ff) 1 ff 1 2 x T s; 8ff 2 <ref> [0; 1] </ref>: (68) Proof. Consider the constant C 5 as in the statement of Lemma 4.2 and define fl j maxf1; (2n + 1)C 5 )g: (69) We will show that fl fulfills the requirements of the lemma. <p> ffx i )s i (ff) (1 ff)x i s i C 5 ff 2 (x T s) 23ffi (1 ff)j (x T s) 1+ffi C 5 ff 2 (x T s) 23ffi j (x T s) 1+ffi 1 ff 1 + C 5 j 4 : for all ff 2 <ref> [0; 1] </ref>. Similarly, from relation (57), we obtain (x + ffx) T s (ff) x T s 1 ff 1 nC 5 j 3 ; 8ff 2 [0; 1]: (72) Relation (55) with p = 4 and q = 3 and the assumption that (x; y; s) 2 N 4 (ffi; <p> 2 (x T s) 23ffi j (x T s) 1+ffi 1 ff 1 + C 5 j 4 : for all ff 2 <ref> [0; 1] </ref>. Similarly, from relation (57), we obtain (x + ffx) T s (ff) x T s 1 ff 1 nC 5 j 3 ; 8ff 2 [0; 1]: (72) Relation (55) with p = 4 and q = 3 and the assumption that (x; y; s) 2 N 4 (ffi; j; fl) imply that (x; y; s) 2 N 3 (ffi; j; fl). <p> Indeed, using (72), (73) and (69), we obtain (x + ffx) T s (ff) x T s 1 ff + ffnC 5 (x T s) 13ffi # " nC 5 ffi # ffi !! for every ff 2 <ref> [0; 1] </ref>. The following lemma will be useful later in the selection of the step sizes ff k for algorithm PDA. <p> = o q (s T x + x T s) i=1 x i + s i = o (q n) We now evaluate the left hand side of (103). &gt;From (57) it follows that (x + ffx) T s (ff) 1 ff + nC 5 j 3 ; 8ff 2 <ref> [0; 1] </ref>: (106) Moreover, it follows from (56) that for i = 1; : : : ; n (x i +ffx i )s i (ff) (x T s) 23ffi 1 ff C 5 j 4 ; 8ff 2 [0; 1]; where the last inequality is due to the fact that x <p> s (ff) 1 ff + nC 5 j 3 ; 8ff 2 <ref> [0; 1] </ref>: (106) Moreover, it follows from (56) that for i = 1; : : : ; n (x i +ffx i )s i (ff) (x T s) 23ffi 1 ff C 5 j 4 ; 8ff 2 [0; 1]; where the last inequality is due to the fact that x i s i j (x T s) 1+ffi . <p> OE q (x; s) " x T s i=1 " x i s i q log 1 ff + nC 5 j 3 i=1 " (x T s) 14ffi # " nC 5 (x T s) 13ffi # " C 5 (x T s) 14ffi # for all ff 2 <ref> [0; 1] </ref>.
Reference: [2] <author> R. Fletcher, </author> <title> Practical Methods of Optimization, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <note> second ed., </note> <year> 1987. </year>
Reference-contexts: Our strategy is similar to one that has been suggested for the choice of penalty parameter in the nonsmooth penalty function approach for constrained optimization (see Fletcher <ref> [2] </ref>); namely, to embed Algorithm PDPR in an outer loop in which fl is successively increased until a suitable value is found.
Reference: [3] <author> J. Ji, F. Potra, and S. Huang, </author> <title> A predictor-corrector method for linear complementarity problems with polynomial complexity and superlinear convergence, </title> <type> Technical Report, </type> <institution> Department of Mathematics, The University of Iowa, </institution> <address> Iowa City, Iowa, 52240, USA, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: For example, the predictor-corrector algorithms of Ye et al. [13] for linear programming and Ji, Potra and Huang <ref> [3] </ref> and Ye and Anstreicher [12] for linear complementarity problems use neighborhoods of the form N 1 , while the linear programming algorithm of Zhang and Tapia [15] uses N 2 .
Reference: [4] <author> J. Ji, F. Potra, R. A. Tapia, and Y. Zhang, </author> <title> An interior-point method with polynomial complexity and superlinear convergence for linear complementarity problems, </title> <type> Technical Report TR-91-23, </type> <institution> Dept. of Mathematical Sciences, Rice University, </institution> <address> Houston, TX 77251, USA, </address> <year> 1991. </year> <month> 32 </month>
Reference: [5] <author> M. Kojima, Y. Kurita, and S. Mizuno, </author> <title> Large-step interior point algorithms for linear complementarity problems, </title> <journal> Research Reports on Information Sciences, Ser. </journal> <note> B : Operations Research B-243, </note> <institution> Dept. of Information Sciences, Tokyo Institute of Technology, </institution> <address> Oh-Okayama, Meguro-ku, Tokyo 152, Japan, </address> <year> 1991. </year>
Reference: [6] <author> M. Kojima, N. Megiddo, and T. Noma, </author> <title> Homotopy continuation methods for nonlinear complementarity problems, </title> <journal> Mathematics of Operations Research, </journal> <volume> 16 (1991), </volume> <pages> pp. 754-774. </pages>
Reference: [7] <author> K. A. McShane, </author> <title> A superlinearly convergent O( p nL) iteration primal-dual linear programming algorithm, manuscript, </title> <editor> U. S. </editor> <publisher> Government, </publisher> <address> 2537 Villanova Drive, Vienna, Virginia, USA, </address> <year> 1991. </year>
Reference: [8] <author> S. Mehrotra, </author> <title> Quadratic convergence in a primal-dual method, </title> <type> Technical Report 91-15, </type> <institution> Dept. of Industrial Engineering and Management Science, Northwestern University, </institution> <address> Evanston, IL 60208, USA, </address> <month> September </month> <year> 1991. </year>
Reference: [9] <author> R. D. C. Monteiro, </author> <title> A globally convergent interior point algorithm for convex programming, </title> <type> Technical Report 91-021, </type> <institution> Dept. of Systems and Industrial Engineering, University of Arizona, </institution> <address> Tucson, AZ 85721, USA, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: By a suitable choice of parameters, the q-order of the local convergence can lie anywhere in the range (1; 2). To make the algorithm converge globally from any strictly feasible starting point, we embed the affine scaling technique into the potential reduction algorithm discussed in Monteiro <ref> [9] </ref>. <p> Section 5 contains the global convergence theory. We outline the globally convergent algorithm presented in Monteiro <ref> [9] </ref> and show that if some iterate K satisfies the initial point conditions for the locally convergent algorithm, superlinear convergence also occurs. <p> In the next section, this algorithm is embedded in the globally convergent potential reduction algorithm of Monteiro <ref> [9] </ref>. In describing the algorithm, we first show how the step calculated in (18) can be used to move from one iterate to the next. <p> However, this last choice is not attractive since ^ff k is not easily computable. 24 5 A globally and superlinearly convergent potential reduction algorithm In this section we embed the locally convergent algorithm of the previous section in the potential reduction algorithm of Monteiro <ref> [9] </ref>. We start by outlining a version of the algorithm in [9] in which the centering parameter (namely, the parameter oe k in the notation of [9]) is chosen to be zero. The directions so obtained are referred to as primal-dual affine scaling directions. <p> not attractive since ^ff k is not easily computable. 24 5 A globally and superlinearly convergent potential reduction algorithm In this section we embed the locally convergent algorithm of the previous section in the potential reduction algorithm of Monteiro <ref> [9] </ref>. We start by outlining a version of the algorithm in [9] in which the centering parameter (namely, the parameter oe k in the notation of [9]) is chosen to be zero. The directions so obtained are referred to as primal-dual affine scaling directions. For simplicity of exposition, we fix certain parameters in his algorithm to numerical values. <p> convergent potential reduction algorithm In this section we embed the locally convergent algorithm of the previous section in the potential reduction algorithm of Monteiro <ref> [9] </ref>. We start by outlining a version of the algorithm in [9] in which the centering parameter (namely, the parameter oe k in the notation of [9]) is chosen to be zero. The directions so obtained are referred to as primal-dual affine scaling directions. For simplicity of exposition, we fix certain parameters in his algorithm to numerical values. <p> Hence, some component of either x k or s k must be negative. Thus, the maximum in (97) is finite. The following global convergence theorem can be proved as a consequence of the results presented in Monteiro <ref> [9] </ref>. Theorem 5.1 In Algorithm PDPR, lim x k T and the sequence f (x k ; y k ; s k )g has at least one limit point. <p> The second term on the right hand side serves to bias the step towards the central path, and is a common feature of most interior point algorithms. The global convergence analysis in Monteiro <ref> [9] </ref> still holds when oe k is chosen in this way, while our local convergence analysis still goes through provided that oe k approaches zero sufficiently rapidly (that is, like some power of (x k T s k )) during the latter stages of the algorithm.
Reference: [10] <author> T. Tsuchiya, </author> <title> Quadratic convergence of Iri and Imai's method for degenerate linear programming problems, </title> <note> Research Memorandum 412, </note> <institution> The Institute of Statistical Mathematics, 4-6-7 Minami-Azabu, Minato-ku, </institution> <address> Tokyo 106, Japan, </address> <year> 1991. </year>
Reference: [11] <author> Y. Ye, </author> <title> On the q-order of convergence of interior-point algorithms for linear programming, </title> <type> Working Paper 91-17, </type> <institution> The College of Business Administration, The University of Iowa, </institution> <address> Iowa City, IA 52242, USA, </address> <year> 1991. </year>
Reference-contexts: In the papers by Ye <ref> [11] </ref> and Ye and Anstreicher [12], it is necessary 2 to expand the neighborhood N 1 (fi) during the final stages in order to obtain rapid local convergence. The basic algorithm we describe in this paper calculates search directions by using a primal-dual affine scaling technique.
Reference: [12] <author> Y. Ye and K. Anstreicher, </author> <title> On quadratic and O( p nL) convergence of a predictor-corrector algorithm for LCP, </title> <type> Technical Report, </type> <institution> Department of Management Sciences, The University of Iowa, </institution> <address> Iowa City, IA 52242, USA, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: introduction section of Ye and Anstreicher <ref> [12] </ref>. In this paper, we discuss superlinearly convergent primal-dual affine scaling methods for solving the convex programming problem min f (x); Ax = b; x 0; (1) fl This research was supported by the National Science Foundation (NSF) under Grant No. <p> For example, the predictor-corrector algorithms of Ye et al. [13] for linear programming and Ji, Potra and Huang [3] and Ye and Anstreicher <ref> [12] </ref> for linear complementarity problems use neighborhoods of the form N 1 , while the linear programming algorithm of Zhang and Tapia [15] uses N 2 . <p> In the papers by Ye [11] and Ye and Anstreicher <ref> [12] </ref>, it is necessary 2 to expand the neighborhood N 1 (fi) during the final stages in order to obtain rapid local convergence. The basic algorithm we describe in this paper calculates search directions by using a primal-dual affine scaling technique. <p> Providing upper bounds for the remaining components of the search directions, namely x B and s N , is more difficult. This part of the development is based on the approach which appears in the paper of Ye and Anstreicher <ref> [12] </ref>. We start with the following lemma of Ye and Anstreicher [12, Lemma 3.4]. Lemma 3.4 Let M 2 IR pfip be a positive semi-definite matrix and assume that (J; L) form a partition of f1; : : : ; pg. <p> This part of the development is based on the approach which appears in the paper of Ye and Anstreicher [12]. We start with the following lemma of Ye and Anstreicher <ref> [12, Lemma 3.4] </ref>. Lemma 3.4 Let M 2 IR pfip be a positive semi-definite matrix and assume that (J; L) form a partition of f1; : : : ; pg. <p> the matrix M and the partition (J; L) of f1; : : : ; m + ng for which M JJ = Q BB A T A :B 0 : (32) Using the above result, we next prove a lemma that is similar to Lemma 3.5 of Ye and Anstreicher <ref> [12] </ref>. In fact, the two results are identical if the function f (x) is quadratic. Lemma 3.6 Suppose that Assumption 4 holds. Let (x; y; s) be a strictly feasible point and let D j X 1=2 S 1=2 . Let (x; y; s) denote the solution of (18).
Reference: [13] <author> Y. Ye, O. G uler, R. A. Tapia, and Y. Zhang, </author> <title> A quadratically convergent O( nL)-iteration algorithm for linear programming, </title> <type> Technical Report TR-91-26, </type> <institution> Dept. of Mathematical Sciences, Rice University, </institution> <address> Houston, TX 77251, USA, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: For example, the predictor-corrector algorithms of Ye et al. <ref> [13] </ref> for linear programming and Ji, Potra and Huang [3] and Ye and Anstreicher [12] for linear complementarity problems use neighborhoods of the form N 1 , while the linear programming algorithm of Zhang and Tapia [15] uses N 2 .
Reference: [14] <author> Y. Zhang and R. A. Tapia, </author> <title> A quadratically convergent polynomial primal-dual interior-point algorithm for linear programming, </title> <type> Technical Report TR 90-40, </type> <institution> Dept. of Mathematical Sciences, Rice University, </institution> <address> Houston, TX 77251, USA, </address> <year> 1990. </year> <title> [15] , Superlinear and quadratic convergence of primal-dual interior-point methods for linear programming revisited, </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 73 (1992), </volume> <pages> pp. 229-242. </pages>
Reference: [16] <author> Y. Zhang, R. A. Tapia, and J. E. Dennis, </author> <title> On the superlinear and quadratic con-vergence of primal-dual interior point linear programming algorithms, </title> <type> Technical Report TR 90-6, </type> <institution> Dept. of Mathematical Sciences, Rice University, </institution> <address> Houston, TX 77251, USA, </address> <month> January </month> <year> 1990. </year>
Reference: [17] <author> Y. Zhang, R. A. Tapia, and F. Potra, </author> <title> On the superlinear convergence of interior point algorithms for a general class of problems, </title> <type> Technical Report TR 90-9, </type> <institution> Dept. of Mathematical Sciences, Rice University, </institution> <address> Houston, TX 77251, USA, </address> <month> March </month> <year> 1990. </year> <month> 34 </month>
References-found: 16

