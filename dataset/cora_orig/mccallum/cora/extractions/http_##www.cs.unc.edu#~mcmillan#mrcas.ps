URL: http://www.cs.unc.edu/~mcmillan/mrcas.ps
Refering-URL: http://www.cs.unc.edu/Research/graphics/pubs.html
Root-URL: http://www.cs.unc.edu
Title: Virtual Space Teleconferencing using a Sea of Cameras  
Author: Henry Fuchs, Gary Bishop, Kevin Arthur, Leonard McMillan Ruzena Bajcsy, Sang Wook Lee, Hany Farid Takeo Kanade 
Address: Chapel Hill  
Affiliation: University of North Carolina at  University of Pennsylvania  Carnegie Mellon University  
Abstract: A new approach to telepresence is presented in which a multitude of stationary cameras are used to acquire both photometric and depth information. A virtual environment is constructed by displaying the acquired data from the remote site in accordance with the head position and orientation of a local participant. Shown are preliminary results of a depth image of a human subject calculated from 11 closely spaced video camera positions. A user wearing a head-mounted display walks around this 3D data that has been inserted into a 3D model of a simple room. Future systems based on this approach may exhibit more natural and intuitive interaction among participants than current 2D teleconferencing systems. 
Abstract-found: 1
Intro-found: 1
Reference: [Barnard and Fischler, 1982] <author> S. T. Barnard and M. A. Fischler. </author> <title> Computational stereo. </title> <journal> Computing Surveys, </journal> <volume> 14(4) </volume> <pages> 553-572, </pages> <year> 1982. </year>
Reference-contexts: The extraction of depth information from a set of two or more images is a well known problem in robotic vision <ref> [Barnard and Fischler, 1982; Dhond and Aggarwal, 1989] </ref>. In the traditional application one or two cameras mounted to a mobile platform are used to acquire depth information at each pixel within the overlapping region of the sensor arrays as the robot moves through the environment.
Reference: [Bishop et al., 1992] <author> G. Bishop, H. Fuchs, et al. </author> <title> Research directions in virtual environments. </title> <journal> Computer Graphics, </journal> <volume> 26(3) </volume> <pages> 153-177, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: 1 Introduction In the near future, immersive stereo displays, three-dimensional sound, and tactile feedback will be increasingly capable of providing a sensation of presence in a virtual environment <ref> [Sutherland, 1968; Bishop et al., 1992] </ref>. When this technology is applied for use in long-range communication, the goal is to provide a sense of telepresence to the participant.
Reference: [Caudell et al., 1993] <author> T. P. Caudell, A. L. Janin, and S. K. Johnson. </author> <title> Neural modelling of face animation for telecommuting in virtual reality. </title> <booktitle> In Proceedings of the IEEE Virtual Reality Annual International Symposium, </booktitle> <pages> pages 478-485, </pages> <month> September 18-22, </month> <year> 1993. </year>
Reference: [Dhond and Aggarwal, 1989] <author> U. R. Dhond and J. K. Aggarwal. </author> <title> Structure from stereo a review. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 19(6) </volume> <pages> 1489-1510, </pages> <year> 1989. </year>
Reference-contexts: The extraction of depth information from a set of two or more images is a well known problem in robotic vision <ref> [Barnard and Fischler, 1982; Dhond and Aggarwal, 1989] </ref>. In the traditional application one or two cameras mounted to a mobile platform are used to acquire depth information at each pixel within the overlapping region of the sensor arrays as the robot moves through the environment. <p> In effect there are only "virtual cameras" that correspond to the participant's eye positions in the environment. 4 Depth Acquisition 4.1 Overview The major steps in recovering depth information from a pair or sequence of images are: (1) preprocessing, (2) matching, and (3) recovering depth (see <ref> [Dhond and Aggarwal, 1989] </ref> for a review of stereo algorithms). The preprocessing stage generally consists of a rectification step that accounts for lens distortion and non-parallel axis camera geometry [Tsai, 1987; Weng et al., 1992b]. The process of matching is the most important and difficult stage in most stereo algorithms.
Reference: [Farid et al., 1994] <author> H. Farid, S. W. Lee, and R. </author> <title> Bajcsy. View selection strategies for multi-view, wide-baseline stereo. </title> <type> Technical Report MS-CIS-94-18, </type> <institution> University of Pennsylvania, Department of Computer and Information Science, </institution> <year> 1994. </year>
Reference-contexts: A stereo algorithm is presented that attempts to exploit, maximally, the benefits of small and large baselines and mask sizes. In particular, a multi-baseline, coarse-to-fine approach to stereo is adopted <ref> [Okutomi and Kanade, 1993; Kanade, 1993; Farid et al., 1994] </ref>, where several closely spaced views are taken (multi-baseline) and matching across these views is done for several different mask sizes (coarse-to-fine). The use of several views and mask sizes introduces a need for more sophisticated matching and combination strategies.
Reference: [Fuchs and Neumann, 1993] <author> H. Fuchs and U. Neumann. </author> <title> A vision of telepresence for medical consultation and other applications. </title> <booktitle> In Proceedings of the 6th International Symposium on Robotics Research, </booktitle> <month> October 2-5, </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: These considerations lead us to systems in which each participant wears a head-mounted display to look around a remote environment whose surface geometries are continuously sensed by a multitude of video cameras mounted along the walls and ceiling, from which depth maps are extracted through cross-correlation stereo techniques <ref> [Fuchs and Neumann, 1993] </ref>. Views acquired from several cameras can then be processed and displayed on a head-mounted display with an integrated tracking system to provide images of the remote environment.
Reference: [Hirose et al., 1993] <author> M. Hirose, K. Yokoyama, and S. Sato. </author> <title> Transmission of realistic sensation: Development of a virtual dome. </title> <booktitle> In Proceedings of the IEEE Virtual Reality Annual International Symposium, </booktitle> <pages> pages 125-131, </pages> <month> September 18-22, </month> <year> 1993. </year>
Reference-contexts: 3 Previous Work Previous approaches to telepresence tend to fall into one of the following categories: (1) a remote system provides incremental updates to a locally maintained model [Caudell et al., 1993; Ohya et al., 1993; Terzopoulos and Waters, 1993], (2) dynamic textures are mapped onto an essentially static model <ref> [Hirose et al., 1993] </ref>, (3) images from a multicamera conference room are projected onto a large field-of-view display, and (4) a boom mounted stereo camera pair is controlled by the movement of a remote observer wearing a head-mounted display.
Reference: [Kanade, 1993] <author> T. Kanade. </author> <title> Very fast 3-d sensing hardware. </title> <booktitle> In Proceedings of the 6th International Symposium on Robotics Research, </booktitle> <month> October 2-5, </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: A stereo algorithm is presented that attempts to exploit, maximally, the benefits of small and large baselines and mask sizes. In particular, a multi-baseline, coarse-to-fine approach to stereo is adopted <ref> [Okutomi and Kanade, 1993; Kanade, 1993; Farid et al., 1994] </ref>, where several closely spaced views are taken (multi-baseline) and matching across these views is done for several different mask sizes (coarse-to-fine). The use of several views and mask sizes introduces a need for more sophisticated matching and combination strategies. <p> There are several strategies that may be adopted for matching across such a sequence of images; below, we present one such approach. Whereas the original multi-baseline stereo algorithms <ref> [Okutomi and Kanade, 1993; Kanade, 1993] </ref> perform correlation to the left- or right-most image in a sequence of images, the algorithm described here correlates to the center image in the sequence. <p> To address this, one of the authors is directing an effort at Carnegie Mellon University to develop a video-rate (30 frames per second) stereo machine that can take up to 6 camera inputs <ref> [Kanade, 1993] </ref>. We believe that these issues can be resolved over time, and that the cost of the technology will fall, eventually making the proposed system practical for real use. 8 Conclusions Our initial experiments show promise for the sea-of-cameras approach to virtual space teleconferencing.
Reference: [Koch, 1993] <author> R. Koch. </author> <title> Automatic reconstruction of buildings from stereoscopic image sequences. </title> <booktitle> Proceedings of Eurographics '93, </booktitle> <volume> 12(3) </volume> <pages> 339-350, </pages> <year> 1993. </year>
Reference-contexts: This same basic approach has also been applied to computer graphics as a technique for static model generation <ref> [Koch, 1993] </ref>. Our approach differs in that a multitude of permanently mounted cameras are used to acquire dynamic, or more accurately throw-away, models of a scene.
Reference: [Ohya et al., 1993] <author> J. Ohya, Y. Kitamura, H. Takemura, F. Kishino, and N. Terashima. </author> <title> Real-time reproduction of 3d human images in virtual space teleconferencing. </title> <booktitle> In Proceedings of the IEEE Virtual Reality Annual International Symposium, </booktitle> <pages> pages 408-414, </pages> <month> September 18-22, </month> <year> 1993. </year> <editor> [Okutomi and Kanade, 1993] M. Okutomi and T. </editor> <title> Kanade. A multiple-baseline stereo. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(4) </volume> <pages> 353-363, </pages> <year> 1993. </year>
Reference: [Sutherland, 1968] <author> I. Sutherland. </author> <title> A head-mounted three dimensional display. </title> <booktitle> In Proceedings of the Fall Joint Computer Conference, </booktitle> <pages> pages 757-764. </pages> <publisher> Thompson Books, </publisher> <address> Washington, D.C., </address> <year> 1968. </year>
Reference-contexts: 1 Introduction In the near future, immersive stereo displays, three-dimensional sound, and tactile feedback will be increasingly capable of providing a sensation of presence in a virtual environment <ref> [Sutherland, 1968; Bishop et al., 1992] </ref>. When this technology is applied for use in long-range communication, the goal is to provide a sense of telepresence to the participant.
Reference: [Terzopoulos and Waters, 1993] <author> D. Terzopoulos and K. Waters. </author> <title> Analysis and synthesis of facial image sequences using physical and anatomical models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(6) </volume> <pages> 569-579, </pages> <year> 1993. </year>
Reference: [Tsai, 1987] <author> R. Tsai. </author> <title> A versatile camera calibration technique for high-accuracy 3d machine vision metrology using off-the-shelf tv cameras and lenses. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(4):323-344, </volume> <year> 1987. </year>
Reference-contexts: The preprocessing stage generally consists of a rectification step that accounts for lens distortion and non-parallel axis camera geometry <ref> [Tsai, 1987; Weng et al., 1992b] </ref>. The process of matching is the most important and difficult stage in most stereo algorithms. The matching process determines correspondence between "features" that are projections of the same physical entity in each view.
Reference: [Weng et al., 1992a] <author> J. Weng, N. Ahuja, and T. Huang. </author> <title> Matching two perspective views. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(8) </volume> <pages> 806-825, </pages> <year> 1992. </year>
Reference-contexts: Once the correspondence between "features" has been established, calculating the depth is usually a straightforward computation dependent on the camera configuration and optics. One of the most common stereo reconstruction paradigms is matching image features from two parallel axis views (see <ref> [Weng et al., 1992a] </ref> for a review). This method provides a disparity value d for matched pairs of points for each point in either the left or right image.
Reference: [Weng et al., 1992b] <author> J. Weng, P. Cohen, and M. Herniou. </author> <title> Camera calibration with distortion models and accuracy evaluation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(10) </volume> <pages> 965-980, </pages> <year> 1992. </year> <title> data courtesy of Cyberware and modelled body data. a user walking around the above scene. This shows the user (lower portion) and his view for one eye. the user has moved forward in the room. camera views. extracted geometry. </title>
Reference-contexts: The preprocessing stage generally consists of a rectification step that accounts for lens distortion and non-parallel axis camera geometry <ref> [Tsai, 1987; Weng et al., 1992b] </ref>. The process of matching is the most important and difficult stage in most stereo algorithms. The matching process determines correspondence between "features" that are projections of the same physical entity in each view.
References-found: 15

