URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR391.ps.Z
Refering-URL: http://www.cs.indiana.edu/trindex.html
Root-URL: 
Title: On Lower Bounds for the Matrix Chain Ordering Problem  
Author: Phillip G. Bradford Venkatesh Choppella Gregory J. E. Rawlins 
Date: November 17, 1993  
Abstract: This paper shows that the radix model is not reasonable for solving the Matrix Chain Ordering Problem. In particular, to have an n-matrix instance of this problem with an optimal parenthesization of depth fi(n) in the worst case requires the matrix dimensions to be exponential in n. Considering bit complexity, a worst case lower bound of (n 2 ) is given. This worst case lower bound is parameterized and, depending on the optimal product tree depth, it goes from (n 2 ) down to (n lg n). Also, this paper gives an (n lg n) work lower bound for the Matrix Chain Ordering Problem for a class of algorithms on the atomic comparison model with unit cost comparisons. This lower bound, to the authors' knowledge, captures all known algorithms for solving the Matrix Chain Ordering Problem, but does not consider bit operations. Finally, a trade-off is given between the bit complexity lower bound and the atomic comparison based lower bound. This trade-off basically shows that hard instances for the comparison based model are easy instances for the bit complexity model and vice versa.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, M. M. Klawe, S. Moran, P. Shor, R. Wilber: </author> <title> "Geometric Applications of A Matrix Search Algorithm," </title> <journal> Algorithmica, </journal> <volume> Vol. 2, </volume> <pages> 195-208, </pages> <year> 1987. </year> <month> 29 </month>
Reference-contexts: In addition, Bradford, Rawlins and Shannon's parallel algorithm [7, 8] is an O (lg n) factor from optimal and would be asymptotically optimal if an asymptotically optimal O (lg n) time parallel algorithm for computing row minima on totally monotone matrices is found <ref> [1, 3, 2] </ref>. Finally, this paper gives a trade-off between the bit complexity lower bound and the atomic comparison based lower bound. This trade-off is essentially based on the optimal product tree depth. <p> and Shing [21, Page 233] for a similar notion.) The contribution of a triangle with vertices w i ; w j ; and w k ; relative to w 1 , such that w j = maxf w i ; w j ; w k g, is measured by t <ref> [1] </ref> j = w 1 w j w k + w 1 w i w j (w 1 w i w k + w i w j w k ) For a single monotone polygon, we have k = j 1 and i = j 2. The t [1]s are directly <p> The t <ref> [1] </ref>s are directly based on inequality (1). In fact, the t [1] values are the key to the approximation algorithms for the MCOP [10, 18, 12, 6]. Now, by inequality (1) we have, if t [1] j &lt; 0, then the product cost w j2 w j1 w j is a burden in the polygon p if t [1] j &gt; 0, <p> The t <ref> [1] </ref>s are directly based on inequality (1). In fact, the t [1] values are the key to the approximation algorithms for the MCOP [10, 18, 12, 6]. Now, by inequality (1) we have, if t [1] j &lt; 0, then the product cost w j2 w j1 w j is a burden in the polygon p if t [1] j &gt; 0, then the product cost w j2 w j1 w j contributes to the polygon p These contributions or burdens can be considered to be <p> fact, the t <ref> [1] </ref> values are the key to the approximation algorithms for the MCOP [10, 18, 12, 6]. Now, by inequality (1) we have, if t [1] j &lt; 0, then the product cost w j2 w j1 w j is a burden in the polygon p if t [1] j &gt; 0, then the product cost w j2 w j1 w j contributes to the polygon p These contributions or burdens can be considered to be relative to either the triangles w j2 w j1 w j or the H-arcs w j1 |w j2 . <p> This lemma is central for intuition about the t-table. Take the monotone alternating 7-gon in Figure 7 which has the following t <ref> [1] </ref> values, t [1] 4 = w 1 w 2 w 4 + w 1 w 3 w 4 (w 1 w 2 w 3 + w 2 w 3 w 4 ) t [1] 6 = w 1 w 4 w 6 + w 1 w 5 w 6 (w <p> This lemma is central for intuition about the t-table. Take the monotone alternating 7-gon in Figure 7 which has the following t <ref> [1] </ref> values, t [1] 4 = w 1 w 2 w 4 + w 1 w 3 w 4 (w 1 w 2 w 3 + w 2 w 3 w 4 ) t [1] 6 = w 1 w 4 w 6 + w 1 w 5 w 6 (w 1 w 4 <p> Take the monotone alternating 7-gon in Figure 7 which has the following t <ref> [1] </ref> values, t [1] 4 = w 1 w 2 w 4 + w 1 w 3 w 4 (w 1 w 2 w 3 + w 2 w 3 w 4 ) t [1] 6 = w 1 w 4 w 6 + w 1 w 5 w 6 (w 1 w 4 w 5 + w 4 w 5 w 6 ) Where for appropriate i and k, the expression w 1 w i w i+2 is the cost of a triangle in <p> Notice that the product costs without underlines or overlines cancel out. This leads directly to a proof of the next lemma, Lemma 2 Given a monotone alternating polygon P , then P n+1 i=4 t <ref> [1] </ref> i measures the difference between the cost of the linear product of P and the cost of the alternating product of P . This lemma also holds for all t values in a particular range, see Figure 8. <p> In general, taking the partial prefix sum of all rows of such a t-table, if any of these partial sums are negative, then an alternating triangulation is not optimal. 11 Corollary 3 Let P be an alternating monotone (n + 1)-gon. If 0 &gt; P k i=4 t <ref> [1] </ref> i for some k such that n + 1 k 4, then the alternating triangulation of P is not optimal. Lemma 3 Given an alternating monotone polygon with at least 4 weights, we have t [1] i &lt; t [2] i &lt; &lt; t [i 4] i &lt; t [i <p> If 0 &gt; P k i=4 t <ref> [1] </ref> i for some k such that n + 1 k 4, then the alternating triangulation of P is not optimal. Lemma 3 Given an alternating monotone polygon with at least 4 weights, we have t [1] i &lt; t [2] i &lt; &lt; t [i 4] i &lt; t [i 3] i . <p> Looking at the relationships of the t values, we note that if t <ref> [1] </ref> i 0 for all i such that n + 1 i 4, then the algorithm in Figure 4 asymptotically optimally generates such monotone alternating polygons. Given an alternating monotone polygon, a block is any t-table that has all positive t values. <p> In addition, initially we choose the second and third dimensions as small as possible. All local triangulations must be optimal, otherwise by Lemma 3 all t values can't be positive. Specifically, if all of the t <ref> [1] </ref> values are positive, then all t [i] for i &gt; 1 are also positive. Also, if for any valid i and j, say t [i] j is negative, then t [1] j is negative. <p> Specifically, if all of the t <ref> [1] </ref> values are positive, then all t [i] for i &gt; 1 are also positive. Also, if for any valid i and j, say t [i] j is negative, then t [1] j is negative. It follows by induction that the algorithm generates the "most compact" polygon, so all t values are positive. 2 The columns of a t-table corresponding to an instance of the MCOP are numbered by increasing values starting with 4 and going up through n + 1. <p> Figure 10 gives the t-table for the bi-modal polygon in Figure 9. It is important to note that between t <ref> [1] </ref> 8 and t [3] 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t [2] 7 t [2] 9 t [3] 8 t [3] 9 Some polygons <p> Figure 10 gives the t-table for the bi-modal polygon in Figure 9. It is important to note that between t <ref> [1] </ref> 8 and t [3] 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t [2] 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may have V-arcs interspersed with H-arcs. <p> Figure 10 gives the t-table for the bi-modal polygon in Figure 9. It is important to note that between t <ref> [1] </ref> 8 and t [3] 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t [2] 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may have V-arcs interspersed with H-arcs. <p> Figure 10 gives the t-table for the bi-modal polygon in Figure 9. It is important to note that between t <ref> [1] </ref> 8 and t [3] 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t [2] 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may have V-arcs interspersed with H-arcs. <p> It is important to note that between t <ref> [1] </ref> 8 and t [3] 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t [2] 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may have V-arcs interspersed with H-arcs. <p> It is important to note that between t <ref> [1] </ref> 8 and t [3] 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t [2] 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may have V-arcs interspersed with H-arcs. In such polygons, the only possible chance that w i1 |w i2 is an H-arc in an optimal triangulation is when t [i3] i 0. <p> Otherwise we will violate Theorem 6, hence we can't have the desired H-arcs. (This is because the H-arc w i1 |w i2 can only be in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t [3] 6 j t <ref> [1] </ref> 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + <p> have the desired H-arcs. (This is because the H-arc w i1 |w i2 can only be in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t [3] 6 j t <ref> [1] </ref> 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + <p> t [i 3] i 0.) t [3] 6 j t <ref> [1] </ref> 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) and when t [i <p> j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t <ref> [1] </ref> 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) and when t [i 3] i &gt; 0 we assume t [i 4] i = 0 giving 17 w 3 w 2 (w 2 w 1 ) =) w 3 w 2 w 2 w 1 <p> Assume column i has all positive values and suppose column i + 1 has a negative sum, see 0 &gt; t <ref> [1] </ref> i+1 since column i + 1 has a negative sum. This means, if t [1] i + t [1] i+1 t [b (i + 1)=2c] i+1 , then t [1] i + t [1] i+1 &lt; 0. <p> Assume column i has all positive values and suppose column i + 1 has a negative sum, see 0 &gt; t <ref> [1] </ref> i+1 since column i + 1 has a negative sum. This means, if t [1] i + t [1] i+1 t [b (i + 1)=2c] i+1 , then t [1] i + t [1] i+1 &lt; 0. <p> Assume column i has all positive values and suppose column i + 1 has a negative sum, see 0 &gt; t <ref> [1] </ref> i+1 since column i + 1 has a negative sum. This means, if t [1] i + t [1] i+1 t [b (i + 1)=2c] i+1 , then t [1] i + t [1] i+1 &lt; 0. <p> column i has all positive values and suppose column i + 1 has a negative sum, see 0 &gt; t <ref> [1] </ref> i+1 since column i + 1 has a negative sum. This means, if t [1] i + t [1] i+1 t [b (i + 1)=2c] i+1 , then t [1] i + t [1] i+1 &lt; 0. Therefore, in terms of the sum along the top row (of the corresponding t-table) that must be maintained to have an optimal alternating product, by Corollary 3, column i + 1's negative t [1] value cancels out any gain by column i's positive <p> positive values and suppose column i + 1 has a negative sum, see 0 &gt; t <ref> [1] </ref> i+1 since column i + 1 has a negative sum. This means, if t [1] i + t [1] i+1 t [b (i + 1)=2c] i+1 , then t [1] i + t [1] i+1 &lt; 0. Therefore, in terms of the sum along the top row (of the corresponding t-table) that must be maintained to have an optimal alternating product, by Corollary 3, column i + 1's negative t [1] value cancels out any gain by column i's positive t [1] value. <p> t [b (i + 1)=2c] i+1 , then t <ref> [1] </ref> i + t [1] i+1 &lt; 0. Therefore, in terms of the sum along the top row (of the corresponding t-table) that must be maintained to have an optimal alternating product, by Corollary 3, column i + 1's negative t [1] value cancels out any gain by column i's positive t [1] value. Recalling that the only chance of having subexponential growth of the weights is, if there are at least (n lg 1+* n) columns with negative sums. 21 The intuition behind the next lemma is the following. <p> + t <ref> [1] </ref> i+1 &lt; 0. Therefore, in terms of the sum along the top row (of the corresponding t-table) that must be maintained to have an optimal alternating product, by Corollary 3, column i + 1's negative t [1] value cancels out any gain by column i's positive t [1] value. Recalling that the only chance of having subexponential growth of the weights is, if there are at least (n lg 1+* n) columns with negative sums. 21 The intuition behind the next lemma is the following. <p> Assume most columns have negative sums, then to maintain a positive sum in the top row of the t-table, we must show that the magnitude of the columns with positive t <ref> [1] </ref>s are larger than their (many) negative counterparts. But, for each column with a positive t [1], there are n columns with negative sums, for some * &gt; 0. The next lemma shows that if (n=lg 1+* n) columns with negative sums don't "cancel out" one positive t [1], then the weights grow exponentially. <p> positive t <ref> [1] </ref>s are larger than their (many) negative counterparts. But, for each column with a positive t [1], there are n columns with negative sums, for some * &gt; 0. The next lemma shows that if (n=lg 1+* n) columns with negative sums don't "cancel out" one positive t [1], then the weights grow exponentially. In fact, the next lemma proves that this even holds for only (lg 1+* n) such negative columns. Lemma 6 Suppose the t-table of a monotone (n + 1)-gon with an optimal alternating triangulation is such that t [1] i 0 &gt; t [1] k <p> don't "cancel out" one positive t <ref> [1] </ref>, then the weights grow exponentially. In fact, the next lemma proves that this even holds for only (lg 1+* n) such negative columns. Lemma 6 Suppose the t-table of a monotone (n + 1)-gon with an optimal alternating triangulation is such that t [1] i 0 &gt; t [1] k , for i &lt; k. If there are (lg 1+* n) columns k, where t [bk=2c] k &lt; t [1] i + t [1] k , then the weights grow exponentially. Proof: Starting with 0 &gt; t [s] k (t [1] i + t <p> t <ref> [1] </ref>, then the weights grow exponentially. In fact, the next lemma proves that this even holds for only (lg 1+* n) such negative columns. Lemma 6 Suppose the t-table of a monotone (n + 1)-gon with an optimal alternating triangulation is such that t [1] i 0 &gt; t [1] k , for i &lt; k. If there are (lg 1+* n) columns k, where t [bk=2c] k &lt; t [1] i + t [1] k , then the weights grow exponentially. Proof: Starting with 0 &gt; t [s] k (t [1] i + t [1] k ) for k <p> Lemma 6 Suppose the t-table of a monotone (n + 1)-gon with an optimal alternating triangulation is such that t <ref> [1] </ref> i 0 &gt; t [1] k , for i &lt; k. If there are (lg 1+* n) columns k, where t [bk=2c] k &lt; t [1] i + t [1] k , then the weights grow exponentially. Proof: Starting with 0 &gt; t [s] k (t [1] i + t [1] k ) for k &gt; i and let s = b (k + 1)=2c giving 0 &gt; (w s w 1 ) [w k (w <p> Lemma 6 Suppose the t-table of a monotone (n + 1)-gon with an optimal alternating triangulation is such that t <ref> [1] </ref> i 0 &gt; t [1] k , for i &lt; k. If there are (lg 1+* n) columns k, where t [bk=2c] k &lt; t [1] i + t [1] k , then the weights grow exponentially. Proof: Starting with 0 &gt; t [s] k (t [1] i + t [1] k ) for k &gt; i and let s = b (k + 1)=2c giving 0 &gt; (w s w 1 ) [w k (w k1 + w k2 <p> such that t <ref> [1] </ref> i 0 &gt; t [1] k , for i &lt; k. If there are (lg 1+* n) columns k, where t [bk=2c] k &lt; t [1] i + t [1] k , then the weights grow exponentially. Proof: Starting with 0 &gt; t [s] k (t [1] i + t [1] k ) for k &gt; i and let s = b (k + 1)=2c giving 0 &gt; (w s w 1 ) [w k (w k1 + w k2 )] + (w 1 w s ) [w k1 w k2 ] w 1 w i1 (w <p> i 0 &gt; t <ref> [1] </ref> k , for i &lt; k. If there are (lg 1+* n) columns k, where t [bk=2c] k &lt; t [1] i + t [1] k , then the weights grow exponentially. Proof: Starting with 0 &gt; t [s] k (t [1] i + t [1] k ) for k &gt; i and let s = b (k + 1)=2c giving 0 &gt; (w s w 1 ) [w k (w k1 + w k2 )] + (w 1 w s ) [w k1 w k2 ] w 1 w i1 (w i w i2 ) <p> In particular, say t [b (i + 1)=2c] i+1 t <ref> [1] </ref> i + t [1] i+1 and without loss say 0 &gt; t [b (i + 1)=2c] i+1 . Then we know that 0 &gt; t [1] i + t [1] i+1 . Now, since 0 &gt; t [1] i + t [1] i+1 , this forces the top row to <p> In particular, say t [b (i + 1)=2c] i+1 t <ref> [1] </ref> i + t [1] i+1 and without loss say 0 &gt; t [b (i + 1)=2c] i+1 . Then we know that 0 &gt; t [1] i + t [1] i+1 . Now, since 0 &gt; t [1] i + t [1] i+1 , this forces the top row to have a negative sum <p> In particular, say t [b (i + 1)=2c] i+1 t <ref> [1] </ref> i + t [1] i+1 and without loss say 0 &gt; t [b (i + 1)=2c] i+1 . Then we know that 0 &gt; t [1] i + t [1] i+1 . Now, since 0 &gt; t [1] i + t [1] i+1 , this forces the top row to have a negative sum because we must have (n lg 1+* n) such columns. <p> In particular, say t [b (i + 1)=2c] i+1 t <ref> [1] </ref> i + t [1] i+1 and without loss say 0 &gt; t [b (i + 1)=2c] i+1 . Then we know that 0 &gt; t [1] i + t [1] i+1 . Now, since 0 &gt; t [1] i + t [1] i+1 , this forces the top row to have a negative sum because we must have (n lg 1+* n) such columns. <p> In particular, say t [b (i + 1)=2c] i+1 t <ref> [1] </ref> i + t [1] i+1 and without loss say 0 &gt; t [b (i + 1)=2c] i+1 . Then we know that 0 &gt; t [1] i + t [1] i+1 . Now, since 0 &gt; t [1] i + t [1] i+1 , this forces the top row to have a negative sum because we must have (n lg 1+* n) such columns. Therefore, by Corollary 3 if the top row has a negative sum, then we can't have an optimal alternating product. <p> say t [b (i + 1)=2c] i+1 t <ref> [1] </ref> i + t [1] i+1 and without loss say 0 &gt; t [b (i + 1)=2c] i+1 . Then we know that 0 &gt; t [1] i + t [1] i+1 . Now, since 0 &gt; t [1] i + t [1] i+1 , this forces the top row to have a negative sum because we must have (n lg 1+* n) such columns. Therefore, by Corollary 3 if the top row has a negative sum, then we can't have an optimal alternating product. <p> For example, take the following, Theorem 15 (Bradford et al. [9]) The problem of edge minimizing m jumpers in n unit rows can be reduced to the problem of finding the row minima of an m fi n totally monotone matrix. In <ref> [1] </ref> it is shown that solving the row minima problem sequentially in a n fi m totally monotone matrix costs fi (n).
Reference: [2] <author> A. Aggarwal and J. Park: </author> <title> "Parallel Searching Multidimensional Monotone Arrays," </title> <note> to appear in the Journal of Algorithms and parts of 29 th FOCS, 497-512, </note> <year> 1988. </year>
Reference-contexts: In addition, Bradford, Rawlins and Shannon's parallel algorithm [7, 8] is an O (lg n) factor from optimal and would be asymptotically optimal if an asymptotically optimal O (lg n) time parallel algorithm for computing row minima on totally monotone matrices is found <ref> [1, 3, 2] </ref>. Finally, this paper gives a trade-off between the bit complexity lower bound and the atomic comparison based lower bound. This trade-off is essentially based on the optimal product tree depth. <p> If 0 &gt; P k i=4 t [1] i for some k such that n + 1 k 4, then the alternating triangulation of P is not optimal. Lemma 3 Given an alternating monotone polygon with at least 4 weights, we have t [1] i &lt; t <ref> [2] </ref> i &lt; &lt; t [i 4] i &lt; t [i 3] i . <p> It is important to note that between t [1] 8 and t [3] 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t <ref> [2] </ref> 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may have V-arcs interspersed with H-arcs. In such polygons, the only possible chance that w i1 |w i2 is an H-arc in an optimal triangulation is when t [i3] i 0. <p> It is important to note that between t [1] 8 and t [3] 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t <ref> [2] </ref> 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may have V-arcs interspersed with H-arcs. In such polygons, the only possible chance that w i1 |w i2 is an H-arc in an optimal triangulation is when t [i3] i 0. <p> 6, hence we can't have the desired H-arcs. (This is because the H-arc w i1 |w i2 can only be in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t [3] 6 j t [1] 6 j t [5] 8 j t [3] 8 + t <ref> [2] </ref> 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + <p> (n + 1)-gon if t [i 3] i 0.) t [3] 6 j t [1] 6 j t [5] 8 j t [3] 8 + t <ref> [2] </ref> 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) <p> j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t <ref> [2] </ref> 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) and when t [i 3] i &gt; 0 we assume t [i 4] i = 0 giving 17 w 3 w 2 (w 2 w 1 ) =) w 3 w 2
Reference: [3] <author> M. J. Atallah and S. R. Kosaraju: </author> <title> "An Efficient Parallel Algorithm for the Row Minima of a Totally Monotone Matrix," </title> <type> 394-403, </type> <note> SODA 1991. And to appear in the Journal of Algorithms. </note>
Reference-contexts: In addition, Bradford, Rawlins and Shannon's parallel algorithm [7, 8] is an O (lg n) factor from optimal and would be asymptotically optimal if an asymptotically optimal O (lg n) time parallel algorithm for computing row minima on totally monotone matrices is found <ref> [1, 3, 2] </ref>. Finally, this paper gives a trade-off between the bit complexity lower bound and the atomic comparison based lower bound. This trade-off is essentially based on the optimal product tree depth. <p> This lemma also holds for all t values in a particular range, see Figure 8. In Figure 8, suppose 0 &gt; t <ref> [3] </ref> 6 +t [3] 7 +t [3] 8 +t [3] 9 . Then in the subpolygon between w 3 and w 9 ; the optimal triangulation is not the alternating triangulation. Hence such an entire monotone alternating (n + 1)-gon cannot have an optimal alternating triangulation. <p> This lemma also holds for all t values in a particular range, see Figure 8. In Figure 8, suppose 0 &gt; t <ref> [3] </ref> 6 +t [3] 7 +t [3] 8 +t [3] 9 . Then in the subpolygon between w 3 and w 9 ; the optimal triangulation is not the alternating triangulation. Hence such an entire monotone alternating (n + 1)-gon cannot have an optimal alternating triangulation. <p> This lemma also holds for all t values in a particular range, see Figure 8. In Figure 8, suppose 0 &gt; t <ref> [3] </ref> 6 +t [3] 7 +t [3] 8 +t [3] 9 . Then in the subpolygon between w 3 and w 9 ; the optimal triangulation is not the alternating triangulation. Hence such an entire monotone alternating (n + 1)-gon cannot have an optimal alternating triangulation. <p> This lemma also holds for all t values in a particular range, see Figure 8. In Figure 8, suppose 0 &gt; t <ref> [3] </ref> 6 +t [3] 7 +t [3] 8 +t [3] 9 . Then in the subpolygon between w 3 and w 9 ; the optimal triangulation is not the alternating triangulation. Hence such an entire monotone alternating (n + 1)-gon cannot have an optimal alternating triangulation. <p> Figure 10 gives the t-table for the bi-modal polygon in Figure 9. It is important to note that between t [1] 8 and t <ref> [3] </ref> 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t [2] 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may <p> important to note that between t [1] 8 and t <ref> [3] </ref> 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t [2] 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may have V-arcs interspersed with H-arcs. In such polygons, the only possible chance that w i1 |w i2 is an H-arc in an optimal triangulation is when t [i3] i 0. <p> that between t [1] 8 and t <ref> [3] </ref> 8 there is no t value due to the structure of the polygon in Figure 9. 13 t [1] 5 t [1] 6 t [1] 7 t [1] 8 t [1] 9 t [2] 7 t [2] 9 t [3] 8 t [3] 9 Some polygons with optimal triangulations may have V-arcs interspersed with H-arcs. In such polygons, the only possible chance that w i1 |w i2 is an H-arc in an optimal triangulation is when t [i3] i 0. <p> Otherwise we will violate Theorem 6, hence we can't have the desired H-arcs. (This is because the H-arc w i1 |w i2 can only be in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t <ref> [3] </ref> 6 j t [1] 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j <p> we will violate Theorem 6, hence we can't have the desired H-arcs. (This is because the H-arc w i1 |w i2 can only be in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t <ref> [3] </ref> 6 j t [1] 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + <p> in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t <ref> [3] </ref> 6 j t [1] 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each <p> + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t <ref> [3] </ref> 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) and when t [i 3] i &gt; 0 we assume t [i 4] i = 0 giving 17 w 3 w 2 (w 2 w 1 ) =)
Reference: [4] <author> O. Berkman, D. Breslauer, Z. Galil, B. Schieber and U. Vishkin: </author> <title> "Highly Parallelizable Problems," </title> <booktitle> Symposium on the Theory on Computing, </booktitle> <pages> 309-319, </pages> <year> 1989. </year>
Reference-contexts: That is, we can compute the parenthesization of this associative product by solving the following all nearest smaller value (ANSV) problem <ref> [4, 5] </ref>: Given w 1 ; w 2 ; : : : ; w n+1 drawn from a totally ordered set, for each w i find the largest j, where 1 j &lt; i, and smallest k where i &lt; k n, so that w j &lt; w i and w <p> Then as in <ref> [4, 5] </ref> call w i and w k a match and denote each match by a pair [w i ; w k ]. The basic intuition behind solving the MCOP problem by applying the ANSV problem is to let matrix dimensions approximate the depth of parentheses [6]. <p> i2 can only be in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t [3] 6 j t [1] 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t <ref> [4] </ref> 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns <p> + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t <ref> [4] </ref> 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) and when t [i 3] i &gt; 0 we assume t [i 4] i = 0 giving 17 w 3 w 2 (w 2
Reference: [5] <author> O. Berkman, B. Schieber and U. Vishkin: </author> <title> "Optimal Doubly Logarithmic Parallel Algorithms Based on Finding All Nearest Smaller Values," </title> <journal> J. of Algorithms, </journal> <volume> Vol. 14, </volume> <pages> 344-370, </pages> <year> 1993. </year>
Reference-contexts: Theorem 1 also leads directly to a simple parallel lower bound for the MCOP directly from Berkman et al.'s parallel processor lower bound for triangulating a monotone polygon <ref> [5] </ref>. That is, the parallel approximation algorithms of Czumaj [12] and Bradford [6] cannot run faster than (lg lg n) time using O (n lg c n) processors on the CRCW PRAM for c a constant where c &gt; 0. <p> That is, we can compute the parenthesization of this associative product by solving the following all nearest smaller value (ANSV) problem <ref> [4, 5] </ref>: Given w 1 ; w 2 ; : : : ; w n+1 drawn from a totally ordered set, for each w i find the largest j, where 1 j &lt; i, and smallest k where i &lt; k n, so that w j &lt; w i and w <p> Then as in <ref> [4, 5] </ref> call w i and w k a match and denote each match by a pair [w i ; w k ]. The basic intuition behind solving the MCOP problem by applying the ANSV problem is to let matrix dimensions approximate the depth of parentheses [6]. <p> Otherwise we will violate Theorem 6, hence we can't have the desired H-arcs. (This is because the H-arc w i1 |w i2 can only be in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t [3] 6 j t [1] 6 j t <ref> [5] </ref> 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + <p> H-arc w i1 |w i2 can only be in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t [3] 6 j t [1] 6 j t <ref> [5] </ref> 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j <p> j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t <ref> [5] </ref> 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) and when t [i 3] i &gt; 0 we assume t [i 4] i = 0 giving 17 w 3
Reference: [6] <author> P. G. Bradford: </author> <title> "Efficient Parallel Dynamic Programming," </title> <booktitle> Extended Abstract in the Proceed ings of the 30 th Allerton Conference on Communication, Control and Computation, </booktitle> <institution> University of Illinois at Urbana-Champaign, </institution> <month> 185-194, </month> <year> 1992. </year> <note> Full version submitted. </note>
Reference-contexts: Theorem 1 also leads directly to a simple parallel lower bound for the MCOP directly from Berkman et al.'s parallel processor lower bound for triangulating a monotone polygon [5]. That is, the parallel approximation algorithms of Czumaj [12] and Bradford <ref> [6] </ref> cannot run faster than (lg lg n) time using O (n lg c n) processors on the CRCW PRAM for c a constant where c &gt; 0. <p> Theorem 2 leads directly to sequential and parallel approximation algorithms for solving the MCOP to within 15.5 % of optimal <ref> [10, 18, 12, 6] </ref>. Given only a sequence of integers representing the depth of parentheses in an associative product (for example see the bottom row in Figure 1), then using a stack, for each parenthesis we can compute its matching parenthesis (see the top row in Figure 1). <p> Then as in [4, 5] call w i and w k a match and denote each match by a pair [w i ; w k ]. The basic intuition behind solving the MCOP problem by applying the ANSV problem is to let matrix dimensions approximate the depth of parentheses <ref> [6] </ref>. A multi-modal instance of the MCOP has a corresponding instance of the (n + 1)-gon triangulation problem that has a weight list that forms several "bumps." For example, the depths of the parentheses in Figure 1 have two bumps. <p> The t [1]s are directly based on inequality (1). In fact, the t [1] values are the key to the approximation algorithms for the MCOP <ref> [10, 18, 12, 6] </ref>. <p> j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t <ref> [6] </ref> 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) and when t [i 3] i &gt; 0 we assume t [i 4] i = 0 <p> This problem models many problems that are often solved using dynamic programming. 3.2 A Model for the MCOP This subsection follows <ref> [6, 7, 9] </ref> very closely. Here a graph problem is given that can model many problems which have dynamic programming solutions. In fact, recurrence (7) can be solved by finding a shortest path on such a graph. <p> Finding this shortest path is tantamount to solving recurrence (7). Therefore, starting with a chain of n matrices, finding a shortest path from (0; 0) to (1; n) in D n solves the MCOP <ref> [6] </ref>. <p> Since a path of critical nodes represents a parenthesization, all critical nodes are compatible. Also, D n has at most n 1 critical nodes and there is at least one path from (0; 0) to (1; n) that includes all critical nodes <ref> [6] </ref>. All vertices and edges that can reach (i; t) by a unit path form the subgraph D (i; t). When D (i; j) has a monotonic weight list w i ; : : : ; w j+1 , then D (i; j) is monotonic. <p> A canonical subgraph of the form D (i;t) (j;j+1) , is a leaf canonical subgraph and is written D (i;t) . It has the same nodes and edges as D (i; t). It turns out that these bands and leaf subgraphs together form trees <ref> [20, 21, 6] </ref>. ANSV matches and the four corresponding critical nodes are circled in D n . Notice the tree structure that canonical graphs form in Figure 18. A proof of the next theorem is straightforward examining recurrence (7).
Reference: [7] <author> P. G. Bradford, G. J. E. Rawlins and G. E. Shannon: </author> <title> "Matrix Chain Ordering in Polylog Time with n=lg n Processors," </title> <note> Full Version, </note> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: This lower bound shows that Hu and Shing's O (n lg n) algorithm [19, 20, 21] is asymptotically optimal and Ramanan's parallel algorithm [26, 27] is an O (lg 3 n) factor from optimal. In addition, Bradford, Rawlins and Shannon's parallel algorithm <ref> [7, 8] </ref> is an O (lg n) factor from optimal and would be asymptotically optimal if an asymptotically optimal O (lg n) time parallel algorithm for computing row minima on totally monotone matrices is found [1, 3, 2]. <p> This technique generates instances of the MCOP that exhibit the "father-son" relationship of [21], which was used for the sequential solution of the MCOP by Hu and Shing [20, 21]. In parallel, different methods can be applied for dealing with these instances <ref> [7, 9] </ref>. Instances of the MCOP with some negative t values can also be generated with a similar method to the one just outlined. For instance, we can start with an (n + 1)-gon generated by the algorithm of Figure 4. <p> (This is because the H-arc w i1 |w i2 can only be in an optimal monotone (n + 1)-gon if t [i 3] i 0.) t [3] 6 j t [1] 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t <ref> [7] </ref> 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + <p> j t [1] 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t <ref> [7] </ref> 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t [9] 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) and when t [i 3] i &gt; 0 we assume t [i <p> This problem models many problems that are often solved using dynamic programming. 3.2 A Model for the MCOP This subsection follows <ref> [6, 7, 9] </ref> very closely. Here a graph problem is given that can model many problems which have dynamic programming solutions. In fact, recurrence (7) can be solved by finding a shortest path on such a graph.
Reference: [8] <author> P. G. Bradford, G. J. E. Rawlins and G. E. Shannon: </author> <title> "Matrix Chain Ordering in Polylog Time with n=lg n Processors," </title> <type> Technical Report # 369, </type> <month> December </month> <year> 1992, </year> <note> also updated version submitted. </note>
Reference-contexts: This lower bound shows that Hu and Shing's O (n lg n) algorithm [19, 20, 21] is asymptotically optimal and Ramanan's parallel algorithm [26, 27] is an O (lg 3 n) factor from optimal. In addition, Bradford, Rawlins and Shannon's parallel algorithm <ref> [7, 8] </ref> is an O (lg n) factor from optimal and would be asymptotically optimal if an asymptotically optimal O (lg n) time parallel algorithm for computing row minima on totally monotone matrices is found [1, 3, 2].
Reference: [9] <author> P. G. Bradford, G. J. E. Rawlins and G. E. Shannon: </author> <title> "Efficient Matrix Chain Ordering in Polylog Time," </title> <month> July, </month> <year> 1993. </year>
Reference-contexts: This technique generates instances of the MCOP that exhibit the "father-son" relationship of [21], which was used for the sequential solution of the MCOP by Hu and Shing [20, 21]. In parallel, different methods can be applied for dealing with these instances <ref> [7, 9] </ref>. Instances of the MCOP with some negative t values can also be generated with a similar method to the one just outlined. For instance, we can start with an (n + 1)-gon generated by the algorithm of Figure 4. <p> 0.) t [3] 6 j t [1] 6 j t [5] 8 j t [3] 8 + t [2] 8 + t [1] 8 j t [7] 10 j t [5] 10 + t [4] 10 + t [3] 10 + t [2] 10 + t [1] 10 j t <ref> [9] </ref> 12 j t [7] 12 + t [6] 12 + t [5] 12 + t [4] 12 + t [3] 12 + t [2] 12 + t [1] 12 j Now, considering the columns (still assuming they each have a non-negative sum) and when t [i 3] i &gt; 0 <p> This problem models many problems that are often solved using dynamic programming. 3.2 A Model for the MCOP This subsection follows <ref> [6, 7, 9] </ref> very closely. Here a graph problem is given that can model many problems which have dynamic programming solutions. In fact, recurrence (7) can be solved by finding a shortest path on such a graph. <p> From the results of this paper, using a fixed or logarithmic radix model to improve these algorithms is not reasonable. But, other properties of the MCOP might give better bounds for this problem. For example, take the following, Theorem 15 (Bradford et al. <ref> [9] </ref>) The problem of edge minimizing m jumpers in n unit rows can be reduced to the problem of finding the row minima of an m fi n totally monotone matrix.
Reference: [10] <author> F. Y. Chin: </author> <title> "An O(n) Algorithm for Determining Near-Optimal Computation Order of Matrix Chain Products," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 21, No. 7, </volume> <pages> 544-549, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: Let d i ; d i+1 ; and d i+2 be three adjacent matrix dimensions in an instance of the MCOP where d i &lt; d i+1 and d i+1 &gt; d i+2 , in addition, let d fl = min 1in+1 Theorem 2 (Chin <ref> [10] </ref>; and Hu and Shing [18, 17]) If d fl d i d i+2 + d i d i+1 d i+2 &lt; d fl d i d i+1 + d fl d i+1 d i+2 then the product (M i * M i+1 ) is in an optimal parenthesization. <p> A proof of this theorem is left to the literature, see <ref> [10] </ref> and [18, 17] for different proofs. The basic intuition is that since d fl is the smallest matrix dimension, then replacing d fl with any larger matrix dimension will not change the inequality of Theorem 2. <p> Theorem 2 leads directly to sequential and parallel approximation algorithms for solving the MCOP to within 15.5 % of optimal <ref> [10, 18, 12, 6] </ref>. Given only a sequence of integers representing the depth of parentheses in an associative product (for example see the bottom row in Figure 1), then using a stack, for each parenthesis we can compute its matching parenthesis (see the top row in Figure 1). <p> The t [1]s are directly based on inequality (1). In fact, the t [1] values are the key to the approximation algorithms for the MCOP <ref> [10, 18, 12, 6] </ref>.
Reference: [11] <author> T. H. Cormen, C. E. Leiserson and R. L. Rivest: </author> <title> Introduction to Algorithms, </title> <publisher> McGraw Hill, </publisher> <year> 1990. </year>
Reference-contexts: 1 Introduction The matrix chain ordering problem (MCOP) is to find the cheapest way to multiply a chain of n matrices, where the matrices are pairwise compatible but of varying dimensions <ref> [11] </ref>. There has been significant research on the MCOP, take for example [6, 7, 8, 10, 12, 13, 15, 16, 18, 20, 21, 24, 25, 26, 27, 28, 29, 31]. The MCOP is also the focus of much pedagogy because of its amenability to an elementary dynamic programming solution. <p> See also <ref> [11] </ref>. Any chain of n pairwise compatible matrices M 1 ; M 2 ; ; M n , has n + 1 dimensions which we write as d 1 ; d 2 ; ; d n+1 . <p> MCOP, the corresponding (n + 1)-gon is made by putting the dimensions, in their given order, above the x-axis at a height corresponding to their size, and placing equal length edges between d i and d (i mod (n+1))+1 , for i such that n + 1 i 1, see <ref> [11, 20] </ref>. (To aviod intersecting lines, some geometric manipulation may have to be done.) Now the dimensions are renumbered as described above and they are called polygon weights which are written as ws.
Reference: [12] <author> A. Czumaj: </author> <title> "An Optimal Parallel Algorithm for Computing a Near-Optimal Order of Matrix Multiplications," </title> <publisher> SWAT, Springer Verlag, </publisher> <pages> LNCS # 621 , 62-72, </pages> <year> 1992. </year>
Reference-contexts: Theorem 1 also leads directly to a simple parallel lower bound for the MCOP directly from Berkman et al.'s parallel processor lower bound for triangulating a monotone polygon [5]. That is, the parallel approximation algorithms of Czumaj <ref> [12] </ref> and Bradford [6] cannot run faster than (lg lg n) time using O (n lg c n) processors on the CRCW PRAM for c a constant where c &gt; 0. <p> Theorem 2 leads directly to sequential and parallel approximation algorithms for solving the MCOP to within 15.5 % of optimal <ref> [10, 18, 12, 6] </ref>. Given only a sequence of integers representing the depth of parentheses in an associative product (for example see the bottom row in Figure 1), then using a stack, for each parenthesis we can compute its matching parenthesis (see the top row in Figure 1). <p> The t [1]s are directly based on inequality (1). In fact, the t [1] values are the key to the approximation algorithms for the MCOP <ref> [10, 18, 12, 6] </ref>.
Reference: [13] <author> A. Czumaj: </author> <title> "Parallel algorithm for the matrix chain product and the optimal triangulation problem," </title> <booktitle> STACS, </booktitle> <publisher> Springer Verlag, LNCS # 665, </publisher> <pages> 294-305, </pages> <year> 1993. </year>
Reference: [14] <author> L. E. Deimel, Jr. and T. A. Lampe: </author> <title> "An Invariance Theorem Concerning Optimal Computation of Matrix Chain Products," </title> <institution> North Carolina State Univ. </institution> <note> Tech Report # TR79-14. </note>
Reference-contexts: This algorithm is shown to produce instances of the MCOP with exponential dimensions in n. Given an instance of the MCOP we will look at the corresponding problem of finding an optimal triangulation of a convex polygon with integer vertices. 3 Theorem 1 (Deimel and Lampe <ref> [14] </ref>; Hu and Shing [20]) Determining the optimal order to multiply n matrices can be done by finding an optimal triangulation of a corresponding (n + 1)-gon. See also [11].
Reference: [15] <author> S.-H. S. Huang, H. Liu, V. Viswanathan: </author> <title> "Parallel Dynamic Programming," </title> <booktitle> Proceedings of the 2 nd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> 497-500, </pages> <year> 1990. </year>
Reference: [16] <author> S.-H. S. Huang, H. Liu, V. Viswanathan: </author> <title> "A Sublinear Parallel Algorithm for Some Dynamic Programming Problems," </title> <journal> Theoretical Computer Science, </journal> <volume> Vol. 106, </volume> <pages> 361-371, </pages> <year> 1992. </year>
Reference: [17] <author> T. C. Hu: </author> <title> Combinatorial Algorithms, </title> <publisher> Addison-Wesley, </publisher> <year> 1982. </year>
Reference-contexts: Let d i ; d i+1 ; and d i+2 be three adjacent matrix dimensions in an instance of the MCOP where d i &lt; d i+1 and d i+1 &gt; d i+2 , in addition, let d fl = min 1in+1 Theorem 2 (Chin [10]; and Hu and Shing <ref> [18, 17] </ref>) If d fl d i d i+2 + d i d i+1 d i+2 &lt; d fl d i d i+1 + d fl d i+1 d i+2 then the product (M i * M i+1 ) is in an optimal parenthesization. <p> A proof of this theorem is left to the literature, see [10] and <ref> [18, 17] </ref> for different proofs. The basic intuition is that since d fl is the smallest matrix dimension, then replacing d fl with any larger matrix dimension will not change the inequality of Theorem 2.
Reference: [18] <author> T. C. Hu and M. T. Shing: </author> <title> "An O(n) Algorithm to Find a Near-Optimum Partition of a Convex Polygon," </title> <journal> J. of Algorithms, </journal> <volume> Vol. 2, </volume> <pages> 122-138, </pages> <year> 1981. </year> <month> 30 </month>
Reference-contexts: Let d i ; d i+1 ; and d i+2 be three adjacent matrix dimensions in an instance of the MCOP where d i &lt; d i+1 and d i+1 &gt; d i+2 , in addition, let d fl = min 1in+1 Theorem 2 (Chin [10]; and Hu and Shing <ref> [18, 17] </ref>) If d fl d i d i+2 + d i d i+1 d i+2 &lt; d fl d i d i+1 + d fl d i+1 d i+2 then the product (M i * M i+1 ) is in an optimal parenthesization. <p> A proof of this theorem is left to the literature, see [10] and <ref> [18, 17] </ref> for different proofs. The basic intuition is that since d fl is the smallest matrix dimension, then replacing d fl with any larger matrix dimension will not change the inequality of Theorem 2. <p> Theorem 2 leads directly to sequential and parallel approximation algorithms for solving the MCOP to within 15.5 % of optimal <ref> [10, 18, 12, 6] </ref>. Given only a sequence of integers representing the depth of parentheses in an associative product (for example see the bottom row in Figure 1), then using a stack, for each parenthesis we can compute its matching parenthesis (see the top row in Figure 1). <p> Taking particular care to put the odd numbered weights on the left side of the polygon and the even numbered weights on the right side of the polygon gives an alternating monotone polygon, also see <ref> [18] </ref>. 6 The algorithm in Figure 4 seems to be due to Chin or Hu and Shing, but to our knowledge it was never published 1 . The algorithm in Figure 4 is invoked with some w 1 2. <p> The t [1]s are directly based on inequality (1). In fact, the t [1] values are the key to the approximation algorithms for the MCOP <ref> [10, 18, 12, 6] </ref>. <p> Directly by the work of Hu and Shing <ref> [18, 20, 21] </ref>, it is easy to see that for any possible parenthesization of n elements, there is an instance of the MCOP that has as an optimal parenthesization. In particular, consider the following theorem.
Reference: [19] <author> T. C. Hu and M. T. Shing: </author> <title> "Some Theorems about Matrix Multiplication," </title> <booktitle> Proceedings of the 21 st Annual IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> 28-35, </pages> <year> 1980. </year>
Reference-contexts: To the authors' knowledge, the class of problems that this lower bound applies to includes all presently known algorithms for solving the MCOP. This lower bound shows that Hu and Shing's O (n lg n) algorithm <ref> [19, 20, 21] </ref> is asymptotically optimal and Ramanan's parallel algorithm [26, 27] is an O (lg 3 n) factor from optimal. <p> This is shown the next subsections. 2.2 The Exponential Size of a Class of Inputs for the MCOP This subsection shows that there are instances of the MCOP that must have their dimensions exponential in n. The notion of H-arc and V-arc, from Hu and Shing <ref> [19, 20] </ref>, is central to lots of work on the MCOP. Given four weights w i+1 &gt; w i &gt; w i1 and w i2 which form a quadrilateral in a monotone (n + 1)-gon, then there are two possibilities in triangulating this quadrilateral. <p> In general, take any four weights w i ; w j ; w s ; and w t inscribing a quadrilateral in an (n + 1)-gon. With this, the formal definition of H-arcs and V-arcs is <ref> [19, 20] </ref>, * w s |w t is an H-arc iff minf w i ; w j g &lt; minf w s ; w t g and maxf w s ; w t g &lt; maxf w i ; w j g. * w s |w t is a V-arc iff
Reference: [20] <author> T. C. Hu and M. T. Shing: </author> <title> "Computation of Matrix Product Chains. Part I," </title> <journal> SIAM J. on Computing, </journal> <volume> Vol. 11, No. 3, </volume> <pages> 362-373, </pages> <year> 1982. </year>
Reference-contexts: Science, Indiana University, 215 Lindley Hall, Bloomington, Indiana 47405. email: choppell@cs.indiana.edu. x Department of Computer Science, Indiana University, 215 Lindley Hall, Bloomington, Indiana 47405. email: rawlins@cs.indiana.edu. 1 instances of the MCOP limited to those that can be represented in a fixed radix model, Hu and Shing's algorithm for the MCOP <ref> [20, 21] </ref> is asymptotically optimal. A nave information-theoretic lower bound fails: solving the MCOP distinguishes one of a Catalan number of possible valid parenthesizations. <p> To the authors' knowledge, the class of problems that this lower bound applies to includes all presently known algorithms for solving the MCOP. This lower bound shows that Hu and Shing's O (n lg n) algorithm <ref> [19, 20, 21] </ref> is asymptotically optimal and Ramanan's parallel algorithm [26, 27] is an O (lg 3 n) factor from optimal. <p> Given an instance of the MCOP we will look at the corresponding problem of finding an optimal triangulation of a convex polygon with integer vertices. 3 Theorem 1 (Deimel and Lampe [14]; Hu and Shing <ref> [20] </ref>) Determining the optimal order to multiply n matrices can be done by finding an optimal triangulation of a corresponding (n + 1)-gon. See also [11]. <p> MCOP, the corresponding (n + 1)-gon is made by putting the dimensions, in their given order, above the x-axis at a height corresponding to their size, and placing equal length edges between d i and d (i mod (n+1))+1 , for i such that n + 1 i 1, see <ref> [11, 20] </ref>. (To aviod intersecting lines, some geometric manipulation may have to be done.) Now the dimensions are renumbered as described above and they are called polygon weights which are written as ws. <p> This is shown the next subsections. 2.2 The Exponential Size of a Class of Inputs for the MCOP This subsection shows that there are instances of the MCOP that must have their dimensions exponential in n. The notion of H-arc and V-arc, from Hu and Shing <ref> [19, 20] </ref>, is central to lots of work on the MCOP. Given four weights w i+1 &gt; w i &gt; w i1 and w i2 which form a quadrilateral in a monotone (n + 1)-gon, then there are two possibilities in triangulating this quadrilateral. <p> In general, take any four weights w i ; w j ; w s ; and w t inscribing a quadrilateral in an (n + 1)-gon. With this, the formal definition of H-arcs and V-arcs is <ref> [19, 20] </ref>, * w s |w t is an H-arc iff minf w i ; w j g &lt; minf w s ; w t g and maxf w s ; w t g &lt; maxf w i ; w j g. * w s |w t is a V-arc iff <p> This formal definition includes squares inscribable in multi-modal (n + 1)-gons. Theorem 4 (Hu and Shing <ref> [20] </ref>) Any (n + 1)-gon whose optimal triangulation corresponds to the solution of an instance the MCOP is made of only H-arcs and V-arcs. The next corollary is an immediate consequence of the last theorem. <p> For example, Figure 9 contains a polygon that has a t-table with two extended canonical sets of columns. This figure assumes that each of the two bumps in the weight list forms an optimal alternating product on its own <ref> [20] </ref>. In particular, the columns of weights w 4 ; w 6 ; and w 8 form one extended canonical set and the columns of weights w 5 ; w 7 ; and w 9 form the other set. <p> This technique generates instances of the MCOP that exhibit the "father-son" relationship of [21], which was used for the sequential solution of the MCOP by Hu and Shing <ref> [20, 21] </ref>. In parallel, different methods can be applied for dealing with these instances [7, 9]. Instances of the MCOP with some negative t values can also be generated with a similar method to the one just outlined. <p> Directly by the work of Hu and Shing <ref> [18, 20, 21] </ref>, it is easy to see that for any possible parenthesization of n elements, there is an instance of the MCOP that has as an optimal parenthesization. In particular, consider the following theorem. <p> Directly by the work of Hu and Shing [18, 20, 21], it is easy to see that for any possible parenthesization of n elements, there is an instance of the MCOP that has as an optimal parenthesization. In particular, consider the following theorem. Theorem 11 (Hu and Shing <ref> [20] </ref>) Given a matrix dimension list w 1 ; : : : ; w n+1 with the three smallest dimensions w 1 &lt; w 2 &lt; w 3 , then the products w 1 w 2 and w 1 w 3 are in some associative product (s) in an optimal parenthesization. <p> Corollary 5 In the worst case solving the MCOP takes (n 2 ) bit operations. Corollary 5 is asymptotically tight since in <ref> [20, 21] </ref> Hu and Shing give an algorithm for solving the monotone (n + 1)-gon triangulation problem in O (n) atomic operations. In addition, just to verify that an (n + 1)-gon is monotone costs fi (n). <p> A canonical subgraph of the form D (i;t) (j;j+1) , is a leaf canonical subgraph and is written D (i;t) . It has the same nodes and edges as D (i; t). It turns out that these bands and leaf subgraphs together form trees <ref> [20, 21, 6] </ref>. ANSV matches and the four corresponding critical nodes are circled in D n . Notice the tree structure that canonical graphs form in Figure 18. A proof of the next theorem is straightforward examining recurrence (7).
Reference: [21] <author> T. C. Hu and M. T. Shing: </author> <title> "Computation of Matrix Product Chains. Part II," </title> <journal> SIAM J. on Computing, </journal> <volume> Vol. 13, No. 2, </volume> <pages> 228-251, </pages> <year> 1984. </year>
Reference-contexts: Science, Indiana University, 215 Lindley Hall, Bloomington, Indiana 47405. email: choppell@cs.indiana.edu. x Department of Computer Science, Indiana University, 215 Lindley Hall, Bloomington, Indiana 47405. email: rawlins@cs.indiana.edu. 1 instances of the MCOP limited to those that can be represented in a fixed radix model, Hu and Shing's algorithm for the MCOP <ref> [20, 21] </ref> is asymptotically optimal. A nave information-theoretic lower bound fails: solving the MCOP distinguishes one of a Catalan number of possible valid parenthesizations. <p> To the authors' knowledge, the class of problems that this lower bound applies to includes all presently known algorithms for solving the MCOP. This lower bound shows that Hu and Shing's O (n lg n) algorithm <ref> [19, 20, 21] </ref> is asymptotically optimal and Ramanan's parallel algorithm [26, 27] is an O (lg 3 n) factor from optimal. <p> In order to have as many alternating products as possible, we include the product made up by the dimensions w i ; w j ; and w k . (See Hu and Shing <ref> [21, Page 233] </ref> for a similar notion.) The contribution of a triangle with vertices w i ; w j ; and w k ; relative to w 1 , such that w j = maxf w i ; w j ; w k g, is measured by t [1] j = <p> Now we can insert l 00 into l 0 below the H-arc between w k+1 and w k+2 giving a new polygon. This technique generates instances of the MCOP that exhibit the "father-son" relationship of <ref> [21] </ref>, which was used for the sequential solution of the MCOP by Hu and Shing [20, 21]. In parallel, different methods can be applied for dealing with these instances [7, 9]. <p> This technique generates instances of the MCOP that exhibit the "father-son" relationship of [21], which was used for the sequential solution of the MCOP by Hu and Shing <ref> [20, 21] </ref>. In parallel, different methods can be applied for dealing with these instances [7, 9]. Instances of the MCOP with some negative t values can also be generated with a similar method to the one just outlined. <p> Directly by the work of Hu and Shing <ref> [18, 20, 21] </ref>, it is easy to see that for any possible parenthesization of n elements, there is an instance of the MCOP that has as an optimal parenthesization. In particular, consider the following theorem. <p> Corollary 5 In the worst case solving the MCOP takes (n 2 ) bit operations. Corollary 5 is asymptotically tight since in <ref> [20, 21] </ref> Hu and Shing give an algorithm for solving the monotone (n + 1)-gon triangulation problem in O (n) atomic operations. In addition, just to verify that an (n + 1)-gon is monotone costs fi (n). <p> A canonical subgraph of the form D (i;t) (j;j+1) , is a leaf canonical subgraph and is written D (i;t) . It has the same nodes and edges as D (i; t). It turns out that these bands and leaf subgraphs together form trees <ref> [20, 21, 6] </ref>. ANSV matches and the four corresponding critical nodes are circled in D n . Notice the tree structure that canonical graphs form in Figure 18. A proof of the next theorem is straightforward examining recurrence (7).
Reference: [22] <author> M. Marcus: </author> <title> Introduction to Modern Algebra, </title> <publisher> Marcel Dekker, </publisher> <year> 1978. </year>
Reference-contexts: There is an associative binary operator "*" on R satisfying the following conditions <ref> [22] </ref>: 1. If (a; b) 2 R, then a * b 2 S. 2. (a * b; c) 2 R iff (a; b * c) 2 R and (a * b) * c = a * (b * c). 3.
Reference: [23] <author> F. P. Preparata and M. I. Shamos: </author> <title> Computational Geometry|An Introduction, </title> <publisher> Springer Ver-lag, </publisher> <year> 1985. </year>
Reference-contexts: Next, using the three weights w 1 ; w j ; w k try to generate the next higher weight and place it appropriately on the list of polygon nodes. Generating weights in this fashion and appropriately alternating them from side to side gives a simple monotone polygon <ref> [23] </ref>.
Reference: [24] <author> P. Ramanan: </author> <title> "Obtaining Lower Bounds Using Artificial Components," </title> <journal> Information Processing Letters, </journal> <volume> Vol. 24, </volume> <pages> 243-246, </pages> <year> 1987. </year>
Reference-contexts: A. C.-C. Yao's work on decision trees has played an important role in the development of good lower bounds for a variety of problems. Building on Yao's work, Ramanan gives tight lower bounds to problems related to the matrix chain ordering problem in <ref> [24] </ref>.
Reference: [25] <author> P. Ramanan: </author> <title> "A New Lower Bound Technique and its Application: Tight Lower Bounds for a Polygon Triangularization Problem," </title> <booktitle> Proceedings of the Second Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> 281-290, </pages> <year> 1991. </year>
Reference-contexts: A. C.-C. Yao's work on decision trees has played an important role in the development of good lower bounds for a variety of problems. Building on Yao's work, Ramanan gives tight lower bounds to problems related to the matrix chain ordering problem in [24]. In addition, in <ref> [25] </ref>, Ramanan shows these techniques give a lower bound such that, 2 "If we could extend our lower bound technique to bounded degree algebraic decision trees, we would have a tight (n lg n) lower bound for the [MCOP]." Ramanan's lower bound techniques work on problems that seem to be close
Reference: [26] <author> P. Ramanan: </author> <title> "An Efficient Parallel Algorithm for Finding an Optimal Order of Computing a Matrix Chain Product," </title> <type> Technical Report, </type> <institution> WSUCS-92-2, Wichita State University, </institution> <month> June, </month> <year> 1992. </year>
Reference-contexts: To the authors' knowledge, the class of problems that this lower bound applies to includes all presently known algorithms for solving the MCOP. This lower bound shows that Hu and Shing's O (n lg n) algorithm [19, 20, 21] is asymptotically optimal and Ramanan's parallel algorithm <ref> [26, 27] </ref> is an O (lg 3 n) factor from optimal.
Reference: [27] <author> P. Ramanan: </author> <title> "An Efficient Parallel Algorithm for the Matrix Chain Product Problem," </title> <type> Technical Report, </type> <institution> WSUCS-93-1, Wichita State University, </institution> <month> January, </month> <year> 1993. </year>
Reference-contexts: To the authors' knowledge, the class of problems that this lower bound applies to includes all presently known algorithms for solving the MCOP. This lower bound shows that Hu and Shing's O (n lg n) algorithm [19, 20, 21] is asymptotically optimal and Ramanan's parallel algorithm <ref> [26, 27] </ref> is an O (lg 3 n) factor from optimal.
Reference: [28] <author> W. Rytter: </author> <title> "On Efficient Parallel Computation for Some Dynamic Programming Problems," </title> <journal> Theoretical Computer Science, </journal> <volume> Vol. 59, </volume> <pages> 297-307, </pages> <year> 1988. </year>
Reference: [29] <author> L. G. Valiant, S. Skyum, S. Berkowitz and C. Rackoff: </author> <title> "Fast Parallel Computation of Polynomials Using Few Processors," </title> <journal> SIAM J. on Computing, </journal> <volume> Vol. 12, No. 4, </volume> <pages> 641-644, </pages> <month> Nov. </month> <year> 1983. </year>
Reference: [30] <author> A. C.-C. Yao: </author> <title> "Lower bounds for Algebraic Computation Trees with Integer Inputs," </title> <journal> SIAM J. of Computing, </journal> <volume> Vol. 20, No. 4, </volume> <pages> 655-668, </pages> <year> 1991. </year>
Reference: [31] <author> F. F. Yao: </author> <title> "Speed-Up in Dynamic Programming," </title> <journal> SIAM J. on Algebraic and Discrete Methods, </journal> <volume> Vol. 3, No. 4, </volume> <pages> 532-540, </pages> <year> 1982. </year> <month> 31 </month>
References-found: 31

