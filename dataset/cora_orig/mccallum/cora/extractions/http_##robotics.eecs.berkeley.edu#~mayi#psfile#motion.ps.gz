URL: http://robotics.eecs.berkeley.edu/~mayi/psfile/motion.ps.gz
Refering-URL: http://robotics.eecs.berkeley.edu/~mayi/publication.html
Root-URL: 
Email: fmayi, janka, sastryg@robotics.eecs.berkeley.edu  
Title: Motion Recovery From Image Sequences: Discrete Viewpoint vs. Differential Viewpoint  
Author: Yi Ma Jana Kosecka Shankar Sastry 
Date: February 12, 1998  
Address: Berkeley, CA 94720-1774  
Affiliation: Electronics Research Laboratory University of California at Berkeley  
Abstract: The aim of this paper is to explore intrinsic geometric methods of recovering the three dimensional motion of a moving camera from a sequence of images. Generic similarities between the discrete approach and the differential approach are revealed through a parallel development of their analogous motion estimation theories. We begin with a brief review of the (discrete) essential matrix approach, showing how to recover the 3D displacement from image correspondences. The space of normalized essential matrices is characterized geometrically: the unit tangent bundle of the rotation group is a double covering of the space of normalized essential matrices. This characterization naturally explains the geometry of the possible number of 3D displacements which can be obtained from the essential matrix. Second, a differential version of the essential matrix constraint previously explored by [21, 22] is introduced in a isomorphic section. We then present the precise characterization of the space of differential essential matrices, which gives rise to a novel eigenvector-decomposition-based 3D velocity estimation algorithm from the optical flow measurements. This algorithm gives a unique solution to the motion estimation problem and serves as a differential counterpart of the SVD-based 3D displacement estimation algorithm from the discrete case. Finally, simulation results are presented evaluating the performance of our algorithm in terms of bias and sensitivity of the estimates with respect to the noise in optical flow measurements. Future work will apply these results to cooperate vision with other inertial navigation sensors to recover 3D motion and orientation of mobile robots. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> William M. Boothby. </author> <title> An Introduction to Differential Manifolds and Riemannian Geometry. </title> <publisher> Academic Press, </publisher> <address> second edition, </address> <year> 1986. </year>
Reference-contexts: It is known from differential geometry that the set of tangent vectors (the tangent space) of the rotation group SO (3) at the identity element e, is the set of skew matrices so (3) (see Boothby <ref> [1] </ref>), that is: T e (SO (3)) = so (3): (24) Since SO (3) is a Lie group, the tangent space at any point R 2 SO (3) is given by the push-forward map: T R (SO (3)) = R fl (so (3)) = fRSjS 2 so (3)g: (25) It is <p> Proof: The compactness is trivial. That E 1 is embedded in R 3fi3 follows from the fact that, if F : N ! M is a one-to-one immersion and N is compact, then F is an embedding (see Boothby <ref> [1] </ref>). This property validates potential motion estimation algorithms which might require certain smoothness or regularity on the space of the parameters to be estimated. 2.3 Algorithm In this section, we introduce the three-step SVD-based 3D displacement estimation algorithm pro posed by Toscani and Faugeras [19].
Reference: [2] <author> Michael J. Brooks, Wojciech Chojnacki, and Luis Baumela. </author> <title> Determining the ego-motion of an uncalibrated camera from instantaneous optical flow. </title> <publisher> in press, </publisher> <year> 1997. </year>
Reference-contexts: The motion estimation algorithm can thus be dramatically simplified. The differential approach developed in this paper can also be generalized to uncalibrated camera <ref> [21, 2] </ref>. <p> is given by a linear transformation specified by the so-called intrinsic-parameter matrix of the camera: A = @ 0 s 2 s 1 i 2 1 For a general treatment of the camera self-calibration in the differential case, one should refer to Vieville and Faugeras [21] and Brooks et al <ref> [2] </ref>. Here we assume A is time-invariant. <p> Note that the fundamental matrix F has an asymmetric part and symmetric part, as the essential matrix does. Such matrices have at most eight degrees of freedom. Actually, it is shown by Brooks et al <ref> [2] </ref> that the set of all F is only a 7-dimensional submanifold in R 9 , i.e. it has 7 degrees of freedom. However, F (with normalized linear velocity v) is a function of 10 free parameters, 5 25 for motion and 5 for camera intrinsic parameters. <p> Some interesting and solvable cases have been studied by Brooks et al in <ref> [2] </ref>. 4.3 Experimental Results We carried out initial simulations in order to study the performance of our algorithm. We chose to evaluate it in terms of bias and sensitivity of the estimate with respect to the noise in the optical flow measurements. <p> In this paper, we have assumed that the camera is ideal. This approach can be extended to uncalibrated camera case, where the motion estimation and camera self-calibration problem can be solved simultaneously, using the differential essential constraint <ref> [21, 2] </ref>. In this case, the essential matrix is replaced by the 27 fundamental matrix which captures both motion information and camera intrinsic parameters. It is shown in [2], that the space of such fundamental matrices is a 7-dimensional algebraic variety in R 3fi3 . <p> In this case, the essential matrix is replaced by the 27 fundamental matrix which captures both motion information and camera intrinsic parameters. It is shown in <ref> [2] </ref>, that the space of such fundamental matrices is a 7-dimensional algebraic variety in R 3fi3 . Thus, besides five motion parameters, only two extra intrinsic parameters can be recovered.
Reference: [3] <author> A. R. Bruss and B. K. Horn. </author> <title> Passive navigation. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 21 </volume> <pages> 3-20, </pages> <year> 1983. </year>
Reference-contexts: Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn <ref> [3] </ref>) or linear subspace methods (Heeger and Jepson [4, 5]). Kanatani [6] proposed a linear algorithm reformulating Zhuang's approach in terms of essential parameters and twisted flow.
Reference: [4] <author> D. J. Heeger and A. D. Jepson. </author> <title> Subspace methods for recovering rigid motion I: Algorithm and implementation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(2) </volume> <pages> 95-117, </pages> <year> 1992. </year>
Reference-contexts: Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn [3]) or linear subspace methods (Heeger and Jepson <ref> [4, 5] </ref>). Kanatani [6] proposed a linear algorithm reformulating Zhuang's approach in terms of essential parameters and twisted flow. <p> However, as in the discrete case, one can get rid of the ambiguous solution by adding the "positive depth constraint". Remark 5 By the way of comparison to the Heeger and Jepson's algorithm <ref> [4] </ref>, note that the equation (82) may be rewritten to highlight the dependence on optical flow as: [A 1 (u) j A 2 ] e = 0 (97) where A 1 (u) 2 R mfi3 is a linear function of the measured optical flow and A 2 2 R mfi6 is
Reference: [5] <author> A. D. Jepson and D. J. Heeger. </author> <title> Linear subspace methods for recovering translation direction. Spatial Vision in Humans and Robots, </title> <publisher> Cambridge Univ. Press, </publisher> <pages> pages 39-62, </pages> <year> 1993. </year>
Reference-contexts: Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn [3]) or linear subspace methods (Heeger and Jepson <ref> [4, 5] </ref>). Kanatani [6] proposed a linear algorithm reformulating Zhuang's approach in terms of essential parameters and twisted flow.
Reference: [6] <author> K. Kanatani. </author> <title> 3d interpretation of optical flow by renormalization. </title> <journal> International Journal of Computer Vision, </journal> <volume> 11(3) </volume> <pages> 267-282, </pages> <year> 1993. </year>
Reference-contexts: Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn [3]) or linear subspace methods (Heeger and Jepson [4, 5]). Kanatani <ref> [6] </ref> proposed a linear algorithm reformulating Zhuang's approach in terms of essential parameters and twisted flow. <p> Another potential way to improve this algorithm is to study the systematic bias introduced by the least square method in step 1. A similar problem has been studied by Kanatani <ref> [6] </ref> and an algorithm was proposed to remove such bias from Zhuang's algorithm [22]. 4 In order to guarantee v 0 to be of unit length, one needs to "re-normalize" e, i.e. multiply e by a scalar such that the vector determined by the first three entries is of unit length.
Reference: [7] <author> H. C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: Among the efforts to solve this problem, one of the more appealing approaches is the essential matrix approach, proposed by Longuet-Higgins, Huang and Faugeras et al in 1980s <ref> [7] </ref>. It shows that the relative 3D displacement of a camera can be recovered from an intrinsic geometric constraint between two images of the same scene, the so-called Longuet-Higgins constraint (also called the epipolar or essential constraint). <p> The image of the point q taken by the camera at the initial position then is q o = (q o ), and the image of the same point taken at the current position is q c = (q c ). It was first obtained by Longuet-Higgins <ref> [7] </ref> in 1981 that the two corresponding image points q o and q c have to satisfy a geometric constraint, the so-called Longuet-Higgins constraint: Theorem 1 (Longuet-Higgins Constraint) Let the 3D displacement of the frame F c relative to the frame F o be given by the rigid body motion g
Reference: [8] <author> Waxman A. M., Kamgar-Parsi B., and Subbarao M. </author> <title> Closed form solutions to image flow equations for 3d structure and motion. </title> <journal> International Journal of Computer Vision 1, </journal> <pages> pages 239-258, </pages> <year> 1987. </year>
Reference-contexts: This problem has also been explored by many researchers: an algorithm was proposed in 1984 by Zhuang et al [22] with a simplified version given in 1986 [23]; and a first order algorithm was given by Waxman et al <ref> [8] </ref> in 1987. Most of the algorithms start from the basic bilinear constraint relating optical flow to the linear and angular velocities and solve for rotation and translation separately using either numerical optimization techniques (Bruss and Horn [3]) or linear subspace methods (Heeger and Jepson [4, 5]).
Reference: [9] <author> Yi Ma, Jana Kosecka, and Shankar Sastry. </author> <title> Vision guided navigation for a nonholonomic mobile robot. </title> <institution> Electronic Research Laboratory Memorandum, UC Berkeley, UCB/ERL(M97/42), </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: Roughly speaking, these constraints confine the infinitesimal 3D motion but not the global motion of the mobile base (as an example of studying vision with nonholonomic constraints see Ma, Kosecka and Sastry <ref> [9] </ref>). A big advantage of the differential essential approach over the discrete one is that it can make use of these nonholonomic constraints and much simplify the motion estimation algorithms. We show this by an example of a kinematic aircraft. <p> An example study of vision guided nonholonomic system can be found in <ref> [9] </ref>. In this paper, we have assumed that the camera is ideal. This approach can be extended to uncalibrated camera case, where the motion estimation and camera self-calibration problem can be solved simultaneously, using the differential essential constraint [21, 2].
Reference: [10] <author> Stephen Maybank. </author> <title> Theory of Reconstruction from Image Motion. </title> <booktitle> Springer Series in Information Sciences. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <month> 28 </month>
Reference-contexts: The study of the essential matrix then led to a three-step SVD-based algorithm for recovering the 3D displacement from noisy image correspondences, proposed in 1986 by Toscani and Faugeras [19] and later summarized in Maybank <ref> [10] </ref>. Motivated by recent interests in dynamical motion estimation schemes (Soatto, Frezza and Perona [15]) which usually require smoothness and regularity of the parameter space, the geometric property of the essential matrix space is further explored: the unit tangent bundle of the rotation group, i.e. <p> For a detailed proof of this algorithm see Maybank <ref> [10] </ref>. Let E = R T ^p 2 R 3fi3 be the essential matrix associated with the Longuet-Higgins constraint (6). <p> However, since the measurements are usually noisy, there might not exist any solution of e for Ae = 0. In this case, we use the one which minimizes the error function kAek 2 . It is straight forward to know that (Theorem 6.1 of Maybank <ref> [10] </ref>): Lemma 3 If a matrix A 2 R nfin has the singular value decomposition A = U V T and c n (V ) is the n th column vector of V (the singular vector associated to the smallest singular value n ), then e = c n (V ) <p> For the proof of this theorem see Maybank <ref> [10] </ref>. We are finally ready to give the algorithm. Three-Step SVD-Based 3D Displacement Estimation Algorithm: 1. <p> Remark 2 Note that if E 2 E 1 satisfies the Longuet-Higgins constraint, so does E 2 E 1 . This introduces the so-called "twisted-pair" ambiguity (Maybank <ref> [10] </ref>). Thus, totally, we get four ambiguous solutions of the 3D displacement for a given set of image correspondences. However, after imposing the so-called "positive depth constraint", that all the points lie in front of the camera, the ambiguities will be resolved and there is only one best solution. <p> In the discrete case, there are two 3D displacements corresponding to an essential matrix. However, the velocity corresponding to a differential essential matrix is unique. This is because, in the differential case, the twist-pair ambiguity (see Maybank <ref> [10] </ref>), which is caused by a 180 ffi rotation of the camera around the translation direction, is avoided. It is clear that the normalized differential essential space E 0 1 is a 5-dimensional differentiable submanifold embedded in R 6fi3 . <p> Thus, for this algorithm, in general, the optical flow vectors of at least eight points are needed to recover the 3D velocity, i.e. m 8, although the minimum number of optical flows needed is 5 (see Maybank <ref> [10] </ref>). When the measurements are noisy, there might be no solution of e for Ae = 0. As in the discrete case, we choose the solution which minimizes the error function kAek 2 . This can be mechanized using Lemma 3.
Reference: [11] <author> Philip F. McLauchlan and David W. Murray. </author> <title> A unifying framework for structure and motion recovery from image sequences. </title> <booktitle> In Proceeding of Fifth International Conference on Computer Vision, </booktitle> <pages> pages 314-320, </pages> <address> Cambridge, MA, USA, 1995. </address> <publisher> IEEE Comput. Soc. Press. </publisher>
Reference-contexts: So the two are usually viewed as separate problems. In spite of the fact that the robustness of existing algorithms has been studied quite extensively, it has been suggested that the fact that the structure and motion estimation are decoupled typically hinders their performance <ref> [11] </ref>. Some algorithms address the problem of motion and structure (shape) recovery simultaneously either in batch [18] or recursive fashion [11]. <p> that the robustness of existing algorithms has been studied quite extensively, it has been suggested that the fact that the structure and motion estimation are decoupled typically hinders their performance <ref> [11] </ref>. Some algorithms address the problem of motion and structure (shape) recovery simultaneously either in batch [18] or recursive fashion [11]. The approaches to the motion estimation only, can be partitioned into the discrete and differential methods depending on whether they use as an input set of point correspondences or image velocities.
Reference: [12] <author> Richard M. Murray, Zexiang Li, and Shankar S. Sastry. </author> <title> A Mathematical Introduction to Robotic Manipulation. </title> <publisher> CRC press Inc., </publisher> <year> 1994. </year>
Reference-contexts: Actually, e ^p is given by the Rodrigues' formula: e ^p = I + ^p sin () + ^p 2 (1 cos ()): (15) For details, see Murray, Li and Sastry <ref> [12] </ref>. Lemma 1 Given any non-zero skew matrix S 2 so (3), if, for a rotation matrix R 2 SO (3), RS is also a skew matrix, then R = I or e ^p where ^p is the unit skew matrix associated with S. Further, e ^p S = S. <p> 2^p ^p = ^p: (20) According to Rodrigues' formula, we have: e 2^p = I + ^p sin (2) + ^p 2 (1 cos (2)) (21) (20) yields: ^p 2 sin (2) + ^p 3 (1 cos (2)) = 0: (22) Since ^p 2 and ^p 3 are linear independent <ref> [12] </ref>, we have sin (2) = 1 cos (2) = 0. That is, is equal to 2k or 2k + , k 2 Z. Therefore, R is equal to I or e ^p . <p> moving camera frame satisfy: q o = R (t)q c (t) + p (t): (40) Differentiating this equation yields: _q c = R T _ Rq c R T _p: (41) Since R T _ R 2 so (3) and R T _p 2 R 3 (see Murray et al <ref> [12] </ref>), we may define ! = (! 1 ; ! 2 ; ! 3 ) T 2 R 3 and v = (v 1 ; v 2 ; v 3 ) T 2 R 3 to be: The interpretation of these velocities is: ! is the angular velocity of the camera <p> Using the homogeneous representation for g (for a good reference on homogeneous representation see Murray, Li and Sastry <ref> [12] </ref>), the kinematic equations of the aircraft motion are given by: _g = g B @ ! 3 0 ! 1 0 0 0 0 0 C A (101) where ! 1 stands for pitch rate, ! 2 for roll rate, ! 3 for yaw rate and v 1 the velocity
Reference: [13] <author> Andrew Kelly Packard. </author> <title> What's new with : structured uncertainty in multivariable control. </title> <type> PhD thesis, </type> <institution> EECS, UC Berkeley, </institution> <year> 1988. </year>
Reference: [14] <author> Steven Thomas Smith. </author> <title> Geometric optimization methods for adaptive filtering. </title> <type> PhD thesis, </type> <institution> Division of Applied Sciences, Harvard University, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Taking the Riemannian metric induced from T 1 (SO (3)) for E 1 , it is then converted to an optimization problem on a Riemannian manifold, a topic which has been studied by Smith, Brockett et al <ref> [14] </ref>. A dynamic version of this algorithm which recursively estimates the essential vector e using implicit extended Kalman filter, the so-called essential filter, has been proposed by Soatto [15].
Reference: [15] <author> S. Soatto, R. Frezza, and P. Perona. </author> <title> Motion estimation via dynamic vision. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 41(3) </volume> <pages> 393-413, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: The study of the essential matrix then led to a three-step SVD-based algorithm for recovering the 3D displacement from noisy image correspondences, proposed in 1986 by Toscani and Faugeras [19] and later summarized in Maybank [10]. Motivated by recent interests in dynamical motion estimation schemes (Soatto, Frezza and Perona <ref> [15] </ref>) which usually require smoothness and regularity of the parameter space, the geometric property of the essential matrix space is further explored: the unit tangent bundle of the rotation group, i.e. T 1 (SO (3)), is a double covering of the space of normalized essential matrices. <p> However, the essential matrix approach based on the Longuet-Higgins constraint only recovers discrete 3D displacement. The velocity information can only be approximately obtained from the inverse of the exponential map, as Soatto et al did in <ref> [15] </ref>. In principle, the displacement estimation algorithms obtained by using epipolar constraints work well when the displacement (especially the translation) between the two images is relatively large. <p> A construction based on the SVD of the essential matrix is given in Soatto et al <ref> [15] </ref>. However, since the SVD of an essential matrix is not unique and the unitary matrices U; V associated with the SVD are in O (3) not necessarily in the rotation group SO (3), the proof given in [15] is not complete. <p> the SVD of the essential matrix is given in Soatto et al <ref> [15] </ref>. However, since the SVD of an essential matrix is not unique and the unitary matrices U; V associated with the SVD are in O (3) not necessarily in the rotation group SO (3), the proof given in [15] is not complete. In this section, we show that such construction actually depends on a stronger characterization of the essential matrix than the one given by Huang & Faugeras (Theorem 2). Based on this characterization, we give the proof for an explicit construction of the solutions. <p> This theorem gives a global characterization for the local coordinates assigned by Soatto et al in <ref> [15] </ref> to the essential space. Since T 1 (SO (3)) is a 5-dimensional connected compact manifold, we thus also have: Corollary 1 (Regularity of the Normalized Essential Space) The normalized essential space E 1 is a 5-dimensional connected compact differentiable manifold embedded in R 3fi3 . <p> A dynamic version of this algorithm which recursively estimates the essential vector e using implicit extended Kalman filter, the so-called essential filter, has been proposed by Soatto <ref> [15] </ref>. <p> This property is useful when using estimation schemes which require some regularity of the parameter space (for example, the dynamic estimation scheme proposed by Soatto et al <ref> [15] </ref>). 3.3 Algorithm Based on the previous study on the differential essential matrix, in this section, we propose an algorithm which recovers the 3D velocity of the camera from a set of (possibly noisy) optical flows. <p> There are infinite many pairs of (!; v) satisfying the same set of differential Longuet-Higgins constraints. However, it is shown by Soatto et al <ref> [15] </ref> that, in the dynamical estimation approach, one can actually make use of the noise in the measurements to obtain correct estimate of the rotational component R regardless the scale or accuracy of estimation of the translation vector p. The same should hold also in the differential case. <p> In order to exploit temporal coherence of motion and improve algorithm's robustness, a dynamic (recursive) motion estimation scheme, which uses implicit extended Kalman filter for estimating the essential parameters, has been proposed by Soatto et al <ref> [15] </ref> for the discrete case. The same ideas certainly apply to our algorithm.
Reference: [16] <author> Norman Steenrod. </author> <title> The Topology of Fiber Bundles. </title> <publisher> Princeton Mathematical Series. Princeton University Press, </publisher> <year> 1951. </year>
Reference-contexts: Thus, the tangent bundle (for a reference on fiber bundle theory see Steenrod <ref> [16] </ref>) of the rotation group SO (3), defined to be: T (SO (3)) = R2SO (3) is equivalent to the space SO (3) fi so (3) (Lie groups have trivial tangent bundles), which, in turn, can be used to represent the configuration space of a rigid body motion (the base point
Reference: [17] <author> T. Y. Tian, C. Tomasi, and D. J. Heeger. </author> <title> Comparison of approaches to egomotion computation. </title> <booktitle> In Proceedings of 1996 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 315-20, </pages> <address> Los Alamitos, CA, USA, 1996. </address> <publisher> IEEE Comput. Soc. Press. </publisher>
Reference-contexts: The image size was considered to be 512x512 pixels. Our algorithm has been implemented in Matlab and the simulations have been performed using example sets proposed by <ref> [17] </ref> in their paper on comparison of the egomotion estimation from optical flow 5 . The motion estimation was performed by observing the motion of a random cloud of points placed in front of the camera. <p> The presented results demonstrate the performance of the algorithm while translating along X-axis and rotating around Z-axis with rate of 23 o per frame. The analysis of the obtained results of the motion estimation algorithm was performed using benchmarks proposed by <ref> [17] </ref>. The bias is expressed as an angle between the average estimate out of all trails (for a given setting of parameters) and the true direction of translation and/or rotation. <p> The evaluation of the results and more extensive simulations are currently underway. We believe that through thorough understanding of the source of translational bias we can obtain even better 5 We would like to thank the authors in <ref> [17] </ref> for making the code for simulations of various algorithms and evaluation of their results available on the web. 26 the average translation and rotation. The ratio between the magnitude of linear and angular velocity is 1. the average translation and rotation.
Reference: [18] <author> Carlo Tomasi and Takeo Kanade. </author> <title> Shape and motion from image streams under orthography. </title> <journal> Intl. Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: Some algorithms address the problem of motion and structure (shape) recovery simultaneously either in batch <ref> [18] </ref> or recursive fashion [11]. The approaches to the motion estimation only, can be partitioned into the discrete and differential methods depending on whether they use as an input set of point correspondences or image velocities.
Reference: [19] <author> G. Toscani and O. D. Faugeras. </author> <title> Structure and motion from two noisy perspective images. </title> <booktitle> Proceedings of IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 221-227, </pages> <year> 1986. </year>
Reference-contexts: The study of the essential matrix then led to a three-step SVD-based algorithm for recovering the 3D displacement from noisy image correspondences, proposed in 1986 by Toscani and Faugeras <ref> [19] </ref> and later summarized in Maybank [10]. <p> This property validates potential motion estimation algorithms which might require certain smoothness or regularity on the space of the parameters to be estimated. 2.3 Algorithm In this section, we introduce the three-step SVD-based 3D displacement estimation algorithm pro posed by Toscani and Faugeras <ref> [19] </ref>. For a detailed proof of this algorithm see Maybank [10]. Let E = R T ^p 2 R 3fi3 be the essential matrix associated with the Longuet-Higgins constraint (6). <p> In addition, in the differential case understanding of the space of differential essential matrices leads to a new egomotion estimation algorithm, which is a natural counterpart of the three-step SVD based algorithm in developed for the discrete case by <ref> [19] </ref>. In order to exploit temporal coherence of motion and improve algorithm's robustness, a dynamic (recursive) motion estimation scheme, which uses implicit extended Kalman filter for estimating the essential parameters, has been proposed by Soatto et al [15] for the discrete case. The same ideas certainly apply to our algorithm.
Reference: [20] <author> Roger Y. Tsai and Thomas S. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects with curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-6(1):13-27, </volume> <month> January </month> <year> 1984. </year>
Reference-contexts: This endows the resulting motion estimation algorithms with some advantageous features: they do not need to assume any a priori knowledge of the scene; and are computationally simpler (comparing to most non-intrinsic motion estimation algorithms), using mostly linear algebraic techniques. Tsai and Huang <ref> [20] </ref> then proved that, given an essential matrix associated with the Longuet-Higgins constraint, there are only two possible 3D displacements.
Reference: [21] <author> T. Vieville and O. D. Faugeras. </author> <title> Motion analysis with a camera with unknown, and possibly varying intrinsic parameters. </title> <booktitle> Proceedings of Fifth International Conference on Computer Vision, </booktitle> <pages> pages 750-756, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The motion estimation algorithm can thus be dramatically simplified. The differential approach developed in this paper can also be generalized to uncalibrated camera <ref> [21, 2] </ref>. <p> image and the ideal image is given by a linear transformation specified by the so-called intrinsic-parameter matrix of the camera: A = @ 0 s 2 s 1 i 2 1 For a general treatment of the camera self-calibration in the differential case, one should refer to Vieville and Faugeras <ref> [21] </ref> and Brooks et al [2]. Here we assume A is time-invariant. <p> In this paper, we have assumed that the camera is ideal. This approach can be extended to uncalibrated camera case, where the motion estimation and camera self-calibration problem can be solved simultaneously, using the differential essential constraint <ref> [21, 2] </ref>. In this case, the essential matrix is replaced by the 27 fundamental matrix which captures both motion information and camera intrinsic parameters. It is shown in [2], that the space of such fundamental matrices is a 7-dimensional algebraic variety in R 3fi3 .
Reference: [22] <author> Xinhua Zhuang and R. M. Haralick. </author> <title> Rigid body motion and optical flow image. </title> <booktitle> Proceedings of the First International Conference on Artificial Intelligence Applications, </booktitle> <pages> pages 366-375, </pages> <year> 1984. </year>
Reference-contexts: A differential (or continuous) version of the 3D motion estimation problem is to recover the 3D velocity of the camera from optical flow. This problem has also been explored by many researchers: an algorithm was proposed in 1984 by Zhuang et al <ref> [22] </ref> with a simplified version given in 1986 [23]; and a first order algorithm was given by Waxman et al [8] in 1987. <p> Thus one can not directly use the previously derived results for special symmetric matrices to recover the 3D velocity. In the algorithms proposed in Zhuang <ref> [22, 23] </ref>, such s, with the linear velocity v obtained from the skew-symmetric part, is directly used to calculate the angular velocity !. <p> Another potential way to improve this algorithm is to study the systematic bias introduced by the least square method in step 1. A similar problem has been studied by Kanatani [6] and an algorithm was proposed to remove such bias from Zhuang's algorithm <ref> [22] </ref>. 4 In order to guarantee v 0 to be of unit length, one needs to "re-normalize" e, i.e. multiply e by a scalar such that the vector determined by the first three entries is of unit length. 22 Remark 4 Since both E; E 2 E 0 1 satisfy the
Reference: [23] <author> Xinhua Zhuang, Thomas S. Huang, and Narendra Ahuja. </author> <title> A simplified linear optic flow-motion algorithm. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 42 </volume> <pages> 334-344, </pages> <year> 1988. </year> <month> 29 </month>
Reference-contexts: This problem has also been explored by many researchers: an algorithm was proposed in 1984 by Zhuang et al [22] with a simplified version given in 1986 <ref> [23] </ref>; and a first order algorithm was given by Waxman et al [8] in 1987. <p> Thus one can not directly use the previously derived results for special symmetric matrices to recover the 3D velocity. In the algorithms proposed in Zhuang <ref> [22, 23] </ref>, such s, with the linear velocity v obtained from the skew-symmetric part, is directly used to calculate the angular velocity !.
References-found: 23

