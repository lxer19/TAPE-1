URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-96-1309/CS-TR-96-1309.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-96-1309/
Root-URL: http://www.cs.wisc.edu
Email: @cs.wisc.edu  
Title: Content-Based Queries in Image Databases  
Author: Uri Shaft and Raghu Ramakrishnan (uri, raghu) 
Note: Paper Number TR1309  
Date: March 19, 1996  
Affiliation: Computer Sciences Department Univ. of Wisconsin-Madison  
Abstract: Current image retrieval systems have many important limitations. Many are specialized for a particular class of images and/or queries. The more general systems support relatively weak querying by content (e.g., by color, texture or shape, but with no deeper understanding of the structure of the image). Few (if any) have addressed the issue of truly large collections of images, and how the underlying techniques scale. There are many aspects to a DBMS supporting image retrieval by content. In this paper, we focus on a data model and give an example of a data definition language (DDL) for image data, and demonstrate the gains to be had by incorporating such a DDL in a general-purpose image DBMS. Specifically, we make contributions in five areas: (1) A proposal for a data model for images. (2) The use of DDL definitions for guiding automatic feature extraction, using a constraint-based scheduling algorithm that calls upon a library of standard and specialized image analysis routines. (3) The use of extracted features (based on the data model and DDL definitions) in representing and indexing large sets of images, and in query formulation and evaluation. (4) A system architecture that supports the use of specialized feature extraction algorithms, which may be independently developed in various important application domains, and may rely upon domain-specific image analysis techniques. To our knowledge, this is the first proposal for the use of a non-trivial data model (coupled with an image description language) for processing large sets of images in a DBMS. We discuss the impact of the data model and the DDL on various aspects of the system, and experimentally demonstrate some major benefits of this approach. In particular, we show how very large image sets can be effectively queried | using meaningful, domain-specific restrictions on the attributes and relationships of objects contained in images | with users providing input only on a per-collection, rather than a per-image, basis. We show that the approach is scalable, and demonstrate that content-based querying of very large collections of images using a domain-independent image DBMS is a viable goal.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Barber, W. Equitz, C. Faloutsos, M. Flickner, W. Niblack, D. Petkovic, and P. Yanker, </author> <title> "Query by Content for Large On-Line Image Collections", </title> <type> IBM Technical Report RJ-9408, </type> <address> Yorktown Heights, NY, </address> <year> 1993 </year>
Reference-contexts: Section 6.1 uses the data model that comes with the PIQ system. In contrast we tried two other data models that are similar to what is available in the QBIC <ref> [1] </ref> system. These are discussed in Sections 6.2, 6.3 We show the results of the same similarity query for each of the data models. Section 6.4 describes two different similarity metrics that also use the PIQ data model. <p> of similarity that an "average user" may agree upon, but it is equally important to allow users to specify what they mean by "similar" when they need to do so. 6.2 Class Definition with Only Color The DDL class definition here is influenced by the data model of the QBIC <ref> [1] </ref> system. In the QBIC system all objects have the same type and the features that can be extracted for an object are limited to color, shape and texture. There is also a sketch attribute for entire images. <p> While we have thus far concentrated on a declarative DDL, it may well be that this must be complemented by a more procedural DDL in certain situations. 10 Related Work Perhaps the most sophisticated system supporting query by content over general image sets is QBIC <ref> [1] </ref>. QBIC automatically extracts the following attributes for images and for user-identified objects within images: color, shape, sketch and texture. We have followed QBIC with respect to how we handle color and shape attributes. A sketch in QBIC is a very reduced resolution edge-map.
Reference: [2] <author> Beckmann, N., Kriegel, H.P., Schneider, R., Seeger, B. </author> <title> "The R* Tree: An Efficient and Robust Access Method for Points and Rectangles", </title> <booktitle> Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <year> 1990. </year>
Reference: [3] <author> Carey, M., DeWitt, D., Franklin, M., Hall, N., McAuliffe, M., Naughton, J., Schuh, D., Solomon, M., Tan, C., Tsatalos,O., White, S., Zwilling, M. </author> <title> "Shoring up Persistent Objects", </title> <booktitle> Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <year> 1994. </year>
Reference: [4] <author> Chiueh, T., </author> <title> "Content-Based Image Indexing," </title> <booktitle> Proc. 20th Int. Conf. on Very Large Data Bases, </booktitle> <year> 1994. </year>
Reference: [5] <author> DeWitt, D., Kabra, N., Luo, J., Patel, J., Yu, J. </author> <title> "Client-Server Paradise", </title> <booktitle> Proc. 20th Int. Conf. on Very Large Data Bases, </booktitle> <year> 1994. </year>
Reference: [6] <author> Freeston, M.W., </author> <title> "The Bang File: A New Kind of Grid File," </title> <booktitle> Proc. ACM Sigmod Int. Conf. on Management of Data, </booktitle> <year> 1987. </year>
Reference: [7] <author> Goldstein, J., Ramakrishnan, R. and Yu, </author> <title> Jie-bing "Using Constraints to Query R* Trees", </title> <type> Manuscript. </type>
Reference: [8] <author> Grosky, </author> <title> W.I., "Toward a Data Model for Integrated Pictorial Databases," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> Vol. 25, No. 3, </volume> <pages> pp. 371-382, </pages> <year> 1984. </year>
Reference: [9] <author> Grosky, W.I., and Mehrotra, R., </author> <title> "Index-based Object Recognition in Pictorial Data Management," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> vol. 52, </volume> <pages> pp. 416-436, </pages> <year> 1990. </year>
Reference: [10] <author> Grosky, </author> <title> W.I., "Multimedia Information Systems," </title> <journal> IEEE MultiMedia Magazine, Vo1. </journal> <volume> 1, No. 1, </volume> <month> Spring </month> <year> 1994. </year>
Reference: [11] <author> A. Gupta, T. Weymouth, and R. Jain, </author> <title> "Semantic Queries with Pictures: the VIMSYS Model," </title> <booktitle> Proc. of the 17th Int. Conf. on Very Large Data Bases, </booktitle> <month> September </month> <year> 1991. </year>
Reference-contexts: Thus, queries about the relationships between component objects and their features cannot be posed. In PIQ, we have sought to address these two limitations of QBIC. A notable example of a system that is tailored to a specific domain of images is VIMSYS <ref> [11] </ref>. Although VIMSYS is specialized to a single domain (faces), a design objective was to collect all the domain-specific details into one module. The system performs well for the domain of faces.
Reference: [12] <author> Guttman, A. </author> <title> "R Trees: A Dynamic Index Structure for Spatial Searching," </title> <booktitle> Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <year> 1984. </year>
Reference: [13] <author> Hellerstein, J.M., </author> <title> "Practical Predicate Placement," </title> <booktitle> Proc. ACM Sigmod Int. Conf. on Management of Data, </booktitle> <year> 1994. </year> <month> 24 </month>
Reference: [14] <author> Jagadish, H.V. </author> <title> "A Retrieval Technique for Similar Shapes," </title> <booktitle> Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <year> 1991. </year>
Reference-contexts: Along with each vector, we store a pointer to the corresponding image and object. This idea (with only one vector per image) was proposed by Jagadish <ref> [14] </ref>, and is very promising. Our approach can be seen as a generalization of this idea in which an image is used to generate several vectors.
Reference: [15] <author> Ramesh Jain, R. Kasturi, and B. G. Schunck. </author> <title> Machine Vision. </title> <publisher> McGraw Hill, </publisher> <year> 1995. </year>
Reference: [16] <author> Ramesh Jain, </author> <booktitle> "NSF Workshop on Visual Information Management Systems," SIGMOD Record, </booktitle> <volume> Vol. 22, No. 3, pp.57-75, </volume> <year> 1993. </year>
Reference: [17] <author> Kurokawa, M., </author> <title> "An Approach to Retrieving Images by Using their Pictorial Features," </title> <booktitle> Proc. of the ICIP, </booktitle> <address> Singapore, </address> <month> September </month> <year> 1989, </year> <pages> ICIP. </pages>
Reference: [18] <author> King-Ip Lin, H.V. Jagadish, and Christos Faloutsos, </author> <title> "The TV-Tree an Index Structure for High-Dimensional Data", </title> <journal> VLDB Journal, </journal> <volume> Vol. 3, </volume> <pages> pp. 517-542, </pages> <year> 1994. </year>
Reference: [19] <author> D. Lomet and B. Salzberg, </author> <title> "The hB-Tree: A Multi-attribute Access Method with Good Guaranteed Performance," </title> <journal> ACM TODS Vol. </journal> <volume> 15, No. 4, </volume> <month> Dec. </month> <year> 1990. </year>
Reference: [20] <author> Nievergelt, J., Hinterberger, H., Sevcik, </author> <title> S.C. "The Grid File: An Adaptable, Symmetric Multikey File Structure," </title> <booktitle> Readings in Database Systems, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference: [21] <author> F. Rabitti and P. Savino, </author> <title> "Query processing on Image Databases," </title> <booktitle> 2nd Working Conf, on Visual Database Systems, </booktitle> <pages> pp. 174-88, </pages> <address> Budapest, Hungary, </address> <month> April </month> <year> 1991, </year> <booktitle> IFIP WG 2.6. </booktitle>
Reference: [22] <author> Ramakrishnan, R., Srivastava, D., and Sudarshan, S. </author> <title> "CORAL: Control, Relations and Logic," </title> <booktitle> Proc. of the Int. Conf. on Very Large Databases, </booktitle> <year> 1992. </year>
Reference: [23] <author> Samet, H., </author> <title> "The Quadtree and Related Hierarchical Data Structures," </title> <journal> Computing Surveys, </journal> <month> June </month> <year> 1984. </year>
Reference: [24] <author> Santini, S. and Jain, R., </author> <title> "Similarity Matching", </title> <note> Submitted to IEEE Trans. on PAMI, </note> <year> 1995. </year>
Reference-contexts: We can do the same with attributes of arbitrary type. In order to capture the notion of similarity, several ideas have been proposed. Although many sophisticated techniques have been developed for similarity measurement <ref> [24] </ref>, no attempts have been made to experimentally evaluate their efficacy in image databases. A very interesting research direction is to explore the use of DDL descriptions to define similarity.
Reference: [25] <author> Sellis, T., Roussopoulos, N., Faloutsos, C., </author> <title> "The R+ Tree: A Dynamic Index for Multi-Dimensional Objects," </title> <booktitle> Proc. 13th Inf. Conf. on VLDB, </booktitle> <year> 1987, </year> <pages> pp. 507-518. </pages>
Reference: [26] <author> Seshadri, P., Livny, M. and Ramakrishnan, R., "SEQ: </author> <title> A Model for Sequence Databases," </title> <booktitle> Proc. of the Int. Conf. on Data Engineering, </booktitle> <address> Taiwan, </address> <year> 1995. </year>

References-found: 26

