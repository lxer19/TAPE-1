URL: http://ptolemy.eecs.berkeley.edu/~dstevens/PNpaper.ps
Refering-URL: http://ptolemy.eecs.berkeley.edu/~dstevens/PNpaper.html
Root-URL: http://www.cs.berkeley.edu
Title: Implementation of Process Networks in Java  
Author: Richard S, Stevens Marlene Wan, Peggy Laramie, Thomas M. Parks, Edward A. Lee 
Date: July 10, 1997 1  10 July 1997  
Note: Implementation of Process Networks in Java  DRAFT:  1.0 Introduction  
Abstract: A process network, as described by G. Kahn, is a network of sequential processes connected by FIFO queues. Process networks, a generalization of dataow graphs, are used extensively for representing signal processing algorithms. The requirement to run for long times with limited memory raises concerns about deadlocking and memory requirements. T. Parks gives an algorithm for executing a given process network forever in bounded memory, whenever possible. This algorithm depends on recognition of and response to deadlock conditions. We implemented this algorithm in Java and devised a new robust method for detecting deadlocks. Managing concurrency has become a critical issue in many domain-specific models of computation. Concurrency is required in reactive systems, which need to interact with an environment that produces multiple simultaneous stimuli. Networked applications are inherently concurrent, as is any application with a non-trivial user interface. The Java language provides threads, which are concurrent sequential programs that can share data, precisely to deal with such applications. However, programming with threads in their raw form can easily lead to errors that are difficult to diagnose. In particular, the Java language (correctly) does not define precisely how threads are scheduled. This is dependent on the implementation. Consequently, writing multithreaded applications that behave identically across multiple implementations requires painstaking care and attention to detail. A Kahn process network is a directed graph, comprising a set of nodes (processes) connected by a set of directed arcs (FIFO queues) [1, 2]. Each process executes a sequential program. At any given moment this process may read a data token from one of its input queues, or it may write a data token to one of its output queues, subject to the following constraint: if a process attempts to read a token from an empty queue, the read is blocked, and the process must wait until a token is available on that queue. Such process networks are known to be determinate 2 , which means that the sequence of tokens passing through 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Kahn, </author> <title> The semantics of a simple language for parallel programming, </title> <booktitle> Information Processing 74, </booktitle> <pages> pp. 471-475, </pages> <address> Stockholm, </address> <month> August </month> <year> 1974. </year>
Reference-contexts: This is dependent on the implementation. Consequently, writing multithreaded applications that behave identically across multiple implementations requires painstaking care and attention to detail. A Kahn process network is a directed graph, comprising a set of nodes (processes) connected by a set of directed arcs (FIFO queues) <ref> [1, 2] </ref>. Each process executes a sequential program. <p> Richard S. Stevens is an employee of the U.S. Government, whose written work is not subject to copy right. His contribution to this work falls within the scope of 17 U.S.C. A7 105. 2. Kahn <ref> [1] </ref> gives a more general condition for determinacy, that processes be monotonic functions mapping input sequences to output sequences, where monotonic is with respect to a prefix order. <p> Implementation of Process Networks in Java July 10, 1997 2 each queue over time is dependent only on the process network and not on its implementation <ref> [1, 2, 3] </ref>. A deadlock occurs when every process in the network is blocked while attempting to read an empty queue. Kahn process networks provide a higher-level concurrency model that is inherently determinate, guaranteeing consistent behavior across implementations. <p> Writing is not blocking; each queue may store an unlimited amount of data. Kahn proved that a process network is determinate in the following sense: The sequence of tokens on each queue is determined solely by the process network and not by its implementation <ref> [1, 2] </ref>. It can also be shown that if a process network will deadlock, then it must deadlock in a unique state that is independent of the scheduling method [1, 2, 3]. Blocking reads may be specified in terms of get and put methods on the data queue. <p> It can also be shown that if a process network will deadlock, then it must deadlock in a unique state that is independent of the scheduling method <ref> [1, 2, 3] </ref>. Blocking reads may be specified in terms of get and put methods on the data queue. The get method is called by the process reading from the queue, and the put method is called by the process writing to the queue. <p> At this point Q is empty but not blocking a read. If A now writes to Q, a token will be added to Q. Because B is not waiting for a token, notification is not necessary. 3.0 Bounded Memory Scheduling In a process network <ref> [1, 2] </ref>, no restriction is placed on the number of processes in the network or on the amount of memory required by individual processes. Either or both may be unbounded.
Reference: [2] <author> G. Kahn & D. MacQueen, </author> <title> Coroutines and Networks of Parallel Processes, </title> <booktitle> Information Processing 77, </booktitle> <address> pp.993-998 Toronto, </address> <month> August </month> <year> 1977. </year>
Reference-contexts: This is dependent on the implementation. Consequently, writing multithreaded applications that behave identically across multiple implementations requires painstaking care and attention to detail. A Kahn process network is a directed graph, comprising a set of nodes (processes) connected by a set of directed arcs (FIFO queues) <ref> [1, 2] </ref>. Each process executes a sequential program. <p> Implementation of Process Networks in Java July 10, 1997 2 each queue over time is dependent only on the process network and not on its implementation <ref> [1, 2, 3] </ref>. A deadlock occurs when every process in the network is blocked while attempting to read an empty queue. Kahn process networks provide a higher-level concurrency model that is inherently determinate, guaranteeing consistent behavior across implementations. <p> Writing is not blocking; each queue may store an unlimited amount of data. Kahn proved that a process network is determinate in the following sense: The sequence of tokens on each queue is determined solely by the process network and not by its implementation <ref> [1, 2] </ref>. It can also be shown that if a process network will deadlock, then it must deadlock in a unique state that is independent of the scheduling method [1, 2, 3]. Blocking reads may be specified in terms of get and put methods on the data queue. <p> It can also be shown that if a process network will deadlock, then it must deadlock in a unique state that is independent of the scheduling method <ref> [1, 2, 3] </ref>. Blocking reads may be specified in terms of get and put methods on the data queue. The get method is called by the process reading from the queue, and the put method is called by the process writing to the queue. <p> At this point Q is empty but not blocking a read. If A now writes to Q, a token will be added to Q. Because B is not waiting for a token, notification is not necessary. 3.0 Bounded Memory Scheduling In a process network <ref> [1, 2] </ref>, no restriction is placed on the number of processes in the network or on the amount of memory required by individual processes. Either or both may be unbounded.
Reference: [3] <author> R. Stevens & D. Kaplan, </author> <title> Determinacy of Generalized Schema, </title> <journal> IEEE Trans. Comp., </journal> <volume> Vol. </volume> <pages> 41 pp. 776-779, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Implementation of Process Networks in Java July 10, 1997 2 each queue over time is dependent only on the process network and not on its implementation <ref> [1, 2, 3] </ref>. A deadlock occurs when every process in the network is blocked while attempting to read an empty queue. Kahn process networks provide a higher-level concurrency model that is inherently determinate, guaranteeing consistent behavior across implementations. <p> It can also be shown that if a process network will deadlock, then it must deadlock in a unique state that is independent of the scheduling method <ref> [1, 2, 3] </ref>. Blocking reads may be specified in terms of get and put methods on the data queue. The get method is called by the process reading from the queue, and the put method is called by the process writing to the queue.
Reference: [4] <author> J. Buck, </author> <title> Scheduling Dynamic Dataow Graphs with Bounded Memory Using the Token Flow Model, </title> <type> Ph.D. Thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1993. </year>
Reference-contexts: run in bounded memory? Specifically, is there a bound B and a scheduling scheme for running the process network such that the number of tokens on each queue never exceeds B? Each of the above questions is equivalent to the halting problem of a Turing machine and is thus undecidable <ref> [4, 6] </ref>. If a process network eventually reaches a deadlock state, then it runs in bounded memory. Thus the question of undecidability for execution in bounded memory applies in the case where running forever is either possible or not known.
Reference: [5] <author> E. Lee & T. Parks, </author> <title> Dataow Process Networks, </title> <booktitle> IEEE Proceedings, </booktitle> <pages> pp. 773-799, </pages> <month> May </month> <year> 1995 </year>
Reference-contexts: They are excellent for computation-intensive real-time applications such as signal and image processing, as evidenced by the widespread acceptance of dataow in the signal processing community. Dataow is a special case of Kahn process networks <ref> [5] </ref>. Process networks are more difficult to use, however, for transaction-based applications where sharing a common database is key. Many real-time applications are intended to run indefinitely using a limited amount of memory.
Reference: [6] <author> T. Parks, </author> <title> Bounded Scheduling of Process Networks, </title> <type> Ph.D Thesis, </type> <institution> University of Cali-fornia, Berkeley, </institution> <year> 1995. </year>
Reference-contexts: Some process networks can be analyzed statically to determine whether or not they meet these criteria. However, one of the authors (Parks) has observed that, in general, the questions of whether a process network meets these criteria are not decidable in finite time <ref> [6] </ref>. A further question arises about algorithms for scheduling the execution of a process network, and whether a given algorithm will use unbounded memory when bounded memory will suffice. Parks provides a method of running a process network forever in bounded memory, if possible. <p> In Section 3 we give a precise description of blocking writes and Parks prescription for running in bounded memory. Section 4 presents our Java implementation, together with our analysis of the two methods for detecting deadlocks. Section 5 gives some examples of process networks taken from <ref> [6] </ref>. Having run these examples using our implementation, we make some observations about the behavior that we observed. 2.0 Process Networks A process network is a set of sequential processes communicating via first-in-first-out (FIFO) channels, or queues [1,2]. <p> We are not concerned about token size, memory requirements of individual processes, or the number of processes and queues in the process network. We summarize the results of Parks <ref> [6] </ref>. <p> run in bounded memory? Specifically, is there a bound B and a scheduling scheme for running the process network such that the number of tokens on each queue never exceeds B? Each of the above questions is equivalent to the halting problem of a Turing machine and is thus undecidable <ref> [4, 6] </ref>. If a process network eventually reaches a deadlock state, then it runs in bounded memory. Thus the question of undecidability for execution in bounded memory applies in the case where running forever is either possible or not known. <p> Several scheduling policies are well known, such as data driven and demand driven. Data driven scheduling activates a process as soon as sufficient input tokens are available. Demand driven scheduling defers process activation until its output tokens are needed. For further information about these and other scheduling policies, see <ref> [6] </ref>. Implementation of Process Networks in Java July 10, 1997 5 Most traditional scheduling policies, such as data driven and demand driven, will execute process networks forever, if possible. <p> For each of the traditional scheduling policies there is an example of a process network which the policy runs, using unbounded memory when bounded memory would suffice <ref> [6] </ref>. Parks gives an algorithm that runs a process network forever in bounded memory whenever that is possible. If a process network requires unbounded memory to run forever, then there is a conict between the two goals of running forever and doing so in bounded memory. <p> Beyond that, Parks observes that it is sufficient to increase the capacity of just one queue, i.e., one with minimum capacity chosen from the queues that are blocking writes <ref> [6] </ref>. 4.0 Implementation in Java The Java language [7, 8, 9] has a number of features that makes programming and debugging relatively easy: Scheduling algorithm for execution in bounded memory, if possible. void deadlockManager () - do - waitForDeadlock (); if (trueDeadlock) terminate (); increaseQueueCapacities (); // Artificial deadlock - forever; <p> When a deadlock occurs, no process threads are running, and so the main thread runs to analyze and handle the deadlock. An implementation of this solution is described in <ref> [6] </ref>. (2) Keep a count of all current read and write blocks. A deadlock is detected when the total number of blocks equals the number of processes, at which point the main thread analyzes and handles the deadlock. This is a new approach. <p> Implementation of Process Networks in Java July 10, 1997 9 and write blocks. For the main thread we use the algorithm shown in Figure 3.2, increasing the capacity of just one queue for each artificial deadlock, a blocking queue with the lowest capacity as suggested in <ref> [6] </ref>. 5.0 Tests and examples cases. See [6] for details. int get () - if (empty) - recordReadBlock (); waitForPut (); - if (waitingForGet) - recordWriteUnblock (); resumePut (); - return firstToken (); - void put (int value) - if (full) - recordWriteBlock (); waitForGet (); - enqueue (value); if (waitingForPut) <p> For the main thread we use the algorithm shown in Figure 3.2, increasing the capacity of just one queue for each artificial deadlock, a blocking queue with the lowest capacity as suggested in <ref> [6] </ref>. 5.0 Tests and examples cases. See [6] for details. int get () - if (empty) - recordReadBlock (); waitForPut (); - if (waitingForGet) - recordWriteUnblock (); resumePut (); - return firstToken (); - void put (int value) - if (full) - recordWriteBlock (); waitForGet (); - enqueue (value); if (waitingForPut) - recordReadUnblock (); resumeGet (); - to <p> The process repeats until the lower output queue of multiple (5) has capacity 3, at which point the process network has sufficient memory to run forever. This behavior is consistent with observations reported in <ref> [6] </ref>. print print Example 5.5 add (1) begin_ with (0) multiple (3) duplicate Example 5.6 add (1) begin_ with (0) duplicate multiple (5) merge print Implementation of Process Networks in Java July 10, 1997 14 6.0 Summary and Conclusions We discussed an implementation of process networks in Java.
Reference: [7] <author> K. Arnold & J. Gosling, </author> <title> The Java Programming Language, 1996, </title> <publisher> Addison Wesley. </publisher>
Reference-contexts: Beyond that, Parks observes that it is sufficient to increase the capacity of just one queue, i.e., one with minimum capacity chosen from the queues that are blocking writes [6]. 4.0 Implementation in Java The Java language <ref> [7, 8, 9] </ref> has a number of features that makes programming and debugging relatively easy: Scheduling algorithm for execution in bounded memory, if possible. void deadlockManager () - do - waitForDeadlock (); if (trueDeadlock) terminate (); increaseQueueCapacities (); // Artificial deadlock - forever; - Implementation of Process Networks in Java July <p> This is accomplished in Java by declaring methods to be synchronized. When a thread calls a synchronized method of an object, that object is locked, preventing any other concurrent calls to synchronized methods of that object <ref> [7, 8, 9] </ref>.
Reference: [8] <author> G. Cornell & C. Horstmann, </author> <title> Core Java, 1996, </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: Beyond that, Parks observes that it is sufficient to increase the capacity of just one queue, i.e., one with minimum capacity chosen from the queues that are blocking writes [6]. 4.0 Implementation in Java The Java language <ref> [7, 8, 9] </ref> has a number of features that makes programming and debugging relatively easy: Scheduling algorithm for execution in bounded memory, if possible. void deadlockManager () - do - waitForDeadlock (); if (trueDeadlock) terminate (); increaseQueueCapacities (); // Artificial deadlock - forever; - Implementation of Process Networks in Java July <p> This is accomplished in Java by declaring methods to be synchronized. When a thread calls a synchronized method of an object, that object is locked, preventing any other concurrent calls to synchronized methods of that object <ref> [7, 8, 9] </ref>.
Reference: [9] <author> M. </author> <title> Grand, Java Language Reference, </title> <year> 1997, </year> <month> OReilly. </month>
Reference-contexts: Beyond that, Parks observes that it is sufficient to increase the capacity of just one queue, i.e., one with minimum capacity chosen from the queues that are blocking writes [6]. 4.0 Implementation in Java The Java language <ref> [7, 8, 9] </ref> has a number of features that makes programming and debugging relatively easy: Scheduling algorithm for execution in bounded memory, if possible. void deadlockManager () - do - waitForDeadlock (); if (trueDeadlock) terminate (); increaseQueueCapacities (); // Artificial deadlock - forever; - Implementation of Process Networks in Java July <p> This is accomplished in Java by declaring methods to be synchronized. When a thread calls a synchronized method of an object, that object is locked, preventing any other concurrent calls to synchronized methods of that object <ref> [7, 8, 9] </ref>.
References-found: 9

