URL: ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1140.ps.Z
Refering-URL: http://www.ai.mit.edu/people/girosi/home-page/memos.html
Root-URL: 
Title: A Theory of Networks for Approximation and Learning  
Author: Tomaso Poggio and Federico Girosi 
Date: July 1989  31  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY and CENTER FOR BIOLOGICAL INFORMATION PROCESSING WHITAKER COLLEGE  
Pubnum: A.I. Memo No.1140  C.B.I.P. Paper No.  
Abstract: Learning an input-output mapping from a set of examples, of the type that many neural networks have been constructed to perform, can be regarded as synthesizing an approximation of a multi-dimensional function, that is solving the problem of hy-persurface reconstruction. From this point of view, this form of learning is closely related to classical approximation techniques, such as generalized splines and regularization theory. This paper considers the problems of an exact representation and, in more detail, of the approximation of linear and nonlinear mappings in terms of simpler functions of fewer variables. Kolmogorov's theorem concerning the representation of functions of several variables in terms of functions of one variable turns out to be almost irrelevant in the context of networks for learning. We develop a theoretical framework for approximation based on regularization techniques that leads to a class of three-layer networks that we call Generalized Radial Basis Functions (GRBF), since they are mathematically related to the well-known Radial Basis Functions, mainly used for strict interpolation tasks. GRBF networks are not only equivalent to generalized splines, but are also closely related to pattern recognition methods such as Parzen windows and potential functions and to several neural network algorithms, such as Kanerva's associative memory, backpropagation and Kohonen's topology preserving map. They also have an interesting interpretation in terms of prototypes that are synthesized and optimally combined during the learning stage. The paper introduces several extensions and applications of the technique and discusses intriguing analogies with neurobiological data. c fl Massachusetts Institute of Technology, 1994 This paper describes research done within the Center for Biological Information Processing, in the Department of Brain and Cognitive Sciences, and at the Artificial Intelligence Laboratory. This research is sponsored by a grant from the Office of Naval Research (ONR), Cognitive and Neural Sciences Division; by the Artificial Intelligence Center of Hughes Aircraft Corporation; by the Alfred P. Sloan Foundation; by the National Science Foundation. Support for the A. I. Laboratory's artificial intelligence research is provided by the Advanced Research Projects Agency of the Department of Defense under Army contract DACA76-85-C-0010, and in part by ONR contract N00014-85-K-0124. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Abelson. </author> <title> Towards a theory of local and global in computation. </title> <journal> Theoretical Computer Science, </journal> <volume> 6 </volume> <pages> 41-67, </pages> <year> 1978. </year>
Reference-contexts: The original statement (Lorentz, 1976) is the following: Theorem 2.1 (Kolmogorov, 1957) There exist fixed increasing continuous functions h pq (x), on I = <ref> [0; 1] </ref> so that each continuous function f on I n can be written in the form f (x 1 ; :::; x n ) = q=1 n X h pq (x p )); where g q are properly chosen continuous functions of one variable. <p> The original statement of Kolmogorov (1957) is the following: Theorem A.1 There exist fixed increasing continuous functions h pq (x), on I = <ref> [0; 1] </ref> so that each continuous function f on I n can be written in the form f (x 1 ; :::; x n ) = q=1 n X h pq (x p )); where g q are properly chosen continuous functions of one variable. <p> Vitushkin showed that such a characterization is possible and gave an explicit formula. Let f be a r times continuously differentiable function defined on I n with all its partial derivatives of order r belonging to the class Lip <ref> [0; 1] </ref> ff . Vitushkin puts = n and shows that it can be used to measure the inverse of the complexity of a class of functions.
Reference: [2] <editor> F.P. Agterberg. Geomathematics. </editor> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1974. </year>
Reference: [3] <author> A. Albert. </author> <title> Regression and the Moore-Penrose Pseudoinverse. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference: [4] <author> J.S. Albus. </author> <title> A theory of cerebellar functions. </title> <journal> Math. Bio., </journal> <volume> 10 </volume> <pages> 25-61, </pages> <year> 1971. </year>
Reference: [5] <author> J.Y. Aloimonos. </author> <title> Unification and integration of visual modules: an extension of the Marr paradigm. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <pages> pages 507-551, </pages> <address> Palo Alto, CA, May 1989. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: [6] <author> W. Arai. </author> <title> Mapping abilities of three-layer networks. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, pages I-419-I-423, </booktitle> <address> Washington D.C., </address> <month> June </month> <year> 1989. </year> <institution> IEEE TAB Neural Network Committee. </institution>
Reference: [7] <author> V.I. Arnol'd. </author> <title> On functions of three variables. </title> <journal> Dokl. Akad. Nauk SSSR, </journal> <volume> 114 </volume> <pages> 679-681, </pages> <year> 1957. </year>
Reference: [8] <author> A. R. Barron and Barron R. L. </author> <title> Statistical learning networks: a unifying view. </title> <booktitle> In Symposium on the Interface: Statistics and Computing Science, </booktitle> <address> Reston, Virginia, </address> <month> April </month> <year> 1988. </year>
Reference: [9] <author> R. Basri and S. Ullman. </author> <title> Recognition by linear combinations of models. </title> <type> Technical Report CS89-11, </type> <institution> Weizman Institute of Science, </institution> <year> 1989. </year>
Reference: [10] <author> E. B. Baum. </author> <title> On the capabilities of multilayer perceptrons. </title> <journal> J. Complexity, </journal> <volume> 4 </volume> <pages> 193-215, </pages> <year> 1988. </year>
Reference: [11] <author> E. B. Baum and D. Haussler. </author> <title> What size net gives valid generalization? In D. </title> <editor> S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems I, </booktitle> <pages> pages 81-90. </pages> <publisher> Morgan Kaufmann Publishers, Carnegie Mellon University, </publisher> <year> 1989. </year> <month> 56 </month>
Reference: [12] <author> E.B. Baum, J. Moody, and F. Wilczek. </author> <title> Internal representations for associative memory. </title> <journal> Biological Cybernetics, </journal> <volume> 59 </volume> <pages> 217-228, </pages> <year> 1988. </year>
Reference: [13] <author> A. Ben-Israel and T.N.E. Greville. </author> <title> Generalized inverses: theory and applications. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1974. </year>
Reference: [14] <author> M. Bertero. </author> <title> Regularization methods for linear inverse problems. </title> <editor> In C. G. Talenti, editor, </editor> <title> Inverse Problems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1986. </year>
Reference: [15] <author> M. Bertero, T. Poggio, and V. Torre. </author> <title> Ill-posed problems in early vision. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 76 </volume> <pages> 869-889, </pages> <year> 1988. </year>
Reference: [16] <editor> S. Bochner. Vorlesungen ueber Fouriersche Integrale. In Akademische Verlagsge-sellschaft, </editor> <address> Leipzig, </address> <year> 1932. </year>
Reference: [17] <author> S. Bochner. </author> <title> Lectures on Fourier integral. </title> <publisher> Princeton Univ. Press, </publisher> <address> Princeton, New Jersey, </address> <year> 1959. </year>
Reference: [18] <author> D. Braess. </author> <title> Nonlinear Approximation Theory. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1986. </year>
Reference: [19] <author> A. Brandt. </author> <title> Multilevel adaptive solutions to boundary-value problems. </title> <journal> Math. Comp., </journal> <volume> 31 </volume> <pages> 333-390, </pages> <year> 1977. </year>
Reference: [20] <author> D.S. Broomhead and D. Lowe. </author> <title> Multivariable functional interpolation and adaptive networks. </title> <journal> Complex Systems, </journal> <volume> 2 </volume> <pages> 321-355, </pages> <year> 1988. </year>
Reference: [21] <author> S.M. Carrol and B.W. Dickinson. </author> <title> Construction of neural nets using the Radon transform. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, pages I-607-I-611, </booktitle> <address> Washington D.C., </address> <month> June </month> <year> 1989. </year> <institution> IEEE TAB Neural Network Committee. </institution>
Reference: [22] <author> M. Casdagli. </author> <title> Nonlinear prediction of chaotic time-series. </title> <journal> Physica D, </journal> <volume> 35 </volume> <pages> 335-356, </pages> <year> 1989. </year>
Reference: [23] <author> R. Courant and D. </author> <title> Hilbert. </title> <journal> Methods of mathematical physics. </journal> <volume> Vol. 2. </volume> <publisher> Interscience, </publisher> <address> London, England, </address> <year> 1962. </year>
Reference: [24] <author> D.D. Cox. </author> <title> Multivariate smoothing spline functions. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 21 </volume> <pages> 789-813, </pages> <year> 1984. </year>
Reference: [25] <author> P. Craven and G. Wahba. </author> <title> Smoothing noisy data with spline functions: estimating the correct degree of smoothing by the method of generalized cross validation. </title> <journal> Numer. Math, </journal> <volume> 31 </volume> <pages> 377-403, </pages> <year> 1979. </year>
Reference: [26] <author> G. Cybenko. </author> <title> Continuous valued neural networks with two hidden layers are sufficient. </title> <type> Technical report, </type> <institution> Dept. of Computer Sciences, Tufts Univ., </institution> <address> Medford, MA, </address> <year> 1988. </year>
Reference: [27] <author> G. Cybenko. </author> <title> Approximation by superposition of a sigmoidal function. </title> <journal> Math. Control Systems Signals, </journal> <volume> 2(4) </volume> <pages> 303-314, </pages> <year> 1989. </year>
Reference: [28] <author> J. Demmel. </author> <title> The geometry of ill-conditioning. </title> <journal> J. Complexity, </journal> <volume> 3 </volume> <pages> 201-229, </pages> <year> 1987. </year> <month> 57 </month>
Reference: [29] <author> R. A. DeVore and V. A. Popov. </author> <title> Free multivariate splines. Constructive Approximation, </title> <booktitle> 3 </booktitle> <pages> 239-248, </pages> <year> 1987. </year>
Reference: [30] <author> J. Duchon. </author> <title> Interpolation des fonctions de deux variables suivant le principle de la flexion des plaques minces. </title> <journal> R.A.I.R.O. Anal. Numer., </journal> <volume> 10 </volume> <pages> 5-12, </pages> <year> 1976. </year>
Reference: [31] <author> J. Duchon. </author> <title> Spline minimizing rotation-invariant semi-norms in Sobolev spaces. </title> <editor> In W. Schempp and K. Zeller, editors, </editor> <title> Constructive theory of functions os several variables, </title> <booktitle> Lecture Notes in Mathematics, </booktitle> <volume> 571. </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1977. </year>
Reference: [32] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference: [33] <author> R. Durbin and D.E. Rumelhart. </author> <title> Product units: a computationally powerful and biologically plausible extension to backpropagation networks. </title> <editor> In D. S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems I. </booktitle> <publisher> Morgan Kaufmann Publishers, Carnegie Mellon University, </publisher> <year> 1989. </year>
Reference: [34] <author> J.D. Farmer, E. Ott, and J.A. Yorke. </author> <title> The dimension of chaotic attractors. </title> <journal> Physica D, </journal> <volume> 7 </volume> <pages> 153-180, </pages> <year> 1983. </year>
Reference: [35] <author> J.D. Farmer and J.J. Sidorowich. </author> <title> Exploiting chaos to predict the future and reduce noise. </title> <type> Technical report, </type> <institution> Los Alamos National Laboratory, </institution> <address> New Mexico, </address> <year> 1988. </year>
Reference: [36] <author> T. Flash and N. Hogan. </author> <title> The coordination of arm movements: an experiment confirmed mathematical model. </title> <journal> The Journal of Neuroscience, </journal> <volume> 5(7) </volume> <pages> 1688-1703, </pages> <year> 1985. </year>
Reference: [37] <author> R. Franke. </author> <title> Scattered data interpolation: tests of some method. </title> <journal> Math. Comp., </journal> <volume> 38(5) </volume> <pages> 181-200, </pages> <year> 1982. </year>
Reference: [38] <author> K. Funahashi. </author> <title> On the approximate realization of continuous mappings by neural networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 2 </volume> <pages> 183-192, </pages> <year> 1989. </year>
Reference: [39] <author> D. Geiger and F. Girosi. </author> <title> Parallel and deterministic algorithms for MRFs: surface reconstruction and integration. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1114, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1989. </year>
Reference: [40] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-6:721-741, </volume> <year> 1984. </year>
Reference: [41] <author> A. Gersho. </author> <title> On the structure of vector quantizers. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 28(2) </volume> <pages> 157-166, </pages> <year> 1982. </year>
Reference: [42] <author> F. Girosi and T. Poggio. </author> <title> Networks for learning: a view from the theory of approximation of functions. </title> <editor> In P. Antognetti and V. Milutinovicc, editors, </editor> <booktitle> Neural Networks: Concepts, Applications, and Implementations, </booktitle> <volume> Vol. I, chapter 6, </volume> <pages> pages 110-155. </pages> <publisher> Pren-tice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1991. </year>
Reference: [43] <author> W. E. L. </author> <title> Grimson. From Images to Surfaces. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1981. </year> <month> 58 </month>
Reference: [44] <author> R.L. </author> <title> Harder and R.M. Desmarais. Interpolation using surface splines. </title> <journal> J. Aircraft, </journal> <volume> 9 </volume> <pages> 189-191, </pages> <year> 1972. </year>
Reference: [45] <author> R.L. Hardy. </author> <title> Multiquadric equations of topography and other irregular surfaces. </title> <journal> J. Geophys. Res, </journal> <volume> 76 </volume> <pages> 1905-1915, </pages> <year> 1971. </year>
Reference: [46] <author> J. G. Harris. </author> <title> An analog VLSI chip for thin-plate surface interpolation. </title> <editor> In D. S. Touret-zky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems I. </booktitle> <publisher> Morgan Kaufmann Publishers, Carnegie Mellon University, </publisher> <year> 1989. </year>
Reference: [47] <author> R. Hecht-Nielsen. </author> <title> Kolmogorov's mapping neural network existence theorem. </title> <booktitle> In Proc. 1987 IEEE International Conference on Neural Networks, pages III-593-III-605, New-York, 1987. </booktitle> <publisher> IEEE Press. </publisher>
Reference: [48] <author> D. </author> <title> Hilbert. </title> <journal> Mathematische probleme. Nachr. Akad. Wiss. </journal> <volume> Gottingen, </volume> <pages> pages 290-329, </pages> <year> 1900. </year>
Reference: [49] <author> A. Hurlbert and T. Poggio. </author> <title> Synthetizing a color algorithm from examples. </title> <journal> Science, </journal> <volume> 239 </volume> <pages> 482-485, </pages> <year> 1988. </year>
Reference: [50] <author> I. R. Jackson. </author> <title> Convergence properties of radial basis functions. Constructive approximation, </title> <booktitle> 4 </booktitle> <pages> 243-264, </pages> <year> 1988. </year>
Reference: [51] <author> J.P. Kahane. </author> <title> Sur le theoreme de superposition de Kolmogorov. </title> <journal> Journal of Approximation Theory, </journal> <volume> 13 </volume> <pages> 229-234, </pages> <year> 1975. </year>
Reference: [52] <author> P. Kanerva. </author> <title> Sparse distributed memory. </title> <publisher> M.I.T. Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference: [53] <author> J.D. Keeler. </author> <title> Comparison between Kanervas SDM and Hopfield-type neural networks. </title> <journal> Cognitive Science, </journal> <volume> 12 </volume> <pages> 299-329, </pages> <year> 1988. </year>
Reference: [54] <author> S. Kirkpatrick, </author> <title> C.D. Gelatt, and M.P. Vecchi. Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220 </volume> <pages> 219-227, </pages> <year> 1983. </year>
Reference: [55] <author> R.W. Klopfenstein and R. Sverdlove. </author> <title> Approximation by uniformly spaced gaussian functions. In E.W. Cheney, editor, </title> <booktitle> Approximation Theory IV, </booktitle> <pages> pages 575-580. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1983. </year>
Reference: [56] <author> C. Koch and T. Poggio. </author> <title> Biophysics of computational systems: Neurons, synapses, and membranes. In G.M. Edelman, W.E. </title> <editor> Gall, and W.M. Cowan, editors, </editor> <booktitle> Synaptic Function, </booktitle> <pages> pages 637-697. </pages> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference: [57] <author> T. Kohonen. </author> <title> Associative Memory: A System Theoretic Approach. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1978. </year>
Reference: [58] <author> A. N. </author> <title> Kolmogorov. On the representation of continuous functions of several variables by superposition of continuous functions of one variable and addition. </title> <journal> Dokl. Akad. Nauk SSSR, </journal> <volume> 114 </volume> <pages> 953-956, </pages> <year> 1957. </year> <month> 59 </month>
Reference: [59] <author> A. Lapedes and R. Farber. </author> <title> Nonlinear signal processing using neural networks: predic-tion and system modelling. </title> <institution> Los Alamos National Laboratory LA-UR-87-2662, </institution> <year> 1987. </year> <note> Submitted to Proc. IEEE. </note>
Reference: [60] <author> H.C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projecions. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference: [61] <author> G. G. Lorentz. </author> <title> Metric entropy, widths, and superposition of functions. </title> <journal> Amer. Math. Monthly, </journal> <volume> 69 </volume> <pages> 469-485, </pages> <year> 1962. </year>
Reference: [62] <author> G. G. Lorentz. </author> <title> Metric entropy and approximation. </title> <journal> Bull. Amer. Math. Soc, </journal> <volume> 72 </volume> <pages> 903-937, </pages> <year> 1966. </year>
Reference: [63] <author> G. G. Lorentz. </author> <title> On the 13-th problem of Hilbert. </title> <booktitle> In Proceedings of Symposia in Pure Mathematics, </booktitle> <pages> pages 419-429, </pages> <address> Providence, RI, 1976. </address> <publisher> Americam Mathematical Society. </publisher>
Reference: [64] <author> G. G. Lorentz. </author> <title> Approximation of Functions. </title> <publisher> Chelsea Publishing Co., </publisher> <address> New York, </address> <year> 1986. </year>
Reference: [65] <author> S.-K. Ma. </author> <title> Modern Theory of Critical Phenomena. </title> <address> W.A. </address> <publisher> Benjamin Inc., </publisher> <address> New York, </address> <year> 1976. </year>
Reference: [66] <author> J. MacQueen. </author> <title> Some methods of classification and analysis of multivariate observations. </title> <editor> In L.M. LeCam and J. Neyman, editors, </editor> <booktitle> Proc. 5th Berkeley Symposium on Math., Stat., and Prob., </booktitle> <pages> page 281. </pages> <address> U. </address> <publisher> California Press, </publisher> <address> Berkeley, CA, </address> <year> 1967. </year>
Reference: [67] <author> D. Marr. </author> <title> A theory of cerebellar cortex. </title> <journal> J. Physiology, </journal> <volume> 202 </volume> <pages> 437-470, </pages> <year> 1969. </year>
Reference: [68] <author> D. Marr and T. Poggio. </author> <title> Cooperative computation of stereo disparity. </title> <journal> Science, </journal> <volume> 194 </volume> <pages> 283-287, </pages> <year> 1976. </year>
Reference: [69] <author> J. L. Marroquin, S. Mitter, and T. Poggio. </author> <title> Probabilistic solution of ill-posed problems in computational vision. </title> <journal> J. Amer. Stat. Assoc., </journal> <volume> 82 </volume> <pages> 76-89, </pages> <year> 1987. </year>
Reference: [70] <author> J. Meinguet. </author> <title> An intrinsic approach to multivariate spline interpolation at arbitrary points. </title> <editor> In B. H. Sahney, editor, </editor> <title> Polynomial and Spline Approximation. </title> <address> Reidal, Dor-drecht, </address> <year> 1979. </year>
Reference: [71] <author> J. Meinguet. </author> <title> Multivariate interpolation at arbitrary points made simple. </title> <journal> J. Appl. Math. Phys., </journal> <volume> 30 </volume> <pages> 292-304, </pages> <year> 1979. </year>
Reference: [72] <author> B. W. Mel. MURPHY: </author> <title> a robot that learns by doing. </title> <editor> In D. Z. Anderson, editor, </editor> <booktitle> Neural Information Processing Systems. </booktitle> <institution> American Institute of Physics, University of Colorado, </institution> <address> Denver, </address> <year> 1987. </year>
Reference: [73] <author> N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller. </author> <title> Equation of state calculations by fast computing machines. </title> <journal> J. Phys. Chem, </journal> <volume> 21:1087, </volume> <year> 1953. </year>
Reference: [74] <author> C. A. Micchelli. </author> <title> Interpolation of scattered data: distance matrices and conditionally positive definite functions. Constructive Approximation, </title> <booktitle> 2 </booktitle> <pages> 11-22, </pages> <year> 1986. </year> <month> 60 </month>
Reference: [75] <author> M. L. Minsky and S. Papert. </author> <title> Perceptrons. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1969. </year>
Reference: [76] <author> J. Moody. </author> <title> Fast learning in multi resolution hierarchies. </title> <editor> In D. S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems I, </booktitle> <pages> pages 29-39. </pages> <publisher> Morgan Kaufmann Publishers, Carnegie Mellon University, </publisher> <year> 1989. </year>
Reference: [77] <author> J. Moody and C. Darken. </author> <title> Fast learning in networks of locally-tuned processing units. </title> <journal> Neural Computation, </journal> <volume> 1(2) </volume> <pages> 281-294, </pages> <year> 1989. </year>
Reference: [78] <author> B. Moore and T. Poggio. </author> <title> Representations properties of multilayer feedforward networks. </title> <booktitle> In Abstracts of the first annual INNS meeting, </booktitle> <pages> page 502, </pages> <address> New York, 1988. </address> <publisher> Pergamon Press. </publisher>
Reference: [79] <author> V.A. Morozov. </author> <title> Methods for solving incorrectly posed problems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984. </year>
Reference: [80] <author> S. Omohundro. </author> <title> Efficient algorithms with neural network behaviour. </title> <journal> Complex Systems, </journal> <volume> 1:273, </volume> <year> 1987. </year>
Reference: [81] <author> G. Parisi. </author> <title> Statistical Field Theory. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusets, </address> <year> 1988. </year>
Reference: [82] <author> E. Parzen. </author> <title> On estimation of a probability density function and mode. </title> <journal> Ann. Math. Statis., </journal> <volume> 33 </volume> <pages> 1065-1076, </pages> <year> 1962. </year>
Reference: [83] <author> R. Penrose. </author> <title> A generalized inverse for matrices. </title> <journal> Proc. Cambridge Philos. Soc., </journal> <volume> 51 </volume> <pages> 406-413, </pages> <year> 1955. </year>
Reference: [84] <author> D. I. Perrett, A.J. Mistlin, and A.J. Chitty. </author> <title> Visual neurones responsive to faces. </title> <journal> Trends in Neuroscience, </journal> <volume> 10(9) </volume> <pages> 358-364, </pages> <year> 1987. </year>
Reference: [85] <author> T. Poggio. </author> <title> On optimal nonlinear associative recall. </title> <journal> Biological Cybernetics, </journal> <volume> 19 </volume> <pages> 201-209, </pages> <year> 1975. </year>
Reference: [86] <author> T. Poggio. </author> <title> Visual algorithms. </title> <editor> In O. J. Braddick and A. C. Sleigh, editors, </editor> <booktitle> Physical and Biological Processing of Images, </booktitle> <pages> pages 128-153. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1982. </year>
Reference: [87] <author> T. Poggio and S. Edelman. </author> <title> A network that learns to recognize 3D objects. </title> <journal> Nature, </journal> <volume> 343 </volume> <pages> 263-266, </pages> <year> 1990. </year>
Reference: [88] <author> T. </author> <title> Poggio and the staff. MIT progress in understanding images. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <address> Cambridge, MA, April 1988. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: [89] <author> T. </author> <title> Poggio and the staff. M.I.T. progress in understanding images. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <pages> pages 56-74, </pages> <address> Palo Alto, CA, May 1989. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: [90] <author> T. Poggio and V. Torre. </author> <title> A theory of synaptic interactions. In W.E. </title> <editor> Reichardt and T. Poggio, editors, </editor> <booktitle> Theoretical approaches in neurobiology, </booktitle> <pages> pages 28-38. </pages> <publisher> The M.I.T Press, </publisher> <address> Cambridge, MA, </address> <year> 1978. </year> <month> 61 </month>
Reference: [91] <author> M. J. D. Powell. </author> <title> Radial basis functions for multivariable interpolation: a review. </title> <editor> In J. C. Mason and M. G. Cox, editors, </editor> <title> Algorithms for Approximation. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1987. </year>
Reference: [92] <author> S. Renals and R. Rohwer. </author> <title> Phoneme classification experiments using radial basis functions. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, pages I-461-I-467, </booktitle> <address> Washington D.C., </address> <month> June </month> <year> 1989. </year> <institution> IEEE TAB Neural Network Committee. </institution>
Reference: [93] <author> H.L. Resnikoff. </author> <title> On the psychophysical function. </title> <journal> J. Math. Biol., </journal> <volume> 2 </volume> <pages> 265-276, </pages> <year> 1975. </year>
Reference: [94] <author> S. Rippa. </author> <title> Interpolation and smoothing of scattered data by radial basis functions. M.sc. </title> <type> thesis, </type> <institution> Tel Aviv University, </institution> <year> 1984. </year>
Reference: [95] <author> J. Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference: [96] <author> H. Ritter and K. Schulten. </author> <title> Topology conserving mappings for learning motor tasks. </title> <booktitle> In Proc. AIP Conference: Neural networks of computing, </booktitle> <pages> pages 376-380, </pages> <address> Snowbird, Utah, </address> <year> 1986. </year> <note> J.S. Denker. </note>
Reference: [97] <author> H. Ritter and K. Schulten. </author> <title> Extending Kohonen's self-organizing mapping algorithm to learn ballistic movements. </title> <editor> In R. Eckmiller and C. von der Malsburg, editors, </editor> <booktitle> Neural Computers, </booktitle> <pages> pages 393-406. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference: [98] <author> H. Ritter and K. Schulten. </author> <title> Convergence properties of Kohonen's topology conserving maps: fluctuations, stability, and dimension selection. </title> <journal> Biological Cybernetics, </journal> <volume> 60 </volume> <pages> 59-71, </pages> <year> 1988. </year>
Reference: [99] <author> A. Rosenfeld and A.C. Kak. </author> <title> Digital Picture Processing. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference: [100] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <booktitle> In Parallel Distributed Processing, chapter 8, </booktitle> <pages> pages 318-362. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference: [101] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning representations by back-propagating errors. </title> <journal> Nature, </journal> <volume> 323(9) </volume> <pages> 533-536, </pages> <month> October </month> <year> 1986. </year>
Reference: [102] <author> E. Saund. </author> <title> Dimensionality-reduction using connectionist networks. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 941, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1987. </year>
Reference: [103] <author> I.P. Schagen. </author> <title> Interpolation in two dimensions anew technique. </title> <journal> J. Inst Math. Appl., </journal> <volume> 23 </volume> <pages> 53-59, </pages> <year> 1979. </year>
Reference: [104] <author> I.J. </author> <title> Schoenberg. Metric spaces and completely monotone functions. </title> <journal> Ann. of Math., </journal> <volume> 39 </volume> <pages> 811-841, </pages> <year> 1938. </year>
Reference: [105] <author> I.J. </author> <title> Schoenberg. Metric spaces and positive definite functions. </title> <journal> Ann. of Math., </journal> <volume> 44 </volume> <pages> 522-536, </pages> <year> 1938. </year>
Reference: [106] <author> J. Schwartz. </author> <title> On the effectiveness of backpropagation learning in trainable N 2 nets, and of other related form of discrimination learning. </title> <type> Preprint, </type> <year> 1988. </year>
Reference: [107] <author> T. J. Sejnowski and C. R. Rosenberg. </author> <title> Parallel networks that learn to pronounce english text. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 145-168, </pages> <year> 1987. </year>
Reference: [108] <author> R.J. Solomonoff. </author> <title> Complexity-based induction systems: comparison and convergence theorems. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 24, </volume> <year> 1978. </year>
Reference: [109] <author> D.A. Sprecher. </author> <title> On the structure of continuous functions of several variables. </title> <journal> Trans. Amer. Math. Soc., </journal> <volume> 115 </volume> <pages> 340-355, </pages> <year> 1965. </year>
Reference: [110] <author> J. Stewart. </author> <title> Positive definite functions and generalizations, an historical survey. </title> <journal> Rocky Mountain J. Math., </journal> <volume> 6 </volume> <pages> 409-434, </pages> <year> 1976. </year>
Reference: [111] <author> C. J. Stone. </author> <title> Optimal global rates of convergence for nonparametric regression. </title> <journal> The Annals of Statistics, </journal> <volume> 10 </volume> <pages> 1040-1053, </pages> <year> 1982. </year>
Reference: [112] <author> C. J. Stone. </author> <title> Additive regression and other nonparametric models. </title> <journal> The Annals of Statistics, </journal> <volume> 13 </volume> <pages> 689-705, </pages> <year> 1985. </year>
Reference: [113] <author> A. N. </author> <title> Tikhonov. Solution of incorrectly formulated problems and the regularization method. </title> <journal> Soviet Math. Dokl., </journal> <volume> 4 </volume> <pages> 1035-1038, </pages> <year> 1963. </year>
Reference: [114] <author> A. N. Tikhonov and V. Y. Arsenin. </author> <title> Solutions of Ill-posed Problems. </title> <editor> W. H. Winston, </editor> <address> Washington, D.C., </address> <year> 1977. </year>
Reference: [115] <author> V. Torre and T. Poggio. </author> <title> An application: a synaptic mechanism possibly underlying motion detection. In W.E. </title> <editor> Reichardt and T. Poggio, editors, </editor> <booktitle> Theoretical approaches in neurobiology, </booktitle> <pages> pages 39-46. </pages> <publisher> The M.I.T Press, </publisher> <address> Cambridge, MA, </address> <year> 1978. </year>
Reference: [116] <author> R.Y. Tsai and T.S. Huang. </author> <title> Uniqueness and estimation of 3-D motion parameters of a rigid planar patch from three perspective views. </title> <booktitle> In Proc. of IEEE International Conference on ASSP, </booktitle> <address> Paris, France, </address> <month> May 3-5 </month> <year> 1982. </year>
Reference: [117] <author> V. N. Vapnik and A. Y. Chervonenkis. </author> <title> On the uniform convergence of relative fre-quences of events to their probabilities. </title> <journal> Th. Prob. and its Applications, </journal> <volume> 17(2) </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference: [118] <author> A. G. Vitushkin. </author> <title> On Hilbert's thirteenth problem. </title> <journal> Dokl. Akad. Nauk SSSR, </journal> <volume> 95 </volume> <pages> 701-704, </pages> <year> 1954. </year>
Reference: [119] <author> A. G. Vitushkin and G.M. </author> <title> Henkin. Linear superposition of functions. </title> <journal> Russian Math. Surveys, </journal> <volume> 22 </volume> <pages> 77-125, </pages> <year> 1967. </year>
Reference: [120] <author> G. Wahba. </author> <title> Practical approximate solutions to linear operator equations when the data are noisy. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 14, </volume> <year> 1977. </year>
Reference: [121] <author> N. Wax. </author> <title> Selected papers on noise and stochastic processes. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <year> 1954. </year> <month> 63 </month>
Reference: [122] <author> D. Wolpert. </author> <title> Alternative generalizers to neural nets. </title> <booktitle> In Abstracts of the first annual INNS meeting, </booktitle> <address> New York, 1988. </address> <publisher> Pergamon Press. </publisher>
Reference: [123] <author> A. Yuille and N. Grzywacz. </author> <title> The motion coherence theory. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 344-354, </pages> <address> Washington, D.C., December 1988. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: [124] <author> D. Zipser and R.A. Andersen. </author> <title> A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons. </title> <journal> Nature, </journal> <volume> 331 </volume> <pages> 679-684, </pages> <year> 1988. </year> <month> 64 </month>
References-found: 124

