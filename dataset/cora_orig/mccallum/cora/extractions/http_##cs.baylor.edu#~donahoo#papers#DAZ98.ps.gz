URL: http://cs.baylor.edu/~donahoo/papers/DAZ98.ps.gz
Refering-URL: http://cs.baylor.edu/~donahoo/
Root-URL: http://cs.baylor.edu
Email: fmjd,ammar,ewzg@cc.gatech.edu  
Title: Multiple-Channel Multicast Scheduling for Scalable Bulk-data Transport  
Author: Michael J. Donahoo Mostafa H. Ammar Ellen W. Zegura 
Note: This research is supported in part by grants from the National Science Foundation (NCR9628379) and the  
Address: Atlanta, GA 30332  
Affiliation: Networking and Telecommunications Group College of Computing Georgia Institute of Technology  Georgia Research Alliance.  
Abstract: A key technique for allowing a server to handle a large volume of requests for file transfers is to multicast the data to the set of requesting clients. Typically, the paths from the server to the clients will be heterogeneous in bandwidth availability. Multiple-Channel Multicast (MCM) is an approach that can be used to handle this heterogeneity. In this approach the data is multicast over multiple channels, each addressed as a separate multicast group. Each receiver subscribes to a set of channels (i.e., joins the corresponding multicast groups) commensurate with its own rate capabilities. Of particular interest in the design of MCM schemes is the scheduling of data transmission across the multiple channels to accomodate asynchronous requests from clients. In this paper, we present and analyze a new multiple-channel multicast approach called Partition Organization (PO) scheduling. The scheme is designed to result in good reception efficiency when compared to existing proposals while improving on their performance when other measures of interest (which we introduce) are considered. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Swarup Acharya, Michael Franklin, and Stanley Zdonik. </author> <title> Dissemination-based data delivery using broadcast disks. </title> <journal> IEEE Personal Communications, </journal> <volume> 2(6), </volume> <month> December </month> <year> 1995. </year>
Reference-contexts: If the number of clients is large, the server faces challenges in scalability. A key technique for allowing the server to handle a large volume of requests is to multicast the data to the set of clients <ref> [24, 25, 8, 1, 12, 2, 14] </ref>. The application scenario outlined above makes the use of multicast difficult, however. First, the clients will typically make requests over time, without synchronization.
Reference: [2] <author> Kevin C. Almeroth, Mostafa H. Ammar, and Zongming Fei. </author> <title> Scalable delivery of web pages using cyclic best-effort (UDP) multicast. </title> <booktitle> In INFOCOM'98, </booktitle> <month> May </month> <year> 1998. </year>
Reference-contexts: If the number of clients is large, the server faces challenges in scalability. A key technique for allowing the server to handle a large volume of requests is to multicast the data to the set of clients <ref> [24, 25, 8, 1, 12, 2, 14] </ref>. The application scenario outlined above makes the use of multicast difficult, however. First, the clients will typically make requests over time, without synchronization.
Reference: [3] <author> Mostafa H. Ammar and Li-Ran Wu. </author> <title> Improving the throughput of point-to-multipoint ARQ protocols through destination set splitting. </title> <booktitle> In Proceedings of INFOCOM'92, </booktitle> <pages> pages 262-71. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: We compare the PO and SO schemes in Section 6, and conclude in Section 7. 2 Related Work A simple form of multiple-channel multicasting involves sending the entire file over separate multicast channels at different rates <ref> [3, 7] </ref>. A receiver joins the single channel that has the highest rate that does not exceed the receiver's rate capability. This Destination-Set Splitting approach has the disadvantage that the same data is sent over each channel, potentially leading to signficant inefficiencies in network usage.
Reference: [4] <author> Supratik Bhattacharyya, James F. Kurose, Don Towsley, and Ramesh Nagarajan. </author> <title> Efficient multicast flow control using multiple multicast groups. </title> <type> Technical Report UM-CS-1997-015, </type> <institution> University of Massachusetts, </institution> <month> March </month> <year> 1997. </year>
Reference-contexts: Further, since each receiver listens to one and only one group, the number of receivers per group (and, thus, the advantage of multicast) may be limited. The work of Bhattacharyya et al. <ref> [4] </ref> proposes scheduling the data across multiple multicast groups with receivers joining multiple groups to get the entire file. If the scheduling across the groups is done well, this is more efficient than Destination-Set Splitting. <p> In this Static Striping approach, the groups and rates are scheduled a priori after all receivers register their rates with the sender. Using registered rates, optimal data rates and schedules for a set of channels can be derived <ref> [4] </ref>. This approach suffers from the problem of requiring the collection of the receiver rates at the sender, which limits scalability with respect to the maximum number of simultaneous receivers.
Reference: [5] <author> Jean-Chrysostome Bolot and Andres Vega-Garcia. </author> <title> Control mechanisms for packet audio in the internet. </title> <booktitle> In Proceedings of INFOCOM'96, </booktitle> <pages> pages 232-239. </pages> <publisher> IEEE, </publisher> <month> April </month> <year> 1996. </year>
Reference-contexts: The time to receive the extraneous packet A results in inefficient use of the channel. Researchers have proposed the use of Forward Error Correction (FEC) to recover from packet loss at the receiver in reliable multicast protocols <ref> [5, 9, 15, 16, 20, 19] </ref>. A (k; n) encoder takes k packets of source data and produces n k redundancy packets such that any k of the n (k original + n k redundancy) packets can be used to reconstruct the original k packets [11, 17, 18].
Reference: [6] <author> Shun Yan Cheung and Mostafa H. Ammar. </author> <title> Using destination set grouping to improve the performance of window-controlled multipoint connections. </title> <booktitle> In Proceedings of INFOCOM 96, </booktitle> <month> march </month> <year> 1996. </year>
Reference-contexts: In addition, receiver startup must be synchronized since transmission is tailored for all receivers to start together. 2 Multiple-channel multicasting has been used in the context of streaming video to multiple receivers <ref> [6, 13, 10] </ref>. The semantics of this application are somewhat different, however. For video, each receiver desires to get the best quality that can be sustained by the path from the sender. Receivers with different rate capabilities will get different data.
Reference: [7] <author> Shun Yan Cheung, Mostafa H. Ammar, and Xue Li. </author> <title> On the use of destination set grouping to improve fairness in multicast video distribution. </title> <journal> Computer Communications, </journal> <volume> 19 </volume> <pages> 723-736, </pages> <year> 1996. </year>
Reference-contexts: We compare the PO and SO schemes in Section 6, and conclude in Section 7. 2 Related Work A simple form of multiple-channel multicasting involves sending the entire file over separate multicast channels at different rates <ref> [3, 7] </ref>. A receiver joins the single channel that has the highest rate that does not exceed the receiver's rate capability. This Destination-Set Splitting approach has the disadvantage that the same data is sent over each channel, potentially leading to signficant inefficiencies in network usage.
Reference: [8] <author> Russell J. Clark and Mostafa H. Ammar. </author> <title> Providing scalable Web services using multicast. </title> <booktitle> In Proceedings of the 2nd International Workshop on Services in Distributed and Networked Environments (SDNE 95), </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: If the number of clients is large, the server faces challenges in scalability. A key technique for allowing the server to handle a large volume of requests is to multicast the data to the set of clients <ref> [24, 25, 8, 1, 12, 2, 14] </ref>. The application scenario outlined above makes the use of multicast difficult, however. First, the clients will typically make requests over time, without synchronization.
Reference: [9] <author> Mark Handley. </author> <title> An examination of MBone performance. </title> <address> http://buttle.lcs.mit.edu/ mjh/mbone.ps, </address> <month> January </month> <year> 1997. </year>
Reference-contexts: The time to receive the extraneous packet A results in inefficient use of the channel. Researchers have proposed the use of Forward Error Correction (FEC) to recover from packet loss at the receiver in reliable multicast protocols <ref> [5, 9, 15, 16, 20, 19] </ref>. A (k; n) encoder takes k packets of source data and produces n k redundancy packets such that any k of the n (k original + n k redundancy) packets can be used to reconstruct the original k packets [11, 17, 18].
Reference: [10] <author> Xue Li, Sanjoy Paul, and Mostafa Ammar. </author> <title> Layered video multicast with retransmission (lvmr): Hierarchical rate control schemes. </title> <booktitle> In Proceedings of Infocom'98, </booktitle> <address> San Francisco, CA, </address> <month> March </month> <year> 1998. </year> <month> 22 </month>
Reference-contexts: Third, if the number of clients is large, implosion of feedback information at the sender is a concern. To handle receiver rate heterogeneity and avoid feedback implosion, a number of researchers have considered the use of multiple channels with receiver-driven rate adaptation <ref> [22, 23, 13, 10] </ref>. The idea is that the sender uses multiple channels, each addressed as a separate multicast group. Each receiver subscribes to set of channels (i.e., joins the corresponding multicast groups) commensurate with its own rate capabilities. <p> In addition, receiver startup must be synchronized since transmission is tailored for all receivers to start together. 2 Multiple-channel multicasting has been used in the context of streaming video to multiple receivers <ref> [6, 13, 10] </ref>. The semantics of this application are somewhat different, however. For video, each receiver desires to get the best quality that can be sustained by the path from the sender. Receivers with different rate capabilities will get different data.
Reference: [11] <author> Shu Lin and Daniel J. Dostello Jr. </author> <title> Error Control Coding: </title> <booktitle> Fundamentals and Applications. Computer Applications in Electrical Engineering. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1983. </year>
Reference-contexts: A (k; n) encoder takes k packets of source data and produces n k redundancy packets such that any k of the n (k original + n k redundancy) packets can be used to reconstruct the original k packets <ref> [11, 17, 18] </ref>. Consider the example in Figure 2 where the sender creates two redundancy packets, R 1 and R 2 , from two original packets, A and B, in a (k = 2; n = 4) erasure packet encoding.
Reference: [12] <author> Sameer Mahajan, Michael J. Donahoo, Shamkant B. Navathe, and Mostafa Ammar. </author> <title> Grouping techniques for update propagation in intermittently connected databases. </title> <booktitle> In Fourteenth Internation Conference on Data Engineering, </booktitle> <pages> pages 46-53. </pages> <publisher> IEEE, </publisher> <month> February </month> <year> 1997. </year>
Reference-contexts: If the number of clients is large, the server faces challenges in scalability. A key technique for allowing the server to handle a large volume of requests is to multicast the data to the set of clients <ref> [24, 25, 8, 1, 12, 2, 14] </ref>. The application scenario outlined above makes the use of multicast difficult, however. First, the clients will typically make requests over time, without synchronization.
Reference: [13] <author> Steven McCanne, Van Jacobson, and Martin Vetterli. </author> <title> Receiver-driven layered multicast. </title> <booktitle> In ACM SIG-COMM'96 Conference, </booktitle> <pages> pages 117-130. </pages> <publisher> ACM, ACM Press, </publisher> <month> October </month> <year> 1996. </year>
Reference-contexts: Third, if the number of clients is large, implosion of feedback information at the sender is a concern. To handle receiver rate heterogeneity and avoid feedback implosion, a number of researchers have considered the use of multiple channels with receiver-driven rate adaptation <ref> [22, 23, 13, 10] </ref>. The idea is that the sender uses multiple channels, each addressed as a separate multicast group. Each receiver subscribes to set of channels (i.e., joins the corresponding multicast groups) commensurate with its own rate capabilities. <p> In addition, receiver startup must be synchronized since transmission is tailored for all receivers to start together. 2 Multiple-channel multicasting has been used in the context of streaming video to multiple receivers <ref> [6, 13, 10] </ref>. The semantics of this application are somewhat different, however. For video, each receiver desires to get the best quality that can be sustained by the path from the sender. Receivers with different rate capabilities will get different data.
Reference: [14] <author> Jorg Nonnenmacher and Ernst Biersack. </author> <title> Asynchronous multicast push: AMP. </title> <booktitle> In Proceedings of ICCC'97, </booktitle> <month> November </month> <year> 1997. </year>
Reference-contexts: If the number of clients is large, the server faces challenges in scalability. A key technique for allowing the server to handle a large volume of requests is to multicast the data to the set of clients <ref> [24, 25, 8, 1, 12, 2, 14] </ref>. The application scenario outlined above makes the use of multicast difficult, however. First, the clients will typically make requests over time, without synchronization.
Reference: [15] <author> Jorg Nonnenmacher, Ernst Biersack, and Don Towsley. </author> <title> Parity-based loss recovery for reliable multicast transmission. </title> <booktitle> In Proceedings of ACM SIGCOMM'97 Conference, </booktitle> <volume> volume 27, </volume> <pages> pages 289-300. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1997. </year> <type> Tech. Report: </type> <institution> UM-CS-1997-017. </institution>
Reference-contexts: The time to receive the extraneous packet A results in inefficient use of the channel. Researchers have proposed the use of Forward Error Correction (FEC) to recover from packet loss at the receiver in reliable multicast protocols <ref> [5, 9, 15, 16, 20, 19] </ref>. A (k; n) encoder takes k packets of source data and produces n k redundancy packets such that any k of the n (k original + n k redundancy) packets can be used to reconstruct the original k packets [11, 17, 18].
Reference: [16] <author> Jorg Nonnenmacher and E.W. Biersack. </author> <title> Reliable multicast: Where to use FEC. </title> <booktitle> In Proceedings 5th Workshop on Protocols for High Speed Networks, </booktitle> <pages> pages 134-148, </pages> <month> October </month> <year> 1996. </year> <note> http://www.eurecom.fr/ non-nen/mypages/FECgain.ps.gz. </note>
Reference-contexts: The time to receive the extraneous packet A results in inefficient use of the channel. Researchers have proposed the use of Forward Error Correction (FEC) to recover from packet loss at the receiver in reliable multicast protocols <ref> [5, 9, 15, 16, 20, 19] </ref>. A (k; n) encoder takes k packets of source data and produces n k redundancy packets such that any k of the n (k original + n k redundancy) packets can be used to reconstruct the original k packets [11, 17, 18].
Reference: [17] <author> Luigi Rizzo. </author> <title> Effective erasure codes for reliable computer communication protocols. </title> <journal> Computer Communication Review, </journal> <month> April </month> <year> 1997. </year>
Reference-contexts: A (k; n) encoder takes k packets of source data and produces n k redundancy packets such that any k of the n (k original + n k redundancy) packets can be used to reconstruct the original k packets <ref> [11, 17, 18] </ref>. Consider the example in Figure 2 where the sender creates two redundancy packets, R 1 and R 2 , from two original packets, A and B, in a (k = 2; n = 4) erasure packet encoding.
Reference: [18] <author> Luigi Rizzo. </author> <title> On the feasibility of software FEC. </title> <address> http://www.iet.unipi.it/ luigi/softfec.ps, </address> <year> 1997. </year>
Reference-contexts: A (k; n) encoder takes k packets of source data and produces n k redundancy packets such that any k of the n (k original + n k redundancy) packets can be used to reconstruct the original k packets <ref> [11, 17, 18] </ref>. Consider the example in Figure 2 where the sender creates two redundancy packets, R 1 and R 2 , from two original packets, A and B, in a (k = 2; n = 4) erasure packet encoding. <p> Redundancy: Recall that FEC decoding complexity is directly related to the number of missing packets we must reconstruct at the receiver. The percentage of the k packets received for each block that are redundancy packets directly relates to the decode complexity at the receiver <ref> [18] </ref>. Consequently, we evaluate the percentage of redundancy packets in our experiments. Figure 11 gives the percentage of redundancy packets for both schemes with varying packet loss. Note that irrespective of packet loss rate, the SO scheme exhibits a high percentage of redundancy packets.
Reference: [19] <author> Luigi Rizzo and Lorenzo Vicisano. </author> <title> A reliable multicast data distribution protocol based on software FEC techniques. </title> <booktitle> In Proceedings of the Fourth IEEE HPCS'97 Workshop, </booktitle> <month> June </month> <year> 1997. </year> <note> http://www.cs.ucl.ac.uk/staff/L.Vicisano/hpcs97.ps.gz. </note>
Reference-contexts: The time to receive the extraneous packet A results in inefficient use of the channel. Researchers have proposed the use of Forward Error Correction (FEC) to recover from packet loss at the receiver in reliable multicast protocols <ref> [5, 9, 15, 16, 20, 19] </ref>. A (k; n) encoder takes k packets of source data and produces n k redundancy packets such that any k of the n (k original + n k redundancy) packets can be used to reconstruct the original k packets [11, 17, 18].
Reference: [20] <author> Lorenzo Vicisano. </author> <title> Notes on a cumulative organization of data packets across multiple stream with different rates. </title> <note> http://www.cs.ucl.ac.uk/staff/L.Vicisano/layer.ps.gz, January 1997. </note>
Reference-contexts: We compare our PO scheme to another scheduling scheme for bulk-data transfer, namely the Session Organization (SO) scheme proposed by Vicisano <ref> [20] </ref>. We find that our scheme offers significant performance improvement for metrics likely to be of interest to applications. The remainder of the paper is organized as follows. In the next section, we discuss related work, including multiple-channel scheduling for applications with slightly different requirements than outlined above. <p> In this context, the video can be hierarchically encoded, with each "layer" sent on a different multicast group. A receiver starts by joining the base layer with minimal quality, and then adds layers until losses are unacceptable. As mentioned in the Introduction, the work of Vicisano <ref> [20] </ref> is closest to ours in target application environment. Vicisano proposes two MCM scheduling schemes, Session Organization (SO) and Channel Organization (CO). The SO scheme outperforms the CO scheme for the metrics reported by Vicisano [20], thus we focus our comparisons on the SO scheme. <p> As mentioned in the Introduction, the work of Vicisano <ref> [20] </ref> is closest to ours in target application environment. Vicisano proposes two MCM scheduling schemes, Session Organization (SO) and Channel Organization (CO). The SO scheme outperforms the CO scheme for the metrics reported by Vicisano [20], thus we focus our comparisons on the SO scheme. Vicisano et al. have also considered the use of their scheduling schemes to provide "TCP-like congestion control" with receiver-driven protocols [21, 23]. <p> The time to receive the extraneous packet A results in inefficient use of the channel. Researchers have proposed the use of Forward Error Correction (FEC) to recover from packet loss at the receiver in reliable multicast protocols <ref> [5, 9, 15, 16, 20, 19] </ref>. A (k; n) encoder takes k packets of source data and produces n k redundancy packets such that any k of the n (k original + n k redundancy) packets can be used to reconstruct the original k packets [11, 17, 18]. <p> Thus, we are interested in knowing the percentage of redundancy packets used in decoding. Note that these are per-receiver performance measures. In our evaluation later we will report the average over all receivers in our experiments. 6 4 The Session Organization (SO) Scheduling Scheme Vicisano <ref> [20] </ref> proposes an MCM approach called the Session Organization (SO) scheduling scheme [20]. The example shown in Figure 1 is a simplified version of an SO schedule. <p> Note that these are per-receiver performance measures. In our evaluation later we will report the average over all receivers in our experiments. 6 4 The Session Organization (SO) Scheduling Scheme Vicisano <ref> [20] </ref> proposes an MCM approach called the Session Organization (SO) scheduling scheme [20]. The example shown in Figure 1 is a simplified version of an SO schedule. <p> A total of R phases are needed for the lowest numbered channel to eventually carry all packets. 4.2 Discussion of the SO Scheme Vicisano's analysis evaluates the SO scheme using a single performance metric, reception efficiency <ref> [20] </ref>. Here we discuss the SO scheme from the perspective of the other performance measures presented earlier. <p> That is, the number of redundant FEC packets cannot be chosen independent of k and R, indeed n grows quickly with the number of channels. Recall that the complexity of encoding is directly related to the number of redundancy packets which is n k = (R 1)k (1) From <ref> [20] </ref>, we know that increasing k results in better reception efficiency; however, according to Equation 1 increasing k results in a linear increase in encoding complexity. <p> In this paper we consider the issue of how to partition and schedule the data among the multiple channels for bulk-data multicast applications. We introduce a set of performance measures and discuss how a scheme previously proposed by Vicisano <ref> [20] </ref> performs according to these measures. This motivates the development of our new PO scheduling scheme. Our performance experiments show 19 20 that the PO scheme compares favorably with Vicisano's SO scheme as far as reception efficiency is concerned but has better performance on other performance measures. <p> Appendix B: PO Schedule Specification The PO scheme has the following packet organization: 7 Figure 16 is a derivation of Figure 2 in <ref> [20] </ref>. 21 C O fi fi i k fi fi ; fi j (k+ffi)(!+1) (! + 1) fi n c i n c j C R fi fi B fi fi n (k+ffi) n c i n c j ! (2) where C O j (i) and C R j (i)
Reference: [21] <author> Lorenzo Vicisano and Jon Crowcroft. </author> <title> One to many reliable bulk-data transfer in the MBone. </title> <booktitle> In Proceedings of the Third International Workshop on High Performance Protocol Architectures HIPPARCH '97, </booktitle> <month> June </month> <year> 1997. </year> <note> http://www.cs.ucl.ac.uk/staff/L.Vicisano/hipparch97.ps.gz. </note>
Reference-contexts: The SO scheme outperforms the CO scheme for the metrics reported by Vicisano [20], thus we focus our comparisons on the SO scheme. Vicisano et al. have also considered the use of their scheduling schemes to provide "TCP-like congestion control" with receiver-driven protocols <ref> [21, 23] </ref>.
Reference: [22] <author> Lorenzo Vicisano, Mark Handley, and Jon Crowcroft. B-MART, </author> <title> bulk-data (non-real-time) multiparty adaptive reliable transfer protocol. </title> <publisher> ftp://cs.ucl.ac.uk/darpa/bulk.ps. </publisher>
Reference-contexts: Third, if the number of clients is large, implosion of feedback information at the sender is a concern. To handle receiver rate heterogeneity and avoid feedback implosion, a number of researchers have considered the use of multiple channels with receiver-driven rate adaptation <ref> [22, 23, 13, 10] </ref>. The idea is that the sender uses multiple channels, each addressed as a separate multicast group. Each receiver subscribes to set of channels (i.e., joins the corresponding multicast groups) commensurate with its own rate capabilities.
Reference: [23] <author> Lorenzo Vicisano, Luigi Rizzo, and Jon Crowcroft. </author> <title> TCP-like congestion control for layered multicast data transfer. </title> <booktitle> In Proceedings of Infocom'98, </booktitle> <pages> pages 996-1003, </pages> <month> March </month> <year> 1998. </year> <month> ftp://cs.ucl.ac.uk/darpa/infocom98.ps. </month>
Reference-contexts: Third, if the number of clients is large, implosion of feedback information at the sender is a concern. To handle receiver rate heterogeneity and avoid feedback implosion, a number of researchers have considered the use of multiple channels with receiver-driven rate adaptation <ref> [22, 23, 13, 10] </ref>. The idea is that the sender uses multiple channels, each addressed as a separate multicast group. Each receiver subscribes to set of channels (i.e., joins the corresponding multicast groups) commensurate with its own rate capabilities. <p> The SO scheme outperforms the CO scheme for the metrics reported by Vicisano [20], thus we focus our comparisons on the SO scheme. Vicisano et al. have also considered the use of their scheduling schemes to provide "TCP-like congestion control" with receiver-driven protocols <ref> [21, 23] </ref>.
Reference: [24] <author> J. W. Wong and M. H. Ammar. </author> <title> Analysis of broadcast delivery in the videotex system. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 34(9) </volume> <pages> 863-866, </pages> <month> September </month> <year> 1985. </year>
Reference-contexts: If the number of clients is large, the server faces challenges in scalability. A key technique for allowing the server to handle a large volume of requests is to multicast the data to the set of clients <ref> [24, 25, 8, 1, 12, 2, 14] </ref>. The application scenario outlined above makes the use of multicast difficult, however. First, the clients will typically make requests over time, without synchronization.
Reference: [25] <author> J.W. Wong and Mostafa H. Ammar. </author> <title> Response time performance of videotex systems. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> SAC-4(7):1174-80, </volume> <month> October </month> <year> 1986. </year> <month> 23 </month>
Reference-contexts: If the number of clients is large, the server faces challenges in scalability. A key technique for allowing the server to handle a large volume of requests is to multicast the data to the set of clients <ref> [24, 25, 8, 1, 12, 2, 14] </ref>. The application scenario outlined above makes the use of multicast difficult, however. First, the clients will typically make requests over time, without synchronization.
References-found: 25

