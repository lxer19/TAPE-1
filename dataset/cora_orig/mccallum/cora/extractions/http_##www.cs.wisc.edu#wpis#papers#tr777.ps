URL: http://www.cs.wisc.edu/wpis/papers/tr777.ps
Refering-URL: http://www.cs.wisc.edu/wpis/papers/
Root-URL: http://www.cs.wisc.edu
Title: 1 The Semantics of Program Slicing  
Author: THOMAS REPS and WUU YANG 
Keyword: Categories and Subject Descriptors: D.2.7 [Software Engineering]: Distribution and Maintenance enhancement, restructuring, version control; D.2.9 [Software Engineering]: Management programming teams, software configuration management; D.3.4 [Programming Languages]: Processors compilers, interpreters, optimization; E.1 [Data Structures] graphs General Terms: Theory Additional Key Words and Phrases: control dependence, data dependence, data-flow analysis, dependence graph, program slice, program integration, semantics, termination  
Address: Wisconsin Madison  
Affiliation: University of  
Abstract: A slice of a program with respect to a program point p and variable x consists of all statements of the program that might affect the value of x at point p. Slices can be extracted particularly easily from a program representation called a dependence graph, originally introduced as an intermediate program representation for performing optimizing, vector-izing, and parallelizing transformations. Such slices are of a slightly restricted form: rather than permitting a program to be sliced with respect to program point p and an arbitrary variable, a slice must be taken with respect to a variable that is defined at or used at p. This paper concerns the relationship between the execution behavior of a program and the execution behavior of its slices. Our main results are those stated as the Slicing Theorem and the Termination Theorem. The Slicing Theorem demonstrates that a slice captures a portion of a program's behavior in the sense that, for any initial state on which the program halts, the program and the slice compute the same sequence of values for each element of the slice. The Termination Theorem demonstrates that if a program is decomposed into (two or more) slices, the program halts on any state for which all the slices halt. These results are used to provide semantic justification for a program-integration algorithm of Horwitz, Prins, and Reps. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Aho, A., Sethi, R., and Ullman, J., </author> <booktitle> Compilers: Principles, Techniques and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1986). </address>
Reference-contexts: In addition, G P includes three other categories of vertices: 1) There is a distinguished vertex called the entry vertex. 2) For each variable x for which there is a path in the standard control-flow graph for P on which x is used before being defined (see <ref> [1] </ref>), there is a vertex called the initial definition of x. This vertex represents an assignment to x from the initial state. <p> That is, there is a path in the standard control-flow graph for the program <ref> [1] </ref> by which the definition of x at v 1 reaches the use of x at v 2 . (Initial definitions of variables are considered to occur at the beginning of the control-flow graph, and final uses of variables are considered to occur at its end.) A flow dependence that exists
Reference: 2. <author> Felleisen, M. and Cartwright, R., </author> <title> A semantic basis for program dependence graphs, Extended abstract, </title> <institution> Department of Computer Science, Rice University, Houston, TX (December 1987). </institution>
Reference-contexts: A different approach, using the language's denotational semantics, has been developed by Felleisen and Cartwright in <ref> [2] </ref>. Through a sequence of steps that restructure the language's semantic equations, Fel-leisen and Cartwright decompose the meaning function into two subsidiary functions: one that constructs (a structure similar to) a program dependence graph, and one that interprets these graphs. <p> UW Madison Technical Report #777 - 29 - transformations' correctness leads directly to an analogue of the Equivalence Theorem. It should be pointed out that there is a difference in philosophy between this paper and <ref> [2] </ref> concerning program termination. The semantics developed by Felleisen and Cartwright (as well as the corresponding dependence graph that they derive) incorporates the notion that an . . . assignment makes no sense if a previous assignment to the variable aborts [2]. <p> is a difference in philosophy between this paper and <ref> [2] </ref> concerning program termination. The semantics developed by Felleisen and Cartwright (as well as the corresponding dependence graph that they derive) incorporates the notion that an . . . assignment makes no sense if a previous assignment to the variable aborts [2]. This is in contrast with the semantics of slices obtained with our definitions of program dependence graphs and program slicing; because a diverging computation may be sliced out of a program, a program slice may converge on some initial states for which the original program diverges. <p> For this phenomenon to be captured with techniques like the ones used by Felleisen and Cartwright, a different demand semantics than the one presented in <ref> [2] </ref> is required.
Reference: 3. <author> Ferrante, J., Ottenstein, K., and Warren, J., </author> <title> The program dependence graph and its use in optimization, </title> <journal> ACM Transactions on Programming Languages and Systems 9(3) pp. </journal> <month> 319-349 (July </month> <year> 1987). </year>
Reference-contexts: The program dependence graphs defined in <ref> [3] </ref> introduced the additional feature of an explicit representation for control dependences (see below). Although the definition of program dependence graph given below covers only the restricted language described earlier, and hence is less general than the one given in [3], the structures we define share the feature of representing both <p> The program dependence graphs defined in <ref> [3] </ref> introduced the additional feature of an explicit representation for control dependences (see below). Although the definition of program dependence graph given below covers only the restricted language described earlier, and hence is less general than the one given in [3], the structures we define share the feature of representing both control and data dependences and we will refer to them as program dependence graphs, borrowing the term from [3]. <p> dependence graph given below covers only the restricted language described earlier, and hence is less general than the one given in <ref> [3] </ref>, the structures we define share the feature of representing both control and data dependences and we will refer to them as program dependence graphs, borrowing the term from [3]. <p> A method for determining control dependence edges for arbitrary programs is given in <ref> [3] </ref>; however, because we are assuming that programs include only assignment, conditional, and while statements, the control dependence edges of G P can be determined in a much simpler fashion.
Reference: 4. <author> Horwitz, S., Prins, J., and Reps, T., </author> <title> Integrating non-interfering versions of programs, </title> <type> Technical Report 690, </type> <institution> Department of Computer Sciences, University of WisconsinMadison (March 1987). </institution>
Reference-contexts: The data-dependence edges of a program dependence graph are computed using data-flow analysis. For the restricted language considered in this paper, the necessary computations can be defined in a syntax-directed manner (see <ref> [4] </ref>).
Reference: 5. <author> Horwitz, S., Prins, J., and Reps, T., </author> <title> Integrating non-interfering versions of programs, pp. </title> <booktitle> 133-145 in Conference Record of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <address> (San Diego, CA, </address> <month> January 13-15, </month> <year> 1988), </year> <booktitle> ACM, </booktitle> <address> New York (1988). </address>
Reference-contexts: Program slicing can be used to isolate individual computation threads within a program, which can help a programmer understand complicated code. Program slicing is also used by the algorithm for automatically integrating program variants described in <ref> [5] </ref> and [12]; slices are used to compute a safe approximation to the computation threads that have changed between a program P and a modified version of P, and to help determine whether two different modifications to P interfere. hhhhhhhhhhhhhhhhhhhhhhhhhhhhh This work was supported in part by the National Science Foundation <p> However, it is possible that there is no such program; that is, the merged graph may be an infeasible program dependence graph. This is the second kind of interference that may occur. (The reader is referred to <ref> [5] </ref> for a discussion of reconstructing a program from the merged program dependence graph and the inherent difficulties of this problem.) If neither kind of interference occurs, one of the programs that corresponds to the graph G M is returned as the result of the integration operation. 6.1.
Reference: 6. <author> Horwitz, S., Prins, J., and Reps, T., </author> <title> On the adequacy of program dependence graphs for representing programs, pp. </title> <booktitle> 146-157 in Conference Record of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <address> (San Diego, CA, </address> <month> January 13-15, </month> <year> 1988), </year> <booktitle> ACM, </booktitle> <address> New York (1988). </address>
Reference-contexts: The boldface arrows represent control dependence edges, dashed arrows represent def-order dependence edges, solid arrows represent loop-independent flow dependence edges, and solid arrows with a hash mark represent loop-carried flow dependence edges. The relationship between a program's PDG and the program's execution behavior has been addressed in <ref> [6] </ref>. In particular, it is shown in [6] that if the PDGs of two programs are isomorphic then the programs have the same behavior. The concept of programs with the same behavior is formalized as the concept of strong equivalence, defined as follows: DEFINITION. <p> The relationship between a program's PDG and the program's execution behavior has been addressed in <ref> [6] </ref>. In particular, it is shown in [6] that if the PDGs of two programs are isomorphic then the programs have the same behavior. The concept of programs with the same behavior is formalized as the concept of strong equivalence, defined as follows: DEFINITION. <p> If P and Q are not strongly equivalent, we say they are inequivalent. The term divergence refers to both non-termination (for example, because of infinite loops) and abnormal termination (for example, because of division by zero or the use of an out-of-bounds array index). The main result of <ref> [6] </ref> is the following theorem: (the symbol denotes isomorphism between program dependence graphs). THEOREM. (EQUIVALENCE THEOREM). If P and Q are programs for which G P G Q , then P and Q are strongly equivalent. <p> Therefore, the slice of a feasible PDG is always a feasible PDG. ` Note that there may be programs other than Q whose program dependence graph is isomorphic to G Q . By the Equivalence Theorem, all such programs are strongly equivalent to Q <ref> [6] </ref>. Since a slice of a feasible program dependence graph is feasible, and programs with isomorphic program dependence graphs are strongly equivalent, we can speak of a slice of a program as well as a slice of a program dependence graph. <p> Similarly, there are loop-independent flow edges from all of the initial-definition vertices; thus, the imported variables of a program P consist of those variables that may get their values from the initial state. The Self-Equivalence Lemma The Self-Equivalence Lemma, proved in <ref> [6] </ref>, shows that the definitions of imported and exported variables are consistent with each other and can be used to characterize the state-transforming properties of a sub-tree. LEMMA. (SELF-EQUIVALENCE LEMMA). Let T be a subtree of program P. <p> A Strong Form of the Equivalence Theorem The Equivalence Theorem, which states that programs with isomorphic program dependence graphs are strongly equivalent with respect to the imported and exported variables, was proven in <ref> [6] </ref>. To prove the Slicing Theorem, we need a stronger form of the Equivalence Theorem, which states that, when initiated on the same state, programs with isomorphic program dependence graphs are not only strongly equivalent but actually compute the same sequence of values at each corresponding program point. In [6] the <p> in <ref> [6] </ref>. To prove the Slicing Theorem, we need a stronger form of the Equivalence Theorem, which states that, when initiated on the same state, programs with isomorphic program dependence graphs are not only strongly equivalent but actually compute the same sequence of values at each corresponding program point. In [6] the Equivalence Theorem follows as a corollary of the following lemma: LEMMA. (EQUIVALENCE LEMMA). Suppose that P and Q are programs for which G P G Q . <p> RELATION TO PREVIOUS WORK This paper continues the study of program dependence graphs and program semantics begun in <ref> [6] </ref>. The Equivalence Theorem proven in [6] addresses the relationship between isomorphic PDGs; the Equivalence Theorem shows that if the program dependence graphs of two programs are isomorphic then the programs are strongly equivalent (i.e. given the same initial state, either both diverge or both halt in the same final state). <p> RELATION TO PREVIOUS WORK This paper continues the study of program dependence graphs and program semantics begun in <ref> [6] </ref>. The Equivalence Theorem proven in [6] addresses the relationship between isomorphic PDGs; the Equivalence Theorem shows that if the program dependence graphs of two programs are isomorphic then the programs are strongly equivalent (i.e. given the same initial state, either both diverge or both halt in the same final state). <p> In UW Madison Technical Report #777 - 28 - particular, the relative order of Q's statements is not necessarily the same as in P. This generalization is justified by the Equivalence Theorem from <ref> [6] </ref> together with the Feasibility Lemma from this paper. <p> When def-order dependences are used in program dependence graphs, larger classes of strongly equivalent programs have isomorphic program dependence graphs than when output dependences are used <ref> [6] </ref>. <p> In Section 6, the Slicing and Termination Theorems are used to show that the program that results from a successful integration operation preserves the changed behaviors of the two variants as well as the unchanged behavior of the base program. Both this paper and <ref> [6] </ref> make use of the programming language's operational semantics to relate program dependence graphs to program semantics.
Reference: 7. <author> Kuck, D. J., Muraoka, Y., and Chen, S. C., </author> <title> On the number of operations simultaneously executable in FORTRAN-like programs and their resulting speed-up, </title> <journal> IEEE Transactions on Computers C-21, </journal> <pages> pp. </pages> <month> 1293-1310 (December </month> <year> 1972). </year>
Reference-contexts: Henceforth, we use program and abstract syntax tree synonymously. 2.1. The Program Dependence Graph Different definitions of program dependence representations have been given, depending on the intended application; they are all variations on a theme introduced in <ref> [7, 14, 8, 9] </ref>, and share the common feature of having an explicit representation of data dependences (see below). The program dependence graphs defined in [3] introduced the additional feature of an explicit representation for control dependences (see below).
Reference: 8. <author> Kuck, </author> <title> D.J., </title> <booktitle> The Structure of Computers and Computations, </booktitle> <volume> Vol. 1, </volume> <publisher> John Wiley and Sons, </publisher> <address> New York, NY (1978). </address>
Reference-contexts: Henceforth, we use program and abstract syntax tree synonymously. 2.1. The Program Dependence Graph Different definitions of program dependence representations have been given, depending on the intended application; they are all variations on a theme introduced in <ref> [7, 14, 8, 9] </ref>, and share the common feature of having an explicit representation of data dependences (see below). The program dependence graphs defined in [3] introduced the additional feature of an explicit representation for control dependences (see below).
Reference: 9. <author> Kuck, D.J., Kuhn, R.H., Leasure, B., Padua, D.A., and Wolfe, M., </author> <title> Dependence graphs and compiler optimizations, pp. </title> <booktitle> 207-218 in Conference Record of the Eighth ACM Symposium on Principles of Programming Languages, </booktitle> <address> (Williamsburg, VA, </address> <month> January 26-28, </month> <year> 1981), </year> <booktitle> ACM, </booktitle> <address> New York (1981). </address>
Reference-contexts: Henceforth, we use program and abstract syntax tree synonymously. 2.1. The Program Dependence Graph Different definitions of program dependence representations have been given, depending on the intended application; they are all variations on a theme introduced in <ref> [7, 14, 8, 9] </ref>, and share the common feature of having an explicit representation of data dependences (see below). The program dependence graphs defined in [3] introduced the additional feature of an explicit representation for control dependences (see below).
Reference: 10. <author> Ottenstein, K.J. and Ottenstein, L.M., </author> <title> The program dependence graph in a software development environment, </title> <booktitle> Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <address> (Pittsburgh, PA, </address> <month> April 23-25, </month> <year> 1984), </year> <journal> ACM SIGPLAN Notices 19(5) pp. </journal> <month> 177-184 (May </month> <year> 1984). </year>
Reference-contexts: Dayton St., Madison, WI 53706. UW Madison Technical Report #777 - 2 - The original algorithm given for program slicing was expressed as a sequence of data flow analysis problems [16]. An alternative (and more practical) approach was put forward in <ref> [10] </ref>, where it was pointed out that the slice of a program with respect to an initial set of vertices could be computed by walking backwards over the edges of the program dependence graphs being proposed as the internal representation of programs in a program development environment. <p> Earlier work on program slicing includes [15], [16], and <ref> [10] </ref>. All of this previous work imposes the condition that a slice be a program whose statements are in the same relative order that they are in the ori ginal program. <p> The idea of extracting a program slice by walking backwards over dependence edges appears in <ref> [10] </ref>, 6 although that paper gives no justification for the operation.
Reference: 11. <author> Reps, T. and Teitelbaum, T., </author> <title> The Synthesizer Generator, pp. </title> <booktitle> 42-48 in Proceeding of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> , <address> Pittsburgh, PA (April 23-25, </address> <year> 1984). </year>
Reference: 12. <author> Reps, T. and Horwitz, S., </author> <title> Semantics-based program integration, pp. </title> <booktitle> 1-20 in Proceedings of the Second European Symposium on Programming, </booktitle> <address> (Nancy, Franc e, March 21-24, </address> <year> 1988), </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Vol. 300, </volume> <editor> ed. H. Ganzinger,Springer-Verlag, </editor> <address> New York, NY (1988). </address> <note> UW Madison Technical Report #777 - 30 </note> - 
Reference-contexts: Program slicing can be used to isolate individual computation threads within a program, which can help a programmer understand complicated code. Program slicing is also used by the algorithm for automatically integrating program variants described in [5] and <ref> [12] </ref>; slices are used to compute a safe approximation to the computation threads that have changed between a program P and a modified version of P, and to help determine whether two different modifications to P interfere. hhhhhhhhhhhhhhhhhhhhhhhhhhhhh This work was supported in part by the National Science Foundation under grant
Reference: 13. <author> Reps, T. and Teitelbaum, T., </author> <title> The Synthesizer Generator: A system for constructing language-based editors, </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY (1988). </address>
Reference: 14. <author> Towle, R., </author> <title> Control and data dependence for program transformations, </title> <type> TR 76-788, </type> <institution> Department of Computer Science, University of Illinois, Urbana-Champaign, </institution> <address> IL (March 1976). </address>
Reference-contexts: Henceforth, we use program and abstract syntax tree synonymously. 2.1. The Program Dependence Graph Different definitions of program dependence representations have been given, depending on the intended application; they are all variations on a theme introduced in <ref> [7, 14, 8, 9] </ref>, and share the common feature of having an explicit representation of data dependences (see below). The program dependence graphs defined in [3] introduced the additional feature of an explicit representation for control dependences (see below).
Reference: 15. <author> Weiser, M., </author> <title> Program slices: Formal, psychological, and practical investigations of an automatic program abstraction method., </title> <type> Ph.D. dissertation, </type> <institution> University of Michigan, </institution> <address> Ann Arbor, MI (1979). </address> <note> As reported by personal communication from M. Weiser, </note> <month> July </month> <year> 1988. </year>
Reference-contexts: Earlier work on program slicing includes <ref> [15] </ref>, [16], and [10]. All of this previous work imposes the condition that a slice be a program whose statements are in the same relative order that they are in the ori ginal program. <p> This generalization is justified by the Equivalence Theorem from [6] together with the Feasibility Lemma from this paper. A version of the Slicing Theorem (for the more limited notion of slice described above) was demonstrated in <ref> [15] </ref>; it applies to a different algorithm for extracting slices, based on solving a sequence of data-flow problems, rather than the one studied here, which is based on walking backwards over the edges of a program dependence graph.
Reference: 16. <author> Weiser, M., </author> <title> Program slicing, </title> <journal> IEEE Transactions on Software Engineering SE-10(4) pp. </journal> <month> 352-357 (July </month> <year> 1984). </year> <type> UW Madison Technical Report #777 </type>
Reference-contexts: 1. INTRODUCTION The slice of a program with respect to program point p and variable x consists of all statements and predicates of the program that might affect the value of x at point p <ref> [16] </ref>. Program slicing can be used to isolate individual computation threads within a program, which can help a programmer understand complicated code. <p> Authors' address: Computer Sciences Department, University of Wisconsin, 1210 W. Dayton St., Madison, WI 53706. UW Madison Technical Report #777 - 2 - The original algorithm given for program slicing was expressed as a sequence of data flow analysis problems <ref> [16] </ref>. <p> Earlier work on program slicing includes [15], <ref> [16] </ref>, and [10]. All of this previous work imposes the condition that a slice be a program whose statements are in the same relative order that they are in the ori ginal program. <p> Their proof of the hhhhhhhhhhhhhhhhhhhhhhhhhhhhh 6 As pointed out earlier, the kind of slicing that can be performed using a program dependence graph is more restricted than the kind that can be performed with Weiser's algorithm <ref> [16] </ref>: rather than permitting a program to be sliced with respect to program point p and an arbitrary variable, a slice must be taken with respect to a variable that is defined at or used at p.
References-found: 16

