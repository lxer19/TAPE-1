URL: http://www.cs.pitt.edu/~gupta/research/Comp/cc98.ps
Refering-URL: http://www.cs.pitt.edu/~gupta/research/scheduling.html
Root-URL: 
Title: A Code Motion Framework for Global Instruction Scheduling  
Author: Rajiv Gupta 
Address: Pittsburgh, Pittsburgh, PA 15260, USA  
Affiliation: Dept. of Computer Science, Univ. of  
Abstract: A framework for global instruction scheduling is developed that progressively improves a given instruction schedule by eliminating delay slots in the schedule one at a time through the application of global code motions. The elimination of a delay slot is carried out in two steps: a goal oriented search which identifies a global code motion or a cascade of code motions that eliminate the delay without introducing additional delay slots in critical areas of the program; and a transformation step in which the code motion is performed along with compensation code placement and application of code optimizations enabled by code motion. The framework is powerful in that it incorporates code hoisting, including speculative hoisting, code sinking, and integrates partial redundancy elimination and partial dead code elimination optimizations with the code motion transformations. The framework is flexible in that it allows formulation of new as well as existing powerful scheduling strategies, allows restrictions to be placed on the type of instructions involved in code motion, the program regions from which the instructions can be selected for code motion, and the extent to which code motion alternatives are explored. The framework is efficient because it computes the required data dependence information on demand from the program control flow graph. Thus, it neither requires exhaustive precomputation of all data dependencies and nor their representation in form of a dependence graph prior to scheduling.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> T. Ball and J. Larus, </author> <title> "Efficient Path Profiling," </title> <booktitle> 29th Annual IEEE/ACM Interna tional Symposium on Microarchitecture, </booktitle> <address> Paris, France, </address> <year> 1996. </year>
Reference-contexts: In particular, code motion between different loops is not permitted. The paths in the region are divided into two categories, critical paths and non-critical paths, based upon path profiling information <ref> [1] </ref>. For the purpose of constructing these paths, each nested loop is viewed as being replaced by a single summary node. The elimination of the delay slot is carried out through a code motion that can only improve the schedules along critical paths.
Reference: 2. <author> E. Duesterwald, R. Gupta, </author> <title> and M.L. Soffa, "A Practical Framework for Demand Driven Interprocedural Data Flow Analysis," </title> <note> to appear ACM Transactions on Programming Languages and Systems, </note> <month> November </month> <year> 1998. </year>
Reference-contexts: These constraints are computed on demand as the search for an instruction to fill the delay slot progresses. The advantages of demand-driven analyzers have been demonstrated in <ref> [2] </ref>. Data dependences along critical paths are maintained separately from noncritical paths. In Figure 2 the data dependence information for the path 3-4-6-7-8-11-10 is maintained separately from all other paths. <p> Similarly in other situations we may be able to determine that a statement can be hoisted to a certain program point by consulting the cache. The cost of analysis over the subgraphs can be further reduced using demand-driven analysis techniques presented in <ref> [2] </ref>. These techniques answer a data flow 11 query at a program point by searching for its solution starting at the program point. The search is terminated when the solution is known. Thus, we can often expect the search to terminate before examining the entire subgraph.
Reference: 3. <author> J.A. Fisher, </author> <title> "Trace Scheduling: A Technique for Global Microcode Compaction," </title> <journal> IEEE Transactions on Computers, </journal> <volume> 30(7), </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: Not only are the two tasks individually complex, interactions among code optimizations and instruction scheduling exist that further affect the overall performance of the generated code. A variety of instruction scheduling techniques have been developed <ref> [3, 7, 8, 11] </ref>. These techniques differ in the program representations they use, the types of transformations they are able to perform, and the heuristics used to determine the order in which program regions are scheduled. <p> Primarily by limiting the global scope over which code motion can be performed is sufficient to emulate these techniques. Trace Scheduling <ref> [3] </ref>: In this technique the critical part is limited to a trace which is a sequence of consecutive basic blocks along a program path. A trace cannot extend across loop boundaries.
Reference: 4. <author> R. Gupta, D.A. Berson, and J.Z. Fang, </author> <title> "Path Profile Guided Partial Dead Code Elimination Using Predication," </title> <booktitle> Intl. Conf. on Parallel Arch. and Compilation Techniques, </booktitle> <pages> pages 102-115, </pages> <address> San Francisco, California, </address> <month> November </month> <year> 1997. </year>
Reference-contexts: The anticipability and liveness conditions require that the data flow information be computed with respect to different categories of paths. Conventional analysis techniques compute data flow with respect to all program paths. An approach for path-sensitive analysis was introduced in <ref> [4, 5] </ref> where in addition to computing a data flow fact at a program point, the set of paths along which the fact holds is also computed.
Reference: 5. <author> R. Gupta, D.A. Berson, and J.Z. Fang, </author> <title> "Resource-Sensitive Profile-Directed Data Flow Analysis for Code Optimization," </title> <booktitle> 30th IEEE/ACM Intl. Symp. on Microarchi-tecture, </booktitle> <pages> pages 558-568, </pages> <address> Research Triangle Park, NC, </address> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: The anticipability and liveness conditions require that the data flow information be computed with respect to different categories of paths. Conventional analysis techniques compute data flow with respect to all program paths. An approach for path-sensitive analysis was introduced in <ref> [4, 5] </ref> where in addition to computing a data flow fact at a program point, the set of paths along which the fact holds is also computed.
Reference: 6. <author> R. Gupta, </author> <title> "Code Optimization as a Side Effect of Instruction Scheduling," </title> <booktitle> Intl. Conf. on High Perf. Computing, </booktitle> <pages> pages 370-377, </pages> <address> Bangalore, India, </address> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: This algorithm is an extension of the PRE algorithm proposed by Knoop et al. [9]. The first extension is to handle speculative code motion. The second extension enables discovery of a placement in which one of the positions is the delay slot. More details can be found in <ref> [6] </ref> The PDE optimization eliminates dead executions of statements that may be present along certain program paths. An execution of an assignment statement is considered to be partially dead if along some program path leading from the assignment, the value computed by the assignment is never used.
Reference: 7. <author> R. Gupta and M.L. Soffa, </author> <title> "Region Scheduling: An Approach for Detecting and Redistributing Parallelism," </title> <journal> IEEE Trans. on Software Eng., </journal> <volume> 16(4) </volume> <pages> 421-431, </pages> <year> 1990. </year>
Reference-contexts: Not only are the two tasks individually complex, interactions among code optimizations and instruction scheduling exist that further affect the overall performance of the generated code. A variety of instruction scheduling techniques have been developed <ref> [3, 7, 8, 11] </ref>. These techniques differ in the program representations they use, the types of transformations they are able to perform, and the heuristics used to determine the order in which program regions are scheduled. <p> Trace scheduling does not exploit PRE/PDE opportunities enabled by code motion. Region Scheduling <ref> [7] </ref>: Here first a program dependence graph representation of the program is constructed and then instruction scheduling is carried out by first reordering code within a control region and then performing code motions across control dependent regions.
Reference: 8. <author> W-M. Hwu, S.A. Mahlke, W.Y. Chen, P.P. Chang, N.J. Warter, R.A. Bringmann, R.G. Ouellette, R.E. Hank, T. Kiyohara, G.E. Haab, J.G. Holm, </author> <title> and D.M. Lavery, "The Superblock: An Effective Technique for VLIW and Superscalar Compilation," </title> <journal> Journal of Supercomputing, </journal> <volume> A:229-248, </volume> <year> 1993. </year>
Reference-contexts: Not only are the two tasks individually complex, interactions among code optimizations and instruction scheduling exist that further affect the overall performance of the generated code. A variety of instruction scheduling techniques have been developed <ref> [3, 7, 8, 11] </ref>. These techniques differ in the program representations they use, the types of transformations they are able to perform, and the heuristics used to determine the order in which program regions are scheduled. <p> In addition, the space and time overhead of constructing the program dependence graph is significant. Other PDG based scheduling techniques also suffer from similar drawbacks and do not incorporate PRE and PDE optimizations. Superblock Scheduling <ref> [8] </ref>: In this technique before instruction scheduling is carried out, tail duplication is performed to eliminate code following merge points in the program. Code reordering performed on the resulting superblocks does not result in any compensation code. However, this simplification comes at the cost of significant code growth.
Reference: 9. <author> J. Knoop, O. Ruthing, and B. Steffen, </author> <title> "Lazy Code Motion," </title> <booktitle> ACM SIGPLAN Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 224-234, </pages> <year> 1992. </year>
Reference-contexts: We have developed an algorithm for compensation code placement which performs PRE. This algorithm is an extension of the PRE algorithm proposed by Knoop et al. <ref> [9] </ref>. The first extension is to handle speculative code motion. The second extension enables discovery of a placement in which one of the positions is the delay slot.
Reference: 10. <author> J. Knoop, O. Ruthing, and B. Steffen, </author> <title> "Partial Dead Code Elimination," </title> <booktitle> ACM SIGPLAN Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 147-158, </pages> <year> 1994. </year>
Reference-contexts: In such situations acyclic schedulers sink the statement to the point where the statement becomes fully dead and hence can be entirely eliminated from the critical path. The algorithm for compensation code placement is a straightforward adaptation of the PDE algorithm proposed by Knoop et al. <ref> [10] </ref>.
Reference: 11. <author> M. Schlansker and V. Kathail, </author> <title> "Critical Path Reduction for Scalar Programs," </title> <booktitle> 28th Annual IEEE/ACM International Symposium on Microarchitecture, </booktitle> <month> Nov. </month> <year> 1995. </year> <title> 15 This article was processed using the L a T E X macro package with LLNCS style 16 </title>
Reference-contexts: Not only are the two tasks individually complex, interactions among code optimizations and instruction scheduling exist that further affect the overall performance of the generated code. A variety of instruction scheduling techniques have been developed <ref> [3, 7, 8, 11] </ref>. These techniques differ in the program representations they use, the types of transformations they are able to perform, and the heuristics used to determine the order in which program regions are scheduled. <p> In some situations a critical path in the program may not contain any delay. However, it still may be possible to speedup this path by propagating instructions from it to other less frequently executed paths <ref> [11] </ref>. This task can be performed by artificially introducing delays in the less frequently executed parts to serve as destinations for instructions that may be moved from the more critical paths. Consider the example in Figure 1 (c). It shows a scheduling region which contains the critical path 1-2-3-4-6. <p> However, this simplification comes at the cost of significant code growth. The framework presented in this paper supports a powerful algorithm for generating optimized compensation code and therefore avoids unnecessary code growth due to tail duplication. Critical Path Reduction <ref> [11] </ref>: In this technique the scheduling region being scheduled consists of a multiple entry multiple exit acyclic region. The region exits are classified into two categories, frequently taken and infrequently taken.
References-found: 11

