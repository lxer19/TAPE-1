URL: http://www.eecs.umich.edu/~dpennock/homepage/papers/parallel-final.ps
Refering-URL: http://www.eecs.umich.edu/~dpennock/homepage/resume.html
Root-URL: http://www.cs.umich.edu
Email: dpennock@umich.edu  
Title: Logarithmic Time Parallel Bayesian Inference  
Author: David M. Pennock 
Address: 1101 Beal Avenue Ann Arbor, MI 48109-2110 USA  
Affiliation: University of Michigan AI Laboratory  
Note: In Proceedings of the Fourteenth Annual Conference on Uncertainty in Artificial Intelligence [UAI-98], Madison, WI, USA, July 1998. To Appear.  
Abstract: I present a parallel algorithm for exact probabilistic inference in Bayesian networks. For polytree networks with n variables, the worst-case time complexity is O(log n) on a CREW PRAM (concurrent-read, exclusive-write parallel random-access machine) with n processors, for any constant number of evidence variables. For arbitrary networks, the time complexity is O(r 3w log n) for n processors, or O(w log n) for r 3w n processors, where r is the maximum range of any variable, and w is the induced width (the maximum clique size), after moralizing and trian gulating the network.
Abstract-found: 1
Intro-found: 1
Reference: <author> Abrahamson, K., N. Dadoun, D. G. Kirkpatrick, and T. </author> <month> Przyttycka </month> <year> (1989). </year> <title> A simple parallel tree contraction algorithm. </title> <journal> Journal of Algorithms 10, </journal> <pages> 287-302. </pages>
Reference: <author> Chyu, C. C. </author> <year> (1991). </year> <title> Decomposable probabilistic influence diagrams. </title> <booktitle> Probability in the Engineering and Informational Sciences 5, </booktitle> <pages> 229-243. </pages>
Reference: <author> Cooper, G. </author> <year> (1990). </year> <title> The computational complexity of probabilistic inference using Bayes belief networks. </title> <booktitle> Artificial Intelligence 42, </booktitle> <pages> 393-405. </pages>
Reference-contexts: Bayesian networks exploit conditional independence to represent joint probability distributions compactly, and associated inference algorithms evaluate arbitrary conditional probabilities implied by the network representation (Neapolitan 1990; Pearl 1988). Exact inference is known to be NP-hard (more specifically, #P-complete) <ref> (Cooper 1990) </ref>, and even approximate inference is NP-hard (Dagum and Luby 1993). Nonetheless, clever algorithms exploit network topology to make exact probabilistic reasoning practical for a wide variety of real-world applications.
Reference: <author> Cormen, T. H., C. E. Leiserson, and R. L. </author> <title> Rivest (1992). Introduction to Algorithms. </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference: <author> Dagum, P. and M. </author> <title> Luby (1993). Approximating probabilistic inference in Bayesian belief networks is NP-hard. </title> <booktitle> Artificial Intelligence 60, </booktitle> <pages> 141-153. </pages>
Reference-contexts: Bayesian networks exploit conditional independence to represent joint probability distributions compactly, and associated inference algorithms evaluate arbitrary conditional probabilities implied by the network representation (Neapolitan 1990; Pearl 1988). Exact inference is known to be NP-hard (more specifically, #P-complete) (Cooper 1990), and even approximate inference is NP-hard <ref> (Dagum and Luby 1993) </ref>. Nonetheless, clever algorithms exploit network topology to make exact probabilistic reasoning practical for a wide variety of real-world applications.
Reference: <author> D'Ambrosio, B. </author> <year> (1992). </year> <title> Parallelizing probabilistic inference: Some early explorations. </title> <booktitle> In Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence (UAI-92), </booktitle> <address> Portland, OR, USA, </address> <pages> pp. 59-66. </pages>
Reference: <author> Delcher, A. L., A. J. Grove, S. Kasif, and J. Pearl (1996, </author> <month> February). </month> <title> Logarithmic-time updates and queries in probabilistic networks. </title> <journal> Journal of Artificial Intelligence Research 4, </journal> <pages> 37-59. </pages>
Reference: <author> Diez, F. J. and J. </author> <month> Mira </month> <year> (1994, </year> <month> January). </month> <title> Distributed inference in Bayesian networks. </title> <booktitle> Cybernetics and Systems 25(1), </booktitle> <pages> 39-61. </pages>
Reference: <author> Gibbons, A. and P. </author> <title> Spirakis (1993). </title> <booktitle> Lectures on Parallel Computation. </booktitle> <address> Cambridge, UK: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> JaJa, J. </author> <year> (1992). </year> <title> An Introduction to Parallel Algorithms. </title> <address> Reading, MA, USA: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Jensen, F. V., S. L. Lauritzen, and K. G. </author> <month> Olesen </month> <year> (1990). </year> <title> Bayesian updating in causal probabilistic networks by local computations. </title> <journal> Computational Statistics Quarterly 4, </journal> <pages> 269-282. </pages>
Reference: <author> Klocks, T. </author> <year> (1994). </year> <title> Treewidth: Computations and Approximations. </title> <publisher> Berlin: Springer-Verlag. </publisher>
Reference-contexts: The induced width w of a network, relative to an ordering ff, is defined as the maximum number of nodes in any clique, after moralization and fill-in. Computing the optimal ff, or equivalently the optimal triangulation, that yields the minimum induced width is itself an NP-complete problem <ref> (Klocks 1994) </ref>for this reason, heuristic methods are usually employed. Serial algorithms for inference in cluster trees run in O (r w n) time.
Reference: <author> Kozlov, A. V. </author> <year> (1996, </year> <month> December). </month> <title> Parallel implementations of probabilistic inference. </title> <booktitle> Computer 29(12), </booktitle> <pages> 33-40. </pages>
Reference-contexts: They identify the same two types of con-currency (topological and in-clique), and also only considered parallelizing independent operations: computations for cliques that do not have an ancestor-descendent relationship can be done in parallel. <ref> (Kozlov 1996) </ref>. Delcher et al. (1996) give an O (log n) time serial algorithm for inference queries in tree networks, after a linear time preprocessing step to generate a special data structure.
Reference: <author> Kozlov, A. V. and J. P. Singh (1994, </author> <month> November). </month> <title> A parallel Lauritzen-Spiegelhalter algorithm for probabilistic inference. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <address> Washington, DC. </address>
Reference: <author> Lauritzen, S. L. and D. J. </author> <month> Spiegelhalter </month> <year> (1988). </year> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> Series B 50, </volume> <pages> 157-224. </pages>
Reference: <author> Miller, G. L. and J. </author> <title> Reif (1985). Parallel tree contraction and its applications. </title> <booktitle> In Proceedings of the 26th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 478-489. </pages>
Reference: <author> Neapolitan, R. E. </author> <year> (1990). </year> <title> Probabilistic Reasoning in Expert Systems: Theory and Algorithms. </title> <address> New York: </address> <publisher> John Wiley and Sons. </publisher>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Russell, S. J. and P. </author> <title> Norvig (1995). Artificial Intelligence: A Modern Approach. </title> <address> New Jersey: </address> <publisher> Prentice-Hall. </publisher>
Reference: <author> Shachter, R. D. </author> <year> (1988). </year> <title> Probabilistic inference and influence diagrams. </title> <journal> Operations Research 36(4), </journal> <pages> 589-604. </pages>
Reference: <author> Shachter, R. D. </author> <year> (1990). </year> <title> Evidence absorption and propagation through evidence reversals. </title> <editor> In M. Henrion, R. D. Shachter, L. N. Kanal, and J. F. Lemmer (Eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <volume> Volume 5, </volume> <pages> pp. 173-190. </pages> <publisher> North Holland. </publisher>
Reference: <author> Shachter, R. D., S. K. Andersen, and K. L. </author> <month> Poh </month> <year> (1991). </year> <title> Directed reduction algorithms and decomposable graphs. </title> <editor> In P. P. Bonissone, M. Henrion, L. N. Kanal, and J. F. Lemmer (Eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <volume> Volume 6, </volume> <pages> pp. 197-208. </pages> <address> Amsterdam: </address> <publisher> North Holland. </publisher>
Reference: <author> Shachter, R. D., S. K. Andersen, and P. </author> <title> Szolovits (1994). Global conditioning for probabilistic inference in belief networks. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI-94), </booktitle> <address> Portland, OR, USA, </address> <pages> pp. 514-522. </pages>
Reference: <author> Spiegelhalter, D. J., A. P. Dawid, S. L. Lauritzen, and R. G. </author> <title> Cowell (1993). Bayesian analysis in expert systems. </title> <booktitle> Statistical Science 8(3), </booktitle> <pages> 219-203. </pages>
Reference: <author> Tarjan, R. E. and U. </author> <title> Vishkin (1985, November). An efficient parallel biconnectivity algorithm. </title> <journal> SIAM Journal on Computing 14(4), </journal> <pages> 862-874. </pages>
References-found: 25

