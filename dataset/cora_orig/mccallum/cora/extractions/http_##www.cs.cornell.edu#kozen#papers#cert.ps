URL: http://www.cs.cornell.edu/kozen/papers/cert.ps
Refering-URL: http://www.cs.cornell.edu/kozen/papers/papers.html
Root-URL: 
Email: kozen@cs.cornell.edu  
Title: Efficient Code Certification  
Author: Dexter Kozen 
Date: January 8, 1998  
Address: Ithaca, NY 14853-7501  
Affiliation: Department of Computer Science Cornell University  
Abstract: We introduce a simple and efficient approach to the certification of compiled code. We ensure a basic but nontrivial level of code safety, including control flow safety, memory safety, and stack safety. The system is designed to be simple, efficient, and (most importantly) relatively painless to incorporate into existing compilers. Although less expressive than the proof carrying code of Necula and Lee or typed assembly language of Morrisett et al., our certificates are compact and relatively easy to produce and to verify. Unlike JAVA bytecode, our system operates at the level of native code; it is not interpreted and no further compilation is necessary. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Drew Dean, Ed Felten, and Dan Wallach. </author> <title> JAVA security: From HotJava to Netscape and beyond. </title> <booktitle> In 1996 IEEE Symp. Security and Privacy. IEEE, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: This notion first appeared in a practical system in the JAVA programming language. The JAVA compiler produces virtual machine instructions that can be verified by the client before execution and that are meant to provide a certain basic level of security [2]. Despite certain failings in the initial implementation <ref> [1] </ref>, it nevertheless constituted a significant step forward in practical programming language security.
Reference: [2] <author> Tim Lindholm and Frank Yellin. </author> <title> The JAVA virtual machine specification. </title> <publisher> Addison Wesley, </publisher> <year> 1996. </year>
Reference-contexts: This notion first appeared in a practical system in the JAVA programming language. The JAVA compiler produces virtual machine instructions that can be verified by the client before execution and that are meant to provide a certain basic level of security <ref> [2] </ref>. Despite certain failings in the initial implementation [1], it nevertheless constituted a significant step forward in practical programming language security. <p> The residue of a non-call block may not contain a return. Conditions reminiscent of these appear in the JAVA bytecode verifier <ref> [2] </ref>. These are straightforward and natural restrictions. They are satisfied by our compiler, and we suspect that they (or something very similar) are satisfied by compilers in general, or can be made to be satisfied fairly easily.
Reference: [3] <author> G. Morrisett, D. Tarditi, P. Cheng, C. Stone, R. Harper, and P. Lee. </author> <title> The TIL/ML compiler: Performance and safety through types. </title> <booktitle> In 1996 Workshop on Compiler Support for Systems Software, </booktitle> <year> 1996. </year>
Reference-contexts: Schneider [8, 9] identifies the class of safety properties that can be verified by these methods. In the case of TAL, typing information from a high-level program written in a strongly-typed language is carried through a series of transformations through a platform-independent typed intermediate language (TIL) <ref> [3, 10] </ref> and finally down to the level of the object code itself. The resulting type annotation can be checked by an ordinary type checker.
Reference: [4] <author> Greg Morrisett, David Walker, Karl Crary, and Neal Glew. </author> <title> From System F to typed assembly language. </title> <booktitle> In 1998 Symposium on Principles of Programming Languages. IEEE, </booktitle> <month> January </month> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Recent work by Necula and Lee [5, 6] on proof carrying code (PCC), by Mor-risett et al. <ref> [4] </ref> on typed assembly language (TAL), and by Schneider [8, 9] on automata-based security have demonstrated that general principles of logic, type theory, and program verification can be brought successfully to bear on the security problem.
Reference: [5] <author> George C. Necula. </author> <title> Proof-carrying code. </title> <booktitle> In Proc. 24th Symp. Principles of Programming Languages. ACM, </booktitle> <month> January </month> <year> 1997. </year>
Reference-contexts: It not only introduced a simple and effective approach to providing a basic level of security, but more importantly, it helped to galvanize the attention of the programming language and verification community on critical security issues engendered by the rise of the Internet. Recent work by Necula and Lee <ref> [5, 6] </ref> on proof carrying code (PCC), by Mor-risett et al. [4] on typed assembly language (TAL), and by Schneider [8, 9] on automata-based security have demonstrated that general principles of logic, type theory, and program verification can be brought successfully to bear on the security problem. <p> Although these approaches are quite expressive and general, their chief drawback is that the certificates they produce tend to be large and time-consuming to generate and to verify. For example, proofs in PCC are from 3 to 7 times the size of the object code <ref> [5, 6] </ref>. The automata-based approach of Schneider [8, 9] requires a runtime call on an automaton for each executed instruction, unless an optimizer can determine that the call is unnecessary; thus without effective optimization, runtime performance could be seriously degraded as well. <p> In a strongly typed language or with an optimizing compiler, many of these checks would be unnecessary. In such languages, the extra type information or information obtained from program flow analysis can be included in the certificate. Necula and Lee <ref> [5, 6] </ref> argue that PCC can be used to eliminate certain runtime type checks. This may be true, but to our mind it is an orthogonal issue.
Reference: [6] <author> George C. Necula and Peter Lee. </author> <title> Safe kernel extensions without run-time checking. </title> <booktitle> In Proc. 2nd Symp. Operating System Design and Implementation. ACM, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: It not only introduced a simple and effective approach to providing a basic level of security, but more importantly, it helped to galvanize the attention of the programming language and verification community on critical security issues engendered by the rise of the Internet. Recent work by Necula and Lee <ref> [5, 6] </ref> on proof carrying code (PCC), by Mor-risett et al. [4] on typed assembly language (TAL), and by Schneider [8, 9] on automata-based security have demonstrated that general principles of logic, type theory, and program verification can be brought successfully to bear on the security problem. <p> Although these approaches are quite expressive and general, their chief drawback is that the certificates they produce tend to be large and time-consuming to generate and to verify. For example, proofs in PCC are from 3 to 7 times the size of the object code <ref> [5, 6] </ref>. The automata-based approach of Schneider [8, 9] requires a runtime call on an automaton for each executed instruction, unless an optimizer can determine that the call is unnecessary; thus without effective optimization, runtime performance could be seriously degraded as well. <p> In a strongly typed language or with an optimizing compiler, many of these checks would be unnecessary. In such languages, the extra type information or information obtained from program flow analysis can be included in the certificate. Necula and Lee <ref> [5, 6] </ref> argue that PCC can be used to eliminate certain runtime type checks. This may be true, but to our mind it is an orthogonal issue.
Reference: [7] <author> Thomas W. Reps. </author> <title> Program analysis via graph reachability. </title> <editor> In J. Maluszynski, editor, </editor> <booktitle> Proc. ILPS '97: International Logic Programming Symposium, </booktitle> <pages> pages 5-19. </pages> <publisher> MIT Press, </publisher> <month> October </month> <year> 1997. </year>
Reference-contexts: This might ordinarily be done using flow analysis on the control flow graph <ref> [7] </ref>. However, with the block structure explicit, no expensive analysis is necessary. Pushes and pops are generated only in well-defined contexts, usually as part of a standard subroutine call linkage.
Reference: [8] <author> Fred B. Schneider. </author> <title> Enforceable security policies, </title> <month> September </month> <year> 1997. </year> <type> Preprint. </type>
Reference-contexts: Recent work by Necula and Lee [5, 6] on proof carrying code (PCC), by Mor-risett et al. [4] on typed assembly language (TAL), and by Schneider <ref> [8, 9] </ref> on automata-based security have demonstrated that general principles of logic, type theory, and program verification can be brought successfully to bear on the security problem. These systems are quite general and can potentially be used to express and verify a variety of safety properties. Schneider [8, 9] identifies the <p> and by Schneider <ref> [8, 9] </ref> on automata-based security have demonstrated that general principles of logic, type theory, and program verification can be brought successfully to bear on the security problem. These systems are quite general and can potentially be used to express and verify a variety of safety properties. Schneider [8, 9] identifies the class of safety properties that can be verified by these methods. <p> For example, proofs in PCC are from 3 to 7 times the size of the object code [5, 6]. The automata-based approach of Schneider <ref> [8, 9] </ref> requires a runtime call on an automaton for each executed instruction, unless an optimizer can determine that the call is unnecessary; thus without effective optimization, runtime performance could be seriously degraded as well.
Reference: [9] <author> Fred B. Schneider. </author> <title> Towards fault-tolerant and secure agentry. </title> <booktitle> In Proc. 11th International Workshop WDAG '97, volume 1320 of Lecture Notes in Computer Science, </booktitle> <pages> pages 1-14. </pages> <booktitle> SIGPLAN, </booktitle> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1997. </year>
Reference-contexts: Recent work by Necula and Lee [5, 6] on proof carrying code (PCC), by Mor-risett et al. [4] on typed assembly language (TAL), and by Schneider <ref> [8, 9] </ref> on automata-based security have demonstrated that general principles of logic, type theory, and program verification can be brought successfully to bear on the security problem. These systems are quite general and can potentially be used to express and verify a variety of safety properties. Schneider [8, 9] identifies the <p> and by Schneider <ref> [8, 9] </ref> on automata-based security have demonstrated that general principles of logic, type theory, and program verification can be brought successfully to bear on the security problem. These systems are quite general and can potentially be used to express and verify a variety of safety properties. Schneider [8, 9] identifies the class of safety properties that can be verified by these methods. <p> For example, proofs in PCC are from 3 to 7 times the size of the object code [5, 6]. The automata-based approach of Schneider <ref> [8, 9] </ref> requires a runtime call on an automaton for each executed instruction, unless an optimizer can determine that the call is unnecessary; thus without effective optimization, runtime performance could be seriously degraded as well.

References-found: 9

