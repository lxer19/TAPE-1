URL: ftp://ftp.cs.toronto.edu/pub/parallel/Krieger_etal_IEEEComp94.ps.Z
Refering-URL: http://www.eecg.toronto.edu/~okrieg/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The Alloc Stream Facility: A Redesign of Application-Level Stream I/O  
Author: Orran Krieger, Michael Stumm and Ron Unrau 
Address: Toronto, Canada M5S 1A4  
Affiliation: Computer Systems Research Institute University of Toronto  
Note: IEEE Computer, 27(3), March, 1994, pp. 75--83.  
Abstract: Technical Report CSRI-275 January, 1993 Revised January, 1994 The Computer Systems Research Institute (CSRI) is an interdisciplinary group formed to conduct research and development relevant to computer systems and their application. It is an Institute within the Faculty of Applied Science and Engineering, and the Faculty of Arts and Science, at the University of Toronto, and is supported in part by the Natural Sciences and Engineering Research Council of Canada. 
Abstract-found: 1
Intro-found: 1
Reference: [ABB + 86] <author> M. Accenta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian, and M. Young. </author> <title> Mach: a new kernel foundation for Unix development. </title> <booktitle> In Proceedings of the USENIX 1986 Summer Conference, </booktitle> <pages> pages 93-112, </pages> <year> 1986. </year>
Reference-contexts: But it can also be due to new operating system structures that are becoming more widespread, where the system is controlled by a microkernel and a set of user-level servers <ref> [RAA + 88, ABB + 86, Che88, ALBL91] </ref>.
Reference: [ALBL91] <author> T. Anderson, H. Levy, B. Bershad, and E. La-zowska. </author> <title> The interaction of architecture and operating system design. </title> <booktitle> In 4th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 108-119, </pages> <year> 1991. </year>
Reference-contexts: But it can also be due to new operating system structures that are becoming more widespread, where the system is controlled by a microkernel and a set of user-level servers <ref> [RAA + 88, ABB + 86, Che88, ALBL91] </ref>.
Reference: [BRW89] <author> A. Braunstein, M. Riley, and J. Wilkes. </author> <title> Improving the efficiency of UNIX file buffer caches. </title> <booktitle> In Proc. 12th ACM Symp. on Operating System Principles, </booktitle> <pages> pages 71-82, </pages> <year> 1989. </year>
Reference-contexts: Others have also recognized the potential performance advantage of implementing stream I/O with mapped files. For example, Unix I/O can be implemented in the operating system using mapped files, allowing the system to exploit the virtual memory hardware to improve the search time of the file cache <ref> [BRW89] </ref>. The Mach 3.0 operating system [DA92] reflects Unix I/O calls back to the application level where they are serviced using mapped files. Finally, the sfio library [KV91] uses mapped files whenever possible.
Reference: [CH93] <author> Robert A. Coyne and Harry Hulen. </author> <title> The high performance storage system. </title> <booktitle> In Proceeding of Supercomputing, </booktitle> <pages> pages 83-92, </pages> <address> Portland, Oregon, </address> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: We expect this problem to become more extreme in the future as systems become available that transparently provide access to files stored remotely <ref> [CH93] </ref> and stored in tertiary storage [KSS93]. It will be important that the application level library be able to query the source of a file to be able to optimize performance.
Reference: [Che87] <author> D. Cheriton. UIO: </author> <title> A Uniform I/O System Interface for Distributed Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 5(1) </volume> <pages> 12-46, </pages> <month> February </month> <year> 1987. </year>
Reference-contexts: The Unix I/O facility is simple, easy to use, and has proven to be versatile in that it can be applied in a uniform way to a large variety of I/O services, including disk files, terminals, pipes, networking interfaces and other low-level devices <ref> [Che87] </ref>. Nevertheless, application programs running under Unix typically do not call the Unix I/O system calls directly, but instead use higher-level facilities implemented either by the programming language (e.g.
Reference: [Che88] <author> D. R. Cheriton. </author> <title> The V Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> 31(3) </volume> <pages> 314-333, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: But it can also be due to new operating system structures that are becoming more widespread, where the system is controlled by a microkernel and a set of user-level servers <ref> [RAA + 88, ABB + 86, Che88, ALBL91] </ref>.
Reference: [CK91] <author> Ann L. Chervenak and Randy H. Katz. </author> <title> Performance of a disk array prototype. </title> <booktitle> In Proceedings of the 1991 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 188-197, </pages> <year> 1991. </year>
Reference-contexts: Moreover, in today's state-of-the-art computer systems, memory has become a critical contended resource. For example, researchers that have dramatically improved file I/O bandwidth (by introducing disk arrays [PGK88]) have found that the memory bottleneck prevents them from effectively exploiting the increased I/O bandwidth <ref> [CK91] </ref>. The amount of buffer copying therefore has a large impact on performance. Third, the cost of a system call has also been increasing relative to processor speeds [Ous90].
Reference: [DA92] <author> R. Dean and F. </author> <title> Armand. Data Movement in Ker-nelized Systems. </title> <booktitle> In Usenix Workshop on Micro-kernels and Other Kernel Architectures, </booktitle> <year> 1992. </year>
Reference-contexts: For example, Unix I/O can be implemented in the operating system using mapped files, allowing the system to exploit the virtual memory hardware to improve the search time of the file cache [BRW89]. The Mach 3.0 operating system <ref> [DA92] </ref> reflects Unix I/O calls back to the application level where they are serviced using mapped files. Finally, the sfio library [KV91] uses mapped files whenever possible. <p> Also, read and write operations are not atomic (as is the case with the system call interface). In the Mach 3.0 operating system <ref> [DA92] </ref>, Unix I/O is implemented by an emulation library where the library and the file system cooperate to: 1) handle file offsets shared by multiple applications, 2) ensure that read and write operations are atomic, and 3) handle the EOF problem described above.
Reference: [DP93] <author> P. Druschel and L.L. Peterson. Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility. </title> <booktitle> In Proc. 14th ACM Symp. on Operating System Principles, </booktitle> <pages> pages 189-202, </pages> <year> 1993. </year> <title> 18 These accelerators zero the memory rather than the cache, and hence consume memory bandwidth. </title>
Reference-contexts: With ASF, it is also possible to exploit specialized facilities for transferring data between address spaces, such as Govidan and Anderson's memory mapped stream facility [GA91] and Druschel and Peterson's Fbufs facility <ref> [DP93] </ref>.
Reference: [GA91] <author> R. Govidan and D.P. Anderson. </author> <title> Scheduling and IPC mechanisms for continuous media. </title> <booktitle> In Proc. 13th ACM Symp. on Operating System Principles, </booktitle> <pages> pages 68-109, </pages> <year> 1991. </year>
Reference-contexts: With ASF, it is also possible to exploit specialized facilities for transferring data between address spaces, such as Govidan and Anderson's memory mapped stream facility <ref> [GA91] </ref> and Druschel and Peterson's Fbufs facility [DP93].
Reference: [GL91] <author> Andrew S. Grimshaw and Edmond C. Loyot, Jr. </author> <title> ELFS: object-oriented extensible file systems. </title> <type> Technical Report TR-91-14, </type> <institution> Univ. of Vir-ginia Computer Science Department, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Many of the file system policies, like pre-fetching and compression are implemented by ASF in stream specific modules. Currently, ASF is being modified to: 1) allow the application to select the stream modules that will be used (our approach is similar to that used by the ELFS file system <ref> [GL91] </ref>), and 2) push and pop stream modules on top of existing stream modules (this is similar to the push and pop operations of the System V kernel streams [Rit84].) A To Map, or not to Map We examine basic costs on a number of systems to determine under what conditions
Reference: [HS77] <author> J. Hunt and T. Szymanski. </author> <title> A fast algorithm for computing longest common subsequences. </title> <journal> Communications of the ACM, </journal> <volume> 20(5) </volume> <pages> 350-353, </pages> <year> 1977. </year>
Reference-contexts: The validity of this claim is demonstrated in Table 1, which shows the execution times of three variants of diff, a popular Unix utility that compares the contents of two files <ref> [HS77] </ref>. The first version corresponds to the standard implementation of diff, using the original stdio libraries. The second version corresponds to the same implementation of diff, but linked to an optimized implementation of stdio; we describe this implementation later in the paper.
Reference: [JCF + 83] <author> W. Joy, E. Cooper, R. Fabry, S. Le*er, K. McKu-sick, and D. </author> <title> Mosher. 4.2BSD System Manual. </title> <year> 1983. </year>
Reference-contexts: In the case of outstanding salloc operations (i.e. the read buffer has a reference count greater than zero), the invalidation is deferred until the corresponding sfree operations are called. 4.3.2 Mapped file-based stream modules In this section, we describe stream modules based on the mmap/munmap mapped file interface <ref> [JCF + 83] </ref>, a variant of which is supported by many versions of Unix. The mmap system call takes as parameters the file number, protection flags, the length of the region to be mapped, and an offset into a file.
Reference: [Jon91] <author> M. Jones. </author> <title> Bringing the C Libraries With Us into a Multi-Threaded Future. </title> <booktitle> In USENIX-Winter 91, </booktitle> <pages> pages 81-91, </pages> <year> 1991. </year>
Reference-contexts: The current I/O interfaces, however, are grossly inadequate for multithreaded programs. An obvious inadequacy of the Unix I/O facility, for example, is the way in which errors are reported to applications: a single global variable errno is set by the I/O system whenever an I/O error is encountered <ref> [Jon91] </ref>. If multiple concurrent I/O operations incur errors, than having a single errno variable makes it impossible to distinguish the errors. A second inadequacy of Unix I/O for multithreaded applications is the way random access I/O is supported. <p> An important example of where the comparison to the IRIX system is not fair is the compress and uncompress programs, where the overhead of locking in the installed version of the putc and getc macros is probably quite high <ref> [Jon91] </ref>. We have generally made every effort to ensure that the comparisons to installed facilities are fair, but it is difficult to be certain they are. For example, we do not know what size buffer is used by the installed versions of stdio that we compare against.
Reference: [KP84] <author> B. Kernighan and R. Pike. </author> <title> The Unix programming environment. </title> <publisher> Prentice-Hall, </publisher> <year> 1984. </year>
Reference-contexts: Consider, for example, a typical Unix filter that iteratively reads some input, performs a simple transformation on it, and writes some output <ref> [KP84] </ref>. Since the transformation is often simple, performance of this type of application is generally dominated by input and output. using the stdio I/O library.
Reference: [KS93] <author> Orran Krieger and Michael Stumm. </author> <title> HFS: a flexible file system for large-scale multiprocessors. </title> <booktitle> In Proceedings of the 1993 DAGS/PC Symposium, </booktitle> <pages> pages 6-14, </pages> <address> Hanover, NH, </address> <month> June </month> <year> 1993. </year> <institution> Dartmouth Institute for Advanced Graduate Studies. </institution>
Reference-contexts: The Alloc Stream Facility was originally developed as the application level library for the Hurricane file system, a file system being developed for shared memory multiprocessors with disks distributed across the multiprocessor <ref> [KS93] </ref>. As part of this project, we are investigating different mechanisms for locking and managing the CIOS structures. Many of the file system policies, like pre-fetching and compression are implemented by ASF in stream specific modules.
Reference: [KSS93] <author> J. Kohl, C. Staelin, and M. Stonebraker. Highlight: </author> <title> Using a log-structured file system for tertiary storage management. </title> <booktitle> In USENIX Winter Conference, </booktitle> <pages> pages 435-447. </pages> <publisher> USENIX Association, </publisher> <month> Jan </month> <year> 1993. </year>
Reference-contexts: We expect this problem to become more extreme in the future as systems become available that transparently provide access to files stored remotely [CH93] and stored in tertiary storage <ref> [KSS93] </ref>. It will be important that the application level library be able to query the source of a file to be able to optimize performance.
Reference: [KV91] <author> D. Korn and K.-Phong Vo. SFIO: </author> <note> Safe/Fast String/File I/O. In USENIX-Summer'91, </note> <year> 1991. </year>
Reference-contexts: For example, Korn and Vo's sfio library is a replacement library for stdio that provides a more consistent, powerful and natural interface than stdio and uses algorithms that are more efficient than those used by typical stdio implementations <ref> [KV91] </ref>. In this paper we introduce a new application level I/O facility called the Alloc Stream Facility. The new facility addresses three primary goals. First, it addresses recent computing substrate changes to improve performance, allowing applications to benefit from specific features like mapped files. <p> For record I/O, Cobol and PL/I read both provide a current record, the location of which is determined by the language implementation [Nic75]. Also, the sfpeek operation provided by the sfio library <ref> [KV91] </ref> allows applications access to the libraries internal buffers. However, for both the read defined by Cobol and PL/I and the sfpeek operation defined by sfio, the data is only available until the next I/O operation, which is not suitable for multi-threaded applications. <p> The Mach 3.0 operating system [DA92] reflects Unix I/O calls back to the application level where they are serviced using mapped files. Finally, the sfio library <ref> [KV91] </ref> uses mapped files whenever possible. On some systems, Unix I/O can be more efficient than mapped file I/O for some types of access (e.g., for writing past the EOF).
Reference: [KW88] <author> S. Kleiman and D. Williams. </author> <title> SunOS on SPARC. </title> <institution> Sun Technology, </institution> <month> Summer </month> <year> 1988. </year>
Reference-contexts: Second, because each stream module exports only a small set of functions, it is simple to write a new stream module to adapt to a particular system substrate. We have ported the Alloc Stream Facility to a variety of operating systems, including SunOS <ref> [KW88] </ref>, IRIX [Sil], AIX [Mis90], HP-UX [WL84], and Hurricane [USK93]. Although most of these systems support some variant of Unix, we have found that large improvements in performance can be obtained by adapting the facility to characteristics particular to each system.
Reference: [MB93] <author> C. Maeda and B.N. Bershad. </author> <title> Protocol service decomposition for high-performance networking. </title> <booktitle> In Proc. 14th ACM Symp. on Operating System Principles, </booktitle> <pages> pages 244-255, </pages> <year> 1993. </year>
Reference-contexts: Related work by Maeda and Bershad <ref> [MB93] </ref> demonstrates that substantial performance advantages result from moving critical portions of network protocol processing into the application address space and by modifying the networking interface to avoid unnecessary copying.
Reference: [MG91] <author> Todd Mowry and Anoop Gupta. </author> <title> Tolerating latency through software-controlled prefetching in shared-memory multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 12 </volume> <pages> 87-106, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: If the application accesses data without copying it, than it may be possible to overlap the time to process the data with the time to transfer it to or from the memory (e.g., if prefetching is used for input data <ref> [MG91] </ref>). It is interesting to note that the SPARCserver 400 series machines implement hardware accelerators to reduce the kernel cost of copying data. This accelerator performs memory to memory copies at the full memory bandwidth, bypassing the cache.
Reference: [Mis90] <author> M. Misra, </author> <title> editor. </title> <institution> IBM RISC System/6000 Technology, volume SA23-2619. IBM, </institution> <year> 1990. </year> <pages> Page 19 </pages>
Reference-contexts: Second, because each stream module exports only a small set of functions, it is simple to write a new stream module to adapt to a particular system substrate. We have ported the Alloc Stream Facility to a variety of operating systems, including SunOS [KW88], IRIX [Sil], AIX <ref> [Mis90] </ref>, HP-UX [WL84], and Hurricane [USK93]. Although most of these systems support some variant of Unix, we have found that large improvements in performance can be obtained by adapting the facility to characteristics particular to each system.
Reference: [Nic75] <author> J. </author> <title> Nicholls. </title> <booktitle> The Structure and Design of Pro--gramming Languages, chapter 11, </booktitle> <pages> pages 443-446. </pages> <publisher> Addison-Wesley, </publisher> <year> 1975. </year>
Reference-contexts: The idea of having the I/O facility choose the location of the I/O data is in itself not new. For record I/O, Cobol and PL/I read both provide a current record, the location of which is determined by the language implementation <ref> [Nic75] </ref>. Also, the sfpeek operation provided by the sfio library [KV91] allows applications access to the libraries internal buffers.
Reference: [OD89] <author> J. Ousterhout and F. Douglis. </author> <title> Beating the I/O Bottleneck: A Case for Log-Structured File Systems. </title> <journal> ACM press, Operating Systems Review, </journal> <volume> 23(1) </volume> <pages> 11-28, </pages> <year> 1989. </year>
Reference-contexts: Because of the large memories, files, once accessed, can be expected to remain cached in memory, so that most operating system I/O calls no longer involve accesses to I/O devices. Many files in fact are created and deleted without ever being written to secondary storage <ref> [OD89] </ref>. For this reason, an important component of the cost of I/O is the overhead that stems from copying data from one memory buffer to another and from the cost of making calls to the operating system.
Reference: [Ous90] <author> J. Ousterhout. </author> <title> Why aren't operating systems getting faster as fast as hardware? In Proc. </title> <booktitle> of the Summer USENIX Conference, </booktitle> <pages> pages 247-256, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The amount of buffer copying therefore has a large impact on performance. Third, the cost of a system call has also been increasing relative to processor speeds <ref> [Ous90] </ref>. This is again partially due to the effects of slower relative memory speeds and due to the increased number of registers some modern processors need to save and restore on context switches.
Reference: [PGK88] <author> David Patterson, Garth Gibson, and Randy Katz. </author> <title> A case for redundant arrays of inexpensive disks (RAID). </title> <booktitle> In ACM SIGMOD Conference, </booktitle> <pages> pages 109-116, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Moreover, in today's state-of-the-art computer systems, memory has become a critical contended resource. For example, researchers that have dramatically improved file I/O bandwidth (by introducing disk arrays <ref> [PGK88] </ref>) have found that the memory bottleneck prevents them from effectively exploiting the increased I/O bandwidth [CK91]. The amount of buffer copying therefore has a large impact on performance. Third, the cost of a system call has also been increasing relative to processor speeds [Ous90].
Reference: [Pla92] <author> P.J. Plauger. </author> <title> The Standard C Library. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey 07632, </address> <year> 1992. </year>
Reference-contexts: The standard I/O library for the C programming language, stdio, is an example of a well known application-level I/O facility that is available on numerous operating systems running on almost all current hardware bases <ref> [Pla92] </ref>.
Reference: [RAA + 88] <author> M. Rozier, V. Abrossimov, F. Armand, I. Boule, M. Gien, M. Guillemont, F. Herrmann, C. Kaiser, S. Langlois, P. Leonard, and W. Neuhauser. </author> <title> CHORUS distributed operating systems. </title> <journal> The Usenix Association Computing Systems Journal, </journal> <volume> 1(4) </volume> <pages> 305-370, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: But it can also be due to new operating system structures that are becoming more widespread, where the system is controlled by a microkernel and a set of user-level servers <ref> [RAA + 88, ABB + 86, Che88, ALBL91] </ref>.
Reference: [Rit84] <author> D. Ritchie. </author> <title> A Stream Intput-Output System. </title> <journal> AT&T Bell Laboratories Technical Journal, </journal> <volume> 63(8) </volume> <pages> 1897-1910, </pages> <month> October </month> <year> 1984. </year>
Reference-contexts: to select the stream modules that will be used (our approach is similar to that used by the ELFS file system [GL91]), and 2) push and pop stream modules on top of existing stream modules (this is similar to the push and pop operations of the System V kernel streams <ref> [Rit84] </ref>.) A To Map, or not to Map We examine basic costs on a number of systems to determine under what conditions mapped file I/O should be used.
Reference: [Sha92] <author> Bill Shannon. </author> <title> Implementation information for unix i/o on sunos. </title> <type> personal communication, </type> <year> 1992. </year>
Reference-contexts: If a page in this subset is accessed, then the kernel can service the read request quickly; otherwise, the kernel incurs the cost of a page fault to service the request <ref> [Sha92] </ref>. We have compared the cost of a page read to the cost of a page fault (i.e., touching a mapped page) because each brings a page into the application address space.
Reference: [Sil] <institution> Silicon Graphics, Inc., Mountain View, California. </institution> <note> IRIX Programmer's Reference Manual. </note>
Reference-contexts: Second, because each stream module exports only a small set of functions, it is simple to write a new stream module to adapt to a particular system substrate. We have ported the Alloc Stream Facility to a variety of operating systems, including SunOS [KW88], IRIX <ref> [Sil] </ref>, AIX [Mis90], HP-UX [WL84], and Hurricane [USK93]. Although most of these systems support some variant of Unix, we have found that large improvements in performance can be obtained by adapting the facility to characteristics particular to each system.
Reference: [Ste92] <author> W. Richard Stevens. </author> <title> Advanced Programming in the UNIX Environment. Professional Computing Series. </title> <publisher> Addison Wesley, </publisher> <address> One Jacob Way, Reading, Massachusetts 01867, </address> <year> 1992. </year>
Reference-contexts: As is the case with most application level I/O facilities, the interface and implementation of stdio have remained largely unchanged since the late seventies <ref> [Ste92] </ref>. However, computer architecture, hardware technology and operating systems, which we collectively refer to as the computing substrate, have changed substantially over the last 10-20 years, and consequently application performance can be significantly improved by adapting both the implementation and interfaces of application level I/O facilities to these changes.
Reference: [USK93] <author> Ron Unrau, Michael Stumm, and Orran Krieger. </author> <title> Hierarchical Clustering: A structure for scalable muliprocessor operating system design. </title> <type> Technical Report 268, </type> <institution> Computer Systems Research Institute, University of Toronto, </institution> <year> 1993. </year>
Reference-contexts: We have ported the Alloc Stream Facility to a variety of operating systems, including SunOS [KW88], IRIX [Sil], AIX [Mis90], HP-UX [WL84], and Hurricane <ref> [USK93] </ref>. Although most of these systems support some variant of Unix, we have found that large improvements in performance can be obtained by adapting the facility to characteristics particular to each system. Third, the interface modules are interoperable because they do not buffer data; only the stream modules buffer data. <p> Note, however, that the EOF problem is an artifact of current mapped file interfaces, and is not a generic problem with mapped files per se. For example, the file length and the number of pages in the file are independent in the Hurricane operating system <ref> [USK93] </ref>, so the file length need not be extended when the application uses salloc past the end of the file.
Reference: [VSWL91] <author> Zvonko G. Vranesic, Michael Stumm, Ron White, and David Lewis. </author> <title> "The Hector Multiprocessor". </title> <journal> Computer, </journal> <volume> 24(1), </volume> <month> January </month> <year> 1991. </year>
Reference-contexts: The four systems we consider are: an IBM R6000/350 running AIX, a Sun 4/40 running SunOS, an SGI Iris 4D/240S running IRIX, the Hector prototype <ref> [VSWL91] </ref> running Hurricane. The AIX system has a 4-way set associative physical write back cache with a cache line size of 64 bytes. The Sun system has a direct mapped virtual write through cache with a 16 bytes cache line.
Reference: [WL84] <author> S. Wang and J. Lindberg. HP-UX: </author> <title> implementation of Unix on the HP 9000 series 500 computer systems. </title> <journal> Hewlett-Packard Journal, </journal> <volume> 35(3) </volume> <pages> 7-15, </pages> <month> March </month> <year> 1984. </year> <pages> Page 20 </pages>
Reference-contexts: Second, because each stream module exports only a small set of functions, it is simple to write a new stream module to adapt to a particular system substrate. We have ported the Alloc Stream Facility to a variety of operating systems, including SunOS [KW88], IRIX [Sil], AIX [Mis90], HP-UX <ref> [WL84] </ref>, and Hurricane [USK93]. Although most of these systems support some variant of Unix, we have found that large improvements in performance can be obtained by adapting the facility to characteristics particular to each system.
References-found: 35

