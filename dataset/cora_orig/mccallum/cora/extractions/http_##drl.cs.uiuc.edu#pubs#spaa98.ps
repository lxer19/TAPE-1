URL: http://drl.cs.uiuc.edu/pubs/spaa98.ps
Refering-URL: http://drl.cs.uiuc.edu/pubs/spaa98.html
Root-URL: http://www.cs.uiuc.edu
Email: s-kuog@cs.uiuc.edu  
Phone: (217) 244-7232 (voice) (217) 244-6500 (fax)  
Title: Automatic Parallel I/O Performance Optimization in Panda  
Author: Y. Chen, M. Winslett, Y. Cho, S. Kuo Y. Chen fying, winslett, ycho, 
Affiliation: Computer Science Department, University of Illinois  
Note: Contact author:  
Abstract: Parallel I/O systems typically consist of individual processors, communication networks, and a large number of disks. Managing and utilizing these resources to meet performance, portability and usability goals of applications has become a significant challenge. We believe that a parallel I/O system that automatically selects efficient I/O plans for user applications is a solution to this problem. In this paper, we present such an automatic performance optimization approach for scientific applications performing collective I/O requests on multidimensional arrays. Under our approach, an optimization engine in a parallel I/O system selects optimal I/O plans automatically without human intervention based on a description of the application I/O requests and the system configuration. To validate our hypothesis, we have built an optimizer that uses a rule-based and randomized search-based algorithms to select optimal parameter settings in Panda, a parallel I/O library for multidimensional arrays. Our performance results obtained from two IBM SPs with significantly different configurations show that the Panda optimizer is able to select high-quality I/O plans and deliver high performance under a variety of system configurations with a small total optimization overhead. This research was supported by NASA under grants NAGW 4244 and NCC5 106, and Intel Foundation Graduate Fellowship. Computing facilities were provided by Argonne National Laboratory and Cornell Theory Center, which receives major funding from the National Science Foundation (NSF) and New York State, with additional support from the National Center for Research Resources at the National Institutes of Health (NIH), IBM Corporation, and other members of the Center's Corporate Partnership Program. We especially thank Dr. Ian Foster for his support to access the computing facilities at Argonne National Laboratory. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. M. Anderson, S. P. Amarasinghe, and M. S. Lam. </author> <title> Data and computation transformations for multiprocessors. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Processing, </booktitle> <year> 1995. </year>
Reference-contexts: Some researchers are also investigating automatic performance optimization using compiler techniques. [5] presented performance optimization for an out-of-core application using compile time analysis. <ref> [1] </ref> presented several techniques for array computations. These compile-time based optimization techniques can be quite effective under certain conditions.
Reference: [2] <editor> Adaptive Simulated Annealing (ASA). ftp.alumni.caltech.edu: /pub/ingber/ASA-shar, </editor> <year> 1993. </year>
Reference-contexts: In all the experiments, we used the default ASA parameter settings with a few exceptions. The ASA settings were selected such that all the optimizations can converge to global optimals. The modified parameter settings are listed in Table 2 and other parameter settings are listed in <ref> [2] </ref>. The optimizations were carried on the I/O nodes. Currently, in Panda the automatic optimizations can be done either sequentially on one I/O node or in parallel on all the I/O nodes.
Reference: [3] <author> K.P. Bennett, M.C. Ferris, and Y.E. Ioannidis. </author> <title> A genetic algorithm for database query optimization. </title> <type> Technical Report CS-TR-91-1004, </type> <institution> University of Wisconsin at Madison, </institution> <year> 1991. </year>
Reference-contexts: The performance results presented there suggest that with carefully selected simulated annealing parameter settings, the simulated annealing can be effectively used to identify optimal solutions in a relatively short time. <ref> [3] </ref> presented the use of randomized search algorithm, genetic algorithm, to optimize complex database queries, and their performance results show that genetic algorithms can effectively identify high quality query execution plans, and the selected plans are in general comparable to or better than those generated by other methods. [25] presented techniques
Reference: [4] <author> Robert Bennett, Kelvin Bryant, Alan Sussman, Raja Das, and Joel Saltz. Jovian: </author> <title> A framework for optimizing parallel I/O. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference, </booktitle> <pages> pages 10-20, </pages> <institution> Mississippi State, MS, </institution> <address> October 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: by at least a factor of 2, and the speedup can be as high as a factor of 16. 6 Related Work Considerable effort has been put into building parallel I/O libraries to provide high-performance support for large scale scientific applications, such as Panda [27], DRA [24], PASSION [29], Jovian <ref> [4] </ref>, and PPFS [17]. However, not much work has been done in providing automatic support for performance tuning in parallel I/O systems.
Reference: [5] <author> R. Bordawekar, A. Choudhary, and J. Ramanujam. </author> <title> Automatic optimization of communication in compiling out-of-core stencil codes. </title> <booktitle> In Proceedings of the 10th ACM International Conference on Supercomputing, </booktitle> <pages> pages 366-373, </pages> <address> Philadelphia, PA, May 1996. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Some researchers are also investigating automatic performance optimization using compiler techniques. <ref> [5] </ref> presented performance optimization for an out-of-core application using compile time analysis. [1] presented several techniques for array computations. These compile-time based optimization techniques can be quite effective under certain conditions.
Reference: [6] <author> E. Borowsky, R. Golding, A. Merchant, E. Shriver, M. Spasojevic, and J. Wilkes. </author> <title> Eliminating storage headaches through self-management. </title> <booktitle> In Proceedings of the Second Symposium on Operating Systems Design and Implementation, </booktitle> <address> Seattle, WA, </address> <year> 1996. </year>
Reference-contexts: performance results show that genetic algorithms can effectively identify high quality query execution plans, and the selected plans are in general comparable to or better than those generated by other methods. [25] presented techniques used to automatically make file caching and prefetching decisions based on the hints of access patterns. <ref> [6] </ref> has proposed an attribute-managed storage system approach to enable self-management of complex storage systems. Some researchers are also investigating automatic performance optimization using compiler techniques. [5] presented performance optimization for an out-of-core application using compile time analysis. [1] presented several techniques for array computations.
Reference: [7] <author> M.J. Box, D. Davies, </author> <title> and W.H. Swann. Non-linear optimization techniques. In ICI Monograph No. </title> <type> 5, </type> <institution> Edinburgh, </institution> <address> 1969. </address> <publisher> Oliver & Boyd. </publisher>
Reference-contexts: These algorithms can be effective. However, for a large complex system with nonlinearly interdependent parameters, such heuristic algorithms are extremely difficult to devise. Numerical algorithms such as Newton's method, steepest descent method <ref> [7] </ref>, and direct search methods [16] are also inappropriate since the Panda objective function is not contiguous and differentiable. We have considered several randomized search algorithms, i.e., simulated annealing (SA) [20] and genetic algorithms (GAs) [13, 15].
Reference: [8] <author> Y. Chen, Y. Cho, S. Kuo, K.E. Seamons, M. Subramaniam, and M. Winslett. </author> <title> Server-directed input and output in Panda: A commodity-parts approach to high-performance I/O. </title> <note> Submitted for publication, </note> <year> 1997. </year>
Reference-contexts: We are currently devising special array disk layout alternatives for such applications. We do not discuss them in this paper. Our previous performance studies <ref> [9, 8] </ref> show that often file system is not the only system bottleneck. <p> Oversized or undersized disk units could reduce this overlap, while an optimal disk unit size can maximize this overlap. A detailed analysis on the performance impact of these parameters on Panda can be found in <ref> [12, 9, 8] </ref>. Currently, without automatic techniques, Panda uses a set of default settings for these parameters, which may not be suitable for workloads with changing I/O patterns or changing execution environments as shown in section 5. Panda also allows user applications to provide settings for these parameters if desired.
Reference: [9] <author> Y. Chen, I. Foster, J. Nieplocha, and M. Winslett. </author> <title> Optimizing collective I/O performance on parallel computers: A multisystem study. </title> <booktitle> In Proceedings of 11th ACM International Conference on Supercomputing, </booktitle> <pages> pages 28-35. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1997. </year>
Reference-contexts: We are currently devising special array disk layout alternatives for such applications. We do not discuss them in this paper. Our previous performance studies <ref> [9, 8] </ref> show that often file system is not the only system bottleneck. <p> Oversized or undersized disk units could reduce this overlap, while an optimal disk unit size can maximize this overlap. A detailed analysis on the performance impact of these parameters on Panda can be found in <ref> [12, 9, 8] </ref>. Currently, without automatic techniques, Panda uses a set of default settings for these parameters, which may not be suitable for workloads with changing I/O patterns or changing execution environments as shown in section 5. Panda also allows user applications to provide settings for these parameters if desired.
Reference: [10] <author> Y. Chen, M. Winslett, Y. Cho, and S. Kuo. </author> <title> Speeding up automatic parallel I/O performance optimization in Panda. </title> <note> In Submitted for publication, 1997. 16 </note>
Reference-contexts: With the combination of these approaches, we were able to obtain high quality parameter settings for a variety of experiments with low optimization overhead as shown in section 5. The details of these approaches can be found in <ref> [10] </ref>. <p> 1 fi 8 2 fi 4 fi 4 Table 6: The revised in-memory layouts for the entire array benchmark on the ANL SP. 5.3 Cost of optimization To study the cost of optimization and the behavior of ASA, we also carried out a variety of performance evaluations as shown in <ref> [10] </ref>. In this section, we present the optimization costs for the experiments described in section 5.1 and 5.2. <p> The large ASA performance variance in different experiments came from several factors that affect ASA performance. <ref> [10] </ref> identifies these factors and examines the their impacts on the ASA performance. We do not discuss them in the paper. Figure 11 shows the optimization costs for the out-of-core benchmark on the CTC SP2 as described in section 5.1.2. The optimization costs range from 2 seconds to 250 seconds. <p> The optimization costs range from 2 seconds to 250 seconds. The costs in many cases are higher in the out-of-core benchmark than those shown in Figure 10 because at the time of our out-of-core experiments, the optimization strategies used to reduce the optimization cost <ref> [10] </ref> were not incorporated in this part of the code, and by the time the optimizations were merged, the 13 system configuration for the CTC SP2 has been upgraded significantly. We were not able to repeat the tests using our new strategies [10] in the same execution environments as what were <p> optimization strategies used to reduce the optimization cost <ref> [10] </ref> were not incorporated in this part of the code, and by the time the optimizations were merged, the 13 system configuration for the CTC SP2 has been upgraded significantly. We were not able to repeat the tests using our new strategies [10] in the same execution environments as what were used before the system upgrade. Thus, we report the optimization costs obtained without the special techniques to reduce the cost of optimizations as discussed in [10]. <p> We were not able to repeat the tests using our new strategies <ref> [10] </ref> in the same execution environments as what were used before the system upgrade. Thus, we report the optimization costs obtained without the special techniques to reduce the cost of optimizations as discussed in [10].
Reference: [11] <author> Y. Chen, M. Winslett, S. Kuo, Y. Cho, M. Subramaniam, and K.E. Seamons. </author> <title> Performance modeling for the Panda array I/O library. </title> <booktitle> In Proceedings of Supercomputing '96. </booktitle> <publisher> ACM Press and IEEE Computer Society Press, </publisher> <month> November </month> <year> 1996. </year>
Reference-contexts: Our benchmark suite measures characteristics of the file system, message passing system, and memory system, such as file system throughputs, MPI latencies and bandwidths, and memory bandwidth, etc. These measurements are used in the Panda performance model <ref> [11] </ref> to predict Panda performance on a specific platform. 3.2 The use of automatic performance optimization Our automatic performance optimization approach can be used either before or during application executions. <p> The number of parameters to be determined is 1 + m k, i.e., one n-element tuple representing the disk layout, m parameters representing the disk unit sizes for different I/O requests, and k parameters for which the rule-based approach has already selected settings. The performance model for Panda <ref> [11] </ref> is used to estimate C (D i ;x;y i ) . 4.2.2 Selecting optimal Panda parameter settings using simulated annealing Given objective function (1), the complexity of Panda performance model, and a large Panda solution space, clearly exhaustive search is too expensive to be considered.
Reference: [12] <author> Y. Chen, M. Winslett, K.E. Seamons, S. Kuo, Y. Cho, and M. Subramaniam. </author> <title> Scalable message passing in Panda. </title> <booktitle> In Proceedings of the Fourth Workshop on Input/Output in Parallel and Distributed Systems, </booktitle> <pages> pages 109-121, </pages> <address> Philadelphia, May 1996. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Communication strategy, array disk layout, and disk unit size are the three most important types of parameters. Panda supports two different communication strategies in handling a collective I/O request for different types of I/O workloads, i.e., a server-orchestrated strategy [27] and a client-orchestrated strategy <ref> [12] </ref>, to improve communication system bandwidth utilization. In I/O workloads that include a mix of I/O requests with different characteristics, adaptive approaches are needed to determine proper communication strategies for different requests. Communication system bandwidth utilization can also be improved by selecting proper array disk layouts. <p> Oversized or undersized disk units could reduce this overlap, while an optimal disk unit size can maximize this overlap. A detailed analysis on the performance impact of these parameters on Panda can be found in <ref> [12, 9, 8] </ref>. Currently, without automatic techniques, Panda uses a set of default settings for these parameters, which may not be suitable for workloads with changing I/O patterns or changing execution environments as shown in section 5. Panda also allows user applications to provide settings for these parameters if desired.
Reference: [13] <author> D.E. Goldberg. </author> <title> Genetic algorithms in search, optimization and machine learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Numerical algorithms such as Newton's method, steepest descent method [7], and direct search methods [16] are also inappropriate since the Panda objective function is not contiguous and differentiable. We have considered several randomized search algorithms, i.e., simulated annealing (SA) [20] and genetic algorithms (GAs) <ref> [13, 15] </ref>. Our experience with these algorithms suggests that these algorithms can effectively solve our problems. In this paper, we report our experience with the SA algorithm. SA is a probabilistic hill-climbing optimization algorithm. It resembles the annealing process in statistical mechanics.
Reference: [14] <author> G. Graefe. </author> <title> Query evaluation techniques for large databases. </title> <journal> Computing Surveys, </journal> <volume> 25(2) </volume> <pages> 73-170, </pages> <year> 1993. </year>
Reference-contexts: Despite the lack of automatic optimization work in the parallel I/O world, automatic performance optimization is not uncommon in many other research areas, such as database and operating system research. <ref> [14] </ref> provides a fairly complete discussion of many query processing and optimization techniques used for database systems and the design of query optimizers in database systems. [28] compared several optimization algorithms used to optimize large join queries.
Reference: [15] <author> J. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The university of Michigan press, </publisher> <address> Ann Arbor, Michigan, </address> <year> 1975. </year>
Reference-contexts: Numerical algorithms such as Newton's method, steepest descent method [7], and direct search methods [16] are also inappropriate since the Panda objective function is not contiguous and differentiable. We have considered several randomized search algorithms, i.e., simulated annealing (SA) [20] and genetic algorithms (GAs) <ref> [13, 15] </ref>. Our experience with these algorithms suggests that these algorithms can effectively solve our problems. In this paper, we report our experience with the SA algorithm. SA is a probabilistic hill-climbing optimization algorithm. It resembles the annealing process in statistical mechanics.
Reference: [16] <author> R. Hooke and T.A. Jeeves. </author> <title> "Direct Search" solution of numerical and statistical problems. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 8 </volume> <pages> 212-229, </pages> <year> 1961. </year>
Reference-contexts: These algorithms can be effective. However, for a large complex system with nonlinearly interdependent parameters, such heuristic algorithms are extremely difficult to devise. Numerical algorithms such as Newton's method, steepest descent method [7], and direct search methods <ref> [16] </ref> are also inappropriate since the Panda objective function is not contiguous and differentiable. We have considered several randomized search algorithms, i.e., simulated annealing (SA) [20] and genetic algorithms (GAs) [13, 15]. Our experience with these algorithms suggests that these algorithms can effectively solve our problems.
Reference: [17] <author> J. Huber, C.L. Elford, D.A. Reed, A.A. Chien, </author> <title> and D.S. Blumenthal. PPFS: A high performance portable parallel file system. </title> <booktitle> In Proceedings of the 9th ACM International Conference on Supercomputing, </booktitle> <pages> pages 385-394, </pages> <address> Barcelona, July 1995. </address> <publisher> ACM Press. </publisher>
Reference-contexts: a factor of 2, and the speedup can be as high as a factor of 16. 6 Related Work Considerable effort has been put into building parallel I/O libraries to provide high-performance support for large scale scientific applications, such as Panda [27], DRA [24], PASSION [29], Jovian [4], and PPFS <ref> [17] </ref>. However, not much work has been done in providing automatic support for performance tuning in parallel I/O systems.
Reference: [18] <author> L. Ingber. </author> <title> Simulated annealing: Practice versus theory. </title> <journal> Mathl. Compu. Modelling, </journal> <volume> 18(11) </volume> <pages> 29-57, </pages> <year> 1993. </year>
Reference-contexts: Many early SA algorithms randomly sample an infinite solution space and do not consider the importance and sensitivities of different parameters, hence resulting in long optimization times that may make the approach impractical to use in real systems. The Adaptive Simulated Annealing (ASA) algorithm, developed by Lester Ingber <ref> [18] </ref>, takes into consideration the finite solution space and sensitivities of different parameters and uses an importance-sampling technique to reduce the annealing time.
Reference: [19] <author> Y. Ioannidis and E. Wong. </author> <title> Query optimization by simulated annealing. </title> <booktitle> In Proceedings of the 1987 ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 9-22, </pages> <year> 1987. </year>
Reference-contexts: The performance results showed that the simple iterative improvement is superior to all other methods when the amount of time allowed to perform optimization is small. However, as the optimization time increases, the simulated annealing becomes the winner. <ref> [19] </ref> also showed how to use simulated annealing to optimize recursive queries.
Reference: [20] <author> S. Kirkpatrick, C.D. Gelatt Jr., </author> <title> and M.P. Vecchi. Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220(4598) </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference-contexts: Numerical algorithms such as Newton's method, steepest descent method [7], and direct search methods [16] are also inappropriate since the Panda objective function is not contiguous and differentiable. We have considered several randomized search algorithms, i.e., simulated annealing (SA) <ref> [20] </ref> and genetic algorithms (GAs) [13, 15]. Our experience with these algorithms suggests that these algorithms can effectively solve our problems. In this paper, we report our experience with the SA algorithm. SA is a probabilistic hill-climbing optimization algorithm. It resembles the annealing process in statistical mechanics.
Reference: [21] <author> D. Kotz and N. Nieuwejaar. </author> <title> Dynamic file-access characteristics of a production parallel scientific workload. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <pages> pages 640-649, </pages> <address> Washington, DC, November 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: We discuss related work in section 6, and draw conclusions and outline the future work in section 7. 2 Panda basics Panda is designed for large-scale scientific applications performing collective array I/O operations on distributed-memory multiprocessors, a commonly observed I/O pattern in large scale scientific applications <ref> [26, 21] </ref>. In this paper, we base our discussion on Panda 2.1 with each node either dedicated to application computation or I/O. The dedicated I/O nodes are called "Panda servers" and the compute nodes are called "Panda clients".
Reference: [22] <author> T.M. Madhyasta, C.L. Elford, and D.A. Reed. </author> <title> Optimizing input/output using adaptive file system policies. </title> <booktitle> In Proceedings of the Fifth NASA Goddard Conference on Mass Storage Systems, </booktitle> <pages> pages II:493-514, </pages> <month> September </month> <year> 1996. </year>
Reference: [23] <author> T.M. Madhyasta and D.A. Reed. </author> <title> Intelligent, adaptive file system policy selection. </title> <booktitle> In Proceedings of the Sixth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 172-179. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1996. </year>
Reference-contexts: A recent effort has focused on automatically selecting efficient file system caching and prefetching policies in PPFS using two I/O access pattern classification approaches, i.e., a trained neural network approach and a hidden-Markov model approach ([22] and <ref> [23] </ref>). Automatically classifying the I/O access patterns serves as the first step towards automatic performance optimization. In Panda, we used an application profiler and system microbenchmarking for this purpose.
Reference: [24] <author> J. Nieplocha and I. Foster. </author> <title> Disk resident arrays: An array-oriented I/O library for out-of-core computations. </title> <booktitle> In Proceedings of the Sixth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 196-204. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1996. </year>
Reference-contexts: up the ASA performance by at least a factor of 2, and the speedup can be as high as a factor of 16. 6 Related Work Considerable effort has been put into building parallel I/O libraries to provide high-performance support for large scale scientific applications, such as Panda [27], DRA <ref> [24] </ref>, PASSION [29], Jovian [4], and PPFS [17]. However, not much work has been done in providing automatic support for performance tuning in parallel I/O systems.
Reference: [25] <author> R. Hugo Patterson, G.A. Gibson, Eka Ginting, Daniel Stodolsky, and Jim Zelenka. </author> <title> Informed prefetching and caching. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 79-95, </pages> <address> Copper Mountain, CO, </address> <month> December </month> <year> 1995. </year> <note> ACM Press. </note>
Reference-contexts: short time. [3] presented the use of randomized search algorithm, genetic algorithm, to optimize complex database queries, and their performance results show that genetic algorithms can effectively identify high quality query execution plans, and the selected plans are in general comparable to or better than those generated by other methods. <ref> [25] </ref> presented techniques used to automatically make file caching and prefetching decisions based on the hints of access patterns. [6] has proposed an attribute-managed storage system approach to enable self-management of complex storage systems.
Reference: [26] <author> J.T. Poole. </author> <title> Preliminary survey of I/O intensive applications. </title> <type> Technical Report CCSF-38, </type> <institution> Scalable I/O Initiative, Caltech Concurrent Supercomputing Facilities, Caltech, </institution> <year> 1994. </year>
Reference-contexts: We discuss related work in section 6, and draw conclusions and outline the future work in section 7. 2 Panda basics Panda is designed for large-scale scientific applications performing collective array I/O operations on distributed-memory multiprocessors, a commonly observed I/O pattern in large scale scientific applications <ref> [26, 21] </ref>. In this paper, we base our discussion on Panda 2.1 with each node either dedicated to application computation or I/O. The dedicated I/O nodes are called "Panda servers" and the compute nodes are called "Panda clients".
Reference: [27] <author> K.E. Seamons, Y. Chen, P. Jones, J. Jozwiak, and M. Winslett. </author> <title> Server-directed collective I/O in Panda. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <address> San Diego, CA, December 1995. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: This is especially true on systems with relatively fast disks but slow interconnects such as a workstation cluster environment. To achieve good file system bandwidth utilization, Panda uses the server-directed I/O strategy (SDIO) <ref> [27] </ref>, which ensures long, sequential file system accesses whenever possible. To achieve good communication bandwidth utilization, balance workloads, and increase Panda's internal parallelism, Panda must select proper communication strategy, array disk layout and disk unit size on each I/O node for different collective I/O requests. <p> Communication strategy, array disk layout, and disk unit size are the three most important types of parameters. Panda supports two different communication strategies in handling a collective I/O request for different types of I/O workloads, i.e., a server-orchestrated strategy <ref> [27] </ref> and a client-orchestrated strategy [12], to improve communication system bandwidth utilization. In I/O workloads that include a mix of I/O requests with different characteristics, adaptive approaches are needed to determine proper communication strategies for different requests. <p> can speed up the ASA performance by at least a factor of 2, and the speedup can be as high as a factor of 16. 6 Related Work Considerable effort has been put into building parallel I/O libraries to provide high-performance support for large scale scientific applications, such as Panda <ref> [27] </ref>, DRA [24], PASSION [29], Jovian [4], and PPFS [17]. However, not much work has been done in providing automatic support for performance tuning in parallel I/O systems.
Reference: [28] <author> A. Swami and A. Gupta. </author> <title> Optimization of large join queries. </title> <booktitle> In Proceedings of the 1988 ACM-SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 8-17, </pages> <address> Chicago, IL, </address> <year> 1988. </year>
Reference-contexts: work in the parallel I/O world, automatic performance optimization is not uncommon in many other research areas, such as database and operating system research. [14] provides a fairly complete discussion of many query processing and optimization techniques used for database systems and the design of query optimizers in database systems. <ref> [28] </ref> compared several optimization algorithms used to optimize large join queries. The algorithms studied includes an iterative improvement method, simulated annealing, a perturbation walk, and a quasi-random sampling.

References-found: 28

