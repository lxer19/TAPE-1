URL: http://www.cs.wisc.edu/wpis/papers/tr1362.ps
Refering-URL: http://www.cs.wisc.edu/~reps/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: PARTIAL EVALUATION USING DEPENDENCE GRAPHS  
Author: By Manuvir Das 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Science) at the  
Date: 1998  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: [AH96] <author> P. H. Andersen and C. K. Holst. </author> <title> Termination analysis for o*ine partial evaluation of a higher order functional language. </title> <booktitle> In Proceedings of the Third International Static Analysis Symposium, </booktitle> <year> 1996. </year>
Reference-contexts: Other authors have also tackled the termination problem, and have defined termination analyses that can be combined with congruence-based BTA to produce analyses that provide a termination guarantee for all programs <ref> [Hol91, GJ96, AH96] </ref>. The chief differences between their work and ours are: * Other termination analyses are applicable only to restricted languages, and can analyze only simple kinds of termination criteria. <p> The algorithm described in this paper extends their work by using CFL-Reachability to identify a broader class of size-decreasing paths, and by using an optimistic algorithm. Andersen and Holst have described an extension of Holst's analysis to a higher-order lambda calculus <ref> [AH96] </ref>. Although their primary emphasis was termination analysis for programs with higher-order functions, they observe that their technique for handling higher-order functions can be adapted to discover some size-decreasing paths containing " edges.
Reference: [AHU74] <author> A.V. Aho, J.E. Hopcroft, and J.D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: In order to identify a greater number of in-situ-decreasing parameters than Glenstrup and Jones, we extend the parameter dependency graph with new nodes and new edge markings and we use CFL-Reachability rather than a closed semi-ring graph 168 algorithm <ref> [AHU74, GJ96] </ref>. * There is a general result that all "context-free language reachability problems" can be solved in time cubic in the number of vertices in the graph [Yan90].
Reference: [And92] <author> L.O. Andersen. </author> <title> Self-applicable C program specialization. In Partial Evaluation and Semantics-Based Program Manipulation, </title> <address> San Francisco, Cali-fornia, </address> <note> June 1992 (Technical Report YALEU/DCS/RR-909), pages 54-61. </note> <institution> New Haven, CT: Yale University, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: Baier and Gluck, among others, have developed a partial evaluator for Fortran [BGZ94], while Ander-sen's self-applicable partial evaluator for strictly-conforming Ansi C (c-mix, <ref> [And92] </ref>) handles most of the features of Ansi C, with heap allocated storage being a notable exception. Both of these specializers are based on control-flow representations of the subject program, whereas we are interested in using a dependence graph representation for reasons mentioned earlier.
Reference: [And93] <author> L.O. Andersen. </author> <title> Binding-time analysis and the taming of C pointers. In Partial Evaluation and Semantics-Based Program Manipulation, </title> <address> Copenhagen, Denmark, </address> <month> June </month> <year> 1993, </year> <pages> pages 47-58. </pages> <address> New York: </address> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Therefore, we follow the approach used by cmix [And94], which is a prototype partial evaluator for C programs. cmix employs a congruence-based BTA algorithm, which ignores dynamic control, and therefore provides no termination guarantee. However, it uses a pointer analysis algorithm <ref> [And93] </ref> that conservatively identifies aliasing relationships. We employ the same algorithm, and use its results to conservatively add flow dependence edges to the LDG. Thus, we are able to account for the presence of pointer variables in a manner that is orthogonal to our use of loop dependences. <p> Alternatively, every program variable "points-to" zero or more other program variables. A variable x points-to a variable y if the value of x may represent the address of y. We borrow the pointer analysis algorithm of Lars Andersen from <ref> [And93] </ref>, and use it to build "points-to sets" for all the variables in the program. Note that Andersen's pointer analysis is "flow-insensitive," in the sense that a variable has a single points-to set throughout the program. <p> In other words, our BTA algorithm does not depend on the algorithm used to produce defined and used sets at program points. Therefore, any pointer analysis algorithm can be used in place of the algorithm from <ref> [And93] </ref>. An example of our approach is shown in Figure 35. In the case of multi-procedure programs, aliasing relationships may span procedure boundaries. This is especially true in C programs, which frequently use pointer-valued parameters to simulate call-by-reference parameters. <p> Finally, the static or dynamic behaviour of a pointer variable can be thought of on two levels: The pointer itself may be static or dynamic, while the objects it points to may be static or dynamic. Here again, we copy the approach used by Andersen in <ref> [And93] </ref>. Therefore, our approach to incorporating pointer variables is identical to that of cmix [And94], with the exception that we use extra parameters to handle flow dependences induced by aliasing relationships across procedures, whereas cmix uses a type-inference engine to deduce these dependences.
Reference: [And94] <author> L.O. Andersen. </author> <title> Program Analysis and Specialization for the C Programming Language. </title> <type> PhD thesis, </type> <institution> DIKU, University of Copenhagen, Denmark, </institution> <year> 1994. </year> <note> DIKU Research Report 94/19. </note>
Reference-contexts: Our approach to this problem is as follows: Pointer variables affect the flow dependences in a program, not the control dependences or loop dependences. Therefore, we follow the approach used by cmix <ref> [And94] </ref>, which is a prototype partial evaluator for C programs. cmix employs a congruence-based BTA algorithm, which ignores dynamic control, and therefore provides no termination guarantee. However, it uses a pointer analysis algorithm [And93] that conservatively identifies aliasing relationships. <p> Here again, we copy the approach used by Andersen in [And93]. Therefore, our approach to incorporating pointer variables is identical to that of cmix <ref> [And94] </ref>, with the exception that we use extra parameters to handle flow dependences induced by aliasing relationships across procedures, whereas cmix uses a type-inference engine to deduce these dependences. <p> The table in Figure 52 shows the results of one experiment using our implementation. We wish to compare the cost of PRG specialization with the cost of conventional CFG specialization. For purposes of comparison, we use the specialization phase of cmix <ref> [And94] </ref> as the reference CFG-based specializer. The subject program contains a simple static loop with dynamic code nested within it. We report results for our specializer both with and without the reconstitution algorithm enabled.
Reference: [And95a] <author> P. H. Andersen. </author> <title> C-Mix User Manual (DRAFT). </title> <institution> DIKU, Copenhagen, Den-mark, </institution> <year> 1995. </year>
Reference-contexts: However, our BTA algorithm is able to process calls to malloc. In these respects, we impose 124 the same restrictions that are imposed by cmix, the partial evaluator for C programs developed by Lars Andersen at DIKU <ref> [And95a] </ref>. Finally, we assume that all pointer arithmetic arises from array accesses, because it makes the task of building defined and used sets from points-to sets in the presence of array pointers significantly simpler.
Reference: [And95b] <author> P.H. Andersen. </author> <title> Partial evaluation applied to ray tracing. </title> <type> DIKU Research Report 95/2, </type> <institution> DIKU, University of Copenhagen, Denmark, </institution> <year> 1995. </year>
Reference-contexts: algorithm. power is the power function, bsearch refers to several versions of the binary search function, mix 1 and mix 2 are different versions of a specializer for an imperative language, and ray is an implementation of ray tracing (approx. 2000 lines of C code) by Peter Andersen at DIKU <ref> [And95b] </ref>. aliasing information, an algorithm for constructing loop dependences, and a component that identifies grounded flow dependence cycles and grounded loops using a linear constraint solving technique.
Reference: [App92] <author> A. W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1992. </year>
Reference-contexts: In particular, the behaviour of a particular vertex or the values produced by it cannot be captured directly from the semantics. As a result, we use Ramalingam's semantics for extended PRGs [RR89]. Program representations such as the PRG and SSA form are similar to the continuation passing style (CPS) <ref> [App92] </ref>, in that information is stored about the future use of variables in the program. More formally, Kelsey has shown in [Kel95] that it is always possible to convert programs written in SSA form to CPS.
Reference: [ASU86] <author> A. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: The language provides only scalar integer variables. 25 2.2.1 The control-flow graph The control-flow graph (CFG) <ref> [ASU86] </ref> is an intermediate representation for imperative programs that is useful for dataflow analysis and program optimization. <p> Procedure calls add several complications to the task of developing a dependence-based representation for programs whose semantics is faithful to the standard operational semantics of a program. As a result, we restrict the class of multi-procedure programs represented by SRGs to programs that have "reducible" call graphs <ref> [ASU86] </ref>. A reducible call graph is one in which every call site on a procedure either produces calls that are "entry" calls to the procedure, or produces calls that are recursive calls to the procedure. Our experiments show that this class of programs is fairly general. <p> examined from the Spec95 benchmark suite have reducible call graphs. 2 Second, given a program with an irreducible call graph, it is always possible to automatically transform the program into one that has a reducible call graph, by using an algorithm similar to the node-splitting algorithm described in, for instance, <ref> [ASU86, pp. 664-668] </ref>. We omit the details here. The algorithm is exponential in the worst case; however, it is unlikely that a program will have more than a few irreducible components.
Reference: [AWZ88] <author> B. Alpern, M.N. Wegman, and F.K. Zadeck. </author> <title> Detecting equality of variables in programs. </title> <booktitle> In Conference Record of the Fifteenth ACM Symposium on Principles of Programming Languages, </booktitle> <address> (San Diego, CA, </address> <month> January 13-15, </month> <year> 1988), </year> <pages> pages 1-11, </pages> <year> 1988. </year> <month> 202 </month>
Reference-contexts: These gate vertices are similar to the gate nodes in the SSA form of an imperative program <ref> [AWZ88, RWZ88] </ref>. <p> The PDG has been extended in several different directions: Horwitz et al. defined the system dependence graph (SDG), an extension of the PDG to handle programs with procedures [HRB90]. Alpern et al. defined the static single-assignment (SSA) form <ref> [AWZ88] </ref> for programs, which includes or gate statements for merging data from multiple predecessors, while Yang et al. defined the program representation graph (PRG) as an extension of the PDG with nodes similar 72 to the gate nodes in the SSA form [YHR92].
Reference: [Bal93] <author> T. J. Ball. </author> <title> The Use of Control-Flow and Control Dependence in Software Tools. </title> <type> PhD thesis, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <year> 1993. </year> <note> UW Computer Sciences Technical Report #1169. </note>
Reference-contexts: The CFG for a program can be constructed in time linear in the size of the program using a syntax-directed translation scheme <ref> [Bal93] </ref>. As an example, the power function from Chapter 1 and its CFG are shown in Figure 6. CFGs have a standard denotational semantics in which every program statement is modeled as a state-to-state transformer [Sch86]. <p> For this purpose, several forms of data dependence have been defined in the literature. We consider one form of data dependence termed flow dependence, defined below. We borrow all of the definitions of program dependence in this section from <ref> [Bal93] </ref>. A flow dependence from vertex w to vertex v indicates that a value computed at w may be used at v under some path through the control-flow graph.
Reference: [BFR90] <author> A. Bondorf, F. Frauendorf, and M. Richter. </author> <title> An experiment in automatic self-applicable partial evaluation of Prolog. </title> <type> Technical Report 335, </type> <institution> Lehrstuhl Informatik V, University of Dortmund, Germany, </institution> <year> 1990. </year>
Reference: [BGZ94] <author> R. Baier, R. Gluck, and R. Zochling. </author> <title> Partial evaluation of numerical programs in Fortran. In Partial Evaluation and Semantics-Based Program Manipulation, </title> <address> Orlando, Florida, </address> <note> June 1994 (Technical Report 94/9, </note> <institution> Department of Computer Science, University of Melbourne), </institution> <address> pages 119-132, </address> <year> 1994. </year>
Reference-contexts: Furthermore, he sidesteps the issue of termination of the partial evaluator by assuming that the program terminates for all inputs, which is an overly strong restriction on program behaviour. Baier and Gluck, among others, have developed a partial evaluator for Fortran <ref> [BGZ94] </ref>, while Ander-sen's self-applicable partial evaluator for strictly-conforming Ansi C (c-mix, [And92]) handles most of the features of Ansi C, with heap allocated storage being a notable exception.
Reference: [BH93] <author> S. Bates and S. Horwitz. </author> <title> Incremental program testing using program dependence graphs. </title> <booktitle> In Conference Record of the Twentieth ACM Symposium on Principles of Programming Languages, </booktitle> <address> (Charleston, SC, </address> <month> January 10-13, </month> <year> 1993), </year> <pages> pages 384-396, </pages> <year> 1993. </year>
Reference-contexts: The PDG for the power program is shown in Figure 9. Program dependence graphs have been used as an intermediate program representation in various contexts such as program understanding, maintenance [GL91], debugging [LW86], testing <ref> [Bin92, BH93] </ref>, differencing [Hor90], specialization [RT96], reuse [NEK94], merging [HPR88a], and vectorization and parallelization [KKL + 81]. They have the advantage that they make both flow and control dependences explicit in their structure, leading to efficient algorithms for tracing the relationships between program components.
Reference: [Bin92] <author> D. Binkley. </author> <title> Using semantic differencing to reduce the cost of regression testing. </title> <booktitle> In Proc. of the IEEE Conf. on Softw. </booktitle> <address> Maint. Orlando, FL, </address> <month> Nov. </month> <pages> 9-12, </pages> <year> 1992, </year> <pages> pages 41-50, </pages> <year> 1992. </year>
Reference-contexts: The PDG for the power program is shown in Figure 9. Program dependence graphs have been used as an intermediate program representation in various contexts such as program understanding, maintenance [GL91], debugging [LW86], testing <ref> [Bin92, BH93] </ref>, differencing [Hor90], specialization [RT96], reuse [NEK94], merging [HPR88a], and vectorization and parallelization [KKL + 81]. They have the advantage that they make both flow and control dependences explicit in their structure, leading to efficient algorithms for tracing the relationships between program components.
Reference: [Bon90] <author> A. Bondorf. </author> <title> Self-Applicable Partial Evaluation. </title> <type> PhD thesis, </type> <institution> DIKU, University of Copenhagen, Denmark, </institution> <year> 1990. </year> <note> Revised version: DIKU Report 90/17. </note>
Reference-contexts: Therefore, partial evaluation works well on programs that interpret static data to determine how dynamic data must be manipulated. Large speedups have been reported from partially evaluating circuit simulators [BW90], neural networks [Jac90], computations using networks of processors [RP89], pattern matchers <ref> [CD89, Bon90] </ref>, and other programs that interpret part of their input. However, partial evaluation is not a general program transformation that can change a program's computational method.
Reference: [Bul88] <author> M.A. Bulyonkov. </author> <title> A theoretical approach to polyvariant mixed computation. </title> <editor> In D. Bjtrner, A.P. Ershov, and N.D. Jones, editors, </editor> <booktitle> Partial Evaluation and Mixed Computation, </booktitle> <pages> pages 51-64. </pages> <address> Amsterdam: </address> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: that uses only parameter n, which is static, is executed away, while code that uses either x or a, both of which are dynamic, is emitted. 19 In the context of imperative programs, self-applicable partial evaluators (explained in Section 2.1.1) for flowchart languages have been constructed by Bulyonkov and Er-shov <ref> [Bul88] </ref>, and by Gomard and Jones [GJ89]. Meyer has presented a specialization approach for a Pascal-like language that uses dynamic annotations rather than a separate BTA phase in order to obtain more efficient residual programs [Mey91]. However, his analysis loses some precision as a result.
Reference: [BW90] <author> A. Berlin and D. Weise. </author> <title> Compiling scientific code using partial evaluation. </title> <journal> IEEE Computer, </journal> <volume> 23(12) </volume> <pages> 25-37, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Therefore, partial evaluation works well on programs that interpret static data to determine how dynamic data must be manipulated. Large speedups have been reported from partially evaluating circuit simulators <ref> [BW90] </ref>, neural networks [Jac90], computations using networks of processors [RP89], pattern matchers [CD89, Bon90], and other programs that interpret part of their input. However, partial evaluation is not a general program transformation that can change a program's computational method.
Reference: [CD89] <author> C. Consel and O. Danvy. </author> <title> Partial evaluation of pattern matching in strings. </title> <journal> Information Processing Letters, </journal> <volume> 30 </volume> <pages> 79-86, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: Therefore, partial evaluation works well on programs that interpret static data to determine how dynamic data must be manipulated. Large speedups have been reported from partially evaluating circuit simulators [BW90], neural networks [Jac90], computations using networks of processors [RP89], pattern matchers <ref> [CD89, Bon90] </ref>, and other programs that interpret part of their input. However, partial evaluation is not a general program transformation that can change a program's computational method.
Reference: [CD91] <author> C. Consel and O. Danvy. </author> <title> For a better support of static data flow. </title> <editor> In J. Hughes, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <address> Cambridge, Massachusetts, </address> <booktitle> August 1991 (Lecture Notes in Computer Science, </booktitle> <volume> vol. 523), </volume> <pages> pages 496-519. </pages> <publisher> ACM, Berlin: Springer-Verlag, </publisher> <year> 1991. </year> <month> 203 </month>
Reference-contexts: This might suggest the use of CPS for BTA rather than the PRG used in our approach. Further, Consel and Danvy have shown that conversion of a subject program to CPS style improves the residual program produced for it by a partial evaluator <ref> [CD91] </ref>.
Reference: [CF89] <author> R. Cartwright and M. Felleisen. </author> <title> The semantics of program dependence. </title> <booktitle> Proceedings of the ACM SIGPLAN 89 Conference on Programming Language Design and Implementation, </booktitle> <address> (Portland, OR, </address> <month> June 21-23, </month> <year> 1989), </year> <journal> ACM SIG-PLAN Notices, </journal> <volume> 24(7), </volume> <month> July </month> <year> 1989. </year>
Reference-contexts: Cartwright et al. decomposed the meaning function for a program into a function that transforms programs into "code trees" that resemble PDGs, and an interpreter for code trees that provides an operational semantics for code trees <ref> [CF89] </ref>. These two semantics for PDGs are unsuitable for binding-time analysis because they do not provide a basis for capturing static and dynamic behaviour. In particular, the behaviour of a particular vertex or the values produced by it cannot be captured directly from the semantics.
Reference: [CFR + 88] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and K. Zadeck. </author> <title> An efficient method of computing static single assignment form. </title> <booktitle> In Conference Record of the Sixteenth ACM Symposium on Principles of Programming Languages, </booktitle> <address> (Austin, TX, </address> <month> January 11-13, </month> <year> 1989), </year> <pages> pages 25-35, </pages> <year> 1988. </year>
Reference-contexts: This component is implemented on top of the Wisconsin slicing tool, which contains modules to construct and slice PDGs. The second component of the implementation is the specializer and code generator. In the first phase, we use the algorithm described by Cytron et al in <ref> [CFR + 88] </ref> to introduce if and enter gate vertices into the CFG. For the remaining filtering vertices, we use a procedure described partially by Ramalingam in [RR89] to add the appropriate vertices to the PDG augmented with if and enter vertices.
Reference: [CLR90] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction To Algorithms. </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New Tork, </address> <year> 1990. </year>
Reference-contexts: Our algorithm for constructing loop dependences is shown as Algorithm 1 below. The algorithm has three steps: * In the first step, we identify strongly connected components in the flow dependence sub-graph of the SDG, which includes intra-procedural and inter-procedural flow dependence edges, using a standard algorithm from <ref> [CLR90, pp. 488-493] </ref>. This operation is linear in the size of the flow dependence graph, which is at most quadratic in the size of the program. * In the second step, we identify predicates that control intra-procedural flow dependence edges.
Reference: [DD77] <author> D.E. Denning and P.J. Denning. </author> <title> Certification of programs for secure information flow. </title> <journal> Commun. of the ACM, </journal> <volume> 20(7) </volume> <pages> 504-513, </pages> <month> July </month> <year> 1977. </year>
Reference-contexts: However, it is well known that the values of a variable may be transmitted from program point p 1 to program point p 2 even though there is no path of flow dependence edges from p 1 to p 2 <ref> [DD77] </ref>. (An example of this will be given shortly.) In such instances, the flow of values is captured indirectly via "control dependences." Intuitively, a vertex v is (directly) control dependent on vertex w if the computation at w determines how many times vertex v is executed during the execution of the <p> Control dependences were introduced by Denning and Denning to formalize the notion of information flow in programs, in the context of computer-security issues <ref> [DD77] </ref>. Since then, they have played a fundamental role in vectorizing and parallelizing compilers (for instance, see [FOW87]). The role of control dependences in partial evaluation was first noted by Ershov in [Ers82]. He used the term "logical dependence" to refer to transitive control dependence.
Reference: [DR95] <author> M. Das and T. Reps. </author> <title> Semantic foundations of binding-time analysis for imperative programs. </title> <booktitle> In Conference Record of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> San Diego, CA, </address> <month> June </month> <year> 1995, </year> <pages> pages 100-110, </pages> <year> 1995. </year>
Reference-contexts: All of the BTA algorithms defined in this chapter have this property. A complete description of PRGs in available in [RR89]. Other material presented in this chapter may also be found in <ref> [DR95] </ref>. 3.1 The PRG: A representation that formalizes de pendences In this section we describe the program representation graph, an intermediate form in which control dependences are represented explicitly.
Reference: [DR96] <author> M. Das and T. Reps. </author> <title> BTA termination using cfl-reachability. </title> <type> Technical Report 1329, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: This option yields better results, as it identifies a broader class of in-situ-decreasing parameters, and a narrower class of in-situ-increasing parameters. 167 6.7 Related work The work described in this chapter is also presented in <ref> [DR96] </ref>. The basis for this work is Holst's definition of the in-situ-decreasing property for function parameters in [Hol91]: An in-situ decreasing parameter of a function f strictly decreases in size on every (recursive) chain of calls from f to f .
Reference: [Ers82] <author> A.P. Ershov. </author> <title> Mixed computation: Potential applications and problems for study. </title> <journal> Theoretical Computer Science, </journal> <volume> 18 </volume> <pages> 41-67, </pages> <year> 1982. </year>
Reference-contexts: As a result, partial evaluation usually produces no more than linear speedups [JGS93, pp. 131]. 22 2.1.3 Semantic foundations and correctness The first formalization of the partial evaluation process was provided by Ershov in <ref> [Ers82] </ref>. He treated a program P as the source of a set of elementary computation steps C that could be partitioned into two disjoint components C 0 and C 00 by a partition function . <p> Since then, they have played a fundamental role in vectorizing and parallelizing compilers (for instance, see [FOW87]). The role of control dependences in partial evaluation was first noted by Ershov in <ref> [Ers82] </ref>. He used the term "logical dependence" to refer to transitive control dependence. Jones hinted at the possibility of using control dependences during binding-time analysis in a remark about "indirect dependences" caused by predicates of conditional statements [Jon88], but this direction was not pursued. <p> The first attempt at a semantic foundation for the partial evaluation process was provided by Ershov in <ref> [Ers82] </ref>; he defined it as a partitioning of elementary computation steps C into static computations C 0 and dynamic computations C 00 . Jones provided the first definition of what it means for a BTA algorithm to produce "correct" markings [Jon88] (congruence).
Reference: [FOW87] <author> J. Ferrante, K. Ottenstein, and J. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Accounting for this phenomenon in BTA algorithms is the primary result of this thesis. 2.2.3 The program dependence graph The program dependence graph (PDG) <ref> [FOW87] </ref> of a program P is a directed graph G (P ) = (V ,E), where V is a set of vertices that is identical to the set of vertices in the CFG of P , except for the Exit vertex, and E is a set of directed dependence edges connecting <p> Control dependences were introduced by Denning and Denning to formalize the notion of information flow in programs, in the context of computer-security issues [DD77]. Since then, they have played a fundamental role in vectorizing and parallelizing compilers (for instance, see <ref> [FOW87] </ref>). The role of control dependences in partial evaluation was first noted by Ershov in [Ers82]. He used the term "logical dependence" to refer to transitive control dependence. <p> Our approach is based on dependence graphs because they make the role of control dependences explicit. One such graph is the program dependence graph (PDG) defined by Ferrante et al. in <ref> [FOW87] </ref>. The PDG has been extended in several different directions: Horwitz et al. defined the system dependence graph (SDG), an extension of the PDG to handle programs with procedures [HRB90].
Reference: [Fut71] <author> Y. Futamura. </author> <title> Partial evaluation of computation process an approach to a compiler-compiler. </title> <journal> Systems, Computers, Controls, </journal> <volume> 2(5) </volume> <pages> 45-50, </pages> <year> 1971. </year>
Reference: [GJ89] <author> C. K. Gomard and N. D. Jones. </author> <title> Compiler generation by partial evaluation. </title> <editor> In G. X. Ritter, editor, </editor> <booktitle> Information Processing '89. Proceedings of the IFIP 11th World Computer Congress, </booktitle> <pages> pages 1139-1144. </pages> <publisher> IFIP, Amsterdam: North-Holland, </publisher> <year> 1989. </year>
Reference-contexts: is static, is executed away, while code that uses either x or a, both of which are dynamic, is emitted. 19 In the context of imperative programs, self-applicable partial evaluators (explained in Section 2.1.1) for flowchart languages have been constructed by Bulyonkov and Er-shov [Bul88], and by Gomard and Jones <ref> [GJ89] </ref>. Meyer has presented a specialization approach for a Pascal-like language that uses dynamic annotations rather than a separate BTA phase in order to obtain more efficient residual programs [Mey91]. However, his analysis loses some precision as a result.
Reference: [GJ91] <editor> C.K. Gomard and N.D. Jones. </editor> <title> A partial evaluator for the untyped lambda-calculus. </title> <journal> Journal of Functional Programming, </journal> <volume> 1(1) </volume> <pages> 21-69, </pages> <month> January </month> <year> 1991. </year> <month> 204 </month>
Reference: [GJ96] <author> Arne J. Glenstrup and Neil D. Jones. </author> <title> BTA algorithms to ensure termination of off-line partial evaluation. </title> <booktitle> Andrei Ershov Second International Conference `Perspectives of System Informatics', Lecture Notes in Computer Science, </booktitle> <year> 1996, 1996. </year>
Reference-contexts: A function that contains an in-situ decreasing parameter can only call itself a finite number of times before this parameter takes on the value null and recursion terminates. Glenstrup and Jones have devised a second algorithm that identifies in-situ decreasing parameters <ref> [GJ96] </ref>. They define a structure, called the parameter dependency 34 graph (we refer to this graph as the PG, to avoid confusing it with the PDG described earlier in this chapter), whose edges denote data dependences between function parameters. <p> Other authors have also tackled the termination problem, and have defined termination analyses that can be combined with congruence-based BTA to produce analyses that provide a termination guarantee for all programs <ref> [Hol91, GJ96, AH96] </ref>. The chief differences between their work and ours are: * Other termination analyses are applicable only to restricted languages, and can analyze only simple kinds of termination criteria. <p> Glenstrup and Jones have defined a second algorithm that identifies in-situ decreasing parameters <ref> [GJ96] </ref>. They define a structure, called the parameter dependency graph (we refer to this as the PG to distinguish it from the PDG described in Chapter 2), whose edges denote flow dependences between function parameters. Edges are 133 labeled to indicate their size-changing effects, as in Example 11 below. <p> In Section 6.7, we summarize related work. 6.1 A simple functional language and its semantics In this section we present a simple, first-order call-by-value functional language, F, and the semantics of programs in F. The language and its description are taken directly from Glenstrup and Jones's work in <ref> [GJ96] </ref>; we use the same language so that our results can be compared with previous work, while we reproduce the language description here for completeness. <p> parameter values with which the caller f is called, and ~v k is the vector of parameter values with which the callee f is called. 6.1.2 Call paths We can approximate the transition sequences from the concrete semantics with the abstract call path constructs defined by Glenstrup and Jones in <ref> [GJ96] </ref>. A call path is an abstraction of a transition sequence where every vector of values is replaced by a vector of syntactic expressions. <p> A parameter is BSV if the set of all the different values taken by the parameter, 144 given fixed static inputs to main, is finite. We borrow the definition used by Glenstrup and Jones in <ref> [GJ96] </ref> as Definition 25 below. <p> The lemma is a re-statement of Theorem 8 from <ref> [GJ96] </ref>. 6.3 The augmented parameter dependence graph In this section we present the augmented parameter dependence graph (APG), an extension of Glenstrup and Jones' parameter dependency graph, in which flow dependences between parameters are captured through edges in the graph. <p> This algorithm has a structure that is significantly different from that of Glenstrup and Jones' algorithm in <ref> [GJ96] </ref>. Their algorithm is pessimistic, in the sense that every static parameter is treated as non-BSV until proven otherwise through the steps of the algorithm. In contrast, our algorithm is optimistic: Every static parameter is treated as BSV until (conservatively) shown otherwise. <p> Glenstrup and Jones define a second algorithm for identifying in-situ-decreasing parameters, which uses the markings ", # and = on edges in the parameter dependency graph <ref> [GJ96] </ref>. The algorithm described in this paper extends their work by using CFL-Reachability to identify a broader class of size-decreasing paths, and by using an optimistic algorithm. Andersen and Holst have described an extension of Holst's analysis to a higher-order lambda calculus [AH96]. <p> In order to identify a greater number of in-situ-decreasing parameters than Glenstrup and Jones, we extend the parameter dependency graph with new nodes and new edge markings and we use CFL-Reachability rather than a closed semi-ring graph 168 algorithm <ref> [AHU74, GJ96] </ref>. * There is a general result that all "context-free language reachability problems" can be solved in time cubic in the number of vertices in the graph [Yan90].
Reference: [GKW85] <author> J. R. Gurd, C. C. Kirkham, and I. Watson. </author> <title> The manchester prototype dataflow computer. </title> <journal> CACM, </journal> <volume> 28(1) </volume> <pages> 34-52, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: Much work has been done in the past on executing data-flow graphs, and in designing data-flow machines that can execute data-flow graphs directly. For instance, see [Pap88], [NA89], and <ref> [GKW85] </ref>. All of these designs use a producer-consumer model, in which a consumer is ready to fire or produce a new output value when it has values, 196 tagged appropriately to ensure that input values are matched correctly, available on all of its input arcs from its predecessors.
Reference: [GL91] <author> K.B. Gallagher and J.R. Lyle. </author> <title> Using program slicing in software maintenance. </title> <journal> IEEE Trans. on Softw. Eng., </journal> <volume> SE-17(8):751-761, </volume> <month> August </month> <year> 1991. </year>
Reference-contexts: The PDG for the power program is shown in Figure 9. Program dependence graphs have been used as an intermediate program representation in various contexts such as program understanding, maintenance <ref> [GL91] </ref>, debugging [LW86], testing [Bin92, BH93], differencing [Hor90], specialization [RT96], reuse [NEK94], merging [HPR88a], and vectorization and parallelization [KKL + 81]. They have the advantage that they make both flow and control dependences explicit in their structure, leading to efficient algorithms for tracing the relationships between program components.
Reference: [Har78] <author> A. Haraldsson. </author> <title> A partial evaluator, and its use for compiling iterative statements in Lisp. </title> <booktitle> In Fifth ACM Symposium on Principles of Programming Languages, </booktitle> <address> Tucson, Arizona, </address> <pages> pages 195-202. </pages> <address> New York: </address> <publisher> ACM, </publisher> <year> 1978. </year>
Reference: [Hec77] <author> M. S. Hecht. </author> <title> Flow analysis of computer programs. </title> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: All other variables are marked static. In order to obtain static vs. dynamic markings for every program variable at every program point, we use the markings at PRG vertices as the input to a simple forward any-path Gen-Kill data flow problem <ref> [Hec77] </ref> on the CFG, as shown in Figure 22. There is a one-to-one correspondence between the nodes in the CFG of a program and the non--vertices in the PRG of a program.
Reference: [Hol91] <author> C.K. Holst. </author> <title> Finiteness analysis. </title> <editor> In J. Hughes, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <address> Cambridge, Massachusetts, </address> <booktitle> August 1991 (Lecture Notes in Computer Science, </booktitle> <volume> vol. 523), </volume> <pages> pages 473-495. </pages> <publisher> ACM, Berlin: Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: For functional programs without looping constructs and infinite data structures, non-terminating behaviour must result from infinite recursion. Holst has shown that in programs that manipulate S-expression data (i.e., values built up using cons operations), it is possible to identify functions that are limited to finite recursion <ref> [Hol91] </ref>. He identifies parameters that are "in-situ decreasing": An in-situ decreasing parameter of a function f strictly decreases in size on every (recursive) chain of calls from f to f . <p> Other authors have also tackled the termination problem, and have defined termination analyses that can be combined with congruence-based BTA to produce analyses that provide a termination guarantee for all programs <ref> [Hol91, GJ96, AH96] </ref>. The chief differences between their work and ours are: * Other termination analyses are applicable only to restricted languages, and can analyze only simple kinds of termination criteria. <p> In the context of functional programs without explicit looping constructs and infinite data structures, non-terminating partial evaluation results from infinite recursion (or, infinite unfolding). Holst has shown that in programs that manipulate S-expressions or list data it is possible to identify functions that are limited to finite recursion <ref> [Hol91] </ref>. He identifies parameters that are "in-situ decreasing": An in-situ decreasing parameter of a function f strictly decreases in size on every (recursive) chain of calls from f to f . <p> The basis for this work is Holst's definition of the in-situ-decreasing property for function parameters in <ref> [Hol91] </ref>: An in-situ decreasing parameter of a function f strictly decreases in size on every (recursive) chain of calls from f to f .
Reference: [Hor90] <author> S. Horwitz. </author> <title> Identifying the semantic and textual differences between two versions of a program. </title> <booktitle> Proceedings of the ACM SIGPLAN 90 Conference on Programming Language Design and Implementation, </booktitle> <address> (White Plains, NY, </address> <month> June 20-22, </month> <year> 1990), </year> <journal> ACM SIGPLAN Notices, </journal> <volume> 25(6) </volume> <pages> 234-245, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The PDG for the power program is shown in Figure 9. Program dependence graphs have been used as an intermediate program representation in various contexts such as program understanding, maintenance [GL91], debugging [LW86], testing [Bin92, BH93], differencing <ref> [Hor90] </ref>, specialization [RT96], reuse [NEK94], merging [HPR88a], and vectorization and parallelization [KKL + 81]. They have the advantage that they make both flow and control dependences explicit in their structure, leading to efficient algorithms for tracing the relationships between program components.
Reference: [HPR88a] <author> S. Horwitz, J. Prins, and T. Reps. </author> <title> Integrating non-interfering versions of programs. </title> <booktitle> In Conference Record of the Fifteenth ACM Symposium on Principles of Programming Languages, </booktitle> <address> (San Diego, CA, </address> <month> January 13-15, </month> <year> 1988), </year> <pages> pages 133-145, </pages> <year> 1988. </year>
Reference-contexts: The PDG for the power program is shown in Figure 9. Program dependence graphs have been used as an intermediate program representation in various contexts such as program understanding, maintenance [GL91], debugging [LW86], testing [Bin92, BH93], differencing [Hor90], specialization [RT96], reuse [NEK94], merging <ref> [HPR88a] </ref>, and vectorization and parallelization [KKL + 81]. They have the advantage that they make both flow and control dependences explicit in their structure, leading to efficient algorithms for tracing the relationships between program components. <p> issue is whether PDGs have enough information to remain faithful to the semantics of the programs they represent; this is not readily apparent, because the same PDG may represent multiple programs, as in given the same initial state either both programs diverge or both programs produce the same final state <ref> [HPR88a] </ref>. Therefore, the PDG is a suitable program representation for reasoning about the behaviour of a program. Unlike CFGs, PDGs do not have an agreed-upon operational semantics that can be used to reason about the behaviour of the programs they represent. <p> For instance, Horwitz et al. have shown that if the PDGs of two programs are isomorphic, given the same initial state either both programs diverge or both produce the same final state <ref> [HPR88a] </ref>. Such a property makes it reasonable to develop a semantics for PDGs themselves. Selke has defined a graph rewriting semantics for PDGs [Sel89] that represents computation steps as graph transformations. <p> The program in Figure 49 (b) violates this requirement. Horwitz et al. have described a method to reconstitute sequential code from PDGs for which program text is not available, in the context of program integration <ref> [HPR88a] </ref>. Their solution involves constructing dependence edges similar to output-dependence and anti-dependence edges from the PDG, and then emitting program text using a topological sort on the augmented dependence graph. However, the problem of constructing output-dependence and anti-dependence edges from an arbitrary PDG is NP-complete [Ram89].
Reference: [HPR88b] <author> S. Horwitz, J. Prins, and T. Reps. </author> <title> On the adequacy of program dependence graphs for representing programs. </title> <booktitle> In Conference Record of the Fifteenth ACM Symposium on Principles of Programming Languages, </booktitle> <address> (San Diego, CA, </address> <month> January 13-15, </month> <year> 1988), </year> <pages> pages 146-157, </pages> <year> 1988. </year>
Reference-contexts: In addition to flow and control dependences, the PDG also contains def-order edges that maintain ordering relationships between multiple definitions of the same variable <ref> [HPR88b] </ref>. An example of the use of def-order edges is shown in Figure 8. <p> Therefore, the goal of reconstitution is to generate a sequential program that corresponds to the given PRG. Any program that is represented by the residual PRG would be satisfactory. This is because, as shown by Horwitz et al in <ref> [HPR88b] </ref>, if two programs share the same PDG, they must have the same behaviour in the standard semantics.
Reference: [HRB90] <author> S. Horwitz, T. Reps, and D. Binkley. </author> <title> Interprocedural slicing using dependence graphs. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 12(1) </volume> <pages> 26-60, </pages> <month> January </month> <year> 1990. </year> <month> 205 </month>
Reference-contexts: The idea is to follow all flow and control dependence edges from the set of read vertices in the PRG, marking with D all vertices that are 58 encountered along the way. This operation is identical to a forward program slice <ref> [HRB90] </ref> from the set of read vertices in the PRG. Vertices that are not in this forward slice are marked with S. Vertices that are not in the forward slice of any read vertex (i.e. vertices marked S) are guaranteed to have no read vertex in their backward slices. <p> One such graph is the program dependence graph (PDG) defined by Ferrante et al. in [FOW87]. The PDG has been extended in several different directions: Horwitz et al. defined the system dependence graph (SDG), an extension of the PDG to handle programs with procedures <ref> [HRB90] </ref>. <p> As we mentioned earlier, the PRG is an extension of the program dependence graph, which represents single procedure programs. Horwitz et al have extended the PDG to programs with procedures by defining the system dependence graph (SDG) <ref> [HRB90] </ref>. The SDG contains a dependence graph similar to the PDG for every procedure in the program, and inter-procedural dependence edges that link the procedure dependence 76 graphs in order to account for the procedure calls in the program. <p> we can extend our work to handle arbitrary multi-procedure programs. 77 4.1 The system dependence graph The system dependence graph (SDG) is an extension of the program dependence graph, designed by Horwitz et al to extend the operations of program slicing and integration to programs with procedure definitions and calls <ref> [HRB90] </ref>. Programs represented by SDGs have the same features as the single procedure programs represented by PDGs, with the following extensions: There is a single main procedure and several auxiliary procedures, none of which may call the main procedure. <p> In this section, we define three BTA algorithms as abstract interpretations of the SRG semantics. Operationally, these algorithms are simple reachability operations on the SRG, and can be viewed as variants of operations for inter-procedural program slicing <ref> [HRB90] </ref>. Therefore, each of these algorithm has a running time that is linear in the number of edges in the SRG. Our BTA algorithms are "context-insensitive," in the sense that they do not account for calling context precisely. <p> The idea is to follow all flow and control dependence edges from the set of read vertices in the SRG, marking with D all vertices that are encountered along the way. This operation is identical to a forward inter-procedural program slice <ref> [HRB90] </ref> from the set of read vertices in the SRG. Vertices that are not in this forward slice are marked with S. We present the Strong-Staticness BTA for SRGs as the fixed point of an abstract interpretation that is consistent with the SRG semantics. <p> In this respect, our algorithms are similar to that of cmix, which is not context-sensitive. Horwitz et al. have shown that this problem can be handled efficiently, in the context of program slicing, by introducing "summary" edges in the SDG <ref> [HRB90] </ref>. We omit these edges from the SRG, because it is not clear how we would follow summary edges in a BTA algorithm such as Weak-Staticness BTA that follows dependence edges selectively.
Reference: [Jac90] <author> H.F. Jacobsen. </author> <title> Speeding up the back-propagation algorithm by partial evaluation. Student Project 90-10-13, </title> <institution> DIKU, University of Copenhagen, Denmark. (In Danish), </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: Therefore, partial evaluation works well on programs that interpret static data to determine how dynamic data must be manipulated. Large speedups have been reported from partially evaluating circuit simulators [BW90], neural networks <ref> [Jac90] </ref>, computations using networks of processors [RP89], pattern matchers [CD89, Bon90], and other programs that interpret part of their input. However, partial evaluation is not a general program transformation that can change a program's computational method.
Reference: [JGS93] <author> N.D. Jones, C.K. Gomard, and P. Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference-contexts: However, partial evaluation is not a general program transformation that can change a program's computational method. As a result, partial evaluation usually produces no more than linear speedups <ref> [JGS93, pp. 131] </ref>. 22 2.1.3 Semantic foundations and correctness The first formalization of the partial evaluation process was provided by Ershov in [Ers82]. <p> A variable is BSV if the set of distinct values taken on by it over all possible dynamic inputs is finite <ref> [JGS93, pp. 300] </ref>. <p> If such a vertex is not BSV, it must be static-infinite. Definition 10 PRG G is static-infinite iff Static (G) BSV (G) 6= ;. 2 In contrast with the definition of Jones et al. in <ref> [JGS93, pp. 118] </ref>, which is an informal description of static-infinite computation as an "infinite static loop," that is, "a loop not involving any dynamic tests," Definition 10 is a semantic definition that can be used to characterize the safety properties of a binding-time analysis algorithm. 55 3.3.2 BTA characterizations With a <p> Jones hinted at the possibility of using control dependences during binding-time analysis in a remark about "indirect dependences" caused by predicates of conditional statements [Jon88], but this direction was not pursued. Neither author described how the conservative results of analyses that always follow control dependences could be avoided. In <ref> [JGS93] </ref>, Jones et al. informally presented the notions of "oblivious" and "weakly oblivious" programs (in contrast with unoblivious programs), a distinction based on whether a program involves tests on dynamic data. <p> The idea is to use the knowledge of the text of the interpreter to simplify the code of the partial evaluator. Consider a partial evaluator mix of the form described by Jones et al. in <ref> [JGS93, pp. 85-87] </ref>. The specialization component of mix has a pending loop, which selects a program point from the pending list and performs specialization actions at that program point. The pending list in turn may be updated by the specialization actions at that program point. <p> For each program point, the specializer examines the statements in the code at the program point and processes the code accordingly. Consider the fragment of code within the pending loop of mix below, taken from <ref> [JGS93, pp. 91-93] </ref>: bb = lookup (pp; prog); In the code above, pp is current program point being processed, bb is the basic block at pp, and prog is a linked list of the basic blocks in the interpreter. pp is dynamic, because it is taken from the pending list, which
Reference: [Jon88] <author> N.D. Jones. </author> <title> Automatic program specialization: A re-examination from basic principles. </title> <editor> In D. Bjtrner, A.P. Ershov, and N.D. Jones, editors, </editor> <booktitle> Partial Evaluation and Mixed Computation, </booktitle> <pages> pages 225-282. </pages> <address> Amsterdam: </address> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: He used the term "logical dependence" to refer to transitive control dependence. Jones hinted at the possibility of using control dependences during binding-time analysis in a remark about "indirect dependences" caused by predicates of conditional statements <ref> [Jon88] </ref>, but this direction was not pursued. Neither author described how the conservative results of analyses that always follow control dependences could be avoided. <p> Jones provided the first definition of what it means for a BTA algorithm to produce "correct" markings <ref> [Jon88] </ref> (congruence). As mentioned earlier, the notion of congruence is an unsatisfactory correctness criteria for BTA algorithms; we have shown that the PRG semantics can be used to define suitable criteria.
Reference: [Jon95] <author> N. D. Jones. </author> <title> Mix: Ten years after. </title> <booktitle> In Conference Record of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> San Diego, CA, </address> <month> June </month> <year> 1995, </year> <note> page ??, 1995. </note>
Reference-contexts: Corollary 13 For a set of PRGs Gset that contains no static-infinite PRGs, bta is conditionally safe on Gset , bta is safe on Gset. 2 Thus, a conditionally safe BTA guarantees termination in the absence of static-infinite computation. 3.3.3 Termination versus computational completeness As pointed out by Jones in <ref> [Jon95] </ref>, specialization involves a basic tradeoff between "totality" and "computational completeness." A specializer can be computationally complete in that it executes every static computation in its subject programs, but then on a program that contains static-infinite computations, the specializer must diverge without producing a residual program, thereby violating the totality condition.
Reference: [JSS85] <author> N.D. Jones, P. Sestoft, and H. Stndergaard. </author> <title> An experiment in partial evaluation: The generation of a compiler generator. </title> <editor> In J.-P. Jouannaud, editor, </editor> <booktitle> Rewriting Techniques and Applications, Dijon, France. (Lecture Notes in Computer Science, </booktitle> <volume> vol. 202), </volume> <pages> pages 124-140. </pages> <address> Berlin: </address> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: The table from Figure 37 shows that cmix does not terminate on the power function, when specialized to a known base value, as reported earlier. This is because the 126 congruence-based BTA of cmix ignores dynamic control. Exactly the same problem arises in, for instance, the NORMA interpreter from <ref> [JSS85] </ref>. We have not included these programs here because we have not obtained the source code for them. The goal of our experiments is to show that the Loop-Dependence BTA can handle the common occurrences of static behaviour.
Reference: [Kas65] <author> J. Kasami. </author> <title> An efficient recognition and syntax analysis algorithm for context-free languages. </title> <type> Scientific Report AFCRL-65-758, </type> <institution> Air Force Cam-bridge Research Laboratory, Bedford, </institution> <address> MA, </address> <year> 1965. </year>
Reference-contexts: CFL-reachability problems can be solved using a dynamic-programming algorithm. (The algorithm can be thought of as a generalization of the CYK algorithm for context-free recognition <ref> [Kas65, You67] </ref>.) There is a general result that all CFL-reachability problems can be solved in time cubic in the number of vertices in the graph [Yan90]. Thus, CFL-Reachability affords higher precision than simple reachability, but at the cost of a cubic-time algorithm. <p> restrictions on when two vertices are considered to be "connected" (beyond just "connected by a sequence of edges", as one has with ordinary reachability). 152 CFL-Reachability problems can be solved using a dynamic-programming algorithm. (The algorithm can be thought of as a generalization of the CYK algorithm for context-free recognition <ref> [Kas65, You67] </ref>.) There is a general result that all CFL-Reachability problems can be solved in time cubic in the number of vertices in the graph [Yan90, MR97]. (This holds even if the context-free language is specified with an ambiguous grammar.) Because the number of vertices in the APG for a program
Reference: [Kel95] <author> R. A. Kelsey. </author> <title> A correspondence between continuation passing style and static single assignment form. </title> <booktitle> In ACM SIGPLAN Workshop on Intermediate Representations (IR '95) (Technical Report MSR-TR-95-01, </booktitle> <publisher> Microsoft Research, Microsoft Corporation), </publisher> <pages> pages 13-22, </pages> <year> 1995. </year>
Reference-contexts: As a result, we use Ramalingam's semantics for extended PRGs [RR89]. Program representations such as the PRG and SSA form are similar to the continuation passing style (CPS) [App92], in that information is stored about the future use of variables in the program. More formally, Kelsey has shown in <ref> [Kel95] </ref> that it is always possible to convert programs written in SSA form to CPS. This might suggest the use of CPS for BTA rather than the PRG used in our approach. <p> Further, Consel and Danvy have shown that conversion of a subject program to CPS style improves the residual program produced for it by a partial evaluator [CD91]. The arguments against using CPS are two-fold: (a) As pointed out by Kelsey in <ref> [Kel95] </ref>, converting an imperative program to CPS style requires the same flow analysis as that required to produce 73 the SSA form (or the PRG), and (b) Given a choice between two essentially similar representations, the PRG is preferable as its semantics provides a straightforward way to define a semantic foundation
Reference: [KKL + 81] <author> D. J. Kuck, R. H. Kuhn, B. Leasure, D. A. Padua, and M. Wolfe. </author> <title> Dependence graphs and compiler optimizations. </title> <booktitle> In Conference Record of the Eighth ACM Symposium on Principles of Programming Languages, </booktitle> <address> (Williamsburg, VA, </address> <month> January 26-28, </month> <year> 1981), </year> <pages> pages 207-218, </pages> <year> 1981. </year>
Reference-contexts: The PDG for the power program is shown in Figure 9. Program dependence graphs have been used as an intermediate program representation in various contexts such as program understanding, maintenance [GL91], debugging [LW86], testing [Bin92, BH93], differencing [Hor90], specialization [RT96], reuse [NEK94], merging [HPR88a], and vectorization and parallelization <ref> [KKL + 81] </ref>. They have the advantage that they make both flow and control dependences explicit in their structure, leading to efficient algorithms for tracing the relationships between program components. <p> These data dependences were defined by Kuck et al in <ref> [KKL + 81] </ref>: An output-dependence edge connects two definitions of the same variable, indicating that one definition must appear before the other in the program text. Similarly, an anti-dependence edge links a use of a program variable to a definition 185 of the same variable.
Reference: [Kle52] <author> S.C. Kleene. </author> <title> Introduction to Metamathematics. </title> <publisher> Princeton, </publisher> <address> NJ: D. </address> <publisher> van Nostrand, </publisher> <year> 1952. </year>
Reference: [Kom81] <author> H.J. Komorowski. </author> <title> A Specification of an Abstract Prolog Machine and Its Application to Partial Evaluation. </title> <type> PhD thesis, </type> <institution> Linkoping University, Swe-den, 1981. Linkoping Studies in Science and Technology Dissertations 69. </institution> <month> 206 </month>
Reference: [KR96] <author> T. Knoblock and E. Ruf. </author> <title> Data specialization. </title> <booktitle> Proceedings of the ACM SIG-PLAN 96 Conference on Programming Language Design and Implementation, </booktitle> <address> (Philadelphia, PA, </address> <month> May 21-24, </month> <year> 1996), </year> <journal> ACM SIGPLAN Notices, </journal> <pages> pages 215-225, </pages> <year> 1996. </year>
Reference-contexts: Any such set of programs should include multimedia programs, which appear to hold promise as an application area for partial evaluation of imperative programs <ref> [KR96] </ref>. This remains as one of the many steps that must be taken before partial evaluation is adopted as a practical technique for improving program performance. 201
Reference: [LW86] <author> J. Lyle and M. Weiser. </author> <title> Experiments on slicing-based debugging tools. </title> <booktitle> In Proc. of the First Conf. on Empirical Studies of Programming, </booktitle> <month> June </month> <year> 1986, </year> <pages> pages 133-145, </pages> <year> 1986. </year>
Reference-contexts: The PDG for the power program is shown in Figure 9. Program dependence graphs have been used as an intermediate program representation in various contexts such as program understanding, maintenance [GL91], debugging <ref> [LW86] </ref>, testing [Bin92, BH93], differencing [Hor90], specialization [RT96], reuse [NEK94], merging [HPR88a], and vectorization and parallelization [KKL + 81]. They have the advantage that they make both flow and control dependences explicit in their structure, leading to efficient algorithms for tracing the relationships between program components.
Reference: [Mey91] <author> U. Meyer. </author> <title> Techniques for partial evaluation of imperative languages. In Partial Evaluation and Semantics-Based Program Manipulation, New Haven, </title> <journal> Connecticut (Sigplan Notices, </journal> <volume> vol. 26, no. 9, </volume> <month> September </month> <year> 1991), </year> <pages> pages 94-105. </pages> <address> New York: </address> <publisher> ACM, </publisher> <year> 1991. </year>
Reference-contexts: Meyer has presented a specialization approach for a Pascal-like language that uses dynamic annotations rather than a separate BTA phase in order to obtain more efficient residual programs <ref> [Mey91] </ref>. However, his analysis loses some precision as a result. Furthermore, he sidesteps the issue of termination of the partial evaluator by assuming that the program terminates for all inputs, which is an overly strong restriction on program behaviour.
Reference: [Mog92] <author> T. Mogensen. </author> <title> Self-applicable partial evaluation for pure lambda calculus. In Partial Evaluation and Semantics-Based Program Manipulation, </title> <address> San Francisco, California, </address> <note> June 1992 (Technical Report YALEU/DCS/RR-909), pages 116-121. </note> <institution> New Haven, CT: Yale University, </institution> <year> 1992. </year>
Reference: [MR97] <author> D. Melski and T. Reps. </author> <title> Interconvertibility of set constraints and context-free langauge reachability. </title> <booktitle> In PEPM '97: Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June 12-13, </month> <year> 1997, </year> <pages> pages 74-89. </pages> <address> New York: </address> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: CFL-Reachability problems can be solved using a dynamic-programming algorithm. (The algorithm can be thought of as a generalization of the CYK algorithm for context-free recognition [Kas65, You67].) There is a general result that all CFL-Reachability problems can be solved in time cubic in the number of vertices in the graph <ref> [Yan90, MR97] </ref>. (This holds even if the context-free language is specified with an ambiguous grammar.) Because the number of vertices in the APG for a program p is bounded by O (F + P + V ar + Ops), the problem of identifying whether an L-path exists from every vertex in <p> He used edge markings that are identical to the markings used on the edges of the APG defined in this paper. Melski and Reps have shown that CFL-Reachability problems are convertible into a class of set-constraint problems (and vice versa) <ref> [MR97] </ref>. Because set-constraints are related to regular tree grammars, this result also has some bearing on the relationship between our work and that of Andersen and Holst.
Reference: [MS92] <author> M. Marquard and B. Steensgaard. </author> <title> Partial evaluation of an object-oriented imperative language. </title> <type> Master's thesis, </type> <institution> DIKU, University of Copenhagen, Denmark, </institution> <month> April </month> <year> 1992. </year> <note> Available from ftp.diku.dk as file pub/diku/semantics/papers/D-152.ps.Z. </note>
Reference: [NA89] <author> R. S. Nikhil and Arvind. </author> <booktitle> Can dataflow subsume von neumann computing? In Proceedings of the 16th International Symposium on Computer Architecture, IEEE/ACM, </booktitle> <address> Jerusalem, Israel, </address> <month> May </month> <year> 1989, 1989. </year>
Reference-contexts: Extending the algorithm to programs with procedures appears straightforward, although we have not implemented such an extension as of this time. Much work has been done in the past on executing data-flow graphs, and in designing data-flow machines that can execute data-flow graphs directly. For instance, see [Pap88], <ref> [NA89] </ref>, and [GKW85]. All of these designs use a producer-consumer model, in which a consumer is ready to fire or produce a new output value when it has values, 196 tagged appropriately to ensure that input values are matched correctly, available on all of its input arcs from its predecessors.
Reference: [NEK94] <author> J.Q. Ning, A. Engberts, and W. Kozaczynski. </author> <title> Automated support for legacy code understanding. </title> <journal> CACM, </journal> <volume> 37(5) </volume> <pages> 50-57, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The PDG for the power program is shown in Figure 9. Program dependence graphs have been used as an intermediate program representation in various contexts such as program understanding, maintenance [GL91], debugging [LW86], testing [Bin92, BH93], differencing [Hor90], specialization [RT96], reuse <ref> [NEK94] </ref>, merging [HPR88a], and vectorization and parallelization [KKL + 81]. They have the advantage that they make both flow and control dependences explicit in their structure, leading to efficient algorithms for tracing the relationships between program components.
Reference: [oWM97] <institution> University of Wisconsin-Madison. Wisconsin Program-Slicing Tool 1.0 Reference Manual. University of Wisconsin-Madison, Madison, WI, USA, </institution> <year> 1997. </year> <month> 207 </month>
Reference-contexts: We have developed our implementation, which we refer to as Spec (safe partial evaluation for C), on top of a version of the Wisconsin Program-Slicing Tool developed at the University of Wisconsin <ref> [oWM97] </ref>. This tool provides an infrastructure for building dependence graph representations of C programs. The system has a front-end for Ansi C programs, and a back-end that generates a system dependence graph, given a set of input C programs. The front-end includes an implementation of Andersen's pointer analysis algorithm. <p> However, this cannot be guaranteed. 7.5 Experimental results We have implemented our specializer using a version of the Wisconsin Program-Slicing Tool developed at the University of Wisconsin <ref> [oWM97] </ref>. The specializer includes two independent components: The first component parses the source program, constructs the PRG, builds output-dependence and anti-dependence edges, and performs the BTA phase. This component is implemented on top of the Wisconsin slicing tool, which contains modules to construct and slice PDGs.
Reference: [Pap88] <author> G. M. Papadopoulos. </author> <title> Implementation of a General Purpose Dataflow Mulit-processor. </title> <type> PhD thesis, </type> <institution> Massachussetts Institute of Technology Laboratory for Computer Science, 1988. MIT Laboratory for Computer Science Technical Report 432. </institution>
Reference-contexts: Extending the algorithm to programs with procedures appears straightforward, although we have not implemented such an extension as of this time. Much work has been done in the past on executing data-flow graphs, and in designing data-flow machines that can execute data-flow graphs directly. For instance, see <ref> [Pap88] </ref>, [NA89], and [GKW85].
Reference: [Pet81] <author> J. L. Peterson. </author> <title> Petri Net Theory and the Modeling of Systems. </title> <publisher> Prentice-Hall, </publisher> <address> New Jersey, </address> <year> 1981. </year>
Reference-contexts: The same concept has also been applied to other structures such as petri nets <ref> [Pet81] </ref>. Our PRG execution model is similar to this model. The difference is that we are interested in partial execution of the graph, rather than total execution. The PRG semantics allows us to express PRG specialization as a data-flow computation.
Reference: [Ram89] <author> G. Ramalingam, </author> <year> 1989. </year> <type> Personal communication to Tom Reps. </type>
Reference-contexts: The other issue that arises from the lack of sequential order in PDGs is whether it is possible to recover a sequential program from a PDG, if the original program from which the PDG was derived is not available. This problem is referred to as the "reconstitution" problem; Ramalingam <ref> [Ram89] </ref> has shown that the problem is in general NP-complete. In Chapter 7 of this thesis we present an approach to specialization that involves transforming the dependence graph rather than the control-flow graph. Therefore, in order to produce a residual program, we must carry out reconstitution on the transformed PDG. <p> Their solution involves constructing dependence edges similar to output-dependence and anti-dependence edges from the PDG, and then emitting program text using a topological sort on the augmented dependence graph. However, the problem of constructing output-dependence and anti-dependence edges from an arbitrary PDG is NP-complete <ref> [Ram89] </ref>. In the case of reconstitution from the residual PRG, the problem is NP-complete in the size of the residual PRG, which is directly related to the amount of loop unrolling performed by the specialization phase.
Reference: [Rep95] <author> T. Reps. </author> <title> Shape analysis as a generalized path problem. In Partial Evaluation and Semantics-Based Program Manipulation, </title> <address> La Jolla, California, </address> <month> June </month> <year> 1995, </year> <pages> pages 1-11. </pages> <address> New York: </address> <publisher> ACM, </publisher> <year> 1995. </year>
Reference-contexts: by the cdr operation on state (shown by the edge from v 4 to v 5 ), the net effect is that just a single cdr is applied to vals (as indicated by the edge from v 1 to v 2 ). 2 To handle such cases, we use CFL-Reachability <ref> [Yan90, Rep95] </ref>, a generalized form of graph reachability. A CFL-Reachability problem is one in which a path is considered to connect two vertices in a graph only if the concatenation of the labels on the edges of the path is a word in a certain context-free language. <p> CFL-Reachability has also been used for a number of other program-analysis problems: Reps, Sagiv, and Horwitz have used CFL-Reachability techniques to solve inter-procedural dataflow-analysis problems [RSH94, RSH95] and to perform interprocedural slicing [RHSR94]. Reps has used CFL-Reachability to develop a shape-analysis algorithm <ref> [Rep95] </ref>. He used edge markings that are identical to the markings used on the edges of the APG defined in this paper. Melski and Reps have shown that CFL-Reachability problems are convertible into a class of set-constraint problems (and vice versa) [MR97].
Reference: [Rep97] <author> T. Reps. </author> <title> Program analysis via graph reachability. </title> <booktitle> In Proc. of ILPS '97: International Logic Programming Symposium, (Port Jefferson, </booktitle> <address> NY, </address> <month> Oct. </month> <pages> 12-16, </pages> <year> 1997), </year> <editor> J. Maluszynski (ed.), </editor> <address> pages 5-19, Cambridge, MA, 1997. </address> <publisher> The M.I.T. Press. </publisher>
Reference-contexts: Reps et al. have presented an alternative approach to this problem, which involves using context-free language reachability to "match" parameter-in and parameter-out edges appropriately [RHS95]. It is possible that we could phrase our BTA algorithms declaratively as context-free language reachability problems, and use the scheme in <ref> [RHS95, Rep97] </ref> to account for the calling context on a procedure more precisely. We have not investigated this possibility.
Reference: [RHS95] <author> T. Reps, S. Horwitz, and M. Sagiv. </author> <title> Precise interprocedural dataflow analysis via graph reachability. </title> <booktitle> In Conference Record of the Twenty-Second ACM Symposium on Principles of Programming Languages, </booktitle> <address> (San Francisco, CA, </address> <month> January 23-25, </month> <year> 1995), </year> <pages> pages 49-61, </pages> <year> 1995. </year>
Reference-contexts: However, we can use summary edges to implement a context-sensitive version of Strong-Staticness BTA, since that algorithm follows all the dependence edges in the SRG. Reps et al. have presented an alternative approach to this problem, which involves using context-free language reachability to "match" parameter-in and parameter-out edges appropriately <ref> [RHS95] </ref>. It is possible that we could phrase our BTA algorithms declaratively as context-free language reachability problems, and use the scheme in [RHS95, Rep97] to account for the calling context on a procedure more precisely. We have not investigated this possibility. <p> Reps et al. have presented an alternative approach to this problem, which involves using context-free language reachability to "match" parameter-in and parameter-out edges appropriately [RHS95]. It is possible that we could phrase our BTA algorithms declaratively as context-free language reachability problems, and use the scheme in <ref> [RHS95, Rep97] </ref> to account for the calling context on a procedure more precisely. We have not investigated this possibility.
Reference: [RHSR94] <author> T. Reps, S. Horwitz, M. Sagiv, and G. Rosay. </author> <title> Speeding up slicing. </title> <booktitle> In SIGSOFT 94: Proceedings of the Second ACM SIGSOFT Symposium on the Foundations of Software Engineering, </booktitle> <address> (New Orleans, LA, </address> <month> December 7-9, </month> <year> 1994), </year> <booktitle> ACM SIGSOFT Software Engineering Notes 19(5), </booktitle> <pages> pages 11-20, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: CFL-Reachability has also been used for a number of other program-analysis problems: Reps, Sagiv, and Horwitz have used CFL-Reachability techniques to solve inter-procedural dataflow-analysis problems [RSH94, RSH95] and to perform interprocedural slicing <ref> [RHSR94] </ref>. Reps has used CFL-Reachability to develop a shape-analysis algorithm [Rep95]. He used edge markings that are identical to the markings used on the edges of the APG defined in this paper.
Reference: [RP89] <author> A. Rogers and K. Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> Proceedings of the ACM SIGPLAN 89 Conference on Programming Language Design and Implementation, </booktitle> <address> (Portland, OR, </address> <month> June 21-23, </month> <year> 1989), </year> <journal> ACM SIGPLAN Notices, </journal> <volume> 24(7) </volume> <pages> 69-80, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Therefore, partial evaluation works well on programs that interpret static data to determine how dynamic data must be manipulated. Large speedups have been reported from partially evaluating circuit simulators [BW90], neural networks [Jac90], computations using networks of processors <ref> [RP89] </ref>, pattern matchers [CD89, Bon90], and other programs that interpret part of their input. However, partial evaluation is not a general program transformation that can change a program's computational method.
Reference: [RR89] <author> G. Ramalingam and T. Reps. </author> <title> Semantics of program representation graphs. </title> <type> Technical Report TR-900, </type> <institution> Computer Sciences Department, University of Wisconsin, Madison, WI, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: In particular, we are interested in providing a termination guarantee for partial evaluation in the absence of static-infinite computation. All of the BTA algorithms defined in this chapter have this property. A complete description of PRGs in available in <ref> [RR89] </ref>. Other material presented in this chapter may also be found in [DR95]. 3.1 The PRG: A representation that formalizes de pendences In this section we describe the program representation graph, an intermediate form in which control dependences are represented explicitly. <p> Since the predecessors of a vertex in the PRG are (almost always) its flow and control dependence predecessors, the PRG semantics summarized above makes the role of flow and control dependences explicit. Complete details of the semantics of PRGs can be found in <ref> [RR89] </ref>; in this section, we summarize the relevant concepts. <p> = ? select (x, nil, nil) = nil select (x, y tail 1 , z tail 2 ) = if (x = y) then z select (x, tail 1 , tail 2 ) else select (x, tail 1 , tail 2 ) Some vertex types are omitted for brevity (see <ref> [RR89] </ref> for a complete definition of E G ). 45 Definition 5 The meaning function M over the domain of PRGs is: M : PRG ! VertexFunc M [[G]] = fix F where F : VertexFunc ! VertexFunc F = f:i:v: E G (i; v; f ) The meaning function for <p> For inputs on which the program terminates normally, it has been shown that the two sequences are identical <ref> [RR89] </ref>. 47 3.2 Semantic characterizations of static and finite behaviour In this section we use the PRG semantics to define three increasingly general forms of static behaviour that account for dynamic control. We then define the orthogonal concept of bounded static variation. <p> In particular, the behaviour of a particular vertex or the values produced by it cannot be captured directly from the semantics. As a result, we use Ramalingam's semantics for extended PRGs <ref> [RR89] </ref>. Program representations such as the PRG and SSA form are similar to the continuation passing style (CPS) [App92], in that information is stored about the future use of variables in the program. <p> This is because, as shown by Horwitz et al in [HPR88b], if two programs share the same PDG, they must have the same behaviour in the standard semantics. This result has been extended to PRGs as well, in <ref> [RR89] </ref>. 184 y = 0; Reconstitution of sequential code from the PRG shown in (a) above may yield the program shown in (b) above, if a topological sort of the PRG is used to order the generated code. <p> In the first phase, we use the algorithm described by Cytron et al in [CFR + 88] to introduce if and enter gate vertices into the CFG. For the remaining filtering vertices, we use a procedure described partially by Ramalingam in <ref> [RR89] </ref> to add the appropriate vertices to the PDG augmented with if and enter vertices.
Reference: [RSH94] <author> T. Reps, M. Sagiv, and S. Horwitz. </author> <title> Interprocedural dataflow analysis via graph reachability. </title> <type> Technical Report 94/14, </type> <institution> DIKU, University of Copen-hagen, Denmark, </institution> <month> April </month> <year> 1994. </year> <month> 208 </month>
Reference-contexts: CFL-Reachability has also been used for a number of other program-analysis problems: Reps, Sagiv, and Horwitz have used CFL-Reachability techniques to solve inter-procedural dataflow-analysis problems <ref> [RSH94, RSH95] </ref> and to perform interprocedural slicing [RHSR94]. Reps has used CFL-Reachability to develop a shape-analysis algorithm [Rep95]. He used edge markings that are identical to the markings used on the edges of the APG defined in this paper.
Reference: [RSH95] <author> T. Reps, M. Sagiv, and S. Horwitz. </author> <title> Precise interprocedural dataflow analysis via graph reachability. </title> <booktitle> In Conference Record of the Twenty-Second ACM Syposium on Principles of Programming Languages, </booktitle> <address> (San Francisco, CA, </address> <month> Jan. </month> <pages> 23-25, </pages> <year> 1995), </year> <pages> pages 49-61, </pages> <year> 1995. </year>
Reference-contexts: CFL-Reachability has also been used for a number of other program-analysis problems: Reps, Sagiv, and Horwitz have used CFL-Reachability techniques to solve inter-procedural dataflow-analysis problems <ref> [RSH94, RSH95] </ref> and to perform interprocedural slicing [RHSR94]. Reps has used CFL-Reachability to develop a shape-analysis algorithm [Rep95]. He used edge markings that are identical to the markings used on the edges of the APG defined in this paper.
Reference: [RT96] <author> T. Reps and T. Turnidge. </author> <title> Program specialization via program slicing. </title> <booktitle> Proceedings of the Dagstuhl Seminar on Partial Evaluation, </booktitle> <address> Schloss Dagstuhl, Wadern, Germany, </address> <month> Feb. </month> <pages> 12-16, </pages> <year> 1996, </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> 1110 </volume> <pages> 409-429, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: The PDG for the power program is shown in Figure 9. Program dependence graphs have been used as an intermediate program representation in various contexts such as program understanding, maintenance [GL91], debugging [LW86], testing [Bin92, BH93], differencing [Hor90], specialization <ref> [RT96] </ref>, reuse [NEK94], merging [HPR88a], and vectorization and parallelization [KKL + 81]. They have the advantage that they make both flow and control dependences explicit in their structure, leading to efficient algorithms for tracing the relationships between program components.
Reference: [RWZ88] <author> B. K. Rosen, M.N. Wegman, and F.K. Zadeck. </author> <title> Global value numbers and redundant computations. </title> <booktitle> In Conference Record of the Fifteenth ACM Symposium on Principles of Programming Languages, </booktitle> <address> (San Diego, CA, </address> <month> January 13-15, </month> <year> 1988), 1988. </year>
Reference-contexts: These gate vertices are similar to the gate nodes in the SSA form of an imperative program <ref> [AWZ88, RWZ88] </ref>.
Reference: [Sch86] <author> D. Schmidt. </author> <title> Denotational Semantics. </title> <publisher> Allyn and Bacon, Inc., </publisher> <address> Boston, MA, </address> <year> 1986. </year>
Reference-contexts: As an example, the power function from Chapter 1 and its CFG are shown in Figure 6. CFGs have a standard denotational semantics in which every program statement is modeled as a state-to-state transformer <ref> [Sch86] </ref>. The state represents a snapshot of the sequential execution of the program; it consists of a program point, which represents the current point of execution in the program, and a mapping from program variables to values, representing the values currently held by program variables. <p> Sequence is the domain of value sequences described in <ref> [Sch86, pp. 252-266] </ref>, members of which are partially ordered as follows: (i) ? v s 8 s 2 Sequence (ii) s v s 8 s 2 Sequence (iii) v s 1 v v s 2 iff s 1 v s 2 8 s 1 ; s 2 2 Sequence ; v
Reference: [Sel89] <author> R. P. Selke. </author> <title> A rewriting semantics for program dependence graphs. </title> <booktitle> In Conference Record of the Sixteenth ACM Symposium on Principles of Programming Languages, </booktitle> <address> (Austin, TX, </address> <month> January 11-13, </month> <year> 1989), </year> <pages> pages 12-24, </pages> <year> 1989. </year>
Reference-contexts: The PRG is an augmented version of the PDG that has a pure data-flow semantics, which we describe in detail in Chapter 3. An alternative approach would be to use the graph rewriting semantics for PDGs defined by Selke in <ref> [Sel89] </ref>, in which computation steps are represented as graph transformations. However, the PRG semantics provide a more natural basis for characterizing static and dynamic behaviour. <p> Such a property makes it reasonable to develop a semantics for PDGs themselves. Selke has defined a graph rewriting semantics for PDGs <ref> [Sel89] </ref> that represents computation steps as graph transformations. Cartwright et al. decomposed the meaning function for a program into a function that transforms programs into "code trees" that resemble PDGs, and an interpreter for code trees that provides an operational semantics for code trees [CF89].
Reference: [Wan93] <author> M. Wand. </author> <title> Specifying the correctness of binding-time analysis. </title> <booktitle> In Twentieth ACM Symposium on Principles of Programming Languages, </booktitle> <address> Charleston, South Carolina, </address> <month> January </month> <year> 1993, </year> <pages> pages 137-143. </pages> <publisher> ACM, </publisher> <address> New York: </address> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: As mentioned earlier, the notion of congruence is an unsatisfactory correctness criteria for BTA algorithms; we have shown that the PRG semantics can be used to define suitable criteria. Wand has presented a correctness criterion for BTA-based partial evaluation of terms in the pure -calculus in <ref> [Wan93] </ref>, but it is not clear if that can be applied to specializers for imperative programs. Other authors have also tackled the termination problem, and have defined termination analyses that can be combined with congruence-based BTA to produce analyses that provide a termination guarantee for all programs [Hol91, GJ96, AH96].
Reference: [Wei84] <author> M. Weiser. </author> <title> Program slicing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-10(4):352-357, </volume> <month> July </month> <year> 1984. </year>
Reference-contexts: Finally, we critique these algorithms and point out their benefits and drawbacks when compared with other BTA algorithms. All three algorithms can be viewed operationally as variants of operations for program slicing <ref> [Wei84] </ref>, and can therefore be performed in time linear in the size of the PRG. 3.4.1 The Strong-Staticness BTA The goal of the Strong-Staticness BTA is to identify a subset of all the strongly-static vertices in the PRG of a program.
Reference: [Yan90] <author> M. Yannakakis. </author> <title> Graph-theoretic methods in database theory. </title> <booktitle> In Proceedings of the Symposium on Principles of Database Systems, </booktitle> <year> 1990, </year> <pages> pages 230-242, </pages> <year> 1990. </year>
Reference-contexts: CFL-reachability problems can be solved using a dynamic-programming algorithm. (The algorithm can be thought of as a generalization of the CYK algorithm for context-free recognition [Kas65, You67].) There is a general result that all CFL-reachability problems can be solved in time cubic in the number of vertices in the graph <ref> [Yan90] </ref>. Thus, CFL-Reachability affords higher precision than simple reachability, but at the cost of a cubic-time algorithm. In this chapter, we have reviewed the concepts that are useful in developing termination guarantees for partial evaluation. <p> by the cdr operation on state (shown by the edge from v 4 to v 5 ), the net effect is that just a single cdr is applied to vals (as indicated by the edge from v 1 to v 2 ). 2 To handle such cases, we use CFL-Reachability <ref> [Yan90, Rep95] </ref>, a generalized form of graph reachability. A CFL-Reachability problem is one in which a path is considered to connect two vertices in a graph only if the concatenation of the labels on the edges of the path is a word in a certain context-free language. <p> CFL-Reachability problems can be solved using a dynamic-programming algorithm. (The algorithm can be thought of as a generalization of the CYK algorithm for context-free recognition [Kas65, You67].) There is a general result that all CFL-Reachability problems can be solved in time cubic in the number of vertices in the graph <ref> [Yan90, MR97] </ref>. (This holds even if the context-free language is specified with an ambiguous grammar.) Because the number of vertices in the APG for a program p is bounded by O (F + P + V ar + Ops), the problem of identifying whether an L-path exists from every vertex in <p> Finally, there are no paths in possibly incr path in the APG of the program. Hence, there are no parameters in relation ISI. 2 Since CFL-Reachability problems can be solved in time cubic in the number of vertices in the graph <ref> [Yan90] </ref>, Algorithm 2 has running time O ((F + P + V ar + Ops) 3 where F is the number of functions in p, P is the number of parameters in p, V ar is the number of where variables in p, and Ops is the number of cons/car/cdr operations <p> parameter dependency graph with new nodes and new edge markings and we use CFL-Reachability rather than a closed semi-ring graph 168 algorithm [AHU74, GJ96]. * There is a general result that all "context-free language reachability problems" can be solved in time cubic in the number of vertices in the graph <ref> [Yan90] </ref>.
Reference: [YHR92] <author> W. Yang, S. Horwitz, and T. Reps. </author> <title> A program integration algorithm that accommodates semantics-preserving transformations. </title> <journal> ACM Trans. Software Engineering and Methodology, </journal> <volume> 1(3) </volume> <pages> 310-354, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: et al. defined the static single-assignment (SSA) form [AWZ88] for programs, which includes or gate statements for merging data from multiple predecessors, while Yang et al. defined the program representation graph (PRG) as an extension of the PDG with nodes similar 72 to the gate nodes in the SSA form <ref> [YHR92] </ref>. We are able to use dependence graphs to reason about program behaviour (in this case, static and dynamic behaviour) because they are faithful to the semantics of the program.

References-found: 79

