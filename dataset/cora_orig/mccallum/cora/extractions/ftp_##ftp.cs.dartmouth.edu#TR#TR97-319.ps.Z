URL: ftp://ftp.cs.dartmouth.edu/TR/TR97-319.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/reports/abstracts/TR97-319/
Root-URL: http://www.cs.dartmouth.edu
Email: fjaa,katya,rusg@cs.dartmouth.edu  
Phone: phone: (603) 646 1691 fax: (603) 646 1672  
Title: Generating, Visualizing, and Evaluating High-Quality Clusters for Information Organization  
Author: Javed Aslam Katya Pelekhov Daniela Rus 
Address: Hanover, NH 03755  
Affiliation: Department of Computer Science Dartmouth College  
Abstract: We present and analyze the star clustering algorithm. We discuss an implementation of this algorithm that supports browsing and document retrieval through information organization. We define three parameters for evaluating a clustering algorithm to measure the topic separation and topic aggregation achieved by the algorithm. In the absence of benchmarks, we present a method for randomly generating clustering data. Data from our user study shows evidence that the star algorithm is effective for organizing information. 
Abstract-found: 1
Intro-found: 1
Reference: [All95] <author> J. Allan. </author> <title> Automatic hypertext construction. </title> <type> PhD thesis. </type> <institution> Department of Computer Science, Cornell University, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: Set the star center's degree to zero and decre ment each satellite vertex's degree by one. 6. Repeat steps 4 and 5 until all nodes are marked. 7. Represent each cluster by the document corre sponding to its associated star center. mented version of the Smart system <ref> [Sal91, All95] </ref>, a user interface we have designed, and an implementation of the star and star+ algorithms on top of Smart. To index the documents we used Smart search engine with a cosine normalization weighting scheme. <p> These views provide users with summaries of the data at different levels of detail: text, document, and topic and facilitate browsing by topic structure. The connected graph view (inspired by <ref> [All95] </ref>) has nodes corresponding to the retrieved documents. The nodes are placed in a circle, with nodes corresponding to the same cluster placed together. Gaps between the nodes allow us to identify clusters easily. Edges between nodes are color coded according to the similarity between the documents.
Reference: [Cro80] <author> W. B. Croft. </author> <title> A model of cluster searching based on classification. </title> <journal> Information Systems, </journal> <volume> 5 </volume> <pages> 189-195, </pages> <year> 1980. </year>
Reference-contexts: Efforts have been made to find whether the cluster hypothesis is valid. Voorhees [Voo85] discusses a way of evaluating whether the cluster hypothesis holds and shows negative results. Croft <ref> [Cro80] </ref> describes a method for bottom-up cluster search that could be shown to outperform a full ranking system for the Cranfield collection. Willett's study [Wil88] shows that the methods he surveys do not outperform non-clustered search methods.
Reference: [Cro77] <author> W. B. Croft. </author> <title> Clustering large files of documents using the single-link method. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> pp189-195, </volume> <month> November </month> <year> 1977. </year>
Reference: [CKP93] <author> D. Cutting, D. Karger, and J. Peder-sen. </author> <title> Constant interaction-time scatter/gather browsing of very large document collections. </title> <booktitle> In Proceedings of the 16 th SIGIR, </booktitle> <year> 1993. </year> <title> the star and the augmented star algorithm. The plot denoted the precision recall curves achieved by the star+ algorithm against one of user's clusters. The horizontal lines denote the precision and recall values of the other users. </title>
Reference-contexts: Our work on clustering presented in this paper provides further evidence that clustering is good for applications where the recall is important. We also show that by trading off some of the performance of a fast system such as Scatter/Gather 1 <ref> [CKP93] </ref> with computation to ensure cluster accuracy, (that is, to guarantee a minimum similarity between all pairs of documents in a cluster) clusters can also be good for tasks where precision is important. To compute accurate clusters, we formalize clustering as covering graphs by cliques.
Reference: [HP96] <author> M. Hearst and J. Pedersen. </author> <title> Reexamining the cluster hypothesis: </title> <booktitle> Scatter/Gather on Retrieval Results. In Proceedings of the 19 th SIGIR, </booktitle> <year> 1996. </year>
Reference-contexts: Such applications typically require the algorithm to have high recall, as in the case of browsing and data reduction. Hearst and Pedersen <ref> [HP96] </ref> have already provided evidence that the clustering mechanism of Scatter/Gather is useful for high-recall tasks. Scatter/Gather uses fractionation to compute nearest-neighbour clusters. It is expected to produce clusters with loosely connected documents. Our clustering method trades-off performance for accuracy and yields tightly connected clusters. <p> Willett's study [Wil88] shows that the methods he surveys do not outperform non-clustered search methods. In [JR71] Jardine and van Rijsbergen show some evidence that search results could be improved by clustering. Hearst and Pedersen <ref> [HP96] </ref> re-examine the cluster hypothesis and conclude that it holds for tasks that require high recall, such as browsing. Our work on clustering presented in this paper provides further evidence that clustering is good for applications where the recall is important. <p> We have discussed methods for evaluating clustering and for generating benchmarks for clustering. Our user studies present positive evidence that the star clustering algorithm can be used to organize information and further support the cluster hypothesis. Our work extends previous results <ref> [HP96] </ref> that support using clustering for browsing applications. We argue that by using a clustering algorithm that guarantees the cluster quality through high separation and aggregation, clustering is also beneficial for applica 12 experiments with data generated randomly on the sphere. tions that require high precision.
Reference: [JD88] <author> A. Jain and R. Dubes. </author> <title> Algorithms for Clustering Data, </title> <publisher> Prentice Hall 1988. </publisher>
Reference-contexts: We first review related work. We then introduce our clustering algorithms. We continue by describing our implementation and visualization. Finally, we explain our performance measures and discuss experimental data. 2 Previous Work There has been extensive research on clustering and applications to many domains. For a good overview see <ref> [JD88] </ref>. For a good overview of using clustering in information retrieval see [Wil88]. The use of clustering in information retrieval was mostly driven by the cluster hypothesis [Rij79] which states that relevant documents tend to be more closely related to each other than to non-relevant documents.
Reference: [JR71] <author> N. Jardine and C.J. van Rijsbergen. </author> <title> The use of hierarchical clustering in information retrieval, </title> <booktitle> 7 </booktitle> <pages> 217-240, </pages> <year> 1971. </year>
Reference-contexts: Croft [Cro80] describes a method for bottom-up cluster search that could be shown to outperform a full ranking system for the Cranfield collection. Willett's study [Wil88] shows that the methods he surveys do not outperform non-clustered search methods. In <ref> [JR71] </ref> Jardine and van Rijsbergen show some evidence that search results could be improved by clustering. Hearst and Pedersen [HP96] re-examine the cluster hypothesis and conclude that it holds for tasks that require high recall, such as browsing.
Reference: [KP93] <author> G. Kortsarz and D. Peleg. </author> <title> On choosing a dense subgraph. </title> <booktitle> In Proceedings of the 34th Annual Symposium on Foundations of Computer Science (FOCS), </booktitle> <year> 1993. </year>
Reference-contexts: To compute accurate clusters, we formalize clustering as covering graphs by cliques. Covering by cliques is NP-complete, and thus intractable for large document collections. Recent graph-theoretic results have shown that the problem can't even be approximated in polynomial time [LY94, Zuc93]. Recent results for covering graphs by dense subgraphs <ref> [KP93] </ref> are encouraging. We used a cover by dense subgraphs that are star-shaped 2 .
Reference: [LC96] <author> A. Leouski and B. Croft. </author> <title> An evaluation of techniques for clustering search results. </title> <type> Technical report, </type> <institution> Department of Computer Science, the University of Massachusetts at Amherst, </institution> <year> 1996. </year>
Reference: [LLR95] <author> N. Linial, E. London, and Y. Rabinovich. </author> <title> The geometry of graphs and some of its algorithmic applications. </title> <type> Combinatorica 15(2) </type> <pages> 215-245, </pages> <year> 1995. </year>
Reference-contexts: This setting provides a good placement when the number of clusters returned by the algorithm is small. This algorithm is fast and its running time does not depend on the number of clusters. When the number of clusters is large, the ellipsoid-based method for Euclidean graph embeddings described in <ref> [LLR95] </ref> can be used instead. All three views and a title window allow the user to select an individual document or a cluster.
Reference: [LY94] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <journal> Journal of the ACM 41, </journal> <pages> 960-981, </pages> <year> 1994. </year>
Reference-contexts: To compute accurate clusters, we formalize clustering as covering graphs by cliques. Covering by cliques is NP-complete, and thus intractable for large document collections. Recent graph-theoretic results have shown that the problem can't even be approximated in polynomial time <ref> [LY94, Zuc93] </ref>. Recent results for covering graphs by dense subgraphs [KP93] are encouraging. We used a cover by dense subgraphs that are star-shaped 2 . <p> Each level in the hierarchy summarizes the collection at a granularity provided by the threshold. Unfortunately, this approach is computationally intractable. For real corpora, these graphs can be very large. The clique cover problem is NP-complete, and it does not admit polynomial-time approximation algorithms <ref> [LY94, Zuc93] </ref>. While we cannot perform a clique cover nor even approximate such a cover, we can instead cover our graph by dense subgraphs. What we lose in intra-cluster similarity guarantees, we gain in computational efficiency.
Reference: [Rij79] <author> C.J. van Rijsbergen. </author> <title> Information Retrieval. </title> <publisher> Butterworths, </publisher> <address> London, </address> <year> 1979. </year>
Reference-contexts: For a good overview see [JD88]. For a good overview of using clustering in information retrieval see [Wil88]. The use of clustering in information retrieval was mostly driven by the cluster hypothesis <ref> [Rij79] </ref> which states that relevant documents tend to be more closely related to each other than to non-relevant documents. Efforts have been made to find whether the cluster hypothesis is valid. Voorhees [Voo85] discusses a way of evaluating whether the cluster hypothesis holds and shows negative results.
Reference: [RA95] <author> D. Rus and J. Allan. </author> <title> Structural queries in electronic corpora. </title> <booktitle> In Proceedings of DAGS95: Electronic Publishing and the Information Superhighway, </booktitle> <month> May </month> <year> 1995. </year>
Reference: [Sal89] <author> G. Salton. </author> <title> Automatic Text Processing: the transformation, analysis, and retrieval of information by computer, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference: [Sal91] <author> G. Salton. </author> <title> The Smart document retrieval project. </title> <booktitle> In Proceedings of the Fourteenth Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 356-358. </pages>
Reference-contexts: This method conveys the topic-subtopic structure of the corpus according to the similarity measure used. Our implementation uses a modification of the Smart <ref> [Sal91] </ref> system and the underlying cosine metric. The star algorithm is accurate in that it produces dense clusters that approximate cliques with provable guarantees on the pairwise similarity between cluster documents, yet are computable in O (N 2 ), where N is the number of documents. <p> We measure the similarity between two documents by using the cosine metric in the vector space model of the Smart information retrieval system <ref> [Sal91, SM83] </ref>. G is a complete graph with edges of varying weight. <p> Set the star center's degree to zero and decre ment each satellite vertex's degree by one. 6. Repeat steps 4 and 5 until all nodes are marked. 7. Represent each cluster by the document corre sponding to its associated star center. mented version of the Smart system <ref> [Sal91, All95] </ref>, a user interface we have designed, and an implementation of the star and star+ algorithms on top of Smart. To index the documents we used Smart search engine with a cosine normalization weighting scheme.
Reference: [SM83] <author> G. Salton and M. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: We measure the similarity between two documents by using the cosine metric in the vector space model of the Smart information retrieval system <ref> [Sal91, SM83] </ref>. G is a complete graph with edges of varying weight.
Reference: [SA93] <author> G. Salton and J. Allan. </author> <title> Selective text utilization and text traversal. </title> <booktitle> In Hypertext '93 Proceedings, </booktitle> <pages> pages 131-144, </pages> <address> Seattle, Washington, </address> <year> 1993. </year>
Reference: [SJJ70] <author> K. Spark Jones and D. Jackson. </author> <title> The use of automatically-obtained keyword classifications for information retrieval. </title> <journal> Inform. Stor. Retr. </journal> <volume> 5 </volume> <pages> 174-201, </pages> <year> 1970. </year>
Reference-contexts: For our star-algorithm, an alternative is to return an en 1 Scatter/Gather uses fractionation to compute nearest-neighbor clusters. 2 In <ref> [SJJ70] </ref> stars were also identified to be potentially useful for clustering. tire cluster only when a top-ranked document is the center of a star. We are currently collecting data for this application. 4 Our clustering method In this section we motivate and present two algorithms for organizing information systems.
Reference: [Tur90] <author> H. </author> <title> Turtle. Inference networks for document retrieval. </title> <type> PhD thesis. </type> <institution> University of Mas-sachusetts, Amherst, </institution> <year> 1990. </year>
Reference: [VGJ95] <author> E. Voorhees, N. Gupta, and B. Johnson-Laird. </author> <title> Learning collection fusion strategies. </title> <booktitle> In Proceedings of the 18 th SIGIR, </booktitle> <address> Seattle, WA, </address> <year> 1995. </year>
Reference: [Voo85] <author> E. Voorhees. </author> <title> The cluster hypothesis revisited. </title> <booktitle> In Proceedings of the 8 th SIGIR, </booktitle> <pages> pp 95-104, </pages> <year> 1985. </year>
Reference-contexts: The use of clustering in information retrieval was mostly driven by the cluster hypothesis [Rij79] which states that relevant documents tend to be more closely related to each other than to non-relevant documents. Efforts have been made to find whether the cluster hypothesis is valid. Voorhees <ref> [Voo85] </ref> discusses a way of evaluating whether the cluster hypothesis holds and shows negative results. Croft [Cro80] describes a method for bottom-up cluster search that could be shown to outperform a full ranking system for the Cranfield collection.
Reference: [Wil88] <author> P. Willett. </author> <title> Recent trends in hierarchical document clustering: A critical review. </title> <booktitle> Information Processing and Management, </booktitle> <address> 24:(5):577-597, </address> <year> 1988. </year>
Reference-contexts: Finally, we explain our performance measures and discuss experimental data. 2 Previous Work There has been extensive research on clustering and applications to many domains. For a good overview see [JD88]. For a good overview of using clustering in information retrieval see <ref> [Wil88] </ref>. The use of clustering in information retrieval was mostly driven by the cluster hypothesis [Rij79] which states that relevant documents tend to be more closely related to each other than to non-relevant documents. Efforts have been made to find whether the cluster hypothesis is valid. <p> Voorhees [Voo85] discusses a way of evaluating whether the cluster hypothesis holds and shows negative results. Croft [Cro80] describes a method for bottom-up cluster search that could be shown to outperform a full ranking system for the Cranfield collection. Willett's study <ref> [Wil88] </ref> shows that the methods he surveys do not outperform non-clustered search methods. In [JR71] Jardine and van Rijsbergen show some evidence that search results could be improved by clustering.
Reference: [Wor71] <author> S. Worona. </author> <title> Query clustering in a large document space. </title> <editor> In Ed. G. Salton, </editor> <booktitle> The SMART Retrieval System, </booktitle> <pages> pp 298-310. </pages> <publisher> Prentice-Hall, </publisher> <year> 1971. </year>

References-found: 23

