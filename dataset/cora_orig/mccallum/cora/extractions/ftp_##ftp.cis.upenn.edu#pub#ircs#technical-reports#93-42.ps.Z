URL: ftp://ftp.cis.upenn.edu/pub/ircs/technical-reports/93-42.ps.Z
Refering-URL: http://www.umiacs.umd.edu/users/resnik/pubs.html
Root-URL: 
Title: P  Selection and Information: A Class Based Approach to Lexical Relationships  
Author: N Philip Stuart Resnik 
Degree: (Ph.D. Dissertation) by  
Note: Founded by Benjamin Franklin in 1740 The Institute For Research In Cognitive Science  December 1993 Site of the NSF Science and Technology Center for Research in Cognitive Science  
Affiliation: University of Pennsylvania  
Abstract: IRCS Report 93-42 University of Pennsylvania 3401 Walnut Street, Suite 400C Philadelphia, PA 19104-6228 
Abstract-found: 1
Intro-found: 1
Reference: <author> AHD. </author> <year> 1991. </year> <title> American Heritage Dictionary. </title> <publisher> Houghton Mifflin. </publisher>
Reference-contexts: A number of these issues arise in Chapter 3. 16 In general, of course, some provision must be made for multi-word lexical items. That complication is ignored here. 25 concept BOARD in its sense as a long, flat slab of sawed lumber <ref> (AHD, 1991) </ref>, with synonym set ff 2 ; f n g being fboard ; plank g. Miller et al. (1990, p. 4) comment: These synonym sets (synsets) do not explain what the concepts are; they merely signify that the concepts exist. <p> Table 2.4 shows a breakdown into categories for 49 nouns randomly chosen from the set of nouns in the Brown Corpus that do not appear in the WordNet taxonomy. The reference dictionary for the not in dictionary category was <ref> (AHD, 1991) </ref>, and the one acronym on the list, USP, derives from the United States Pharmacopoeia reference standard. Of the hyphenated terms, just one, vice-president, appears in WordNet as a compound.
Reference: <author> Adrian Akmajian and Frank Heny. </author> <year> 1975. </year> <title> An introduction to the principles of transformational syntax. </title> <publisher> MIT Press. </publisher>
Reference: <author> Robert B. Allen. </author> <year> 1990. </year> <title> Connectionist language users. </title> <journal> Connection Science, </journal> <volume> 2(4) </volume> <pages> 279-311. </pages>
Reference: <author> Hiyan Alshawi. </author> <year> 1987. </year> <title> Processing dictionary definitions with phrasal pattern hierarchies. </title> <note> Computational Linguistics, 13(3-4):195-202. </note>
Reference: <author> Gerry Altmann and Mark Steedman. </author> <year> 1988. </year> <title> Interaction with context during human sentence processing. </title> <journal> Cognition, </journal> <volume> 30 </volume> <pages> 191-238. </pages>
Reference: <author> S. Armstrong, L. Gleitman, and H. Gleitman. </author> <year> 1983. </year> <title> What some concepts might not be. </title> <journal> Cognition, </journal> <volume> 13 </volume> <pages> 263-308. </pages>
Reference: <author> D. Ayuso, G. Donlon, D. MacLaughlin, L. Ramshaw, P. Resnik, V. Shaked, and R. Weischedel. </author> <year> 1989. </year> <title> A guide to IRUS-II application development. </title> <type> BBN Report 7144, </type> <institution> Bolt, Beranek and Newman. </institution>
Reference-contexts: There are several issues in particular that are worth mentioning. * Coverage. In order to perform corpus-based analyses, adequate coverage of the corpus vocabulary is necessary. Traditional knowledge-based forms of deep lexical-conceptual knowledge for example, the domain models in natural language systems like BBN's IRUS <ref> (Ayuso et al., 1989) </ref> will require a great deal of effort if they are to scale up to large quantities of text, unless the domain is highly constrained. <p> Similarly, several of the natural language interfaces developed at BBN (e.g. see <ref> (Ayuso et al., 1989) </ref>) have used variants of the KL-ONE formalism to taxonomically represent world knowledge, implementing selectional constraints using that formalism's notion of role restrictions (Woods and Schmolze, 1991).
Reference: <author> Lalit R. Bahl, Peter F. Brown, Peter V. de Souza, and Robert L. Mercer. </author> <year> 1989. </year> <title> A tree-based statistical language model for natural language speech recognition. </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> 37 </volume> <pages> 1001-1008, </pages> <month> July. </month>
Reference: <author> L.R. Bahl, F. Jelinek, and R.L. Mercer. </author> <year> 1983. </year> <title> A maximum likelihood approach to continuous speech recognition. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, PAMI-5:179-190. Yehoshuah Bar-Hillel. </journal> <year> 1964. </year> <title> Language and Information. </title> <publisher> Addison-Wesley. </publisher>
Reference: <author> Roberto Basili, Maria Teresa Pazienza, and Paola Velardi. </author> <year> 1991. </year> <title> Combining NLP and statistical techniques for lexical acquisition. </title> <booktitle> In Proceedings of the AAAI Fall Symposium on Probabilistic Approaches to Natural Language, </booktitle> <address> Cambridge, Massachusetts, </address> <month> October. </month>
Reference: <author> Roberto Basili, Teresa Pazienza, and Paola Velardi. </author> <year> 1992. </year> <title> Computational lexicons: the neat examples and the odd exemplars. </title> <booktitle> In Third Conference on Applied Natural Language Processing, </booktitle> <pages> pages 96-103. </pages> <institution> Association for Computational Linguistics, </institution> <month> March. </month>
Reference: <author> Richard Beckwith, Christiane Fellbaum, Derek Gross, and George Miller. </author> <year> 1991. </year> <title> WordNet: A lexical database organized on psycholinguistic principles. In Uri Zernik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, </title> <address> pages 211-232. </address> <publisher> Erlbaum. </publisher>
Reference: <author> Peter A. Bensch and Walter J. Savitch. </author> <year> 1992. </year> <title> An occurrence-based model of word categorization. </title> <booktitle> Presented at 3rd Meeting on Mathematics of Language (MOL3), </booktitle> <month> November. </month>
Reference: <author> L. Boggess, R. Agarwal, and R. Davis. </author> <year> 1991. </year> <title> Disambiguation of prepositional phrases in automatically labeled technical texts. </title> <booktitle> In Proceedings of AAAI-91. </booktitle>
Reference: <author> Julie Boland, Michael Tanenhaus, Greg Carlson, and Susan Garnsey. </author> <year> 1989. </year> <title> Lexical projection and the interaction of syntax and semantics in parsing. </title> <journal> Journal of Psycholinguistic Research, </journal> <volume> 18(6) </volume> <pages> 563-575. </pages> <note> 147 Lisa Braden-Harder and Wlodek Zadrozny. </note> <year> 1991. </year> <title> Lexicons for broad coverage semantics. In Uri Zernik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, </title> <address> pages 369-388. </address> <publisher> Erlbaum. </publisher>
Reference: <author> L. Breiman, J. Friedman, R. Olshen, and C. Stone. </author> <year> 1984. </year> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks. </publisher>
Reference-contexts: Because the training data are partitioned at each branching point, by the time a leaf is reached the class it represents may be too small to support statistically reliable predictions. Accordingly, many decision tree construction algorithms prune paths below a certain point (e.g., <ref> (Breiman et al., 1984) </ref>), increasing the size of the classes represented by the leaves of the tree. Bahl et al. take a different approach: they apply interpolated estimation, using estimators based on the equivalence class represented at each node.
Reference: <author> Eric Brill, D. Magerman, M. Marcus, and B. Santorini. </author> <year> 1990. </year> <title> Deducing linguistic structure from the statistics of large corpora. </title> <booktitle> In DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 275-282. </pages>
Reference: <author> Eric Brill. </author> <year> 1991. </year> <title> Discovering the lexical features of a language. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Berkeley, CA. </address>
Reference: <author> Paula Brown and Gary Dell. </author> <year> 1987. </year> <title> Adapting production to comprehension: the explicit mention of instruments. </title> <journal> Cognitive Psychology, </journal> <volume> 19 </volume> <pages> 441-472. </pages>
Reference: <author> Peter F. Brown, Vincent J. Della Pietra, Peter V. deSouza, and Robert L. Mercer. </author> <year> 1990. </year> <title> Class-based n-gram models of natural language. </title> <booktitle> In Proceedings of the IBM Natural Language ITL, </booktitle> <pages> pages 283-298, </pages> <address> Paris, France, </address> <month> March. </month>
Reference: <author> Peter F. Brown, Vincent J. Della Pietra, Peter V. deSouza, Jennifer C. Lai, and Robert L. Mercer. </author> <year> 1992. </year> <title> Class-based n-gram models of natural language. </title> <journal> Computational Linguistics, </journal> <volume> 18(4) </volume> <pages> 467-480, </pages> <month> December. </month>
Reference: <author> Wayles Browne. </author> <year> 1971. </year> <title> Verbs and Unspecified NP Deletion. </title> <journal> Linguistic Inquiry, </journal> <volume> 2 </volume> <pages> 259-260. </pages>
Reference: <author> M. G. Bulmer. </author> <year> 1967. </year> <title> Principles of Statistics. </title> <publisher> Dover Publications. </publisher>
Reference-contexts: On this account, the features or properties that govern selectional constraints remain entirely hidden. Selectional relationships are characterized entirely by the 13 There is a long history of debate concerning the inductive (or logical) view of probability as distinguished from empirical probability. The first chapter of <ref> (Bulmer, 1967) </ref> contains one extremely brief but useful introduction to the distinction. See also (Bar-Hillel, 1964, chapters 15 and 16) for discussion specifically with regard to information theory. 14 I will only be considering predicates corresponding to surface syntactic relationships, but this is easily generalized.
Reference: <author> Roy Byrd, Nicoletta Calzolari, Martin Chodorow, Judith Klavans, and Mary Neff. </author> <year> 1987. </year> <title> Tools and methods for computational linguistics. </title> <note> Computational Linguistics, 13(3-4):219-240. </note>
Reference: <author> Greg Carlson and Michael Tanenhaus. </author> <year> 1988. </year> <title> Thematic roles and language comprehension. </title> <editor> In W. Wilkins, editor, </editor> <booktitle> Thematic Relations, volume 21 of Syntax and Semantics, </booktitle> <pages> pages 263-288. </pages> <publisher> Academic Press. </publisher>
Reference: <author> Jing-Shin Chang, Yih-Fen Luo, and Keh-Yih Su. </author> <year> 1992. </year> <title> GPSM: A generalized probabilistic semantic model for ambiguity resolution. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 177-184. </pages> <booktitle> ACL, </booktitle> <month> June. </month>
Reference: <author> Noam Chomsky. </author> <year> 1957. </year> <title> Syntactic Structures. Mouton, The Hague. </title>
Reference: <author> Noam Chomsky. </author> <year> 1965. </year> <title> Aspects of the Theory of Syntax. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Kenneth Church and William Gale. </author> <month> 19xx. </month> <title> Enhanced Good-Turing and Cat-Cal: Two new methods for estimating probabilities of English bigrams. </title> <address> ms. </address>
Reference: <author> K. Church and P. Hanks. </author> <year> 1989. </year> <title> Word association norms, mutual information, and lexicography. </title> <booktitle> In Proceedings of the 27th Meeting of the Association for Computational Linguistics. </booktitle> <address> Vancouver, B.C. </address>
Reference-contexts: To take a few examples, (Smadja, 1991) uses lexical association measures to extract collocation information from large corpora for use in language generation, <ref> (Church and Hanks, 1989) </ref> propose the use of mutual information to estimate word association norms on the basis of lexical co-occurrence, and (Yarowsky, 1993) shows that local word co-occurrences provide reliable cues for sense disambiguation. (See (Church et al., 1991) for a useful overview of statistical techniques for lexical analysis.) Lexical <p> Perhaps the simplest interpretation of context is string co-occurrence: one word is said to appear in the context of another if the two words are adjacent, or, more generally, if the context word appears within some fixed distance to the left or right. <ref> (Church and Hanks, 1989) </ref> observe that this form of context may help lexicographers identify useful semantic classes: they suggest that by ranking the words occurring to the right of a word (in their example, the verb save) by mutual information, useful patterns may emerge.
Reference: <author> Kenneth Church and Robert Mercer. </author> <year> 1993. </year> <title> Introduction to the special issue on computational linguistics using large corpora. </title> <journal> Computational Linguistics, </journal> <volume> 19(1) </volume> <pages> 1-24. </pages>
Reference: <author> Kenneth W. Church and Ramesh Patil. </author> <year> 1982. </year> <title> Coping with syntactic ambiguity or how to put the block in the box on the table. </title> <journal> American Journal of Computational Linguistics, </journal> <note> 8(3-4):139-149. </note> <author> 148 K. Church, W. Gale, P. Hanks., and D.M. Hindle. </author> <year> 1990. </year> <title> Using statistics in lexical analysis. In Uri Zernik, editor, Lexical Acquisition: Using On-line Resources to Build a Lexicon. </title> <publisher> Lawrence Erlbaum. </publisher>
Reference: <author> Kenneth Church, William Gale, Patrick Hanks, and Donald Hindle. </author> <year> 1991. </year> <title> Using statistics in lexical analysis. In Uri Zernik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, </title> <address> pages 116-164. </address> <publisher> Erlbaum. </publisher>
Reference: <author> Sharon Cote. </author> <year> 1992. </year> <title> Discourse functions of two types of null objects in English. </title> <booktitle> Presented at the 66th Annual Meeting of the Linguistic Society of America, </booktitle> <address> Philadelphia, PA, </address> <month> January. </month>
Reference: <author> Thomas M. Cover and Joy A. Thomas. </author> <year> 1991. </year> <title> Elements of Information Theory. </title> <publisher> John Wiley. </publisher>
Reference-contexts: Let us consider them in turn. 1 Being symmetrical, it also measures how much information X provides about Y . See <ref> (Cover and Thomas, 1991) </ref> for a clear discussion of mutual information and related topics. 8 score verb object 12.34 drink bunch (of) beer 11.75 drink tea 11.75 drink Pepsi 11.75 drink champagne 10.53 drink liquid 10.20 drink beer 9.34 drink wine 7.65 drink water 5.15 drink anything 2.54 drink much 1.25 <p> Since the logarithm is conventionally taken to the base 2, the standard unit of information is the bit, short for binary digit. (I will not elaborate on the reasoning behind the particular mathematical form in (3.1); see (Khinchin, 1957, pages 9-12) for a nice exposition of this point and <ref> (Cover and Thomas, 1991) </ref> for a very readable introduction to information theory as a whole.) Relative entropy is an information-theoretic measure of how two probability distributions differ, which is precisely the question under consideration here. <p> And this is, in fact, the case: an important theorem of information theory is that D (p k q) is always greater than or equal to zero, and equal to zero if and only if p = q <ref> (Cover and Thomas, 1991, p. 26) </ref>. <p> Judgements of prepositional phrase attachment are made using a measure that Basili et al. call conditioned mutual information: I (X=prep; C) = freq (X; prep; C) freq (prep; C)freq (prep; X) : (5.10) (A comparison of this score with the standard information-theoretic definition of conditional mutual information <ref> (Cover and Thomas, 1991, p. 22) </ref> makes it clear that = freq (prep), which is constant for any given disambiguation decision.) Intuitively, the score measures the association of the attachment site X and the class C, given that they are related by prep.
Reference: <author> S. Crain and M. Steedman. </author> <year> 1985. </year> <title> On not being led up the garden path: the use of context by the psychological syntax processor. </title> <editor> In D. Dowty, L. Karttunen, and A. Zwicky, editors, </editor> <booktitle> Natural Language Processing: Psychological, Computational, and Theoretical Perspectives. </booktitle> <publisher> Cambridge University Press. </publisher>
Reference: <author> D. A. Cruse. </author> <year> 1986. </year> <title> Lexical Semantics. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Also see discussion of taxonomies and further references in Chapter 6 of <ref> (Cruse, 1986) </ref>; in particular, Cruse makes a distinction between hyponymy and taxonymy, the latter being a sub-species of the former. A number of these issues arise in Chapter 3. 16 In general, of course, some provision must be made for multi-word lexical items. <p> Naturally there are some unclear cases (e.g. sheep will unconditionally be labelled singular), but in general the simple suffix mappings, together with WordNet's large vocabulary and exceptions list, yield excellent results. Similarity of Meaning Many factors influence judgements of semantic similarity between two nouns; see, for example, <ref> (Cruse, 1986, Chapter 12) </ref> for an extensive discussion of considerations entering into judgements of synonymy. In addition, as discussed in Chapter 2, a great many researchers are investigating techniques for deriving measures of word similarity on the basis of distributional behavior.
Reference: <author> Ido Dagan and Alon Itai. </author> <title> (to appear). Word sense disambiguation using a second language monolingual corpus. </title> <note> To appear in Computational Linguistics. </note>
Reference: <author> I. Dagan. </author> <year> 1990. </year> <title> A statistical filter for resolving pronoun references. </title> <booktitle> In Proceedings of the 7th Israeli Symposium on Artificial Intelligence and Computer Vision. </booktitle>
Reference-contexts: The problem is compounded in cases where the classes themselves are not discrete. Pereira et al. (1993), describing some results of their hierarchical clustering, present the nouns that are closest to the centroid of 8 A quote from <ref> (Dagan, 1990) </ref> seems fairly representative of the prevailing attitude toward computational time among researchers pursuing statistical approaches: Although the construction of the full size database [of co-occurrence statistics] is not feasible for us, it is clearly feasible for a large scale project.
Reference: <author> K. Dahlgren and J. McDowell. </author> <year> 1986. </year> <title> Using commonsense knowledge to disambiguate prepositional phrase modifiers. </title> <booktitle> In AAAI-86, </booktitle> <pages> pages 589-593. </pages>
Reference: <author> Scott Deerwester, Susan Dumais, Goerge Furnas, Thomas Landauer, and Richard Harshman. </author> <year> 1990. </year> <title> Indexing by latent semantic analysis. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(6) </volume> <pages> 391-407. </pages>
Reference: <author> D. Dowty, R. Wall, and S. Peters. </author> <year> 1981. </year> <title> Introduction to Montague Semantics. </title> <address> D. </address> <publisher> Reidel Publishing Co., </publisher> <address> Boston. </address>
Reference-contexts: distinction between semantic and conceptual structure too seriously; Jackendoff's IS-INCLUDED-IN relation seems like it may also be a reasonable basis for hyponymy. 15 It may ultimately be necessary to sort out the semantic issues here a bit more clearly, distinguishing implication, entailment, presupposition, and conventional implicature (see, e.g., discussion in <ref> (Dowty, Wall, and Peters, 1981) </ref>). Also see discussion of taxonomies and further references in Chapter 6 of (Cruse, 1986); in particular, Cruse makes a distinction between hyponymy and taxonymy, the latter being a sub-species of the former. <p> Third, the semantic type of the object can involve truth conditions, or it can involve an entity or entities. (Roughly speaking, these correspond to the types t and e, respectively, found in model-theoretic semantics see, e.g., <ref> (Dowty, Wall, and Peters, 1981) </ref>.) Arguments involving truth conditions may be interrogative (118), exclamatory (119), or propositional (120) (Grimshaw, 1979): (118) a. I wonder how fast Bill can run. b. I wonder. (119) a. I know how very fast Bill can run. b. I know. (120) a.
Reference: <author> David Dowty. </author> <year> 1991. </year> <title> Thematic proto-roles and argument selection. </title> <booktitle> Language, </booktitle> <volume> 67(3) </volume> <pages> 547-615. </pages>
Reference: <author> Theodore Drange. </author> <year> 1966. </year> <title> Type Crossings: Sentential Meaningless in the Border Area of Linguistics and Philosophy. </title> <publisher> Mouton. </publisher>
Reference: <author> Jeffrey Elman. </author> <year> 1989. </year> <title> Representation and structure in connectionist models. </title> <type> Technical Report CRL TR-8903, </type> <institution> University of California, </institution> <address> San Diego. </address>
Reference: <author> Jeffrey Elman. </author> <year> 1990. </year> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14 </volume> <pages> 179-211. </pages>
Reference: <author> U. Essen and V. Steinbiss. </author> <year> 1992. </year> <title> Cooccurrence smoothing for stochastic language modeling. </title> <booktitle> In ICASSP-92, </booktitle> <address> pages I-161 - I-164, San Francisco. </address>
Reference-contexts: Interpolated estimation is one way to combine predictions made on the basis of different equivalence classes. (Grishman and Sterling, 1993), investigating the automated acquisition of selectional constraints, apply co-occurrence smoothing <ref> (Essen and Steinbiss, 1992) </ref>, a technique in which prediction information for distinct words is combined on the basis of their distributional similarity.
Reference: <author> Christiane Fellbaum and Judy Kegl. </author> <year> 1989. </year> <title> Taxonomic structures and cross-category linking in the lexicon. </title> <booktitle> In Proceedings of ESCOL '89, </booktitle> <pages> pages 93-104. </pages> <address> Evelyn Ferstl. </address> <year> 1993. </year> <title> The role of lexical information and discourse context in syntactic processing: a review of psycholinguistic studies. </title> <type> Technical Report 93-03, </type> <institution> University of Colorado at Boulder. </institution> <address> 149 Charles Fillmore. </address> <year> 1986. </year> <title> Pragmatically controlled zero anaphora. </title> <booktitle> In Proceedings of the Berkeley Linguistics Society, </booktitle> <pages> pages 95-107. </pages>
Reference: <author> Cynthia Fisher, Geoffrey Hall, Susan Rakowitz, and Lila Gleitman. </author> <year> 1994. </year> <title> When it is better to receive than to give: syntactic and conceptual constraints on vocabulary growth. </title> <type> Lingua, 92(1). </type>
Reference: <author> Cynthia Fisher, Lila Gleitman, and Henry Gleitman. </author> <year> 1991. </year> <title> On the semantic content of subcategorization frames. </title> <journal> Cognitive Psychology, </journal> <volume> 23(3) </volume> <pages> 331-392, </pages> <month> July. </month>
Reference: <author> J. A. Fodor, M. F. Garrett, E. T. Walker, and C. Parkes. </author> <year> 1980. </year> <title> Against definitions. </title> <journal> Cognition, </journal> <volume> 8(3) </volume> <pages> 1-105. </pages>
Reference: <author> Janet Dean Fodor. </author> <year> 1977. </year> <title> Semantics: theories of meaning in generative grammar. </title> <publisher> Harvard University Press. </publisher>
Reference: <author> Marilyn Ford, Joan Bresnan, and Ronald Kaplan. </author> <year> 1982. </year> <title> A competence-based theory of syntactic closure. In Joan Bresnan, editor, The Mental Representation of Grammatical Relations. </title> <publisher> MIT Press. </publisher>
Reference: <author> W. Francis and H. Kucera. </author> <year> 1982. </year> <title> Frequency Analysis of English Usage. </title> <publisher> Houghton Mifflin Co.: </publisher> <address> New York. </address>
Reference-contexts: This can lead some lexical relationships to go unnoticed. For example, the Brown Corpus of American English <ref> (Francis and Kucera, 1982) </ref> has the attractive (and for some tasks, necessary) property of providing a sample that is balanced across many genres. <p> In the work I will describe here, estimates of verb-object co-occurrence probability were arrived at by constructing a large combined sample from the following sources: 1. Associated Press (AP) news stories (1989) 2. The Brown corpus <ref> (Francis and Kucera, 1982) </ref>, specifically the parsed version of the corpus appearing in the Penn Treebank (Marcus, Santorini, and Marcinkiewicz, 1993) 3. The Wall Street Journal (1988-89), which can also be found in parsed form in the Penn Treebank. 4. <p> As a second assumption, the verb-object samples used in the experiment are taken to be representative of actual usage. In order to ensure that this is the case, the corpora used were as balanced as possible. One experiment used the Brown Corpus <ref> (Francis and Kucera, 1982) </ref>, which, though smaller than some of the text corpora now available (about a million words, total), is the largest readily available sample of English text explicitly designed to be balanced across genres.
Reference: <author> L. Frazier. </author> <year> 1979. </year> <title> On Comprehending Sentences: Syntactic Parsing Strategies. </title> <type> Ph.D. thesis, </type> <institution> University of Massachusetts. </institution>
Reference-contexts: Among the most frequently cited are right association (Kimball, 1973), a preference for constituents to attach to the lowest node to the right in the partial parse tree, and minimal attachment <ref> (Frazier, 1979) </ref>, a preference for choosing the attachment that would result in a parse tree with the fewest nodes. Crucially, such strategies depend only on configurations within parse trees, and not on extra-syntactic factors or even the identity of the lexical items involved. * Referential strategies.
Reference: <author> William Gale, Kenneth Church, and David Yarowsky. </author> <year> 1992a. </year> <title> A method for disambiguating word senses in a large corpus. Statistical Research Reports 104, </title> <institution> AT&T Bell Laboratories, </institution> <month> March. </month> <note> (To appear in Computers and Humanities). </note>
Reference: <author> William Gale, Kenneth Church, and David Yarowsky. </author> <year> 1992b. </year> <title> One sense per discourse. </title> <booktitle> Proceedings of the 4th DARPA Speech and Natural Language Workshop, </booktitle> <month> February. </month>
Reference: <author> G. Gazdar, E. Klein, G. Pullum, and I. Sag. </author> <year> 1985. </year> <title> Generalized Phrase Structure Grammar. </title> <publisher> Harvard University Press. </publisher>
Reference-contexts: and Heny, 1975, p. 56ff)), these are the verbs whose subcategorization frames specify an optional NP direct object: (104) +V # In descriptions based purely on phrase structure, these are verbs having both a transitive and an intransitive expansion, as is the case for sing in the following fragment from <ref> (Gazdar et al., 1985, p. 110) </ref>: (105) a. VP ! H [1] b. die, eat, sing, run, : : : c. runs (106) a.
Reference: <author> Jane Gillette and Lila Gleitman. </author> <title> forthcoming. Effects of situational cues on the identification of nouns and verbs. </title> <address> ms. </address>
Reference: <author> Lila Gleitman, Henry Gleitman, Barbara Landau, and Eric Wanner. </author> <year> 1988. </year> <title> Where learning begins: initial representations for language learning. In Linguistics: The Cambridge Survey, Volume III: Language: Psychological and Biological Aspects. </title> <publisher> Cambridge University Press. </publisher>
Reference: <author> I.J. Good. </author> <year> 1953. </year> <title> The population frequencies of species and the estimation of population parameters. </title> <journal> Biometrika, </journal> <volume> 40(3 and </volume> 4):237-264. 
Reference-contexts: I am convinced that the behavior of this model is not particularly sensitive to the estimation technique used, at least at a general level, since in earlier versions of this work I computed probabilities using the Good-Turing estimate <ref> (Good, 1953) </ref> and obtained entirely comparable results. (See Appendix A.) The selectional relationship I have explored most thoroughly is the one that holds between verbs and their direct objects. <p> In the section that follows, I work through a simple example to illustrate how frequency and probability estimates are done now. A.2 Good-Turing Estimates Together with the frequency estimate in (A.1), in earlier experiments I used the Good-Turing (GT) estimator of probabilities <ref> (Good, 1953) </ref>. The GT estimate is calculated by organizing observations in the sample according to frequency, so that bin n r represents the number of items that were observed exactly r times; for example, n 2 is the number of items that were observed exactly twice.
Reference: <author> G. Grefenstette. </author> <year> 1992. </year> <title> Finding semantic similarity in raw text: </title> <booktitle> the Deese antonyms. In Fall Symposium on Probability and Natural Language. AAAI, </booktitle> <month> October 23-25. </month>
Reference: <author> H.P. Grice. </author> <year> 1975. </year> <title> Logic and conversation. </title> <editor> In P. Cole and J. Morgan, editors, </editor> <booktitle> Syntax and Semantics III Speech Acts, </booktitle> <pages> pages 41-58. </pages> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: Conventional implicatures are distinguished from conversational implicatures in that in the former case the conventional meaning of the words, as opposed to general conversational principles, will determine what is implicated <ref> (Grice, 1975, p. 66) </ref>. Karttunen and Peters focus on cases like the following: (26) a. John managed to solve the problem. b. John didn't manage to solve the problem. (27) It was difficult for John to solve the problem. (28) John solved the problem. <p> Ah! Therefore, when he goes to Boston, John drives a car. c. No he drives a van. The confusion arises, I think, because it is odd to use the label for a superordinate category in contexts like (156) a fact that arises more from conversational principles <ref> (Grice, 1975) </ref> than from inconsistency with the expectations of the verb. (For example, saying John drank a beverage, implies that there is some reason for being less informative than is customary about what he drank.) What is important is not that the words smoking materials be natural in (156a), but rather
Reference: <author> Jane Grimshaw. </author> <year> 1979. </year> <title> Complement selection and the lexicon. </title> <journal> Linguistic Inquiry, </journal> <volume> 10(2) </volume> <pages> 279-326. </pages>
Reference: <author> Jane Grimshaw. </author> <year> 1990. </year> <title> Argument Structure. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. 150 Jane Grimshaw. </address> <year> 1993. </year> <title> The least lexicon. </title> <booktitle> Colloquium of the Institute for Research in Cognitive Science, </booktitle> <institution> University of Pennsylvania. </institution>
Reference: <author> Ralph Grishman and John Sterling. </author> <year> 1992. </year> <title> Acquisition of selectional patterns. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Computational Linguistics (COLING '92), </booktitle> <pages> pages 658-664, </pages> <address> Nantes, France, </address> <month> July. </month>
Reference: <author> Ralph Grishman and John Sterling. </author> <year> 1993. </year> <title> Smoothing of automatically generated selectional constraints. </title> <editor> In Madeleine Bates, editor, </editor> <booktitle> ARPA Workshop on Human Language Technology, </booktitle> <month> March. </month>
Reference: <author> Jess Gropen. </author> <year> 1992. </year> <title> Constraints on a theory of verb learning: insights from polysemy. </title> <booktitle> Presented at the 17th Boston University Conference on Language Development. </booktitle>
Reference: <author> Jess Gropen. </author> <year> 1993. </year> <title> Participant types and the acquisition of verb polysemy. </title> <address> ms., </address> <month> May. </month>
Reference: <author> Stephen Jos e Hanson. </author> <year> 1990. </year> <title> Conceptual clustering and categorization: bridging the gap between induction and causal models. </title> <editor> In Yves Kodratoff and Ryszard S. Michalski, editors, </editor> <booktitle> Machine learning : an artificial intelligence approach, </booktitle> <volume> volume 3, </volume> <pages> pages 235-268. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Marti A. Hearst and Kenneth W. Church. </author> <title> (in preparation). An investigation of the use of lexical associations for prepositional phrase attachment. </title>
Reference: <author> Marti Hearst and Hinrich Sch utze. </author> <year> 1993. </year> <title> Customizing a lexicon to better suit a computational task. </title> <booktitle> In Proceedings of the ACL SIGLEX Workshop, </booktitle> <address> Columbus, Ohio, </address> <month> June. </month>
Reference: <author> D. Hindle and M. Rooth. </author> <year> 1991. </year> <title> Structural ambiguity and lexical relations. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> June. Berkeley, California. </address>
Reference-contexts: Given an instance of ambiguous prepositional phrase attachment from the test set, Hindle and Rooth used a statistical test to assess the direction and significance of the difference between p (pjn1) and p (pjv), a procedure they call lexical association. In <ref> (Hindle and Rooth, 1991) </ref> they used the t-score (Church et al., 1991) as their test, and in (Hindle and Rooth, 1993) they shifted to a log likelihood ratio. <p> On a set of test sentences held out from the training data, the lexical association procedure used in <ref> (Hindle and Rooth, 1991) </ref> (t-score) made the correct attachment 78.3% of the time. For choices with a high level of 116 confidence (magnitude of t greater than 2.1, about 70% of the time), correct attachments were made 84.5% of the time. <p> might call such a proposal conceptual association: calculating a measure of association using the classes to which the direct object and object of the preposition belong, and selecting the attachment site for which the evidence of association is strongest. 9 I attempted this experiment using expected likelihood estimates, as in <ref> (Hindle and Rooth, 1991) </ref>, with data extracted from the Penn Treebank as described below. 117 a.
Reference: <author> D. Hindle and M. Rooth. </author> <year> 1993. </year> <title> Structural ambiguity and lexical relations. </title> <journal> Computational Linguistics, </journal> <volume> 19(1) </volume> <pages> 103-120, </pages> <month> June. </month>
Reference-contexts: In (Hindle and Rooth, 1991) they used the t-score (Church et al., 1991) as their test, and in <ref> (Hindle and Rooth, 1993) </ref> they shifted to a log likelihood ratio. <p> For choices with a high level of 116 confidence (magnitude of t greater than 2.1, about 70% of the time), correct attachments were made 84.5% of the time. Using the log likelihood ratio in <ref> (Hindle and Rooth, 1993) </ref>, they obtained a correct decision 79.7% of the time; for high confidence choices (log likelihood ratio greater than 2.0) they obtained 88.7% accuracy at 70.6% coverage. 5.4.2 Prepositional objects The lexical association strategy performs quite well, despite the fact that the object of the preposition is ignored. <p> Although it is difficult to make comparisons between experiments using different sets of training and test data, it is worth noting that the performance of lexical association in this experiment is comparable with the recent results reported in <ref> (Hindle and Rooth, 1993) </ref> in particular, they report 92.3% accuracy with 54.3% of the test cases covered. On their precision-recall curve, their coverage at 88.7% accuracy is 70.6%. <p> This is something that it is difficult to imagine ascertaining automatically (though see (Basili, Pazienza, and Velardi, 1991; Velardi, 1991) for some discussion of partially automating the process). To echo the quote from <ref> (Hindle and Rooth, 1993) </ref> at the beginning of Section 5.4, if deeper semantic relationships of this kind are necessary in general, then it is hard to see how computational models are going to be able to solve this problem in unrestricted text any time soon.
Reference: <author> Donald Hindle. </author> <year> 1983. </year> <title> User manual for Fidditch, a deterministic parser. </title> <type> Technical memorandum 7590-142, </type> <institution> Naval Research Laboratory. </institution>
Reference: <author> D. Hindle. </author> <year> 1990. </year> <title> Noun classification from predicate-argument structures. </title> <booktitle> In Proceedings of the 28th Annual Meeting of the Assocation of Computational Linguistics, Pittsburgh, Penna., </booktitle> <pages> pages 268-275. </pages>
Reference-contexts: In the next section I illustrate these points by looking at one application of lexical association a proposal by <ref> (Hindle, 1990) </ref> to use mutual information in capturing predicate-argument relationships. In the sections that follow, I discuss the extension of lexical relationships to class-based relationships, and consider the advantages and disadvantages of constructing word classes on the basis of lexical distributions in corpora. <p> Table 2.1 shows the verb-object pairs for the verb drink that occurred more than once, ranked by co-occurrence score, in effect giving the answer to the question `what can you drink?' <ref> (Hindle, 1990, p. 270) </ref>. <p> Given a syntactic analysis, however, it is possible to define word contexts using relationships that are more constrained and linguistically well motivated. For example, <ref> (Hindle, 1990) </ref> proposes a method for classifying nouns on the basis of the verbs for which they appear as arguments, as determined using a robust parser.
Reference: <author> V. M. Holmes, L. Stowe, and L. Cupples. </author> <year> 1989. </year> <title> Lexical expectations in parsing complement-verb sentences. </title> <journal> Journal of Memory and Language, </journal> <volume> 28 </volume> <pages> 668-689. </pages>
Reference-contexts: These effects are demonstrated using stimuli like the following, taken from <ref> (Holmes, Stowe, and Cupples, 1989) </ref>: 69 (89) a. The secretary read the article was already out of date. b. The secretary read the fashion was already out of date. (90) a. The scientist showed the sample was necessary for her project to succeed. b. <p> In this section I will explore the first of these issues, namely the evaluation of the model against human ratings; I consider the second in more detail toward the end of Chapter 4. As a first step, I investigated the behavior of the implemented model using data from <ref> (Holmes, Stowe, and Cupples, 1989, Appendix 2) </ref> concerning verbs that have a bias in favor of taking NP complements. These consisted of sixteen pairs of sentences, three of which I have shown in examples (89)-(91). <p> As a second test, I used the data on clausal-bias verbs from <ref> (Holmes, Stowe, and Cupples, 1989) </ref> that is, verbs that prefer a clausal rather than an NP complement.
Reference: <author> Paul Hopper and Sandra Thompson. </author> <year> 1980. </year> <title> Transitivity in grammar and discourse. </title> <booktitle> Language, </booktitle> <address> 56(2):251 299. </address>
Reference: <author> Laurence Horn. </author> <year> 1989. </year> <title> A Natural History of Negation. </title> <publisher> University of Chicago Press. </publisher>
Reference: <author> Ray Jackendoff. </author> <year> 1983. </year> <title> Semantics and Cognition. </title> <booktitle> Current Studies in Linguistics Series. </booktitle> <publisher> The MIT Press. </publisher>
Reference: <author> Ray Jackendoff. </author> <year> 1990. </year> <title> Semantic Structures. </title> <booktitle> Current Studies in Linguistics Series. </booktitle> <publisher> The MIT Press. </publisher>
Reference: <author> Anil K. Jain and Richard C. Dubes. </author> <year> 1988. </year> <title> Algorithms for Clustering Data. </title> <publisher> Prentice Hall. </publisher> <editor> 151 Frederick Jelinek and Robert L. Mercer. </editor> <year> 1980. </year> <title> Interpolated estimation of Markov source parameters from sparse data. </title> <booktitle> In Proceedings of the Workshop on Pattern Recognition in Practice, </booktitle> <address> Amsterdam, The Netherlands: </address> <publisher> North-Holland, </publisher> <month> May. </month>
Reference: <author> Karen Jensen and Jean-Louis Binot. </author> <year> 1987. </year> <title> Disambiguating prepositional phrase attachments by using on-line dictionary definitions. </title> <journal> Computational Linguistics, </journal> <volume> 13(3) </volume> <pages> 251-260. </pages>
Reference: <author> P. N. Johnson-Laird. </author> <year> 1983. </year> <title> Mental models : towards a cognitive science of language, inference, and consciousness. </title> <publisher> Harvard University Press. </publisher>
Reference: <author> Michael I. Jordan. </author> <year> 1986. </year> <title> Serial order: A parallel distributed processing approach. </title> <type> Technical Report ICS-8604, </type> <institution> Institute for Cognitive Science, University of California at San Diego, La Jolla, </institution> <address> CA. </address>
Reference: <author> P. Jusczyk, K. Hirsh-Pasek, D. Kemler Nelson, L. Kennedy, A. Woodward, and J. Piwoz. </author> <year> 1992. </year> <title> Perception of acoustic correlates of major phrasal units by young infants. </title> <journal> Cognitive Psychology, </journal> <volume> 24 </volume> <pages> 252-293. </pages>
Reference: <author> Hans Kamp and Barbara Partee. </author> <title> in progress. Prototype theory and compositionality. </title> <address> ms. </address>
Reference: <author> Shyam Kapur. </author> <year> 1992. </year> <title> Computational Learning of Languages. </title> <type> Ph.D. thesis, </type> <institution> Cornell University. </institution> <note> Also appears as Cornell CS Technical Report 91-1234, </note> <month> September </month> <year> 1991. </year>
Reference: <author> Lauri Karttunen and Stanley Peters. </author> <year> 1979. </year> <title> Conventional implicature. Syntax and Semantics, </title> <type> 11. </type>
Reference: <author> Dieter Kastovsky. </author> <year> 1980. </year> <title> Selectional restrictions and lexical solidarities. </title> <editor> In Dieter Kastovsky, editor, </editor> <booktitle> Perspektiven der lexikalischen Semantik, </booktitle> <pages> pages 70-92. </pages> <address> Bonn: </address> <publisher> Bouvier Verlag Herbert Grundmann. </publisher>
Reference: <author> J. J. Katz and J. A. Fodor. </author> <year> 1964. </year> <title> The structure of a semantic theory. </title> <editor> In J. A. Fodor and J. J. Katz, editors, </editor> <booktitle> The Structure of Language, chapter 19, </booktitle> <pages> pages 479-518. </pages> <publisher> Prentice Hall. </publisher>
Reference-contexts: First, however, I will briefly review the treatment of category mistakes in generative linguistic theory. 3.3 Selection Restrictions 3.3.1 Selection restrictions as lexical features The phenomena discussed in the previous section appeared in the guise of selection restrictions in <ref> (Katz and Fodor, 1964) </ref>. Katz and Fodor proposed a decompositional theory of word meaning in which lexical entries specified the features applicable to a particular lexical item. <p> and Trueswell (1993) report the mean typicality rating for each of their test items, and I hope to use these data in future work. 3.8 Other Computational Approaches Many computational approaches to selectional constraints have appeared in a form that is more or less similar to the view proposed in <ref> (Katz and Fodor, 1964) </ref>: in implemented systems, something analogous to Boolean applicability conditions is often associated with each argument of a predicate. 26 For example, Schank (1986, p. 172) describes using simple world knowledge rules tied to conceptual rules, so that the conceptual rule that actors can act would be modified <p> An alternative, suggested to me by David Magerman, would be to construct a hidden model in which observed predicate-word co-occurrences provide the data for re-estimation of predicate-class probabilities using the EM algorithm. The relationship between selectional constraints and lexical disambiguation has been in evidence at least since <ref> (Katz and Fodor, 1964) </ref>, and the behavior of the implemented model suggests that selectional association in many cases provides strong evidence for a particular sense.
Reference: <author> J. J. Katz. </author> <year> 1970. </year> <title> Interpretative semantics vs. generative semantics. </title> <booktitle> Foundations of Language, </booktitle> <volume> 6 </volume> <pages> 220-259. </pages>
Reference: <author> Slava M. Katz. </author> <year> 1987. </year> <title> Estimation of probabilities from sparse data for the language model component of a speech recognizer. </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> ASSP-35(3):400-401, </volume> <month> March. </month>
Reference: <author> D. Kemler Nelson, K. Hirsh-Pasek, P. Jusczyk, and K. Cassidy. </author> <year> 1989. </year> <title> How the prosodic cues in motherese might assist language learning. </title> <journal> Journal of Child Language, </journal> <volume> 16 </volume> <pages> 55-68. </pages>
Reference: <author> D. Kemler Nelson. </author> <year> 1989. </year> <title> Developmental trends in infants' sensitivity to prosodic cues correlated with linguistic units. </title> <booktitle> Presented at the biennial meeting of the Society for Research in Child Development, </booktitle> <address> Kansas City, </address> <month> April. </month> <type> manuscript. </type>
Reference: <author> A. I. Khinchin. </author> <year> 1957. </year> <booktitle> Mathematical Foundations of Information Theory. </booktitle> <address> New York: </address> <publisher> Dover Publications. </publisher>
Reference-contexts: Since the logarithm is conventionally taken to the base 2, the standard unit of information is the bit, short for binary digit. (I will not elaborate on the reasoning behind the particular mathematical form in (3.1); see <ref> (Khinchin, 1957, pages 9-12) </ref> for a nice exposition of this point and (Cover and Thomas, 1991) for a very readable introduction to information theory as a whole.) Relative entropy is an information-theoretic measure of how two probability distributions differ, which is precisely the question under consideration here.
Reference: <author> Translated by R. A. Silverman and M. D. </author> <note> Friedman. </note>
Reference: <author> John Kimball. </author> <year> 1973. </year> <title> Seven principles of surface structure parsing in natural language. </title> <journal> Cognition, </journal> <volume> 2 </volume> <pages> 15-47. </pages>
Reference: <author> Kevin Knight. </author> <year> 1993. </year> <title> Building a large ontology for machine translation. </title> <editor> In Madeleine Bates, editor, </editor> <booktitle> ARPA Workshop on Human Language Technology, </booktitle> <month> March. </month>
Reference: <author> S. Kullback and R. A. Leibler. </author> <year> 1951. </year> <title> On information and sufficiency. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 22 </volume> <pages> 79-86. </pages> <note> 152 S. </note> <author> Kurohashi and M. Nagao. </author> <year> 1992. </year> <title> Dynamic programming method for analyzing conjunctive structures in Japanese. </title> <booktitle> In Proceedings of COLING-92, </booktitle> <address> Nantes, France, </address> <month> August. </month>
Reference: <author> Barbara Landau and Lila Gleitman. </author> <year> 1985. </year> <title> Language and Experience. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Anne Lederer and Michael Kelly. </author> <year> 1991. </year> <title> Prosodic correlates to the adjunct/complement distinction in motherese. Papers and Reports in Child Language Development, </title> <type> 30. </type>
Reference: <author> Anne Lederer, Henry Gleitman, and Lila Gleitman. </author> <title> forthcoming. The syntactic contexts of maternal verb use. </title> <address> ms. </address>
Reference: <author> Anne Lederer. </author> <year> 1993. </year> <type> Title? Ph.D. thesis, </type> <institution> University of Pennsylvania. </institution>
Reference: <author> Adrienne Lehrer. </author> <year> 1970. </year> <title> Verbs and deletable objects. </title> <journal> Lingua, </journal> <volume> 25 </volume> <pages> 227-254. </pages>
Reference: <author> D. Lenat, M. Prakash, and M. Shepherd. </author> <year> 1986. </year> <title> CYC: using common sense knowledge to overcome brittleness and knowledge acquisition bottlenecks. </title> <journal> AI Magazine, VI:65-85. </journal>
Reference-contexts: However, they explicitly commit themselves to constrained domains, rather than the world in general, distinguishing themselves from broad-coverage knowledge acquisition endeavors such as CYC <ref> (Lenat, Prakash, and Shepherd, 1986) </ref>. 24 Word Word Forms Meanings f 1 f 2 f 3 : : : f n m 1 fi . . .
Reference: <author> Beth Levin. </author> <year> 1989. </year> <title> Towards a lexical organization of English verbs. </title> <type> Technical report, </type> <institution> Dept. of Linguistics, Northwestern University, </institution> <month> November. </month>
Reference: <author> J. Lyons. </author> <year> 1961. </year> <title> A structural theory of semantics and its application to lexical sub-systems in the vocabulary of Plato. </title> <type> Ph.D. thesis, </type> <institution> University of Cambridge, </institution> <address> England. </address> <booktitle> Published as Structural Semantics, No. 20 of the Publications of the Philological Society, </booktitle> <address> Oxford, </address> <year> 1963. </year>
Reference-contexts: We would be constructing an encyclopedia, which is not what we want; and we could, moreover, never finish it (either medically or logically). One definition of hyponymy that Sparck Jones considers is from <ref> (Lyons, 1961) </ref>, where the lexical relationship is defined in terms of implication between sentences. <p> Again, it should be noted that the notion of entailment that is operative here is concerned not with logical necessity, but with implication in the sense used by <ref> (Lyons, 1961) </ref> that is, entailed properties consist in conclusions that one would be willing to draw. <p> Although an IS-A taxonomy can be interpreted in many different ways, recall that I grounded the formalization in a relationship that might be called plausible entailment: following <ref> (Lyons, 1961) </ref>, the entailment relation is based on the ordinary judgements of the language user, such that one sentence implies another if in saying the one we are prepared to say the other (Sparck Jones, 1964, p. 54).
Reference: <author> Maryellen MacDonald. </author> <title> in press. The interaction of lexical and syntactic ambiguity. Journal of Memory and Language. </title>
Reference: <author> Maryellen MacDonald. </author> <title> in revision. Probabilistic constraints and syntactic ambiguity resolution. </title> <address> ms. </address>
Reference: <author> Brian MacWhinney and Catherine Snow. </author> <year> 1985. </year> <title> The Child Language Data Exchange System. Journal of Child Language, </title> <type> 12. </type>
Reference: <author> Brian MacWhinney. </author> <year> 1991. </year> <title> The CHILDES project : tools for analyzing talk. </title> <publisher> Erlbaum. </publisher>
Reference: <author> David Magerman. </author> <year> 1993. </year> <title> Parsing as statistical pattern recognition. </title> <address> ms., </address> <month> May. </month>
Reference: <author> Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. </author> <year> 1993. </year> <title> Building a large annotated corpus of English: the Penn Treebank. </title> <journal> Computational Linguistics, </journal> <volume> 19 </volume> <pages> 313-330. </pages>
Reference: <author> Mitchell Marcus. </author> <year> 1980. </year> <title> A Theory of Syntactic Recognition for Natural Language. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Gail Mauner, Michael Tanenhaus, and Greg Carlson. </author> <year> 1992. </year> <title> Getting something for nothing: implicit arguments in sentence processing. </title> <address> ms. </address>
Reference: <author> James McCawley. </author> <year> 1968. </year> <title> The role of semantics in a grammar. </title> <editor> In Emmon Bach and Robert Harms, editors, </editor> <booktitle> Universals in Linguistic Theory, </booktitle> <pages> pages 124-169. </pages> <publisher> Holt, Rinehart and Winston. </publisher>
Reference: <author> James D. McCawley. </author> <year> 1971. </year> <title> Interpretative semantics meets Frankenstein. </title> <booktitle> Foundations of Language, </booktitle> <volume> 7 </volume> <pages> 285-296. </pages> <note> 153 Kathleen McKeown and Vasileios Hatzivassiloglou. </note> <year> 1993. </year> <title> Augmenting lexicons automatically: Clustering semantically related adjectives. </title> <editor> In Madeleine Bates, editor, </editor> <booktitle> ARPA Workshop on Human Language Technology, </booktitle> <month> March. </month>
Reference: <author> Ken McRae, Virginia de Sa, and Mark S. Seidenberg. </author> <year> 1992. </year> <title> The role of correlated properties in accessing conceptual memory. </title> <note> Submitted to Cognitive Psychology. </note>
Reference: <author> George A. Miller and Walter G. Charles. </author> <year> 1991. </year> <title> Contextual correlates of semantic similarity. </title> <booktitle> Language and Cognitive Processes, </booktitle> <volume> 6(1) </volume> <pages> 1-28. </pages>
Reference: <author> George Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine Miller. </author> <year> 1990. </year> <title> Five papers on WordNet. </title> <type> CSL Report 43, </type> <institution> Cognitive Science Laboratory, Princeton University, </institution> <month> July. </month>
Reference: <author> George A. Miller. </author> <year> 1971. </year> <title> Empirical methods in the study of semantics. </title> <editor> In D. Steinberg and L. Jakobovits, editors, </editor> <title> Semantics, an interdisciplinary reader in philosophy, </title> <booktitle> linguistics, and psychology, </booktitle> <pages> pages 569-585. </pages> <publisher> Cambridge University Press. </publisher>
Reference: <author> George Miller. </author> <year> 1990a. </year> <title> Nouns in WordNet: A lexical inheritance system, July. </title> <type> CSL Report 43, </type> <institution> Princeton University. </institution> <note> Also appears in International Journal of Lexicography, 3(4), </note> <year> 1990. </year>
Reference: <author> George Miller. </author> <year> 1990b. </year> <title> Wordnet: An on-line lexical database. </title> <journal> International Journal of Lexicography, </journal> <note> 3(4). (Special Issue). </note>
Reference: <author> Roy C. Milton. </author> <year> 1964. </year> <title> An extended table of critical values for the Mann-Whitney (Wilcoxon) two-sample statistic. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 59 </volume> <pages> 925-934. </pages>
Reference: <author> A. Mittwoch. </author> <year> 1971. </year> <title> Idioms and Unspecified NP Deletion. </title> <journal> Linguistic Inquiry, </journal> <volume> 2 </volume> <pages> 255-259. </pages>
Reference-contexts: What was John doing? b. John was drinking his coffee. c. It took John ten minutes to drink his coffee, d. and he drank it without interruption. Furthermore, Mittwoch (1971; 1982) argues that verbs with omitted indefinite objects are interpreted as activities. In <ref> (Mittwoch, 1971) </ref> she shows that when drink appears without a specified object, or with an object of indefinite quantity, as in drank beer, the VP must be interpreted as describing an event that has not necessarily been completed. (149) a. John drank (beer). b. *John drank up (beer). c.
Reference: <author> A. Mittwoch. </author> <year> 1982. </year> <title> On the difference between eating and eating something: activities versus accomplish ments. </title> <journal> Linguistic Inquiry, </journal> <volume> 13(1) </volume> <pages> 113-122. </pages>
Reference: <author> J. Morris and G. Hirst. </author> <year> 1991. </year> <title> Lexical cohesion computed by thesaural relations as an indicator of the structure of text. </title> <journal> Computational Linguistics, </journal> <volume> 17(1) </volume> <pages> 21-48. </pages>
Reference-contexts: Counting other kinds of taxonomic links can be even more problematic; for example, <ref> (Morris and Hirst, 1991) </ref> point out that unbridled transitivity leads to spurious relatedness judgements through chains like fcow,sheep,wool,scarf,boots,hat,snowg. 108 Class c log 1 p (c) hcoin,3566679i 13.51 hcoin,3566477i 12.52 hcash,3566144i 12.45 hcurrency,3565780i 11.69 hmoney,3565439 i 11.27 htender,3562119i 11.27 hmedium of exchange,3561702i 11.21 hasset,3552852 i 9.71 hpossession,11572i 8.17 Table 5.2: Superclasses for
Reference: <author> K. Nelson. </author> <year> 1973. </year> <title> Structure and strategy in learning to talk. </title> <booktitle> Monographs of the Society for Research in Child Development, </booktitle> <pages> 38(1-2). </pages> <note> Serial no. 149. </note>
Reference-contexts: A first point in favor of such an approach is the relatively small number of assumptions that are required, and the psychological plausibility of those that are indispensible. To begin with the taxonomy, it is generally agreed that noun acquisition precedes verb acquisition <ref> (Nelson, 1973) </ref>, and there is evidence to suggest that observation provides reliable evidence for learning how to map noun forms to noun concepts (Gillette and Gleitman, forthcoming).
Reference: <author> Sergei Nirenburg and Victor Raskin. </author> <year> 1987. </year> <title> The subworld concept lexicon and the lexicon management system. </title> <note> Computational Linguistics, 13(3-4):276-289. </note>
Reference: <author> D. N. Osherson and E. E. Smith. </author> <year> 1981. </year> <title> On the adequacy of prototype theory as a theory of concepts. </title> <journal> Cognition, </journal> <volume> 9 </volume> <pages> 35-58. </pages>
Reference-contexts: Furthermore, in contrast to one of the main advantages of definitional theories, adopting a theory of prototypes makes difficult (Armstrong et al.: altogether hopeless) a compositional account of phrase and sentence meanings <ref> (Osherson and Smith, 1981) </ref>. 8 A review of the literature here would constitute too much of a side-trip, unfortunately; for a start see (Fodor et al., 1980; Smith and Medin, 1981; Armstrong, Gleitman, and Gleitman, 1983; Smith and Osherson, 1988),.
Reference: <author> Patrick Paroubek, Yves Schabes, and Aravind K. Joshi. </author> <year> 1992. </year> <title> XTAG a graphical workbench for developing tree-adjoining grammars. </title> <booktitle> In Third Conference on Applied Natural Language Processing, </booktitle> <address> Trento, Italy. </address>
Reference: <author> Neil Pearlmutter and Maryellen MacDonald. </author> <year> 1993. </year> <title> Plausibility and syntactic ambiguity resolution. </title> <booktitle> In Proceedings of the 14th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 498-503, </pages> <address> Hillsdale, NJ. </address> <publisher> Erlbaum. </publisher> <editor> 154 Fernando Pereira, Naftali Tishby, and Lillian Lee. </editor> <year> 1993. </year> <title> Distributional clustering of English words. </title> <booktitle> In Proceedings of ACL-93, </booktitle> <month> June. </month>
Reference: <author> David Pesetsky. </author> <year> 1982. </year> <title> Paths and Categories. </title> <type> Ph.D. thesis, </type> <institution> Massachusetts Institute of Technology. </institution>
Reference: <author> Steven Pinker. </author> <year> 1989. </year> <title> Learnability and Cognition. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> W.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling. </author> <year> 1988. </year> <title> Numerical Recipes in C. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: As an example, consider the case where = w 1 ; : : : ; w k1 , 3 See discussion and references in <ref> (Press et al., 1988) </ref>. 11 ' 1 () = w k2 ; w k1 Here, the first estimator uses two previous words of context, and the second estimator uses just one word of context.
Reference: <author> James Pustejovsky. </author> <year> 1991. </year> <title> The generative lexicon. </title> <journal> Computational Linguistics, </journal> <volume> 17(4). </volume>
Reference: <author> J. R. Quinlan. </author> <year> 1990. </year> <title> Induction of decision trees. </title> <editor> In Jude W. Shavlik and Thomas G. Dietterich, editors, </editor> <booktitle> Readings in Machine Learning. </booktitle> <address> Morgan Kaufmann. </address> <note> Originally published in Machine Learning 1 81-106, </note> <year> 1986. </year>
Reference-contexts: There are many ways to construct decision tree classifiers, the most common of which is to start with the full set of training data at the root, and to proceed top down, recursively partitioning nodes according to the partition that optimizes some measure such as information gain <ref> (Quinlan, 1990) </ref>. In (Bahl et al., 1989) the best partition and hence the choice of equivalence classes created at this branch is chosen by minimizing the average conditional entropy H (W k jc i ) over the equivalence classes fc i g in the partition.
Reference: <author> Philip Resnik and Marti Hearst. </author> <year> 1993. </year> <title> Syntactic ambiguity and conceptual relations. </title> <editor> In Kenneth Church, editor, </editor> <booktitle> Proceedings of the ACL Workshop on Very Large Corpora, </booktitle> <pages> pages 58-64, </pages> <month> June. </month>
Reference: <author> Philip Resnik. </author> <year> 1991. </year> <title> An investigation of lexical class acquisition using a recurrent neural network. </title> <address> ms., </address> <month> December. </month>
Reference: <author> Philip Resnik. </author> <year> 1992a. </year> <title> A class-based approach to lexical discovery. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Newark, Delaware, </address> <month> June. </month> <note> (Student session). </note>
Reference: <author> Philip Resnik. </author> <year> 1992b. </year> <title> Probabilistic tree-adjoining grammar as a framework for statistical natural language processing. </title> <booktitle> In Proceedings of the Fourteenth International Conference on Computational Linguistics (COLING '92), </booktitle> <address> Nantes, France, </address> <month> July. </month>
Reference: <author> Philip Resnik. </author> <year> 1992c. </year> <title> WordNet and distributional analysis: A class-based approach to lexical discovery. </title> <booktitle> In AAAI Workshop on Statistically-based NLP Techniques, </booktitle> <address> San Jose, California, </address> <month> July. </month>
Reference: <author> Philip Resnik. </author> <year> 1993. </year> <title> Semantic classes and syntactic ambiguity. </title> <booktitle> ARPA Workshop on Human Language Technology, </booktitle> <address> March. Princeton. </address>
Reference: <author> Sally Rice. </author> <year> 1988. </year> <title> Unlikely lexical entries. </title> <booktitle> In Proceedings of the Berkeley Linguistics Society, </booktitle> <pages> pages 202-212. </pages>
Reference: <author> Matthew Rispoli. </author> <year> 1992. </year> <title> Discourse and the acquisition of eat. Journal of Child Language. </title>
Reference: <author> Luigi Rizzi. </author> <year> 1986. </year> <title> Null objects in Italian and the theory of pro. </title> <journal> Linguistic Inquiry, </journal> <volume> 17(3) </volume> <pages> 501-557, </pages> <month> Summer. </month>
Reference: <author> Thomas Roeper. </author> <year> 1987. </year> <title> Implicit arguments and the head complement relation. Linguistic Inquiry. </title>
Reference: <author> Eleanor Rosch, Carolyn Mervis, Wayne Gray, David Johnson, and Penny Boyes-Braem. </author> <year> 1976. </year> <title> Basic objects in natural categories. </title> <journal> Cognitive Psychology, </journal> <volume> 8 </volume> <pages> 382-439. </pages>
Reference: <author> Roger Schank. </author> <year> 1986. </year> <title> Language and memory. </title> <editor> In B. Grosz, K. Sparck Jones, and B. Webber, editors, </editor> <booktitle> Readings in Natural Language Processing, </booktitle> <pages> pages 171-192. </pages> <publisher> Morgan Kaufmann. Originally appeared in Cognitive Science 4(3), </publisher> <pages> pp. 243-284, </pages> <year> 1980. </year>
Reference: <author> Hinrich Sch utze. </author> <year> 1993. </year> <title> Part-of-speech induction from scratch. </title> <note> In ACL-93. 155 Hinrich Sch utze. (to appear). </note> <editor> Word space. In S. J. Hanson, J. D. Cowan, and C. L. Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <address> San Mateo CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> R. W. Schvaneveldt, F. T. Durso, and D. W. Dearholt. </author> <year> 1989. </year> <title> Network structures in proximity data. </title> <editor> In G. Bower, editor, </editor> <booktitle> The psychology of learning and motivation: advances in research and theory, </booktitle> <volume> volume 24, </volume> <pages> pages 249-284. </pages> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: on the Tanimoto coefficient, Bensch and Savitch create a clustering by first creating a fully connected graph of the words in the vocabulary, with proximities on the arcs, and then constructing the minimum spanning tree for the graph. (In this respect the technique is a specialization of the Pathfinder algorithm <ref> (Schvaneveldt, Durso, and Dearholt, 1989) </ref>, which also begins with a fully connected graph and produces a network structure.
Reference: <author> Satoshi Sekine, Sofia Ananiadou, Jeremy Carroll, and Jun'ichi Tsujii. </author> <year> 1992. </year> <title> Linguistic knowledge generator. </title> <booktitle> In Proceedings of COLING-92, </booktitle> <pages> pages 560-566, </pages> <address> Nantes, France, </address> <month> August. </month>
Reference: <author> Claude E. Shannon and Warren Weaver. </author> <year> 1949. </year> <title> The Mathematical Theory of Communication. </title> <publisher> University of Illinois Press. </publisher>
Reference: <author> John Sinclair (ed.). </author> <year> 1987. </year> <title> Collins COBUILD English Language Dictionary. </title> <address> Collins: London. </address>
Reference: <author> Jeffrey Mark Siskind. </author> <year> 1992. </year> <title> Naive Physics, Event Perception, Lexical Semantics, and Language Acquisition. </title> <type> Ph.D. thesis, </type> <institution> MIT. </institution>
Reference: <author> Jeffrey Mark Siskind. </author> <year> 1993a. </year> <title> Lexical acquisition as constraint satisfaction. </title> <address> ms. </address>
Reference: <author> Jeffrey Mark Siskind. </author> <year> 1993b. </year> <title> Solving a lexical acquisition task via an encoding as a propositional satisfia bility problem. </title> <booktitle> Poster at the 6th Annual CUNY Sentence Processing Conference, </booktitle> <month> March. </month>
Reference: <author> Frank Smadja. </author> <year> 1991. </year> <title> Macrocoding the lexicon with co-occurrence knowledge. In Uri Zernik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon. </title> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> E. E. Smith and D. L. Medin. </author> <year> 1981. </year> <title> Categories and Concepts. </title> <publisher> Harvard University Press. </publisher>
Reference-contexts: Furthermore, in contrast to one of the main advantages of definitional theories, adopting a theory of prototypes makes difficult (Armstrong et al.: altogether hopeless) a compositional account of phrase and sentence meanings <ref> (Osherson and Smith, 1981) </ref>. 8 A review of the literature here would constitute too much of a side-trip, unfortunately; for a start see (Fodor et al., 1980; Smith and Medin, 1981; Armstrong, Gleitman, and Gleitman, 1983; Smith and Osherson, 1988),.
Reference: <author> Edward Smith and Daniel Osherson. </author> <year> 1988. </year> <title> Compositionality and typicality. </title> <editor> In S. Schiffer and S. Steele, editors, </editor> <booktitle> Cognition and Representation, chapter 3, </booktitle> <pages> pages 37-52. </pages> <address> Boulder, Colorado: </address> <publisher> Westview Press. </publisher>
Reference: <author> Paul Smolensky, Geraldine Legendre, and Yoshiro Miyata. </author> <year> 1992. </year> <title> Principles for an integrated connection ist/symbolic theory of higher cognition. </title> <type> Report CU-CS-600-92, </type> <institution> Computer Science Dept., Univ. of Colorado at Boulder, </institution> <month> July. </month>
Reference: <author> Paul Smolensky. </author> <year> 1988. </year> <title> On the proper treatment of connectionism. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 11 </volume> <pages> 1-74. </pages>
Reference: <author> Padhraic Smyth and Rodney Goodman. </author> <year> 1992. </year> <title> An information theoretic approach to rule induction from databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 4(4) </volume> <pages> 301-316, </pages> <month> August. </month>
Reference: <author> Jeffrey L. Sokolov and Catherine E. Snow, </author> <title> editors. (to appear). Handbook of Research in Language Development using CHILDES. </title> <publisher> Erlbaum Associates. </publisher>
Reference: <author> Karen Sparck Jones. </author> <year> 1964. </year> <title> Synonymy and Semantic Classification. </title> <type> Ph.D. thesis, </type> <institution> University of Cambridge, </institution> <address> England. </address> <note> Published in the Edinburgh Information Technology Series (EDITS), </note> <editor> Sidney Michaelson and Yorick Wilks (eds.), </editor> <publisher> Edinburgh University Press: Edinburgh, </publisher> <address> Scotland, </address> <year> 1986. </year>
Reference: <author> Patrizia Tabossi, Michael Spivey-Knowlton, Ken McRae, and Michael Tanenhaus. </author> <title> (in press). Semantic effects on syntactic ambiguity resolution: evidence for a constraint-based resolution process. Attention and Performance, XV. </title> <note> 156 Michael Tanenhaus, </note> <author> Susan Garnsey, and Julie Boland. </author> <year> 1991. </year> <title> Combinatory lexical information and language comprehension. </title> <editor> In G. Altmann, editor, </editor> <booktitle> Cognitive Models of Speech Processing: Psycholinguistic and Computational Perspectives, </booktitle> <pages> pages 383-408. </pages> <publisher> MIT Press. </publisher>
Reference: <author> A. M. Treisman. </author> <year> 1965. </year> <title> Verbal responses and contextual constraints in language. </title> <journal> Journal of Verbal Learning and Verbal Behavior, </journal> <volume> 4 </volume> <pages> 118-128. </pages> <note> Reprinted in Oldfield, </note> <editor> R. and Marshall, J., eds., </editor> <booktitle> Language, </booktitle> <publisher> Penguin, </publisher> <year> 1968. </year>
Reference: <author> John Trueswell, Michael Tanenhaus, and Susan Garnsey. </author> <year> 1993. </year> <title> Evidence for the immedate use of local semantic constraints in syntactic ambiguity resolution. </title> <booktitle> Presented at the 6th Annual CUNY Sentence Processing Conference, </booktitle> <month> March. </month>
Reference: <author> John Trueswell. </author> <year> 1993. </year> <title> The Use of Verb-Based Subcategorization and Thematic Role Information in Sentence Processing. </title> <type> Ph.D. thesis, </type> <institution> University of Rochester. </institution>
Reference: <author> B. van Fraasen. </author> <year> 1968. </year> <title> Presuppositions, implications, and self-reference. </title> <journal> Journal of Philosophy, </journal> <volume> 65:136 152. </volume>
Reference: <author> Joh van Rooij and Reinier Plomp. </author> <year> 1991. </year> <title> The effect of linguistic entropy on speech perception in noise in young and elderly listeners. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 90(6) </volume> <pages> 2985-2991, </pages> <month> December. </month>
Reference: <author> Paola Velardi, Maria Teresa Pazienza, and Michela Fasolo. </author> <year> 1991. </year> <title> How to encode semantic knowledge: a method for meaning representation and computer-aided acquisition. </title> <journal> Computational Linguistics, </journal> <volume> 17(2) </volume> <pages> 153-170. </pages>
Reference: <author> Paola Velardi. </author> <year> 1991. </year> <title> Acquiring a semantic lexicon for natural language processing. In Uri Zernik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, </title> <address> pages 341-368. </address> <publisher> Erlbaum. </publisher> <address> Zeno Vendler, </address> <year> 1967. </year> <journal> Verbs and Times, </journal> <pages> pages 97-121. </pages> <publisher> Cornell University Press. </publisher>
Reference: <author> James Waldo. </author> <year> 1979. </year> <title> A PTQ semantics for sortal incorrectness. In Linguistics, Philosophy, and Montague Grammar. </title> <institution> University of Texas Press. </institution>
Reference: <author> Ralph Weischedel, Marie Meteer, Richard Schwartz, and Jeff Palmucci. </author> <year> 1989. </year> <title> Coping with ambiguity and unknown words through probabilistic models. </title> <address> ms. </address>
Reference: <author> Ralph Weischedel, Damaris Ayuso, R. Bobrow, Sean Boisen, Robert Ingria, and Jeff Palmucci. </author> <year> 1991. </year> <title> Partial parsing: a report of work in progress. </title> <booktitle> In Proceedings of the Fourth DARPA Speech and Natural Language Workshop, </booktitle> <month> February </month> <year> 1991. </year>
Reference: <author> Ralph Weischedel. </author> <year> 1986. </year> <title> A new semantic computation while parsing: presupposition and entailment. </title> <editor> In B. Grosz, K. Sparck Jones, and B. Webber, editors, </editor> <booktitle> Readings in Natural Language Processing, </booktitle> <pages> pages 313-326. </pages> <publisher> Morgan Kaufmann. </publisher> <editor> Originally appeared in C. Oh and D. Dineen, eds., </editor> <title> Syntax and Semantics II: </title> <booktitle> Presupposition and Entailment, </booktitle> <pages> pp. 155-182, </pages> <publisher> Academic Press, </publisher> <year> 1979. </year>
Reference: <author> Sholom M. Weiss and Casimir A. Kulikowski. </author> <year> 1991. </year> <title> Computer systems that learn: classification and pre diction methods from statistics, neural nets, machine learning, and expert systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address> <note> 157 Greg Whittemore, </note> <author> Kathleen Ferrara, and Hans Brunner. </author> <year> 1990. </year> <title> Empirical study of predictive powers of simple attachment schemes for post-modifier prepositional phrases. </title> <booktitle> In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 23-30. </pages> <address> Pittsburgh, Pennsylvania. </address>
Reference: <author> Yorick Wilks and Dan Fass. </author> <year> 1992. </year> <title> The preference semantics family. Computers & Mathematics with Applications, </title> <publisher> 23(2-5):205-221. </publisher>
Reference: <author> Yorick Wilks, Xiuming Huang, and Dan Fass. </author> <year> 1985. </year> <title> Syntax, preference and right attachment. </title> <booktitle> In IJCAI-85, </booktitle> <pages> pages 779-784. </pages>
Reference: <author> Yorick Wilks. </author> <year> 1986. </year> <title> An intelligent analyzer and understander of English. </title> <editor> In B. Grosz, K. Sparck Jones, and B. Webber, editors, </editor> <booktitle> Readings in Natural Language Processing, </booktitle> <pages> pages 193-204. </pages> <publisher> Morgan Kaufmann. Originally appeared in CACM 18(5), </publisher> <pages> pp. 264-274, </pages> <year> 1975. </year>
Reference: <author> William Woods and James Schmolze. </author> <year> 1991. </year> <title> The KL-ONE family. Computers and Mathematics with Applications, </title> <journal> Special Issue on Semantic Networks in Artificial Intelligence. </journal> <note> Also available as Technical Report TR-20-90, </note> <institution> Aiken Computation Laboratory, Harvard University. </institution>
Reference: <author> Anthony Woods, Paul Fletcher, and Arthur Hughes. </author> <year> 1986. </year> <title> Statistics in Language Studies. </title> <booktitle> Cambridge Textbooks in Linguistics. </booktitle> <publisher> Cambridge University Press: </publisher> <address> Cambridge, England. </address>
Reference: <author> Fei Xu and Steven Pinker. </author> <year> 1992. </year> <title> Weird past tense forms. </title> <booktitle> Presented at the 17th Boston University Conference on Language Development. </booktitle>
Reference: <author> David Yarowsky. </author> <year> 1992. </year> <title> Word-sense disambiguation using statistical models of Roget's categories trained on large corpora. </title> <booktitle> In Proceedings of COLING-92, </booktitle> <pages> pages 454-460, </pages> <address> Nantes, France, </address> <month> July. </month>

References-found: 186

