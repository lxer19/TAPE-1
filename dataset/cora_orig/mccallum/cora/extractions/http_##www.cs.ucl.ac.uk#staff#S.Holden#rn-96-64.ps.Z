URL: http://www.cs.ucl.ac.uk/staff/S.Holden/rn-96-64.ps.Z
Refering-URL: http://www.cs.ucl.ac.uk/staff/S.Holden/new_paper.html
Root-URL: http://www.cs.ucl.ac.uk
Title: Cross-Validation and the PAC Learning Model  
Author: Sean B. 
Keyword: Supervised Learning, Cross-Validation Estimate, Holdout Estimate, Sample Complexity, Error Estimation, PAC Learning, Consistent Algorithms  
Address: Gower Street London WC1E 6BT, UK  
Affiliation: Department of Computer Science University College London  
Note: Electronic Mail:  
Pubnum: RN/96/64 Research  
Email: Holden  S.Holden@cs.ucl.ac.uk  
Phone: Telephone: +44 (0)171 419 3708 Fax: +44 (0)171 387 1397  
Date: December 23, 1996 Note  
Web: URL: http://www.cs.ucl.ac.uk/staff/S.Holden/  
Abstract: A large body of research exists within the general field of computational learning theory which, informally speaking, addresses the following question: how many examples are required so that, with `high probability', after training a supervised learner we can expect the error on the training set to be `close' to the actual probability of error (the generalization error) of the learner? Theoretical frameworks inspired by probably approximately correct (PAC) learning formalise what is meant by `high probability' and `close' in the above statement. A statistician might recognize this problem as that of knowing under what conditions the `resubstitution estimate'as the error on the training set is often referred toprovides in a particular sense a good estimate of the generalization error. It is well-known that, in fact, the resubstitution estimate usually provides a rather bad estimate of this quantity, and that several better estimates exist. In this paper we study two of the latter estimatesthe holdout estimate and the cross-validation estimatewithin a framework inspired by PAC learning theory. We derive upper and lower bounds on the sample complexity of the error estimation problem for these estimates. Our bounds apply for any consistent supervised learner. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: 1 Introduction The aim of this paper is to study the popular practical technique of cross-validation in the context of the probably approximately correct (PAC) learning model first introduced by Valiant <ref> [1] </ref>. This technique is frequently used in practice to estimate the error probability of a pattern classifier, and has a reputation for performing well in many circumstances when used in practical classifier design.
Reference: [2] <author> Ron Kohavi. </author> <title> A study of cross-validation and bootstrap for accuracy estimation and model selection. </title> <editor> In Chriss S. Mellish, editor, </editor> <booktitle> Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1137-1143. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1995. </year>
Reference-contexts: A full description of the technique will be given below, and examples of the use of cross-validation in practical learning problems and comparisons with an alternative technique can be found in Kohavi <ref> [2] </ref>. More specifically, we will be interested in the problem of supervised learning from a sequence of labelled examples. <p> Formally, the value est m CV (L; s) of the m-fold cross-validation estimate is, est m 1 m X er x i (L (sns i )): This is perhaps the most basic form of cross-validation used in practice; see Kohavi <ref> [2] </ref> for more sophisticated forms of the estimate. <p> Second, in the light of the discussion presented above it would be interesting to try to tighten the general upper bounds that have been obtained. Third, it would be interesting to see whether bounds can be obtained for more sophisticated forms of the cross-validation estimate (see <ref> [2] </ref>) and for other error estimates such as the bootstrap (see [10] and Hand [27] for a summary of various other estimates).
Reference: [3] <author> Joel Ratsaby and Ronny Meir. </author> <title> Finite sample size results for robust model selection; application to neural networks. </title> <type> Technical Report NC-TR-96-006, </type> <institution> Faculty of Electrical Engineering, Technion, Haifa 32000, Israel, </institution> <month> January </month> <year> 1996. </year> <note> Published in the NeuroCOLT technical report series. </note>
Reference-contexts: Much of the theoretical work that is available provides only asymptotic results, which are of little assistance when dealing with a finite (possibly small) training sequence (see Ratsaby and Meir <ref> [3] </ref>). Further motivations also exist for studying this problem, and we begin this paper by presenting a brief survey of them. 1.1 Computational Learning Theory and Error Estimation Consider a two-class pattern classification problem defined as follows. <p> Note however that our upper bounds apply for finite numbers of examples, rather than asymptotically; this is important as the behaviour of estimates such as cross-validation for finite numbers of examples is not at present very well understood <ref> [3] </ref>. We have also obtained a lower bound on the number of examples required for error estimation using these techniques. All our bounds apply for any consistent supervised learner. 7 Acknowledgements This work has benefitted from discussions with a number of people.
Reference: [4] <author> Eric B. Baum and David Haussler. </author> <title> What size net gives valid generalization? Neural Computation, </title> <booktitle> 1 </booktitle> <pages> 151-160, </pages> <year> 1989. </year>
Reference-contexts: A typical result is the following, which is given in Baum and Haussler <ref> [4] </ref> and which requires some measurability conditions for the hypothesis space H.
Reference: [5] <author> Martin Anthony and Norman Biggs. </author> <title> Computational Learning Theory. </title> <booktitle> Cambridge Tracts in Theoretical Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: If H has finite Vapnik-Chervonenkis (VC) dimension (see for example Anthony and Biggs <ref> [5] </ref> and section 2 below) then the upper bound can be made arbitrarily small by choosing a large enough n. <p> This paper addresses a question of precisely the sort put forward in [9] in a slightly more restricted setting than that considered in theorem 1. Specifically, we use the standard PAC learning framework where it is assumed that we wish to learn a realizable rule (see for example <ref> [5] </ref>, full definitions are given below), and we study the probability that the cross-validation estimate differs from the true error probability by more than a specified constant *, under quite general conditions. <p> The bounds are obtained in lemma 3 and theorem 4 and apply under very general conditions. In proving this theorem we extend techniques presented in Anthony and Biggs <ref> [5] </ref>, Anthony [23] and elsewhere. In section 4 we briefly consider lower bounds. In section 5 we discuss the results obtained and make some suggestions for future research. <p> we define the growth function F (j) as, F (j) = maxfj F (S)j : S X and jSj = jg: The VC dimension of F is denoted VCdim (F ) and defined as, VCdim (F ) = maxfj : F (j) = 2 j g: By Sauer's lemma (see <ref> [5] </ref>) we know that if d = VCdim (F ) is finite and j d 1, F (j) &lt; ej d The following theorem is a standard result in the concept learning framework. Theorem 2 (see [5], proposition 8.2.3) Let C = H. <p> ) = maxfj : F (j) = 2 j g: By Sauer's lemma (see <ref> [5] </ref>) we know that if d = VCdim (F ) is finite and j d 1, F (j) &lt; ej d The following theorem is a standard result in the concept learning framework. Theorem 2 (see [5], proposition 8.2.3) Let C = H. <p> We will present the proof of theorem 4 using a series of lemmas. The proof extends the techniques of symmetrization and combinatorial bounding used in <ref> [5, 23] </ref>, and our proofs parallel some of the proofs therein. Similar techniques to those used in [5, 23] are used in much of the literature on the uniform convergence of relative frequencies (see for example Blumer et al. [24] and Vapnik and Chervonenkis [25] for further examples of such techniques). <p> We will present the proof of theorem 4 using a series of lemmas. The proof extends the techniques of symmetrization and combinatorial bounding used in <ref> [5, 23] </ref>, and our proofs parallel some of the proofs therein. Similar techniques to those used in [5, 23] are used in much of the literature on the uniform convergence of relative frequencies (see for example Blumer et al. [24] and Vapnik and Chervonenkis [25] for further examples of such techniques). <p> For any sequence a = (a 1 ; : : : ; a i ) we denote by oea the sequence (a oe (1) ; : : : ; a oe (i) ). Lemma 6 (see <ref> [5] </ref>, lemma 8.3.3) Let S be a subset of X n+k and let P be any distribution on X . Let xy be a sequence in X n+k and let G be any subgroup of G n+k . <p> The proof follows directly from equations (9) and (10) using only a simple manipulation of inequalities and the fact that for x &gt; 0 and y &gt; 0, ln (x) (ln (1=y) 1) + yx (see <ref> [5] </ref>). 2 In the two sample complexity bounds provided in theorem 9 we require that n &gt; max (2m=* 2 ; n 0 (m; *; ffi; d)) for some specified n 0 (m; *; ffi; d). <p> The following theorem is obtained by applying the technique that is used in [24] (see also <ref> [5] </ref>) to obtain a lower bound for the sample complexity of a learning function, and, in addition, making use of the fact that L is consistent. Theorem 10 Let C be any concept class where jCj &gt; 2, let C H, and let L be any consistent learning algorithm. <p> Let P be the distribution P (x 1 ) = 1 *, P (x 2 ) = *, and P is zero elsewhere. Then if n ((1 *)=*) ln (1=ffi) we have, P n fx 2 X n : each element in x is x 1 g ffi (see <ref> [24, 5] </ref> for a derivation of this result). <p> The right hand side of this inequality will be less than ffi if, * d log 2 12 ffi (see <ref> [5] </ref>). Comparing this bound with the results obtained above, it appears that we have not yet obtained an improvement over the bound for the resubstitution estimate as was originally desired.
Reference: [6] <author> John Shawe-Taylor and Martin Anthony. </author> <title> Sample sizes for multiple-output threshold networks. </title> <journal> Network, </journal> <volume> 2 </volume> <pages> 107-117, </pages> <year> 1991. </year>
Reference-contexts: A great deal of research in recent years has concentrated on extending results of this kind to deal with multiple class problems (see for example Shawe-Taylor and Anthony <ref> [6] </ref>), and real-valued functions (see for example Haussler [7], Pollard [8]) etc, however there is another potential direction for the extension of such results which to date has received much less emphasis, although it is no less interesting.
Reference: [7] <author> David Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> <volume> 100(1) </volume> <pages> 78-150, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: A great deal of research in recent years has concentrated on extending results of this kind to deal with multiple class problems (see for example Shawe-Taylor and Anthony [6]), and real-valued functions (see for example Haussler <ref> [7] </ref>, Pollard [8]) etc, however there is another potential direction for the extension of such results which to date has received much less emphasis, although it is no less interesting.
Reference: [8] <author> David Pollard. </author> <title> Convergence of Stochastic Processes. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: A great deal of research in recent years has concentrated on extending results of this kind to deal with multiple class problems (see for example Shawe-Taylor and Anthony [6]), and real-valued functions (see for example Haussler [7], Pollard <ref> [8] </ref>) etc, however there is another potential direction for the extension of such results which to date has received much less emphasis, although it is no less interesting.
Reference: [9] <author> Bing Cheng and D. M. Titterington. </author> <title> Neural networks: A review from a statistical perspective. </title> <journal> Statistical Science, </journal> <volume> 9(1) </volume> <pages> 2-54, </pages> <year> 1994. </year>
Reference-contexts: Cheng and Titterington <ref> [9] </ref> have raised the interesting question of what happens to the result stated in theorem 1 if a cross-validation estimate is used in place of a resubstitution estimate. The cross-validation estimate will be defined in full below, however we will give a brief description here. <p> However, the possibility that the looseness of the bounds may in part be due to the bias of the resubstitution estimate has not in general been considered. This paper addresses a question of precisely the sort put forward in <ref> [9] </ref> in a slightly more restricted setting than that considered in theorem 1.
Reference: [10] <author> G. T. Toussaint. </author> <title> Bibliography on estimation of misclassification. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 20(4) </volume> <pages> 472-479, </pages> <year> 1974. </year>
Reference-contexts: The question is particularly interesting in the light of practical experience of error estimation, in that it is now well-known (see for example Toussaint <ref> [10] </ref>) that the resubstitution estimate is not a good estimator of true error in practice due to its considerable optimistic bias. (This simply means that it tends to underestimate the true error.) Clearly therefore the study of error estimates other than the resubstitution estimate is of significant importance if we wish <p> Third, it would be interesting to see whether bounds can be obtained for more sophisticated forms of the cross-validation estimate (see [2]) and for other error estimates such as the bootstrap (see <ref> [10] </ref> and Hand [27] for a summary of various other estimates).
Reference: [11] <author> David Cohn and Gerald Tesauro. </author> <title> How tight are the Vapnik-Chervonenkis bounds? Neural Computation, </title> <booktitle> 4(2) </booktitle> <pages> 249-269, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: In addition, it is now well-known that results such as theorem 1 provide bounds that are too loose to be successfully applied in practice, and several possible reasons have been suggested for this (see for example Cohn and Tesauro <ref> [11] </ref>, Haussler et al. [12] and Holden and Niranjan [13]). However, the possibility that the looseness of the bounds may in part be due to the bias of the resubstitution estimate has not in general been considered.
Reference: [12] <author> David Haussler, Michael Kearns, and Robert Schapire. </author> <title> Bounds on the sample complexity of Bayesian learning using information theory and the VC dimension. </title> <journal> Machine Learning, </journal> <volume> 14 </volume> <pages> 83-113, </pages> <year> 1994. </year>
Reference-contexts: In addition, it is now well-known that results such as theorem 1 provide bounds that are too loose to be successfully applied in practice, and several possible reasons have been suggested for this (see for example Cohn and Tesauro [11], Haussler et al. <ref> [12] </ref> and Holden and Niranjan [13]). However, the possibility that the looseness of the bounds may in part be due to the bias of the resubstitution estimate has not in general been considered.
Reference: [13] <author> Sean B. Holden and Mahesan Niranjan. </author> <title> On the practical applicability of VC dimension bounds. </title> <journal> Neural Computation, </journal> <volume> 7(6) </volume> <pages> 1265-1288, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: In addition, it is now well-known that results such as theorem 1 provide bounds that are too loose to be successfully applied in practice, and several possible reasons have been suggested for this (see for example Cohn and Tesauro [11], Haussler et al. [12] and Holden and Niranjan <ref> [13] </ref>). However, the possibility that the looseness of the bounds may in part be due to the bias of the resubstitution estimate has not in general been considered.
Reference: [14] <author> W. H. Rogers and T. J. Wagner. </author> <title> A finite sample distribution-free performance bound for local discrimination rules. </title> <journal> Annals of Statistics, </journal> <volume> 6(3) </volume> <pages> 506-514, </pages> <year> 1978. </year>
Reference-contexts: We also investigate a similar estimate known as the holdout estimate, and some further related issues. 1.2 Related Work For specific learning algorithms, a small body of previous work has addressed issues similar to those addressed by this paper. Rogers and Wagner <ref> [14] </ref> have studied the deleted estimate used in conjunction with k-local discrimination rules. The deleted estimate, also known as the leave-one-out cross-validation estimate, is a form of cross-validation in which each of the m sections used contains only a single example. <p> Devroye and Wagner [16, 17] study the deleted, holdout and resubstitution estimates in conjunction with k-local and potential function rules. A good description of some of the work in <ref> [14, 16, 17] </ref> can be found in Devroye et al. [18]. In Holden [19], techniques from [16] and Haussler et al. [20] are used to study the deleted estimate in conjunction with the closure algorithm and the deterministic 1-inclusion graph prediction strategy, both of which are described in [20].
Reference: [15] <author> Richard O. Duda and Peter E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley and Sons, </publisher> <year> 1973. </year>
Reference-contexts: The deleted estimate, also known as the leave-one-out cross-validation estimate, is a form of cross-validation in which each of the m sections used contains only a single example. The k-local rules considered are pattern classification techniques such as the k-nearest neighbour algorithm (see Duda and Hart <ref> [15] </ref>) that use only the k members of the training sequence nearest (in an appropriately defined sense) to a new input in order to produce a classification for that input. Devroye and Wagner [16, 17] study the deleted, holdout and resubstitution estimates in conjunction with k-local and potential function rules.
Reference: [16] <author> Luc P. Devroye and T. J. Wagner. </author> <title> Distribution-free performance bounds for potential function rules. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-25(5):601-604, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: Devroye and Wagner <ref> [16, 17] </ref> study the deleted, holdout and resubstitution estimates in conjunction with k-local and potential function rules. A good description of some of the work in [14, 16, 17] can be found in Devroye et al. [18]. <p> Devroye and Wagner [16, 17] study the deleted, holdout and resubstitution estimates in conjunction with k-local and potential function rules. A good description of some of the work in <ref> [14, 16, 17] </ref> can be found in Devroye et al. [18]. In Holden [19], techniques from [16] and Haussler et al. [20] are used to study the deleted estimate in conjunction with the closure algorithm and the deterministic 1-inclusion graph prediction strategy, both of which are described in [20]. <p> Devroye and Wagner [16, 17] study the deleted, holdout and resubstitution estimates in conjunction with k-local and potential function rules. A good description of some of the work in [14, 16, 17] can be found in Devroye et al. [18]. In Holden [19], techniques from <ref> [16] </ref> and Haussler et al. [20] are used to study the deleted estimate in conjunction with the closure algorithm and the deterministic 1-inclusion graph prediction strategy, both of which are described in [20]. RN/96/64 Page 5 Cross-Validation and PAC Learning Sean B.
Reference: [17] <author> Luc P. Devroye and T. J. Wagner. </author> <title> Distribution-free inequalities for the deleted and holdout error estimates. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 25(2) </volume> <pages> 202-207, </pages> <month> March </month> <year> 1979. </year>
Reference-contexts: Devroye and Wagner <ref> [16, 17] </ref> study the deleted, holdout and resubstitution estimates in conjunction with k-local and potential function rules. A good description of some of the work in [14, 16, 17] can be found in Devroye et al. [18]. <p> Devroye and Wagner [16, 17] study the deleted, holdout and resubstitution estimates in conjunction with k-local and potential function rules. A good description of some of the work in <ref> [14, 16, 17] </ref> can be found in Devroye et al. [18]. In Holden [19], techniques from [16] and Haussler et al. [20] are used to study the deleted estimate in conjunction with the closure algorithm and the deterministic 1-inclusion graph prediction strategy, both of which are described in [20].
Reference: [18] <author> Luc Devroye, Laszl o Gy orfi, and Gabor Lugosi. </author> <title> A Probabilistic Theory of Pattern Recognition. </title> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: Devroye and Wagner [16, 17] study the deleted, holdout and resubstitution estimates in conjunction with k-local and potential function rules. A good description of some of the work in [14, 16, 17] can be found in Devroye et al. <ref> [18] </ref>. In Holden [19], techniques from [16] and Haussler et al. [20] are used to study the deleted estimate in conjunction with the closure algorithm and the deterministic 1-inclusion graph prediction strategy, both of which are described in [20]. RN/96/64 Page 5 Cross-Validation and PAC Learning Sean B.
Reference: [19] <author> Sean B. Holden. </author> <title> PAC-like upper bounds for the sample complexity of leave-one-out cross-validation. </title> <booktitle> In Proceedings of the Ninth Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 41-50. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1996. </year> <note> RN/96/64 Page 19 Cross-Validation and PAC Learning Sean B. Holden </note>
Reference-contexts: Devroye and Wagner [16, 17] study the deleted, holdout and resubstitution estimates in conjunction with k-local and potential function rules. A good description of some of the work in [14, 16, 17] can be found in Devroye et al. [18]. In Holden <ref> [19] </ref>, techniques from [16] and Haussler et al. [20] are used to study the deleted estimate in conjunction with the closure algorithm and the deterministic 1-inclusion graph prediction strategy, both of which are described in [20]. RN/96/64 Page 5 Cross-Validation and PAC Learning Sean B.
Reference: [20] <author> D. Haussler, N. Littlestone, and M. K. Warmuth. </author> <title> Predicting f0; 1g-functions on randomly drawn points. </title> <type> Technical Report UCSC-CRL-90-54, </type> <institution> Computer Research Laboratory, Applied Sciences Building, University of California, </institution> <address> Santa Cruz, Santa Cruz, CA 95064, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: A good description of some of the work in [14, 16, 17] can be found in Devroye et al. [18]. In Holden [19], techniques from [16] and Haussler et al. <ref> [20] </ref> are used to study the deleted estimate in conjunction with the closure algorithm and the deterministic 1-inclusion graph prediction strategy, both of which are described in [20]. RN/96/64 Page 5 Cross-Validation and PAC Learning Sean B. <p> In Holden [19], techniques from [16] and Haussler et al. <ref> [20] </ref> are used to study the deleted estimate in conjunction with the closure algorithm and the deterministic 1-inclusion graph prediction strategy, both of which are described in [20]. RN/96/64 Page 5 Cross-Validation and PAC Learning Sean B. Holden In the present paper we obtain results that do not depend on the use of a specific learning algorithm.
Reference: [21] <author> M. Kearns, Y. Mansour, A. Y. Ng, and D. Ron. </author> <title> An experimental and theoretical comparison of model selection methods. </title> <booktitle> In Proceedings of the Eighth Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 21-30, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: RN/96/64 Page 5 Cross-Validation and PAC Learning Sean B. Holden In the present paper we obtain results that do not depend on the use of a specific learning algorithm. Some further work addressing issues closely related to those studied in this paper can be found in Kearns et al. <ref> [21] </ref> and Kearns [22], in which the holdout estimate has been studied in the context of model selection. 1.3 Structure of the Paper In section 2 we provide some background material and notation for the paper.
Reference: [22] <author> Michael Kearns. </author> <title> A bound on the error of cross validation using the approximation and estimation rates, with consequences for the training-test split. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> pages 183-189. </pages> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Holden In the present paper we obtain results that do not depend on the use of a specific learning algorithm. Some further work addressing issues closely related to those studied in this paper can be found in Kearns et al. [21] and Kearns <ref> [22] </ref>, in which the holdout estimate has been studied in the context of model selection. 1.3 Structure of the Paper In section 2 we provide some background material and notation for the paper.
Reference: [23] <author> Martin Anthony. </author> <title> On deviation of relative frequencies from probabilities. </title> <type> Technical Report LSE-MPS-2, </type> <institution> London School of Economics and Political Science, Houghton Street, </institution> <address> London WC2A 2AE, U.K., </address> <month> January </month> <year> 1991. </year>
Reference-contexts: The bounds are obtained in lemma 3 and theorem 4 and apply under very general conditions. In proving this theorem we extend techniques presented in Anthony and Biggs [5], Anthony <ref> [23] </ref> and elsewhere. In section 4 we briefly consider lower bounds. In section 5 we discuss the results obtained and make some suggestions for future research. <p> We will present the proof of theorem 4 using a series of lemmas. The proof extends the techniques of symmetrization and combinatorial bounding used in <ref> [5, 23] </ref>, and our proofs parallel some of the proofs therein. Similar techniques to those used in [5, 23] are used in much of the literature on the uniform convergence of relative frequencies (see for example Blumer et al. [24] and Vapnik and Chervonenkis [25] for further examples of such techniques). <p> We will present the proof of theorem 4 using a series of lemmas. The proof extends the techniques of symmetrization and combinatorial bounding used in <ref> [5, 23] </ref>, and our proofs parallel some of the proofs therein. Similar techniques to those used in [5, 23] are used in much of the literature on the uniform convergence of relative frequencies (see for example Blumer et al. [24] and Vapnik and Chervonenkis [25] for further examples of such techniques).
Reference: [24] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Similar techniques to those used in [5, 23] are used in much of the literature on the uniform convergence of relative frequencies (see for example Blumer et al. <ref> [24] </ref> and Vapnik and Chervonenkis [25] for further examples of such techniques). For notational convenience we will divide any x 2 X n into two parts and RN/96/64 Page 10 Cross-Validation and PAC Learning Sean B. <p> The following theorem is obtained by applying the technique that is used in <ref> [24] </ref> (see also [5]) to obtain a lower bound for the sample complexity of a learning function, and, in addition, making use of the fact that L is consistent. <p> Let P be the distribution P (x 1 ) = 1 *, P (x 2 ) = *, and P is zero elsewhere. Then if n ((1 *)=*) ln (1=ffi) we have, P n fx 2 X n : each element in x is x 1 g ffi (see <ref> [24, 5] </ref> for a derivation of this result).
Reference: [25] <author> V. N. Vapnik and A. Chervonenkis. </author> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory of Probability and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference-contexts: Similar techniques to those used in [5, 23] are used in much of the literature on the uniform convergence of relative frequencies (see for example Blumer et al. [24] and Vapnik and Chervonenkis <ref> [25] </ref> for further examples of such techniques). For notational convenience we will divide any x 2 X n into two parts and RN/96/64 Page 10 Cross-Validation and PAC Learning Sean B.
Reference: [26] <author> Shai Ben-David, </author> <year> 1996. </year> <title> Private communication. </title>
Reference-contexts: Also, it is no longer necessary to insist that m divides n, and the result still applies when the folds used in calculating the cross-validation estimate are of different sizes. A further lower bound result has been proposed by Ben-David <ref> [26] </ref>. 5 Discussion 5.1 Upper Bounds One of the main motivations for this research was the fact that the cross-validation and holdout estimates are known to be better techniques than the resubstitution estimate for estimating the true error in practice.
Reference: [27] <author> David Hand. </author> <title> Recent advances in error rate estimation. </title> <journal> Pattern Recognition Letters, </journal> <volume> 4 </volume> <pages> 335-346, </pages> <year> 1986. </year> <note> RN/96/64 Page 20 </note>
Reference-contexts: Third, it would be interesting to see whether bounds can be obtained for more sophisticated forms of the cross-validation estimate (see [2]) and for other error estimates such as the bootstrap (see [10] and Hand <ref> [27] </ref> for a summary of various other estimates).
References-found: 27

