URL: http://vibes.cs.uiuc.edu/Publications/Theses/ElfordMS.ps.gz
Refering-URL: http://vibes.cs.uiuc.edu/Publications/Theses/theses.htm
Root-URL: http://www.cs.uiuc.edu
Title: EFFECTS OF TRENDS IN DISK TECHNOLOGY ON DISK ARRAYS  
Author: BY CHRISTOPHER LLOYD ELFORD 
Degree: B.S., University of Houston, 1991 THESIS Submitted in partial fulfillment of the requirements for the degree of Master of Science in Computer Science in the Graduate College of the  
Address: 1994 Urbana, Illinois  
Affiliation: University of Illinois at Urbana-Champaign,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Cabrera, L. F., and Long, D. E. </author> <title> Exploiting Multiple I/O Streams to Provide High Data-rates. </title> <type> Tech. Rep. </type> <institution> UCSC-CRL-91-08, UC San Diego/CSE, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: They showed that I/O performance optimization consists of both device level improvements and an improved caching interface. Chervenak and Katz created a hardware RAID prototype. Alternately, disks can also be coupled via a software interface which performs striping and parity calculations. Cabrera and Long <ref> [1, 2] </ref> analyzed a distributed striped disk array consisting of disks distributed across a local network. In addition to building a prototype, they performed a simulation study which examines the relative performance of several different types of disks in their system. <p> This array mapping logic can be implemented in hardware as part of the array device as is done in many commercial disk arrays. This mapping can also be done in software as part of a software implementation of a disk array <ref> [1, 2] </ref>. 2.3.1 Disk Arrays Explored For the analyses presented in this thesis, the performance of a disk array is bound to several basic sets of assumptions.
Reference: [2] <author> Cabrera, L. F., and Long, D. E. Swift: </author> <title> Using Distributed Disk Striping to Provide High I/O Data Rates. </title> <type> Tech. Rep. </type> <institution> UCSC-CRL-91-46, UC San Diego/CSE, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: They showed that I/O performance optimization consists of both device level improvements and an improved caching interface. Chervenak and Katz created a hardware RAID prototype. Alternately, disks can also be coupled via a software interface which performs striping and parity calculations. Cabrera and Long <ref> [1, 2] </ref> analyzed a distributed striped disk array consisting of disks distributed across a local network. In addition to building a prototype, they performed a simulation study which examines the relative performance of several different types of disks in their system. <p> This array mapping logic can be implemented in hardware as part of the array device as is done in many commercial disk arrays. This mapping can also be done in software as part of a software implementation of a disk array <ref> [1, 2] </ref>. 2.3.1 Disk Arrays Explored For the analyses presented in this thesis, the performance of a disk array is bound to several basic sets of assumptions.
Reference: [3] <author> Calderbank, A., Coffman, E., and Flatto, L. </author> <title> 50-Head Disk Drive Promises to Speed Access by a Factor of 10. </title> <booktitle> Electronic Design 32 (1984), </booktitle> <pages> 37-38. </pages>
Reference-contexts: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . switch heads rather than moving to a new track <ref> [3] </ref>. Optical disks offer vast quantities of storage at the cost of increased access times. These options have proven very costly because development costs are amortized over a very small market.
Reference: [4] <author> Chen, P., Lee, E., Gibson, G., Katz, R., and Patterson, D. </author> <title> RAID: High-Performance, Reliable Secondary Storage. </title> <journal> ACM Computing Surveys, </journal> <note> submitted for publication </note> . 
Reference-contexts: 32.4 19.4 43 Diameter (Inches) 14 5.25 5.25 5.25 5.25 3.5 2.5 1.3 Capacity (Megabytes) 645 613 1050 1830 1800 320 128 21.4 Interface Speed (Mbytes/sec) 3 5 5 10 10 10 10 5 Table 2.2: Representative Disk Parameters Table 2.3 indicates the relative rates of evolution in disk technology <ref> [4] </ref>. Data densities are increasing significantly faster than the rate at which seek times are decreasing and rotation speeds are increasing.
Reference: [5] <author> Chen, S., and Towsley, D. </author> <title> The Design and Evaluation of RAID 5 and Parity Striping Disk Array Architectures. </title> <journal> Journal of Parallel and Distributed Computing 17 (1993), </journal> <pages> 58-74. </pages>
Reference-contexts: For small requests, the disks' seek times dominate service time and limits performance. For larger requests, however, seek delays are amortized and have a smaller effect. Chen and Towsley <ref> [5] </ref> described analytic models for a level five RAID and a parity striped disk array architecture. For a typical disk, they compared the performance of these two disk array architectures for several request sizes and request arrival rates. <p> Unfortunately, her analytic model is not easily solvable for general disk service distributions. The analytic models proposed in the studies performed by Kim, Chen, and Towsley used open queuing models which resulted in complicated expressions for utilization and response time <ref> [9, 10, 5] </ref>. Lee and Katz [11] presented a closed queuing model of asynchronous disk arrays instead. In their model, some number of requesting processes cycle between issuing disk array requests and waiting for them to complete.
Reference: [6] <author> Chervenak, A. L., and Katz, R. H. </author> <title> Performance of a Disk Array Prototype. </title> <booktitle> Proceedings of the 1991 ACM SIGMETRICS Conference 19 ((May 1991)), </booktitle> <pages> 188-197. </pages>
Reference-contexts: The original RAID document purposefully defined minimal requirements for each RAID level. Within the taxonomy there is a wide range of possible implementations. Lee [12] studied eight different RAID parity placement strategies and compared their performance to simple disk striping. Chervenak and Katz <ref> [6] </ref> studied the performance of a RAID prototype developed at U.C. Berkeley. Unlike previous studies which relied on simulation, their study is based on a real RAID prototype. Their study concentrated on the effects of cache, memory, and interface contention on the performance of the RAID array.
Reference: [7] <author> DeGroot, M. H. </author> <title> Probability and Statistics. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1987. </year>
Reference-contexts: Because disks rotate independently, the rotational latency of the disk array is the maximum of the rotational latencies of the individual disks. The probability density function of the maximum of n i.i.d. random variables with proba bility density function f (x) and distribution function F (x) <ref> [7] </ref> is f max n (x) = n [F (x)] f (y): (3:4) The probability density function of the uniform distribution is given in (2.4), F (x) = 1 dx = c Substituting in (3.4), we obtain the probability density function of the maximum of D i.i.d. uniform random variables: f
Reference: [8] <author> Herring, B., and Prather, W. </author> <title> A Simulation Model for Analyzing Service Times in a Rotational Position Sensing Disk System. </title> <booktitle> Simulation 46 (1986), </booktitle> <pages> 185-191. </pages>
Reference-contexts: Finally, array-controller interface delay depends on request size and interface speed. Because interface speed is fixed by the disk architecture and request size does not vary, interface delay is constant. 4 Note that this presumes rotational position sensing <ref> [8] </ref>. 19 Chapter 3 Analytic Models In x2.4.2, we discussed the distributions of seek delay, rotational latency, transfer time, and interface delay. These components combine to yield the service time of a single disk.
Reference: [9] <author> Kim, M. Y. </author> <title> Synchronized Disk Interleaving. </title> <journal> IEEE Transactions on Computers C-35 (1986), </journal> <pages> 978-988. </pages>
Reference-contexts: The Cray-2 offers solid state disks that can be used as a temporary random access file cache. Can arrays of commodity disks offer better performance than these proprietary I/O subsystems? Will their performance advantage continue to exist with the commodity disks of the future? Kim <ref> [9] </ref> explored the hardware synchronization of disk arrays. She created an analytic model of synchronized disk arrays and compared their performance to independently operating or decoupled disks. <p> Unfortunately, her analytic model is not easily solvable for general disk service distributions. The analytic models proposed in the studies performed by Kim, Chen, and Towsley used open queuing models which resulted in complicated expressions for utilization and response time <ref> [9, 10, 5] </ref>. Lee and Katz [11] presented a closed queuing model of asynchronous disk arrays instead. In their model, some number of requesting processes cycle between issuing disk array requests and waiting for them to complete. <p> We will discuss how our models can be extrapolated to predict the performance of some other disk array models. In all cases, the disks in the array are assumed to share a single interface. 11 2.3.1.1 Fully Synchronous Array In a fully synchronous array <ref> [9] </ref>, disks are both seek and rotationally synchronized. The disk array contains additional hardware that ensures that the heads on all D disks are positioned identically. Sector zero on all disks passes under the heads concurrently. In addition, the disks seek in unison. <p> Because this is not the case, we 28 find the distribution of seek and rotation together. The probability density function of seek with latency is obtained by convolving (2.1) and (2.4) <ref> [9] </ref> as f s+r (zjfi; c) = Z z f s (xjfi)f r (z xjc)dx = &gt; &lt; 1 fiz for 0 z c, c e 1 for z &gt; c. The associated distribution function is obtained by integrating (3.8) [9]: F s+r (tjfi; c) = Z t f s+r (zjfi; <p> seek with latency is obtained by convolving (2.1) and (2.4) <ref> [9] </ref> as f s+r (zjfi; c) = Z z f s (xjfi)f r (z xjc)dx = &gt; &lt; 1 fiz for 0 z c, c e 1 for z &gt; c. The associated distribution function is obtained by integrating (3.8) [9]: F s+r (tjfi; c) = Z t f s+r (zjfi; c)dz = &gt; &lt; t 1 fit for 0 t c, e fit fic (3.9) Substituting (3.8) and (3.9) into (3.4) gives the probability function of the maximum seek and rotational latency: f max n (x) = nF s+r (x)f
Reference: [10] <author> Kim, M. Y. </author> <title> Asynchronous Disk Interleaving: Approximating Access Delays. </title> <journal> IEEE Transactions on Computers 40 (July 1991), </journal> <pages> 801-810. 89 </pages>
Reference-contexts: Chen and Towsley concluded that RAID level five disk arrays can offer better performance than parity striped architectures when request size is smaller than the striping unit. They recommended large striping units for RAID level five disk arrays. Kim <ref> [10] </ref> extends her previous study of synchronous disk arrays by examining the performance of asynchronous disk arrays. She found several approximations for simulating or predicting the performance of these asynchronous disk arrays. <p> Unfortunately, her analytic model is not easily solvable for general disk service distributions. The analytic models proposed in the studies performed by Kim, Chen, and Towsley used open queuing models which resulted in complicated expressions for utilization and response time <ref> [9, 10, 5] </ref>. Lee and Katz [11] presented a closed queuing model of asynchronous disk arrays instead. In their model, some number of requesting processes cycle between issuing disk array requests and waiting for them to complete. <p> In addition, synchronous disk arrays can only service a single request at a time. The fully asynchronous 12 architecture is a relaxed implementation of the partially synchronous model which addresses these issues. In a fully asynchronous disk array <ref> [10] </ref>, disks seek and rotate independently. Data is logically striped across all the disks rather than physically striped as in the previous models. While block i is on disk i mod D, block i and i + 1 need not be on the same track on their respective disks.
Reference: [11] <author> Lee, E., and Katz, R. </author> <title> An Analytic Performance Model of Disk Arrays. </title> <booktitle> In ACM SIGMETRICS (May 1993), </booktitle> <pages> pp. 98-109. </pages>
Reference-contexts: Unfortunately, her analytic model is not easily solvable for general disk service distributions. The analytic models proposed in the studies performed by Kim, Chen, and Towsley used open queuing models which resulted in complicated expressions for utilization and response time [9, 10, 5]. Lee and Katz <ref> [11] </ref> presented a closed queuing model of asynchronous disk arrays instead. In their model, some number of requesting processes cycle between issuing disk array requests and waiting for them to complete. <p> Hence, seek time is not a linear function of seek distance. As an example, Figure 2.2 shows the seek time distribution as a function of seek distance for the Wren 7 and the IBM 0661 <ref> [11] </ref>. Each track contains the same number of logical subdivisions or sectors where data is stored. After seeking, the disk rotates until the read/write head is positioned at the first of the requested sectors and then rotates through the request's sectors to transfer the data.
Reference: [12] <author> Lee, E. K. </author> <title> Software and Implementation Issues in the Implementation of a RAID Prototype. </title> <type> Tech. Rep. </type> <institution> UCB/CSD 90/573, UC Berkley/CSD, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: Since Patterson et. al. defined the RAID taxonomy, many groups have analyzed the performance of RAID systems. The original RAID document purposefully defined minimal requirements for each RAID level. Within the taxonomy there is a wide range of possible implementations. Lee <ref> [12] </ref> studied eight different RAID parity placement strategies and compared their performance to simple disk striping. Chervenak and Katz [6] studied the performance of a RAID prototype developed at U.C. Berkeley. Unlike previous studies which relied on simulation, their study is based on a real RAID prototype. <p> High performance system developers, seeking to capitalize on strides in commodity disk technology, have proposed and built various forms of disk arrays <ref> [12, 13] </ref>. Groups of commodity disks can be physically coupled via hardware or logically coupled via software. <p> This prevents a single disk from becoming a hot spot during disk writes, while simultaneously increasing the number of disks involved in servicing read requests. If the data is arranged such that parity blocks divide groups of data blocks <ref> [12] </ref>, large read requests must either read the parity information or issue multiple disk transactions, increasing rotational latencies. Level five RAID reads are similar to synchronous, partially synchronous, or asynchronous disk arrays depending on the level of disk coupling in the RAID.
Reference: [13] <author> Patterson, D., Gibson, G., and Katz, R. </author> <title> A Case For Redundant Arrays of Inexpensive Disks (RAID). </title> <booktitle> In Proceedings of ACM SIGMOD (December 1988). </booktitle>
Reference-contexts: Assuming the disk failure rates in a disk array are independent, the mean time to failure of a disk array is the mean time to failure of a single disk divided by the number of disks in the array. Patterson, Gibson, and Katz <ref> [13] </ref> realized that the mean time to failure of commodity disks was about 30,000 hours in 1988. A sixteen disk striped array would have a mean time to failure of eleven weeks. Disks arrays with hardware synchronization potentially have dependent failure characteristics yielding an even smaller mean time to failure. <p> A sixteen disk striped array would have a mean time to failure of eleven weeks. Disks arrays with hardware synchronization potentially have dependent failure characteristics yielding an even smaller mean time to failure. Therefore, Patterson et. al. explored ways to improve the reliability of disk arrays <ref> [13] </ref>. Patterson et. al. [13] enumerated several ways of storing redundant data on disk arrays. They defined a five level RAID 2 taxonomy. RAIDs extend the mean time to failure of disk arrays by storing information redundantly. <p> Disks arrays with hardware synchronization potentially have dependent failure characteristics yielding an even smaller mean time to failure. Therefore, Patterson et. al. explored ways to improve the reliability of disk arrays <ref> [13] </ref>. Patterson et. al. [13] enumerated several ways of storing redundant data on disk arrays. They defined a five level RAID 2 taxonomy. RAIDs extend the mean time to failure of disk arrays by storing information redundantly. <p> High performance system developers, seeking to capitalize on strides in commodity disk technology, have proposed and built various forms of disk arrays <ref> [12, 13] </ref>. Groups of commodity disks can be physically coupled via hardware or logically coupled via software. <p> Decoupled disk systems trade higher response times on single requests for inter-request parallelism and potentially higher throughput. 2.3.2 Applicability to RAID Systems With the growing availability and popularity of commercial RAID systems <ref> [13] </ref>, it is instructive to consider how our models apply to these RAID systems. Most commercial RAID systems support Berkeley RAID levels one, three and five, as well as simple disk striping, which is now called RAID level zero; see Table 2.4.
Reference: [14] <author> Reddy, A. L., and Banerjee, P. </author> <title> A Study of Parallel Disk Organizations. </title> <booktitle> Computer Architecture News 17 (1989), </booktitle> <pages> 40-47. 90 </pages>
Reference-contexts: However, by synchronizing a disk array, all disks must cooperate to service each re 1 Single Large Expensive Disks 2 quest. This potentially increases queuing delays. When disks are decoupled, multiple requests can be serviced concurrently, potentially lowering the queuing delay of an arbitrary request. Reddy and Banerjee <ref> [14] </ref> extended Kim's work with a simulation study of a synchronized DEC RA81 disk array. Reddy and Banerjee's study attempted to characterize the tradeoffs between disk synchronization and independent or decoupled access streams to the individual disks.
References-found: 14

