URL: http://www.cs.utah.edu/~stoller/pubs/isca98.ps
Refering-URL: http://www.cs.utah.edu/~stoller/pubs/pubs.html
Root-URL: 
Title: Increasing TLB Reach Using Superpages Backed by Shadow Memory  
Date: November 24, 1997  
Abstract: The amount of memory that can be accessed without causing a TLB fault, the so-called reach of a TLB, is failing to keep pace with the increasingly large working sets of applications. We propose to extend TLB reach via a novel Memory Controller TLB (MTLB) that lets us aggressively create superpages from non-contiguous, unaligned regions of physical memory. This flexibility increases the OS's ability to use superpages on arbitrary application data. The MTLB supports shadow pages, regions of physical address space for which the MTLB remaps accesses to "real" physical pages. The MTLB preserves per-base-page referenced and dirty bits, which enables the OS to swap shadow-backed superpages more efficiently than conventional superpages. Simulation of nine applications, including the SPECint95 benchmarks, demonstrated that a modest-sized MTLB improves performance of applications with moderate-to-high TLB miss rates by 5-20%. Simulation also showed that this mechanism can more than double the effective reach of a processor TLB with no modification to the processor MMU.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bershad, B., Lee, D., Romer, T., and Chen, J. </author> <title> Avoiding Conflict Misses Dynamically in Large Direct-Mapped Caches. </title> <booktitle> In Proceedings of the 6th Symposium on Architectural Support for Programming Languages and Operating Systems (Oct. </booktitle> <year> 1994), </year> <pages> pp. 158-170. </pages>
Reference-contexts: In the future, we intend to investigate several ways to further exploit the existence of shadow memory and an MTLB. We are currently exploring ways to use shadow memory to implement no-copy page recoloring <ref> [1] </ref> and MMC-provided stream buffers [10, 12]. In addition, we continuing to investigate whether swapping of base pages within a superpage can be supported in the context of current CPU/memory interface limitations. We also are investigating the space of practical MTLB implementations to determine what organizations and latencies are feasible.
Reference: [2] <author> Bryg, W., Chan, K., and Fiduccia, N. </author> <title> A High-Performance, Low-Cost Multiprocessor Bus for Workstations and Midrange Servers. </title> <journal> Hewlett-Packard Journal 47, </journal> <month> 1 (February </month> <year> 1996), </year> <pages> 18-24. 18 </pages>
Reference-contexts: Again, all superpage creation was performed by sbrk (). 3.2 Simulation Environment The simulation results were all obtained using an execution-driven simulator that models a single-issue 4 240 MHZ processor with cycle-accurate models of the cache, bus, and memory controller. The bus modeled is HP's Runway bus <ref> [2] </ref> clocked at 120 MHZ. The main memory controller (MMC) is similar to HP's memory controller [7] used in its HP 9000 J and K-class commercial servers and high end workstations. The instruction cache is assumed to be perfect.
Reference: [3] <author> Chandra, S., Larus, J., and Rogers, A. </author> <booktitle> Where is Time Spent in Message-Passing and Shared Memory Programs? In Proceedings of the 6th Symposium on Architectural Support for Programming Languages and Operating Systems (Oct. </booktitle> <year> 1994), </year> <pages> pp. 61-73. </pages>
Reference-contexts: Radix is run with the default arguments, except that the number of keys is set to 1048576. The amount of space mapped is 8437760 bytes in length, and requires 14 superpages. Em3d performs three dimensional modeling of electromagnetic wave propagation. The particular version used here <ref> [3] </ref> is a message passing version run on a single processor. The runs reported here model 6000 nodes and use 4.5MB of dynamically allocated space, which is remapped using 16 superpages. Gcc is actually the cc1 pass of the version 2.5.3 gcc compiler for the Sparc architecture, also from Spec95.
Reference: [4] <author> Chen, J. B., Borg, A., and Jouppi, N. P. </author> <title> A Simulation Based Study of TLB Performance. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture (May 1992), </booktitle> <pages> pp. 114-123. </pages> <note> [5] et al, </note> <author> J. E. </author> <title> Internal Organization of the Alpha 21164, a 300-MHz 64-bit Quad-issue CMOS RISC Microprocessor. </title>
Reference: [6] <author> Gwennap, L. </author> <title> HP Pumps Up PA-8x00 Family. </title> <type> Microprocessor Report 10, </type> <month> 14 (October </month> <year> 1994). </year>
Reference-contexts: The small reach of the PA8000 TLB was a sufficiently serious performance bottleneck for many commercial applications that HP increased the TLB size to 120 entries for its next generation PA 8200 <ref> [6] </ref>. Even with 120 entries, however, the PA8200 TLB reach is still only 480 kilobytes when 4-kilobyte pages are used, less than half the size of the L1 cache. <p> the cost of cache flushing is quite modest, averaging 1400 CPU cycles per 4KB page. 3.4 Basic Results In this section, we compare the performance of systems with and without MTLBs for a range of reasonable CPU TLB sizes, selected because they correspond to TLBs in very recent high-end processors <ref> [8, 6] </ref>. The cache size is fixed at 512KB for all of these runs. The MTLB, when present, is configured with 128 entries, is 2-way set associative, and employs a not-recently-used replacement algorithm. The simulated MTLB does not write back updated reference/modification information into its mapping table.
Reference: [7] <author> Hotchkiss, T., Marschke, N., and McClosky, R. </author> <title> A New Memory System Design for Com mercial and Technical Computing Products. </title> <journal> Hewlett-Packard Journal 47, </journal> <month> 1 (February </month> <year> 1996), </year> <pages> 44-51. </pages>
Reference-contexts: The bus modeled is HP's Runway bus [2] clocked at 120 MHZ. The main memory controller (MMC) is similar to HP's memory controller <ref> [7] </ref> used in its HP 9000 J and K-class commercial servers and high end workstations. The instruction cache is assumed to be perfect. The data cache model employs a single level, direct mapped, 512-kilobyte, virtually indexed, physically tagged cache, similar to that used with the HP PA8000 [11].
Reference: [8] <author> Intel Corporation. </author> <title> Pentium Pro Family Developer's Manual, </title> <month> January </month> <year> 1996. </year>
Reference-contexts: the cost of cache flushing is quite modest, averaging 1400 CPU cycles per 4KB page. 3.4 Basic Results In this section, we compare the performance of systems with and without MTLBs for a range of reasonable CPU TLB sizes, selected because they correspond to TLBs in very recent high-end processors <ref> [8, 6] </ref>. The cache size is fixed at 512KB for all of these runs. The MTLB, when present, is configured with 128 entries, is 2-way set associative, and employs a not-recently-used replacement algorithm. The simulated MTLB does not write back updated reference/modification information into its mapping table.
Reference: [9] <author> J.Huck, and Hays, J. </author> <title> Architectural Support for Translation Table Management in Large Ad dress Space Machines. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture (June 1993), </booktitle> <pages> pp. 39-50. </pages>
Reference-contexts: Misses are handled by a trap routine that employs a 16K entry virtual-to-physical hash table. Each entry is 16 bytes (half of a cache line) in length. The table structure used is the hashed page table model commonly used on HP PA-RISC architectures <ref> [9] </ref>. In addition to the main TLB, a single-entry micro-ITLB holding the most recent instruction translation is also modeled.
Reference: [10] <author> Jouppi, N. </author> <title> Improving direct-mapped cache performance by the addition of a small fully associative cache and prefetch buffers. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture (May 1990), </booktitle> <pages> pp. 364-373. </pages>
Reference-contexts: In the future, we intend to investigate several ways to further exploit the existence of shadow memory and an MTLB. We are currently exploring ways to use shadow memory to implement no-copy page recoloring [1] and MMC-provided stream buffers <ref> [10, 12] </ref>. In addition, we continuing to investigate whether swapping of base pages within a superpage can be supported in the context of current CPU/memory interface limitations. We also are investigating the space of practical MTLB implementations to determine what organizations and latencies are feasible.
Reference: [11] <author> Kane, G. PA-RISC 2.0 Architecture, </author> <year> 1996. </year>
Reference-contexts: Unfortunately, the small size of typical pages combined with the small size of typical TLBs severely limits the reach of typical systems. For example, the HP PA8000 <ref> [11] </ref> supports a 96-entry unified instruction/data TLB. When used with a fixed page size of 4 kilobytes, the resulting TLB reach is only 384 kilobytes. <p> Starting in the early 1990's, processor architectures began to support TLBs that allow each entry to be independently configured to map variable-sized superpages <ref> [13, 11, 5] </ref>. Super-pages are constrained to be a power of 2 multiple of some base page size aligned on a multiple of the superpage size. <p> Super-pages are constrained to be a power of 2 multiple of some base page size aligned on a multiple of the superpage size. In the SGI R10000 [13] and HP PA-RISC 2.0 <ref> [11] </ref>, the base page size is 4 kilobytes, and superpages range in multiples of powers of 4 from 16KB to a maximum of 16MB or 64MB. <p> A larger size allows the MTLB to adopt a less aggressive structure than the full associa tivity that is standard in many processor TLBs <ref> [11, 13, 5] </ref>. A typical MTLB-enabled system might provide on the order of 512 megabytes of shadow virtual address space, enough to map three orders of magnitude more memory than a typical processor TLB. <p> The instruction cache is assumed to be perfect. The data cache model employs a single level, direct mapped, 512-kilobyte, virtually indexed, physically tagged cache, similar to that used with the HP PA8000 <ref> [11] </ref>. Cache lines are 32 bytes, hits are handled in a single cycle, and the cache is non-blocking and writeback. The CPU TLBs modeled are all unified I/D, single-cycle, fully associative, and employ a not-recently-used replacement policy.
Reference: [12] <author> McKee, S., and Wulf, W. </author> <title> Access Ordering and Memory-Conscious Cache Utilization. </title> <booktitle> In Proceedings of the First Annual Symposium on High Performance Computer Architecture (Jan. </booktitle> <year> 1995), </year> <pages> pp. 253-262. </pages>
Reference-contexts: In the future, we intend to investigate several ways to further exploit the existence of shadow memory and an MTLB. We are currently exploring ways to use shadow memory to implement no-copy page recoloring [1] and MMC-provided stream buffers <ref> [10, 12] </ref>. In addition, we continuing to investigate whether swapping of base pages within a superpage can be supported in the context of current CPU/memory interface limitations. We also are investigating the space of practical MTLB implementations to determine what organizations and latencies are feasible.
Reference: [13] <institution> MIPS Technologies Inc. </institution> <note> MIPS R10000 Microprocessor User's Manual, Version 2.0, </note> <month> December </month> <year> 1996. </year>
Reference-contexts: Starting in the early 1990's, processor architectures began to support TLBs that allow each entry to be independently configured to map variable-sized superpages <ref> [13, 11, 5] </ref>. Super-pages are constrained to be a power of 2 multiple of some base page size aligned on a multiple of the superpage size. <p> Super-pages are constrained to be a power of 2 multiple of some base page size aligned on a multiple of the superpage size. In the SGI R10000 <ref> [13] </ref> and HP PA-RISC 2.0 [11], the base page size is 4 kilobytes, and superpages range in multiples of powers of 4 from 16KB to a maximum of 16MB or 64MB. <p> A larger size allows the MTLB to adopt a less aggressive structure than the full associa tivity that is standard in many processor TLBs <ref> [11, 13, 5] </ref>. A typical MTLB-enabled system might provide on the order of 512 megabytes of shadow virtual address space, enough to map three orders of magnitude more memory than a typical processor TLB.
Reference: [14] <author> M.Talluri, and Hill, M. </author> <title> Surpassing the TLB Performance of Superpages with Less Operating System Support. </title> <booktitle> In Proceedings of the 6th Symposium on Architectural Support for Programming Languages and Operating Systems (Oct. </booktitle> <year> 1994), </year> <pages> pp. 171-182. </pages>
Reference-contexts: Three of the most serious problems associated with general utilization of superpages are (i) the requirement that they be used only to map regions of physical memory that are appropriately sized, aligned, and contiguous <ref> [14] </ref>; (ii) the difficulty associated with determining 1 SGI's IRIX6.4 appears to be the first commercially available OS with such support. Even on the SGI machines, support for superpages for user memory appears to be limited to their NUMA systems.
Reference: [15] <author> M.Talluri, Kong, S., Hill, M., and Patterson, D. </author> <title> Tradeoffs in Supporting Two Page Sizes. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture (May 1992), </booktitle> <pages> pp. 415-424. </pages>
Reference: [16] <author> Perl, S. E., and Sites, R. </author> <title> Studies of Windows NT Performance Using Dynamic Execution Traces. </title> <booktitle> In Proceedings of the Second Symposium on Operating System Design and Implementation (October 1996), </booktitle> <pages> pp. 169-184. </pages>
Reference-contexts: These results demonstrate the potential of the proposed mechanism. It is likely to be even more effective on applications with significantly larger working sets and worse spatial locality, such as is often found in large databases and other commercially important applications <ref> [16] </ref>. The rest of the paper is organized as follows. In Section 2 we present in more detail the proposed functionality, including detailed descriptions of the extra MMC translation hardware and the modest support required from the operating system's VM software.
Reference: [17] <author> Romer, T. H., Ohrlich, W. H., Karlin, A. R., and Bershad, B. </author> <title> Reducing TLB and Memory Overhead Using Online Superpage Promotion. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture (June 1995), </booktitle> <pages> pp. 176-187. </pages>
Reference-contexts: These machines are primarily used as batch-like compute servers where applications are carefully sized to fit in memory so as to optimize performance. On such systems, paging is designed to be an infrequent event. 2 for which regions they are suitable and economical <ref> [17] </ref>, and (iii) the need for the OS to swap entire superpages on and off disk if paging is required. In this paper, we present a mechanism that addresses problems (i) and (iii) directly, and by changing the economics of using superpages, reduces the importance of problem (ii). <p> They propose subblock TLBs as a way to mitigate some of the cost of solving these problems in the OS' virtual memory system. Romer et al <ref> [17] </ref> address the problem of selecting regions that can effectively benefit from mapping via superpages.
Reference: [18] <author> Woo, S., Ohara, M., Torrie, E., Singh, J., and Gupta, A. </author> <title> The SPLASH-2 Programs: Char acterization and Methodological Considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture (June 1995), </booktitle> <pages> pp. 24-36. 19 </pages>
Reference-contexts: We measure vortex with a slightly modified Spec95 training run, which dynamically 11 allocates approximately 18 MB over the course of the run. Radix is a sort program from the Splash2 benchmarks <ref> [18] </ref>. Its primary data structures are all dynamically allocated at the beginning of the program. We map the entire dynamically allocated space after the allocations are complete and before the larger structures are initialized.
References-found: 17

