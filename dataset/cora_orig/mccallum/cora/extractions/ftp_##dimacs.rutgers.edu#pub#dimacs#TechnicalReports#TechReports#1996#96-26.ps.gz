URL: ftp://dimacs.rutgers.edu/pub/dimacs/TechnicalReports/TechReports/1996/96-26.ps.gz
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1996.html
Root-URL: http://www.cs.rutgers.edu
Title: by  
Author: Michael Saks ; Aravind Srinivasan ; Shiyu Zhou ; 
Note: Explicit OR-Dispersers with Polylogarithmic Degree 1  DIMACS is a partnership of Rutgers University, Princeton University, AT&T Research, Bellcore, and Bell Laboratories. DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receives support from the New Jersey Commission on Science and Technology.  
Abstract: DIMACS Technical Report 96-26 1 The first and third authors were supported in part by NSF grant CCR-9215293. The second author was supported in part by grant 93-6-6 of the Alfred P. Sloan Foundation to the Institute for Advanced Study, and in part by ESPRIT Basic Research Action Programme of the EC under contract No. 7141 (project ALCOM II). All three authors were also supported in part by DIMACS (Center for Discrete Mathematics & Theoretical Computer Science), through NSF grant NSF-STC91-19999 and by the New Jersey Commission on Science and Technology. A preliminary version of this paper appeared in the proceedings of the 27th ACM Symposium on Theory of Computing, 1995. 2 Department of Mathematics, Rutgers University, New Brunswick, NJ 08854, USA. E-mail: saks@math.rutgers.edu. 3 Department of Information Systems and Computer Science, National University of Singapore, Sin-gapore 119260. Parts of this work were done: (i) at the National University of Singapore, (ii) at the School of Mathematics, Institute for Advanced Study, Princeton, NJ 08540, USA, (iii) at DIMACS, (iv) while visiting the Department of Applied Mathematics and Computer Science, Weizmann Institute of Science, Rehovot 76100, Israel, and (v) while visiting the Department of Computer Science, University of Warwick, Coventry CV4 7AL, UK. E-mail: aravind@iscs.nus.sg. 4 Department of Computer Science, Rutgers University, New Brunswick, NJ 08854, USA. E-mail: szhou@cs.rutgers.edu. 
Abstract-found: 1
Intro-found: 1
Reference: [Blu86] <author> M. Blum, </author> <title> "Independent Unbiased Coin Flips from a Correlated Biased Source: a Finite Markov Chain," </title> <journal> Combinatorica, </journal> <volume> 6(2): </volume> <pages> 97-108, </pages> <year> 1986. </year>
Reference-contexts: For example, von Neumann [Neu63] presented a technique to convert - 5 - independent but biased coin-flips into independent and unbiased ones; Blum <ref> [Blu86] </ref> showed how to convert the bits output by an unknown Markov chain into a sequence of perfectly random bits. However, for more general faulty sources, it can be shown (see e.g. [SV86]) that to construct such a direct conversion f is impossible.
Reference: [CG88] <author> B. Chor and O. Goldreich, </author> <title> "Unbiased Bits from Sources of Weak Randomness and Probabilistic Communication Complexity," </title> <journal> SIAM J. Comput., </journal> <volume> 17(2) </volume> <pages> 230-261, </pages> <year> 1988. </year>
Reference-contexts: For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in [VV85, Vaz86, Vaz87a, Vaz87b]. A more general model "PRB-sources" is considered later by Chor and Goldreich <ref> [CG88] </ref>. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [CW89] <author> A. Cohen and A. Wigderson, "Dispersers, </author> <title> Deterministic Amplification, and Weak Random Sources," </title> <booktitle> Proc. IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 14-19. </pages>
Reference-contexts: 1 Introduction A disperser is a type of expander which was first introduced by Sipser in [Sip88]. Cohen and Wigderson <ref> [CW89] </ref> classified dispersers into two types: OR-dispersers and MAJORITY-dispersers. <p> For the case where ffi is a fixed positive constant, Zuckerman [Zuc91, Zuc96] showed - 6 - how to simulate any BPP algorithm efficiently with ffi-sources. What about sources whose entropy rate decreases with R: how weak can the source get and still be usable for efficient simulations? In <ref> [CW89] </ref>, it was observed that, for information-theoretic reasons, if S is any class of sources for which there is an efficient black-box simulation of RP or BPP (that works correctly with high probability) using any source S 2 S, then every source S must be close to a ffi-source with ffi <p> which takes time m O (logm) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in [TaS96], where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) In <ref> [San87, Sip88, CW89] </ref> it was observed that the black-box simulation described above can be defined by a sequence G m = (V m ; W m ; E m ) of bipartite multigraphs, one for each m, where V m = f0; 1g R (m) and W m = f0; 1g
Reference: [FLW92] <author> A. M. Ferrenberg, D. P. Landau, and Y. J. Wong, </author> <title> "Monte Carlo simulations: Hidden errors from "good" random number generators," </title> <journal> Physical Review Letters, </journal> <volume> 69(23) </volume> <pages> 3382-3384, </pages> <year> 1992. </year>
Reference-contexts: Empirically, this often seems to be sufficient. However, there are reports of algorithms giving quite different results under different pseudo-random generators (see e.g., <ref> [FLW92] </ref> for such reports on Monte-Carlo simulations, and [Hsu93, HRD94] for the deviant performance of some RN C algorithms for graph problems). An alternative approach is to use the output of some physical source of randomness, such as a Zener diode, or the last digits of a real-time clock.
Reference: [FN93] <author> A. Fiat and M. Naor, </author> <title> "Implicit O(1) probe search," </title> <journal> SIAM J. Comput., </journal> <volume> 22 </volume> <pages> 1-10, </pages> <year> 1993. </year>
Reference-contexts: For example, it gives improvements on the expander construction and the consequent applications given in [WZ93], on the the hardness results of approximating the clique function [Zuc93, SZ94], and on the results for a problem in data structures: implicit O (1) probe search <ref> [FN93, Zuc91] </ref>. These consequences were each observed by previous researchers, and provided much of the motivation for the search for good dispersers. The details of these improvements can be derived from the corresponding original papers by plugging in our construction, and will not be given here.
Reference: [HRD94] <author> T.-s. Hsu, V. Ramachandran, and N. Dean, </author> <title> "Parallel implementation of algorithms for finding connected components," </title> <booktitle> Proc. DIMACS International Algorithm Implementation Challenge, </booktitle> <year> 1994, </year> <pages> pp. 1-14. </pages>
Reference-contexts: Empirically, this often seems to be sufficient. However, there are reports of algorithms giving quite different results under different pseudo-random generators (see e.g., [FLW92] for such reports on Monte-Carlo simulations, and <ref> [Hsu93, HRD94] </ref> for the deviant performance of some RN C algorithms for graph problems). An alternative approach is to use the output of some physical source of randomness, such as a Zener diode, or the last digits of a real-time clock.
Reference: [Hsu93] <author> T.-s. Hsu, </author> <title> "Graph augmentation and related problems: theory and practice," </title> <type> PhD thesis, </type> <institution> Department of Computer Sciences, University of Texas at Austin, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: Empirically, this often seems to be sufficient. However, there are reports of algorithms giving quite different results under different pseudo-random generators (see e.g., [FLW92] for such reports on Monte-Carlo simulations, and <ref> [Hsu93, HRD94] </ref> for the deviant performance of some RN C algorithms for graph problems). An alternative approach is to use the output of some physical source of randomness, such as a Zener diode, or the last digits of a real-time clock.
Reference: [IZ89] <author> R. Impagliazzo and D. Zuckerman, </author> <title> "How to Recycle Random Bits", </title> <booktitle> Proc. 30th Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 248-253. - 29 </pages> - 
Reference: [ILL89] <author> R. Impagliazzo, L. Levin, and M. Luby, </author> <title> "Pseudo-Random Generation from One-Way Functions," </title> <booktitle> Proc. ACM Symposium on Theory of Computing, </booktitle> <year> 1989, </year> <pages> pp. 12-24. </pages>
Reference: [Neu63] <author> J. von Neumann, </author> <title> "Various techniques for use in connection with random digits", </title> <booktitle> in von Neumann's Collected works, </booktitle> <pages> pp 768-770, </pages> <address> Pergaman, New York, </address> <year> 1963. </year>
Reference-contexts: For example, von Neumann <ref> [Neu63] </ref> presented a technique to convert - 5 - independent but biased coin-flips into independent and unbiased ones; Blum [Blu86] showed how to convert the bits output by an unknown Markov chain into a sequence of perfectly random bits.
Reference: [Nis96] <author> N. Nisan, </author> <title> "Extracting Randomness: How and Why", </title> <booktitle> Proc. IEEE Conference on Computational Complexity (formerly "Structure in Complexity Theory"), </booktitle> <year> 1996, </year> <pages> pp. 44-58. </pages>
Reference-contexts: The details of these improvements can be derived from the corresponding original papers by plugging in our construction, and will not be given here. We refer the reader to a comprehensive survey paper by Nisan <ref> [Nis96] </ref>. 1.1 The Equivalence of RP and Strong-RP Definition 1.1 Random polynomial time (RP) is the set of languages L f0; 1g fl such that there is a deterministic polynomial-time Turing machine M L (; ) for which x 2 L ! P r [M L (x; y) accepts] &gt; 1=2;
Reference: [NZ93] <author> N. Nisan and D. Zuckerman, </author> <title> "More Deterministic Simulation in Logspace," </title> <booktitle> Proc. ACM Symposium on Theory of Computing, </booktitle> <year> 1993, </year> <pages> pp. 235-244. </pages>
Reference-contexts: For this discussion, let us assume V = f0; 1g n ; n = log N and W = f0; 1g m ; m = log M , and that N; M; T are related as in the Main Theorem. Building on the ideas developed in <ref> [NZ93] </ref> and [SZ94], our construction G D = (V; W; E) of an (N; M; T )- disperser with degree polylogarithmic in N is obtained by composing two bipartite graphs. Let Z = f0; 1g sn where s = a log n for some constant a. <p> The family F C of functions mapping Z to W that specifies carrier G C is obtained by adjusting parameters in the "block-wise extractor" as presented in [SZ94], which is in turn an improvement on a similar construction in <ref> [NZ93] </ref>. Generally speaking, a block-wise extractor is a function taking two input strings z and y such that if z comes from a block-wise source and y from a pure random source, then the distribution induced on the output of the function is nearly uniform. <p> Intuitively, to convert an arbitrary distribution D into a block-wise source we want to "chop up" the sequence of bits from D into a sequence of blocks so that each block has a sufficient amount of information relative to D. As in <ref> [NZ93] </ref>, the good bit indicator is an appropriate way to measure the dispersal of information within any string from the source. <p> It turns out that the analysis in the later sections will be simplified if we know that D is a smooth source. The next lemma, basically from <ref> [NZ93] </ref>, says that any source is close to a smooth source with almost the same min-entropy. <p> The proof we present is a variant of the correctness proof of the extractor (Function C) in <ref> [NZ93] </ref>. In Section 4.2 we defined the parameters t s = 32 and q = p s = 4t s + d6 log ne (thus q = O (log n)).
Reference: [San87] <author> M. Santha, </author> <title> "On Using Deterministic Functions in Probabilistic Algorithms," </title> <journal> Information and Computation, </journal> <volume> 74(3): </volume> <pages> 241-249, </pages> <year> 1987. </year>
Reference-contexts: In this paper we investigate the problem of efficiently constructing OR-dispersers with small degree. For convenience, we will use the term "disperser" instead of "OR-disperser" unless otherwise specified. It was proved in <ref> [San87] </ref> by a probabilistic argument that there exist (N; M; T )-dispersers for N &gt; T = M with degree at most log 2 N + 2. <p> which takes time m O (logm) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in [TaS96], where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) In <ref> [San87, Sip88, CW89] </ref> it was observed that the black-box simulation described above can be defined by a sequence G m = (V m ; W m ; E m ) of bipartite multigraphs, one for each m, where V m = f0; 1g R (m) and W m = f0; 1g
Reference: [SV86] <author> M. Santha and U. Vazirani, </author> <title> "Generating Quasi-Random Sequences from Slightly Random Sources," </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33 </volume> <pages> 75-87, </pages> <year> 1986. </year>
Reference-contexts: However, for more general faulty sources, it can be shown (see e.g. <ref> [SV86] </ref>) that to construct such a direct conversion f is impossible. On the other hand, the following broader idea of conversion (introduced in [VV85, Vaz86]) works for simulating randomized algorithms: Suppose the randomized computation C we wish to simulate needs m random bits. <p> The high-level structure of this simulation is common to all subsequent work in this area. We refer to such a simulation as a "black-box" simulation. Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani <ref> [SV86] </ref> studied the class of weak sources called "slightly random sources", which was further examined in [VV85, Vaz86, Vaz87a, Vaz87b]. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models.
Reference: [Sip88] <author> M. Sipser, "Expanders, </author> <title> Randomness, or Time versus Space," </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36: </volume> <pages> 379-383, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction A disperser is a type of expander which was first introduced by Sipser in <ref> [Sip88] </ref>. Cohen and Wigderson [CW89] classified dispersers into two types: OR-dispersers and MAJORITY-dispersers. <p> We call W x L = fy 2 f0; 1g m jM L (x; y) acceptsg the witness set of M L on input x, where m is the number of random bits used by M L on inputs of length jxj. Sipser <ref> [Sip88] </ref> defined the complexity class strong random polynomial time (Strong-RP) to be the class of languages L for which there is an RP machine M L (; ) and a real number 0 &lt; &lt; 1 such that on input a string x 2 L of (any) length n, M L <p> The construction we give here is sufficient for Sipser's purposes and so we obtain Theorem 1.1 RP = Strong-RP. Proof: The argument in this proof is essentially the same as in Sipser's original paper <ref> [Sip88] </ref>. We show the proof here for later reference. It is immediate that Strong-RP RP; we now show that RP Strong-RP. Suppose we have an RP machine M L that needs m random bits on an input x 2 L of length n, for some m polynomial in n. <p> which takes time m O (logm) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in [TaS96], where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) In <ref> [San87, Sip88, CW89] </ref> it was observed that the black-box simulation described above can be defined by a sequence G m = (V m ; W m ; E m ) of bipartite multigraphs, one for each m, where V m = f0; 1g R (m) and W m = f0; 1g
Reference: [SZ94] <author> A. Srinivasan and D. Zuckerman, </author> <title> "Computing with Very Weak Random Sources", </title> <booktitle> Proc. IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1994, </year> <pages> pp. 264-275. </pages> <note> Full version available as Technical Report TRA4/96, </note> <institution> Department of Information Systems and Computer Science, National University of Singapore, </institution> <month> April </month> <year> 1996. </year>
Reference-contexts: In fact, most of the previous disperser constructions are implicit in the work of simulating randomized algorithms using weak sources. The best previously known constructions are due to Zuckerman [Zuc91, Zuc96], who achieved degree polylogarithmic in N if N = T O (1) , and Srinivasan and Zuckerman <ref> [SZ94] </ref>, whose construction works for N = 2 polylog (T ) but requires degree (log N ) O (log log N) . In recent work that was inspired in part by a preliminary version of the present paper, Ta-Shma [TaS96] improved the degree of the construction in [SZ94] to (log N <p> Srinivasan and Zuckerman <ref> [SZ94] </ref>, whose construction works for N = 2 polylog (T ) but requires degree (log N ) O (log log N) . In recent work that was inspired in part by a preliminary version of the present paper, Ta-Shma [TaS96] improved the degree of the construction in [SZ94] to (log N ) O (log (k) log N) for any fixed integer k, where log (k) denotes the logarithm to the base 2 iterated k times (i.e., log (1) x = log 2 x, log (2) x = log 2 log 2 x, etc.). <p> It is worth noticing that although the constructions of [Zuc91], <ref> [SZ94] </ref> and [TaS96] do not give polylogarithmic degree, they do give MAJORITY-dispersers. Unfortunately, we could not strengthen our construction to give a MAJORITY-disperser. <p> There are other consequences of our disperser construction. For example, it gives improvements on the expander construction and the consequent applications given in [WZ93], on the the hardness results of approximating the clique function <ref> [Zuc93, SZ94] </ref>, and on the results for a problem in data structures: implicit O (1) probe search [FN93, Zuc91]. These consequences were each observed by previous researchers, and provided much of the motivation for the search for good dispersers. <p> The question is: for each &gt; 0, is there a polynomial-time simulation of BPP, or even RP, that works for all -minimally random sources? The previously best known simulation for RP with -minimally random sources is due to <ref> [SZ94] </ref>, which takes time m O (logm) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in [TaS96], where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) In <p> For this discussion, let us assume V = f0; 1g n ; n = log N and W = f0; 1g m ; m = log M , and that N; M; T are related as in the Main Theorem. Building on the ideas developed in [NZ93] and <ref> [SZ94] </ref>, our construction G D = (V; W; E) of an (N; M; T )- disperser with degree polylogarithmic in N is obtained by composing two bipartite graphs. Let Z = f0; 1g sn where s = a log n for some constant a. <p> Carrier G C is similarly specified by a family F C of functions. The family F C of functions mapping Z to W that specifies carrier G C is obtained by adjusting parameters in the "block-wise extractor" as presented in <ref> [SZ94] </ref>, which is in turn an improvement on a similar construction in [NZ93]. <p> Generally speaking, a block-wise extractor is a function taking two input strings z and y such that if z comes from a block-wise source and y from a pure random source, then the distribution induced on the output of the function is nearly uniform. By modifying the construction in <ref> [SZ94] </ref>, we obtain a block-wise extractor C such that on input a string z coming from any block-wise source on Z with s equal-sized blocks and with block-wise min-entropy nearly log T , and a purely random string y of length O (log n), the distribution induced on C (z; y) <p> The function C is a straightforward modification of the block-wise extractor of <ref> [SZ94] </ref>. To describe the construction, we need the following Improved Leftover Hash Lemma, which is presented as Corollary 3.4 in the full version of [SZ94]: Lemma 4.1 Let t n be nonnegative integers, D be an n-bit source of min-entropy t, k &gt; 0, and * 2 1k . <p> The function C is a straightforward modification of the block-wise extractor of <ref> [SZ94] </ref>. To describe the construction, we need the following Improved Leftover Hash Lemma, which is presented as Corollary 3.4 in the full version of [SZ94]: Lemma 4.1 Let t n be nonnegative integers, D be an n-bit source of min-entropy t, k &gt; 0, and * 2 1k . <p> Acknowledgements. Aravind Srinivasan thanks David Zuckerman for their past joint work <ref> [SZ94] </ref>, through which he could learn from David's deep understanding of computing with imperfect sources of randomness. Shiyu Zhou would like to thank Endre Szemeredi for introducing him to this subject.
Reference: [TaS96] <author> A. Ta-Shma, </author> <title> "On extracting randomness from weak random sources", </title> <booktitle> Proc. ACM Symposium on Theory of Computing, </booktitle> <year> 1996, </year> <pages> pp. 276-285. </pages>
Reference-contexts: In recent work that was inspired in part by a preliminary version of the present paper, Ta-Shma <ref> [TaS96] </ref> improved the degree of the construction in [SZ94] to (log N ) O (log (k) log N) for any fixed integer k, where log (k) denotes the logarithm to the base 2 iterated k times (i.e., log (1) x = log 2 x, log (2) x = log 2 log <p> It is worth noticing that although the constructions of [Zuc91], [SZ94] and <ref> [TaS96] </ref> do not give polylogarithmic degree, they do give MAJORITY-dispersers. Unfortunately, we could not strengthen our construction to give a MAJORITY-disperser. <p> for all -minimally random sources? The previously best known simulation for RP with -minimally random sources is due to [SZ94], which takes time m O (logm) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in <ref> [TaS96] </ref>, where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) In [San87, Sip88, CW89] it was observed that the black-box simulation described above can be defined by a sequence G m = (V m ; W m ; E m ) of
Reference: [Vaz86] <author> U. Vazirani, </author> <title> "Randomness, Adversaries and Computation," </title> <type> Ph.D. Thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1986. </year>
Reference-contexts: However, for more general faulty sources, it can be shown (see e.g. [SV86]) that to construct such a direct conversion f is impossible. On the other hand, the following broader idea of conversion (introduced in <ref> [VV85, Vaz86] </ref>) works for simulating randomized algorithms: Suppose the randomized computation C we wish to simulate needs m random bits. The simulation first requests R = R (m) bits from the faulty source. <p> Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in <ref> [VV85, Vaz86, Vaz87a, Vaz87b] </ref>. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [Vaz87a] <author> U. Vazirani, </author> <title> "Efficiency Considerations in Using Semi-Random Sources," </title> <booktitle> Proc. ACM Symposium on Theory of Computing, </booktitle> <year> 1987, </year> <pages> pp. 160-168. </pages>
Reference-contexts: Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in <ref> [VV85, Vaz86, Vaz87a, Vaz87b] </ref>. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [Vaz87b] <author> U. Vazirani, </author> <title> "Strong Communication Complexity or Generating Quasi-Random Sequences from Two Communicating Semi-Random Sources," </title> <journal> Combinatorica, </journal> <volume> 7 (4): </volume> <pages> 375-392, </pages> <year> 1987. </year>
Reference-contexts: Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in <ref> [VV85, Vaz86, Vaz87a, Vaz87b] </ref>. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [VV85] <author> U. Vazirani and V. Vazirani, </author> <title> "Random Polynomial Time is Equal to Slightly-Random Polynomial Time," </title> <booktitle> Proc. IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1985, </year> <pages> pp. 417-428. </pages> <note> See also U. </note> <author> Vazirani and V. Vazirani, </author> <title> "Random polynomial time is equal to semi-random polynomial time", </title> <type> Technical Report 88-959, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1988. </year> <month> - 30 </month> - 
Reference-contexts: However, for more general faulty sources, it can be shown (see e.g. [SV86]) that to construct such a direct conversion f is impossible. On the other hand, the following broader idea of conversion (introduced in <ref> [VV85, Vaz86] </ref>) works for simulating randomized algorithms: Suppose the randomized computation C we wish to simulate needs m random bits. The simulation first requests R = R (m) bits from the faulty source. <p> Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in <ref> [VV85, Vaz86, Vaz87a, Vaz87b] </ref>. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [WZ93] <author> A. Wigderson and D. Zuckerman, </author> <title> "Expanders that Beat the Eigenvalue Bound: Explicit Construction and Applications," </title> <booktitle> Proc. ACM Symposium on Theory of Computing, </booktitle> <year> 1993, </year> <pages> pp. 245-251. </pages>
Reference-contexts: There are other consequences of our disperser construction. For example, it gives improvements on the expander construction and the consequent applications given in <ref> [WZ93] </ref>, on the the hardness results of approximating the clique function [Zuc93, SZ94], and on the results for a problem in data structures: implicit O (1) probe search [FN93, Zuc91]. These consequences were each observed by previous researchers, and provided much of the motivation for the search for good dispersers.
Reference: [Zuc90] <author> D. Zuckerman, </author> <title> "General Weak Random Sources," </title> <booktitle> Proc. IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1990, </year> <pages> pp. 534-543. </pages>
Reference-contexts: For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in [VV85, Vaz86, Vaz87a, Vaz87b]. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In <ref> [Zuc90, Zuc91] </ref>, Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [Zuc91] <author> D. Zuckerman, </author> <title> "Simulating BPP Using a General Weak Random Source," </title> <booktitle> Proc. IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1991, </year> <pages> pp. 79-89. </pages> <note> Final version to appear in Algorithmica (copies available on request from the author). </note>
Reference-contexts: In fact, most of the previous disperser constructions are implicit in the work of simulating randomized algorithms using weak sources. The best previously known constructions are due to Zuckerman <ref> [Zuc91, Zuc96] </ref>, who achieved degree polylogarithmic in N if N = T O (1) , and Srinivasan and Zuckerman [SZ94], whose construction works for N = 2 polylog (T ) but requires degree (log N ) O (log log N) . <p> It is worth noticing that although the constructions of <ref> [Zuc91] </ref>, [SZ94] and [TaS96] do not give polylogarithmic degree, they do give MAJORITY-dispersers. Unfortunately, we could not strengthen our construction to give a MAJORITY-disperser. <p> For example, it gives improvements on the expander construction and the consequent applications given in [WZ93], on the the hardness results of approximating the clique function [Zuc93, SZ94], and on the results for a problem in data structures: implicit O (1) probe search <ref> [FN93, Zuc91] </ref>. These consequences were each observed by previous researchers, and provided much of the motivation for the search for good dispersers. The details of these improvements can be derived from the corresponding original papers by plugging in our construction, and will not be given here. <p> For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in [VV85, Vaz86, Vaz87a, Vaz87b]. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In <ref> [Zuc90, Zuc91] </ref>, Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X. <p> Any source is a 0-source, and a 1-source is the pure random source. In general, the smaller that ffi gets, the weaker (stochastically) the source can be. For the case where ffi is a fixed positive constant, Zuckerman <ref> [Zuc91, Zuc96] </ref> showed - 6 - how to simulate any BPP algorithm efficiently with ffi-sources.
Reference: [Zuc93] <author> D. Zuckerman, </author> <title> "NP-complete problems have a version that's hard to approximate," </title> <booktitle> Proc. IEEE Conference on Structure in Complexity Theory, </booktitle> <year> 1993, </year> <pages> pp. 305-312. </pages>
Reference-contexts: There are other consequences of our disperser construction. For example, it gives improvements on the expander construction and the consequent applications given in [WZ93], on the the hardness results of approximating the clique function <ref> [Zuc93, SZ94] </ref>, and on the results for a problem in data structures: implicit O (1) probe search [FN93, Zuc91]. These consequences were each observed by previous researchers, and provided much of the motivation for the search for good dispersers.
Reference: [Zuc96] <author> D. Zuckerman, </author> <title> "Randomness-optimal sampling, extractors and constructive leader election", </title> <booktitle> Proc. ACM Symposium on Theory of Computing, </booktitle> <year> 1996, </year> <pages> pp. 286-295. </pages>
Reference-contexts: In fact, most of the previous disperser constructions are implicit in the work of simulating randomized algorithms using weak sources. The best previously known constructions are due to Zuckerman <ref> [Zuc91, Zuc96] </ref>, who achieved degree polylogarithmic in N if N = T O (1) , and Srinivasan and Zuckerman [SZ94], whose construction works for N = 2 polylog (T ) but requires degree (log N ) O (log log N) . <p> Any source is a 0-source, and a 1-source is the pure random source. In general, the smaller that ffi gets, the weaker (stochastically) the source can be. For the case where ffi is a fixed positive constant, Zuckerman <ref> [Zuc91, Zuc96] </ref> showed - 6 - how to simulate any BPP algorithm efficiently with ffi-sources.
References-found: 26

