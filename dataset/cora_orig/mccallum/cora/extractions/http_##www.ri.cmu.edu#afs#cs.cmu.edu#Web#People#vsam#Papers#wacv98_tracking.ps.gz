URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/People/vsam/Papers/wacv98_tracking.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/Web/People/vsam/iubapage.html
Root-URL: 
Email: email: fajljhironobujrajug@cs.cmu.edu  
Title: Moving target classification and tracking from real-time video  
Author: Alan J. Lipton Hironobu Fujiyoshi Raju S. Patil 
Web: URL: http://www.cs.cmu.edu/~ vsam  
Address: 5000 Forbes Avenue, Pittsburgh, PA, 15213  
Affiliation: The Robotics Institute. Carnegie Mellon University  
Abstract: This paper describes an end-to-end method for extracting moving targets from a real-time video stream, classifying them into predefined categories according to image-based properties, and then robustly tracking them. Moving targets are detected using the pixelwise difference between consecutive image frames. A classi-ficatoin metric is applied these targets with a temporal consistency constraint to classify them into three categories: human, vehicle or background clutter. Once classified, targets are tracked by a combination of temporal differencing and template matching. The resulting system robustly identifies targets of interest, rejects background clutter, and continually tracks over large distances and periods of time despite occlusions, appearance changes and cessation of target motion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Kanade, R. Collins, A. Lipton, P. Anandan, P. </author> <booktitle> Burt "Cooperative Multisensor Video Surveillance" Proceedings of DARPA Image Understanding Workshop 1997, </booktitle> <volume> Vol. I, </volume> <pages> pp. 3-10, </pages> <year> 1997. </year>
Reference-contexts: 1 Introduction The increasing availability of video sensors and high performance video processing hardware opens up exciting possibilities for tackling many video understanding problems <ref> [1] </ref>. It is important to develop robust real-time video understanding techniques which can process the large amounts of data attainable. Central to many video understanding problems are the themes of target classification and tracking. Historically, target classification has been performed on single images or static imagery [12, 13, 6].
Reference: [2] <author> C. Anderson, P. Burt, G. </author> <title> van der Wal "Change detection and tracking using pyramid transformation techniques" SPIE Intelligent Robots and Computer Vision Vol. </title> <booktitle> 579, </booktitle> <pages> pp. 72-78, </pages> <year> 1985 </year>
Reference-contexts: Future work involves using temporal filtering and building on some of the ideas presented in [5] and [11] to achieve target recognition and multiple target tracking. Two of the basic methods for target tracking in real-time video applications are temporal differencing (DT) <ref> [2] </ref> and template correlation matching. In the former approach, video frames separated by a constant time ffit are compared to find regions which have changed. In the latter approach each video image is scanned for the region which best correlates to an image template. Independently, these methods have significant shortcomings.
Reference: [3] <author> A. Lipton, H. Fujiyoshi, R. </author> <title> Patil "Moving target detection and classification from real-time video" submitted to IEEE WACV 98, </title> <year> 1998. </year>
Reference: [4] <author> M. Hansen, P. Anandan, K. Dana, G. van der Wal, P. </author> <booktitle> Burt "Real-time scene stabilization and mosaic construction" Proceedings of DARPA Image Understanding Workshop 1994, </booktitle> <year> 1994 </year>
Reference-contexts: In the latter approach each video image is scanned for the region which best correlates to an image template. Independently, these methods have significant shortcomings. DT tracking is impossible if there is significant camera motion, unless an appropriate image stabilisation algorithm is employed <ref> [4] </ref>. It also fails if the target becomes occluded or ceases its motion. Template correlation matching generally requires that the target object's appearance remains constant. The method is generally not robust to changes in object size, orientation or even changing lighting conditions.
Reference: [5] <author> M. Isard and A. </author> <title> Blake "Contour tracking by stochastic propagation of conditional density" Proceedings of European Conf. </title> <booktitle> on Computer Vision 96, </booktitle> <pages> pp. 343-356, </pages> <year> 1996 </year>
Reference-contexts: This allows the system to disambiguate targets in the case of occlusions or background clutter. Many systems for target tracking are based on Kalman filters but as pointed out by <ref> [5] </ref>, they are of limited use because they are based on unimodal Gaussian densities and hence cannot support simultaneous alternative motion hypotheses. Isard and Blake [5] present a new stochastic algorithm for robust tracking which is superior to previous Kalman filter based approaches. <p> Many systems for target tracking are based on Kalman filters but as pointed out by <ref> [5] </ref>, they are of limited use because they are based on unimodal Gaussian densities and hence cannot support simultaneous alternative motion hypotheses. Isard and Blake [5] present a new stochastic algorithm for robust tracking which is superior to previous Kalman filter based approaches. Bregler [11] presents a probabilistic decomposition of human dynamics to learn and recognize human beings (or their gaits) in video sequences. <p> Hence the use of Kalman filtering or other probabilistic approaches is avoided. Future work involves using temporal filtering and building on some of the ideas presented in <ref> [5] </ref> and [11] to achieve target recognition and multiple target tracking. Two of the basic methods for target tracking in real-time video applications are temporal differencing (DT) [2] and template correlation matching.
Reference: [6] <author> K. Ikeuchi, T. Shakunaga, M. Wheeler, T. </author> <title> Ya-mazaki "Invariant histograms and deformable template matching for SAR target recognition" Proceedings of IEEE CVPR 96, </title> <journal> pp. </journal> <pages> 100-105, </pages> <year> 1996 </year>
Reference-contexts: It is important to develop robust real-time video understanding techniques which can process the large amounts of data attainable. Central to many video understanding problems are the themes of target classification and tracking. Historically, target classification has been performed on single images or static imagery <ref> [12, 13, 6] </ref>. More recently, however, video streams have been exploited for target detection [8, 14, 15]. Many methods like these, are computationally expensive and are innaplicable to real-time applications, or require spe-cialised hardware to operate in the real-time domain.
Reference: [7] <author> J. Davis, A. </author> <title> Bobick "The representation and recognition of human movement using temporal templates" Proceedings of IEEE CVPR 97, </title> <note> pp. 928 - 934, 1997 them is tracked for about 3 mins. </note>
Reference-contexts: Consequently, the classification metric which is explored in this paper, is based purely on a target's shape, and not on its image content. Furthermore, the temporal component of video allows a temporal consistency constraint <ref> [7] </ref> to be used in the classification approach. Multiple hypotheses of a target's classification can be maintained over time until the system is confident that it can accurately classify the target. This allows the system to disambiguate targets in the case of occlusions or background clutter.
Reference: [8] <author> I. Haritaoglu, D. Harwood, L. S. </author> <title> Davis "W 4 Who? When? Where? What? A Real Time System for Detecing and Tracking People" FGR98 submitted, </title> <year> 1998 </year>
Reference-contexts: Central to many video understanding problems are the themes of target classification and tracking. Historically, target classification has been performed on single images or static imagery [12, 13, 6]. More recently, however, video streams have been exploited for target detection <ref> [8, 14, 15] </ref>. Many methods like these, are computationally expensive and are innaplicable to real-time applications, or require spe-cialised hardware to operate in the real-time domain. However, methods such as Pfinder [14], W 4 [8] and Beymer et al [10] are designed to extract targets in real-time. <p> More recently, however, video streams have been exploited for target detection [8, 14, 15]. Many methods like these, are computationally expensive and are innaplicable to real-time applications, or require spe-cialised hardware to operate in the real-time domain. However, methods such as Pfinder [14], W 4 <ref> [8] </ref> and Beymer et al [10] are designed to extract targets in real-time. The philosophy behind these techniques is the segmentation of an image, or video stream, into object vs. non-object regions. This is based on matching regions of interest to reasonably detailed target models. <p> It is clear that the most obvious types of targets which will be of interest are humans and vehicles <ref> [8, 9] </ref>. For this reason, a classifier to detect these two groups has been implemented. The metric is based on the knowledge that humans are, in general, smaller than vehicles, and that they have more complex shapes.
Reference: [9] <author> M. Oren, C. Papageorgiou, P. Sinha, E. Osuna, T. </author> <title> Poggio "Pedestrian detection using wavelet templates" Proceedings of IEEE CVPR 97, </title> <journal> pp. </journal> <pages> 193-199, </pages> <year> 1997 </year>
Reference-contexts: It is clear that the most obvious types of targets which will be of interest are humans and vehicles <ref> [8, 9] </ref>. For this reason, a classifier to detect these two groups has been implemented. The metric is based on the knowledge that humans are, in general, smaller than vehicles, and that they have more complex shapes.
Reference: [10] <author> D. Beymer, P. McLauchlan, B. Coifman, and J. </author> <title> Malik "A real-time computer vision system for measuring traffic parameters" Proceedings of IEEE CVPR 97, </title> <journal> pp. </journal> <pages> 495-501, </pages> <year> 1997 </year>
Reference-contexts: Many methods like these, are computationally expensive and are innaplicable to real-time applications, or require spe-cialised hardware to operate in the real-time domain. However, methods such as Pfinder [14], W 4 [8] and Beymer et al <ref> [10] </ref> are designed to extract targets in real-time. The philosophy behind these techniques is the segmentation of an image, or video stream, into object vs. non-object regions. This is based on matching regions of interest to reasonably detailed target models.
Reference: [11] <author> C. </author> <booktitle> Bregler "Learning and recognizing human dynamics in video sequences" Proceedings of IEEE CVPR 97, </booktitle> <pages> pp. 568-574, </pages> <year> 1997 </year>
Reference-contexts: Isard and Blake [5] present a new stochastic algorithm for robust tracking which is superior to previous Kalman filter based approaches. Bregler <ref> [11] </ref> presents a probabilistic decomposition of human dynamics to learn and recognize human beings (or their gaits) in video sequences. <p> Hence the use of Kalman filtering or other probabilistic approaches is avoided. Future work involves using temporal filtering and building on some of the ideas presented in [5] and <ref> [11] </ref> to achieve target recognition and multiple target tracking. Two of the basic methods for target tracking in real-time video applications are temporal differencing (DT) [2] and template correlation matching. In the former approach, video frames separated by a constant time ffit are compared to find regions which have changed.
Reference: [12] <author> R. kasturi and R. C. </author> <booktitle> Jain "Computer Vision; Principles" IEEE Computer Society Press, </booktitle> <year> 1991 </year>
Reference-contexts: It is important to develop robust real-time video understanding techniques which can process the large amounts of data attainable. Central to many video understanding problems are the themes of target classification and tracking. Historically, target classification has been performed on single images or static imagery <ref> [12, 13, 6] </ref>. More recently, however, video streams have been exploited for target detection [8, 14, 15]. Many methods like these, are computationally expensive and are innaplicable to real-time applications, or require spe-cialised hardware to operate in the real-time domain.
Reference: [13] <author> M. Turk, A. </author> <title> Pentland "Eigenfaces for recognition." </title> <journal> Journal of Cognitive Neuroscience , 3, </journal> <volume> 1, </volume> <pages> 71-86, </pages> <year> 1991. </year>
Reference-contexts: It is important to develop robust real-time video understanding techniques which can process the large amounts of data attainable. Central to many video understanding problems are the themes of target classification and tracking. Historically, target classification has been performed on single images or static imagery <ref> [12, 13, 6] </ref>. More recently, however, video streams have been exploited for target detection [8, 14, 15]. Many methods like these, are computationally expensive and are innaplicable to real-time applications, or require spe-cialised hardware to operate in the real-time domain.
Reference: [14] <author> C. Wren, A. Azarbayejani, T. Darrell, A. </author> <title> Pent-land "Pfinder: </title> <journal> Real-Time Tracking of the Human Body" IEEE Transactions on Pattern Analysis and Machine Intelligence July 1997, </journal> <volume> vol 19, no 7, </volume> <pages> pp. 780-785 </pages>
Reference-contexts: Central to many video understanding problems are the themes of target classification and tracking. Historically, target classification has been performed on single images or static imagery [12, 13, 6]. More recently, however, video streams have been exploited for target detection <ref> [8, 14, 15] </ref>. Many methods like these, are computationally expensive and are innaplicable to real-time applications, or require spe-cialised hardware to operate in the real-time domain. However, methods such as Pfinder [14], W 4 [8] and Beymer et al [10] are designed to extract targets in real-time. <p> More recently, however, video streams have been exploited for target detection [8, 14, 15]. Many methods like these, are computationally expensive and are innaplicable to real-time applications, or require spe-cialised hardware to operate in the real-time domain. However, methods such as Pfinder <ref> [14] </ref>, W 4 [8] and Beymer et al [10] are designed to extract targets in real-time. The philosophy behind these techniques is the segmentation of an image, or video stream, into object vs. non-object regions. This is based on matching regions of interest to reasonably detailed target models.
Reference: [15] <author> D. Koller, K. Danilidis, H.-H. </author> <title> Nagel "Model-Based Object Tracking in Monocular Image Sequences of Road Traffic Scenes" International Journal of Computer Vision, </title> <type> 10-3, </type> <pages> pp. 257-281, </pages> <year> 1993 </year>
Reference-contexts: Central to many video understanding problems are the themes of target classification and tracking. Historically, target classification has been performed on single images or static imagery [12, 13, 6]. More recently, however, video streams have been exploited for target detection <ref> [8, 14, 15] </ref>. Many methods like these, are computationally expensive and are innaplicable to real-time applications, or require spe-cialised hardware to operate in the real-time domain. However, methods such as Pfinder [14], W 4 [8] and Beymer et al [10] are designed to extract targets in real-time.
References-found: 15

