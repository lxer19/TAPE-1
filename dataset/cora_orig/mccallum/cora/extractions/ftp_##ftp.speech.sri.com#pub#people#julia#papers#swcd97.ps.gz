URL: ftp://ftp.speech.sri.com/pub/people/julia/papers/swcd97.ps.gz
Refering-URL: http://www.speech.sri.com/people/julia/publi.html
Root-URL: 
Title: Physical Applications of an Agent Architecture Examples in Mobile Robotics and Surgery Training Systems.  
Author: Didier Guzzoni Adam Cheyer Luc Julia Kurt Konolige 
Date: February 25, 1997  
Affiliation: EPFL (Swiss Federal Institute of Technology)  Artificial Intelligence Laboratory, SRI International  
Abstract: 1 Abstract 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Konolige. </author> <title> Operation Manual for the Pioneer Mobile Robot. </title> <institution> SRI, </institution> <year> 1995 </year>
Reference-contexts: behind as a mobile telephone was stretching things a bit, so we cleared our strategy with the judges well before the contest. 2.2 The open agent architecture When planning our strategy for how to approach this year's robot contest, we decided to take advantage of our recent integration of Saphira <ref> [1] </ref> as an agent within the Open Agent Architecture (OAA)[2]. The OAA is 1 a framework for constructing multi agent systems that has been used by SRI and clients to construct more than fifteen applications in various domains [3]. <p> The knowledge layer, in turn, may lie on top of existing stand alone applications, and serves to map the functionality of the underlying application into the ICL. In the case of the physical robots, we installed an agent interface on top of Saphira <ref> [1] </ref>, so that information about the robot's location, and commands to navigate the robot, were made available to all agents. The OAA agent library provides common functionality across all agents. Each agent can respond to or produce requests for information or service, and can install triggers to monitor real-world conditions. <p> A top level program, the strategy agent, was designed to synchronize and control the robots and software agents. 2 structure.ps 80 fi 61 mm database agent, map manager agent, strategy agent and speech recognition agent were running on a UNIX workstation (Sparc20). On the robots, each Saphira <ref> [1] </ref> agent was running (under Windows 95) on a laptop computer, each equipped with sound devices and text-to-speech converters. The link between the robots and the Sparc20 was through wireless Ethernet links. <p> In addition, since agents are able to communicate information by asking and responding to queries, it is easy to set up software agents, like the mapping and strategy agents, to keep track of and control multiple robots. We'll briefly describe the capabilities of the agents. Saphira Saphira <ref> [1] </ref> is a powerful system which allows a robot to be independent by giving it high level behaviors (movement constraints, obstacle avoidance, map building, location to reach). This control program extracts pieces of information by reading and interpreting sensors values, such as sonars readings, camera images or wheels positions. <p> Instead, we built a strategy for the event by hand, taking into account the various contingencies that could arise. The strategy was written as a set of 4 coupled finite-state machines (FS), one for each robot agent. Because the two Pioneer <ref> [1] </ref> robots had similar tasks, their FS machines were equivalent. Figure 3 shows the strategies for these agents.Note that the FS strategies are executed by the strategy agent not the robots.
Reference: [2] <author> Philip R. Cohen & Adam Cheyer. </author> <title> An Open Agent Architecture. </title> <booktitle> AAAI Spring Symposium, </booktitle> <year> 1994 </year>
Reference-contexts: agents could help us to enhance our simulator in order to provide surgeons with high level multimodal interfaces, using concepts tested within our mobile robotics activities. 5 3.2 Agent compatible The interesting point here, is that the whole system is designed as an agent compatible with the OAA T M <ref> [2] </ref>. It means that every object in the scene (including the point of view) can be locally controlled to any 3D pointing device described above, or remotely linked to a distant agent.
Reference: [3] <author> Adam J. Cheyer & Douglas B. Moran. </author> <title> Software Agents. </title> <institution> SRI, </institution> <year> 1995 </year>
Reference-contexts: The OAA is 1 a framework for constructing multi agent systems that has been used by SRI and clients to construct more than fifteen applications in various domains <ref> [3] </ref>. Applying the OAA to the Office Navigation task in the robot competition was done to provide the following advantages: * Distributed Agents can run on different platforms and operating systems, and can cooperate in parallel to achieve a task.
Reference: [4] <author> Adam J. Cheyer & Luc Julia. </author> <title> Multimodals Maps : An Agent-based Approach. </title> <booktitle> International Conference on Cooperative Multimodals Communication (CMC/95), </booktitle> <address> 24-26 May 1995, Eindhoven, The Netherlands. </address>
Reference-contexts: However, to successfully attain a high level of human-computer cooperation, the interpretation of on-line data must be accurate and fast enough to give rapid and correct feedback to the user. The gesture recognition engine used in our application is fully described in <ref> [4] </ref>. There is no constraint on the number of strokes. The latest evaluations gave better than 96 accuracy, and the recognition was performed in less than half a second on a PC0 486/50, satisfying what we judge is required in terms of quality and speed [5].
Reference: [5] <author> Douglas B. Moran, Adam J. Cheyer, Luc Julia, David L. Martin, Sangkyu Park, </author> <title> The Open Agent Architecture and Its Multimodal User Interface. </title> <institution> SRI, </institution> <year> 1996 </year>
Reference-contexts: There is no constraint on the number of strokes. The latest evaluations gave better than 96 accuracy, and the recognition was performed in less than half a second on a PC0 486/50, satisfying what we judge is required in terms of quality and speed <ref> [5] </ref>. Given that our map manager program is an agent, the speech recognition agent can also be used in the system. Therefore, the user can talk to the system in order to control the robots or the display.
Reference: [6] <author> Didier R. Guzzoni, Kurt Konolige, Adam J. Cheyer, Luc Julia, </author> <title> Many robots make short work. </title> <publisher> AAAI Journal, </publisher> <year> 1997 </year>
Reference-contexts: To describe our tools, we will use as frame work the system developed to compete in the AAAI robot contest <ref> [6] </ref> which took place last summer in Portland (Oregon). Thanks to an agent architecture, we allowed three robots to cooperate each other, under the supervision of a user (using a multimodal interface).
Reference: [7] <author> P. Nguyen, </author> <title> libptk A summary. </title> <address> EPFL, </address> <year> 1996 </year>
Reference-contexts: The involved modalities are speech recognition and 3D pointing (mouse 3D, force feedback system) 3.3 The tools we developed The heart of the system is a library called libptk <ref> [7] </ref>. This set of functions allows a programmer to quickly and easily create virtual reality based simulators. The main features of this library are : * Real time rendering The library is built to provide real time simulations.
Reference: [8] <author> Y. Andenmatten, Representation realiste d'organes. EPFL, </author> <year> 1997 </year>
Reference-contexts: A texture is placed into the surface of an object through a texture laboratory <ref> [8] </ref>, allowing the user to choose how the texture will stick to the object. In addition to that, textures can be classic 2D images or a real time video flow, coming from a video database or any conventional camera device [9].
Reference: [9] <author> F. </author> <month> Quinet, </month> <institution> Utilisation de techniques infographiques pour la generation de textures dynamiques. EPFL, </institution> <year> 1997 </year>
Reference-contexts: In addition to that, textures can be classic 2D images or a real time video flow, coming from a video database or any conventional camera device <ref> [9] </ref>.
Reference: [10] <author> K-Team Koala USER MANUAL. EPFL, Lausanne, </author> <month> September </month> <year> 1994 </year> <month> 7 </month>
Reference-contexts: Each node in the FS graph represents a task that the strategy agent dispatches to a robot, e.g., navigating to a particular location. The robot in the Director's room, a Koala <ref> [10] </ref>, has a simple task: just wait until all the other robots have completed their task, then announce the time and place of the meeting.
References-found: 10

