URL: http://www.cs.dartmouth.edu/~jasonliu/courses/sim188/biblio/djs94.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~jasonliu/courses/sim188/notes-09.html
Root-URL: http://www.cs.dartmouth.edu
Title: Execution-Driven Simulation of Multiprocessors: Address and Timing Analysis  
Author: S. Dwarkadas J. R. Jump and J. B. Sinclair 
Keyword: Categories and Subject Descriptors: B.3.3 [Memory Structures]: Performance Analysis and Design Aids (uniprocessors and multiprocessors) execution-driven cache simulation, dynamic tracing; C.4 [Computer Systems Organization]: Performance of Systems measurement and modeling techniques; General Terms: measurement, performance, verification Additional Key Words and Phrases: execution-driven simulation, parallel tracing, shared-memory multiprocessors, distributed systems  
Address: Houston, TX77251-1892 1  
Affiliation: Department of Computer Science  Department of Electrical and Computer Engineering Rice University,  
Abstract: This paper describes and evaluates an efficient execution-driven technique for the simulation of multiprocessors that includes the simulation of system memory and is driven by real program workloads. The technique produces correctly interleaved address traces at run time without disk access overhead or hardware support, allowing accurate simulation of the effects of a variety of architectural alternatives on programs. We have implemented a simulator based on this technique that offers substantial advantages in terms of reduced time and space overheads when compared to instruction-driven or trace-driven simulation techniques, without significant loss of accuracy. The paper presents the results of several validation experiments used to quantify the accuracy and efficiency of the simulator for sequential, distributed, and shared-memory multiprocessors, and several parallel programs. These experiments show that prediction errors of less than 5% compared to actual execution times and overheads 6 to 30 times lower than those incurred by cycle-level simulation can be achieved. Predictions of relative performance metrics such as speedup tend to be even more accurate, making this technique especially attractive as an efficient method for comparative investigations of parallel system designs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, R. L. Sites, and M. Horowitz. ATUM: </author> <title> A new technique for capturing address traces using microcode. </title> <booktitle> In Proceedings of The 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 119-127, </pages> <month> June </month> <year> 1986. </year> <journal> vol. </journal> <volume> 14, no. </volume> <pages> 3. </pages>
Reference-contexts: Our technique generates timing information and/or address traces for the program on the fly [11] during execution. This avoids the large space overhead incurred by trace-driven simulation and the time involved in accessing these large traces from disk, as well as the specialized hardware needed to generate these traces <ref> [1, 6] </ref>. The execution-driven technique achieves its goal of avoiding the high overhead associated with instruction-level simulation while retaining most of its accuracy by extracting as much information as possible from the program at compile time. <p> The overhead associated with address trace generation using instruction-level simulation is reported to be on the order of 1000 <ref> [1] </ref>. Using a hardware tracing facility (as in the T-bit of the VAX processor) that interpretively determines instruction and data addresses, the overhead is about 100. If microcoding is used, the overhead is about 10. These figures do not include cache simulation. <p> Borg et al. [3] use link time code modification to generate long traces on sequential RISC machines, once again generating traces efficiently for later analysis. ATUM <ref> [1] </ref> captures address traces using microcode. While this technique is efficient, long traces must be stored on disk, and a processor with user-programmable microcode is necessary to produce the traces.
Reference: [2] <author> B. N. Bershad, E. D. Lazowska, and H. M. Levy. </author> <title> PRESTO: A System for Object-Oriented Parallel Programming. </title> <type> Technical Report TR 87-09-01, </type> <institution> Department of Computer Science, University of Washington, </institution> <address> Seattle, WA, </address> <month> September </month> <year> 1987. </year>
Reference-contexts: The parallel programs under evaluation may be written using Concurrent C [21] or Presto <ref> [2] </ref>. The shared memory parallel programming model presented to the user consists of lightweight threads executing in a single address space. These threads synchronize using flags, locks, barriers or semaphores (Concurrent C), and monitors or condition variables (Presto). Programs may also use the PARMACS parallel programming macros [4]. <p> It provides the user with primitives to design both shared and distributed memory programs. * Presto : This is the C++ programming model provided to the user. Presto, written in C++, is an object-oriented programming environment designed for shared memory systems and developed at the University of Washington, Seattle <ref> [2] </ref>. A Presto interface has been provided to the user by porting Presto on top of Concurrent C [24]. * YACSIM (Yet Another C SIMulation Package): This is a process-level, discrete-event simulator providing a set of procedures for process creation, delaying, event queue manipulation, and statistics collection [9, 18].
Reference: [3] <author> A. Borg, R. E. Kessler, and D. W. Wall. </author> <title> Generation and analysis of very long address traces. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Pixie [22] is a profiling tool developed to analyze basic block usage and execution time on the MIPS R2000, and can be used to generate traces for later processing by a simulation tool. Borg et al. <ref> [3] </ref> use link time code modification to generate long traces on sequential RISC machines, once again generating traces efficiently for later analysis. ATUM [1] captures address traces using microcode.
Reference: [4] <author> J. Boyle, R. Butler, T. Disz, B. Glickfeld, E. Lus k, R. Overbeek, J. Patterson, and R. Stevens. </author> <title> Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart and Winston, Inc., </publisher> <year> 1987. </year> <month> 27 </month>
Reference-contexts: The shared memory parallel programming model presented to the user consists of lightweight threads executing in a single address space. These threads synchronize using flags, locks, barriers or semaphores (Concurrent C), and monitors or condition variables (Presto). Programs may also use the PARMACS parallel programming macros <ref> [4] </ref>. The basic components of the RPPT software system are as follows: 10 * Concurrent C: This is the C programming model provided to the user [21].
Reference: [5] <author> E.A. Brewer, C.N. Dellarocas, A. Colbrook, and W.E. Weihl. PROTEUS: </author> <title> A High--Performance Parallel-Architecture Simulator. </title> <type> Technical Report MIT/LCS/TR-516, </type> <institution> Laboratory for Computer Science, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: Tango [10] is a multiprocessor simulation and tracing package based on the execution-driven approach, which concentrates on program data accesses. Tango originally used UNIX processes to simulate parallelism, resulting in high context switching overhead. A recent version of Tango uses light weight processes as in our simulator. PROTEUS <ref> [5] </ref>, another execution-driven simulation system, also concentrates only on shared data addresses and instruments the high-level language to generate the shared data addresses, while profiling at assembly level to extract timing information. Neither the Tango nor the Proteus projects have provided extensive validation results for shared-memory machines.
Reference: [6] <author> D. W. Clark. </author> <title> Cache performance in the VAX-11/780. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 1(1) </volume> <pages> 24-37, </pages> <month> February </month> <year> 1983. </year>
Reference-contexts: Our technique generates timing information and/or address traces for the program on the fly [11] during execution. This avoids the large space overhead incurred by trace-driven simulation and the time involved in accessing these large traces from disk, as well as the specialized hardware needed to generate these traces <ref> [1, 6] </ref>. The execution-driven technique achieves its goal of avoiding the high overhead associated with instruction-level simulation while retaining most of its accuracy by extracting as much information as possible from the program at compile time.
Reference: [7] <author> R. G. Covington, S. Dwarkadas, J. R. Jump, S. Madala, and J. B. Sinclair. </author> <title> The Efficient Simulation of Parallel Computer Systems. </title> <journal> International Journal in Computer Simulation, </journal> <volume> 1 </volume> <pages> 31-58, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: We have developed and evaluated an efficient technique for the simulation of multiprocessors that includes the simulation of system memory and/or caches and is driven by real programs. The method used is a variant of execution-driven simulation <ref> [8, 7] </ref>. Our goal is to speed up the simulation without a significant loss of accuracy compared to other techniques such as instruction-driven simulation, and without incurring the large storage overheads of trace-driven approaches or requiring special hardware support. <p> In the case of message-based systems, the program may be profiled to generate only timing information at the beginning of each basic block. The message transmissions themselves are simulated in great detail. This results 11 in program slowdowns of 1.2 to 15 <ref> [7] </ref> at 16 processors with slowdown factors depending on the frequency of communication of a particular application. If the performance of the system caches must be determined, address trace information may also be generated. <p> The two components to the architecture model are provided with a well-defined interface, and interact closely with one another. 3 Evaluation We have presented validation data for message-based architectures in <ref> [7] </ref>. In this section, we present validation results for shared memory architectures (some data is also presented in [13]). In particular, we compare results produced by a simulation of the Sequent Symmetry against measurements on the corresponding real machine.
Reference: [8] <author> R. G. Covington, S. Madala, V. Mehta, J. R. Jump, and J. B. Sinclair. </author> <title> The Rice Parallel Processing Testbed. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 4-11, </pages> <address> Santa Fe, NM, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: We have developed and evaluated an efficient technique for the simulation of multiprocessors that includes the simulation of system memory and/or caches and is driven by real programs. The method used is a variant of execution-driven simulation <ref> [8, 7] </ref>. Our goal is to speed up the simulation without a significant loss of accuracy compared to other techniques such as instruction-driven simulation, and without incurring the large storage overheads of trace-driven approaches or requiring special hardware support. <p> Simulation of the architecture during the actual execution of the parallel program under consideration permits us to determine the effects of the architecture on the execution of the program with a high degree of accuracy. We have implemented this technique as part of the Rice Parallel Processing Testbed <ref> [8] </ref>, a simulation tool for the performance evaluation of parallel computer systems. In the RPPT, we perform a compile time analysis of the program and convert it into one that will provide information on instruction execution times and memory accesses to the simulator as it executes. <p> Since the Matrix Multiply program has a very low miss rate and very little coherence traffic, its execution-driven simulation overhead is low. 23 4 Related Work Since the inception of execution-driven simulation ( <ref> [8] </ref>), several simulation tools that use a similar concept have been developed. A similar approach to cache simulation as that used 24 Program Execution-Driven Cycle-Level Overhead Overhead Successive Over-Relaxation (SOR) 1259x 7682x Matrix Multiply (MM) 390x 12740x Table 2 Simulation Overheads - Instruction-Driven Vs.
Reference: [9] <author> R.G. Covington and J.R. </author> <title> Jump. CSIM 2.0 User's Manual. </title> <type> Technical Report TR 8712, </type> <institution> Department of Electrical and Computer Engineering, Rice University, Houston, TX, </institution> <month> October </month> <year> 1987. </year>
Reference-contexts: A Presto interface has been provided to the user by porting Presto on top of Concurrent C [24]. * YACSIM (Yet Another C SIMulation Package): This is a process-level, discrete-event simulator providing a set of procedures for process creation, delaying, event queue manipulation, and statistics collection <ref> [9, 18] </ref>. YACSIM primitives may be used to model any architecture being simulated. * Address and Timing Profilers: A program analyzer is used to modify the assembly language version of the program so that address and timing information may be extracted at run time.
Reference: [10] <author> H. Davis, S. R. Goldschmidt, and J. Hennessy. </author> <title> Tango: A Multiprocessor Simulation and Tracing System. </title> <type> Technical report, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <year> 1990. </year>
Reference-contexts: Systems of this nature do not allow for dynamic changes in the address trace due to timing variations in the architecture and timing dependent behavior of the program. Tango <ref> [10] </ref> is a multiprocessor simulation and tracing package based on the execution-driven approach, which concentrates on program data accesses. Tango originally used UNIX processes to simulate parallelism, resulting in high context switching overhead. A recent version of Tango uses light weight processes as in our simulator.
Reference: [11] <author> M. Dubois, F. Briggs, I. Patil, and M. Balakrishnan. </author> <title> Trace-driven simulations of parallel and distributed algorithms in multiprocessors. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages 909-915, </pages> <year> 1986. </year>
Reference-contexts: Such interactions can include message passing, synchronization, cache misses, and accesses to shared variables. Our technique generates timing information and/or address traces for the program on the fly <ref> [11] </ref> during execution. This avoids the large space overhead incurred by trace-driven simulation and the time involved in accessing these large traces from disk, as well as the specialized hardware needed to generate these traces [1, 6].
Reference: [12] <author> S. Dwarkadas. </author> <title> Efficient methods for cache performance prediction. </title> <type> Master's thesis, </type> <institution> Department of Electrical and Computer Engineering, Rice University, Houston TX, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: Figure 1 shows the basic cycle of the execution-driven simulator. The profiler, which is an important component for simulating shared memory systems, is described briefly in the next subsection. A detailed analysis, description, and validation of the profiling technique can be found in <ref> [12] </ref> and [14]. The description of the profiler is followed by an overview of the simulation system that we have developed. 2.1 The Address Trace and Timing Profilers Conventional simulation techniques used to predict the performance of system memory involve two main steps.
Reference: [13] <author> S. Dwarkadas, J. R. Jump, R. Mukherjee, and J. B. Sinclair. </author> <title> Execution-Driven Simulation of Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of the 1993 SCS Western Multiconference, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: The two components to the architecture model are provided with a well-defined interface, and interact closely with one another. 3 Evaluation We have presented validation data for message-based architectures in [7]. In this section, we present validation results for shared memory architectures (some data is also presented in <ref> [13] </ref>). In particular, we compare results produced by a simulation of the Sequent Symmetry against measurements on the corresponding real machine.
Reference: [14] <author> S. Dwarkadas, J. R. Jump, and J. B. Sinclair. </author> <title> Efficient Simulation of Cache Memories. </title> <booktitle> In Proceedings of the Winter Simulation Conference, </booktitle> <month> December </month> <year> 1989. </year>
Reference-contexts: Figure 1 shows the basic cycle of the execution-driven simulator. The profiler, which is an important component for simulating shared memory systems, is described briefly in the next subsection. A detailed analysis, description, and validation of the profiling technique can be found in [12] and <ref> [14] </ref>. The description of the profiler is followed by an overview of the simulation system that we have developed. 2.1 The Address Trace and Timing Profilers Conventional simulation techniques used to predict the performance of system memory involve two main steps. <p> If only data addresses are required, the address template per basic block need not be created or examined. The execution-driven methodology has been used to implement profilers for the Motorola 68020, Intel 80386, and SPARC processors. The 68020 profiler was validated in <ref> [14] </ref>. The ratio of simulation time to actual workload execution time is called the slowdown factor or overhead. <p> By extending 7 the execution-driven concept to the dynamic generation of address traces and the simulation of caches, we have developed a space efficient approach that is significantly faster than conventional instruction-level simulations. In the next section, we present a summary of our uniprocessor validation results (see <ref> [14] </ref> for a more detailed analysis). 2.1.1 Profiler Validation The simulation system was validated to determine the accuracy of the execution time predictions made by the simulator. <p> If the performance of the system caches must be determined, address trace information may also be generated. In this case, the cache data structures and timing information must be updated, but there is no coherency maintainance overhead for a message-passing system of this nature. The overhead involved is 60-180 <ref> [14] </ref> for the simulation of a set-associative cache with a write back policy, as compared to the Concurrent C version of the program. The program is rescheduled only at process interaction points, which may be only the message sends and receives.
Reference: [15] <author> S. J. Eggers, D. R. Keppel, E. J. Koldinger, and H. M. Levy. </author> <title> Techniques for efficient inline tracing on a shared memory multiprocessor. </title> <booktitle> In SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Hence, it is difficult to use TRAPEDS to study trade-offs in computation and communication. We have developed and validated accurate network and communication models for both distributed and shared memory systems. The use of these models in conjunction with the execution-driven technique enables accurate performance prediction. MPtrace <ref> [15] </ref> uses the execution-driven approach to generate traces of information that allow an address trace to be reconstructed. It achieves an overhead of 2 to 3 times normal 25 execution time (excluding trace storage) by transferring the work of trace reconstruction to the post-processing phase. <p> Our overhead figures include trace reconstruction, since we avoid disk access by dynamically processing the trace. The post-processing phase in MPtrace is extremely slow, generating about 3000 addresses per second <ref> [15] </ref>. Overhead reduction in the trace generation phase is also important for MPtrace since it directly affects the accuracy of the trace.
Reference: [16] <author> M. Federwisch and L. Ball. Mpsas: </author> <title> a Programmer and User Manual. Sun Microsystems, </title> <year> 1990. </year>
Reference-contexts: In the next section, we provide an overview of the execution-driven approach, validate the profiling technique, and explain the details of our simulator. Section 3 provides an evaluation of our simulation approach on the Sequent Symmetry [20] as well as a comparison with a cycle-level simulator <ref> [16] </ref>. Section 5 concludes by providing an overview of our work. 2 The Execution-Driven Technique In execution-driven simulation, the execution of the program and the simulation of the architecture are interleaved. <p> The cycle-level simulator used was a modified version of MPSAS <ref> [16, 17] </ref>, which is a single-bus multiprocessor simulator developed by Sun Microsystems. A cycle-level simulator provides a detailed analysis of program/architecture behavior, and hence is fairly accurate.
Reference: [17] <author> J. Greenwood. </author> <title> The Design of a Scalable Hierarchical-Bus, Shared-Memory Multiprocessor. </title> <type> Master's thesis, </type> <institution> Rice University, Houston TX, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: The cycle-level simulator used was a modified version of MPSAS <ref> [16, 17] </ref>, which is a single-bus multiprocessor simulator developed by Sun Microsystems. A cycle-level simulator provides a detailed analysis of program/architecture behavior, and hence is fairly accurate.
Reference: [18] <author> J. R. </author> <title> Jump. YACSIM Reference Manual. </title> <institution> Rice University, </institution> <year> 1992. </year> <month> 28 </month>
Reference-contexts: A Presto interface has been provided to the user by porting Presto on top of Concurrent C [24]. * YACSIM (Yet Another C SIMulation Package): This is a process-level, discrete-event simulator providing a set of procedures for process creation, delaying, event queue manipulation, and statistics collection <ref> [9, 18] </ref>. YACSIM primitives may be used to model any architecture being simulated. * Address and Timing Profilers: A program analyzer is used to modify the assembly language version of the program so that address and timing information may be extracted at run time.
Reference: [19] <author> R. H. Katz, S. J. Eggers, D. A. Wood, C. L. Perkins, and R. G. Sheldon. </author> <title> Implementing a Cache Consistency Protocol. </title> <booktitle> In Proceedings of the 12th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 276-283. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1985. </year>
Reference-contexts: The coherence protocol is write back with invalidation of other copies when the data is shared, similar to the Berkeley protocol <ref> [19] </ref>. In addition, when a cache that has the dirty copy of a cache line supplies the data, the cache also invalidates its own copy regardless of whether the request was for a read or a write access. Coherence is maintained by using the bus network's snooping ability.
Reference: [20] <author> T. Lovett and S. Thakkar. </author> <title> The Symmetry Multiprocessor System. </title> <booktitle> In Proceedings of the 1988 International Conference on Parallel Processing, </booktitle> <pages> pages 303-310, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Our results show that we have developed an efficient simulator with an accuracy of within 5% for the Sequent Symmetry 2 <ref> [20] </ref>. The errors are mostly due to the variable execution times of the complex instructions, which our simulator does not attempt to predict. <p> In the next section, we provide an overview of the execution-driven approach, validate the profiling technique, and explain the details of our simulator. Section 3 provides an evaluation of our simulation approach on the Sequent Symmetry <ref> [20] </ref> as well as a comparison with a cycle-level simulator [16]. Section 5 concludes by providing an overview of our work. 2 The Execution-Driven Technique In execution-driven simulation, the execution of the program and the simulation of the architecture are interleaved.
Reference: [21] <author> S. Madala. </author> <title> Concurrent C User's Manual. </title> <type> Technical Report TR 8701, </type> <institution> Dept. of Electrical and Computer Engineering, Rice University, Houston, TX, </institution> <month> January </month> <year> 1987. </year>
Reference-contexts: During the execution, the timing information from the architecture model is combined with the estimates of instruction execution times to obtain accurate estimates of the overall execution times of a parallel program on a chosen architecture. The parallel programs under evaluation may be written using Concurrent C <ref> [21] </ref> or Presto [2]. The shared memory parallel programming model presented to the user consists of lightweight threads executing in a single address space. These threads synchronize using flags, locks, barriers or semaphores (Concurrent C), and monitors or condition variables (Presto). <p> Programs may also use the PARMACS parallel programming macros [4]. The basic components of the RPPT software system are as follows: 10 * Concurrent C: This is the C programming model provided to the user <ref> [21] </ref>. It provides the user with primitives to design both shared and distributed memory programs. * Presto : This is the C++ programming model provided to the user.
Reference: [22] <institution> MIPS Computer Systems, Inc. </institution> <note> MIPS Languages and Programmer's Manual, </note> <year> 1986. </year>
Reference-contexts: The post-processing phase in MPtrace is extremely slow, generating about 3000 addresses per second [15]. Overhead reduction in the trace generation phase is also important for MPtrace since it directly affects the accuracy of the trace. Pixie <ref> [22] </ref> is a profiling tool developed to analyze basic block usage and execution time on the MIPS R2000, and can be used to generate traces for later processing by a simulation tool.
Reference: [23] <author> C. L. Mitchell and M. J. Flynn. </author> <title> A workbench for computer architects. </title> <booktitle> IEEE Design and Test of Computers, </booktitle> <pages> pages 19-29, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: A similar approach to cache simulation as that used 24 Program Execution-Driven Cycle-Level Overhead Overhead Successive Over-Relaxation (SOR) 1259x 7682x Matrix Multiply (MM) 390x 12740x Table 2 Simulation Overheads - Instruction-Driven Vs. Execution-Driven in RPPT is used in <ref> [23] </ref>, but only instruction addresses are traced. The TRAPEDS [28] approach is limited to non-multiprogrammed multicomputer address trace analysis, and does not deal with shared memory systems. TRAPEDS also does not model communication accurately, since it does not evaluate the effects of contention.
Reference: [24] <author> R. Mukherjee. </author> <title> Efficient Simulation of Shared Memory Parallel Systems. </title> <type> Master's thesis, </type> <institution> Rice University, Houston TX, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: Presto, written in C++, is an object-oriented programming environment designed for shared memory systems and developed at the University of Washington, Seattle [2]. A Presto interface has been provided to the user by porting Presto on top of Concurrent C <ref> [24] </ref>. * YACSIM (Yet Another C SIMulation Package): This is a process-level, discrete-event simulator providing a set of procedures for process creation, delaying, event queue manipulation, and statistics collection [9, 18].
Reference: [25] <author> S. K. Reinhardt, M. D. Hill, J. R. Larus, A. R. Lebeck, J. C. Lewis, and D. A. Wood. </author> <title> The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Neither the Tango nor the Proteus projects have provided extensive validation results for shared-memory machines. The Wisconsin Wind Tunnel <ref> [25] </ref> uses the execution-driven approach to evaluate cache-coherent shared-memory computers on a CM-5, but requires the use of the CM-5 memory's error-correcting code (ECC) bits. Mint [29] is a MIPS code interpreter for parallel programs that generates memory reference traces used to drive simulations of multiprocessor systems.
Reference: [26] <author> ROSS Technology, Inc. </author> <title> SPARC RISC User's Guide, </title> <note> second edition, Feburary 1990. </note>
Reference-contexts: 21 Program Average Overhead Subgraph Isomorphism (ISO) 639x Fast Fourier Transform (FFT) 505x Mergesort (MERGE) 861x Gaussian Elimination (GAUSS) 598x Table 1 Simulation Overheads Sequent Symmetry 3.2 Single Bus SPARC Architecture We also compared the simulator to a cycle-level simulator by using both to simulate a single-bus-based architecture of SPARC <ref> [26] </ref> processors. The cycle-level simulator used was a modified version of MPSAS [16, 17], which is a single-bus multiprocessor simulator developed by Sun Microsystems. A cycle-level simulator provides a detailed analysis of program/architecture behavior, and hence is fairly accurate.
Reference: [27] <institution> Sequent Computer Systems, Inc. </institution> <type> Sequent Symmetry Technical Summary, </type> <month> August </month> <year> 1987. </year>
Reference-contexts: We also compare the execution-driven simulation of a SPARC-based multiprocessor with a corresponding instruction-level simulation of the same system in order to evaluate the accuracy and efficiency of execution-driven simulation relative to this more conventional approach to simulating computer systems. 3.1 The Sequent Symmetry The Sequent Symmetry <ref> [27] </ref> is a single bus shared memory multiprocessor with a private cache at each processor. The coherence protocol is write back with invalidation of other copies when the data is shared, similar to the Berkeley protocol [19].
Reference: [28] <author> C. B. Stunkel and W. K. Fuchs. TRAPEDS: </author> <title> Producing traces for multicomputers via execution driven simulation. </title> <booktitle> In Proceedings of the 1989 ACM International Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 70-78, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: A similar approach to cache simulation as that used 24 Program Execution-Driven Cycle-Level Overhead Overhead Successive Over-Relaxation (SOR) 1259x 7682x Matrix Multiply (MM) 390x 12740x Table 2 Simulation Overheads - Instruction-Driven Vs. Execution-Driven in RPPT is used in [23], but only instruction addresses are traced. The TRAPEDS <ref> [28] </ref> approach is limited to non-multiprogrammed multicomputer address trace analysis, and does not deal with shared memory systems. TRAPEDS also does not model communication accurately, since it does not evaluate the effects of contention. Hence, it is difficult to use TRAPEDS to study trade-offs in computation and communication.
Reference: [29] <author> J. E. Veenstra. </author> <title> Mint Tutorial and User Manual. </title> <type> Technical Report 452, </type> <institution> Department of Computer Science, University of Rochester, Rochester, </institution> <address> NY, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Neither the Tango nor the Proteus projects have provided extensive validation results for shared-memory machines. The Wisconsin Wind Tunnel [25] uses the execution-driven approach to evaluate cache-coherent shared-memory computers on a CM-5, but requires the use of the CM-5 memory's error-correcting code (ECC) bits. Mint <ref> [29] </ref> is a MIPS code interpreter for parallel programs that generates memory reference traces used to drive simulations of multiprocessor systems.
Reference: [30] <author> J. P. Weinberger. </author> <title> Cheap dynamic instruction counting. </title> <journal> AT&T Bell Laboratories Technical Journal, </journal> <volume> 63(8), </volume> <month> October </month> <year> 1984. </year> <month> 29 </month>
Reference-contexts: A basic block is a maximal contiguous set of instructions, all of which will be executed exactly once if the first is executed, and conversely <ref> [30] </ref>. Thus, any instruction that is the target of a branch and any instruction following a branch starts a basic block.
References-found: 30

