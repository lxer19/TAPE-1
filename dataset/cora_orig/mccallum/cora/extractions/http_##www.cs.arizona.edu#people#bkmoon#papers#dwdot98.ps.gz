URL: http://www.cs.arizona.edu/people/bkmoon/papers/dwdot98.ps.gz
Refering-URL: http://www.cs.arizona.edu/people/bkmoon/papers.html
Root-URL: http://www.cs.arizona.edu
Email: adatta@loochi.bpa.arizona.edu  bkmoon@cs.arizona.edu  helen@loochi.bpa.arizona.edu  
Title: A Case for Parallelism in Data Warehousing and OLAP  
Author: Anindya Datta Bongki Moon Helen Thomas 
Address: Tucson, AZ 85721  Tucson, AZ 85721  Tucson, AZ 85721  
Affiliation: Dept. of MIS University of Arizona  Dept. of Computer Science University of Arizona  Dept. of MIS University of Arizona  
Abstract: In recent years the database community has experienced a tremendous increase in the availability of new technologies to support efficient storage and retrieval of large volumes of data, namely data warehousing and On-Line Analytical Processing (OLAP) products. Efficient query processing is critical in such an environment, yet achieving quick response times with OLAP queries is still largely an open issue. In this paper we propose a solution approach to this problem by applying parallel processing techniques to a warehouse environment. We suggest an efficient partitioning strategy based on the relational representation of a data warehouse (i.e., star schema). Furthermore, we incorporate a particular indexing strategy, DataIndexes, to further improve query processing times and parallel resource utilization, and propose a preliminary parallel star-join strategy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Chauduri and U. Dayal. </author> <title> An overview of data warehousing and OLAP technology. </title> <booktitle> SIGMOD Record, </booktitle> <volume> 26(1) </volume> <pages> 65-74, </pages> <month> March </month> <year> 1997. </year>
Reference-contexts: In contrast to OLTP systems, data warehouses are designed for decision support purposes and contain long periods of historical data. For this reason, data warehouses tend to be extremely large it is quite possible for a data warehouse to be hundreds of gigabytes to terabytes in size <ref> [1] </ref>. The information in a warehouse is usually multidimensional in nature, requiring the capability to view the data from a variety of perspectives. In this environment, aggregated and summarized data are much more important than detailed records. <p> Precomputation strategies involve deriving tables that store precomputed answers to queries. Such tables are often referred to as summary tables or materialized views <ref> [1] </ref>. There is a tradeoff between response times and the storage requirements of precomputed data. Determining how much data to precompute is an issue that has been addressed in [7].
Reference: [2] <author> E. Codd, S. Codd, and C. Salley. </author> <title> Providing OLAP (on-line analitycal processing) to user-analysts: An IT mandate. </title> <type> Technical report, </type> <institution> E.F. Codd & Associates, </institution> <year> 1993. </year>
Reference-contexts: A data warehouse can be defined as an on-line repository of historical enterprise data that is used to support decision making [8]. OLAP refers to the technologies that allows users to efficiently retrieve data from the data warehouse <ref> [2] </ref>. Throughout this paper, we refer to the combination of a data warehouse and its corresponding OLAP techniques as an OLAP system. fl The author list is in alphabetical order.
Reference: [3] <author> G. Copeland, W. Alexander, E. Boughter, and T. Keller. </author> <title> Data placement in Bubba. </title> <booktitle> In Proc. ACM SIGMOD, </booktitle> <address> Chicago, IL, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Various methods have been developed over the years to distribute data across sites. Some early work in the area has concentrated on hash-or range-partitioning based on a single key <ref> [3] </ref>. This approach is also supported by a number of database vendors (e.g., Oracle, Informix and NCR). More recently, multi-attribute declustering techniques have been pro posed and analyzed [11]. As mentioned previously, we are not aware of any published academic work related to parallelism in data warehouses.
Reference: [4] <author> D. DeWitt and J. Gray. </author> <title> Parallel database systems: The future of high performance database systems. </title> <journal> Comm. of the ACM, </journal> <volume> 35(6) </volume> <pages> 85-98, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: A large body of work exists in applying parallel processing techniques to relational database systems (e.g., <ref> [4] </ref>). From this work has emerged the notion that highly-parallel, shared-nothing architectures can yield much better performance than equivalent closely-coupled systems [4]. Indeed, may commercial database vendors have capitalized on this fact [5]. <p> A large body of work exists in applying parallel processing techniques to relational database systems (e.g., <ref> [4] </ref>). From this work has emerged the notion that highly-parallel, shared-nothing architectures can yield much better performance than equivalent closely-coupled systems [4]. Indeed, may commercial database vendors have capitalized on this fact [5]. An issue that is closely related to parallelism is that of declustering large data sets over a number of nodes in a parallel database machine. Various methods have been developed over the years to distribute data across sites.
Reference: [5] <author> S. Engelbert, J. Gray, T. Kocher, and P. Stah. </author> <title> A benchmark of non-stop SQL Release 2 demonstrating near-linear speedup and scaleup on large databases. </title> <type> Technical Report 89.4, </type> <institution> Tandem Computers, </institution> <month> May </month> <year> 1989. </year> <title> Tandem Part No.27469. </title>
Reference-contexts: Thus, a scalable architecture is crucial in a warehouse environment. Shared-nothing architectures have been shown to achieve near linear speedups and scale-ups in OLTP environments as well as on complex relational queries <ref> [5] </ref>, and so it is worth investigating their performance in OLAP systems. Still another reason that the appeal for parallelism is so strong in an OLAP system relates to the logical design of a warehouse. This point is best illustrated using an example. <p> A large body of work exists in applying parallel processing techniques to relational database systems (e.g., [4]). From this work has emerged the notion that highly-parallel, shared-nothing architectures can yield much better performance than equivalent closely-coupled systems [4]. Indeed, may commercial database vendors have capitalized on this fact <ref> [5] </ref>. An issue that is closely related to parallelism is that of declustering large data sets over a number of nodes in a parallel database machine. Various methods have been developed over the years to distribute data across sites.
Reference: [6] <author> G. Graefe. </author> <title> Query evaluation techniques for large databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 25(2) </volume> <pages> 73-170, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: There exist relatively fast algorithms (e.g., merge and hash joins) for evaluating joins. However, approaches that use pointers to the underlying data, instead of the actual records, tend to give a better performance than other join strategies <ref> [6] </ref>. Indeed, we can significantly reduce the number of data blocks to be accessed while processing a join by storing the RIDs of the matching records in the corresponding dimension table instead of the corresponding key values in a BDI for a foreign key column.
Reference: [7] <author> V. Harinarayan, A. Rajaraman, and J. Ullman. </author> <title> Implementing data cubes efficiently. </title> <booktitle> In Proc. ACM SIG-MOD, </booktitle> <pages> pages 205-216, </pages> <address> Montreal, Canada, </address> <month> June 4-6 </month> <year> 1996. </year>
Reference-contexts: Such tables are often referred to as summary tables or materialized views [1]. There is a tradeoff between response times and the storage requirements of precomputed data. Determining how much data to precompute is an issue that has been addressed in <ref> [7] </ref>. The work in indexing strategies includes traditional approaches, such as tree-based indexing (e.g., [9]), as well as non-traditional approaches, such as positional indexing, which has been proposed in [13, 16]. DataIndexes is a form of positional indexing.
Reference: [8] <author> W. Inmon. </author> <title> Building the Data Warehouse. </title> <editor> J. </editor> <publisher> Wiley & Sons, Inc., </publisher> <address> second edition, </address> <year> 1996. </year>
Reference-contexts: A data warehouse can be defined as an on-line repository of historical enterprise data that is used to support decision making <ref> [8] </ref>. OLAP refers to the technologies that allows users to efficiently retrieve data from the data warehouse [2]. Throughout this paper, we refer to the combination of a data warehouse and its corresponding OLAP techniques as an OLAP system. fl The author list is in alphabetical order.
Reference: [9] <author> T. Johnson and D. Shasha. </author> <title> Some approaches to index design for cube forests. </title> <journal> Bulletin of the Technical Committee on Data Engineering, </journal> <volume> 20(1), </volume> <month> March </month> <year> 1997. </year>
Reference-contexts: There is a tradeoff between response times and the storage requirements of precomputed data. Determining how much data to precompute is an issue that has been addressed in [7]. The work in indexing strategies includes traditional approaches, such as tree-based indexing (e.g., <ref> [9] </ref>), as well as non-traditional approaches, such as positional indexing, which has been proposed in [13, 16]. DataIndexes is a form of positional indexing. Algorithm 3 Parallel Star Join Note: Requires the DataIndexing scheme described in Section 3.1 and the partitioning strategy described in Section 3.2.
Reference: [10] <author> K. </author> <title> Lyons, </title> <journal> AT&T Research. Private communication, </journal> <month> July-August </month> <year> 1997. </year>
Reference-contexts: In addition to the already large size of most warehouses, growth is another important factor in OLAP systems. Data warehouses tend to grow quite rapidly. For example, AT&T has a data warehouse containing call detail information that grows at a rate of approximately 18 GB per day <ref> [10] </ref>. Thus, a scalable architecture is crucial in a warehouse environment. Shared-nothing architectures have been shown to achieve near linear speedups and scale-ups in OLTP environments as well as on complex relational queries [5], and so it is worth investigating their performance in OLAP systems.
Reference: [11] <author> B. Moon and J. H. Saltz. </author> <title> Scalability analysis of declus-tering methods for multidimensional range queries. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 10(2), </volume> <month> Mar/Apr </month> <year> 1998. </year>
Reference-contexts: Some early work in the area has concentrated on hash-or range-partitioning based on a single key [3]. This approach is also supported by a number of database vendors (e.g., Oracle, Informix and NCR). More recently, multi-attribute declustering techniques have been pro posed and analyzed <ref> [11] </ref>. As mentioned previously, we are not aware of any published academic work related to parallelism in data warehouses.
Reference: [12] <author> P. O'Neil and G. Graefe. </author> <title> Multi-table joins through bitmapped join indices. </title> <booktitle> SIGMOD Record, </booktitle> <volume> 24(3) </volume> <pages> 8-11, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: A number of indexing schemes have been proposed in the literature. Among these, four index types are shown in [13] to be particularly appropriate for OLAP systems: B + - trees , bitmapped indexes <ref> [12] </ref>, projection indexes and bit-sliced indexes [13]. A DataIndex, like the projection index, exploits a positional indexing strategy. A projection index is simply a mirror image of the column being indexed. <p> Many queries on the star schema of Figure 1 would access one or more dimension tables and the central SALES table. Access methods that efficiently support join operations thus become crucial in decision support environments <ref> [12, 14] </ref>. The idea of a BDI presented in the previous section can very easily be extended to support such operations. Consider for instance, an analyst who is interested in possible trends or seasonalities in discounts offered to customers.
Reference: [13] <author> P. O'Neil and D. Quass. </author> <title> Improved query performance with variant indexes. </title> <editor> In J. M. Peckman, editor, </editor> <booktitle> Proc. ACM SIGMOD, volume 26(2) of SIGMOD Record, </booktitle> <pages> pages 38-49, </pages> <address> Tucson, Arizona, </address> <month> May 13-15 </month> <year> 1997. </year>
Reference-contexts: More specifically, the SALES table will likely be indexed on each of its six dimensional attributes (namely, PartKey, SuppKey, CustKey, ShipDate, CommitDate and ReceiptDate). A number of indexing schemes have been proposed in the literature. Among these, four index types are shown in <ref> [13] </ref> to be particularly appropriate for OLAP systems: B + - trees , bitmapped indexes [12], projection indexes and bit-sliced indexes [13]. A DataIndex, like the projection index, exploits a positional indexing strategy. A projection index is simply a mirror image of the column being indexed. <p> A number of indexing schemes have been proposed in the literature. Among these, four index types are shown in <ref> [13] </ref> to be particularly appropriate for OLAP systems: B + - trees , bitmapped indexes [12], projection indexes and bit-sliced indexes [13]. A DataIndex, like the projection index, exploits a positional indexing strategy. A projection index is simply a mirror image of the column being indexed. <p> Any such record can easily be re-built from these since its component rows in the resulting tables all share the same ordinal position. This ordinal mapping is key to the idea of positional indexing. See <ref> [13, 16] </ref> for details. Each of the 7 new tables is a DataIndex. We now describe two specific types of DataIndexes, Basic DataIndexes and Join DataIndexes. Basic DataIndex (BDI) A DataIndex can be simply created as a vertical partition of a relational table. <p> Determining how much data to precompute is an issue that has been addressed in [7]. The work in indexing strategies includes traditional approaches, such as tree-based indexing (e.g., [9]), as well as non-traditional approaches, such as positional indexing, which has been proposed in <ref> [13, 16] </ref>. DataIndexes is a form of positional indexing. Algorithm 3 Parallel Star Join Note: Requires the DataIndexing scheme described in Section 3.1 and the partitioning strategy described in Section 3.2.
Reference: [14] <author> Red Brick Systems. </author> <title> Star schema processing for complex queries. </title> <type> White Paper, </type> <month> July </month> <year> 1997. </year>
Reference-contexts: Many queries on the star schema of Figure 1 would access one or more dimension tables and the central SALES table. Access methods that efficiently support join operations thus become crucial in decision support environments <ref> [12, 14] </ref>. The idea of a BDI presented in the previous section can very easily be extended to support such operations. Consider for instance, an analyst who is interested in possible trends or seasonalities in discounts offered to customers.
Reference: [15] <institution> Transaction Processing Performance Council, </institution> <address> San Jose, </address> <month> CA. </month> <title> TPC Benchmark D (Decision Support) Standard Specification, revision 1.2.3 edition, </title> <month> June </month> <year> 1997. </year>
Reference-contexts: In a ROLAP environment, the data is stored in a relational database using a star schema. A star schema usually consists of a single fact table and set of dimension tables. Consider the star schema presented in Figure 1, which was derived from the TPC-D benchmark database <ref> [15] </ref> (with a scale factor of 1). The schema models the activities of a world-wide wholesale supplier over a period of 7 years. The fact table is the SALES table, and the dimension tables are the PART, SUPPLIER, CUSTOMER, and TIME tables. <p> In a star-join, one or more dimension tables are joined with the fact table. For example, the following query is a three-dimensional star-join that identifies the volumes sold locally by suppliers in the United States for the period between 1996 and 1998 <ref> [15] </ref>: Query 1 SELECT U.Name, SUM (S.ExtPrice) FROM SALES S, TIME T, CUSTOMER C, SUPPLIER U WHERE T.Year BETWEEN 1996 AND 1998 AND U.Nation='United States' AND C.Nation='United States' AND S.ShipDate = T.TimeKey AND S.CustKey = C.CustKey AND S.SuppKey = U.SuppKey GROUP BY U.Name A set of attributes that are frequently used
Reference: [16] <author> I. Viguier, A. Datta, and K. Ramamritham. </author> <title> "have your data and index it, too", efficient storage and indexing for data warehouses. </title> <type> Technical Report GOOD-TR-9702, </type> <institution> Dept. of MIS, University of Ari-zona, </institution> <month> June </month> <year> 1997. </year> <note> Submitted for Publication URL: http://loochi.bpa.arizona.edu. </note>
Reference-contexts: The specific vertical partitioning method that we propose is referred to as DataIndexes. A DataIndex is a storage structure that serves both as an index as well as data <ref> [16] </ref>. We discuss DataIndexes in more detail in a later section. For now, we turn our attention to how parallelism can be achieved in OLAP systems. 3 Achieving Parallelism in Data Warehousing In this section we propose several preliminary ideas to achieve parallelism in data warehousing. <p> An important issue in parallel processing is the declustering of data. Declustering involves decomposing the database into chunks or partitions. We now propose a declustering scheme for a ROLAP star schema based on the principle of DataIndexes, a physical design strategy recently proposed in the literature <ref> [16] </ref>. <p> Any such record can easily be re-built from these since its component rows in the resulting tables all share the same ordinal position. This ordinal mapping is key to the idea of positional indexing. See <ref> [13, 16] </ref> for details. Each of the 7 new tables is a DataIndex. We now describe two specific types of DataIndexes, Basic DataIndexes and Join DataIndexes. Basic DataIndex (BDI) A DataIndex can be simply created as a vertical partition of a relational table. <p> This partition is referred to as a Basic DataIndex (BDI). Retrievals using BDIs rely on ordinal position to RID mapping. For exact details of the mapping from RID to ordinal position, refer to <ref> [16] </ref>. Join DataIndex (JDI) In decision support databases, a large portion of the workload consists of queries that operate on multiple tables. Many queries on the star schema of Figure 1 would access one or more dimension tables and the central SALES table. <p> The JDI on SALES.ShipDate would then consist of a list of RIDs on the TIME table. In this structure, instead of storing the data corresponding to the ShipDate column, the JDI provides a direct mapping between individual tuples of the SALES and TIME tables. It has been shown in <ref> [16] </ref> that the join required to answer Query 2 can thus be performed in a single scan of the JDI. This property of JDIs is indeed attractive, since the size of this index is, of course, proportional to the number of tuples in the table from which it was derived. <p> Determining how much data to precompute is an issue that has been addressed in [7]. The work in indexing strategies includes traditional approaches, such as tree-based indexing (e.g., [9]), as well as non-traditional approaches, such as positional indexing, which has been proposed in <ref> [13, 16] </ref>. DataIndexes is a form of positional indexing. Algorithm 3 Parallel Star Join Note: Requires the DataIndexing scheme described in Section 3.1 and the partitioning strategy described in Section 3.2.
References-found: 16

