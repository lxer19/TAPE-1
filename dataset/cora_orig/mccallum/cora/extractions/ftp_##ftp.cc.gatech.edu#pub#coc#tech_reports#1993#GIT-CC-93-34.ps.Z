URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1993/GIT-CC-93-34.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.93.html
Root-URL: 
Email: mahesh@cc.gatech.edu  
Title: GIT-CC-93/34 A Theory of Interaction and Independence in Sentence Understanding  
Author: Kavi Mahesh 
Degree: A THESIS PROPOSAL Presented to The Academic Faculty In Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy in Information and Computer Science The Committee: Dr. Kurt Eiselt (Advisor) Dr. Susan Bovair (Psychology) Dr. Ashwin Ram  
Date: February 1993  
Affiliation: Georgia Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [Abney and Johnson, 1991] <author> S. P. Abney and M. Johnson. </author> <title> Memory Requirements and Local Am biguities of Parsing Strategies. </title> <journal> Journal of Psycholinguistic Research, </journal> <volume> 20(3) </volume> <pages> 233-250, </pages> <year> 1991. </year>
Reference-contexts: The unified process in COMPERE is such a bottom-up, early-commitment parsing mechanism integrated with top-down guidance through expectations. The parsing method being developed is a variant of left-corner parsing methods which have distinct advantages in explaining human parsing behaviors <ref> [Abney and Johnson, 1991] </ref>. The operators and the control structure that constitute the unified process are shown briefly in the following algorithm: For each word in a sentence, in left to right order, 1. Access lexical entries (word). 2.
Reference: [Abney, 1989] <author> S. P. Abney. </author> <title> A Computational Model of Human Parsing. </title> <journal> Journal of Psycholinguistic Research, </journal> <volume> 18(1) </volume> <pages> 129-144, </pages> <year> 1989. </year>
Reference: [Allen, 1987] <author> J. Allen. </author> <title> Natural Language Understanding. </title> <publisher> The Benjamin/Cummings Publishing Company, Inc., </publisher> <year> 1987. </year>
Reference-contexts: For this purpose, we have adapted a set of thematic roles or cases listed in the classic textbook on Natural Language Understanding by James Allen <ref> [Allen, 1987] </ref>. They are: 5 UNIFIED COMPUTATIONAL MODEL: COMPERE 31 1. Agent 2. Theme 3. Experiencer 4. Beneficiary 5. Instrument 6. At-Location 7. To-Location 8. From-Location 9. Co-Agent 10.
Reference: [Bates et al., 1991] <author> E. Bates, B. Wulfeck, and B. MacWhinney. </author> <title> Cross-Linguistic Research in Apha sia: An Overview. </title> <journal> Brain and Language, </journal> <volume> 41(2) </volume> <pages> 123-148, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: We can study just one natural language and in particular, English. Though English is very different from many languages for instance in its relentless reliance on word order information <ref> [Bates et al., 1991] </ref>, we believe that the overall process and architecture of language processing is the same across languages. Differences, if any, would be in the relative importance of sources of information and in the strategies used for extracting the information from linguistic markings in the text.
Reference: [Birnbaum and Selfridge, 1981] <author> L. Birnbaum and M. Selfridge. </author> <title> Conceptual analysis of natural language. </title> <editor> In R. Schank and C. Riesbeck, editors, </editor> <booktitle> Inside Computer Understanding, </booktitle> <pages> pages 318-353. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1981. </year>
Reference-contexts: Syntax was ignored in integrated processing models attempting to fill the proper role of syntax by semantic or conceptual expectations <ref> [Birnbaum and Selfridge, 1981; Lebowitz, 1983; Lehnert et al., 1983] </ref>. However, "the use of such a criterion in parsing is bound often to be unreliable, since the reason for having syntax at all is presumably that real events frequently contradict such expectations" [Crain and Steedman, 1985; Forster, 1979].
Reference: [Birnbaum, 1986] <author> L. Birnbaum. </author> <title> Integrated Processing in Planning and Understanding. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> December </month> <year> 1986. </year> <note> Research Report #489. </note>
Reference-contexts: Functionally independent integrated processing: Different knowledge sources such as syntactic and semantic knowledge are accessible and applicable independent of one another. The Integrated Processing Hypothesis states that the language processor makes decisions as early as possible by integrating information from all available knowledge sources <ref> [Birnbaum, 1986] </ref>. The integrated processing hypothesis does not require integrated representations. Sentence processing can be an integrated process without having to integrate different sources of knowledge a priori. 2. <p> each other? These are questions that we attempt to answer in the course of this work. 3.1 Functionally independent integrated processing According to the integrated processing hypothesis, every kind of knowledge available to the sentence processor must be applied at the earliest opportunity in making decisions while processing a sentence <ref> [Birnbaum, 1986; Birnbaum, 1989; Schank, Lebowitz, and Birnbaum, 1980] </ref>. (See also the "Immediacy principle" of Carpenter and Just [Carpenter and Just, 1988].) Functional independence, on the other hand, says that different knowledge sources are usable independent of each other [Caramazza and Berndt, 1978]. <p> By retaining functional independence, we can give each kind of knowledge that goes into sentence understanding its proper role. Only then can a model of sentence processing adhere to the integrated processing hypothesis <ref> [Birnbaum, 1986] </ref> by applying knowledge of any and all types whenever possible to make ambiguity-resolution decisions. <p> semantics preceding syntax, was proposed by Lytinen (1986) and implemented in the MOPTRANS program. 10 However, we do ignore phonology, morphology, and so on; also, there is no model of pragmatic or discourse processing at the present time. 4 SENTENCE PROCESSING MODELS 24 4.3 Integrated Models The Integrated Processing Hypothesis <ref> [Birnbaum, 1986; Birnbaum, 1989; Schank et al., 1980] </ref> states that the language processor applies syntactic, semantic, and other kinds of knowledge at the earliest opportunity in processing a piece of text. Thus, it is essentially a different expression of the same hypothesis that Stowe called the Immediate Semantic Decision Hypothesis.
Reference: [Birnbaum, 1989] <author> L. Birnbaum. </author> <title> A Critical Look at the Foundations of Autonomous Syntactic Analysis. </title> <booktitle> In Proceedings of the Eleventh Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 99-106. </pages> <publisher> Cognitive Science Society, </publisher> <year> 1989. </year>
Reference-contexts: each other? These are questions that we attempt to answer in the course of this work. 3.1 Functionally independent integrated processing According to the integrated processing hypothesis, every kind of knowledge available to the sentence processor must be applied at the earliest opportunity in making decisions while processing a sentence <ref> [Birnbaum, 1986; Birnbaum, 1989; Schank, Lebowitz, and Birnbaum, 1980] </ref>. (See also the "Immediacy principle" of Carpenter and Just [Carpenter and Just, 1988].) Functional independence, on the other hand, says that different knowledge sources are usable independent of each other [Caramazza and Berndt, 1978]. <p> semantics preceding syntax, was proposed by Lytinen (1986) and implemented in the MOPTRANS program. 10 However, we do ignore phonology, morphology, and so on; also, there is no model of pragmatic or discourse processing at the present time. 4 SENTENCE PROCESSING MODELS 24 4.3 Integrated Models The Integrated Processing Hypothesis <ref> [Birnbaum, 1986; Birnbaum, 1989; Schank et al., 1980] </ref> states that the language processor applies syntactic, semantic, and other kinds of knowledge at the earliest opportunity in processing a piece of text. Thus, it is essentially a different expression of the same hypothesis that Stowe called the Immediate Semantic Decision Hypothesis.
Reference: [Caramazza and Berndt, 1978] <author> A. Caramazza and R. S. Berndt. </author> <title> Semantic and syntactic processes in aphasia: A review of the literature. </title> <journal> Psychological Bulletin, </journal> <volume> 85 </volume> <pages> 898-918, </pages> <year> 1978. </year>
Reference-contexts: at the earliest opportunity in making decisions while processing a sentence [Birnbaum, 1986; Birnbaum, 1989; Schank, Lebowitz, and Birnbaum, 1980]. (See also the "Immediacy principle" of Carpenter and Just [Carpenter and Just, 1988].) Functional independence, on the other hand, says that different knowledge sources are usable independent of each other <ref> [Caramazza and Berndt, 1978] </ref>. If, for some reason, a knowledge source fails to provide any information for making a decision, information arising from other knowledge sources can still be applied to make the best decision based on available information. <p> It allows each faculty to function if others fail for some reason <ref> [Caramazza and Berndt, 1978; Eiselt, 1989] </ref>. Functional independence need not necessarily mean neurological independence, according to which there are separate parts of the brain corresponding to the different functions of language processing. There are several reasons for hypothesizing a functionally independent architecture for the sentence processor. <p> sentence processing seem to suggest a fast, autonomous, automatic process [Fodor, 1983; Fodor, 1987]. 3 EVIDENCE FOR THE CLAIMS 12 3 EVIDENCE FOR THE CLAIMS 13 Evidence from Aphasic Studies: An important source of evidence for functional independence between levels of language processing lies in behavioral studies with aphasic subjects <ref> [Caramazza and Berndt, 1978] </ref>. People who have suffered focal neural damage in the Broca's area, Broca's aphasics, exhibit impaired syntactic processing abilities. Those with a damage in a different part, Wernicke's aphasics, appear to retain syntactic processing abilities but have trouble producing coherent semantic content.
Reference: [Carpenter and Daneman, 1981] <author> P. A. Carpenter and M. Daneman. </author> <title> Lexical Retrieval and Error Recovery in Reading: A Model Based on Eye Fixations. </title> <journal> Journal of Verbal Learning and Verbal Behavior, </journal> <volume> 20 </volume> <pages> 137-160, </pages> <year> 1981. </year>
Reference-contexts: Information coming later on in the sentence might alter their preferences for different interpretations. People are capable not only of resolving ambiguities but also recovering from such errors in many cases <ref> [Carpenter and Daneman, 1981; Eiselt, 1989; Eiselt and Holbrook, 1991] </ref>. Not all errors in resolving an ambiguity lead to a garden path. People can often recover from the errors they make locally when later input shows the error.
Reference: [Carpenter and Just, 1988] <author> P. A. Carpenter and M. A. </author> <title> Just. The Role of Working Memory in Lan guage Comprehension. </title> <editor> In D. Klahr and K. Kotovsky, editors, </editor> <title> Complex information processing: The impact of Herbert A. </title> <publisher> Simon. Erlbaum, </publisher> <year> 1988. </year>
Reference-contexts: independent integrated processing According to the integrated processing hypothesis, every kind of knowledge available to the sentence processor must be applied at the earliest opportunity in making decisions while processing a sentence [Birnbaum, 1986; Birnbaum, 1989; Schank, Lebowitz, and Birnbaum, 1980]. (See also the "Immediacy principle" of Carpenter and Just <ref> [Carpenter and Just, 1988] </ref>.) Functional independence, on the other hand, says that different knowledge sources are usable independent of each other [Caramazza and Berndt, 1978].
Reference: [Charniak, 1983] <author> E. Charniak. </author> <title> Passing Markers: A Theory of Contextual Influence in Language Comprehension. </title> <journal> Cognitive Science, </journal> <volume> 7 </volume> <pages> 171-190, </pages> <year> 1983. </year>
Reference-contexts: For instance, even in the total absence of syntax as in (7) we still get some meaning out of the text. (7a) Skid crash hospital. [Winograd, 1973] (7b) Fire match arson hotel. <ref> [Charniak, 1983] </ref> Lack of independence of syntax also leads to difficulties in accounting for syntactic generalizations across different semantic entities.
Reference: [Chomsky, 1957] <author> N. Chomsky. </author> <title> Syntactic structures. </title> <publisher> Mouton, </publisher> <year> 1957. </year>
Reference-contexts: Intuitively, human sentence understanding behavior shows the independence of syntax and semantics. To illustrate this point, one can argue that, for instance, people can judge grammaticality independent of meaning as in sentences like (6) which make little sense if any <ref> [Chomsky, 1957] </ref>. (6) Colorless green ideas sleep furiously. On the other hand, people can put up with imperfect syntax and get the meaning out of ungram-matical strings of words.
Reference: [Clifton and Ferreira, 1987] <author> C. Clifton and F. Ferreira. </author> <title> Modularity in sentence comprehension. </title> <editor> In J. L. Garfield, editor, </editor> <title> Modularity in Knowledge Representation and Natural-Language Understanding. </title> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: Another source of evidence for autonomy comes from psycholinguistic experiments using eye-movement recording techniques to measure word-by-word reading times <ref> [Clifton and Ferreira, 1987; Frazier, 1987] </ref>. Such studies show that people take longer to read the disambiguating part of a garden-path sentence such as the emphasized parts of (10) irrespective of contextual bias. (10) The editor played the tape agreed the story was big.
Reference: [Cottrell, 1985] <author> G. W. Cottrell. </author> <title> Connectionist Parsing. </title> <booktitle> In Proceedings of the Seventh Annual Conference of the Cognitive Science Society, </booktitle> <address> Irvine, CA, </address> <pages> pages 201-211, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: common format . "These similarities are compatible with models in which lexical and grammatical forms are represented in a common format and/or accessed by a common set of processing mechanisms. ..." [Bates, et al., 1991] Uncontrolled interaction between separate processes as it happens in certain connectionist network models for instance <ref> [Cottrell, 1985; Waltz and Pollack, 1984; Waltz and Pollack, 1985] </ref>, does not seem to be capable of producing the kind of ambiguity resolution behaviors observable in limited delayed decisions and error recoveries. <p> However, it should be generalized to show the differences between (1) and (2) for instance. (2) The courses taught at the academy were very demanding. * Demonstrate functional independence. One way to do this is by means of lesion studies <ref> [Cottrell, 1985; Small, 1991] </ref>. We can turn off syntactic or semantic processing by making the corresponding type of knowledge unavailable to show that the other can still function normally. This was attempted with ungrammatical sentences.
Reference: [Crain and Steedman, 1985] <author> S. Crain and M. Steedman. </author> <title> On not being led up the garden path: the use of context by the psychological syntax processor. </title> <editor> In D. R. Dowty, L. Karttunen, and A. M. Zwicky, editors, </editor> <booktitle> Natural Language Parsing: Psychological, computational, and theoretical perspectives. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1985. </year> <note> REFERENCES 59 </note>
Reference-contexts: interaction of knowledge at different levels. 3.1.1 Evidence for Integration Intuitively, since the purpose of language is its communicative function and not syntactic gram-maticality judgment, the human language processor should use the meaning of the text as early as possible in making any decision during the course of language understanding <ref> [Crain and Steedman, 1985; Tyler and Marslen-Wilson, 1977] </ref>. Thus, the human sentence understander is forever trying to integrate information arising from knowledge sources at different levels in order to come up with a single interpretation that makes the best sense overall (i.e., at the syntactic, semantic, conceptual, and other levels). <p> For example, such higher-level information might be the knowledge that only animate objects can be actors of teaching. The More Constraints the Better: Natural languages appear to allow a high degree of local syntactic ambiguity <ref> [Crain and Steedman, 1985] </ref>. If the sentence processor supports interaction between syntax and higher levels, and if it produces fully interpreted semantic entities corresponding to incomplete fragments of the sentence, the context in which these entities are evaluated can be a powerful source of redundancy. <p> However, "the use of such a criterion in parsing is bound often to be unreliable, since the reason for having syntax at all is presumably that real events frequently contradict such expectations" <ref> [Crain and Steedman, 1985; Forster, 1979] </ref>. In integrated models, information available right away from syntax could not be utilized in making sentence processing decisions. <p> In other situations, semantic preferences could influence the decisions that the processor makes in resolving syntactic ambiguities. Such behavior would be the same as the ones explained by models which argue for the early effects of semantic and contextual information in syntactic processing <ref> [e.g., Crain and Steedman, 1985; Tyler and Marslen-Wilson, 1977] </ref>.
Reference: [Eiselt and Holbrook, 1991] <author> K. P. Eiselt and J. K. Holbrook. </author> <title> Toward a Unified Theory of Lexical Error Recovery. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society. Cognitive Science Society, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Information coming later on in the sentence might alter their preferences for different interpretations. People are capable not only of resolving ambiguities but also recovering from such errors in many cases <ref> [Carpenter and Daneman, 1981; Eiselt, 1989; Eiselt and Holbrook, 1991] </ref>. Not all errors in resolving an ambiguity lead to a garden path. People can often recover from the errors they make locally when later input shows the error. <p> It would then switch to the interpretation that is now best with respect to the new information as well as the earlier. This theory of conditional retention and error recovery in lexical processing was verified psychologically by experimental results <ref> [Eiselt and Holbrook, 1991; Holbrook, 1989] </ref>. The computational model demonstrated that the same mechanism could account for recovery from errors in resolving pragmatic ambiguities. Syntactic Error Recovery: Studies of structural ambiguity resolution in syntax showed error recovery behaviors similar to that in semantics as described above.
Reference: [Eiselt et al., To appear] <author> K. Eiselt, K. Mahesh, and J. Holbrook. </author> <title> Having Your Cake and Eating It Too: Autonomy and Interaction in a Model of Sentence Processing. </title> <booktitle> To appear in the Proceedings of the Eleventh National Conference on Artificial Intelligence, AAAI-93, </booktitle> <month> July 11-16, </month> <year> 1993, </year> <note> To appear. </note>
Reference-contexts: are crucial to the design of an integrated language processing and reasoning system. 3.3 Unified process The unified process claim for syntactic and semantic error recovery can be interpreted to say that the human sentence processor is best described as a single unified process operating on several independent knowledge sources <ref> [Eiselt et al., To appear; Holbrook et al., 1992] </ref>. To say that the two kinds of errors are handled the same way is to say that the overall control structure of the sentence understanding process is the same for syntax and semantics. <p> We plan to extend the semantics in COMPERE to include other aspects of linguistic semantics such as time and tense, space, modification, and so on [Frawley, 1992]. 5.3 The unified model: COMPERE Our model of sentence understanding called COMPERE (Cognitive Model of Parsing and Error Recovery) 13 (Figure 13) <ref> [Eiselt et al., To appear; Holbrook et al., 1992] </ref> has a single unified process operating on independent sources of syntactic and semantic knowledge. This is made possible by a uniform representation of both kinds of knowledge in the same form.
Reference: [Eiselt, 1985] <author> K. Eiselt. </author> <title> A Parallel-process Model of On-Line Inference Processing. </title> <booktitle> In Proc. of IJCAI-85, </booktitle> <pages> pages 863-869, </pages> <address> Los Angeles, CA, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: model is that it loses independence between its knowledge sources gradually as the model chunks them together into monolithic units. 4 SENTENCE PROCESSING MODELS 26 4.4.3 The ATLAST model A model which used this decomposition, though it did not actually model all levels of sentence processing, is the ATLAST model <ref> [Eiselt, 1985; Eiselt, 1989] </ref>. ATLAST was a model of unified lexical (semantic) and pragmatic ambiguity resolution and error recovery. Syntactic knowledge was assumed to be processed separately using an augmented transition network (ATN) parser.
Reference: [Eiselt, 1989] <author> K. P. Eiselt. </author> <title> Inference Processing and Error Recovery in Sentence Understanding. </title> <type> Ph.D. thesis, </type> <institution> University of California, </institution> <address> Irvine, CA, </address> <year> 1989. </year> <type> Tech. Report 89-24. </type>
Reference-contexts: It allows each faculty to function if others fail for some reason <ref> [Caramazza and Berndt, 1978; Eiselt, 1989] </ref>. Functional independence need not necessarily mean neurological independence, according to which there are separate parts of the brain corresponding to the different functions of language processing. There are several reasons for hypothesizing a functionally independent architecture for the sentence processor. <p> Information coming later on in the sentence might alter their preferences for different interpretations. People are capable not only of resolving ambiguities but also recovering from such errors in many cases <ref> [Carpenter and Daneman, 1981; Eiselt, 1989; Eiselt and Holbrook, 1991] </ref>. Not all errors in resolving an ambiguity lead to a garden path. People can often recover from the errors they make locally when later input shows the error. <p> Not all errors in resolving an ambiguity lead to a garden path. People can often recover from the errors they make locally when later input shows the error. Lexical and Pragmatic Error Recovery: The ATLAST model <ref> [Eiselt, 1989] </ref> proposed a Conditional Retention Mechanism [Holbrook et al., 1988] for error recovery in resolving lexical and pragmatic ambiguities. According to this, the sentence processor selects the best interpretation in the current context and makes an early commitment when possible. <p> model is that it loses independence between its knowledge sources gradually as the model chunks them together into monolithic units. 4 SENTENCE PROCESSING MODELS 26 4.4.3 The ATLAST model A model which used this decomposition, though it did not actually model all levels of sentence processing, is the ATLAST model <ref> [Eiselt, 1985; Eiselt, 1989] </ref>. ATLAST was a model of unified lexical (semantic) and pragmatic ambiguity resolution and error recovery. Syntactic knowledge was assumed to be processed separately using an augmented transition network (ATN) parser. <p> An obvious reason is parsimony. Why start with many different processes if we can do with just one? A more important reason is the evidence from Stowe's experiments which showed that people's ambiguity resolution and error recovery behavior in syntactic ambiguities is much the same as what ATLAST <ref> [Eiselt, 1989] </ref> demonstrated for lexical and pragmatic ambiguities. Given that these ambiguities require the use of different kinds of knowledge to be resolved, we have some evidence for the existence of the same kind of ambiguity resolution and error recovery happening in different faculties. <p> Stowe's work (1991) showed that syntactic analysis as it happens in human sentence processing is itself pretty much the same process as the semantic analysis process such as the one proposed in ATLAST <ref> [Eiselt, 1989] </ref>. For instance, it accesses multiple structures in parallel, can pursue multiple interpretations in parallel, can switch from one interpretation to another, and interacts with other faculties of language processing. <p> same (spreading activation) process. 5 UNIFIED COMPUTATIONAL MODEL: COMPERE 29 5 Unified Computational Model: COMPERE In the last section we saw several models of sentence processing with a variety of architectures from the sequential architecture of Forster's model to the integrated architecture of IPP to the parallel architecture of ATLAST <ref> [Eiselt, 1989; Forster, 1979; Lebowitz, 1983] </ref>. Before looking at our model of sentence understanding, let us take a moment to see the set of assumptions on which COMPERE is based. 5.1 Assumptions As any exploratory theory, COMPERE has been designed by assuming several things. <p> However, we believe that extending the ambiguity resolution capabilities of the unified process to the domain of semantics amounts to simple and straightforward modifications to the program. COMPERE's ancestor program, ATLAST <ref> [Eiselt, 1989] </ref>, has demonstrated such ambiguity resolution capabilities and we plan to incorporate them in COMPERE in the near future. 5.7 Error Recovery COMPERE is able to make the kinds of errors that people do and to recover from them automatically, as people do. <p> Our model also retains information about alternative interpretations so that it can switch to one of the retained interpretations if later information proves the current interpretation wrong. We have shown that this method, proposed originally for semantic and pragmatic error recovery <ref> [Eiselt, 1989] </ref>, is applicable to syntactic error recovery as well. 7.2 Further Work Though we have presented this work at times as though it has been completed, there is a lot of it that is still to be modeled or not completely understood.
Reference: [Ferreira and Clifton, 1985] <author> F. Ferreira and C. Clifton. </author> <title> The Independence of Syntactic Processing. </title> <journal> The Journal of Memory and Language, </journal> <volume> 25 </volume> <pages> 348-368, </pages> <year> 1985. </year>
Reference: [Fodor, 1978] <author> J. D. Fodor. </author> <title> Parsing strategies and constraints on transformations. </title> <booktitle> Linguistic In quiry, </booktitle> <volume> 9 </volume> <pages> 427-474, </pages> <year> 1978. </year>
Reference: [Fodor, 1983] <author> J. A. Fodor. </author> <title> The Modularity of Mind. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference-contexts: Further intuitive support for autonomy comes from the complexity of interaction and that of integrating preferences from several higher levels in making online decisions. The speed and automaticity of decisions at the lower levels of sentence processing seem to suggest a fast, autonomous, automatic process <ref> [Fodor, 1983; Fodor, 1987] </ref>. 3 EVIDENCE FOR THE CLAIMS 12 3 EVIDENCE FOR THE CLAIMS 13 Evidence from Aphasic Studies: An important source of evidence for functional independence between levels of language processing lies in behavioral studies with aphasic subjects [Caramazza and Berndt, 1978].
Reference: [Fodor, 1987] <author> J. A. Fodor. </author> <title> Modules, Frames, Fridgeons, Sleeping Dogs, and the Music of the Spheres. </title> <editor> In J. L. Garfield, editor, </editor> <title> Modularity in Knowledge Representation and Natural-Language Understanding. </title> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: Further intuitive support for autonomy comes from the complexity of interaction and that of integrating preferences from several higher levels in making online decisions. The speed and automaticity of decisions at the lower levels of sentence processing seem to suggest a fast, autonomous, automatic process <ref> [Fodor, 1983; Fodor, 1987] </ref>. 3 EVIDENCE FOR THE CLAIMS 12 3 EVIDENCE FOR THE CLAIMS 13 Evidence from Aphasic Studies: An important source of evidence for functional independence between levels of language processing lies in behavioral studies with aphasic subjects [Caramazza and Berndt, 1978]. <p> The amount and nature of interaction between the different modules can be described in terms of different kinds of modularity <ref> [Fodor, 1987; Marslen-Wilson and Tyler, 1987; Tanenhaus et al., 1987] </ref>. Representational modularity, also known as information encapsulation, means that each module has its own exclusive representation of a kind of knowledge that is not accessible to any other module. Knowledge sources are exclusive to processes.
Reference: [Ford et al., 1983] <author> M. Ford, J. Bresnan, and R. Kaplan. </author> <title> A competence-based theory of syntactic closure. </title> <editor> In J. Bresnan, editor, </editor> <title> The Mental Representation of Grammatical Relations. </title> <publisher> MIT Press, </publisher> <year> 1983. </year>
Reference: [Forster, 1979] <author> K. I. Forster. </author> <title> Levels of Processing and the Structure of the Language Processor. </title> <editor> In W. E. Cooper and E. C. T. Walker, editors, </editor> <title> Sentence Processing: Psycholinguistic Studies Presented to Merrill Garrett. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1979. </year>
Reference-contexts: However, "the use of such a criterion in parsing is bound often to be unreliable, since the reason for having syntax at all is presumably that real events frequently contradict such expectations" <ref> [Crain and Steedman, 1985; Forster, 1979] </ref>. In integrated models, information available right away from syntax could not be utilized in making sentence processing decisions. <p> same (spreading activation) process. 5 UNIFIED COMPUTATIONAL MODEL: COMPERE 29 5 Unified Computational Model: COMPERE In the last section we saw several models of sentence processing with a variety of architectures from the sequential architecture of Forster's model to the integrated architecture of IPP to the parallel architecture of ATLAST <ref> [Eiselt, 1989; Forster, 1979; Lebowitz, 1983] </ref>. Before looking at our model of sentence understanding, let us take a moment to see the set of assumptions on which COMPERE is based. 5.1 Assumptions As any exploratory theory, COMPERE has been designed by assuming several things.
Reference: [Frawley, 1992] <author> W. Frawley. </author> <title> Linguistic Semantics. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1992. </year>
Reference-contexts: Thematic roles alone do not of course completely capture the semantics of a natural language. We plan to extend the semantics in COMPERE to include other aspects of linguistic semantics such as time and tense, space, modification, and so on <ref> [Frawley, 1992] </ref>. 5.3 The unified model: COMPERE Our model of sentence understanding called COMPERE (Cognitive Model of Parsing and Error Recovery) 13 (Figure 13) [Eiselt et al., To appear; Holbrook et al., 1992] has a single unified process operating on independent sources of syntactic and semantic knowledge. <p> We could extend the semantics to capture other aspects of meaning such as spatial and temporal relationships <ref> [Frawley, 1992] </ref>. * We could enhance conceptual processing capabilities and figure out how to use the output of COMPERE in a reasoning task.
Reference: [Frazier and Rayner, 1982] <author> L. Frazier and K. Rayner. </author> <title> Making and Correcting Errors during Sen tence Comprehension: Eye Movements in the Analysis of Structurally Ambiguous Sentences. </title> <journal> Cognitive Psychology, </journal> <volume> 14 </volume> <pages> 178-210, </pages> <year> 1982. </year>
Reference: [Frazier and Rayner, 1987] <author> L. Frazier and K. Rayner. </author> <title> Resolution of Syntactic Category Ambi guities: Eye Movements in Parsing Lexically Ambiguous Sentences. </title> <journal> Journal of Memory and Language, </journal> <volume> 26 </volume> <pages> 505-526, </pages> <year> 1987. </year>
Reference-contexts: Similarly, eye-movement studies by Frazier, Rayner and others, <ref> [Frazier and Rayner, 1987; Frazier, 1989] </ref> have shown that categorially ambiguous words do not result in immediate selection.
Reference: [Frazier et al., 1983] <author> L. Frazier, C. Clifton, and J. Randall. </author> <title> Filling Gaps: Decision Principles and Structure in Sentence Comprehension. </title> <journal> Cognition, </journal> <volume> 13 </volume> <pages> 187-222, </pages> <year> 1983. </year>
Reference: [Frazier, 1987] <author> L. Frazier. </author> <title> Theories of Sentence Processing. </title> <editor> In J. L. Garfield, editor, </editor> <booktitle> Modularity in Knowledge Representation and Natural Language Understanding. </booktitle> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: An example of the kind of sentences they used is shown in (5). (5a) The reporter exposed corruption in government. (5b) The reporter exposed corruption in the article. They found that people had no structural preference such as minimal attachment <ref> [Kimball, 1973; Frazier, 1987] </ref>. Instead, they found a significant interaction with sentential context. For instance, 3 EVIDENCE FOR THE CLAIMS 9 when the context predicted high attachment, VP attachment was easier (as in (5b)), but when the context predicted nominal attachment, attachment to the NP was easier instead ((5a)). <p> An example of a syntactic generalization exhibited by the language processor in a variety of constructs is the Minimal Attachment principle <ref> [Frazier, 1987; Kimball, 1973] </ref> which subsumes a class of preferences for a syntactically minimal interpretation. <p> These behaviors can be explained by a preference called the Minimal Attachment criterion <ref> [Frazier, 1987; Kimball, 1973] </ref> according to which the sentence processor prefers that structure which has the least number of nodes in it. That is, the interpretation which is minimal in structure gets selected. <p> That is, the interpretation which is minimal in structure gets selected. Minimal attachment is a very general criterion applicable to many different kinds of sentences and has been used as the criterion for syntactic decisions made at local structural ambiguities <ref> [Frazier, 1987] </ref>. However, there are competing structural preferences such as Right Association [Kimball, 1973] which seem to work at other times in sentences where minimal attachment fails. <p> Another source of evidence for autonomy comes from psycholinguistic experiments using eye-movement recording techniques to measure word-by-word reading times <ref> [Clifton and Ferreira, 1987; Frazier, 1987] </ref>. Such studies show that people take longer to read the disambiguating part of a garden-path sentence such as the emphasized parts of (10) irrespective of contextual bias. (10) The editor played the tape agreed the story was big. <p> selects one 8 While the alternative explanation that the sentence processor conducts a partial, underdetermined analysis of the sentence so that it can continue any of the multiple analyses after seeing later evidence, is an interesting one, it cannot explain garden path behaviors caused by the inferiority of certain interpretations <ref> [Frazier, 1987] </ref>. 3 EVIDENCE FOR THE CLAIMS 18 subcategorization based only on general syntactic preferences such as the minimal attachment principle. For instance, in (16), know can take either a noun phrase or a sentential complement. (16) Karen knew the answer to the difficult problem was correct. <p> Syntactic Preferences: Syntactic preferences have been considered to result from structural criteria such as high or low attachment or minimality of the number of nodes in a structure <ref> [Frazier, 1987] </ref>. Thus the sentence processor is said to choose the minimal structure or one with right association and so on. <p> COMPERE is intended to demonstrate that the range of behaviors that these models account for, and the behaviors that the "first analysis" models <ref> [e.g., Frazier, 1987] </ref> account for, can be explained by a unified model with a single processor operating on multiple independent sources of knowledge. 5.8 COMPERE, the Program COMPERE has been implemented in a Common Lisp computer program. We have adopted the method of incremental design in building this program.
Reference: [Frazier, 1989] <author> L. Frazier. </author> <title> Against Lexical Generation of Syntax. </title> <editor> In W. Marslen-Wilson, editor, </editor> <title> Lexical Representation and Process. </title> <publisher> MIT Press, </publisher> <year> 1989. </year> <note> REFERENCES 60 </note>
Reference-contexts: Similarly, eye-movement studies by Frazier, Rayner and others, <ref> [Frazier and Rayner, 1987; Frazier, 1989] </ref> have shown that categorially ambiguous words do not result in immediate selection. <p> More than all, there is evidence against such lexical generation of syntax <ref> [Frazier, 1989] </ref>. The sentence processor seems to be delaying decisions as we saw earlier when there are major categorial ambiguities such as a noun-verb ambiguity. It however makes immediate decisions without waiting for disambiguating information in subcategory ambiguities such as a transitive-intransitive ambiguity. <p> Other approaches to categorial grammars combine semantic information to various degrees in their categories. This not only takes away the independence between syntax and semantics, it also makes processing more lexically based. Such an account will have difficulties capturing the generalization observable in syntactic processing <ref> [Frazier, 1989] </ref> apart from not being parsimonious. Our representation tries to capture generalizations as far as possible by representing argument structures separately from the major syntactic categories and by hierarchicalizing the categorial information.
Reference: [Goel and Eiselt, 1991] <author> A. K. Goel and K. P. Eiselt. </author> <title> Mental Models, Text Interpretation, and Knowledge Acquisition. </title> <booktitle> AAAI Spring Symposium on Integrated Intelligent Architectures, </booktitle> <year> 1991. </year>
Reference: [Holbrook et al., 1988] <author> J. K. Holbrook, K. P. Eiselt, R. H. Granger, and E. H. Matthei. </author> <title> (Almost) Never Letting Go: Inference Retention during Text Understanding. </title> <editor> In S. L. Small, G. W. Cottrell, and M. K. Tanenhaus, editors, </editor> <title> Lexical Ambiguity Resolution: Perspectives from Psy-cholinguistics, Neuropsychology, </title> <booktitle> and Artificial Intelligence, </booktitle> <pages> pages 383-409. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1988. </year>
Reference-contexts: Not all errors in resolving an ambiguity lead to a garden path. People can often recover from the errors they make locally when later input shows the error. Lexical and Pragmatic Error Recovery: The ATLAST model [Eiselt, 1989] proposed a Conditional Retention Mechanism <ref> [Holbrook et al., 1988] </ref> for error recovery in resolving lexical and pragmatic ambiguities. According to this, the sentence processor selects the best interpretation in the current context and makes an early commitment when possible. However, it does not discard the alternative interpretations; it retains them for possible later use.
Reference: [Holbrook et al., 1992] <author> J. K. Holbrook, K. P. Eiselt, and K. Mahesh. </author> <title> A Unified Process Model of Syntactic and Semantic Error Recovery in Sentence Understanding. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 195-200. </pages> <publisher> Cognitive Science Society, </publisher> <month> August </month> <year> 1992. </year>
Reference-contexts: are crucial to the design of an integrated language processing and reasoning system. 3.3 Unified process The unified process claim for syntactic and semantic error recovery can be interpreted to say that the human sentence processor is best described as a single unified process operating on several independent knowledge sources <ref> [Eiselt et al., To appear; Holbrook et al., 1992] </ref>. To say that the two kinds of errors are handled the same way is to say that the overall control structure of the sentence understanding process is the same for syntax and semantics. <p> We plan to extend the semantics in COMPERE to include other aspects of linguistic semantics such as time and tense, space, modification, and so on [Frawley, 1992]. 5.3 The unified model: COMPERE Our model of sentence understanding called COMPERE (Cognitive Model of Parsing and Error Recovery) 13 (Figure 13) <ref> [Eiselt et al., To appear; Holbrook et al., 1992] </ref> has a single unified process operating on independent sources of syntactic and semantic knowledge. This is made possible by a uniform representation of both kinds of knowledge in the same form. <p> It can deal with fairly complex syntax with relative clauses and complements. However, its role knowledge is fairly limited at this time and its conceptual knowledge is even more so. The COMPERE program follows closely the spirit of our theoretical model described earlier <ref> [Holbrook et al., 1992] </ref>, but diverges slightly in actual implementation.
Reference: [Holbrook, 1989] <author> J. K. Holbrook. </author> <title> Studies of inference retention in lexical ambiguity resolution. </title> <type> Ph.D. thesis, </type> <institution> School of Social Sciences, University of California, Irvine, </institution> <year> 1989. </year>
Reference-contexts: It would then switch to the interpretation that is now best with respect to the new information as well as the earlier. This theory of conditional retention and error recovery in lexical processing was verified psychologically by experimental results <ref> [Eiselt and Holbrook, 1991; Holbrook, 1989] </ref>. The computational model demonstrated that the same mechanism could account for recovery from errors in resolving pragmatic ambiguities. Syntactic Error Recovery: Studies of structural ambiguity resolution in syntax showed error recovery behaviors similar to that in semantics as described above.
Reference: [Holmes et al., 1989] <author> V. M. Holmes, L. Stowe, and L. Cupples. </author> <title> Lexical Expectations in Parsing Complement-Verb Sentences. </title> <journal> Journal of Memory and Language, </journal> <volume> 28 </volume> <pages> 668-689, </pages> <year> 1989. </year>
Reference: [Holmes, 1987] <author> V. M. Holmes. </author> <title> Syntactic parsing: In search of the garden path. </title> <editor> In M. Coltheart, editor, </editor> <title> Attention and Performance XII. </title> <publisher> Erlbaum, </publisher> <year> 1987. </year>
Reference: [Jacobs et al., 1990] <author> P. S. Jacobs, G. R. Krupka, S. W. McRoy, L. F. Rau, N. K. Sondheimer, and U. Zernik. </author> <title> Generic Text Processing: A Progress Report. </title> <booktitle> In Proceedings DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 359-364. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <month> June </month> <year> 1990. </year>
Reference: [Jurafsky, 1991] <author> D. Jurafsky. </author> <title> An On-Line Model of Human Sentence Interpretation. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 449-454. </pages> <publisher> Cognitive Science Society, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: Such a decomposition was used by Jurafsky who called the three steps above access, integration, and selection <ref> [Jurafsky, 1991; Jurafsky, 1992] </ref>. Jurafsky's model was also an integrated model since all types of knowledge were represented in integrated units called grammatical constructions. <p> We also assume that people do not reprocess surface structures internally in some kind of buffer which would store parts of the sentence they are currently reading. 8. We do not need structural transformations in syntax. We are assuming, as others have done before <ref> [e.g., Jurafsky, 1991] </ref>, that constructs such as questions for which transformations have been proposed can be handled in semantics without having to do transformations in syntax. 9. The language processor has a universal goal to resolve ambiguities by choosing one from a set of possible interpretations. 10. <p> It can not for instance, produce the deep structure of a question through WH-transformations. We assume that question words can be dealt with in semantics, as others have shown in their models <ref> [Jurafsky, 1991] </ref>. We make no attempt to process question words in this work. The above analysis does not consider certain grammatical features such as agreement in gender, number, person, tense, reflexives, tag questions, and so on.
Reference: [Jurafsky, 1992] <author> D. Jurafsky. </author> <title> An On-Line Computational Model of Human Sentence Interpretation. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, AAAI 92, </booktitle> <pages> pages 302-308, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: We claim that integrated processing does not preclude functional independence. A number of people have (implicitly) assumed that integrated processing implies integrated representations. For instance, models such as CA, IPP, and the recent model by Jurafsky have no separable representation of syntactic knowledge <ref> [e.g., Jurafsky, 1992; Lebowitz, 1983] </ref>. In fact, the approach taken by Jurafsky, namely, to represent every kind of knowledge in integrated knowledge structures called grammatical constructions, rules out the independent access and application of any one type of knowledge. <p> Such a decomposition was used by Jurafsky who called the three steps above access, integration, and selection <ref> [Jurafsky, 1991; Jurafsky, 1992] </ref>. Jurafsky's model was also an integrated model since all types of knowledge were represented in integrated units called grammatical constructions.
Reference: [Just and Carpenter, 1992] <author> M. A. Just and P. Carpenter. </author> <title> A Capacity Theory of Comprehension: Individual Differences in Working Memory. </title> <journal> Psychological Review, </journal> <volume> 99(1) </volume> <pages> 122-149, </pages> <year> 1992. </year>
Reference: [Kay, 1973] <author> M. Kay. </author> <title> The MIND System. </title> <editor> In R. Rustin, editor, </editor> <booktitle> Natural language processing, </booktitle> <pages> pages 155-188. </pages> <publisher> Algorithmics Press, </publisher> <year> 1973. </year>
Reference-contexts: One can perform a purely bottom-up processing with a grammar represented as a set of rules. However, this is not efficient since it would make commitments much later than it could; a bottom-up parser such as a chart parser <ref> [Kay, 1973] </ref> does not commit to a structure until it has seen every part of it. Such a parser would not be an online model of parsing.
Reference: [Kimball, 1973] <author> J. Kimball. </author> <title> Seven Principles of Surface Structure Parsing. </title> <journal> Cognition, </journal> <volume> 2 </volume> <pages> 15-47, </pages> <year> 1973. </year>
Reference-contexts: An example of the kind of sentences they used is shown in (5). (5a) The reporter exposed corruption in government. (5b) The reporter exposed corruption in the article. They found that people had no structural preference such as minimal attachment <ref> [Kimball, 1973; Frazier, 1987] </ref>. Instead, they found a significant interaction with sentential context. For instance, 3 EVIDENCE FOR THE CLAIMS 9 when the context predicted high attachment, VP attachment was easier (as in (5b)), but when the context predicted nominal attachment, attachment to the NP was easier instead ((5a)). <p> An example of a syntactic generalization exhibited by the language processor in a variety of constructs is the Minimal Attachment principle <ref> [Frazier, 1987; Kimball, 1973] </ref> which subsumes a class of preferences for a syntactically minimal interpretation. <p> These behaviors can be explained by a preference called the Minimal Attachment criterion <ref> [Frazier, 1987; Kimball, 1973] </ref> according to which the sentence processor prefers that structure which has the least number of nodes in it. That is, the interpretation which is minimal in structure gets selected. <p> Minimal attachment is a very general criterion applicable to many different kinds of sentences and has been used as the criterion for syntactic decisions made at local structural ambiguities [Frazier, 1987]. However, there are competing structural preferences such as Right Association <ref> [Kimball, 1973] </ref> which seem to work at other times in sentences where minimal attachment fails. Right Association or Late Closure says that the incoming constituent is attached to the current structure rather than a previous structure higher up in the parse tree.
Reference: [King and Just, 1991] <author> J. King and M. A. </author> <title> Just. Individual Differences in Syntactic Processing: The Role of Working Memory. </title> <journal> Journal of Memory and Language, </journal> <volume> 30 </volume> <pages> 580-602, </pages> <year> 1991. </year>
Reference: [Lebowitz, 1983] <author> M. Lebowitz. </author> <title> Memory-Based Parsing. </title> <journal> Artificial Intelligence, </journal> <volume> 21 </volume> <pages> 363-404, </pages> <year> 1983. </year>
Reference-contexts: We claim that integrated processing does not preclude functional independence. A number of people have (implicitly) assumed that integrated processing implies integrated representations. For instance, models such as CA, IPP, and the recent model by Jurafsky have no separable representation of syntactic knowledge <ref> [e.g., Jurafsky, 1992; Lebowitz, 1983] </ref>. In fact, the approach taken by Jurafsky, namely, to represent every kind of knowledge in integrated knowledge structures called grammatical constructions, rules out the independent access and application of any one type of knowledge. <p> Syntax was ignored in integrated processing models attempting to fill the proper role of syntax by semantic or conceptual expectations <ref> [Birnbaum and Selfridge, 1981; Lebowitz, 1983; Lehnert et al., 1983] </ref>. However, "the use of such a criterion in parsing is bound often to be unreliable, since the reason for having syntax at all is presumably that real events frequently contradict such expectations" [Crain and Steedman, 1985; Forster, 1979]. <p> They do not retain independence in the use of the different kinds of knowledge involved in linguistic competence. As a result, integrated models do not account for functionally independent behaviors in language understanding. Examples of integrated models include IPP <ref> [Lebowitz, 1983] </ref>, BORIS [Lehnert, Dyer, Johnson, Yang, and Harley, 1983], DMAP [Riesbeck and Martin, 1986a; Riesbeck and Martin 1986b], and AQUA [Ram, 1989]. . <p> same (spreading activation) process. 5 UNIFIED COMPUTATIONAL MODEL: COMPERE 29 5 Unified Computational Model: COMPERE In the last section we saw several models of sentence processing with a variety of architectures from the sequential architecture of Forster's model to the integrated architecture of IPP to the parallel architecture of ATLAST <ref> [Eiselt, 1989; Forster, 1979; Lebowitz, 1983] </ref>. Before looking at our model of sentence understanding, let us take a moment to see the set of assumptions on which COMPERE is based. 5.1 Assumptions As any exploratory theory, COMPERE has been designed by assuming several things.
Reference: [Lehman et al., 1991] <author> J. F. Lehman, R. L. Lewis, and A. Newell. </author> <title> Integrating Knowledge Sources in Language Comprehension. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 461-466, </pages> <year> 1991. </year> <note> REFERENCES 61 </note>
Reference: [Lehnert et al., 1983] <author> W. G. Lehnert, M. G. Dyer, P. N. Johnson, C. J. Yang, and S. Harley. </author> <title> BORIS An Experiment in In-Depth Understanding of Narratives. </title> <journal> Artificial Intelligence, </journal> <volume> 20(1) </volume> <pages> 15-62, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: Syntax was ignored in integrated processing models attempting to fill the proper role of syntax by semantic or conceptual expectations <ref> [Birnbaum and Selfridge, 1981; Lebowitz, 1983; Lehnert et al., 1983] </ref>. However, "the use of such a criterion in parsing is bound often to be unreliable, since the reason for having syntax at all is presumably that real events frequently contradict such expectations" [Crain and Steedman, 1985; Forster, 1979].
Reference: [Lewis, 1992] <author> R. L. Lewis. </author> <title> A Computational Theory of Human Sentence Comprehension. </title> <type> PhD Thesis Proposal, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1992. </year>
Reference-contexts: Models with orthogonal decompositions could differ from one another in their architectural details such as whether they propose all possible interpretations and then select them, or they propose and select one at a time, and so on. For instance, the NL-SOAR model <ref> [Lehman, Lewis, and Newell, 1991; Lewis, 1992] </ref> can only pursue one interpretation of a sentence at a time.
Reference: [Lytinen, 1986] <author> S. L. Lytinen. </author> <title> Dynamically combining syntax and semantics in natural language processing. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 574-578, </pages> <year> 1986. </year>
Reference-contexts: Integrated systems, even when they represented different types of knowledge separately from one another <ref> [e.g., Lytinen, 1986] </ref>, did not retain functional independence between the knowledge types; their processing architectures made the use of one type of knowledge dependent on the use of another. In this work, we claim that knowledge sources can be represented independent of each other to retain functional independence between them. <p> In integrated models, information available right away from syntax could not be utilized in making sentence processing decisions. For instance, Lytinen's semantics-first model of language processing called MOPTRANS <ref> [Lytinen, 1986] </ref> used animacy cues to determine the actor of a sentence though syntax would tell right away who the actor was (by using the fact that the actor occurs to the left of the verb in an English sentence in active voice).
Reference: [MacDonald et al., 1992] <author> M. C. MacDonald, M. A. Just, and P. A. Carpenter. </author> <title> Working Memory Constraints on the Processing of Syntactic Ambiguity. </title> <journal> Cognitive Psychology, </journal> <volume> 24 </volume> <pages> 56-98, </pages> <year> 1992. </year>
Reference: [Marr, 1982] <author> D. Marr. </author> <title> Vision: A Computational investigation into the Human Representation and Processing of Visual Information. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1982. </year>
Reference: [Marslen-Wilson and Tyler, 1987] <author> W. Marslen-Wilson and L. K. Tyler. </author> <title> Against Modularity. </title> <editor> In J. L. Garfield, editor, </editor> <title> Modularity in Knowledge Representation and Natural-Language Understanding. </title> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: The amount and nature of interaction between the different modules can be described in terms of different kinds of modularity <ref> [Fodor, 1987; Marslen-Wilson and Tyler, 1987; Tanenhaus et al., 1987] </ref>. Representational modularity, also known as information encapsulation, means that each module has its own exclusive representation of a kind of knowledge that is not accessible to any other module. Knowledge sources are exclusive to processes.
Reference: [McRoy and Hirst, 1990] <author> S. W. McRoy and G. Hirst. </author> <title> Race-Based Parsing and Syntactic Disam biguation. </title> <journal> Cognitive Science, </journal> <volume> 14 </volume> <pages> 313-353, </pages> <year> 1990. </year>
Reference: [Pearlmutter and MacDonald, 1992] <author> N. J. Pearlmutter and M. C. MacDonald. </author> <title> Plausibility and Syntactic Ambiguity Resolution. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 498-503. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1992. </year>
Reference: [Peterson and Mahesh, Unpublished] <author> J. Peterson and K. Mahesh. </author> <title> Building a natural language understanding system wearing many hats. </title> <type> Unpublished manuscript, Unpublished. </type>
Reference: [Ram, 1989] <author> A. Ram. </author> <title> Question-driven understanding: An integrated theory of story understanding, memory and learning. </title> <type> Ph.D. thesis, </type> <institution> Yale University, </institution> <address> New Haven, CT, </address> <month> May </month> <year> 1989. </year> <note> Research Report #710. </note>
Reference-contexts: As a result, integrated models do not account for functionally independent behaviors in language understanding. Examples of integrated models include IPP [Lebowitz, 1983], BORIS [Lehnert, Dyer, Johnson, Yang, and Harley, 1983], DMAP [Riesbeck and Martin, 1986a; Riesbeck and Martin 1986b], and AQUA <ref> [Ram, 1989] </ref>. .
Reference: [Rayner, 1978] <author> K. Rayner. </author> <title> Eye Movements in Reading and Information Processing. </title> <journal> Psychological Bulletin, </journal> <volume> 85 </volume> <pages> 618-660, </pages> <year> 1978. </year>
Reference: [Riesbeck and Martin, 1986a] <author> C. K. Riesbeck and C. E. Martin. </author> <title> Direct Memory Access Parsing. </title> <editor> In J. L. Kolodner and C. K. Riesbeck, editors, </editor> <booktitle> Experience, memory, and reasoning, </booktitle> <pages> pages 209-226. </pages> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: As a result, integrated models do not account for functionally independent behaviors in language understanding. Examples of integrated models include IPP [Lebowitz, 1983], BORIS [Lehnert, Dyer, Johnson, Yang, and Harley, 1983], DMAP <ref> [Riesbeck and Martin, 1986a; Riesbeck and Martin 1986b] </ref>, and AQUA [Ram, 1989]. .
Reference: [Riesbeck and Martin, 1986b] <author> C. K. Riesbeck and C. E. Martin. </author> <title> Towards Completely Integrated Parsing and Inferencing. </title> <booktitle> In Proceedings of the Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 381-387. </pages> <publisher> Cognitive Science Society, </publisher> <month> August </month> <year> 1986. </year>
Reference: [Schank et al., 1980] <author> R. C. Schank, M. Lebowitz, and L. Birnbaum. </author> <title> An Integrated Understander. </title> <journal> American Journal of Computational Linguistics, </journal> <volume> 6(1) </volume> <pages> 13-30, </pages> <year> 1980. </year>
Reference-contexts: semantics preceding syntax, was proposed by Lytinen (1986) and implemented in the MOPTRANS program. 10 However, we do ignore phonology, morphology, and so on; also, there is no model of pragmatic or discourse processing at the present time. 4 SENTENCE PROCESSING MODELS 24 4.3 Integrated Models The Integrated Processing Hypothesis <ref> [Birnbaum, 1986; Birnbaum, 1989; Schank et al., 1980] </ref> states that the language processor applies syntactic, semantic, and other kinds of knowledge at the earliest opportunity in processing a piece of text. Thus, it is essentially a different expression of the same hypothesis that Stowe called the Immediate Semantic Decision Hypothesis.
Reference: [Seidenberg et al., 1982] <author> M. S. Seidenberg, M. K. Tanenhaus, J. M. Leiman, and M. Bienkowski. </author> <title> Automatic Access of the Meanings of Ambiguous Words in Context: Some Limitations of Knowledge-Based Processing. </title> <journal> Cognitive Psychology, </journal> <volume> 14 </volume> <pages> 489-537, </pages> <year> 1982. </year> <note> REFERENCES 62 </note>
Reference-contexts: It then passes the syntactic categories of the word to the syntactic knowledge representation. At the same time, it also passes pointers to the meaning (s) of the word to the conceptual representation. This is a multiple-access model which is supported by a large body of experimental evidence <ref> [Seidenberg et al., 1982] </ref>. * Instantiation: The processor builds instances of nodes for the syntactic category of the node, the meanings of the word, and the primitive roles if any suggested by the syntactic categories.
Reference: [Small, 1991] <author> S. L. </author> <title> Small. Focal and Diffuse Lesions of Cognitive Models. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 85-90. </pages> <publisher> Cognitive Science Society, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: However, it should be generalized to show the differences between (1) and (2) for instance. (2) The courses taught at the academy were very demanding. * Demonstrate functional independence. One way to do this is by means of lesion studies <ref> [Cottrell, 1985; Small, 1991] </ref>. We can turn off syntactic or semantic processing by making the corresponding type of knowledge unavailable to show that the other can still function normally. This was attempted with ungrammatical sentences.
Reference: [Spivey-Knowlton, 1992] <author> M. J. Spivey-Knowlton. </author> <title> Another Context Effect in Sentence Processing: Implications for the Principle of Referential Support. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 486-491. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1992. </year>
Reference: [Steedman, 1987] <author> M. Steedman. </author> <title> Combinatory Grammars and Human Sentence Processing. </title> <editor> In J. L. Garfield, editor, </editor> <booktitle> Modularity in Knowledge Representation and Natural Language UNnderstand-ing. </booktitle> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: The representation of the grammar is similar to Categorial Grammars <ref> [Steedman, 1987; Steedman, 1989] </ref>. Since a rule in a grammar has to be able to express a relationship between three or more constituents, grammatical relationships can not be expressed as binary relationships. As such, syntactic knowledge is not amenable to semantic network representations without significant enhancements to them. <p> Categorial Grammars The discussion of representing argument structures enables us to address the question of how our representation of syntactic knowledge differs from categorial grammars <ref> [Steedman, 1987; Steedman, 1989] </ref>. The most radical proposals of categorial grammars purport completely bottom-up processing mentioned earlier and hence can not account for a host of evidence from human sentence processing behavior. Other approaches to categorial grammars combine semantic information to various degrees in their categories.
Reference: [Steedman, 1989] <author> M. J. Steedman. </author> <title> Grammar, Interpretation, and Processing from the Lexicon. </title> <editor> In W. Marslen-Wilson, editor, </editor> <title> Lexical Representation and Process. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: The representation of the grammar is similar to Categorial Grammars <ref> [Steedman, 1987; Steedman, 1989] </ref>. Since a rule in a grammar has to be able to express a relationship between three or more constituents, grammatical relationships can not be expressed as binary relationships. As such, syntactic knowledge is not amenable to semantic network representations without significant enhancements to them. <p> Categorial Grammars The discussion of representing argument structures enables us to address the question of how our representation of syntactic knowledge differs from categorial grammars <ref> [Steedman, 1987; Steedman, 1989] </ref>. The most radical proposals of categorial grammars purport completely bottom-up processing mentioned earlier and hence can not account for a host of evidence from human sentence processing behavior. Other approaches to categorial grammars combine semantic information to various degrees in their categories.
Reference: [Stowe, 1991] <author> L. A. </author> <title> Stowe. Ambiguity Resolution: Behavioral Evidence for a Delay. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 257-262. </pages> <publisher> Cognitive Science Society, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: People garden-path on reduced-relative ambiguous structures such as in (1). (1) The officers taught at the academy were very demanding. However, sentence (2) which has the same surface structure as (1), does not result in garden-path behavior <ref> [Stowe, 1991] </ref>. (2) The courses taught at the academy were very demanding. <p> Their experiments showed that such semantic and contextual interaction happens well before any sentential or clause boundary is encountered. They argued that garden-pathing is a contextual phenomenon and can both be prevented and induced by the context in which a sentence is processed. Cupples and Stowe <ref> [Stowe, 1991] </ref> used sentences such as in (1) and (2) (1) The officers taught at the academy were very demanding. (2) The courses taught at the academy were very demanding. and measured word-by-word reading times to establish that semantic information such as the animacy of the subject influences the immediate assignment <p> People had difficulty with the more complex syntactic structure (the complement structure as in (18b)) even when there was a semantic bias in favor of it (as in 18b) <ref> [Stowe, 1991] </ref>. For instance, in (18c), the sentence in (18a) has been made longer by introducing the relative clause who came in. <p> People seemed to have trouble with the more complex syntactic structure even when there was a semantic bias towards it; they went ahead with the minimal syntactic structure and had to make repairs upon reading the disambiguating items. To explain these results, Stowe <ref> [Stowe, 1991] </ref> hypothesized that the absence of garden-path behavior when there is semantic bias towards the more complex structure may not be because the semantically preferred more complex structure had been chosen as proposed by Crain and Steedman (1985) and others. <p> certain connectionist systems [Waltz and Pollack, 1985]. 11 However, uncontrolled interaction leads to difficulties in 11 One might argue that connectionist systems with many interacting networks have the same process of spreading 4 SENTENCE PROCESSING MODELS 28 accounting for the kind of limited delay behavior seen in human sentence processing <ref> [Stowe, 1991] </ref>. The sentence processor needs a control structure monitoring the interaction between the different faculties. activation running in each network and not separate processes as described here. <p> Officers might just as well teach or be taught. (1) The officers taught at the academy were very demanding. Stowe <ref> [Stowe, 1991] </ref> has proposed an alternative explanation for such syntactic preferences which I am attempting to generalize to language processing as a whole. <p> syntactic and semantic processing. * Impose working memory limitations [Carpenter and Just, 1988; Just and Carpenter, 1992; King and Just, 1991; MacDonald, Just, and Carpenter, 1992] on the model and use such a limitation to make decisions such as whether to pursue multiple interpretations in parallel or choose one interpretation <ref> [Stowe, 1991] </ref>. * At some point in the development of this model, we would like to extend COMPERE to understand more than single sentences. * We have been using a very limited definition of semantics.
Reference: [Stowe, In press] <author> L. </author> <title> Stowe. Thematic structures and sentence comprehension. </title> <editor> In G. Carlson and M. Tanenhaus, editors, </editor> <booktitle> Linguistic Structure in Language Processing. </booktitle> <address> Dordrecht: </address> <publisher> Reidel, In press. </publisher>
Reference: [Tanenhaus and Carlson, 1989] <author> M. K. Tanenhaus and G. N. Carlson. </author> <title> Lexical Structure and Lan guage Comprehension. </title> <editor> In W. Marslen-Wilson, editor, </editor> <title> Lexical Representation and Process. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: However, there is an additional kind of knowledge involved in determining roles and also in determining permissible syntactic structures. It is the knowledge of what kinds of heads (usually verbs) take what arguments. It has been called variously as predicate argument structure or subcategorization structure <ref> [e.g., Tanenhaus and Carlson, 1989; Tanenhaus, Garnsey, and Boland, 1991] </ref>. It is this knowledge that helps the sentence processor make distinctions between, say, intransitive, transitive, bitransitive verbs, and verbs that are combinations of those.
Reference: [Tanenhaus et al., 1987] <author> M. K. Tanenhaus, G. S. Dell, and G. Carlson. </author> <title> Context Effects in Lexical Processing: A Connectionist Approach to Modularity. </title> <editor> In J. L. Garfield, editor, </editor> <title> Modularity in Knowledge Representation and Natural-Language Understanding. </title> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: The amount and nature of interaction between the different modules can be described in terms of different kinds of modularity <ref> [Fodor, 1987; Marslen-Wilson and Tyler, 1987; Tanenhaus et al., 1987] </ref>. Representational modularity, also known as information encapsulation, means that each module has its own exclusive representation of a kind of knowledge that is not accessible to any other module. Knowledge sources are exclusive to processes.
Reference: [Tanenhaus et al., 1991] <author> M. Tanenhaus, S. Garnsey, and J. Boland. </author> <title> Combinatory Lexical Informa tion and Language Comprehension. </title> <editor> In G. Altmann, editor, </editor> <booktitle> Cognitive Models of Speech Processing: Psycholinguistic and Computational Perspectives. </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference: [Taraban and McClelland, 1988] <author> R. Taraban and J. L. McClelland. </author> <title> Constituent Attachment and Thematic Role Assignment in Sentence Processing: Influences of Content-Based Expectations. </title> <journal> Journal of Memory and Language, </journal> <volume> 27 </volume> <pages> 597-632, </pages> <year> 1988. </year>
Reference: [Trueswell and Tanenhaus, 1992] <author> J. C. Trueswell and M. K. Tanenhaus. </author> <title> Consulting temporal con text during sentence comprehension: Evidence from the monitoring of eye movements in reading. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 492-497. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1992. </year>
Reference: [Tyler and Marslen-Wilson, 1977] <author> L. K. Tyler and W. D. Marslen-Wilson. </author> <title> The On-Line Effects of Semantic Context on Syntactic Processing. </title> <journal> Journal of Verbal Learning and Verbal Behavior, </journal> <volume> 16 </volume> <pages> 683-692, </pages> <year> 1977. </year>
Reference-contexts: interaction of knowledge at different levels. 3.1.1 Evidence for Integration Intuitively, since the purpose of language is its communicative function and not syntactic gram-maticality judgment, the human language processor should use the meaning of the text as early as possible in making any decision during the course of language understanding <ref> [Crain and Steedman, 1985; Tyler and Marslen-Wilson, 1977] </ref>. Thus, the human sentence understander is forever trying to integrate information arising from knowledge sources at different levels in order to come up with a single interpretation that makes the best sense overall (i.e., at the syntactic, semantic, conceptual, and other levels). <p> In other situations, semantic preferences could influence the decisions that the processor makes in resolving syntactic ambiguities. Such behavior would be the same as the ones explained by models which argue for the early effects of semantic and contextual information in syntactic processing <ref> [e.g., Crain and Steedman, 1985; Tyler and Marslen-Wilson, 1977] </ref>.
Reference: [Waltz and Pollack, 1984] <author> D. L. Waltz and J. B. Pollack. </author> <title> Phenomenologically Plausible Parsing. </title> <booktitle> In Proc. AAAI-84, </booktitle> <pages> pages 335-339, </pages> <year> 1984. </year>
Reference-contexts: common format . "These similarities are compatible with models in which lexical and grammatical forms are represented in a common format and/or accessed by a common set of processing mechanisms. ..." [Bates, et al., 1991] Uncontrolled interaction between separate processes as it happens in certain connectionist network models for instance <ref> [Cottrell, 1985; Waltz and Pollack, 1984; Waltz and Pollack, 1985] </ref>, does not seem to be capable of producing the kind of ambiguity resolution behaviors observable in limited delayed decisions and error recoveries.
Reference: [Waltz and Pollack, 1985] <author> D. L. Waltz and J. B. Pollack. </author> <title> Massively Parallel Parsing: A Strongly Interactive Model of Natural Language Interpretation. </title> <journal> Cognitive Science, </journal> <volume> 9 </volume> <pages> 51-74, </pages> <year> 1985. </year> <note> REFERENCES 63 </note>
Reference-contexts: common format . "These similarities are compatible with models in which lexical and grammatical forms are represented in a common format and/or accessed by a common set of processing mechanisms. ..." [Bates, et al., 1991] Uncontrolled interaction between separate processes as it happens in certain connectionist network models for instance <ref> [Cottrell, 1985; Waltz and Pollack, 1984; Waltz and Pollack, 1985] </ref>, does not seem to be capable of producing the kind of ambiguity resolution behaviors observable in limited delayed decisions and error recoveries. <p> A third possible hypothesis is that there are separate processes for different faculties, but there is unrestricted interaction between them. Such a hypothesis can be found in certain connectionist systems <ref> [Waltz and Pollack, 1985] </ref>. 11 However, uncontrolled interaction leads to difficulties in 11 One might argue that connectionist systems with many interacting networks have the same process of spreading 4 SENTENCE PROCESSING MODELS 28 accounting for the kind of limited delay behavior seen in human sentence processing [Stowe, 1991].
Reference: [Wanner and Maratsos, 1978] <author> E. Wanner and M. Maratsos. </author> <title> An ATN Approach to Comprehension. </title> <editor> In M. Halle, J. Bresnan, and G. A. Miller, editors, </editor> <booktitle> Linguistic Theory and Psychological Reality, </booktitle> <pages> pages 119-161. </pages> <publisher> MIT Press, </publisher> <year> 1978. </year>
Reference-contexts: A grammar for a natural language can be represented in different ways. When represented simply as a set of rewrite rules, a grammar is suitable for a top-down analysis as done by an augmented transition network (ATN) <ref> [Wanner and Maratsos, 1978; Woods, 1970; Woods, 1973] </ref>. However, top-down processing forces a sentence processor to make unnecessary commitments along the way with a consequent problem of frequent and wasteful backtracking that does not happen in human sentence processing behavior.
Reference: [Winograd, 1973] <author> T. Winograd. </author> <title> A Procedural Model of Language Understanding. </title> <editor> In R. C. Schank and K. M. Colby, editors, </editor> <booktitle> Computer models of thought and language, </booktitle> <pages> pages 152-186. </pages> <editor> W. H. </editor> <publisher> Freeman, </publisher> <year> 1973. </year>
Reference-contexts: On the other hand, people can put up with imperfect syntax and get the meaning out of ungram-matical strings of words. For instance, even in the total absence of syntax as in (7) we still get some meaning out of the text. (7a) Skid crash hospital. <ref> [Winograd, 1973] </ref> (7b) Fire match arson hotel. [Charniak, 1983] Lack of independence of syntax also leads to difficulties in accounting for syntactic generalizations across different semantic entities.
Reference: [Woods, 1970] <author> W. A. Woods. </author> <title> Transition network grammars for natural language analysis. </title> <journal> Com munications of the ACM, </journal> <volume> 13 </volume> <pages> 591-606, </pages> <year> 1970. </year> <note> Also reprinted in Readings in Natural Language Processing, </note> <editor> Grosz, Jones, and Webber (ed.), </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1986. </year>
Reference-contexts: A grammar for a natural language can be represented in different ways. When represented simply as a set of rewrite rules, a grammar is suitable for a top-down analysis as done by an augmented transition network (ATN) <ref> [Wanner and Maratsos, 1978; Woods, 1970; Woods, 1973] </ref>. However, top-down processing forces a sentence processor to make unnecessary commitments along the way with a consequent problem of frequent and wasteful backtracking that does not happen in human sentence processing behavior.
Reference: [Woods, 1973] <author> W. A. Woods. </author> <title> An experimental parsing system for transition network grammars. </title> <editor> In R. Rustin, editor, </editor> <booktitle> Natural language processing. </booktitle> <publisher> Algorithmics Press, </publisher> <year> 1973. </year>
Reference-contexts: A grammar for a natural language can be represented in different ways. When represented simply as a set of rewrite rules, a grammar is suitable for a top-down analysis as done by an augmented transition network (ATN) <ref> [Wanner and Maratsos, 1978; Woods, 1970; Woods, 1973] </ref>. However, top-down processing forces a sentence processor to make unnecessary commitments along the way with a consequent problem of frequent and wasteful backtracking that does not happen in human sentence processing behavior.
References-found: 79

