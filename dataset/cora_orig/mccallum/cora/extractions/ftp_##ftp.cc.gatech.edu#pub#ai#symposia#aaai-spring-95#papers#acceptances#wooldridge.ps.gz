URL: ftp://ftp.cc.gatech.edu/pub/ai/symposia/aaai-spring-95/papers/acceptances/wooldridge.ps.gz
Refering-URL: ftp://ftp.cc.gatech.edu/pub/ai/symposia/aaai-spring-95/papers/finals.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: M.Wooldridge@doc.mmu.ac.uk  
Title: An Abstract General Model and Logic of Resource-Bounded Believers  
Author: Michael Wooldridge 
Address: Chester Street, Manchester M1 5GD United Kingdom  
Affiliation: Department of Computing Manchester Metropolitan University  
Abstract: This paper presents an abstract general model for representing the belief systems of resource-bounded reasoning agents. The intuition which underlies this new model is that it is possible to capture the key properties of many different types of belief system in a structure called a belief extension relation. The paper shows how such a relation may be derived for any system that satisfies some basic properties. The resulting formalism is simple, and yet sufficiently rich that it generalises many other frameworks for representing belief. A logic is defined, using the new model to give a semantics to belief modalities. The properties of the model and logic are discussed in detail. The paper closes with a discussion and remarks on future work. 
Abstract-found: 1
Intro-found: 1
Reference: <editor> Bond, A. H. and Gasser, L., editors (1988). </editor> <booktitle> Readings in Distributed Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: with understanding and constructing computer systems that contain multiple interacting agents, each of which is an AI system in its own right; it is widely accepted that to (co-)operate effectively in a multi-agent environment, agents need to be able to manipulate representations of the state and behaviour of other agents <ref> (Bond and Gasser, 1988, pp25-29) </ref>. An obvious research problem is to devise knowledge representation formalisms that are suitable for this purpose. This paper contributes to the theoretical foundations of such formalisms; it considers the representation of belief in multi-agent AI systems.
Reference: <author> Chellas, B. </author> <year> (1980). </year> <title> Modal Logic: An Introduction. </title> <publisher> Cam-bridge University Press: </publisher> <address> Cambridge, England. </address>
Reference-contexts: Note that the K axiom and the necessitation rule of normal modal logic <ref> (Chellas, 1980) </ref> do not in general hold for belief modalities in L B , and thus L B does not fall prey to logical omniscience. <p> This notion of necessity is that at the heart of normal modal logics, where j is said to be necessary iff j is true in all possibilities <ref> (Chellas, 1980) </ref>. However, it is important to note that belief is not being given a normal modal interpretation here. This leads to the following derivation of an agent's b.e. relation. <p> Although there are many properties which correspond to theorems, (see, e.g., <ref> (Chellas, 1980) </ref>), only five are of real interest from the point of view of belief logics: those called K, T, D, 4, and 5. These theorems, and the conditions they correspond to, are summarised in Table 1. <p> We refer to this logic as the system KT4. As it turns out, there are just eleven distinct systems of modal logic based on the theorems K, T, D, 4, and 5 (see <ref> (Chellas, 1980, p132) </ref>). These are: K, K4, K5, KD, KT, K45, KD5, KD4, KT4, KD45, and KT5. However, axiom T is generally taken to characterise knowledge, not belief.
Reference: <author> Cohen, P. R. and Levesque, H. J. </author> <year> (1990). </year> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 213-261. </pages>
Reference-contexts: Another well-known attempt to integrate models of belief with other mental attitudes is <ref> (Cohen and Levesque, 1990) </ref>, where belief and goal modalities are used to define the notion of intention. Finally, note that in other work, we have considered the implications of adding temporal modalities to L B (Wooldridge, 1994; Wooldridge and Fisher, 1994).
Reference: <author> Fagin, R. and Halpern, J. Y. </author> <year> (1985). </year> <title> Belief, awareness, and limited reasoning. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence (IJCAI-85), </booktitle> <pages> pages 480-490, </pages> <address> Los Angeles, CA. </address>
Reference-contexts: Another attempt to weaken possible worlds semantics is due to Fagin-Halpern, who developed a logic containing an operator to represent those formulae an agent is `aware of'; the semantics of this operator are given by simply associating a set of formulae with an agent <ref> (Fagin and Halpern, 1985) </ref>. The logic also contains an implicit belief operator, with a normal modal semantics. `Explicit' belief is then defined as implicit belief plus awareness; the resulting logic of explicit belief is weaker than implicit belief.
Reference: <author> Gibbs, J. R. </author> <year> (1994). </year> <title> Tableau-based theorem proving in a temporal belief logic. </title> <type> Master's thesis, </type> <institution> Department of Computing, Manchester Metropolitan University, Chester St., </institution> <address> Manchester M1 5GD, UK. </address>
Reference-contexts: A PROLOG implementation of this procedure has been developed and tested on a number of problems <ref> (Gibbs, 1994) </ref>. Secondly, recall the informal interpretation given to an agent's b.e. relation, as described earlier: if i believes D and (D, j) BE i then i also believes j.
Reference: <author> Halpern, J. Y. and Moses, Y. </author> <year> (1992). </year> <title> A guide to completeness and complexity for modal logics of knowledge and belief. </title> <journal> Artificial Intelligence, </journal> <volume> 54 </volume> <pages> 319-379. </pages>
Reference-contexts: In order to conveniently represent the properties of belief systems, a logic containing belief modalities is defined; the semantics of this logic are given in terms of the new model. The new model is then compared to two other formalisms, (the deduction model (Konolige, 1986a) and normal modal logics <ref> (Halpern and Moses, 1992) </ref>), and is shown to general-ise them. Some remarks on implementing the new model are then presented. The paper begins, in the following section, by reviewing previous attempts to formally model belief.
Reference: <author> Hintikka, J. </author> <year> (1962). </year> <title> Knowledge and Belief. </title> <publisher> Cornell University Press: </publisher> <address> Ithaca, NY. </address>
Reference-contexts: Background The commonest technique for modelling belief is to use a modal logic with possible worlds semantics (Chellas, 1980; Halpern and Moses, 1992); this approach was first developed by Hintikka <ref> (Hintikka, 1962) </ref>. Normal modal logics have properties that make them simple and interesting tools to work with, and have proved to be valuable in the formal study of belief. However, there are a number of problems associated with normal modal logics of belief.
Reference: <author> Konolige, K. </author> <year> (1986a). </year> <title> A Deduction Model of Belief. </title> <publisher> Pitman Publishing: London and Morgan Kaufmann: </publisher> <address> San Mateo, CA. </address>
Reference-contexts: In order to conveniently represent the properties of belief systems, a logic containing belief modalities is defined; the semantics of this logic are given in terms of the new model. The new model is then compared to two other formalisms, (the deduction model <ref> (Konolige, 1986a) </ref> and normal modal logics (Halpern and Moses, 1992)), and is shown to general-ise them. Some remarks on implementing the new model are then presented. The paper begins, in the following section, by reviewing previous attempts to formally model belief. <p> Moreover, under some circumstances, they still predict that agents have unreasonable deductive capabilities. The second alternative is to reject possible worlds altogether, and seek an alternative semantic base. The best-known example of such work is the deduction model of belief, due to Konolige <ref> (Konolige, 1986a) </ref>. In essence, the deduction model is an attempt to directly model the belief systems of agents in AI; the concerns of the deduction model are thus very much the concerns of this paper. <p> Note that we do not require the b.e. relation to be based on logical inference. It need not be a proof relation (as in <ref> (Konolige, 1986a) </ref>); we can model agents whose `reasoning' is not based on logical inference, as well as those that are. <p> this paper is as follows. j bel (b i ) i believes j j bel (b i ) i believes j j bel (b i ) i doesn't believe j j bel (b i ) i doesn't believe j Thus the new model is a sentential model of belief; see <ref> (Konolige, 1986a, pp110-118) </ref> for a discussion of such models. Note that it is possible for a belief model to represent agents that have `no opinion' on some formula. It is also possible for a model to represent an agent that believes both a formula and its negation. <p> In short, we can use all propositional modes of reasoning in L B . However, L B has some properties that L 0 does not. To illustrate this, we first establish an analogue of Konolige's attachment lemma <ref> (Konolige, 1986a, pp34-35) </ref>. (Note that if D = fj 1 , , j n g then [i]D abbreviates [i]j 1 , , [i]j n .) Lemma 2 The set f [i]D, [i]Dg is unsatisfiable iff $j D such that (D, j) BE i . <p> The beliefs of almost any conceivable agent can be described via a set of formulae of some language. In particular, the beliefs of AI systems are generally directly represented as a set of formulae. (It was this observation, of course, that gave the impetus to Konolige's deduction model <ref> (Konolige, 1986a, pp12-13) </ref>.) The purpose of the second requirement is simply to ensure that the set of all sets of L-formulae can be partitioned into two disjoint sets: one representing legal belief states, the other representing illegal belief states. <p> The Deduction Model of Belief The model of belief systems presented in this paper is similar in some respects to Konolige's deduction model <ref> (Konolige, 1986a) </ref>. In fact, as we shall demonstrate formally, the new model actually generalises the deduction model, in that the behaviour of any belief system in the deduction model can be represented using the new model. Before this result is established, a review of the deduction model is given. <p> For this reason, we shall consider this axiom no further here; we restrict our attention to the four remaining axioms and their eight remaining systems: K, K4, K5, KD, K45, KD5, KD4, and KD45. We shall shortly define a correspondence theorem, (cf. <ref> (Konolige, 1986a, pp104-108) </ref>), which relates L w and these eight systems to L B , in much the same way that the previous section related L B to the deduction model. First, however, some notation. <p> First, note that a tableau-based decision procedure for L B has been developed, and is described in the associated technical report (Wooldridge, 1994). (It has not been presented here due to space restrictions.) This proof method has been used on a number of examples, including the wisest man puzzle <ref> (Konolige, 1986a, pp57-61) </ref>. A PROLOG implementation of this procedure has been developed and tested on a number of problems (Gibbs, 1994). Secondly, recall the informal interpretation given to an agent's b.e. relation, as described earlier: if i believes D and (D, j) BE i then i also believes j. <p> Finally, note that reasoning in L B may utilise the technique of semantic attachment, described by Konolige (and attributed by him to Weyhrauch) <ref> (Konolige, 1986a, p7) </ref>. The idea is that when reasoning in L B we must often decide whether (fj 1 , , j n g, j) BE i , for some agent i and fj 1 , , j n , jg Form (L B ).
Reference: <author> Konolige, K. </author> <year> (1986b). </year> <title> What awareness isn't: A sentential view of implicit and explicit belief (position paper). </title> <editor> In Halpern, J. Y., editor, </editor> <booktitle> Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 241-250. </pages> <publisher> Morgan Kaufmann Publishers: </publisher> <address> San Mateo, CA. </address>
Reference: <author> Lakemeyer, G. </author> <year> (1991). </year> <title> A computationally attractive first-order logic of belief. </title> <booktitle> In JELIA-90: Proceedings of the European Workshop on Logics in AI (LNAI Volume 478), </booktitle> <pages> pages 333-347. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: He then defined an `explicit belief' operator, with a semantics given in terms of situations. The logic of explicit belief is much weaker than that of normal modal belief. Levesque's original proposal has been extended into the first-order realm by Lakermeyer <ref> (Lakemeyer, 1991) </ref>. Another attempt to weaken possible worlds semantics is due to Fagin-Halpern, who developed a logic containing an operator to represent those formulae an agent is `aware of'; the semantics of this operator are given by simply associating a set of formulae with an agent (Fagin and Halpern, 1985).
Reference: <author> Levesque, H. J. </author> <year> (1984). </year> <title> A logic of implicit and explicit belief. </title> <booktitle> In Proceedings of the Fourth National Conference on Artificial Intelligence (AAAI-84), </booktitle> <pages> pages 198-202, </pages> <address> Aus-tin, TX. </address>
Reference-contexts: A number of attempts have been made to weaken possible worlds semantics. One of the best-known is due to Levesque <ref> (Levesque, 1984) </ref>. To weaken the notion of a world, Levesque borrowed some ideas from situation semantics; situations (worlds) in his logic may assign either true, false, or both to a proposition, and thus they do not act like propos-itional valuations.
Reference: <author> Stein, G. C. and Barnden, J. A. </author> <year> (1995). </year> <title> Towards more flexible and common-sensical reasoning about beliefs. </title> <editor> In Cox, M. and Freed, M., editors, </editor> <booktitle> Representing Mental States and Mechanisms Proceedings of the 1995 Spring Symposium. </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: This point is discussed in (Wooldridge, 1994). Implementation Aspects The issues surrounding the implementation of a system which makes use of L B in some way are not the primary concern of this paper (see, e.g., <ref> (Stein and Barnden, 1995) </ref> for a description of the CASEMENT system for reasoning with beliefs). Nevertheless, it is worth briefly commenting on these issues.
Reference: <author> Wooldridge, M. </author> <year> (1994). </year> <title> A temporal belief logic. </title> <type> Technical report, </type> <institution> Department of Computing, Manchester Metropolitan University, Chester St., </institution> <address> Manchester M1 5GD, UK. </address>
Reference-contexts: Is S is a set, then (S) is the powerset of S. We use for the empty set. Note that all proofs have been omitted due to space restrictions; they may be found in the associated technical report <ref> (Wooldridge, 1994) </ref>. Background The commonest technique for modelling belief is to use a modal logic with possible worlds semantics (Chellas, 1980; Halpern and Moses, 1992); this approach was first developed by Hintikka (Hintikka, 1962). <p> We can actually prove a stronger result than this, which is more in the spirit of the deduction model result, above. However, the statement of this result is a good deal more involved, and so we omit it; see <ref> (Wooldridge, 1994) </ref>. Remarks The results of this section are important for the new model, as they show that it can be used to represent the kinds of belief system that existing formalisms are capable of representing. <p> This point is discussed in <ref> (Wooldridge, 1994) </ref>. Implementation Aspects The issues surrounding the implementation of a system which makes use of L B in some way are not the primary concern of this paper (see, e.g., (Stein and Barnden, 1995) for a description of the CASEMENT system for reasoning with beliefs). <p> Nevertheless, it is worth briefly commenting on these issues. First, note that a tableau-based decision procedure for L B has been developed, and is described in the associated technical report <ref> (Wooldridge, 1994) </ref>. (It has not been presented here due to space restrictions.) This proof method has been used on a number of examples, including the wisest man puzzle (Konolige, 1986a, pp57-61). A PROLOG implementation of this procedure has been developed and tested on a number of problems (Gibbs, 1994).
Reference: <author> Wooldridge, M. </author> <year> (1995). </year> <title> This is MYWORLD: The logic of an agent-oriented testbed for DAI. </title> <editor> In Wooldridge, M. and Jennings, N. R., editors, </editor> <booktitle> Intelligent Agents: Theories, Architectures, and Languages (LNAI Volume 890), </booktitle> <pages> pages 160-178. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: Future work will look at integrating this model with other components of an agent's cognitive makeup (for example, the interaction between beliefs and intentions); this work has already begun, in a practical sense, in an agent-oriented DAI testbed called MYWORLD <ref> (Wooldridge, 1995) </ref>. Another well-known attempt to integrate models of belief with other mental attitudes is (Cohen and Levesque, 1990), where belief and goal modalities are used to define the notion of intention.
Reference: <author> Wooldridge, M. and Fisher, M. </author> <year> (1994). </year> <title> A decision procedure for a temporal belief logic. </title> <editor> In Gabbay, D. M. and Ohl-bach, H. J., editors, </editor> <booktitle> Temporal Logic Proceedings of the First International Conference (LNAI Volume 827), </booktitle> <pages> pages 317-331. </pages> <publisher> Springer-Verlag: </publisher> <address> Heidelberg, Germany. </address>
Reference-contexts: Is S is a set, then (S) is the powerset of S. We use for the empty set. Note that all proofs have been omitted due to space restrictions; they may be found in the associated technical report <ref> (Wooldridge, 1994) </ref>. Background The commonest technique for modelling belief is to use a modal logic with possible worlds semantics (Chellas, 1980; Halpern and Moses, 1992); this approach was first developed by Hintikka (Hintikka, 1962). <p> We can actually prove a stronger result than this, which is more in the spirit of the deduction model result, above. However, the statement of this result is a good deal more involved, and so we omit it; see <ref> (Wooldridge, 1994) </ref>. Remarks The results of this section are important for the new model, as they show that it can be used to represent the kinds of belief system that existing formalisms are capable of representing. <p> This point is discussed in <ref> (Wooldridge, 1994) </ref>. Implementation Aspects The issues surrounding the implementation of a system which makes use of L B in some way are not the primary concern of this paper (see, e.g., (Stein and Barnden, 1995) for a description of the CASEMENT system for reasoning with beliefs). <p> Nevertheless, it is worth briefly commenting on these issues. First, note that a tableau-based decision procedure for L B has been developed, and is described in the associated technical report <ref> (Wooldridge, 1994) </ref>. (It has not been presented here due to space restrictions.) This proof method has been used on a number of examples, including the wisest man puzzle (Konolige, 1986a, pp57-61). A PROLOG implementation of this procedure has been developed and tested on a number of problems (Gibbs, 1994).
References-found: 15

