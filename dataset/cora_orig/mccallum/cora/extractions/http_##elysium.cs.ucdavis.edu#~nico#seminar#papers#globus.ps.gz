URL: http://elysium.cs.ucdavis.edu/~nico/seminar/papers/globus.ps.gz
Refering-URL: http://elysium.cs.ucdavis.edu/~nico/seminar/seminar.html
Root-URL: http://www.cs.ucdavis.edu
Email: http://www.globus.org/  
Title: Globus: A Metacomputing Infrastructure Toolkit  
Author: Ian Foster Carl Kesselman 
Abstract: Emerging high-performance applications require the ability to exploit diverse, geographically distributed resources. These applications use high-speed networks to integrate supercomputers, large databases, archival storage devices, advanced visualization devices, and/or scientific instruments to form networked virtual supercomputers or metacomputers. While the physical infrastructure to build such systems is becoming widespread, the heterogeneous and dynamic nature of the metacomputing environment poses new challenges for developers of system software, parallel tools, and applications. In this article, we introduce Globus, a system that we are developing to address these challenges. The Globus system is intended to achieve a vertically integrated treatment of application, middleware, and network. A low-level toolkit provides basic mechanisms such as communication, authentication, network information, and data access. These mechanisms are used to construct various higher-level metacomputing services, such as parallel programming tools and schedulers. Our long-term goal is to build an Adaptive Wide Area Resource Environment (AWARE), an integrated set of higher-level services that enable applications to adapt to heterogeneous and dynamically changing meta-computing environments. Preliminary versions of Globus components were deployed successfully as part of the I-WAY networking experiment.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Berman, R. Wolski, S. Figueira, J. Schopf, and G. Shao, </author> <title> Application-level scheduling on distributed heterogeneous networks, </title> <booktitle> in Proceedings of Supercomputing '96, </booktitle> <publisher> ACM Press, </publisher> <year> 1996. </year>
Reference-contexts: The definition, development, application, evaluation, and refinement of these components are ongoing processes that we expect to proceed for the next two years at least. We hope to involve more of the metacomputing community in this process, by adapting relevant higher-level services (e.g., application-level scheduling <ref> [1] </ref>, performance steering [27], object-based libraries [14]) to use Globus mecha 14 nisms, and by participating in the construction of additional testbeds (e.g., GUSTO).
Reference: [2] <author> C. Catlett and L. </author> <title> Smarr, Metacomputing, </title> <journal> Communications of the ACM, </journal> <volume> 35 (1992), </volume> <pages> pp. 44-52. </pages>
Reference-contexts: 1 Introduction New classes of high-performance applications are being developed that require unique capabilities not available in a single computer. Such applications are enabled by the construction of networked virtual supercomputers, or metacomputers <ref> [2] </ref>, execution environments in which high-speed networks are used to connect supercomputers, databases, scientific instruments, and advanced display devices, perhaps located at geographically distributed sites.
Reference: [3] <author> K. M. Chandy and C. Kesselman, </author> <title> CC ++ : A declarative concurrent object oriented programming notation, in Research Directions in Object Oriented Programming, </title> <publisher> The MIT Press, </publisher> <year> 1993, </year> <pages> pp. 281-313. </pages>
Reference-contexts: These interfaces include a complete implementation of MPI (and hence tools layered on top of MPI, such as many High Performance Fortran systems); Compositional C++ <ref> [3] </ref>, a parallel extension to C++; Fortran M, a task-parallel Fortran; nPerl, a version of the Perl scripting language extended with remote reference and remote procedure call mechanisms; and NexusJava, a Java class library that supports remote procedure calls.
Reference: [4] <author> T. DeFanti, I. Foster, M. Papka, R. Stevens, and T. Kuhfuss, </author> <title> Overview of the I-WAY: Wide area visual supercomputing, </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 10 (1996), </volume> <pages> pp. 123-130. </pages>
Reference-contexts: In each case, the ability to construct networked virtual supercomputers can provide qualitatively new capabilities that enable new approaches to problem solving. 2.1 Metacomputing Applications Scientists and engineers are just beginning to explore the new applications enabled by networked supercomputing. The I-WAY experiment <ref> [4] </ref> identified four significant application classes. 1. Desktop supercomputing. These applications couple high-end graphics capabilities with remote supercomputers and/or databases. This coupling connects users more tightly with computing capabilities, while at the same time achieving distance independence between resources, developers, and users. 2. Smart instruments.
Reference: [5] <author> D. Diachin, L. Freitag, D. Heath, J. Herzog, W. Michels, and P. Plassmann, </author> <title> Remote engineering tools for the design of pollution control systems for commercial boilers, </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 10 (1996), </volume> <pages> pp. 208-218. </pages>
Reference-contexts: For example, the I-WAY networking experiment, which connected supercomputers and other resources at 17 different sites across North America, saw 60 groups develop applications in areas as diverse as large-scale scientific simulation [24, 25], collaborative engineering <ref> [5, 6] </ref>, and supercomputer-enhanced scientific instruments [18]. fl Mathematics and Computer Science Division, Argonne National Laboratory, foster@mcs.anl.gov y The Beckman Institute, California Institute of Technology, carl@compbio.caltech.edu 1 2 Metacomputers have much in common with both distributed and parallel systems, yet also differ from these two architectures in important ways. <p> Collaborative environments. A third set of applications couple multiple virtual environments so that users at different locations can interact with each other and with supercomputer simulations <ref> [5, 6] </ref>. 4. Distributed supercomputing. These applications couple multiple computers to tackle problems that are too large for a single computer or that can benefit from executing different problem components on different computer architectures [22, 24, 25]. We can distinguish scheduled and unscheduled modes of operation.
Reference: [6] <author> T. L. Disz, M. E. Papka, M. Pellegrino, and R. Stevens, </author> <title> Sharing visualization experiences among remote virtual environments, </title> <booktitle> in International Workshop on High Performance Computing for Computer Graphics and Visualization, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995, </year> <pages> pp. 217-237. 15 </pages>
Reference-contexts: For example, the I-WAY networking experiment, which connected supercomputers and other resources at 17 different sites across North America, saw 60 groups develop applications in areas as diverse as large-scale scientific simulation [24, 25], collaborative engineering <ref> [5, 6] </ref>, and supercomputer-enhanced scientific instruments [18]. fl Mathematics and Computer Science Division, Argonne National Laboratory, foster@mcs.anl.gov y The Beckman Institute, California Institute of Technology, carl@compbio.caltech.edu 1 2 Metacomputers have much in common with both distributed and parallel systems, yet also differ from these two architectures in important ways. <p> Collaborative environments. A third set of applications couple multiple virtual environments so that users at different locations can interact with each other and with supercomputer simulations <ref> [5, 6] </ref>. 4. Distributed supercomputing. These applications couple multiple computers to tackle problems that are too large for a single computer or that can benefit from executing different problem components on different computer architectures [22, 24, 25]. We can distinguish scheduled and unscheduled modes of operation.
Reference: [7] <author> S. Fitzgerald, I. Foster, C. Kesselman, G. von Laszewski, W. Smith, and S. Tuecke, </author> <title> A directory service for configuring high-performance distributed computations, </title> <type> preprint, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1997. </year>
Reference-contexts: Globus defines a single, unified access mechanism for this wide range of information, called the Metacomputing Directory Service (MDS) <ref> [7] </ref>. Building on the data representation and application programming interface defined by the Lightweight Directory Access Protocol (LDAP), MDS defines a framework in which can be represented information of interest in distributed computing applications. <p> Eventually, we expect most GUSTO sites to be accessible over the National Science Foundation's OC3 vBNS network. Authentication is based on the uniform certificate mechanism described above. The initial information service is provided by an information server that maintains information about resource configuration and current network characteristics <ref> [7] </ref>.
Reference: [8] <author> I. Foster, J. Geisler, C. Kesselman, and S. Tuecke, </author> <title> Managing multiple communication methods in high-performance networked computing systems, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> (1997). To appear. </note>
Reference-contexts: This interface is used extensively by other Globus modules and has also been used to construct various higher-level services, including parallel programming tools (Section 5.1). The Active Messages [21] and Fast Messages [26] systems have similarities in goals and approach, but there are also significant differences <ref> [8] </ref>. 9 Nexus programs bind communication startpoints and endpoints to form communication links. If multiple startpoints are bound to an endpoint, incoming communications are interleaved, in the same manner as messages sent to the same node in a message passing system. <p> The Nexus interface and implementation support rule-based selection (Section 3.2) of the methods|such as protocol, compression method, and quality of service|used to perform communication <ref> [8] </ref>. Different communication methods can be associated with different communication links, with selection rules determining which method should be used when a new link is established. These mechanisms have been used to support multiple communication protocols [8] and selective use of secure communication [11] in heterogeneous environments. 4.2 Metacomputing Directory Service <p> of the methods|such as protocol, compression method, and quality of service|used to perform communication <ref> [8] </ref>. Different communication methods can be associated with different communication links, with selection rules determining which method should be used when a new link is established. These mechanisms have been used to support multiple communication protocols [8] and selective use of secure communication [11] in heterogeneous environments. 4.2 Metacomputing Directory Service As noted above, metacomputing environments depend critically on access to information about the underlying networked supercomputing system. <p> We have introduced selection, information, and notification mechanisms and have defined Globus component interfaces so that these mechanisms can be used to guide the configuration process. Preliminary experiments with dynamic communication selection suggest that these configuration mechanisms can have considerable value <ref> [8] </ref>.
Reference: [9] <author> I. Foster, J. Geisler, W. Nickless, W. Smith, and S. Tuecke, </author> <title> Software infrastructure for the I-WAY high-performance distributed computing experiment, </title> <booktitle> in Proc. 5th IEEE Symp. on High Performance Distributed Computing, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996, </year> <pages> pp. 562-571. </pages>
Reference-contexts: This situation is acceptable if the user (or resource) trusts the administration of the site issuing the Globus-signed certificate. 6 Globus Testbeds and Experiences We have referred above to the I-WAY experiment, in which a number of Globus components were first deployed as part of the I-Soft software environment <ref> [9] </ref>. These components included the Nexus communication library, Kerberos-based authentication, a process creation mechanism, and a centralized scheduler for compute resources. While inadequate in a number of respects (e.g., nonscalable, no scheduling of network resources), this experiment did demonstrate the advantages of the Globus approach of providing basic mechanisms. <p> Authentication is based on the uniform certificate mechanism described above. The initial information service is provided by an information server that maintains information about resource configuration and current network characteristics [7]. This information is updated dynamically, providing a more accurate view of system configuration than was available in I-Soft <ref> [9] </ref>. 7 Conclusions and Future Work The Globus project is attacking the metacomputing software problem from the bottom up, by developing basic mechanisms that can be used to implement a variety of higher-level services.
Reference: [10] <author> I. Foster, J. Geisler, and S. Tuecke, </author> <title> MPI on the I-WAY: A wide-area, multimethod implementation of the Message Passing Interface, </title> <booktitle> in Proceedings of the 1996 MPI Developers Conference, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996, </year> <pages> pp. 10-17. </pages>
Reference-contexts: We say a few words here about the Globus implementation of MPI. A "Nexus device" supports the abstract device interface used within the MPICH implementation of MPI [16]. This device uses Nexus RSRs to implement the basic data transfer operations required by MPI <ref> [10] </ref>; higher-level MPI functionality then transfers unchanged from MPICH.
Reference: [11] <author> I. Foster, N. Karonis, C. Kesselman, G. Koenig, and S. Tuecke, </author> <title> A secure communications infrastructure for high-performance distributed computing, </title> <type> Preprint ANL/MCS-P613-0996, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1996. </year>
Reference-contexts: Different communication methods can be associated with different communication links, with selection rules determining which method should be used when a new link is established. These mechanisms have been used to support multiple communication protocols [8] and selective use of secure communication <ref> [11] </ref> in heterogeneous environments. 4.2 Metacomputing Directory Service As noted above, metacomputing environments depend critically on access to information about the underlying networked supercomputing system. <p> A recent redesign of both Nexus and the MPICH abstract device interface has succeeded in eliminating most of this overhead. In addition to this use of Nexus, the Globus implementation of MPI uses Globus mechanisms for authentication and process startup <ref> [11] </ref>.
Reference: [12] <author> I. Foster, C. Kesselman, and S. Tuecke, </author> <title> The Nexus approach to integrating multithreading and communication, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37 (1996), </volume> <pages> pp. 70-82. </pages>
Reference-contexts: In each case, we outline how the component maps to different implementations, is used to implement different higher-level services, and supports the development of AWARE services and applications. 4.1 Communications The Globus communications module is based on the Nexus communication library <ref> [12] </ref>. Nexus defines five basic abstractions: nodes, contexts, threads, communication links, and remote service requests (Figure 3). The Nexus functions that manipulate these abstractions constitute the Globus communication interface.
Reference: [13] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, B. Manchek, and V. Sunderam, </author> <title> PVM: Parallel Virtual Machine|A User's Guide and Tutorial for Network Parallel Computing, </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Decision processes can require complex combinations of these data in order to achieve efficient end-to-end configuration of complex networked systems. 3 The Globus Metacomputing Infrastructure Toolkit A number of pioneering efforts have produced useful services for the metacomputing application developer. For example, Parallel Virtual Machine (PVM) <ref> [13] </ref> and the Message Passing Interface (MPI) [17] provide a machine-independent communication layer, Condor [20] provides a uniform view of processor resources, Legion [14] builds system components on a distributed object-oriented model, and the Andrew File System (AFS) [23] provides a uniform view of file resources.
Reference: [14] <author> A. Grimshaw and W. Wolf, </author> <title> Legion a view from 50,000 feet, </title> <booktitle> in Proc. 5th IEEE Symp. on High Performance Distributed Computing, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996, </year> <pages> pp. 89-99. </pages>
Reference-contexts: For example, Parallel Virtual Machine (PVM) [13] and the Message Passing Interface (MPI) [17] provide a machine-independent communication layer, Condor [20] provides a uniform view of processor resources, Legion <ref> [14] </ref> builds system components on a distributed object-oriented model, and the Andrew File System (AFS) [23] provides a uniform view of file resources. Each of these systems has been proven effective in large-scale application experiments. <p> We hope to involve more of the metacomputing community in this process, by adapting relevant higher-level services (e.g., application-level scheduling [1], performance steering [27], object-based libraries <ref> [14] </ref>) to use Globus mecha 14 nisms, and by participating in the construction of additional testbeds (e.g., GUSTO). The Globus project is also addressing the configuration problem in metacomputing systems, with the goal of producing an Adaptive Wide Area Resource Environment that supports the construction of adaptive services and applications.
Reference: [15] <author> A. Grimshaw, W. Wulf, J. French, A. Weaver, and P. Reynolds, Jr., Legion: </author> <title> The next logical step toward a nationwide virtual computer, </title> <type> Tech. Rep. </type> <institution> CS-94-21, Department of Computer Science, University of Virginia, </institution> <year> 1994. </year>
Reference-contexts: Nevertheless, we can make general observations about their characteristics (see also <ref> [15] </ref>). * Scale and the need for selection. To date, most metacomputing experiments have been performed on relatively small testbeds, with the 17-site I-WAY being the largest.
Reference: [16] <author> W. Gropp, E. Lusk, N. Doss, and A. Skjellum, </author> <title> A high-performance, portable implementation of the MPI message passing interface standard, </title> <type> Technical Report ANL/MCS-TM-213, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1996. </year>
Reference-contexts: We say a few words here about the Globus implementation of MPI. A "Nexus device" supports the abstract device interface used within the MPICH implementation of MPI <ref> [16] </ref>. This device uses Nexus RSRs to implement the basic data transfer operations required by MPI [10]; higher-level MPI functionality then transfers unchanged from MPICH.
Reference: [17] <author> W. Gropp, E. Lusk, and A. Skjellum, </author> <title> Using MPI: Portable Parallel Programming with the Message Passing Interface, </title> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: For example, Parallel Virtual Machine (PVM) [13] and the Message Passing Interface (MPI) <ref> [17] </ref> provide a machine-independent communication layer, Condor [20] provides a uniform view of processor resources, Legion [14] builds system components on a distributed object-oriented model, and the Andrew File System (AFS) [23] provides a uniform view of file resources.
Reference: [18] <author> C. Lee, C. Kesselman, and S. Schwab, </author> <title> Near-realtime satellite image processing: Metacomputing in CC++, </title> <journal> Computer Graphics and Applications, </journal> <volume> 16 (1996), </volume> <pages> pp. 79-84. </pages>
Reference-contexts: For example, the I-WAY networking experiment, which connected supercomputers and other resources at 17 different sites across North America, saw 60 groups develop applications in areas as diverse as large-scale scientific simulation [24, 25], collaborative engineering [5, 6], and supercomputer-enhanced scientific instruments <ref> [18] </ref>. fl Mathematics and Computer Science Division, Argonne National Laboratory, foster@mcs.anl.gov y The Beckman Institute, California Institute of Technology, carl@compbio.caltech.edu 1 2 Metacomputers have much in common with both distributed and parallel systems, yet also differ from these two architectures in important ways. <p> a discussion of current system status and future plans. 2 Metacomputing We use the term metacomputer to denote a networked virtual supercomputer, constructed dynamically from geographically distributed resources linked by high-speed networks. architecture was used in the I-WAY for real-time image processing of a data stream from a meteorological satellite <ref> [18] </ref>. In that application, data passed from the satellite downlink to a a cloud detection program running on a remote supercomputer, and then to a graphics computer for rendering. Metacomputing, like more mainstream applications of distributed computing, is moti 3 Fig. 1. <p> These applications couple high-end graphics capabilities with remote supercomputers and/or databases. This coupling connects users more tightly with computing capabilities, while at the same time achieving distance independence between resources, developers, and users. 2. Smart instruments. These applications connect users to instruments such as microscopes, telescopes, or satellite downlinks <ref> [18] </ref> that are themselves coupled with remote supercomputers. This computational enhancement can enable both quasi realtime processing of instrument output and interactive steering. 4 Fig. 2. This figure shows a networked supercomputing system used during the I-WAY experiment for the real-time analysis of data from a meteorological satellite.
Reference: [19] <author> J. Linn, </author> <title> Generic security service application program interface, Internet RFC 1508, </title> <year> (1993). </year>
Reference-contexts: To increase the degree of abstraction at the toolkit interface, we are moving towards the use of the Generic Security System (GSS) <ref> [19] </ref>. GSS defines a standard procedure and API for obtaining credentials (passwords or certificates), for mutual authentication (client and server), and for message-oriented encryption and decryption. GSS is independent of any particular security mechanism and can be layered on top of different security methods, such as Kerberos and SSL.
Reference: [20] <author> M. Litzkow, M. Livney, and M. </author> <title> Mutka, Condor a hunter of idle workstations, </title> <booktitle> in Proc. 8th Intl Conf. on Distributed Computing Systems, </booktitle> <year> 1988, </year> <pages> pp. 104-111. </pages>
Reference-contexts: We can distinguish scheduled and unscheduled modes of operation. In scheduled mode, resources, once acquired, are dedicated to an application. In unscheduled mode, applications use otherwise idle resources that may be reclaimed if needed; Condor <ref> [20] </ref> is one system that supports this mode of operation. <p> For example, Parallel Virtual Machine (PVM) [13] and the Message Passing Interface (MPI) [17] provide a machine-independent communication layer, Condor <ref> [20] </ref> provides a uniform view of processor resources, Legion [14] builds system components on a distributed object-oriented model, and the Andrew File System (AFS) [23] provides a uniform view of file resources. Each of these systems has been proven effective in large-scale application experiments.
Reference: [21] <author> A. Mainwaring, </author> <title> Active Message applications programming interface and communication subsystem organization, </title> <type> tech. rep., </type> <institution> Dept. of Computer Science, UC Berkeley, Berkeley, </institution> <address> CA, </address> <year> 1996. </year>
Reference-contexts: The Nexus functions that manipulate these abstractions constitute the Globus communication interface. This interface is used extensively by other Globus modules and has also been used to construct various higher-level services, including parallel programming tools (Section 5.1). The Active Messages <ref> [21] </ref> and Fast Messages [26] systems have similarities in goals and approach, but there are also significant differences [8]. 9 Nexus programs bind communication startpoints and endpoints to form communication links.
Reference: [22] <author> C. Mechoso et al., </author> <title> Distribution of a Coupled-ocean General Circulation Model across high-speed networks, </title> <booktitle> in Proceedings of the 4th International Symposium on Computational Fluid Dynamics, </booktitle> <year> 1991. </year>
Reference-contexts: Distributed supercomputing. These applications couple multiple computers to tackle problems that are too large for a single computer or that can benefit from executing different problem components on different computer architectures <ref> [22, 24, 25] </ref>. We can distinguish scheduled and unscheduled modes of operation. In scheduled mode, resources, once acquired, are dedicated to an application. In unscheduled mode, applications use otherwise idle resources that may be reclaimed if needed; Condor [20] is one system that supports this mode of operation.
Reference: [23] <author> J. Morris et al., Andrew: </author> <title> A distributed personal computing environment, </title> <journal> Communications of the ACM, </journal> <month> 29 </month> <year> (1986). </year>
Reference-contexts: For example, Parallel Virtual Machine (PVM) [13] and the Message Passing Interface (MPI) [17] provide a machine-independent communication layer, Condor [20] provides a uniform view of processor resources, Legion [14] builds system components on a distributed object-oriented model, and the Andrew File System (AFS) <ref> [23] </ref> provides a uniform view of file resources. Each of these systems has been proven effective in large-scale application experiments.
Reference: [24] <author> J. Nieplocha and R. Harrison, </author> <title> Shared memory NUMA programming on the I-WAY, </title> <booktitle> in Proc. 5th IEEE Symp. on High Performance Distributed Computing, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996, </year> <pages> pp. 432-441. </pages>
Reference-contexts: For example, the I-WAY networking experiment, which connected supercomputers and other resources at 17 different sites across North America, saw 60 groups develop applications in areas as diverse as large-scale scientific simulation <ref> [24, 25] </ref>, collaborative engineering [5, 6], and supercomputer-enhanced scientific instruments [18]. fl Mathematics and Computer Science Division, Argonne National Laboratory, foster@mcs.anl.gov y The Beckman Institute, California Institute of Technology, carl@compbio.caltech.edu 1 2 Metacomputers have much in common with both distributed and parallel systems, yet also differ from these two architectures in <p> Distributed supercomputing. These applications couple multiple computers to tackle problems that are too large for a single computer or that can benefit from executing different problem components on different computer architectures <ref> [22, 24, 25] </ref>. We can distinguish scheduled and unscheduled modes of operation. In scheduled mode, resources, once acquired, are dedicated to an application. In unscheduled mode, applications use otherwise idle resources that may be reclaimed if needed; Condor [20] is one system that supports this mode of operation.
Reference: [25] <author> M. Norman et al., </author> <title> Galaxies collide on the I-WAY: An example of heterogeneous wide-area collaborative supercomputing, </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 10 (1996), </volume> <pages> pp. 131-140. </pages>
Reference-contexts: For example, the I-WAY networking experiment, which connected supercomputers and other resources at 17 different sites across North America, saw 60 groups develop applications in areas as diverse as large-scale scientific simulation <ref> [24, 25] </ref>, collaborative engineering [5, 6], and supercomputer-enhanced scientific instruments [18]. fl Mathematics and Computer Science Division, Argonne National Laboratory, foster@mcs.anl.gov y The Beckman Institute, California Institute of Technology, carl@compbio.caltech.edu 1 2 Metacomputers have much in common with both distributed and parallel systems, yet also differ from these two architectures in <p> Distributed supercomputing. These applications couple multiple computers to tackle problems that are too large for a single computer or that can benefit from executing different problem components on different computer architectures <ref> [22, 24, 25] </ref>. We can distinguish scheduled and unscheduled modes of operation. In scheduled mode, resources, once acquired, are dedicated to an application. In unscheduled mode, applications use otherwise idle resources that may be reclaimed if needed; Condor [20] is one system that supports this mode of operation.
Reference: [26] <author> S. Pakin, M. Lauria, and A. Chien, </author> <title> High performance messaging on workstations: Illinois Fast Messages (fm) for Myrinet, </title> <booktitle> in Proceedings of Supercomputing '95, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference-contexts: The Nexus functions that manipulate these abstractions constitute the Globus communication interface. This interface is used extensively by other Globus modules and has also been used to construct various higher-level services, including parallel programming tools (Section 5.1). The Active Messages [21] and Fast Messages <ref> [26] </ref> systems have similarities in goals and approach, but there are also significant differences [8]. 9 Nexus programs bind communication startpoints and endpoints to form communication links.
Reference: [27] <author> D. Reed, C. Elford, T. Madhyastha, E. Smirni, and S. </author> <title> Lamm, The Next Frontier: Interactive and Closed Loop Performance Steering, </title> <booktitle> in Proceedings of the 1996 ICPP Workshop on 16 Challenges for Parallel Processing, </booktitle> <month> Aug. </month> <year> 1996, </year> <pages> pp. 20-31. </pages>
Reference-contexts: The definition, development, application, evaluation, and refinement of these components are ongoing processes that we expect to proceed for the next two years at least. We hope to involve more of the metacomputing community in this process, by adapting relevant higher-level services (e.g., application-level scheduling [1], performance steering <ref> [27] </ref>, object-based libraries [14]) to use Globus mecha 14 nisms, and by participating in the construction of additional testbeds (e.g., GUSTO).
Reference: [28] <author> R. Thakur, W. Gropp, and E. Lusk, </author> <title> An Abstract-Device Interface for Implementing Portable Parallel-I/O Interfaces, </title> <booktitle> in Proceedings of The 6th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: To address these problems, the Globus data access module defines primitives that provide remote access to parallel file systems. This remote I/O (RIO) interface (Figure 5) is based on the abstract I/O device (ADIO) interface <ref> [28] </ref>. ADIO defines an interface for opening, closing, reading and writing parallel files. It does not define semantics for caching, file replication, or parallel file descriptor semantics. Several popular I/O systems have been implemented efficiently on ADIO [28]. <p> (RIO) interface (Figure 5) is based on the abstract I/O device (ADIO) interface <ref> [28] </ref>. ADIO defines an interface for opening, closing, reading and writing parallel files. It does not define semantics for caching, file replication, or parallel file descriptor semantics. Several popular I/O systems have been implemented efficiently on ADIO [28]. RIO extends ADIO by adding transparent remote access and global naming using a URL-based naming scheme. RIO remote access features use Nexus mechanisms. 5 Higher-Level Services In the preceding section, we described the core interfaces and services provided by the Globus toolkit.
Reference: [29] <author> R. Wolski, </author> <title> Dynamically forecasting network performance using the network weather service, </title> <type> Tech. Rep. </type> <institution> TR-CS96-494, U.C. </institution> <address> San Diego, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Information may be obtained from multiple sources: for example, from standard information services such as the Network Information Service (NIS) or Simple Network Management Protocol (SNMP); from specialized services such as the Network Weather Service <ref> [29] </ref>; or from external sources such as the system manager or an application. Globus defines a single, unified access mechanism for this wide range of information, called the Metacomputing Directory Service (MDS) [7].
References-found: 29

