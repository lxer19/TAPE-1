URL: ftp://ftp.cs.helsinki.fi/pub/Reports/by_Project/Cosco/Learning_in_neural_networks_with_Bayesian_prototypes.ps.gz
Refering-URL: http://www.cs.helsinki.fi/~tirri/publications.html
Root-URL: 
Title: Learning in neural networks with Bayesian prototypes  
Author: Petri Myllymaki and Henry Tirri 
Address: P.O.Box 26, FIN-00014 University of Helsinki, Finland  
Affiliation: University of Helsinki, Department of Computer Science  
Date: March 1994), 60-64.  
Note: Proceedings of SOUTHCON'94 (Orlando,  
Abstract: Given a set of samples of a probability distribution on a set of discrete random variables, we study the problem of constructing a good approximative neural network model of the underlying probability distribution. Our approach is based on an unsupervised learning scheme where the samples are first divided into separate clusters, and each cluster is then coded as a single vector. These Bayesian prototype vectors consist of conditional probabilities representing the attribute-value distribution inside the corresponding cluster. Using these prototype vectors, it is possible to model the underlying joint probability distribution as a simple Bayesian network (a tree), which can be realized as a feedforward neural network capable of probabilistic reasoning. In this framework, learning means choosing the size of the prototype set, partitioning the samples into the corresponding clusters, and constructing the cluster prototypes. We describe how the prototypes can be determined, given a partition of the samples, and present a method for evaluating the likelihood of the corresponding Bayesian tree. We also present a greedy heuristic for searching through the space of different partition schemes with different numbers of clusters, aiming at an optimal approximation of the probability distribution. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Cheeseman, J. Kelly, M. Self, J. Stutz, W. Taylor and D. Freeman, </author> <title> AutoClass: A Bayesian Classification System. Pp. </title> <booktitle> 54-64 in Proc. of the Fifth International Conference on Machine Learning, </booktitle> <address> Ann Arbor, June 12-14, </address> <publisher> 1988 (Mor-gan Kaufmann). </publisher>
Reference: [2] <author> G.F. Cooper and E. Herskovits, </author> <title> A Bayesian Method for Induction of Probabilistic Networks from Data. </title> <journal> Machine Learning, </journal> <volume> vol. </volume> <pages> 9 , pp. 309-347, </pages> <year> 1992. </year>
Reference: [3] <author> W. Hsu, L.S. Hsu and M.F. Tenorio, </author> <title> The Clus-net Algorithm and Time Series Prediction. </title> <journal> International Journal of Neural Systems, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 247-255, </pages> <month> September </month> <year> 1993. </year>
Reference: [4] <author> H. Kitano, </author> <title> Challenges of Massive Parallelism. Pp. </title> <booktitle> 813-834 in Proc. of IJCAI-93, the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Chambery, France, </address> <publisher> August 1993 (Morgan Kaufmann). </publisher>
Reference: [5] <author> I. Kononenko, </author> <title> Successive Naive Bayesian Classifier. </title> <journal> Informatica, </journal> <volume> vol. 17, </volume> <pages> pp. 167-174, </pages> <year> 1993. </year>
Reference: [6] <author> P. Langley, </author> <title> Induction of Recursive Bayesian Classifiers. </title> <note> Pp. 153-164 in P.B. </note> <editor> Brazdil (ed.), </editor> <booktitle> Proc. of ECML-93, European Conference on Machine Learning, </booktitle> <address> Vienna, Austria, April 5-7, </address> <publisher> 1993 (Springer-Verlag). </publisher>
Reference: [7] <author> W. Lam and F. Bacchus, </author> <title> Using Causal Information and Local Measures to Learn Bayesian Networks. Pp. </title> <editor> 243-250 in D. Heckerman and A. Mamdani (eds.), </editor> <booktitle> Proc. of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Washington, D.C., July 9-11, </address> <publisher> 1993 (Morgan Kaufmann). </publisher>
Reference: [8] <author> S. Lee and S. Shimoji, BAYESNET: </author> <title> Bayesian Classification Network Bsed on Biased Random Competition using Gaussian Kernels. Pp. </title> <booktitle> 1354-1359 in Proc. of the IEEE International Conf. on Neural Networks, </booktitle> <address> San Francisco, </address> <publisher> March 1993 (IEEE Press). </publisher>
Reference: [9] <author> J. Moody and C. Darken, </author> <title> Fast learning in networks of locally-tuned processing units. </title> <journal> Neural Computation, </journal> <volume> vol. 1, </volume> <pages> 281-294, </pages> <year> 1989. </year>
Reference: [10] <author> P. Myllymaki and H. Tirri, </author> <title> Bayesian Case-Based Reasoning with Neural Networks. Pp. </title> <booktitle> 422-427 in Proc. of the IEEE International Conf. on Neural Networks, </booktitle> <address> San Francisco, </address> <publisher> March 1993 (IEEE Press). </publisher>
Reference: [11] <author> P. Myllymaki and H. Tirri, </author> <title> Massively Parallel Case-Based Reasoning with Probabilistic Similarity Metrics. </title> <note> Pp. 48-53 in M.M. </note> <editor> Richter, S. Wess, K.-D. Althoff and F. Maurer (eds.), </editor> <booktitle> Proc. of the First European Workshop on Case-Based Reasoning, </booktitle> <institution> University of Kaiserslautern, </institution> <month> 1-5 November, </month> <year> 1993. </year> <type> SEKI Report SR-93-12 (SFB 314), </type> <institution> University of Kaiserslautern. </institution>
Reference: [12] <author> R. </author> <title> Neapolitan, Probabilistic Reasoning in Expert Systems. </title> <publisher> Wiley Interscience, </publisher> <year> 1990. </year>
Reference: [13] <author> E. Parzen, </author> <title> On estimation of a probability distribution and mode. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> vol. 33, </volume> <pages> pp. 1065-1076, </pages> <year> 1962. </year>
Reference: [14] <author> J. Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference: [15] <author> J. Rissanen, </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific, </publisher> <year> 1989. </year>
Reference: [16] <author> W.R. Robinson, </author> <title> Counting unlabeled acyclic digraphs. In C.H.C. Little (ed.), </title> <booktitle> Lecture notes in mathematics 622: Combinatorial mathematics. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1977. </year>
Reference: [17] <author> D.F. Specht, </author> <title> Probabilistic Neural Networks. </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 3, </volume> <pages> pp. 109-118, </pages> <year> 1990. </year>
Reference: [18] <author> D.F. Specht, </author> <title> A General Regression Neural Network. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 2, No. 6, </volume> <pages> pp. 568-576, </pages> <month> November </month> <year> 1991. </year> <month> 64 </month>
References-found: 18

