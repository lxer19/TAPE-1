URL: http://www-swiss.ai.mit.edu/~switz/amorphous/papers/aimemo1614.ps
Refering-URL: http://www-swiss.ai.mit.edu/~switz/amorphous/paperlisting.html
Root-URL: 
Title: Paradigms for Structure in an Amorphous Computer  
Author: Daniel Coore, Radhika Nagpal, Ron Weiss 
Web: URL ftp://publications.ai.mit.edu/ai-publications/  
Note: Copyright c Massachusetts Institute of Technology, 1997. This publication can be retrieved by anonymous ftp at  
Date: 1614 October 6, 1997  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Memo No.  
Abstract: Recent developments in microfabrication and nanotechnology will enable the inexpensive manufacturing of massive numbers of tiny computing elements with sensors and actuators. New programming paradigms are required for obtaining organized and coherent behavior from the cooperation of large numbers of unreliable processing elements that are interconnected in unknown, irregular, and possibly time-varying ways. Amorphous computing is the study of developing and programming such ultrascale computing environments. This paper presents an approach to programming an amorphous computer by spontaneously organizing an unstructured collection of processing elements into cooperative groups and hierarchies. This paper introduces a structure called an AC Hierarchy, which logically organizes processors into groups at different levels of granularity. The AC hierarchy simplifies programming of an amorphous computer through new language abstractions, facilitates the design of efficient and robust algorithms, and simplifies the analysis of their performance. Several example applications are presented that greatly benefit from the AC hierarchy. This paper introduces three algorithms for constructing multiple levels of the hierarchy from an unstructured This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for this research was provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-96-1-1228. Radhika Nagpal was also supported by the AT&T GRPW Fellowship. collection of processors.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Hal Abelson, Tom Knight, and Gerry Sussman. </author> <note> Amorphous computing. White paper, </note> <month> October </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Amorphous computing is the study of developing and programming ultrascale computing environments <ref> [1] </ref>. Recent developments in microfabrication and nanotechnology will enable the inexpensive manufacturing of vast numbers of tiny computing elements with integrated sensors and microactuators.
Reference: [2] <author> Baruch Awerbuch, Lenore Cohen, and Mark Smith. </author> <title> Efficient asynchronous distributed symmetry breaking. </title> <booktitle> In Proceedings of the 26th Annual Symposium on the Theory of Computation, </booktitle> <address> Montreal, Canada, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: group grows quadratically in the height of the tree, as opposed to exponentially. 21 5 Related Work The leader election mechanisms used by the clubs and tree-regions algorithms, are similar to other parallel algorithms for Maximal Independent Set (MIS) problem described by Luby [9], and applied to asynchronous networks in <ref> [10, 2] </ref>. In this case however, the properties of coverage and low message overhead are more important than obtaining a maximal independent set. Many synchronous and asynchronous algorithms for generating spanning trees are described in [10]. [3] presents an algorithm that produces tree based clusters by using global ids.
Reference: [3] <author> Baruch Awerbuch, Andrew Goldberg, Michael Luby, and Serge Plotkin. </author> <title> Network decomposition and locality in distributed computation. </title> <booktitle> In Proceedings of the 30th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 364-369, </pages> <institution> Research Triangle Park, North Carolina, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: In this case however, the properties of coverage and low message overhead are more important than obtaining a maximal independent set. Many synchronous and asynchronous algorithms for generating spanning trees are described in [10]. <ref> [3] </ref> presents an algorithm that produces tree based clusters by using global ids. Many different papers have suggested aggregation and hierarchies of aggregates as a possible mechanism for programming and hiding complexity. Swarm [7] presents a hierarchy based language for simulation environments.
Reference: [4] <author> Andrew A. Chien. </author> <title> Concurrent Aggregates (CA): Supporting Modularity in Massively-Parallel Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: Many different papers have suggested aggregation and hierarchies of aggregates as a possible mechanism for programming and hiding complexity. Swarm [7] presents a hierarchy based language for simulation environments. Concurrent Aggregates <ref> [5, 4] </ref> also presents a language based on aggregates being treated as objects which is to be used to program a parallel machine. The main difference is the spatial nature of the amorphous computer and the direct mapping between the hierarchy language and the distribution of tasks.
Reference: [5] <author> Andrew A. Chien and William J. Dally. </author> <title> Concurrent aggregates. </title> <booktitle> In Second ACM SIG-PLAN Symposium on Principles and Practice of Parallel Programming. ACM, </booktitle> <month> March </month> <year> 1990. </year>
Reference-contexts: Many different papers have suggested aggregation and hierarchies of aggregates as a possible mechanism for programming and hiding complexity. Swarm [7] presents a hierarchy based language for simulation environments. Concurrent Aggregates <ref> [5, 4] </ref> also presents a language based on aggregates being treated as objects which is to be used to program a parallel machine. The main difference is the spatial nature of the amorphous computer and the direct mapping between the hierarchy language and the distribution of tasks.
Reference: [6] <author> Steven R. Hall, Edward F. Crawley, Jonathan P. How, and Benjamin Ward. </author> <title> Hierarchic control architecture for intelligent structures. </title> <journal> J. Guidance, Control, and Dynamics, </journal> <volume> 14(3), </volume> <month> May-June </month> <year> 1991. </year>
Reference-contexts: Processors accumulate sensory input and use actuators to control the property of interest. The distributed control problem, where control decisions are based on only a subset of all the sensory information, is not well understood. Hall, Crawley, How and Ward show in <ref> [6, 8] </ref> that an effective approach to controlling a stiff material (e.g. maintaining a particular shape) in a distributed manner is to build a hierarchical controller. They describe a two level hierarchical control system. <p> The success of the two-phased actuation (as opposed to computing the sum of responses and applying it once) depends heavily on the light coupling of the two levels' controllers. Some approaches to reducing the coupling between the lower and higher level controllers are discussed in <ref> [6] </ref>. Increasing the number of levels in the hierarchical controller without sacrificing its effectiveness is a non-trivial task. One of the crucial obstacles would be the decoupling of the controllers at the different levels.
Reference: [7] <author> David Hiebeler. </author> <title> The swarm simulation system and individual-based modeling. In Decision Support 2001: Advanced Technology for Natural Resource Management, </title> <address> Toronto, Canada, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Many synchronous and asynchronous algorithms for generating spanning trees are described in [10]. [3] presents an algorithm that produces tree based clusters by using global ids. Many different papers have suggested aggregation and hierarchies of aggregates as a possible mechanism for programming and hiding complexity. Swarm <ref> [7] </ref> presents a hierarchy based language for simulation environments. Concurrent Aggregates [5, 4] also presents a language based on aggregates being treated as objects which is to be used to program a parallel machine.
Reference: [8] <author> Jonathan P. How and Steven R. Hall. </author> <title> Local control design methodologies for a hierarchic control architecture. </title> <journal> J. Guidance, Control, and Dynamics, </journal> <volume> 15(3), </volume> <month> May-June </month> <year> 1992. </year>
Reference-contexts: Processors accumulate sensory input and use actuators to control the property of interest. The distributed control problem, where control decisions are based on only a subset of all the sensory information, is not well understood. Hall, Crawley, How and Ward show in <ref> [6, 8] </ref> that an effective approach to controlling a stiff material (e.g. maintaining a particular shape) in a distributed manner is to build a hierarchical controller. They describe a two level hierarchical control system.
Reference: [9] <author> Michael Luby. </author> <title> A simple parallel algorithm for the maximal independent set problem. </title> <journal> SIAM Journal of Computing, </journal> <volume> 15(4), </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: After time R, leaders can detect conflicts by conferring with their neighbors. If there is a conflict, the conflicting leaders and their members run another round of overlapping clubs. The algorithm is similar to the maximal independent set algorithm described in <ref> [9] </ref> and has similar expected time complexity of O (log n), where n is the total number of processors. However, overlapping clubs is well suited for a broadcast environment because of its low message overhead and low synchronization requirements. Overlapping clubs produces valid groups even in if message loss occurs. <p> Hence, the number of processors in a group grows quadratically in the height of the tree, as opposed to exponentially. 21 5 Related Work The leader election mechanisms used by the clubs and tree-regions algorithms, are similar to other parallel algorithms for Maximal Independent Set (MIS) problem described by Luby <ref> [9] </ref>, and applied to asynchronous networks in [10, 2]. In this case however, the properties of coverage and low message overhead are more important than obtaining a maximal independent set.
Reference: [10] <author> Nancy Lynch. </author> <title> Distributed Algorithms. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Wonderland, </address> <year> 1996. </year>
Reference-contexts: group grows quadratically in the height of the tree, as opposed to exponentially. 21 5 Related Work The leader election mechanisms used by the clubs and tree-regions algorithms, are similar to other parallel algorithms for Maximal Independent Set (MIS) problem described by Luby [9], and applied to asynchronous networks in <ref> [10, 2] </ref>. In this case however, the properties of coverage and low message overhead are more important than obtaining a maximal independent set. Many synchronous and asynchronous algorithms for generating spanning trees are described in [10]. [3] presents an algorithm that produces tree based clusters by using global ids. <p> In this case however, the properties of coverage and low message overhead are more important than obtaining a maximal independent set. Many synchronous and asynchronous algorithms for generating spanning trees are described in <ref> [10] </ref>. [3] presents an algorithm that produces tree based clusters by using global ids. Many different papers have suggested aggregation and hierarchies of aggregates as a possible mechanism for programming and hiding complexity. Swarm [7] presents a hierarchy based language for simulation environments.
Reference: [11] <author> Paul F. Tsuchiya. </author> <title> The landmark hierarchy: A new hierarchy for routing in very large networks. </title> <booktitle> In Proc. of the SIGCOMM '88 Symposium on Communications Architectures and Protocols, </booktitle> <address> Stanford, CA, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: In this context, edges reflect physical distances between the named entities. When comparing two names, the length of the matching prefixes between them indicates the physical distance between the processors they represent. Certain routing schemes, such as area routing <ref> [11] </ref>, use organizations with properties similar to the AC Hierarchy properties. Area routing uses a hierarchy of areas, where the name of a processor is the sequence fA n ; : : : ; A 1 g of areas at different granularities to which it belongs.
References-found: 11

