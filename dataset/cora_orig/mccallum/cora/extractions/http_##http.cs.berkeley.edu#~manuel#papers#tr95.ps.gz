URL: http://http.cs.berkeley.edu/~manuel/papers/tr95.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~manuel/publications.html
Root-URL: 
Title: Better Static Memory Management: Improving Region-Based Analysis of Higher-Order Languages  
Author: Alexander Aiken Manuel Fahndrich Raph Levien 
Address: Berkeley  
Affiliation: Computer Science Division University of California,  
Pubnum: (Tech Report CSD-95-866)  
Abstract: Static memory management replaces runtime garbage collection with compile-time annotations that make all memory allocation and deallocation explicit in a program. We improve upon the Tofte/Talpin region-based scheme for compile-time memory management [TT94]. In the Tofte/Talpin approach, all values, including closures, are stored in regions. Region lifetimes coincide with lexical scope, thus forming a runtime stack of regions and eliminating the need for garbage collection. We relax the requirement that region lifetimes be lexical. Rather, regions are allocated late and deallocated as early as possible by explicit memory operations. The placement of allocation and deallocation annotations is determined by solving a system of constraints that expresses all possible annotations. Experiments show that our approach reduces memory requirements significantly, in some cases asymptotically.
Abstract-found: 1
Intro-found: 1
Reference: [App90] <author> Andrew Appel. </author> <title> A runtime system. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 3(4) </volume> <pages> 343-380, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Generational garbage collection [LH83] significantly reduces the average time per garbage collection, but does not change the fundamental time/space tradeoff. The key idea of generational garbage collection is to separate objects by their lifetime; short-lived objects are treated separately from long-lived ones. Modern generational garbage collectors <ref> [App90] </ref> exhibit good overall performance, often with an overhead of under 40% (including the overhead of maintaing garbage collector invariants, and reasonable cache performance [DTM94].
Reference: [App92] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Instead, we present representative examples of three typical patterns of behavior we have identified. A number of programs show asymptotic improvement over the Tofte/Talpin system. One example given in their paper (due to Appel <ref> [App92] </ref>), has O (n 2 ) space complexity. Our completion of this program exhibits O (n) space complexity (Figure 10). In this program, our analysis is able to deallocate a recursive function's parameter before function evaluation completes.
Reference: [Bak78] <author> Henry Baker. </author> <title> List processing in real time on a serial computer. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: However, it retains many of the problems mentioned above: pauses, memory consumption, and interoperability. 49 There are a number of techniques for reducing or eliminating the garbage collection pauses, including the incremental mark--sweep collector of Dijkstra et al [DLM + 78] and the incremental copying collector of Baker <ref> [Bak78] </ref>. The latter technique relies on some additional computation (called a read barrier) for read operations. On modern architectures, it is generally agreed that the cost of a read barrier is prohibitive.
Reference: [BW88] <author> Hans-J. Boehm and Mark Weiser. </author> <title> Garbage collection in an uncooperative enviroment. </title> <journal> Software Practice and Experience, </journal> <volume> 18(9) </volume> <pages> 214-221, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: This approach reduces the pauses, but does not eliminate them altogether. Also, the technique does not address the problems of memory usage or interoperability. Conservative garbage collection <ref> [BW88] </ref> does address the interoperability issue. With this type of collector (based on mark and sweep rather than copying), the compiler need maintain no invariants for the garbage collector. Without any such invariants, the collector is not capable of precisely distinguishing between pointers and non-pointers.
Reference: [CC77] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation: a unified lattice model for static analysis of programs by construction of approximation of fixpoints. </title> <booktitle> In Proc. of the 4th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 238-252, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: Closure analysis, an application of abstract interpretation <ref> [CC77] </ref>, approximates execution order in higher-order programs [Shi88, Ses92]. However, closure analysis alone is not sufficient for our purposes, because of problems with state polymorphism and region aliasing (see below). Imprecision in state polymorphism gives poor completions, but failure to detect aliasing may result in unsound completions.
Reference: [Deu90] <author> Alain Deutsch. </author> <title> On determining lifetime and aliasing of dynamically allocated data in higher-order functional specifications. </title> <booktitle> In Proc. of the 17th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 157-168, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Our results do not resolve this question, but we do show that static memory management can be significantly better than previously demonstrated. Much previous work has focussed on reducing, rather than eliminating, garbage collection <ref> [HJ90, Deu90] </ref>. The primary motivation for static memory management put forth in [TT94] is to reduce the amount of memory required to run general functional programs efficiently. Two other applications interest us. First, the pauses in execution caused by garbage collection pose a difficulty for programs with real-time constraints.
Reference: [DLM + 78] <author> Edsger W. Dijkstra, Leslie Lamport, A.J. Martin, C.S. Scholten, and E.F.M. Steffens. </author> <title> On-the-fly garbage collection: An exercise in cooperation. </title> <journal> Communications of the ACM, </journal> <volume> 21(11) </volume> <pages> 966-975, </pages> <month> November </month> <year> 1978. </year>
Reference-contexts: Two other applications interest us. First, the pauses in execution caused by garbage collection pose a difficulty for programs with real-time constraints. While there has been substantial work on real-time garbage collection <ref> [DLM + 78, NO93] </ref>, we find the simpler model of having no garbage collector at all appealing and worth investigation. Second, most programs written today are not written in garbage-collected applicative languages, but rather in procedural languages with programmer-specified memory management. <p> However, it retains many of the problems mentioned above: pauses, memory consumption, and interoperability. 49 There are a number of techniques for reducing or eliminating the garbage collection pauses, including the incremental mark--sweep collector of Dijkstra et al <ref> [DLM + 78] </ref> and the incremental copying collector of Baker [Bak78]. The latter technique relies on some additional computation (called a read barrier) for read operations. On modern architectures, it is generally agreed that the cost of a read barrier is prohibitive.
Reference: [DM82] <author> L. Damas and Robin Milner. </author> <title> Principal type schemes for functinoal programs. </title> <booktitle> In Proc. of the 9th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-212, </pages> <month> January </month> <year> 1982. </year>
Reference-contexts: Region polymorphism is implemented by passing the regions at runtime as extra parameters to the function. 2.3 Types Source language types are the standard ones of the Damas-Milner type system <ref> [DM82] </ref>, as specified by the following grammar: t ::= ff j int j t ! t The target language has a somewhat richer type language, which describes an expression's use of regions, as well as the type of its value. <p> However, we give the inference rules (Figure 3) and a high-level overview. The inference rules are a refinement of the ML type inference rules <ref> [DM82] </ref>. They derive translations of the following form: T E ` e ) e 0 : ; ' This sentence states that, in type environment T E, source language expression e translates into target language expression e 0 , which has type and place , and effect '.
Reference: [DTM94] <author> Amer Diwan, David Tarditi, and Eliot Moss. </author> <title> Memory subsystem performance of programs using copying garbage collection. </title> <booktitle> In Proc. of the 21st Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 1-14, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Modern generational garbage collectors [App90] exhibit good overall performance, often with an overhead of under 40% (including the overhead of maintaing garbage collector invariants, and reasonable cache performance <ref> [DTM94] </ref>. However, it retains many of the problems mentioned above: pauses, memory consumption, and interoperability. 49 There are a number of techniques for reducing or eliminating the garbage collection pauses, including the incremental mark--sweep collector of Dijkstra et al [DLM + 78] and the incremental copying collector of Baker [Bak78].
Reference: [Fra91] <author> P. Fradet. </author> <title> Syntactic detection of single-threading using continuations. </title> <booktitle> In Functional Programming Languages and Computer Architecture, 5th ACM Conference (LNCS 523), </booktitle> <pages> pages 241-258, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: The purpose of storage mode analysis is to determine when the store can be replaced with the atbot annotation, and when it must remain attop. To do so, it uses a rather standard backwards flow algorithm, similar to globalization and single-threadedness analyses <ref> [Ses92, Fra91, Sch85] </ref>. A further goal of storage mode analysis is to allow region polymorphic functions to also be polymorphic in storage mode.
Reference: [FY69] <author> Robert R. Fenichel and Jerome C. Yochelson. </author> <title> A LISP garbage-collector for virtual-memory computer systems. </title> <journal> Communications of the ACM, </journal> <volume> 12(11) </volume> <pages> 611-612, </pages> <month> November </month> <year> 1969. </year>
Reference-contexts: These problems have also been addressed by trying to improve garbage collection. The problem of a large heap requirement is a consequence of stop and copy collectors <ref> [FY69] </ref>. In their simplest form, these collectors work by allocating all new storage in a contiguous space, i.e. by incrementing an allocation pointer. When the space is exhausted, all the live (i.e. reachable from the roots) data is copied into another space.
Reference: [Gir87] <author> J.-Y. Girard. </author> <title> Linear logic. </title> <journal> Theoretical Computer Science, </journal> <volume> 50 </volume> <pages> 1-102, </pages> <year> 1987. </year>
Reference-contexts: All other cells are subject to garbage collection. Another promising avenue is linear logic <ref> [Gir87] </ref>. Expressions with linear types are guaranteed to have only one reference to each value. If it is possible to infer that a function is linear, then other optimizations may be possible. Lafont proposed interaction nets [Laf90] as language design based on linear logic.
Reference: [Hed88] <author> Lucy Hederman. </author> <title> Compile time garbage collection using reference count analysis. </title> <type> Master's thesis, </type> <institution> Rice University, Department of Computer Science, </institution> <year> 1988. </year>
Reference-contexts: One example of this analysis is the reference count analysis of Hudak [Hud86], implemented in the Russel compiler by Hederman <ref> [Hed88] </ref>. In Hederman's implementation, the reference count analysis associates an abstract reference count with each program point and variable. When such a reference count passes from one to zero, the value bound to the variable may be deallocated.
Reference: [Hen92] <author> Fritz Henglein. </author> <title> Global tagging optimization by type inference. </title> <booktitle> In Proc. of the 1992 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 205-215, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: If c p = true the region state prior to the allocation point is U and afterwards A, i.e. allocation. If c p = false, then the state prior is equal to the state after, i.e. no allocation. This approach is similar in spirit to the coercions of <ref> [Hen92] </ref>.
Reference: [Hen93] <author> Fritz Henglein. </author> <title> Type inference with polymorphic recursion. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(2), </volume> <month> April </month> <year> 1993. </year>
Reference-contexts: Allowing arbitrary constraints to appear in types would defeat this. As it is, the type language is expressive enough that the necessary constraints can be specified, and simple enough that type equality can be tested efficiently. If the language included recursive generic polymorphism, typing would be undecidable <ref> [Hen93] </ref>. Thus, in an expression of the form letrec f (x) = e 1 in e 2 , the type variables in the type of f are quantified only within e 2 , not in e 1 .
Reference: [HJ90] <author> Geoff W. Hamilton and Simon B. Jones. </author> <title> Compile-time garbage collection by necessity analysis. </title> <booktitle> In Proc. of the 1990 Glasgow Workshop on Functional Programming, </booktitle> <pages> pages 66-70, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Our results do not resolve this question, but we do show that static memory management can be significantly better than previously demonstrated. Much previous work has focussed on reducing, rather than eliminating, garbage collection <ref> [HJ90, Deu90] </ref>. The primary motivation for static memory management put forth in [TT94] is to reduce the amount of memory required to run general functional programs efficiently. Two other applications interest us. First, the pauses in execution caused by garbage collection pose a difficulty for programs with real-time constraints. <p> The result of this optimization is to reduce the frequency of garbage collections. Garbage collection itself, with its attendant problems, is still required. There are a number of other analyses that have the same goal, to identify some of the values which are no longer live, including sharing analysis <ref> [HJ90] </ref>, which determines that some storage cells are not shared, so that when the last reference to the cell disappears it can be immediately reclaimed. All other cells are subject to garbage collection. Another promising avenue is linear logic [Gir87].
Reference: [Hud86] <author> Paul Hudak. </author> <title> A sematic model of reference counting and its abstraction. </title> <booktitle> In ACM Symposium on LISP and Functional Languages, </booktitle> <pages> pages 351-363, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: However, if the explicit deallocation is paired with a subsequent allocation (of a compatible number of bytes), the two operations can be merged into a reuse, avoiding the overhead of both the deallocation and the allocation. One example of this analysis is the reference count analysis of Hudak <ref> [Hud86] </ref>, implemented in the Russel compiler by Hederman [Hed88]. In Hederman's implementation, the reference count analysis associates an abstract reference count with each program point and variable. When such a reference count passes from one to zero, the value bound to the variable may be deallocated.
Reference: [Laf90] <author> Yves Lafont. </author> <title> Interaction nets. </title> <booktitle> In Proc. of the 17th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 95-108, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Another promising avenue is linear logic [Gir87]. Expressions with linear types are guaranteed to have only one reference to each value. If it is possible to infer that a function is linear, then other optimizations may be possible. Lafont proposed interaction nets <ref> [Laf90] </ref> as language design based on linear logic. Lafont claims that interaction nets can be implemented without garbage collection. Ruggieri and Murtagh [RM88] proposed an analysis with the aim of eliminating garbage collection altogether.
Reference: [LH83] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Communications of the ACM, </journal> <volume> 26(6) </volume> <pages> 419-429, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: However, if the memory were exactly twice the size of the reachable data, then garbage collection would be required for every allocation. Garbage overhead decreases with as the ratio increases. A typical value for the ratio is five. Generational garbage collection <ref> [LH83] </ref> significantly reduces the average time per garbage collection, but does not change the fundamental time/space tradeoff. The key idea of generational garbage collection is to separate objects by their lifetime; short-lived objects are treated separately from long-lived ones.
Reference: [MTH90] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: We present the example informally; the formal presentation begins in Section 2. Consider the following simple program, taken from [TT94]: (let x = (2,3) in y:(fst x; y) end) 5 The source language is a conventional typed, call-by-value lambda calculus; it is essentially the applicative subset of ML <ref> [MTH90] </ref>. The annotated program produced by the Tofte/Talpin system is: Example 1.1 letregion 4 ; 5 in letregion 6 in let x = (2@ 2 ,3@ 6 )@ 4 in end end There are two kinds of annotations: letregion in e binds a new region to the region variable . <p> [[alloc before e 1 ]] R by 287,268 (290) s 1 ; r sat R; S out (291) s 1 ; r sat R; S out 272,Lemma 6.10 The result for [ALLOC BEFORE] follows from 289 and 291. 7 Implementation and Experiments We have implemented our algorithm in Standard ML <ref> [MTH90] </ref>. Our system is built on top of an implementation of the system described in [TT93, TT94], generously provided to us by Mads Tofte. The implementation is extended with numbers, pairs, lists, and conditionals, so that non-trivial programs can be tested.
Reference: [NO93] <author> Scott Nettles and James O'Toole. </author> <title> Real-time replication garbage collection. </title> <booktitle> In Proc. SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 217-226, </pages> <month> June </month> <year> 1993. </year> <month> 51 </month>
Reference-contexts: Two other applications interest us. First, the pauses in execution caused by garbage collection pose a difficulty for programs with real-time constraints. While there has been substantial work on real-time garbage collection <ref> [DLM + 78, NO93] </ref>, we find the simpler model of having no garbage collector at all appealing and worth investigation. Second, most programs written today are not written in garbage-collected applicative languages, but rather in procedural languages with programmer-specified memory management. <p> Another approach to avoiding pauses is for the program to maintain a log of changes to memory, which is consumed by a collector thread (i.e. process sharing the same address space) <ref> [NO93] </ref>. This approach reduces the pauses, but does not eliminate them altogether. Also, the technique does not address the problems of memory usage or interoperability. Conservative garbage collection [BW88] does address the interoperability issue.
Reference: [PS92] <author> Jens Palsberg and Michael I. Schwartzbach. </author> <title> Safety analysis versus type inference. </title> <journal> Information Processing Letters, </journal> <volume> 43(4) </volume> <pages> 175-180, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Thus, an abstract region environment preserves the region aliasing structure of the underlying region environment. The region-based closure analysis is given in Figure 5. Following <ref> [PS92] </ref>, the analysis is presented as a system of constraints; any solution of the constraints is sound. We assume that program variables are renamed as necessary so that each variable is identified with a unique binding.
Reference: [RM88] <author> Cristina Ruggieri and Thomas P. Murtagh. </author> <title> Lifetime analysis of dynamically allocated objects. </title> <booktitle> In Proc. of the 15th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 285-293, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: In their scheme, runtime memory is partitioned into regions. Every computed value is stored in some region. Regions themselves are allocated and deallocated according to a stack discipline akin to the standard implementation of activation records in procedural languages and similar to that of <ref> [RM88] </ref>. The assignment of values to regions is decided statically by the compiler and the program is annotated to include operations for managing regions. Thus, there is no need for a garbage collectorall memory allocation and deallocation is statically specified in the program. <p> Thus, we cannot implement the stack of regions using a traditional stack. Rather, the implementation technique is similar to the stack of subheaps scheme of Ruggieri and Murtagh <ref> [RM88] </ref>. <p> If it is possible to infer that a function is linear, then other optimizations may be possible. Lafont proposed interaction nets [Laf90] as language design based on linear logic. Lafont claims that interaction nets can be implemented without garbage collection. Ruggieri and Murtagh <ref> [RM88] </ref> proposed an analysis with the aim of eliminating garbage collection altogether. In their analysis, all heap-allocated data is divided into a stack of sub-heaps, one for each procedure activation record. When the procedure exits, all of the data in the associated activation record is deallocated.
Reference: [Sch85] <author> D.A. Schmidt. </author> <title> Detecting global variables in denotational specifications. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(2) </volume> <pages> 299-310, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: The purpose of storage mode analysis is to determine when the store can be replaced with the atbot annotation, and when it must remain attop. To do so, it uses a rather standard backwards flow algorithm, similar to globalization and single-threadedness analyses <ref> [Ses92, Fra91, Sch85] </ref>. A further goal of storage mode analysis is to allow region polymorphic functions to also be polymorphic in storage mode.
Reference: [Ses92] <author> Peter Sestoft. </author> <title> Analysis and Efficient Implementation of Functional Programs. </title> <type> PhD dissertation, </type> <institution> University of Copenhagen, Department of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: A well-known solution to this problem is closure analysis <ref> [Ses92] </ref>, which gives a useful approximation to the set of possible closures at every application. Our algorithm consists of two phases. We begin with the Tofte/Talpin annotation of a program (Section 2), ultimately producing a completed program with explicit allocation and deallocation operations (Section 3). <p> The purpose of storage mode analysis is to determine when the store can be replaced with the atbot annotation, and when it must remain attop. To do so, it uses a rather standard backwards flow algorithm, similar to globalization and single-threadedness analyses <ref> [Ses92, Fra91, Sch85] </ref>. A further goal of storage mode analysis is to allow region polymorphic functions to also be polymorphic in storage mode. <p> Closure analysis, an application of abstract interpretation [CC77], approximates execution order in higher-order programs <ref> [Shi88, Ses92] </ref>. However, closure analysis alone is not sufficient for our purposes, because of problems with state polymorphism and region aliasing (see below). Imprecision in state polymorphism gives poor completions, but failure to detect aliasing may result in unsound completions. Consider again the program in Example 2.1.
Reference: [Shi88] <author> Olin Shivers. </author> <title> Control flow analysis in Scheme. </title> <booktitle> In Proc. SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 164-174, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Closure analysis, an application of abstract interpretation [CC77], approximates execution order in higher-order programs <ref> [Shi88, Ses92] </ref>. However, closure analysis alone is not sufficient for our purposes, because of problems with state polymorphism and region aliasing (see below). Imprecision in state polymorphism gives poor completions, but failure to detect aliasing may result in unsound completions. Consider again the program in Example 2.1.
Reference: [TJ92] <author> Jean-Pierre Talpin and Pierre Jouvelot. </author> <title> Polymorphic type, region, and effect inference. </title> <journal> Journal of Functional Programming, </journal> <volume> 2(3), </volume> <year> 1992. </year>
Reference-contexts: In fact, some previous work on effect systems used explicit systems of constraints <ref> [TJ92] </ref>. However, explicit constraints were not used in the Tofte/Talpin system because of a problem in conjunction with recursion. The letrec region inference rule expresses the recursion by matching the type assumptions for f (ocurring in the body) with the derived type for f .
Reference: [Tof90] <author> Mads Tofte. </author> <title> Type inference for polymorphic references. </title> <journal> Information and Computation, </journal> <volume> 89(1), </volume> <month> November </month> <year> 1990. </year>
Reference: [Tof94] <author> Mads Tofte. </author> <title> Storage mode analysis. </title> <type> Personal communication, </type> <month> October </month> <year> 1994. </year>
Reference-contexts: There is no published account of storage mode analysis. Our knowledge of it is based on the prototype implementation provided to us by Mads Tofte, as well as a personal communication <ref> [Tof94] </ref>. <p> The implementation is roughly 5,500 lines plus the roughly 8,500 lines of code in the Tofte/Taplin base implementation. Our annotations are orthogonal to the storage mode analysis mentioned in [TT94] and described in more detail in <ref> [Tof94] </ref> and in Section 2.6. Thus, the target programs contain both storage mode annotations and the allocation annotations described in this paper. On the other hand, our analysis subsumes the optimization described in Appendix B of [TT94], so that optimization is disabled in our system.
Reference: [TT93] <author> Mads Tofte and Jean-Pierre Talpin. </author> <title> A theory of stack allocation in polymorphically typed languages. </title> <type> Technical Report 93/15, </type> <institution> Department of Computer Science, University of Copenhagen, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: Our proof does not attempt to make the reuse of regions formally safe. The proof requires letregion constructs to use fresh regions. This is arguably a weakness with respect to the Tofte/Talpin system, where the reuse of regions is provably safe <ref> [TT93] </ref>. However, we prove that once a region is deallocated, no more reads or writes to the memory held by that region are made. 6.3 Relations between abstract and concrete entities The following paragraphs define relations between abstract and concrete entities that are used throughout the proof. <p> Our system is built on top of an implementation of the system described in <ref> [TT93, TT94] </ref>, generously provided to us by Mads Tofte. The implementation is extended with numbers, pairs, lists, and conditionals, so that non-trivial programs can be tested. For each source program, we first use the Tofte/Talpin system to region annotate the program. We then compute the extended closure analysis (Section 4).
Reference: [TT94] <author> Mads Tofte and Jean-Pierre Talpin. </author> <title> Implementation of the typed call-by-value -calculus using a stack of regions. </title> <booktitle> In Proc. of the 21st Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 188-201, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: 1 Introduction In a recent paper, Tofte and Talpin propose a novel method for memory management in typed, higher-order languages <ref> [TT94] </ref>. In their scheme, runtime memory is partitioned into regions. Every computed value is stored in some region. Regions themselves are allocated and deallocated according to a stack discipline akin to the standard implementation of activation records in procedural languages and similar to that of [RM88]. <p> The assignment of values to regions is decided statically by the compiler and the program is annotated to include operations for managing regions. Thus, there is no need for a garbage collectorall memory allocation and deallocation is statically specified in the program. The system in <ref> [TT94] </ref> makes surprisingly economical use of memory. However, it is usually possible to do significantly better and in some cases dramatically better than the Tofte/Talpin algorithm. <p> Our results do not resolve this question, but we do show that static memory management can be significantly better than previously demonstrated. Much previous work has focussed on reducing, rather than eliminating, garbage collection [HJ90, Deu90]. The primary motivation for static memory management put forth in <ref> [TT94] </ref> is to reduce the amount of memory required to run general functional programs efficiently. Two other applications interest us. First, the pauses in execution caused by garbage collection pose a difficulty for programs with real-time constraints. <p> Our approach to static memory management is best illustrated with an example. We present the example informally; the formal presentation begins in Section 2. Consider the following simple program, taken from <ref> [TT94] </ref>: (let x = (2,3) in y:(fst x; y) end) 5 The source language is a conventional typed, call-by-value lambda calculus; it is essentially the applicative subset of ML [MTH90]. <p> The URL is: http://kiwi.cs.berkeley.edu/nogc 2 Background on the Tofte/Talpin System Our approach makes use of Tofte and Talpin's region and effect inference algorithm. This section describes the Tofte/Talpin region inference system in more detail. For a full description, please refer to <ref> [TT94] </ref>. This section is intended as an informal overview to aid in understanding our extensions. We use the term full system to refer to the composition of the Tofte/Talpin system as described in [TT94] and our extensions. <p> For a full description, please refer to <ref> [TT94] </ref>. This section is intended as an informal overview to aid in understanding our extensions. We use the term full system to refer to the composition of the Tofte/Talpin system as described in [TT94] and our extensions. <p> The effect of evaluating an expression is the set of regions accessed (i.e. read or written) as a result of that evaluation. The arrow efffect of a function is the effect of applying that function. In <ref> [TT94] </ref>, there is a further distinction between get and put effects, but that distinction is not needed here. The * names the effect, and is useful for two purposes. <p> Given a compound type scheme = 8 1 ; : : : ; k ; ff 1 ; : : : ; ff n ; * 1 ; : : : ; * m :t and type t 0 , we use the notation of <ref> [TT94] </ref> to denote instantiation: t 0 (via S) means that t 0 is an instance of , if there exists a substitution S such that S (t ) = t 0 . Instantiation in the case where is a simple type scheme is defined similarly. <p> (' n ' 0 ) T E ` e ) letregion 1 ; : : : ; k in e 0 : ; ' 0 [LETREGION] 2.4 The region inference algorithm A full description of the region inference algorithm is beyond the scope of this report (for more details, see <ref> [TT94] </ref>). However, we give the inference rules (Figure 3) and a high-level overview. The inference rules are a refinement of the ML type inference rules [DM82]. <p> The letrec region inference rule expresses the recursion by matching the type assumptions for f (ocurring in the body) with the derived type for f . In the implementation of the region inference rules <ref> [TT94] </ref>, this matching is accomplished by iterating until a fixpoint is reached. Such an implementation requires that testing equality of types can be done efficiently. Allowing arbitrary constraints to appear in types would defeat this. <p> However, typing is still decidable in the presence of recursive region polymorphism, so region variables in the type of f are quantified within both e 1 and e 2 . The introduction of recursive region polymorphism is one of the main technical advances of <ref> [TT94] </ref> and is essential for the quality of the results. Here is an example of the translation. The source program, given below, simply counts down to zero in tail-recursive fashion. To make the example interesting, we use constructs outside the minimal language presented above. <p> Most importantly, the notion of store is explicit. The representation of recursion is changed accordingly; instead of a special closure form for recursive functions, a standard closure is used, but with a cycle in the store. The operational semantics of Figure 4 are quite similar to those given in <ref> [TT94] </ref>, for which it was proved that the translation specified by the region inference rules is sound. The semantics given in Figure 4 do differ somewhat from the Tofte/Talpin system, in that unallocated and deallocated states for regions, and extra allocation and deallocation expressions have been added. <p> The first construct (letregion) behaves exactly as described in Section 2, where the new region is initially unallocated and is deallo-cated at the end. The second construct letregion tt has the same semantics as in <ref> [TT94] </ref>, i.e. a region is initially allocated but empty, and still allocated at the end. There are no free/alloc constructs for such regions. The reason for the second construct is the finite nature of our color abstraction. <p> Our system is built on top of an implementation of the system described in <ref> [TT93, TT94] </ref>, generously provided to us by Mads Tofte. The implementation is extended with numbers, pairs, lists, and conditionals, so that non-trivial programs can be tested. For each source program, we first use the Tofte/Talpin system to region annotate the program. We then compute the extended closure analysis (Section 4). <p> The implementation is roughly 5,500 lines plus the roughly 8,500 lines of code in the Tofte/Taplin base implementation. Our annotations are orthogonal to the storage mode analysis mentioned in <ref> [TT94] </ref> and described in more detail in [Tof94] and in Section 2.6. Thus, the target programs contain both storage mode annotations and the allocation annotations described in this paper. On the other hand, our analysis subsumes the optimization described in Appendix B of [TT94], so that optimization is disabled in our <p> to the storage mode analysis mentioned in <ref> [TT94] </ref> and described in more detail in [Tof94] and in Section 2.6. Thus, the target programs contain both storage mode annotations and the allocation annotations described in this paper. On the other hand, our analysis subsumes the optimization described in Appendix B of [TT94], so that optimization is disabled in our system. Summary performance measures are in Table 2. All of the examples we have tried are analyzed in a matter of seconds by our system on a standard workstation. <p> The Quicksort graph (Figure 11) has a curious feature: at times the memory usage drops below the amount needed to store the list! Our measurements count only heap memory usage. The evaluation stack is not counted, a measurement methodology consistent with <ref> [TT94] </ref>. Quicksort is not unusual in the behavior of using the evaluation stack to store values that would seem to belong in the heap. <p> This runtime layout differs from a traditional stack in that allocations can be performed in any of the sub-heaps, not just the one at the top of the stack. The most closely related work to ours is of course the Tofte/Talpin region inference <ref> [TT94] </ref>, which is described in detail in Section 2. 9 Discussion and Conclusions It remains an open question whether our system is a practical approach to memory management. The complexity of the region-based closure analysis is worst-case exponential time.
References-found: 31

