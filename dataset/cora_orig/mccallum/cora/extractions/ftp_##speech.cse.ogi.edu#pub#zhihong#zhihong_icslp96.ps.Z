URL: ftp://speech.cse.ogi.edu/pub/zhihong/zhihong_icslp96.ps.Z
Refering-URL: http://cslu.cse.ogi.edu/people/hu/index.html
Root-URL: http://www.cse.ogi.edu
Email: (zhihong,johans,barnard,cole)@cse.ogi.edu  
Title: Speech Recognition Using Syllable-Like Units  
Author: Zhihong Hu, Johan Schalkwyk, Etienne Barnard, Ronald Cole 
Affiliation: Oregon Graduate Institute of Science and Technology  
Note: Center for Spoken Language Understanding,  
Abstract: It is well known that speech is dynamic and that frame-based systems lack the ability to realistically model the dynamics of speech. Segment-based systems offer the potential to integrate the dynamics of speech, at least within the phoneme boundaries, although it is difficult to obtain accurate phonemic segmentation in fluent speech. In this paper we propose a new approach which uses syllable-like units in recognition. In the proposed approach, syllable-like units are defined by rules and used as the basic units of recognition. The motivation for using syllable-like units is (1) by modeling perceptually more meaningful units, better modeling of speech can be achieved; and (2) this method provides a better framework for incorporating dynamic modeling techniques into the recognition system. The proposed approach has achieved the same recognition performance on the task of recognizing months of the year as compared to the best frame-based recognizer available. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Cole, B. Oshika, M. Noel, T. Lander, and M. Fanty, </author> <title> "Labeler agreement in phonetic labeling of continuous speech," </title> <booktitle> in International Conference on Spoken Language Processing, </booktitle> <pages> pp. 2131-2134, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: However, it is well known that speech is non stationary. In fluent speech phoneme segmentation is not easy as is shown (for example) in the process of labeling fluent speech, some of the segment boundaries are arbitrary and must be defined by convention <ref> [1] </ref>. Phoneme-based recognition has been attempted using both frame-based and segment-based approaches. Frame-based systems are currently more popular since they do not require explicit detection of segment boundaries and thus give better classification performance. However, they suffer from severe modeling limitations.
Reference: 2. <author> O. Ghitza and M. Sondhi, </author> <title> "Hidden markov models with templates as non-stationary states: an application to speech recognition," </title> <booktitle> Computer Speech and Language, </booktitle> <volume> vol. 2, </volume> <pages> pp. 101-119, </pages> <year> 1993. </year>
Reference-contexts: Although segment-based systems have the ability to integrate the dynamics of speech, this is mostly constrained within the phoneme boundaries. Given the difficulty of obtaining accurate phonemic segmentation, especially in fluent speech, this is particularly restrictive. Various attempts have been tried to overcome the limitations of frame-based systems <ref> [2, 3] </ref>. However, these attempts are still constrained by the phoneme-based paradigm, therefore leaving the fundamental problems unsolved. Recent research in segment based systems [4, 5] shows how to model both the dynamics within the segment boundary as well as the transitional part between segment boundaries.
Reference: 3. <author> Z. Hu, E. Barnard, and R. Cole, </author> <title> "Transition-based feature extraction within frame-based recognition," </title> <booktitle> in Eu-rospeech, </booktitle> <pages> pp. 1555-1558, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Although segment-based systems have the ability to integrate the dynamics of speech, this is mostly constrained within the phoneme boundaries. Given the difficulty of obtaining accurate phonemic segmentation, especially in fluent speech, this is particularly restrictive. Various attempts have been tried to overcome the limitations of frame-based systems <ref> [2, 3] </ref>. However, these attempts are still constrained by the phoneme-based paradigm, therefore leaving the fundamental problems unsolved. Recent research in segment based systems [4, 5] shows how to model both the dynamics within the segment boundary as well as the transitional part between segment boundaries.
Reference: 4. <author> W. Goldenthal, </author> <title> Statistical Trajectory Models for Phonetic Recognition. </title> <type> PhD thesis, </type> <institution> M.I.T., </institution> <month> Auguest </month> <year> 1994. </year>
Reference-contexts: Various attempts have been tried to overcome the limitations of frame-based systems [2, 3]. However, these attempts are still constrained by the phoneme-based paradigm, therefore leaving the fundamental problems unsolved. Recent research in segment based systems <ref> [4, 5] </ref> shows how to model both the dynamics within the segment boundary as well as the transitional part between segment boundaries. Various trajectory models are used, which proved to be very useful at modeling dynamics in speech. <p> However, these approaches either need accurate segmentation, which is difficult to achieve, or assume every single frame as a possible boundary, followed by an expensive exhaustive search method applied to a lattice constructed using all the possible boundaries <ref> [4] </ref>. In order to take advantage of the modeling ability of the trajectory models and not be constrained by the segmentation accuracy, we propose a new recognition strategy which uses syllable-like units as the basic unit for recognition. <p> Also, since the segmentation algorithm in general over-generates segments, almost all the boundaries between units defined in this approach will be detected. Using this segmentation algorithm, insertions of boundaries will therefore occur. Statistical trajectory models as described in <ref> [4] </ref> are computed for each of the units defined. Artificial neural networks or Gaussian mixture models are then trained to estimate probabilities for the units defined. The search is implemented using the Viterbi algorithm in a time-asynchronous manner. <p> For each unit, the trajectory model consists of 10 states. 2 1 For more information on the census database contact noel@cse.ogi.edu. 2 In Goldenthal's thesis <ref> [4] </ref>, he found that 10 states is good enough to model a segment. Our experiments also show that The feature space consists of 8 PLP coefficients for each state plus log duration of the unit. Therefore the total dimension of the feature vector is 81.
Reference: 5. <author> M. Ostendorf and S. Roukos, </author> <title> "A stochastic segment model for phoneme-based continuous speech recognition," </title> <journal> IEEE Transaction on Accoustics, Speech, and Signal Processing., </journal> <volume> vol. 37, no. 12, </volume> <pages> pp. 1857-1869, </pages> <year> 1989. </year>
Reference-contexts: Various attempts have been tried to overcome the limitations of frame-based systems [2, 3]. However, these attempts are still constrained by the phoneme-based paradigm, therefore leaving the fundamental problems unsolved. Recent research in segment based systems <ref> [4, 5] </ref> shows how to model both the dynamics within the segment boundary as well as the transitional part between segment boundaries. Various trajectory models are used, which proved to be very useful at modeling dynamics in speech.
Reference: 6. <author> R.A.Cole, D.G.Novick, M.Fanty, P.Vermeulen, S.Suttong, D.Burnett, and J.Schalkwyk, </author> <title> "A prototype voice ques-tionary for the US census," </title> <booktitle> in International Conference on Spoken Language Processing, </booktitle> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: The connected path indicates the highest scoring path for the word May, pronounced (m ei). 3. Experiments and results We tested our approach using a database consisting of the twelve months of the year. This database is a subset of the Census data collected at OGI <ref> [6] </ref>. 1 The database consists of a total of 814 transcribed files for the training set, and 796 transcribed files for the development test set. This results in an average of 67 repetitions per word in the vocabulary.
References-found: 6

