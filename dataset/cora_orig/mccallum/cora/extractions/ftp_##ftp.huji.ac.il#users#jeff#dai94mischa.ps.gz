URL: ftp://ftp.huji.ac.il/users/jeff/dai94mischa.ps.gz
Refering-URL: http://www.cs.huji.ac.il/labs/dai/papers.html
Root-URL: 
Email: mischa@cs.huji.ac.il, jeff@cs.huji.ac.il  
Title: Long Term Constraints in Multiagent Negotiation  
Author: Michael Palatnik Jeffrey S. Rosenschein 
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Computer Science Department Hebrew University  
Abstract: We consider negotiation over resources among self-motivated agents. Negotiation occurs over time: there are time constraints that affect how each agent values the resource. The agents also consider the possibility that they will encounter each other in future negotiations. We cope with agents having incomplete information, emphasizing probability management techniques. Questions arising in this research are: 1. When is it worth it for an agent to lie? 2. How beneficial can such lies be? 3. Is the system with a lying agent robust? 4. How can lies be discouraged? The main contributions of this work are our ability to deal with multiple encounters among agents, and our treatment of the problem that enables elementary mutual learning.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. E. Conry, R. A. Meyer, and V. R. Lesser. </author> <title> Multistage negotiation in distributed planning. </title> <editor> In Alan H. Bond and Les Gasser, editors, </editor> <booktitle> Readings in Distributed Artificial Intelligence, </booktitle> <pages> pages 367-384. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: The Task Distribution Problem is the problem of allocating particular tasks (labor portions) to particular agents, such as through market mechanisms. The classical model using this approach is the Contract Net system [2]. Similar problems were examined by Durfee and Lesser [3], by Conry <ref> [1] </ref>, and by Ephrati and Rosenschein [4, 6, 5] (who used voting techniques). Sathi and Fox [12] used a market-like mechanism, where the agents negotiated buying and selling the resources until a compromise is reached. 2 Initial Setting Our initial assumptions closely follow [9]. 1. <p> First we introduce global time, advancing in discrete time moments t 2 T , where T = f0; 1; 2; : : :g. Assumption 8. Utility value over time Utility value decreases over time with a constant discount rate ffi, ffi 2 <ref> [0; 1] </ref>. U (t 0 + t ) = ffi t U (t 0 ): Here U (t 0 ) 2 is the utility of an event which occurs at the current moment. <p> Let's investigate the difference to agent W 's Utility in the case where it tells the truth (i.e., as proposed in [9]) and in the case where it lies. We'd like to know two conditions: <ref> [1] </ref> the utility difference is positive (weak), [2] the utility is maximal (strong). Let's consider the simplified case where there are no other interactions in the system. That is, the only encounters are between W i and A j .
Reference: [2] <author> R. Davis and R. G. Smith. </author> <title> Negotiation as a metaphor for distributed problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 20(1) </volume> <pages> 63-109, </pages> <year> 1983. </year>
Reference-contexts: The Task Distribution Problem is the problem of allocating particular tasks (labor portions) to particular agents, such as through market mechanisms. The classical model using this approach is the Contract Net system <ref> [2] </ref>. Similar problems were examined by Durfee and Lesser [3], by Conry [1], and by Ephrati and Rosenschein [4, 6, 5] (who used voting techniques). <p> Let's investigate the difference to agent W 's Utility in the case where it tells the truth (i.e., as proposed in [9]) and in the case where it lies. We'd like to know two conditions: [1] the utility difference is positive (weak), <ref> [2] </ref> the utility is maximal (strong). Let's consider the simplified case where there are no other interactions in the system. That is, the only encounters are between W i and A j .
Reference: [3] <author> E. H. Durfee and V. R. Lesser. </author> <title> Using partial global plans to coordinate distributed problem solvers. </title> <booktitle> Proceedings of IJCAI-87, </booktitle> <pages> pages 875-883, </pages> <year> 1987. </year>
Reference-contexts: The Task Distribution Problem is the problem of allocating particular tasks (labor portions) to particular agents, such as through market mechanisms. The classical model using this approach is the Contract Net system [2]. Similar problems were examined by Durfee and Lesser <ref> [3] </ref>, by Conry [1], and by Ephrati and Rosenschein [4, 6, 5] (who used voting techniques). Sathi and Fox [12] used a market-like mechanism, where the agents negotiated buying and selling the resources until a compromise is reached. 2 Initial Setting Our initial assumptions closely follow [9]. 1.
Reference: [4] <author> E. Ephrati and J. S. Rosenschein. </author> <title> Constrained intelligent action: Planning under the influence of a master agent. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 263-268, </pages> <address> San Jose, California, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The classical model using this approach is the Contract Net system [2]. Similar problems were examined by Durfee and Lesser [3], by Conry [1], and by Ephrati and Rosenschein <ref> [4, 6, 5] </ref> (who used voting techniques). Sathi and Fox [12] used a market-like mechanism, where the agents negotiated buying and selling the resources until a compromise is reached. 2 Initial Setting Our initial assumptions closely follow [9]. 1.
Reference: [5] <author> E. Ephrati and J. S. Rosenschein. </author> <title> Distributed consensus mechanisms for self-interested heterogeneous agents. </title> <booktitle> In First International Conference on Intelligent and Cooperative Information Systems, </booktitle> <pages> pages 71-79, </pages> <address> Rotterdam, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The classical model using this approach is the Contract Net system [2]. Similar problems were examined by Durfee and Lesser [3], by Conry [1], and by Ephrati and Rosenschein <ref> [4, 6, 5] </ref> (who used voting techniques). Sathi and Fox [12] used a market-like mechanism, where the agents negotiated buying and selling the resources until a compromise is reached. 2 Initial Setting Our initial assumptions closely follow [9]. 1.
Reference: [6] <author> E. Ephrati and J. S. Rosenschein. </author> <title> multi-agent planning as a dynamic search for social consensus. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 423-429, </pages> <address> Chambery, France, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: The classical model using this approach is the Contract Net system [2]. Similar problems were examined by Durfee and Lesser [3], by Conry [1], and by Ephrati and Rosenschein <ref> [4, 6, 5] </ref> (who used voting techniques). Sathi and Fox [12] used a market-like mechanism, where the agents negotiated buying and selling the resources until a compromise is reached. 2 Initial Setting Our initial assumptions closely follow [9]. 1.
Reference: [7] <author> S. Kraus and J. Wilkenfeld. </author> <title> The function of time in cooperative negotiations. </title> <booktitle> In Proc. of AAAI-91, </booktitle> <pages> pages 179-184, </pages> <address> California, </address> <year> 1991. </year>
Reference-contexts: When is it worth it for an agent to lie? 2. How beneficial can such lies be? 3. Is the system with a lying agent robust? 4. How can lies be discouraged? The work is an extension of the model of multi-agent negotiations under time constraints presented in <ref> [7, 8, 9] </ref>. The main contributions of the current work are our ability to deal with multiple encounters among agents, and our treatment of the problem that enables elementary mutual learning.
Reference: [8] <author> S. Kraus and J. Wilkenfeld. </author> <title> Negotiation over time in a multi-agent environment: Preliminary report. </title> <booktitle> In Proc. of IJCAI-91, </booktitle> <pages> pages 56-61, </pages> <address> Australia, </address> <year> 1991. </year>
Reference-contexts: When is it worth it for an agent to lie? 2. How beneficial can such lies be? 3. Is the system with a lying agent robust? 4. How can lies be discouraged? The work is an extension of the model of multi-agent negotiations under time constraints presented in <ref> [7, 8, 9] </ref>. The main contributions of the current work are our ability to deal with multiple encounters among agents, and our treatment of the problem that enables elementary mutual learning.
Reference: [9] <author> S. Kraus, J. Wilkenfeld, and G. Zlotkin. </author> <title> Multiagent negotiation under time constraints. </title> <type> Technical report, </type> <institution> University of Maryland, College Park, MD 20742, </institution> <year> 1992. </year>
Reference-contexts: When is it worth it for an agent to lie? 2. How beneficial can such lies be? 3. Is the system with a lying agent robust? 4. How can lies be discouraged? The work is an extension of the model of multi-agent negotiations under time constraints presented in <ref> [7, 8, 9] </ref>. The main contributions of the current work are our ability to deal with multiple encounters among agents, and our treatment of the problem that enables elementary mutual learning. <p> Sathi and Fox [12] used a market-like mechanism, where the agents negotiated buying and selling the resources until a compromise is reached. 2 Initial Setting Our initial assumptions closely follow <ref> [9] </ref>. 1. Bilateral Negotiation | In each given period of time no more than two agents need the same resource. Whenever there is an overlap between the time segments in which two agents need the same resource, these agents will be involved in a negotiation process. 2. <p> Estimation of the Interaction Time Agent W knows the upper bound Sup (t ) of the time interval between two successive interactions. Let's investigate the difference to agent W 's Utility in the case where it tells the truth (i.e., as proposed in <ref> [9] </ref>) and in the case where it lies. We'd like to know two conditions: [1] the utility difference is positive (weak), [2] the utility is maximal (strong). Let's consider the simplified case where there are no other interactions in the system. <p> Let's consider the simplified case where there are no other interactions in the system. That is, the only encounters are between W i and A j . Following the results of <ref> [9] </ref> | Theorem 3 | we consider each interaction to consist of four phases. First, W makes its "ritual" offer | A rejects | A in turn offers a deal | W either opts out or accepts it. <p> As was proved by Kraus et al. (Theorem 3 in <ref> [9] </ref>), each interaction follows the same course. Agent W makes an offer, A rejects and makes its counter offer, then at the final stage W either accepts A's offer or opts out. <p> After the backtracking procedure, we open a new "sub-history" which is consistent with all of the previous history, except the "candidate-for-liars" opting outs. 11 5 The Optimal Offer Going back to Theorem 3 of <ref> [9] </ref>, we notice that A makes the choice of the deal, offered to the given opponent by maximization of its expected utility. It makes a lot of sense considering the local short-term view, but appears to be not always justified with regard to multiple encounters.
Reference: [10] <author> M. J. Osborne and A. Rubinstein. </author> <title> Bargaining and Markets. </title> <publisher> Academic Press Inc., </publisher> <address> San Diego, California, </address> <year> 1990. </year>
Reference-contexts: For the detailed analysis see <ref> [10] </ref>. Two agents will negotiate in order to divide M (M 2 IN ) units of a common resource. We assume that the negotiation moves are performed at the discrete time moments t 2 T , where T = f0; 1; 2; :::g.
Reference: [11] <author> Michael Palatnik. </author> <title> Long term constraints in multiagent negotiation. </title> <type> Master's thesis, </type> <institution> Hebrew University, </institution> <year> 1993. </year>
Reference-contexts: The matrix of belief, maintained as described, is consistent in the above defined sense. Lemma 1 The Matrix of Belief 's Consistency If the matrix of belief is maintained as described above it is consistent unless a conflict occurs. Proof : The proof can be found in <ref> [11] </ref>. We have already mentioned that in the case of a square matrix (N = k; 8jN j = 1) the initial number of hypotheses is jH init j = N !.
Reference: [12] <author> A. Sathi and M. Fox. </author> <title> Constraint-directed negotiation of resource reallocations. </title> <editor> In L. Gasser and M. Huhns, editors, </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <volume> volume 2, chapter 8, </volume> <pages> pages 163-193. </pages> <publisher> Pitman, </publisher> <address> London, </address> <year> 1989. </year> <month> 15 </month>
Reference-contexts: The classical model using this approach is the Contract Net system [2]. Similar problems were examined by Durfee and Lesser [3], by Conry [1], and by Ephrati and Rosenschein [4, 6, 5] (who used voting techniques). Sathi and Fox <ref> [12] </ref> used a market-like mechanism, where the agents negotiated buying and selling the resources until a compromise is reached. 2 Initial Setting Our initial assumptions closely follow [9]. 1. Bilateral Negotiation | In each given period of time no more than two agents need the same resource.
References-found: 12

