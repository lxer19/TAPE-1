URL: file://ftp.cs.ucsd.edu/pub/baden/tr/cluster.ps.gz
Refering-URL: http://www.cs.ucsd.edu/groups/hpcl/scg/tr.html
Root-URL: http://www.cs.ucsd.edu
Title: Parallel Cluster Identification for Multidimensional Lattices  
Author: Stephen J. Fink Craig Huston Scott B. Baden Karl Jansen 
Keyword: Index terms: cluster identification, Ising model, connected component labeling, parallel algorithm, Swendson-Wang dynamics  
Abstract: The cluster identification problem is a variant of connected component labeling that arises in cluster algorithms for spin models in statistical physics. We present a multidimensional version of Belkhale and Banerjee's Quad algorithm for connected component labeling on distributed memory parallel computers. Our extension abstracts away extraneous spatial connectivity information in more than two dimensions, simplifying implementation for higher dimensionality. We identify two types of locality present in cluster configurations, and present optimizations to exploit locality for better performance. Performance results from 2D, 3D, and 4D Ising model simulations with Swendson-Wang dynamics show that the optimizations improve performance by 20-80%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. P. Belkhale and P. Banerjee, </author> <title> "Parallel algorithms for geometric connected component labeling on a hypercube multiprocessor," </title> <journal> IEEE Transactions On Computers, </journal> <volume> vol. 41, </volume> <pages> pp. 699-709, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Furthermore, cluster configurations may be highly irregular, preventing a priori analysis of communication and computation patterns. Parallel algorithms for cluster identification must overcome these difficulties to achieve good performance. We have developed a multidimensional extension of Belkhale and Banerjee's Quad algorithm <ref> [1, 2] </ref>, a 2D connected component labeling algorithm developed for VLSI circuit extraction on a hypercube multiprocessor. This paper presents performance results from applying the algorithm to Ising model simulations with Swendson-Wang dynamics [3] in 2D, 3D, and 4D. <p> Hierarchical methods for connected component labeling are characterized by a spatial domain decomposition and propagation of global information in log P stages. Our approach is based on the hierarchical Quad algorithm for VLSI circuit extraction on a hypercube multiprocessor <ref> [1] </ref>. Other hierarchical methods for distributed memory computers have been used for image component labeling [12, 13]. Baillie and Coddington consider a MIMD hierarchical algorithm for the Ising model, but do not achieve good parallel efficiency [5]. Mino presents a hierarchical labeling algorithm for vector architectures [14]. <p> Thus the labeling step is not ideally matched to a distributed memory architecture, and requires an efficient parallel algorithm. 4 Cluster Identification Algorithm 4.1 2D Quad Algorithm Our cluster identification method is based on Belkhale and Banerjee's Quad algorithm for geometric connected component labeling <ref> [1] </ref>, which was developed to label connected sets 6 of rectangles that represent VLSI circuits in a plane. It is straightforward to apply the same algorithm to label clusters in a 2D lattice of spin values. <p> It is straightforward to apply the same algorithm to label clusters in a 2D lattice of spin values. A brief description of the Quad algorithm as applied to a 2D lattice of spins is presented here. For a more complete description of the Quad algorithm, see <ref> [1] </ref>. The cluster labeling algorithm consists of a local labeling phase and a global combining phase. First, the global 2D lattice is partitioned blockwise across the processor array. Each processor labels the clusters in its local partition of the plane with some sequential labeling algorithm. <p> + Bff (B)), where P is the number of processors, ff () is the inverse of Ackerman's function, t s is the message startup time, t b is the communication time per byte, and B is is the number of border rectangles along a cross section of the global domain <ref> [1] </ref>. The number of border rectangles in VLSI circuit extraction applications corresponds to the number of border bonds in cluster identification applications. For cluster identification on a 2D lattice, let N be the lattice size and p be the probability that there is a bond between two adjacent lattice points. <p> By the last stage, each processor must handle a cross-section of the entire global domain. With many processors and large problem sizes, this can degrade the algorithm's performance <ref> [1] </ref>. To mitigate this effect, we have developed optimizations that exploit properties of the cluster configuration for better performance. In Monte Carlo Ising model simulations, the cluster configuration structure depends heavily on the coupling constant . <p> Subcritical configurations exhibit Type 1 locality, and supercritical configurations exhibit Type 2 locality. Configurations at criticality show some aspects of both types. Belkhale and Banerjee exploit Type 1 locality in two dimensions with the Overlap Quad algorithm <ref> [1] </ref>. In this algorithm, information regions overlap and only clusters that span the overlap region must be merged. Intuitively, small clusters are eliminated in early stages of the algorithm, leaving only large clusters to merge in later stages.
Reference: [2] <author> S. J. Fink, S. B. Baden, and K. Jansen, </author> <title> "Cluster identification on a distributed memory multiprocessor," </title> <booktitle> in Proceedings of the 1994 Scalable High Performance Computing Conference, (Knoxville, Tenessee), </booktitle> <pages> pp. 239-246, </pages> <month> May </month> <year> 1994. </year> <month> 25 </month>
Reference-contexts: Furthermore, cluster configurations may be highly irregular, preventing a priori analysis of communication and computation patterns. Parallel algorithms for cluster identification must overcome these difficulties to achieve good performance. We have developed a multidimensional extension of Belkhale and Banerjee's Quad algorithm <ref> [1, 2] </ref>, a 2D connected component labeling algorithm developed for VLSI circuit extraction on a hypercube multiprocessor. This paper presents performance results from applying the algorithm to Ising model simulations with Swendson-Wang dynamics [3] in 2D, 3D, and 4D. <p> They conclude that the host-node approach is inappropriate for 3D due to increased memory requirements on the host node. Fink et al. present 2D and 3D results from a preliminary implementation of the multidimensional Quad algorithm <ref> [2] </ref>. This paper includes 4D results and introduces issues pertaining to a dimension-independent implementation. 3 Ising Model Many physical systems such as binary fluids, liquid and gas systems, and magnets exhibit phase transitions. In order to understand these "critical phenomena," simple effective models have been constructed in statistical mechanics. <p> Figure 3 illustrates this for 3D lattices. This concept was first applied by Fink et al. to the 3D Quad algorithm <ref> [2] </ref>, and a 10 border bonds in the same order on each processor. similar optimization was applied to 3D lattices by Bauernfeind et al.[15]. We define an order on the border bonds by considering each (d 1)-dimensional border as a subset of the d-dimensional global lattice.
Reference: [3] <author> R. H. Swendson and J.-S. Wang, </author> <title> "Nonuniversal critical dynamics in monte carlo simu-lations," </title> <journal> Physical Review Letters, </journal> <volume> vol. 58, </volume> <pages> pp. 86-88, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: We have developed a multidimensional extension of Belkhale and Banerjee's Quad algorithm [1, 2], a 2D connected component labeling algorithm developed for VLSI circuit extraction on a hypercube multiprocessor. This paper presents performance results from applying the algorithm to Ising model simulations with Swendson-Wang dynamics <ref> [3] </ref> in 2D, 3D, and 4D. Our extension abstracts away extraneous spatial information so that distributed data structures are managed in a dimension-independent manner. This strategy considerably simplifies implementation in more than two dimensions. To our knowledge, this implementation is the first parallelization of cluster identification in 4D. <p> Thus, even for correlation lengths ~ as small as 10 to 100, critical slowing-down severely limits the effectiveness of local-update algorithms for the Ising model [20]. In order to avoid critical slowing-down, Swendson and Wang's cluster algorithm updates whole regions of spins simultaneously <ref> [3] </ref>. This non-local update scheme generates 5 independent configurations in fewer iterations that the conventional algorithms. The cluster algorithm has a much smaller value of z, often approaching 0. Therefore, it eliminates critical slowing-down completely. The Swendson-Wang cluster algorithm proceeds as follows: 1. Compute bonds between spins.
Reference: [4] <author> M. Flanigan and P. Tamayo, </author> <title> "A parallel cluster labeling method for monte carlo dynamics," </title> <journal> International Journal of Modern Physics C, </journal> <volume> vol. 3, </volume> <pages> pp. 1235-49, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Flanigan and Tamayo present a relaxation algorithm for a block domain decomposition <ref> [4] </ref>. In this method, neighboring processors compare cluster labels and iterate until a steady state is reached. Baillie and Coddington consider a similar approach in their self-labeling algorithm [5]. <p> Although the optimizations were developed with the multidimensional Quad algorithm in mind, we conjecture that they would also be effective for other cluster identification algorithms, such as relaxation methods <ref> [4, 6, 7] </ref>. The multidimensional Quad algorithm and optimizations may be also be appropriate for other variants of connected component labeling.
Reference: [5] <author> C. F. Baillie and P. D. Coddington, </author> <title> "Cluster identification algorithms for spin models | sequential and parallel," </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol. 3, </volume> <pages> pp. 129-144, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Flanigan and Tamayo present a relaxation algorithm for a block domain decomposition [4]. In this method, neighboring processors compare cluster labels and iterate until a steady state is reached. Baillie and Coddington consider a similar approach in their self-labeling algorithm <ref> [5] </ref>. Both relaxation methods demonstrate reasonable scaleup for 2D problems, but for critical cluster configurations the number of relaxation iterations grows as the distance between the furthest two processors (2 p P for block decompositions on P processors). <p> Multigrid methods to accelerate the relaxation algorithm for large clusters have been presented for SIMD architectures [8, 9]. Host-node algorithms involve communicating global connectivity information to a single 3 processor. This host processor labels the global graph and then communicates the results to other processors. Host-node algorithms <ref> [10, 11, 5] </ref> do not scale to more than a few processors since the serialized host process becomes a bottleneck. Hierarchical methods for connected component labeling are characterized by a spatial domain decomposition and propagation of global information in log P stages. <p> Other hierarchical methods for distributed memory computers have been used for image component labeling [12, 13]. Baillie and Coddington consider a MIMD hierarchical algorithm for the Ising model, but do not achieve good parallel efficiency <ref> [5] </ref>. Mino presents a hierarchical labeling algorithm for vector architectures [14]. There has been comparably little work evaluating MIMD cluster identification algorithms in more than two dimensions. Bauernfeind et al. consider both relaxation and a host-node approaches to the 3D problem [15]. <p> Monte Carlo simulations of the Ising model generate a sequence of spin configurations. In traditional local-update Monte Carlo Ising model simulations, a spin's value may or may not change depending on the values of its neighbors and a random variable <ref> [5] </ref>. Since each spin update depends solely on local information, these algorithms map naturally onto a distributed memory architecture. The interesting physics arises from spin configurations in the critical region, where phase transitions occur. In these configurations, neighboring spins form large clusters in which all spins have the same value. <p> uses the path compression heuristic but not union-by-rank.) Adding together communication and computation, the running time for global combining is O (log P t s + t b pdN d1 d1 d1 Breadth-First Search (BFS) has been shown to be an efficient algorithm to perform the sequential local labeling step <ref> [5] </ref>. Since BFS runs in O (jV j+jEj) [21], the local labeling phase runs in O (( N P ) + ( pdN P )). Thus, for any dimension lattice, the time for the local phase will dominate the time for the global phase as long as N is large.
Reference: [6] <author> D. W. Heermann and A. N. Burkitt, </author> <title> "Parallelization of the Ising model and its performance evaluation," </title> <journal> Parallel Computing, </journal> <volume> vol. 13, </volume> <pages> pp. 345-357, </pages> <year> 1990. </year>
Reference-contexts: Both relaxation methods demonstrate reasonable scaleup for 2D problems, but for critical cluster configurations the number of relaxation iterations grows as the distance between the furthest two processors (2 p P for block decompositions on P processors). Other approaches similar to relaxation have been presented with strip decompositions <ref> [6, 7] </ref>. Strip decompositions result in only two external surfaces per processor. However, the distance between two processors can be as large as P , which increases the number of stages to reach a steady state. <p> Although the optimizations were developed with the multidimensional Quad algorithm in mind, we conjecture that they would also be effective for other cluster identification algorithms, such as relaxation methods <ref> [4, 6, 7] </ref>. The multidimensional Quad algorithm and optimizations may be also be appropriate for other variants of connected component labeling.
Reference: [7] <author> J. Kertesz and D. Stauffer, </author> <title> "Swendson-wang dynamics on large 2d critical Ising models," </title> <journal> International Journal of Modern Physics C, </journal> <volume> vol. 3, </volume> <pages> pp. 1275-9, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Both relaxation methods demonstrate reasonable scaleup for 2D problems, but for critical cluster configurations the number of relaxation iterations grows as the distance between the furthest two processors (2 p P for block decompositions on P processors). Other approaches similar to relaxation have been presented with strip decompositions <ref> [6, 7] </ref>. Strip decompositions result in only two external surfaces per processor. However, the distance between two processors can be as large as P , which increases the number of stages to reach a steady state. <p> Although the optimizations were developed with the multidimensional Quad algorithm in mind, we conjecture that they would also be effective for other cluster identification algorithms, such as relaxation methods <ref> [4, 6, 7] </ref>. The multidimensional Quad algorithm and optimizations may be also be appropriate for other variants of connected component labeling.
Reference: [8] <author> J. Apostolakis, P. Coddington, and E. Marinari, </author> <title> "A multi-grid cluster labeling scheme," </title> <journal> Europhysics Letters, </journal> <volume> vol. 17, </volume> <pages> pp. 189-194, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: However, the distance between two processors can be as large as P , which increases the number of stages to reach a steady state. Multigrid methods to accelerate the relaxation algorithm for large clusters have been presented for SIMD architectures <ref> [8, 9] </ref>. Host-node algorithms involve communicating global connectivity information to a single 3 processor. This host processor labels the global graph and then communicates the results to other processors.
Reference: [9] <author> R. C. Brower, P. Tamayo, and B. York, </author> <title> "A parallel multigrid algorithm for percolation clusters," </title> <journal> Journal of Statistical Physics, </journal> <volume> vol. 63, no. 1, </volume> <pages> pp. 73-88, </pages> <year> 1991. </year>
Reference-contexts: However, the distance between two processors can be as large as P , which increases the number of stages to reach a steady state. Multigrid methods to accelerate the relaxation algorithm for large clusters have been presented for SIMD architectures <ref> [8, 9] </ref>. Host-node algorithms involve communicating global connectivity information to a single 3 processor. This host processor labels the global graph and then communicates the results to other processors.
Reference: [10] <author> G. Barkema and T. MacFarland, </author> <title> "Parallel simulation of the Ising model," </title> <journal> Physical Review E, </journal> <volume> vol. 50, </volume> <pages> pp. 1623-28, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Multigrid methods to accelerate the relaxation algorithm for large clusters have been presented for SIMD architectures [8, 9]. Host-node algorithms involve communicating global connectivity information to a single 3 processor. This host processor labels the global graph and then communicates the results to other processors. Host-node algorithms <ref> [10, 11, 5] </ref> do not scale to more than a few processors since the serialized host process becomes a bottleneck. Hierarchical methods for connected component labeling are characterized by a spatial domain decomposition and propagation of global information in log P stages.
Reference: [11] <author> R. Hackl, H. G. Matuttis, J. M. Singer, T. Husslein, and I. Morgenstern, </author> <title> "Paralleliza-tion of the 2d swendson-wang algorithm," in Workshop on Large Scale Computational Physics on Massively Parallel Computers (H. </title> <editor> J. Herrmann and F. Karsch, </editor> <booktitle> eds.), </booktitle> <pages> pp. 59-72, </pages> <publisher> World Scientific, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: Multigrid methods to accelerate the relaxation algorithm for large clusters have been presented for SIMD architectures [8, 9]. Host-node algorithms involve communicating global connectivity information to a single 3 processor. This host processor labels the global graph and then communicates the results to other processors. Host-node algorithms <ref> [10, 11, 5] </ref> do not scale to more than a few processors since the serialized host process becomes a bottleneck. Hierarchical methods for connected component labeling are characterized by a spatial domain decomposition and propagation of global information in log P stages.
Reference: [12] <author> A. Choudhary and R. Thakur, </author> <title> "Evaluation of connected component labeling algorithms on shared and distributed memory multiprocessors," </title> <booktitle> in Proceedings of the Sixth International Parallel Processing Symposium, </booktitle> <pages> pp. 362-365, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Our approach is based on the hierarchical Quad algorithm for VLSI circuit extraction on a hypercube multiprocessor [1]. Other hierarchical methods for distributed memory computers have been used for image component labeling <ref> [12, 13] </ref>. Baillie and Coddington consider a MIMD hierarchical algorithm for the Ising model, but do not achieve good parallel efficiency [5]. Mino presents a hierarchical labeling algorithm for vector architectures [14]. There has been comparably little work evaluating MIMD cluster identification algorithms in more than two dimensions.
Reference: [13] <author> B. Falsafi and R. Miller, </author> <title> "Component labeling algorithms on an intel ipsc/2 hypercube," </title> <booktitle> in Proceedings of the Fifth Distributed Memory Computing Conference, </booktitle> <volume> vol. 1, </volume> <pages> pp. 159-164, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Our approach is based on the hierarchical Quad algorithm for VLSI circuit extraction on a hypercube multiprocessor [1]. Other hierarchical methods for distributed memory computers have been used for image component labeling <ref> [12, 13] </ref>. Baillie and Coddington consider a MIMD hierarchical algorithm for the Ising model, but do not achieve good parallel efficiency [5]. Mino presents a hierarchical labeling algorithm for vector architectures [14]. There has been comparably little work evaluating MIMD cluster identification algorithms in more than two dimensions.
Reference: [14] <author> H. Mino, </author> <title> "A vectorized algorithm for cluster formation in the Swendson-Wang dynamics," </title> <journal> Computer Physics Communications, </journal> <volume> vol. 66, </volume> <pages> pp. 25-30, </pages> <year> 1991. </year>
Reference-contexts: Other hierarchical methods for distributed memory computers have been used for image component labeling [12, 13]. Baillie and Coddington consider a MIMD hierarchical algorithm for the Ising model, but do not achieve good parallel efficiency [5]. Mino presents a hierarchical labeling algorithm for vector architectures <ref> [14] </ref>. There has been comparably little work evaluating MIMD cluster identification algorithms in more than two dimensions. Bauernfeind et al. consider both relaxation and a host-node approaches to the 3D problem [15]. They introduce the channel reduction and net list optimizations to reduce communication and computation requirements in 3D.
Reference: [15] <author> M. Bauernfeind, R. Hackl, H.-G. Matuttis, J. Singer, T. Husslein, and I.Morgenstern, </author> <title> "3D Ising model with swendson-wang dynamics: A parallel approach," </title> <journal> Physica A, </journal> <volume> vol. 212, </volume> <pages> pp. 277-298, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Mino presents a hierarchical labeling algorithm for vector architectures [14]. There has been comparably little work evaluating MIMD cluster identification algorithms in more than two dimensions. Bauernfeind et al. consider both relaxation and a host-node approaches to the 3D problem <ref> [15] </ref>. They introduce the channel reduction and net list optimizations to reduce communication and computation requirements in 3D. They conclude that the host-node approach is inappropriate for 3D due to increased memory requirements on the host node.
Reference: [16] <author> G. Parisi, </author> <title> Statistical Field Theory. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1988. </year> <month> 26 </month>
Reference-contexts: In order to understand these "critical phenomena," simple effective models have been constructed in statistical mechanics. The simplest such model, the Ising model, gives qualitative insights into the properties of phase transitions and sometimes can even 4 provide quantitative predictions for measurable physical quantities <ref> [16] </ref>. The Ising model can be solved exactly in 2D [17]. In more than two dimensions, exact solutions are not known and numerical simulations are often used to obtain approximate results.
Reference: [17] <author> L. Onsager, "Crystal statistics. i. </author> <title> a two-dimensional model with an order-disorder tran-sition," </title> <journal> Phys. Review, </journal> <volume> vol. 65, </volume> <pages> pp. 117-149, </pages> <year> 1944. </year>
Reference-contexts: The simplest such model, the Ising model, gives qualitative insights into the properties of phase transitions and sometimes can even 4 provide quantitative predictions for measurable physical quantities [16]. The Ising model can be solved exactly in 2D <ref> [17] </ref>. In more than two dimensions, exact solutions are not known and numerical simulations are often used to obtain approximate results. For example, numerical simulations of the 3D Ising model can be used to determine properties of phase transitions in systems like binary liquids [18].
Reference: [18] <author> S. Klessinger and G. Munster, </author> <title> "Numerical investigation of the interface tension in the three-dimensional Ising model," </title> <journal> Nuclear Physics B, </journal> <volume> vol. 386, no. 3, </volume> <pages> pp. 701-13, </pages> <year> 1992. </year>
Reference-contexts: In more than two dimensions, exact solutions are not known and numerical simulations are often used to obtain approximate results. For example, numerical simulations of the 3D Ising model can be used to determine properties of phase transitions in systems like binary liquids <ref> [18] </ref>. The 4D Ising model is a prototype of a relativistic field theory and can be used to learn about non-perturbative aspects, in particular phase transitions, of such theories [19].
Reference: [19] <author> K. Jansen, T. Trappenberg, I. Montvay, G. Munster, and U. Wolff, </author> <title> "Broken phase of the 4-dimensional Ising model in a finite volume," </title> <journal> Nuclear Physics B, </journal> <volume> vol. 322, </volume> <pages> pp. 698-720, </pages> <year> 1989. </year>
Reference-contexts: The 4D Ising model is a prototype of a relativistic field theory and can be used to learn about non-perturbative aspects, in particular phase transitions, of such theories <ref> [19] </ref>. In d dimensions, the Ising model consists of a d-dimensional lattice of variables (called spins) that take discrete values of 1. Neighboring spins are coupled, with a coupling strength which is inversely proportional to the temperature T .
Reference: [20] <author> D. W. Heermann, </author> <title> Computer simulation methods in theoretical physics. </title> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: For local update schemes the value z (the dynamical critical exponent) is z 2. Thus, even for correlation lengths ~ as small as 10 to 100, critical slowing-down severely limits the effectiveness of local-update algorithms for the Ising model <ref> [20] </ref>. In order to avoid critical slowing-down, Swendson and Wang's cluster algorithm updates whole regions of spins simultaneously [3]. This non-local update scheme generates 5 independent configurations in fewer iterations that the conventional algorithms. The cluster algorithm has a much smaller value of z, often approaching 0.
Reference: [21] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms. </title> <address> San Francisco: </address> <publisher> The MIT Press and McGraw-Hill Book Company, </publisher> <year> 1990. </year>
Reference-contexts: The messages contain the CCOMP set labels and border lists of the current information region. Processor Q 1 merges the CCOMP sets on the common border of the two information regions using a Union-Find data structure <ref> [21] </ref>. The other border lists of the two information regions are concatenated to form the information region for processor Q 1 in the next stage. <p> Using the path compression and union by rank optimizations of Union-Find operations <ref> [21] </ref>, the total work spent merging clusters is O (pdN d1 d1 d )). (Our implementation uses the path compression heuristic but not union-by-rank.) Adding together communication and computation, the running time for global combining is O (log P t s + t b pdN d1 d1 d1 Breadth-First Search (BFS) <p> Since BFS runs in O (jV j+jEj) <ref> [21] </ref>, the local labeling phase runs in O (( N P ) + ( pdN P )). Thus, for any dimension lattice, the time for the local phase will dominate the time for the global phase as long as N is large. <p> The global lattice has a toroidal topology in all directions. When using bubble elimination, only Manhattan neighbors are considered. The local labeling method is Breadth-First Search <ref> [21] </ref>. According to the Swendson-Wang algorithm, clusters must be flipped randomly after the cluster identification step. For a spatially decomposed parallel implementation, it is necessary that all processors obtain consistent pseudorandom numbers when generating the new spins for clusters that span more than one processor.
Reference: [22] <author> R. C. Gonzalez and P. Wintz, </author> <title> Digital Image Processing. </title> <address> Reading, Massachusetts: </address> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1977. </year>
Reference-contexts: We compress the representation of each list using run-length encoding <ref> [22] </ref>.
Reference: [23] <author> S. R. Kohn and S. B. Baden, </author> <title> "A robust parallel programming model for dynamic, nonuniform scientific computation," </title> <booktitle> in Proceedings of the 1994 Scalable High Performance Computing Conference, (Knoxville, Tenessee), </booktitle> <pages> pp. 509-517, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Thus, after cluster merging, all spins in a cluster are guaranteed to be consistent. To simplify implementation in more than 2 dimensions, we use the LPARX programming library, version 1.1 <ref> [23] </ref>. LPARX manages data distribution and communication between Cartesian lattices, and greatly simplifies the sections of the code that manages the regular spin lattice.
Reference: [24] <author> S. B. Baden, S. R. Kohn, S. M. Figueira, and S. J. Fink, </author> <title> "The LPARX user's guide v2.0," </title> <type> tech. rep., </type> <institution> University of California - San Diego, CSE 0114, </institution> <address> 9500 Gilman Drive, La Jolla, CA 92092-0114, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: LPARX manages data distribution and communication between Cartesian lattices, and greatly simplifies the sections of the code that manages the regular spin lattice. The kernel of the cluster algorithm is written in a message-passing style using the mp++ message-passing layer of LPARX <ref> [24] </ref>, a generic message-passing system resembling the 16 Message Passing Interface [25]. Since the cluster algorithm is largely dimension-independent, the message-passing code is almost identical for each problem dimensionality. In fact, the same code generates the 2D,3D, and 4D versions; compile-time macros determine the problem dimensionality.
Reference: [25] <author> Message Passing Interface Forum, </author> <title> MPI: A Message-Passing Interface Standard (v1.0), </title> <month> May </month> <year> 1994. </year>
Reference-contexts: The kernel of the cluster algorithm is written in a message-passing style using the mp++ message-passing layer of LPARX [24], a generic message-passing system resembling the 16 Message Passing Interface <ref> [25] </ref>. Since the cluster algorithm is largely dimension-independent, the message-passing code is almost identical for each problem dimensionality. In fact, the same code generates the 2D,3D, and 4D versions; compile-time macros determine the problem dimensionality.

References-found: 25

