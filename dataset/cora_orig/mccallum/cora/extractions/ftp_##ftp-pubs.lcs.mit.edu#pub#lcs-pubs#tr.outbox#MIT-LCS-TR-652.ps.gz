URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tr.outbox/MIT-LCS-TR-652.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/tr600.html
Root-URL: 
Title: Client Cache Management in a Distributed Object Database  
Author: by Mark Stuart Day Barbara Liskov 
Degree: (1987) Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Doctor of Philosophy at the  All rights reserved. Author  Certified by  Professor of Software Science and Engineering Thesis Supervisor Accepted by F.R. Morgenthaler Chair, Department Committee on Graduate Students  
Date: (1983)  May 1995  February 23, 1995  
Address: (1983) B.S.E.E., Washington University  
Affiliation: B.S.C.S., Washington University  S.M., Massachusetts Institute of Technology  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1995.  Department of Electrical Engineering and Computer Science  NEC  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Atul Adya. </author> <title> A distributed commit protocol for optimistic concurrency control. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: Copying objects to a client cache and managing that cache introduce new problems. Others have addressed aspects of storage management [48] and concurrency control <ref> [1] </ref>. The thesis addresses the following three performance-related problems: * implementing inter-object references; * bringing objects into the client cache; and * evicting objects from the client cache. The most important results are the following: 1. <p> This information allows the server to invalidate objects in a client cache that have been made obsolete by updates at the server [46]. The same information is also used for efficient concurrency control <ref> [1] </ref> and distributed garbage collection [48]. The server's information always represents a superset of the objects actually in the client's cache: no object can be in the client's cache without being recorded at the server, but the server may record an object that is not in use at the client. <p> Failing to keep the server up-to-date can cause the system's performance to degrade to the point where it behaves as though there were no prefetching, only single-object fetching. In addition, good performance of the system's concurrency control mechanism <ref> [1] </ref> and distributed garbage collector [48] also depend on having information at the server that is close to the actual state of the client. Correctness does not require updating of the server's information about the client state; the updating is intended to improve performance.
Reference: [2] <author> Anant Agarwal and Steven D. Pudar. </author> <title> Column-associative caches: A technique for reducing the miss rate of direct-mapped caches. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 179-190, </pages> <year> 1993. </year>
Reference-contexts: The "replacement policy" of a processor cache is typically determined by the hardware cost of building a particular degree and flavor of associativity; for recent examples, see work on column-associative caches <ref> [2] </ref> or skewed-associative caches [61]. The designers of processor caches are also concerned with how to write back changes: see Jouppi's recent work [37] for an example.
Reference: [3] <author> T. Lougenia Anderson, Arne J. Berre, Moira Mallison, Harry H. Porter, III, and Bruce Schnei-der. </author> <title> The HyperModel benchmark. </title> <booktitle> In Conference on Extended Database Technology (EDBT 90), </booktitle> <pages> pages 317-331. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: However, OO7 seems superior to other published synthetic benchmarks for object databases, such as OO1 [14] and HyperModel <ref> [3] </ref>.
Reference: [4] <author> Fran~cois Bancilhon, Claude Delobel, and Paris Kanellakis, </author> <title> editors. Building an Object-Oriented Database: </title> <publisher> The Story of O 2 . Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: The first dimension is directness (direct, indirect, or mixed) and the second dimension is eagerness (eager or lazy). 46 Eager Lazy Indirect LOOM [39], others LIS [40] Mixed Thor node marking Thor edge marking with surrogates Persistent Smalltalk [33] Direct O 2 resident mode <ref> [4] </ref> Thor edge marking Exodus [73] Consider directness first. A direct swizzling technique translates an inter-object reference into the address of the object itself. Edge marking in Thor, as described in this chapter, is an example of direct swizzling. Similarly, Exodus [73] uses direct swizzling, as does O 2 [4] in <p> mode <ref> [4] </ref> Thor edge marking Exodus [73] Consider directness first. A direct swizzling technique translates an inter-object reference into the address of the object itself. Edge marking in Thor, as described in this chapter, is an example of direct swizzling. Similarly, Exodus [73] uses direct swizzling, as does O 2 [4] in its so-called resident mode. In contrast, an indirect swizzling technique translates such a reference into the address of a descriptor for the object, which in turn contains the address of the object itself. Direct swizzling is more efficient than indirect swizzling in both space and time. <p> Now consider eagerness. An eager swizzling technique ensures that any object in the client cache contains only swizzled pointers; there are no names left in object fields. Node marking as described in this chapter is an example of eager swizzling. The resident mode of O 2 <ref> [4] </ref> is another example of eager swizzling. In contrast, a lazy swizzling technique allows object fields to contain names or swizzled pointers, converting names to pointers only as needed. <p> Thor transfers groups of objects from server to client. On receiving a fetch request, a Thor server selects objects to send in response. The group of objects selected is called the prefetch group. Thor's dynamic selection of the group contrasts with most distributed object databases <ref> [4, 8, 9, 10] </ref>, which cluster objects statically into pages and transfer pages in response to fetch requests. This chapter describes and compares different techniques for selecting prefetch groups.
Reference: [5] <author> L. A. Belady. </author> <title> A study of replacement algorithms for a virtual-storage computer. </title> <journal> IBM Systems Journal, </journal> <volume> 5(2) </volume> <pages> 78-101, </pages> <year> 1966. </year>
Reference-contexts: The algorithm minimizes the number of fetches required. This problem is not solved by Belady's opt algorithm <ref> [5] </ref> for paging systems, since opt only deals with a single page at a time; the minfetch algorithm discards multiple objects of varying sizes. Since a paged system can only discard whole pages, minfetch can do better than Belady's opt at minimizing fetches. <p> Previous work on virtual memory policies [24] demonstrated that the fault rate of a program is much more sensitive to memory size than to the choice of paging algorithm, for all reasonable algorithms including Belady's unrealizable optimal algorithm <ref> [5] </ref>. This result is rather similar to the discovery in this chapter that the minfetch policy does somewhat better than any of the realizable policies, but that even its performance degrades rather quickly with decreasing memory size.
Reference: [6] <author> Veronique Benzaken and Claude Delobel. </author> <title> Enhancing performance in a persistent object store: Clustering strategies in O 2 . In Alan Dearle, </title> <editor> Gail M. Shaw, and Stanley B. Zdonik, editors, </editor> <title> Implementing Persistent Object Bases: </title> <booktitle> Principles and Practice, </booktitle> <pages> pages 403-412. </pages> <publisher> Morgan Kauf-mann, </publisher> <year> 1991. </year>
Reference-contexts: The roots of the techniques used are typically found in the techniques developed for packing records into pages [60, 75, 59, 49]. A significant amount of work has also been done on the specific problems of clustering objects into pages <ref> [6, 31, 67, 62, 15, 28] </ref>. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems. Accordingly, for dynamic prefetching to be of any value, it has to do something better than can be done by clustering objects into pages.
Reference: [7] <author> Margaret H. Butler. </author> <title> Storage reclamation in object oriented database systems. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 410-425, </pages> <year> 1987. </year>
Reference-contexts: This mechanism requires more control over the execution stack than Thor has. For portability, Thor methods are ultimately compiled by the local C compiler, rather than being compiled directly to native code. Butler's work <ref> [7] </ref> is concerned with garbage collection for an object-oriented database, but is primarily concerned with the problem of garbage collecting persistent storage.
Reference: [8] <author> Paul Butterworth, Allen Otis, and Jacob Stein. </author> <title> The GemStone object database management system. </title> <journal> Communications of the ACM, </journal> <volume> 34(10) </volume> <pages> 64-77, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Thor transfers groups of objects from server to client. On receiving a fetch request, a Thor server selects objects to send in response. The group of objects selected is called the prefetch group. Thor's dynamic selection of the group contrasts with most distributed object databases <ref> [4, 8, 9, 10] </ref>, which cluster objects statically into pages and transfer pages in response to fetch requests. This chapter describes and compares different techniques for selecting prefetch groups. <p> The indirection through the ROT also means that it is straightforward to relocate an object within memory. Several other object-oriented databases (GemStone <ref> [8, 66] </ref>, Orion [41], Jasmine [36]) use basically the same cache structure as LOOM. We chose to use direct swizzling in Thor to avoid the time and space overheads caused by indirect swizzling.
Reference: [9] <author> M. J. Carey, D. J. DeWitt, G. Graefe, D. M. Haight, J. E. Richardson, D. T. Schuh, E. J. Shekita, and S. L. Vandenberg. </author> <title> The EXODUS extensible DBMS project: An overview. </title> <editor> In Stanley B. Zdonik and David Maier, editors, </editor> <booktitle> Readings in Object-Oriented Database Systems, </booktitle> <pages> pages 474-499. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year> <month> 137 </month>
Reference-contexts: Thor transfers groups of objects from server to client. On receiving a fetch request, a Thor server selects objects to send in response. The group of objects selected is called the prefetch group. Thor's dynamic selection of the group contrasts with most distributed object databases <ref> [4, 8, 9, 10] </ref>, which cluster objects statically into pages and transfer pages in response to fetch requests. This chapter describes and compares different techniques for selecting prefetch groups.
Reference: [10] <author> Michael J. Carey, David J. DeWitt, Michael J. Franklin, Nancy E. Hall, Mark L. McAuliffe, Jeffrey F. Naughton, Daniel T. Schuh, Marvin H. Solomon, C.K. Tan, Odysseas G. Tsatalos, Seth White, and Michael J. Zwilling. </author> <title> Shoring up persistent applications. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 383-394, </pages> <year> 1994. </year>
Reference-contexts: Thor transfers groups of objects from server to client. On receiving a fetch request, a Thor server selects objects to send in response. The group of objects selected is called the prefetch group. Thor's dynamic selection of the group contrasts with most distributed object databases <ref> [4, 8, 9, 10] </ref>, which cluster objects statically into pages and transfer pages in response to fetch requests. This chapter describes and compares different techniques for selecting prefetch groups.
Reference: [11] <author> Michael J. Carey, David J. DeWitt, Chander Kant, and Jeffrey F. Naughton. </author> <title> A status report on the OO7 OODBMS benchmarking effort. </title> <booktitle> In Proceedings of the ACM Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA), </booktitle> <pages> pages 414-426, </pages> <year> 1994. </year>
Reference-contexts: I would not expect significantly different results from a more varied collection of object sizes. The designers of the OO7 benchmark did not mention any concerns about the range of object sizes or the realism of the database in a recent status report <ref> [11] </ref>. 1.2.2 Particular configuration The experiments were run on a single machine (so there was no network delay) and in a way that ensured that all objects of interest were in memory (so there were no disk reads). <p> However, OO7 seems superior to other published synthetic benchmarks for object databases, such as OO1 [14] and HyperModel [3]. In a recent evaluation of lessons learned so far from OO7 <ref> [11] </ref>, the authors do not indicate that they have received any complaints that their benchmark is particularly unrealistic or unrepresentative. 3.1 Database Structure The OO7 database is made up of a tree of Assemblies with CompositeParts at the leaves (see text) and a graph of AtomicParts and Connections (see Figure 3-2).
Reference: [12] <author> Michael J. Carey, David J. DeWitt, and Jeffrey F. Naughton. </author> <title> The OO7 benchmark. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 12-21, </pages> <address> Washington, DC, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: First, they were run with a particular synthetic workload. Second, they were run on a particular configuration of hardware and software. This section considers the effect of these limitations on the results. 1.2.1 Synthetic workload The experiments use a part of the OO7 benchmark <ref> [12] </ref> for object databases. The intent is to capture the dominant effects of a generic computation in an object database. Accordingly, the experiments 11 involve read-only traversal of inter-object references. <p> Chapter 3 describes the database, and the traversals of that database, used for assessing performance. The database and traversals are adapted from the OO7 benchmark suite <ref> [12] </ref>, which represents the best published benchmark suite for object-oriented databases. Chapter 3 also explains the constraints that led to using this approach for assessing performance. Chapter 4 describes how inter-object references are represented at the client. <p> With this information in hand to resolve some early design questions, the implementation of the system can proceed; future work can re-examine the system's behavior with larger and more realistic applications. The object graphs used are based on the database of the OO7 benchmarks <ref> [12] </ref> developed at the University of Wisconsin.
Reference: [13] <author> Michael J. Carey, Michael J. Franklin, and Markos Zaharioudakis. </author> <title> Fine-grained sharing in a page server OODBMS. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 359-370, </pages> <year> 1994. </year>
Reference-contexts: I believe that DeWitt et al. have shown the need for fetching reasonably large groups of objects, but have not presented data that supports their conclusions about object-server architectures. More recent work <ref> [13] </ref> continues to make the case for pages by comparing them to single-object-fetching systems. The second, less serious problem is that the authors define an "object server" to be something that is able to execute methods.
Reference: [14] <author> R. G. G. Cattell and J. Skeen. </author> <title> Object operations benchmark. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17(1) </volume> <pages> 1-31, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: However, OO7 seems superior to other published synthetic benchmarks for object databases, such as OO1 <ref> [14] </ref> and HyperModel [3]. <p> However, when objects are to be evicted from the cache, surrogates can be useful even if fetched objects are swizzled using edge marking. I am aware of three groups that have done swizzling studies, all using databases derived from the OO1 benchmark <ref> [14] </ref>: White and DeWitt [73], Hosking and Moss [33, 34], and Kemper and Kossmann [40]. White and DeWitt compared different implementations of lazy direct swizzling (edge marking) and swizzling at the granularity of pages (ObjectStore [42]).
Reference: [15] <author> Ellis E. Chang and Randy H. Katz. </author> <title> Exploiting inheritance and structure semantics for effective clustering and buffering in an object-oriented dbms. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 348-357, </pages> <year> 1989. </year>
Reference-contexts: The roots of the techniques used are typically found in the techniques developed for packing records into pages [60, 75, 59, 49]. A significant amount of work has also been done on the specific problems of clustering objects into pages <ref> [6, 31, 67, 62, 15, 28] </ref>. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems. Accordingly, for dynamic prefetching to be of any value, it has to do something better than can be done by clustering objects into pages. <p> As was shown by the sparse and dense traversals, very different computations sharing the same objects can benefit from dynamic prefetching. There has been some work arguing for dynamic reclustering <ref> [15, 50] </ref>; however, such reclustering is expensive compared to dynamically computing prefetch groups (since reclustering involves disk writes) and it is challenging to decide when it is worth reclustering. <p> Thor is an example of a system with servers that deal with objects, but do not run methods. There is some other evidence previous to this work that points toward the possible value of dynamically computing object groups. Chang and Katz <ref> [15] </ref> argued for dynamic clustering and buffering at runtime based on structural information. In the context of a client/server system, their data and arguments can be viewed as supporting a model more like Thor's use of object groups than a typical page server system.
Reference: [16] <author> Jia-bing R. Cheng and A. R. Hurson. </author> <title> Effective clustering of complex objects in object-oriented databases. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 22-31, </pages> <year> 1991. </year>
Reference-contexts: It is worth noting that Cheng and Hurson earlier advocated an elaborate static clustering technique <ref> [16] </ref> to address the performance 79 deficiencies of simpler clustering techniques. In their proposed clustering technique, objects were first clustered into primary clusters, then reclustered into secondary clusters.
Reference: [17] <author> Jia-bing R. Cheng and A. R. Hurson. </author> <title> On the performance issues of object-based buffering. </title> <booktitle> In Proceedings of the Conference on Parallel and Distributed Information Systems, </booktitle> <pages> pages 30-37, </pages> <year> 1991. </year>
Reference-contexts: In the context of a client/server system, their data and arguments can be viewed as supporting a model more like Thor's use of object groups than a typical page server system. Cheng and Hurson <ref> [17] </ref> determined that an object buffer pool and prefetching improved performance compared to a page store even when the prefetching was fairly sloppy (only 50% accurate). <p> It is worth noting that Cheng and Hurson earlier advocated an elaborate static clustering technique [16] to address the performance 79 deficiencies of simpler clustering techniques. In their proposed clustering technique, objects were first clustered into primary clusters, then reclustered into secondary clusters. Their report on prefetching <ref> [17] </ref> partially repudiates the arguments they made in favor of their clustering scheme. 5.5.3 Prefetching Early work on prefetching in databases, such as that by Smith [64], depends on repeated sequential access to data pages. <p> The prefetching mechanism in this thesis is a simpler approach, intended to boost the basic performance of the system without requiring the storage and tracking of prefetcher state. Cheng and Hurson <ref> [17] </ref> proposed a model of a "moving window" for prefetching, with the window centered at the object currently in use and containing all of the objects reachable from that object.
Reference: [18] <author> H.-T. Chou, D. DeWitt, R. Katz, and A. Klug. </author> <title> Design and implementation of the Wisconsin storage system. </title> <journal> Software: Practice and Experience, </journal> <volume> 15(10) </volume> <pages> 943-962, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: DeWitt et al. carried out a study of client-server architectures [27] that compared an object server, a page server, and a file server. The different configurations were all derived from the WiSS system <ref> [18] </ref>, which is organized as a layered structure. The different versions of the system correspond to placing the client/server split between different layers of the system. DeWitt et al. found that no one architecture was superior in all situations.
Reference: [19] <author> Eric Cooper, Scott Nettles, and Indira Subramanian. </author> <title> Improving the performance of SML garbage collection using application-specific virtual memory management. </title> <booktitle> In Proceedings of the ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 43-52, </pages> <year> 1992. </year>
Reference-contexts: problem of managing the server's persistent storage. 6.6.3 Shrinking and Garbage Collection Cooper et al. describe how they modified Standard ML of New Jersey (SML) [51] and implemented an SML-specific external pager for Mach so that VM cache management could take advantage of the knowledge of the SML garbage collector <ref> [19] </ref>. The garbage collector marked pages as discardable or nondiscardable based on their current role in the garbage collection process.
Reference: [20] <author> Kenneth M. Curewitz, P. Krishnan, and Jeffrey Scott Vitter. </author> <title> Practical prefetching via data compression. </title> <note> Brown University Technical Note. 138 </note>
Reference-contexts: The results of this thesis suggest that prefetching is the area most likely to yield performance gains. Possibilities include different prefetching algorithms or storing application-specific information with objects. Vitter and Krishnan [72] have studied the use of data compression algorithms to achieve optimal prefetching and Curewitz, Krishnan and Vitter <ref> [20] </ref> have applied practical prefetchers derived from this theory to database traces. Their work would be a logical starting point for developing more sophisticated prefetchers to replace the simple ones that I implemented.
Reference: [21] <author> Mark Day. </author> <title> Object groups may be better than pages. </title> <booktitle> In Proceedings of the 4th Workshop on Workstation Operating Systems, </booktitle> <pages> pages 119-122, </pages> <year> 1993. </year>
Reference-contexts: to get any value from the state the prefetcher has built up is either to have the prefetcher shared with other clients or to save the prefetcher's state in the database in a form where it can be used subsequently (for example, in a stored prefetch hint called a crystal <ref> [21] </ref>). The prefetching mechanism in this thesis is a simpler approach, intended to boost the basic performance of the system without requiring the storage and tracking of prefetcher state. <p> Their work would be a logical starting point for developing more sophisticated prefetchers to replace the simple ones that I implemented. I have proposed a mechanism called crystals as a way of controlling prefetching in a system like Thor <ref> [21] </ref>. A crystal is an object that represents an explicitly- or implicitly-constructed group of objects. When the computation reaches the crystal, the associated group of objects is prefetched. The work on transparent informed prefetching [58] applies a similar approach in the context of Unix.
Reference: [22] <author> Mark Day, Sanjay Ghemawat, Robert Gruber, Barbara Liskov, and Andrew C. Myers. </author> <title> Theta reference manual. Memo 88, MIT LCS Programming Methodology Group, </title> <month> December </month> <year> 1994. </year>
Reference-contexts: This definition uses C++ syntax for the reader's convenience, although the actual Thor implementation is in an early dialect of the language Theta <ref> [22] </ref>. Client applications must manipulate objects entirely in terms of the operations provided by types; they have no knowledge of the fields of objects, nor any knowledge of the inheritance structure of classes.
Reference: [23] <author> Peter J. Denning. </author> <title> The working set model for program behavior. </title> <journal> Communications of the ACM, </journal> <volume> 11(5) </volume> <pages> 323-333, </pages> <month> May </month> <year> 1968. </year>
Reference-contexts: The shifting traversal consists of multiple partially-overlapping iterations of the dense traversal. This realizes, although in a very simple form, the phase/transition behavior that characterizes real programs [25]. Each of the dense traversals is henceforth called an elementary traversal. The complete shifting traversal has a shifting working set <ref> [23] </ref>: with a large enough cache, each elementary traversal except the first has 2/3 of its objects present from the previous traversal. The shifting traversal uses a wide database that is approximately two of the previously-used databases, joined at the roots.
Reference: [24] <author> Peter J. Denning. </author> <title> Virtual memory. </title> <journal> Computing Surveys, </journal> <volume> 2(3) </volume> <pages> 153-189, </pages> <month> September </month> <year> 1970. </year>
Reference-contexts: Previous work on virtual memory policies <ref> [24] </ref> demonstrated that the fault rate of a program is much more sensitive to memory size than to the choice of paging algorithm, for all reasonable algorithms including Belady's unrealizable optimal algorithm [5]. <p> This result is rather similar to the discovery in this chapter that the minfetch policy does somewhat better than any of the realizable policies, but that even its performance degrades rather quickly with decreasing memory size. Policies like clock are better than policies like random in a virtual-memory environment <ref> [24] </ref>, and there are two plausible explanations for this difference. First is that objects (the granularity of eviction in Thor) are much smaller than pages (the granularity of eviction in virtual-memory systems).
Reference: [25] <author> Peter J. Denning. </author> <title> Working sets past and present. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 6(1) </volume> <pages> 64-84, </pages> <month> January </month> <year> 1980. </year>
Reference-contexts: It is based on the dense traversal used in earlier tests (see Chapter 4 for details). The shifting traversal consists of multiple partially-overlapping iterations of the dense traversal. This realizes, although in a very simple form, the phase/transition behavior that characterizes real programs <ref> [25] </ref>. Each of the dense traversals is henceforth called an elementary traversal. The complete shifting traversal has a shifting working set [23]: with a large enough cache, each elementary traversal except the first has 2/3 of its objects present from the previous traversal.
Reference: [26] <author> O. </author> <title> Deux. </title> <journal> The story of O 2 . IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 91-108, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: O 2 uses client virtual memory to manage memory. If there is no more swap space, space for objects "is freed"; the exact process is unclear <ref> [26] </ref>. It appears that no attempt is made to manage storage until swap space runs out; this means that the client can be thrashing with reads and 94 writes to its local disk, in addition to whatever costs are incurred from the server's disk.
Reference: [27] <author> David J. DeWitt, Philippe Futtersack, David Maier, and Fernando Velez. </author> <title> A study of three alternative workstation-server architectures for object oriented database systems. </title> <booktitle> In Proceedings of the 16th Conference on Very Large Data Bases, </booktitle> <pages> pages 107-121, </pages> <address> Brisbane, Australia, </address> <year> 1990. </year>
Reference-contexts: Another possibility is to fetch a page containing the needed object and whatever else has been placed on the same page; this is called a page server. An earlier study by De Witt et al. <ref> [27] </ref> showed that a page server usually outperforms a single-object server. There is a third possibility, not considered by that study: it is possible to send a group of objects to the client. <p> Context-specific or type-specific swizzling appears unjustified. 48 Chapter 5 Prefetching In the previous chapter, the client fetched only one object at a time from a server. This arrangement is simple, but the performance of single-object fetching is unacceptable <ref> [27, 33, 34] </ref>. To improve performance, the number of fetches must be reduced; some entity larger than a single object must be transferred from server to client. This chapter investigates techniques for the server to send more than one object at a time to the client. <p> DeWitt et al. carried out a study of client-server architectures <ref> [27] </ref> that compared an object server, a page server, and a file server. The different configurations were all derived from the WiSS system [18], which is organized as a layered structure. The different versions of the system correspond to placing the client/server split between different layers of the system.
Reference: [28] <author> Pamela Drew and Roger King. </author> <title> The performance and utility of the Cactis implementation algorithms. </title> <booktitle> In Proceedings of the Conference on Very Large Data Bases (VLDB), </booktitle> <pages> pages 135-147, </pages> <year> 1990. </year>
Reference-contexts: The roots of the techniques used are typically found in the techniques developed for packing records into pages [60, 75, 59, 49]. A significant amount of work has also been done on the specific problems of clustering objects into pages <ref> [6, 31, 67, 62, 15, 28] </ref>. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems. Accordingly, for dynamic prefetching to be of any value, it has to do something better than can be done by clustering objects into pages.
Reference: [29] <author> Sanjay Ghemawat. </author> <title> Disk management for object-oriented databases. </title> <booktitle> In Proceedings of the 3rd International Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 222-225, </pages> <year> 1993. </year>
Reference-contexts: The experiments ensure that all objects of interest are in the server cache. The problems of managing the server cache and the server's disk are beyond the scope of this thesis; Ghemawat <ref> [29, 30] </ref> is addressing some of those problems. This thesis also ignores the details of the application. Computations are described in terms of a database viewed as an object graph. The objects in the database are treated as nodes of a multigraph, and inter-object references are edges of that multigraph.
Reference: [30] <author> Sanjay Ghemawat, M. Frans Kaashoek, and Barbara Liskov. </author> <title> Disk management policies for object-oriented databases. </title> <note> Extended abstract submitted to OSDI '94. </note>
Reference-contexts: The experiments ensure that all objects of interest are in the server cache. The problems of managing the server cache and the server's disk are beyond the scope of this thesis; Ghemawat <ref> [29, 30] </ref> is addressing some of those problems. This thesis also ignores the details of the application. Computations are described in terms of a database viewed as an object graph. The objects in the database are treated as nodes of a multigraph, and inter-object references are edges of that multigraph.
Reference: [31] <author> Olivier Gruber and Laurent Amsaleg. </author> <title> Object grouping in Eos. </title> <editor> In M. Tamer Ozsu, Umesh Dayal, and Patrick Valduriez, editors, </editor> <booktitle> Distributed Object Management, </booktitle> <pages> pages 117-131. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1994. </year>
Reference-contexts: The roots of the techniques used are typically found in the techniques developed for packing records into pages [60, 75, 59, 49]. A significant amount of work has also been done on the specific problems of clustering objects into pages <ref> [6, 31, 67, 62, 15, 28] </ref>. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems. Accordingly, for dynamic prefetching to be of any value, it has to do something better than can be done by clustering objects into pages.
Reference: [32] <author> John L. Hennessey and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Like total, random does not require any information about object usage to be maintained, and so avoids the space and time costs required for that maintenance. For hardware caches, a random replacement policy is approximately as good as more elaborate policies <ref> [32] </ref>.
Reference: [33] <author> Antony L. Hosking and J. Eliot B. Moss. </author> <title> Object fault handling for persistent programming languages: A performance evaluation. </title> <booktitle> In Proceedings of the ACM Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA), </booktitle> <pages> pages 288-303, </pages> <year> 1993. </year>
Reference-contexts: There are two relatively independent dimensions of swizzling techniques. The first dimension is directness (direct, indirect, or mixed) and the second dimension is eagerness (eager or lazy). 46 Eager Lazy Indirect LOOM [39], others LIS [40] Mixed Thor node marking Thor edge marking with surrogates Persistent Smalltalk <ref> [33] </ref> Direct O 2 resident mode [4] Thor edge marking Exodus [73] Consider directness first. A direct swizzling technique translates an inter-object reference into the address of the object itself. Edge marking in Thor, as described in this chapter, is an example of direct swizzling. <p> Node marking as described in this chapter is an example of mixed swizzling: inter-object references via full surrogates are indirect, but those full surrogates are snapped out by the garbage collector and replaced by direct pointers. Persistent Smalltalk <ref> [33, 34] </ref> is another example of mixed swizzling; but instead of using the garbage collector to snap out the descriptors (which are called indirect blocks in Persistent Smalltalk), there is a special scanning step that runs as part of an object fault. <p> I am aware of three groups that have done swizzling studies, all using databases derived from the OO1 benchmark [14]: White and DeWitt [73], Hosking and Moss <ref> [33, 34] </ref>, and Kemper and Kossmann [40]. White and DeWitt compared different implementations of lazy direct swizzling (edge marking) and swizzling at the granularity of pages (ObjectStore [42]). They found that swizzling on discovery is superior to swizzling on reference (Section 4.1.2 explains the difference). <p> Context-specific or type-specific swizzling appears unjustified. 48 Chapter 5 Prefetching In the previous chapter, the client fetched only one object at a time from a server. This arrangement is simple, but the performance of single-object fetching is unacceptable <ref> [27, 33, 34] </ref>. To improve performance, the number of fetches must be reduced; some entity larger than a single object must be transferred from server to client. This chapter investigates techniques for the server to send more than one object at a time to the client.
Reference: [34] <author> Antony L. Hosking and J. Eliot B. Moss. </author> <title> Protection traps and alternatives for memory management of an object-oriented language. </title> <booktitle> In Proceedings of the 14th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 106-119, </pages> <year> 1993. </year> <month> 139 </month>
Reference-contexts: It was difficult to assess the importance of the swizzling technique in the absence of data from an implementation. There is no consensus in the literature: Moss [52] reasoned that node marking and edge marking should have roughly similar performance, but a later paper by Hosking and Moss <ref> [34] </ref> suggested in a footnote that edge marking is "not competitive" with node marking. Kemper and Kossmann's study [40] concluded that there were significant differences among swizzling techniques on different workloads. <p> Node marking as described in this chapter is an example of mixed swizzling: inter-object references via full surrogates are indirect, but those full surrogates are snapped out by the garbage collector and replaced by direct pointers. Persistent Smalltalk <ref> [33, 34] </ref> is another example of mixed swizzling; but instead of using the garbage collector to snap out the descriptors (which are called indirect blocks in Persistent Smalltalk), there is a special scanning step that runs as part of an object fault. <p> I am aware of three groups that have done swizzling studies, all using databases derived from the OO1 benchmark [14]: White and DeWitt [73], Hosking and Moss <ref> [33, 34] </ref>, and Kemper and Kossmann [40]. White and DeWitt compared different implementations of lazy direct swizzling (edge marking) and swizzling at the granularity of pages (ObjectStore [42]). They found that swizzling on discovery is superior to swizzling on reference (Section 4.1.2 explains the difference). <p> Context-specific or type-specific swizzling appears unjustified. 48 Chapter 5 Prefetching In the previous chapter, the client fetched only one object at a time from a server. This arrangement is simple, but the performance of single-object fetching is unacceptable <ref> [27, 33, 34] </ref>. To improve performance, the number of fetches must be reduced; some entity larger than a single object must be transferred from server to client. This chapter investigates techniques for the server to send more than one object at a time to the client. <p> The comparable problem in a virtual memory system is a reference to an evicted page, which is handled by hardware. Although it is tempting to use such page-faulting hardware to assist object systems [42, 63] some evidence <ref> [34] </ref> suggests that such page-faulting hardware is ill-suited to support object operations, primarily because of the mismatch between the size of a typical object and the size of a typical page. To avoid the dangling-reference problem using only software, objects are not simply evicted and replaced in Thor.
Reference: [35] <author> Tony Hosking and Eliot Moss, </author> <month> March </month> <year> 1994. </year> <type> Personal communication. </type>
Reference-contexts: Although an early analysis by Moss [52] matched my results, my results appear to differ from the more recent report of Hosking and Moss, who found edge marking "clearly uncompetitive" ([34], footnote 7). However, a personal communication <ref> [35] </ref> describing their implementation in more detail explains that their edge marking scheme is not swizzling: instead, it is doing repeated lookups, and accordingly is not comparable to the edge marking described here. Kemper and Kossmann's study [40] concluded that there were significant differences among swizzling techniques on different workloads.
Reference: [36] <author> Hiroshi Ishikawa, Fumio Suzuki, Fumihiko Kozakura, Akifumi Makinouchi, Mika Miyagishima, Yoshio Izumida, Masaaki Aoshima, and Yasuo Yamane. </author> <title> The model, language, and implementation of an object-oriented multimedia knowledge base management system. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 18(1) </volume> <pages> 1-50, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Direct swizzling is more efficient than indirect swizzling in both space and time. However, indirect swizzling simplifies storage management because object descriptors make it easy to relocate or evict objects. Examples of systems using indirect swizzling are LOOM [39], Emerald [38], Orion [41] and Jasmine <ref> [36] </ref>. Some systems have mixed swizzling, in which an inter-object reference may be direct at some times and indirect at others; these systems are attempting to get some of the good properties of both direct and indirect swizzling. <p> The indirection through the ROT also means that it is straightforward to relocate an object within memory. Several other object-oriented databases (GemStone [8, 66], Orion [41], Jasmine <ref> [36] </ref>) use basically the same cache structure as LOOM. We chose to use direct swizzling in Thor to avoid the time and space overheads caused by indirect swizzling.
Reference: [37] <author> Norman P. Jouppi. </author> <title> Cache write policies and performance. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 191-201, </pages> <year> 1993. </year>
Reference-contexts: The designers of processor caches are also concerned with how to write back changes: see Jouppi's recent work <ref> [37] </ref> for an example. This sort of work is not applicable to object caches as described in this thesis, since objects are never written back except at transaction commit. Similarly, work done on virtual memory systems is not directly applicable to a client object cache.
Reference: [38] <author> Eric Jul, Henry Levy, Norman Hutchinson, and Andrew Black. </author> <title> Fine-grained mobility in the Emerald system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 109-133, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Direct swizzling is more efficient than indirect swizzling in both space and time. However, indirect swizzling simplifies storage management because object descriptors make it easy to relocate or evict objects. Examples of systems using indirect swizzling are LOOM [39], Emerald <ref> [38] </ref>, Orion [41] and Jasmine [36]. Some systems have mixed swizzling, in which an inter-object reference may be direct at some times and indirect at others; these systems are attempting to get some of the good properties of both direct and indirect swizzling.
Reference: [39] <author> Ted Kaehler and Glenn Krasner. </author> <title> LOOM Large object-oriented memory for Smalltalk-80 systems. </title> <editor> In Stanley B. Zdonik and David Maier, editors, </editor> <booktitle> Readings in Object-Oriented Database Systems, </booktitle> <pages> pages 298-307. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: A reference to an object cached at the client can be converted to use the address of the local copy of that object. Such a conversion is called swizzling. After swizzling, subsequent uses of the reference can avoid the overhead of translating the object reference to its current address. <ref> [39] </ref> was the first system to use swizzling; the technique has since become the norm for persistent object systems. A system like Thor transfers object groups, not pages; Chapter 5 justifies that design choice. For this chapter the object-group-transfer architecture is simply assumed. <p> I start from Kemper and Kossmann's terms to categorize related work on swizzling techniques. There are two relatively independent dimensions of swizzling techniques. The first dimension is directness (direct, indirect, or mixed) and the second dimension is eagerness (eager or lazy). 46 Eager Lazy Indirect LOOM <ref> [39] </ref>, others LIS [40] Mixed Thor node marking Thor edge marking with surrogates Persistent Smalltalk [33] Direct O 2 resident mode [4] Thor edge marking Exodus [73] Consider directness first. A direct swizzling technique translates an inter-object reference into the address of the object itself. <p> Direct swizzling is more efficient than indirect swizzling in both space and time. However, indirect swizzling simplifies storage management because object descriptors make it easy to relocate or evict objects. Examples of systems using indirect swizzling are LOOM <ref> [39] </ref>, Emerald [38], Orion [41] and Jasmine [36]. Some systems have mixed swizzling, in which an inter-object reference may be direct at some times and indirect at others; these systems are attempting to get some of the good properties of both direct and indirect swizzling. <p> For most applications, it is important to understand how performance degrades before the system stops completely. The next chapter considers details of when and how shrinking should take place for good performance. 93 6.6 Related Work 6.6.1 Pure Shrinking LOOM <ref> [39] </ref> was the first system with mechanisms similar to the swizzling and surrogates presented in this thesis. <p> decrement a counter at each object graph mutation; in contrast, a system using reverse reference lists must store a potentially large bag of reverse references for each object, and must insert addresses into these bags or remove pointers from these bags at each such mutation. 6.6.2 Pure Garbage Collection LOOM <ref> [39] </ref> built on an existing Smalltalk system, so instead of using a garbage collector it extended the reference counting scheme used for that system.
Reference: [40] <author> Alfons Kemper and Donald Kossmann. </author> <title> Adaptable pointer swizzling strategies in object bases. </title> <booktitle> In Proceedings of the 9th International Conference on Data Engineering, </booktitle> <pages> pages 155-162, </pages> <year> 1993. </year>
Reference-contexts: There is no consensus in the literature: Moss [52] reasoned that node marking and edge marking should have roughly similar performance, but a later paper by Hosking and Moss [34] suggested in a footnote that edge marking is "not competitive" with node marking. Kemper and Kossmann's study <ref> [40] </ref> concluded that there were significant differences among swizzling techniques on different workloads. They went so far as to propose type-specific and context-specific approaches to swizzling, so that applications could mix swizzling techniques for performance. <p> If it appears that performance could be significantly improved with smaller code, it may be worth revisiting the node marking scheme. 4.7 Related work As previously indicated, Moss [52] first categorized swizzling techniques as edge marking or node marking. Kemper and Kossmann <ref> [40] </ref> subsequently distinguished techniques based on their eagerness (eager vs. lazy) and directness (direct vs. indirect). I start from Kemper and Kossmann's terms to categorize related work on swizzling techniques. There are two relatively independent dimensions of swizzling techniques. <p> I start from Kemper and Kossmann's terms to categorize related work on swizzling techniques. There are two relatively independent dimensions of swizzling techniques. The first dimension is directness (direct, indirect, or mixed) and the second dimension is eagerness (eager or lazy). 46 Eager Lazy Indirect LOOM [39], others LIS <ref> [40] </ref> Mixed Thor node marking Thor edge marking with surrogates Persistent Smalltalk [33] Direct O 2 resident mode [4] Thor edge marking Exodus [73] Consider directness first. A direct swizzling technique translates an inter-object reference into the address of the object itself. <p> I am aware of three groups that have done swizzling studies, all using databases derived from the OO1 benchmark [14]: White and DeWitt [73], Hosking and Moss [33, 34], and Kemper and Kossmann <ref> [40] </ref>. White and DeWitt compared different implementations of lazy direct swizzling (edge marking) and swizzling at the granularity of pages (ObjectStore [42]). They found that swizzling on discovery is superior to swizzling on reference (Section 4.1.2 explains the difference). <p> However, a personal communication [35] describing their implementation in more detail explains that their edge marking scheme is not swizzling: instead, it is doing repeated lookups, and accordingly is not comparable to the edge marking described here. Kemper and Kossmann's study <ref> [40] </ref> concluded that there were significant differences among swizzling techniques on different workloads. <p> Although O 2 uses indirect swizzling, so that moving an object in the address space is relatively easy, the address of an O 2 object never changes while the object is in memory; there is no copying garbage collection. Kemper and Kossmann <ref> [40] </ref> studied a mechanism of reverse reference lists for doing storage management without using a garbage collector. Each object keeps a list of the objects that hold references to it.
Reference: [41] <author> Won Kim, Nat Ballou, Hong-Tai Chou, Jorge F. Garza, Darrell Woelk, and Jay Banerjee. </author> <title> Integrating an object-oriented programming system with a database system. </title> <booktitle> In Proceedings of the ACM Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA), </booktitle> <pages> pages 142-152, </pages> <year> 1988. </year>
Reference-contexts: Direct swizzling is more efficient than indirect swizzling in both space and time. However, indirect swizzling simplifies storage management because object descriptors make it easy to relocate or evict objects. Examples of systems using indirect swizzling are LOOM [39], Emerald [38], Orion <ref> [41] </ref> and Jasmine [36]. Some systems have mixed swizzling, in which an inter-object reference may be direct at some times and indirect at others; these systems are attempting to get some of the good properties of both direct and indirect swizzling. <p> The indirection through the ROT also means that it is straightforward to relocate an object within memory. Several other object-oriented databases (GemStone [8, 66], Orion <ref> [41] </ref>, Jasmine [36]) use basically the same cache structure as LOOM. We chose to use direct swizzling in Thor to avoid the time and space overheads caused by indirect swizzling.
Reference: [42] <author> Charles Lamb, Gordon Landis, Jack Orenstein, and Dan Weinreb. </author> <title> The ObjectStore database system. </title> <journal> Communications of the ACM, </journal> <volume> 34(10) </volume> <pages> 51-63, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: White and DeWitt compared different implementations of lazy direct swizzling (edge marking) and swizzling at the granularity of pages (ObjectStore <ref> [42] </ref>). They found that swizzling on discovery is superior to swizzling on reference (Section 4.1.2 explains the difference). They also showed that a software swizzling scheme using edge marking is competitive with ObjectStore, even though ObjectStore takes advantage of virtual memory hardware. <p> The comparable problem in a virtual memory system is a reference to an evicted page, which is handled by hardware. Although it is tempting to use such page-faulting hardware to assist object systems <ref> [42, 63] </ref> some evidence [34] suggests that such page-faulting hardware is ill-suited to support object operations, primarily because of the mismatch between the size of a typical object and the size of a typical page.
Reference: [43] <author> Butler Lampson and Howard Sturgis. </author> <title> Crash recovery in a distributed data storage system. </title> <type> Technical report, </type> <institution> Xerox Palo Alto Research Center, </institution> <year> 1979. </year>
Reference-contexts: Servers are specialized to hold data reliably and to provide it to clients on request, while clients are specialized to run applications and present information to people. A server needs a large amount of disk storage. It may be implemented with multiple disks for reliability <ref> [43] </ref>, or with multiple replicated computers to provide both high availability and high reliability [47]. With the cooperation of clients, servers implement concurrency control mechanisms [46] to ensure that groups of objects are updated consistently.
Reference: [44] <author> Samuel J. Le*er, Marshall Kirk McKusick, Michael J. Karels, and John S. Quarterman. </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Essentially, the lru policy is a very close approximation, while clock is only a coarse one-bit approximation, similar to what is commonly used for virtual memory systems (e.g. <ref> [44] </ref>).
Reference: [45] <author> A. Lempel and J. Ziv. </author> <title> On the complexity of finite sequences. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 22, </volume> <year> 1976. </year>
Reference-contexts: Fido uses a neural-net mechanism whose details are unimportant for this discussion. The data compression prefetcher adapts the Lempel-Ziv compression algorithm <ref> [45] </ref> to prefetching, replacing a repeated sequence of page accesses with a single prefetch in much the same way that a data compressor replaces sequences of characters with a single code. While both these techniques are powerful and general, they have a significant start-up cost.
Reference: [46] <author> Barbara Liskov, Mark Day, and Liuba Shrira. </author> <title> Distributed object management in Thor. </title> <editor> In M. Tamer Ozsu, Umesh Dayal, and Patrick Valduriez, editors, </editor> <booktitle> Distributed Object Management, </booktitle> <pages> pages 79-91. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1994. </year>
Reference-contexts: A server needs a large amount of disk storage. It may be implemented with multiple disks for reliability [43], or with multiple replicated computers to provide both high availability and high reliability [47]. With the cooperation of clients, servers implement concurrency control mechanisms <ref> [46] </ref> to ensure that groups of objects are updated consistently. In contrast to a server, a client needs a good display, and processing power and storage adequate to the application (s) being run by any particular user. Dividing the system into clients and servers has a number of advantages. <p> An important related result is that for the experiments performed, varying the prefetching policy has a larger effect on system performance than varying the cache management policy. 1.2 Experimental Limitations The conclusions of this thesis are based on experiments I ran with a prototype client-server object database called Thor <ref> [46] </ref>. Those experiments had two basic limitations. First, they were run with a particular synthetic workload. Second, they were run on a particular configuration of hardware and software. <p> For each chapter where there is related work, a section near the end of the chapter discusses that work and its relationship to the content of the chapter. 15 16 Chapter 2 System Model This thesis reports on experimental work done in the context of Thor <ref> [46] </ref>, a distributed object database system currently being implemented at MIT. This chapter presents a model of a distributed object database that abstracts away many of the details of Thor. <p> This chapter compares the performance of edge marking and node marking in Thor. The initial design of Thor <ref> [46] </ref> used a node-marking technique. Subsequently, I proposed an edge-marking 29 technique. It was difficult to assess the importance of the swizzling technique in the absence of data from an implementation. <p> This information allows the server to invalidate objects in a client cache that have been made obsolete by updates at the server <ref> [46] </ref>. The same information is also used for efficient concurrency control [1] and distributed garbage collection [48].
Reference: [47] <author> Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Liuba Shrira, and Michael Williams. </author> <title> Replication in the Harp file system. </title> <booktitle> In Proceedings of the ACM Symposium on Operating Systems Principles (SOSP), </booktitle> <pages> pages 226-238, </pages> <month> October </month> <year> 1991. </year> <month> 140 </month>
Reference-contexts: A server needs a large amount of disk storage. It may be implemented with multiple disks for reliability [43], or with multiple replicated computers to provide both high availability and high reliability <ref> [47] </ref>. With the cooperation of clients, servers implement concurrency control mechanisms [46] to ensure that groups of objects are updated consistently. In contrast to a server, a client needs a good display, and processing power and storage adequate to the application (s) being run by any particular user.
Reference: [48] <author> Umesh Maheshwari. </author> <title> Distributed garbage collection in a client-server, transactional, persistent object system. </title> <type> Technical Report MIT/LCS/TR-574, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1993. </year>
Reference-contexts: However, before such a comparison can be made, it is necessary to understand both how to manage an object cache and what the important parameters are for its performance. Copying objects to a client cache and managing that cache introduce new problems. Others have addressed aspects of storage management <ref> [48] </ref> and concurrency control [1]. The thesis addresses the following three performance-related problems: * implementing inter-object references; * bringing objects into the client cache; and * evicting objects from the client cache. The most important results are the following: 1. <p> This information allows the server to invalidate objects in a client cache that have been made obsolete by updates at the server [46]. The same information is also used for efficient concurrency control [1] and distributed garbage collection <ref> [48] </ref>. The server's information always represents a superset of the objects actually in the client's cache: no object can be in the client's cache without being recorded at the server, but the server may record an object that is not in use at the client. <p> Failing to keep the server up-to-date can cause the system's performance to degrade to the point where it behaves as though there were no prefetching, only single-object fetching. In addition, good performance of the system's concurrency control mechanism [1] and distributed garbage collector <ref> [48] </ref> also depend on having information at the server that is close to the actual state of the client. Correctness does not require updating of the server's information about the client state; the updating is intended to improve performance.
Reference: [49] <author> Salvatore T. </author> <month> March. </month> <title> Techniques for structuring database records. </title> <journal> Computing Surveys, </journal> <volume> 15(1) </volume> <pages> 45-79, </pages> <month> March </month> <year> 1983. </year>
Reference-contexts: The roots of the techniques used are typically found in the techniques developed for packing records into pages <ref> [60, 75, 59, 49] </ref>. A significant amount of work has also been done on the specific problems of clustering objects into pages [6, 31, 67, 62, 15, 28]. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems.
Reference: [50] <author> William J. McIver, Jr. and Roger King. </author> <title> Self-adaptive, on-line reclustering of complex object data. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 407-418, </pages> <year> 1994. </year>
Reference-contexts: Because of the dependence on clustering, a page caching system can have poor performance because an application's access pattern changes rapidly, because an application's access pattern is difficult to predict, or because multiple applications have conflicting access patterns for shared objects. Recent work by McIver and King <ref> [50] </ref> recognizes these problems and proposes on-line reclustering as a solution. This thesis proposes, implements, and measures a more radical approach: abandoning the use of pages as the unit of transfer between server and client. <p> As was shown by the sparse and dense traversals, very different computations sharing the same objects can benefit from dynamic prefetching. There has been some work arguing for dynamic reclustering <ref> [15, 50] </ref>; however, such reclustering is expensive compared to dynamically computing prefetch groups (since reclustering involves disk writes) and it is challenging to decide when it is worth reclustering.
Reference: [51] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: In a client/server system like Thor, the client cache management problem is decoupled from the problem of managing the server's persistent storage. 6.6.3 Shrinking and Garbage Collection Cooper et al. describe how they modified Standard ML of New Jersey (SML) <ref> [51] </ref> and implemented an SML-specific external pager for Mach so that VM cache management could take advantage of the knowledge of the SML garbage collector [19]. The garbage collector marked pages as discardable or nondiscardable based on their current role in the garbage collection process.
Reference: [52] <author> J. E. B. Moss. </author> <title> Working with persistent objects: To swizzle or not to swizzle. </title> <type> Technical Report 90-38, COINS, </type> <institution> University of Massachusetts - Amherst, </institution> <year> 1990. </year>
Reference-contexts: A system like Thor transfers object groups, not pages; Chapter 5 justifies that design choice. For this chapter the object-group-transfer architecture is simply assumed. In a system that transfers objects, there are two plausible granularities at which swizzling may take place: individual references or whole objects. Following Moss's terminology <ref> [52] </ref> I use edge marking as synonymous with swizzling at the granularity of individual references, and node marking as synonymous with swizzling whole objects. <p> The initial design of Thor [46] used a node-marking technique. Subsequently, I proposed an edge-marking 29 technique. It was difficult to assess the importance of the swizzling technique in the absence of data from an implementation. There is no consensus in the literature: Moss <ref> [52] </ref> reasoned that node marking and edge marking should have roughly similar performance, but a later paper by Hosking and Moss [34] suggested in a footnote that edge marking is "not competitive" with node marking. <p> Useful future work would include an examination of real applications running on Thor to determine their instruction cache miss rates. If it appears that performance could be significantly improved with smaller code, it may be worth revisiting the node marking scheme. 4.7 Related work As previously indicated, Moss <ref> [52] </ref> first categorized swizzling techniques as edge marking or node marking. Kemper and Kossmann [40] subsequently distinguished techniques based on their eagerness (eager vs. lazy) and directness (direct vs. indirect). I start from Kemper and Kossmann's terms to categorize related work on swizzling techniques. <p> They found that swizzling on discovery is superior to swizzling on reference (Section 4.1.2 explains the difference). They also showed that a software swizzling scheme using edge marking is competitive with ObjectStore, even though ObjectStore takes advantage of virtual memory hardware. Although an early analysis by Moss <ref> [52] </ref> matched my results, my results appear to differ from the more recent report of Hosking and Moss, who found edge marking "clearly uncompetitive" ([34], footnote 7).
Reference: [53] <author> J. Eliot B. Moss. </author> <title> Design of the Mneme persistent object store. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 8(2) </volume> <pages> 103-139, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: The intent is to capture the dominant effects of a generic computation in an object database. Accordingly, the experiments 11 involve read-only traversal of inter-object references. Fast traversal of inter-object references is a key factor that motivates the use of object databases instead of relational databases <ref> [53] </ref>. Use of a read-only workload separates this fundamental component of performance from the question of concurrency control mechanisms and their performance.
Reference: [54] <author> Andrew Myers. </author> <type> Personal communication, </type> <month> June </month> <year> 1994. </year>
Reference-contexts: So far, the measurements suggest that the values for our model are L = 13 and J = 12. These numbers are rather too high for the processor used <ref> [54] </ref>, suggesting that some of the instructions assigned a unit cost by this model in fact had a higher cost.
Reference: [55] <author> Andrew C. Myers. </author> <title> Fast object operations in a persistent programming system. </title> <type> Technical Report MIT/LCS/TR-599, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: For all of these measures, I am describing code generated by the DEC cxx compiler (C++ for OSF/1 AXP systems v1.2) running with optimization -O2 on a DEC 3000. I follow Myers's model <ref> [55] </ref>, assigning a cost of L to each load that is unlikely to hit in the hardware cache, a cost of J to each indirect or conditional jump instruction, and a cost of 1 to each other instruction.
Reference: [56] <author> James O'Toole. </author> <title> Garbage collecting the object cache. An informal working document., </title> <month> October </month> <year> 1992. </year>
Reference-contexts: The combination of shrinking and garbage collection in Thor has some of the same character as their system, but Thor applies the idea to individual objects instead of pages, and to a client object cache instead of a VM cache. O'Toole <ref> [56] </ref> has sketched a scheme for using replication garbage collection and shrinking (which he calls re-surrogating) to manage a cache of persistent objects.
Reference: [57] <author> Mark Palmer and Stanley B. Zdonik. </author> <title> Fido: A cache that learns to fetch. </title> <booktitle> In Proceedings of the 17th International Conference on Very Large Data Bases, </booktitle> <pages> pages 255-264, </pages> <year> 1991. </year>
Reference-contexts: Thor's prefetching is much more flexible than Smith's and similar work, since the units being prefetched are objects and they are being fetched from the server's memory rather than from disk. Both the Fido cache <ref> [57] </ref> and optimal prefetching using data compression [72] learn arbitrary repeated access patterns, and are correspondingly more powerful than the mechanisms described in this chapter. Fido uses a neural-net mechanism whose details are unimportant for this discussion.
Reference: [58] <author> R. Hugo Patterson, Garth A. Gibson, and M. Satyanarayanan. </author> <title> A status report on research in transparent informed prefetching. </title> <type> Technical Report CMU-CS-93-113, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: A crystal is an object that represents an explicitly- or implicitly-constructed group of objects. When the computation reaches the crystal, the associated group of objects is prefetched. The work on transparent informed prefetching <ref> [58] </ref> applies a similar approach in the context of Unix. Tait and Duchamp [70] describe a mechanism for file prefetching that attempts to work automatically, matching file access patterns to previously-seen file access patterns. It would be interesting to see if the same idea could be applied to object fetching.
Reference: [59] <author> Peter Scheuermann, Young Chul Park, and Edward Omiecinski. </author> <title> Heuristic reorganization of clustered files. </title> <editor> In W. Litwin and H.-J. Schek, editors, </editor> <booktitle> Proceedings of the 3rd International Conference on Foundations of Data Organization and Algorithms (FODO), </booktitle> <pages> pages 16-30. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: The roots of the techniques used are typically found in the techniques developed for packing records into pages <ref> [60, 75, 59, 49] </ref>. A significant amount of work has also been done on the specific problems of clustering objects into pages [6, 31, 67, 62, 15, 28]. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems.
Reference: [60] <author> Mario Schkolnick. </author> <title> A clustering algorithm for hierarchical structures. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 2(1) </volume> <pages> 27-44, </pages> <month> March </month> <year> 1977. </year> <month> 141 </month>
Reference-contexts: The roots of the techniques used are typically found in the techniques developed for packing records into pages <ref> [60, 75, 59, 49] </ref>. A significant amount of work has also been done on the specific problems of clustering objects into pages [6, 31, 67, 62, 15, 28]. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems.
Reference: [61] <author> Andre Seznec. </author> <title> A case for two-way skewed-associative caches. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 169-178, </pages> <year> 1993. </year>
Reference-contexts: The "replacement policy" of a processor cache is typically determined by the hardware cost of building a particular degree and flavor of associativity; for recent examples, see work on column-associative caches [2] or skewed-associative caches <ref> [61] </ref>. The designers of processor caches are also concerned with how to write back changes: see Jouppi's recent work [37] for an example. This sort of work is not applicable to object caches as described in this thesis, since objects are never written back except at transaction commit.
Reference: [62] <author> Karen Shannon and Richard Snodgrass. </author> <title> Semantic clustering. </title> <editor> In Alan Dearle, Gail M. Shaw, and Stanley B. Zdonik, editors, </editor> <title> Implementing Persistent Object Bases: </title> <booktitle> Principles and Practice., </booktitle> <pages> pages 389-402. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The roots of the techniques used are typically found in the techniques developed for packing records into pages [60, 75, 59, 49]. A significant amount of work has also been done on the specific problems of clustering objects into pages <ref> [6, 31, 67, 62, 15, 28] </ref>. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems. Accordingly, for dynamic prefetching to be of any value, it has to do something better than can be done by clustering objects into pages.
Reference: [63] <author> Vivek Singhal, Sheetal V. Kakkad, and Paul R. Wilson. </author> <title> Texas: An efficient, portable persistent store. </title> <booktitle> In Proceedings of the 5th International Workshop on Persistent Object Systems, </booktitle> <year> 1992. </year>
Reference-contexts: The comparable problem in a virtual memory system is a reference to an evicted page, which is handled by hardware. Although it is tempting to use such page-faulting hardware to assist object systems <ref> [42, 63] </ref> some evidence [34] suggests that such page-faulting hardware is ill-suited to support object operations, primarily because of the mismatch between the size of a typical object and the size of a typical page.
Reference: [64] <author> Alan Jay Smith. </author> <title> Sequentiality and prefetching in database systems. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 3(3) </volume> <pages> 223-247, </pages> <month> September </month> <year> 1978. </year>
Reference-contexts: In their proposed clustering technique, objects were first clustered into primary clusters, then reclustered into secondary clusters. Their report on prefetching [17] partially repudiates the arguments they made in favor of their clustering scheme. 5.5.3 Prefetching Early work on prefetching in databases, such as that by Smith <ref> [64] </ref>, depends on repeated sequential access to data pages. Smith's prefetcher uses the length of the most recent group of sequential accesses (the current run length) to determine how many additional pages to prefetch.
Reference: [65] <author> Alan Snyder. </author> <title> The essence of objects: Concepts and terms. </title> <journal> IEEE Software, </journal> <pages> pages 31-42, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: In the proposed standard terminology for object systems <ref> [65] </ref>, the invocation "c.to ()" is a request. It identifies an operation on the object c, but does not determine how the operation will be performed. 30 31 The code that actually runs in response to a request is called a method.
Reference: [66] <author> Marc San Soucie, Allen Otis, and Bob Bretl, </author> <month> October </month> <year> 1993. </year> <title> Personal communication in response to an early draft of the section on GemStone. </title>
Reference-contexts: The indirection through the ROT also means that it is straightforward to relocate an object within memory. Several other object-oriented databases (GemStone <ref> [8, 66] </ref>, Orion [41], Jasmine [36]) use basically the same cache structure as LOOM. We chose to use direct swizzling in Thor to avoid the time and space overheads caused by indirect swizzling.
Reference: [67] <author> James W. Stamos. </author> <title> Static grouping of small objects to enhance performance of a paged virtual memory. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(2) </volume> <pages> 155-180, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: Pseudopaging is intended to be an approximation of the prefetching performance of a realistic page-fetching system; accordingly, the clustering is not optimal, but it is not particularly bad either. In particular, this creation-order clustering is better than two of the static clusterings (breadth-first and depth-first) used by Stamos <ref> [67] </ref> in his study. It is less effective than what could be achieved by the most sophisticated clustering techniques [71], but it is also much less demanding of both computation and insight into the database. <p> The roots of the techniques used are typically found in the techniques developed for packing records into pages [60, 75, 59, 49]. A significant amount of work has also been done on the specific problems of clustering objects into pages <ref> [6, 31, 67, 62, 15, 28] </ref>. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems. Accordingly, for dynamic prefetching to be of any value, it has to do something better than can be done by clustering objects into pages. <p> Clustering can be seen as a particularly static, heavily-constrained technique for computing object groups of fixed size. There are relatively few good performance studies of different approaches to clustering. One is work by Stamos <ref> [67, 68] </ref>, who compared the LOOM persistent object system to a paged virtual 75 76 memory so as to understand the tradeoffs between paging and object swapping. Stamos's work differs from my work on Thor in three ways. <p> Second, Stamos considered only static grouping strategies (i.e. clustering, not prefetching). Third, Stamos considered a system with relatively small pages: 512-byte pages on a machine with 16-bit addresses. Stamos concluded <ref> [67] </ref> that * simple static clustering (such as depth-first or breadth-first based on static pointers) works better than a random arrangement of objects, * more elaborate schemes do not work significantly better than simple schemes, and * no simple scheme is clearly superior in all cases.
Reference: [68] <author> James William Stamos. </author> <title> A large object-oriented virtual memory: Grouping strategies, measurements, and performance. </title> <type> Technical Report SCG-82-2, </type> <institution> Xerox Palo Alto Research Center, </institution> <month> May </month> <year> 1982. </year>
Reference-contexts: Clustering can be seen as a particularly static, heavily-constrained technique for computing object groups of fixed size. There are relatively few good performance studies of different approaches to clustering. One is work by Stamos <ref> [67, 68] </ref>, who compared the LOOM persistent object system to a paged virtual 75 76 memory so as to understand the tradeoffs between paging and object swapping. Stamos's work differs from my work on Thor in three ways. <p> In a related technical report <ref> [68] </ref>, Stamos also showed that LOOM's object fetching/replacement performs better for a small memory than a system using page fetching/replacement, although LOOM's advantage varies inversely with the quality of the initial placement (clustering).
Reference: [69] <author> Andrew Straw, Fred Mellender, and Steve Riegel. </author> <title> Object management in a persistent Smalltalk system. </title> <journal> Software Practice and Experience, </journal> <volume> 19(8) </volume> <pages> 719-737, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: In a system with compaction, an allocation requires only changing the freespace pointer. Wilson's survey [74] concludes that reference counting systems have generally performed poorly compared to copying collectors, and there is nothing in the structure of Thor that would contradict that assessment. Alltalk <ref> [69] </ref> uses a mechanism that integrates garbage collection with the pushing and popping of frames as Smalltalk methods are called and return. This mechanism requires more control over the execution stack than Thor has.
Reference: [70] <author> Carl D. Tait and Dan Duchamp. </author> <title> Detection and exploitation of file working sets. </title> <booktitle> In Proceedings of the 11th Conference on Distributed Computing Systems, </booktitle> <pages> pages 2-9, </pages> <year> 1991. </year>
Reference-contexts: A crystal is an object that represents an explicitly- or implicitly-constructed group of objects. When the computation reaches the crystal, the associated group of objects is prefetched. The work on transparent informed prefetching [58] applies a similar approach in the context of Unix. Tait and Duchamp <ref> [70] </ref> describe a mechanism for file prefetching that attempts to work automatically, matching file access patterns to previously-seen file access patterns. It would be interesting to see if the same idea could be applied to object fetching.
Reference: [71] <author> Manolis M. Tsangaris and Jeffrey F. Naughton. </author> <title> On the performance of object clustering techniques. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 144-153, </pages> <year> 1992. </year>
Reference-contexts: With page caching, the mechanisms for fetching and cache management are simple because the units handled are all the same size; however, a page caching system must have its objects clustered into pages, and that clustering process is difficult <ref> [71] </ref>. A clustering of objects into pages is a static prediction of overall application access patterns. <p> In particular, this creation-order clustering is better than two of the static clusterings (breadth-first and depth-first) used by Stamos [67] in his study. It is less effective than what could be achieved by the most sophisticated clustering techniques <ref> [71] </ref>, but it is also much less demanding of both computation and insight into the database. The average pseudopage has about 60 objects in it, so we would expect dynamic prefetching of groups of 60 or more objects to beat pseudopaging. <p> Stamos's work is rather old, and one might think that newer work in the area would show different results. However, Tsangaris and Naughton <ref> [71] </ref> recently compared the performance of a number of clustering techniques on a number of workloads. They clustered the data based on "training" workloads, then measured performance for "testing" workloads that might be quite different.
Reference: [72] <author> Jeffrey Scott Vitter and P. Krishnan. </author> <title> Optimal prefetching via data compression. </title> <booktitle> In Proceedings of the 32nd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 121-130, </pages> <year> 1991. </year>
Reference-contexts: Thor's prefetching is much more flexible than Smith's and similar work, since the units being prefetched are objects and they are being fetched from the server's memory rather than from disk. Both the Fido cache [57] and optimal prefetching using data compression <ref> [72] </ref> learn arbitrary repeated access patterns, and are correspondingly more powerful than the mechanisms described in this chapter. Fido uses a neural-net mechanism whose details are unimportant for this discussion. <p> There is still room for improvement in the performance of the system when fetching. The results of this thesis suggest that prefetching is the area most likely to yield performance gains. Possibilities include different prefetching algorithms or storing application-specific information with objects. Vitter and Krishnan <ref> [72] </ref> have studied the use of data compression algorithms to achieve optimal prefetching and Curewitz, Krishnan and Vitter [20] have applied practical prefetchers derived from this theory to database traces.
Reference: [73] <author> Seth J. White and David J. DeWitt. </author> <title> A performance study of alternative object faulting and pointer swizzling strategies. </title> <booktitle> In Proceedings of the 18th VLDB Conference, </booktitle> <pages> pages 419-431, </pages> <year> 1992. </year> <month> 142 </month>
Reference-contexts: Swizzling on discovery ensures that every reference used has been swizzled in the cached object. Swizzling on reference avoids unnecessary fetches but often fails to gain any significant benefit from swizzling. How, then, should one choose between these alternatives? White and DeWitt have shown <ref> [73] </ref> that computations often fetch a reference from an object into a local variable before using that reference. This is true even for implementations of methods. <p> The first dimension is directness (direct, indirect, or mixed) and the second dimension is eagerness (eager or lazy). 46 Eager Lazy Indirect LOOM [39], others LIS [40] Mixed Thor node marking Thor edge marking with surrogates Persistent Smalltalk [33] Direct O 2 resident mode [4] Thor edge marking Exodus <ref> [73] </ref> Consider directness first. A direct swizzling technique translates an inter-object reference into the address of the object itself. Edge marking in Thor, as described in this chapter, is an example of direct swizzling. Similarly, Exodus [73] uses direct swizzling, as does O 2 [4] in its so-called resident mode. <p> surrogates Persistent Smalltalk [33] Direct O 2 resident mode [4] Thor edge marking Exodus <ref> [73] </ref> Consider directness first. A direct swizzling technique translates an inter-object reference into the address of the object itself. Edge marking in Thor, as described in this chapter, is an example of direct swizzling. Similarly, Exodus [73] uses direct swizzling, as does O 2 [4] in its so-called resident mode. In contrast, an indirect swizzling technique translates such a reference into the address of a descriptor for the object, which in turn contains the address of the object itself. <p> In contrast, a lazy swizzling technique allows object fields to contain names or swizzled pointers, converting names to pointers only as needed. Edge marking as described in this chapter is an example of a lazy swizzling technique; Exodus <ref> [73] </ref> is another example of a lazy swizzling system. We can combine these two dimensions into the table of Figure 4-9, which shows where various systems fit in. LIS, which is shown as an example of lazy indirect swizzling, is not actually a system. <p> However, when objects are to be evicted from the cache, surrogates can be useful even if fetched objects are swizzled using edge marking. I am aware of three groups that have done swizzling studies, all using databases derived from the OO1 benchmark [14]: White and DeWitt <ref> [73] </ref>, Hosking and Moss [33, 34], and Kemper and Kossmann [40]. White and DeWitt compared different implementations of lazy direct swizzling (edge marking) and swizzling at the granularity of pages (ObjectStore [42]). They found that swizzling on discovery is superior to swizzling on reference (Section 4.1.2 explains the difference).
Reference: [74] <author> Paul R. Wilson. </author> <title> Uniprocessor garbage collection techniques. </title> <editor> In Y. Bekkers and J. Cohen, editors, </editor> <booktitle> International Workshop on Memory Management, </booktitle> <pages> pages 1-42. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year> <note> Lecture Notes in Computer Science 637. </note>
Reference-contexts: As previously noted, reference counting garbage collectors have trouble competing with copying garbage collectors <ref> [74] </ref>. <p> Because of the use of reference counting (which 95 does not compact of storage), allocation was considerably more complex and costly in LOOM than it is in Thor. In a system with compaction, an allocation requires only changing the freespace pointer. Wilson's survey <ref> [74] </ref> concludes that reference counting systems have generally performed poorly compared to copying collectors, and there is nothing in the structure of Thor that would contradict that assessment.
Reference: [75] <author> C.T. Yu, Cheing-Mei Suen, K. Lam, and M.K. Siu. </author> <title> Adaptive record clustering. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 10(2) </volume> <pages> 180-204, </pages> <month> June </month> <year> 1985. </year> <pages> 143 144 </pages>
Reference-contexts: The roots of the techniques used are typically found in the techniques developed for packing records into pages <ref> [60, 75, 59, 49] </ref>. A significant amount of work has also been done on the specific problems of clustering objects into pages [6, 31, 67, 62, 15, 28]. Fetching a multi-object page instead of a single object is the only prefetching done in most object systems.
References-found: 75

