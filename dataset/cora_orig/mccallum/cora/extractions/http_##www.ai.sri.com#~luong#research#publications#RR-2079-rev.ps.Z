URL: http://www.ai.sri.com/~luong/research/publications/RR-2079-rev.ps.Z
Refering-URL: http://www.ai.sri.com/~luong/research/publications/publications.html
Root-URL: 
Title: Motion of an Uncalibrated Stereo Rig: Self-Calibration and Metric Reconstruction  PROGRAMME 4  
Author: Zhengyou Zhang Quang-Tuan Luong Olivier Faugeras Robotique, 
Note: N  
Affiliation: INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE  image et vision  
Date: 1994  2079 Octobre 1993  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D. Brown, </author> <title> "Close-range camera calibration," </title> <booktitle> Photogrammetric Engineering, </booktitle> <pages> pp. 855-866, </pages> <year> 1971. </year>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry <ref> [1, 3] </ref> or in Computer Vision and Robotics [26, 8, 13, 27, 24, 29, 30] (see [28] for a recent review). <p> Denoting the homogeneous coordinates of a vector x = [x; y; ] T by ~ x, i.e., ~ x = <ref> [x; y; ; 1] </ref> T , we have s ~ m = P ~ M. The basic assumption behind this model is that the relationship between the world coordinates and the pixel coordinates is linear projective. <p> Without loss of generality, y 1 can be a point at infinity with the projective parameter t 1 such that y 1 = <ref> [1; t 1 ; 0] </ref> T .
Reference: [2] <author> R. Deriche and T. Blaszka, </author> <title> "Recovering and characterizing image features using an efficient model based approach," </title> <booktitle> in Proc. IEEE Conf. Comput. Vision Pattern Recog., </booktitle> <address> (New York, NY), </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Two CCD cameras with resolution 512 fi 512 are used. The points of interest used for self-calibration are also shown as indicated by the white crosses. These points are extracted with sub-pixel accuracy by an interactive program of Deriche and Blaszka <ref> [2] </ref>. However, a few points, especially those on the background are not well localized.
Reference: [3] <author> W. Faig, </author> <title> "Calibration of close range photogrammetry systems: mathematical formulation," </title> <journal> Photogrammetric engineering and remote sensing, </journal> <volume> vol. 41, no. 12, </volume> <pages> pp. 1479-1486, </pages> <year> 1975. </year>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry <ref> [1, 3] </ref> or in Computer Vision and Robotics [26, 8, 13, 27, 24, 29, 30] (see [28] for a recent review).
Reference: [4] <author> O. D. Faugeras, </author> <title> Three-Dimensional Computer Vision: A Geometric Viewpoint. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: Once we have computed ff u and ff v , we can compute the essential matrix by E = A T FA. The rotation and translation are then computed from E by any standard methods such as those described in <ref> [6, 31, 4] </ref>. We thus compute ff ul , ff vl , R l and t l for the left camera from the fundamental matrix F ll .
Reference: [5] <author> O. Faugeras, Q.-T. Luong, and S. Maybank, </author> <title> "Camera self-calibration: theory and experiments," </title> <booktitle> in Proc. Second European Conf. </booktitle> <publisher> Comput. </publisher> <editor> Vision (G. Sandini, </editor> <publisher> ed.), </publisher> <pages> pp. 563-578, </pages> <note> Springer-Verlag, Lecture Notes in Computer Science 588, </note> <month> May </month> <year> 1992. </year>
Reference-contexts: However, the algorithm is very sensitive to noise, and is of no practical use. Luong, in cooperation with them, has developed a real practical system as long as the points of interest can be located with sub-pixel precision, say 0.2 pixels, in image planes <ref> [15, 5] </ref>. In this paper, we describe a self-calibration method for a binocular stereo rig from one displacement using a simplified camera model (i.e., the principal points are known). <p> Equation (4) is a fundamental constraint underlying any two images if they are perspective projections of one and the same scene. Let F = A T 2 TRA 1 1 , F is known as the fundamental matrix of the two images <ref> [15, 5] </ref>.
Reference: [6] <author> O. Faugeras, F. Lustman, and G. Toscani, </author> <title> "Motion and structure from motion from point and line matches," </title> <booktitle> in Proc. First Int'l Conf. Comput. Vision, </booktitle> <address> (London, UK), </address> <pages> pp. 25-34, </pages> <year> 1987. </year>
Reference-contexts: Once we have computed ff u and ff v , we can compute the essential matrix by E = A T FA. The rotation and translation are then computed from E by any standard methods such as those described in <ref> [6, 31, 4] </ref>. We thus compute ff ul , ff vl , R l and t l for the left camera from the fundamental matrix F ll .
Reference: [7] <author> O. Faugeras and L. Robert, </author> <title> "What can two images tell us about a third one ?," Int'l J. </title> <journal> Comput. Vision, </journal> <note> 1994. accepted for publication. Also INRIA Research Report No. </note> <year> 2018, 1993. </year>
Reference-contexts: These two epipolar lines are the intersections of the plane going through the three optical centers (the so-called trifocal plane <ref> [7] </ref>) with I 1 and I 4 , respectively. Thus, we observe [7]: * the two epipolar lines correspond to each other between I 1 and I 4 , and * the two epipoles e 14 and e 41 must lie on these two lines, respectively. <p> These two epipolar lines are the intersections of the plane going through the three optical centers (the so-called trifocal plane <ref> [7] </ref>) with I 1 and I 4 , respectively. Thus, we observe [7]: * the two epipolar lines correspond to each other between I 1 and I 4 , and * the two epipoles e 14 and e 41 must lie on these two lines, respectively.
Reference: [8] <author> O. Faugeras and G. Toscani, </author> <title> "The calibration problem for stereo," </title> <booktitle> in Proc. IEEE Conf. Com-put. Vision Pattern Recog., </booktitle> <address> (Miami, FL), </address> <pages> pp. 15-20, </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1986. </year> <note> INRIA Self-Calibration and Metric Reconstruction of an Uncalibrated Stereo 21 </note>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry [1, 3] or in Computer Vision and Robotics <ref> [26, 8, 13, 27, 24, 29, 30] </ref> (see [28] for a recent review). The usual method of calibration is to compute cameras parameters from one or more images of an object of known size and shape, for example, a flat plate with a regular pattern marked on it. <p> We have made such simplification for the following reasons: * With the current technology, the angle can be made very close to =2. Indeed, we have carried out a large number of experiments on our CCD cameras using a classical calibration method <ref> [8] </ref>, and the differences between the estimated and =2 are found to be in the order of 10 6 radians. * The position of the principal point is in practice very close to the image center. On the other hand, it is very difficult to be precisely estimated. <p> On the other hand, it is very difficult to be precisely estimated. To show this, Fig. 3a shows three images taken from three different positions by the same camera. The corners on the grids have been used to estimate the intrinsic parameters using a classical calibration method <ref> [8] </ref>. The results are given in Fig. 3b. We see that the difference in u 0 and v 0 is quite big from position to position. Note that this simplification has also been adopted by many researchers [26, 12].
Reference: [9] <author> R. </author> <title> Hartley, "Estimation of relative camera positions for uncalibrated cameras," </title> <booktitle> in Proc. Second European Conf. Comput. Vision, </booktitle> <pages> pp. 579-587, </pages> <year> 1992. </year>
Reference-contexts: The motion rigidity provides several constraints on the camera intrinsic parameters. They are more commonly known as the epipolar constraint , and can be expressed as a 3 fi 3, so-called fundamental matrix . Hartley <ref> [9] </ref> proposed a singular-value-decomposition method to compute the focal lengths from a pair of images if all other cameras parameters are known. Trivedi [25] tried to determine only the coordinates of the principal point of a camera. Maybank and Faugeras [18] proposed a theory of self-calibration.
Reference: [10] <author> B. Horn, </author> <title> "Closed-form solution of absolute orientation using unit quaternions," </title> <journal> Journal of the Optical Society of America A, </journal> <volume> vol. 7, </volume> <pages> pp. 629-642, </pages> <month> Apr. </month> <year> 1987. </year>
Reference-contexts: In particular, he should see two planes in the foreground. To give an idea of the quantitative performance, we consider the points on the grid pattern because we have manually measured their positions. Using an algorithm similar to that described in <ref> [10] </ref>, we are able to compute the scalar factor, the rotation matrix and the translation between the points reconstructed and those measured manually. The scale computed is 301.69.
Reference: [11] <author> T. Huang and O. Faugeras, </author> <title> "Some properties of the E matrix in two-view motion estimation," </title> <journal> IEEE Trans. PAMI, </journal> <volume> vol. 11, </volume> <pages> pp. 1310-1312, </pages> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: Consider now the case of the left camera, i.e., F ll . For the reason of simplicity, the subscript will be omitted. From the definition of F, we have E = A T FA, where E = TR is called the essential matrix. As is well known <ref> [11] </ref>, E is subject to two independent polynomial constraints in addition to det E = 0. This implies that the entries of A are subject to two independent polynomial constraints inherited from E. As there are only two unknowns, ff u and ff v , they can then be solved.
Reference: [12] <author> K. Kanatani and Y. Onodera, </author> <title> "Anatomy of camera calibration using vanishing points," </title> <journal> IEICE transactions on informations and systems, </journal> <volume> vol. E74, </volume> <pages> pp. 3369-3378, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: The results are given in Fig. 3b. We see that the difference in u 0 and v 0 is quite big from position to position. Note that this simplification has also been adopted by many researchers <ref> [26, 12] </ref>. They claim that a deviation of the location of the principal point by a dozen of pixels from the real location does not produce any severe distortion in 3-D reconstruction.
Reference: [13] <author> R. Lenz and R. Tsai, </author> <title> "Techniques for calibrating of the scale factor and image center for high accuracy 3D machine vision metrology," </title> <booktitle> in Proc. Int'l Conf. Robotics Automation, </booktitle> <address> (Raleigh, NC), </address> <pages> pp. 68-75, </pages> <year> 1987. </year>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry [1, 3] or in Computer Vision and Robotics <ref> [26, 8, 13, 27, 24, 29, 30] </ref> (see [28] for a recent review). The usual method of calibration is to compute cameras parameters from one or more images of an object of known size and shape, for example, a flat plate with a regular pattern marked on it.
Reference: [14] <author> H. Longuet-Higgins, </author> <title> "A computer algorithm for reconstructing a scene from two projections," </title> <journal> Nature, </journal> <volume> vol. 293, </volume> <pages> pp. 133-135, </pages> <year> 1981. </year>
Reference-contexts: This is the well-known co-planarity constraint or epipolar equation in solving motion and structure from motion problems when the intrinsic parameters of the cameras are known <ref> [14] </ref>. Let the displacement from the first camera to the second be (R; t). Let m 1 and m 2 be the images of a 3-D point M on the cameras.
Reference: [15] <institution> Q.-T. Luong, Matrice fondamentale et calibration visuelle sur l'environnement: Vers une plus grande autonomie des systemes robotiques. Dissertation, University of Paris XI, Orsay, Paris, France, </institution> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: However, the algorithm is very sensitive to noise, and is of no practical use. Luong, in cooperation with them, has developed a real practical system as long as the points of interest can be located with sub-pixel precision, say 0.2 pixels, in image planes <ref> [15, 5] </ref>. In this paper, we describe a self-calibration method for a binocular stereo rig from one displacement using a simplified camera model (i.e., the principal points are known). <p> Equation (4) is a fundamental constraint underlying any two images if they are perspective projections of one and the same scene. Let F = A T 2 TRA 1 1 , F is known as the fundamental matrix of the two images <ref> [15, 5] </ref>. <p> can think of the fundamental matrix as providing the two epipoles (i.e., e 1 and e 2 , the vertexes of the two pencils of epipolar lines) and the 3 parameters of the homography between these two pencils, and this is the only geometric information available from two uncalibrated images <ref> [18, 15] </ref>. This implies that the fundamental matrix has only seven degrees of freedom. Indeed, it is only defined up to a scale factor and its determinant is zero. Geometrically, F ~ m 1 defines the epipolar line of point m 1 in the second image. <p> The epipoles (e 1 and e 2 ) and the homography coefficients (a, b, c and d) can be computed from the fundamental matrix F. The reader is referred to <ref> [18, 15] </ref> for more about the epipolar transformation and the Kruppa equations. <p> However, the self calibration may be less stable because a larger set of unknowns is involved in the minimization leaving less constraint on the solution, as noticed by Luong <ref> [15] </ref> in calibrating a single camera from three views. We have not yet implemented this method. 8 Conclusion In this paper, we have described a new method for calibrating a stereo rig by moving it in an environment without using any reference points (self-calibration).
Reference: [16] <author> Q.-T. Luong, R. Deriche, O. Faugeras, and T. Papadopoulo, </author> <title> "On determining the fundamental matrix: Analysis of different methods and experimental results," </title> <institution> Rapport de Recherche 1894, INRIA Sophia-Antipolis, France, </institution> <year> 1993. </year>
Reference-contexts: Several methods have been proposed in <ref> [16] </ref>. We have used a linear least-squares method followed by a non-quadratic minimization to improve the results. Consider now the case of the left camera, i.e., F ll . For the reason of simplicity, the subscript will be omitted.
Reference: [17] <author> D. Marr and T. Poggio, </author> <title> "A computational theory of human stereo vision," </title> <booktitle> in Proc. </booktitle> <publisher> Royal Society London, </publisher> <pages> pp. 301-328, </pages> <year> 1979, </year> <editor> B. </editor> <volume> 204. </volume>
Reference-contexts: 1 Introduction It is well recognized <ref> [17, 19, 20] </ref> that stereoscopic cues play an important role in understanding the 3-D environment surrounded us and provide a robust way for 3-D reconstruction.
Reference: [18] <author> S. Maybank and O. Faugeras, </author> <title> "A theory of self-calibration of a moving camera," </title> <journal> Int'l J. Comput. Vision, </journal> <volume> vol. 8, </volume> <pages> pp. 123-152, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: One problem is that it is impossible to calibrate online, while the cameras are involved in a visual task <ref> [18] </ref>. Any change of camera calibration occurring during the performance of the task cannot be corrected without interrupting the task. <p> Hartley [9] proposed a singular-value-decomposition method to compute the focal lengths from a pair of images if all other cameras parameters are known. Trivedi [25] tried to determine only the coordinates of the principal point of a camera. Maybank and Faugeras <ref> [18] </ref> proposed a theory of self-calibration. They showed that a camera can be in general completely calibrated from three different displacements. At the same time, they proposed an algorithm using tools from algebraic geometry. However, the algorithm is very sensitive to noise, and is of no practical use. <p> can think of the fundamental matrix as providing the two epipoles (i.e., e 1 and e 2 , the vertexes of the two pencils of epipolar lines) and the 3 parameters of the homography between these two pencils, and this is the only geometric information available from two uncalibrated images <ref> [18, 15] </ref>. This implies that the fundamental matrix has only seven degrees of freedom. Indeed, it is only defined up to a scale factor and its determinant is zero. Geometrically, F ~ m 1 defines the epipolar line of point m 1 in the second image. <p> This implies that the entries of A are subject to two independent polynomial constraints inherited from E. As there are only two unknowns, ff u and ff v , they can then be solved. Let us now follow the theory of self-calibration developed by Maybank and Faugeras <ref> [18] </ref>. Consider the absolute conic: x 2 1 + x 2 3 = 0, x 4 = 0. <p> The epipoles (e 1 and e 2 ) and the homography coefficients (a, b, c and d) can be computed from the fundamental matrix F. The reader is referred to <ref> [18, 15] </ref> for more about the epipolar transformation and the Kruppa equations.
Reference: [19] <author> J. E. W. Mayhew and J. P. </author> <title> Frisby, "Psychophysical and computational studies towards a theory of human stereopsis," </title> <journal> Artif. Intell., </journal> <volume> vol. 17, </volume> <pages> pp. 349-385, </pages> <year> 1981. </year>
Reference-contexts: 1 Introduction It is well recognized <ref> [17, 19, 20] </ref> that stereoscopic cues play an important role in understanding the 3-D environment surrounded us and provide a robust way for 3-D reconstruction.
Reference: [20] <author> J. Mayhew and J. Frisby, eds., </author> <title> 3D Model Recognition from Stereoscopic Cues. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction It is well recognized <ref> [17, 19, 20] </ref> that stereoscopic cues play an important role in understanding the 3-D environment surrounded us and provide a robust way for 3-D reconstruction.
Reference: [21] <author> J. L. Mundy and A. Zisserman, eds., </author> <title> Geometric invariance in computer vision. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: The basic assumption behind this model is that the relationship between the world coordinates and the pixel coordinates is linear projective. This allows us to use the powerful tools of projective geometry, which is emerging as an attractive framework for computer vision <ref> [21] </ref>. With the state of the art of the technology, camera distortion is reasonably small, and the pinhole model is thus a good approximation.
Reference: [22] <author> Numerical Algorithms Group, </author> <title> NAg, FORTRAN Library Manual, </title> <type> mark 14 ed., </type> <year> 1990. </year>
Reference-contexts: The minimization is performed by the Nag routine E04GDF, which is a modified Gauss-Newton algorithm for finding an unconstrained minimum of a sum of squares of M nonlinear functions in N variables (M N ) <ref> [22] </ref>. It demands the first derivative of the objective function and an initial estimate of the intrinsic and extrinsic parameters to be supplied. In the next section, we shall describe how to compute the initial estimation.
Reference: [23] <author> C. C. Slama, ed., </author> <title> Manual of Photogrammetry. </title> <journal> American Society of Photogrammetry, </journal> <note> fourth ed., </note> <year> 1980. </year>
Reference-contexts: However, it is clear from Eq. (4) that a translation can only be determined up to a scale. We thus normalize each translation such that its norm is 1. More precisely, each translation is represented by its spherical coordinates. A rotation is described by the Rodrigues matrix <ref> [23] </ref>: R = 1 + (a 2 + b 2 + c 2 )=4 6 1 + (a 2 b 2 c 2 )=4 c + ab=2 b + ac=2 b + ac=2 a + bc=2 1 + (a 2 b 2 + c 2 )=4 7 A rotation is thus
Reference: [24] <author> G. Toscani, </author> <title> Systeme de Calibration Optique et Perception du Mouvement en Vision Artificielle. </title> <type> Dissertation, </type> <institution> University of Paris XI, Orsay, Paris, France, </institution> <year> 1987. </year>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry [1, 3] or in Computer Vision and Robotics <ref> [26, 8, 13, 27, 24, 29, 30] </ref> (see [28] for a recent review). The usual method of calibration is to compute cameras parameters from one or more images of an object of known size and shape, for example, a flat plate with a regular pattern marked on it.
Reference: [25] <author> H. P. Trivedi, </author> <title> "Can multiple views make up for lack of camera registration," </title> <journal> Image and Vision Computing, </journal> <volume> vol. 6, </volume> <pages> pp. 29-32, </pages> <month> Feb. </month> <year> 1988. </year> <note> RR n-2079 22 Z. </note> <author> Zhang, Q.-T. Luong, O. </author> <note> Faugeras </note>
Reference-contexts: They are more commonly known as the epipolar constraint , and can be expressed as a 3 fi 3, so-called fundamental matrix . Hartley [9] proposed a singular-value-decomposition method to compute the focal lengths from a pair of images if all other cameras parameters are known. Trivedi <ref> [25] </ref> tried to determine only the coordinates of the principal point of a camera. Maybank and Faugeras [18] proposed a theory of self-calibration. They showed that a camera can be in general completely calibrated from three different displacements.
Reference: [26] <author> R. Tsai, </author> <title> "An efficient and accurate camera calibration technique for 3D machine vision," </title> <booktitle> in Proc. IEEE Conf. Comput. Vision Pattern Recog., </booktitle> <address> (Miami, FL), </address> <pages> pp. 364-374, </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1986. </year>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry [1, 3] or in Computer Vision and Robotics <ref> [26, 8, 13, 27, 24, 29, 30] </ref> (see [28] for a recent review). The usual method of calibration is to compute cameras parameters from one or more images of an object of known size and shape, for example, a flat plate with a regular pattern marked on it. <p> The results are given in Fig. 3b. We see that the difference in u 0 and v 0 is quite big from position to position. Note that this simplification has also been adopted by many researchers <ref> [26, 12] </ref>. They claim that a deviation of the location of the principal point by a dozen of pixels from the real location does not produce any severe distortion in 3-D reconstruction.
Reference: [27] <author> R. Tsai and R. Lenz, </author> <title> "A new technique for fully autonomous and efficient 3D robotics hand-eye calibration," </title> <booktitle> in Proc. Int'l Symposium Robotics Res., </booktitle> <address> (Santa Cruz, CA), </address> <month> Aug. </month> <year> 1987. </year>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry [1, 3] or in Computer Vision and Robotics <ref> [26, 8, 13, 27, 24, 29, 30] </ref> (see [28] for a recent review). The usual method of calibration is to compute cameras parameters from one or more images of an object of known size and shape, for example, a flat plate with a regular pattern marked on it.
Reference: [28] <author> R. Tsai, </author> <title> "Synopsis of recent progress on camera calibration for 3D machine vision," in The Robotics Review (O. </title> <editor> Khatib, J. Craig, and T. Lozano-Pirez, </editor> <booktitle> eds.), </booktitle> <pages> pp. 147-159, </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry [1, 3] or in Computer Vision and Robotics [26, 8, 13, 27, 24, 29, 30] (see <ref> [28] </ref> for a recent review). The usual method of calibration is to compute cameras parameters from one or more images of an object of known size and shape, for example, a flat plate with a regular pattern marked on it.
Reference: [29] <author> G. Wei and S. Ma, </author> <title> "Two plane camera calibration: A unified model," </title> <booktitle> in Proc. IEEE Conf. Comput. Vision Pattern Recog., (Hawaii), </booktitle> <pages> pp. 133-138, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry [1, 3] or in Computer Vision and Robotics <ref> [26, 8, 13, 27, 24, 29, 30] </ref> (see [28] for a recent review). The usual method of calibration is to compute cameras parameters from one or more images of an object of known size and shape, for example, a flat plate with a regular pattern marked on it.
Reference: [30] <author> J. Weng, P. Cohen, and M. Herniou, </author> <title> "Camera calibration with distorton models and accuracy evaluation," </title> <journal> IEEE Trans. PAMI, </journal> <volume> vol. 14, no. 10, </volume> <pages> pp. 965-980, </pages> <year> 1992. </year>
Reference-contexts: This is the purpose of camera calibration. A wealth of work on camera calibration has been carried out by researchers either in Photogrammetry [1, 3] or in Computer Vision and Robotics <ref> [26, 8, 13, 27, 24, 29, 30] </ref> (see [28] for a recent review). The usual method of calibration is to compute cameras parameters from one or more images of an object of known size and shape, for example, a flat plate with a regular pattern marked on it.
Reference: [31] <author> J. Weng, T. Huang, and N. Ahuja, </author> <title> "Motion and structure from two perspective views: Algorithms, error analysis and error estimation," </title> <journal> IEEE Trans. PAMI, </journal> <volume> vol. 11, </volume> <pages> pp. 451-476, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Once we have computed ff u and ff v , we can compute the essential matrix by E = A T FA. The rotation and translation are then computed from E by any standard methods such as those described in <ref> [6, 31, 4] </ref>. We thus compute ff ul , ff vl , R l and t l for the left camera from the fundamental matrix F ll .
Reference: [32] <author> Z. Zhang, R. Deriche, O. Faugeras, and Q.-T. Luong, </author> <title> "A robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry," </title> <type> Research Report 2273, </type> <institution> INRIA Sophia-Antipolis, France, </institution> <month> May </month> <year> 1994. </year> <note> submitted to Artificial Intelligence Journal. </note>
Reference-contexts: In order to apply the technique described in this paper, we must establish correspondences between two images (stereo or temporal) with unknown epipolar geometry. This is a difficult problem. We have recently developed an algorithm to solve it, and very good results have been obtained <ref> [33, 32] </ref>. The idea is to establish matches through the recovery of the unknown epipolar geometry. <p> The epipolar geometry can then be accurately estimated using a meaningful image criterion. This algorithm produces the fundamental matrix as well as the correspondences between two images. The executable code and the report <ref> [32] </ref> are available through anonymous ftp on krakatoa.inria.fr in the directory pub/tmp/zhang.

References-found: 32

