URL: http://www.ri.cmu.edu/afs/cs/project/stereo-machine/www/iros95.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs/project/stereo-machine/www/StereoMachine.html
Root-URL: 
Title: Development of a Video-Rate Stereo Machine  
Author: Takeo Kanade, Hiroshi Kano, Shigeru Kimura Atsushi Yoshida, Kazuo Oda 
Date: August 5-9, 1995,  
Note: Proceedings of International Robotics and Systems Conference (IROS95)  
Address: 5000 Forbes Ave., Pittsburgh PA 15213  Pittsburgh PA.  
Affiliation: Robotics Institute, Carnegie Mellon University  
Abstract: A video-rate stereo machine has been developed at CMU with the capability of generating a dense range map, aligned with an intensity image, at the video rate. The target performance of the CMU video-rate stereo machine is: 1) multi image input of 6 cameras; 2) high throughput of 30 million pointdisparity measurement per second; 3) high frame rate of 30 frame/sec; 4) a dense depth map of 256 240 pixels; 5) disparity search range of up to 60 pixels; 6) high precision of up to 7 bits (with interpolation); 7) uncertainty estimation available for each pixel. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Nicholas Ayache and Francis Lustman, </author> <title> Trinocular stereovi-sion for robotics. </title> <type> Technical Report 1086, </type> <institution> INRIA, </institution> <month> Sept. </month> <year> 1989. </year>
Reference: [2] <author> Pascal Fua, </author> <title> A parallel stereo algorithm that produces dense depth maps and preserves image features. </title> <type> Technical Report 1369, </type> <institution> Unite de Recherche, INRIA-Sophia Antipolis, France, </institution> <month> January </month> <year> 1991. </year>
Reference: [3] <author> Ali E.Kayaalp and James L. Eckman, </author> <title> A pipeline architecture for near real-time stereo range detection. </title> <type> Technical Report GDLS-AI-TR-88-1, </type> <institution> General Dynamics AI Lab, </institution> <month> November </month> <year> 1988. </year>
Reference: [4] <author> L.H.Matthies, </author> <title> Stereo vision for planetary rovers: stochastic modeling to near real time implementation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 8 </volume> (1):71-91,1992. 
Reference-contexts: The PRISM3 system, developed by Teleos [6], the JPL stereo implemented on DataCube <ref> [4] </ref>, CMUs Warp-based multi-baseline stereo [9], and INRIAs system [13] are the four most advanced real-time stereo systems; yet they do not provide a complete video-rate output of range as dense as the input image with low latency.
Reference: [5] <author> T.Nakahara and T.Kanade, </author> <title> Experiments in multiple-baseline stereo. </title> <type> Technical report, </type> <institution> Carnegie Mellon University, Computer Science Department, </institution> <month> August </month> <year> 1992. </year>
Reference: [6] <author> H.K.Nishihara, </author> <title> Real-time implementation of a sign-correlation algorithm for image-matching. </title> <note> (Draft) Teleos Research, </note> <month> February </month> <year> 1990. </year>
Reference-contexts: The PRISM3 system, developed by Teleos <ref> [6] </ref>, the JPL stereo implemented on DataCube [4], CMUs Warp-based multi-baseline stereo [9], and INRIAs system [13] are the four most advanced real-time stereo systems; yet they do not provide a complete video-rate output of range as dense as the input image with low latency.
Reference: [7] <author> Masatoshi Okutomi and Takeo Kanade, </author> <title> A multi-baseline stereo. </title> <booktitle> In Proc. of Computer Vision and Pattern Recognition, </booktitle> <month> June </month> <year> 1991. </year> <note> Also appeared in IEEE Trans. on PAMI, 15(4),1993. </note>
Reference: [8] <author> Masatoshi Okutomi, Takeo Kanade and N.Nakahara, </author> <title> A multiple-baseline stereo method. </title> <booktitle> In Proc. of DARPA Image Understanding Workshop, </booktitle> <pages> pages 409-426. DARPA, </pages> <month> January </month> <year> 1992. </year>

References-found: 8

