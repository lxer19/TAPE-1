URL: http://www.eecs.umich.edu/techreports/cse/1993/CSE-TR-192-93.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse93.html
Root-URL: http://www.eecs.umich.edu
Email: email: fsjhan, rosen, kgshing@eecs.umich.edu  
Title: DOCTOR: An IntegrateD ftware Fault InjeC T iO n  
Author: EnviR onment Seungjae Han, Harold A. Rosenberg, and Kang G. Shin 
Keyword: Index Terms Fault injection, communication faults, error-detection latency coverage, synthetic workloads, dependability and performance monitor, validation and evaluation of fault-tolerance mechanisms, distributed real-time systems, dependable communications, distributed diagnosis.  
Address: Ann Arbor, Michigan 48109-2122.  
Affiliation: Real-Time Computing Laboratory Department of Electrical Engineering and Computer Science The University of Michigan  
Abstract: This paper presents an integrateD ftware fault injeC n enviR onment (DOCTOR) which is capable of injecting various types of faults with different options, automatically collecting performance and dependability data, and generating synthetic workloads under which system dependability is evaulated. A comprehensive graphical user interface is also provided. A special emphasis is given to the portability of this dependability experiment tool set. The fault-injection tool supports three types of faults: processor faults, memory faults, and communication faults. It also allows for injecting permanent, transient or intermittent faults. The proposed design methodology for DOCTOR has been implemented on a distributed real-time system called HARTS [1], and its capability is demonstrated through numerous experiments. Dependability measures, such as detection coverage & latency and the associated performance overhead, are evaluated through extensive experiments. Communication fault injection is used to evaluate a probabilistic distributed diagnosis algorithm. The results show that the algorithm performs better than its predicted worst case, yet is quite sensitive to various coverage and inter-processor test parameters. The work reported here is supported in part by the Office of Naval Research under Grants N00014-91-J-1115 and N00014-92-1080, the National Aeronautic and Space Administration under Grant NAG-1493, and the National Science Foundation under Grants MIP-9012549 and MIP-9203895. Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the funding agencies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. G. Shin, </author> <title> "HARTS: A distributed real-time architecture," </title> <journal> IEEE Computer, </journal> <volume> vol. 24, no. 5, </volume> <pages> pp. 25-35, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In addition, an automated and user-transparent multi-run facility allows experiments to be repeated any number of times with no additional user intervention. The proposed SFI environment, called an integrateD ftware fault-injeC n enviR onmenti or DOCTOR for short, is implemented on HARTS <ref> [1] </ref>, and several error detection and recovery mechanisms are evaluated using these tools. Section 2 presents the fault model of our SFI, as well as the architecture of DOCTOR. Section 3 gives a brief description of the initial target system, HARTS, and discusses the underlying implementation issues. <p> Communication failures are specified in a manner similar to memory errors, except with some additional options. Messages can be lost, altered, or delayed. If the node has multiple incoming and outgoing links, as in a point-to-point architecture such as HARTS <ref> [1] </ref>, different fault types can be specified separately for each link. Lost messages are simply not delivered to the recipient. The user can specify whether outgoing, incoming, or all messages are lost at the faulty link. <p> Network Interface Board Processor (IV-3207) Processor (IV-3207) IEEE 802.3 Ethernet Workstation HARTS node Communication fault injection may be more complicated, depending on the structure of the communication protocol stack, and its degree of integration with the operating system. 3 Implementation on HARTS The first target system of DOCTOR is HARTS <ref> [1] </ref>, a real-time distributed system. Presented below are the relevant details of HARTS and important implementation issues. 3.1 Description of the Target System HARTS is comprised of multiprocessor nodes connected by a point-to-point interconnection network. 1 Each HARTS node consists of several Application Processors (APs) and a Network Processor (NP).
Reference: [2] <author> J. C. Laprie, </author> <title> "Dependability: Basic concepts and terminology," </title> <booktitle> IFIP WG 10.4, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: 1 Introduction One of the major problems in developing a dependable system is how to evaluate its dependability. Generally, there are several attributes of dependability, such as reliability, availability, maintainability, and performance-related measures (performability) <ref> [2] </ref>. Numerous approaches have been proposed to validate and evaluate system dependability, including formal proofs, analytical modeling, and experimental methods. As computer systems become more complex, evaluation by modeling may become intractable. Dependability evaluation with fault-injection experiments has therefore become a popular alternative.
Reference: [3] <author> K. G. Shin and Y. H. Lee, </author> <title> "Measurement and application of fault latency," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. C-35, no. 4, </volume> <pages> pp. 370-375, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: This approach is aimed at accelerating the occurrence of faults in order to assess the effectiveness of fault-tolerance mechanisms while executing realistic programs on the target system. There have been several methods proposed for hardware fault injection, such as pin-level fault injection <ref> [3, 4, 5] </ref>, and heavy-ion radiation [6]. However, these methods have become increasingly more difficult to use, mainly due to the complexity of contemporary computer architectures and the high-degree of integration of functions into an ever-shrinking VLSI chip.
Reference: [4] <author> G. Finelli, </author> <title> "Characterization of fault recovery through fault injection on ftmp," </title> <journal> IEEE Trans. Reliability, </journal> <volume> vol. 36, no. 2, </volume> <pages> pp. 164-170, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: This approach is aimed at accelerating the occurrence of faults in order to assess the effectiveness of fault-tolerance mechanisms while executing realistic programs on the target system. There have been several methods proposed for hardware fault injection, such as pin-level fault injection <ref> [3, 4, 5] </ref>, and heavy-ion radiation [6]. However, these methods have become increasingly more difficult to use, mainly due to the complexity of contemporary computer architectures and the high-degree of integration of functions into an ever-shrinking VLSI chip.
Reference: [5] <author> J. Arlat, Y. Crouzet, and J.-C. Laprie, </author> <title> "Fault injection for dependability validation of fault-tolerant computing systems.," </title> <booktitle> in Proc. Int'l Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 348-355, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: This approach is aimed at accelerating the occurrence of faults in order to assess the effectiveness of fault-tolerance mechanisms while executing realistic programs on the target system. There have been several methods proposed for hardware fault injection, such as pin-level fault injection <ref> [3, 4, 5] </ref>, and heavy-ion radiation [6]. However, these methods have become increasingly more difficult to use, mainly due to the complexity of contemporary computer architectures and the high-degree of integration of functions into an ever-shrinking VLSI chip.
Reference: [6] <author> U. Gunneflo, J. Karlsson, and J. Torin, </author> <title> "Evaluation of error detection schemes using fault injection by heavy-ion radiation," </title> <booktitle> in Proc. Int'l Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 340-347, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: This approach is aimed at accelerating the occurrence of faults in order to assess the effectiveness of fault-tolerance mechanisms while executing realistic programs on the target system. There have been several methods proposed for hardware fault injection, such as pin-level fault injection [3, 4, 5], and heavy-ion radiation <ref> [6] </ref>. However, these methods have become increasingly more difficult to use, mainly due to the complexity of contemporary computer architectures and the high-degree of integration of functions into an ever-shrinking VLSI chip.
Reference: [7] <author> G. Choi, R. Iyer, and V. Carreno, </author> <title> "Simulated fault injection: A methodology to evaluate fault tolerant microprocessor architectures," </title> <journal> IEEE Trans. Reliability, </journal> <volume> vol. 39, no. 4, </volume> <pages> pp. 486-490, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: However, these methods have become increasingly more difficult to use, mainly due to the complexity of contemporary computer architectures and the high-degree of integration of functions into an ever-shrinking VLSI chip. As a result, simulation approaches <ref> [7, 8, 9] </ref> and software fault-injection methods have appeared as viable alternatives to hardware fault injection. The authors of [10, 11] introduced software fault injection (SFI), in which faults or errors are inserted into the system memory in order to produce errors or emulate actual errors.
Reference: [8] <author> K. Goswami and R. Iyer, </author> <title> "Simulation of software behaviour under hardware faults," </title> <booktitle> in Proc. Int'l Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 218-227. </pages> <publisher> IEEE, </publisher> <year> 1993. </year> <month> 25 </month>
Reference-contexts: However, these methods have become increasingly more difficult to use, mainly due to the complexity of contemporary computer architectures and the high-degree of integration of functions into an ever-shrinking VLSI chip. As a result, simulation approaches <ref> [7, 8, 9] </ref> and software fault-injection methods have appeared as viable alternatives to hardware fault injection. The authors of [10, 11] introduced software fault injection (SFI), in which faults or errors are inserted into the system memory in order to produce errors or emulate actual errors.
Reference: [9] <author> E. Czeck and D. Siewiorek, </author> <title> "Effects of transient gate-level faults on program behaviour," </title> <booktitle> in Proc. Int'l Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 236-243. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: However, these methods have become increasingly more difficult to use, mainly due to the complexity of contemporary computer architectures and the high-degree of integration of functions into an ever-shrinking VLSI chip. As a result, simulation approaches <ref> [7, 8, 9] </ref> and software fault-injection methods have appeared as viable alternatives to hardware fault injection. The authors of [10, 11] introduced software fault injection (SFI), in which faults or errors are inserted into the system memory in order to produce errors or emulate actual errors.
Reference: [10] <author> Z. Segall et al., </author> <title> "Fiat fault injection based automated testing environment," </title> <booktitle> in FTCS-18, </booktitle> <pages> pp. 102-107, </pages> <year> 1988. </year>
Reference-contexts: As a result, simulation approaches [7, 8, 9] and software fault-injection methods have appeared as viable alternatives to hardware fault injection. The authors of <ref> [10, 11] </ref> introduced software fault injection (SFI), in which faults or errors are inserted into the system memory in order to produce errors or emulate actual errors. <p> to eliminate the unpredictability in memory access caused by page faults. 11 FIA OS Fault-tolerant Mechanism Buffer ControllerBuffer Buffer Server Server Server File File File command VME bus DCM event is furnished with a memory protection facility or virtual memory, one can use either software techniques like `Trojan horse' in <ref> [10] </ref>, or hardware-dependent techniques like those in [11, 12]. Communication faults are injected by a special communication protocol layer that can be inserted anywhere in the protocol stack.
Reference: [11] <author> R. Chillarege and N. S. Bowen, </author> <title> "Understanding large system failures | a fault injection experiment," </title> <booktitle> in Proc. Int'l Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 356-363, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: As a result, simulation approaches [7, 8, 9] and software fault-injection methods have appeared as viable alternatives to hardware fault injection. The authors of <ref> [10, 11] </ref> introduced software fault injection (SFI), in which faults or errors are inserted into the system memory in order to produce errors or emulate actual errors. <p> caused by page faults. 11 FIA OS Fault-tolerant Mechanism Buffer ControllerBuffer Buffer Server Server Server File File File command VME bus DCM event is furnished with a memory protection facility or virtual memory, one can use either software techniques like `Trojan horse' in [10], or hardware-dependent techniques like those in <ref> [11, 12] </ref>. Communication faults are injected by a special communication protocol layer that can be inserted anywhere in the protocol stack. This fault injection layer accepts timing and fault type commands from FIA, and uses information from the parameter files generated by the EGM to initialize the message history structures.
Reference: [12] <author> G. Kanawati, N. Kanawati, and J. Abraham, "FERRARI: </author> <title> A tool for the validation of system dependability properties," </title> <booktitle> in Proc. Int'l Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 336-344. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: However, the memory fault model can only represent the effects of a limited number of actual faults, because some errors are hard to simulate by changing memory contents. In <ref> [12] </ref>, fault injection into CPU components was emulated, and in [13], communication faults were added. A combination of SFI and hardware fault injection is utilized in [14]. In spite of these efforts, the capability of representing diverse fault types with SFI is still limited. <p> However, the exact effect of faults in each component of a processor is highly architecture-dependent. Instead of using the detailed knowledge of specific CPU architecture in order to emulate actual faults more directly as was done in <ref> [12] </ref>, we chose to emulate the consequence of actual faults. Without using any special hardware, we make use of executable image modification, which changes some existing instructions generated by the compiler or inserts extra instructions for fault-injection purposes. <p> caused by page faults. 11 FIA OS Fault-tolerant Mechanism Buffer ControllerBuffer Buffer Server Server Server File File File command VME bus DCM event is furnished with a memory protection facility or virtual memory, one can use either software techniques like `Trojan horse' in [10], or hardware-dependent techniques like those in <ref> [11, 12] </ref>. Communication faults are injected by a special communication protocol layer that can be inserted anywhere in the protocol stack. This fault injection layer accepts timing and fault type commands from FIA, and uses information from the parameter files generated by the EGM to initialize the message history structures.
Reference: [13] <author> K. Echtle and M. Leu, </author> <title> "The EFA fault injector for fault-tolerant distributed system testing," </title> <booktitle> in Workshop on Fault-Tolerant Parallel and Distributed Systems, </booktitle> <pages> pp. 28-35. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: However, the memory fault model can only represent the effects of a limited number of actual faults, because some errors are hard to simulate by changing memory contents. In [12], fault injection into CPU components was emulated, and in <ref> [13] </ref>, communication faults were added. A combination of SFI and hardware fault injection is utilized in [14]. In spite of these efforts, the capability of representing diverse fault types with SFI is still limited. <p> It may be placed between any two protocol layers, but is normally inserted directly below the protocol or user program to be tested. This approach is similar to that in <ref> [13] </ref>. The current implementation takes advantage of the features of the x -kernel operating system, in which our communication protocols are implemented. All protocols in the x -kernel are implemented using same interface between layers, called the Uniform Protocol Interface (UPI).
Reference: [14] <author> T. Dilenno, D. Yaskin, and J. Barton, </author> <title> "Fault tolerance testing in the advanced automation system," </title> <booktitle> in Proc. Int'l Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 18-25, </pages> <year> 1991. </year>
Reference-contexts: In [12], fault injection into CPU components was emulated, and in [13], communication faults were added. A combination of SFI and hardware fault injection is utilized in <ref> [14] </ref>. In spite of these efforts, the capability of representing diverse fault types with SFI is still limited.
Reference: [15] <author> D. L. Kiskis, </author> <title> Generation of Synthetic Workloads for Distributed Real-Time Computing Systems, </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: A workload produces demands for the system resources, so the structure and behavior of the workload may affect the result significantly. In DOCTOR, the user can use a real application 7 program as a workload, or use a synthetic workload produced by SWG <ref> [15] </ref>. Because the syn-thetic workload is parameterized, the user has direct control of the workload characteristics, and so experiments can be conducted under various workload conditions. SWG compiles a high-level description of a workload to produce an executable synthetic workload, ready to be downloaded to a processing node. <p> SWG is a useful tool for generating representative workloads, especially when actual application code is unavailable at an early stage of system design. A detailed account of the SW specification language can be found in <ref> [15] </ref>. Figure 9 shows the conceptual structure of these experiments. The error-detection mechanism tested in this experiment is a simplified software-implemented watchdog monitor. It uses the asynchronous disjoint signature monitoring technique for multiprocessor systems as in [28].
Reference: [16] <author> J. Meyer, "Performability: </author> <title> a retrospective and some pointers to the future," Performance Evaluation 14, </title> <publisher> North-Holland, </publisher> <pages> pp. 139-156, </pages> <year> 1992. </year>
Reference-contexts: The problem of separate measurement of performance and dependability is mentioned in <ref> [16] </ref>. The basic function of DCM is to log the events generated by the monitored object. The FIA and fault-tolerance mechanisms under test generate such events, and if performance is monitored along with dependability, the event triggering instructions should be placed in the operating system kernel.
Reference: [17] <institution> IV-3207 VMEbus Single Board Computer and Multiprocessing Engine User's Manual, Iron-ics Inc., </institution> <year> 1991. </year>
Reference-contexts: In the current configuration, the nodes of HARTS are VMEbus-based Motorola 68040 systems. Each HARTS node has 1-3 AP cards, an NP card, and a communication network interface board. Each AP card is the Ironics IV-3207 <ref> [17] </ref>, a VMEbus-based 68040 card, and 1 Initially it was a continuously-wrapped hexagonal mesh topology, but now it is not restricted to this topology only. 10 another IV-3207 card serves as an NP.
Reference: [18] <institution> VME CIM 250 Reference/User's Manual, Ancor Communications Inc., </institution> <year> 1992. </year>
Reference-contexts: Each AP card is the Ironics IV-3207 [17], a VMEbus-based 68040 card, and 1 Initially it was a continuously-wrapped hexagonal mesh topology, but now it is not restricted to this topology only. 10 another IV-3207 card serves as an NP. The Ancor VME CIM 250 <ref> [18] </ref>, which composes a fiber optic interconnection fabric through Ancor CXT 250 switch [19], works as a communication network interface board. A custom network adapter board, called SPIDER [20], is currently under development. Each node of HARTS runs an operating system called HARTOS [21].
Reference: [19] <institution> CXT 250 16-Port Switch Installer's/User's Manual, Ancor Communications Inc., </institution> <year> 1993. </year>
Reference-contexts: The Ancor VME CIM 250 [18], which composes a fiber optic interconnection fabric through Ancor CXT 250 switch <ref> [19] </ref>, works as a communication network interface board. A custom network adapter board, called SPIDER [20], is currently under development. Each node of HARTS runs an operating system called HARTOS [21].
Reference: [20] <author> J. Dolter, S. Daniel, A. Mehra, J. Rexford, W. Feng, and K. G. Shin, "Spider: </author> <title> Flexible and efficient communication support for point-to-point distributed systems," </title> <type> Technical report, </type> <institution> University of Michigan, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: The Ancor VME CIM 250 [18], which composes a fiber optic interconnection fabric through Ancor CXT 250 switch [19], works as a communication network interface board. A custom network adapter board, called SPIDER <ref> [20] </ref>, is currently under development. Each node of HARTS runs an operating system called HARTOS [21]. HARTOS is primarily an extension of the functionality of pSOS +m [22], a commercial real-time executive to work in a multiprocessor and distributed environment.
Reference: [21] <author> K. G. Shin, D. Kandlur, D. Kiskis, P. Dodd, H. Rosenberg, and A. Indiresan, </author> <title> "A distributed real-time operating system," </title> <journal> IEEE Software, </journal> <pages> pp. 58-68, </pages> <month> September </month> <year> 1992. </year> <note> [22] pSOS+/68K User's Manual, </note> <institution> Integrated Systems Inc., </institution> <year> 1992. </year>
Reference-contexts: The Ancor VME CIM 250 [18], which composes a fiber optic interconnection fabric through Ancor CXT 250 switch [19], works as a communication network interface board. A custom network adapter board, called SPIDER [20], is currently under development. Each node of HARTS runs an operating system called HARTOS <ref> [21] </ref>. HARTOS is primarily an extension of the functionality of pSOS +m [22], a commercial real-time executive to work in a multiprocessor and distributed environment. While pSOS +m provides system support within a node, an extended version of the x -kernel [23] operating system coordinates communication between nodes.
Reference: [23] <author> N. C. Hutchinson and L. L. Peterson, </author> <title> "The x-Kernel: An architecture for implementing network protocols," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 1-13, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: HARTOS is primarily an extension of the functionality of pSOS +m [22], a commercial real-time executive to work in a multiprocessor and distributed environment. While pSOS +m provides system support within a node, an extended version of the x -kernel <ref> [23] </ref> operating system coordinates communication between nodes. The x -kernel provides facilities for implementing communication protocols, such as a uniform protocol interface and libraries to efficiently manipulate messages and maintain mappings. Software for HARTS is developed on Sun workstations. A Sun sparcstation serves as the main connection to HARTS.
Reference: [24] <author> P. Ramanathan, D. Kandlur, and K. G. Shin, </author> <title> "Hardware-assisted software clock synchronization for homogeneous distributed systems," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. C-39, no. 4, </volume> <pages> pp. 514-524, </pages> <year> 1990. </year>
Reference-contexts: If a prespecified fault injection time is reached, a predetermined or randomly selected fault is injected, such as changing the value of the program counter. In the other case, the program will follow the normal sequence. Currently, the hardware-assisted clock synchronization protocol <ref> [24] </ref> of HARTS is under development, so we added a software-implemented clock-synchronization capability to ECM. The clocks of processor nodes are synchronized periodically, once at the beginning of each experiment, or once every run, or as often as needed.
Reference: [25] <author> D. Haban and D. Wybranietz, </author> <title> "A hybrid monitor for behavoir and performance analysis of distributed systems," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 16, no. 2, </volume> <pages> pp. 197-211, </pages> <month> Februay </month> <year> 1990. </year>
Reference-contexts: between runs or some APs must be reset due to failures, DCM can continue its function without disruption. 14 AP-3 AP-1 Comparator WorkloadFIA DAM DCM ready/ack ready/ack ready/ack ready/ack Workload data data stop stop report report report fault fault ready/ack log sync sync ECM stop Communication between DCM and log-event <ref> [25] </ref> generating processes (e.g., FIA) is done through the VMEbus on the HARTS node. DCM allocates a distinct buffer area for each client process. Logged data are stored in the file system mounted on the dedicated processor of running DCM. Similarly, one file is opened for each client process.
Reference: [26] <author> D. Heller, </author> <title> Motif Programming Manual, </title> <publisher> O'Reilly & Associates Inc., </publisher> <year> 1991. </year>
Reference-contexts: Logged data are stored in the file system mounted on the dedicated processor of running DCM. Similarly, one file is opened for each client process. Figure 3 depicts the basic working mechanism of data collection. GUI is implemented based on X-window Motif <ref> [26] </ref>, and runs as a separate process. Figure 4 shows the main window of GUI, and Figure 5 shows the DAM window. One critical problem in implementing a multi-run facility is the re-initialization of both workloads and the fault-injection environment.
Reference: [27] <author> A. Mahmood and E. McCluskey, </author> <title> "Concurrent error detection using watchdog processor-a survey," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. C-37, no. 2, </volume> <pages> pp. 160-174, </pages> <year> 1988. </year>
Reference-contexts: All experiments were performed on HARTS. Since DOCTOR offers an automated multi-run facility, it is easy to run experiments as many times as needed while varying various (including workload-related) parameters. The first experiment evaluates a duplicate-match error-detection method, while the second experiment evaluates a signature monitoring detection method <ref> [27] </ref>.
Reference: [28] <author> S. Tomas and J. Shen, </author> <title> "A roving monitoring processor for detection of control flow errors in multiple processor systems," </title> <booktitle> in Proc. Int'l Conf. on Computer Design: VLSI Comput., </booktitle> <pages> pp. 531-539, </pages> <year> 1985. </year>
Reference-contexts: A detailed account of the SW specification language can be found in [15]. Figure 9 shows the conceptual structure of these experiments. The error-detection mechanism tested in this experiment is a simplified software-implemented watchdog monitor. It uses the asynchronous disjoint signature monitoring technique for multiprocessor systems as in <ref> [28] </ref>. In our scheme, explicit signature-send instructions are inserted in the program, and the signature history of an error-free run is used as a reference structure of the watchdog monitor. Tasks on different processors transmit their signature to the watchdog monitor through dedicated signature queues.
Reference: [29] <author> M. Barborak, M. Malek, and A. Dahbura, </author> <title> "The consensus problem in fault tolerant computing," </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 25, no. 2, </volume> <pages> pp. 171-220, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: There have been a number of distributed diagnosis algorithms proposed to address this issue. A good survey of distributed diagnosis algorithms, and their 20 place in the broader context of consenus algorithms, is given in <ref> [29] </ref>. The algorithm we chose to implement and test is the probabilistic distributed diagnosis algorithm given in [30]. In probabilistic diagnosis algorithms, no bound is placed on the number of faulty nodes. These algorithms define procedures for using information gathered during interprocessor tests to identify a set of faulty nodes.
Reference: [30] <author> D. Fussell and S. Rangarajan, </author> <title> "Probabilistic diagnosis of multiprocessor systems with arbitrary connectivity," </title> <booktitle> Proc. Int'l Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 560-565, </pages> <year> 1989. </year>
Reference-contexts: A good survey of distributed diagnosis algorithms, and their 20 place in the broader context of consenus algorithms, is given in [29]. The algorithm we chose to implement and test is the probabilistic distributed diagnosis algorithm given in <ref> [30] </ref>. In probabilistic diagnosis algorithms, no bound is placed on the number of faulty nodes. These algorithms define procedures for using information gathered during interprocessor tests to identify a set of faulty nodes. <p> The diagnosis can be done using either local or global information, and the analysis of these algorithms generally includes proving results about the probability of arriving at a correct diagnosis, given certain assumptions about the system. The algorithm in <ref> [30] </ref> is intended for the diagnosis of distributed systems of arbitrary connectivity, and is based on comparison testing. Each run of the diagnosis algorithm consists of a number of rounds of testing. <p> There are a number of interesting observations to be drawn from this data. The first thing to notice is that in almost all cases, the measured diagnostic accuracy of the algorithm exceeded that predicted by the probabilistic model in <ref> [30] </ref>, in many cases by a significant percentage. This is because the model makes a number of pessimistic assumptions, and therefore predicts only the worst case performance of the algorithm. <p> When the test coverage is 95%, only 3 rounds are required to reach 100%. As predicted by the asymptotic analysis of the algorithm in <ref> [30] </ref>, both the measured and predicted diagnostic accuracy converge to 100% as the number of tests increase, but the measured accuracy starts much higher, and converges more quickly than predicted.
Reference: [31] <author> H. Rosenberg and K. G. Shin, </author> <title> "Software fault injection and its application in distributed systems," </title> <booktitle> in Proc. Int'l Symp. on Fault-Tolerant Computing, </booktitle> <pages> pp. 208-217. </pages> <publisher> IEEE, </publisher> <year> 1993. </year> <month> 27 </month>
Reference-contexts: The proposed methodology was implemented on a real-time distributed system, HARTS, and extensive experiments conducted, demonstrating its power and utility. The initial work on SFI described in <ref> [31] </ref> has been expanded significantly. We implemented a wide range of fault type and injection options, and developed an injection control mechanism as well as a data collection mechanism which minimizes the interference with the objects under test.
References-found: 30

