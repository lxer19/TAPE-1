URL: http://www.isr.umd.edu/Labs/CACSE/FSQP/pt93.ps
Refering-URL: http://www.isr.umd.edu/Labs/CACSE/FSQP/fsqp.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Combining Feasibility, Descent and Superlinear Convergence in Inequality Constrained Optimization 1  
Author: Eliane R. Panier and Andre L. Tits 
Keyword: Key words: constrained optimization, sequential quadratic programming, feasibility, su-perlinear convergence.  
Address: College Park, MD 20742  
Affiliation: Institute for Systems Research and Department of Electrical Engineering University of Maryland,  
Note: On  AMS(MOS) subject classifications: 90C30, 65K10.  
Pubnum: Mathematical Programming  
Date: 59 (1993) 261-276  Received March 1989 Revised manuscript received 20 June 1990; 30 October 1991  
Abstract: c fl1993 North-Holland. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or distribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from North-Holland. Abstract. Extension of quasi-Newton techniques from unconstrained to constrained optimization via Sequential Quadratic Programming (SQP) presents several difficulties. Among these are the possible inconsistency, away from the solution, of first order approximations to the constraints, resulting in infeasibility of the quadratic programs; and the task of selecting a suitable merit function, to induce global convergence. In the case of inequality constrained optimization, both of these difficulties disappear if the algorithm is forced to generate iterates that all satisfy the constraints, and that yield monotonically decreasing objective function values. (Feasibility of the successive iterates is in fact required in many contexts such as in real-time applications or when the objective function is not well defined outside the feasible set). It has been recently shown that this can be achieved while preserving local two-step superlinear convergence. In this note, the essential ingredients for an SQP-based method exhibiting the desired properties are highlighted. Correspondingly, a class of such algorithms is described and analyzed. Tests performed with an efficient implementation are discussed. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> 13 </institution>
Reference-contexts: (Note that, in view of the linear indepen-dence of the gradients of the active constraints at x fl , the matrices R T k R k are invertible for k large enough.) This holds, for example, under some conditions, when H k is constructed using the BFGS update formula (see <ref> [13] </ref>). Proposition 3.6. For k large enough, the step size t k is one. Finally, two-step superlinear convergence follows. The proof is not given as it follows step by step, with minor modifications, that of [13, Sections 2-3] (see also [16]). Theorem 3.7. <p> Proposition 3.6. For k large enough, the step size t k is one. Finally, two-step superlinear convergence follows. The proof is not given as it follows step by step, with minor modifications, that of <ref> [13, Sections 2-3] </ref> (see also [16]). Theorem 3.7. Under the stated assumptions, the convergence is two-step superlinear, i.e., lim kx k+2 x fl k = 0: 4.
Reference: [1] <author> Harwell Subroutine Library, </author> <title> Library Reference Manual, </title> <address> Harwell, England, </address> <year> 1985. </year>
Reference-contexts: Such a direction can, for example, be obtained as the solution of min 1 kd 1 k 2 + maxfhrf (x); d 1 i; max j Second the coefficient in the convex combination determining d will be computed, given d 0 , via a map () : IR n ! <ref> [0; 1] </ref> such that (d 0 ) = 1 (so that d = d 1 ) when kd 0 k is larger than some given threshold, (d 0 ) is bounded away from zero outside every neighborhood of zero and, for kd 0 k small, (d 0 ) = O (kd <p> Experiments were conducted on all problems from [8] where a feasible initial point is provided and no nonlinear equality constraints are present. We tested three algorithms on those problems: Algorithm 2.1 as implemented in FSQP 2.3, Algorithm A of [10], and the 1984 version of VF02AD <ref> [1] </ref>.
Reference: [2] <author> P. T. BOGGS AND J. W. TOLLE, </author> <title> A Strategy for Global Convergence in a Sequential Quadratic Programming Algorithm, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 26 (1989), </volume> <pages> pp. 600-623. </pages>
Reference-contexts: These questions have been the object of intense research and various avenues have been proposed to address them (see, e.g., <ref> [2] </ref>, [3], [5], [7], [12], [14]).
Reference: [3] <author> G. DIPILLO AND L. GRIPPO, </author> <title> A Continuously Differentiable Exact Penalty Function for Nonlinear Programming with Inequality Constraints, </title> <journal> SIAM J. Control Optim., </journal> <volume> 23 (1985), </volume> <pages> pp. 72-84. </pages>
Reference-contexts: These questions have been the object of intense research and various avenues have been proposed to address them (see, e.g., [2], <ref> [3] </ref>, [5], [7], [12], [14]).
Reference: [4] <author> M. K. H. FAN, L. -S. WANG, J. KONINCKX, and A. L. </author> <title> TITS, Software Package for Optimization-Based Design with User-Supplied Simulators, </title> <journal> IEEE Control System Magazine, </journal> <month> 9 </month> <year> (1989). </year>
Reference-contexts: Besides the FSQP Fortran batch implementation, Algorithm 2.1 has been integrated in an interactive optimization-based design package (C code: CONSOLE <ref> [4] </ref>). To this end, we had to devise an extension of the algorithm to constrained minimax and semi-infinite problems.
Reference: [5] <author> R. FLETCHER, </author> <title> Numerical Experiments with an Exact L 1 Penalty Function Method, in Nonlinear Programming 4, </title> <editor> O. L. Mangasarian, R. R. Meyer, and S. M. Robinson, eds., </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1981, </year> <pages> pp. 99-129. </pages>
Reference-contexts: These questions have been the object of intense research and various avenues have been proposed to address them (see, e.g., [2], [3], <ref> [5] </ref>, [7], [12], [14]).
Reference: [6] <author> P. E. GILL, W. MURRAY, M. A. SAUNDERS, and M. H. WRIGHT, </author> <title> User's Guide for QPSOL (Version 3.2): A Fortran Package for Quadratic Programming, </title> <institution> Systems Optimization Laboratory, Stanford University, </institution> <type> Technical Report SOL 84-6, </type> <address> Stan-ford, CA 94305, </address> <year> 1984. </year>
Reference-contexts: Next, in our tests, the quadratic programming subproblems (2.7), (5.1) and (5.3) were solved by means of subroutine QPSOL Version 3.2 <ref> [6] </ref>, with the "feasibility tolerance" parameter set to 10 14 . Concerning the line search, FSQP 2.3 pays special attention to the order in which the functions (objective and constraints) are evaluated.
Reference: [7] <author> S. P. HAN, </author> <title> A Globally Convergent Method for Nonlinear Programming, </title> <journal> J. Optim. Theory Appl., </journal> <volume> 22 (1977), </volume> <pages> pp. 297-309. </pages>
Reference-contexts: These questions have been the object of intense research and various avenues have been proposed to address them (see, e.g., [2], [3], [5], <ref> [7] </ref>, [12], [14]). <p> The main difference between Algorithm 2.1 and Algorithm A of [10] is a simpler, more rational scheme for selecting the search direction away from a solution. On this basis, it was hoped that FSQP would improve on Algorithm A of <ref> [7] </ref> in many of the instances when the number of objective function evaluations of the latter seemed unduly large when compared to that of VF02AD, e.g., for problems 57, 100 and 117. It appears that this is indeed the case.
Reference: [8] <author> W. HOCK AND K. SCHITTKOWSKI, </author> <title> Test Examples for Nonlinear Programming Codes, </title> <booktitle> Lecture Notes in Economics and Mathematical Systems (187), </booktitle> <publisher> Springer Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Specifically in (2.7), (5.1) and (5.3), affine feasibility is required for x k + d 0 ; x k + d 1 , and x k + d k + ~ d, respectively. Experiments were conducted on all problems from <ref> [8] </ref> where a feasible initial point is provided and no nonlinear equality constraints are present. We tested three algorithms on those problems: Algorithm 2.1 as implemented in FSQP 2.3, Algorithm A of [10], and the 1984 version of VF02AD [1]. <p> was that the Euclidean norm of the gradient of the Lagrangian (KKT vector), with KKT multipliers corresponding to quadratic program (2.7), be less than a prespecified small * (the value of this threshold was chosen, for each problem, based on the norm of the final KKT vector as reported in <ref> [8] </ref>). The results are summarized in Table 1. (Some results for Algorithm A are slightly different from those reported in [10] because of a different stopping criterion.) In that table, No is the number of the test problem in [8], NF is the number of evaluations of the objective function, NG <p> on the norm of the final KKT vector as reported in <ref> [8] </ref>). The results are summarized in Table 1. (Some results for Algorithm A are slightly different from those reported in [10] because of a different stopping criterion.) In that table, No is the number of the test problem in [8], NF is the number of evaluations of the objective function, NG the number of evaluations of scalar constraint functions, NIT the number of iterations, FV the final value of the objective function, VC the final constraint violation (always 0 for FSQP and A), KKT the Euclidean norm of the final
Reference: [9] <author> D. Q. MAYNE AND E. POLAK, </author> <title> A Superlinearly Convergent Algorithm for Constrained Optimization Problems, </title> <journal> Math. Programming Stud., </journal> <volume> 16 (1982), </volume> <pages> pp. 45-61. </pages>
Reference-contexts: Here, t 2 (2,3) is preselected. Note that (2.6) will likely yield better results than, say, min 1 k ~ dk 2 4 inspired by <ref> [9] </ref> and used in [10], since the former uses a (refined) model of (P ) rather than merely a refined model of the active constraints. Algorithm 2.1 Parameters. ff 2 (0; 1 2 ); fi 2 (0; 1).
Reference: [10] <author> E. R. PANIER AND A. L. </author> <title> TITS, A Superlinearly Convergent Feasible Method for the Solution of Inequality Constrained Optimization Problems, </title> <journal> SIAM J. Control Op-tim., </journal> <volume> 25 (1987), </volume> <pages> pp. 934-950. </pages>
Reference-contexts: It was recently shown that it is indeed possible to satisfy (1.2) and (1.3) while preserving the local two-step superlinear convergence of the quasi-Newton SQP iteration <ref> [10] </ref>. The algorithm proposed in [10] suffers from some drawbacks, however, namely its relative complexity and the possible repeated switching between a modified SQP direction and a first order direction resorted to when the former is deemed unsuitable. <p> It was recently shown that it is indeed possible to satisfy (1.2) and (1.3) while preserving the local two-step superlinear convergence of the quasi-Newton SQP iteration <ref> [10] </ref>. The algorithm proposed in [10] suffers from some drawbacks, however, namely its relative complexity and the possible repeated switching between a modified SQP direction and a first order direction resorted to when the former is deemed unsuitable. <p> Convergence results are briefly reported in Section 3. Implementation details as well as some numerical results are discussed in Section 4. Section 5 is devoted to concluding remarks. Many of the results given in Section 3 are stated without proof as they are essentially identical to results in <ref> [10] </ref>. To avoid any loss of continuity, other proofs are given in an appendix. 2. A class of algorithms The following is assumed to hold. A1. The feasible set X is nonempty. A2. The functions f; g j ; j = 1; : : : ; m are continuously differentiable. <p> Here, t 2 (2,3) is preselected. Note that (2.6) will likely yield better results than, say, min 1 k ~ dk 2 4 inspired by [9] and used in <ref> [10] </ref>, since the former uses a (refined) model of (P ) rather than merely a refined model of the active constraints. Algorithm 2.1 Parameters. ff 2 (0; 1 2 ); fi 2 (0; 1). Data. x 0 2 X; H 0 2 IR nfin ; symmetric positive definite. Step 0. <p> Experiments were conducted on all problems from [8] where a feasible initial point is provided and no nonlinear equality constraints are present. We tested three algorithms on those problems: Algorithm 2.1 as implemented in FSQP 2.3, Algorithm A of <ref> [10] </ref>, and the 1984 version of VF02AD [1]. <p> The results are summarized in Table 1. (Some results for Algorithm A are slightly different from those reported in <ref> [10] </ref> because of a different stopping criterion.) In that table, No is the number of the test problem in [8], NF is the number of evaluations of the objective function, NG the number of evaluations of scalar constraint functions, NIT the number of iterations, FV the final value of the objective <p> All tests were performed in double precision, on a Sun Microsystems Sparcstation 1. Locally the iterations for all three algorithms are essentially identical. The main difference between Algorithm 2.1 and Algorithm A of <ref> [10] </ref> is a simpler, more rational scheme for selecting the search direction away from a solution. <p> Let fx k g k2K be any subsequence converging to x fl . Two cases are to be considered. i) The subsequence fd 0 k g k2K converges to zero. In this case the result follows from an argument along the lines of the proof of Theorem 3.3 in <ref> [10] </ref>. ii) There exists a subsequence fd 0 k g k2K 0 K and a value d 0 &gt; 0 such that kd 0 k k &gt; d 0 ; 8 k 2 K 0 : Suppose, by contradiction, that x fl is not a KKT point. <p> The argument used in Proposition 3.2 of <ref> [10] </ref> then implies that, in this case, the step performed by the line search is bounded away from zero. This and the monotonic decrease of f imply therefore that the objective function is unbounded on fx k g k2K 0 , in contradiction with the continuity of f . <p> Using the same argument as in the proof of Proposition 4.2 in <ref> [10] </ref>, it can then be proven that d 0 k ! 0 as k ! 1, k 2 K, a contradiction. Thus i) a) holds. <p> Finally, i) c) is satisfied in view of the definition of d k , and of the properties of (). Parts ii) and iii) can be shown in the same way as in the proof of Proposition 4.2 in <ref> [10] </ref>. The following two lemmas are used below, in the proof of Proposition 3.6. Lemma A.1. ([10, Lemma 4.4]) There exists some constant C &gt; 0 such that, for k large enough, X k;j g j (x k ) C ( j2I (x fl ) 1 Lemma A.2. <p> j (x k + d k ) + hrg j (x k ); ~ d k i = kd k k t ; j 2 I (x fl ) : (A:10) With (A.9) and (A.10) established, since t 2 (2,3), the claim can be proved identically to Proposition 4.8 in <ref> [10] </ref>, using Lemmas A1 and A2 and Proposition 3.5 using the fact that, since - 2 and both d 0 k and d 1 d k = d 0 k d 0 k k - ) = d 0 k k 2 ): Acknowledgements. The authors wish to thank J.L.
Reference: [11] <author> E. R. PANIER, A. L. TITS, and J. N. HERSKOVITS, </author> <title> A QP-Free, Globally Convergent, Locally Superlinearly Convergent Algorithm for Inequality Constrained Optimization, </title> <journal> SIAM J. Control Optim., </journal> <volume> 26 (1988), </volume> <pages> pp. 788-811. </pages>
Reference-contexts: Another quasi-Newton method producing feasible iterates but involving only the solution of linear systems of equations (rather than quadratic programs) was recently proposed <ref> [11] </ref>. In the neighborhood of a solution the work per iteration of the latter and the SQP-type methods described here is similar, as the set of active constraints of the quadratic program eventually remains invariant from one iteration to the next.
Reference: [12] <author> M. J. D. POWELL, </author> <title> A Fast Algorithm for Nonlinearly Constrained Optimization Calculations, in Numerical Analysis, </title> <note> Dundee, 1977, Lecture Notes in Mathematics 630, </note> <editor> G. A. Watson, ed., </editor> <publisher> Springer-Verlag, </publisher> <year> 1978, </year> <pages> pp. </pages> <month> 144-157. </month> <title> [13] , The Convergence of Variable Metric Methods for Nonlinearly Constrained Optimization Calculations, in Nonlinear Programming 3, </title> <editor> O. L. Mangasarian, R. R. Meyer, and S. M. Robinson, eds., </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1978, </year> <pages> pp. 27-63. </pages>
Reference-contexts: These questions have been the object of intense research and various avenues have been proposed to address them (see, e.g., [2], [3], [5], [7], <ref> [12] </ref>, [14]). <p> Finally, we have used (5.3) instead of (2.6) because the former prevents an excessive correction when d k is large, and constraints unlikely to affect ~ d k are not evaluated. FSQP updates H k according to the BFGS formula with Powell's modification <ref> [12] </ref> and H 0 7 is the identity matrix; and ff and fi have values 10 7 and 0.5 respectively.
Reference: [14] <author> M. J. D. POWELL AND Y. X. YUAN, </author> <title> A Recursive Quadratic Programming Algorithm that Uses Differentiable Exact Penalty Functions, </title> <journal> Math. Programming, </journal> <volume> 35 (1986), </volume> <pages> pp. 265-278. </pages>
Reference-contexts: These questions have been the object of intense research and various avenues have been proposed to address them (see, e.g., [2], [3], [5], [7], [12], <ref> [14] </ref>).
Reference: [15] <author> S. M. ROBINSON, </author> <title> Perturbed Kuhn-Tucker Points and Rates of Convergence for a Class of Nonlinear-Programming Algorithms, </title> <journal> Math. Programming, </journal> <volume> 7 (1974), </volume> <pages> pp. 1-16. 14 </pages>
Reference-contexts: This and the monotonic decrease of f imply therefore that the objective function is unbounded on fx k g k2K 0 , in contradiction with the continuity of f . Proof of Proposition 3.4. Under the stated assumptions, the KKT point x fl is isolated <ref> [15] </ref>, i.e., for some * &gt; 0, the ball B (x fl ; *) does not contain any KKT point other than x fl . Let fx k g k2K be any subsequence converging to x fl .
Reference: [16] <author> J. STOER, </author> <title> The Convergence of Sequential Quadratic Programming Methods for Solv--ing Nonlinear Programs, in Recent Advances in Communication and Control Theory, </title> <editor> R. E. Kalman, G. I. Marchuk, A. E. Ruberti, and A. J. Viterbi, eds., </editor> <booktitle> Optimization Software, </booktitle> <publisher> Inc., </publisher> <address> New York, N.Y., </address> <year> 1987, </year> <pages> pp. 412-421. </pages>
Reference-contexts: Proposition 3.6. For k large enough, the step size t k is one. Finally, two-step superlinear convergence follows. The proof is not given as it follows step by step, with minor modifications, that of [13, Sections 2-3] (see also <ref> [16] </ref>). Theorem 3.7. Under the stated assumptions, the convergence is two-step superlinear, i.e., lim kx k+2 x fl k = 0: 4. Implementation and Computational Experiments An efficient implementation of Algorithm 2.1 has been produced as part of a FORTRAN code dubbed FSQP (available from the authors).
Reference: [17] <author> J. ZHOU AND A. L. </author> <title> TITS, User's Guide for FSQP Version 2.3 A Fortran Code for Solving Optimization Problems, Possibly Minimax, with General Inequality Constraints and Linear Equality Constraints, Generating Feasible Iterates, </title> <institution> Systems Research Center, University of Maryland, SRC TR-90-60r1b, College Park, MD 20742, </institution> <year> 1991. </year>
Reference-contexts: Theorem 3.7. Under the stated assumptions, the convergence is two-step superlinear, i.e., lim kx k+2 x fl k = 0: 4. Implementation and Computational Experiments An efficient implementation of Algorithm 2.1 has been produced as part of a FORTRAN code dubbed FSQP (available from the authors). Version 2.3 <ref> [17] </ref> of FSQP was used to perform the numerical tests discussed below.
References-found: 17

