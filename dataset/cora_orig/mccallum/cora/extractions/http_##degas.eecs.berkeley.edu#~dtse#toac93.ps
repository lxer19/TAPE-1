URL: http://degas.eecs.berkeley.edu/~dtse/toac93.ps
Refering-URL: http://degas.eecs.berkeley.edu/~dtse/pub.html
Root-URL: 
Title: OPTIMAL ASYMPTOTIC IDENTIFICATION UNDER BOUNDED DISTURBANCES  
Author: David N.C. Tse Munther A. Dahleh John N. Tsitsiklis 
Address: Cambridge, MA 02139  
Affiliation: Laboratory for Information and Decision Systems, M.I.T.  
Abstract: This paper investigates the intrinsic limitation of worst-case identification of LTI systems using data corrupted by bounded disturbances, when the unknown plant is known to belong to a given model set. This is done by analyzing the optimal worst-case asymptotic error achievable by performing experiments using any bounded inputs and estimating the plant using any identification algorithm. First, it is shown that under some topological conditions on the model set, there is an identification algorithm which is asymptotically optimal for any input. Characterization of the optimal asymptotic error as a function of the inputs is also obtained. These results hold for any error metric and disturbance norm. Second, these general results are applied to three specific identification problems: identification of stable systems in the ` 1 norm, identification of stable rational systems in the H 1 norm, and identification of unstable rational systems in the gap metric. For each of these problems, the general characterization of optimal asymptotic error is used to find near-optimal inputs to minimize the error. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Blumer, A. Ehrenfeucht. D. Haussler, M. Warmuth, </author> <note> "Occam's Razor", Information Processing Letters 24, pp.377-380, </note> <year> 1987. </year>
Reference-contexts: This avoids overfitting of data, a problem 11 which crops up all the time in statistics and pattern recognition. It is interesting to note that this same principle of Occam's Razor has also been applied to guarantee convergence in distribution-free probabilistic learning problems <ref> [1, 25] </ref>. In contrast to the -compactness condition that guarantees convergence, a stronger compactness condition guarantees uniform convergence. Proposition 3.9 Suppose convergence in the -topology on M implies component-wise convergence of the impulse response.
Reference: [2] <author> M.A. Dahleh and M.H. Khammash, </author> <title> "Controller Design in the Presence of Structured Uncertainty," </title> <note> to appear in Automatica special issue on robust control. </note>
Reference-contexts: sequence u 2 l 1 , let Z (u) denote the set of all zeros of its z-transform U (z) inside the open unit disk. (Note that U (z) is analytic inside the open unit disk.) 22 Definition 4.13 A sequence u is said to excite at frequency ! 2 <ref> [0; 2] </ref> if lim sup j k=0 i.e. the Fourier series of u at ! is unbounded. Let (u) denote the set of all frequences at which u excites. We shall now give the following result, the proof of which can be found in the appendix. <p> First, it will be demonstrated that any input that contains all finite sequences of 1's and -1's excites at all frequencies. Proposition 4.17 Let u be any sequence which contains all finite sequences of 1's and -1's. Then (u) = <ref> [0; 2] </ref>. Proof. Let ! 0 be an arbitrary frequency in [0; 2]. Take any M &gt; 0. The sum P is divergent, so we can find an integer L such that P L k=0 j cos k! 0 j &gt; M . <p> Proposition 4.17 Let u be any sequence which contains all finite sequences of 1's and -1's. Then (u) = <ref> [0; 2] </ref>. Proof. Let ! 0 be an arbitrary frequency in [0; 2]. Take any M &gt; 0. The sum P is divergent, so we can find an integer L such that P L k=0 j cos k! 0 j &gt; M . <p> The significance of these error metrics is that if the worst-case error is small in these metrics, methods exist for synthesizing controllers to achieve robust performance <ref> [2, 3] </ref>. The results show that accurate identification is possible in the worst case for a specific choice of inputs depending on the model set. For identification in the ` 1 norm, algorithms for computing estimates are based on linear programming and are easily implementable. <p> The dimension of the realization is L and some of the states are complex but they occur in conjugate pairs. (These correspond to conjugate poles.) Since <ref> [ N i=1 (u (i) ) = [0; 2] </ref>, the frequency ! 1 lies in (v) for some input v 2 fu (1) ; : : : ; u (N) g. <p> The dimension of the realization is L and some of the states are complex but they occur in conjugate pairs. (These correspond to conjugate poles.) Since [ N i=1 (u (i) ) = <ref> [0; 2] </ref>, the frequency ! 1 lies in (v) for some input v 2 fu (1) ; : : : ; u (N) g. <p> Suppose the first condition is not satisfied; consider an ! 0 2 <ref> [0; 2] </ref> but ! 0 62 [ N i=1 (u (i) ). Consider the unstable system h n = cos (n! 0 ). Lemma A.1 (b) implies that u (i) fl e jn! 0 is bounded for all i.
Reference: [3] <author> J. C. Doyle, </author> <title> "Analysis of Feedback Systems with Structured Uncertainty," </title> <booktitle> IEEE Proceedings 129, </booktitle> <address> 242-250,1982. </address>
Reference-contexts: The significance of these error metrics is that if the worst-case error is small in these metrics, methods exist for synthesizing controllers to achieve robust performance <ref> [2, 3] </ref>. The results show that accurate identification is possible in the worst case for a specific choice of inputs depending on the model set. For identification in the ` 1 norm, algorithms for computing estimates are based on linear programming and are easily implementable.
Reference: [4] <author> E. Fogel and Y. F. Huang, </author> " <title> On the value of information in system identification-bounded noise case", </title> <journal> Automatica, vol.18, no.2, </journal> <volume> pp.229-238, </volume> <year> 1982. </year>
Reference-contexts: Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances <ref> [4, 13, 18, 19, 20, 24, 26] </ref>. More recently, specific identification algorithms are proposed in [7, 8, 9, 22] for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data.
Reference: [5] <author> T.T. Georgiou and M.C. Smith, </author> <title> "Optimal Robustness in the Gap Metric", </title> <journal> IEEE Trans. Automatic Control, AC-35, </journal> <volume> No. 6, </volume> <pages> pp. 673-686, </pages> <year> 1990. </year>
Reference-contexts: The question of whether one can design closed-loop experiments to achieve such conditions is left open. An appropriate error metric to use for unstable plants is the gap metric <ref> [5, 27, 34] </ref>. The important property of the gap metric is that it generates the graph topology [32], which is the weakest topology in which closed-loop stability is a robust property, or in which the closed-loop system varies continuously as a function of the open-loop system. <p> Since the zero plant is also in this uncertainty set and the gap distance between the zero plant and any unstable plant is 1 <ref> [5] </ref>, the diameter of this uncertainty set must be 1. Hence the diameter of information, which is the diameter of the largest uncertainty set, is also 1. 2 We now give explicit necessary and sufficient conditions for inputs to be able to test stability. We begin with two definitions.
Reference: [6] <author> G.C. Goodwin, </author> <title> "Experiment design in system identification" in Encyclopedia of Systems and Control (M. </title> <editor> Singh, Ed.), </editor> <publisher> Pergamon Press, </publisher> <year> 1987. </year>
Reference-contexts: In contrast to these works, we deal with general aspects of optimal worst-case asymptotic identification in a general error metric. Moreover, the issue of optimal experiment design, although considered in stochastic system identification (eg. <ref> [6, 16, 35] </ref>), has not been satisfactorily addressed in the worst-case setting. The contributions of this paper are two-folded. At a more general level, it introduces a framework for the analysis of optimal worst-case asymptotic error under bounded disturbances.
Reference: [7] <author> G. Gu and P.P. Khargonekar, </author> <title> "A Class of Algorithms for Identification in H 1 ", preprint. </title>
Reference-contexts: 1 Introduction Recently, there has been a growing line of work with the common theme that system identification should be performed so that the worst-case error of the resulting model is small in a metric compatible with robust control <ref> [7, 8, 9, 22, 30] </ref>. This paper addresses the questions of asymptotically optimal identification algorithms and experiment designs from this point of view. <p> Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances [4, 13, 18, 19, 20, 24, 26]. More recently, specific identification algorithms are proposed in <ref> [7, 8, 9, 22] </ref> for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data. <p> It will be seen that these conditions are quite strong and essentially require the model set to be finite-dimensional. It is worthwhile to note that the model set considered in <ref> [7, 8] </ref> satisfies these conditions. <p> Common examples of such compact model sets are the uniformly stable ones, of the form M s (g) fh : jh i j jg i j for all ig where g is any stable plant. The specific model sets considered in <ref> [7] </ref> and [8] belong to this class. In the particular case when g i is taken to be 0 for all i larger than some given M , we get the model set of finite-impulse- response of length M .
Reference: [8] <author> A.J. Helmicki, C.A. Jacobson and C.N. Nett, </author> <title> "Identification in H 1 : A robust convergent nonlinear algorithm", </title> <booktitle> Proceedings of the 1989 International Symposium on the Mathematical Theory of Networks and System, </booktitle> <year> 1989. </year>
Reference-contexts: 1 Introduction Recently, there has been a growing line of work with the common theme that system identification should be performed so that the worst-case error of the resulting model is small in a metric compatible with robust control <ref> [7, 8, 9, 22, 30] </ref>. This paper addresses the questions of asymptotically optimal identification algorithms and experiment designs from this point of view. <p> Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances [4, 13, 18, 19, 20, 24, 26]. More recently, specific identification algorithms are proposed in <ref> [7, 8, 9, 22] </ref> for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data. <p> It will be seen that these conditions are quite strong and essentially require the model set to be finite-dimensional. It is worthwhile to note that the model set considered in <ref> [7, 8] </ref> satisfies these conditions. <p> Common examples of such compact model sets are the uniformly stable ones, of the form M s (g) fh : jh i j jg i j for all ig where g is any stable plant. The specific model sets considered in [7] and <ref> [8] </ref> belong to this class. In the particular case when g i is taken to be 0 for all i larger than some given M , we get the model set of finite-impulse- response of length M . <p> Then u fl g + d = u fl h + d 0 so D (u; RH 1 ; ffi) kg hk H 1 = 2ffi. 2 19 A similar result on frequency response experiments is given by <ref> [8] </ref>. 4.3 Identification of Unstable Plants in the Gap Metric Our general framework of optimal asymptotic identification applies, to a large extent, to unstable as well as stable systems.
Reference: [9] <author> A.J. Helmicki, C.A. Jacobson and C.N. Nett, </author> <title> "Identification in H 1 : Linear Algorithms", </title> <booktitle> Proceedings of the 1990 American Control Conference, </booktitle> <pages> pp 2418-2423. </pages>
Reference-contexts: 1 Introduction Recently, there has been a growing line of work with the common theme that system identification should be performed so that the worst-case error of the resulting model is small in a metric compatible with robust control <ref> [7, 8, 9, 22, 30] </ref>. This paper addresses the questions of asymptotically optimal identification algorithms and experiment designs from this point of view. <p> Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances [4, 13, 18, 19, 20, 24, 26]. More recently, specific identification algorithms are proposed in <ref> [7, 8, 9, 22] </ref> for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data.
Reference: [10] <author> A.J. Helmicki, C.A. Jacobson and C.N. Nett, </author> <title> "Control-oriented System Identification: </title> <note> A Worst-case/deterministic Approach in H 1 '," to appear in IEEE Trans. Automatic Control. </note>
Reference-contexts: It is the notion of convergence considered by Helmicki et. al. in their framework <ref> [10] </ref>. Demanding uniform convergence is too restrictive a formulation for a general theory of fundamental limitations of worst-case identification. Although such uniform convergence is certainly desirable, it is impossible to achieve for many interesting model sets.
Reference: [11] <author> C.A. Jacobson and C.N. Nett, </author> <title> "Worst-case system identification in ` 1 : Optimal algorithms and error bounds," </title> <booktitle> in Proc. of the 1991 American Control Conference, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: More recently, specific identification algorithms are proposed in [7, 8, 9, 22] for worst-case identification in the H 1 metric from noisy frequency response data and in <ref> [11, 21] </ref> for identification in the ` 1 metric from time series data. In contrast to these works, we deal with general aspects of optimal worst-case asymptotic identification in a general error metric. <p> Generally, we will assume that the algorithm has access to what the model set M is and also the value of ffi, the bound on the disturbance. In the terminology of Helmicki et. al. <ref> [11] </ref>, the algorithm is tuned. However, in some cases, we will be able to give stronger results using algorithms which are untuned to the value of ffi.
Reference: [12] <author> J.M. Krause, G. Stein, </author> <title> P.P. Khargonekar, "Robust Performance of Adaptive Controllers with General Uncertainty Structure", </title> <booktitle> Proceedings of the 29th Conference on Decision and Control, </booktitle> <pages> pp. 3168-3175, </pages> <year> 1990. </year>
Reference-contexts: As far as we know, this issue has not been considered in an unknown-but-bounded noise setting; in fact, it has been taken for granted that consistency always holds <ref> [12] </ref>. Instead, it will now be shown that a compactness condition on the model set will guarantee consistency. The following theorem shows that, under a -compactness assumption on M, D (u; M; ffi) is an upper bound for the optimal asymptotic error.
Reference: [13] <author> R. Lozano-Leal and R. Ortega, </author> <title> "Reformulation of the parameter identification problem for systems with bounded disturbances", </title> <journal> Automatica, vol.23, no.2, </journal> <volume> pp.247-251, </volume> <year> 1987. </year>
Reference-contexts: Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances <ref> [4, 13, 18, 19, 20, 24, 26] </ref>. More recently, specific identification algorithms are proposed in [7, 8, 9, 22] for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data.
Reference: [14] <editor> M.K. Lau, R.L. Kosut, S. Boyd, </editor> <title> "Parameter Set Estimation of Systems with Uncertain Non-parametric Dynamics and Disturbances", </title> <booktitle> Proceedings of the 29th Conference on Decision and Control, </booktitle> <pages> pp. 3162-3167, </pages> <year> 1990. </year>
Reference-contexts: The question is when the latter can be viewed as a limit of the former. In <ref> [14] </ref>, such a consistency result is established by placing a stationarity assumption on the noise and then appealing to the law of large numbers.
Reference: [15] <author> A. Markushevich, </author> <title> Theory of Functions of A Complex Variable, Volume I, </title> <publisher> Prentice Hall, </publisher> <year> 1965. </year>
Reference-contexts: Neither the existence nor the non-existence of a bounded input having both the properties required by Corollary 4.15 has been established. However, bounded inputs which excite at all frequencies do exist. In fact, Lusin <ref> [15] </ref> has constructed a sequence which excites at all frequencies despite the fact that the sequence actually tends to 0. Stability testing is a necessary property the inputs must satisfy in order to have robustness in the asymptotic error.
Reference: [16] <author> R.K. Mehra, </author> <title> "Optimal input signals for parameter estimation in dynamic systems-A survey and new results", </title> <journal> IEEE Trans. Automatic Control, </journal> <volume> vol AC-19, pp.753-768, </volume> <year> 1974. </year> <month> 31 </month>
Reference-contexts: In contrast to these works, we deal with general aspects of optimal worst-case asymptotic identification in a general error metric. Moreover, the issue of optimal experiment design, although considered in stochastic system identification (eg. <ref> [6, 16, 35] </ref>), has not been satisfactorily addressed in the worst-case setting. The contributions of this paper are two-folded. At a more general level, it introduces a framework for the analysis of optimal worst-case asymptotic error under bounded disturbances.
Reference: [17] <author> C.A. Michelli and T.J. Rivlin, </author> <title> "A survey of optimal recovery" in Optimal Estimation in Ap--proximation Theory (C.A. Michelli and T.J. Rivlin, </title> <address> Eds),Plenun, New York, </address> <year> 1977. </year>
Reference-contexts: A natural framework to study worst-case identification is provided by information-based complexity theory <ref> [17, 28, 29] </ref>. This theory provides a general mathematical framework for analyzing the optimal error achievable in solving a problem using a given amount of possibly inaccurate and partial information. <p> These are the model sets which are convex and balanced. (A set A is said to be balanced if for every h in A, h is also in A.) The following proposition gives the characterization, and it follows from a basic result in information-based complexity theory <ref> [17] </ref>. Proposition 4.1 Suppose (g; h) kg hk X for some norm k k X . If M is a balanced convex subset of X , then the worst-case diameter is attained when the true plant and the disturbance are both 0.
Reference: [18] <author> M. Milanese and G. Belforte, </author> <title> "Estimation theory and uncertainty intervals evaluation in the presence of unknown but bounded errors: Linear families of models and estimators", </title> <journal> IEEE Trans. Automatic Control, AC-27, </journal> <volume> pp.408-414, </volume> <year> 1982. </year>
Reference-contexts: Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances <ref> [4, 13, 18, 19, 20, 24, 26] </ref>. More recently, specific identification algorithms are proposed in [7, 8, 9, 22] for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data.
Reference: [19] <author> M. Milanese and R. Tempo, </author> <title> "Optimal algorithm theory for robust estimation and prediction", </title> <journal> IEEE Trans. Automatic Control, </journal> <volume> AC-30, </volume> <pages> pp. 730-738, </pages> <year> 1985. </year>
Reference-contexts: Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances <ref> [4, 13, 18, 19, 20, 24, 26] </ref>. More recently, specific identification algorithms are proposed in [7, 8, 9, 22] for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data.
Reference: [20] <author> M. Milanese, </author> <title> "Estimation theory and prediction in the presence of unknown and bounded uncertainty: a survey", in Robustness in Identification and Control, </title> <editor> M. Milanese, R. Tempo, A. Vicino Eds, </editor> <publisher> Plenum Press, </publisher> <year> 1989. </year>
Reference-contexts: Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances <ref> [4, 13, 18, 19, 20, 24, 26] </ref>. More recently, specific identification algorithms are proposed in [7, 8, 9, 22] for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data.
Reference: [21] <author> P.M. Makila, </author> <title> "Robust Identification and Galois Sequences", </title> <type> Technical Report 91-1, </type> <institution> Process Control Laboratory, Swedish University of Abo, </institution> <month> January, </month> <year> 1991. </year>
Reference-contexts: More recently, specific identification algorithms are proposed in [7, 8, 9, 22] for worst-case identification in the H 1 metric from noisy frequency response data and in <ref> [11, 21] </ref> for identification in the ` 1 metric from time series data. In contrast to these works, we deal with general aspects of optimal worst-case asymptotic identification in a general error metric. <p> Thus, D (u fl ; M; ffi) = diam (S 1 (M; u fl ; 0; ffi)) = sup g2S 1 (M;u fl ;0;ffi) 2 An input satisfying the above condition has been proposed independently by Makila <ref> [21] </ref> for ` 1 identification.
Reference: [22] <author> P.M. Makila and J.R. Partington, </author> <title> "Robust Approximation and Identification in H 1 ", Proc. </title> <booktitle> 1991 American Control Conference, </booktitle> <month> June, </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Recently, there has been a growing line of work with the common theme that system identification should be performed so that the worst-case error of the resulting model is small in a metric compatible with robust control <ref> [7, 8, 9, 22, 30] </ref>. This paper addresses the questions of asymptotically optimal identification algorithms and experiment designs from this point of view. <p> Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances [4, 13, 18, 19, 20, 24, 26]. More recently, specific identification algorithms are proposed in <ref> [7, 8, 9, 22] </ref> for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data.
Reference: [23] <author> J. Munkres, </author> <title> Topology A First Course, </title> <publisher> Prentice Hall, </publisher> <year> 1975. </year>
Reference-contexts: p ffi, so the plant h is also in the set S 1 (M; u; uflg+d; ffi) Hence, by definition of the infinite-horizon diameter of information, (g; h) D (u; M; ffi). 2 The desired topological condition involves the topology of component-wise convergence of sequences, or the so-called product topology. <ref> [23] </ref>. Lemma 3.8 Fix the inputs u 2 Bl N 1 and ffi &gt; 0. Let A M fi M be compact in the product topology, and suppose T u;ffi (g; h) is finite for every (g; h) 2 A. Then sup (g;h)2A T u;ffi (g; h) is also finite.
Reference: [24] <author> J.P. Norton, </author> <title> "Identification and application of bounded-parameter models", </title> <journal> Automatica, vol.23, no.4, </journal> <volume> pp.497-507, </volume> <year> 1987. </year>
Reference-contexts: Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances <ref> [4, 13, 18, 19, 20, 24, 26] </ref>. More recently, specific identification algorithms are proposed in [7, 8, 9, 22] for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data.
Reference: [25] <author> J. Pearl, </author> <title> "On the Connection between the Complexity and Credibility of Inferred Models", </title> <journal> Internat. J. General Systems,4, </journal> , <pages> 255-264, </pages> <year> 1978. </year>
Reference-contexts: This avoids overfitting of data, a problem 11 which crops up all the time in statistics and pattern recognition. It is interesting to note that this same principle of Occam's Razor has also been applied to guarantee convergence in distribution-free probabilistic learning problems <ref> [1, 25] </ref>. In contrast to the -compactness condition that guarantees convergence, a stronger compactness condition guarantees uniform convergence. Proposition 3.9 Suppose convergence in the -topology on M implies component-wise convergence of the impulse response.
Reference: [26] <author> L. Pronzato and E. Walter, </author> <title> "Experiment design in bounded-error context: Comparison with D-optimality", </title> <journal> Automatica, vol.25, no.3, </journal> <volume> pp.383-391, </volume> <year> 1989. </year>
Reference-contexts: Although mainstream system identification research adopts stochastic models for the noise, there is a line of work which deals with worst-case identification under bounded disturbances <ref> [4, 13, 18, 19, 20, 24, 26] </ref>. More recently, specific identification algorithms are proposed in [7, 8, 9, 22] for worst-case identification in the H 1 metric from noisy frequency response data and in [11, 21] for identification in the ` 1 metric from time series data.
Reference: [27] <author> A. K. El-Sakkary, </author> " <title> The Gap Metric: Robustness of Stabilization of Feedback Systems", </title> <journal> IEEE Trans. Automatic Control, </journal> <volume> AC-30, </volume> <pages> pp. 240-247, </pages> <year> 1985. </year>
Reference-contexts: The question of whether one can design closed-loop experiments to achieve such conditions is left open. An appropriate error metric to use for unstable plants is the gap metric <ref> [5, 27, 34] </ref>. The important property of the gap metric is that it generates the graph topology [32], which is the weakest topology in which closed-loop stability is a robust property, or in which the closed-loop system varies continuously as a function of the open-loop system.
Reference: [28] <author> J.F. Traub and H. Wozniakowski, </author> <title> A General Theory of Optimal Algorithms, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: A natural framework to study worst-case identification is provided by information-based complexity theory <ref> [17, 28, 29] </ref>. This theory provides a general mathematical framework for analyzing the optimal error achievable in solving a problem using a given amount of possibly inaccurate and partial information. <p> Consequently, the infinite-horizon 7 optimal worst-case error lower bounds the optimal asymptotic error E 1 (u; M; ffi). On the other hand, by a central result in information-based complexity theory <ref> [28] </ref>, this infinite-horizon optimal error is given by the infinite-horizon radius of information R (u; M; ffi), which in turn is lower bounded by half the diameter of information D (u; M; ffi).
Reference: [29] <author> J.F. Traub, G. Wasilkowski and H. Wazniakowski, </author> <title> Information-Based Complexity, </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: A natural framework to study worst-case identification is provided by information-based complexity theory <ref> [17, 28, 29] </ref>. This theory provides a general mathematical framework for analyzing the optimal error achievable in solving a problem using a given amount of possibly inaccurate and partial information.
Reference: [30] <author> D.N.C. Tse, M.A. Dahleh, J.N. Tsitsiklis, </author> " <title> Optimal and Robust Identification in the ` 1 norm", </title> <booktitle> in Proc. of the 1991 American Control Conference, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Recently, there has been a growing line of work with the common theme that system identification should be performed so that the worst-case error of the resulting model is small in a metric compatible with robust control <ref> [7, 8, 9, 22, 30] </ref>. This paper addresses the questions of asymptotically optimal identification algorithms and experiment designs from this point of view.
Reference: [31] <author> D.N.C. Tse, </author> " <title> Optimal and Robust Identification Under Bounded Disturbances", </title> <type> Master's thesis, </type> <institution> Dept. of Elec. Eng. and Comp. Sci., M.I.T., </institution> <month> February, </month> <year> 1991. </year>
Reference-contexts: A Proof of Theorem 4.14 To prove this result, we need the following lemma, the proof of which is elementary but tedious, and can be found in <ref> [31] </ref>. Lemma A.1 Let u 2 Bl 1 and let h be a complex-valued impulse response (i.e. the sequence values can be complex) with a strictly proper rational transfer function H (z) = i=0 ff i z i (It has a single pole repeated M times at e j! ).
Reference: [32] <author> M. Vidyasagar, </author> <title> Control System Synthesis, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1985. </year>
Reference-contexts: The question of whether one can design closed-loop experiments to achieve such conditions is left open. An appropriate error metric to use for unstable plants is the gap metric [5, 27, 34]. The important property of the gap metric is that it generates the graph topology <ref> [32] </ref>, which is the weakest topology in which closed-loop stability is a robust property, or in which the closed-loop system varies continuously as a function of the open-loop system.
Reference: [33] <author> G. Zames, </author> <title> "On the metric complexity of casual linear systems: *-entropy and *-dimension for continuous-time", </title> <journal> IEEE Trans. on Automatic Control, </journal> <volume> Vol. 24, </volume> <month> April </month> <year> 1979. </year> <month> 32 </month>
Reference-contexts: Our emphasis is less on finding efficient algorithms and more on finding the fundamental limitations in identification accuracy achievable by any identification algorithm in the limit of observing more and more data corrupted by non-stochastic noise. Thus, this work is in the flavor of the questions posed by Zames <ref> [33] </ref>. We will deal exclusively with discrete-time, single-input-single-output linear time-invariant systems. In this formulation, the unknown plant is a priori known to be in a certain subset M of the space of all LTI systems; this subset will be called a model set M.
Reference: [34] <author> G. Zames and A. El-Sakkary, </author> " <title> Unstable Systems and the Gap Metric", </title> <booktitle> Proc. of the Allerton Conference, </booktitle> <pages> pp. 380-385, </pages> <month> Oct. </month> <year> 1980. </year>
Reference-contexts: The question of whether one can design closed-loop experiments to achieve such conditions is left open. An appropriate error metric to use for unstable plants is the gap metric <ref> [5, 27, 34] </ref>. The important property of the gap metric is that it generates the graph topology [32], which is the weakest topology in which closed-loop stability is a robust property, or in which the closed-loop system varies continuously as a function of the open-loop system.
Reference: [35] <author> M. Zarrop, </author> <title> Optimal Experimental Design for Dynamic System Identification, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: In contrast to these works, we deal with general aspects of optimal worst-case asymptotic identification in a general error metric. Moreover, the issue of optimal experiment design, although considered in stochastic system identification (eg. <ref> [6, 16, 35] </ref>), has not been satisfactorily addressed in the worst-case setting. The contributions of this paper are two-folded. At a more general level, it introduces a framework for the analysis of optimal worst-case asymptotic error under bounded disturbances.
Reference: [36] <author> S. Zhu, M. Hautus, C. Praagman, </author> <title> "A Lower and Upper Bound for the Gap Metric", </title> <booktitle> Proc. of the 28th Conf. on Decision and Control, </booktitle> <pages> pp. 2337-2341, </pages> <month> Dec., </month> <year> 1989. </year> <month> 33 </month>
Reference-contexts: To prove this result, it suffices to show that the infinite-horizon gap diameter of information satisfies D gap (u; M fd ; ffi) 2 p We make use of the following lower bound for the gap metric <ref> [36] </ref>: ffi (h; 0) 1 + khk 2 Now, = sup sup diam gap S 1 (M fd ; u; h fl u + d; ffi) diam gap S 1 (M fd ; u; 0; ffi) = sup g2M fd ;kgfluk 1 ffi 2ffi (g; 0) since ffi (g; 0) =
References-found: 36

