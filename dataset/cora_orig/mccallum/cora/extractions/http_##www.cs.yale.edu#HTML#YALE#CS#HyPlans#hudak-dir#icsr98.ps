URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/hudak-dir/icsr98.ps
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/hudak-paul.html
Root-URL: http://www.cs.yale.edu
Email: paul.hudak@yale.edu  
Title: Modular Domain Speciflc Languages and Tools  
Author: Paul Hudak 
Keyword: software reuse, modularity, abstraction, domain speciflc languages, functional languages, formal methods.  
Address: New Haven, CT 06520  
Affiliation: Department of Computer Science Yale University  
Abstract: A domain speciflc language (DSL) allows one to develop software for a particular application domain quickly and efiectively, yielding programs that are easy to understand, reason about, and maintain. On the other hand, there may be a signiflcant overhead in creating the infrastructure needed to support a DSL. To solve this problem, a methodology is described for building domain speciflc embedded languages (DSELs), in which a DSL is designed within an existing, higher-order and typed, programming language such as Haskell or ML. In addition, techniques are described for building modular interpreters and tools for DSELs. The resulting methodology facilitates reuse of syntax, semantics, implementation code, software tools, as well as look-and-feel. 
Abstract-found: 1
Intro-found: 1
Reference: [Ben86] <author> Jon Bentley. </author> <title> Little languages. </title> <journal> CACM, </journal> <volume> 29(8) </volume> <pages> 711-721, </pages> <year> 1986. </year>
Reference-contexts: A DSL is not (necessarily) "general purpose." Rather, it should capture precisely the semantics of an application domain, no more and no less. Bentley also makes a strong argument for DSLs as "little languages" <ref> [Ben86] </ref>.
Reference: [BLS98] <author> Don Batory, Bernie Lofaso, and Yannis Smaragdakis. JTS: </author> <title> A tool suite for building GenVoca generators. </title> <booktitle> In Proceedings of 5th International Conference on Software Reuse. IEEE/ACM, </booktitle> <year> 1998. </year>
Reference-contexts: With such an infrastructure, the savings implied by Figure 1 are more likely to be achievable. The idea of embedding a DSL within an existing language is not new, of course. Lisp macros have been used for years to develop embedded languages. Modern objectoriented approaches such as Jakarta <ref> [BLS98] </ref> take a software-generator approach to the problem: a DSL is a speciflcation language that a software generator uses to create the program of interest. Our approach, however, is distinctive in two ways. First, it is based on a pure embedding|no preprocessor, macro-expander, or generator.
Reference: [Car93] <author> J. Caruso. </author> <title> Prototyping demonstration problem for the prototech hiper-d joint prototyping demonstration project. </title> <type> CCB Report 0.2, </type> <institution> Naval Surface Warfare Cen--ter, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: Everything was written entirely in standard Haskell. As an example, a DSEL for the domain of geometric region analysis came about through an experiment conducted jointly by Darpa, ONR, and the Naval Surface Warfare Center. This well-documented experiment (see <ref> [Car93, CHJ93, LBK + 94] </ref>) demonstrates not only the viability of the DSEL approach, but also its evolvability. Three difierent versions of the system were developed, each capturing more advanced notions of the target system, with no a priori knowledge of the changes that would be required.
Reference: [CHJ93] <author> W.E. Carlson, P. Hudak, and M.P. Jones. </author> <title> An experiment using Haskell to prototype "geometric region servers" for navy command and control. </title> <type> Research Report 1031, </type> <institution> Department of Computer Science, Yale University, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: Everything was written entirely in standard Haskell. As an example, a DSEL for the domain of geometric region analysis came about through an experiment conducted jointly by Darpa, ONR, and the Naval Surface Warfare Center. This well-documented experiment (see <ref> [Car93, CHJ93, LBK + 94] </ref>) demonstrates not only the viability of the DSEL approach, but also its evolvability. Three difierent versions of the system were developed, each capturing more advanced notions of the target system, with no a priori knowledge of the changes that would be required.
Reference: [DRW96] <author> P. Devanbu, D. Rosenblum, and A. Wolf. </author> <title> Generating testing and analysis tools. </title> <journal> ACM Transactions on Software Engineering and Methodology, </journal> <year> 1996. </year>
Reference-contexts: Unoptimized Instrumented Instrumented Total system (ms) interpreter (ms) program (ms) speedup fac 478.42 11.20 (43) 0.69 (16) 693 power2 568.17 14.17 (40) 0.34 (42) 1671 deriv 2642.00 61.53 (40) 0.88 (70) 2797 qsort 1554.50 36.82 (42) 2.34 (16) 664 nsqrt 494.00 12.08 (41) 1.16 (10) 425 proaches to tool generation <ref> [DRW96] </ref>. We have used existing partial evaluation techniques to do this, with dramatic improvements in performance. Unfortunately, there does not currently exist a suitable, easy-to-use partial evaluator for Haskell. Our approach was to convert the Haskell program to Scheme, partially evaluate the Scheme program, and then translate back into Haskell.
Reference: [EH97] <author> Conal Elliott and Paul Hudak. </author> <title> Functional reactive animation. </title> <booktitle> In International Conference on Functional Programming, </booktitle> <pages> pages 163-173, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: The root of that process, however, is a good understanding of the domain semantics itself: one that recognizes layers of abstraction rather than one monolithic structure. 4.1 Simple Graphics To demonstrate this, let's look at a simplifled version of Fran <ref> [EH97, Ell97] </ref>, a DSEL that we have developed in collaboration with Microsoft, for "functional reactive animation." We begin with some simple operators for manipulating graphical objects, or "pictures," as shown in Figure 3. 2 With these operators a rich algebra of pictures can be established. <p> (lift1 f b1) t = f (b1 t) (lift2 f b1 b2) t = f (b1 t) (b2 t) 3 This lifting can be done more elegantly by using Haskell's type classes to overload the operators over, above, etc., but for simplicity this technicality is avoided in this paper; see <ref> [EH97] </ref> for details. <p> described algebra of animations still holds in the reactive framework|nothing "gets broken"|and additionally there is an algebra of reactivity that is reminiscent of that for other process calculii. (Further details on the design, semantics, and implementation of reactivity is beyond the scope of this paper, but may be found in <ref> [EH97, Ell97] </ref>.) 5 Modular Monadic Interpreters A DSEL in Haskell can be thought of as a higher-order algebraic structure, a flrst-class value that has the "look and feel" of special syntax. In some sense it is still just notation; its semantics is captured by an interpreter.
Reference: [Ell97] <author> Conal Elliott. </author> <title> Modeling interactive 3D and multimedia animation with an embedded language. </title> <booktitle> In Proceedings of the flrst conference on DomainSpeciflc Languages. USENIX, </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: The root of that process, however, is a good understanding of the domain semantics itself: one that recognizes layers of abstraction rather than one monolithic structure. 4.1 Simple Graphics To demonstrate this, let's look at a simplifled version of Fran <ref> [EH97, Ell97] </ref>, a DSEL that we have developed in collaboration with Microsoft, for "functional reactive animation." We begin with some simple operators for manipulating graphical objects, or "pictures," as shown in Figure 3. 2 With these operators a rich algebra of pictures can be established. <p> described algebra of animations still holds in the reactive framework|nothing "gets broken"|and additionally there is an algebra of reactivity that is reminiscent of that for other process calculii. (Further details on the design, semantics, and implementation of reactivity is beyond the scope of this paper, but may be found in <ref> [EH97, Ell97] </ref>.) 5 Modular Monadic Interpreters A DSEL in Haskell can be thought of as a higher-order algebraic structure, a flrst-class value that has the "look and feel" of special syntax. In some sense it is still just notation; its semantics is captured by an interpreter.
Reference: [Esp93] <author> David Espinosa. </author> <title> Modular denotational semantics. </title> <type> Unpublished manuscript, </type> <month> De-cember </month> <year> 1993. </year>
Reference-contexts: These building blocks can then be assembled to yield languages that have only a few, a majority, or even all of the individual language features. Progress by Moggi, Espanol, and Steele <ref> [Mog89, Ste94, Esp93, Esp95] </ref> laid the groundwork for our recent efiort at producing a modular interpreter for a nontrivial language [LHJ95], and basing modular compiler construction technology on it [LH96, Lia98]. The use of monads [PJW93, Wad90] to structure the design was critical.
Reference: [Esp95] <author> David Espinosa. </author> <title> Semantic Lego. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <year> 1995. </year>
Reference-contexts: These building blocks can then be assembled to yield languages that have only a few, a majority, or even all of the individual language features. Progress by Moggi, Espanol, and Steele <ref> [Mog89, Ste94, Esp93, Esp95] </ref> laid the groundwork for our recent efiort at producing a modular interpreter for a nontrivial language [LHJ95], and basing modular compiler construction technology on it [LH96, Lia98]. The use of monads [PJW93, Wad90] to structure the design was critical.
Reference: [GHJV95] <author> E. Gamma, R. Helm, R. Johnson, and J. Vlissides. </author> <title> Design Pattens: Elements of Reusable ObjectOriented Software. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: Figure 7 provides a useful viewpoint of these two levels of optimization. Similar results as these can be achieved in objectoriented systems using design patterns <ref> [GHJV95] </ref> and more directed ap Program Unoptimized Instrumented Instrumented Total system (ms) interpreter (ms) program (ms) speedup fac 478.42 11.20 (43) 0.69 (16) 693 power2 568.17 14.17 (40) 0.34 (42) 1671 deriv 2642.00 61.53 (40) 0.88 (70) 2797 qsort 1554.50 36.82 (42) 2.34 (16) 664 nsqrt 494.00 12.08 (41) 1.16 (10)
Reference: [Hen82] <author> P. Henderson. </author> <title> Functional geometry. </title> <booktitle> In Proceedings of the 1982 ACM Symposium on Lisp and Functional Programmming, </booktitle> <pages> pages 179-187. </pages> <publisher> ACM, </publisher> <year> 1982. </year>
Reference-contexts: With these axioms many useful properties of graphical objects can be established. 2 These are not unlike those for geometric regions given previously, but are even more like Henderson's functional graphics given in <ref> [Hen82] </ref>.
Reference: [HPJWe92] <editor> P. Hudak, S. Peyton Jones, and P. Wadler (editors). </editor> <title> Report on the Programming Language Haskell, A Non-strict Purely Functional Language (Version 1.2). </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 27(5), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: First, it is based on a pure embedding|no preprocessor, macro-expander, or generator. Second, it emphasizes the importance of semantics, as manifested through modular algebraic approaches to DSL implementation. In the remainder of this paper I describe the results of using the functional language Haskell <ref> [HPJWe92] </ref> to build DSELs. Haskell has several features that I believe are crucial to the pure embedding of a DSL: higher-order functions, lazy evaluation, poly-morphism, and type classes.
Reference: [Joh75] <author> S.C. Johnson. </author> <title> Yacc yet another compiler compiler. </title> <type> Technical Report 32, </type> <institution> Bell Labs, </institution> <year> 1975. </year>
Reference-contexts: A language with less of these features could possibly also be used, but probably only with a higher emphasis on preprocessing and the complexities thus introduced. 3 Syntax vs. Semantics Tools such as Lex [Les75] and Yacc <ref> [Joh75] </ref>, as well as more sophisticated programming environment generators (e.g. [Rep84]), have been shown to be quite useful in designing new programming languages; they are certainly better than building lexers, parsers, and other tools from scratch.
Reference: [KH95] <author> A. Kishon and P. Hudak. </author> <title> Semantics-directed program execution monitoring. </title> <journal> Journal of Functional Programming, </journal> <volume> 5(4), </volume> <month> October </month> <year> 1995. </year>
Reference-contexts: lazy profller result difiers from the eager one because acc is never demanded by the lazy interpreter: Run&gt; execute (profiler & eager) badFact (1, [(fac,4), (mul,3)]) Run&gt; execute (profiler & lazy) badFact (1, [(fac,4)]) Using these basic ideas, rather sophisticated debuggers for a variety of languages can be quickly developed <ref> [KH95, Kis92] </ref>. 6 Partial Evaluation Perhaps all of this seems too good to be true. Indeed, there is one major drawback to our approach to modular interpreter construction: each building block imposes an independent layer of interpretive overhead, resulting in seemingly impractical interpreters for any realistic DSL.
Reference: [Kis92] <author> A. Kishon. </author> <title> Theory and Art of Semantics-Directed Program Execution Monitoring. </title> <type> PhD thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: lazy profller result difiers from the eager one because acc is never demanded by the lazy interpreter: Run&gt; execute (profiler & eager) badFact (1, [(fac,4), (mul,3)]) Run&gt; execute (profiler & lazy) badFact (1, [(fac,4)]) Using these basic ideas, rather sophisticated debuggers for a variety of languages can be quickly developed <ref> [KH95, Kis92] </ref>. 6 Partial Evaluation Perhaps all of this seems too good to be true. Indeed, there is one major drawback to our approach to modular interpreter construction: each building block imposes an independent layer of interpretive overhead, resulting in seemingly impractical interpreters for any realistic DSL.
Reference: [LBK + 94] <author> J.A.N. Lee, B. Blum, P. Kanellakis, H. </author> <title> Crisp, and J.A. Caruso. ProtoTech HiPer-D Joint Prototyping Demonstration Project, </title> <month> February </month> <year> 1994. </year> <pages> Unpublished; 400 pages. </pages>
Reference-contexts: Everything was written entirely in standard Haskell. As an example, a DSEL for the domain of geometric region analysis came about through an experiment conducted jointly by Darpa, ONR, and the Naval Surface Warfare Center. This well-documented experiment (see <ref> [Car93, CHJ93, LBK + 94] </ref>) demonstrates not only the viability of the DSEL approach, but also its evolvability. Three difierent versions of the system were developed, each capturing more advanced notions of the target system, with no a priori knowledge of the changes that would be required.
Reference: [Les75] <author> M.E. Lesk. </author> <title> Lex alexical analyzer generator. </title> <type> Technical Report 39, </type> <institution> Bell Labs, </institution> <year> 1975. </year>
Reference-contexts: A language with less of these features could possibly also be used, but probably only with a higher emphasis on preprocessing and the complexities thus introduced. 3 Syntax vs. Semantics Tools such as Lex <ref> [Les75] </ref> and Yacc [Joh75], as well as more sophisticated programming environment generators (e.g. [Rep84]), have been shown to be quite useful in designing new programming languages; they are certainly better than building lexers, parsers, and other tools from scratch.
Reference: [LH96] <author> Sheng Liang and Paul Hudak. </author> <title> Modular denotational semantics for compiler construction. </title> <booktitle> In European Symposium on Programming, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: Progress by Moggi, Espanol, and Steele [Mog89, Ste94, Esp93, Esp95] laid the groundwork for our recent efiort at producing a modular interpreter for a nontrivial language [LHJ95], and basing modular compiler construction technology on it <ref> [LH96, Lia98] </ref>. The use of monads [PJW93, Wad90] to structure the design was critical. Our approach means that language features can be added long after the initial design, even if they involve fundamental changes in the interpreter functionality. <p> It is also possible with this approach to capture not only domainspeciflc semantics, but also domain-speciflc optimizations. These optimizations can be done incrementally and independently from each other and from the core semantics. We have used this to implement traditional compiler optimizations <ref> [LH96, Lia98] </ref>, but the same techniques could be used for domainspeciflc optimizations. To get a feel for how a monadic interpreter works, note that a conventional interpreter maps, say, a term, environment, and store, to an answer. <p> Indeed, there is one major drawback to our approach to modular interpreter construction: each building block imposes an independent layer of interpretive overhead, resulting in seemingly impractical interpreters for any realistic DSL. Although our modular monadic approach can be used to reason about compiler construction <ref> [LH96] </ref>, we would prefer to use (and reuse) the modular interpreters. The solution is to use partial evaluation.
Reference: [LHJ95] <author> Sheng Liang, Paul Hudak, and Mark Jones. </author> <title> Monad transformers and modular interpreters. </title> <booktitle> In Proceedings of 22nd ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 333-343, </pages> <address> New York, </address> <month> January </month> <year> 1995. </year> <note> ACM Press. </note>
Reference-contexts: Progress by Moggi, Espanol, and Steele [Mog89, Ste94, Esp93, Esp95] laid the groundwork for our recent efiort at producing a modular interpreter for a nontrivial language <ref> [LHJ95] </ref>, and basing modular compiler construction technology on it [LH96, Lia98]. The use of monads [PJW93, Wad90] to structure the design was critical. Our approach means that language features can be added long after the initial design, even if they involve fundamental changes in the interpreter functionality.
Reference: [Lia98] <author> Sheng Liang. </author> <title> Modular Monadic Semantics and Compilation. </title> <type> PhD thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <month> May </month> <year> 1998. </year>
Reference-contexts: Progress by Moggi, Espanol, and Steele [Mog89, Ste94, Esp93, Esp95] laid the groundwork for our recent efiort at producing a modular interpreter for a nontrivial language [LHJ95], and basing modular compiler construction technology on it <ref> [LH96, Lia98] </ref>. The use of monads [PJW93, Wad90] to structure the design was critical. Our approach means that language features can be added long after the initial design, even if they involve fundamental changes in the interpreter functionality. <p> It is also possible with this approach to capture not only domainspeciflc semantics, but also domain-speciflc optimizations. These optimizations can be done incrementally and independently from each other and from the core semantics. We have used this to implement traditional compiler optimizations <ref> [LH96, Lia98] </ref>, but the same techniques could be used for domainspeciflc optimizations. To get a feel for how a monadic interpreter works, note that a conventional interpreter maps, say, a term, environment, and store, to an answer.
Reference: [Mog89] <author> E. Moggi. </author> <title> Computational lambda-calculus and monads. </title> <booktitle> In Proceedings of Symposium on Logic in Computer Science, </booktitle> <pages> pages 14-23. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: These building blocks can then be assembled to yield languages that have only a few, a majority, or even all of the individual language features. Progress by Moggi, Espanol, and Steele <ref> [Mog89, Ste94, Esp93, Esp95] </ref> laid the groundwork for our recent efiort at producing a modular interpreter for a nontrivial language [LHJ95], and basing modular compiler construction technology on it [LH96, Lia98]. The use of monads [PJW93, Wad90] to structure the design was critical.
Reference: [PJML98] <author> Simon Peyton-Jones, Erik Meijer, and Dan Leijen. </author> <title> Scripting COM components in haskell. </title> <booktitle> In Proceedings of 5th International Conference on Software Reuse. IEEE/ACM, </booktitle> <year> 1998. </year>
Reference-contexts: We and others in the Haskell community have done so using Haskell in a variety of domains: parser generation, graphics, animation, simulation, music composition, hardware design, VLSI layout, pretty printing, concurrency, GUIs, component scripting <ref> [PJML98] </ref>, and geometric region analysis, to name a few. Each of these applications was a pure embedding: neither Haskell semantics nor implementation was modifled, nor was a preprocessor used to add extra language features. Everything was written entirely in standard Haskell.
Reference: [PJW93] <author> S. Peyton Jones and P. Wadler. </author> <title> Imperative functional programming. </title> <booktitle> In Proceedings 20th Symposium on Principles of Programming Languages. ACM, </booktitle> <month> January </month> <year> 1993. </year> <note> (to appear). </note>
Reference-contexts: Progress by Moggi, Espanol, and Steele [Mog89, Ste94, Esp93, Esp95] laid the groundwork for our recent efiort at producing a modular interpreter for a nontrivial language [LHJ95], and basing modular compiler construction technology on it [LH96, Lia98]. The use of monads <ref> [PJW93, Wad90] </ref> to structure the design was critical. Our approach means that language features can be added long after the initial design, even if they involve fundamental changes in the interpreter functionality.
Reference: [Rep84] <author> T. W. Reps. </author> <title> Generating Language-Based Environments. </title> <publisher> The MIT Press, </publisher> <year> 1984. </year>
Reference-contexts: A language with less of these features could possibly also be used, but probably only with a higher emphasis on preprocessing and the complexities thus introduced. 3 Syntax vs. Semantics Tools such as Lex [Les75] and Yacc [Joh75], as well as more sophisticated programming environment generators (e.g. <ref> [Rep84] </ref>), have been shown to be quite useful in designing new programming languages; they are certainly better than building lexers, parsers, and other tools from scratch. On the other hand, syntactic minutiae should arguably be the least of a language designer's worries.
Reference: [Ste94] <author> Guy L. Steele Jr. </author> <title> Building interpreters by composing monads. </title> <booktitle> In Conference Record of POPL '94: 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, Portland, Ore-gon, </booktitle> <pages> pages 472-492, </pages> <address> New York, </address> <month> January </month> <year> 1994. </year> <note> ACM Press. </note>
Reference-contexts: These building blocks can then be assembled to yield languages that have only a few, a majority, or even all of the individual language features. Progress by Moggi, Espanol, and Steele <ref> [Mog89, Ste94, Esp93, Esp95] </ref> laid the groundwork for our recent efiort at producing a modular interpreter for a nontrivial language [LHJ95], and basing modular compiler construction technology on it [LH96, Lia98]. The use of monads [PJW93, Wad90] to structure the design was critical.
Reference: [Wad90] <author> P. Wadler. </author> <title> Comprehending monads. </title> <booktitle> In Proceedings of Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 61-78, </pages> <address> Nice, France, </address> <month> June </month> <year> 1990. </year> <note> ACM. </note>
Reference-contexts: Progress by Moggi, Espanol, and Steele [Mog89, Ste94, Esp93, Esp95] laid the groundwork for our recent efiort at producing a modular interpreter for a nontrivial language [LHJ95], and basing modular compiler construction technology on it [LH96, Lia98]. The use of monads <ref> [PJW93, Wad90] </ref> to structure the design was critical. Our approach means that language features can be added long after the initial design, even if they involve fundamental changes in the interpreter functionality.
References-found: 26

