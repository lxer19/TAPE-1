URL: http://www.cs.washington.edu/homes/xqin/numa.ps
Refering-URL: http://www.cs.washington.edu/homes/xqin/
Root-URL: 
Title: Performance Prediction and Evaluation of Parallel Processing on a NUMA Multiprocessor  
Author: Xiaodong Zhang and Xiaohan Qin 
Keyword: Index Terms barrier, interprocessor communication, interconnection network, NUMA architec tures, pre-scheduling, self-scheduling, remote memory access, shared memory, UMA architectures.  
Note: This research has been supported in part by the National Science Foundation under grants CCR-9008991 and CCR-9102854, and a grant from the San Antonio Area Foundation, SAAF-26-7400-03.  
Address: San Antonio, Texas 78285 0664  
Affiliation: Division of Computer Science University of Texas at San Antonio  
Abstract: Non-Uniform Memory Access (NUMA) architectures make it possible to build large-scale shared memory multiprocessor systems in comparison with non-scalable Uniform Memory Access (UMA) architectures. Most NUMA multiprocessor operations such as scheduling and synchronizing processes, accessing data from processors to memory models and allocating distributed memory space to different processors, are performed through interconnection networks such as a multistage switching network. The efficiency of these basic operations determines the parallel processing performance on a NUMA multiprocessor. This paper presents several analytical models to predict and evaluate the overhead of interprocessor communication, process scheduling, process synchronization and remote memory access where network contention and memory contention are considered. Performance measurements to support the models and analyses through several numerical examples have been done on the BBN GP1000, a NUMA shared memory multiprocessor. Both analytical and experimental results give a comprehensive and clear understanding of the various effects, which are important for the effective use of a NUMA shared memory multiprocessor. The results in this paper may be used to determine optimal strategies in developing an efficient programming environment for a NUMA system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. A. </author> <title> Amdahl, "Validity of the single-processor approach to achieving large scale computing capabilities", </title> <booktitle> AFIPS Conference Proceedings, </booktitle> <volume> Vol. </volume> <pages> 30, </pages> <address> Reston, VA: </address> <publisher> AFIPS Press, </publisher> <year> 1967, </year> <pages> pp. 483-485. </pages>
Reference-contexts: It is our goal to provide reasonably accurate NUMA performance models to incorporate both interconnection network effects and NUMA system effects by the analyses and experiments. 1.2 Performance models Our performance analyses start with Amdahl's law <ref> [1] </ref> which is in its simplest form of execution time versus number of processors p T (p) = t s + p This model can be viewed as separating a program into a perfectly parallelized time section t p , and strictly sequential time section t s and running on a
Reference: [2] <author> T. Axelrod, </author> <title> "Effects of Synchronization barriers on multiprocessor performance" Parallel Computing, </title> <journal> Vol. </journal> <volume> 3, </volume> <year> 1986, </year> <pages> pp. 129-140. </pages>
Reference-contexts: A simple algorithm of the barrier to synchronize the pre-scheduling is the accumulating counter barrier (see e.g. <ref> [2] </ref>), which is implemented on the BBN GP1000. This consists of two locks and a shared counter. The first lock controls access to the shared counter, which records the number of processes that have arrived at the barrier. This counter must be globally shared and all access to it serialized.
Reference: [3] <institution> BBN Advanced Computer Inc., Butterfly GP1000 Switch Tutorial, </institution> <year> 1989. </year>
Reference-contexts: Some remote memory access delay has been measured on the BBN butterfly systems between a processor and a memory module pair without considering the memory and network contentions at all or without considering the random contentions. (see e.g. <ref> [3] </ref>, [10]). However, in real parallel processing on a NUMA system, the remote memory access delay is more complicated because of the memory and network contentions. <p> For example, GP1000 spends about 0.5 s to establish a remote memory access connection through the 2-level switches. After the connection is established, the read or write operations are performed by data communication in the rate of 0.125 s for every 4-bits. (see e.g. <ref> [3] </ref>). The network contention is basically determined by the remote access rate, defined as the number of remote access per time unit, which is denoted as in (4.1). We constructed two programs for measuring and comparing the remote memory access effects on the GP1000.
Reference: [4] <institution> BBN Advanced Computer Inc., Inside the GP1000, </institution> <year> 1989. </year>
Reference: [5] <institution> BBN Advanced Computer Inc., Uniform System Approach, </institution> <year> 1989. </year>
Reference-contexts: The time ratio between a local access and a remote access with no other processors active on the GP1000 is up to 1:15 depending on the types of the access (see e.g. [10]). The GP1000 provides a parallel programming environment called the Uniform System (see <ref> [5] </ref>) where the parallel tasks may be distributed and processed without regard to the physical location of the data associated with the tasks.
Reference: [6] <author> L. Bhuyan et al, </author> <title> "Design and performance of generalized interconnection network", </title> <booktitle> Tutorial Advanced Computer Architecture, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1986, </year> <pages> pp. 133-142. </pages>
Reference-contexts: Their system experiments conclude that the placement and movement of code and data are crucial to NUMA performance. The performance of a general multistage interconnection network, such as the Omega network has been evaluated analytically (see e.g. <ref> [6] </ref>, [7], [15]). The analysis work is independent on the NUMA architecture although the multistage interconnection network is commonly used for a NUMA system.
Reference: [7] <author> L. Bhuyan et al, </author> <title> "Performance of multiprocessor interconnection network", </title> <journal> IEEE Computer, </journal> <volume> Vol. 22, No. 2, </volume> <year> 1989, </year> <pages> pp. 25-37. </pages>
Reference-contexts: Their system experiments conclude that the placement and movement of code and data are crucial to NUMA performance. The performance of a general multistage interconnection network, such as the Omega network has been evaluated analytically (see e.g. [6], <ref> [7] </ref>, [15]). The analysis work is independent on the NUMA architecture although the multistage interconnection network is commonly used for a NUMA system.
Reference: [8] <author> Y. Birk et al, </author> <title> "A simple mechanism for efficient barrier synchronization in MIMD machines", </title> <booktitle> Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <volume> Vol. II, </volume> <year> 1990, </year> <month> pp.195-198. </month>
Reference-contexts: Inter ested readers may refer to [20] and <ref> [8] </ref>. 3.2 Self-scheduling and shared memory programming In order to balance the processing load, the tasks are dynamically scheduled or self-scheduled to processors at runtime.
Reference: [9] <author> R. Bisiani and M. Ravishankar, </author> <title> "PLUS: a distributed shared-memory system. </title> <booktitle> Proceedings of the 17th Annual International Symposium on Computer Architecture, IEEE Computer Society, </booktitle> <year> 1990, </year> <pages> pp. 115-124. </pages>
Reference-contexts: Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], [16], [23]), Cedar at the University of Illinois (see e.g. [14], [26]), the IBM RP3 (see e.g. [21]), Cm* and PLUS at Carnegie-Mellon University (see e.g. <ref> [9] </ref>, [17], [22]), Hector (see [25]) and Paradigm (see [11]), in which the BBN butterfly machines are the only systems commercially available, and the rest are research model architectures. 1.1 Programming models on a NUMA architectures Programming models on a NUMA architecture can be classified into three types: distributed memory, partially
Reference: [10] <author> F. Bodin, et al, </author> <title> "Performance evaluation and prediction for parallel algorithms on the BBN GP1000", </title> <booktitle> Proceeding of 1990 International Conference on Supercomputing, </booktitle> <publisher> ACM Press, </publisher> <year> 1990, </year> <pages> pp. 401-413. </pages>
Reference-contexts: The performance factors of NUMA multiprocessors (for example, the BBN GP1000), such as the data access time, scheduling overhead and others have been measured through various application programs (see e.g. <ref> [10] </ref>, [30]). As memory architectures and interconnection networks become more complex, the performance prediction and evaluation of a NUMA architecture become more difficult. <p> The time ratio between a local access and a remote access with no other processors active on the GP1000 is up to 1:15 depending on the types of the access (see e.g. <ref> [10] </ref>). The GP1000 provides a parallel programming environment called the Uniform System (see [5]) where the parallel tasks may be distributed and processed without regard to the physical location of the data associated with the tasks. <p> Some remote memory access delay has been measured on the BBN butterfly systems between a processor and a memory module pair without considering the memory and network contentions at all or without considering the random contentions. (see e.g. [3], <ref> [10] </ref>). However, in real parallel processing on a NUMA system, the remote memory access delay is more complicated because of the memory and network contentions.
Reference: [11] <author> D. R. Cheriton et al, </author> <title> "Paradigm: a highly scalable shared-memory multicomputer architecture", </title> <journal> IEEE Computer, </journal> <volume> Vol 24, No. 2, </volume> <year> 1991, </year> <pages> pp. 33-48. </pages>
Reference-contexts: Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], [16], [23]), Cedar at the University of Illinois (see e.g. [14], [26]), the IBM RP3 (see e.g. [21]), Cm* and PLUS at Carnegie-Mellon University (see e.g. [9], [17], [22]), Hector (see [25]) and Paradigm (see <ref> [11] </ref>), in which the BBN butterfly machines are the only systems commercially available, and the rest are research model architectures. 1.1 Programming models on a NUMA architectures Programming models on a NUMA architecture can be classified into three types: distributed memory, partially shared memory and fully shared memory.
Reference: [12] <author> J. E. Dennis Jr., R. B. Schnabel, </author> <title> Numerical Methods for Nonlinear Optimization and Nonlinear Equations, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey. </address>
Reference-contexts: In addition, many block bordered equations result in nearly singular or singular Jacobians in the iteration process. Thus, the Newton step needs to be modified dynamically to converge to a solution. The modifications on some of the subsystems, such as a line search and matrix perturbations (see e.g. <ref> [12] </ref>) require extra computing time that cannot be predicted statically before running the program. The testing circuit problem we simulated was the 741 op-amp from [27], where q = 4.
Reference: [13] <author> H. P. Flatt, K. Kennedy, </author> <title> "Performance of parallel processors", </title> <journal> Parallel Computing, </journal> <volume> Vol. 12, No. 1, </volume> <year> 1989, </year> <pages> pp. 1-12. </pages>
Reference-contexts: by adding an overhead function term T o (p) to include the practical effects T (p) = t s + p The modified Amdahl's model has been used for evaluating parallel processing performance on different architectures, such as the vector supercomputers (see e.g. [18]), distributed memory mul-ticomputer hypercube (see e.g. <ref> [13] </ref>), and UMA shared memory multiprocessors (see e.g. [28]).
Reference: [14] <author> D. Gajski, et al, </author> <title> "Cedar a large scale multiprocessor", </title> <booktitle> Proceedings of the 1983 international Conference on Parallel Processing, </booktitle> <year> 1983, </year> <pages> pp. 524-529. </pages>
Reference-contexts: Therefore, a NUMA architecture can scale large number of processors in shared memory multiprocessor design. Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], [16], [23]), Cedar at the University of Illinois (see e.g. <ref> [14] </ref>, [26]), the IBM RP3 (see e.g. [21]), Cm* and PLUS at Carnegie-Mellon University (see e.g. [9], [17], [22]), Hector (see [25]) and Paradigm (see [11]), in which the BBN butterfly machines are the only systems commercially available, and the rest are research model architectures. 1.1 Programming models on a NUMA
Reference: [15] <author> E. Gelenbe, </author> <title> Multiprocessor Performance, </title> <publisher> John Wiley and Sons, </publisher> <year> 1989. </year>
Reference-contexts: Their system experiments conclude that the placement and movement of code and data are crucial to NUMA performance. The performance of a general multistage interconnection network, such as the Omega network has been evaluated analytically (see e.g. [6], [7], <ref> [15] </ref>). The analysis work is independent on the NUMA architecture although the multistage interconnection network is commonly used for a NUMA system. <p> It then selects an alternative route, and after a random delay, tries again. Our model is based on the nonblocking-network architecture, which is used for most NUMA systems. 4.2 A model of remote memory access Gelenbe <ref> [15] </ref> describes the behavior of a remote memory access in a nonblocking multi-stage interconnection network by a state transition diagram called drop approach (see Figure 5). Here a processor makes a remote memory access by formulating requests for access to the set of switches 15 network. along that path.
Reference: [16] <author> C. D. Howe, </author> <title> "An overview of the Butterfly GP1000: a large-scale parallel Unix computer", </title> <booktitle> Proceedings of the Third International Conference of Supercomputing, </booktitle> <volume> Vol. 3, </volume> <year> 1988, </year> <pages> pp. 134-141. </pages>
Reference-contexts: Therefore, a NUMA architecture can scale large number of processors in shared memory multiprocessor design. Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], <ref> [16] </ref>, [23]), Cedar at the University of Illinois (see e.g. [14], [26]), the IBM RP3 (see e.g. [21]), Cm* and PLUS at Carnegie-Mellon University (see e.g. [9], [17], [22]), Hector (see [25]) and Paradigm (see [11]), in which the BBN butterfly machines are the only systems commercially available, and the rest
Reference: [17] <author> A. K. Jones et al, </author> <title> "Software management of Cm* a distributed multiprocessor", </title> <booktitle> 1977 National Computer Conference, </booktitle> <volume> Vol. 46, </volume> <year> 1977, </year> <pages> pp. 657-663. </pages>
Reference-contexts: Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], [16], [23]), Cedar at the University of Illinois (see e.g. [14], [26]), the IBM RP3 (see e.g. [21]), Cm* and PLUS at Carnegie-Mellon University (see e.g. [9], <ref> [17] </ref>, [22]), Hector (see [25]) and Paradigm (see [11]), in which the BBN butterfly machines are the only systems commercially available, and the rest are research model architectures. 1.1 Programming models on a NUMA architectures Programming models on a NUMA architecture can be classified into three types: distributed memory, partially shared
Reference: [18] <author> A. H. Karp, H. P. Flatt, </author> <title> "Measuring parallel processor performance", </title> <journal> Communications of the ACM, </journal> <volume> Vol. 33, No. 5, </volume> <year> 1990, </year> <pages> pp. 539-543. </pages>
Reference-contexts: Amdahl's model may be modified by adding an overhead function term T o (p) to include the practical effects T (p) = t s + p The modified Amdahl's model has been used for evaluating parallel processing performance on different architectures, such as the vector supercomputers (see e.g. <ref> [18] </ref>), distributed memory mul-ticomputer hypercube (see e.g. [13]), and UMA shared memory multiprocessors (see e.g. [28]).
Reference: [19] <author> R. P. LaRowe, Jr., C. S. Ellis, </author> <title> "Experimental comparison of memory Management policies for NUMA multiprocessors", </title> <type> Technical Report, </type> <institution> CS-1990-10, Department of Computer Science, Duke University, </institution> <year> 1990. </year>
Reference-contexts: A scheduling mechanism is supported to schedule the processes dynamically among the processors in run time. Several related studies have been conducted to understand and improve the parallel processing performance on a NUMA multiprocessor. LaRowe and Ellis (see <ref> [19] </ref>) take an experimental approach to compare a wide-range of memory management policies on a target NUMA system, the BBN GP1000. Their system experiments conclude that the placement and movement of code and data are crucial to NUMA performance.
Reference: [20] <author> C. A. Lee, </author> <title> "Barrier synchronization over multistage interconnection networks", </title> <type> Report SSD-TR-90-35, </type> <institution> The Aerospace Corporation, El Segundo, California 1990. </institution>
Reference-contexts: Inter ested readers may refer to <ref> [20] </ref> and [8]. 3.2 Self-scheduling and shared memory programming In order to balance the processing load, the tasks are dynamically scheduled or self-scheduled to processors at runtime.
Reference: [21] <author> G. Pfister, </author> <title> "The IBM research parallel processor prototype (RP3): Introduction and architecture", </title> <booktitle> Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <volume> Vol. 2, </volume> <year> 1985, </year> <pages> pp. 160-169. </pages>
Reference-contexts: Therefore, a NUMA architecture can scale large number of processors in shared memory multiprocessor design. Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], [16], [23]), Cedar at the University of Illinois (see e.g. [14], [26]), the IBM RP3 (see e.g. <ref> [21] </ref>), Cm* and PLUS at Carnegie-Mellon University (see e.g. [9], [17], [22]), Hector (see [25]) and Paradigm (see [11]), in which the BBN butterfly machines are the only systems commercially available, and the rest are research model architectures. 1.1 Programming models on a NUMA architectures Programming models on a NUMA architecture
Reference: [22] <author> R. J. Swan, </author> <title> "Cm* a modular, multi-microprocessor", </title> <booktitle> 1977 National Computer Conference, </booktitle> <volume> Vol. 46, </volume> <year> 1977, </year> <pages> pp. 637-644. </pages>
Reference-contexts: Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], [16], [23]), Cedar at the University of Illinois (see e.g. [14], [26]), the IBM RP3 (see e.g. [21]), Cm* and PLUS at Carnegie-Mellon University (see e.g. [9], [17], <ref> [22] </ref>), Hector (see [25]) and Paradigm (see [11]), in which the BBN butterfly machines are the only systems commercially available, and the rest are research model architectures. 1.1 Programming models on a NUMA architectures Programming models on a NUMA architecture can be classified into three types: distributed memory, partially shared memory
Reference: [23] <author> R. Thomas, </author> <title> "Behavior of the Butterfly parallel processor in the presence of memory hot spots", </title> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <year> 1986, </year> <pages> pp. 51-58. </pages>
Reference-contexts: Therefore, a NUMA architecture can scale large number of processors in shared memory multiprocessor design. Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], [16], <ref> [23] </ref>), Cedar at the University of Illinois (see e.g. [14], [26]), the IBM RP3 (see e.g. [21]), Cm* and PLUS at Carnegie-Mellon University (see e.g. [9], [17], [22]), Hector (see [25]) and Paradigm (see [11]), in which the BBN butterfly machines are the only systems commercially available, and the rest are <p> This ties up more resources in the switch, and increases the chance that subsequent messages will also block. The non-blocking network greatly reduces the traffic conflicts in practice (see e.g. <ref> [23] </ref>): when conflicts happen, the switch has all but the "first" message retreat back to its source and free up their path. It then selects an alternative route, and after a random delay, tries again.
Reference: [24] <author> W. Wu, </author> <title> Experimental Studies on Different Programming Models on the BBN GP1000, </title> <institution> Master Thesis of Computer Science, University of Texas at San Antonio 1991. </institution>
Reference-contexts: This is because a connection between a processor and a remote memory module for remote memory access is established through two level switches. Therefore, the distributed programming model on the BBN GP1000 is not preferred unless very large data sets need to be exchanged occasionally. (see <ref> [24] </ref>). 3 Process scheduling models and synchronization overhead There are two major process scheduling models available on a NUMA multiprocessor, pre-scheduling for the partially shared memory programming model and self-scheduling for the fully shared memory programming model.
Reference: [25] <author> Z. G. Vranesic et al, "Hector: </author> <title> a hierarchically structured shared memory multiprocessor", </title> <journal> IEEE Computer, </journal> <volume> Vol. 24, No. 1, </volume> <year> 1991, </year> <pages> pp. 72-80. </pages>
Reference-contexts: Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], [16], [23]), Cedar at the University of Illinois (see e.g. [14], [26]), the IBM RP3 (see e.g. [21]), Cm* and PLUS at Carnegie-Mellon University (see e.g. [9], [17], [22]), Hector (see <ref> [25] </ref>) and Paradigm (see [11]), in which the BBN butterfly machines are the only systems commercially available, and the rest are research model architectures. 1.1 Programming models on a NUMA architectures Programming models on a NUMA architecture can be classified into three types: distributed memory, partially shared memory and fully shared
Reference: [26] <author> P. Yew, </author> <title> "Architecture of the Cedar parallel supercomputer", </title> <type> Technical Report CSRD 609, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, </institution> <year> 1986. </year>
Reference-contexts: Therefore, a NUMA architecture can scale large number of processors in shared memory multiprocessor design. Examples of current NUMA architectures include BBN Butterfly family (see e.g. [3]-[5], [16], [23]), Cedar at the University of Illinois (see e.g. [14], <ref> [26] </ref>), the IBM RP3 (see e.g. [21]), Cm* and PLUS at Carnegie-Mellon University (see e.g. [9], [17], [22]), Hector (see [25]) and Paradigm (see [11]), in which the BBN butterfly machines are the only systems commercially available, and the rest are research model architectures. 1.1 Programming models on a NUMA architectures
Reference: [27] <author> X. Zhang, </author> <title> "Parallel partition and simulation for large-scale circuits on a local memory mul-ticomputer", </title> <journal> International Journal of Computer Aided VLSI Design, </journal> <volume> Vol. 2, No. 2, </volume> <year> 1990, </year> <pages> pp. 213-237. </pages>
Reference-contexts: For detailed mathematical analyses of the nonlinear block bordered equations, reader may refer to <ref> [27] </ref>. The circuit equations usually are highly nonlinear so that a Newton step easily may result in an increase in the function norm. In addition, many block bordered equations result in nearly singular or singular Jacobians in the iteration process. <p> The modifications on some of the subsystems, such as a line search and matrix perturbations (see e.g. [12]) require extra computing time that cannot be predicted statically before running the program. The testing circuit problem we simulated was the 741 op-amp from <ref> [27] </ref>, where q = 4. Using the pre-scheduling model, the block bordered equations f i (x i ; x q+1 ) = 0 of the 741 op-amp circuit were distributed among 1, 2, and 4 nodes of the GP1000 respectively. <p> This is because the partitioned systems were well balanced before the runtime, therefore the dynamic scheduling became a real overhead in the multiprocessing. We also simulated an analog filter connected by 3 blocks of 741 op-amp circuit (see <ref> [27] </ref>) on 13 the GP1000 where 12 sub-circuit systems are generated. The 12 block equations of the analog filter were distributed among 1, 3, 6, and 12 nodes of the GP1000 respectively.
Reference: [28] <author> X. Zhang, </author> <title> "Performance measurement and modeling to evaluate various effects on a shared memory multiprocessor", </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 17, No. 1, </volume> <year> 1991, </year> <pages> pp. </pages> <month> 87-93.. </month>
Reference-contexts: (p) to include the practical effects T (p) = t s + p The modified Amdahl's model has been used for evaluating parallel processing performance on different architectures, such as the vector supercomputers (see e.g. [18]), distributed memory mul-ticomputer hypercube (see e.g. [13]), and UMA shared memory multiprocessors (see e.g. <ref> [28] </ref>). The overhead function T o (p) can be affected by the structure of the application which influences the necessity for communication, task dispatching algorithm used to control assignment of processes to processors as well as the hardware and software mechanisms for communication and synchronization.
Reference: [29] <author> X. Zhang, </author> <title> "System effects of interprocessor communication latency in multicomputers", </title> <journal> IEEE Micro, </journal> <volume> Vol. 21, No. 2, </volume> <year> 1991, </year> <pages> pp. 12-19. </pages>
Reference-contexts: We used Different sizes of message packets, from 1 byte to 8K bytes, in our experiment, and used a least square fit to approximate ff and fi. Table 1 gives the ff and fi of the GP1000 comparing with other five types of distributed memory multicomputers (see e.g. <ref> [29] </ref>). Our experimental results show that the message-passing on the GP1000 is not very efficient. The bandwidth of the communication channel fi is same as the one of Intel iPSC/1, a representative of the first generation hypercube multicomputer.
Reference: [30] <author> X. Zhang, P. Srinivasan, </author> <title> "Distributed task processing performance on a NUMA shared memory multiprocessor", </title> <booktitle> Proceedings of the Second IEEE Symposium on Parallel and Distributed Processing Conference, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1990, </year> <pages> pp. 786-789. 23 network. 24 </pages>
Reference-contexts: The performance factors of NUMA multiprocessors (for example, the BBN GP1000), such as the data access time, scheduling overhead and others have been measured through various application programs (see e.g. [10], <ref> [30] </ref>). As memory architectures and interconnection networks become more complex, the performance prediction and evaluation of a NUMA architecture become more difficult.
References-found: 30

