URL: ftp://ams.sunysb.edu/pub/geometry/msi-workshop/95/claudio.ps.gz
Refering-URL: http://ams.sunysb.edu/~held/proc_usb_comp_geo-95.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Automatic Generation of Triangular Irregular Networks using Greedy Cuts  
Author: Claudio T. Silva Joseph S. B. Mitchell Arie E. Kaufman 
Affiliation: State University of New York at Stony Brook  
Abstract: We propose a new approach to the automatic generation of triangular irregular networks from dense terrain models. We have developed and implemented an algorithm based on the greedy principle used to compute minimum-link paths in polygons. Our algorithm works by taking greedy cuts ("bites") out of a simple closed polygon that bounds the yet-to-be triangulated region. The algorithm starts with a large polygon, bounding the whole extent of the terrain to be triangulated, and works its way inward, performing at each step, one of three basic operations: ear cutting, greedy biting, and edge splitting. We give experimental evidence that our method is competitive with current algorithms and has the potential to be faster and to generate much fewer triangles. Also, it is able to keep the structural terrain fidelity at almost no extra cost in running time and it requires very little memory beyond that for the input height array. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. K. Agarwal and S. Suri. </author> <title> Surface approximation and geometric partitions. </title> <booktitle> In Proc. Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 34-43, </pages> <year> 1994. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see <ref> [1, 3, 15, 17] </ref>), or within a constant factor of optimal, if the surface is convex (see [2]). Unfortunately, the polynomial time bounds for these theoretically good approaches is rather high (at least cubic).
Reference: [2] <author> H. Bronnimann and M. T. Goodrich. </author> <title> Almost optimal set covers in finite VC-dimension. </title> <booktitle> In Proc. 10th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 293-302, </pages> <year> 1994. </year>
Reference-contexts: simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see [1, 3, 15, 17]), or within a constant factor of optimal, if the surface is convex (see <ref> [2] </ref>). Unfortunately, the polynomial time bounds for these theoretically good approaches is rather high (at least cubic).
Reference: [3] <author> K. L. Clarkson. </author> <title> Algorithms for polytope covering and approximation. </title> <booktitle> In Proc. 3rd Workshop Algorithms Data Struct., volume 709 of Lecture Notes in Computer Science, </booktitle> <pages> pages 246-252, </pages> <year> 1993. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see <ref> [1, 3, 15, 17] </ref>), or within a constant factor of optimal, if the surface is convex (see [2]). Unfortunately, the polynomial time bounds for these theoretically good approaches is rather high (at least cubic). <p> The principle that drives our method (and is related to that of <ref> [3, 17, 24] </ref>) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry [11, 16, 23] and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]).
Reference: [4] <author> G. Das and D. Joseph. </author> <title> Minimum vertex hulls for polyhedral domains. </title> <journal> Theoret. Comput. Sci., </journal> <volume> 103 </volume> <pages> 107-135, </pages> <year> 1992. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) <ref> [5, 4] </ref>, but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see [1, 3, 15, 17]), or within a constant factor of optimal, if the surface is convex (see [2]).
Reference: [5] <author> Gautam Das and Michael T. Goodrich. </author> <title> On the complexity of approximating and illuminating three-dimensional convex polyhedra. </title> <booktitle> In Proc. 4th Workshop Algorithms Data Struct., Lecture Notes in Computer Science, page To appear. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) <ref> [5, 4] </ref>, but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see [1, 3, 15, 17]), or within a constant factor of optimal, if the surface is convex (see [2]).
Reference: [6] <author> M. de Berg and K. Dobrindt. </author> <title> On levels of detail in terrains. </title> <booktitle> In Proc. 11th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages C26-C27, </pages> <year> 1995. </year>
Reference-contexts: For a survey, see Scarlatos' dissertation [18] and the survey by Heckbert [12]. A recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt <ref> [6] </ref>, who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail. See also [13, 14] for an approach called the "drop heuristic" and its comparison with other methods.
Reference: [7] <author> L. De Floriani. </author> <title> A pyramidal data structure for triangle-based surface representation. </title> <journal> IEEE Comput. Graph. Appl., </journal> <volume> 9 </volume> <pages> 67-78, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: A new version of his code is publically available, and we used it for comparison with our method. Substantial research has been conducted on creating hierarchical structures on top of TINs <ref> [7, 20] </ref>, and on techniques to improve the quality of TIN meshes [21]. For a survey, see Scarlatos' dissertation [18] and the survey by Heckbert [12].
Reference: [8] <author> R. J. Fowler and J. J. Little. </author> <title> Automatic extraction of irregular network digital terrain models. </title> <journal> Computer Graphics, </journal> <volume> 13(2) </volume> <pages> 199-207, </pages> <month> August </month> <year> 1979. </year>
Reference-contexts: TINs stand out as being one of the most convenient to use for rendering and other geometric manipulation operations. A TIN is a set of contiguous nonoverlapping triangles whose vertices are placed adaptively over the DEM domain <ref> [8] </ref>. The automatic generation of TIN models from DEM models is an important area of research and is the main topic of this article. <p> Fowler and Little <ref> [8] </ref> gave one of the first (and still very popular) methods to address the problem of automatic generation of TINs directly from DEMs. Their method is very simple. First, they classify the points by automatically choosing some "important" features of the terrain, such as, ridges, peaks, etc.
Reference: [9] <author> W. R. Franklin. </author> <title> Triangulated irregular network to approximate digital terrain, Section 2.3, Research Interests. </title> <type> Technical report, </type> <institution> Electrical, Computer, and Systems Engineering Dept., Rensselaer Polytechnic Institute, </institution> <address> Troy, NY, </address> <year> 1994. </year> <note> Manuscript and code available on ftp://ftp.cs.rpi.edu/pub/franklin/. </note>
Reference-contexts: At each step, a new point is added to the triangulation until no points are farther from the original surface than a certain predefined threshold, *. This phase is designed to preserve the "statistical fidelity" (i.e, to make it fit the specified error bound). Franklin <ref> [9] </ref> proposed a similar approach back in 1973. It appears that his method had no notion of structural fidelity and he did not use the Delaunay triangulation as the basis for his method.
Reference: [10] <author> M. T. Goodrich. </author> <title> Efficient piecewise-linear function approximation using the uniform metric. </title> <booktitle> In Proc. 10th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 322-331, </pages> <year> 1994. </year>
Reference-contexts: This problem is well studied in computational geometry [11, 16, 23] and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see <ref> [10] </ref>). Our problem is of one higher dimension.
Reference: [11] <author> L. J. Guibas, J. E. Hershberger, J. S. B. Mitchell, and J. S. Snoeyink. </author> <title> Approximating polygons and subdivisions with minimum link paths. </title> <journal> Internat. J. Comput. Geom. Appl., </journal> <volume> 3(4) </volume> <pages> 383-415, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: The principle that drives our method (and is related to that of [3, 17, 24]) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry <ref> [11, 16, 23] </ref> and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]). Our problem is of one higher dimension.
Reference: [12] <author> P. S. Heckbert and M. </author> <title> Garland. Fast polygonal approximation of terrains and height fields. </title> <type> Technical Report CMU-CS-95-181, </type> <institution> Carnegie Mellon University, </institution> <year> 1995. </year>
Reference-contexts: Substantial research has been conducted on creating hierarchical structures on top of TINs [7, 20], and on techniques to improve the quality of TIN meshes [21]. For a survey, see Scarlatos' dissertation [18] and the survey by Heckbert <ref> [12] </ref>. A recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt [6], who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail.
Reference: [13] <author> J. Lee. </author> <title> A drop heuristic conversion method for extracting irregular network for digital elevation models. </title> <booktitle> In GIS/LIS '89 Proc., </booktitle> <volume> volume 1, </volume> <pages> pages 30-39. </pages> <booktitle> American Congress on Surveying and Mapping, </booktitle> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: A recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt [6], who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail. See also <ref> [13, 14] </ref> for an approach called the "drop heuristic" and its comparison with other methods. Common to all these previous methods is a necessity to have a complete starting triangulation, that is either refined by adding new points, or decimated [22] by removing redundant points.
Reference: [14] <author> J. Lee. </author> <title> Comparison of existing methods for building triangular irregular network models of terrain from grid digital elevation models. </title> <journal> Intl. J. of Geographical Information Systems, </journal> <volume> 5(3) </volume> <pages> 267-285, </pages> <month> July-Sept. </month> <year> 1991. </year>
Reference-contexts: A recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt [6], who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail. See also <ref> [13, 14] </ref> for an approach called the "drop heuristic" and its comparison with other methods. Common to all these previous methods is a necessity to have a complete starting triangulation, that is either refined by adding new points, or decimated [22] by removing redundant points.
Reference: [15] <author> J. S. B. Mitchell. </author> <title> Approximation algorithms for geometric separation problems. </title> <type> Technical report, </type> <institution> Dept, of Applied Math, University at Stony Brook, Stony Brook, </institution> <address> NY, </address> <month> July, </month> <year> 1993. </year>
Reference-contexts: From an algorithmic point of view, terrain simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see <ref> [1, 3, 15, 17] </ref>), or within a constant factor of optimal, if the surface is convex (see [2]). Unfortunately, the polynomial time bounds for these theoretically good approaches is rather high (at least cubic).
Reference: [16] <author> J. S. B. Mitchell, G. Rote, and G. Woeginger. </author> <title> Minimum-link paths among obstacles in the plane. </title> <journal> Algorithmica, </journal> <volume> 8 </volume> <pages> 431-459, </pages> <year> 1992. </year>
Reference-contexts: The principle that drives our method (and is related to that of [3, 17, 24]) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry <ref> [11, 16, 23] </ref> and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]). Our problem is of one higher dimension.
Reference: [17] <author> J. S. B. Mitchell and S. Suri. </author> <title> Separation and approximation of polyhedral surfaces. </title> <booktitle> In Proc. 3rd ACM-SIAM Sympos. Discrete Algorithms, </booktitle> <pages> pages 296-306, </pages> <year> 1992. </year>
Reference-contexts: The need for global information impacts the running time and memory requirements of these algorithms. Our work is based on an entirely different approach for the triangulation and simplification of the data. It is based on an idea in the method developed by Mitchell and Suri <ref> [17] </ref>, where a greedy set cover approach was developed for approximating convex surfaces, and used recently by Varshney [24] in heuristics for simplifying CAD models. We can consider the input DEM to be an instance of a TIN with very high resolution. <p> From an algorithmic point of view, terrain simplification is hard (NP-hard) [5, 4], but some polynomial-time algorithms are known for computing a nearly-optimal (i.e., nearly minimum-facet) approximating surface, guaranteed to be within a factor O (log n) of optimal (see <ref> [1, 3, 15, 17] </ref>), or within a constant factor of optimal, if the surface is convex (see [2]). Unfortunately, the polynomial time bounds for these theoretically good approaches is rather high (at least cubic). <p> The principle that drives our method (and is related to that of <ref> [3, 17, 24] </ref>) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry [11, 16, 23] and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]).
Reference: [18] <author> L. Scarlatos. </author> <title> Spatial data representations for rapid visualization and analysis. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, State University of New York at Stony Brook, Stony Brook, </institution> <address> NY 11794-4400, </address> <year> 1993. </year>
Reference-contexts: The automatic generation of TIN models from DEM models is an important area of research and is the main topic of this article. Several factors are important in judging the quality of the TIN representation of a given DEM (list partially adapted from <ref> [18, 19] </ref>): * Numerical accuracy measured as maximum, mean, or standard deviation error; * Visual accuracy usually assessed by inspection and by number of "slivery" triangles; * Size of the model measured as the number of output triangles; y Dept. of Computer Science z Dept. of Applied Mathematics & Statistics x <p> Substantial research has been conducted on creating hierarchical structures on top of TINs [7, 20], and on techniques to improve the quality of TIN meshes [21]. For a survey, see Scarlatos' dissertation <ref> [18] </ref> and the survey by Heckbert [12]. A recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt [6], who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail.
Reference: [19] <author> L. Scarlatos and T. Pavlidis. </author> <title> Hierarchical triangulation using terrain features. </title> <booktitle> In Proc. of the IEEE Conference on Visualization Visualization '90, </booktitle> <pages> pages 168-175. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: The automatic generation of TIN models from DEM models is an important area of research and is the main topic of this article. Several factors are important in judging the quality of the TIN representation of a given DEM (list partially adapted from <ref> [18, 19] </ref>): * Numerical accuracy measured as maximum, mean, or standard deviation error; * Visual accuracy usually assessed by inspection and by number of "slivery" triangles; * Size of the model measured as the number of output triangles; y Dept. of Computer Science z Dept. of Applied Mathematics & Statistics x
Reference: [20] <author> L. Scarlatos and T. Pavlidis. </author> <title> Hierarchical triangulation using cartographics coherence. CVGIP: Graph. Models Image Process., </title> <booktitle> 54(2) </booktitle> <pages> 147-161, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: A new version of his code is publically available, and we used it for comparison with our method. Substantial research has been conducted on creating hierarchical structures on top of TINs <ref> [7, 20] </ref>, and on techniques to improve the quality of TIN meshes [21]. For a survey, see Scarlatos' dissertation [18] and the survey by Heckbert [12].
Reference: [21] <author> L. Scarlatos and T. Pavlidis. </author> <title> Optimizing triangulation by curvature equalization. </title> <booktitle> In Proc. of the IEEE Conference on Visualization Visualization '92, </booktitle> <pages> pages 333-339. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: A new version of his code is publically available, and we used it for comparison with our method. Substantial research has been conducted on creating hierarchical structures on top of TINs [7, 20], and on techniques to improve the quality of TIN meshes <ref> [21] </ref>. For a survey, see Scarlatos' dissertation [18] and the survey by Heckbert [12]. A recent approach to building hierarchical models of terrains is given by de Berg and Dobrindt [6], who apply a hierarchical refinement of the Delaunay triangulation to represent terrain TINs at many levels of detail.
Reference: [22] <author> W. J. Schroeder, J. A. Zarge, and W. E. Lorensen. </author> <title> Decimation of triangle meshes. </title> <booktitle> In SIGGRAPH '92, </booktitle> <volume> volume 26, </volume> <pages> pages 65-70, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: See also [13, 14] for an approach called the "drop heuristic" and its comparison with other methods. Common to all these previous methods is a necessity to have a complete starting triangulation, that is either refined by adding new points, or decimated <ref> [22] </ref> by removing redundant points. These approaches require that the algorithm maintain in memory a complete triangulation representation of the input, extended with various pieces of global information (e.g., most deviant point per trian gle). The need for global information impacts the running time and memory requirements of these algorithms.
Reference: [23] <author> S. Suri. </author> <title> On some link distance problems in a simple polygon. </title> <journal> IEEE Trans. Robot. Autom., </journal> <volume> 6 </volume> <pages> 108-113, </pages> <year> 1990. </year>
Reference-contexts: The principle that drives our method (and is related to that of [3, 17, 24]) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry <ref> [11, 16, 23] </ref> and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]). Our problem is of one higher dimension.
Reference: [24] <author> A. Varshney. </author> <title> Hierarchical Geometric Approximations. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, University of North Carolina, </institution> <address> Chapel Hill, NC 27599-3175, </address> <year> 1994. TR-050-1994. </year>
Reference-contexts: Our work is based on an entirely different approach for the triangulation and simplification of the data. It is based on an idea in the method developed by Mitchell and Suri [17], where a greedy set cover approach was developed for approximating convex surfaces, and used recently by Varshney <ref> [24] </ref> in heuristics for simplifying CAD models. We can consider the input DEM to be an instance of a TIN with very high resolution. <p> The principle that drives our method (and is related to that of <ref> [3, 17, 24] </ref>) is the same greedy principle that is used to compute minimum-link paths in simple polygons. This problem is well studied in computational geometry [11, 16, 23] and can be used to find an optimal piecewise-linear approximation to a function of a single variable (see [10]).
References-found: 24

