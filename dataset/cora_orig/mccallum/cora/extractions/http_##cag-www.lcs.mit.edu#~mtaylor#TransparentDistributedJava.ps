URL: http://cag-www.lcs.mit.edu/~mtaylor/TransparentDistributedJava.ps
Refering-URL: http://cag-www.lcs.mit.edu/~mtaylor/paper.html
Root-URL: 
Title: Transparent Distributed Java  
Author: Douglas S. J. De Couto Brandon W. Porter Michael B. Taylor 
Date: November 30, 1997  
Abstract: We describe our modifications to the Kaffe Java runtime to support transparent distribution of Java threads and objects across multiple processors and machines. We also discuss the design of a shared object system used by the Java runtime to provide transparent object sharing to Java applications. Although we also implemented a version for symmetric multiprocessors (SMPs), this paper focuses on a version designed for networks of workstations (NOWs). We describe our experiences and difficulties in modifying Kaffe, and present some ideas on how to best construct a distributed Java runtime system which includes support for transparent distributed threads and objects. Finally, we present performance results based on micro and application level benchmarks. These results show that a single-threaded Java runtime can be converted into a multi-thread distributed runtime without great loss of performance. The results also however show that the same issues arise with transparency, scalability and performance as in any distributed parallel system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anderson, Thomas E., David E. Culler, David A. Patterson, </author> <title> and the NOW team. "A Case for Networks of Workstations: NOW." </title> <booktitle> IEEE Micro. </booktitle> <month> February, </month> <year> 1995 </year>
Reference-contexts: Because a Java program can be compiled into a single set of bytecodes which will run on different fl fdecouto,bwporter,mbtg@mit.edu machines, and because the Java language has built-in threading support, Java provides a natural platform for distributed heterogeneous computing on networks of workstations (NOWs) <ref> [1] </ref> and symmetric multiprocessors (SMPs). We undertook this project with the vision of modifying a Java runtime system to transparently execute multithreaded Java programs across a single processor, an SMP, or a NOW.
Reference: [2] <author> Bertelsen, Peter. </author> <title> "Semantics of Java Byte Code." </title> <institution> Department of Information Technology, Technical University of Denmark. </institution> <month> March, </month> <year> 1997. </year> <note> Available at ftp://ftp.dina.kvl.dk/pub/Staff/ Peter.Bertelsen/jvm-semantics.ps.gz. </note>
Reference-contexts: The Java Virtual Machine is not completely specified; also, there are some inconsistencies and errors in the Java Virtual Machine specification which complicate the Kaffe implementation <ref> [2] </ref>. For instance, in Java, every class is associated with an object instance that contains information about that class. But every object instance must also be associated with a class. <p> But every object instance must also be associated with a class. Thus there is a circularity problem when loading the root of the Java class hierarchy, Java.lang.Object, which must be resolved by special handling in the Kaffe interpreter <ref> [2] </ref>. Even the parts of the Java runtime environment which are completely specified are complex and hard to understand. When Kaffe initializes its run time environment, it has to construct and initialize many objects to support threads, I/O, strings, and other various aspects of the Java programming environment.
Reference: [3] <author> Christansen, Bernd O., et al."Javelin: </author> <title> Internet-Based Parallel Computation Using Java." </title> <booktitle> ACM 1997 Workshop on Java for Science and Engineering Computation. </booktitle>
Reference-contexts: It then preprocesses the annotated code into regular Java code that uses RMI to distribute objects and computation across a network. JavaParty also allows programs to access objects stored locally without the overhead of RMI. Javelin <ref> [3] </ref> provides an application level framework for distributing computation over the Internet. It is essentially a broker system where clients send tasks to a broker; the broker then distributes the tasks to participating computers. It does not leverage Java's built in threading model, and provides a limited programming model.
Reference: [4] <author> De Couto, Douglas S. J., Brandon W. Porter and Michael B. Taylor. </author> <title> "A Survey of Distributed Java Computing and Software Shard Memory Systems." 6.853 Mock Area Exam, </title> <month> October, </month> <year> 1997. </year> <note> Available at http://graphics.lcs.mit.edu/~decouto/ 6.853/project/area-exam.ps. </note>
Reference-contexts: Another difference between our work and Java/DSM is that we provide location transparent thread distribution. A more detailed discussion of these distributed Java systems and software shared memory systems can be found in <ref> [4] </ref>. 3 Design and Implementation The salient parameters for any parallel Java runtime are: how threading is implemented, how sharing of objects is facilitated between these threads, if constant pool objects and internal data structures are shared objects, how garbage collecting is performed on these objects, how I/O is performed, and
Reference: [5] <author> Gosling, James, Bill Joy, and Guy Steele. </author> <title> The Java anguage Specification. </title> <publisher> Addison Wesley, </publisher> <year> 1996. </year> <title> [6] "Remote Method Invocation Specification." </title> <journal> Java-Soft. </journal> <note> Available at http://www.javasoft.com. </note>
Reference-contexts: 1 Introduction Java <ref> [5] </ref> [8] is one of the fastest growing computer languages. This phenomenon is due in part to Java's massive industry support. But it is also due to Java's convenient language structures, libraries, and runtime system.
Reference: [7] <author> Kehler, Pete, et al. "TreadMarks: </author> <title> Distributed Shared Memory on Standard workstations and Operating Systems." </title> <booktitle> 1994 Winter USENIX. </booktitle>
Reference-contexts: It does not leverage Java's built in threading model, and provides a limited programming model. Java/DSM [13] is the system most similar to our work. It too aims to provide a transparent distributed Java runtime environment on heterogeneous computers. Java/DSM uses the TreadMarks <ref> [7] </ref> software shared memory system to share memory and perform synchronization; Java/DSM also performs data type conversion and garbage collection across different machines. According to [13], Java/DSM is also not a complete distributed Java runtime: it does not fully support I/O, and does not have location transparent threading. <p> The SAM system [10] is finegrained but not transparent. It requires the programmer to make semantic changes in the actual application code. An example of a coarse-grained and transparent shared memory system is the TreadMarks page-based system <ref> [7] </ref>, which requires minimal changes to the application code and works at the virtual memory management level. However, in these systems, the unit of sharing is not related to the application, which causes them to be prone to false sharing.
Reference: [8] <author> Lindholm, Tim, and Frank Yellin. </author> <title> The Java Virtual Machine Specification. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: 1 Introduction Java [5] <ref> [8] </ref> is one of the fastest growing computer languages. This phenomenon is due in part to Java's massive industry support. But it is also due to Java's convenient language structures, libraries, and runtime system.
Reference: [9] <author> Philipsen, Michael and Matthias Zenger. </author> <title> "Java-party Transparent Remote Objects in Java." </title> <booktitle> ACM 1997 Workshop on Java for Science and Engineering Computation. </booktitle>
Reference-contexts: RMI also supports heterogeneous plat-forms through data conventions. In practice, RMI implementations require a relatively high degree of programming overhead up to 66% more code for some applications <ref> [9] </ref>. A distributed thread implementation uses the built-in language constructs for threads, and consequently requires less programming effort by application developers. JavaParty [9] allows programmers to annotate threads and classes in Java code as "remote". <p> In practice, RMI implementations require a relatively high degree of programming overhead up to 66% more code for some applications <ref> [9] </ref>. A distributed thread implementation uses the built-in language constructs for threads, and consequently requires less programming effort by application developers. JavaParty [9] allows programmers to annotate threads and classes in Java code as "remote". It then preprocesses the annotated code into regular Java code that uses RMI to distribute objects and computation across a network. JavaParty also allows programs to access objects stored locally without the overhead of RMI.
Reference: [10] <author> Scales, Daniel J. and Monica S. Lam. </author> <title> "The Design and Evaluation of a Shared Object System for Distributed Memory Machines." </title> <booktitle> First Symposium on OPerating Systems Design and Implementation (OSDI), </booktitle> <year> 1994. </year>
Reference-contexts: The Shasta system [11] is both transparent and fine-grained. It rewrites binary executables to transparently reimplement load and store instructions as necessary. It customizes the size of the basic sharing unit, and performs analysis so that memory on the stack is not shared unnecessarily. The SAM system <ref> [10] </ref> is finegrained but not transparent. It requires the programmer to make semantic changes in the actual application code.
Reference: [11] <author> Scales, Daniel J., Kouroush Gharachorloo, and Chandramohan A. Thekkath. </author> <title> "Shasta: A Low Overhead, Software-Only Approach for Supporting Fine-Grain Shared Memory." </title> <booktitle> Proceedings of the Seventh International Conference on Architectural Support for Porgramming Languages and Operating Systems. </booktitle> <month> October, </month> <year> 1996. </year>
Reference-contexts: It is transparent if the process to transform a non shared memory application into a software shared memory application does not require programmer intervention. The Shasta system <ref> [11] </ref> is both transparent and fine-grained. It rewrites binary executables to transparently reimplement load and store instructions as necessary. It customizes the size of the basic sharing unit, and performs analysis so that memory on the stack is not shared unnecessarily. The SAM system [10] is finegrained but not transparent. <p> Regardless, the best way to accelerate the network operations would be to a more direct interface to the network. A good start might be using UDP data-grams instead of the more heavyweight TCP protocol. More extreme measure could be taken. The Shasta <ref> [11] </ref> project, for instance, provided the applications with direct access to the network device. 5.2 Application Benchmark: RayTrace For our application-level benchmark, we searched for an application that had the following properties: it was easily parallelizable; it was already written as an existing Java program; and it was easily scalable to
Reference: [12] <editor> The Magic Cookie Reference Manual, </editor> <volume> Volume 1. </volume> <publisher> SOB Technologies Inc, </publisher> <year> 1997. </year>
Reference-contexts: We used a "magic cookie" (or "magic number") scheme to differentiate between local object references and shared object references <ref> [12] </ref>. Each shared class instance is represented locally with a modified form of the object data structure (Figure 4). This stucture starts with a special, unique magic cookie value, and contains the dispatch tables and corresponding shared object id.
Reference: [13] <author> Yu, Weimin and Alan Cox. "Java/DSM: </author> <title> A Platform for Heterogeneous Computing." </title> <booktitle> ACM 1997 Workshop on Java for Science and Engineering Computation. </booktitle> <pages> 17 </pages>
Reference-contexts: It is essentially a broker system where clients send tasks to a broker; the broker then distributes the tasks to participating computers. It does not leverage Java's built in threading model, and provides a limited programming model. Java/DSM <ref> [13] </ref> is the system most similar to our work. It too aims to provide a transparent distributed Java runtime environment on heterogeneous computers. Java/DSM uses the TreadMarks [7] software shared memory system to share memory and perform synchronization; Java/DSM also performs data type conversion and garbage collection across different machines. <p> It too aims to provide a transparent distributed Java runtime environment on heterogeneous computers. Java/DSM uses the TreadMarks [7] software shared memory system to share memory and perform synchronization; Java/DSM also performs data type conversion and garbage collection across different machines. According to <ref> [13] </ref>, Java/DSM is also not a complete distributed Java runtime: it does not fully support I/O, and does not have location transparent threading. There is no information about how Java/DSM implements distributed threads, nor are there any reported performance measurements.
References-found: 12

