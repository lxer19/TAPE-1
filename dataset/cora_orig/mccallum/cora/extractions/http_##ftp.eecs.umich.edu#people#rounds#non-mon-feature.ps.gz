URL: http://ftp.eecs.umich.edu/people/rounds/non-mon-feature.ps.gz
Refering-URL: http://ftp.eecs.umich.edu/people/rounds/
Root-URL: http://www.eecs.umich.edu
Title: Suggestions for a Non-monotonic Feature Logic  
Author: William C. Rounds 
Note: DRAFT!!!  
Address: Ann Arbor, Michigan 48109 U.S.A. CWI Kruislaan 413 1098 SJ Amsterdam Netherlands  
Affiliation: Artificial Intelligence Laboratory University of Michigan  
Abstract: We use Scott's domain theory and methods from Reiter's default logic to suggest some ways of modelling default constraints in feature logic. We show how default feature rules, derived from default constraints, can be used to give ways to augment strict feature structures with default information. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Blackburn and E. Spaan. </author> <title> A modal perspective on the computational complexity of attribute value grammar. </title> <journal> Journal of Logic, Language, and Information, </journal> <volume> 2 </volume> <pages> 129-169, </pages> <year> 1993. </year>
Reference-contexts: For us, the full semantics is a considerable complication, especially given Blackburn and Spaan's result that in general, the existence of a resolved structure given an arbitrary constraint system is undecidable <ref> [1] </ref>. For this reason, we will generally ignore algorithms for computing resolved structures and extensions. Lascarides, Briscoe, Asher, and Copestake [13] have also treated these problems. <p> We could also consider a variant notion in which for each type a, there was a set C (a) of GPSG-style constraints, and then require inheritance of these onto subtypes. Blackburn and Spaan <ref> [1] </ref>, and Reape [20] have investigated this direction extensively. In their formulation, the type symbols a can be thought of as special propositional variables, perhaps rewritten as p a . The modality l : ' is written hli', and a negation operator :OE is included.
Reference: [2] <author> P. Buneman, A. Jung, and A. Ohori. </author> <title> Using powerdomains to generalize relational data bases. </title> <journal> Theoretical Computer Science, </journal> <volume> 91 </volume> <pages> 23-55, </pages> <year> 1991. </year>
Reference-contexts: One can use other orderings on sets of domain elements to get new powerdomains. Two other common constructions, for example, are the Hoare (lower) and the Plotkin (convex) powerdomains. See Gunter and Scott [8] for a survey. More powerdomains can be found in the work of Buneman et al. <ref> [2] </ref>, Gunter [7], and Libkin [14].
Reference: [3] <author> B. Carpenter. </author> <title> The Logic of Typed Feature Structures. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Using the idea of or-sets, and updates, we are able to find a natural notion of default which allows us to characterize the notion of "completing" a feature structure with both strict and default constraints. Our basic data structure is the typed feature structure, discussed in Carpenter's book <ref> [3] </ref>. We start with recursive type constraint systems, as in [3, Chapter 15]. Our setting is slightly different from that used by Carpenter, but we follow his ideas in defining the notion of resolved or "completed" feature structure. <p> Our basic data structure is the typed feature structure, discussed in Carpenter's book [3]. We start with recursive type constraint systems, as in <ref> [3, Chapter 15] </ref>. Our setting is slightly different from that used by Carpenter, but we follow his ideas in defining the notion of resolved or "completed" feature structure. <p> For this the relevant linguistic theories are feature-based theories like HPSG [18]. We focus on the notion of typed feature structures <ref> [3] </ref>, which are the bearers of linguistic information in such theories 1 . Definition 2.1 Let L be a set of feature labels and A be a finite Scott domain of types. <p> We could consider other restrictions on the domain of feature structures imposed by Carpenter <ref> [3] </ref>. Structures could be required to obey appropriateness conditions; and we dcould also require structures to include disjointness information, essentially barring the possibility of structure-sharing. <p> A consequence of this is that we can pass back and forth between formulas and the set of minimal satisfiers of these formulas. (See Carpenter <ref> [3] </ref> for full information on how to do this.) One other distinguishing characteristic of Kasper-Rounds logic is persistence. Because the logic contains no negations, we have the fact that if an element d satisfies ', and d v e, then e satisfies ' too. <p> Thus a type inherits constraints from all of its supertypes. Carpenter formalizes this idea as recursive type constraint systems <ref> [3, Chapter 15] </ref>. We begin with an example not involving inheritance. <p> Of course there may be no such structure; but we show that if there is one, then there is a least such in the subsumption order. Further, in analogy with a result of Carpenter <ref> [3, Chapter 15] </ref>, this structure (if it is finite) may be found by using the FCR's as rewriting rules. We then go on to show that one may also understand the situation by regarding FCRs as default rules in the domain of feature structures. <p> For this purpose, we introduce a " parallel" rewriting relation. as in Carpenter <ref> [3, Definition 196] </ref>. Definition 5.3 Assume given a finite set S of constraints of the form (C 1 ; C 2 ). Let F and G be feature structures. <p> The finite feature structures are in fact the compact elements of the domain of abstract feature structures. The following lemma is again attributable to Carpenter <ref> [3, Theorem 192] </ref>. However, in this lemma we are using breadth-first rewriting instead of the rewriting used by Carpenter. Lemma 5.5 Let F be a finite feature structure, and let S;par fl ) be the reflexive, transitive closure of the relation S;par ) . <p> We formalize this in the following definition. Definition 8.2 An abstract feature structure F is said to be well-typed if whenever f 2 L, and p and pf are paths of F , then f is appropriate for (p). Carpenter <ref> [3, Theorem 52] </ref> shows that the collection of well-typed feature structures is a sub-BCPO of the collection of feature structures; the ordering v A restricted to the well-typed structures still is a Scott domain. <p> Once again Carpenter shows that inequated structures form a Scott domain <ref> [3, Theorem 80] </ref>. It is straightforward to show as well that the collection of well-typed and inequated structures is again such a domain. By "feature structure" we now mean an abstract, well-typed, and negated structure. We are almost ready for our new logic with negation.
Reference: [4] <author> A. Dawar and K. Vijay-Shanker. </author> <title> A three-valued interpretation of negation in feature structure descriptions. </title> <booktitle> In Proceedings of 27th Annual meeting of the Association for Computational Linguistics, </booktitle> <year> 1991. </year>
Reference-contexts: At the end of the paper we propose a definition of non-monotonic feature logic using our new default semantics. We define a notion of non-monotonic entailment between formulas of feature logic; for a sample feature logic we propose a logic with negation due to Dawar and Vijayshanker <ref> [4] </ref>, but using a typed feature signature as in Carpenter's book. Such a logic is able to express most of the constraints commoly found in GPSG or HPSG-like theories, including constraints on coreference. <p> Finally, we do not know the status of the Or law. We think that it should hold, but we have no proof at the moment. 8 Logics and Inheritance In this section we return to more specific logics for feature structures. We consider Dawar and Vijayshanker's three-valued logic <ref> [4] </ref>, which allows negation; and we combine this with Carpenter's appropriateness specifications. Doing this also requres a change in the definition of feature structures, as we must now include negative information in them. This we do using Carpenter's notion of (weakly) inequated feature structures.
Reference: [5] <author> G. Gazdar, E. Klein, G. Pullum, and I. Sag. </author> <title> Generalized Phrase Structure Grammar. </title> <publisher> Harvard university Press, </publisher> <year> 1985. </year>
Reference-contexts: 1 Introduction This paper is a mathematical treatment of some of the issues which have arisen in trying to define a version of nonmonotonic feature logic which would adequately reflect the semantics of strict and default feature constraints as in the theory of Generalized Phrase Structure Grammar (GPSG) <ref> [5] </ref>, and to a lesser extent, in Head-driven Phrase-Structure Grammmar (HPSG) [18]. The problem seems fairly straightforward on the surface, since there are many tools available from the non-monotonic reasoning literature. <p> F is said to be resolved with respect to C iff for all p 2 T , We wish to present an alternative definition here: one which will allow a slightly more general type constraint system, similar to one appearing in the linguistic theory Generalized Phrase-Structure Grammar (GPSG) <ref> [5] </ref>. That theory allows constraints on structures like the following: [+INV, BAR 2] oe [SUBJ]: These constraints are called Feature Co-occurrence Restrictions (FCRs).
Reference: [6] <author> M. Gelfond, V. Lifschitz, H. Przymuzinska, and M. Truszczynski. </author> <title> Disjunctive defaults. </title> <booktitle> In Proceedings of Second Annual Conference on Knowledge Representation, </booktitle> <pages> pages 230-237. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: We specifically use the Smyth powerdomain to add disjunctive information to feature structures. This is like using default logic, but we depart from standard default logic by using a nonstandard kind of default. Our construction resembles that of Gelfond et al. <ref> [6] </ref>, who define a notion of "disjunctive default." Our semantics, though, is not really the same, as we work in the domain-theoretic setting, while the Gelfond setting is still that of first-order logic. Our crucial definition comes from the domain-theoretic semantics of data bases, due to Libkin [14]. <p> One might expect that a standard version of default feature logic would do the job. This does not work, though. It turns out that we run into the "or problem" considered by workers in default logic (see, e.g., Poole [19], or Gelfond et al. <ref> [6] </ref>.) For example, consider the default rules p : q and q If we start with the formula p_r then neither precondition of the rules can be established (by proof), so neither is applicable; but it seems that we should be able to add the information q (conjunctively) to our stock.
Reference: [7] <author> C. Gunter. </author> <title> The mixed powerdomain. </title> <journal> Theoretical Computer Science, </journal> <volume> 103 </volume> <pages> 311-334, </pages> <year> 1992. </year>
Reference-contexts: Two other common constructions, for example, are the Hoare (lower) and the Plotkin (convex) powerdomains. See Gunter and Scott [8] for a survey. More powerdomains can be found in the work of Buneman et al. [2], Gunter <ref> [7] </ref>, and Libkin [14].
Reference: [8] <author> C. A. Gunter and D. S. Scott. </author> <title> Semantic domains. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B: Formal Models and Semantics, chapter 12, </booktitle> <pages> pages 633-674. </pages> <publisher> Elsevier, </publisher> <year> 1990. </year>
Reference-contexts: One can use other orderings on sets of domain elements to get new powerdomains. Two other common constructions, for example, are the Hoare (lower) and the Plotkin (convex) powerdomains. See Gunter and Scott <ref> [8] </ref> for a survey. More powerdomains can be found in the work of Buneman et al. [2], Gunter [7], and Libkin [14].
Reference: [9] <author> M. Johnson. </author> <title> Attribute-Value Logic and the Theory of Grammar. Center for Study of Language and Information, </title> <booktitle> 1988. </booktitle> <pages> 32 </pages>
Reference-contexts: In particular, one expects that a version of Reiter`s default logic [21], tailored to the case of feature logic, would be the appropriate tool to use, especially since feature logic can be translated into first-order language <ref> [9] </ref>. We have found, though, that such a translation does not get at the issues involved. One problem with this is that a straightforward use of default rules in default logic would model default implicative constraints using default rules, but strict constraints using material implication.
Reference: [10] <author> R. Kasper and W. </author> <title> Rounds. A logical semantics for feature structures. </title> <booktitle> In Proc. of 24th Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 257-266, </pages> <year> 1986. </year>
Reference-contexts: Apply Lemma 2.1 with d = f i . Then we get OE (?; d 0 ; i + 1) = f i t f (f i ) = f i+1 : 3 Feature logic The language KR was introduced in <ref> [10] </ref>, [11] to solve the problem of expressing disjunctive information in feature structures, while at the same time capturing the constraints implicit in Shieber's PATR-II [24]. The language KR consists of basic and compound formulas.
Reference: [11] <author> R. Kasper and W. </author> <title> Rounds. The logic of unification in grammar. </title> <journal> Linguistics and Philosophy, </journal> <volume> 13 </volume> <pages> 33-58, </pages> <year> 1990. </year>
Reference-contexts: Apply Lemma 2.1 with d = f i . Then we get OE (?; d 0 ; i + 1) = f i t f (f i ) = f i+1 : 3 Feature logic The language KR was introduced in [10], <ref> [11] </ref> to solve the problem of expressing disjunctive information in feature structures, while at the same time capturing the constraints implicit in Shieber's PATR-II [24]. The language KR consists of basic and compound formulas.
Reference: [12] <author> S. Kraus, D. Lehmann, and M. Magidor. </author> <title> Nonmonotonic reasoning, preferential models, and cumulative logics. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 167-207, </pages> <year> 1990. </year>
Reference-contexts: Such a logic is able to express most of the constraints commoly found in GPSG or HPSG-like theories, including constraints on coreference. We briefly indicate how our entailment notion might 2 or might not satisfy the laws due to Kraus, Lehmann, and Magidor <ref> [12] </ref>. We also suggest how to incorporate these notions into inheritance hierarchies. <p> Since fa; b; c; dg is the generalization of the two extensions, a _ b _ c _ d is the strongest nonmonotonic consequence of true up to logical equivalence. 25 We next consider the basic Kraus-Lehmann-Magidor <ref> [12] </ref> axioms for "reasonable" notions of preferential entailment.
Reference: [13] <author> A. Lascarides, T. Briscoe, N. Asher, and A. </author> <title> Copestake. Order-independent and persistent typed default unification. </title> <note> To appear in Linguistics and Philosophy. </note>
Reference-contexts: For this reason, we will generally ignore algorithms for computing resolved structures and extensions. Lascarides, Briscoe, Asher, and Copestake <ref> [13] </ref> have also treated these problems. They extend the work of Young and Rounds [25], and some of the work in Young's thesis, by introducing a notion of order-independent and persistent typed default unification. <p> A similar scheme was suggested by Young [26], and the issue has been studied as well by Lascarides et al. <ref> [13] </ref>. Both these proposals are computationally oriented; unifications using Young's method of non-monotonic sorts, or Lascarides' notion of persistent typed default unification, can actually be carried out for lexical and other systems of defaults. <p> A start on the problem would be to reconcile the present results with the ideas on default unification presented in [26] and <ref> [13] </ref>. Acknowledgements. The present paper would not have been possible without the help of G. Q. Zhang, from whom I learned many facts about domains and defaults in domains, and to Mark Young, from whom I learned about nonmonotonicity.
Reference: [14] <author> L. Libkin. </author> <title> Aspects of Partial Information in Databases. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <year> 1994. </year>
Reference-contexts: Our crucial definition comes from the domain-theoretic semantics of data bases, due to Libkin <ref> [14] </ref>. Using the idea of or-sets, and updates, we are able to find a natural notion of default which allows us to characterize the notion of "completing" a feature structure with both strict and default constraints. Our basic data structure is the typed feature structure, discussed in Carpenter's book [3]. <p> Two other common constructions, for example, are the Hoare (lower) and the Plotkin (convex) powerdomains. See Gunter and Scott [8] for a survey. More powerdomains can be found in the work of Buneman et al. [2], Gunter [7], and Libkin <ref> [14] </ref>. <p> We extend this definition to antichains by simply saying that an antichain X = fF 1 ; : : : ; F n g is resolved whenever each F i is resolved. We are going to consider a crucial definition, due to Libkin <ref> [14] </ref>. We will state it for general domains; for this we need to generalize disjunctive constraints. Definition 6.4 A disjunctive constraint over a domain D is a pair (a; B), where a 2 (D) and B is a nonempty finite antichain over D.
Reference: [15] <author> M. A. Moshier. </author> <title> Extensions to Unification Grammar for the Description of Programming Languages. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1988. </year>
Reference-contexts: This rather imposing definition (due originally to Moshier <ref> [15] </ref>, and anticipated by Pereira and Shieber [16]) captures notations like the following: 2 6 6 vp " NUM sing PERS 3rd # SUBJ 1 3 7 7 Here the feature names are things like AGR and NUM, whilst types are things like "vp" and "3rd".
Reference: [16] <author> F. Pereira and S. Shieber. </author> <title> The semantics of grammar formalisms seen as computer languages. </title> <booktitle> In Proceedings of 10th International Conference on Computational Linguistics: COLING 84, </booktitle> <year> 1984. </year>
Reference-contexts: This rather imposing definition (due originally to Moshier [15], and anticipated by Pereira and Shieber <ref> [16] </ref>) captures notations like the following: 2 6 6 vp " NUM sing PERS 3rd # SUBJ 1 3 7 7 Here the feature names are things like AGR and NUM, whilst types are things like "vp" and "3rd".
Reference: [17] <author> C. Pollard and M. A. Moshier. </author> <title> Unifying partial descriptions of sets. </title> <editor> In P. Hansen, editor, </editor> <booktitle> Vancouver Studies in Cognitive Science: </booktitle> <volume> vol. </volume> <editor> I. </editor> <publisher> University of British Columbia Press, </publisher> <year> 1990. </year>
Reference-contexts: This reoccurs in our setting of strict and default constraints. Our solution to these limitation problem is to use domain theory, or the theory of complete partial orders. We follow Pollard and Moshier <ref> [17] </ref> in modelling disjunctive information using so-called powerdomains. We specifically use the Smyth powerdomain to add disjunctive information to feature structures. This is like using default logic, but we depart from standard default logic by using a nonstandard kind of default. <p> The structure pG is called the translation of G along p (cf. Pollard and Moshier <ref> [17] </ref>). 13 We make the following observation, whose proof is straightforward. <p> At this point it looks like "irrelevant" information is entering our extension. However, this is a feature of Smyth-style approximation, as pointed out by Pollard and Moshier <ref> [17] </ref>. Notice that the above antichain is not resolved. For example, the structure a [f : ?] will be replaced by fa [f : a]; a [f : b]g in the next iteration. <p> Only in the case when there is a resolved element of the Smyth powerdomain dominating our starting element does the theorem guarantee unique extensions. Additionally, we might mention that our version of the Smyth powerdomain omits the top or inconsistent "empty" set. This differs from Pollard and Moshier <ref> [17] </ref>, who make use of the Smyth domain as a complete distributive lattice. However, in the default setting, including the top element tends to trivialize the results, because we then never get multiple extensions; in cases like the Nixon Diamond it seems that such extensions are what is wanted.
Reference: [18] <author> C. Pollard and I. Sag. </author> <title> Head-driven Phrase Structure Grammar. </title> <publisher> University of Chicago Press, </publisher> <year> 1994. </year>
Reference-contexts: some of the issues which have arisen in trying to define a version of nonmonotonic feature logic which would adequately reflect the semantics of strict and default feature constraints as in the theory of Generalized Phrase Structure Grammar (GPSG) [5], and to a lesser extent, in Head-driven Phrase-Structure Grammmar (HPSG) <ref> [18] </ref>. The problem seems fairly straightforward on the surface, since there are many tools available from the non-monotonic reasoning literature. <p> For this the relevant linguistic theories are feature-based theories like HPSG <ref> [18] </ref>. We focus on the notion of typed feature structures [3], which are the bearers of linguistic information in such theories 1 . Definition 2.1 Let L be a set of feature labels and A be a finite Scott domain of types. <p> Combined with the results in the previous paragraph, this means that the set of satisfiers of any Kasper-Rounds formula can be described as the upward closure, in the subsumption preorder, of the set of minimal satisfiers. 4 Strict and default constraints 4.1 Strict constraints: FCRs In the linguistic theory HPSG <ref> [18] </ref>, feature structures must be constrained. One formalization of this idea is that every substructure of a feature structure which is of a certain type (in A) must satisfy a KR formula which has been associated with that type beforehand.
Reference: [19] <author> D. L. Poole. </author> <title> What the lottery paradox tells us about default reasoning. </title> <booktitle> In Proceedings of First Annual Conference on Knowledge Representation. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: One might expect that a standard version of default feature logic would do the job. This does not work, though. It turns out that we run into the "or problem" considered by workers in default logic (see, e.g., Poole <ref> [19] </ref>, or Gelfond et al. [6].) For example, consider the default rules p : q and q If we start with the formula p_r then neither precondition of the rules can be established (by proof), so neither is applicable; but it seems that we should be able to add the information <p> More generally, we have indicated through the use of update defaults a universal way of adding disjunctive information to an element or elements of a domain which does not suffer from the "reasoning by cases" problem mentioned by Poole <ref> [19] </ref>. We plan to apply this idea in other Scott domains besides the domain of feature structures. A primary candidate is the domain-theoretic model theory for first-order logic studied in [22].
Reference: [20] <author> M. Reape. </author> <title> Introduction to Semantics of Unification-based Grammar Formalisms. </title> <publisher> Kluwer, </publisher> <year> 1994. </year>
Reference-contexts: We could also consider a variant notion in which for each type a, there was a set C (a) of GPSG-style constraints, and then require inheritance of these onto subtypes. Blackburn and Spaan [1], and Reape <ref> [20] </ref> have investigated this direction extensively. In their formulation, the type symbols a can be thought of as special propositional variables, perhaps rewritten as p a . The modality l : ' is written hli', and a negation operator :OE is included.
Reference: [21] <author> Raymond Reiter. </author> <title> A logic for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13 </volume> <pages> 81-132, </pages> <year> 1980. </year>
Reference-contexts: The problem seems fairly straightforward on the surface, since there are many tools available from the non-monotonic reasoning literature. In particular, one expects that a version of Reiter`s default logic <ref> [21] </ref>, tailored to the case of feature logic, would be the appropriate tool to use, especially since feature logic can be translated into first-order language [9]. We have found, though, that such a translation does not get at the issues involved. <p> Therefore, from an abstract point of view, a default set in a Scott domain (D; v) serves to generate a certain relation on D which at least satisfies the property that (x; y) 2 implies x v y. We take to be the extension relation, due to Reiter <ref> [21] </ref> in the case where the domain D is the domain of closed first-order theories. Definition 2.3 Let (D; v) be a Scott domain. Let be a default set in D. Also, define D &gt; to be the domain D with an "inconsistent element" &gt; above all other elements.
Reference: [22] <author> W. Rounds, , and G. Q. Zhang. </author> <title> Logical considerations on default semantics. To appear,Proc. </title> <booktitle> 3rd Int'l Symp. on Mathematics and AI, </booktitle> <year> 1994. </year>
Reference-contexts: The proof can be found in <ref> [22] </ref>. The point of the theorems is that techniques originally developed for default logic can be generalized to many more situations. The following paragraphs provide a whole class of examples, this time involving a monotonic notion. We give these because our main theorems have a similar flavor. <p> We plan to apply this idea in other Scott domains besides the domain of feature structures. A primary candidate is the domain-theoretic model theory for first-order logic studied in <ref> [22] </ref>. As problems needing further research, we should mention that our semantics for defaults yields a notion of nonmonotonic entailment only between compact elements of the Smyth powerdomain; these correspond in a natural way to the compact open sets in the Scott topology of the domain.
Reference: [23] <author> W. Rounds and G. Q. Zhang. </author> <title> Domain theory meets default logic. </title> <journal> Logic and Computation, </journal> <volume> 5 </volume> <pages> 1-25, </pages> <year> 1995. </year>
Reference-contexts: If xy and xy 0 , then either y = y 0 or y 6" y 0 . 5. If xz and y v z, then (x t y) z: Proof. The original proofs for these, in terms of information systems (a representation of Scott domains), are given in <ref> [23] </ref>. For completeness, we give the proof of the existence of extensions, exactly like the proof of Reiter, but generalized to domains. We define a sequence hx i i inductively.
Reference: [24] <author> S. Shieber. </author> <title> The design of a computer language for linguistic information. </title> <booktitle> In Proceedings of 12th COLING, </booktitle> <pages> pages 211-215, </pages> <year> 1986. </year>
Reference-contexts: ; i + 1) = f i t f (f i ) = f i+1 : 3 Feature logic The language KR was introduced in [10], [11] to solve the problem of expressing disjunctive information in feature structures, while at the same time capturing the constraints implicit in Shieber's PATR-II <ref> [24] </ref>. The language KR consists of basic and compound formulas.
Reference: [25] <author> M. Young and W. </author> <title> Rounds. A logical semantics for nonmonotonic feature structures. </title> <booktitle> In Proc. ACL Symp. on Computational Linguistcs, </booktitle> <year> 1993. </year> <month> 33 </month>
Reference-contexts: For this reason, we will generally ignore algorithms for computing resolved structures and extensions. Lascarides, Briscoe, Asher, and Copestake [13] have also treated these problems. They extend the work of Young and Rounds <ref> [25] </ref>, and some of the work in Young's thesis, by introducing a notion of order-independent and persistent typed default unification. There is actually a family of such unification operations, each of which makes the important distinction between strict and default information.
Reference: [26] <author> Mark Young. </author> <title> Features, Unification, and Nonmonotonicity. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1994. </year>
Reference-contexts: Young's thesis <ref> [26] </ref> treats some of these issues: he considers disjunctive constraints, inheritance, and strict and default information using the method of nonmonotonic sorts. <p> A similar scheme was suggested by Young <ref> [26] </ref>, and the issue has been studied as well by Lascarides et al. [13]. Both these proposals are computationally oriented; unifications using Young's method of non-monotonic sorts, or Lascarides' notion of persistent typed default unification, can actually be carried out for lexical and other systems of defaults. <p> At present one can only implement our definitions in finite spaces; even the space of feature structures will present a challenge if we are to use our present definitions. A start on the problem would be to reconcile the present results with the ideas on default unification presented in <ref> [26] </ref> and [13]. Acknowledgements. The present paper would not have been possible without the help of G. Q. Zhang, from whom I learned many facts about domains and defaults in domains, and to Mark Young, from whom I learned about nonmonotonicity.
Reference: [27] <author> G. Q. Zhang and W. </author> <title> Rounds. Defaults in domain theory. </title> <note> Submitted for publication. 34 </note>
Reference-contexts: We would not consider the added "top" element to be an extension, even though it might be a fixed point of the function y:phi (x; y). This point is raised again in the sections on the Smyth powerdomain. Here is an example from <ref> [27] </ref> to illustrate the basic idea of the definition. Example. Consider the scenario of finding out somebody's last name if we have the partial information that the name starts with 'sm'. <p> See <ref> [27] </ref> for discussion. In general the Cautious Monotony law does not hold. For completeness we adapt an example from [27]. Example. Consider the Scott domain consisting of four sorts f?; a; b; b 0 g. <p> See <ref> [27] </ref> for discussion. In general the Cautious Monotony law does not hold. For completeness we adapt an example from [27]. Example. Consider the Scott domain consisting of four sorts f?; a; b; b 0 g. These are ordered by ? v a; a v b, and a v b 0 , where b is inconsistent with b 0 .
References-found: 27

