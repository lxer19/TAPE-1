URL: http://www.cs.yale.edu/users/toyama/papers/layered.ps.gz
Refering-URL: http://www.cs.yale.edu/users/toyama/toyama.html
Root-URL: http://www.cs.yale.edu
Title: Incremental Focus of Attention for Robust Visual Tracking  
Author: Kentaro Toyama and Gregory D. Hager 
Date: October 22, 1995  
Address: P.O. Box 208285 New Haven, CT 06520  
Affiliation: Department of Computer Science Yale Univ.,  
Abstract: We present an incremental focus of attention (IFA) architecture for adding robustness to software-based, real-time, motion trackers. The framework provides a structure which, when given the entire camera image to search, efficiently focuses the attention of the system into a narrow set of configurations that includes the target configuration. IFA offers a means for automatic tracking initialization and reinitialization when environmental conditions momentarily deteriorate and cause the system to lose track of its target. Systems based on the framework degrade gracefully as various assumptions about the environment are violated. In particular, when constructed with multiple tracking algorithms of varying precision, the failure of a single algorithm causes another, less precise algorithm to take over, thereby allowing the system to return approximate information on feature location or configuration. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE J. of Rob. and Autom., </journal> <volume> 1(1) </volume> <pages> 24-30, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: In this way, the information provided by IFA-based tracking algorithms gracefully degrades as various assumptions about the environment are violated. In the pursuit of robustness, we have been inspired in part by the subsumption architecture of robotics <ref> [1, 2] </ref>. We, too, believe that robustness comes from decomposing a system based on complete tasks, as opposed to partitioning a complex task into functionally abstract modules.
Reference: [2] <author> R. A. Brooks. </author> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 139-159, </pages> <year> 1991. </year>
Reference-contexts: In this way, the information provided by IFA-based tracking algorithms gracefully degrades as various assumptions about the environment are violated. In the pursuit of robustness, we have been inspired in part by the subsumption architecture of robotics <ref> [1, 2] </ref>. We, too, believe that robustness comes from decomposing a system based on complete tasks, as opposed to partitioning a complex task into functionally abstract modules.
Reference: [3] <author> J. D. Crisman and C. E. Thorpe. SCARF: </author> <title> a color vision system that tracks roads and intersections. </title> <journal> IEEE Trans. Rob. and Autom., </journal> <volume> 9(1) </volume> <pages> 49-38, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: As with any selector, multiple calls to this selector will eventually cover the entire input set. Color-based selector: A color-based selector marks the regions in a image which contain certain range of hues (similar to the way different regions are categorized by color in <ref> [3] </ref>).
Reference: [4] <author> J. L. Crowley, P. Stelmaszyk, T. Skordas, and P. Puget. </author> <title> Measurement and integration of 3-D structures by tracking edge lines. </title> <journal> Int'l Journal of Computer Vision, </journal> <volume> 8(1) </volume> <pages> 29-52, </pages> <year> 1992. </year>
Reference-contexts: Mistracking is detected when the line segments of adjacent corners are out of alignment or if distinct corners merge together. 3-D Model Tracker: A 3-D model tracker (such as the ones described in <ref> [4, 8, 12] </ref>) tracks the 3-D pose of an object with respect to the camera. The input configuration set would be the approximate pose of the object with an error margin, and the output set could be a smaller set of poses.
Reference: [5] <author> S. M. Culhane and J. K. Tsotsos. </author> <title> An attentional prototype for early vision. </title> <booktitle> In Computer Vision - ECCV '92, </booktitle> <pages> pages 551-560, </pages> <address> Italy, </address> <month> May </month> <year> 1992. </year> <month> 27 </month>
Reference-contexts: Yet, while we do formulate tracking as a search problem, the differences between AI searching algorithms and IFA are obvious: the domains, the speed of operation, and the combinatorial aspects of the problems differ significantly. The IFA architecture is, ultimately, a close cousin of focus of attention algorithms <ref> [5, 18, 19] </ref>. These algorithms use layered processing to implement both parallel and inherently serial procedures for narrowing attention. The intention is to create fast, robust vision systems. There are, however, a few theoretical differences between our approach and that of most focus of attention research. <p> The union of output sets over time equals the input set (this is similar to the reasoning behind inhibition of input areas in focus of attention work <ref> [5] </ref>). This restriction ensures that the system as a whole will not fall into a loop where a selector insistently produces a set that doesn't include the target state.
Reference: [6] <author> L. D. Erman, F. Hayes-Roth, V. R. Lesser, and D. R. Reddy. </author> <title> The HEARSAY-II speech understanding system: Integrating knowledge to resolve uncertainty. </title> <journal> Computing Surveys, </journal> <volume> 12(2) </volume> <pages> 213-253, </pages> <year> 1980. </year>
Reference-contexts: Unlike foveation, however, the IFA architecture channels attention based on visual events instead of relying on a predetermined geometrical scheme. If we view tracking as a large search problem, IFA can even claim precursors in classic artificial intelligence applications such as STRIPS [7] and Hearsay <ref> [6] </ref> which cull search spaces by examining various preconditions. A layer of an IFA tracker culls the search space for the next layer by checking if regions marked by certain visual cues warrant further attention.
Reference: [7] <author> R. E. Fikes and N. J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: Unlike foveation, however, the IFA architecture channels attention based on visual events instead of relying on a predetermined geometrical scheme. If we view tracking as a large search problem, IFA can even claim precursors in classic artificial intelligence applications such as STRIPS <ref> [7] </ref> and Hearsay [6] which cull search spaces by examining various preconditions. A layer of an IFA tracker culls the search space for the next layer by checking if regions marked by certain visual cues warrant further attention.
Reference: [8] <author> D. B. Gennery. </author> <title> Visual tracking of known three-dimensional objects. </title> <journal> Int'l Journal of Computer Vision, </journal> <volume> 7(3) </volume> <pages> 243-270, </pages> <year> 1992. </year>
Reference-contexts: Mistracking is detected when the line segments of adjacent corners are out of alignment or if distinct corners merge together. 3-D Model Tracker: A 3-D model tracker (such as the ones described in <ref> [4, 8, 12] </ref>) tracks the 3-D pose of an object with respect to the camera. The input configuration set would be the approximate pose of the object with an error margin, and the output set could be a smaller set of poses.
Reference: [9] <author> G. D. Hager. </author> <title> Calibration-free visual control using projective invariance. </title> <booktitle> In Proceedings of the ICCV, </booktitle> <pages> pages 1009-1015, </pages> <year> 1995. </year> <note> Also available as Yale CS-RR-1046. </note>
Reference-contexts: SSD-based multi-pattern tracker: The same tracker as above, but which tracks successfully if the current image contains a match to any of several stored images. 3.1 Robust Disk Tracking In the past, we have often used 3.5 inch diskettes as a convenient target for various experiments with visual servoing <ref> [9] </ref>. These experiments, while successful in demonstrating hand-eye coordination, were nevertheless extremely sensitive to disturbances.
Reference: [10] <author> G. D. Hager. </author> <title> The "X-vision" system: A general purpose substrate for real-time vision-based robotics. </title> <booktitle> In Proceedings of the Workshop on Vision for Robots, </booktitle> <pages> pages 56-63, </pages> <year> 1995. </year> <note> Also available as Yale CS-RR-1078. </note>
Reference-contexts: The search space for such a tracker may be restricted to a predefined size in order to assure reasonable real-time performance. On the other hand, some window-based line segment trackers (such as those described in <ref> [10] </ref>) are designed to find lines within a band of orientations, lengths, and image locations. In order to connect a point-feature tracker to a line tracker, some translation and partitioning of output sets is required. Selectors also focus the attention of the system by favoring certain output sets over others. <p> The following are a few examples of trackers and selectors: 7 Polygon Tracker: A feature-based polygon tracker tracks polygonal shapes as multiple corners, which are in turn tracked as two intersecting line segments (a rectangle tracker is described in <ref> [10] </ref>). The polygonal tracker will narrow a "compact" set of input configurations, into an smaller set of configurations which corresponds to the image projection of the polygon together with some allowance for noise. <p> It returns an output set whose elements are configurations that correspond to affine transformations of the template which match with the current camera image. It fails if the computed sum-of-squared-difference (SSD) residue is above a given threshold (see <ref> [10] </ref>). The residue of an SSD computation is the actual pixel-by-pixel sum of squared differences. Variations of this tracker may perform the same function with a subset of affine transformations. <p> The SSD-based system spends much of its time in layer 1, especially following complete occlusion. Layer 1 corresponds 19 a a b c a a b c high clutter (bottom). 20 to the coarse SSD tracker. Due to the the actual implementation of our SSD tracking (see <ref> [10, 13] </ref>) which is based on a steepest-descent algorithm, a relatively long tracking phase is required for this tracker. Thus, the full tracking phase must be endured before it can recognize whether the object tracked is the actual target. <p> Placing the fine tracker in the innermost loop fashions the top of the framework and added robustness is the result. In this way, we have been able to easily adapt the framework to provide robustness for trackers of the X Vision system <ref> [10] </ref>, which offers a set of modular tools for feature-based motion tracking. 4 Towards a Notion of Robustness As stated at the outset, our goal is to provide "robust" tracking through incremental focus of attention.
Reference: [11] <author> A. Kosaka and G. Nakazawa. </author> <title> Vision-based motion tracking of rigid objects using prediction of uncertainties. </title> <booktitle> In Proc. 1995 IEEE Conf. on Rob. and Autom., </booktitle> <pages> pages 2637-2644, </pages> <address> Nagoya, Japan, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Visual events such as changes in the background, foreground occlusion, ambient light changes, and unanticipated motion of the camera or the target, conspire to produce undetected, irrecoverable failure in many existing visual trackers. Although there have been attempts to make trackers more robust with respect to certain disturbances (e.g., <ref> [11, 16, 17] </ref>), little has been done toward developing an effective, generalizable computational framework for dealing with these problems. In this article, we present the Incremental Focus of Attention (IFA) architecture. IFA is a framework for adding robustness to most existing real-time feature-based tracking algorithms.
Reference: [12] <author> D. G. Lowe. </author> <title> Robust model-based motion tracking through the integration of search and estimation. </title> <journal> Int'l Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 113-122, </pages> <year> 1992. </year>
Reference-contexts: Mistracking is detected when the line segments of adjacent corners are out of alignment or if distinct corners merge together. 3-D Model Tracker: A 3-D model tracker (such as the ones described in <ref> [4, 8, 12] </ref>) tracks the 3-D pose of an object with respect to the camera. The input configuration set would be the approximate pose of the object with an error margin, and the output set could be a smaller set of poses.
Reference: [13] <author> J. Shi and C. Tomasi. </author> <title> Good features to track. </title> <booktitle> In Computer Vision and Patt. Recog., </booktitle> <pages> pages 593-600. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: The SSD-based system spends much of its time in layer 1, especially following complete occlusion. Layer 1 corresponds 19 a a b c a a b c high clutter (bottom). 20 to the coarse SSD tracker. Due to the the actual implementation of our SSD tracking (see <ref> [10, 13] </ref>) which is based on a steepest-descent algorithm, a relatively long tracking phase is required for this tracker. Thus, the full tracking phase must be endured before it can recognize whether the object tracked is the actual target.
Reference: [14] <author> H. Tagare and D. McDermott. </author> <title> Model-based edge selection for 2-D object recognition. </title> <institution> DCS RR-1044, Yale University, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: Pop-out is an effect found in animals, where certain locally identifiable cues, such as motion or color, rapidly focus visual attention. In computer vision, pop-out translates to algorithms which, because they perform image processing only on locally confined areas of an image, could theoretically be performed rapidly in parallel <ref> [14] </ref>. The IFA framework might be considered similar to repeated applications of pop-out algorithms, but it differs in that the algorithms need not be parallelizable: while pop-out might characterize some parts of our framework, it does not properly describe others.
Reference: [15] <author> D. Terzopoulos and T. F. Rabie. </author> <title> Animat vision: </title> <booktitle> Active vision in artificial animals. In Int'l Conf. on Comp. Vision, </booktitle> <pages> pages 801-808, </pages> <month> June </month> <year> 1995. </year> <month> 28 </month>
Reference-contexts: Foveation is another computer vision concept inspired by nature with which the IFA framework shares conceptual traits. In foveated vision, the resolution of an image is inversely proportional to its distance from the center, or fovea <ref> [15, 17] </ref>. Most often, foveation is used to provide both a region of high accuracy and a wide field of view for a reasonable computational cost. Our framework also takes advantage of speed gained by processing on images of varying resolution.
Reference: [16] <author> K. Toyama and G. D. Hager. </author> <title> Keeping your eye on the ball: Tracking occluding contours of unfamiliar objects without distraction. </title> <booktitle> In Proc. 1995 Int'l Conf. on Intel. Rob. and Sys., </booktitle> <pages> pages 354-359, </pages> <address> Pittsburgh, PA, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Visual events such as changes in the background, foreground occlusion, ambient light changes, and unanticipated motion of the camera or the target, conspire to produce undetected, irrecoverable failure in many existing visual trackers. Although there have been attempts to make trackers more robust with respect to certain disturbances (e.g., <ref> [11, 16, 17] </ref>), little has been done toward developing an effective, generalizable computational framework for dealing with these problems. In this article, we present the Incremental Focus of Attention (IFA) architecture. IFA is a framework for adding robustness to most existing real-time feature-based tracking algorithms.
Reference: [17] <author> K. Toyama and G. D. Hager. </author> <title> Tracker fusion for robustness in visual feature tracking. </title> <booktitle> In SPIE Int'l Sym. Intel. Sys. and Adv. Manufacturing, volume 2589, </booktitle> <address> Philadelphia, PA, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: Visual events such as changes in the background, foreground occlusion, ambient light changes, and unanticipated motion of the camera or the target, conspire to produce undetected, irrecoverable failure in many existing visual trackers. Although there have been attempts to make trackers more robust with respect to certain disturbances (e.g., <ref> [11, 16, 17] </ref>), little has been done toward developing an effective, generalizable computational framework for dealing with these problems. In this article, we present the Incremental Focus of Attention (IFA) architecture. IFA is a framework for adding robustness to most existing real-time feature-based tracking algorithms. <p> Foveation is another computer vision concept inspired by nature with which the IFA framework shares conceptual traits. In foveated vision, the resolution of an image is inversely proportional to its distance from the center, or fovea <ref> [15, 17] </ref>. Most often, foveation is used to provide both a region of high accuracy and a wide field of view for a reasonable computational cost. Our framework also takes advantage of speed gained by processing on images of varying resolution.
Reference: [18] <author> J. K. Tsotsos. </author> <title> An inhibitory beam for attentional selection. In Spatial Vision for Humans and Robots. </title> <publisher> Cambridge University Press, </publisher> <year> 1993. </year>
Reference-contexts: Yet, while we do formulate tracking as a search problem, the differences between AI searching algorithms and IFA are obvious: the domains, the speed of operation, and the combinatorial aspects of the problems differ significantly. The IFA architecture is, ultimately, a close cousin of focus of attention algorithms <ref> [5, 18, 19] </ref>. These algorithms use layered processing to implement both parallel and inherently serial procedures for narrowing attention. The intention is to create fast, robust vision systems. There are, however, a few theoretical differences between our approach and that of most focus of attention research.
Reference: [19] <author> J. K. Tsotsos. </author> <title> Towards a computational model of visual attention. </title> <editor> In T. Papathomas, C. Chubb, A. Gorea, and E. Kowler, editors, </editor> <booktitle> Early Vision and Beyond, </booktitle> <pages> pages 207-218. </pages> <publisher> MIT Press, </publisher> <year> 1995. </year> <month> 29 </month>
Reference-contexts: Yet, while we do formulate tracking as a search problem, the differences between AI searching algorithms and IFA are obvious: the domains, the speed of operation, and the combinatorial aspects of the problems differ significantly. The IFA architecture is, ultimately, a close cousin of focus of attention algorithms <ref> [5, 18, 19] </ref>. These algorithms use layered processing to implement both parallel and inherently serial procedures for narrowing attention. The intention is to create fast, robust vision systems. There are, however, a few theoretical differences between our approach and that of most focus of attention research.
References-found: 19

