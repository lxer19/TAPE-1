URL: http://www.stat.colostate.edu/~tweedie/documents/mada8.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Self-Targeting Candidates for Metropolis-Hastings Algorithms  
Author: O. Stramer and R.L. Tweedie 
Keyword: Hastings algorithms, Metropolis algorithms, "burn-in" problem, Markov chain Monte Carlo, diffusions, Langevin models, discrete approximations, posterior distributions, irreducible Markov processes, geometric ergodicity, uniform ergodicity, Gibbs sampling  
Note: AMS Subject Classifications: 60J05, 60J10, 60J70, 65C05, 62E17  
Date: January 15, 1998  
Abstract: The Metropolis-Hastings algorithm for estimating a distribution is based on choosing a candidate Markov chain and then accepting or rejecting moves of the candidate to produce a chain known to have as the invariant measure. The traditional methods use candidates essentially unconnected to . Based on diffusions for which is invariant, we develop for one-dimensional distributions a class of candidate distributions that "self-target" towards the high density areas of . These produce Metropolis-Hastings algorithms with convergence rates that appear to be considerably better than those known for the traditional candidate choices, such as random walk. In particular, for wide classes of these choices may effectively help reduce the "burn-in" problem. We illustrate this behaviour for examples with exponential and polynomial tails, and for a logistic regression model using a Gibbs sampling algorithm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.E. Besag. </author> <title> Comments on "Representations of knowledge in complex systems" by U. Grenander and M.I. Miller. </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 56, </volume> <year> 1994. </year>
Reference-contexts: The rationale for using this candidate is therefore simple: since the Langevin diffusion already converges to , then the chain Q L should also converge in the "right direction" (if not quite to ), and should require only minimal corrections through a Metropolis step (1) in order to converge correctly <ref> [1] </ref>.
Reference: [2] <author> J.E. Besag and P.J. Green. </author> <title> Spatial statistics and Bayesian computation (with discussion). </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 55 </volume> <pages> 25-38, </pages> <year> 1993. </year>
Reference-contexts: The M-H algorithms allow simulation of a probability distribution which is only known up to a constant (normalising) factor. This is surprisingly widely relevant, occurring especially when is a Bayesian posterior distribution, but in many other contexts also <ref> [2, 3, 6] </ref>.
Reference: [3] <author> J.E. Besag, P.J. Green, D. Higdon, and K.L. Mengersen. </author> <title> Bayesian computation and stochastic systems (with discussion). </title> <journal> Statistical Science, </journal> <volume> 10 </volume> <pages> 3-66, </pages> <year> 1995. </year> <month> 29 </month>
Reference-contexts: The M-H algorithms allow simulation of a probability distribution which is only known up to a constant (normalising) factor. This is surprisingly widely relevant, occurring especially when is a Bayesian posterior distribution, but in many other contexts also <ref> [2, 3, 6] </ref>.
Reference: [4] <author> Pei-de Chen. </author> <title> Hastings-Metropolis algorithms without reference measures. </title> <note> Statistics and Prob--ability Letters (to appear). </note>
Reference-contexts: To avoid technical difficulties and assumptions, we assume here that X is IR = (1; 1) equipped with the Borel -field B, and both and Q (x; ) have densities (y) and q (x; y) with respect to Lebesgue measure Leb : much more general formulations are possible (see <ref> [20, 4, 6] </ref>) and our methods can be adapted to them, albeit with different degrees of difficulty.
Reference: [5] <author> A. Gelman, G.O. Roberts and W.R. Gilks. </author> <title> Efficient Metropolis jumping rules. In Bayesian Statistics 5, </title> <editor> ed. J.M. Bernardo, J.O. Berger, A.P. Dawid, and A.F.M. Smith, </editor> <address> New York: </address> <publisher> Oxford University Press, </publisher> <year> 1995. </year>
Reference-contexts: Using Figure 10 we have that (ffj) is approximately normal with variance 0:016 and thus from <ref> [5] </ref> we have that among the class of symmetric normal candidate distributions, the most efficient candidate distribution is N (x; 2:4 2 fl 0:016), which we use in E (i). is 0:016 In Figure 11 we estimate the conditional mean m (x; t), where t denotes the number 28 of steps
Reference: [6] <author> W.R. Gilks, S. Richardson, </author> <title> and D.J. Spiegelhalter. Markov Chain Monte Carlo in Practice. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1996. </year>
Reference-contexts: The M-H algorithms allow simulation of a probability distribution which is only known up to a constant (normalising) factor. This is surprisingly widely relevant, occurring especially when is a Bayesian posterior distribution, but in many other contexts also <ref> [2, 3, 6] </ref>. <p> To avoid technical difficulties and assumptions, we assume here that X is IR = (1; 1) equipped with the Borel -field B, and both and Q (x; ) have densities (y) and q (x; y) with respect to Lebesgue measure Leb : much more general formulations are possible (see <ref> [20, 4, 6] </ref>) and our methods can be adapted to them, albeit with different degrees of difficulty. <p> 3, we showed v (x; t) for the MADA chain c M h using D (iii); the conditional variance converges quite rapidly for all starting points for case D (iii), which is uniformly ergodic. ut 9 A logistic regression model We conclude by considering a Bayesian logistic regression model (see <ref> [6] </ref>). <p> We wish to simulate the two dimensional posterior distribution (ff; ). One way to do this is to use the Gibb sampler, where we successively update each component with a value picked from its distribution conditional on the current value of the other component <ref> [6] </ref>. We simulate 1000 observations from this logistic model with = 1:10096 and ff = 2:276053: these were random draws of and ff from N (0; 1). For the sake of illustration we fix = 1:10096 and simulate (ffj = 1:10096).
Reference: [7] <author> W.K. Hastings. </author> <title> Monte Carlo sampling methods using Markov chains and their applications. </title> <journal> Biometrika, </journal> <volume> 57 </volume> <pages> 97-109, </pages> <year> 1970. </year>
Reference-contexts: In particular, these choices may effectively help reduce the "burn-in" problem for wide classes of . In the standard construction <ref> [12, 7] </ref> of the M-H algorithm on a space X, one first considers a candidate transition kernel Q (x; ); x 2 X, which generates potential transitions for a discrete time Markov chain evolving on X.
Reference: [8] <author> A. M. Horowitz. </author> <title> The second order Langevin equation and numerical simulations. </title> <journal> Nuclear Physics, </journal> <volume> B280:510-522, </volume> <year> 1987. </year>
Reference-contexts: Diffusion approximations have also been used in the physics literature recently, but 3 with a substantially different emphasis, as we discuss in Section 3. Whilst we concen-trate on finding better probabilistic choices of the candidate to improve convergence rates, in <ref> [8, 9] </ref> the focus is on the way in which the discretization of the underlying Langevin and related diffusions can be improved by more complex approximations. <p> We compare this with other methods in Section 9. A different approach in the physics literature, discussed in <ref> [8, 9] </ref>, seeks to improve on the choice of the Langevin-Euler approximation by using a second-order Langevin equation. There it is shown that adding a second order `time' derivative to the Langevin equation leads to a more efficient algorithm.
Reference: [9] <author> A. M. Horowitz. </author> <title> A generalized guided Monte Carlo algorithm. </title> <journal> Physics Letters, </journal> <volume> 268 </volume> <pages> 247-252, </pages> <year> 1991. </year>
Reference-contexts: Diffusion approximations have also been used in the physics literature recently, but 3 with a substantially different emphasis, as we discuss in Section 3. Whilst we concen-trate on finding better probabilistic choices of the candidate to improve convergence rates, in <ref> [8, 9] </ref> the focus is on the way in which the discretization of the underlying Langevin and related diffusions can be improved by more complex approximations. <p> We compare this with other methods in Section 9. A different approach in the physics literature, discussed in <ref> [8, 9] </ref>, seeks to improve on the choice of the Langevin-Euler approximation by using a second-order Langevin equation. There it is shown that adding a second order `time' derivative to the Langevin equation leads to a more efficient algorithm.
Reference: [10] <author> P. E. Kloeden and E. Platen. </author> <title> Numerical solution of stochastic differential equations. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: There are a number of methods which can be proposed to try and improve the simple Langevin-Euler scheme. One is to use higher order schemes for the Langevin diffusion, based on stochastic Taylor expansions which reduce the error due to discretization <ref> [10] </ref>. <p> Again we note that higher order schemes, based on stochastic Taylor expansions and analogous to (7) but for the more general class of diffusions, are also available (see <ref> [10] </ref>). However, they are complicated since they involve higher powers of white noise, and are thus harder to employ as candidate distributions in the Metropolis-Hastings algorithm.
Reference: [11] <author> K.L. Mengersen and R.L. Tweedie. </author> <title> Rates of convergence of the Hastings and Metropolis algorithms. </title> <journal> Annals of Statistics, </journal> <volume> 24 </volume> <pages> 101-121, </pages> <year> 1996. </year>
Reference-contexts: This is surprisingly widely relevant, occurring especially when is a Bayesian posterior distribution, but in many other contexts also [2, 3, 6]. Recent work on the probabilistic structure of M-H algorithms includes criteria for convergence and approaches to the speed of convergence of the algorithm <ref> [11, 15, 18, 20, 16] </ref>, and in this paper we give a new class fl Work supported in part by NSF Grants DMS 9504798 and DMS 9504561 y Postal Address: Department of Statistics and Actuarial Science, University of Iowa, Iowa City IA 52242, USA z Postal Address: Department of Statistics, Colorado <p> The first, denoted D (i), is a random walk candidate: that is, we choose q (x; y) = q (jx yj) so that the increment is independent of x. In this case we take a normal increment distribution with variance 1. It can be shown <ref> [11] </ref> that for such a random walk candidate on IR, geometric (but not uniform) ergodicity holds (roughly) if and only if the tails of are no heavier than simple exponential, regardless of the shape of q. Hence for any t-distribution this scheme is not geometrically ergodic. <p> In the former, we choose q (x; y) = q (y) to be independent of x, and in the latter case we choose q (x; y) = q (jx yj) so that the increment is independent of x. It can be shown <ref> [20, 11] </ref> that for independent candidates, we have uniform ergodicity in (3) essentially if and only if ffi = inf [q (w)=(w)] &gt; 0; (4) and in this case we can find the rate of convergence as, for all x, kP n (x; ) k 2 [1 ffi] n : (5) <p> and only if ffi = inf [q (w)=(w)] &gt; 0; (4) and in this case we can find the rate of convergence as, for all x, kP n (x; ) k 2 [1 ffi] n : (5) For random walk candidates on IR, as noted above we have in contrast <ref> [11] </ref> that for geometric ergodicity holds (roughly) we need the tails of to be no heavier than simple exponential. <p> that, even when the Langevin diffusions converge quickly, the naive Euler discretization (and its Metropolised form) may lose this geometric rate of convergence, even for quite simple densities such as (x) / exp (jxj fi ) with fi &gt; 2, for which the classical random walk candidates perform much better <ref> [11] </ref>. There are a number of methods which can be proposed to try and improve the simple Langevin-Euler scheme. One is to use higher order schemes for the Langevin diffusion, based on stochastic Taylor expansions which reduce the error due to discretization [10]. <p> Proof Under these continuity conditions it follows from <ref> [11] </ref> that all compact sets are small for P , as they also are for Q from [13, Chapter 6]. <p> Again we will evaluate convergence through the behaviour of the conditional variances v (x; t) with x = 1, x = 5 and x = 9. In Figure 1, we showed v (x; t) for the Metropolis algorithm using D (i); in this case as shown in <ref> [11] </ref> the chain does not converge exponentially fast and indeed convergence clearly depends on the starting point. <p> Cases E (i), E (ii) and E (iii) are geometrically ergodic, from Theorem 6.1 for E (ii) and E (iii) and from <ref> [11] </ref> for case E (i).
Reference: [12] <author> N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller. </author> <title> Equations of state calculations by fast computing machines. </title> <journal> J. Chemical Physics, </journal> <volume> 21 </volume> <pages> 1087-1091, </pages> <year> 1953. </year>
Reference-contexts: In particular, these choices may effectively help reduce the "burn-in" problem for wide classes of . In the standard construction <ref> [12, 7] </ref> of the M-H algorithm on a space X, one first considers a candidate transition kernel Q (x; ); x 2 X, which generates potential transitions for a discrete time Markov chain evolving on X.
Reference: [13] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Markov Chains and Stochastic Stability. </title> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: the same point given by r (x) = P (x; fxg) = q (x; y)[1 ff (x; y)]dy: (2) The crucial property of the M-H algorithm is that, with this choice of ff, the target is invariant for the operator P : that is, (A) = R is then standard <ref> [13, 14, 16] </ref> that under some weak conditions, including irreducibility and aperiodicity, the n-step transition probabilities P n (x; A) converge to in the total variation norm: for all x kP (x; ) k := 2 sup jP (x; A) (A)j = R (x; n) ! 0: (3) As exemplified in <p> for which convergence in (3) is geometrically fast, in the sense that R (x; n) R (x) n for some &lt; 1; or even uniformly fast, in the sense that R (x; n) is independent of x (and is then necessarily of the form R (x; n) = R n <ref> [13, Chapter 16] </ref>). In Section 3 we describe a class of "self-targeting" candidate distributions Q ST (x; ) which are derived from discrete (h-step) approximations to diffusion processes of a more general form than the Langevin diffusions considered in [15]. <p> Proof Under these continuity conditions it follows from [11] that all compact sets are small for P , as they also are for Q from <ref> [13, Chapter 6] </ref>. <p> Proof Under these continuity conditions it follows from [11] that all compact sets are small for P , as they also are for Q from [13, Chapter 6]. If Q is geometrically ergodic, we have from Theorem 15.0.1 of <ref> [13] </ref> that there exists a function V 1, bounded on compact sets, and a &lt; 1; b &lt; 1 such that for all sufficiently large compact sets C Z Choose * small enough that + * = 0 &lt; 1. <p> If C is large enough that r (x) *; x 2 C c then we have immediately R R 0 V (x) + [b + sup w2C V (w)]1l C (x): Thus using the sufficiency of (15) as in Theorem 15.0.1 of <ref> [13] </ref>, we have that P is also geometrically ergodic. 11 If Q is uniformly ergodic we have similarly from Theorem 16.0.2 of [13] that there is a bounded V such that (14) holds; as in (15), this inequality is maintained for the same bounded V for P , and so from <p> we have immediately R R 0 V (x) + [b + sup w2C V (w)]1l C (x): Thus using the sufficiency of (15) as in Theorem 15.0.1 of <ref> [13] </ref>, we have that P is also geometrically ergodic. 11 If Q is uniformly ergodic we have similarly from Theorem 16.0.2 of [13] that there is a bounded V such that (14) holds; as in (15), this inequality is maintained for the same bounded V for P , and so from the sufficiency in Theorem 16.0.2 of [13] we have that P is also uniformly ergodic. ut The continuity conditions can certainly be <p> geometrically ergodic. 11 If Q is uniformly ergodic we have similarly from Theorem 16.0.2 of <ref> [13] </ref> that there is a bounded V such that (14) holds; as in (15), this inequality is maintained for the same bounded V for P , and so from the sufficiency in Theorem 16.0.2 of [13] we have that P is also uniformly ergodic. ut The continuity conditions can certainly be weakened: all we need is that both Q and P are T-chains in the sense of [13, Chapter 6]. <p> maintained for the same bounded V for P , and so from the sufficiency in Theorem 16.0.2 of [13] we have that P is also uniformly ergodic. ut The continuity conditions can certainly be weakened: all we need is that both Q and P are T-chains in the sense of <ref> [13, Chapter 6] </ref>.
Reference: [14] <author> G.O. Roberts and A.F.M. Smith. </author> <title> Simple conditions for the convergence of the Gibbs sampler and Hastings-Metropolis algorithms. </title> <journal> Stoch. Proc. Applns., </journal> <volume> 49 </volume> <pages> 207-216, </pages> <year> 1994. </year>
Reference-contexts: the same point given by r (x) = P (x; fxg) = q (x; y)[1 ff (x; y)]dy: (2) The crucial property of the M-H algorithm is that, with this choice of ff, the target is invariant for the operator P : that is, (A) = R is then standard <ref> [13, 14, 16] </ref> that under some weak conditions, including irreducibility and aperiodicity, the n-step transition probabilities P n (x; A) converge to in the total variation norm: for all x kP (x; ) k := 2 sup jP (x; A) (A)j = R (x; n) ! 0: (3) As exemplified in
Reference: [15] <author> G.O. Roberts and R.L. Tweedie. </author> <title> Exponential convergence of Langevin diffusions and their discrete approximations. </title> <journal> Bernouilli, </journal> <volume> 2 </volume> <pages> 341-364, </pages> <year> 1996. </year>
Reference-contexts: This is surprisingly widely relevant, occurring especially when is a Bayesian posterior distribution, but in many other contexts also [2, 3, 6]. Recent work on the probabilistic structure of M-H algorithms includes criteria for convergence and approaches to the speed of convergence of the algorithm <ref> [11, 15, 18, 20, 16] </ref>, and in this paper we give a new class fl Work supported in part by NSF Grants DMS 9504798 and DMS 9504561 y Postal Address: Department of Statistics and Actuarial Science, University of Iowa, Iowa City IA 52242, USA z Postal Address: Department of Statistics, Colorado <p> 14, 16] that under some weak conditions, including irreducibility and aperiodicity, the n-step transition probabilities P n (x; A) converge to in the total variation norm: for all x kP (x; ) k := 2 sup jP (x; A) (A)j = R (x; n) ! 0: (3) As exemplified in <ref> [15] </ref>, the user is often faced with a choice between a traditional version of the M-H algorithm, where the candidate is, say, a random walk which moves independently of the shape of , and a more "targeted" candidate distribution, 2 designed for the particular in the problem. <p> In Section 3 we describe a class of "self-targeting" candidate distributions Q ST (x; ) which are derived from discrete (h-step) approximations to diffusion processes of a more general form than the Langevin diffusions considered in <ref> [15] </ref>. These use information about to move automatically towards the "high-density" areas of : indeed, in many cases is already approximately stationary for Q ST , even before the M-H adjustment (1) is put in place. <p> Hence for any t-distribution this scheme is not geometrically ergodic. The second, denoted D (ii), is Q L , given by (6) below: this is the "Langevin-Euler" scheme with h = 1, described by Roberts and Tweedie <ref> [15] </ref>. We know that this is not geometrically ergodic from [15], but the mean and variance converge at polynomial rates 3 and 2 respectively, from Theorem 7.1 below. <p> Hence for any t-distribution this scheme is not geometrically ergodic. The second, denoted D (ii), is Q L , given by (6) below: this is the "Langevin-Euler" scheme with h = 1, described by Roberts and Tweedie <ref> [15] </ref>. We know that this is not geometrically ergodic from [15], but the mean and variance converge at polynomial rates 3 and 2 respectively, from Theorem 7.1 below. <p> The idea of shaping the candidate density based on the target was introduced as long ago as [17] and in the probabilistic literature has been recently studied in Roberts and Tweedie <ref> [15] </ref>: they consider the candidate distribution Q L (x; ) = N (x + 1 where h &gt; 0; N is the standard normal distributions, and r is the differential operator rf (x) = df =dx. <p> This choice is motivated by the fact that is the stationary measure for a Langevin diffusion process, and <ref> [17, 15, 19] </ref> Q L are the approximate h-step transition probabilities for this diffusion, based on a discretization known as the Euler scheme. 7 The rationale for using this candidate is therefore simple: since the Langevin diffusion already converges to , then the chain Q L should also converge in the <p> Given this argument, one particularly surprising result in <ref> [15] </ref> is therefore that, even when the Langevin diffusions converge quickly, the naive Euler discretization (and its Metropolised form) may lose this geometric rate of convergence, even for quite simple densities such as (x) / exp (jxj fi ) with fi &gt; 2, for which the classical random walk candidates perform <p> Note that the Euler scheme is simply the first order Taylor approximation of x;h and 2 x;h . There are obviously no unique choices of b; in (8). If 1 then we retrieve the Langevin model of <ref> [15] </ref> in (8), but we will find below that many other combinations have more desirable properties. <p> Proof This follows since under these conditions it is easy to show that the rejection probability r (x) ! 1 as x ! 1. The result thus follows from Theorem 5.1 of <ref> [15] </ref>. ut 6 Using a t-distribution to improve convergence It is perhaps surprising that the boundary case fi = 2 and fl s &gt; 0 is not actually uniformly ergodic, since Theorem 6.2 of [19] shows that the candidate chain D h is uniformly ergodic in this case. <p> In contrast, essentially as noted also in <ref> [15] </ref>, the MADA chain based on the Euler approximation to the Langevin diffusion is exponentially ergodic if and only if is in class E fl and 1 fi 2. 7 Polynomial convergence of the Langevin schemes As we have shown, one can find geometrically or even uniformly converging schemes for virtually <p> Note that in general we get better rates of convergence for lighter tailed (i.e. for larger fi), and for larger values of fl s . Example 1 The exponential class E We say that 2 E, as introduced in <ref> [15, 19] </ref>, if for some x 0 , and some constants fl s &gt; 0 and 0 &lt; fi &lt; 1, takes the form (x) / e fljxj fi ; jxj x 0 : We now compare the MADA chain properties in Table 1 to those based on the Euler approximations <p> Choose 2 (x) = (n + x 2 ) 2 . Then c M h is uniformly ergodic if 2 &lt; fl s &lt; n + 1 and geometrically ergodic if 2 = fl s &lt; n + 1. In <ref> [15] </ref>, it is shown that the MADA chain based on Q L is not geometrically ergodic for this class of densities. ut We now carry out these computations in a little more detail in some specific cases. 20 Example 3 Comparison of different algorithms Consider a heavy tailed distri-bution with fi <p> B (i) 1, b (x) = 0:8x (1 + x 2 ) 0:6 : that is, we base the model on the Langevin diffusion, and since fl s = 0, the chain M h is not geometrically ergodic as in <ref> [15] </ref>; B (ii) b (x) = 0:4x + x 0:6 (1+x 2 ) 0:4 , 2 (x) = (1 + x 2 ) 0:6 ; we use the MADA chain M h obtained from the variation Q ST , and since fl s = 1:2, we have geometric conver gence from <p> In Figure 2, we showed v (x; t) for the MADA chain M h using D (ii); in this case as shown in <ref> [15] </ref> the chain does not converge exponentially fast but from Theorem 7.1 it still has a third order polynomial subgeometric rate of convergence to .
Reference: [16] <author> G.O. Roberts and R.L. Tweedie. </author> <title> Geometric convergence and central limit theorems for multidimensional Hastings and Metropolis algorithms. </title> <journal> Biometrika, </journal> <volume> 83, </volume> <year> 1996. </year>
Reference-contexts: This is surprisingly widely relevant, occurring especially when is a Bayesian posterior distribution, but in many other contexts also [2, 3, 6]. Recent work on the probabilistic structure of M-H algorithms includes criteria for convergence and approaches to the speed of convergence of the algorithm <ref> [11, 15, 18, 20, 16] </ref>, and in this paper we give a new class fl Work supported in part by NSF Grants DMS 9504798 and DMS 9504561 y Postal Address: Department of Statistics and Actuarial Science, University of Iowa, Iowa City IA 52242, USA z Postal Address: Department of Statistics, Colorado <p> the same point given by r (x) = P (x; fxg) = q (x; y)[1 ff (x; y)]dy: (2) The crucial property of the M-H algorithm is that, with this choice of ff, the target is invariant for the operator P : that is, (A) = R is then standard <ref> [13, 14, 16] </ref> that under some weak conditions, including irreducibility and aperiodicity, the n-step transition probabilities P n (x; A) converge to in the total variation norm: for all x kP (x; ) k := 2 sup jP (x; A) (A)j = R (x; n) ! 0: (3) As exemplified in <p> Similar results, showing the sufficiency of an exponential tail condition (plus some smoothness conditions) for geometric convergence of higher dimensional models when the candidate is a random walk, are given in <ref> [16] </ref>. In these traditional algorithms, the choice of the candidate is not guided by except in a very loose sense as in, say, (4).
Reference: [17] <author> P.J. Rossky, J.D. Doll, and H.L. Friedman. </author> <title> Brownian dynamics as smart Monte Carlo simulation. </title> <journal> Journal of Chemical Physics, </journal> <volume> 69 </volume> <pages> 4628-4633, </pages> <year> 1978. </year>
Reference-contexts: In these traditional algorithms, the choice of the candidate is not guided by except in a very loose sense as in, say, (4). The idea of shaping the candidate density based on the target was introduced as long ago as <ref> [17] </ref> and in the probabilistic literature has been recently studied in Roberts and Tweedie [15]: they consider the candidate distribution Q L (x; ) = N (x + 1 where h &gt; 0; N is the standard normal distributions, and r is the differential operator rf (x) = df =dx. <p> This choice is motivated by the fact that is the stationary measure for a Langevin diffusion process, and <ref> [17, 15, 19] </ref> Q L are the approximate h-step transition probabilities for this diffusion, based on a discretization known as the Euler scheme. 7 The rationale for using this candidate is therefore simple: since the Langevin diffusion already converges to , then the chain Q L should also converge in the
Reference: [18] <author> A.F.M. Smith and G.O. Roberts. </author> <title> Bayesian computation via the Gibbs sampler and related Markov chain Monte Carlo methods (with discussion). </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <volume> 55 </volume> <pages> 3-24, </pages> <year> 1993. </year>
Reference-contexts: This is surprisingly widely relevant, occurring especially when is a Bayesian posterior distribution, but in many other contexts also [2, 3, 6]. Recent work on the probabilistic structure of M-H algorithms includes criteria for convergence and approaches to the speed of convergence of the algorithm <ref> [11, 15, 18, 20, 16] </ref>, and in this paper we give a new class fl Work supported in part by NSF Grants DMS 9504798 and DMS 9504561 y Postal Address: Department of Statistics and Actuarial Science, University of Iowa, Iowa City IA 52242, USA z Postal Address: Department of Statistics, Colorado
Reference: [19] <author> O. Stramer and R.L. Tweedie. </author> <title> Geometric and subgeometric convergence of diffusions with given stationary distributions. </title> <note> (submitted for publication). </note>
Reference-contexts: This choice is motivated by the fact that is the stationary measure for a Langevin diffusion process, and <ref> [17, 15, 19] </ref> Q L are the approximate h-step transition probabilities for this diffusion, based on a discretization known as the Euler scheme. 7 The rationale for using this candidate is therefore simple: since the Langevin diffusion already converges to , then the chain Q L should also converge in the <p> The choice of this approximation to the diffusion is discussed in more detail in <ref> [19] </ref>; the choice of C is always somewhat pragmatic, although if possible C should include the modes of . We show in [19] that the discretization on which (10), (11) is based gives a more effective approximation than the Euler method. <p> The choice of this approximation to the diffusion is discussed in more detail in <ref> [19] </ref>; the choice of C is always somewhat pragmatic, although if possible C should include the modes of . We show in [19] that the discretization on which (10), (11) is based gives a more effective approximation than the Euler method. Note that the Euler scheme is simply the first order Taylor approximation of x;h and 2 x;h . There are obviously no unique choices of b; in (8). <p> Thus we introduce a Metropolis accept-reject step, as described in (1). Following <ref> [19] </ref>, we will write the chain corresponding to Q ST as D h , and we write M h for the Metropolised version of D h . We will call M h the Metropolis-adjusted diffusion algorithm, or MADA chain. A key result that enables us to use results from [19] links <p> Following <ref> [19] </ref>, we will write the chain corresponding to Q ST as D h , and we write M h for the Metropolised version of D h . We will call M h the Metropolis-adjusted diffusion algorithm, or MADA chain. A key result that enables us to use results from [19] links the convergence properties of discretizations and MADA chains. Theorem 4.1 Suppose (x) is positive and continuous, and q (x; y) is positive and continuous in both variables. Let P be the transition law of the Metropolised chain formed from Q. <p> However, they hold in all of the examples below, and although some further fine-tuning of Q ST may be needed to ensure (13) holds, in general the MADA chain M h will retain the convergence properties of D h developed in <ref> [19] </ref>. 5 Uniform convergence of the MADA algorithms We now consider geometric convergence properties of the chains M h . In particular we show that for a broad class of densities , one can always construct some MADA chain M h that converges uniformly fast to as its stationary distribution. <p> In particular we show that for a broad class of densities , one can always construct some MADA chain M h that converges uniformly fast to as its stationary distribution. As in <ref> [19] </ref>, we define two classes of target distributions : The asymptotically exponential class E fl : has asymptotically exponential tails such that jxj fi ! ff; x ! 1; (16) for some ff; fi &gt; 0. <p> Theorem 5.1 Assume that Condition A1 holds with fi &gt; 2. Then the MADA chain M h is uniformly (geometrically) ergodic for any h. Proof We have from Theorem 6.2 of <ref> [19] </ref> that under these conditions, the law Q ST is uniformly ergodic. We thus need only check (13). Let * &gt; 0 be arbitrary. <p> ) + P (Z &lt; x;h P (Z &gt; (M 1 1)=`)) + P (Z &lt; (M + 1)=`)) (18) Thus for all jxj &gt; M , P (x; fxg) C c q (x; y) + C 1 and the result follows. ut Note that as in Theorem 6.2 of <ref> [19] </ref>, we could directly show that E [t C ] is bounded using the argument above, which is an alternative criterion for uniform ergodicity. It is clear what is happening here. <p> The result thus follows from Theorem 5.1 of [15]. ut 6 Using a t-distribution to improve convergence It is perhaps surprising that the boundary case fi = 2 and fl s &gt; 0 is not actually uniformly ergodic, since Theorem 6.2 of <ref> [19] </ref> shows that the candidate chain D h is uniformly ergodic in this case. <p> Hence, as in (19), we have that (22) holds. The result now follows from Theorem 4.1, and the geometric ergodicity of D h under (21) (and its uniform ergodicity when fi = 2 and fl s &gt; 0): this follows exactly as in the proof of Theorem 6.1 of <ref> [19] </ref>. ut In this case, the t distribution has a longer tail than the normal distribution and thus is more appropriate for densities with heavier tails, since a condition similar to (4) holds. We next assume that the assumptions of Theorem 6.1 are satisfied, but with the weaker assumption (23). <p> We call the resulting candidate b Q ST . We now have Theorem 6.2 Assume that condition A1 holds and that fl s + fi 2 &gt; 0. Then the MADA chain c M h obtained from the variation b Q ST is uniformly ergodic. Proof We have from <ref> [19] </ref> that the candidate chain c D h is uniformly ergodic. <p> We will consider Condition A2: Suppose that is in P fl and 2 (x)=(x) ! 1; jxj ! 1 where 0 fl s &lt; and fl s 2. Using Theorem 6.1 of <ref> [19] </ref> we have that under Condition A2, D h is geometrically ergodic, but M h based on Q ST fails to satisfy the condition P (x; fxg) ! 0 as x ! 1. <p> However, implementating these may require considerable computation, and it may be convenient to use the simple Langevin diffusion with the first order scheme (the Euler scheme) if its convergence properties are not too poor, especially if we can start from the "center" of in some sense. We showed in <ref> [19] </ref> that when fl s = 0 and b (x) ! 0 when jxj ! 1, the Euler scheme (with no Metropolis adjustment) is not geometrically ergodic but still has a 17 subgeometric (polynomial or better) rate of convergence to , for the f -norm kP n (x; ) k f <p> Guided by the results in <ref> [21, 19] </ref>, we find conditions under which such a subgeometric rate of convergence will also hold for the MADA chain. Theorem 7.1 Suppose b is continuous, (x) 1, and that either Condition A1 holds with fi &lt; 1 or that Condition A2 holds. <p> We first show that there exists some c &gt; 0 such that Z P L (x; dy)jyj k jxj k cjxj k0:5 ; jxj &gt; : (25) Using <ref> [19] </ref> we have that (25) holds with Q L , the transition probability of the Euler chain. From (15) it is now sufficient for (25) to show that r (x)jxj k ! 0 as jxj ! 1. <p> Note that in general we get better rates of convergence for lighter tailed (i.e. for larger fi), and for larger values of fl s . Example 1 The exponential class E We say that 2 E, as introduced in <ref> [15, 19] </ref>, if for some x 0 , and some constants fl s &gt; 0 and 0 &lt; fi &lt; 1, takes the form (x) / e fljxj fi ; jxj x 0 : We now compare the MADA chain properties in Table 1 to those based on the Euler approximations <p> In Figure 4, we show v (x; t) for the MADA chain using B (i); in this case the Euler scheme is a good approximation for the diffusion, but although M h is "close" to the discrete approximation, convergence is very slow; in fact as shown in <ref> [19] </ref> the diffusion itself does not converge exponentially fast.
Reference: [20] <author> L. Tierney. </author> <title> Markov chains for exploring posterior distributions (with discussion). </title> <journal> Ann. Statist., </journal> <volume> 22 </volume> <pages> 1701-1762, </pages> <year> 1994. </year>
Reference-contexts: This is surprisingly widely relevant, occurring especially when is a Bayesian posterior distribution, but in many other contexts also [2, 3, 6]. Recent work on the probabilistic structure of M-H algorithms includes criteria for convergence and approaches to the speed of convergence of the algorithm <ref> [11, 15, 18, 20, 16] </ref>, and in this paper we give a new class fl Work supported in part by NSF Grants DMS 9504798 and DMS 9504561 y Postal Address: Department of Statistics and Actuarial Science, University of Iowa, Iowa City IA 52242, USA z Postal Address: Department of Statistics, Colorado <p> To avoid technical difficulties and assumptions, we assume here that X is IR = (1; 1) equipped with the Borel -field B, and both and Q (x; ) have densities (y) and q (x; y) with respect to Lebesgue measure Leb : much more general formulations are possible (see <ref> [20, 4, 6] </ref>) and our methods can be adapted to them, albeit with different degrees of difficulty. <p> In the former, we choose q (x; y) = q (y) to be independent of x, and in the latter case we choose q (x; y) = q (jx yj) so that the increment is independent of x. It can be shown <ref> [20, 11] </ref> that for independent candidates, we have uniform ergodicity in (3) essentially if and only if ffi = inf [q (w)=(w)] &gt; 0; (4) and in this case we can find the rate of convergence as, for all x, kP n (x; ) k 2 [1 ffi] n : (5)
Reference: [21] <author> P. Tuominen and R.L. Tweedie. </author> <title> Subgeometric rates of convergence of f-ergodic Markov chains. </title> <journal> Adv. Appl. Probab., </journal> <volume> 26 </volume> <pages> 775-798, </pages> <year> 1994. </year> <month> 30 </month>
Reference-contexts: Guided by the results in <ref> [21, 19] </ref>, we find conditions under which such a subgeometric rate of convergence will also hold for the MADA chain. Theorem 7.1 Suppose b is continuous, (x) 1, and that either Condition A1 holds with fi &lt; 1 or that Condition A2 holds. <p> The proof follows now from (25) by using the same argument as in the proof of Proposition 5.2 of <ref> [21] </ref>. ut 8 Exponential and polynomial examples We can summarise the results above for the various types of tail behaviour of and choices of fl s as in Table 1.
References-found: 21

