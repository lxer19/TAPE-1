URL: http://www.cs.mu.oz.au/tr_db/mu_97_20.ps.gz
Refering-URL: http://www.cs.mu.oz.au/tr_db/TR.html
Root-URL: 
Email: fprew,ljkg@cs.mu.oz.au  
Title: A Simple Fast Edge-Based Visual Tracker  
Author: David Prewer Les Kitchen 
Address: Parkville, Victoria 3052, Australia  
Affiliation: Department of Computer Science The University of Melbourne  
Date: September 1997  
Pubnum: Technical Report 97/20  
Abstract: This paper describes a simple visual tracking program. The program has its genesis partly in the idea that it is often preferable to do many simple actions quickly rather than to attempt to do more sophisticated things that take longer. This idea is particularly attractive in the area of visual tracking, where the flow of input data may be at a rate of 10 or 20 Mbytes per second. The tracker described here extracts edges in a frame of an image sequence and attempts to find corresponding edges in the next (and subsequent) frame(s) of the sequence. Using computationally cheap versions of these conventional computer vision techniques the program is capable of tracking moving objects at considerably faster than frame-rate. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. L. Barron, S. S. Beauchemin, and D. J. </author> <title> Fleet. On optical flow. </title> <booktitle> In AIICSR 94: Proc. 6th Int. Conf. on Artificial Intelligence and Information Control Systems of Robots, </booktitle> <pages> pages 3-14, </pages> <address> Bratislava, Slovakia, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow <ref> [9, 13, 1, 2] </ref>, feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12].
Reference: [2] <author> M.J. Black and P. Anandan. </author> <title> A framework for the robust estimation of optical flow. </title> <booktitle> In Proceedings of 4th Int. Conf. on Computer Vision (ICCV'93), </booktitle> <pages> pages 231-236, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow <ref> [9, 13, 1, 2] </ref>, feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12].
Reference: [3] <author> A. Blake, R. Curwen, and A. Zisserman. </author> <title> A framework for spatio-temoral control in the tracking of visual contours. </title> <journal> International Journal of Computer Vision, </journal> <volume> 11(2) </volume> <pages> 127-145, </pages> <year> 1993. </year>
Reference-contexts: The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models <ref> [15, 3, 4] </ref>, and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
Reference: [4] <author> A. Blake and M. Isard. </author> <title> 3D position, attitude and shape input using video tracking of hands and lips. </title> <booktitle> In Proc. ACM Siggraph, </booktitle> <pages> pages 185-192, </pages> <year> 1994. </year> <month> 12 </month>
Reference-contexts: The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models <ref> [15, 3, 4] </ref>, and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
Reference: [5] <author> T. K. Cheng, L. Kitchen, and Z. Q. Liu. </author> <title> Multi-agent real-time 3D track-ing in robot vision. </title> <booktitle> In Proceedings of ACSC'95, Eighteenth Australasian Computer Science Conference, </booktitle> <pages> pages 80-89, </pages> <address> Adelaide, Australia, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence <ref> [8, 5] </ref>, edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12].
Reference: [6] <author> J. L. Crowley, P. Stelmaszyk, T. Skordas, and P. Puget. </author> <title> Measurement and integration of 3-D structures by tracking edges lines. </title> <journal> International Journal of Computer Vision, </journal> <volume> 8(1) </volume> <pages> 29-52, </pages> <year> 1992. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence <ref> [16, 7, 21, 23, 6] </ref>, active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
Reference: [7] <author> R. Deriche and O. Faugeras. </author> <title> Tracking line segments. </title> <journal> Image and Vision Computing, </journal> <volume> 8(4) </volume> <pages> 261-270, </pages> <year> 1990. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence <ref> [16, 7, 21, 23, 6] </ref>, active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
Reference: [8] <author> O. D. Faugeras and S. Maybank. </author> <title> Motion from point matches: Multiplicity of solutions. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 225-246, </pages> <year> 1990. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence <ref> [8, 5] </ref>, edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12].
Reference: [9] <author> C. L. Fennema and W. B. Thompson. </author> <title> Velocity determination in scenes containing several moving objects. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 9(4) </volume> <pages> 301-315, </pages> <year> 1979. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow <ref> [9, 13, 1, 2] </ref>, feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12].
Reference: [10] <author> D. B. Gennery. </author> <title> Visual tracking of known three-dimensional objects. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(3) </volume> <pages> 243-270, </pages> <year> 1992. </year>
Reference-contexts: The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking <ref> [10, 17] </ref>. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
Reference: [11] <author> G. D. Hager and P. N. Belhumeur. </author> <title> Real-time tracking of image regions with changes in geometry and illumination. </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 403-410, </pages> <year> 1996. </year>
Reference-contexts: In this technique a small patch of the image is tracked by finding the corresponding patch in the subsequent images (s) that has the smallest sum of squared differences in pixel intensity values to the "template" patch <ref> [22, 12, 11] </ref>. This technique suffers from sensitivity to changes in orientation and lighting, and produces no real information about what is being tracked.
Reference: [12] <author> G. D. Hager and K. Toyama. </author> <title> X Vision: A portable substrate for real-time vision applications. </title> <type> Technical Report TR-1078, </type> <institution> Department of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <year> 1995. </year>
Reference-contexts: 1 Introduction Relative motion of objects in the environment with respect to a vision system causes visual motion. Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years <ref> [20, 18, 12, 19] </ref>. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17]. <p> Recently there has been an increase in robotic applications that require visual tracking of one sort or another <ref> [12] </ref>. This visual tracking is usually done in the context of a particular overall task. The techniques frequently have a limited applicability beyond the task that they have been designed for, producing a multiplicity of ad hoc techniques. <p> In this technique a small patch of the image is tracked by finding the corresponding patch in the subsequent images (s) that has the smallest sum of squared differences in pixel intensity values to the "template" patch <ref> [22, 12, 11] </ref>. This technique suffers from sensitivity to changes in orientation and lighting, and produces no real information about what is being tracked.
Reference: [13] <author> B. K. P. Horn and B. G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-204, </pages> <year> 1981. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow <ref> [9, 13, 1, 2] </ref>, feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12].
Reference: [14] <author> S. Hutchinson, G. D. Hager, and P. I. Corke. </author> <title> A tutorial on visual servo control. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 12(5) </volume> <pages> 651-670, </pages> <year> 1996. </year>
Reference-contexts: The specific problem that is addressed is the tracking of the intensity edge segments that are found in a window defined within the first frame of an image sequence. Window-based tracking techniques such as this provide one means of helping to make vision cheap and tractable <ref> [14] </ref>. The tracker that has been developed is composed of a number of essentially independent modules (see Figure 1). In the current implementation, the Image Acquirer simply opens each of a sequence of image files and reads them into 1 a data structure in memory in turn.
Reference: [15] <author> H. Kass, A. Witkin, and D. Terzopoulos. Snakes: </author> <title> Active contour models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1 </volume> <pages> 321-331, </pages> <year> 1987. </year>
Reference-contexts: The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models <ref> [15, 3, 4] </ref>, and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
Reference: [16] <author> Y. Liu and T. S. Huang. </author> <title> A linear algorithm for motion estimation using straight line correspondences. </title> <booktitle> In Proc. Int. Conf. on Pattern Recognition, </booktitle> <pages> pages 213-219, </pages> <year> 1988. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence <ref> [16, 7, 21, 23, 6] </ref>, active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
Reference: [17] <author> D. G. Lowe. </author> <title> Robust model-based motion tracking through the integration of search and estimation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 113-122, </pages> <year> 1992. </year>
Reference-contexts: The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking <ref> [10, 17] </ref>. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
Reference: [18] <author> P. F. McLauchlan and D. W. Murray. </author> <title> A unifying framework for structure and motion recovery from image sequences. </title> <booktitle> In Proc. 5th Int. Conf. on Computer Vision, </booktitle> <address> Cambridge, Massachusetts, </address> <month> June </month> <year> 1995. </year> <month> 13 </month>
Reference-contexts: 1 Introduction Relative motion of objects in the environment with respect to a vision system causes visual motion. Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years <ref> [20, 18, 12, 19] </ref>. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17].
Reference: [19] <author> A. Mitiche and P. Bouthemy. </author> <title> Computation and analysis of image motion: A synopsis of current problems and methods. </title> <journal> International Journal of Computer Vision, </journal> <volume> 19(1) </volume> <pages> 29-55, </pages> <year> 1996. </year>
Reference-contexts: 1 Introduction Relative motion of objects in the environment with respect to a vision system causes visual motion. Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years <ref> [20, 18, 12, 19] </ref>. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17].
Reference: [20] <author> D. W. Murray and B. F. Buxton. </author> <title> Experiments in the Machine Interpretation of Visual Motion. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: 1 Introduction Relative motion of objects in the environment with respect to a vision system causes visual motion. Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years <ref> [20, 18, 12, 19] </ref>. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence [16, 7, 21, 23, 6], active contour models [15, 3, 4], and model-based tracking [10, 17].
Reference: [21] <author> M. E. Spetsakis and J. Aloimonos. </author> <title> Structure from motion using line correspondences. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 171-183, </pages> <year> 1990. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence <ref> [16, 7, 21, 23, 6] </ref>, active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
Reference: [22] <author> M. Wessler. </author> <title> A modular visual tracking system. </title> <type> Master's thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: In this technique a small patch of the image is tracked by finding the corresponding patch in the subsequent images (s) that has the smallest sum of squared differences in pixel intensity values to the "template" patch <ref> [22, 12, 11] </ref>. This technique suffers from sensitivity to changes in orientation and lighting, and produces no real information about what is being tracked.
Reference: [23] <author> Z. Zhang and O. Faugeras. </author> <title> Determining motion from 3D line segment matches: A comparative study. </title> <journal> Image and Vision Computing, </journal> <volume> 9(1) </volume> <pages> 10-19, </pages> <year> 1991. </year>
Reference-contexts: Analysis of such visual motion in sequences of images has been addressed by many researchers over a number of years [20, 18, 12, 19]. The techniques that have been used include optical flow [9, 13, 1, 2], feature point correspondence [8, 5], edge or contour correspondence <ref> [16, 7, 21, 23, 6] </ref>, active contour models [15, 3, 4], and model-based tracking [10, 17]. Recently there has been an increase in robotic applications that require visual tracking of one sort or another [12]. This visual tracking is usually done in the context of a particular overall task.
References-found: 23

