URL: http://www.csc.ncsu.edu/faculty/young/publications/pic.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/young/publications/papers.html
Root-URL: http://www.csc.ncsu.edu
Email: myoung+@pitt.edu  jmoore@cs.pitt.edu  
Phone: voice: (412) 624-7035 fax: (412) 624-9149  voice: (412) 624-7050 fax: (412) 624-9149  
Title: Does Discourse Planning Require A Special-Purpose Planner?  
Author: R. Michael Young Johanna D. Moore 
Address: Pittsburgh Pittsburgh, PA 15206  Pittsburgh Pittsburgh, PA 15206  
Affiliation: Intelligent Systems Program Univerisity of  Department of Computer Science, and Learning Research and Development Center University of  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Michael Bratman. </author> <title> Intentions, Plans, and Practical Reason. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: If, however, the effect that failed was not an intended effect, the speaker need not generate an alternative response to achieve it. In fact, replanning to achieve unintended effects is not appropriate behavior for a rational agent <ref> [1, 2] </ref>. Alternatively, if the effect that failed was intended, but served only as a precondition of an action whose intended effects succeeded despite the failure, then again the speaker may chose not to respond.
Reference: [2] <author> Philip R. Cohen and Hector Levesque. </author> <title> Rational interaction as the basis for communication. </title> <editor> In Philip R. Cohen, Jerry Morgan, and Martha E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: If, however, the effect that failed was not an intended effect, the speaker need not generate an alternative response to achieve it. In fact, replanning to achieve unintended effects is not appropriate behavior for a rational agent <ref> [1, 2] </ref>. Alternatively, if the effect that failed was intended, but served only as a precondition of an action whose intended effects succeeded despite the failure, then again the speaker may chose not to respond.
Reference: [3] <author> Philip R. Cohen and C. Raymond Perrault. </author> <title> Elements of a plan-based theory of speech acts. </title> <journal> Cognitive Science, </journal> <volume> 3 </volume> <pages> 177-212, </pages> <year> 1979. </year>
Reference-contexts: The effects of these actions are precondition for a combine-belief act. This combine-belief act is similar to Cohen and Perrault's <ref> [3] </ref> CONVINCE operator for achieving perlocutionay effects. For now, we use these combine-belief steps in DPOCL as a place holder for a more complete model of the inferences that a hearer draws as a result of communication.
Reference: [4] <author> Barbara J. Grosz and Candace L. Sidner. </author> <title> Attention, intention, and the structure of discourse. </title> <journal> Computational Linguistics, </journal> <volume> 12(3) </volume> <pages> 175-204, </pages> <year> 1986. </year>
Reference-contexts: That is, the plan should achieve all of its goals and be bug free. This doesn't sound like alot to ask, but, as we describe in [14], most special-purpose discourse planning systems do not guarantee this property. Form: Computational linguists (e.g., <ref> [4, 9, 10] </ref>) have argued that in order to handle discourse phenomena such as anaphora resolutions and clarification subdialogues discourse plans must represent the intentional and informational structures of the discourses they produce. <p> Form: Computational linguists (e.g., [4, 9, 10]) have argued that in order to handle discourse phenomena such as anaphora resolutions and clarification subdialogues discourse plans must represent the intentional and informational structures of the discourses they produce. As defined by Grosz and Sidner <ref> [4] </ref>, intentional structure consists of two types of relations between discourse actions. If an action that satisfies one intention, I 1 , is intended to provide part of the satisfaction of another intention, I 2 , then I 2 dominates I 1 .
Reference: [5] <author> Mark T. </author> <title> Maybury. Communicative acts for explanation generation. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 37(2) </volume> <pages> 135-172, </pages> <year> 1992. </year>
Reference-contexts: DPOCL is a hierarchical extension to recent work in partial-order, causal link (POCL) planning [6, 11]. POCL planners build plans iteratively by: 1 Maybury <ref> [5] </ref> also recognizes the need to distinguish between algorithm and representation, but his planner relies on a theory of action that fails to account for the causal relationship between steps in plans. 2 Begin-Subplan End-Subplan Cause-to-Believe (engaged (L,B))) Combine-Belief (x) Begin-Subplan End-Subplan Inform (engaged (L,B))) Combine-Belief (x) Support (engaged (L,B))) Begin-Plan <p> Decomposition is represented by operators that specify a) a partial plan to be used to achieve the effects of an abstract step and b) a list of contraints, similar to the action-operator constraints used by previous discourse planners <ref> [5, 9] </ref>. These constraints specify conditions that must be true at the time the abstract action executes in order for the decomposition operator to be used. They do not generate subgoals for the planner to achieve. Instead they serve as a filter for screening out inappropriate decompositions.
Reference: [6] <author> David McAllister and David Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 634-639, </pages> <year> 1991. </year> <month> 7 </month>
Reference-contexts: We can easily share domain theories with other researchers. 4 DPOCL A Domain-Independent Planner that Gen erates Discourse Plans We have constructed a discourse planner, called DPOCL, that adheres to this declarative model. DPOCL is a hierarchical extension to recent work in partial-order, causal link (POCL) planning <ref> [6, 11] </ref>.
Reference: [7] <author> Johanna D. Moore. </author> <title> Indexing and exploiting a discourse history to generate context--sensitive explanations. </title> <booktitle> In Proceedings of the ARPA Human Language Technology Workshop, </booktitle> <pages> pages 165-170. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference-contexts: Clearly, differentiating between intended and unintended effects of discourse actions is critical for generating appropriate responses. In addition, a representation of intentional and informational structure has been shown to be crucial for generating responses that take prior utterances into account <ref> [7, 8] </ref>. 7 Extending the Model Although the DPOCL planner does not currently address the issues listed below, they can be viewed as additional representational challenges for a domain theory. * Addressing a Single Communicative Goal in Multiple Ways to Increase the Likelihood of Success: In the plan shown in Figure
Reference: [8] <author> Johanna D. Moore, Beno^it Lemaire, and James A. Rosenblum. </author> <title> Discourse generation for instructional applications: Identifying and exploiting relevant prior explanations. </title> <note> submitted for publication. </note>
Reference-contexts: Clearly, differentiating between intended and unintended effects of discourse actions is critical for generating appropriate responses. In addition, a representation of intentional and informational structure has been shown to be crucial for generating responses that take prior utterances into account <ref> [7, 8] </ref>. 7 Extending the Model Although the DPOCL planner does not currently address the issues listed below, they can be viewed as additional representational challenges for a domain theory. * Addressing a Single Communicative Goal in Multiple Ways to Increase the Likelihood of Success: In the plan shown in Figure
Reference: [9] <author> Johanna D. Moore and Cecile L. Paris. </author> <title> Planning text for advisory dialogues: Capturing intentional and rhetorical information. </title> <journal> Computational Linguistics, </journal> <volume> 19(4) </volume> <pages> 651-695, </pages> <year> 1993. </year>
Reference-contexts: That is, the plan should achieve all of its goals and be bug free. This doesn't sound like alot to ask, but, as we describe in [14], most special-purpose discourse planning systems do not guarantee this property. Form: Computational linguists (e.g., <ref> [4, 9, 10] </ref>) have argued that in order to handle discourse phenomena such as anaphora resolutions and clarification subdialogues discourse plans must represent the intentional and informational structures of the discourses they produce. <p> Decomposition is represented by operators that specify a) a partial plan to be used to achieve the effects of an abstract step and b) a list of contraints, similar to the action-operator constraints used by previous discourse planners <ref> [5, 9] </ref>. These constraints specify conditions that must be true at the time the abstract action executes in order for the decomposition operator to be used. They do not generate subgoals for the planner to achieve. Instead they serve as a filter for screening out inappropriate decompositions.
Reference: [10] <author> Johanna D. Moore and Martha E. Pollack. </author> <title> A problem for RST: The need for multi-level discourse analysis. </title> <journal> Computational Linguistics, </journal> <volume> 18(4) </volume> <pages> 537-544, </pages> <year> 1992. </year>
Reference-contexts: That is, the plan should achieve all of its goals and be bug free. This doesn't sound like alot to ask, but, as we describe in [14], most special-purpose discourse planning systems do not guarantee this property. Form: Computational linguists (e.g., <ref> [4, 9, 10] </ref>) have argued that in order to handle discourse phenomena such as anaphora resolutions and clarification subdialogues discourse plans must represent the intentional and informational structures of the discourses they produce.
Reference: [11] <author> Scott Penberthy and Daniel Weld. UCPOP: </author> <title> A sound, complete partial order planner for ADL. </title> <booktitle> In Proceedings of Knowledge Representation Conference, </booktitle> <pages> pages 103-114, </pages> <year> 1991. </year>
Reference-contexts: We can easily share domain theories with other researchers. 4 DPOCL A Domain-Independent Planner that Gen erates Discourse Plans We have constructed a discourse planner, called DPOCL, that adheres to this declarative model. DPOCL is a hierarchical extension to recent work in partial-order, causal link (POCL) planning <ref> [6, 11] </ref>.
Reference: [12] <author> Earl D. Sacerdoti. </author> <title> A structure for plans and behavior. </title> <publisher> Elsevier, North-Holland, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: They do not generate subgoals for the planner to achieve. Instead they serve as a filter for screening out inappropriate decompositions. When an abstract parent step is expanded by adding its substeps to the plan, dummy steps (similar to NOAH's <ref> [12] </ref> split and join nodes) are created in order to mark the beginning and ending of the subplan. The effects of the parent step are treated as preconditions for the dummy final step. The planner establishes these preconditions like the preconditions for any other step.
Reference: [13] <author> Marilyn Walker. </author> <title> Informational Redundancy and Resource Bounds in Dialog. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <year> 1994. </year>
Reference-contexts: Unfortunately, this approach fails to capture an important discourse-related phenomena. Often a speaker will assert the same proposition several times in the same discourse. If the speaker hasn't asserted a contradictory utterance, why should he repeat his action? Walker <ref> [13] </ref> offers a model for explaining such informationally redundant utterances (IRU's). In her model, IRU's are explained by modeling discourse participants as agents with limited attentional and inferential capacity.
Reference: [14] <author> R. Michael Young. </author> <title> Characterizing formal properties of discourse planning systems. </title> <year> 1994. </year>
Reference-contexts: That is, the plan should achieve all of its goals and be bug free. This doesn't sound like alot to ask, but, as we describe in <ref> [14] </ref>, most special-purpose discourse planning systems do not guarantee this property. Form: Computational linguists (e.g., [4, 9, 10]) have argued that in order to handle discourse phenomena such as anaphora resolutions and clarification subdialogues discourse plans must represent the intentional and informational structures of the discourses they produce.
Reference: [15] <author> R. Michael Young, Johanna D. Moore, and Martha E. Pollack. </author> <title> Towards a principled representation for discourse plans. </title> <type> Technical Report 94-2, </type> <institution> Intelligent Systems Program, University of Pittsburgh, Pittsburgh, Pennsylvania, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: A single effect from one step may have any number of causal links emanating from it, and an individual step may have causal links from any number of its effects to any number of other steps. * Being Sensitive to Prior Plans and Their Failures: As explained in <ref> [15] </ref>, the formal representation of causal and decompositional connections between steps in the DPOCL plan makes the definition of intention in terms of these concepts straightforward. Informally, an effect is intended if it plays a causal role in the plan.
Reference: [16] <author> R. Michael Young, Martha E. Pollack, and Johanna D. Moore. </author> <title> Decomposition and causality in partial order planning, </title> <booktitle> 1994. To appear in the Proceedings of the Second International Conference on Artificial Intelligence and Planning Systems. </booktitle>
Reference-contexts: DPOCL uses essentially the same POCL planning process, with the addition of a step that creates the hierarchical structure by expanding each abstract action into the steps for its subplan. A complete description of DPOCL's algorithm is beyond the scope of this paper; for a full account, see <ref> [16] </ref>. An example of a simple DPOCL discourse plan, represented as a directed acyclic graph, is shown in Figure 1. In this figure each node represents a step in the plan. Two types of arcs connect plan steps.
Reference: [17] <author> R. Michael Young, Martha E. Pollack, and Johanna D. Moore. </author> <title> Decomposition and causality in partial order planning. </title> <type> Technical Report 94-1, </type> <institution> Intelligent Systems Program, University of Pittsburgh, Pittsburgh, Pennsylvania, </institution> <month> January </month> <year> 1994. </year> <note> To appear in the Second International Conference on Artificial Intelligence and Planning Systems. 8 </note>
Reference-contexts: For instance, some other step might come between s j and s i and undo s j 's effect before s i can use it. 3 For a proof of DPOCL's soundness, see <ref> [17] </ref>. 4 any set of consistent operators (no matter what application or domain), DPOCL is guaranteed to produce a plan that will achieve its goals when executed in its initial state.
References-found: 17

