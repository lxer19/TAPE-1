URL: http://www.cs.berkeley.edu/~fateman/papers/benb.ps
Refering-URL: http://www.cs.berkeley.edu/~fateman/ocrpapers.html
Root-URL: 
Title: Optical Character Recognition for Typeset Mathematics  
Author: Benjamin P. Berman Richard J. Fateman 
Address: Berkeley  
Affiliation: Computer Science Division, EECS Department University of California at  
Abstract: There is a wealth of mathematical knowledge that could be potentially very useful in many computational applications, but is not available in electronic form. This knowledge comes in the form of mechanically typeset books and journals going back more than a hundred years. Besides these older sources, there are a great many current publications, filled with useful mathematical information, which are difficult if not impossible to obtain in electronic form. What we would like to do is extract character information from these documents, which could then be passed to higher-level parsing routines for further extraction of mathematical content (or any other useful 2-dimensional semantic content). Unfortunately, current commercial OCR (optical character recognition) software packages are quite unable to handle mathematical formulas, since their algorithms at all levels use heuristics developed for other document styles 1 . We are concerned with the development of OCR methods that are able to handle this specialized task of mathematical expression recognition. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Bokser. </author> <booktitle> "Omnidocument technologies." Proceedings of the IEEE, </booktitle> <month> July </month> <year> 1992, </year> <note> vol.80, (no.7) 1066|78. </note>
Reference-contexts: It is an elaboration and extension of a paper accepted for ISSAC94 (Oxford, UK, July, 1994). 1 They are however, remarkably capable in other domains. A useful general reference is the paper by Bokser <ref> [1] </ref>, which discusses in some detail the Calera scheme; other competing commercial systems include Caere and Xerox Imaging Systems. today. <p> It was improved and generalized somewhat based on ideas in Mindy Bokser's paper <ref> [1] </ref> in May, 1993. Principally, she suggests that a recognizer based on simple properties (a 16 by 16 grid of gray-scale values), and closeness based on neural network training, would work fine.
Reference: [2] <author> G. Borgefors. </author> <title> "Distance transforms in digital images." </title> <journal> IEEE Trans. Pat. Anal. an Mach. Intel., </journal> <volume> 34 </volume> <pages> 344-271, </pages> <year> 1986. </year>
Reference-contexts: This turns out to be very well suited to our application as we generally want to compare one particular unidentified character to each of several plausible model characters. There are at least a few good ways to compute the distance transform in an efficient manner. The first <ref> [2] </ref> uses several serial passes of the data to propagate out estimations 6 of distance from ON pixels, where the distance is 0. Another method [11] makes separate vertical and horizontal sweeps of the data to deduce its distances. <p> Since we are only interested in examining matches that are very close in nature, we can choose a very low threshold. This low threshold value can greatly increase the efficiency of the algorithm in [11], whereas the other algorithm <ref> [2] </ref> is not as well suited to this particular constraint. We refer the reader to the references for details of the algorithms. 6 The Learning Phase: Details The main goal for the learning phase is to develop a set of model characters for a corpus 7 .
Reference: [3] <author> P. Chou, </author> <title> "Recognition of equations using a two-dimensional stochastic context-free grammar", </title> <booktitle> SPIE Conf. on Visual Communications and Image Processing, </booktitle> <address> Philadelphia, PA, </address> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: Chou <ref> [3] </ref>. This paper describes a 2-D parser which runs on a bit map produced by eqn and then peppered with noise. <p> Joined with some graph-type recognition, certain types of chemical and physical diagrams could be tackled as well. Since beginning this work in the Spring of 1993, we have found on-going related activity at Xerox's Palo Alto Research Center by Dennis Arnon, Phil Chou, and Gary Kopec <ref> [3] </ref>, [9]. The theoretical framework provided by this work, viewing OCR as a signal processing (decoding) task, identifies equation recognition as one special case among a number of OCR tasks.
Reference: [4] <author> D. Bierens de Haan. </author> <title> Nouvelles Tables d'Integrales De finies edition of 1867 corrected, with an English Translation of the Introduction by J.F. </title> <editor> Ritt. G. E. </editor> <publisher> Stechert & Co. </publisher> <address> NY. </address> <year> 1939. </year>
Reference-contexts: Both size and font information provide other useful hints to the parser, as the use of large letters, small letters, boldface, italics, and different fonts can provide additional semantics. Non-obviously, we have found references (e.g. <ref> [4] </ref>) using different fonts and sizing for numbers depending upon their use as (for example) page numbers, equation labels, reference numbers, base-line coefficients, exponents, or footnotes 2 . 3 Science vs. <p> This is not entirely comfortable. Furthermore, the typeset characteristics of some of glyphs varies substantially with historical and aesthetic criteria. One source of material <ref> [4] </ref> sets the "+" with a descender as low as the tail of a "p". The standard size of font used for T E X mathematics has a smaller "+". <p> At this point, there are 3 kinds of objects remaining on the page: 1. Disconnected characters: These are characters that have been split up into 2 or more separate objects because they were disconnected on the page. See figure 1 illustrating the 400 dots/inch resolution on an example from <ref> [4] </ref>. 2. "Over-connected" characters: This happens when 2 or more characters are smashed into one object because they were touching at some point. See figure 2. 3. Unrecognizable characters and/or garbage: These are items that can not, for whatever reason, be recognized. <p> To get an idea of the time this all takes, let us assume that prior to our looking at an equation, the page processing has identified a "zone" containing a single equation from <ref> [4] </ref> See figure 3. This was scanned at 200 dpi, and slightly cleaned up so that our naive recognition would work. Cleaning constituted breaking connected glyphs in Sin and Cos; we also removed the dots above the i's but that could have been handled other ways, too.
Reference: [5] <author> Richard J. Fateman. </author> <title> "Recognition and Parsing of Typeset Mathematics," </title> <type> UCB CS Division internal report, </type> <month> January </month> <year> 1994. </year>
Reference-contexts: 1 Introduction This work is a part of a larger project <ref> [5] </ref> that intends to encode, for use by computer algebra systems, integral tables and other documents currently available in hardcopy only. We concentrate here on the surprisingly "unsolved" problems of OCR for mathematical equations.
Reference: [6] <author> Richard J. Fateman and Theodore H. Einwohner. </author> <title> "Automated Integral Tables" UCB CS Division internal report, </title> <month> January </month> <year> 1994. </year>
Reference-contexts: When the recognizer fails in this way it can trigger a temporary return to the learning phase. 7.6 Are Typeset Results Correct? Correctness, and other questions having to do with the content of the integral tables themselves, are discussed at length in a draft document <ref> [6] </ref>. Since a referee raised the particular issue of correctness, we should point out that we do not take for granted that the formulas in the tables of integrals are error-free. Quite the contrary.
Reference: [7] <author> D.P. Huttenlocher, Gregory A. Klandermand, William J. Rucklidge. </author> <title> "Comparing Images Using the Hausdorff Distance," </title> <institution> Cornell Univ. CS Dept. Tech. Rpt. </institution>
Reference-contexts: We discuss one such set of techniques in substantial detail. In the remainder of this section we are somewhat more formal in describing the distance measurements be tween objects in 2-dimensional space. 5.1 The Voronoi Surface The first important concept is the Voronoi surface <ref> [7] </ref>, or its rasterized equivalent, the distance transform [11]. Given a space A and an image I within that space, the Voronoi surface assigns to every point a 2 A the distance from a to the closest point in I. <p> In particular, we use a metric known as the Hausdorff distance <ref> [7] </ref>. <p> This does not specify the distance from B to A : : : since there could be points in B that are indefinitely far from anything in A. Along with Huttenlocher, <ref> [7] </ref> we will refer to this asymmetric version as the directed Hausdorff distance. If we want a more complete description of the distance between A and B, we can simply take the greater of the distances from A to B and from B to A.
Reference: [8] <author> Melvin Klerer and Fred Grossman. </author> <title> "Error Rates in Tables of Indefinite Integrals." </title> <institution> Industrial Math. </institution> <month> 18 </month> <year> (1968) </year> <month> 31-62. </month> <title> See also, by the same authors, A new table of indefinite integrals; computer processed Dover, </title> <address> New York, </address> <year> 1971. </year>
Reference-contexts: Since a referee raised the particular issue of correctness, we should point out that we do not take for granted that the formulas in the tables of integrals are error-free. Quite the contrary. Substitution of numbers for parameters and numerical integration can form a partial confirmation, <ref> [8] </ref> but this too may be inadequate|the prospect for errors with regard to validity of domains is also substantial, and a particular weak point with computer algebra systems today. Only with indefinite integral formulas is there a prospect of checking by differentiating the result.
Reference: [9] <author> G. Kopec and P. Chou, </author> <title> "Automatic generation of custom document image decoders", </title> <booktitle> Proc. Second Intl. Conf. on Doc. </booktitle> <institution> Anal. and Recog., Tsukuba Science City, </institution> <address> Japan, </address> <month> Oct. </month> <pages> 20-22, </pages> <year> 1993. </year>
Reference-contexts: Joined with some graph-type recognition, certain types of chemical and physical diagrams could be tackled as well. Since beginning this work in the Spring of 1993, we have found on-going related activity at Xerox's Palo Alto Research Center by Dennis Arnon, Phil Chou, and Gary Kopec [3], <ref> [9] </ref>. The theoretical framework provided by this work, viewing OCR as a signal processing (decoding) task, identifies equation recognition as one special case among a number of OCR tasks.
Reference: [10] <author> Nicholas Mitchell. </author> <title> "A Parser for Two-Dimensional OCR of Mathematics," </title> <note> UCB progress report 1994. </note>
Reference-contexts: A glyph is a representation of a character that includes font information as well as the alphanumeric "value". Later processing <ref> [10] </ref> deals with the "transcription" process that relates text like x + y 2 to an interpretation such as $x+y^2$ in T E X or (plus x (power y 2)) in Lisp. The OCR software generally available focuses primarily on 1-dimensional text.

References-found: 10

