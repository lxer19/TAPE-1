URL: http://iacoma.cs.uiuc.edu/iacoma-papers/osplacelong.ps
Refering-URL: http://iacoma.cs.uiuc.edu/papers.html
Root-URL: http://www.cs.uiuc.edu
Email: torrella,xia,daigle@cs.uiuc.edu  
Title: Optimizing the Instruction Cache Performance of the Operating System 1  
Author: Josep Torrellas, Chun Xia and Russell Daigle 
Web: http://iacoma.cs.uiuc.edu  
Address: IL 61801  
Affiliation: Computer Science Department University of Illinois at Urbana-Champaign,  
Abstract: High instruction cache hit rates are key to high performance. One known technique to improve the hit rate of caches is to minimize cache interference by improving the layout of the basic blocks of the code. However, the performance impact of this technique has been reported for application code only, even though there is evidence that the operating system often uses the cache heavily and with less uniform patterns than applications. It is unknown how well existing optimizations perform for systems code and whether better optimizations can be found. We address this problem in this paper. This paper characterizes in detail the locality patterns of the operating system code and shows that there is substantial locality. Unfortunately, caches are not able to extract much of it: rarely-executed special-case code disrupts spatial locality, loops with few iterations that call routines make loop locality hard to exploit, and plenty of loop-less code hampers temporal locality. Based on our observations, we propose an algorithm to expose these localities and reduce interference in the cache. For a range of cache sizes, associativities, lines sizes and organizations we show that we reduce total instruction miss rates by 31-86%, or up to 2.9 absolute points. Using a simple model, this corresponds to execution time reductions of the order of 10-25%. In addition, our optimized operating system combines well with optimized and unoptimized applications.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, P. Chow, M. Horowitz, J. Acken, A. Salz, and J. Hennessy. </author> <title> On-Chip Caches for High-Performance Processors. </title> <booktitle> In Advanced Research in VLSI: Proceedings of the 1987 Stanford Conference, </booktitle> <pages> pages 1-24, </pages> <month> March </month> <year> 1987. </year>
Reference-contexts: Improving the performance of instruction caches has been addressed by many researchers. It has been shown that it is feasible to reduce the misses in applications by improving the layout of the code in memory <ref> [1, 12, 13, 15, 16, 17, 18, 21, 22, 24] </ref>. The techniques proposed are based on repositioning or replicating code at the procedure or basic block level, usually to reduce cache conflicts or utilize the cache lines better. <p> In most cases, these techniques perform quite well, speeding up applications by 5-30% or even more. The schemes where the block of code that gets repositioned or replicated is the procedure <ref> [1, 24] </ref> tend to be less effective. This is because a procedure has parts that are invoked frequently and parts that are not. As a result, it is not the optimal unit to handle.
Reference: [2] <author> A. Agarwal, J. Hennessy, and M. Horowitz. </author> <title> Cache Performance of Operating System and Multiprogramming Workloads. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(4) </volume> <pages> 393-431, </pages> <month> November </month> <year> 1988. </year> <month> 26 </month>
Reference-contexts: Indeed, there is some evidence that backs this claim. Clark [11] reported a lower performance of the VAX-11/780 cache when operating system activity was taken into account. Similarly, Agarwal et al <ref> [2] </ref> pointed out the many cache misses caused by the operating system. Torrellas et al [23] reported that the operating system code causes a large fraction of the cache misses and, in addition, suffers considerable self-interference in the cache.
Reference: [3] <author> A. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Consequently, exposing spatial locality can potentially remove many misses. 3.2.2 Loop Locality The second type of locality that we examine is the locality provided by loops. To identify the loops, we use dataflow analysis <ref> [3] </ref>. For our analysis, we divide the loops into those that do not call procedures and those that do. We now consider each category in turn. Loops Without Procedure Calls Our measurements show that these loops do not dominate the execution time of the operating system. <p> We use dataflow analysis as discussed by Aho et al <ref> [3] </ref>. Then, we select the loops with at least a minimum number of iterations per invocation (currently set to 6). We pull the basic blocks of these loops out of the sequences and put them, in the same order, in a contiguous area at the end of the sequences.
Reference: [4] <author> T. Anderson, H. Levy, B. Bershad, and E. Lazowska. </author> <title> The Interaction of Architecture and Operating System Design. </title> <booktitle> In Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 108-120, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Similarly, Chen and Bershad [8] reported that system code has lower locality than application code. They also pointed out the self-interference in the cache. Other researchers like Ousterhout [20] and Anderson et al <ref> [4] </ref> also indicated the different nature of the operating system activity. Finally, Nagle et al [19] pointed out that instruction cache performance is becoming increasingly important in new-generation operating systems.
Reference: [5] <editor> J. B. </editor> <address> Andrews. </address>
Reference-contexts: The machine uses Alliant processors, which run Motorola 68020 assembly code with some extensions. We custom-designed a hardware performance monitor that gathers uninterrupted reference traces of application and operating system in real time without introducing much perturbation. The performance monitor <ref> [5] </ref> has one probe connected to each of the four processors. The probes collect all instruction and data references issued by the processors except those that hit in the per-processor 16-Kbyte on-chip instruction cache. Each probe has a trace buffer that stores over one million references.
References-found: 5

