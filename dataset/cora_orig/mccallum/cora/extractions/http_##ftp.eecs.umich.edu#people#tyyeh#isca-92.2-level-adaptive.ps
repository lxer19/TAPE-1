URL: http://ftp.eecs.umich.edu/people/tyyeh/isca-92.2-level-adaptive.ps
Refering-URL: http://ftp.eecs.umich.edu/people/tyyeh/
Root-URL: http://www.eecs.umich.edu
Title: Alternative Implementations of Two-Level Adaptive Branch Prediction  
Author: Tse-Yu Yeh and Yale N. Patt 
Address: Ann Arbor, Michigan 48109-2122  
Affiliation: Gold Coast, Australia.  Department of Electrical Engineering and Computer Science The University of Michigan  
Date: 124 134, May 19 21, 1992,  
Note: The 19th Annual International Symposium on Computer Architecture pp.  
Abstract: As the issue rate and depth of pipelining of high performance Superscalar processors increase, the importance of an excellent branch predictor becomes more vital to delivering the potential performance of a wide-issue, deep pipelined microarchitecture. We propose a new dynamic branch predictor (Two-Level Adaptive Branch Prediction) that achieves substantially higher accuracy than any other scheme reported in the literature. The mechanism uses two levels of branch history information to make predictions, the history of the last k branches encountered, and the branch behavior for the last s occurrences of the specific pattern of these k branches. We have identified three variations of the Two-Level Adaptive Branch Prediction, depending on how finely we resolve the history information gathered. We compute the hardware costs of implementing each of the three variations, and use these costs in evaluating their relative effectiveness. We measure the branch prediction accuracy of the three variations of Two-Level Adaptive Branch Prediction, along with several other popular proposed dynamic and static prediction schemes, on the SPEC benchmarks. We show that the average prediction accuracy for Two-Level Adaptive Branch Prediction is 97 percent, while the other known schemes achieve at most 94.4 percent average prediction accuracy. We measure the effectiveness of different prediction algorithms and different amounts of history and pattern information. We measure the costs of each variation to obtain the same prediction accuracy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T-Y Yeh and Y.N. Patt, </author> <title> "Two-Level Adaptive Branch Prediction", </title> <type> Technical Report CSE-TR-117-91, </type> <institution> Computer Science and Engineering Division, Department of EECS, The University of Michigan, </institution> <month> (Nov. </month> <year> 1991). </year>
Reference: [2] <author> T-Y Yeh and Y.N. Patt, </author> <title> "Two-Level Adaptive Branch Prediction", </title> <booktitle> The 24th ACM/IEEE International Symposium and Workshop on Microarchitecture , (Nov. </booktitle> <year> 1991), </year> <pages> pp. 51-61. </pages>
Reference: [3] <author> M. Butler, T-Y Yeh, Y.N. Patt, M. Alsup, H. Scales, and M. Shebanow, </author> <title> "Instruction Level Parallelism is Greater Than Two", </title> <booktitle> Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <month> (May. </month> <year> 1991), </year> <pages> pp. 276-286. </pages>
Reference: [4] <author> D. R. Kaeli and P. G. Emma, </author> <title> "Branch History Table Prediction of Moving Target Branches Due to Subroutine Returns" , Proceedings of the 18th International Symposium on Computer Architecture, </title> <month> (May </month> <year> 1991), </year> <pages> pp. 34-42. </pages>
Reference: [5] <author> Motorola Inc., </author> <title> "M88100 User's Manual", </title> <address> Phoenix, Ari-zona, (March 13, </address> <year> 1989). </year>
Reference: [6] <author> W.W. Hwu, T.M.Conte, and P.P.Chang, </author> <title> "Comparing Software and Hardware Schemes for Reducing the Cost of Branches", </title> <booktitle> Proceedings of the 16th International Symposium on Computer Architecture, </booktitle> <month> (May </month> <year> 1989). </year>
Reference-contexts: The literature is full of suggested branch prediction schemes <ref> [6, 13, 14, 17] </ref>. Some are static in that they use opcode information and profiling statistics to make predictions. Others are dynamic in that they use run-time execution history to make predictions. <p> This latter scheme is effective for loop intensive code, but does not work well for programs where the branch behavior is irregular. Also, profiling <ref> [6, 13] </ref> can be used to predict branches by measuring the tendency of a branch on sample data sets and presetting a static prediction bit in the opcode according to that tendency. Unfortunately, branch behavior for the sample data may be very different from the data that appears at run-time.
Reference: [7] <author> N.P. Jouppi and D. Wall, </author> <title> "Available Instruction-Level Parallelism for Superscalar and Superpipelined Machines.", </title> <booktitle> Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> (April </month> <year> 1989), </year> <pages> pp. 272-282. </pages>
Reference: [8] <author> D. J. Lilja, </author> <title> "Reducing the Branch Penalty in Pipelined Processors ", IEEE Computer, </title> <month> (July </month> <year> 1988), </year> <month> pp.47-55. </month>
Reference: [9] <author> W.W. Hwu and Y.N. Patt, </author> <title> "Checkpoint Repair for Out-of-order Execution Machines", </title> <journal> IEEE Transactions on Computers, </journal> <month> (December </month> <year> 1987), </year> <month> pp.1496-1514. </month>
Reference: [10] <author> P. G. Emma and E. S. Davidson, </author> <title> "Characterization of Branch and Data Dependencies in Programs for Evaluating Pipeline Performance" , IEEE Transactions on Computers, </title> <month> (July </month> <year> 1987), </year> <month> pp.859-876. </month>
Reference: [11] <author> J. A. DeRosa and H. M. Levy, </author> <booktitle> "An Evaluation of Branch Architectures ", Proceedings of the 14th International Symposium on Computer Architecture, </booktitle> <month> (June </month> <year> 1987), </year> <month> pp.10-16. </month>
Reference: [12] <author> D.R. Ditzel and H.R. McLellan, </author> <title> "Branch Folding in the CRISP Microprocessor: Reducing Branch Delay to Zero", </title> <booktitle> Proceedings of the 14th International Symposium on Computer Architecture, </booktitle> <month> (June </month> <year> 1987), </year> <month> pp.2-9. </month>
Reference: [13] <author> S. McFarling and J. Hennessy, </author> <title> "Reducing the Cost of Branches", </title> <booktitle> Proceedings of the 13th International Symposium on Computer Architecture, </booktitle> <year> (1986), </year> <month> pp.396-403. </month>
Reference-contexts: The literature is full of suggested branch prediction schemes <ref> [6, 13, 14, 17] </ref>. Some are static in that they use opcode information and profiling statistics to make predictions. Others are dynamic in that they use run-time execution history to make predictions. <p> This latter scheme is effective for loop intensive code, but does not work well for programs where the branch behavior is irregular. Also, profiling <ref> [6, 13] </ref> can be used to predict branches by measuring the tendency of a branch on sample data sets and presetting a static prediction bit in the opcode according to that tendency. Unfortunately, branch behavior for the sample data may be very different from the data that appears at run-time.
Reference: [14] <author> J. Lee and A. J. Smith, </author> <title> "Branch Prediction Strategies and Branch Target Buffer Design", </title> <booktitle> IEEE Computer, </booktitle> <month> (January </month> <year> 1984), </year> <month> pp.6-22. </month>
Reference-contexts: The literature is full of suggested branch prediction schemes <ref> [6, 13, 14, 17] </ref>. Some are static in that they use opcode information and profiling statistics to make predictions. Others are dynamic in that they use run-time execution history to make predictions. <p> J. Smith [17] proposed utilizing a branch target buffer to store, for each branch, a two-bit saturating up-down counter which collects and subsequently bases its prediction on branch history information about that branch. Lee and A. Smith proposed <ref> [14] </ref> a Static Training method which uses statistics gathered prior to execution time coupled with the history pattern of the last k run-time executions of the branch to make the next prediction as to which way that branch will go. <p> Automata A3 and A4 are variations of A2. Both Static Training <ref> [14] </ref> and Two-Level Adaptive Branch Prediction are dynamic branch predictors, because their predictions are based on run-time information, i.e. the dynamic branch history.
Reference: [15] <author> T.R. Gross and J. Hennessy, </author> <title> "Optimizing Delayed Branches", </title> <booktitle> Proceedings of the 15th Annual Workshop on Microprogramming, </booktitle> <month> (Oct. </month> <year> 1982), </year> <month> pp.114-120. </month>
Reference: [16] <author> D.A. Patterson and C.H. Sequin, "RISC-I: </author> <title> A Reduced Instruction Set VLSI Computer", </title> <booktitle> Proceedings of the 8th International Symposium on Computer Architecture, </booktitle> <month> (May. </month> <year> 1981), </year> <month> pp.443-458. </month>
Reference: [17] <author> J.E. Smith, </author> <title> "A Study of Branch Prediction Strategies", </title> <booktitle> Proceedings of the 8th International Symposium on Computer Architecture, </booktitle> <month> (May. </month> <year> 1981), </year> <month> pp.135-148. </month>
Reference-contexts: The literature is full of suggested branch prediction schemes <ref> [6, 13, 14, 17] </ref>. Some are static in that they use opcode information and profiling statistics to make predictions. Others are dynamic in that they use run-time execution history to make predictions. <p> Static schemes can be as simple as always predicting that the branch will be taken, or can be based on the opcode, or on the direction of the branch, as in "if the branch is backward, predict taken, if forward, predict not taken" <ref> [17] </ref>. This latter scheme is effective for loop intensive code, but does not work well for programs where the branch behavior is irregular. <p> In all cases, the fact that the dynamic prediction is being made on the basis of run-time history information implies that substantial additional hardware is required. J. Smith <ref> [17] </ref> proposed utilizing a branch target buffer to store, for each branch, a two-bit saturating up-down counter which collects and subsequently bases its prediction on branch history information about that branch. Lee and A. <p> The automaton A2 is a saturating up-down counter, similar to the automaton used in J. Smith's branch target buffer design for keeping branch history <ref> [17] </ref>. 3/T 2/T T N T T Automaton A1 3/T 2/T T T N T T Automaton A2 (2-bit Saturating Up-down Counter) 3/T 2/T T T N T T Automaton A4 3/T 2/T T N N N T N Automaton A3 1/T T Automaton Last-Time (LT) N In J. <p> If a predictor does not have a certain feature in the naming convention, the corresponding field is left blank. Scheme specifies the scheme, for example, GAg, PAg, PAp or Branch Target Buffer design (BTB) <ref> [17] </ref>. In History ( Size, Associativity, Entry Content), History is the entity used to keep history information of branches, for example, HR (A single history register), IBHT, or BHT. <p> Note that their accuracy depends greatly on the similarities between the data sets used for training and testing. The prediction accuracy for the branch target buffer using 2-bit saturating up-down counters <ref> [17] </ref> is around 93 percent. The Profiling scheme achieves about 91 percent prediction accuracy. The branch target buffer using Last-Time achieves about 89 percent prediction accuracy. Most of the prediction accuracy curves of BTFN and Always Taken are below the base line (76 percent).
Reference: [18] <author> T. C. Chen, </author> <title> "Parallelism, Pipelining and Computer Efficiency", </title> <booktitle> Computer Design, </booktitle> <volume> Vol. 10, No. 1, </volume> <month> (Jan. </month> <year> 1971), </year> <month> pp.69-74. </month>
References-found: 18

