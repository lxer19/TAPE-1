URL: http://http.cs.berkeley.edu/~camillo/StereoDrive/stereo.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~camillo/StereoDrive/StereoDrive.html
Root-URL: 
Title: An integrated stereo-based approach to automatic vehicle guidance  
Author: J.Weber, D. Koller, Q.-T. Luong and J. Malik 
Note: This work is to be presented at the International Conference On Computer Vision, Boston, in June of 1995.  
Abstract: We propose a new approach for vision based longitudinal and lateral vehicle control. The novel feature of this approach is the use of binocular vision. We integrate two modules consisting of a new, domain-specific, efficient binocular stereo algorithm, and a lane marker detection algorithm, and show that the integration results in a improved performance for each of the modules. Longitudinal control is supported by detecting and measuring the distances to leading vehicles using binocular stereo. The knowledge of the camera geometry with respect to the locally planar road is used to map the images of the road plane in the two camera views into alignment. This allows us to separate image features into those lying in the road plane, e.g. lane markers, and those due to other objects which are dynamically integrated into an obstacle map. Therefore, in contrast with the previous work, we can cope with the difficulties arising from occlusion of lane markers by other vehicles. The detection and measurement of the lane markers provides us with the positional parameters and the road curvature which are needed for lateral vehicle control. Moreover, this information is also used to update the camera geometry with respect to the road, therefore allowing us to cope with the problem of vibrations and road inclination to obtain consistent results from binocular stereo. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O.D. Altan, H.K. Patnaik, and R.P. Roesser. </author> <title> Computer architecture and implementation of vision-based real-time lane sensing. </title> <booktitle> In Proc. of the Intelligent Vehicles '92 Symposium, </booktitle> <pages> pages 202-206, </pages> <year> 1992. </year>
Reference-contexts: A leading project is the LANELOK system developed at GM Research. Continuing work has resulted in a real-time implementation reported in <ref> [1] </ref>. The use of binocular stereopsis for vehicle control has been successfully demonstrated by JPL's planetary robotic vehicle [20] and Nissan's PVS vehicle [23]. Both systems realize a tradeoff between performance time and density of a depth map. <p> Therefore, in this coordinate system, a 2-D point [x; y] is associated to the optical ray <ref> [x; y; 1] </ref>. The intrinsic parameters matrix A allows us to obtain normalized coordinates from pixel coordinates, and vice-versa. They can be determined by camera calibration [30], and we will generally assume in the sequel of the paper that this is the case.
Reference: [2] <author> D. Aubert and C. Thorpe. </author> <title> Color image processing for navigation: two road trackers. </title> <type> Technical Report CMU-RI-TR-90-09, </type> <institution> Carnegie Mellon University, </institution> <year> 1990. </year>
Reference-contexts: For reasons of efficiency, this scheme has been slightly modified, in that the image window around the lane is warped (like in <ref> [2] </ref>) to align the expected orientation with the vertical, instead of using a rotated filter. This allows us to use a separable filter and therefore to avoid having to do 2D convolution. 20 The candidate positions are obtained as local maxima of the responses.
Reference: [3] <author> Peter N. Belhumeur. </author> <title> A baysian treatment of the stereo correspondence problem using half-occluded regions. </title> <booktitle> In Proc. International Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 506-511, </pages> <address> Champaign, Illinois, </address> <month> June 15-18, </month> <year> 1992. </year>
Reference-contexts: The process for obstacle detection is sketched in Fig. 5. 4 Temporal integration Computing depth from just a pair of images is known to be sensitive to noise. In addition, correctly dealing with occlusion at depth discontinuities may require a computationally expensive algorithm <ref> [3] </ref>. One can improve the accuracy of the depth estimation by exploiting the temporal integration of information with time using the expected dynamics of the scene. For the case of an autonomous vehicle, the input consists of two video signals providing 30 frames per second.
Reference: [4] <author> S. Carlsson and J.-O. Eklundh. </author> <title> Object detection using model based prediction and motion parallax. </title> <booktitle> In Proc. First European Conference on Computer Vision, </booktitle> <pages> pages 297-306. </pages> <address> Antibes, France, </address> <month> Apr. </month> <pages> 23-26, </pages> <year> 1990, </year> <editor> O. Faugeras (ed.), </editor> <booktitle> Lecture Notes in Computer Science 427, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, New York, </address> <year> 1990. </year>
Reference: [5] <author> S. Chandrashekar, A. Meygret, and M. Thonnat. </author> <title> Temporal analysis of stereo image sequences of traffic scenes. </title> <booktitle> In Proc. Vehicle Navigation and Information Systems Conference, </booktitle> <pages> pages 203-212, </pages> <year> 1991. </year>
Reference-contexts: A combination of stereo and optical flow is suggested in <ref> [5] </ref> in order to perform a temporal analysis of stereo image sequences of traffic scenes. They do not explicitly address the problem of obstacle detection in the context of vehicle guidance, but the general problem of object identification.
Reference: [6] <author> J. Crisman. </author> <title> Color Vision for the Detection of unstructured Roads and Intersection. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon-University, </institution> <year> 1990. </year>
Reference-contexts: The model can represent accurately straight lines, arc of circles, and the transitions between them. In spite of the small number of parameters, and of these simplifications, the model is more accurate than assuming just zero curvature <ref> [31, 6, 14] </ref> or parabolic sections [16]. In order to avoid unstabilities in the portions of low curvature, the sign of the curvature is constrained to be identical along the different segments.
Reference: [7] <author> D. DeMenthon and L.S. Davis. </author> <title> Reconstruction of a road by local image matches and global 3d optimiztion. </title> <booktitle> In Proc. International Conf. on Robotics and Automation, </booktitle> <pages> pages 1337-1342, </pages> <year> 1990. </year>
Reference-contexts: Right: the spurious feature points (purple) are removed using the residual disparity with respect to the ground plane 24 this geometry. Indeed, it has been reported <ref> [7] </ref> that a small difference in the assumed and actual camera tilt angle with respect to the ground affects the 3D reconstruction significantly.
Reference: [8] <editor> E.D. Dickmanns and B.D. Mysliwetz. </editor> <title> Recursive 3-d road and relative ego-state recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14 </volume> <pages> 199-213, </pages> <year> 1992. </year> <month> 33 </month>
Reference-contexts: These curvature estimates also provides desirable look-ahead information for a smooth ride in the car. 1.1 Related Research By far the most important and impressive work on a visually guided AVCS has been done in the group of Dickmanns (see <ref> [8] </ref> and the references cited therein). Their work resulted in a demonstration in 1987 of their 5-ton van, the VaMoRs running autonomously on a stretch of the Autobahn at speeds of up to 100 km/h. Vision was used to provide input for both lateral and longitudinal control on free roads. <p> In the coordinate system linked to the car, this is: * the difference in horizontal offset of the lane marker * the difference in orientation of the lane marker In addition to these parameters, we also take into account road curvature (like <ref> [8, 15] </ref>). Its allows us to improve the control strategies in the sense that predictions for control variables are available that provide a smooth and safe ride. <p> Its allows us to improve the control strategies in the sense that predictions for control variables are available that provide a smooth and safe ride. A model featuring these parameters has already been successfully used by Dickmanns and al <ref> [8] </ref>, but there is a substantial difference between our approach and his. Dickmanns approach relied heavily on an 5 integrated dynamic model with a large number of parameters including vehicle dynamics and implicit control laws. <p> The computation of the actual 3D points from the values of the model parameters is quite expensive, since curvature is a second-order quantity and therefore, two integral calculations would be required in the exact case. Even using the first-order approximation <ref> [8] </ref> is not fast enough, and thus to have a fast 21 access to the curve from its parameters we use a look-up-table which is precomputed.
Reference: [9] <author> W. Enkelmann. </author> <title> Obstacle detection by evaluation of optical flow fields from image sequences. </title> <booktitle> In Proc. First European Conference on Computer Vision, </booktitle> <pages> pages 134-138. </pages> <address> Antibes, France, </address> <month> Apr. </month> <pages> 23-26, </pages> <year> 1990, </year> <editor> O. Faugeras (ed.), </editor> <booktitle> Lecture Notes in Computer Science 427, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, New York, </address> <year> 1990. </year>
Reference: [10] <author> F. Ferrari, E. Grosso, G. Sandini, and M. Magrassi. </author> <title> A stereo vision system for real time obstacle avoidance in unknown environment. </title> <booktitle> In Proc. IROS, </booktitle> <pages> pages 703-708, </pages> <address> Tsuchiura, Japan, </address> <year> 1990. </year>
Reference-contexts: Please note that this does not assume at this stage any camera calibration, which was to be expected, since the identification of a plane is an operation which can be done in un-calibrated perspective images, a fact already exploited for obstacle detection by <ref> [10] </ref>.
Reference: [11] <author> D.A. Gordon. </author> <title> Perceptual basis of vehicular guidance. </title> <journal> Public Roads, </journal> <volume> 34(3) </volume> <pages> 53-68, </pages> <year> 1966. </year>
Reference-contexts: If the car is on a straight portion of the road or a a circular arc, the extend of lateral misalignment from the correct trajectory is indicated by the rate and extend of slewing and side-slipping of the lane markers <ref> [11] </ref>. One of the big advantages of this framework is that it enables us to formulate the problem of road following as one of nulling deviation from the steady state by using visual information that is easy to extract directly from the image (generalizing the approach of [25]).
Reference: [12] <author> H.v. </author> <title> Helmholtz. Treatise on Physiological Optics (translated by J.P.C. </title> <journal> Southall), </journal> <volume> volume 1-3. </volume> <publisher> Dover, </publisher> <address> NY, </address> <year> 1925. </year>
Reference-contexts: We have chosen this term to acknowledge the fact that this insight is due to Helmholtz <ref> [12] </ref> more than a hundred years ago. Helmholtz observed that objectively vertical lines in the left and the right view perceptually appear slightly rotated.
Reference: [13] <author> T.M. Jochem, D.A. Pomerleau, and C.E. Thorpe. Maniac: </author> <title> A next generation neurally based autonomous road follower. </title> <booktitle> In Image Understanding Workshop, </booktitle> <pages> pages 473-479, </pages> <address> Washington, DC, </address> <month> April 18-23, </month> <year> 1993, 1993. </year>
Reference: [14] <author> S.K. Kenue. Lanelok: </author> <title> Detection of lane boundaries and vehicle tracking using image-processing techniques: </title> <booktitle> Part i+ii. In SPIE Mobile Robots IV, </booktitle> <year> 1989. </year>
Reference-contexts: The model can represent accurately straight lines, arc of circles, and the transitions between them. In spite of the small number of parameters, and of these simplifications, the model is more accurate than assuming just zero curvature <ref> [31, 6, 14] </ref> or parabolic sections [16]. In order to avoid unstabilities in the portions of low curvature, the sign of the curvature is constrained to be identical along the different segments.
Reference: [15] <author> K. Kluge and C. Thorpe. </author> <title> Representation and recovery of road geometry in YARF. </title> <booktitle> In Proc. Intelligent Vehicles, </booktitle> <pages> pages 114-119, </pages> <address> Detroit, MI, </address> <year> 1992. </year>
Reference-contexts: In the coordinate system linked to the car, this is: * the difference in horizontal offset of the lane marker * the difference in orientation of the lane marker In addition to these parameters, we also take into account road curvature (like <ref> [8, 15] </ref>). Its allows us to improve the control strategies in the sense that predictions for control variables are available that provide a smooth and safe ride.
Reference: [16] <author> K. Kluge and C. Thorpe. </author> <title> Representation and recovery of road geometry in yarf. </title> <booktitle> In Proc. Intelligent vehicules symposium, </booktitle> <pages> pages 114-119, </pages> <year> 1992. </year>
Reference-contexts: The model can represent accurately straight lines, arc of circles, and the transitions between them. In spite of the small number of parameters, and of these simplifications, the model is more accurate than assuming just zero curvature [31, 6, 14] or parabolic sections <ref> [16] </ref>. In order to avoid unstabilities in the portions of low curvature, the sign of the curvature is constrained to be identical along the different segments.
Reference: [17] <author> D. Koller, Q.-T. Luong, and J. Malik. </author> <title> Binocular stereopsis and lane marker flow for vehicle navigation: lateral and longitudinal control. </title> <type> Technical Report UCB/CSD-94-804, </type> <institution> University of California at Berkeley, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: It is to be noted that for reasons of space, we are not able to give all the technical details (some of them are in <ref> [17] </ref>) and rather try to give a description which is sufficient for the reader to understand what we are doing.
Reference: [18] <author> Q.-T. Luong and O.D. Faugeras. </author> <title> Determining the Fundamental matrix with planes: unstability and new algorithms. </title> <booktitle> In Proc. Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 489-494, </pages> <address> New-York, </address> <year> 1993. </year> <month> 34 </month>
Reference-contexts: Therefore, we are able to identify points of the road plane in a precise and reliable way, in each camera. In the most general case, the correspondence of at least four different points is needed to compute the homography H 12 between the two images <ref> [18] </ref>. The homography can then be used to separate the obstacles from the ground plane.
Reference: [19] <author> H.A. Mallot, H.H. Bulthoff, J.J. Little, and S. Bohrer. </author> <title> Inverse perspective mapping simplifies optical flow computation and obstacle detection. </title> <journal> Biological cybernetics, </journal> <volume> 64(3) </volume> <pages> 177-185, </pages> <year> 1991. </year>
Reference-contexts: Then, any object above the ground plane will have non-zero disparity. This is very convenient because the human visual 9 system is most sensitive around the operating point of zero disparity. A related approach has been presented in <ref> [19] </ref>.
Reference: [20] <author> L. Matthies. </author> <title> Stereo vision for planetary rovers: Stochastic modeling to near real-time implementation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 8 </volume> <pages> 71-91, </pages> <year> 1992. </year>
Reference-contexts: A leading project is the LANELOK system developed at GM Research. Continuing work has resulted in a real-time implementation reported in [1]. The use of binocular stereopsis for vehicle control has been successfully demonstrated by JPL's planetary robotic vehicle <ref> [20] </ref> and Nissan's PVS vehicle [23]. Both systems realize a tradeoff between performance time and density of a depth map. For obstacle detection it is actually not necessary to compute a dense depth map neither is it necessary to perform the depth map computation at video rate.
Reference: [21] <author> A. Meygret and M. Thonnat. </author> <title> Object detection in road scenes usng stereo data. </title> <booktitle> In Pro-Art Workshop on Vision, </booktitle> <institution> Sophia Antipolis, </institution> <month> April 19-20, </month> <year> 1990. </year>
Reference: [22] <author> A. Meygret, M. Thonnat, and M. Berthod. </author> <title> A pyramidal stereovision algorithm based on contour chain points. </title> <booktitle> In Proc. Second European Conference on Computer Vision, </booktitle> <pages> pages 83-88, </pages> <address> S. Margherita, Ligure, Italy, </address> <month> May 18-23, </month> <year> 1992, </year> <editor> G. Sandini (ed.), </editor> <booktitle> Lecture Notes in Computer Science 588, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, Heidelberg, New York, </address> <year> 1992. </year>
Reference: [23] <author> M. Ohzora, T. Ozaki, S. Sasaki, M. Yoshida, and Y. Hiratsuka. </author> <title> Video-rate image processing system for an autonomous personal vehicle system. </title> <booktitle> In IAPR Workshop on Machine Vision Application, </booktitle> <pages> pages 389-392, </pages> <address> Tokyo, Japan, </address> <month> Nov. </month> <pages> 28-30, </pages> <year> 1990, 1990. </year>
Reference-contexts: A leading project is the LANELOK system developed at GM Research. Continuing work has resulted in a real-time implementation reported in [1]. The use of binocular stereopsis for vehicle control has been successfully demonstrated by JPL's planetary robotic vehicle [20] and Nissan's PVS vehicle <ref> [23] </ref>. Both systems realize a tradeoff between performance time and density of a depth map. For obstacle detection it is actually not necessary to compute a dense depth map neither is it necessary to perform the depth map computation at video rate.
Reference: [24] <author> D.A. Pomerleau. </author> <title> Progress in neural network-based vision for autonomous robot driving. </title> <booktitle> In Proc. of the Intelligent Vehicles '92 Symposium, </booktitle> <pages> pages 391-396, </pages> <year> 1992. </year>
Reference-contexts: Other examples of the numerous sites where research in this area is being conducted include the CMU NavLab project [28] which is the key university-based project on this theme. The currently favored lane following algorithm in the Navlab project seems to be the ALVINN system <ref> [24] </ref>. ALVINN is based on training a neural network with input a 30x32 low resolution image and output the desired steering command. The best performance cited is that of a 21.2 mile run at speeds of up to 55 miles per hour.
Reference: [25] <author> D. Raviv and M. Herman. </author> <title> A new approach to vision and control for road following. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 217-225, </pages> <address> Lahaina, Maui, Hawaii, </address> <month> June 3-6, </month> <year> 1991. </year>
Reference-contexts: A more recent project on road following in the US is a collaboration between NIST and Florida Atlantic University <ref> [25] </ref>. Lateral control is based on sensing the optical flow at a certain tangent point on the lane and steering so as to make it have no horizontal component. <p> One of the big advantages of this framework is that it enables us to formulate the problem of road following as one of nulling deviation from the steady state by using visual information that is easy to extract directly from the image (generalizing the approach of <ref> [25] </ref>). In the coordinate system linked to the car, this is: * the difference in horizontal offset of the lane marker * the difference in orientation of the lane marker In addition to these parameters, we also take into account road curvature (like [8, 15]).
Reference: [26] <author> Bill Ross. </author> <title> A practical stereo vision system. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 148-153, </pages> <address> Seattle, WA, </address> <month> June 21-23, </month> <year> 1993. </year>
Reference-contexts: Both systems realize a tradeoff between performance time and density of a depth map. For obstacle detection it is actually not necessary to compute a dense depth map neither is it necessary to perform the depth map computation at video rate. A trinocular stereo system is used by <ref> [26] </ref>, where the third camera actually serves as a mean to confirm and refine the results obtained from two cameras. Research closest related to our obstacle detection approach is described in [33].
Reference: [27] <author> M. Schwartzinger, T. Zielke, D. Noll, M. Brauckmann, </author> <title> and W.v. Seelen. Vision-based car-following: Detection, tracking, and identification. </title> <booktitle> In Proc. of the Intelligent Vehicles '92 Symposium, </booktitle> <pages> pages 24-29, </pages> <year> 1992. </year>
Reference-contexts: Vision was used to provide input for both lateral and longitudinal control on free roads. Further development of this work has been in collaboration with von Seelen's group in Bochum <ref> [27] </ref> and the Daimler Benz VITA project [32]. For collision avoidance with vehicles in one's lane, model-based techniques are used which exploit heuristics such as symmetry of the bounding box of the vehicle.
Reference: [28] <author> C. Thorpe, </author> <title> editor. Vision and Navigation: The Carnegie-Mellon Navlab. </title> <publisher> Kluwer Academic Pub--lishers, Norwell, </publisher> <address> Mass, </address> <year> 1990. </year>
Reference-contexts: It seems to us that these techniques are not as reliable and precise as those using binocular stereopsis. Other examples of the numerous sites where research in this area is being conducted include the CMU NavLab project <ref> [28] </ref> which is the key university-based project on this theme. The currently favored lane following algorithm in the Navlab project seems to be the ALVINN system [24]. ALVINN is based on training a neural network with input a 30x32 low resolution image and output the desired steering command.
Reference: [29] <author> Roger Tsai and Thomas S. Huang. </author> <title> Estimating Three-dimensional motion parameters of a rigid planar patch, II: singular value decomposition. </title> <journal> IEEE Transactions on Acoustic, Speech and Signal Processing, </journal> <volume> 30, </volume> <year> 1982. </year>
Reference-contexts: Moreover, the knowledge of the intrinsic parameters allows one to decompose the homography matrix according to (3) and to get the relative position and orientation of the two cameras, as well as the position of the plane with respect to the cameras <ref> [29] </ref>. From these parameters, the homographies between the images and the ground plane H 1 and H 2 can be obtained. In the situations where the Helmholtz shear applies, the calculations are more simple, and this is what we describe next.
Reference: [30] <author> R.Y. Tsai. </author> <title> Synopsis of Recent Progress on Camera Calibration for 3D Machine Vision. </title> <editor> In Oussama Khatib, John J. Craig, and Tomas Lozano-Perez, editors, </editor> <booktitle> The Robotics Review, </booktitle> <pages> pages 147-159. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: Therefore, in this coordinate system, a 2-D point [x; y] is associated to the optical ray [x; y; 1]. The intrinsic parameters matrix A allows us to obtain normalized coordinates from pixel coordinates, and vice-versa. They can be determined by camera calibration <ref> [30] </ref>, and we will generally assume in the sequel of the paper that this is the case.
Reference: [31] <author> M.A. Turk, D.G. Morgenthaler, K.D. Gremban, and M. Marra. </author> <title> Vits | a vision system for autonomous land vehicle navigation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 10 </volume> <pages> 342-361, </pages> <year> 1988. </year>
Reference-contexts: The model can represent accurately straight lines, arc of circles, and the transitions between them. In spite of the small number of parameters, and of these simplifications, the model is more accurate than assuming just zero curvature <ref> [31, 6, 14] </ref> or parabolic sections [16]. In order to avoid unstabilities in the portions of low curvature, the sign of the curvature is constrained to be identical along the different segments.
Reference: [32] <author> B. Ullmer. </author> <title> Vita an autonomous road vehicle (arv) for collision avoidance in traffic. </title> <booktitle> In Proc. of the Intelligent Vehicles '92 Symposium, </booktitle> <pages> pages 36-41, </pages> <year> 1992. </year>
Reference-contexts: Vision was used to provide input for both lateral and longitudinal control on free roads. Further development of this work has been in collaboration with von Seelen's group in Bochum [27] and the Daimler Benz VITA project <ref> [32] </ref>. For collision avoidance with vehicles in one's lane, model-based techniques are used which exploit heuristics such as symmetry of the bounding box of the vehicle. It seems to us that these techniques are not as reliable and precise as those using binocular stereopsis.
Reference: [33] <author> Y. Zheng, D.G. Jones, S.A. Billings, J.E. W. Mayhew, and J.P. Frisby. Switcher: </author> <title> a stereo algorithm for ground plane obstacle detection. </title> <journal> Image and Vision Computing, </journal> <volume> 8 </volume> <pages> 57-62, </pages> <year> 1990. </year> <month> 36 </month>
Reference-contexts: A trinocular stereo system is used by [26], where the third camera actually serves as a mean to confirm and refine the results obtained from two cameras. Research closest related to our obstacle detection approach is described in <ref> [33] </ref>. They perform first a rectification of the stereo images to achieve zero vertical disparity, before they estimate the disparity by comparing the variances of the difference in a window of the rectified left and right image.
References-found: 33

