URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tr.outbox/MIT-LCS-TR-649.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/tr600.html
Root-URL: 
Title: QuickStep: A System for Performance Monitoring and Debugging Parallel Applications on the Alewife Multiprocessor  
Author: by Sramana Mitra Anant Agarwal 
Degree: Submitted to the DEPARTMENT OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCE in partial fulfillment of the requirements for the degree of MASTER OF SCIENCE at the  All rights reserved Signature of Author:  Certified by:  Associate Professor of Computer Science and Engineering Thesis Supervisor Accepted by: Frederic. R. Morgenthaler Chairman, EECS Committee on Graduate Students  
Note: c 1995,  
Date: 1993  February 1995  November 28, 1994  
Address: Smith College,  
Affiliation: A.B., Computer Science and Economics  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  Massachusetts Institute of Technology  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Anant Agarwal et. al. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprcoessor. </title> <booktitle> Proceedings of Workshop on Scalable Shared Memory Multiprocessors, </booktitle> <year> 1991. </year>
Reference-contexts: Consequently, there is the need for tools to assist in performance debugging. The Alewife machine is a large-scale multiprocessor with distributed shared memory built at the MIT Laboratory for Computer Science <ref> [1] </ref>. Alewife consists of a group of processing nodes connected by a two-dimensional mesh interconnection network. <p> A synthetic benchmark program to test cache hit-miss statistics; verifiers for cached reads and overall data cache hit-ratio statistics. */ #include &lt;primops.h&gt; #include &lt;stdio.h&gt; #include &lt;parallel.h&gt; int num = 9; void proc1 (); void clear_counters (); main (int argc, char *argv []) - int missprob, loopbound; missprob = atoi (argv <ref> [1] </ref>); loopbound = atoi (argv [2]); do_in_parallel (proc1, missprob, loopbound); - void proc1 (int miss_prob, int loopbound) - int k, l; k = (int)((float)miss_prob*0.01*(float)loopbound+0.5); l = (loopbound-k); /* Counters are cleared so that the data can be obtained for this section of the code only. */ clear_counters (); 64 for (i <p> &lt;stdio.h&gt; #include &lt;parallel.h&gt; int num = 9; void proc1 (); /* struct for dynamic allocation */ typedef struct dummy - unsigned d1; unsigned d2; unsigned d3; unsigned d4; unsigned d5; DUMMY; typedef DUMMY *DUMMY_PTR; main (int argc, char *argv []) - int missprob, loopbound; DUMMY_PTR temp; missprob = atoi (argv <ref> [1] </ref>); loopbound = atoi (argv [2]); temp = (DUMMY *)shmalloc (sizeof (DUMMY)); temp-&gt;d1 = 1; temp-&gt;d2 = 2; temp-&gt;d3 = 3; temp-&gt;d4 = 4; temp-&gt;d5 = 5; do_in_parallel (proc1, temp, missprob, loopbound); - void proc1 (DUMMY_PTR tmp, int missprob, int loopbound) - int k, l; k = (int)((float)missprob*0.01*(float)loopbound+0.5); l = (loopbound-k); <p> #include &lt;parallel.h&gt; int num = 9; void proc1 (); /* struct for dynamic allocation */ typedef struct dummy - unsigned d1; unsigned d2; unsigned d3; unsigned d4; unsigned d5; DUMMY; typedef DUMMY *DUMMY_PTR; main (int argc, char *argv []) - int missprob, loopbound; DUMMY_PTR temp; 67 missprob = atoi (argv <ref> [1] </ref>); loopbound = atoi (argv [2]); temp = (DUMMY *)shmalloc (sizeof (DUMMY)); temp-&gt;d1 = 1; temp-&gt;d2 = 2; temp-&gt;d3 = 3; temp-&gt;d4 = 4; temp-&gt;d5 = 5; do_in_parallel (proc1, temp, missprob, loopbound); - void proc1 (DUMMY_PTR tmp, int missprob, int loopbound) - int k, l; k = (int)((float)missprob*0.01*(float)loopbound+0.5); l = (loopbound-k);
Reference: [2] <author> Ziya Aral and Ilya Gertner. </author> <title> High-Level Debugging in Parasight. In Parallel and distributed debugging. </title> <booktitle> Proceedings of the ACM SIGPLAN/SIGACT workshop, </booktitle> <month> May 5-6, </month> <year> 1988, </year> <institution> Madison, Wisconsin, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: The execution times are propagated along the edges of this graph to attribute times for routines to the routines that invoke them. In the parallel world, a debugger called Parasight was developed at Encore Computer Corporation <ref> [2] </ref>. Parasight implements high-level debugging facilities as separate programs that are linked dynamically to a target program. Parasight was implemented on Multimax, a shared memory multiprocessor. <p> test cache hit-miss statistics; verifiers for cached reads and overall data cache hit-ratio statistics. */ #include &lt;primops.h&gt; #include &lt;stdio.h&gt; #include &lt;parallel.h&gt; int num = 9; void proc1 (); void clear_counters (); main (int argc, char *argv []) - int missprob, loopbound; missprob = atoi (argv [1]); loopbound = atoi (argv <ref> [2] </ref>); do_in_parallel (proc1, missprob, loopbound); - void proc1 (int miss_prob, int loopbound) - int k, l; k = (int)((float)miss_prob*0.01*(float)loopbound+0.5); l = (loopbound-k); /* Counters are cleared so that the data can be obtained for this section of the code only. */ clear_counters (); 64 for (i = 0; i &lt; k; <p> = 9; void proc1 (); /* struct for dynamic allocation */ typedef struct dummy - unsigned d1; unsigned d2; unsigned d3; unsigned d4; unsigned d5; DUMMY; typedef DUMMY *DUMMY_PTR; main (int argc, char *argv []) - int missprob, loopbound; DUMMY_PTR temp; missprob = atoi (argv [1]); loopbound = atoi (argv <ref> [2] </ref>); temp = (DUMMY *)shmalloc (sizeof (DUMMY)); temp-&gt;d1 = 1; temp-&gt;d2 = 2; temp-&gt;d3 = 3; temp-&gt;d4 = 4; temp-&gt;d5 = 5; do_in_parallel (proc1, temp, missprob, loopbound); - void proc1 (DUMMY_PTR tmp, int missprob, int loopbound) - int k, l; k = (int)((float)missprob*0.01*(float)loopbound+0.5); l = (loopbound-k); 66 for (i = 0; <p> 9; void proc1 (); /* struct for dynamic allocation */ typedef struct dummy - unsigned d1; unsigned d2; unsigned d3; unsigned d4; unsigned d5; DUMMY; typedef DUMMY *DUMMY_PTR; main (int argc, char *argv []) - int missprob, loopbound; DUMMY_PTR temp; 67 missprob = atoi (argv [1]); loopbound = atoi (argv <ref> [2] </ref>); temp = (DUMMY *)shmalloc (sizeof (DUMMY)); temp-&gt;d1 = 1; temp-&gt;d2 = 2; temp-&gt;d3 = 3; temp-&gt;d4 = 4; temp-&gt;d5 = 5; do_in_parallel (proc1, temp, missprob, loopbound); - void proc1 (DUMMY_PTR tmp, int missprob, int loopbound) - int k, l; k = (int)((float)missprob*0.01*(float)loopbound+0.5); l = (loopbound-k); for (i = 0; i
Reference: [3] <author> Ricardo Bianchini. </author> <title> Alewife Systems Memo #43. Application Performance on the Alewife Multiprocessor, </title> <month> September </month> <year> 1994. </year>
Reference-contexts: The main goal of the system is to aid in identifying performance bottlenecks and tuning programs to reduce the effect of such bottlenecks. Furthermore, it can also be used to analyze effects of optimization of application code. We use MP3D and SOR two large parallel applications <ref> [3] </ref> to demonstrate appilcations of Quickstep. 5.1 Case Study 1: MP3D 5.1.1 Description In this chapter, we use MP3D an application from the SPLASH suite to demonstrate how QuickStep provides useful insight into program behavior as a result of optimization.
Reference: [4] <author> B. Bliss, M. C. Brunet and E. Gallopoulos. </author> <title> Automatic Parallel Program Instrumentation with Applications in Performance and Error Analysis. </title> <institution> University of Illinois Technical Report No. CSRD-1025, </institution> <month> June </month> <year> 1990. </year>
Reference: [5] <author> Eric A. Brewer and Chrysanthos N. Dellarocas. </author> <title> Proteus User Documentation. </title>
Reference-contexts: At the end of the run, they are output into a raw data file in a simple column format. A sample data file is given in Figure 3.9. The raw file is then processed to generate a binary file that is in the Proteus <ref> [5] </ref> trace file format, that can be viewed with a graphical interface supported by the Proteus Stats program. Chapter 2 shows examples of graphs obtained as outputs of the QuickStep system. The column headings from the raw data file are used to generate headings and menus for the graphs.
Reference: [6] <author> Helmar Burkhart and Roland Millen. </author> <title> Performance-Measurement Tools in a Multiprocessor Environment. </title> <journal> In IEEE Transactions on Computers, </journal> <volume> Vol. 38, No. 5, </volume> <month> May </month> <year> 1989. </year>
Reference-contexts: The principal metric in Quartz is normalized processor time: the total processor time spent in each section of the code divided by the number of other processors that are concurrently busy when that section of code is being executed. Other related works can be found in <ref> [6] </ref>, [7], [8] and [20]. A tool called Memspy is described in [18] that offers the additional feature of extremely detailed information to identify and fix memory bottlenecks. Memspy isolates causes of cache misses like cold 12 start misses, interference misses, etc. which is very useful.
Reference: [7] <author> Jack Dongarra, Orlie Brewer, James Arthur Kohl and Samuel Fineberg. </author> <title> Tools to Aid in the Design, Implementation, and Understanding of Matrix Algorithms for Parallel Processors. </title> <journal> In Journal for Parallel and Distributed Computing, </journal> <volume> 9, </volume> <pages> pp 185-202, </pages> <year> 1990. </year>
Reference-contexts: The principal metric in Quartz is normalized processor time: the total processor time spent in each section of the code divided by the number of other processors that are concurrently busy when that section of code is being executed. Other related works can be found in [6], <ref> [7] </ref>, [8] and [20]. A tool called Memspy is described in [18] that offers the additional feature of extremely detailed information to identify and fix memory bottlenecks. Memspy isolates causes of cache misses like cold 12 start misses, interference misses, etc. which is very useful.
Reference: [8] <author> Raymond R. Glenn and Daniel V. Pryor. </author> <title> Instrumentation for a Massively Parallel MIMD Application. </title> <journal> In Journal of Parallel and Distributed Computing, </journal> <volume> 12, </volume> <pages> pp 223-236, </pages> <year> 1991. </year>
Reference-contexts: The principal metric in Quartz is normalized processor time: the total processor time spent in each section of the code divided by the number of other processors that are concurrently busy when that section of code is being executed. Other related works can be found in [6], [7], <ref> [8] </ref> and [20]. A tool called Memspy is described in [18] that offers the additional feature of extremely detailed information to identify and fix memory bottlenecks. Memspy isolates causes of cache misses like cold 12 start misses, interference misses, etc. which is very useful.
Reference: [9] <author> Aaron J. Goldberg. </author> <title> Reducing Overhead in Counter-Based Execution Profiling. </title> <type> Stan-ford Technical Report No. </type> <institution> CSL-TR-91-495, </institution> <month> October </month> <year> 1991. </year>
Reference: [10] <author> Aaron J. Goldberg. </author> <title> Multiprocessor Peformance Debugging and Memory Bottlenecks. </title> <type> Stanford Technical Report No. </type> <institution> CSL-TR-92-542, </institution> <month> August </month> <year> 1992. </year> <month> 77 </month>
Reference-contexts: QuickStep utilizes these features to provide a performance monitoring and debugging platform. 9 10 1.1 Performance Monitoring and Debugging Methods: Back- ground Several efforts have been directed at identifying performance bottlenecks in parallel programs. The popular techniques are Static Analysis, Simulation, Emulation, Hardware Instrumentation and Software Instrumentation <ref> [10] </ref>. 1.1.1 Static Analysis Static analysis although fast, has limited applicability. The most extensive research in static analysis was done at the University of Illinois as a part of the Cedar multiprocessor project [16].
Reference: [11] <author> Aaron J. Goldberg and John Hennessy. </author> <title> Mtool: An Integrated System for Peformance Debugging Shared Memory Multiprocessor Applications. </title> <journal> In IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4:1, </volume> <pages> pp 28-40, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Memspy isolates causes of cache misses like cold 12 start misses, interference misses, etc. which is very useful. Mtool is a software tool for analyzing performance loss by isolating memory and synchronization overheads <ref> [11] </ref>. Mtool provides a platform for scanning where a parallel program spends its execution time. The taxonomy includes four categories: Compute Time, Synchronization Overhead, Memory Hierarchy Losses, and Extra Work in Parallel Program (versus Sequential).
Reference: [12] <author> S. Graham, P. Kessler and M. McKusick. </author> <title> Gprof: A call graph execution profiler. </title> <booktitle> In Proceedings of the ACM/SIGPLAN Symposium of Compiler Construction, </booktitle> <pages> pp 120-126, </pages> <year> 1982. </year>
Reference-contexts: Software instrumentation, however, introduces inaccuracies due to their intrusive nature. One of the earliest attempts at performance debugging in the sequential domain was gprof an execution profiler that outputs data concerning execution timings in different routines <ref> [12] </ref>. Gprof monitors the number of times each profiled routine is called (Call Count) and the time spent in each profiled routine. The arcs of a dynamic call graph traversed by an execution of the program are also monitored and the call graph is built by post processing this data.
Reference: [13] <author> John Kubiatowicz, David Chaiken and Anant Agarwal. </author> <title> Closing the Window of Vulnerability in Multiphase Memory Transactions. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS V), </booktitle> <pages> pp 274-284, </pages> <month> October </month> <year> 1992. </year>
Reference: [14] <author> John Kubiatowicz. </author> <title> Alewife Systems Memo #19. Users Manual for the Alewife 1000 Controller, </title> <month> November </month> <year> 1991. </year>
Reference: [15] <author> John Kubiatowicz and Anant Agarwal. </author> <title> Anatomy of a Message in the Alewife Multiprocessor. </title> <booktitle> In Proceedings of the International Supercomputing Conference (ISC) 1993, </booktitle> <address> Tokyo, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: The code for instrumenting the statistics gathering facility is included as a part of the Alewife kernel and the statistics monitoring mode is activated by adding features to the host interface. The Alewife kernel supports a message-passing interface <ref> [15] </ref> which is used to communicate between the host and the machine. Alewife also supports a timer interrupt facility which is used to interrupt processors at specified times to collect statistics for a certain interval.
Reference: [16] <author> A. Kwok and W. Abu-Sufah. Tcedar: </author> <title> A performance evaluation tool for cedar. </title> <type> Technical Report CSRD 84, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1984. </year>
Reference-contexts: The popular techniques are Static Analysis, Simulation, Emulation, Hardware Instrumentation and Software Instrumentation [10]. 1.1.1 Static Analysis Static analysis although fast, has limited applicability. The most extensive research in static analysis was done at the University of Illinois as a part of the Cedar multiprocessor project <ref> [16] </ref>. Static analysis involves predicting the performance of loops, counts of local and global memory references, estimates of MFLOPS, etc. based on simple models of instruction latencies and memory hierarchies. The Illinois project later went on to use more sophisticated techniques like exploiting compiler dependency analysis in the predictive models.
Reference: [17] <author> Daniel Lenoski et. al. </author> <title> The Stanford Dash Multiprocessor. </title> <booktitle> In IEEE Computer, </booktitle> <pages> pp 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Therefore, simulation is hardly an effective tool for performance debugging. It is used more for detailed analysis of architectural tradeoffs and is important because it allows evaluation without real hardware. Simulation has been used extensively in the Stanford DASH <ref> [17] </ref> project, as well as in Alewife during the architectural design phase. 1.1.3 Emulation Emulation is a method of hardware system debugging that is becoming increasingly popular.
Reference: [18] <author> Margaret Martonosi and Anoop Gupta. MemSpy: </author> <title> Analyzing Memory System Bottlenecks in Programs. In Performance Evaluation Review, </title> <booktitle> 20:1, </booktitle> <pages> pp 1-12, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Other related works can be found in [6], [7], [8] and [20]. A tool called Memspy is described in <ref> [18] </ref> that offers the additional feature of extremely detailed information to identify and fix memory bottlenecks. Memspy isolates causes of cache misses like cold 12 start misses, interference misses, etc. which is very useful. Mtool is a software tool for analyzing performance loss by isolating memory and synchronization overheads [11].
Reference: [19] <author> Barton P. Miller et. al.. IPS-2: </author> <title> The Second Generation of a Parallel Program Measurement System. </title> <journal> In IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 1, No. 2, </volume> <month> April </month> <year> 1990. </year>
Reference-contexts: Parasight was implemented on Multimax, a shared memory multiprocessor. IPS is a performance measurement system for parallel and distributed programs that uses knowledge about the semantics of a program's structure to provide a large amount of easily accessible performance data and analysis techniques that guide programmers to performance bottlenecks <ref> [19] </ref>. IPS is based on the software instrumentation technique. Quartz is another tool for tuning parallel program performance on shared memory multiprocessors.
Reference: [20] <author> Zary Segall and Larry Rudolph. PIE: </author> <title> A Programming and Intrumentation Environment for Parallel Processing. </title> <booktitle> In IEEE Software, </booktitle> <pages> pp 22-37, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: Other related works can be found in [6], [7], [8] and <ref> [20] </ref>. A tool called Memspy is described in [18] that offers the additional feature of extremely detailed information to identify and fix memory bottlenecks. Memspy isolates causes of cache misses like cold 12 start misses, interference misses, etc. which is very useful.
Reference: [21] <author> J. P. Singh, W. D. Weber, and A. Gupta. </author> <title> SPLASH: Stanford Parallel Applications for Shared-Memory. </title> <journal> Computer Architecture News, </journal> <volume> 20(1) </volume> <pages> 5-44, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The tunnel is represented as a 3D space array of unit-sized cells. Particles move through the space array and can only collide with particles occupying the same cell in the same time step. A complete description of this program can be found in <ref> [21] </ref>. Ricardo Bianchini has done a study on the performance of large parallel applications on Alewife. Ricardo's study includes experimentation with multiple implementations of Mp3d. In this chapter, we have used three different implementations of Mp3d and run each on a 16-node Alewife machine, with 18000 particles for 6 iterations.
Reference: [22] <author> SPARC Architecture Manual. </author> <year> 1988. </year> <institution> SUN Microsystems, Mountain View, California. </institution>
Reference: [23] <author> Stephen Walters. </author> <title> Computer-Aided Prototyping for ASIC-Based Systems. </title> <booktitle> IEEE Design and Test of Computers, </booktitle> <year> 1991. </year>
Reference-contexts: Field-programmable gate arrays have made possible an implementation technology that is ideal for full system prototyping, yet does not require the construction of actual silicon chips <ref> [23] </ref>. Emulation, also called Computer Aided Prototyping, combines CAE translation 11 and synthesis software with FPGA technology to automatically produce hardware proto-types of chip designs from netlists.
Reference: [24] <author> Benson Wen. Foghorn: </author> <title> Parallel Performance Statistics on Alewife. </title> <type> Bachelor's Thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1993. </year> <month> 78 </month>
References-found: 24

