URL: ftp://ftp.cs.yale.edu/pub/hager/papers/mob_manip_long.ps.gz
Refering-URL: http://www.cs.yale.edu/users/hager/papers.html
Root-URL: http://www.cs.yale.edu
Email: email: wendelin.feiten@mchp.siemens.de, hager-greg@cs.yale.edu  
Title: Modeling and Control for Mobile Manipulation in Everyday Environments  
Author: Wendelin Feiten Bjorn Magnussen Jochen Bauer Gregory D. Hager Kentaro Toyama 
Affiliation: Siemens AG  Department of Computer Science Yale University  
Abstract: In this article, we describe our first efforts toward building a system capable of both mobility and manipulation. In particular, we outline the system hardware and software architecture, paying particular attention to our use of specialized vision processing and visual servoing techniques for manipulation. We include a set of preliminary experiments showing the feasibility of the approach on the problem of opening a door. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agre, P. E. and D. </author> <title> Chapman (1987). Pengi: An implementation of a theory of activity. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 268-272. </pages>
Reference-contexts: The system state model is maintained continual sensor monitoring and inference, similar in concept to that proposed by Agre <ref> (Agre and Chapman 1987) </ref>. In particular, in the case of vision, visual tracking is used heavily. Achieving in the target state is what drives the system. At each time point, the system compares the current and target states and computes mismatches.
Reference: <author> Feiten, W., R. Bauer, and G. </author> <month> Lawitzky </month> <year> (1994). </year> <title> Robust obstacle avoidance in unknown and cramped environments. </title> <booktitle> In Proceedings of the ICRA '94, </booktitle> <pages> pp. 2412-2417. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference: <author> Hager, G. D. </author> <year> (1997). </year> <title> A modular system for robust hand-eye coordination. </title> <journal> IEEE Trans. Rob. Automat.. </journal>
Reference: <author> Hager, G. D. and K. </author> <title> Toyama (1995). The "X-vision" system: A general purpose substrate for real-time vision applications. </title> <institution> DCS RR-1078, Yale University. </institution> <note> To Appear in Comp. </note> <editor> Vis. </editor> <booktitle> Image Understanding. </booktitle>
Reference: <author> Hager, G. D. and K. </author> <title> Toyama (1996). XVision: Combining image warping and geometric constraints for fast visual tracking. </title> <booktitle> In Computer Vision-ECCV'96, </booktitle> <pages> pp. 507-517. </pages> <publisher> Springer Ver-lag. </publisher> <month> Helpmate </month> <year> (1997). </year> <note> HelpMate Presentation, </note> <institution> Yale University. </institution>
Reference-contexts: The methods we use for visual search are an outgrowth of previous work at Yale on Incremental Focus of Attention (henceforth IFA), a framework for robust motion tracking systems <ref> (Toyama and Hager 1996) </ref>. Conceptually, IFA layers different tracking algorithms and heuristics into a control hierarchy which focuses the "attention" of the system onto relevant subregions of the image. The result is an effective method of target re-acquisition which also operates on commodity computing hardware.
Reference: <author> Horswill, I. </author> <year> (1993). </year> <title> Specialization of Perceptual Processes. </title> <publisher> Ph.d.thesis, MIT. </publisher>
Reference-contexts: Although a general "door handle finder" is impossible with today's understanding of cognitive processes, one can use environmental constraints as positive design criteria for a specialized door handle finder <ref> (Horswill 1993) </ref>.
Reference: <author> Rencken, W. D. </author> <year> (1993). </year> <title> Concurrent localization and map building for mobile robots using ul-trasonicsensors. </title> <booktitle> In Proceedings of the IROS '93, </booktitle> <pages> pp. 2192-2197. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference: <author> Rencken, W. D. </author> <year> (1994). </year> <title> Autonomous sonar navigation in indoor, unknown and unstructured environments. </title> <booktitle> In Proceedings of the IROS '94, </booktitle> <pages> pp. 431-438. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference: <author> Toyama, K. and G. D. </author> <title> Hager (1996). Incremental focus of attention for robust visual tracking. </title> <booktitle> In CVPR '96, </booktitle> <pages> pp. 189-195. </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: The methods we use for visual search are an outgrowth of previous work at Yale on Incremental Focus of Attention (henceforth IFA), a framework for robust motion tracking systems <ref> (Toyama and Hager 1996) </ref>. Conceptually, IFA layers different tracking algorithms and heuristics into a control hierarchy which focuses the "attention" of the system onto relevant subregions of the image. The result is an effective method of target re-acquisition which also operates on commodity computing hardware.
Reference: <author> Wienkop, U., G. Lawitzky, and W. </author> <month> Feiten </month> <year> (1994). </year> <title> Intelligent low-cost mobility. </title> <booktitle> In Proceedings of the IROS '94, </booktitle> <pages> pp. 1708-1715. </pages> <publisher> IEEE Computer Society Press. </publisher>
References-found: 10

