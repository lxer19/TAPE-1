URL: http://www.cs.unc.edu/~scher/define.ps
Refering-URL: http://www.cs.unc.edu/~scher/frameless.html
Root-URL: http://www.cs.unc.edu
Email: scher@cs.unc.edu  
Title: Defining and Refining Frameless Rendering  
Author: Ellen J. Scher Zagier 
Keyword: CR Categories and Subject Descriptors: I.3.3 [Computer Graphics]: Picture/Image Generation Pixel-level Rendering; I.3.5 [Computer Graphics]: Frameless Rendering.  Additional Key Words and Phrases: reduced latency, virtual environments, progressive refinement, frameless rendering, motion blur, temporal frequency, visual perception.  
Address: Hill, NC 27599-3175.  
Affiliation: Department of Computer Science, University of North Carolina, Chapel  
Abstract: Frameless Rendering (FR) is a rendering paradigm which performs stochastic temporal filtering by updating pixels in a random order, based on most recent available input data, and displaying them to the screen immediately [3]. It has inherent in its design, visual artifacts that come across as spatial scatter. Due to the asyn-chronicity of pixel updates, a noisy or scattered image is perceived if the update rate is not fast enough. We describe the factors that influence the perceptual quality when Frameless Rendering is implemented such as object and viewpoint velocities, pattern and object size, and pattern and object separation. The factors are formalized mathematically with respect to their impact on spatial scatter. Spatial scatter is defined formally as a combination of velocity, density and gradient. We also attempt to define Frameless Rendering in terms of a new graphics pipeline, and more concretely in terms of strategies for pixel prioritization and handling aging pixels. We zoom in on three factors that influence the perceptual quality. We compare scenes with strong versus weak temporal coherence, high versus low frequency content, and high versus low pixel computation rates. If strong temporal coherence is maintained, a Frameless Rendering sequence exhibits little image degradation. Cutaway scenes have no coherence between two successive frames and offer a a natural dissolve. Weak temporal coherence is associated with decreased image fidelity. Image sequences comprised of scenes with primarily low frequency content exhibit very little image degradation when compared to image sequences comprised of scenes with high frequencies. Computation speeds of 30 M pixels=second, sampling inputs at 100 Hz, give the smoothness of motion and visual fidelity of a traditional 30 fps double-buffered animation. (See Section 7 for an anomalous case.) Compute speeds of 1 to 4 M pixels=second reduce latency and smooth motion seen in a comparable double-buffered animation. We also show comparisons of Frameless Rendering with reduced pixel resolution. In cases of strong temporal coherence, Frameless Rendering exhibits relatively little image degradation in comparison with the reduced pixel resolution alternative. On the other hand, in cases of relatively weak temporal coherence, the low resolution image sequence exhibits relatively little image degradation when compared with the Frameless Rendering. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Albert J. Ahumada, Jr. and Cynthia H. </author> <title> Null. Image quality: A multidimensional problem. In A.B. </title> <editor> Watson, editor, </editor> <booktitle> Digital Images and Human Vision, </booktitle> <pages> pages 141-148, </pages> <year> 1993. </year>
Reference-contexts: This information can then be used to steer Frameless Rendering usage accordingly. There have also been salient analyses of how to measure image quality. A particularly robust scheme is preference factoring <ref> [1] </ref>. By using observer preferences, they assign weights to the different physical characteristics pertinent to image quality. The visible differences predictor [10] is a more formal algorithmic approach to preference factoring. It considers physical differences mathematically and correlates them to visible differences. <p> Good latency-reduction techniques, such as hardware address recalculation [33], handle isolated head rotations. Use Preference Factoring and the Visible Differences Predictor to steer Essential Frameless Rendering: Preference factoring <ref> [1] </ref> organizes the multidimensional human visual problem space by using observer preferences and assign weights to the different physical characteristics. The visible differences predictor [10] considers physical differences mathematically and correlates it to visible 12 differences.
Reference: [2] <author> Larry Bergman, Henry Fuchs, Eric Grant, and Susan Spach. </author> <title> Image rendering by adaptive refinement. </title> <booktitle> In Computer Graphics: Proceedings of SIGGRAPH'86, </booktitle> <volume> volume 20, No. 4, </volume> <pages> pages 29-37. </pages> <publisher> ACM SIGGRAPH, </publisher> <year> 1986. </year>
Reference-contexts: This technique requires discretization as motion slows and as the image converges to a fully rendered one. They also exploit spatial coherence, which although it produces immediate benefits, deviates from maintaining the Golden Thread <ref> [2, 3] </ref>, one of the goals of Frameless Rendering (see 5.1 for further information). <p> We use this idea throughout our exposition of Frameless Rendering. 5.1 Progressive Refinement Technique Frameless Rendering, in its bare bones form [3], limits image degradation while maintaining the Golden Thread <ref> [2, 3] </ref>. A goal of Frameless Rendering is to maintain this golden thread concept. That is, any implementation step or set of steps, when repeated, should allow images to smoothly and continuously converge to an ideal image.
Reference: [3] <author> Gary Bishop, Henry Fuchs, Leonard McMillan, and Ellen J. Scher Zagier. </author> <title> Frameless rendering: Double buffering considered harmful. </title> <booktitle> In Computer Graphics (SIGGRAPH '94 Proceedings), </booktitle> <pages> pages 175-176, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: And, Frameless Rendering as a calculation avoidance technique, has some nice natural properties such as: preserving topology and maintaining the integrity of diffuse, as well as specular, lighting effects. 3 Previous Frameless Results 3.1 Frameless Rendering Simulations Researchers at UNC Chapel Hill have illustrated that the utilization of Frameless Rendering <ref> [3] </ref> can offer a more fluid animation than traditional double buffering. This translates to quicker response time in interactive applications, with only a slight degradation of image quality. <p> This technique requires discretization as motion slows and as the image converges to a fully rendered one. They also exploit spatial coherence, which although it produces immediate benefits, deviates from maintaining the Golden Thread <ref> [2, 3] </ref>, one of the goals of Frameless Rendering (see 5.1 for further information). <p> We use this idea throughout our exposition of Frameless Rendering. 5.1 Progressive Refinement Technique Frameless Rendering, in its bare bones form <ref> [3] </ref>, limits image degradation while maintaining the Golden Thread [2, 3]. A goal of Frameless Rendering is to maintain this golden thread concept. That is, any implementation step or set of steps, when repeated, should allow images to smoothly and continuously converge to an ideal image. <p> We use this idea throughout our exposition of Frameless Rendering. 5.1 Progressive Refinement Technique Frameless Rendering, in its bare bones form [3], limits image degradation while maintaining the Golden Thread <ref> [2, 3] </ref>. A goal of Frameless Rendering is to maintain this golden thread concept. That is, any implementation step or set of steps, when repeated, should allow images to smoothly and continuously converge to an ideal image.
Reference: [4] <author> Christina Burbeck. </author> <title> Encoding spatial relations. </title> <booktitle> Pattern Recognition by Man and Machine, </booktitle> <pages> pages 8-17, </pages> <year> 1990. </year>
Reference-contexts: displayed imagery occurs, and thus the visual illusion of continuous illumination is maintained (refresh rate required for no percepti ble flicker). 1 ing interdependent constraints: scene motion (velocities, accelera-tion, temporal coherence measure), boundary types (sharp or dull), and scene detail (length and separation of detail in objects, patterns, etc.) 2 <ref> [4] </ref>. We explore three of these factors via experimental comparisons: temporal coherence, scene fourier spectra, and pixel compute rate. Our findings are discussed in Section 7. There are three steps to analyzing the multidimensional problem space of factors that can influence perceptual quality within a Frameless Rendering implementation.
Reference: [5] <author> Christina Burbeck and Stephen Pizer. </author> <title> Object representation by cores: Identifying and representing primitive spatial regions. </title> <booktitle> Vision Research, </booktitle> <year> 1994. </year>
Reference-contexts: The gradient is a scale-space measure [19]. We refer to the scatter magnitude as the scale of the scatter, because its analysis can be accomplished with scale-space tools. These tools such as Anisotropic Diffusion [38] and Cores <ref> [5] </ref> are common in Computer Vision and Image Processing. They have been applied to Computer Graphics applications by Witkin and others. The velocity of the scatter, by definition, includes the rate and direction linear motion. The velocity is defined for each point on an object's image plane projection. <p> Target Room. Variable Conductance Diffusion (VCD) and Cores: Compare Frameless Rendering techniques using a model observer. The model observer will identify shapes, statically, using tools designed to function according to the workings of our human visual system. VCD and Cores are examples of such tools <ref> [5, 31] </ref>. Cumulative Cores, generated by summing over time, can be used to do some temporal analysis. One caveat: these are scale space tools and will require scale space guidance that varies across applications, as well as within an application.
Reference: [6] <author> David Burr. </author> <title> Visual processing of motion. </title> <booktitle> In Trends in Neuro Sciences, </booktitle> <volume> volume 9, No. 7, </volume> <month> July </month> <year> 1986. </year>
Reference-contexts: It is more difficult to visually articulate when our head (actually our eye) is moving rapidly <ref> [6] </ref>. <p> The indication is that there is some value to having old and new information flashed at the same instant in time. Frameless Rendering may be approximating the human visual system's integration of information over a 125 ms time window <ref> [6] </ref>. If an application's achievable frame rate is 30 f ps then a new frame is shown every 33 ms In 125 ms between 3 and 4 full frames have flashed before the eye.
Reference: [7] <author> Shenchang Eric Chen. </author> <title> Quicktime VR an image-based approach to virtual environment navigation. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 29-38. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year> <institution> held in Los Angeles, California, </institution> <month> 06-11 August </month> <year> 1995. </year>
Reference-contexts: Combine techniques which handle head rotation well with Frameless Rendering which handles translation well Assuming that tracking head translations produces animations with strong frame-to-frame coherence, create a hybrid scheme which switches between Frameless Rendering and say, Quicktime VR <ref> [7] </ref>, at some threshold of magnitude of angular velocity of the head. Good latency-reduction techniques, such as hardware address recalculation [33], handle isolated head rotations.
Reference: [8] <author> William S. Cleveland. </author> <title> The elements of graphing data. In Graphical Perception. </title> <publisher> Wadsworth, Inc, </publisher> <year> 1985. </year>
Reference-contexts: These were quantified within the scatter framework. The final step is to talk about how different qualities of scatter affect the psychovisual response. In order to begin this we consider the 10 graphical perception tasks enumerated by Cleveland <ref> [8] </ref>. They are angle, area, color 9 hue, color saturation, density or amount of black, length or distance, position along a common scale, position along identical, nonaliged scales, slope and volume.
Reference: [9] <author> Robert L. Cook. </author> <title> Practical aspects of distributed ray tracing. </title> <booktitle> In SIGGRAPH '86 Developments in Ray Tracing seminar notes, </booktitle> <month> Aug </month> <year> 1986. </year>
Reference-contexts: There are advanced multistage filters for handling nonuniform sampling: application of nested box filters of decreasing size in areas of high sampling density [28], combined with averaging and normalizing based on sampling density [43]. A simpler weighted averaging filter <ref> [9, 11] </ref> will suffice, though, because there is relatively low variance in sampling density due to the stochastic nature of Frameless Rendering. Reconstruction has become important in image-based rendering and 3 Contrast Sensitivity Function: a function of spatial frequency it shows the human visual system's sensitivity to retinal contrast.
Reference: [10] <author> Scott Daly. </author> <title> The visible differences predictor: An algorithm for the assessment of image fidelity. In A.B. </title> <editor> Watson, editor, </editor> <booktitle> Digital Images and Human Vision, </booktitle> <pages> pages 179-206, </pages> <year> 1993. </year>
Reference-contexts: There have also been salient analyses of how to measure image quality. A particularly robust scheme is preference factoring [1]. By using observer preferences, they assign weights to the different physical characteristics pertinent to image quality. The visible differences predictor <ref> [10] </ref> is a more formal algorithmic approach to preference factoring. It considers physical differences mathematically and correlates them to visible differences. This research is all pertinent to analyzing the loss of image fidelity with Frameless Rendering ( see Section 8). <p> Use Preference Factoring and the Visible Differences Predictor to steer Essential Frameless Rendering: Preference factoring [1] organizes the multidimensional human visual problem space by using observer preferences and assign weights to the different physical characteristics. The visible differences predictor <ref> [10] </ref> considers physical differences mathematically and correlates it to visible 12 differences. The results of these two methods can be used to steer Essential Frameless Rendering design.
Reference: [11] <author> Mark A. Z. Dippe and Erling Henry Wold. </author> <title> Stochastic sampling: Theory and application. </title> <editor> In George W. Zobrist, editor, </editor> <booktitle> Progress in Computer Graphics. </booktitle> <publisher> Ablex Publishing, </publisher> <address> Norwood, NJ, </address> <year> 1991. </year>
Reference-contexts: There are advanced multistage filters for handling nonuniform sampling: application of nested box filters of decreasing size in areas of high sampling density [28], combined with averaging and normalizing based on sampling density [43]. A simpler weighted averaging filter <ref> [9, 11] </ref> will suffice, though, because there is relatively low variance in sampling density due to the stochastic nature of Frameless Rendering. Reconstruction has become important in image-based rendering and 3 Contrast Sensitivity Function: a function of spatial frequency it shows the human visual system's sensitivity to retinal contrast.
Reference: [12] <author> David J. </author> <title> Fleet. Measurement of Image Velocity. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1992. </year>
Reference-contexts: The velocity is defined for each point on an object's image plane projection. It is similar to the model of 2-D image velocity. Some of the same issues that complicate measuring image velocity, such as occlusion, transparency, shadows, specular reflections, and atmospheric effects <ref> [12] </ref> also complicate extrication of the scatter velocity. For now, we use a simplified model of scatter velocity that parallels 2d-motion fields [14]. This model can not handle occlusion. Specifically, consider this case of self occlusion: a rotating flat-shaded sphere.
Reference: [13] <author> Daniel Scott Fritsch. </author> <title> Registration of Radiotherapy Images using Multiscale Medial Description of Image Structure. </title> <type> PhD thesis, </type> <institution> University of North Carolina at Chapel Hill, Department of Computer Science, </institution> <address> Chapel Hill, NC 27599-3175, </address> <year> 1993. </year>
Reference-contexts: The gradient at a point in each of these images is another scale-space gradient. In this case, convolution does not actually decrease the pixel resolution of the image, so there is a gradient computable for each pixel from the original image resolution. A zoom invariant gradient <ref> [13] </ref> will not introduce new maxima and minima across scales. 6.3 Projection of Multidimensional Parameter Space Numerous factors affect the perceptual visual quality of an interactive application running with an Frameless Rendering implementation.
Reference: [14] <author> J. J. Gibson, </author> <title> editor. The Perception of the Visual World. </title> <address> Houghton-Mifflin, Boston, </address> <year> 1950. </year>
Reference-contexts: Some of the same issues that complicate measuring image velocity, such as occlusion, transparency, shadows, specular reflections, and atmospheric effects [12] also complicate extrication of the scatter velocity. For now, we use a simplified model of scatter velocity that parallels 2d-motion fields <ref> [14] </ref>. This model can not handle occlusion. Specifically, consider this case of self occlusion: a rotating flat-shaded sphere. In terms of motion flow fields, pixels are moving on the image plane, but there is no visible scatter.
Reference: [15] <author> Steven J. Gortler, Radek Grzeszczuk, Richard Szeliski, and Michael F. Cohen. </author> <booktitle> The lumigraph. In SIGGRAPH 96 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 43-54. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1996. </year> <month> 13 </month>
Reference-contexts: The sensitivity is bandpass: low and high spatial frequencies correlate with diminished sensitivity. 4 the research offers a many options for reconstruction filters and techniques <ref> [27, 15, 22] </ref>. 5 Frameless Rendering Defined In this section we define Frameless Rendering in terms of an adaptive refinement philosophy, an ideal host renderer and an ideal host display.
Reference: [16] <author> Ralph Norman Haber and Maurice Hershenson. </author> <title> The Psychol--ogy of Visual Perception. </title> <publisher> Holt, Rinehart and Winston, Inc., </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: The scatter area, which can be derived from the scatter velocity and boundary conditions, has meaning with respect to the perceptual impact by the size of the retinal image. The scatter density's importance is related to how the human visual system fills in spatially and temporally (pursuit movements) <ref> [16] </ref> given surrounding spatiotemporal information. 7 Experiments and Results Images were rendered on an HP workstation using the public domain rendering program, Rayshade [20], developed at Princeton University for creating ray-traced images.
Reference: [17] <author> James T. Kajiya. </author> <title> The rendering equation. </title> <editor> In David C. Evans and Russell J. Athay, editors, </editor> <booktitle> Computer Graphics (SIGGRAPH '86 Proceedings), </booktitle> <volume> volume 20, </volume> <pages> pages 143-150, </pages> <month> Aug </month> <year> 1986. </year>
Reference-contexts: A combination of existing techniques can be combined to build a renderer that handles diffuse as well as specular lighting and computes the sample values independently by tracing independent rays <ref> [17] </ref>. A Monte Carlo method can be used for stochasticly sampling rays to approximate the surface reflectance function. A sufficient number of independent rays are cast nonuniformly to avoid aliasing artifacts [29].
Reference: [18] <author> Stanley A. Klein. </author> <title> Image quality and image compression: A psychophysicist's viewpoint. In A.B. </title> <editor> Watson, editor, </editor> <booktitle> Digital Images and Human Vision, </booktitle> <pages> pages 73-88, </pages> <year> 1993. </year>
Reference-contexts: Image compression and Frameless Rendering share the common goal of minimizing the number of samples required for an image while maximizing image fidelity. Impressive results have been accomplished in the analyzing how to maintain image integrity. The psychophysical issues pertinent to image quality have been detailed <ref> [18] </ref>. The goal of this analysis is to adapt image compression methods to visual sensitivity. For example, the contrast sensitivity function 3 [21] can be used for cosine transform compression [41]. Issues concerning maintenance of image quality are of immediate relevance to Frameless Rendering.
Reference: [19] <author> J.J. Koenderink. </author> <title> The structure of images. </title> <journal> Biological Cybernetics, </journal> <volume> 50 </volume> <pages> 363-370, </pages> <year> 1984. </year>
Reference-contexts: Velocity, density, area, and gradient are the factors contributing to the quality of the spatial scatter. Velocity includes the direction of the scatter and the magnitude or scale of the scatter. The gradient is a scale-space measure <ref> [19] </ref>. We refer to the scatter magnitude as the scale of the scatter, because its analysis can be accomplished with scale-space tools. These tools such as Anisotropic Diffusion [38] and Cores [5] are common in Computer Vision and Image Processing.
Reference: [20] <author> Craig E. Kolb. </author> <title> Rayshade user's guide and reference manual, </title> <year> 1992. </year>
Reference-contexts: The scatter density's importance is related to how the human visual system fills in spatially and temporally (pursuit movements) [16] given surrounding spatiotemporal information. 7 Experiments and Results Images were rendered on an HP workstation using the public domain rendering program, Rayshade <ref> [20] </ref>, developed at Princeton University for creating ray-traced images. This rendering package coupled with a the public domain program, animate, were the tools necessary for creating a frame-based animation.
Reference: [21] <author> Michael S. Landy and J. Anthony Movshon, </author> <title> editors. Computational Models of Visual Processing. </title> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Finally, we make educated conjecture as to the factors that influence the spatiotemporal perceptual quality of Frameless Rendering by considering each spatial scatter characteristic in turn. For example, signal processing theory of noise applies to the scale of the scatter, and the well-known contrast sensitivity function <ref> [21] </ref> is pertinent to analysis of the scatter gradient. Scatter Formulation + Experiments = Conclusion that temporal coherence and bandlimiting are correlated with a good Frameless Rendering showing. We show mathematically and experimentally how strong temporal coherence reduces the scale of the scatter in the direction of the scatter. <p> Impressive results have been accomplished in the analyzing how to maintain image integrity. The psychophysical issues pertinent to image quality have been detailed [18]. The goal of this analysis is to adapt image compression methods to visual sensitivity. For example, the contrast sensitivity function 3 <ref> [21] </ref> can be used for cosine transform compression [41]. Issues concerning maintenance of image quality are of immediate relevance to Frameless Rendering.
Reference: [22] <author> Marc Levoy and Pat Hanrahan. </author> <title> Light field rendering. </title> <booktitle> In SIGGRAPH 96 Conference Proceedings, Annual Conference Series. ACM SIGGRAPH, </booktitle> <publisher> Addison Wesley, </publisher> <month> August </month> <year> 1996. </year>
Reference-contexts: The sensitivity is bandpass: low and high spatial frequencies correlate with diminished sensitivity. 4 the research offers a many options for reconstruction filters and techniques <ref> [27, 15, 22] </ref>. 5 Frameless Rendering Defined In this section we define Frameless Rendering in terms of an adaptive refinement philosophy, an ideal host renderer and an ideal host display.
Reference: [23] <author> Marc Levoy and Ross Whitaker. </author> <booktitle> Gaze-directed volume rendering. Computer Graphics (Proc. 1990 Symposium on Interactive 3D Graphics), </booktitle> <volume> 24(2) </volume> <pages> 217-223, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: The visible differences predictor [10] considers physical differences mathematically and correlates it to visible 12 differences. The results of these two methods can be used to steer Essential Frameless Rendering design. Foveal 5 and macular 6 view importance sampling <ref> [23] </ref>: Given eye-tracking of the viewer, over time a sample that is in the high acuity region of the viewer's frustum will be updately more frequently than a sample in the periphery.
Reference: [24] <author> John-Peter Lewis. </author> <title> Algorithms for solid noise synthesis. </title> <editor> In Jef-frey Lane, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '89 Proceedings), </booktitle> <volume> volume 23, </volume> <pages> pages 263-270, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Further, we know that if there are aliases outside the window of visibility [39], then we cannot see these aliases. We also know from scale-space theory [25] that we can talk about extracting the signal at a particular scale. Noise functions have been well-defined <ref> [24] </ref>, and can be used for comparison with the graphs of the scatter.
Reference: [25] <author> Tony Lindeberg. </author> <title> Scale-space theory in computer vision. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1994. </year>
Reference-contexts: Further, we know that if there are aliases outside the window of visibility [39], then we cannot see these aliases. We also know from scale-space theory <ref> [25] </ref> that we can talk about extracting the signal at a particular scale. Noise functions have been well-defined [24], and can be used for comparison with the graphs of the scatter. <p> Lower order approximations may be used by finite methods, considering only nearby neighbor values. We define the gradient as a scale-space entity <ref> [25] </ref>. It can be defined for 1 point (or 1 pixel) or at any scale, , representing a neighborhood of points. The scale, , can be based on a continuous entity, as is the Gaussian kernel, or a discrete entity, such as a neighborhood of pixels.
Reference: [26] <author> Jeffrey Lubin. </author> <title> The use of psychophysical data and models in the analysis of display system performance. In A.B. </title> <editor> Watson, editor, </editor> <booktitle> Digital Images and Human Vision, </booktitle> <pages> pages 163-178, </pages> <year> 1993. </year>
Reference-contexts: The television industry has researched these lines, too, because they are concerned with image compression problem and have a relatively fixed, and high, standard of perceptual quality. The requirements for a fast-paced broadcast such as a hockey game vastly differ from those for a weather broadcast <ref> [26] </ref>. A good application-dependent Frameless Renderer can be developed by understanding these requirements. 4.2 Signal Processing The Frameless Rendering artifacts come across as noise. But, the visible spatial scatter actually contains information that the visual system is using.
Reference: [27] <author> Leonard McMillan and Gary Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 39-46. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year> <institution> held in Los Angeles, California, </institution> <month> 06-11 August </month> <year> 1995. </year>
Reference-contexts: The sensitivity is bandpass: low and high spatial frequencies correlate with diminished sensitivity. 4 the research offers a many options for reconstruction filters and techniques <ref> [27, 15, 22] </ref>. 5 Frameless Rendering Defined In this section we define Frameless Rendering in terms of an adaptive refinement philosophy, an ideal host renderer and an ideal host display.
Reference: [28] <author> Don P. Mitchell. </author> <title> Generating antialiased images at low sampling densities. </title> <editor> In Maureen C. Stone, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '87 Proceedings), </booktitle> <volume> volume 21, </volume> <pages> pages 65-72, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: There are advanced multistage filters for handling nonuniform sampling: application of nested box filters of decreasing size in areas of high sampling density <ref> [28] </ref>, combined with averaging and normalizing based on sampling density [43]. A simpler weighted averaging filter [9, 11] will suffice, though, because there is relatively low variance in sampling density due to the stochastic nature of Frameless Rendering.
Reference: [29] <author> Don P. Mitchell. </author> <title> The antialiasing problem in ray tracing. </title> <booktitle> In SIGGRAPH '90 Advanced Topics in Ray Tracing course notes, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: A Monte Carlo method can be used for stochasticly sampling rays to approximate the surface reflectance function. A sufficient number of independent rays are cast nonuniformly to avoid aliasing artifacts <ref> [29] </ref>. The display: Sample size and distribution, based on a user's eyepoint, can address only one user's eyepoint per display. For many users to be accommodated, they each need to have their own visual interface into the synthetic world.
Reference: [30] <author> Mike Morton. </author> <title> Digital dissolve effect. </title> <journal> Graphics Gems I, </journal> <pages> pages 304-407, </pages> <year> 1986. </year>
Reference-contexts: On the other hand, in cases of relatively weak temporal coherence, the low resolution image sequence showed relatively little image degradation when compared with the 2 Frameless Rendered image sequence. Frameless Rendering exhibits a natural dissolve effect when two successive frames are completely different <ref> [30] </ref>. This is illustrated by an HMD simulation where the user changes floors of a gallery with the push of a single button. The room the user is leaving naturally fades out as the room he or she is entering fades into view. <p> It appears from this demonstration that Frameless Rendering will fare better in applications that do not require dramatic viewpoint or head rotations. Dissolve: Frameless Rendering exhibits a natural dissolve effect when two successive frames are completely different <ref> [30] </ref>. This is illustrated by an HMD simulation where the user can change floors of a gallery with the push of a single button. The room the user is leaving naturally fades out as the room he or she is entering fades into view.
Reference: [31] <author> Stephen Pizer, Christina Burbeck, Daniel Fritch, Brian Morse, Alan Liu, Shobha Murthy, and Derek Puff. </author> <title> Human perception and computer image analysis of objects in images. </title> <booktitle> Proceedings of the Conference of the Australia Pattern Recognition Society (DICTA-93), </booktitle> <volume> 1 </volume> <pages> 19-26, </pages> <year> 1993. </year>
Reference-contexts: Target Room. Variable Conductance Diffusion (VCD) and Cores: Compare Frameless Rendering techniques using a model observer. The model observer will identify shapes, statically, using tools designed to function according to the workings of our human visual system. VCD and Cores are examples of such tools <ref> [5, 31] </ref>. Cumulative Cores, generated by summing over time, can be used to do some temporal analysis. One caveat: these are scale space tools and will require scale space guidance that varies across applications, as well as within an application. <p> For example, increased difficulty in finding shape middles, Cores, is an indication of loss of pertinent visual information <ref> [31] </ref>. Analyze images in terms of Image Energy: Using least squares and root mean square measurements of total intensity deviation from fully rendered frame, images can be analyzed in terms of image energy.
Reference: [32] <author> John Poulton. </author> <title> Overview of pixel-planes/pixelflow project, </title> <booktitle> 1995. UNC Seminar, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: Frameless Rendering, despite its constraint that the rendering scheme be point-sampled or pixel-sampled, will be one of the surviving speedup techniques available as we rapidly approach the one-pixel-polygon barrier <ref> [32] </ref>. It fits well with the move toward pixel-based rendering (versus polygon-based rendering) as in image-based rendering paradigms.
Reference: [33] <author> Matthew Regan and Ronald Pose. </author> <title> Priority rendering with a virtual reality address recalculation pipeline. </title> <booktitle> In Computer Graphics (SIGGRAPH '94 Proceedings), </booktitle> <pages> pages 155-162, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Good latency-reduction techniques, such as hardware address recalculation <ref> [33] </ref>, handle isolated head rotations. Use Preference Factoring and the Visible Differences Predictor to steer Essential Frameless Rendering: Preference factoring [1] organizes the multidimensional human visual problem space by using observer preferences and assign weights to the different physical characteristics. <p> Foveal 5 and macular 6 view importance sampling [23]: Given eye-tracking of the viewer, over time a sample that is in the high acuity region of the viewer's frustum will be updately more frequently than a sample in the periphery. Layers: By dividing the scene into layers in depth <ref> [33] </ref>, priority for updating visible pixels can be based on their distance from the eyepoint (emphasizing layers near the eyepoint), and based on their image plane velocity (emphasizing layers effecting a large distance change on the image plane).
Reference: [34] <author> J. M. Rolfe and K.J. </author> <title> Staples, editors. Flight Simulation. </title> <publisher> Cam-bridge University Press, </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference-contexts: Pixel Computation Rate: We experimented with a wide range of frame rates. Frameless Rendering exhibits an obvious smoothing payoff when frame rates are below 10 f ps. This is well below the 20 Hz threshold of detectability of a noncontinuous visual effect <ref> [34] </ref>. At 30 f ps, sequences are interchangeable in playback whether they use double buffering or Frameless Rendering. This is regardless of the number of temporal supersamples. One anomalous case surfaced after repeated playback of the rotating torus.
Reference: [35] <author> Ellen J. Scher Zagier. Frameless antialiasing. </author> <type> Technical Report UNC-CS-TR-95-026, </type> <institution> Department of Computer Science, University of North Carolina at Chapel Hill, </institution> <year> 1995. </year>
Reference-contexts: In a frameless environment, though, there is no reason to resort to an all-or-none extreme. If there is time for x number of samples to be computed at time t then all x samples should be computed and displayed. Frameless antialiasing's potential <ref> [35] </ref> was illustrated with the following experiment. Frameless antialiasing simulates pre-display of ready samples by displaying current information for in between frames. At each in-between frame the next 1=n samples are updated (n= the number of frameless frames to one double-buffered frame).
Reference: [36] <author> C.E. Shannon. </author> <title> Communications in the presence of noise. </title> <booktitle> In Proceedings IRE, </booktitle> <volume> volume 37, </volume> <pages> pages 10-21, </pages> <year> 1949. </year>
Reference-contexts: But, the visible spatial scatter actually contains information that the visual system is using. We know from sampling theory that if the sampling frequency is greater than twice the highest frequency in the environment being sampled then no signal can be the alias for another <ref> [36] </ref>. Further, we know that if there are aliases outside the window of visibility [39], then we cannot see these aliases. We also know from scale-space theory [25] that we can talk about extracting the signal at a particular scale. <p> The alternatives are based on conclusions from our experiments and the spatial scatter mathematical underpinning. 8.1 Measuring FR Image Quality Quantify temporal aliasing: For a given object velocity, compute the frame sampling rate necessary for fluid motion using sampling theory <ref> [36] </ref>. If the double buffering frame rate is less than the adequate sampling rate, then temporal aliasing occurs. If the frequency aliases are within the window of visibility [39] then the motion may not appear smooth. This is the range where Frameless Rendering has the greatest potential.
Reference: [37] <author> Andre State, Jonathan McAllister, Ulrich Neumann, Hong Chen, Tim Cullip, David T. Chen, and Henry Fuchs. </author> <title> Interactive volume visualization on a heterogeneous message-passing multicomputer. </title> <booktitle> In Proceedings of the 1995 ACM Symposium on Interactive 3D Computer Graphics, </booktitle> <pages> pages 69-74, </pages> <year> 1995. </year>
Reference-contexts: It has the automatic adaptive refinement feature of Frameless Rendering as all pixels converge to their current value when the motion has stopped. 3.3 Volume Rendering Application A volume rendering implementation was developed which combined frameless rendering principles with a preexisting adaptive refinement capability on an existing volume rendering system <ref> [37] </ref>. Partial updating can be chosen at thresholds of 25%, 50%, and 100%. 3 The decrease in total number of samples, versus pixels, computed per frame allows new frames to be generated faster.
Reference: [38] <author> Bart M. ter Haar Romeny, </author> <title> editor. Geometry-Driven Diffusion in Computer Vision. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1994. </year>
Reference-contexts: Velocity includes the direction of the scatter and the magnitude or scale of the scatter. The gradient is a scale-space measure [19]. We refer to the scatter magnitude as the scale of the scatter, because its analysis can be accomplished with scale-space tools. These tools such as Anisotropic Diffusion <ref> [38] </ref> and Cores [5] are common in Computer Vision and Image Processing. They have been applied to Computer Graphics applications by Witkin and others. The velocity of the scatter, by definition, includes the rate and direction linear motion. <p> A traditional method for obtaining coarse to fine scaling is a pyramidal structure where the bottom image of the pyramid is the full resolution image, and the upper images are successive reductions in resolution obtained by subsampling and application of some smoothing filter <ref> [38] </ref>. The resolution is a factor of the size of the reduction operator used to proceed to the next level of the pyramid. The scale-space gradient measure in this context is the normal gradient measured on a reduced resolution image.
Reference: [39] <author> Brian A. Wandell. </author> <title> Foundations of Vision. </title> <publisher> Sinauer Associates, Inc., </publisher> <address> Sunderland, MA, </address> <year> 1995. </year>
Reference-contexts: We know from sampling theory that if the sampling frequency is greater than twice the highest frequency in the environment being sampled then no signal can be the alias for another [36]. Further, we know that if there are aliases outside the window of visibility <ref> [39] </ref>, then we cannot see these aliases. We also know from scale-space theory [25] that we can talk about extracting the signal at a particular scale. Noise functions have been well-defined [24], and can be used for comparison with the graphs of the scatter. <p> This is fundamentally a psychophysics problem that has many contributing competing dimensions. Our visual inference is based on patterns, colors, motion and depth, and also on viewing geometry and object recognition. Experimentation with blind people suddenly gaining their sight for the first time <ref> [39] </ref> showed that they pick up the first four skills: understanding patterns, colors, etc., but have trouble with the latter two: object recognition and viewing geometry. <p> Object motion: The human visual system uses its entire field of view to identify and track motion. It is the one activity the visual periphery handles well, despite the significantly reduced visual acuity of that region. As long as there are no frequency aliases within the window of visibility <ref> [39] </ref>, then the motion has been adequately sampled. If temporal coherence is strong, frameless rendering will tend to fare better in perceived image quality because aging pixels' intensity value is less out of date. Object motion complexity: The human visual system tends to correlate independent motions. <p> It is equal to the distance the image plane projection traveled since its last update. It is the magnitude of the motion flow vector <ref> [39] </ref> for the point. For example, let T = (T x , T y , T z ) be the point's translational velocity and R be the point's rotational velocity about some axis A = (A x , A y , A z ). <p> If the double buffering frame rate is less than the adequate sampling rate, then temporal aliasing occurs. If the frequency aliases are within the window of visibility <ref> [39] </ref> then the motion may not appear smooth. This is the range where Frameless Rendering has the greatest potential.
Reference: [40] <author> J.Y.A Wang and E.H. Adelson. </author> <title> Representing moving images with layers. </title> <booktitle> In IEEE Transactions in Image Processing, </booktitle> <volume> volume 3, </volume> <pages> pages 625-630, </pages> <month> Sept </month> <year> 1994. </year>
Reference-contexts: This philosophy is not new: a similar hardware idea, sprites, is used for doing fast animation. Superimposed layers of pixmaps are manipulated independently. Image processing research also exploits this layered approach in creating velocity flow diagrams to predict information for future frames <ref> [40] </ref>. Gradient Importance Sampling: Importance sampling based on regions of high gradient to emphasize boundary information was suggested in section 5.4. Extensive literature supports the claim that it is an area of perceptual significance.
Reference: [41] <author> Andrew B. Watson, </author> <title> editor. Digital Images and Human Vision. </title> <publisher> The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The psychophysical issues pertinent to image quality have been detailed [18]. The goal of this analysis is to adapt image compression methods to visual sensitivity. For example, the contrast sensitivity function 3 [21] can be used for cosine transform compression <ref> [41] </ref>. Issues concerning maintenance of image quality are of immediate relevance to Frameless Rendering.
Reference: [42] <author> H. Whitaker and J. Halas. </author> <title> Timing for Animation. </title> <publisher> Focal Press Ltd., </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: There are anomalous behaviors, such as the common wagon wheel problem where the spokes appear to move backwards, which are comprised of arbitrarily high frequencies and no discrete sampling can address the problem <ref> [42] </ref>. Vary object motion complexity: Object motion complexity refers to the number of objects undergoing independent motions in the scene. It may also refer to the nature of the motion such as constant velocity versus. acceleration.
Reference: [43] <author> Turner Whitted. </author> <title> An improved illumination model for shaded display. </title> <journal> Communications of the ACM, </journal> <volume> 23(6) </volume> <pages> 343-349, </pages> <month> June </month> <year> 1980. </year>
Reference-contexts: There are advanced multistage filters for handling nonuniform sampling: application of nested box filters of decreasing size in areas of high sampling density [28], combined with averaging and normalizing based on sampling density <ref> [43] </ref>. A simpler weighted averaging filter [9, 11] will suffice, though, because there is relatively low variance in sampling density due to the stochastic nature of Frameless Rendering.
Reference: [44] <author> Matthias Wloka and Robert C. Zeleznik. </author> <title> Interactive real-time motion blur. </title> <booktitle> In Proceedings of CGI'94: Insight Through Computer Graphics, </booktitle> <year> 1995. </year> <month> 14 </month>
Reference-contexts: This results in a lower effective display resolution. 3.4 Beyond Frameless Rendering At Brown University researchers developed a technique in which they remap the computation buffer to the display buffer by interleaving quadrants to effectively quarter the resolution of the display buffer <ref> [44] </ref>. They improved the frameless rendering motion blur effect by using a semi transparent grid: a value for a pixel halfway between the old value and the new value is used. <p> FR - Full-frame Updates: Choose number of pixels to be updated on each input for the Frameless Rendering side. The other side gets full frame updates. This option was used to investigate power of low-cost motion blur effect <ref> [44] </ref>. FR Essential FR: Essential Frameless Rendering uses neighbor information for value of aging pixels. The low resolution version is created by reducing the sampling, but propagating the information to neighbor pixels at a higher pixel resolution (nearest neighbor reconstruction). <p> So within the range of approximately 5-10 f ps we can expect to see smoothing effects by deliberately retaining old information, even if full frame computation is possible. This free temporal antialiasing effect is discussed in Wloka and Zeleznik's real-time motion blur work <ref> [44] </ref>. 8 Future Work Frameless Rendering is relatively new and unchartered. Consequently much of the Frameless Rendering work falls into the category of future work. For historic purposes, we provide details of viable alternatives to refining and analyzing Frameless Rendering.
References-found: 44

