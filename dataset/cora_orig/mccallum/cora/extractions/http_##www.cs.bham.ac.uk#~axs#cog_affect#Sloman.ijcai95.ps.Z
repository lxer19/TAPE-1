URL: http://www.cs.bham.ac.uk/~axs/cog_affect/Sloman.ijcai95.ps.Z
Refering-URL: http://www.cs.bham.ac.uk/~axs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: A.Sloman@cs.bham.ac.uk,  
Title: A Philosophical Encounter  
Author: Aaron Sloman 
Web: http://www.cs.bham.ac.uk/~axs  
Address: B15 2TT, England  
Affiliation: School of Computer Science Cognitive Science Research Centre The University of Birmingham,  
Date: August 1995  
Note: In Proceedings 14th International Joint Conference on AI Montreal,  
Abstract: This paper, along with the following paper by John McCarthy, introduces some of the topics to be discussed at the IJCAI95 event `A philosophical encounter: An interactive presentation of some of the key philosophical problems in AI and AI problems in philosophy.' Philosophy needs AI in order to make progress with many difficult questions about the nature of mind, and AI needs philosophy in order to help clarify goals, methods, and concepts and to help with several specific technical problems. Whilst philosophical attacks on AI continue to be welcomed by a significant subset of the general public, AI defenders need to learn how to avoid philosophically naive rebuttals.
Abstract-found: 1
Intro-found: 1
Reference: [ Bates et al., 1991 ] <author> J. Bates, A. B. Loyall, and W. S. Reilly. </author> <title> Broad agents. </title> <booktitle> In Paper presented at AAAI spring symposium on integrated intelligent architectures, </booktitle> <year> 1991. </year> <note> (Available in SIGART BULLETIN, 2(4), </note> <month> Aug. </month> <year> 1991, </year> <pages> pp. 38-40). </pages>
Reference-contexts: A new potentially important area of influence of AI on both philosophy and psychology concerns the study of motivation and emotions. As designs for complete or `broad' ( <ref> [ Bates et al., 1991 ] </ref> ) agent architectures develop, we can expect to obtain a much deeper grasp of how motivational and emotional states arise, along with moods, attitudes, personality, and the like.
Reference: [ Beaudoin and Sloman, 1993 ] <author> L.P. Beaudoin and A. Slo-man. </author> <title> A study of motive processing and attention. </title> <editor> In A.Sloman, D.Hogg, G.Humphreys, D. Partridge, and A. Ramsay, editors, </editor> <booktitle> Prospects for Artificial Intelligence, </booktitle> <pages> pages 229-238. </pages> <publisher> IOS Press, </publisher> <address> Amsterdam, </address> <year> 1993. </year>
Reference: [ Boden, 1978 ] <author> M. A. </author> <title> Boden. </title> <booktitle> Artificial Intelligence and Natural Man. </booktitle> <publisher> Harvester Press, </publisher> <address> Hassocks, Sussex, </address> <year> 1978. </year> <title> Second edition 1986. </title> <publisher> MIT Press. </publisher>
Reference-contexts: 1 AI as philosophy Most AI researchers regard philosophy as irrelevant to their work, though some textbooks (e.g. <ref> [ Boden, 1978; Russell and Norvig, 1995 ] </ref> ) treat the two as strongly related, as does McCarthy, one of the founders of AI.
Reference: [ Dennett, 1978 ] <author> D. C. Dennett. Brainstorms: </author> <title> Philosophical Essays on Mind and Psychology. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1978. </year>
Reference: [ Dennett, 1991 ] <author> D. C. Dennett. </author> <title> Consciousness Explained. </title> <publisher> Penguin Press, </publisher> <address> Allen Lane, </address> <year> 1991. </year>
Reference-contexts: Another topic on which AI can advance philosophy concerns `qualia', sometimes also referred to as `raw feels'. These are defined variously as the contents of our experience, the answer to what it is like to feel, see or want something, and so on ( <ref> [ Dennett, 1991 ] </ref> ). Some philosophers require that qualia have no physical effects and claim that different people may have different qualia without any objectively detectable evidence existing for the difference. One reaction is to argue against their existence, as Dennett does. <p> Arguments showing the absurdity of this tendency are powerfully articulated in <ref> [ Dennett, 1991 ] </ref> . In some philosophers, the tendency is incurable. Perhaps teaching them how to design robots with qualia will finally cure some who resist all other treatments. But some incurables will always remain. One day, their ranks will include robot philosophers who claim to have qualia.
Reference: [ Hayes, 1985 ] <author> P.J. Hayes. </author> <booktitle> The second naive physics manifesto, </booktitle> <pages> pages 1-36. </pages> <publisher> Ablex, </publisher> <address> Norwood, NJ, </address> <year> 1985. </year> [ <pages> kqml, </pages> <year> 1994 </year> <month> ] </month> <year> 1994. </year> <title> The KQML project and related activities are described in Web documents accessible via http://www.cs.umbc.edu/kqml. </title>
Reference-contexts: This extends the process outlined in chapter 4 of [ Sloman, 1978 ] , linking conceptual analysis in philosophy with articulation of knowledge for intelligent artefacts. McCarthy's paper gives more examples of connections between AI and philosophy. See also <ref> [ McCarthy and Hayes, 1969; Hayes, 1985 ] </ref> . 3 Two way influences, and more I have listed some topics on which AI informs philosophy and others on which philosophy informs AI.
Reference: [ Marr, 1982 ] <author> D. Marr. </author> <title> Vision. </title> <publisher> Freeman, </publisher> <year> 1982. </year>
Reference-contexts: is obvious that a complete autonomous agent, unlike simple expert systems, must have myriad distinct, coexisting, interacting, information stores, including both long term collections of general information, personal history, procedural information, and short term stores corresponding to current goals and plans, suppositions, imaginings, thoughts, different levels in perceptual processing ( <ref> [ Marr, 1982; Minsky, 1987; Slo-man, 1989 ] </ref> ), and motor control.
Reference: [ McCarthy and Hayes, 1969 ] <author> J. McCarthy and P.J. Hayes. </author> <title> Some philosophical problems from the standpoint of AI. </title> <publisher> Edin. Univ. Press, Edinburgh, </publisher> <year> 1969. </year>
Reference-contexts: This extends the process outlined in chapter 4 of [ Sloman, 1978 ] , linking conceptual analysis in philosophy with articulation of knowledge for intelligent artefacts. McCarthy's paper gives more examples of connections between AI and philosophy. See also <ref> [ McCarthy and Hayes, 1969; Hayes, 1985 ] </ref> . 3 Two way influences, and more I have listed some topics on which AI informs philosophy and others on which philosophy informs AI.
Reference: [ McCarthy, 1990 ] <author> J. McCarthy. </author> <title> Formalising Common Sense. </title> <publisher> Ablex, </publisher> <address> Norwood, New Jersey, </address> <year> 1990. </year>
Reference-contexts: This is required both as part of the methodology of knowledge elicitation for expert systems, and also for design of robots intended to communicate with humans, act on human goals, use human criteria for resolving conflicts and deal with the unexpected in ways that are acceptable to humans ( <ref> [ McCarthy, 1990 ] </ref> ). This extends the process outlined in chapter 4 of [ Sloman, 1978 ] , linking conceptual analysis in philosophy with articulation of knowledge for intelligent artefacts. McCarthy's paper gives more examples of connections between AI and philosophy.
Reference: [ McCarthy, 1995 ] <author> J. McCarthy. </author> <title> Making robots conscious of their mental states. </title> <booktitle> In AAAI Spring Symposium on Representing Mental States and Mechanisms, </booktitle> <year> 1995. </year> <note> Accessible via http://www-formal.stanford.edu/jmc/. </note>
Reference-contexts: What is not so obvious is that an agent needs to be able to attend to and control some of its internal databases ( <ref> [ Minsky, 1987; Sloman, 1990; McCarthy, 1995 ] </ref> ) and may need to be 1 able to inform others about them, which we can do with varying degrees of accuracy (e.g. describing how we feel or how things look to us, or painting pictures, or setting up a situation that recreates
Reference: [ Minsky, 1987 ] <author> M. L. Minsky. </author> <title> The Society of Mind. </title> <publisher> Wil-liam Heinemann Ltd., </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: is obvious that a complete autonomous agent, unlike simple expert systems, must have myriad distinct, coexisting, interacting, information stores, including both long term collections of general information, personal history, procedural information, and short term stores corresponding to current goals and plans, suppositions, imaginings, thoughts, different levels in perceptual processing ( <ref> [ Marr, 1982; Minsky, 1987; Slo-man, 1989 ] </ref> ), and motor control. <p> What is not so obvious is that an agent needs to be able to attend to and control some of its internal databases ( <ref> [ Minsky, 1987; Sloman, 1990; McCarthy, 1995 ] </ref> ) and may need to be 1 able to inform others about them, which we can do with varying degrees of accuracy (e.g. describing how we feel or how things look to us, or painting pictures, or setting up a situation that recreates
Reference: [ Narayanan, 1993 ] <editor> (Ed) N.H. Narayanan. </editor> <title> The imagery debate revisited. </title> <journal> Special issue of Computational Intelligence, </journal> <volume> 9(4) </volume> <pages> 303-435, </pages> <year> 1993. </year> <note> (Paper by J.Glasgow, and commentaries). </note>
Reference-contexts: More recently the old philosophical controversy about varieties of forms of representations (e.g. logical and pictorial), which I discussed in [ 1971 ] , has become a topic of active AI research ( <ref> [ Narayanan, 1993 ] </ref> ).
Reference: [ Newell, 1982 ] <author> A. Newell. </author> <title> The knowledge level. </title> <journal> Artificial Intelligence, </journal> <volume> 18(1) </volume> <pages> 87-127, </pages> <year> 1982. </year>
Reference-contexts: This undermines a common interpretation of Newell's and Simon's `physical symbol system hypothesis' (e.g. <ref> [ Newell, 1982 ] </ref> ), for most of the symbols AI is concerned about are not physical, but structures in virtual machines.
Reference: [ Newell, 1990 ] <author> A. Newell. </author> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference: [ Russell and Norvig, 1995 ] <author> Stuart Russell and Peter Norvig. </author> <title> Artificial Intelligence, A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: 1 AI as philosophy Most AI researchers regard philosophy as irrelevant to their work, though some textbooks (e.g. <ref> [ Boden, 1978; Russell and Norvig, 1995 ] </ref> ) treat the two as strongly related, as does McCarthy, one of the founders of AI.
Reference: [ Simon, 1967 ] <author> H. A. Simon. </author> <title> Motivational and emotional controls of cognition, </title> <booktitle> 1967. Reprinted in Models of Thought, </booktitle> <publisher> Yale University Press, </publisher> <pages> 29-38, </pages> <year> 1979. </year>
Reference: [ Sloman and Croucher, 1981 ] <author> A. Sloman and M. Croucher. </author> <title> Why robots will have emotions. </title> <booktitle> In Proc 7th Int. Joint Conf. on AI, </booktitle> <address> Vancouver, </address> <year> 1981. </year>
Reference: [ Sloman, 1971 ] <author> A. Sloman. </author> <title> Interactions between philosophy and ai: </title> <booktitle> The role of intuition and non-logical reasoning in intelligence. In Proc 2nd IJCAI, London, 1971. Repr in Artificial Intelligence, </booktitle> <year> 1971. </year>
Reference: [ Sloman, 1978 ] <author> A. Sloman. </author> <title> The Computer Revolution in Philosophy: Philosophy, Science and Models of Mind. </title> <publisher> Harvester Press (and Humanities Press), </publisher> <address> Hassocks, Sussex, </address> <year> 1978. </year>
Reference-contexts: This extends the process outlined in chapter 4 of <ref> [ Sloman, 1978 ] </ref> , linking conceptual analysis in philosophy with articulation of knowledge for intelligent artefacts. McCarthy's paper gives more examples of connections between AI and philosophy.
Reference: [ Sloman, 1985 ] <author> A. Sloman. </author> <booktitle> What enables a machine to understand? In Proc 9th IJAI, </booktitle> <pages> pages 995-1001, </pages> <address> Los Angeles, </address> <year> 1985. </year>
Reference-contexts: many topics I have not had room to address, including: consciousness and free will (both of them `cluster' concepts rather than names for something that is either present or absent); issues raised by Searle and Penrose in their attacks on AI; how machines can understand the symbols they use ( <ref> [ Sloman, 1985 ] </ref> ); the relevance of metamathematical incompleteness theorems; confusions surrounding the Tur-ing test; the role of states like pain and pleasure in intelligent agents; ethical issues about the rights and responsibilities of intelligent artefacts; debates about the philosophical significance of the choice between connectionist implementations and symbolic implementations
Reference: [ Sloman, 1989 ] <author> A. Sloman. </author> <title> On designing a visual system (towards a gibsonian computational model of vision). </title> <journal> Journal of Experimental and Theoretical AI, </journal> <volume> 1(4) </volume> <pages> 289-337, </pages> <year> 1989. </year>
Reference: [ Sloman, 1990 ] <author> A. Sloman. </author> <title> Notes on consciousness. </title> <journal> AISB Quarterly, </journal> (72):8-14, 1990. Also presented at Rockefeller foundation workshop on consciousness, Villa Serbelloni, Bellagio March 1990, organiser D.C.Dennett. 
Reference-contexts: What is not so obvious is that an agent needs to be able to attend to and control some of its internal databases ( <ref> [ Minsky, 1987; Sloman, 1990; McCarthy, 1995 ] </ref> ) and may need to be 1 able to inform others about them, which we can do with varying degrees of accuracy (e.g. describing how we feel or how things look to us, or painting pictures, or setting up a situation that recreates
Reference: [ Sloman, 1994a ] <author> A. Sloman. </author> <title> Explorations in design space. </title> <booktitle> In Proceedings 11th European Conference on AI, </booktitle> <address> Amsterdam, </address> <year> 1994. </year>
Reference: [ Sloman, 1994b ] <author> A. Sloman. </author> <title> Semantics in an intelligent control system. </title> <journal> Philosophical Transactions of the Royal Society: Physical Sciences and Engineering, </journal> <volume> 349(1689) </volume> <pages> 43-58, </pages> <year> 1994. </year>
Reference-contexts: Dennett's `intentional stance' [ 1978 ] chapter 1, attributes beliefs and desires to agents on the assumption that they are rational. Newell's knowledge level ( [ 1982; 1990 ] ) is also defined in terms of a presupposition of rationality. However deeper analysis shows ( <ref> [ Sloman, 1994b ] </ref> ) that mechanisms of intelligence can be understood at the information processing level without assuming rationality. Something closer to the design stance than to the intentional stance underpins ordinary concepts like `belief', `desire', `intention'. <p> relevance of metamathematical incompleteness theorems; confusions surrounding the Tur-ing test; the role of states like pain and pleasure in intelligent agents; ethical issues about the rights and responsibilities of intelligent artefacts; debates about the philosophical significance of the choice between connectionist implementations and symbolic implementations (I have argued elsewhere ( <ref> [ Sloman, 1994b ] </ref> ) that architecture dominates mechanism); whether mentality requires causal embedding in an external physical environment (as argued in the `systems' reply to Searle); whether AI needs non-computational as well as computational mechanisms; analysis of the concept of `computation'; and prospects for future forms of intelligence, including distributed
Reference: [ Sloman, 1995 ] <author> A. Sloman. </author> <title> Exploring design space & niche space. </title> <booktitle> In Proc. 5th Scandinavian Conf. on AI, </booktitle> <address> Trondheim, Amsterdam, 1995. </address> <publisher> IOS Press. </publisher>
Reference: [ Strawson, 1959 ] <author> P. F. Strawson. </author> <title> Individuals: An essay in descriptive metaphysics. </title> <publisher> Methuen, </publisher> <address> London, </address> <year> 1959. </year> <month> 4 </month>
References-found: 26

