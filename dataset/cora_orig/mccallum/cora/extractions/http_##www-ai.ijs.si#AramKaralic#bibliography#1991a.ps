URL: http://www-ai.ijs.si/AramKaralic/bibliography/1991a.ps
Refering-URL: http://www-ai.ijs.si/AramKaralic/bibliography/1991a.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Aram.Karalic@ijs.si  
Title: SIGNIFICANCE LEVEL BASED CLASSIFICATION WITH MULTIPLE TREES  
Author: Aram Karalic, Vlado Pirnat 
Date: 1991  
Note: e mail:  
Address: Jamova 39 61111 Ljubljana Yugoslavia  
Affiliation: Jozef Stefan Institute  
Abstract: Usually, algorithms for machine learning during the classification return a single class for a given object. Many of the systems do not estimate a reliability of their answer. In the article a method is presented that returns multiple classes as possible. The method also gives the user an estimation of the answer's reliability. Additionally, the method enables also classification in domains where one example can belong to more than one class. The described ideas are tested on a real medical domain | rheumatology. The results are compared with the results of the classical algorithms for machine learning and with the results of general practitioners. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Catlett, J., Christopher, J.: </author> <title> "Is it better to learn each class separately?", </title> <type> technical report, </type> <institution> University of Sydney, Australia, </institution> <year> 1987. </year>
Reference: [2] <author> Cestnik, B.: </author> <title> "Estimating Probabilities: A Crucial Task in Machine Learning", </title> <booktitle> Proceedings of ECAI-90, </booktitle> <address> Stockholm, Sweden, </address> <month> august </month> <year> 1990. </year>
Reference-contexts: The system's answer is: (0.00 1.00 0.00), saying that our new example belongs to class C2 with probability 1. 1 But it is obvious that this probability estimate is extremely inaccurate, because it was calculated only from three learning examples. It was also stated in <ref> [2] </ref> that the probability estimation is one of the crucial tasks in certain subareas of machine learning. 2. In many of the problems suitable for the application of machine learning example can belong to more than one class.
Reference: [3] <author> Cestnik, B., Kononenko, I., Bratko, I.: </author> <title> "ASSISTANT 86: A Knowledge elicitation tool for sophisticated users", </title> <editor> in: Bratko, I., Lavrac, N. (eds.): </editor> <booktitle> Progress in Machine Learning, </booktitle> <publisher> Sigma Press, </publisher> <address> Wilmslow, </address> <year> 1987. </year>
Reference-contexts: An experiment with the described method of classification was performed and the obtained results were compared with the results of the classical use of ASSISTANT. Parameter settings for the ASSISTANT, which are described in <ref> [3] </ref>, are displayed in Table 1.
Reference: [4] <author> Ferguson, </author> <title> G.A., "Statistical Analysis in Psychology and Education", Chapter 11, </title> <publisher> McGraw-Hill, </publisher> <address> London, </address> <year> 1959. </year>
Reference-contexts: Let us now explain the statistical test that is based on the principles of statistical tests explained in <ref> [4] </ref>. The test is explained only for the case when R i &gt; 0:5. The other situation (R i &lt; 0:5) is handled analogously. Recall that R i = k=N .
Reference: [5] <author> Kononenko, I.: </author> <title> "The design of the ASSISTANT Inductive Learning System", M.Sc. </title> <type> Thesis, </type> <institution> E.Kardelj University, Faculty for Electrical and Computer Engineering, Ljubljana, </institution> <note> 1985 (in Slovene). </note>
Reference-contexts: To further reduce the dissimilarity between the two measures of performance, each correct answer was weighted with a 1=jSPDj. This technique is also implemented in original ASSISTANT <ref> [5] </ref>. In the experiments the weighted percentage of correct answers, which we denoted with acc, the size of the SPD (denoted with siz) and the percentage of cases when jSPDj was more than one (denoted with MT1) were measured. The mean values and standard deviations were measured for each parameter.
Reference: [6] <author> Michie D., Al Attar A.: </author> <title> "Use of sequential Bayes with class probability trees", </title> <note> to appear in: </note> <editor> J.E.Hayes - Michie, D.Michie, E.Tyugu (eds.), </editor> <booktitle> Machine Intelligence 12, </booktitle> <publisher> Oxford University Press. </publisher>
Reference: [7] <author> Mladenic, D.: </author> <title> "Magnus Assistant: a system for machine learning", B.Sc. </title> <type> Thesis, </type> <institution> E.Kardelj University, Faculty for Electrical Engineering and Computer Science, Ljubljana, </institution> <note> 1990 (in Slovene). </note>
Reference: [8] <author> Quinlan, J.R.: </author> <title> "Induction of Decision Trees", Machine Learning 1, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1986. </year> <month> 11 </month>
Reference-contexts: Thus, with different classification algorithms the same knowledge base can be interpreted in several ways. In this article only the algorithms that construct knowledge base in the form of decision trees (e.g. ASSISTANT [5,3,7], ID3 <ref> [8] </ref>, etc.) are discussed. Nevertheless, the described ideas can be generalized also to algorithms with different knowledge representations. The two situations that can often occur in the context of machine learning in real-world domains and that are not treated properly by the existing learning systems are the following: 1.
References-found: 8

