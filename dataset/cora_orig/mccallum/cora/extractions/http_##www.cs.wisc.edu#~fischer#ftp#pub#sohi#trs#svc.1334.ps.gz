URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/trs/svc.1334.ps.gz
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/trs/
Root-URL: http://www.cs.wisc.edu
Email: gsri,vijay@cs.wisc.edu, jes@ece.wisc.edu, sohi@cs.wisc.edu  
Title: Speculative Versioning Cache  
Author: Sridhar Gopal, T. N. Vijaykumar, James E. Smith and Gurindar S. Sohi 
Keyword: Dependence Speculation, Memory Disambiguation, Multiscalar, Memory Versioning, Multiple Reader Multiple Writer protocol.  
Date: July 14 1997  
Address: USA  
Affiliation: University of Wisconsin-Madison,  
Abstract: During the execution of a sequential program, dependences involving loads and stores are ambiguous until their addresses are known. Ambiguous memory dependences impede the extraction of instruction level parallelism. Memory dependence speculation is a hardware technique to overcome ambiguous memory dependences. This technique enables processors to execute loads and stores before the addresses of preceding loads and stores are known. When a store address is known, if a later load to the same address is found, a misspeculation is posted. The misspeculation is handled similar to a branch misprediction. Store values are buffered and committed in program order. Multiple uncommitted stores to a memory location create multiple versions of the location. Program order among the versions is tracked to maintain sequential semantics, i.e., the versions are committed in the correct order and loads are supplied with correct versions. The problem of maintaining sequential semantics in the presence of multiple speculative versions of memory locations is called speculative versioning of memory. Most modern microprocessors dispatch instructions from a single dynamic instruction stream and maintain a time-ordering of the versions using load-store queues. The queues support a simple form of speculative versioning. Several recent proposed processors including the Multiscalar processor and single chip multiprocessors, however, partition the single dynamic instruction stream into multiple fragments and dispatch these fragments to multiple processing units (PUs). Such hierarchical processor designs naturally lead to hierarchical memory organizations. But load-store queues are not designed to support speculative versioning in hierarchical organizations. The Address Resolution Buffer (ARB) has been proposed to provide this support. The ARB uses a single shared buffer connected to all the PUs and hence, every memory access incurs the latency of the interconnection network. The shared buffer is a potential bandwidth bottleneck. Our proposal, called the Speculative Versioning Cache (SVC), contains a private cache with each PU organized similar to a cache coherent Symmetric Multiprocessor. The SVC conceptually unifies cache coherence and memory dependence speculation. The SVC eliminates the latency and bandwidth problems of the ARB. A preliminary experimental evaluation of SPEC95 benchmarks shows that (i) hit latency is an important factor affecting performance (even for a latency tolerant processor like the multiscalar) and, (ii) private cache solutions trade-off hit rate for hit latency to achieve performance. The experiments show that the SVC performs up to 8% better than an ARB without any bank contention. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> IEEE Standard for Scalable Coherent Interface (SCI) 1596-1992. </institution> <note> IEEE 1993. </note>
Reference-contexts: This ordered set or list, called the Version Ordering List (VOL), can be implemented using explicit pointers (for example, as a linked list like in SCI <ref> [1] </ref>). The following sections elaborate on a design that uses pointers in each cache line to maintain the VOL.
Reference: [2] <institution> PowerPC 620 RISC microprocessor technical summary. IBM order number MPR620TSU-01, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: A key element of this straightforward approach is that a load instruction is not issued until the addresses of all the preceding stores are determined. This approach may diminish ILP unnecessarily, especially in the common case where the load is not dependent on preceding stores. More aggressive uniprocessor implementations <ref> [8, 6, 2] </ref> issue load instructions as soon as their addresses are known, even though the addresses of all previous stores may not be known.
Reference: [3] <author> B.N.Bershad, M.J.Zekauskas, and W.A.Sawdon. </author> <title> The Midway distributed shared memory system. </title> <booktitle> In Compcon 93, </booktitle> <pages> pages 528537. </pages> <publisher> CS Press, </publisher> <year> 1993. </year>
Reference-contexts: Multiple Writer (MRMW) protocol 3 that tracks copies of multiple 2 In reality, the store has to be communicated only until the task that has created the next version, if any, of the location. 3 MRMW protocols have been implemented in software by distributed shared memory systems like the Midway <ref> [3] </ref> and the TreadMarks [14]. 5 speculative versions of each memory location. This MRMW protocol uses a version directory that maintains ordered sets for each line, each of which tracks the program order among the multiple speculative versions of a line.
Reference: [4] <author> Manoj Franklin and Gurindar S. Sohi. ARB: </author> <title> A hardware mechanism for dynamic reordering of memory references. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 45(5):552571, </volume> <month> May </month> <year> 1996. </year>
Reference-contexts: Consequently, there is a need for speculative versioning mechanisms that operate within this hierarchical organization. The Address Resolution Buffer <ref> [4] </ref> (ARB) provides speculative versioning for such hierarchical organization of instructions. The ARB uses a shared buffer with each entry comprising multiple versions of the same memory location. <p> A schematic of the Version Control Logic is shown in Figure 5. For the base design, the VCL responses are similar to that of the disambiguation logic in the ARB <ref> [4] </ref>; the disambiguation logic searches for previous/succeeding stages in a line to satisfy a PU access. The program order among the tasks assigned to the PUs enforces an implicit total order among the PUs and hence the L1 caches.
Reference: [5] <author> James R. Goodman. </author> <title> Using cache memory to reduce processor-memory traffic. </title> <booktitle> In Proceedings of the 10th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 124131, </pages> <year> 1983. </year>
Reference-contexts: Similar functionality is required of a cache coherent Symmetric Multiprocessor (SMP), which tracks the caches that have a copy of every address. SMPs, however, need not track the order among these copies since all the copies are of a single version. SMPs typically use snooping-bus based cache coherence <ref> [5] </ref> to implement a Multiple Reader Single Writer (MRSW) protocol that tracks copies of a single version of each memory location. This MRSW protocol uses a coherence directory that is a collection of sets, each of which tracks the sharers of a line.
Reference: [6] <author> Doug Hunt. </author> <title> Advanced performance features of the 64-bit PA-8000. </title> <booktitle> In Compcon 95 Digest of Papers, </booktitle> <pages> pages 123128. </pages> <publisher> CS Press, </publisher> <month> March </month> <year> 1995. </year>
Reference-contexts: A key element of this straightforward approach is that a load instruction is not issued until the addresses of all the preceding stores are determined. This approach may diminish ILP unnecessarily, especially in the common case where the load is not dependent on preceding stores. More aggressive uniprocessor implementations <ref> [8, 6, 2] </ref> issue load instructions as soon as their addresses are known, even though the addresses of all previous stores may not be known.
Reference: [7] <author> Quinn Jacobson, Steve Bennett, Nikhil Sharma, and James E. Smith. </author> <title> Control flow speculation in multiscalar processors. </title> <booktitle> In Proceedings of the Third International Symposium on High-Performance Computer Architecture, </booktitle> <year> 1997. </year>
Reference-contexts: The control flow predictor of this control unit uses a dynamic path-based scheme that selects from up to 4 task targets per prediction and tracks 7 path histories XOR-folded into a 15-bit path register <ref> [7] </ref>. The predictor storage consists of both a task target table and a task address table, each with 32K entries indexed by the path register. Each target table entry is a 2-bit counter and a 2-bit target. Each address table entry has a 2-bit counter and a 32-bit address.
Reference: [8] <author> Jim Keller. </author> <title> The 21264: A superscalar Alpha processor with out-of-order execution. </title> <booktitle> Presentation at the 9th Annual Microprocessor Forum, </booktitle> <address> San Jose, California, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: A key element of this straightforward approach is that a load instruction is not issued until the addresses of all the preceding stores are determined. This approach may diminish ILP unnecessarily, especially in the common case where the load is not dependent on preceding stores. More aggressive uniprocessor implementations <ref> [8, 6, 2] </ref> issue load instructions as soon as their addresses are known, even though the addresses of all previous stores may not be known.
Reference: [9] <author> D. Lilja, D. Marcovitz, and P.-C. Yew. </author> <title> Memory reference behavior and cache performance in a shared memory multiprocessor. </title> <type> Technical Report 836, </type> <institution> CSRD, University of Illinois, Urbana-Champaign, </institution> <month> December </month> <year> 1988. </year>
Reference-contexts: This phenomenon is observed even for parallel programs where misses for read-only shared data is higher with private caches than a shared one. We borrow the technique proposed by <ref> [9] </ref>, snarfing, to mitigate this problem. Our SVC implementation snarfs data on the bus if the corresponding cache set has a free line available. <p> Comparing the same total amounts of storage, the distribution of storage for the SVC produces higher miss rates than for the ARB (perl is an exception). We attribute the increase in miss rates for the SVC to two factors. Firstly, distributing the available storage results in reference spreading <ref> [9] </ref> and replication of data reduces available storage. Secondly, the fine-grain sharing of data between multiscalar tasks causes the latest version of a line to constantly move from one L1 cache to another (migratory data). Such fine-grain communication may increase the number of total misses as well.
Reference: [10] <author> J. S. Liptay. </author> <title> Structural aspects of the system/360 model 85 part II: The cache. </title> <journal> IBM Systems Journal, </journal> <volume> 7(1):1521, </volume> <year> 1968. </year>
Reference-contexts: We mitigate the effects of false sharing by using a technique similar to the sector cache <ref> [10] </ref>. Each line is divided into sub-blocks and the L and S bits are maintained for each sub-block. The sub-block or versioning block size is less than the address block size (storage unit for which an address tag is maintained).
Reference: [11] <author> Kunle Olukotun, Basem A. Nayfeh, Lance Hammond, Ken Wilson, and Kun-Yung Chang. </author> <title> The case for a single-chip multiprocessor. </title> <booktitle> In Proceedings of the 7th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 211, </pages> <month> October 15, </month> <year> 1996. </year>
Reference-contexts: These approaches are aimed at higher levels of ILP and use replicated processing units with hierarchical control for a number of practical engineering reasons [12]. Proposed next generation multiprocessors <ref> [11, 17] </ref> that provide hardware support for dependence speculation use such hierarchical orchestration of the multiple processing units. These highly parallel, hierarchical designs naturally lead to memory address streams with a similar hierarchical structure. <p> The following sections elaborate on a design that uses pointers in each cache line to maintain the VOL. The private cache organization of the SVC makes it a feasible memory system for proposed next generation single chip multiprocessors that execute sequential programs on tightly coupled PUs using automatic parallelization <ref> [11, 17] </ref>. Previously, ambiguous memory dependences limited the range of programs chosen for automatic parallelization.
Reference: [12] <author> Subbarao Palacharla, Norman P. Jouppi, and James E. Smith. </author> <title> Complexity-effective superscalar processors. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 206218, </pages> <month> June 24, </month> <year> 1997. </year>
Reference-contexts: These approaches are aimed at higher levels of ILP and use replicated processing units with hierarchical control for a number of practical engineering reasons <ref> [12] </ref>. Proposed next generation multiprocessors [11, 17] that provide hardware support for dependence speculation use such hierarchical orchestration of the multiple processing units. These highly parallel, hierarchical designs naturally lead to memory address streams with a similar hierarchical structure.
Reference: [13] <author> David A. Patterson and John L. Hennessy. </author> <title> Computer Architecture A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1996. </year>
Reference-contexts: With line sizes greater than a word, false sharing effects are observed <ref> [13] </ref>. In addition to causing higher bus traffic, false sharing leads to more squashes when a store from a task shares a cache line with a load (to a different address) from a later task and they are executed out-of-order.
Reference: [14] <editor> P.Keleher et al. Treadmarks: </editor> <title> Distributed shared memory on standard workstations and operating systems. </title> <booktitle> In Proceedings of Usenix Winter Conference, </booktitle> <pages> pages 115132, </pages> <address> Berkeley, California, 1994. </address> <publisher> Usenix Association. </publisher>
Reference-contexts: 3 that tracks copies of multiple 2 In reality, the store has to be communicated only until the task that has created the next version, if any, of the location. 3 MRMW protocols have been implemented in software by distributed shared memory systems like the Midway [3] and the TreadMarks <ref> [14] </ref>. 5 speculative versions of each memory location. This MRMW protocol uses a version directory that maintains ordered sets for each line, each of which tracks the program order among the multiple speculative versions of a line.
Reference: [15] <author> Gurindar S. Sohi, Scott E. Breach, and T. N. Vijaykumar. </author> <title> Multiscalar processors. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 414425, </pages> <month> June 2224, </month> <year> 1995. </year>
Reference-contexts: The presence of store queues provides a simple form of speculative versioning. However, proposed next generation processor designs use replicated processing units that dispatch and/or issue instructions in a distributed manner. These future approaches partition the instruction stream into 2 tasks <ref> [15] </ref> or traces [18] and use higher level instruction control units to distribute them to the processing units for execution. These approaches are aimed at higher levels of ILP and use replicated processing units with hierarchical control for a number of practical engineering reasons [12].
Reference: [16] <author> Gurindar S. Sohi and Manoj Franklin. </author> <title> High-bandwidth data memory systems for superscalar processors. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 5362, </pages> <month> April 811, </month> <year> 1991. </year>
Reference-contexts: The ARB comprises a fully-associative cache with 256 rows and five stages; a shared data cache of 32KB or 64KB direct-mapped storage in 16-byte lines backs up the ARB. Both loads and stores are non-blocking with 32 MSHRs <ref> [16] </ref> and a 32-entry writeback buffer each in the ARB and the data cache. An MSHR can combine up to 8 accesses to the same line. The data cache has a 32-entry writeback buffer. The MSHRs and the writeback buffer are equally divided among 4 banks of storage.
Reference: [17] <author> J. Gregory Steffan and Todd C. Mowry. </author> <title> The potential for thread-level data speculation in tightly-coupled multiprocessors. </title> <type> Technical Report CSRI-TR-350, </type> <institution> Computer Systems Research Institute, University of Toronto, </institution> <month> February </month> <year> 1997. </year>
Reference-contexts: These approaches are aimed at higher levels of ILP and use replicated processing units with hierarchical control for a number of practical engineering reasons [12]. Proposed next generation multiprocessors <ref> [11, 17] </ref> that provide hardware support for dependence speculation use such hierarchical orchestration of the multiple processing units. These highly parallel, hierarchical designs naturally lead to memory address streams with a similar hierarchical structure. <p> The following sections elaborate on a design that uses pointers in each cache line to maintain the VOL. The private cache organization of the SVC makes it a feasible memory system for proposed next generation single chip multiprocessors that execute sequential programs on tightly coupled PUs using automatic parallelization <ref> [11, 17] </ref>. Previously, ambiguous memory dependences limited the range of programs chosen for automatic parallelization.
Reference: [18] <author> Sriram Vajapeyam and Tulika Mitra. </author> <title> Improving superscalar instruction dispatch and issue by exploiting dynamic code sequences. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 112, </pages> <month> June 24, </month> <year> 1997. </year>
Reference-contexts: The presence of store queues provides a simple form of speculative versioning. However, proposed next generation processor designs use replicated processing units that dispatch and/or issue instructions in a distributed manner. These future approaches partition the instruction stream into 2 tasks [15] or traces <ref> [18] </ref> and use higher level instruction control units to distribute them to the processing units for execution. These approaches are aimed at higher levels of ILP and use replicated processing units with hierarchical control for a number of practical engineering reasons [12].
References-found: 18

