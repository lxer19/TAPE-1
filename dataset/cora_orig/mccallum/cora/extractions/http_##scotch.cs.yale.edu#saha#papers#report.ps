URL: http://scotch.cs.yale.edu/saha/papers/report.ps
Refering-URL: http://scotch.cs.yale.edu/saha/papers/index.html
Root-URL: http://www.cs.yale.edu
Affiliation: Yale University Department of Computer Science  
Abstract: Efficient Runtime Type Passing Bratin Saha Dept. of Computer Science Yale University YALEU/DCS/CS-690 Report May 5th, 1998 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Programs written in various source languages are first fed into a language-specific front end which does parsing, elaboration, type-checking, and pattern-match compilation; the source program is then translated into the FLINT intermediate format. The middle end does conventional dataflow and loop optimizations <ref> [1, 48] </ref>, local and cross-module type specializations, and -calculus-based contractions and reductions [3]; it then produces an optimized version of the FLINT code. <p> TYPED INTERMEDIATE FORMAT 3 * Optimization ready. The compiler middle end performs various kinds of optimizations on the intermediate code. For this reason, the intermediate representation must be compatible with all standard program analysis and transformations <ref> [3, 1] </ref>. The intermediate language should also contain explicit loop (and recursion) construct to support sophisticated loop optimizations. * System-programming friendly. The intermediate language must provide excellent support to low-level system programming such as safe type-cast, dynamic types, and bit-manipulation primitives. <p> Executing the function doit results in three type applications, the Array.sub function, pair, and f. In each iteration, sub and pair are applied to types fffl ff and ff respectively. A clever compiler may do a loop-invariant removal <ref> [1] </ref> to avoid the repeated type construction (e.g., ff fl ff) and application (e.g., pair [ff]). Notice that optimizing type applications such as f [sfls] is much less obvious; f is nested inside pair, and its repeated type applications are not apparent in the doit function. <p> Peyton Jones [38, 35, 37] also described a number of optimizations which have similar spirits but have totally different aims. Appel [3] describes let hoisting in the context of ML. In general, using correctness preserving transformations as a compiler optimization <ref> [1, 3] </ref> is a well established technique and has received quite a bit of attention in the functional programming area. We have proposed a method for minimizing the cost of runtime type passing. <p> For some heavily polymorphic benchmarks like vliw, kb-comp, boyer, the savings are considerable while in the case of monomorphic benchmarks like fft, the gains are negligible. The algorithm presented here is of course based on the idea of common subexpression elimination <ref> [1, 3] </ref> that is done by any standard compiler. The TIL compiler [49] uses an explicit lettype construct in the language to eliminate common type expressions. 3.3.
Reference: [2] <author> A. W. Appel. </author> <title> A runtime system. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 3(4) </volume> <pages> 343-380, </pages> <year> 1990. </year>
Reference-contexts: The runtime system provides support to system-wide garbage collection, foreign-function call interface, and connections to lower-level operating system services. Our current implementation borrows SML/NJ's runtime system <ref> [40, 2, 15] </ref> which runs under all major machine platforms. We plan to extend it to support new services such as dynamic linking and bytecode execution. 1.3 Typed Intermediate Format Using common intermediate languages to share compiler infrastructure is not a new idea. <p> The standard Girard-Reynolds polymorphic calculus F ! is often defined as follows: (kinds) ::= j 1 ! 2 (types) ::= t j 1 ! 2 j 8t :: : j t :: : j 1 <ref> [ 2 ] </ref> (terms) e ::= x j x : :e j @e 1 e 2 j flt :: :e j e [] The calculus contains three syntactic classes: kinds (), types (), and terms (e). Here, kinds classify types, and types classify terms. <p> A higher-order type 1 can be applied to another type 2 , written as 1 <ref> [ 2 ] </ref>. At the term level, in addition to the usual lambda abstraction and application, F ! also support explicit type abstraction and type application (written as flt :: :e and e []). <p> As in F ! , the terms are an explicitly typed -calculus (but in A-normal form) with explicit constructor abstraction and application forms. (kinds) ::= j 1 ! 2 (constructors) ::= t j Int j 1 ! 2 j t :: : j 1 <ref> [ 2 ] </ref> (types) ::= T () j 1 ! 2 j 8t :: : (terms) e ::= i j x j let x = e 1 in e 2 j @x 1 x 2 j f ix [x i : i ; e i ] (values) e v ::= i <p> eliminated. 3.2.1 Formal Description The source language for the algorithm is shown in Fig 3.1 and is the standard predicative variant of the Girard-Reynolds polymorphic -calculus F ! . (kinds) ::= j 1 ! 2 (constructors) ::= t j Int j 1 ! 2 j t :: : j 1 <ref> [ 2 ] </ref> (types) ::= T () j 1 ! 2 j 8t :: : (terms) e ::= i j x j let x = e 1 in e 2 j x : :e j @x 1 x 2 j flt :: :e j x [] of the form H; 4; <p> = (H 1 ; t 1 ; ) I ( 2 ; H 1 ) = (H 2 ; t 2 ; ) t a new typevar I ( 1 ! 2 ; H) = (H [t 7! t 1 ! t 2 ; ]; t; ) S ( 1 <ref> [ 2 ] </ref>) = I ( 1 ; H) = (H 1 ; t 1 ; k 1 ) I ( 2 ; H 1 ) = (H 2 ; t 2 ; k 2 ) t a new typevar I ( 1 [ 2 ]; H) = (H [t 7! <p> ; ]; t; ) S ( 1 <ref> [ 2 ] </ref>) = I ( 1 ; H) = (H 1 ; t 1 ; k 1 ) I ( 2 ; H 1 ) = (H 2 ; t 2 ; k 2 ) t a new typevar I ( 1 [ 2 ]; H) = (H [t 7! t 1 [t 2 ]; k 1 [k 2 ]]; t; k 1 [k 2 ]) S (t 1 :: k 1 :) = 4 (t 1 :: k 1 :) = k 1 ! k 2 t a new typevar I (t <p> operator projects from a sequence of constructors. (kinds) ::= j 1 ! 2 j ( 1 ; : : : ; n ) (constructors) ::= t j Int j Real j 1 ! 2 j t :: : j [ 1 fi : : : fi n ] j 1 <ref> [ 2 ] </ref> j ( 1 ; : : : ; n ) j i The target type and term language is shown in Fig 4.2 and is mostly standard. It has a dedicated type Rtype which is needed to type the runtime representation of the constructors.
Reference: [3] <author> A. W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: The middle end does conventional dataflow and loop optimizations [1, 48], local and cross-module type specializations, and -calculus-based contractions and reductions <ref> [3] </ref>; it then produces an optimized version of the FLINT code. The back end compiles FLINT into machine code through the usual phases such as representation analysis [43] (to compile polymorphism), safe-for-space closure conversion [46] (to compile higher-order functions), register allocation, instruction scheduling, and machine-code generation [8]. <p> TYPED INTERMEDIATE FORMAT 3 * Optimization ready. The compiler middle end performs various kinds of optimizations on the intermediate code. For this reason, the intermediate representation must be compatible with all standard program analysis and transformations <ref> [3, 1] </ref>. The intermediate language should also contain explicit loop (and recursion) construct to support sophisticated loop optimizations. * System-programming friendly. The intermediate language must provide excellent support to low-level system programming such as safe type-cast, dynamic types, and bit-manipulation primitives. <p> First, the middle end performs a series of conventional control and data flow optimizations. All optimizations are type-preserving so the resulting FLINT code will still type-check under the same typing rules. Because FLINT terms are always in the A-normal form, all CPS-based optimizations <ref> [3] </ref> apply to FLINT as well. Apart from the presence of polymorphism and higher-order functions, the resulting FLINT code should be very close to the low-level machine languages. <p> The algorithm exploits the use of compile-time control and data flow information to optimize closure representations. By extensive closure sharing and allocating as many closures in registers as possible, the closure conversion algorithm not only gives good performance but also satisfies the strong safe for space complexity rule <ref> [3] </ref>, thus achieving good asymptotic space usage. 1.5 Conclusions To demonstrate the power of the FLINT language, we have built a new front end that translates the entire SML'97 [26] plus MacQueen-Tofte higher-order modules [24]) into our typed common intermediate format. <p> Johnsson [17] describes different forms of lambda lifting and the pros and cons of each. Peyton Jones [38, 35, 37] also described a number of optimizations which have similar spirits but have totally different aims. Appel <ref> [3] </ref> describes let hoisting in the context of ML. In general, using correctness preserving transformations as a compiler optimization [1, 3] is a well established technique and has received quite a bit of attention in the functional programming area. <p> Peyton Jones [38, 35, 37] also described a number of optimizations which have similar spirits but have totally different aims. Appel [3] describes let hoisting in the context of ML. In general, using correctness preserving transformations as a compiler optimization <ref> [1, 3] </ref> is a well established technique and has received quite a bit of attention in the functional programming area. We have proposed a method for minimizing the cost of runtime type passing. <p> For some heavily polymorphic benchmarks like vliw, kb-comp, boyer, the savings are considerable while in the case of monomorphic benchmarks like fft, the gains are negligible. The algorithm presented here is of course based on the idea of common subexpression elimination <ref> [1, 3] </ref> that is done by any standard compiler. The TIL compiler [49] uses an explicit lettype construct in the language to eliminate common type expressions. 3.3.
Reference: [4] <author> M. Blume. </author> <title> A compilation manager for SML/NJ. as part of SML/NJ User's Guide, </title> <year> 1995. </year>
Reference-contexts: With the use of suspension terms, type application is always done on a by-need basis, and once it is done, the result will be memoized for future use. Our preliminary measurements have shown that on heavily functorized applications such as SML/NJ Compilation Manager <ref> [4] </ref>, our optimized implementation is an order-of-magnitude faster (in compilation time) than naive implementations. Representing type variables as de Bruijn indices does have its drawback. For example, the type-based manipulation becomes much harder to program.
Reference: [5] <author> N. de Bruijn. </author> <title> A survey of the project AUTOMATH. In To H. </title> <editor> B. </editor> <booktitle> Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism, </booktitle> <pages> pages 579-606. </pages> <note> Edited by J. </note> <editor> P. Seldin and J. R. Hindley, </editor> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: Naive implementation of these operations would lead to duplicate copying, redundant traversal, and extremely slow compilation. We use the following techniques to optimize the representations of kinds, constructors, and types ( see all type variables as de Bruijn indices <ref> [5] </ref>. Under de Bruijn notations, all constructors and types have unique representations. We then hash-cons all the kinds, constructors, and types into three separate hash-tables. Each kind (tkind), constructor (tyc), or type (lty) is represented as an internal hash cell (or icell). Each icell is a reference cell that 1.4. <p> The algorithm is implemented in a single pass by a bottom up traversal of the syntax tree. An earlier stage of the compiler performs type specialization. This phase also checks for duplicate type applications and performs "common type-application elimination". We use de Bruijn notations <ref> [5, 30] </ref> to represent types. But the type information to be manipulated is kept to a minimum by the algorithm.
Reference: [6] <author> J. Dean, G. DeFouw, D. Grove, V. Litvinov, and C. Chambers. </author> <title> Vortex: An optimizing compiler for object-oriented languages. </title> <booktitle> In Proc. ACM SIGPLAN '96 Conf. on Object-Oriented Programming Systems, Languages, and applications, </booktitle> <pages> pages 83-100, </pages> <address> New York, </address> <month> October </month> <year> 1996. </year> <note> ACM Press. </note>
Reference-contexts: We plan to extend it to support new services such as dynamic linking and bytecode execution. 1.3 Typed Intermediate Format Using common intermediate languages to share compiler infrastructure is not a new idea. Many existing compilers, such as GNU GCC, Stanford's SUIF [10], and U. Washington's Vortex <ref> [6] </ref>, all use some kind of shared intermediate format for multiple source languages. In addition, the C programming language has been used as the de facto standard target language for a long time.
Reference: [7] <author> C. Flanagan, A. Sabry, B. F. Duba, and M. Felleisen. </author> <title> The essence of compiling with continuations. </title> <booktitle> In Proc. ACM SIGPLAN '93 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 237-247, </pages> <address> New York, June 1993. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Throughout the paper we take a few liberties with the syntax: we allow ourselves infix operators, multiple definitions in a single let expression to abbreviate a sequence of nested let expressions, and term applications that are at times not in A-Normal form <ref> [7] </ref>. We also use indentation to indicate the program nesting structure. 2.2.2 Informal description Before we move on to the formal description of the algorithm, we will present the basic ideas informally. <p> Rules (exp) and (app) are just the identity transformations. Since the IL is in the A-normal form <ref> [7] </ref>, no type applications can occur in these terms. Rule (fn) deals with abstractions. We first translate the body of the abstraction. H now contains the type applications and the type functions that were in e and is returned as the header from the translation. <p> We will formalise these constraints in terms of the FLINT calculus later in this section. The core language of FLINT is based upon a predicative variant of the Girard-Reynolds polymorphic - calculus F ! [9, 41], with the term language written in A-normal form <ref> [7] </ref>. It contains the following four syntactic 28 CHAPTER 2. OPTIMAL TYPE LIFTING classes: kinds (), constructors (), types (), terms (e), as shown in Figure 2.7. Here, kinds classify constructors, and types classify terms. Constructors of kind name monotypes.
Reference: [8] <author> L. George, F. Guillaume, and J. Reppy. </author> <title> A portable and optimizing backend for the SML/NJ compiler. </title> <booktitle> In Proceedings of the 1994 International Conference on Compiler Construction, </booktitle> <pages> pages 83-97. </pages> <publisher> Springer-Verlag, </publisher> <month> April </month> <year> 1994. </year>
Reference-contexts: The back end compiles FLINT into machine code through the usual phases such as representation analysis [43] (to compile polymorphism), safe-for-space closure conversion [46] (to compile higher-order functions), register allocation, instruction scheduling, and machine-code generation <ref> [8] </ref>. All the compilation stages are deliberately made independent of each other so that they may be pieced together in different ways for different languages. The runtime system provides support to system-wide garbage collection, foreign-function call interface, and connections to lower-level operating system services. <p> After the optimizations, the back end uses flexible representation analysis [43] to compile polymorphism and safe-for-space closure conversion to compile higher-order functions [46]; it then does the standard register allocation, instruction scheduling, and machine code generation <ref> [8] </ref>. In the rest of this section, we glance at several important techniques used in our compiler back end. 1.4.1 Type Specialization Because polymorphic functions are often more expensive than monomorphic functions, the middle end of our compiler performs several rounds of type specialization to decrease the degree of polymorphism.
Reference: [9] <author> J. Y. Girard. </author> <title> Interpretation Fonctionnelle et Elimination des Coupures dans l'Arithmetique d'Ordre Superieur. </title> <type> PhD thesis, </type> <institution> University of Paris VII, </institution> <year> 1972. </year>
Reference-contexts: It should be high-level enough to express polymorphism and higher-order functions but low-level enough to support all standard optimizations. 1.3.2 Background The core language of FLINT is a predicative variant of the Girard-Reynolds polymorphic -calculus F ! <ref> [9, 41] </ref>, with the term language written in the A-normal form [42]. In the following, we first give a introduction about F ! , and then formally define the Core-FLINT language. <p> tyc = tycI icell (* hash-consed tycI cell *) and lty = ltyI icell (* hash-consed ltyI cell *) and tycEnv = ...... (* tyc environment *) Chapter 2 Optimal Type Lifting 2.1 Introduction Modern compilers for ML-like polymorphic languages [25, 26] usually use variants of the Girard-Reynolds polymorphic -calculus <ref> [9, 41] </ref> as their intermediate languages (ILs). Implementation of these ILs often involves passing types explicitly as run-time parameters [50, 49, 44]: each polymorphic type variable gets instantiated to the actual type through run-time type application. <p> We will formalise these constraints in terms of the FLINT calculus later in this section. The core language of FLINT is based upon a predicative variant of the Girard-Reynolds polymorphic - calculus F ! <ref> [9, 41] </ref>, with the term language written in A-normal form [7]. It contains the following four syntactic 28 CHAPTER 2. OPTIMAL TYPE LIFTING classes: kinds (), constructors (), types (), terms (e), as shown in Figure 2.7. Here, kinds classify constructors, and types classify terms. Constructors of kind name monotypes.
Reference: [10] <author> M. Hall, J. Anderson, S. Amarasinghe, B. Murphy, S. Liao, E. Bugnion, and M. Lam. </author> <title> Maximizing multiprocessor performance with the SUIF compiler. </title> <booktitle> IEEE Computer, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: We plan to extend it to support new services such as dynamic linking and bytecode execution. 1.3 Typed Intermediate Format Using common intermediate languages to share compiler infrastructure is not a new idea. Many existing compilers, such as GNU GCC, Stanford's SUIF <ref> [10] </ref>, and U. Washington's Vortex [6], all use some kind of shared intermediate format for multiple source languages. In addition, the C programming language has been used as the de facto standard target language for a long time.
Reference: [11] <author> R. Harper and J. C. Mitchell. </author> <title> On the type structure of Standard ML. </title> <journal> ACM Trans. Prog. Lang. Syst., </journal> <volume> 15(2) </volume> <pages> 211-252, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Translation from the Core-ML-like (or Core-Haskell-like) language to FLINT is same as the standard embedding of ML into F ! <ref> [11] </ref>; other features such as ML datatypes are translated into FLINT type constructors. Compilation from SML higher-order modules to FLINT is quite a challenge because higher-order modules involve the use of dependent types which, in general, cannot be expressed as F ! -like polymorphism. <p> We provide the implementation results at the end of this chapter. 2.2 The Type Lifting Algorithm This section presents our optimal type lifting algorithm. We use an explicitly typed variant of the Core-ML calculus <ref> [11] </ref>, shown in Figure 2.1, as the source and target languages. The type lifting algorithm (Fig. 2.2) is expressed as a type-directed program transformation that lifts all type applications to the top-level. <p> We illustrate the algorithm on an example program and then prove the type correctness and the semantic correctness of our translation. 2.2.1 The language We use an explicitly typed variant of the Core-ML calculus <ref> [11] </ref> as our source and target languages. The syntax is shown in Fig 2.1. <p> Mark P. Jones [18] has worked on the related problem of optimising dictionary passing in the implementation of type classes. We elaborated on this in Section 2.3. In their study of the type theory of Standard ML, Harper and Mitchell <ref> [11] </ref> argued that an explicitly typed interpretation of ML polymorphism has better semantic properties and scales more easily to cover the full language. The idea of passing types to polymorphic functions is exploited by Morrison et al. [29] in the implementation of Napier.
Reference: [12] <author> R. Harper, J. C. Mitchell, and E. Moggi. </author> <title> Higher-order modules and the phase distinction. </title> <booktitle> In Seventeenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 341-344, </pages> <address> New York, Jan 1990. </address> <publisher> ACM Press. </publisher>
Reference-contexts: For example, the front end for ML can translate higher-order modules into the Core-FLINT-like calculus <ref> [45, 12] </ref> in a type-preserving way, thus completely eliminating the need of module constructs from the intermediate language. Similarly, type classes in Haskell can also be embedded into F ! through explicit dictionary passing. 1.3.
Reference: [13] <author> R. Harper and G. Morrisett. </author> <title> Compiling polymorphism using intensional type analysis. </title> <booktitle> In Twenty-second Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 130-141, </pages> <address> New York, Jan 1995. </address> <publisher> ACM Press. </publisher>
Reference-contexts: This complicates the semantics and makes the calculus impredicative. Following Harper and Morrisett <ref> [13] </ref>, we split the type hierarchy into two levels: a constructor level characterizes the monomorphic types (and 4 CHAPTER 1. <p> The term formation rules are in the form of ; ` e : where 4 is a kind environment mapping type variables to kinds, and is the type environment mapping term variables to types. Harper and Morrisett <ref> [13, 28] </ref> have shown that type checking for predicative F ! -like calculus is decidable, and furthermore, its typing rules are consistent with the standard call-by-value operational semantics. 1.3.4 The Full Language In order to make FLINT as simple as possible, we let the front end deal with many higher-level language <p> Maintaining type information in this manner helps in ensuring the correctness of a compiler; more importantly, it also enables many interesting optimizations and applications. For example, both pretty-printing and debugging on polymorphic values require complete type information at runtime in order to work correctly. Intensional type analysis <ref> [13, 49, 43] </ref>, which is used by some compilers [49, 44] to support efficient data representation, also requires the propagation of type information into the target code. Finally, run-time type information is crucial to the implementation of tag-less garbage collection [50], pickling, and type dynamic [22]. <p> The work of Ohori on compiling record operations [33] is similarly based on a type passing interpretation of polymorphism. Jones [19] has proposed evidence passing|a general framework for passing data derived from types to "qualified" polymorphic operations. Harper and Morisett <ref> [13] </ref> proposed an alternative approach for compiling polymorphism where types are passed as arguments to polymorphic routines in order to determine the representation of an object.
Reference: [14] <author> P. Hudak, S. P. Jones, and P. W. et al. </author> <title> Report on the programming language Haskell, a non-strict, purely functional language version 1.2. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(5), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: We will briefly compare our approach with his optimisations on dictionary passing we will not however talk about eliminating dictionaries through partial evaluation [20]. Since the type systems and the implementation of dictionaries differs slightly in Haskell and Gofer, we will consider the two separately. Haskell <ref> [14] </ref> performs context reduction and simplifies the set of constraints in a type.
Reference: [15] <author> L. Huelsbergen. </author> <title> A portable C interface for Standard ML of New Jersey. </title> <type> Technical memorandum, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NJ, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: The runtime system provides support to system-wide garbage collection, foreign-function call interface, and connections to lower-level operating system services. Our current implementation borrows SML/NJ's runtime system <ref> [40, 2, 15] </ref> which runs under all major machine platforms. We plan to extend it to support new services such as dynamic linking and bytecode execution. 1.3 Typed Intermediate Format Using common intermediate languages to share compiler infrastructure is not a new idea.
Reference: [16] <author> R. Hughes. </author> <title> The design and implementation of programming languages. </title> <type> PhD thesis, </type> <institution> Programming Research Group, Oxford University, Oxford, UK, </institution> <year> 1983. </year>
Reference-contexts: The lifting of type applications is similar in spirit to the hoisting of loop invariant expressions outside a loop. It could be considered as a special case of a fully lazy transformation <ref> [16, 37] </ref> with the maximal free subexpressions restricted to be type computations. However, the fully-lazy transformation as described in Peyton Jones [37] will not lift all type applications to the top level. <p> Many modern compilers like the FLINT/ML compiler [44], TIL [49] and the Glasgow Haskell compiler [34] use an explicitly typed language as the intermediate language for the compilation. 2.7. RELATED WORK AND CONCLUSIONS 33 Lambda lifting and full laziness are part of the folklore of functional programming. Hughes <ref> [16] </ref> showed that by doing lambda lifting in a particular way, full laziness can be preserved. Johnsson [17] describes different forms of lambda lifting and the pros and cons of each.
Reference: [17] <author> T. Johnsson. </author> <title> Lambda Lifting: Transforming Programs to Recursive Equations. </title> <booktitle> In The Second International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 190-203, </pages> <address> New York, </address> <month> September </month> <year> 1985. </year> <note> Springer-Verlag. </note>
Reference-contexts: One is the lifting of type applications and the other is the lifting of polymorphic function definitions. At first glance, the lifting of function definitions may seem 2.3. COMPARISON WITH JONES' AND MINAMIDE'S OPTIMISATIONS 19 similar to lambda lifting <ref> [17] </ref>. However the lifting in the two cases is different. Lambda lifting converts a program with local function definitions into a program consisting only of global function definitions whereas the lifting shown here preserves the nesting structure of the program. <p> RELATED WORK AND CONCLUSIONS 33 Lambda lifting and full laziness are part of the folklore of functional programming. Hughes [16] showed that by doing lambda lifting in a particular way, full laziness can be preserved. Johnsson <ref> [17] </ref> describes different forms of lambda lifting and the pros and cons of each. Peyton Jones [38, 35, 37] also described a number of optimizations which have similar spirits but have totally different aims. Appel [3] describes let hoisting in the context of ML.
Reference: [18] <author> M. P. Jones. </author> <title> Qualified Types: Theory and Practice. </title> <type> PhD thesis, </type> <institution> Oxford University Computing Laboratory, Oxford, </institution> <month> july </month> <year> 1992. </year> <note> Technical Monograph PRG-106. </note>
Reference-contexts: Finally, Minamide's algorithm deals only with the Core-ML calculus and does not mention how his method may be extended to ML-style modules. In our case though, we have implemented our algorithm on the entire SML'97 language with higher-order modules. Jones <ref> [18] </ref> has also worked on a similar problem related to type classes in the implementation of Haskell and Gofer. Type classes in these languages are implemented by dictionary passing and if done naively can lead to the same dictionaries being created repeatedly. <p> In Gofer <ref> [18] </ref>, however, instance declarations are not used to simplify the context. Therefore the type of f in the above example would be Eq [a] =&gt; a ! a ! Bool. Jones' optimisation of dictionary parameters can now be performed even in the presence of separately compiled modules. <p> He proposes a refinement of Tolmach's method to eliminate runtime construction of type parameters. We have elaborated on this difference in Section 2.3. The speedups obtained in our method are comparable to the ones reported in his paper. Mark P. Jones <ref> [18] </ref> has worked on the related problem of optimising dictionary passing in the implementation of type classes. We elaborated on this in Section 2.3.
Reference: [19] <author> M. P. Jones. </author> <title> A theory of qualified types. </title> <booktitle> In The 4th European Symposium on Programming, </booktitle> <pages> pages 287-306, </pages> <address> Berlin, </address> <month> February </month> <year> 1992. </year> <title> Spinger-Verlag. </title> <type> 51 52 BIBLIOGRAPHY </type>
Reference-contexts: However, the disadvantage is that he can no longer type-check his transformation with the existing type system; instead, he has to make use of an auxiliary type system based on the qualified type system of Jones <ref> [19] </ref> and the implementation calculus for the compilation of polymorphic 20 CHAPTER 2. OPTIMAL TYPE LIFTING records of Ohori [33]. Our algorithm on the other hand is a source-to-source transformation whose output can be type-checked with the type-checker for the source program. <p> The idea of passing types to polymorphic functions is exploited by Morrison et al. [29] in the implementation of Napier. The work of Ohori on compiling record operations [33] is similarly based on a type passing interpretation of polymorphism. Jones <ref> [19] </ref> has proposed evidence passing|a general framework for passing data derived from types to "qualified" polymorphic operations. Harper and Morisett [13] proposed an alternative approach for compiling polymorphism where types are passed as arguments to polymorphic routines in order to determine the representation of an object.
Reference: [20] <author> M. P. Jones. </author> <title> Dictionary-free overloading by partial evaluation. </title> <booktitle> In Proceedings of the ACM SIGPLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 107-117. </pages> <institution> University of Melbourne TR 94/9, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: The operation is then performed by selecting out the appropriate functions from the dictionary. We will briefly compare our approach with his optimisations on dictionary passing we will not however talk about eliminating dictionaries through partial evaluation <ref> [20] </ref>. Since the type systems and the implementation of dictionaries differs slightly in Haskell and Gofer, we will consider the two separately. Haskell [14] performs context reduction and simplifies the set of constraints in a type.
Reference: [21] <author> X. Leroy. </author> <title> Unboxed objects and polymorphic typing. </title> <booktitle> In Nineteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 177-188, </pages> <address> New York, </address> <month> Jan </month> <year> 1992. </year> <note> ACM Press. Longer version available as INRIA Tech Report. </note>
Reference-contexts: Finally, type information has proven invaluable for efficient compilation of statically typed languages <ref> [21, 47, 49] </ref>; types are also useful for debugging compilers and proving properties of programs. 1.3.1 Rationale The current FLINT language is designed based on the following principles: * Strong and explicit typing. ML-like languages often have very tricky type inference problems. <p> Under flexible representation analysis, recursive and mutable data objects can use unboxed representations without incurring expensive runtime cost on heavily polymorphic code. In contrast, the coercion-based approach used in Gallium <ref> [21] </ref> and SML/NJ [47] does not support unboxed representations on recursive and mutable objects; the type-passing approach used in TIL [49] does handle all data objects, but it involves heavy-weight runtime type analysis and code manipulations. 1.4.4 Closure Conversion After the polymorphism is eliminated, we use an efficient and safe-for-space closure <p> The boxing interpretation of polymorphism which applies the appropriate coercions based on the type of an object was studied by Leroy <ref> [21] </ref> and Shao [43]. Many modern compilers like the FLINT/ML compiler [44], TIL [49] and the Glasgow Haskell compiler [34] use an explicitly typed language as the intermediate language for the compilation. 2.7.
Reference: [22] <author> X. Leroy and M. Mauny. </author> <title> Dynamics in ML. </title> <booktitle> In The Fifth International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 406-426, </pages> <address> New York, </address> <month> August </month> <year> 1991. </year> <note> Springer-Verlag. </note>
Reference-contexts: Intensional type analysis [13, 49, 43], which is used by some compilers [49, 44] to support efficient data representation, also requires the propagation of type information into the target code. Finally, run-time type information is crucial to the implementation of tag-less garbage collection [50], pickling, and type dynamic <ref> [22] </ref>. However, the added information available at run time as a result of type passing does not come for free. Depending on the sophistication of the type representation, run-time type passing can add a significant overhead to the time and space usage of a program.
Reference: [23] <author> T. Lindholm and F. Yellin. </author> <title> The Java Virtual Machine Specification. </title> <publisher> Addison-Wesley, </publisher> <year> 1997. </year>
Reference: [24] <author> D. MacQueen and M. Tofte. </author> <title> A semantics for higher order functors. </title> <booktitle> In The 5th European Symposium on Programming, </booktitle> <pages> pages 409-423, </pages> <address> Berlin, </address> <month> April </month> <year> 1994. </year> <pages> Spinger-Verlag. </pages>
Reference-contexts: The product kind makes it possible to define type functions that takes a sequence of type constructors as argument and returns another sequence as the result. This is useful to express the parameterized modules such as ML higher-order functors <ref> [24] </ref>. <p> algorithm not only gives good performance but also satisfies the strong safe for space complexity rule [3], thus achieving good asymptotic space usage. 1.5 Conclusions To demonstrate the power of the FLINT language, we have built a new front end that translates the entire SML'97 [26] plus MacQueen-Tofte higher-order modules <ref> [24] </ref>) into our typed common intermediate format. This new front end and the FLINT middle end have been incorporated and released as part of the Standard ML of New Jersey compiler since version 109.24 (January 9, 1997).
Reference: [25] <author> R. Milner, M. Tofte, and R. Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: tkind = tkindI icell (* hash-consed tkindI cell *) and tyc = tycI icell (* hash-consed tycI cell *) and lty = ltyI icell (* hash-consed ltyI cell *) and tycEnv = ...... (* tyc environment *) Chapter 2 Optimal Type Lifting 2.1 Introduction Modern compilers for ML-like polymorphic languages <ref> [25, 26] </ref> usually use variants of the Girard-Reynolds polymorphic -calculus [9, 41] as their intermediate languages (ILs). Implementation of these ILs often involves passing types explicitly as run-time parameters [50, 49, 44]: each polymorphic type variable gets instantiated to the actual type through run-time type application. <p> The tapp rule also assumes that the type application is not curried and therefore the newly introduced variable v (denoting the lifted type application) is monomorphic and is not further type applied. Finally, following SML <ref> [26, 25] </ref>, polymorphic functions are not recursive. 2 This restriction is crucial to proving that all type applications can be lifted to the top level.
Reference: [26] <author> R. Milner, M. Tofte, R. Harper, and D. MacQueen. </author> <title> The Definition of Standard ML (Revised). </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1997. </year>
Reference-contexts: as possible, the closure conversion algorithm not only gives good performance but also satisfies the strong safe for space complexity rule [3], thus achieving good asymptotic space usage. 1.5 Conclusions To demonstrate the power of the FLINT language, we have built a new front end that translates the entire SML'97 <ref> [26] </ref> plus MacQueen-Tofte higher-order modules [24]) into our typed common intermediate format. This new front end and the FLINT middle end have been incorporated and released as part of the Standard ML of New Jersey compiler since version 109.24 (January 9, 1997). <p> tkind = tkindI icell (* hash-consed tkindI cell *) and tyc = tycI icell (* hash-consed tycI cell *) and lty = ltyI icell (* hash-consed ltyI cell *) and tycEnv = ...... (* tyc environment *) Chapter 2 Optimal Type Lifting 2.1 Introduction Modern compilers for ML-like polymorphic languages <ref> [25, 26] </ref> usually use variants of the Girard-Reynolds polymorphic -calculus [9, 41] as their intermediate languages (ILs). Implementation of these ILs often involves passing types explicitly as run-time parameters [50, 49, 44]: each polymorphic type variable gets instantiated to the actual type through run-time type application. <p> The tapp rule also assumes that the type application is not curried and therefore the newly introduced variable v (denoting the lifted type application) is monomorphic and is not further type applied. Finally, following SML <ref> [26, 25] </ref>, polymorphic functions are not recursive. 2 This restriction is crucial to proving that all type applications can be lifted to the top level.
Reference: [27] <author> Y. Minamide. </author> <title> Full lifting of type parameters. </title> <type> Technical report, </type> <institution> RIMS, Kyoto University, </institution> <year> 1997. </year>
Reference-contexts: For example, Tolmach [50] implemented a tag-free garbage collector via explicit type passing; he reported that the memory allocated for type information sometimes exceeded the memory saved by the tag-free approach. Clearly, it is desirable to optimize the run-time type passing in polymorphic code <ref> [27] </ref>. In fact, a better goal would be to guarantee that explicit type passing never blows up the execution cost of a program. Let's consider the following sample code we took some liberties with the syntax by using an explicitly typed variant of the Core-ML. <p> the beginning of this subsection. flfffifl. let u = fi*fl let let u 1 = f [t 1 *ff] y 2 = flt 3 . in x 3 . u 2 (x 3 ) ... let u 3 = y 2 [fl*t 5 ] in y 3 [u]x 1 Minamide <ref> [27] </ref> has also worked on the same problem but has used an entirely different approach from ours. He lifts the construction of type parameters from within a polymorphic function to the call sites of the function. <p> Type lifting does not obviate this and hence the speedup is negligible. 2.7 Related Work and Conclusions Tolmach [50] has worked on a similar problem and proposed a method based on the lazy substitution on types. He used the method in the implementation of the tag-free garbage collector. Minamide <ref> [27] </ref> has also attacked the same problem but has used an entirely different approach from ours. He proposes a refinement of Tolmach's method to eliminate runtime construction of type parameters. We have elaborated on this difference in Section 2.3.
Reference: [28] <author> G. Morrisett. </author> <title> Compiling with Types. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> December </month> <year> 1995. </year> <note> Tech Report CMU-CS-95-226. </note>
Reference-contexts: The term formation rules are in the form of ; ` e : where 4 is a kind environment mapping type variables to kinds, and is the type environment mapping term variables to types. Harper and Morrisett <ref> [13, 28] </ref> have shown that type checking for predicative F ! -like calculus is decidable, and furthermore, its typing rules are consistent with the standard call-by-value operational semantics. 1.3.4 The Full Language In order to make FLINT as simple as possible, we let the front end deal with many higher-level language
Reference: [29] <author> R. Morrison, A. Dearle, R. C. H. Connor, and A. L. Brown. </author> <title> An ad hoc approach to the implementation of polymor-phism. </title> <journal> ACM Trans. Prog. Lang. Syst., </journal> <volume> 13(3), </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: The idea of passing types to polymorphic functions is exploited by Morrison et al. <ref> [29] </ref> in the implementation of Napier. The work of Ohori on compiling record operations [33] is similarly based on a type passing interpretation of polymorphism. Jones [19] has proposed evidence passing|a general framework for passing data derived from types to "qualified" polymorphic operations.
Reference: [30] <author> G. Nadathur. </author> <title> A notation for lambda terms II: Refinements and applications. </title> <type> Technical Report CS-1994-01, </type> <institution> Duke University, Durham, NC, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: Finally, to make type reduction lazy, we use Nadathur's suspension notations <ref> [30, 31] </ref> to represent the intermediate result of unevaluated type applications. Intuitively, a type suspension such as LT_ENV (t; i; j; e) is a quadruple consisting of a term t with two indices and an environment. <p> The algorithm is implemented in a single pass by a bottom up traversal of the syntax tree. An earlier stage of the compiler performs type specialization. This phase also checks for duplicate type applications and performs "common type-application elimination". We use de Bruijn notations <ref> [5, 30] </ref> to represent types. But the type information to be manipulated is kept to a minimum by the algorithm.
Reference: [31] <author> G. Nadathur and D. S. Wilson. </author> <title> A representation of lambda terms suitable for operations on their intensions. </title> <booktitle> In 1990 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 341-348, </pages> <address> New York, June 1990. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Finally, to make type reduction lazy, we use Nadathur's suspension notations <ref> [30, 31] </ref> to represent the intermediate result of unevaluated type applications. Intuitively, a type suspension such as LT_ENV (t; i; j; e) is a quadruple consisting of a term t with two indices and an environment. <p> The first index i indicates an embedding level with respect to which variable references have been determined within the term, and the second index j indicates a new embedding level <ref> [31] </ref>. The environment e determines the bindings for the type variables. SML datatype definitions.
Reference: [32] <author> G. Necula. </author> <title> Proof-carrying code. </title> <booktitle> In Twenty-Fourth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <address> New York, Jan 1997. </address> <publisher> ACM Press. </publisher>
Reference: [33] <author> A. Ohori. </author> <title> A compilation method for ML-style polymorphic record calculi. </title> <booktitle> In Nineteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <address> New York, Jan 1992. </address> <publisher> ACM Press. </publisher>
Reference-contexts: OPTIMAL TYPE LIFTING records of Ohori <ref> [33] </ref>. Our algorithm on the other hand is a source-to-source transformation whose output can be type-checked with the type-checker for the source program. Finally, Minamide's algorithm deals only with the Core-ML calculus and does not mention how his method may be extended to ML-style modules. <p> The idea of passing types to polymorphic functions is exploited by Morrison et al. [29] in the implementation of Napier. The work of Ohori on compiling record operations <ref> [33] </ref> is similarly based on a type passing interpretation of polymorphism. Jones [19] has proposed evidence passing|a general framework for passing data derived from types to "qualified" polymorphic operations.
Reference: [34] <author> S. Peyton Jones. </author> <title> Implementing lazy functional languages on stock hardware: </title> <journal> the Spineless Tagless G-machine. Journal of Functional Programming, </journal> <volume> 2(2) </volume> <pages> 127-202, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: The boxing interpretation of polymorphism which applies the appropriate coercions based on the type of an object was studied by Leroy [21] and Shao [43]. Many modern compilers like the FLINT/ML compiler [44], TIL [49] and the Glasgow Haskell compiler <ref> [34] </ref> use an explicitly typed language as the intermediate language for the compilation. 2.7. RELATED WORK AND CONCLUSIONS 33 Lambda lifting and full laziness are part of the folklore of functional programming. Hughes [16] showed that by doing lambda lifting in a particular way, full laziness can be preserved.
Reference: [35] <author> S. Peyton Jones. </author> <title> Compiling haskell by program transformation: a report from trenches. </title> <booktitle> In Proceedings of the European Symposium on Programming, </booktitle> <address> Linkoping, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Hughes [16] showed that by doing lambda lifting in a particular way, full laziness can be preserved. Johnsson [17] describes different forms of lambda lifting and the pros and cons of each. Peyton Jones <ref> [38, 35, 37] </ref> also described a number of optimizations which have similar spirits but have totally different aims. Appel [3] describes let hoisting in the context of ML.
Reference: [36] <author> S. Peyton Jones and J. Launchbury. </author> <title> Unboxed values as first class citizens in a non-strict functional language. </title> <booktitle> In The Fifth International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 636-666, </pages> <address> New York, </address> <month> August </month> <year> 1991. </year> <note> ACM Press. </note>
Reference: [37] <author> S. Peyton Jones and D. Lester. </author> <title> A modular fully-lazy lambda lifter in haskell. </title> <journal> Software Practice and Experience, </journal> <volume> 21 </volume> <pages> 479-506, </pages> <year> 1991. </year>
Reference-contexts: The lifting of type applications is similar in spirit to the hoisting of loop invariant expressions outside a loop. It could be considered as a special case of a fully lazy transformation <ref> [16, 37] </ref> with the maximal free subexpressions restricted to be type computations. However, the fully-lazy transformation as described in Peyton Jones [37] will not lift all type applications to the top level. <p> It could be considered as a special case of a fully lazy transformation [16, 37] with the maximal free subexpressions restricted to be type computations. However, the fully-lazy transformation as described in Peyton Jones <ref> [37] </ref> will not lift all type applications to the top level. Specifically, type applications of a polymorphic function that is defined inside other functions will not be lifted to the top level. Our algorithm though is guaranteed to lift all type applications to depth zero. <p> Hughes [16] showed that by doing lambda lifting in a particular way, full laziness can be preserved. Johnsson [17] describes different forms of lambda lifting and the pros and cons of each. Peyton Jones <ref> [38, 35, 37] </ref> also described a number of optimizations which have similar spirits but have totally different aims. Appel [3] describes let hoisting in the context of ML.
Reference: [38] <author> S. Peyton Jones, W. Partain, and A. Santos. Let-floating: </author> <title> moving bindings to give faster programs. </title> <booktitle> In Proc. International Conference on Functional Programming (ICFP'96), </booktitle> <address> New York, June 1996. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Hughes [16] showed that by doing lambda lifting in a particular way, full laziness can be preserved. Johnsson [17] describes different forms of lambda lifting and the pros and cons of each. Peyton Jones <ref> [38, 35, 37] </ref> also described a number of optimizations which have similar spirits but have totally different aims. Appel [3] describes let hoisting in the context of ML.
Reference: [39] <author> J. H. Reppy. </author> <title> CML: A higher-order concurrent language. </title> <booktitle> In Proc. ACM SIGPLAN '91 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 293-305. </pages> <publisher> ACM Press, </publisher> <year> 1991. </year>
Reference-contexts: also includes primitives such as N-bit integers (trapping or non-trapping), N-bit words, N-bit characters (ascii or unicode), N-bit floating-point numbers, strings, boolean types, boxed reference cells, array, packed arrays, vectors, packed vectors, mono arrays and mono vectors, ML-like immutable records (nested or flat), first-class continuations, control continuations (used by CML <ref> [39] </ref>), suspensions (or thunks, to support lazy evaluations). 1.3.5 Implementations One challenge in implementing the FLINT intermediate language is to represent constructors and types compactly and efficiently. Type-based analysis often involve operations such as type application, normalization, and equality test.
Reference: [40] <author> J. H. Reppy. </author> <title> A high-performance garbage collector for Standard ML. </title> <type> Technical memorandum, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NJ, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: The runtime system provides support to system-wide garbage collection, foreign-function call interface, and connections to lower-level operating system services. Our current implementation borrows SML/NJ's runtime system <ref> [40, 2, 15] </ref> which runs under all major machine platforms. We plan to extend it to support new services such as dynamic linking and bytecode execution. 1.3 Typed Intermediate Format Using common intermediate languages to share compiler infrastructure is not a new idea.
Reference: [41] <author> J. C. Reynolds. </author> <title> Towards a theory of type structure. </title> <booktitle> In Proceedings, Colloque sur la Programmation, Lecture Notes in Computer Science, </booktitle> <volume> volume 19, </volume> <pages> pages 408-425. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1974. </year>
Reference-contexts: It should be high-level enough to express polymorphism and higher-order functions but low-level enough to support all standard optimizations. 1.3.2 Background The core language of FLINT is a predicative variant of the Girard-Reynolds polymorphic -calculus F ! <ref> [9, 41] </ref>, with the term language written in the A-normal form [42]. In the following, we first give a introduction about F ! , and then formally define the Core-FLINT language. <p> tyc = tycI icell (* hash-consed tycI cell *) and lty = ltyI icell (* hash-consed ltyI cell *) and tycEnv = ...... (* tyc environment *) Chapter 2 Optimal Type Lifting 2.1 Introduction Modern compilers for ML-like polymorphic languages [25, 26] usually use variants of the Girard-Reynolds polymorphic -calculus <ref> [9, 41] </ref> as their intermediate languages (ILs). Implementation of these ILs often involves passing types explicitly as run-time parameters [50, 49, 44]: each polymorphic type variable gets instantiated to the actual type through run-time type application. <p> We will formalise these constraints in terms of the FLINT calculus later in this section. The core language of FLINT is based upon a predicative variant of the Girard-Reynolds polymorphic - calculus F ! <ref> [9, 41] </ref>, with the term language written in A-normal form [7]. It contains the following four syntactic 28 CHAPTER 2. OPTIMAL TYPE LIFTING classes: kinds (), constructors (), types (), terms (e), as shown in Figure 2.7. Here, kinds classify constructors, and types classify terms. Constructors of kind name monotypes.
Reference: [42] <author> A. Sabry and P. Wadler. </author> <title> A reflection on call-by-value. </title> <booktitle> In Proc. 1996 ACM SIGPLAN International Conference on Functional Programming (ICFP'96), </booktitle> <pages> pages 13-24. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1996. </year> <note> BIBLIOGRAPHY 53 </note>
Reference-contexts: It should be high-level enough to express polymorphism and higher-order functions but low-level enough to support all standard optimizations. 1.3.2 Background The core language of FLINT is a predicative variant of the Girard-Reynolds polymorphic -calculus F ! [9, 41], with the term language written in the A-normal form <ref> [42] </ref>. In the following, we first give a introduction about F ! , and then formally define the Core-FLINT language. <p> The usual term expressions must now satisfy new syntactic restrictions as standard A-normal forms <ref> [42] </ref>. More specifically, each function application (or type application) can only refer to values (as @v 1 v 2 ).
Reference: [43] <author> Z. Shao. </author> <title> Flexible representation analysis. </title> <booktitle> In Proc. 1997 ACM SIGPLAN International Conference on Functional Programming (ICFP'97), </booktitle> <pages> pages 85-98. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1997. </year>
Reference-contexts: The middle end does conventional dataflow and loop optimizations [1, 48], local and cross-module type specializations, and -calculus-based contractions and reductions [3]; it then produces an optimized version of the FLINT code. The back end compiles FLINT into machine code through the usual phases such as representation analysis <ref> [43] </ref> (to compile polymorphism), safe-for-space closure conversion [46] (to compile higher-order functions), register allocation, instruction scheduling, and machine-code generation [8]. All the compilation stages are deliberately made independent of each other so that they may be pieced together in different ways for different languages. <p> Apart from the presence of polymorphism and higher-order functions, the resulting FLINT code should be very close to the low-level machine languages. After the optimizations, the back end uses flexible representation analysis <ref> [43] </ref> to compile polymorphism and safe-for-space closure conversion to compile higher-order functions [46]; it then does the standard register allocation, instruction scheduling, and machine code generation [8]. <p> The middle-end optimizer does all of these. 1.4.3 Representation Analysis One novel aspect in our back end is to use the new flexible representation analysis technique <ref> [43] </ref> to compile the polymorphic functions and functors. Under flexible representation analysis, recursive and mutable data objects can use unboxed representations without incurring expensive runtime cost on heavily polymorphic code. <p> Maintaining type information in this manner helps in ensuring the correctness of a compiler; more importantly, it also enables many interesting optimizations and applications. For example, both pretty-printing and debugging on polymorphic values require complete type information at runtime in order to work correctly. Intensional type analysis <ref> [13, 49, 43] </ref>, which is used by some compilers [49, 44] to support efficient data representation, also requires the propagation of type information into the target code. Finally, run-time type information is crucial to the implementation of tag-less garbage collection [50], pickling, and type dynamic [22]. <p> The boxing interpretation of polymorphism which applies the appropriate coercions based on the type of an object was studied by Leroy [21] and Shao <ref> [43] </ref>. Many modern compilers like the FLINT/ML compiler [44], TIL [49] and the Glasgow Haskell compiler [34] use an explicitly typed language as the intermediate language for the compilation. 2.7. RELATED WORK AND CONCLUSIONS 33 Lambda lifting and full laziness are part of the folklore of functional programming.
Reference: [44] <author> Z. Shao. </author> <title> An overview of the FLINT/ML compiler. </title> <booktitle> In Proc. 1997 ACM SIGPLAN Workshop on Types in Compilation, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: Implementation of these ILs often involves passing types explicitly as run-time parameters <ref> [50, 49, 44] </ref>: each polymorphic type variable gets instantiated to the actual type through run-time type application. Maintaining type information in this manner helps in ensuring the correctness of a compiler; more importantly, it also enables many interesting optimizations and applications. <p> For example, both pretty-printing and debugging on polymorphic values require complete type information at runtime in order to work correctly. Intensional type analysis [13, 49, 43], which is used by some compilers <ref> [49, 44] </ref> to support efficient data representation, also requires the propagation of type information into the target code. Finally, run-time type information is crucial to the implementation of tag-less garbage collection [50], pickling, and type dynamic [22]. <p> THE TYPE LIFTING ALGORITHM 13 We describe the algorithm in later sections and also prove that it is both type-preserving and semantically sound. We have implemented it in the FLINT/ML compiler <ref> [44] </ref> and tested it on a few benchmarks. We provide the implementation results at the end of this chapter. 2.2 The Type Lifting Algorithm This section presents our optimal type lifting algorithm. <p> The boxing interpretation of polymorphism which applies the appropriate coercions based on the type of an object was studied by Leroy [21] and Shao [43]. Many modern compilers like the FLINT/ML compiler <ref> [44] </ref>, TIL [49] and the Glasgow Haskell compiler [34] use an explicitly typed language as the intermediate language for the compilation. 2.7. RELATED WORK AND CONCLUSIONS 33 Lambda lifting and full laziness are part of the folklore of functional programming.
Reference: [45] <author> Z. Shao. </author> <title> Typed cross-module compilation. </title> <type> Technical Report YALEU/DCS/RR-1126, </type> <institution> Dept. of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <month> November </month> <year> 1997. </year>
Reference-contexts: For example, the front end for ML can translate higher-order modules into the Core-FLINT-like calculus <ref> [45, 12] </ref> in a type-preserving way, thus completely eliminating the need of module constructs from the intermediate language. Similarly, type classes in Haskell can also be embedded into F ! through explicit dictionary passing. 1.3. <p> The details of the translation to FLINT are given in <ref> [45] </ref>. In ML, structures are the basic module unit and functors are parameterised structures. Polymorphic functions may escape as part of structures and be initialized later at a functor application site.
Reference: [46] <author> Z. Shao and A. W. Appel. </author> <title> Space-efficient closure representations. </title> <booktitle> In 1994 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 150-161, </pages> <address> New York, June 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The back end compiles FLINT into machine code through the usual phases such as representation analysis [43] (to compile polymorphism), safe-for-space closure conversion <ref> [46] </ref> (to compile higher-order functions), register allocation, instruction scheduling, and machine-code generation [8]. All the compilation stages are deliberately made independent of each other so that they may be pieced together in different ways for different languages. <p> Apart from the presence of polymorphism and higher-order functions, the resulting FLINT code should be very close to the low-level machine languages. After the optimizations, the back end uses flexible representation analysis [43] to compile polymorphism and safe-for-space closure conversion to compile higher-order functions <ref> [46] </ref>; it then does the standard register allocation, instruction scheduling, and machine code generation [8]. <p> [47] does not support unboxed representations on recursive and mutable objects; the type-passing approach used in TIL [49] does handle all data objects, but it involves heavy-weight runtime type analysis and code manipulations. 1.4.4 Closure Conversion After the polymorphism is eliminated, we use an efficient and safe-for-space closure conversion algorithm <ref> [46] </ref> to compile the higher-order functions. The algorithm exploits the use of compile-time control and data flow information to optimize closure representations.
Reference: [47] <author> Z. Shao and A. W. Appel. </author> <title> A type-based compiler for Standard ML. </title> <booktitle> In Proc. ACM SIGPLAN '95 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 116-129. </pages> <publisher> ACM Press, </publisher> <year> 1995. </year>
Reference-contexts: Finally, type information has proven invaluable for efficient compilation of statically typed languages <ref> [21, 47, 49] </ref>; types are also useful for debugging compilers and proving properties of programs. 1.3.1 Rationale The current FLINT language is designed based on the following principles: * Strong and explicit typing. ML-like languages often have very tricky type inference problems. <p> Under flexible representation analysis, recursive and mutable data objects can use unboxed representations without incurring expensive runtime cost on heavily polymorphic code. In contrast, the coercion-based approach used in Gallium [21] and SML/NJ <ref> [47] </ref> does not support unboxed representations on recursive and mutable objects; the type-passing approach used in TIL [49] does handle all data objects, but it involves heavy-weight runtime type analysis and code manipulations. 1.4.4 Closure Conversion After the polymorphism is eliminated, we use an efficient and safe-for-space closure conversion algorithm [46] <p> Boyer and mandelbrot are monomorphic benchmarks (involving large lists) and predictably do not benefit from the optimization. Even though life is a heavily polymorphic benchmark, most of its time is spent in the polymorphic equality function <ref> [47] </ref>. Type lifting does not obviate this and hence the speedup is negligible. 2.7 Related Work and Conclusions Tolmach [50] has worked on a similar problem and proposed a method based on the lazy substitution on types. He used the method in the implementation of the tag-free garbage collector.
Reference: [48] <author> D. Tarditi. </author> <title> Design and Implementation of Code Optimizations for a Type-Directed Compiler for Standard ML. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> December </month> <year> 1996. </year> <note> Tech Report CMU-CS-97-108. </note>
Reference-contexts: Programs written in various source languages are first fed into a language-specific front end which does parsing, elaboration, type-checking, and pattern-match compilation; the source program is then translated into the FLINT intermediate format. The middle end does conventional dataflow and loop optimizations <ref> [1, 48] </ref>, local and cross-module type specializations, and -calculus-based contractions and reductions [3]; it then produces an optimized version of the FLINT code.
Reference: [49] <author> D. Tarditi, G. Morrisett, P. Cheng, C. Stone, R. Harper, and P. Lee. </author> <title> TIL: A type-directed optimizing compiler for ML. </title> <booktitle> In Proc. ACM SIGPLAN '96 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 181-192. </pages> <publisher> ACM Press, </publisher> <year> 1996. </year>
Reference-contexts: Finally, type information has proven invaluable for efficient compilation of statically typed languages <ref> [21, 47, 49] </ref>; types are also useful for debugging compilers and proving properties of programs. 1.3.1 Rationale The current FLINT language is designed based on the following principles: * Strong and explicit typing. ML-like languages often have very tricky type inference problems. <p> In contrast, the coercion-based approach used in Gallium [21] and SML/NJ [47] does not support unboxed representations on recursive and mutable objects; the type-passing approach used in TIL <ref> [49] </ref> does handle all data objects, but it involves heavy-weight runtime type analysis and code manipulations. 1.4.4 Closure Conversion After the polymorphism is eliminated, we use an efficient and safe-for-space closure conversion algorithm [46] to compile the higher-order functions. <p> Implementation of these ILs often involves passing types explicitly as run-time parameters <ref> [50, 49, 44] </ref>: each polymorphic type variable gets instantiated to the actual type through run-time type application. Maintaining type information in this manner helps in ensuring the correctness of a compiler; more importantly, it also enables many interesting optimizations and applications. <p> Maintaining type information in this manner helps in ensuring the correctness of a compiler; more importantly, it also enables many interesting optimizations and applications. For example, both pretty-printing and debugging on polymorphic values require complete type information at runtime in order to work correctly. Intensional type analysis <ref> [13, 49, 43] </ref>, which is used by some compilers [49, 44] to support efficient data representation, also requires the propagation of type information into the target code. Finally, run-time type information is crucial to the implementation of tag-less garbage collection [50], pickling, and type dynamic [22]. <p> For example, both pretty-printing and debugging on polymorphic values require complete type information at runtime in order to work correctly. Intensional type analysis [13, 49, 43], which is used by some compilers <ref> [49, 44] </ref> to support efficient data representation, also requires the propagation of type information into the target code. Finally, run-time type information is crucial to the implementation of tag-less garbage collection [50], pickling, and type dynamic [22]. <p> The boxing interpretation of polymorphism which applies the appropriate coercions based on the type of an object was studied by Leroy [21] and Shao [43]. Many modern compilers like the FLINT/ML compiler [44], TIL <ref> [49] </ref> and the Glasgow Haskell compiler [34] use an explicitly typed language as the intermediate language for the compilation. 2.7. RELATED WORK AND CONCLUSIONS 33 Lambda lifting and full laziness are part of the folklore of functional programming. <p> The algorithm presented here is of course based on the idea of common subexpression elimination [1, 3] that is done by any standard compiler. The TIL compiler <ref> [49] </ref> uses an explicit lettype construct in the language to eliminate common type expressions. 3.3.
Reference: [50] <author> A. Tolmach. </author> <title> Tag-free garbage collection using explicit type parameters. </title> <booktitle> In Proc. 1994 ACM Conf. on Lisp and Functional Programming, </booktitle> <pages> pages 1-11, </pages> <address> New York, June 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Implementation of these ILs often involves passing types explicitly as run-time parameters <ref> [50, 49, 44] </ref>: each polymorphic type variable gets instantiated to the actual type through run-time type application. Maintaining type information in this manner helps in ensuring the correctness of a compiler; more importantly, it also enables many interesting optimizations and applications. <p> Intensional type analysis [13, 49, 43], which is used by some compilers [49, 44] to support efficient data representation, also requires the propagation of type information into the target code. Finally, run-time type information is crucial to the implementation of tag-less garbage collection <ref> [50] </ref>, pickling, and type dynamic [22]. However, the added information available at run time as a result of type passing does not come for free. Depending on the sophistication of the type representation, run-time type passing can add a significant overhead to the time and space usage of a program. <p> However, the added information available at run time as a result of type passing does not come for free. Depending on the sophistication of the type representation, run-time type passing can add a significant overhead to the time and space usage of a program. For example, Tolmach <ref> [50] </ref> implemented a tag-free garbage collector via explicit type passing; he reported that the memory allocated for type information sometimes exceeded the memory saved by the tag-free approach. Clearly, it is desirable to optimize the run-time type passing in polymorphic code [27]. <p> Even though life is a heavily polymorphic benchmark, most of its time is spent in the polymorphic equality function [47]. Type lifting does not obviate this and hence the speedup is negligible. 2.7 Related Work and Conclusions Tolmach <ref> [50] </ref> has worked on a similar problem and proposed a method based on the lazy substitution on types. He used the method in the implementation of the tag-free garbage collector. Minamide [27] has also attacked the same problem but has used an entirely different approach from ours.
Reference: [51] <author> A. K. Wright. </author> <title> Polymorphism for imperative languages without imperative types. </title> <type> Technical Report Tech Report TR 93-200, </type> <institution> Dept. of Computer Science, Rice University, Houston, Texas, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: There are several aspects of this calculus that are worth noting. First, we restrict polymorphic definitions to value expressions (e v ) only so that moving type functions and type applications is semantically sound <ref> [51] </ref>. Variables introduced by normal -abstraction are always monomorphic, and polymorphic functions are introduced only by the let construct. In our calculus, type applications of polymorphic functions are never curried and therefore in the algorithm in Fig 2.2, the exp rule assumes that the variable is monomorphic.
References-found: 51

