URL: http://www.cs.nmsu.edu/lldap/download/jicslp/kish.ps.gz
Refering-URL: http://www.cs.nmsu.edu/lldap/jicslp/kish.html
Root-URL: http://www.cs.nmsu.edu
Email: kish@cs.man.ac.uk  
Title: Some Aspect of Implementing the Parallel DASWAM System  
Author: Kish Shen 
Address: Manchester M13 9PL U.K.  
Affiliation: Department of Computer Science University of Manchester  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Crammond. </author> <title> Implementation of Committed Choice Logic Languages on Shared Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Heriot-Watt University, </institution> <year> 1988. </year>
Reference-contexts: The woken work queue have been implemented in two different ways: in the original method, 5 This was suggested by V. Santos Costa, and has been developed independently in several earlier and-parallel systems, the earliest of which seems to be Crammond's implementation of Parlog <ref> [1] </ref> (thanks to Johan Montelius for pointing this out). 6 Actually, a different routine is called when a worker becomes idle because of suspension.
Reference: [2] <author> M. V. Hermenegildo. </author> <title> An Abstract Machine Based Execution Model for Computer Architecture Design and Efficient Implementation of Logic Programs in Parallel. </title> <type> PhD thesis, </type> <institution> The University of Texas At Austin, </institution> <year> 1986. </year>
Reference-contexts: Parallelism in DDAS is indicated via ECGEs, an annotations that indicates where parallelism is to be exploited this is an extension (to exploiting DAP) of the CGE annotation of &-Prolog <ref> [2] </ref>. Finally, in order to maintain equivalence to Prolog, a backward execution scheme, which defines the actions to be taken when a failure occurs, has to be defined. <p> Parallelism arises when more than one worker is simultaneously executing code from different parts of the program's search-space. The system is an extension and enhancement of the independent and-parallelism RAP-WAM <ref> [2] </ref> system: the workers are WAMs [9] modified to deal with and-parallel execution under DDAS, and consists of the abstract machine, plus the various stacks associated with a WAM, and a couple of extra stacks/heaps needed for parallel execution (collectively referred to as a stack set), which are accessible by other
Reference: [3] <author> K. Shen. </author> <title> Exploiting And-parallelism in Prolog: the Dynamic Dependent And-parallel Scheme (DDAS). </title> <booktitle> In Logic Programming: Proceedings of the Joint International Conference and Symposium on Logic Programming, </booktitle> <pages> pages 717-731. </pages> <publisher> The MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: 1. Introduction The DASWAM system is a proto-type implementation of the DDAS and-parallel execution scheme for Prolog <ref> [4, 3] </ref>. It was initially implemented as a pseudo-parallel system where the parallel execution was simulated, but this was subsequently converted to a real parallel system that has been ported to a wide range of shared-memory multiprocessors. <p> A Brief Overview of DDAS DDAS (Dynamic Dependent And-parallel Scheme) is a parallel execution model for Prolog (or Prolog-like languages). It was designed to allow the exploitation of non-deterministic dependent and-parallelism. Details of this scheme is beyond the scope of this paper, but has been extensively documented elsewhere <ref> [4, 3, 6] </ref>. The main aim of the scheme is to exploit as much and-parallelism as possible, without incurring too high an overhead. The key innovative idea behind DDAS is that of the dynamic producer.
Reference: [4] <author> K. Shen. </author> <title> Studies of And/Or Parallelism in Prolog. </title> <type> PhD thesis, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <year> 1992. </year>
Reference-contexts: 1. Introduction The DASWAM system is a proto-type implementation of the DDAS and-parallel execution scheme for Prolog <ref> [4, 3] </ref>. It was initially implemented as a pseudo-parallel system where the parallel execution was simulated, but this was subsequently converted to a real parallel system that has been ported to a wide range of shared-memory multiprocessors. <p> The initial results from this system are very encouraging, and have been reported in [7]. The purpose of this paper is to serve as a companion paper to [7], documenting the implementation of the parallel DASWAM system itself. The pseudo-parallel DASWAM system has been documented extensively previously <ref> [4, 5, 8] </ref>, but the parallel DASWAM system has not been described, except very briefly in [7]. This paper will assume that the reader has some familiarity with the pseudo-parallel DASWAM. <p> This paper will assume that the reader has some familiarity with the pseudo-parallel DASWAM. A brief introduction will be given here, but readers are referred to <ref> [4, 8] </ref> for a more complete guide. 1.1. A Brief Overview of DDAS DDAS (Dynamic Dependent And-parallel Scheme) is a parallel execution model for Prolog (or Prolog-like languages). It was designed to allow the exploitation of non-deterministic dependent and-parallelism. <p> A Brief Overview of DDAS DDAS (Dynamic Dependent And-parallel Scheme) is a parallel execution model for Prolog (or Prolog-like languages). It was designed to allow the exploitation of non-deterministic dependent and-parallelism. Details of this scheme is beyond the scope of this paper, but has been extensively documented elsewhere <ref> [4, 3, 6] </ref>. The main aim of the scheme is to exploit as much and-parallelism as possible, without incurring too high an overhead. The key innovative idea behind DDAS is that of the dynamic producer. <p> This is more complicated than the simple backtracking in Prolog because actions may need to be co-ordinated between and-goals that are/were executed in parallel. For correctness, this scheme must maintain equivalence to sequential Prolog <ref> [4] </ref>. Due to the non-determinism, extra information has to be available to allow for the correct backward execution behaviour, which imposes extra overhead during the forward execution phase but may help to increase the cleverness (and complexity) of the backward execution scheme. <p> The changes will be briefly discussed in this section. The following discussion assumes some familiarity with the old code, and it is beyond the scope of this paper to describe this in detail. The reader is referred to <ref> [4] </ref> for details of the old code. The new backward execution code differs from the old one only at the implementation level; the high-level view of the backward execution scheme stays the same.
Reference: [5] <author> K. Shen. </author> <title> Implementing Dynamic Dependent And-parallelism. </title> <booktitle> In Logic Programming: Proceedings of the Tenth International Conference, </booktitle> <pages> pages 167-183. </pages> <publisher> The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The initial results from this system are very encouraging, and have been reported in [7]. The purpose of this paper is to serve as a companion paper to [7], documenting the implementation of the parallel DASWAM system itself. The pseudo-parallel DASWAM system has been documented extensively previously <ref> [4, 5, 8] </ref>, but the parallel DASWAM system has not been described, except very briefly in [7]. This paper will assume that the reader has some familiarity with the pseudo-parallel DASWAM.
Reference: [6] <author> K. Shen. </author> <title> Improving the Execution of the Dependent And-parallel Prolog DDAS. </title> <editor> In C. Halatis, D. Maritsas, G. Philokyprou, and S. Theodoridis, editors, </editor> <booktitle> PARLE'94 Parallel Architectures and Languages Europe, </booktitle> <pages> pages 438-452. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year> <note> Published as Lecture Notes in Computer Science 817. </note>
Reference-contexts: A Brief Overview of DDAS DDAS (Dynamic Dependent And-parallel Scheme) is a parallel execution model for Prolog (or Prolog-like languages). It was designed to allow the exploitation of non-deterministic dependent and-parallelism. Details of this scheme is beyond the scope of this paper, but has been extensively documented elsewhere <ref> [4, 3, 6] </ref>. The main aim of the scheme is to exploit as much and-parallelism as possible, without incurring too high an overhead. The key innovative idea behind DDAS is that of the dynamic producer.
Reference: [7] <author> K. Shen. </author> <title> Initial Results from the Parallel Implementation of DASWAM. </title> <booktitle> Accepted at Joint International/Symposium of Logic Programming, </booktitle> <year> 1996. </year>
Reference-contexts: It was initially implemented as a pseudo-parallel system where the parallel execution was simulated, but this was subsequently converted to a real parallel system that has been ported to a wide range of shared-memory multiprocessors. The initial results from this system are very encouraging, and have been reported in <ref> [7] </ref>. The purpose of this paper is to serve as a companion paper to [7], documenting the implementation of the parallel DASWAM system itself. The pseudo-parallel DASWAM system has been documented extensively previously [4, 5, 8], but the parallel DASWAM system has not been described, except very briefly in [7]. <p> The initial results from this system are very encouraging, and have been reported in <ref> [7] </ref>. The purpose of this paper is to serve as a companion paper to [7], documenting the implementation of the parallel DASWAM system itself. The pseudo-parallel DASWAM system has been documented extensively previously [4, 5, 8], but the parallel DASWAM system has not been described, except very briefly in [7]. This paper will assume that the reader has some familiarity with the pseudo-parallel DASWAM. <p> in <ref> [7] </ref>. The purpose of this paper is to serve as a companion paper to [7], documenting the implementation of the parallel DASWAM system itself. The pseudo-parallel DASWAM system has been documented extensively previously [4, 5, 8], but the parallel DASWAM system has not been described, except very briefly in [7]. This paper will assume that the reader has some familiarity with the pseudo-parallel DASWAM. A brief introduction will be given here, but readers are referred to [4, 8] for a more complete guide. 1.1. <p> The results presented in <ref> [7] </ref> suggest that the current DASWAM system has achieved quite effective and efficient lockings which allows most of the parallelism in a program to be effectively exploited. The actual implementation of some of these locks shall now be outlined. <p> these speedups are worker owning the stack: the same worker that will perform the link, so these two events cannot occur simultaneously and thus locking is not needed. 10 1996 Compulog Net Meeting on Parallelism and Implementation Technology computed was performed some time ago, and unlike the results presented in <ref> [7] </ref> and the result in the next section, the timing measurement is from the start of the execution until the very end (the newer results measures time interval from the start until the return of the last solution), including the time to shutdown the whole DASWAM system, and also the final <p> Thus the optimised speedups of Boyer are not as good as reported in <ref> [7] </ref>. This final backtracking time is not important because it is after the return of the last solution, but it can be important if the program performs much backtracking before returning the last solution. <p> change improved the speedup for the DAP kkqueens benchmark, as shown in Figure 2, although it did not solve the more fundamental problem: the re-execution of the instruction the task was suspended on seem to take an order of magnitude longer to execute than the average instruction, as discussed in <ref> [7] </ref>. It is expected that further improvements to the performance of the type outlined above would be possible when the executions of programs are examined in more detail. 1996 Compulog Net Meeting on Parallelism and Implementation Technology 11 4.3.
Reference: [8] <author> K. Shen. </author> <title> Overview of DASWAM: Exploitation of Dependent And-parallelism. </title> <journal> Journal of Logic Programming, </journal> <note> 1996. In Press. </note>
Reference-contexts: The initial results from this system are very encouraging, and have been reported in [7]. The purpose of this paper is to serve as a companion paper to [7], documenting the implementation of the parallel DASWAM system itself. The pseudo-parallel DASWAM system has been documented extensively previously <ref> [4, 5, 8] </ref>, but the parallel DASWAM system has not been described, except very briefly in [7]. This paper will assume that the reader has some familiarity with the pseudo-parallel DASWAM. <p> This paper will assume that the reader has some familiarity with the pseudo-parallel DASWAM. A brief introduction will be given here, but readers are referred to <ref> [4, 8] </ref> for a more complete guide. 1.1. A Brief Overview of DDAS DDAS (Dynamic Dependent And-parallel Scheme) is a parallel execution model for Prolog (or Prolog-like languages). It was designed to allow the exploitation of non-deterministic dependent and-parallelism.
Reference: [9] <author> D. H. D. Warren. </author> <title> An Abstract Prolog Instruction Set. </title> <type> Technical Note 309, </type> <institution> SRI International, </institution> <address> 333 Ravenswood Ave., Menlo Park CA 94025, USA, </address> <year> 1983. </year>
Reference-contexts: Parallelism arises when more than one worker is simultaneously executing code from different parts of the program's search-space. The system is an extension and enhancement of the independent and-parallelism RAP-WAM [2] system: the workers are WAMs <ref> [9] </ref> modified to deal with and-parallel execution under DDAS, and consists of the abstract machine, plus the various stacks associated with a WAM, and a couple of extra stacks/heaps needed for parallel execution (collectively referred to as a stack set), which are accessible by other workers.
References-found: 9

