URL: http://www.cs.umn.edu/Users/dept/users/kumar/mlevel_kway.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Email: fkarypis, kumarg@cs.umn.edu  
Title: Multilevel k -way Partitioning Scheme for Irregular Graphs  
Author: George Karypis and Vipin Kumar 
Date: Last updated on October 9, 1997  
Address: Minneapolis, MN 55455,  5:31pm  
Affiliation: University of Minnesota, Department of Computer Science Army HPC Research Center  at  
Pubnum: Technical Report: 95-064  
Abstract: The algorithms described in this paper are implemented by the `METIS: Unstructured Graph Partitioning and Sparse Matrix Ordering System'. METIS is available on WWW at URL: http://www.cs.umn.edu/karypis/metis Abstract In this paper we present and study a class of graph partitioning algorithms that reduce the size of the graph by collapsing vertices and edges, find a k-way partitioning of the smaller graph, and then uncoarsen and refine it to construct a k-way partitioning for the original graph. These algorithms compute a k-way partitioning of a graph G D .V; E/ in O.jEj/ time which is faster by a factor of O.log k/ than previously proposed multilevel recursive bisection algorithms. A key contribution of our work is in finding a high quality and computationally inexpensive refinement algorithm that can improve upon an initial k-way partitioning. We also study the effectiveness of the overall scheme for a variety of coarsening schemes. We present experimental results on a large number of graphs arising in various domains including finite element methods, linear programming, VLSI, and transportation. Our experiments show that this new scheme produces partitions that are of comparable or better quality than those produced by the multilevel bisection algorithm, and requires substantially smaller time. Graphs containing up to 450000 vertices and 3300000 edges, can be partitioned in 256 domains in less than 40 seconds on a workstation, such as SGI's Challenge. Compared with the widely used multilevel spectral bisection algorithm, our new algorithm is usually two orders of magnitude faster, and produces partitions with substantially smaller edge-cut. fl This work was supported by NSF CCR-9423082, by the Army Research Office contract DA/DAAH04-95-1-0538, by the IBM Partenrship Award, and by the Army High Performance Computing Research Center under the auspices of the Department of the Army, Army Research Laboratory cooperative agreement number DAAH04-95-2-0003/contract number DAAH04-95-C-0008, the content of which does not necessarily reflect the position or the policy of the government, and no official endorsement should be inferred. Access to computing facilities was provided by AHPCRC, Minnesota Supercomputer Institute, Cray Research Inc, and by the Pittsburgh Supercomputing Center. Related papers are available via WWW at URL: http://www.cs.umn.edu/karypis 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Stephen T. Barnard and Horst D. Simon. </author> <title> A fast multilevel implementation of recursive spectral bisection for partitioning unstructured problems. </title> <booktitle> In Proceedings of the sixth SIAM conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 711-718, </pages> <year> 1993. </year>
Reference-contexts: Since the finer graph has more degrees of freedom, such refinements decrease the edge-cut. The experiments presented in [16] show that compared to the state-of-the-art implementation of the well known spectral bisection <ref> [1] </ref>, MLRB produces partitionings that are significantly better and is an order of magnitude faster. The complexity of the MLRB for producing a k-way partitioning of a graph G D .V ; E/, is O.jE j log k/ [16]. <p> From this table we see that even the larger problem (448000 vertex mesh of GM's Saturn car) is partitioned in under 40 seconds. Figures 12 and 13 present the relative quality and run-time, respectively, of MLkP with respect to multilevel spectral bisection (MSB) <ref> [1] </ref>. From these figures we see that for all the graphs, MLkP produces better partitionings than MSB. In some cases MLkP produces partitionings that cut over 70% fewer edges than those cut by the MSB.
Reference: [2] <author> T. Bui and C. Jones. </author> <title> A heuristic for reducing fill in sparse matrix factorization. </title> <booktitle> In 6th SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <pages> pages 445-452, </pages> <year> 1993. </year>
Reference-contexts: After log k phases, graph G is partitioned into k partitions. Thus, the problem of performing a k-way partitioning is reduced to that of performing a sequence of bisections. Recently <ref> [2, 12, 16] </ref> multilevel recursive bisection (MLRB) algorithm has emerged as a highly effective method for computing a k-way partitioning of a graph. The basic structure of a multilevel bisection algorithm is very simple. <p> This edge collapsing idea can be formally defined in terms of matchings <ref> [2, 12] </ref>. A matching of a graph is a set of edges, no two of which are incident on the same vertex. Thus, the next level coarser graph G iC1 is constructed from G i by finding a matching of G i and collapsing the vertices being matched into multinodes. <p> We also end the coarsening phase if the reduction in the size of successively graphs is less than a factor of 0.8. In the remaining sections we describe three ways that we used to select maximal matchings for coarsening. Two of these matchings, RM <ref> [2, 12] </ref> and HEM [16], have been previously investigated in the context of MLRB. Random Matching (RM) A maximal matching can be generated efficiently using a randomized algorithm. In our experiments we used a randomized algorithm similar to that described in [2, 12, 16]. <p> Two of these matchings, RM [2, 12] and HEM [16], have been previously investigated in the context of MLRB. Random Matching (RM) A maximal matching can be generated efficiently using a randomized algorithm. In our experiments we used a randomized algorithm similar to that described in <ref> [2, 12, 16] </ref>. The random maximal matching 5 algorithm works as follows. The vertices are visited in random order. If a vertex u has not been matched yet, then we randomly select one of its unmatched adjacent vertices. <p> Now, this becomes the initial partitioning for the next pass of the algorithm. In the case of multilevel recursive bisection algorithms <ref> [2, 12, 16] </ref>, KL refinement becomes very powerful, as the initial partitioning available at each successive uncoarsening level is already a good partition. However, refining a k-way partitioning is significantly more complicated because vertices can move from a partition to many other partitions; thus, increasing the optimization space combinatorially.
Reference: [3] <author> Chung-Kuan Cheng and Yen-Chuen A. Wei. </author> <title> An improved two-way partitioning algorithm with stable performance. </title> <journal> IEEE Transactions on Computer Aided Design, </journal> <volume> 10(12) </volume> <pages> 1502-1511, </pages> <month> December </month> <year> 1991. </year>
Reference: [4] <author> C. M. Fiduccia and R. M. Mattheyses. </author> <title> A linear time heuristic for improving network partitions. </title> <booktitle> In In Proc. 19th IEEE Design Automation Conference, </booktitle> <pages> pages 175-181, </pages> <year> 1982. </year>
Reference-contexts: Hence, it may still be possible to improve the projected partitioning of G i1 by local refinement heuristics. A class of local refinement algorithms that tend to produce very good results are those that are based on the Kernighan-Lin (KL) partitioning algorithm [17] and their variants <ref> [4, 12] </ref>. The KL algorithm incrementally swaps vertices among partitions of a bisection to reduce the edge-cut of the partitioning, until the partitioning reaches a local minima. One commonly used variation of the KL algorithm for bisection refinement is due to Fiduccia-Mattheyses [4]. <p> The KL algorithm incrementally swaps vertices among partitions of a bisection to reduce the edge-cut of the partitioning, until the partitioning reaches a local minima. One commonly used variation of the KL algorithm for bisection refinement is due to Fiduccia-Mattheyses <ref> [4] </ref>. In particular, for each vertex v, this variation of the KL algorithm computes the gain which is the reduction in the edge-cut achieved by moving v to the other partition. These vertices are inserted into two priority queues, one for each partition, according to their gains.
Reference: [5] <author> J. Garbers, H. J. Promel, and A. Steger. </author> <title> Finding clusters in VLSI circuits. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Aided Design, </booktitle> <pages> pages 520-523, </pages> <year> 1990. </year>
Reference-contexts: For each vertex v we compute the gains of moving v to one of its 1 A partitioning is at a local minima, if movement of any vertex from one part to the other does not improve the edge-cut. 8 I D <ref> [5] </ref> D 2 N.5/ D f0; 2g neighbor partitions. In particular, for every b 2 N .v/ we compute E D [v] b as the sum of the weights of the edges .v; u/ such that P i [u] D b. <p> Given these definitions, the gain of moving vertex v to partition b 2 N .v/ is g [v] b D E D [v] b I D [v]. These definitions are illustrated in Figure 3. For example for vertex 5, N <ref> [5] </ref> D f0; 2g, I D [5] D 2, E D [5] 0 D 2, and E D [5] 2 D 3. However, in addition to decreasing the edge-cut, moving a vertex from one partition to another must not create partitions whose size is unbalanced. <p> Given these definitions, the gain of moving vertex v to partition b 2 N .v/ is g [v] b D E D [v] b I D [v]. These definitions are illustrated in Figure 3. For example for vertex 5, N <ref> [5] </ref> D f0; 2g, I D [5] D 2, E D [5] 0 D 2, and E D [5] 2 D 3. However, in addition to decreasing the edge-cut, moving a vertex from one partition to another must not create partitions whose size is unbalanced. <p> These definitions are illustrated in Figure 3. For example for vertex 5, N <ref> [5] </ref> D f0; 2g, I D [5] D 2, E D [5] 0 D 2, and E D [5] 2 D 3. However, in addition to decreasing the edge-cut, moving a vertex from one partition to another must not create partitions whose size is unbalanced. <p> These definitions are illustrated in Figure 3. For example for vertex 5, N <ref> [5] </ref> D f0; 2g, I D [5] D 2, E D [5] 0 D 2, and E D [5] 2 D 3. However, in addition to decreasing the edge-cut, moving a vertex from one partition to another must not create partitions whose size is unbalanced. In particular, our partitioning refinement algorithms move a vertex only if it satisfies the following Balancing Condition.
Reference: [6] <author> J. R. Gilbert and E. Zmijewski. </author> <title> A parallel graph partitioning algorithm for a message-passing multiprocessor. </title> <journal> International Journal of Parallel Programming, </journal> (16):498-513, 1987. 
Reference-contexts: This scheme is substantially faster than the direct generalization [11] of the KL bisection refinement algorithm, but is equally effective in the multilevel context. Furthermore, this new k-way refinement algorithm is inherently parallel [15] (unlike the original KL refinement algorithm which is known to be inherently sequential in nature <ref> [6] </ref>), making it possible to develop high-quality parallel graph partitioning algorithms. 3 We test our scheme on a large number of graphs arising in various domains including finite element methods, linear programming, VLSI, and transportation. <p> Absence of a priority queue in our GR refinement algorithm makes it naturally suited for parallel implementations. In contrast, the original KL refinement algorithm (and its generalization in the k-way partitioning context) are inherently sequential <ref> [6] </ref>. In [15] we have developed a highly parallel formulation of our multilevel k-way partitioning algorithm that uses the vertex-coloring of the successively coarser graph to effectively parallelize both the coarsening as well as the k-way refinement algorithms.
Reference: [7] <author> Lars Hagen and Andrew Kahng. </author> <title> Fast spectral methods for ratio cut partitioning and clustering. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Aided Design, </booktitle> <pages> pages 10-13, </pages> <year> 1991. </year>
Reference: [8] <author> Lars Hagen and Andrew Kahng. </author> <title> A new approach to effective circuit clustering. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Aided Design, </booktitle> <pages> pages 422-427, </pages> <year> 1992. </year>
Reference: [9] <author> M. T. Heath and Padma Raghavan. </author> <title> A Cartesian parallel nested dissection algorithm. </title> <journal> SIAM Journal of Matrix Analysis and Applications, </journal> <volume> 16(1) </volume> <pages> 235-253, </pages> <year> 1995. </year>
Reference-contexts: The run time of our k-way partitioning algorithm is comparable to the run time of a small number (2-4) runs of geometric recursive bisection algorithms <ref> [9, 24, 19, 18, 20] </ref>. Note that geometric algorithms are applicable only if coordinates of the vertices are available, and require tens of runs to produce cuts that are of similar quality to those produced by spectral bisection. The remainder of the paper is organized as follows.
Reference: [10] <author> Bruce Hendrickson and Robert Leland. </author> <title> An improved spectral graph partitioning algorithm for mapping parallel computations. </title> <type> Technical Report SAND92-1460, </type> <institution> Sandia National Laboratories, </institution> <year> 1992. </year>
Reference-contexts: However in the refinement phase, we need to refine a k-way partitioning, which is considerably more complicated than refining a bisection. In fact, a direct generalization of the KL refinement algorithm to k-way partitioning used in <ref> [10] </ref> is substantially more expensive than performing a KL refinement of a bisection [17]. Even for 8-way refinement, the run time is quite high for these schemes [11]. Computing k-way refinement for k &gt; 8 is prohibitively expensive. In this paper we present a k-way partitioning algorithm. <p> However, refining a k-way partitioning is significantly more complicated because vertices can move from a partition to many other partitions; thus, increasing the optimization space combinatorially. An extension of the KL refinement algorithm in the case of k-way refinement is described in <ref> [10] </ref>. This algorithm uses k.k 1/ priority queues, one for each type of move. In each step of the algorithm, the moves with the highest gain are found from each of these k.k 1/ queues, and the move with the highest gain that preserves or improves the balance, is performed. <p> The complexity of k-way refinement is significantly higher than that of 2-way refinement, and for a graph with m edges, this complexity is O.k fl m/. This approach is only practical for small values of k. Due to this high complexity, the multilevel recursive octasection algorithm described in <ref> [10] </ref>, requires the same amount of time as multilevel recursive bisection, even though recursive octasection spends much less time for coarsening. We have developed simple k-way refinement algorithms that are simplified versions of the k-way Kernighan-Lin refinement algorithm, and their complexity is independent of the number of partitions being refined. <p> The graph partitioning package Chaco 2.0 [11, 12] also implements multilevel quadrisection and octasection partitioning algorithms. Chaco uses random matching during coarsening, and spectral quadrisection and octasection methods to directly divide the coarsest graph into four and eight pieces, respectively 3 <ref> [10] </ref>. The key difference between our scheme and the one implemented in Chaco's recursive octasection is that their Kernighan-Lin refinement algorithm is direct generalization of the 2-way refinement algorithm to handle both 4-way and 8-way refinement.
Reference: [11] <author> Bruce Hendrickson and Robert Leland. </author> <title> The chaco user's guide, version 1.0. </title> <type> Technical Report SAND93-2339, </type> <institution> Sandia National Laboratories, </institution> <year> 1993. </year>
Reference-contexts: In fact, a direct generalization of the KL refinement algorithm to k-way partitioning used in [10] is substantially more expensive than performing a KL refinement of a bisection [17]. Even for 8-way refinement, the run time is quite high for these schemes <ref> [11] </ref>. Computing k-way refinement for k &gt; 8 is prohibitively expensive. In this paper we present a k-way partitioning algorithm. The run time of this k-way multilevel algorithm (MLkP) is linear to the number of edges i.e., O.jE j/. <p> A key contribution of our work is a simple and yet powerful scheme for refining a k-way partitioning in the multilevel context. This scheme is substantially faster than the direct generalization <ref> [11] </ref> of the KL bisection refinement algorithm, but is equally effective in the multilevel context. <p> This is repeated for a small number of iterations or until convergence. Note that in each step, the vertices selected for movement by the GKLR algorithm and by the generalized KL of <ref> [11] </ref> may be quite different. GKLR selects a vertex v that has a move (among all possible moves to neighboring partitions N .v/) with the highest gain g [v] max . <p> Thus, in each step, GKLR does not necessarily selects the vertex with the largest realizable gain. Furthermore, since the single priority queue contains only vertices whose sum of the external degrees is greater or equal to the internal degree, GKLR has less powerful hill-climbing capabilities than the generalized KL <ref> [11] </ref> that uses multiple priority queues and considers all the vertices. 3 Experimental Results We evaluated the performance of the multilevel graph partitioning algorithm on a wide range of graphs arising in different application domains. The characteristics of these graphs are described in Table 1. <p> In some cases MLkP produces partitionings that cut over 70% fewer edges than those cut by the MSB. Furthermore, from Figure 13 we see that MLkP is up to two orders of magnitude faster the MSB. The graph partitioning package Chaco 2.0 <ref> [11, 12] </ref> also implements multilevel quadrisection and octasection partitioning algorithms. Chaco uses random matching during coarsening, and spectral quadrisection and octasection methods to directly divide the coarsest graph into four and eight pieces, respectively 3 [10].
Reference: [12] <author> Bruce Hendrickson and Robert Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <type> Technical Report SAND93-1301, </type> <institution> Sandia National Laboratories, </institution> <year> 1993. </year>
Reference-contexts: After log k phases, graph G is partitioned into k partitions. Thus, the problem of performing a k-way partitioning is reduced to that of performing a sequence of bisections. Recently <ref> [2, 12, 16] </ref> multilevel recursive bisection (MLRB) algorithm has emerged as a highly effective method for computing a k-way partitioning of a graph. The basic structure of a multilevel bisection algorithm is very simple. <p> For many of these graphs, the process of graph partitioning takes even less time than the time to read the graph from the disk into memory. Compared with the widely used multilevel spectral bisection algorithm <ref> [23, 22, 12] </ref>, our new algorithm is usually two orders of magnitude faster, and produces partitionings with substantially smaller edge-cut. The run time of our k-way partitioning algorithm is comparable to the run time of a small number (2-4) runs of geometric recursive bisection algorithms [9, 24, 19, 18, 20]. <p> The remainder of the paper is organized as follows. Section 2 defines the graph partitioning problem and presents the basic concepts of multilevel k-way graph partitioning. Some of the material presented in this section on coarsening strategies is similar to that for multilevel recursive bisection <ref> [12, 16] </ref>, but is included here to make this paper self contained. <p> In the case where more than one vertex of V v i contain edges to the same vertex u, the weight of the edge of v is equal to the sum of the weights of these edges. This coarsening method ensures the following properties <ref> [12] </ref>: (i) the edge-cut of the partitioning in a coarser graph is equal to the edge-cut of the same partition in the finer graph; (ii) a balanced partitioning of the coarser graphs leads to 4 successively decreased; during the initial partitioning phase, a k-way partitioning of the smaller graph is computed <p> This edge collapsing idea can be formally defined in terms of matchings <ref> [2, 12] </ref>. A matching of a graph is a set of edges, no two of which are incident on the same vertex. Thus, the next level coarser graph G iC1 is constructed from G i by finding a matching of G i and collapsing the vertices being matched into multinodes. <p> We also end the coarsening phase if the reduction in the size of successively graphs is less than a factor of 0.8. In the remaining sections we describe three ways that we used to select maximal matchings for coarsening. Two of these matchings, RM <ref> [2, 12] </ref> and HEM [16], have been previously investigated in the context of MLRB. Random Matching (RM) A maximal matching can be generated efficiently using a randomized algorithm. In our experiments we used a randomized algorithm similar to that described in [2, 12, 16]. <p> Two of these matchings, RM [2, 12] and HEM [16], have been previously investigated in the context of MLRB. Random Matching (RM) A maximal matching can be generated efficiently using a randomized algorithm. In our experiments we used a randomized algorithm similar to that described in <ref> [2, 12, 16] </ref>. The random maximal matching 5 algorithm works as follows. The vertices are visited in random order. If a vertex u has not been matched yet, then we randomly select one of its unmatched adjacent vertices. <p> Hence, it may still be possible to improve the projected partitioning of G i1 by local refinement heuristics. A class of local refinement algorithms that tend to produce very good results are those that are based on the Kernighan-Lin (KL) partitioning algorithm [17] and their variants <ref> [4, 12] </ref>. The KL algorithm incrementally swaps vertices among partitions of a bisection to reduce the edge-cut of the partitioning, until the partitioning reaches a local minima. One commonly used variation of the KL algorithm for bisection refinement is due to Fiduccia-Mattheyses [4]. <p> Now, this becomes the initial partitioning for the next pass of the algorithm. In the case of multilevel recursive bisection algorithms <ref> [2, 12, 16] </ref>, KL refinement becomes very powerful, as the initial partitioning available at each successive uncoarsening level is already a good partition. However, refining a k-way partitioning is significantly more complicated because vertices can move from a partition to many other partitions; thus, increasing the optimization space combinatorially. <p> In some cases MLkP produces partitionings that cut over 70% fewer edges than those cut by the MSB. Furthermore, from Figure 13 we see that MLkP is up to two orders of magnitude faster the MSB. The graph partitioning package Chaco 2.0 <ref> [11, 12] </ref> also implements multilevel quadrisection and octasection partitioning algorithms. Chaco uses random matching during coarsening, and spectral quadrisection and octasection methods to directly divide the coarsest graph into four and eight pieces, respectively 3 [10].
Reference: [13] <author> G. Karypis and V. Kumar. </author> <title> Analysis of multilevel graph partitioning. </title> <type> Technical Report TR 95-037, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis. A short version appears in Supercomputing 95. </note>
Reference-contexts: Hence, by selecting a maximal matching M i whose edges have a large weight, we can decrease the edge-weight of the coarser graph by a greater amount. As the analysis in <ref> [13] </ref> shows, since the coarser graph has smaller edge-weight, it also has a smaller edge-cut. Finding a maximal matching that contains edges with large weight is the idea behind the heavy-edge matching originally introduced in [16]. <p> The complexity of computing a heavy-edge matching is O.jE j/, which is asymptotically similar to that for computing the random matching. Modified Heavy Edge Matching (HEM*) The analysis of the multilevel bisection algorithm in <ref> [13] </ref> shows that a good edge-cut of a coarser graph is closer to that of a good edge-cut of the original graph if the average degree of the coarser graph is small. <p> 119368 95452 92358 BCSSTK32 221234 155286 143176 342679 287300 265350 INPRO1 244035 159632 149373 405038 319496 301075 BBMAT 324794 154878 89305 584891 350850 196325 MAP2 1064 911 839 2382 2205 2173 Table 2: Quality of initial partitionings for the RM, HEM, and HEM* matching schemes. and HEM*.) As discussed in <ref> [13] </ref>, the effectiveness of a coarsening scheme depends on how successful it is in removing a significant amount of edge-weight from the successive coarser graphs. According to this criterion, HEM and HEM* are strictly better coarsening schemes than RM because they remove more edge-weight from the graph.
Reference: [14] <author> G. Karypis and V. Kumar. METIS: </author> <title> Unstructured graph partitioning and sparse matrix ordering system. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Available on the WWW at URL http://www.cs.umn.edu/karypis/metis. </note>
Reference-contexts: In summary, GR and GKLR tend to produce partitionings that have similar edge-cuts, but with GKLR requiring significantly more time than GR. 3.3 Comparison with Other Partitioning Schemes recursive bisection algorithm (MLRB) described in [16] (implemented in METIS <ref> [14] </ref>). METIS is a set of programs for partitioning unstructured graphs and for ordering sparse matrices that implements various algorithms described in [16]. For each graph we plot the ratio of the edge-cut of the MLkP algorithm to the edge-cut of the MLRB algorithm.
Reference: [15] <author> G. Karypis and V. Kumar. </author> <title> Parallel multilevel k-way partitioning scheme for irregular graphs. </title> <type> Technical Report TR 96-036, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1996. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis. A short version appears in Supercomputing 96. </note>
Reference-contexts: This scheme is substantially faster than the direct generalization [11] of the KL bisection refinement algorithm, but is equally effective in the multilevel context. Furthermore, this new k-way refinement algorithm is inherently parallel <ref> [15] </ref> (unlike the original KL refinement algorithm which is known to be inherently sequential in nature [6]), making it possible to develop high-quality parallel graph partitioning algorithms. 3 We test our scheme on a large number of graphs arising in various domains including finite element methods, linear programming, VLSI, and transportation. <p> Absence of a priority queue in our GR refinement algorithm makes it naturally suited for parallel implementations. In contrast, the original KL refinement algorithm (and its generalization in the k-way partitioning context) are inherently sequential [6]. In <ref> [15] </ref> we have developed a highly parallel formulation of our multilevel k-way partitioning algorithm that uses the vertex-coloring of the successively coarser graph to effectively parallelize both the coarsening as well as the k-way refinement algorithms.
Reference: [16] <author> G. Karypis and V. Kumar. </author> <title> A fast and highly quality multilevel scheme for partitioning irregular graphs. </title> <journal> SIAM Journal on Scientific Computing, </journal> <note> to appear. Also available on WWW at URL http://www.cs.umn.edu/karypis. A short version appears in Intl. Conf. on Parallel Processing 1995. </note>
Reference-contexts: After log k phases, graph G is partitioned into k partitions. Thus, the problem of performing a k-way partitioning is reduced to that of performing a sequence of bisections. Recently <ref> [2, 12, 16] </ref> multilevel recursive bisection (MLRB) algorithm has emerged as a highly effective method for computing a k-way partitioning of a graph. The basic structure of a multilevel bisection algorithm is very simple. <p> Since the finer graph has more degrees of freedom, such refinements decrease the edge-cut. The experiments presented in <ref> [16] </ref> show that compared to the state-of-the-art implementation of the well known spectral bisection [1], MLRB produces partitionings that are significantly better and is an order of magnitude faster. <p> The complexity of the MLRB for producing a k-way partitioning of a graph G D .V ; E/, is O.jE j log k/ <ref> [16] </ref>. The multilevel paradigm can also be used to construct a k-way partitioning of the graph directly as illustrated in parts, and this k-partitioning is refined successively as the graph is uncoarsened back into the original graph. <p> Our experiments show that this new scheme produces partitionings that are of comparable or better quality than those produced by the state-of-the-art implementation of the MLRB algorithm <ref> [16] </ref>, and requires substantially smaller time. Graphs containing up to 450000 vertices and 3300000 edges, can be partitioned in 256 partitions in less than 40 seconds on a workstation, such as SGI's Challenge. <p> The remainder of the paper is organized as follows. Section 2 defines the graph partitioning problem and presents the basic concepts of multilevel k-way graph partitioning. Some of the material presented in this section on coarsening strategies is similar to that for multilevel recursive bisection <ref> [12, 16] </ref>, but is included here to make this paper self contained. <p> We also end the coarsening phase if the reduction in the size of successively graphs is less than a factor of 0.8. In the remaining sections we describe three ways that we used to select maximal matchings for coarsening. Two of these matchings, RM [2, 12] and HEM <ref> [16] </ref>, have been previously investigated in the context of MLRB. Random Matching (RM) A maximal matching can be generated efficiently using a randomized algorithm. In our experiments we used a randomized algorithm similar to that described in [2, 12, 16]. The random maximal matching 5 algorithm works as follows. <p> Two of these matchings, RM [2, 12] and HEM [16], have been previously investigated in the context of MLRB. Random Matching (RM) A maximal matching can be generated efficiently using a randomized algorithm. In our experiments we used a randomized algorithm similar to that described in <ref> [2, 12, 16] </ref>. The random maximal matching 5 algorithm works as follows. The vertices are visited in random order. If a vertex u has not been matched yet, then we randomly select one of its unmatched adjacent vertices. <p> As the analysis in [13] shows, since the coarser graph has smaller edge-weight, it also has a smaller edge-cut. Finding a maximal matching that contains edges with large weight is the idea behind the heavy-edge matching originally introduced in <ref> [16] </ref>. A heavy-edge matching is computed using a randomized algorithm similar to that for computing a random matching described earlier. The vertices are again visited in random order. <p> Second, even if we are able to coarsen the graph down to only k vertices, the weights of these vertices are likely to be quite different, making the initial partitioning highly unbalanced. In our algorithm, the k-way partitioning of G m is computed using our multilevel bisection algorithm <ref> [16] </ref>. <p> Now, this becomes the initial partitioning for the next pass of the algorithm. In the case of multilevel recursive bisection algorithms <ref> [2, 12, 16] </ref>, KL refinement becomes very powerful, as the initial partitioning available at each successive uncoarsening level is already a good partition. However, refining a k-way partitioning is significantly more complicated because vertices can move from a partition to many other partitions; thus, increasing the optimization space combinatorially. <p> In summary, GR and GKLR tend to produce partitionings that have similar edge-cuts, but with GKLR requiring significantly more time than GR. 3.3 Comparison with Other Partitioning Schemes recursive bisection algorithm (MLRB) described in <ref> [16] </ref> (implemented in METIS [14]). METIS is a set of programs for partitioning unstructured graphs and for ordering sparse matrices that implements various algorithms described in [16]. For each graph we plot the ratio of the edge-cut of the MLkP algorithm to the edge-cut of the MLRB algorithm. <p> have similar edge-cuts, but with GKLR requiring significantly more time than GR. 3.3 Comparison with Other Partitioning Schemes recursive bisection algorithm (MLRB) described in <ref> [16] </ref> (implemented in METIS [14]). METIS is a set of programs for partitioning unstructured graphs and for ordering sparse matrices that implements various algorithms described in [16]. For each graph we plot the ratio of the edge-cut of the MLkP algorithm to the edge-cut of the MLRB algorithm. Ratios that are less than one indicate that MLkP produces better partitionings than MLRB. For this comparison and for the 14 refinement scheme. <p> For coarse graphs, even a movement of a single vertex at the partition boundary is equivalent to moving a large number of vertices in the original graph. In fact, as discussed in <ref> [16] </ref> even for MLRB, many simpler variations of the KL refinement algorithm, results in equally effective refinement scheme due to the same reason. Absence of a priority queue in our GR refinement algorithm makes it naturally suited for parallel implementations.
Reference: [17] <author> B. W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> The Bell System Technical Journal, </journal> <year> 1970. </year>
Reference-contexts: However in the refinement phase, we need to refine a k-way partitioning, which is considerably more complicated than refining a bisection. In fact, a direct generalization of the KL refinement algorithm to k-way partitioning used in [10] is substantially more expensive than performing a KL refinement of a bisection <ref> [17] </ref>. Even for 8-way refinement, the run time is quite high for these schemes [11]. Computing k-way refinement for k &gt; 8 is prohibitively expensive. In this paper we present a k-way partitioning algorithm. <p> Hence, it may still be possible to improve the projected partitioning of G i1 by local refinement heuristics. A class of local refinement algorithms that tend to produce very good results are those that are based on the Kernighan-Lin (KL) partitioning algorithm <ref> [17] </ref> and their variants [4, 12]. The KL algorithm incrementally swaps vertices among partitions of a bisection to reduce the edge-cut of the partitioning, until the partitioning reaches a local minima. One commonly used variation of the KL algorithm for bisection refinement is due to Fiduccia-Mattheyses [4].
Reference: [18] <author> Gary L. Miller, Shang-Hua Teng, W. Thurston, and Stephen A. Vavasis. </author> <title> Automatic mesh partitioning. </title> <editor> In A. George, John R. Gilbert, and J. W.-H. Liu, editors, </editor> <title> Sparse Matrix Computations: Graph Theory Issues and Algorithms. (An IMA Workshop Volume). </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1993. </year> <month> 24 </month>
Reference-contexts: The run time of our k-way partitioning algorithm is comparable to the run time of a small number (2-4) runs of geometric recursive bisection algorithms <ref> [9, 24, 19, 18, 20] </ref>. Note that geometric algorithms are applicable only if coordinates of the vertices are available, and require tens of runs to produce cuts that are of similar quality to those produced by spectral bisection. The remainder of the paper is organized as follows.
Reference: [19] <author> Gary L. Miller, Shang-Hua Teng, and Stephen A. Vavasis. </author> <title> A unified geometric approach to graph separators. </title> <booktitle> In Proceedings of 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 538-547, </pages> <year> 1991. </year>
Reference-contexts: The run time of our k-way partitioning algorithm is comparable to the run time of a small number (2-4) runs of geometric recursive bisection algorithms <ref> [9, 24, 19, 18, 20] </ref>. Note that geometric algorithms are applicable only if coordinates of the vertices are available, and require tens of runs to produce cuts that are of similar quality to those produced by spectral bisection. The remainder of the paper is organized as follows.
Reference: [20] <author> B. Nour-Omid, A. Raefsky, and G. Lyzenga. </author> <title> Solving finite element equations on concurrent computers. </title> <editor> In A. K. Noor, editor, </editor> <publisher> American Soc. Mech. Eng, </publisher> <pages> pages 291-307, </pages> <year> 1986. </year>
Reference-contexts: The run time of our k-way partitioning algorithm is comparable to the run time of a small number (2-4) runs of geometric recursive bisection algorithms <ref> [9, 24, 19, 18, 20] </ref>. Note that geometric algorithms are applicable only if coordinates of the vertices are available, and require tens of runs to produce cuts that are of similar quality to those produced by spectral bisection. The remainder of the paper is organized as follows.
Reference: [21] <author> R. Ponnusamy, N. Mansour, A. Choudhary, and G. C. Fox. </author> <title> Graph contraction and physical optimization methods: a quality-cost tradeoff for mapping data on parallel computers. </title> <booktitle> In International Conference of Supercomputing, </booktitle> <year> 1993. </year>
Reference: [22] <author> Alex Pothen, H. D. Simon, Lie Wang, and Stephen T. Bernard. </author> <title> Towards a fast implementation of spectral nested dissection. </title> <booktitle> In Supercomputing '92 Proceedings, </booktitle> <pages> pages 42-51, </pages> <year> 1992. </year>
Reference-contexts: For many of these graphs, the process of graph partitioning takes even less time than the time to read the graph from the disk into memory. Compared with the widely used multilevel spectral bisection algorithm <ref> [23, 22, 12] </ref>, our new algorithm is usually two orders of magnitude faster, and produces partitionings with substantially smaller edge-cut. The run time of our k-way partitioning algorithm is comparable to the run time of a small number (2-4) runs of geometric recursive bisection algorithms [9, 24, 19, 18, 20].
Reference: [23] <author> Alex Pothen, Horst D. Simon, and Kang-Pu Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM Journal of Matrix Analysis and Applications, </journal> <volume> 11(3) </volume> <pages> 430-452, </pages> <year> 1990. </year>
Reference-contexts: For many of these graphs, the process of graph partitioning takes even less time than the time to read the graph from the disk into memory. Compared with the widely used multilevel spectral bisection algorithm <ref> [23, 22, 12] </ref>, our new algorithm is usually two orders of magnitude faster, and produces partitionings with substantially smaller edge-cut. The run time of our k-way partitioning algorithm is comparable to the run time of a small number (2-4) runs of geometric recursive bisection algorithms [9, 24, 19, 18, 20].
Reference: [24] <author> P. Raghavan. </author> <title> Line and plane separators. </title> <type> Technical Report UIUCDCS-R-93-1794, </type> <institution> Department of Computer Science, University of Illinois, Urbana, </institution> <address> IL 61801, </address> <month> February </month> <year> 1993. </year>
Reference-contexts: The run time of our k-way partitioning algorithm is comparable to the run time of a small number (2-4) runs of geometric recursive bisection algorithms <ref> [9, 24, 19, 18, 20] </ref>. Note that geometric algorithms are applicable only if coordinates of the vertices are available, and require tens of runs to produce cuts that are of similar quality to those produced by spectral bisection. The remainder of the paper is organized as follows.
Reference: [25] <author> Kirk Schloegel, George Karypis, and Vipin Kumar. </author> <title> Multilevel diffusion schemes for repartitioning of adaptive meshes. </title> <type> Technical Report TR 97-013, </type> <institution> University of Minnesota, Department of Computer Science, </institution> <year> 1997. </year> <note> http://www.cs.umn.edu/karypis. </note>
Reference-contexts: An additional advantage of the MLkP algorithm over MLRB is that MLkP is much more suited in the context of parallel execution of adaptive computations <ref> [26, 25] </ref>. For example, in adaptive finite element computation, the mesh that models the physical domain changes dynamically as the simulation progresses. In particular, some parts of the mesh become finer and other parts get coarser.
Reference: [26] <author> Kirk Schloegel, George Karypis, and Vipin Kumar. </author> <title> Repartitioning of adaptive meshes: Experiments with multilevel diffusion. </title> <booktitle> In Proceedings of the Third International Euro-Par Conference, </booktitle> <pages> pages 945-949, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: An additional advantage of the MLkP algorithm over MLRB is that MLkP is much more suited in the context of parallel execution of adaptive computations <ref> [26, 25] </ref>. For example, in adaptive finite element computation, the mesh that models the physical domain changes dynamically as the simulation progresses. In particular, some parts of the mesh become finer and other parts get coarser.
Reference: [27] <author> Horst D. Simon and Shang-Hua Teng. </author> <title> How good is recursive bisection? Technical Report RNR-93-012, NAS Systems Division, </title> <booktitle> Moffet Field, </booktitle> <address> CA, </address> <year> 1993. </year> <month> 25 </month>
Reference-contexts: First, the entire graph now needs to be coarsened only once, reducing the complexity of this phase to O.jEj/ down from O.jEj log k/. Second, it is well known that recursive bisection can do arbitrarily worse than k-way partitioning <ref> [27] </ref>. Thus, a method that obtains a k-way partitioning directly can potentially produce much better partitionings. Note that the direct computation of a good k-way partitioning is harder than the computation of a good bisection (although both problems are NP-hard) in general.
References-found: 27

