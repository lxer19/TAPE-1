URL: http://www.cs.berkeley.edu/~daf/icip97-2.ps.Z
Refering-URL: http://elib.cs.berkeley.edu:8080/admin/quarterly_reports/report.97.html
Root-URL: 
Email: daf@cs.berkeley.edu mfleck@cs.uiowa.edu  
Title: Finding People and Animals by Guided Assembly  
Author: D.A. Forsyth M.M. Fleck 
Keyword: Object Recognition, Computer Vision, Content based retrieval, Image databases, Learning in vision  
Address: Berkeley, CA 94720 Iowa City, IA 52240  
Affiliation: Computer Science Division Department of Computer Science U.C. Berkeley University of Iowa  
Abstract: This paper describes a new representation for people and animals, called a body plan. The representation is an organized collection of grouping hints obtained from constraints on color, texture, shape, and geometrical relations. Body plans can be learned from image data, using established statistical learning techniques. Body plans are well adapted to segmentation and recognition in complex environments, such as the huge libraries of digitized images now becoming widely available. Two specific applications of body plans are presented: an algorithm that determines whether an image depicts a scantily clad human and an algorithm that learns and uses a body plan to find pictures of horses. Both algorithms demonstrate excellent performance on large, poorly controlled input data. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Connell, Jonathan H. and J. </author> <title> Michael Brady "Generating and Generalizing Models of Visual Objects," </title> <booktitle> Artificial Intelligence 31/2, </booktitle> <pages> pp. 159-183, </pages> <year> 1987 </year>
Reference-contexts: These observations suggest representing objects as assemblies of a constrained class of primitive: cylinders or generalized cylinders. Typical versions of this idea appear in <ref> [1, 2, 3, 7, 9] </ref>. Previous algorithms, however, have displayed little practical success, because their models contain insufficient information to support robust segmentation. The key to success is for segmentation and recognition to use all the information and constraints available from the object model.

Reference: [3] <author> Binford, </author> <title> T.O., "Body-centered representation and perception," ProceedingsObject Representation in Computer Vision., Hebert, </title> <editor> M. et al. (eds), </editor> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: These observations suggest representing objects as assemblies of a constrained class of primitive: cylinders or generalized cylinders. Typical versions of this idea appear in <ref> [1, 2, 3, 7, 9] </ref>. Previous algorithms, however, have displayed little practical success, because their models contain insufficient information to support robust segmentation. The key to success is for segmentation and recognition to use all the information and constraints available from the object model.
Reference: [4] <author> M.M. Fleck, D.A. Forsyth and C. Bregler, </author> <title> "Finding naked people," </title> <booktitle> Proc. European Conf. on Computer Vision, Edited by: </booktitle> <editor> Buxton, B.; Cipolla, R. </editor> <address> Berlin, Germany: </address> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <pages> p. 593-602 </pages>
Reference-contexts: This measures how well the algorithm, acting as a filter, is increasing the density of test images in its output set, relative to its input set. 3.1 Sparsely clad humans The basic structure of our system is described in <ref> [4] </ref>, which describes the body plan used; the experimental results given here are more recent. The system segments human skin using colour and texture criteria, assembles extended segments, and uses a simple, hand built body plan to support geometric reasoning. <p> Test images were automatically reduced to fit into a 128 by 192 window, and rotated as necessary to achieve the minimum reduction. 4302 assorted images were used as controls. If images are selected only on the basis of the number of skin pixels only (see <ref> [4] </ref>), 448 test images are marked (a recall of 79 % ) but 485 control images are marked. Thus, the response ratio is 7.
Reference: [5] <author> Forsyth, D.A. and Fleck, </author> <title> M.M., "Body Plans," </title> <booktitle> Proc. </booktitle> <address> CVPR-97, </address> <year> 1997. </year>
Reference-contexts: For a sufficiently large collection of segments, the kinematic constraints on mammalian joints imply that the predicate will fail on many false groups. We use a simple learning strategy for learning these predicates. A more detailed description of the implementation appears in in <ref> [5] </ref>. 3 Experimental results We have built two systems to demonstrate the new approach. The first can very accurately tell whether an image contains a person wearing little or no clothing; the second can tell whether an image contains a horse.
Reference: [6] <author> Forsyth, D.A., Malik, J., Fleck, M.M., Greenspan, H., Le-ung, T., Belongie, S., Carson, C. and Bregler, C., </author> <title> "Finding pictures of objects in large collections of images," </title> <booktitle> Proc. 2'nd International Workshop on Object Representation in Computer Vision, </booktitle> <month> April, </month> <year> 1996. </year>
Reference-contexts: In other words, they require algorithms which can perform object recognition, using large, general model-bases, to which new classes of object or action can easily be added. Typical content-based retrieval systems, reviewed briefly along with user requirements in <ref> [6] </ref>, model images as collections of two dimensional coloured and textured shapes. This paradigm has motivated extensive work on user interfaces that support image recovery.
Reference: [7] <author> Marr, D., and Nishihara, H.K., </author> <title> "Representation and Recognition of the Spatial Organization of Three-Dimensional Shapes", </title> <journal> Proc. Roy. Soc. B, </journal> <volume> B-200, </volume> <pages> 269-294, </pages> <year> 1977. </year>
Reference-contexts: These observations suggest representing objects as assemblies of a constrained class of primitive: cylinders or generalized cylinders. Typical versions of this idea appear in <ref> [1, 2, 3, 7, 9] </ref>. Previous algorithms, however, have displayed little practical success, because their models contain insufficient information to support robust segmentation. The key to success is for segmentation and recognition to use all the information and constraints available from the object model.
Reference: [8] <author> Wren, C., Azabayejani, A., Darrell, T. and Pentland, A., "Pfinder: </author> <title> real-time tracking of the human body," MIT Media Lab Perceptual Computing Section TR 353, </title> <year> 1995. </year>
Reference-contexts: Robust performance on large image collections requires a more flexible theory of shape. Building satisfactory systems also requires automatic segmentation of significant objects. Typical recent systems for finding people or animals typically simplify segmentation using either motion cues or a known or simplified background (e.g. <ref> [8] </ref>, which segments by subtracting a known background).
Reference: [9] <author> Zerroug, M. and Nevatia, R., </author> <title> "Three-dimensional part-based descriptions from a real intensity image," </title> <booktitle> Proceedings of 23rd Image Understanding Workshop, </booktitle> <year> 1994. </year>
Reference-contexts: These observations suggest representing objects as assemblies of a constrained class of primitive: cylinders or generalized cylinders. Typical versions of this idea appear in <ref> [1, 2, 3, 7, 9] </ref>. Previous algorithms, however, have displayed little practical success, because their models contain insufficient information to support robust segmentation. The key to success is for segmentation and recognition to use all the information and constraints available from the object model.
Reference: [10] <author> Zisserman, A., Forsyth, D.A., Mundy, J.L., Rothwell, C.A., and Liu, J.S., </author> <title> "3D Object Recognition using Invariance," </title> <journal> Artificial Intelligence, </journal> <volume> 78, </volume> <pages> 239-288, </pages> <year> 1995. </year>
References-found: 9

