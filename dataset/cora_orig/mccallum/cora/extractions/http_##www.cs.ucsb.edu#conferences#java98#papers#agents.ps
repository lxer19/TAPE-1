URL: http://www.cs.ucsb.edu/conferences/java98/papers/agents.ps
Refering-URL: http://www.cs.ucsb.edu/conferences/java98/program.html
Root-URL: http://www.cs.ucsb.edu
Title: Adaptive Placement of Parallel Java Agents in a Scalable Computing Cluster  
Author: Arie Keren and Amnon Barak 
Address: Jerusalem 91904, Israel  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Abstract: This paper describes a framework for parallel computing in a locally confined, scalable computing cluster (SCC) using Java agents. The framework consists of a programming model with agents and asynchronous invocations, and a scheme for adaptive placement of multiple agents in an SCC. Our scheme is geared to improve the overall performance by a dynamic match between the available cluster resources and the execution requirements of the agents. This is accomplished by agent migrations among the nodes using on-line algorithms for load leveling and reduction of the inter agent communication overhead. Simulations of several examples show that our scheme outperforms a static agent placement scheme by as much as 40% for the test cases.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Agha. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Note that these annotations may impair the simplicity and the portability of a parallel application. An alternative approach, is to extend the Java object model towards distributed memory architectures, using a variation of the Actor model <ref> [1] </ref>, which is the basis for many parallel object-oriented systems. In the Actor model each object has its own memory, objects are active, and they cooperate by exchanging messages. Our framework adopts an Actor-based approach and extends Java with agents and asynchronous method invocations.
Reference: [2] <author> T. E. Anderson, D. E. Culler, and D. A. Patterson. </author> <title> A case for NOW. </title> <journal> IEEE Micro, </journal> <volume> 15(1) </volume> <pages> 54-64, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Such applications could be implemented by using multiple, collaborating agents, called "parallel agents". Parallel agents can be useful for the execution of demanding applications, e.g., data mining and high-performance computing. A possible hardware configuration of a web-server for the execution of parallel agents is a Scalable Computing Cluster (SCC) <ref> [2] </ref>, consisting of a collection of commodity workstations that are connected by a high speed LAN. This is a cost-effective high performance environment that offers opportunities for parallel processing, parallel I/O and high availability.
Reference: [3] <author> A. Barak, S. Guday, and R. G. Wheeler. </author> <title> The MOSIX Distributed Operating System, Load Balancing for UNIX, chapter 8. </title> <publisher> LNCS 672. Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: This index is sent to other nodes using two simultaneous dessimination schemes. First, each node sends its load index by attaching it to messages that are sent by its agents to other nodes. Load indexes are also sent to randomly chosen nodes, using a probabilistic load exchange algorithm <ref> [3] </ref>, in order to support a dynamic configuration. The net result is that at each time unit, each node has information about a subset of nodes in the cluster. This subset is called the node's information window.
Reference: [4] <author> J. B. Carter, J. K. Bennett, and W. Zwaenepoel. </author> <title> Techniques for reducing consistency-related communication in distributed shared-memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 13(3) </volume> <pages> 205-243, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Therefore, in practical DSM systems the programmer is responsible to annotate the application objects with the appropriate consistency protocol, or even to implement some application-specific protocol, in order to reduce the number of such messages <ref> [4] </ref>. Note that these annotations may impair the simplicity and the portability of a parallel application. An alternative approach, is to extend the Java object model towards distributed memory architectures, using a variation of the Actor model [1], which is the basis for many parallel object-oriented systems.
Reference: [5] <author> G. Fox and W. Furmanski. </author> <title> Overview of Java for parallel computing and as a general language for scientific and engineering simulation and modelling. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 9(6), </volume> <month> June </month> <year> 1997. </year>
Reference-contexts: Java is the main language for implementing WWW agents [7]. This is due to its ability to support code mobility. Other advantages of Java are its simplicity, object-orientation, portability and multi-threading. This make it ideal for the development of parallel applications <ref> [5] </ref>. Such applications could be implemented by using multiple, collaborating agents, called "parallel agents". Parallel agents can be useful for the execution of demanding applications, e.g., data mining and high-performance computing.
Reference: [6] <author> L. V. Kale, M. Bhandarkar, and T. Wilmarth. </author> <title> Design and implementation of parallel Java with global object space. </title> <booktitle> In PDPTA'97, </booktitle> <month> July </month> <year> 1997. </year>
Reference-contexts: Object migration is supported and can be used by the runtime system to balance the load and to enhance locality. Parallel Java <ref> [6] </ref>, another project similar to ours, extends Java with remote objects, one-way asynchronous invocations and object groups. A simple static load-balance strategy creates remote objects on a randomly chosen node. Migration is not supported. This paper presents a framework for agent-based parallel computing in a locally confined computing cluster.
Reference: [7] <author> J. Kiniry and D. Zimmerman. </author> <title> A hands-on look at Java mobile agents. </title> <journal> IEEE Internet Computing, </journal> <volume> 1(4) </volume> <pages> 21-30, </pages> <month> July </month> <year> 1997. </year>
Reference-contexts: 1 Introduction Agent-based software engineering has become a popular methodology for the development of advanced software systems. Java is the main language for implementing WWW agents <ref> [7] </ref>. This is due to its ability to support code mobility. Other advantages of Java are its simplicity, object-orientation, portability and multi-threading. This make it ideal for the development of parallel applications [5]. Such applications could be implemented by using multiple, collaborating agents, called "parallel agents".
Reference: [8] <author> K. Langendoen, R. Bhoedjang, and H. Bal. </author> <title> Models for asynchronous message handling. </title> <journal> IEEE Concurrency, </journal> <volume> 5(2) </volume> <pages> 28-38, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Current implementations of distributed objects in Java, e.g. RMI, suffer from poor performance which limit their possible usage in parallel applications. On the other hand, recent works showed that multi-threading and asynchronous models of communication can be efficiently implemented on high-speed networks <ref> [8] </ref>. It is an open question if these methods can be used for an implementation of low-latency communication in Java. We are also developing a new scheme, that is based on theoretically proven competitive algorithms, for on-line assignment of agents in a scalable computing cluster.
Reference: [9] <author> F. Mueller. </author> <title> Distributed shared-memory threads: </title> <booktitle> DSM-Threads. In Workshop on Runtime Systems for Parallel Programming (RTSPP), </booktitle> <address> IPPS'97, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: The execution requirements of the agents are monitored and dynamically matched against the overall, available cluster resources. 2 Agent-based parallel computing in Java One possible approach for Java-based parallel programming in distributed-memory multicomputers, is to use Distributed Shared Memory (DSM) in order to provide the shared-memory illusion for threads <ref> [9] </ref>. However, DSM can suffer from poor performance due to the overhead of the messages that preserve the consistency of shared objects.
Reference: [10] <author> ObjectSpace. </author> <title> ObjectSpace Voyager, </title> <type> Technical Overview, </type> <month> September </month> <year> 1997. </year>
Reference-contexts: We plan to implement the described framework in our scalable computing cluster that consists of over 80 Pentium based PC's connected by the Myrinet LAN. The implementation involves two concurrent efforts. The first one will use an existing Java agent system which offers communication and mobility mechanisms, e.g. Voyager <ref> [10] </ref>. We will add a management layer that will implement the proposed load balancing scheme. The second effort emphases an efficient implementation of the basic communication and mobility mechanisms in the JVM, or above it. Current implementations of distributed objects in Java, e.g.
Reference: [11] <author> M. Philippsen and M. Zenger. </author> <title> JavaParty transparent remote objects in Java. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 9(11) </volume> <pages> 1225-1242, </pages> <month> November </month> <year> 1997. </year> <month> 5 </month>
Reference-contexts: Several projects use Java as a language for parallel computation in a locally confined computing cluster, in which all the machines are located in close proximity and belong to the same organization, e.g., a multiprocessor web server. For example, JavaParty <ref> [11] </ref> is geared to support parallel computing on a cluster of workstations by providing a semi-transparent DSM, in which remote objects and threads are explicitly identified by means of the remote keyword.
References-found: 11

