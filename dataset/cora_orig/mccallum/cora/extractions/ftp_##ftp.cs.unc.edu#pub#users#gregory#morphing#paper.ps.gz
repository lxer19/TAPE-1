URL: ftp://ftp.cs.unc.edu/pub/users/gregory/morphing/paper.ps.gz
Refering-URL: http://www.cs.unc.edu/~lin/papers.html
Root-URL: http://www.cs.unc.edu
Email: -gregory,andrei,lin,dm,livingst-@cs.unc.edu  
Title: Feature-based Surface Decomposition for Polyhedral Morphing  
Author: Arthur Gregory, Andrei State, Ming C. Lin, Dinesh Manocha, Mark A. Livingston 
Web: http://www.cs.unc.edu/~geom/3Dmorphing  
Address: Chapel Hill  
Affiliation: Department of Computer Science, University of North Carolina at  
Abstract: We present a new approach for establishing correspondence for morphing between two homeomorphic polyhedral models. The user can specify corresponding feature pairs on the polyhedra with a simple and intuitive interface. Based on these features, our algorithm decomposes the boundary of each polyhedron into the same number of morphing patches. A 2D mapping for each morphing patch is computed in order to merge the topologies of the polyhedra one patch at a time. We create a morph by defining morphing trajectories between the feature pairs and by interpolating them across the merged polyhedron. The user interface provides high-level control as well as local refinement to improve the morph. The implementation has been applied to several polyhedra composed of thousands of polygons. The system can also handle homeomorphic non-simple polyhedra that have holes. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Barr, A., </author> <title> Global and local deformations of solid primitives. </title> <journal> ACM Computer Graphics, 1984. </journal> <volume> 18(3): </volume> <pages> p. 21-30. </pages>
Reference-contexts: Therefore, approaches based on voxelization followed by 3D volume morphing have limitations as well. 2.3 3D Shape Transformations and Metamorphosis Several approaches related to establishing correspondence between 3D polygonal objects for shape transformation and metamorphosis have been proposed. Physically-based modeling techniques based on deformations <ref> [1, 37] </ref> and particle systems [33] can be used for object metamorphosis. Hong et al. [18] present an approach for polyhedral models that matches the faces whose centroids are closest. Chen and Parent [6] present an algorithm to transform piecewise linear 2D contours and extend it to 3D cylindrical objects.
Reference: 2. <author> Beier, T. and S. Neely, </author> <title> Feature-based image metamorphosis, </title> <booktitle> in Computer Graphics (SIGGRAPH '92 Proceedings). 1992. p. </booktitle> <pages> 35-42. 26 </pages>
Reference-contexts: Initially the user selects some corresponding elements called feature pairs. Although we borrow this term from previous morphing algorithms for images or 3D volumetric models <ref> [2, 26] </ref>, our concept of a feature is closer to the sparse control mesh used in [11]. Our algorithm includes a simple and intuitive user interface for feature specification and automatically generates a feature net. <p> The set of algorithms can be classified into those that operate on raster images <ref> [2, 10, 25, 41, 42] </ref> and those that operate on vector-based or geometric representations [15, 35, 36, 40]. A common procedure to establish correspondence is to place a mesh over the entire image, which implies a bilinear warping function. <p> A common procedure to establish correspondence is to place a mesh over the entire image, which implies a bilinear warping function. Warping of these features can be controlled by energy minimization [36] or feature-based constraints [35]. Beier and Neely presented an elegant feature-based approach <ref> [2] </ref>. The features may correspond to points or lines [2, 39] or to snakes [25]. Mappings that have been used include (bi)linear mappings [2, 39] and spline-based mappings or freeform deformations [25] in conjunction with a weighting function which effectively controls the range over which a feature has influence. <p> Warping of these features can be controlled by energy minimization [36] or feature-based constraints [35]. Beier and Neely presented an elegant feature-based approach [2]. The features may correspond to points or lines <ref> [2, 39] </ref> or to snakes [25]. Mappings that have been used include (bi)linear mappings [2, 39] and spline-based mappings or freeform deformations [25] in conjunction with a weighting function which effectively controls the range over which a feature has influence. <p> Warping of these features can be controlled by energy minimization [36] or feature-based constraints [35]. Beier and Neely presented an elegant feature-based approach [2]. The features may correspond to points or lines <ref> [2, 39] </ref> or to snakes [25]. Mappings that have been used include (bi)linear mappings [2, 39] and spline-based mappings or freeform deformations [25] in conjunction with a weighting function which effectively controls the range over which a feature has influence. Ranjan and Fournier [32] presented an approach which uses circles to partition the objects. <p> These include use of Fourier transforms that warp linearly in Fourier space [19]. This is a simple approach and requires minimal user specification, but inhibits intuitive understanding of the morph. Lerios et al. [26] have presented a 3D extension of Beier and Neelys <ref> [2] </ref> approach. It allows the user to specify a set of features and permits fine user control. 3D polyhedral models can be voxelized to allow use of 3D-volume morphing. However, the intermediate stages of the morph are volumes and converting them into 4 geometric models produces topologically complex objects. <p> Scaling, positioning, and orienting the input polyhedra with respect to each other must be performed by the user in preparation for 3D morphing and directly influences the appearance of the morph. This requirement is quite similar to the preparation required for 2D image morphing <ref> [2] </ref>. <p> The algorithm computes 19 weighting factors for each extremal vertex based on their distances along shortest paths toward the interior vertex. The weighting function is similar to that of Beier and Neely <ref> [2] </ref>. highlighted (white) trajectory is shown with its Bzier control points, which are the fixed endpoints of the trajectory. The green control points can be moved by the user. In both cases above, the weighting factors are applied to the tangent vectors at each endpoint of a trajectory. <p> The algorithm also allows the user to individually modify this mapping for 20 individual extremal vertices, in order to make some parts of the polyhedrons morph sooner or later than others. This is analogous to the techniques used for 2D image morphing <ref> [2] </ref>. 6.3 Interpolating Surface Attributes In addition to the morphing trajectories required by the algorithm, other attributes of the input polyhedra need to be interpolated to generate a good morph. These include vertex colors, lighting coefficients, normal vectors, etc. <p> In the worst case it can take O ((m+n) k log Q) time. As result, the overall complexity of the algorithm is O (K (m+n)), where K = max-k log Q ,Q-. Our approach does not suffer from the ghosting problems seen in image and volume morphing <ref> [2, 26] </ref>. However, a similar scenario can occur, self-intersection. We can check for it automatically through collision detection algorithms, but this is prohibitively expensive. Furthermore, self-intersection may be desirable and in some cases even necessary in order to allow some part of a morphing object to reach its target position. <p> Morphing between animated models. In traditional 2D morphing, an image sequence of a moving actor can be morphed into another sequence showing a different moving actor. This is typically accomplished by (tediously) re-specifying correspondences for each pair (or at least for many pairs) of frames within the image sequences <ref> [2] </ref>. An extension of our approach could handle this problem in the following way: once correspondences have been specified for a computer-animated character, they can remain attached to the character's topology and carry over throughout the animation sequence. In other words, the correspondence features are animated together with the character.
Reference: 3. <author> Berg, </author> <title> M.d., </title> <editor> et al., </editor> <booktitle> Computational Geometry: Algorithms and Applications. 1997: </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: The time complexity of this part of the algorithm depends on the complexity of locating the triangle for each interior vertex of P A i . A simple search procedure would be linear in the number of triangles. However, using efficient data structures for planar point location <ref> [3] </ref>, which involves linear time preprocessing, this search time can be reduced to be logarithmic in the number of triangles. 16 5.4 Merging The algorithm has so far produced mappings into p i such that the vertices V A A V j =&gt; v j , and edges E A A <p> After intersection computation and splitting, we denote the set of all vertices and edges in p i by x AB AB , respectively. 5.5 Reconstruction After computing the intersection of all the edges, the algorithm produces a planar straight-line graph (PSLG) <ref> [3] </ref> from those intersections. The PSLG is constructed from the x and g . The next step is to compute a triangulation of these PSLGs.
Reference: 4. <author> Bethel, E. and S. Uselton, </author> <title> Shape distortion in computer-assisted keyframe animation, in State of the Art in Computer Animation, </title> <editor> N.M.-T.a.D. Thalmann, Editor. </editor> <booktitle> 1989, </booktitle> <publisher> Springer-Verlag. </publisher> <address> p. </address> <pages> 215-224. </pages>
Reference-contexts: Hong et al. [18] present an approach for polyhedral models that matches the faces whose centroids are closest. Chen and Parent [6] present an algorithm to transform piecewise linear 2D contours and extend it to 3D cylindrical objects. Bethel and Uselton <ref> [4] </ref> add degenerate vertices and faces to two polyhedra until they have a common vertex neighborhood graph. Kaul and Rossignac [21] transform a pair of polyhedra by using their Minkowski sums. Hodgins and Pollard [17] have presented an algorithm for interpolating between control systems of dynamic models.
Reference: 5. <author> Chen, D., A. State, and D. </author> <title> Banks, Interactive Shape Metamorphosis. </title> <booktitle> Proc. of 1995 Symposium on Interactive 3D Graphics, 1995: p. </booktitle> <pages> 43-44. </pages>
Reference-contexts: Parent [29, 30] has also described a method for deformation of polyhedral objects based on implicit functions. Kent et al. [22, 23] have presented a shape transformation algorithm for genus-0 polyhedra that involves projecting the models onto a sphere. Chen et al. <ref> [5] </ref> have produced 3D morphs of cylindrical images. Galin and Akkouche [13] have presented an algorithm for blob metamorphosis based on Minkowski sums. Lazarus and Verroust [24] have proposed a method based on skeletal curves.
Reference: 6. <author> Chen, E. and R. Parent, </author> <title> Shape Averaging and its Applications to Industrial Design. </title> <journal> IEEE Computer Graphics & Applications, 1989. </journal> <volume> 9(1): </volume> <pages> p. 47-54. </pages>
Reference-contexts: It is possible to generate 2D images from a 3D model and apply 2D morphing algorithms to these. In this case, the intermediate stages of the morph are images. For many applications in animation and design, the 3D models themselves should be transformed and not their images <ref> [6, 21] </ref>. Furthermore, if the viewpoint or the lighting parameters are changed, the 2D morph has to be recomputed. On the other hand, 3D morphing is independent of viewing or lighting parameters. <p> Physically-based modeling techniques based on deformations [1, 37] and particle systems [33] can be used for object metamorphosis. Hong et al. [18] present an approach for polyhedral models that matches the faces whose centroids are closest. Chen and Parent <ref> [6] </ref> present an algorithm to transform piecewise linear 2D contours and extend it to 3D cylindrical objects. Bethel and Uselton [4] add degenerate vertices and faces to two polyhedra until they have a common vertex neighborhood graph.
Reference: 7. <author> Chen, M., M.W. Jones, and P. Townsend, </author> <title> Methods for Volume Metamorphosis, in Image Processing for Broadcast and Video Production, </title> <editor> Y.P.a.S. Wilbur, Editor. </editor> <year> 1995. </year>
Reference-contexts: Having a 3D representation also allows the use of computer animation techniques such as keyframing. 2.2 3D Volume Morphing Given two volumes, 3D volume morphing involves producing a sequence of volumes to transform them. A number of approaches have been published <ref> [7, 9, 16, 26, 31] </ref>. These include use of Fourier transforms that warp linearly in Fourier space [19]. This is a simple approach and requires minimal user specification, but inhibits intuitive understanding of the morph. Lerios et al. [26] have presented a 3D extension of Beier and Neelys [2] approach.
Reference: 8. <author> Clarkson, K.L. and P.W. Shor, </author> <title> Applications of random sampling in computational geometry, II. </title> <journal> Discrete Comput. Geom., 1989. </journal> <volume> 4: </volume> <pages> p. 387-421. </pages>
Reference-contexts: In the worst case, k e can be O (n e 2 ). Efficient and optimal algorithms of complexity O (n e log n e + k e ) have been proposed by Clarkson and Shor <ref> [8] </ref> to compute the intersections. However, we are not aware of any robust implementations of these algorithms. In our application, we encounter many degenerate edge configurations. These include almost coincident edges and vertices.

References-found: 8

