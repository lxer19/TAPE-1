URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3346/3346.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: lionel, basili-@cs.umd.edu  morasca@elet.polimi.it  
Title: Goal-Driven Definition of Product Metrics Based on Properties  
Author: Lionel Briand*, Sandro Morasca**, Victor R. Basili* 
Address: College Park, MD, 20742  Piazza Leonardo da Vinci 32, I-20133 Milano, Italy  
Date: 1  
Affiliation: University of Maryland,  Computer Science Department University of Maryland,  Dipartimento di Elettronica e Informazione Politecnico di Milano  
Pubnum: CS-TR-3346  
Abstract: Defining product metrics requires a rigorous and disciplined approach, because useful metrics depend, to a very large extent, on one's goals and assumptions about the studied software process. Unlike in more mature scientific fields, it appears difficult to devise a "universal" set of metrics in software engineering, that can be used across application environments. We propose an approach for the definition of product metrics which is driven by the experimental goals of measurement, expressed via the GQM paradigm, and is based on the mathematical properties of the metrics. This approach integrates several research contributions from the literature into a consistent , practical and rigorous approach. The approach we outline should not be considered as a complete and definitive solution, but as a starting point for discussion about a product metric definition approach widely accepted in the software engineering community. At this point, we intend to provide an intellectual process that we think is necessary to define sound software product metrics. A precise and complete documentation of such an approach will provide the information needed to make the assessment and reuse of a new metric possible. Thus, product metrics are supported by a solid theory which facilitates their review and refinement. Moreover, their definition is made less exploratory and, as a consequence, one is less likely to identify spurious correlations between process and product metrics. 
Abstract-found: 1
Intro-found: 1
Reference: [B92] <author> V. Basili, </author> <title> "Software Modeling and Measurement: </title> <institution> The Goal/Question/Metric Paradigm" University of Maryland, Department of Computer Science, </institution> <type> Tech. Rep. </type> <institution> CS-TR-2956, </institution> <year> 1992. </year>
Reference-contexts: A simple probability calculation [F91] shows that this kind of approach is likely to lead to the identification of spurious statistical relationships, e.g., correlations uniquely due to coincidence. Several important research issues involved in the definition of such an approach have already been investigated. Basili et al. <ref> [B92] </ref> [BR88] have provided templates to define operational experimental goals for software University of Maryland, CS-TR-3346 - 3 measurement. Melton et al. have studied product abstraction properties [MGB90]. Weyuker [W88] and Tian and Zelkowitz [TZ92] have studied desirable properties for complexity metrics. <p> Step 1: Define Experimental Goal (s) Define the experimental goal (s) of the data collection, based on the general corporate objectives (e.g. reduce cycle time) and the available information about the studied development environment (e.g., weaknesses, problems). This step requires goal definition techniques. The Goal/Question/Metric paradigm (GQM) <ref> [B92] </ref> [BR88] is one of the approaches that can be used to this end. It provides a set of templates to define experimental goals and refines them into concrete and realistic questions, which subsequently lead to the definition of metrics. <p> As we will see in Section 6, questions about product characteristics are no longer necessary in our approach. However, GQM questions on the confidence with which assumptions are stated and on the quality (e.g., accuracy of collection procedures, granularity) of data to be collected <ref> [B92, BR88] </ref> still need to be asked. We will not address this issue, which is beyond the scope of this paper. <p> Each step will be discussed in detail in a different section. Each section contains three subsections: Definition of the step Examples Discussion of related issues. 3. Define Experimental Goal (s) (Step 1) Definition In this section, we apply the first step of the Goal/Question/Metric paradigm <ref> [B92, BR88] </ref> to set the measurement goals. Here is a summary of templates that can be used to define goals: Object of study: products, processes, resources Purpose: characterization, evaluation, prediction, improvement, ... Quality focus: cost, correctness, defect removal, changes, reliability, ... Viewpoint: user, customer, manager, developer, corporation, ... <p> Quality focus: cost, correctness, defect removal, changes, reliability, ... Viewpoint: user, customer, manager, developer, corporation, ... A detailed description of the GQM paradigm is beyond the scope of the paper. A comprehensive description of the GQM paradigm can be found in <ref> [B92, BR88] </ref>. It is important to note that the four goal dimensions mentioned above have a direct impact on the remaining steps of the metric definition approach and, from a more general perspective, the whole data collection program.
Reference: [BBC88] <author> J. Bieman et al, </author> <title> "A Standard Representation of Imperative Language Programs for Data Collection and Software Measures Specification", </title> <journal> J. Syst. Software, </journal> <volume> vol. 8, </volume> <pages> pp. 13-37, </pages> <year> 1988. </year>
Reference-contexts: Several abstractions capturing control flow, data flow and data dependency information are available in the literature <ref> [M90, BBC88, O80] </ref>. However, an even larger variety of abstractions can be derived from software products. The set of properties associated with each concept is expanded so as to formalize the order existing on the set of abstractions with respect to each concept as defined by the assumptions. <p> This shows how generic properties constrain the definition of metrics and help make the right decisions. As an example of distance calculations, consider the DU graph in Figure 2. If Assumption 5 is considered, a different abstraction is necessary: Data-Dependency (D-D) graphs <ref> [BBC88] </ref>. This abstraction captures the links between condition expressions and the definitions they can affect. In this case, the following property holds: Property CD3: Definitions versus condition expressions Let DDG 1 and DDG 2 be two Data Dependency graphs.
Reference: [BBH93] <author> L. Briand, V. Basili and C. Hetmanski, </author> <title> "Developing Interpretable Models with Optimized Set Reduction for Identifying High Risk Software Components," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 19 (11), </volume> <month> November, </month> <year> 1993. </year>
Reference-contexts: Such an approach appears particularly necessary for product metrics since these metrics are often more complex than process metrics and address phenomena that are poorly understood. The goal of this paper is to specify (based on our experience <ref> [BMB93, BBH93, BMB94 (a)] </ref>) a practical metric definition approach, specifically aimed at product metrics, and usable as a practical guideline to design technically sound and useful metrics. The focus will be the construction of prediction systems, which is a crucial application of measurement. <p> University of Maryland, CS-TR-3346 - 22 With respect to prediction, experimental validation may be seen as a search for statistical relationships between metrics of the object of study and a descriptive models of the quality focus (e.g., # error for Error-proneness). Numerous analysis techniques, both univariate and multivariate <ref> [S92, BBH93, DG84] </ref>, exist in the statistical and machine learning literature. If such assumptions and properties are not validated, we need to repeat from Step 2, reconsider the assumptions and properties, then redefine new metrics. This metric definition/validation cycle is iterated until the metric validation yields satisfactory results. <p> This approach integrates many contributions from the literature and is intended to be the starting point for a practical product metric definition approach to be discussed by the software engineering community, on both the academic and industrial sides. This approach is the result of our past experience <ref> [BMB93, BBH93, BMB94 (a)] </ref> and is validated through realistic examples. Our future work encompasses a more detailed study and validation of each of the steps involved in the metric definition approach.
Reference: [BBK94] <author> L. Briand, V. Basili, Y. M. Kim and D. Squier, </author> <title> "A Change Analysis Process to Characterize Software Maintenance Projects," </title> <booktitle> IEEE Conference on Software Maintenance, </booktitle> <month> September </month> <year> 1994, </year> <institution> Victoria, British Columbia, Canada. </institution>
Reference-contexts: Various sources of information can be used to devise pertinent assumptions. A thorough understanding of the working procedures, methodologies and techniques used in the studied development environment, combined with the interview of domain experts, is usually very helpful <ref> [BBK94] </ref>. The set of assumptions defines an ordering on the set of products [MGB90] with respect to the quality focus. This ordering will be used to evaluate the adequacy of the metrics defined in the remainder of this approach.
Reference: [BMB93] <author> L. Briand, S. Morasca, V. Basili, </author> <title> "Assessing Software Maintainability at the End of High-Level Design, </title> <booktitle> IEEE Conference on Software Maintenance, </booktitle> <month> September </month> <year> 1993, </year> <institution> Montreal, Quebec, Canada. </institution>
Reference-contexts: Such an approach appears particularly necessary for product metrics since these metrics are often more complex than process metrics and address phenomena that are poorly understood. The goal of this paper is to specify (based on our experience <ref> [BMB93, BBH93, BMB94 (a)] </ref>) a practical metric definition approach, specifically aimed at product metrics, and usable as a practical guideline to design technically sound and useful metrics. The focus will be the construction of prediction systems, which is a crucial application of measurement. <p> This approach integrates many contributions from the literature and is intended to be the starting point for a practical product metric definition approach to be discussed by the software engineering community, on both the academic and industrial sides. This approach is the result of our past experience <ref> [BMB93, BBH93, BMB94 (a)] </ref> and is validated through realistic examples. Our future work encompasses a more detailed study and validation of each of the steps involved in the metric definition approach.
Reference: [BMB94(a)] <author> L. Briand, S. Morasca, V. Basili, </author> <title> "Defining and Validating High-Level Design Metrics", </title> <type> CS-TR 3301, </type> <institution> UMIACS-TR 94-75, University of Maryland, College Park </institution>
Reference: [BMB94(b)] <author> L. Briand, S. Morasca, V. Basili, </author> <booktitle> "Property-based Software Engineering Measurement," </booktitle> <address> CS-TR 3368, UMIACS-TR 94-119, </address> <institution> University of Maryland, College Park </institution>
Reference: [BR88] <author> V. Basili and D. Rombach, </author> <title> "The Tame Project: Towards Improvement-Oriented Software Environments," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 14, no. 6, </volume> <pages> pp. 758-773, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: A simple probability calculation [F91] shows that this kind of approach is likely to lead to the identification of spurious statistical relationships, e.g., correlations uniquely due to coincidence. Several important research issues involved in the definition of such an approach have already been investigated. Basili et al. [B92] <ref> [BR88] </ref> have provided templates to define operational experimental goals for software University of Maryland, CS-TR-3346 - 3 measurement. Melton et al. have studied product abstraction properties [MGB90]. Weyuker [W88] and Tian and Zelkowitz [TZ92] have studied desirable properties for complexity metrics. <p> Step 1: Define Experimental Goal (s) Define the experimental goal (s) of the data collection, based on the general corporate objectives (e.g. reduce cycle time) and the available information about the studied development environment (e.g., weaknesses, problems). This step requires goal definition techniques. The Goal/Question/Metric paradigm (GQM) [B92] <ref> [BR88] </ref> is one of the approaches that can be used to this end. It provides a set of templates to define experimental goals and refines them into concrete and realistic questions, which subsequently lead to the definition of metrics. <p> As we will see in Section 6, questions about product characteristics are no longer necessary in our approach. However, GQM questions on the confidence with which assumptions are stated and on the quality (e.g., accuracy of collection procedures, granularity) of data to be collected <ref> [B92, BR88] </ref> still need to be asked. We will not address this issue, which is beyond the scope of this paper. <p> It is important to mention that most of the outputs (e.g., product abstractions, assumptions) of the steps defined above are reusable. They should be packaged and stored so that they can be efficiently and effectively reused <ref> [BR88] </ref>. In a mature development environment, inputs for most of those steps should come from reused knowledge. Moreover, many refinement loops are not represented in Figure 1. For example, as we said in the description of Step 6, poor experimental results may trigger the need for refining assumptions. <p> Each step will be discussed in detail in a different section. Each section contains three subsections: Definition of the step Examples Discussion of related issues. 3. Define Experimental Goal (s) (Step 1) Definition In this section, we apply the first step of the Goal/Question/Metric paradigm <ref> [B92, BR88] </ref> to set the measurement goals. Here is a summary of templates that can be used to define goals: Object of study: products, processes, resources Purpose: characterization, evaluation, prediction, improvement, ... Quality focus: cost, correctness, defect removal, changes, reliability, ... Viewpoint: user, customer, manager, developer, corporation, ... <p> Quality focus: cost, correctness, defect removal, changes, reliability, ... Viewpoint: user, customer, manager, developer, corporation, ... A detailed description of the GQM paradigm is beyond the scope of the paper. A comprehensive description of the GQM paradigm can be found in <ref> [B92, BR88] </ref>. It is important to note that the four goal dimensions mentioned above have a direct impact on the remaining steps of the metric definition approach and, from a more general perspective, the whole data collection program.
Reference: [DG84] <author> W. Dillon and M. Goldstein, </author> <title> Multivariate Analysis: Methods and Applications, </title> <publisher> Wiley and Sons, </publisher> <year> 1984. </year>
Reference-contexts: University of Maryland, CS-TR-3346 - 22 With respect to prediction, experimental validation may be seen as a search for statistical relationships between metrics of the object of study and a descriptive models of the quality focus (e.g., # error for Error-proneness). Numerous analysis techniques, both univariate and multivariate <ref> [S92, BBH93, DG84] </ref>, exist in the statistical and machine learning literature. If such assumptions and properties are not validated, we need to repeat from Step 2, reconsider the assumptions and properties, then redefine new metrics. This metric definition/validation cycle is iterated until the metric validation yields satisfactory results.
Reference: [F91] <author> N. Fenton, </author> <title> "Software Metrics, A Rigorous Approach," </title> <address> Chapman&Hall, </address> <year> 1991. </year>
Reference-contexts: A purely exploratory approach to metric definition would have for a consequence the experimental evaluation of a large number of relationships between product metrics (possibly not supported by any theory) and development process characteristics (e.g., effort). A simple probability calculation <ref> [F91] </ref> shows that this kind of approach is likely to lead to the identification of spurious statistical relationships, e.g., correlations uniquely due to coincidence. Several important research issues involved in the definition of such an approach have already been investigated. <p> At this point, if the defined abstractions are not fully adequate to define the context-dependent properties, this step can be reiterated. Steps 2, 3, and 4, taken as a whole, can be seen as a macrostep in which measurement models <ref> [F91] </ref> (i.e., abstractions and generic/context-dependent properties, main outputs of Step 4) are defined based on the experimental goals, environmental characteristics, and product information (inputs of Step 2). Step 5: Define Metrics Metrics are defined based upon the defined product abstraction (s), concepts and their associated properties. <p> Properties Size.1-Size.3 hold when applying the admissible transformation of the ratio scale <ref> [F91] </ref>. Therefore, there is no contradiction between our concept of size and the definition of size metrics on a ratio scale. Concept: Complexity Intuitively, the complexity of a product is a measurement concept that is considered extremely relevant to system properties. It has been studied by several researchers [BMB94 (b)].
Reference: [F94] <author> N. Fenton, </author> <title> "Software Measurement: A Necessary Scientific Basis", </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 20, no. 3, </volume> <pages> pp. 199-206, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: However, as we have shown, there may be aspects of the relevant environmental characteristics that cannot be explicitly modeled, e.g., the quality of the data and the validity of the assumptions, so questions may still be necessary to support the full interpretation of the metrics. As pointed out in <ref> [FM90, F94] </ref>, not all abstractions may be comparable with respect to a particular measurement concept. In such cases, it appears difficult to define a total order on the set of abstractions and only a partial order can be obtained [MGB90].
Reference: [FM90] <author> N. Fenton and A. Melton, </author> <title> "Deriving Structurally Based Software Measures", </title> <journal> J. Syst. Software, </journal> <volume> vol. 12, </volume> <pages> pp. 177-187, </pages> <year> 1990. </year> <institution> University of Maryland, </institution> <address> CS-TR-3346 - 24 </address>
Reference-contexts: Melton et al. have studied product abstraction properties [MGB90]. Weyuker [W88] and Tian and Zelkowitz [TZ92] have studied desirable properties for complexity metrics. In addition, the latter authors provided a property-based classification scheme for such metrics. Fenton and Melton <ref> [FM90] </ref>, and Zuse [Z90] have investigated the use of measurement theory to determine measurement scales. Finally, Schneidewind has proposed a validation framework for metrics [S92]. All this research needs to be integrated into a consistent and practical metric definition approach. The paper is organized as follows. <p> However, as we have shown, there may be aspects of the relevant environmental characteristics that cannot be explicitly modeled, e.g., the quality of the data and the validity of the assumptions, so questions may still be necessary to support the full interpretation of the metrics. As pointed out in <ref> [FM90, F94] </ref>, not all abstractions may be comparable with respect to a particular measurement concept. In such cases, it appears difficult to define a total order on the set of abstractions and only a partial order can be obtained [MGB90]. <p> Experimental validation (Step 6) will help us perform such a selection. As a necessary precondition to carrying out a meaningful experimental validation, the measurement scale (i.e., nominal, ordinal, interval, ratio, absolute <ref> [FM90] </ref>, [Z90]) of the metrics must be clearly identified. This prevents metrics from being misused (e.g., taking the average value of an ordinal metric, which is meaningless).
Reference: [IS88] <author> D. Ince, M. Shepperd, </author> <title> "System Design Metrics: a Review and Perspective," </title> <booktitle> Proc. Software Engineering 88, </booktitle> <pages> pages 23-27, </pages> <year> 1988 </year>
Reference-contexts: These include descriptions of organizational structure and work procedures, guidelines, standards, etc. This frequently led to some degree of fuzziness in the metric definitions, properties, and underlying concepts, making the use of the metrics difficult, their interpretation hazardous, and the results of the various validation studies somewhat contradictory <ref> [IS88, K88] </ref>. As a consequence, the number of available metrics in the literature is quite large, but the number of used and useful metrics in industry is small.
Reference: [K88] <author> B. Kitchenham, </author> <title> "An Evaluation of Software Structure Metrics," </title> <booktitle> Proc. COMPSAC 88, </booktitle> <year> 1988 </year>
Reference-contexts: These include descriptions of organizational structure and work procedures, guidelines, standards, etc. This frequently led to some degree of fuzziness in the metric definitions, properties, and underlying concepts, making the use of the metrics difficult, their interpretation hazardous, and the results of the various validation studies somewhat contradictory <ref> [IS88, K88] </ref>. As a consequence, the number of available metrics in the literature is quite large, but the number of used and useful metrics in industry is small.
Reference: [LJS91] <author> K. B. Lakshmanan, S. Jayaprakash, and P. K. Sinha, </author> <title> "Properties of Control-Flow Complexity Measures," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 17, no. 12, </volume> <pages> pp. 1289-1295, </pages> <month> Dec. </month> <year> 1991. </year>
Reference: [M90] <author> L. Moser, </author> <title> "Data Dependency Graphs for Ada Programs", </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 16, no. 5, </volume> <pages> pp. 498-509, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Several abstractions capturing control flow, data flow and data dependency information are available in the literature <ref> [M90, BBC88, O80] </ref>. However, an even larger variety of abstractions can be derived from software products. The set of properties associated with each concept is expanded so as to formalize the order existing on the set of abstractions with respect to each concept as defined by the assumptions.
Reference: [MGB90] <author> A. C. Melton, D.A. Gustafson, J. M. Bieman, and A. A. Baker, </author> <title> "Mathematical Perspective of Software Measures Research," </title> <journal> IEE Software Eng. J., </journal> <volume> vol. 5, no. 5, </volume> <pages> pp. 246-254, </pages> <year> 1990. </year>
Reference-contexts: Several important research issues involved in the definition of such an approach have already been investigated. Basili et al. [B92] [BR88] have provided templates to define operational experimental goals for software University of Maryland, CS-TR-3346 - 3 measurement. Melton et al. have studied product abstraction properties <ref> [MGB90] </ref>. Weyuker [W88] and Tian and Zelkowitz [TZ92] have studied desirable properties for complexity metrics. In addition, the latter authors provided a property-based classification scheme for such metrics. Fenton and Melton [FM90], and Zuse [Z90] have investigated the use of measurement theory to determine measurement scales. <p> Assumptions implicitely define an order on the set of objects of study with respect to the quality focus <ref> [MGB90] </ref>. For instance, components are ordered with respect to their error-proneness. Furthermore, while stating these assumptions, relevant measurement concepts are identified, e.g., size. <p> The objective is to formalize the assumptions stated in Step 3: The intuitive ordering of the objects of study (e.g.,components) with respect to the quality focus (e.g., components' error-proneness) must be preserved by the ordering of abstractions (e.g.,components' control flow graphs) with respect to each measurement concept (e.g., components' size) <ref> [MGB90] </ref>. <p> A thorough understanding of the working procedures, methodologies and techniques used in the studied development environment, combined with the interview of domain experts, is usually very helpful [BBK94]. The set of assumptions defines an ordering on the set of products <ref> [MGB90] </ref> with respect to the quality focus. This ordering will be used to evaluate the adequacy of the metrics defined in the remainder of this approach. An assumption is a statement believed to be true about the relationship between the quality focus and the characteristics of the object of study. <p> As pointed out in [FM90, F94], not all abstractions may be comparable with respect to a particular measurement concept. In such cases, it appears difficult to define a total order on the set of abstractions and only a partial order can be obtained <ref> [MGB90] </ref>. Ultimately, statistical analysis can only be conducted independently on comparable subsets of abstractions. University of Maryland, CS-TR-3346 - 20 One of the main difficulties of this step is to ensure that the set of context-dependent properties is complete.
Reference: [O80] <author> E. I. Oviedo, </author> <title> "Control Flow, Data Flow and Program Complexity," </title> <booktitle> Proc. COMPSAC, </booktitle> <month> Nov. </month> <year> 1980, </year> <pages> pp. 146-152. </pages>
Reference-contexts: Several abstractions capturing control flow, data flow and data dependency information are available in the literature <ref> [M90, BBC88, O80] </ref>. However, an even larger variety of abstractions can be derived from software products. The set of properties associated with each concept is expanded so as to formalize the order existing on the set of abstractions with respect to each concept as defined by the assumptions.
Reference: [RW82] <author> S. Rapps and E. Weyuker, </author> <title> "Data flow analysis test techniques for program test data selection", </title> <booktitle> in Proc. 6th Int. Conf. on Software Engineering, </booktitle> <month> Sept. </month> <year> 1982, </year> <pages> pp. 272-278 </pages>
Reference-contexts: Examples In our example, DU graphs are a suitable abstraction since they capture concepts such as definitions, condition expressions, uses. DU graphs are directed graphs where nodes are statements or conditions and arcs are definition-use clear paths <ref> [RW82] </ref>. Moreover, concepts such as "dependencies" or "distance" can be derived from such graphs. A definition or a condition expression "depends" on a definition when the variable/constant defined in the latter is used in the former.
Reference: [S92] <author> N. F. Schneidewind, </author> <title> "Methodology for Validating Software Metrics," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 18, no. 5, </volume> <pages> pp. 410-422, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: In addition, the latter authors provided a property-based classification scheme for such metrics. Fenton and Melton [FM90], and Zuse [Z90] have investigated the use of measurement theory to determine measurement scales. Finally, Schneidewind has proposed a validation framework for metrics <ref> [S92] </ref>. All this research needs to be integrated into a consistent and practical metric definition approach. The paper is organized as follows. In the next section, we provide an overview of a practical metric design approach in part inspired by the work referenced above and augmented with some new ideas. <p> If the assumptions are not supported by the experimental results, we need to repeat from Step 2, reconsider the assumptions and properties, then redefine new metrics. The definition and validation of metrics are performed iteratively until the metric validation yields satisfactory results <ref> [S92] </ref>. It is important to mention that most of the outputs (e.g., product abstractions, assumptions) of the steps defined above are reusable. They should be packaged and stored so that they can be efficiently and effectively reused [BR88]. <p> Characterization only requires the data to be representative of what is to be characterized. The quality focus helps determine the - dependent variable against which the defined product metrics are going to be experimentally validated (Step 6) <ref> [S92] </ref>. This dependent variable will in fact be a descriptive model of the quality focus. For instance, number of requirement changes per month per thousand of lines of code is a descriptive model of requirement instability. <p> University of Maryland, CS-TR-3346 - 22 With respect to prediction, experimental validation may be seen as a search for statistical relationships between metrics of the object of study and a descriptive models of the quality focus (e.g., # error for Error-proneness). Numerous analysis techniques, both univariate and multivariate <ref> [S92, BBH93, DG84] </ref>, exist in the statistical and machine learning literature. If such assumptions and properties are not validated, we need to repeat from Step 2, reconsider the assumptions and properties, then redefine new metrics. This metric definition/validation cycle is iterated until the metric validation yields satisfactory results.
Reference: [TZ92] <author> J. Tian and M. V. Zelkowitz, </author> <title> "A Formal Program Complexity Model and Its Application," </title> <journal> J. Syst. Software, </journal> <volume> vol. 17, </volume> <pages> pp. 253-266, </pages> <year> 1992. </year>
Reference-contexts: Basili et al. [B92] [BR88] have provided templates to define operational experimental goals for software University of Maryland, CS-TR-3346 - 3 measurement. Melton et al. have studied product abstraction properties [MGB90]. Weyuker [W88] and Tian and Zelkowitz <ref> [TZ92] </ref> have studied desirable properties for complexity metrics. In addition, the latter authors provided a property-based classification scheme for such metrics. Fenton and Melton [FM90], and Zuse [Z90] have investigated the use of measurement theory to determine measurement scales. Finally, Schneidewind has proposed a validation framework for metrics [S92]. <p> This makes the search for metrics less exploratory and provides precise mathematical criteria for assessing the soundness of the metrics to be defined. The mathematical properties characterizing the concepts are identified independently from the concept instantiation into a metric <ref> [TZ92] </ref> [Z90] [W88] and are therefore referred to as generic concept properties. With reference to our simple example, we can say that a property of size is that it is non-negative. <p> These concepts are believed to be relevant with respect to many experimental goals and applications, and in particular with respect to the goal defined above. As for complexity, the properties we define are related to the properties several authors have already provided in the literature (see <ref> [LJS92, TZ92, W88] </ref>). However, since we may want to use these properties on artifacts other than software code and on abstractions other than control-flow graphs, we formalized them in a more general manner. <p> A thorough discussion of these propertieswhich is beyond the scope of this papercan be found in [BMB94 (b)]. These properties are provided as an example. Nevertheless, in the metric definition approach we outline in this paper, other sets of properties <ref> [TZ92] </ref> [W88] may be used, since the selection of properties is, to some extent, subjective. Size and complexity are concepts related to systems, in general, i.e., one can speak about the size of a system and the complexity of a system.
Reference: [W88] <author> E. J. Weyuker, </author> <title> "Evaluating Software Complexity Measures," </title> <journal> IEEE Trans. Software Eng., </journal> <volume> vol. 14, no. 9, </volume> <pages> pp. 1357-1365, </pages> <month> Sept. </month> <year> 1988. </year>
Reference-contexts: Several important research issues involved in the definition of such an approach have already been investigated. Basili et al. [B92] [BR88] have provided templates to define operational experimental goals for software University of Maryland, CS-TR-3346 - 3 measurement. Melton et al. have studied product abstraction properties [MGB90]. Weyuker <ref> [W88] </ref> and Tian and Zelkowitz [TZ92] have studied desirable properties for complexity metrics. In addition, the latter authors provided a property-based classification scheme for such metrics. Fenton and Melton [FM90], and Zuse [Z90] have investigated the use of measurement theory to determine measurement scales. <p> This makes the search for metrics less exploratory and provides precise mathematical criteria for assessing the soundness of the metrics to be defined. The mathematical properties characterizing the concepts are identified independently from the concept instantiation into a metric [TZ92] [Z90] <ref> [W88] </ref> and are therefore referred to as generic concept properties. With reference to our simple example, we can say that a property of size is that it is non-negative. <p> These concepts are believed to be relevant with respect to many experimental goals and applications, and in particular with respect to the goal defined above. As for complexity, the properties we define are related to the properties several authors have already provided in the literature (see <ref> [LJS92, TZ92, W88] </ref>). However, since we may want to use these properties on artifacts other than software code and on abstractions other than control-flow graphs, we formalized them in a more general manner. <p> A thorough discussion of these propertieswhich is beyond the scope of this papercan be found in [BMB94 (b)]. These properties are provided as an example. Nevertheless, in the metric definition approach we outline in this paper, other sets of properties [TZ92] <ref> [W88] </ref> may be used, since the selection of properties is, to some extent, subjective. Size and complexity are concepts related to systems, in general, i.e., one can speak about the size of a system and the complexity of a system.
Reference: [Z90] <author> H. Zuse, </author> <title> Software Complexity: Measures and Methods. </title> <publisher> Amsterdam: de Gruyter, </publisher> <year> 1990. </year>
Reference-contexts: Melton et al. have studied product abstraction properties [MGB90]. Weyuker [W88] and Tian and Zelkowitz [TZ92] have studied desirable properties for complexity metrics. In addition, the latter authors provided a property-based classification scheme for such metrics. Fenton and Melton [FM90], and Zuse <ref> [Z90] </ref> have investigated the use of measurement theory to determine measurement scales. Finally, Schneidewind has proposed a validation framework for metrics [S92]. All this research needs to be integrated into a consistent and practical metric definition approach. The paper is organized as follows. <p> This makes the search for metrics less exploratory and provides precise mathematical criteria for assessing the soundness of the metrics to be defined. The mathematical properties characterizing the concepts are identified independently from the concept instantiation into a metric [TZ92] <ref> [Z90] </ref> [W88] and are therefore referred to as generic concept properties. With reference to our simple example, we can say that a property of size is that it is non-negative. <p> The generic properties associated with a measurement concept should not be contradictorythere must be at least one metric that satisfy them. Moreover, these properties should hold for the admissible transformations <ref> [Z90] </ref> of the scale of measurement (i.e., nominal, ordinal, interval, ratio, absolute) on which it is intended to define metrics. In other words, there should not be any contradiction between the scale of measurement which is assumed while using and interpreting a defined metric and its generic properties. <p> They will, most of the time, capture effects on the ordering of abstractions when modifications are performed on these abstraction. These modifications will often be what is referenced as atomic modifications in <ref> [Z90] </ref>, adding / removing / moving / substituting an edge/node. They will be useful in order to constrain and guide the search for metrics (Step 5). Examples In our example, DU graphs are a suitable abstraction since they capture concepts such as definitions, condition expressions, uses. <p> Experimental validation (Step 6) will help us perform such a selection. As a necessary precondition to carrying out a meaningful experimental validation, the measurement scale (i.e., nominal, ordinal, interval, ratio, absolute [FM90], <ref> [Z90] </ref>) of the metrics must be clearly identified. This prevents metrics from being misused (e.g., taking the average value of an ordinal metric, which is meaningless).
References-found: 23

