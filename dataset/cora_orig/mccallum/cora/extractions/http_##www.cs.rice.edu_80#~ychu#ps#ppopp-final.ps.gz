URL: http://www.cs.rice.edu:80/~ychu/ps/ppopp-final.ps.gz
Refering-URL: http://www.cs.rice.edu:80/~ychu/Yu_Hu.html
Root-URL: 
Title: High Performance Fortran for Highly Irregular Problems  
Author: Y. Charlie Hu S. Lennart Johnsson ShangHua Teng 
Address: Cambridge, MA 02138  Houston, TX 77204  Minneapolis, MN 55455  
Affiliation: Aiken Computation Lab Harvard University  Dept. of Computer Science University of Houston  Dept. of Computer Science University of Minnesota  
Abstract: We present a general data parallel formulation for highly irregular problems in High Performance Fortran (HPF). Our formulation consists of (1) a method for linearizing irregular data structures (2) a data parallel implementation (in HPF) of graph partitioning algorithms applied to the linearized data structure, (3) techniques for expressing irregular communication and nonuniform computations associated with the elements of linearized data structures. We demonstrate and evaluate our formulation on a parallel, hierarchical N body method for the evaluation of potentials and forces of nonuniform particle distributions. Our experimental results demonstrate that efficient data parallel (HPF) implementations of highly nonuniform problems are feasible with the proper language/compiler/runtime support. Our data parallel N body code provides a much needed benchmark code for evaluating and improving HPF compilers. 
Abstract-found: 1
Intro-found: 1
Reference: [2] <author> J. Barnes and P. Hut. </author> <title> A hierarchical O(N log N) force calculation algorithm. </title> <booktitle> Nature, </booktitle> <address> 324:446449, </address> <year> 1986. </year>
Reference-contexts: Hierarchical Nbody methods include the nonadaptive O (N ) methods by Greengard and Rokhlin [9], Zhao [30], Ander-son [1], and the O (N log N ) methods by Appel (proven to be of O (N ) in [7]), and by Barnes and Hut <ref> [2] </ref> and by Callahan and Kosaraju [5]. The methods of Appel, and Barnes and Hut, and Calla-han and Kosaraju are readily extended to nonuniformly distributed particles. Carrier, Greengard, and Rokhlin [6] presented an adaptive version of the GreengardRokhlin method.
Reference: [3] <author> G. E. Blelloch and G. W. Sabot. </author> <title> Compiling collection-oriented languages onto massively parallel computers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8(2):119134, </volume> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: The third feature is not supported in current commercial HPF compilers. With respect to ragged arrays, it is interesting to note that the nested data parallel language NESL <ref> [3] </ref> supports ragged arrays. The technique used to flatten ragged arrays in the compilation of nested data parallel programs relies on highly optimized segmented prefix runtime support to achieve good performance.
Reference: [4] <author> J. A. Board Jr., Z. S. Hakura, W. D. Elliott, D. C. Gray, W. J. Blanke, and J. Leathrum Jr. </author> <title> Scalable implementations of multipoleaccelerated algorithms for molecular dynamics. </title> <booktitle> In Proc. Scalable High Performance Computing Conference SHPCC94. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1994. </year>
Reference-contexts: MP denotes message passing, and SM sharedmemory. Author Method Prog. System Effi. Model BarnesHut method WarrenSalmon [29] BH MP Intel Delta 28% LiuBhatt [19] BH MP CM5 30% Singh et al. [26] BH SM Stanford DASH Nonadaptive O (N) methods Board et al. <ref> [4] </ref> GR SM KSR-1 20% ZhaoJohnsson [31] Zhao SIMD CM2 12% Adaptive O (N) methods Singh et al. [25] GR SM Stanford DASH paradigm. Nonadaptive versions of the O (N ) methods have also been implemented on parallel machines in both the messagepassing and the sharedmemory programming paradigms [4]. <p> et al. <ref> [4] </ref> GR SM KSR-1 20% ZhaoJohnsson [31] Zhao SIMD CM2 12% Adaptive O (N) methods Singh et al. [25] GR SM Stanford DASH paradigm. Nonadaptive versions of the O (N ) methods have also been implemented on parallel machines in both the messagepassing and the sharedmemory programming paradigms [4]. In contrast, due to the more complicated computational structure, little progress has been made on parallel implementations of adaptive versions of the O (N ) methods.
Reference: [5] <author> P. B. Callahan and S. R. Kosaraju. </author> <title> A decomposition of multidimensional point sets with applications to k-nearest-neighbors and n-body potential fields. </title> <journal> JACM, </journal> <volume> 42:6790, </volume> <year> 1995. </year>
Reference-contexts: Hierarchical Nbody methods include the nonadaptive O (N ) methods by Greengard and Rokhlin [9], Zhao [30], Ander-son [1], and the O (N log N ) methods by Appel (proven to be of O (N ) in [7]), and by Barnes and Hut [2] and by Callahan and Kosaraju <ref> [5] </ref>. The methods of Appel, and Barnes and Hut, and Calla-han and Kosaraju are readily extended to nonuniformly distributed particles. Carrier, Greengard, and Rokhlin [6] presented an adaptive version of the GreengardRokhlin method.
Reference: [6] <author> J. Carrier, L. Greengard, and V. Rokhlin. </author> <title> A fast adaptive multipole algorithm for particle simulations. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <month> July </month> <year> 1988. </year>
Reference-contexts: The methods of Appel, and Barnes and Hut, and Calla-han and Kosaraju are readily extended to nonuniformly distributed particles. Carrier, Greengard, and Rokhlin <ref> [6] </ref> presented an adaptive version of the GreengardRokhlin method. Similar extensions can be made to Anderson's and Zhao's methods. 1 Hierarchical N body methods pose great challenges to parallel implementations. <p> Previously (see Table 1), Salmon and Warren [29], Liu and Bhatt [19], and many others have shown that the Barnes Hut method can be implemented efficiently on parallel scalable architectures, using the messagepassing programming 1 The proof in <ref> [6] </ref> that the adaptive method retains O (N ) complexity uses the fact that the depth of the hierarchy in computer simulations is limited by the machine precision, i.e. there is a large constant log 2 * in the big O. <p> List Valid for Definition List1 leaf boxes non-well-separated boxes List2 all boxes wellseparated boxes that are children of the nearfield of box b's parent List3 leaf boxes well-separated offsprings of nearfield boxes List4 all boxes inverse of List3 With the above definitions, an adaptive O (N ) hierarchical method <ref> [6] </ref> proceeds in the following steps: Algorithm. A generic adaptive O (N ) hierarchical method 1. Build Hierarchy. See Section 4.1. 2. Construct Interaction Lists. The List1, 2, 3 are constructed explicitly, via depthfirst traversal of the hierarchy.
Reference: [7] <author> K. Esselink. </author> <title> The order of Appel's algorithm. Information Processing Letter, </title> <address> 41:141147, </address> <year> 1992. </year>
Reference-contexts: Hierarchical Nbody methods include the nonadaptive O (N ) methods by Greengard and Rokhlin [9], Zhao [30], Ander-son [1], and the O (N log N ) methods by Appel (proven to be of O (N ) in <ref> [7] </ref>), and by Barnes and Hut [2] and by Callahan and Kosaraju [5]. The methods of Appel, and Barnes and Hut, and Calla-han and Kosaraju are readily extended to nonuniformly distributed particles. Carrier, Greengard, and Rokhlin [6] presented an adaptive version of the GreengardRokhlin method.
Reference: [8] <author> P. O. Fredrickson and O. A. McBryan. </author> <title> Normalized convergence rates for the PSMG method. </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> 12(1):221229, </volume> <year> 1991. </year>
Reference-contexts: 1 Introduction Data parallel programming provides an effective way to write maintainable, portable, and scalable parallel codes. It has enjoyed great success in solving many structured problems, such as dense matrix computations, finite difference calculations, nonadaptive multigrid <ref> [8] </ref> and nonadaptive hierarchical methods for the potential and force field evaluation of particle interactions [13, 14]. The data parallel programming paradigm has also been used successfully for unstructured finiteelement problems [20, 16, 17]. All the data parallel fl The first two authors were supported by the U.S.
Reference: [9] <author> L. F. Greengard. </author> <title> The rapid evaluationof potential fields in particle systems. </title> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: Largescale Nbody simulations have applications in areas such as celestial mechanics, plasma physics, materials science and molecular design. Hierarchical Nbody methods include the nonadaptive O (N ) methods by Greengard and Rokhlin <ref> [9] </ref>, Zhao [30], Ander-son [1], and the O (N log N ) methods by Appel (proven to be of O (N ) in [7]), and by Barnes and Hut [2] and by Callahan and Kosaraju [5]. <p> Approximate the force or potential due to a cluster of particles with a single computational element; 2. Hierarchically form and use the computational ele ments. All O (N ) methods <ref> [1, 9, 30] </ref> share the same computational structure and differ only in the approximate computational elements they use. There are two kinds of computational elements used in O (N ) methods: farfield potential representation and localfield potential representation.
Reference: [10] <author> B. Hendrickson and R. Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <booktitle> In Supercomputing'96, </booktitle> <address> Philadelphia, PA, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: Using this sampling technique GEO is computationally less demanding than a straightforward implementation of RSB. Recently, the idea of multilevel contraction to reduce the size of the graphs being partitioning has been introduced to RSB with promising results <ref> [18, 10] </ref>.
Reference: [11] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <note> Version 2.0.ffi, October 19, </note> <year> 1996. </year>
Reference-contexts: The third feature is included in the most recent definition of HPF <ref> [11] </ref>, while the forth is not. The nodal code generated by the current generation commercial HPF compilers is not well optimized for many expressions, and the supporting runtime systems are often quite inefficient. The third feature is not supported in current commercial HPF compilers. <p> Although this distribution feature is included as an approved extension in the recently announced HPF 2.0 <ref> [11] </ref>, no commercial compilers available today supports it yet. We have developed a simple padding scheme for emulating uneven array distributions in HPF 1.0, as shown in Figure 8.
Reference: [12] <author> Y. Hu. </author> <title> Efficient Data Parallel Implementations of Hierarchical Nbody Algorithms. </title> <type> PhD thesis, </type> <institution> Harvard University, </institution> <year> 1997. </year>
Reference-contexts: Construction of the three interaction lists in step 2 is performed via several downward traversals of the hierarchy, scanning the entire array of the hierarchy. Details can be found in <ref> [12] </ref>. The lists constructed are stored in 2D pointer arrays. A parallel axis is used for the representation of all the boxes in the hierarchy and a local axis is used to store pointers for the same box.
Reference: [13] <author> Y. Hu and S. L. Johnsson. </author> <title> A data parallel implementation of hierarchical N body methods. </title> <journal> International Journal of Supercomputing Applications and High Performance Computing, </journal> <volume> 10(1):3 40, </volume> <year> 1996. </year>
Reference-contexts: It has enjoyed great success in solving many structured problems, such as dense matrix computations, finite difference calculations, nonadaptive multigrid [8] and nonadaptive hierarchical methods for the potential and force field evaluation of particle interactions <ref> [13, 14] </ref>. The data parallel programming paradigm has also been used successfully for unstructured finiteelement problems [20, 16, 17]. All the data parallel fl The first two authors were supported by the U.S. Air Force under grants AFOSR F49620-93-1-0480 and F49620-96-1-0289. <p> nonuniform problems by applying it to an adaptive hierarchical N body algorithm for nonuniform particle distributions. 3 Hierarchical N body Methods Hierarchical methods for N body simulations have enabled the simulation of particle systems with up to 100 million particles on Massively Parallel Processors (MPP) installed a few years ago <ref> [13] </ref>, and should allow for the simulation of 1 10 billion particle systems in main memory on the MPP systems currently under installation. Largescale Nbody simulations have applications in areas such as celestial mechanics, plasma physics, materials science and molecular design. <p> To our knowledge, the only parallel implementation of this type of method prior to ours is a sharedmemory implementation of a 2D version of the GreengardRokhlin method [25]. In previous work <ref> [13, 14] </ref>, we have shown that efficient scalable code can be produced in data parallel languages for nonadaptive versions of Anderson's method. 3.1 Adaptive O (N ) Hierarchical Methods There are two key ideas in O (N ) hierarchical methods which together achieve the reduced arithmetic complexity: 1. <p> As we have shown in <ref> [13] </ref>, the three translation operations can be performed as matrixvector operations, and furthermore, the translation matrices only depend on the relative locations of source and destination spheres.
Reference: [14] <author> Y. Hu and S. L. Johnsson. </author> <title> Implementing O(N) Nbody algorithms efficiently in dataparallel languages. </title> <journal> Journal of Scientific Programming, </journal> <volume> 5(4):337 364, </volume> <year> 1996. </year>
Reference-contexts: It has enjoyed great success in solving many structured problems, such as dense matrix computations, finite difference calculations, nonadaptive multigrid [8] and nonadaptive hierarchical methods for the potential and force field evaluation of particle interactions <ref> [13, 14] </ref>. The data parallel programming paradigm has also been used successfully for unstructured finiteelement problems [20, 16, 17]. All the data parallel fl The first two authors were supported by the U.S. Air Force under grants AFOSR F49620-93-1-0480 and F49620-96-1-0289. <p> To our knowledge, the only parallel implementation of this type of method prior to ours is a sharedmemory implementation of a 2D version of the GreengardRokhlin method [25]. In previous work <ref> [13, 14] </ref>, we have shown that efficient scalable code can be produced in data parallel languages for nonadaptive versions of Anderson's method. 3.1 Adaptive O (N ) Hierarchical Methods There are two key ideas in O (N ) hierarchical methods which together achieve the reduced arithmetic complexity: 1.
Reference: [15] <author> Y. C. Hu, S.-H. Teng, and S. L. Johnsson. </author> <title> A dataparallel implementation of the geometric partitioning algorithm. </title> <booktitle> In Proc. of the 8th SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> Minneapolis, MN, </address> <month> March </month> <year> 1997. </year>
Reference-contexts: GEO lends itself to efficient data parallel implementations, as shown in <ref> [15] </ref>. Extensive use of sampling can be used to reduce the computational complexity without a significant degradation in the quality of the partitions. Using this sampling technique GEO is computationally less demanding than a straightforward implementation of RSB.
Reference: [16] <author> Z. Johan, K. K. Mathur, S. L. Johnsson, and T. J. Hughes. </author> <title> An efficient communication strategy for Finite Element Methods on the Connection Machine CM5 system. </title> <booktitle> Computer Methods in Applied Mechanics and Engineering, </booktitle> <volume> 113:363 387, </volume> <year> 1994. </year>
Reference-contexts: The data parallel programming paradigm has also been used successfully for unstructured finiteelement problems <ref> [20, 16, 17] </ref>. All the data parallel fl The first two authors were supported by the U.S. Air Force under grants AFOSR F49620-93-1-0480 and F49620-96-1-0289. The third author was supported by an NSF CAREER award (CCR-9502540), an Alfred P. Sloan Research Fellowship, and an Intel research grant.
Reference: [17] <author> Z. Johan, K. K. Mathur, S. L. Johnsson, and T. J. Hughes. </author> <title> Scalability of finite element applications on distributedmemory parallel computers. </title> <booktitle> Computer Methods in Applied Mechanics and Engineering, </booktitle> <volume> 119(1 2):61 72, </volume> <month> November </month> <year> 1994. </year>
Reference-contexts: The data parallel programming paradigm has also been used successfully for unstructured finiteelement problems <ref> [20, 16, 17] </ref>. All the data parallel fl The first two authors were supported by the U.S. Air Force under grants AFOSR F49620-93-1-0480 and F49620-96-1-0289. The third author was supported by an NSF CAREER award (CCR-9502540), an Alfred P. Sloan Research Fellowship, and an Intel research grant.
Reference: [18] <author> G. Karypis and V. Kumar. </author> <title> A fast and high quality multilevel scheme for partitioning irregular graphs. </title> <type> Technical Report Tech. Rep. CORR 95-035, </type> <institution> University of Minnesota, Dept. Computer Science, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: Using this sampling technique GEO is computationally less demanding than a straightforward implementation of RSB. Recently, the idea of multilevel contraction to reduce the size of the graphs being partitioning has been introduced to RSB with promising results <ref> [18, 10] </ref>.
Reference: [19] <author> P. Liu. </author> <title> The parallel implementation of Nbody algorithms. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1994. </year>
Reference-contexts: First, the complex computational structures and mathematics involved demand significant programming efforts; second, the highly irregular and extensive communication patterns make partitioning for locality and loadbalancing on parallel platforms harder than partitioning unstructured meshes. Previously (see Table 1), Salmon and Warren [29], Liu and Bhatt <ref> [19] </ref>, and many others have shown that the Barnes Hut method can be implemented efficiently on parallel scalable architectures, using the messagepassing programming 1 The proof in [6] that the adaptive method retains O (N ) complexity uses the fact that the depth of the hierarchy in computer simulations is limited <p> Table 1: Summary of previous parallel implementations of hierarchical N body methods. MP denotes message passing, and SM sharedmemory. Author Method Prog. System Effi. Model BarnesHut method WarrenSalmon [29] BH MP Intel Delta 28% LiuBhatt <ref> [19] </ref> BH MP CM5 30% Singh et al. [26] BH SM Stanford DASH Nonadaptive O (N) methods Board et al. [4] GR SM KSR-1 20% ZhaoJohnsson [31] Zhao SIMD CM2 12% Adaptive O (N) methods Singh et al. [25] GR SM Stanford DASH paradigm.
Reference: [20] <author> K. K. Mathur, A. Needleman, and V. Tvergaard. </author> <title> Dynamic 3-d analysis of the charpy vnotch test. </title> <booktitle> Modelling and Simulation Materials Science and Engineering, </booktitle> <address> 1(4):467484, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: The data parallel programming paradigm has also been used successfully for unstructured finiteelement problems <ref> [20, 16, 17] </ref>. All the data parallel fl The first two authors were supported by the U.S. Air Force under grants AFOSR F49620-93-1-0480 and F49620-96-1-0289. The third author was supported by an NSF CAREER award (CCR-9502540), an Alfred P. Sloan Research Fellowship, and an Intel research grant.
Reference: [21] <author> G. L. Miller, S.-H. Teng, W. Thurston, and S. A. Vavasis. </author> <title> Finite element meshes and geometric separators. </title> <journal> SIAM J. Scientific Computing, </journal> <note> to appear, </note> <year> 1997. </year>
Reference-contexts: In Fortran 90, irregular problems typically are described using index arrays to introduce a level of indirection for gather and scatter array accesses. Most irregular problems possess as much potential parallelism as their regular counterpart <ref> [21, 28] </ref>, but their nonuniformity is often perceived as making them unfit for the data parallel programming paradigm. Moreover, their nonuniformity poses a serious challenge for loadbalancing the computations while communication is kept at as low a level as possible. <p> Mathematically, it has been proved <ref> [21, 28] </ref> that both unstructured meshes and adaptive N body graphs have provably good partitions, i.e. the ratio of interpartition data movement and intrapartition computation is of the same order as the ratio for regular grids of the same size. <p> The proof of the above theorem given in [28] further shows that a partitioning of this quality can be found by the geometric partitioning algorithm (GEO) of Miller, Teng, Thurston, and Vavasis <ref> [21] </ref> and a variant of spectral partitioning given by Spielman and Teng [27]. 4.2.2 Load Balancing and Partitioning Heuristics Orthogonal recursive bisection (ORB) and Morton and PeanoHilbert ordering have been used to partition particles in the BarnesHut method [24, 29, 25] and to partition boxes in an adaptive fast multipole method <p> coord. + edge good unknown GEO nodal weight + coord. + edge provably good provably good RSB nodal weight + edge provably good provably good only a few lines of arithmetic array operations plus a subroutine call to the HPF sort intrinsic. 4.2.3 Provably Good Partitioning Algorithms Geometric partitioning (GEO) <ref> [21] </ref> and a variant (by Spiel-man and Teng [27]) of recursive spectral bisection (RSB) [23] both offer guarantees on the quality of the partitions. GEO lends itself to efficient data parallel implementations, as shown in [15].
Reference: [22] <author> C.-W. Ou, S. Ranka, and G. Fox. </author> <title> Fast and parallel mapping algorithms for irregular problems. </title> <journal> Journal of Supercomputing, </journal> <volume> 1(23), </volume> <year> 1997. </year>
Reference-contexts: We linearize the nonuniform hierarchical structures through the use of spacefilling curves, a technique that has been used by others with good results, see for instance <ref> [22, 25] </ref>. We express our program/algorithm in terms of primitives such as reduction, prefix sum, segmented prefix sum, gather/scatter, and broadcast. These operations can be efficiently supported by data parallel compilers and runtime systems, as demonstrated by the Connection Machine Fortran compiler and its supporting Connection Machine RunTime System. <p> We use these linear orderings as a basis for the partitioning of the nonuniform hierarchy in our N body problem. Both spacefilling orderings we consider have been used in SPMD style programming for the N body problem, in partitioning unstructured meshes <ref> [22] </ref>, and in message passing and sharedmemory implementations of hierarchical N body methods [29, 25]. In our data parallel formulation, we use them for linearizing the nonuniform hierarchical structures. The 1D arrays so generated will be distributed across processors.
Reference: [23] <author> A. Pothen, H. D. Simon, and K.-P. Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 11(3):430452, </volume> <year> 1990. </year>
Reference-contexts: provably good RSB nodal weight + edge provably good provably good only a few lines of arithmetic array operations plus a subroutine call to the HPF sort intrinsic. 4.2.3 Provably Good Partitioning Algorithms Geometric partitioning (GEO) [21] and a variant (by Spiel-man and Teng [27]) of recursive spectral bisection (RSB) <ref> [23] </ref> both offer guarantees on the quality of the partitions. GEO lends itself to efficient data parallel implementations, as shown in [15]. Extensive use of sampling can be used to reduce the computational complexity without a significant degradation in the quality of the partitions.
Reference: [24] <author> J. K. Salmon. </author> <title> Parallel Hierarchical NBody Methods. </title> <type> PhD thesis, </type> <institution> California Institute of Technology, </institution> <year> 1990. </year>
Reference-contexts: by the geometric partitioning algorithm (GEO) of Miller, Teng, Thurston, and Vavasis [21] and a variant of spectral partitioning given by Spielman and Teng [27]. 4.2.2 Load Balancing and Partitioning Heuristics Orthogonal recursive bisection (ORB) and Morton and PeanoHilbert ordering have been used to partition particles in the BarnesHut method <ref> [24, 29, 25] </ref> and to partition boxes in an adaptive fast multipole method [25]. We have developed a library of data parallel partitioning schemes in HPF, as summarized in Table 4. As a reference, we include the levelbylevel/Morton (LBL) ordering generated by our data parallel hierarchy building algorithm.
Reference: [25] <author> J. Singh, C. Holt, J. Hennessey, and A. Gupta. </author> <title> A parallel adaptive fast multipole method. </title> <booktitle> In Supercomputing'93, </booktitle> <pages> pages 54 65. </pages> <publisher> IEEE Computer Society, Los Alamitos, </publisher> <year> 1993. </year>
Reference-contexts: We linearize the nonuniform hierarchical structures through the use of spacefilling curves, a technique that has been used by others with good results, see for instance <ref> [22, 25] </ref>. We express our program/algorithm in terms of primitives such as reduction, prefix sum, segmented prefix sum, gather/scatter, and broadcast. These operations can be efficiently supported by data parallel compilers and runtime systems, as demonstrated by the Connection Machine Fortran compiler and its supporting Connection Machine RunTime System. <p> Model BarnesHut method WarrenSalmon [29] BH MP Intel Delta 28% LiuBhatt [19] BH MP CM5 30% Singh et al. [26] BH SM Stanford DASH Nonadaptive O (N) methods Board et al. [4] GR SM KSR-1 20% ZhaoJohnsson [31] Zhao SIMD CM2 12% Adaptive O (N) methods Singh et al. <ref> [25] </ref> GR SM Stanford DASH paradigm. Nonadaptive versions of the O (N ) methods have also been implemented on parallel machines in both the messagepassing and the sharedmemory programming paradigms [4]. <p> To our knowledge, the only parallel implementation of this type of method prior to ours is a sharedmemory implementation of a 2D version of the GreengardRokhlin method <ref> [25] </ref>. <p> Both spacefilling orderings we consider have been used in SPMD style programming for the N body problem, in partitioning unstructured meshes [22], and in message passing and sharedmemory implementations of hierarchical N body methods <ref> [29, 25] </ref>. In our data parallel formulation, we use them for linearizing the nonuniform hierarchical structures. The 1D arrays so generated will be distributed across processors. <p> by the geometric partitioning algorithm (GEO) of Miller, Teng, Thurston, and Vavasis [21] and a variant of spectral partitioning given by Spielman and Teng [27]. 4.2.2 Load Balancing and Partitioning Heuristics Orthogonal recursive bisection (ORB) and Morton and PeanoHilbert ordering have been used to partition particles in the BarnesHut method <ref> [24, 29, 25] </ref> and to partition boxes in an adaptive fast multipole method [25]. We have developed a library of data parallel partitioning schemes in HPF, as summarized in Table 4. As a reference, we include the levelbylevel/Morton (LBL) ordering generated by our data parallel hierarchy building algorithm. <p> and a variant of spectral partitioning given by Spielman and Teng [27]. 4.2.2 Load Balancing and Partitioning Heuristics Orthogonal recursive bisection (ORB) and Morton and PeanoHilbert ordering have been used to partition particles in the BarnesHut method [24, 29, 25] and to partition boxes in an adaptive fast multipole method <ref> [25] </ref>. We have developed a library of data parallel partitioning schemes in HPF, as summarized in Table 4. As a reference, we include the levelbylevel/Morton (LBL) ordering generated by our data parallel hierarchy building algorithm.
Reference: [26] <author> J. Singh, C. Holt, T. Ttsuka, A. Gupta, and J. Hennessey. </author> <title> Load balancing and data locality in hierarchical Nbody methods. </title> <type> Technical Report CSLTR92505, </type> <institution> Stanford University, </institution> <year> 1992. </year>
Reference-contexts: Table 1: Summary of previous parallel implementations of hierarchical N body methods. MP denotes message passing, and SM sharedmemory. Author Method Prog. System Effi. Model BarnesHut method WarrenSalmon [29] BH MP Intel Delta 28% LiuBhatt [19] BH MP CM5 30% Singh et al. <ref> [26] </ref> BH SM Stanford DASH Nonadaptive O (N) methods Board et al. [4] GR SM KSR-1 20% ZhaoJohnsson [31] Zhao SIMD CM2 12% Adaptive O (N) methods Singh et al. [25] GR SM Stanford DASH paradigm.
Reference: [27] <author> D. A. Spielman and S.-H. Teng. </author> <title> Spectral partitioning works: planar graphs and finite element meshes. </title> <booktitle> In Proceedings of the 37th Annual Symposium on Foundation of Computer Science, </booktitle> <pages> pages 96107, </pages> <year> 1996. </year>
Reference-contexts: The proof of the above theorem given in [28] further shows that a partitioning of this quality can be found by the geometric partitioning algorithm (GEO) of Miller, Teng, Thurston, and Vavasis [21] and a variant of spectral partitioning given by Spielman and Teng <ref> [27] </ref>. 4.2.2 Load Balancing and Partitioning Heuristics Orthogonal recursive bisection (ORB) and Morton and PeanoHilbert ordering have been used to partition particles in the BarnesHut method [24, 29, 25] and to partition boxes in an adaptive fast multipole method [25]. <p> + coord. + edge provably good provably good RSB nodal weight + edge provably good provably good only a few lines of arithmetic array operations plus a subroutine call to the HPF sort intrinsic. 4.2.3 Provably Good Partitioning Algorithms Geometric partitioning (GEO) [21] and a variant (by Spiel-man and Teng <ref> [27] </ref>) of recursive spectral bisection (RSB) [23] both offer guarantees on the quality of the partitions. GEO lends itself to efficient data parallel implementations, as shown in [15]. Extensive use of sampling can be used to reduce the computational complexity without a significant degradation in the quality of the partitions.
Reference: [28] <author> S.-H. Teng. </author> <title> Provablygood partitioningand load balancingalgorithmsfor parallel adaptive n-body simulation. </title> <note> SIAM J. Sci. Comput., to appear 1996. </note>
Reference-contexts: In Fortran 90, irregular problems typically are described using index arrays to introduce a level of indirection for gather and scatter array accesses. Most irregular problems possess as much potential parallelism as their regular counterpart <ref> [21, 28] </ref>, but their nonuniformity is often perceived as making them unfit for the data parallel programming paradigm. Moreover, their nonuniformity poses a serious challenge for loadbalancing the computations while communication is kept at as low a level as possible. <p> Mathematically, it has been proved <ref> [21, 28] </ref> that both unstructured meshes and adaptive N body graphs have provably good partitions, i.e. the ratio of interpartition data movement and intrapartition computation is of the same order as the ratio for regular grids of the same size. <p> N - body graphs have a higher node degree than typical finite element meshes, especially when the distribution of particles is nonuniform. The following result of Teng <ref> [28] </ref> gives an upper bound on the amount of interaction between partitions as a function of the height of the N body graph. <p> If the height of the hierarchical tree for P is h, then G can be partitioned into k equal computational weighted subgraphs by removing at most O (k 1=d h 1=d n 11=d ) boxes. The proof of the above theorem given in <ref> [28] </ref> further shows that a partitioning of this quality can be found by the geometric partitioning algorithm (GEO) of Miller, Teng, Thurston, and Vavasis [21] and a variant of spectral partitioning given by Spielman and Teng [27]. 4.2.2 Load Balancing and Partitioning Heuristics Orthogonal recursive bisection (ORB) and Morton and PeanoHilbert
Reference: [29] <author> M. Warren and J. Salmon. </author> <title> A parallel hashed octtree Nbody algorithm. </title> <booktitle> In Supercomputing'93, </booktitle> <pages> pages 12 21. </pages> <publisher> IEEE Computer Society, Los Alamitos, </publisher> <year> 1993. </year>
Reference-contexts: First, the complex computational structures and mathematics involved demand significant programming efforts; second, the highly irregular and extensive communication patterns make partitioning for locality and loadbalancing on parallel platforms harder than partitioning unstructured meshes. Previously (see Table 1), Salmon and Warren <ref> [29] </ref>, Liu and Bhatt [19], and many others have shown that the Barnes Hut method can be implemented efficiently on parallel scalable architectures, using the messagepassing programming 1 The proof in [6] that the adaptive method retains O (N ) complexity uses the fact that the depth of the hierarchy in <p> Callahan and Kosaraju's formulation requires O (N log N ) operations independent of the particle distribution. Table 1: Summary of previous parallel implementations of hierarchical N body methods. MP denotes message passing, and SM sharedmemory. Author Method Prog. System Effi. Model BarnesHut method WarrenSalmon <ref> [29] </ref> BH MP Intel Delta 28% LiuBhatt [19] BH MP CM5 30% Singh et al. [26] BH SM Stanford DASH Nonadaptive O (N) methods Board et al. [4] GR SM KSR-1 20% ZhaoJohnsson [31] Zhao SIMD CM2 12% Adaptive O (N) methods Singh et al. [25] GR SM Stanford DASH paradigm. <p> Both spacefilling orderings we consider have been used in SPMD style programming for the N body problem, in partitioning unstructured meshes [22], and in message passing and sharedmemory implementations of hierarchical N body methods <ref> [29, 25] </ref>. In our data parallel formulation, we use them for linearizing the nonuniform hierarchical structures. The 1D arrays so generated will be distributed across processors. <p> by the geometric partitioning algorithm (GEO) of Miller, Teng, Thurston, and Vavasis [21] and a variant of spectral partitioning given by Spielman and Teng [27]. 4.2.2 Load Balancing and Partitioning Heuristics Orthogonal recursive bisection (ORB) and Morton and PeanoHilbert ordering have been used to partition particles in the BarnesHut method <ref> [24, 29, 25] </ref> and to partition boxes in an adaptive fast multipole method [25]. We have developed a library of data parallel partitioning schemes in HPF, as summarized in Table 4. As a reference, we include the levelbylevel/Morton (LBL) ordering generated by our data parallel hierarchy building algorithm.
Reference: [30] <author> F. Zhao. </author> <title> An O(N) algorithmfor 3dimensionalNbody simulations. </title> <type> Technical Report AITR995, </type> <institution> AI Lab, MIT, </institution> <year> 1987. </year>
Reference-contexts: Largescale Nbody simulations have applications in areas such as celestial mechanics, plasma physics, materials science and molecular design. Hierarchical Nbody methods include the nonadaptive O (N ) methods by Greengard and Rokhlin [9], Zhao <ref> [30] </ref>, Ander-son [1], and the O (N log N ) methods by Appel (proven to be of O (N ) in [7]), and by Barnes and Hut [2] and by Callahan and Kosaraju [5]. <p> Approximate the force or potential due to a cluster of particles with a single computational element; 2. Hierarchically form and use the computational ele ments. All O (N ) methods <ref> [1, 9, 30] </ref> share the same computational structure and differ only in the approximate computational elements they use. There are two kinds of computational elements used in O (N ) methods: farfield potential representation and localfield potential representation.
Reference: [31] <author> F. Zhao and S. L. Johnsson. </author> <title> The parallel multipole method on the Connection Machine. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 12(6):14201437, </volume> <month> Nov. </month> <year> 1991. </year> <month> 12 </month>
Reference-contexts: MP denotes message passing, and SM sharedmemory. Author Method Prog. System Effi. Model BarnesHut method WarrenSalmon [29] BH MP Intel Delta 28% LiuBhatt [19] BH MP CM5 30% Singh et al. [26] BH SM Stanford DASH Nonadaptive O (N) methods Board et al. [4] GR SM KSR-1 20% ZhaoJohnsson <ref> [31] </ref> Zhao SIMD CM2 12% Adaptive O (N) methods Singh et al. [25] GR SM Stanford DASH paradigm. Nonadaptive versions of the O (N ) methods have also been implemented on parallel machines in both the messagepassing and the sharedmemory programming paradigms [4].
References-found: 30

