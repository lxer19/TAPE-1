URL: ftp://speech.cse.ogi.edu/pub/docs/SLAM-thesis.ps.Z
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Email: email: dhouse@mitre.org  
Title: Spoken-Language Access to Multimedia (SLAM):  
Author: David House Advisors: Dr. David Novick, Dr. Mark Fanty, Dr. Jonathan Walpole 
Degree: Masters Thesis  
Date: Chapter 1  
Affiliation: Dept. of Computer Science and Engineering Oregon Graduate Institute  
Abstract-found: 0
Intro-found: 1
Reference: <author> Arbash, V. </author> <year> (1995). </year> <type> Personal communication, </type> <month> April, </month> <year> 1995. </year>
Reference: <author> Arons, B. Hyperspeech: </author> <title> Navigating in speech-only hypermedia. </title> <booktitle> (1991). ACM Conference on Hypertext: Hypertext 91 Proceedings, </booktitle> <address> San Antonio, Texas, </address> <month> December 15-18, </month> <year> 1991, </year> <note> p. 133-146, Baltimore: ACM Press. CERN (European Laboratory for Particle Physics) (1994). World-Wide Web Home, URL: http://info.cern.ch/, (undated). 55 Churchyard, </note> <author> H. </author> <year> (1995). </year> <note> htmlchek HTML syntax and cross-reference checker version 4.1, February 20 1995 -- menu, URL: http://uts.cc.utexas.edu/~churchh/htmlchek.html, February 20, </note> <year> 1995. </year>
Reference-contexts: This system uses the hypermedia aspect to organize unstructured information, and used the natural language aspect to help alleviate the problems of disorientation and the cognitive overhead of having too many links. Other groups have investigated using speech with hypermedia systems. One hyper-speech system <ref> (Arons, 1991) </ref> enabled the user to navigate in an audio environment without a visual display; speech recognition was used to maneuver in a database of digitally recorded speech.
Reference: <author> Cohen, P. </author> <year> (1992). </year> <title> The role of natural language in a multimodal interface, </title> <booktitle> Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <address> Monterey, Califor-nia, </address> <month> November 15-18, </month> <year> 1992, </year> <pages> p. 143-149, </pages> <publisher> Baltimore : ACM Press. </publisher>
Reference-contexts: Other researchers have investigated the comparative advantages of multimodal interfaces, including Cohen (1992) and Oviatt (1992, 1994). One of the goals of this research 8 has been to attempt to use the strengths of one modality to overcome for the weaknesses of another <ref> (Cohen, 1992, 143) </ref>, who proposed a framework for this analysis. <p> On the other hand, language has the problem that the user may not know the vocabulary of the recognizer. Spoken lan 9 guage systems are also prone to other problems such as ambiguity and other causes of recognition errors. <ref> (Cohen, 1992) </ref>. 2.3 Previous work with speech access to hypermedia systems Interactive hypertext systems have been proposed for fifty years; a useful survey is provided by Arons (1991). <p> Finally, the spatial nature of the interface limits the set of things to which the user can refer. Users cannot describe entities <ref> (Cohen, 1992) </ref> instead of pointing to them. Similar problems exist with respect to actions. Because they are typically accomplished by selecting a command from a menu or by clicking on an icon, it is difficult to express complex actions other than as a perhaps tedious series of primitives.
Reference: <author> Cole, R., M. Fanty, Y. Muthusamy and M. </author> <title> Gopalakrishnan (1990). Speaker-independent recognition of spoken English letters, </title> <booktitle> Proceedings of the International Joint Conference on Neural Networks, </booktitle> <address> San Diego, CA, </address> <month> June </month> <year> 1990, </year> <title> v.2, </title> <editor> p. </editor> <address> 45-51, Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Cole, R., Hirschman, L., et al. </author> <year> (1995). </year> <title> The challenge of spoken language systems: Research directions for the Nineties. </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> 3(1), </volume> <pages> p. 1-20. </pages>
Reference-contexts: Among other things, the successful cultivation of such systems will require advance empirical work with human subjects, building a variety of new prototype systems, and the development of appropriate metrics for evaluating the accuracy, efficiency, learnability, expressive power, and other characteristics of different multimodal systems. <ref> (Cole, Hirschman et al., 1995, 12) </ref> Development and availability of a spoken-language enhancement to an interface for the World-Wide Web would also increase the availability and visibility of spoken-language technology in the computing community as a whole. <p> This omission was, no doubt, mostly a consequence of the relatively poor state of other means of expression as input modalities; spoken-language systems have made immense progress since 1983 <ref> (Cole, Hirschman et al., 1995) </ref>. Adding spoken-language capabilities to hypermedia holds the promise of extending users abilities in ways they find appealing. Empirical studies of multimodal interfaces have looked at user preferences for different kinds of inputs.
Reference: <author> Cole, R., Novick, D., Burnett, D., Hansen, B., Sutton, S. & Fanty, M. </author> <year> (1994). </year> <title> Towards automatic collection of the U.S. Census, </title> <booktitle> Proceedings of the 1994 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <month> April 19-22, </month> <year> 1994, </year> <institution> Adelaide Convention Centre, Adelaide, </institution> <address> South Australia, v.1, p. 93-96, Piscataway, </address> <institution> NJ : Institute of Electrical and Electronics Engineers. </institution>
Reference-contexts: Given speech to be recognized, OGIs current technology <ref> (Cole et al., 1994) </ref> works as follows: 1. A seventh-order Perceptual Linear Predictive (PLP) analysis (Hermansky, 1990) is performed every 6 msec using a 10 msec window. 2. A neural network classifies every 6-msec frame as voiced or not voiced. 3.
Reference: <author> Conte, E. </author> <year> (1994). </year> <title> A Basic HTML Style Guide: Readability, </title> <address> URL: http:// heasarc.gsfc.nasa.gov/0/docs/heasarc/Style_Guide/readability.html, </address> <month> June 22, </month> <year> 1994. </year>
Reference-contexts: This strongly suggests that designers of hypermedia interfaces should avoid multiple uses of Click here as a hotlink label; rather they should use a lexically meaningful label that refers to the semantics of the linked entity <ref> (Conte, 1994) </ref>. Similarly, there could be confusion between names of labels and names of actions; for example, the word back could be used both as a command to display the previously viewed document or a link label to a different document.
Reference: <author> Domel, P. </author> <year> (1994). </year> <title> Webmap - A graphical hypertext navigation tool. Advance Proceedings of Mosaic and the Web: </title> <booktitle> the Second International WWW Conference 94, p. </booktitle> <pages> 785-798. </pages>
Reference: <author> Fanty, M., Schmid, P., & Cole, R. </author> <year> (1993). </year> <title> City name recognition over the telephone, </title> <booktitle> Proceedings of the 1993 IEEE International Conference on Acoustics, Speech, and Signal 56 Processing, </booktitle> <address> April 27-30, 1993, Minneapolis Convention Center, Minneapolis, Minne-sota, Minneapolis, </address> <month> April </month> <year> 1993, </year> <editor> v.1, p. </editor> <address> 549-552, Piscataway, </address> <institution> NJ : Institute of Electrical and Electronics Engineers. </institution>
Reference: <author> Goddeau, D. </author> <year> (1995). </year> <note> Recent Publications, URL: http://sls-www.lcs.mit.edu/~dg/publications. html, February 1, </note> <year> 1995. </year>
Reference-contexts: Goddeaus Recent Publications page (Figure 4.3) <ref> (Goddeau, 1995) </ref> would produce spoken ambiguity because of the multiple occurrences of the word Postscript. A similar problem would be homophones appearing on the same page.
Reference: <author> Goddeau, D., Brill, E., Glass, J., Pao, C., Phillips, M., Polifroni, J., Seneff, S., and Zue, V. </author> <year> (1994). </year> <title> GALAXY: A human-language interface to on-line travel information, </title> <booktitle> Proceedings of the International Conference on Spoken Language Processing, </booktitle> <address> Yokohama, Japan, </address> <month> Sept. </month> <year> 1994, </year> <title> p. 707-710, </title> <journal> The Acoustical Society of Japan. </journal>
Reference-contexts: Earlier versions of MacMosaic had been compiled with speech recognition enhancements, but those compilations are no longer being performed, although they could be activated with some code changes (Stephenson, 1994). MITs Spoken Language Systems group has been working on GALAXY <ref> (Goddeau, 1994) </ref>, a distributed system for on-line information that handles the natural language aspects of the system at a remote-recognition server.
Reference: <author> Hemphill, C. </author> <year> (1995). </year> <type> Personal communication, </type> <month> February, </month> <year> 1995. </year>
Reference-contexts: Paciello at DEC is working with Hardin at NCSA on the Mosaic Disability Project (Paciello, 1995), one aspect of which is speech recognition. Hemphill at Texas Instruments has completed a prototype speech-enabled Mosaic <ref> (Hemphill, 1995) </ref> that allows for associating extended grammars and dialog states with links and hotlist items. Arbash at SRI developed a speech interface to Mosaic based on work related to the Xtalk project (Arbash, 1994).
Reference: <author> Hermansky, H. </author> <year> (1990). </year> <title> Perceptual Linear Predictive (PLP) Analysis of Speech, </title> <journal> J. Acoust. Soc. Am., v. </journal> <volume> 87, no 4., </volume> <pages> p. 1738-1751. </pages>
Reference-contexts: Given speech to be recognized, OGIs current technology (Cole et al., 1994) works as follows: 1. A seventh-order Perceptual Linear Predictive (PLP) analysis <ref> (Hermansky, 1990) </ref> is performed every 6 msec using a 10 msec window. 2. A neural network classifies every 6-msec frame as voiced or not voiced. 3. The PLP and voicing features in a 168-msec input window are used by a neural network to classify each frame phonetically.
Reference: <author> Hermanky, H., Morgan, N., & Hirsch, H. </author> <year> (1994). </year> <title> Recognition of Speech in Additive and Convolutional Noise Based on RASTA Spectral Processing, </title> <booktitle> Proceedings of the 1994 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <month> April 19-22, </month> <year> 1994, </year> <institution> Adelaide Convention Centre, Adelaide, </institution> <address> South Australia, v.1, p. 421-424, Piscataway, </address> <institution> NJ : Institute of Electrical and Electronics Engineers. </institution>
Reference: <author> Lefebvre, P., Duncan, G., & Poirier, F. </author> <year> (1993). </year> <title> Speaking with computers: A multimodal approach, </title> <booktitle> Proceedings of EuroSpeech93: Third European Conference on Speech Communication and Technology, </booktitle> <address> Berlin, p. </address> <pages> 1665-1668. </pages>
Reference: <author> Lunati, J.-M., & Rudnicky, A. </author> <year> (1990). </year> <title> The design of a spoken language interface, </title> <booktitle> Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <address> Hidden Valley, PA, </address> <month> June </month> <year> 1990, </year> <note> p. 225-229. 57 Lund, J. </note> <year> (1994). </year> <title> Perl Program for Retrieving Web Documents. </title> <note> URL: http:// www.utexas.edu/~zippy/url_get.html, September 28, </note> <year> 1994. </year>
Reference-contexts: Although the hands-free nature of spoken-language interfaces is appealing, early implementations of spoken-language interfaces to hypermedia may have to rely on touch-to-talk methods so that the recognizer is not confused by extraneous speech <ref> (Lunati & Rudnicky, 1990) </ref>, or by prefixing the utterance with a keyword, as in some com mercial interfaces.
Reference: <author> Mauldin, M. </author> <year> (1994). </year> <title> Frequency and Length of half a million WWW Anchors. </title> <address> URL: http://fuzine.mt.cs.cmu.edu/mlm/links.html, June 24, </address> <year> 1994. </year>
Reference-contexts: A confidence measure is computed as the difference between the average frame score of the top choice and the average frame score of the second choice. A review of typical hypermedia documents <ref> (Mauldin, 1994) </ref> reveals that links are often proper nouns. This suggests that recognizers for hypermedia browsers will have to rely on vocabulary-independent techniques rather than extensive task-dependent training.
Reference: <author> Moran, T., & Anderson, R. </author> <year> (1990). </year> <title> The workaday world as a paradigm for CSCW design, </title> <booktitle> Proceedings of the Conference on Computer-Supported Cooperative Work, </booktitle> <address> October 7-10, 1990 Los Angeles, CA, p. 381-393, New York, </address> <institution> NY : The Association for Computing Machinery. </institution>
Reference-contexts: Moreover, the availability of even an experimental spoken-language interface would enable the growing population of Web users to address these questions in the very practice of their own day-to-day computing. If a spoken-language interface is used in the workaday world of cooperative computing <ref> (Moran, 1990) </ref> exemplified by the Web, then we will have (a) empirical evidence of its utility and (b) a fund of varied experiences with the interface that could contribute to improvements.

Reference: <author> Nigay, L., & Coutaz, J. </author> <year> (1993). </year> <title> A design space for multimodal systems: concurrent processing and data fusion, </title> <booktitle> Proceedings of InterCHI93, </booktitle> <address> Amsterdam, </address> <month> April, </month> <year> 1993, </year> <title> p. </title> <type> 172-178, </type> <institution> New York : Association for Computing Machinery. </institution>
Reference: <institution> Olary, Bob (1995). Hartsfield Schools Home page, </institution> <address> URL: http://www.harts-field.leon.k12..us/, April 12, </address> <year> 1995. </year>
Reference-contexts: the user may have more than one link on a page labeled Click Here; if speech was used to access that page, how would the system know which link was referred to by the word here? Examples of WWW pages with this problem include Hartsfield Schools Home Page (Figure 4.1) <ref> (Olary, 1995) </ref> and Faculty of Dentistry Home Page at Kyushu University (Figure 4.2) (Saito, 1995). Goddeaus Recent Publications page (Figure 4.3) (Goddeau, 1995) would produce spoken ambiguity because of the multiple occurrences of the word Postscript. A similar problem would be homophones appearing on the same page.
Reference: <author> Oviatt, S. </author> <year> (1992). </year> <title> Pen/voice: Complementary multimodal communication, </title> <booktitle> In Proceedings of Speech Tech92, </booktitle> <address> New York, </address> <month> February </month> <year> 1992, </year> <pages> p. 238-241. </pages>
Reference-contexts: A substantial amount needs to be learned through empirical and experiential methods such as system building. Indeed, the potential interactions involved in multimodal systems are so complex that it may be impossible to discern their optimal structure without conducting advance exploratory research <ref> (Oviatt, 1992) </ref>. Thus the determination of the important or tractable issues relating to such a project requires development, use, and testing of a spoken-language interface to the World-Wide Web. <p> Second, it helps to avoid confusion between the commands and the link labels that are pronounced the same way. Before spoken command access to SLAM is added, however, an improved recognizer should be put in place 45 to help to avoid spiral degradation errors <ref> (Oviatt, 1992) </ref> that will occur when commands and their successive attempts to be corrected with speech are misrecognized.
Reference: <author> Oviatt, S., & Olsen, E. </author> <year> (1994). </year> <title> Integration themes in multimodal human-computer interaction, </title> <booktitle> Proceedings of Intl. Conference on Speech and Language Processing 94, Yoko-hama, p. </booktitle> <pages> 551-554, </pages> <booktitle> The Acoustical Society of Japan. </booktitle>
Reference: <author> Paciello, M. </author> <year> (1995). </year> <type> Personal communication, </type> <month> January, </month> <year> 1995. </year>
Reference-contexts: Raman at DEC has begun work on a spoken language extension to Mosaic called RETRIEVER (Raman, 1995) that focuses on allowing easier access to the Web to people with disabilities. Paciello at DEC is working with Hardin at NCSA on the Mosaic Disability Project <ref> (Paciello, 1995) </ref>, one aspect of which is speech recognition. Hemphill at Texas Instruments has completed a prototype speech-enabled Mosaic (Hemphill, 1995) that allows for associating extended grammars and dialog states with links and hotlist items.
Reference: <author> Raman, T. </author> <year> (1995). </year> <type> Personal communication, </type> <month> March, </month> <year> 1995. </year>
Reference-contexts: While the current focus of the GALAXY system is the travel domain, MIT is also believed to be applying this technology to creating a speech interface to the WWW as well. Raman at DEC has begun work on a spoken language extension to Mosaic called RETRIEVER <ref> (Raman, 1995) </ref> that focuses on allowing easier access to the Web to people with disabilities. Paciello at DEC is working with Hardin at NCSA on the Mosaic Disability Project (Paciello, 1995), one aspect of which is speech recognition. <p> Such a system would need synthesized-voice output from the system, as well as allow voice input. A useful part of such a system would involve having a means of summarizing WWW documents for users <ref> (Raman, 1995) </ref>, so that long spoken utterances from the system could be replaced with statements like The following document has one main title, two subtitles, and five paragraphs. 6.8 Speech access to hot icons, imagemaps, and text-entry forms Currently SLAM does not permit selection of highlighted pictures and icons, although with
Reference: <author> Resnick, P. </author> <year> (1990). </year> <title> The rainbow pages: Building community with voice technology, </title> <booktitle> Proceedings of DIAC-90, Directions and Implications of Advanced Computing, </booktitle> <address> Boston, MA, </address> <month> July </month> <year> 1990, </year> <pages> p. 2-13, </pages> <address> Palo Alto CA: </address> <institution> Computer Professionals for Social Responsibility. </institution> <note> 59 Rudnicky, </note> <author> A. </author> <year> (1993). </year> <title> Factors affecting choice of speech over keyboard and mouse in a simple data-retrieval task, </title> <booktitle> Proceedings of EuroSpeech93: Third European Conference on Speech Communication and Technology, </booktitle> <address> Berlin, p. </address> <pages> 2161-2164. </pages>
Reference: <author> Saito, </author> <note> Takeshi (1995). </note> <institution> Faculty of Dentistry Home Page, </institution> <note> URL: http://133.5.231.40/, (undated). </note>
Reference-contexts: Here; if speech was used to access that page, how would the system know which link was referred to by the word here? Examples of WWW pages with this problem include Hartsfield Schools Home Page (Figure 4.1) (Olary, 1995) and Faculty of Dentistry Home Page at Kyushu University (Figure 4.2) <ref> (Saito, 1995) </ref>. Goddeaus Recent Publications page (Figure 4.3) (Goddeau, 1995) would produce spoken ambiguity because of the multiple occurrences of the word Postscript. A similar problem would be homophones appearing on the same page.
Reference: <author> Shneiderman, B. </author> <year> (1983). </year> <title> Direct manipulation: A step beyond programming languages, </title> <journal> IEEE Computer, </journal> <volume> 16(8), </volume> <pages> p. 57-69. </pages>
Reference-contexts: World-Wide Web, which provides a rich hypermedia environment that includes outputs in hypertext, images and sound, the inputs to the system remain keyboard and pointer-based. (As the most typical pointer is the mouse, we will use the term mouse-based interface to refer to pointer-based interfaces generally.) The mouse-based direct-manipulation interface <ref> (Shneiderman, 1983) </ref> provided a rational and innovative means of interaction with computer systems. While physical pointing and bitmapped displays solved many of the problems with character-and-keyboard-based interfaces, direct manipulation based on physical pointing did not make use of the full range of expressive capabilities of human users.
Reference: <author> Stephenson, K. </author> <year> (1994). </year> <note> Subject: Re: NCSA Mosaic Mac 2.0 Alpha1. Article &lt;2tcnr8$lhh@vixen.cso.uiuc.edu&gt; in comp.infosystems.www, June 12, </note> <year> 1994. </year>
Reference-contexts: Earlier versions of MacMosaic had been compiled with speech recognition enhancements, but those compilations are no longer being performed, although they could be activated with some code changes <ref> (Stephenson, 1994) </ref>. MITs Spoken Language Systems group has been working on GALAXY (Goddeau, 1994), a distributed system for on-line information that handles the natural language aspects of the system at a remote-recognition server.
Reference: <author> Stock, O. </author> <year> (1991). </year> <title> Natural language and exploration of an information space: The AlFresco interactive system, </title> <booktitle> Proceedings of the Twelfth International Conference on Artificial Intelligence, </booktitle> <address> Darling Harbour, Sydney, Australia, </address> <month> 24-30 August </month> <year> 1991, </year> <pages> p. 972-978, </pages> <address> San Mateo, Calif. </address> : <publisher> M. Kaufmann Publishers. </publisher>
Reference-contexts: Some disadvantages of such systems are that users will have difficulty in actually getting specific information, and are likely to encounter the well-known lost in hyperspace effect (Domel, 1994; Whalen, 1989) during which users get sidetracked and lost while navigating through a hypermedia environment. One system <ref> (Stock, 1991) </ref> combines natural language and hypermedia to explore Ital-ian frescoes. This system uses the hypermedia aspect to organize unstructured information, and used the natural language aspect to help alleviate the problems of disorientation and the cognitive overhead of having too many links.
Reference: <author> Wallach, D. </author> <year> (1994). </year> <title> WWW Size, World-Wide Web page summarizing NSFNet statistics collected at nic.merit.edu, </title> <address> URL: http://www.cs.princeton.edu/grad/dwallach/www-talk/size.html, March 22, </address> <year> 1994. </year>
Reference-contexts: By mid-Spring of 1994, Internet traffic was doubling about every six months. Of this growth, 2 the World-Wide Webs proportional usage was doubling approximately every four months. In absolute volume of traffic, use of the WWW was doubling every two and a half months <ref> (Wallach, 1994) </ref>. Much of the popularity of Mosaic can be attributed to its mouse-based interface, which can quickly, simply, and directly aid the user in browsing the variety of documents available on the Internet.
Reference: <author> Whalen, T., & Patrick, A. </author> <year> (1989). </year> <title> Conversational hypertext: Information access through natural language dialogues with computers, </title> <booktitle> Proceedings of the Conference on Human Factors in Computing Systems: CHI 89, </booktitle> <address> Austin, Texas, April 30-May 4, 1989, p. 289-292, New York, </address> <publisher> NY : ACM Press. </publisher>
References-found: 31

