URL: ftp://ftp.cse.ucsc.edu/pub/ml/disj_proc.ps.Z
Refering-URL: http://www.cse.ucsc.edu/~mark/ftp-ml-root/ExpertBibDir/expbib.html
Root-URL: http://www.cse.ucsc.edu
Title: Tracking the best disjunction  
Author: Peter Auer Manfred K. Warmuth 
Address: Santa Cruz, CA 95064 (USA)  
Affiliation: Department of Computer Science University of California at Santa Cruz  
Abstract: Littlestone developed a simple deterministic on-line learning algorithm for learning k-literal disjunctions. This algorithm (called Winnow) keeps one weight for each of the n variables and does multiplicative updates to its weights. We develop a randomized version of Winnow and prove bounds for an adaptation of the algorithm for the case when the disjunction may change over time. In this case a possible target disjunction schedule T is a sequence of disjunctions (one per trial) and the shift size is the total number of literals that are added/removed from the disjunctions as one progresses through the sequence. We develop an algorithm that predicts nearly as well as the best disjunction schedule for an arbitrary sequence of examples. This algorithm that allows us to track the predictions of the best disjunction is hardly more complex than the original version. However the amortized analysis needed for obtaining worst-case mistake bounds requires new techniques. In some cases our lower bounds show that the upper bounds of our algorithm have the right constant in front of the leading term in the mistake bound and almost the right constant in front of the second leading term. By combining the tracking capability with existing applications of Winnow we are able to enhance these applications to the shifting case as well. 
Abstract-found: 1
Intro-found: 1
Reference: [Aue93] <author> P. Auer. </author> <title> On-line learning of rectangles in noisy environments. </title> <booktitle> In Proceedings of the Sixth Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> pages 253-261. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: This method was previously used for developing noise robust algorithms for predicting 3 For this potential function the weights must be positive. Negative weights are handled via a reduction [Lit88, Lit89, KW94]. nearly as well as the best discretized d-dimensional axis--parallel box <ref> [MW95, Aue93] </ref> or as well as the best pruning of a decision tree [HS95]. In these cases a multiplicative algorithm maintains one weight for each of the exponentially many basic concepts. However for the above examples, the multiplicative algorithms with the exponentially many weights can still be simulated efficiently.
Reference: [CBFH + 94] <author> N. Cesa-Bianchi, Y. Freund, D. P. Helmbold, D. Haussler, R. E. Schapire, and M. K. War-muth. </author> <title> How to use expert advice. </title> <type> Technical Report UCSC-CRL-94-33, </type> <institution> Univ. of Calif. Computer Research Lab, </institution> <address> Santa Cruz, CA, </address> <year> 1994. </year> <note> An extended abstract appeared in STOC '93. </note>
Reference-contexts: For many other standard algorithms such as the Perceptron Algorithm [Ros58], the number of mistakes can grow linearly in the dimension [KW95]. In the meantime a number of algorithms similar to Winnow have been developed that also show the logarithmic growth of the loss bounds in the dimension <ref> [LW94, Vov90, CBFH + 94, HKW94, KW94] </ref>. <p> Consider the following by now standard on-line learning model <ref> [Lit89, Lit88, Vov90, CBFH + 94] </ref>. Learning proceeds in trials. In trial t 1 the algorithm is presented with an instance ~x t (in our case an n-dimensional binary vector) that is used to produce a binary prediction y t . <p> Our lower bounds for both the deterministic and the randomized case cannot be improved significantly because there are essentially matching upper bounds achieved by non-efficient algorithms with the correct factors on the first and the second term. These algorithms use n experts <ref> [CBFH + 94] </ref>. Each expert simply computes the value of a particular k-literal disjunction and one weight is kept per expert. <p> These algorithms use n experts [CBFH + 94]. Each expert simply computes the value of a particular k-literal disjunction and one weight is kept per expert. This amounts to expanding the n-dimensional Boolean inputs into n Boolean inputs and then using single literals (experts) <ref> [LW94, Vov90, CBFH + 94] </ref> as the comparison class instead of k-literal monotone disjunctions. The expected number of mistakes of the probabilistic algorithm is at most Q + p where Q is a bound on the number of classification errors of the best k-literal disjunction. <p> Lemma 5.3 ([LW94]) For any deterministic learning algorithm L, any n 2, and any A 0, there is an example sequence S 2 S 0 (1; A; n) such that M (L; S) 2A + log 2 n: A slight modification of results in <ref> [CBFH + 94] </ref> gives Lemma 5.4 ([CBFH + 94]) There are functions n () and A (n; ) such that for any &gt; 0, any probabilistic learning algorithm L, any n n (), and any A A (n; ), there is an example sequence S 2 S 0 (1; A; n)
Reference: [CBFHW94] <author> N. Cesa-Bianchi, Y. Freund, D. P. Helm-bold, and M. Warmuth. </author> <title> On-line prediction and conversion strategies. </title> <booktitle> In Computational Learning Theory: Eurocolt '93, volume New Series Number 53 of The Institute of Mathematics and its Applications Confer--ence Series, </booktitle> <pages> pages 205-216, </pages> <address> Oxford, 1994. </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: In some sense our algorithm compresses n weights to only n weights. At this point we don't have a computational interpretation of our weights. Such an interpretation was only found for the single literal (expert) case <ref> [CBFHW94] </ref>. As Littlestone [Lit91] we use an amortized analysis with an entropic potential function to obtain our worst-case loss bounds.
Reference: [Cov65] <author> T. </author> <title> Cover. Behavior of sequential predictors of binary sequences. </title> <booktitle> In Proceedings of the 4th Prague Conference on Information Theory, Statistical Decision Functions and Random Processes, </booktitle> <pages> pages 263-272. </pages> <publisher> Publishing House of the Czechoslovak Academy of Sciences, </publisher> <year> 1965. </year>
Reference-contexts: In contrast the potential function used for the analysis of Winnow [Lit88, Lit89] that is also used in this paper is the following generalization 3 of relative entropy <ref> [Cov65] </ref>: P n In the case of linear regression a framework was developed [KW94] for deriving updates from the potential function used in the amortized analysis. The same framework can be adapted to derive both the Perceptron algorithm and Winnow.
Reference: [DH73] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference-contexts: There is a natural competitor to Winnow which is the well known Perceptron algorithm [Ros58] for learning linear threshold functions. This algorithm does additive instead of multiplicative updates. The classical Perceptron Convergence Theorem gives a mistake bound for this algorithm <ref> [DH73, Hay93] </ref>. The proof of this theorem can also be seen as an amortized analysis. However the potential function needed for the perceptron algorithm is quite different from the potential function used for the analysis of Winnow.
Reference: [Hay93] <author> S. Haykin. </author> <title> Neural Networks: a Comprehensive Foundation. </title> <publisher> Macmillan, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: There is a natural competitor to Winnow which is the well known Perceptron algorithm [Ros58] for learning linear threshold functions. This algorithm does additive instead of multiplicative updates. The classical Perceptron Convergence Theorem gives a mistake bound for this algorithm <ref> [DH73, Hay93] </ref>. The proof of this theorem can also be seen as an amortized analysis. However the potential function needed for the perceptron algorithm is quite different from the potential function used for the analysis of Winnow.
Reference: [HKW94] <author> D. Haussler, J. Kivinen, and M. K. War-muth. </author> <title> Tight worst-case loss bounds for predicting with expert advice. </title> <type> Technical Report UCSC-CRL-94-36, </type> <institution> University of California, Santa Cruz, Computer Research Laboratory, </institution> <month> November </month> <year> 1994. </year> <note> An extended abstract appeared in Eurocolt 1995. To appear subject to revision in IEEE Transaction on Information Theory. </note>
Reference-contexts: For many other standard algorithms such as the Perceptron Algorithm [Ros58], the number of mistakes can grow linearly in the dimension [KW95]. In the meantime a number of algorithms similar to Winnow have been developed that also show the logarithmic growth of the loss bounds in the dimension <ref> [LW94, Vov90, CBFH + 94, HKW94, KW94] </ref>. <p> Again the basic building block is a simple on-line algorithm that uses multiplicative weight updates <ref> [Vov90, HKW94] </ref> but now the predictions and the feedback in each trial are real-valued and lie in the interval [0; 1]. The class of loss functions includes the natural loss functions of log loss, square loss and Hellinger loss.
Reference: [HS95] <author> D. P. Helmbold and R. E. Schapire. </author> <title> Predicting nearly as well as the best pruning of a decision tree. </title> <booktitle> In Proc. 6th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 61-68. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Negative weights are handled via a reduction [Lit88, Lit89, KW94]. nearly as well as the best discretized d-dimensional axis--parallel box [MW95, Aue93] or as well as the best pruning of a decision tree <ref> [HS95] </ref>. In these cases a multiplicative algorithm maintains one weight for each of the exponentially many basic concepts. However for the above examples, the multiplicative algorithms with the exponentially many weights can still be simulated efficiently.
Reference: [HW95] <author> M. Herbster and M. K. Warmuth. </author> <title> Tracking the best expert. </title> <booktitle> In Machine Learning: Proceedings of the Twelfth International Conference, </booktitle> <address> San Francisco, CA., 1995. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: In addition to generalizing the work of [LW94] to arbitrary size disjunctions we were able to optimize the constant in the leading term of the mistake bound of Winnow and develop a probabilistic version of the algorithm. In <ref> [HW95] </ref> the work of [LW94] was generalized in a different direction. The focus there is to predict as well as the best shifting expert, where well is measured in terms of other loss functions than the discrete loss (counting mistakes) which is the loss function used in this paper. <p> The class of loss functions includes the natural loss functions of log loss, square loss and Hellinger loss. In this cases more sophisticated methods are needed for recovering small weights quickly <ref> [HW95] </ref> than simply lower bounding the weights. is correct on the current example. Thus only in some of the trials in which the current disjunction would make a mistake the disjunction is shifted.
Reference: [Jum90] <author> G. Jumarie. </author> <title> Relative information. </title> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: The Perceptron algorithm is seeking a weight vector that is consistent with the examples but otherwise minimizes some Euclidean length. Winnow instead minimizes a relative entropy and is thus rooted in the Minimum Relative Entropy Principle of Kullback <ref> [KK92, Jum90] </ref>. We believe that the techniques developed here for learning how to predict as well as the best shifting disjunction will be useful in other settings such as developing algorithms that predict nearly as well as the best shifting linear combination.
Reference: [KK92] <author> J. N. Kapur and H. </author> <title> K Kesavan. Entropy Optimization Principles with Applications. </title> <publisher> Academic Press, Inc., </publisher> <year> 1992. </year>
Reference-contexts: The Perceptron algorithm is seeking a weight vector that is consistent with the examples but otherwise minimizes some Euclidean length. Winnow instead minimizes a relative entropy and is thus rooted in the Minimum Relative Entropy Principle of Kullback <ref> [KK92, Jum90] </ref>. We believe that the techniques developed here for learning how to predict as well as the best shifting disjunction will be useful in other settings such as developing algorithms that predict nearly as well as the best shifting linear combination.
Reference: [KW94] <author> J. Kivinen and M. Warmuth. </author> <title> Using experts for predicting continuous outcomes. </title> <booktitle> In Computational Learning Theory: Eurocolt '93, volume New Series Number 53 of The Institute of Mathematics and its Applications Conference Series, </booktitle> <pages> pages 109-120, </pages> <address> Oxford, 1994. </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: For many other standard algorithms such as the Perceptron Algorithm [Ros58], the number of mistakes can grow linearly in the dimension [KW95]. In the meantime a number of algorithms similar to Winnow have been developed that also show the logarithmic growth of the loss bounds in the dimension <ref> [LW94, Vov90, CBFH + 94, HKW94, KW94] </ref>. <p> In contrast the potential function used for the analysis of Winnow [Lit88, Lit89] that is also used in this paper is the following generalization 3 of relative entropy [Cov65]: P n In the case of linear regression a framework was developed <ref> [KW94] </ref> for deriving updates from the potential function used in the amortized analysis. The same framework can be adapted to derive both the Perceptron algorithm and Winnow. The different potential functions for the algorithms lead to the additive and multiplicative algorithms, respectively. <p> This method was previously used for developing noise robust algorithms for predicting 3 For this potential function the weights must be positive. Negative weights are handled via a reduction <ref> [Lit88, Lit89, KW94] </ref>. nearly as well as the best discretized d-dimensional axis--parallel box [MW95, Aue93] or as well as the best pruning of a decision tree [HS95]. In these cases a multiplicative algorithm maintains one weight for each of the exponentially many basic concepts.
Reference: [KW95] <author> J. Kivinen and M. K. Warmuth. </author> <title> The perceptron algorithm vs. winnow: linear vs. logarithmic mistake bounds when few input variables are relevant. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 289-300. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: Auer is supported by grant J01028-MAT of the Fonds zur Forderung der wissenschaftlichen Forschung, Austria. y M. K. Warmuth acknowledges the support of the NSF grant IRI-9123692. For many other standard algorithms such as the Perceptron Algorithm [Ros58], the number of mistakes can grow linearly in the dimension <ref> [KW95] </ref>. In the meantime a number of algorithms similar to Winnow have been developed that also show the logarithmic growth of the loss bounds in the dimension [LW94, Vov90, CBFH + 94, HKW94, KW94].
Reference: [Lit88] <author> N. Littlestone. </author> <title> Learning when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction One of the most significant successes of the Computational Learning Theory community has been Littlestone's formalization of an on-line model of learning and the development of his algorithm Winnow for learning disjunctions <ref> [Lit89, Lit88] </ref>. The key feature of Winnow is that when learning disjunctions, the number of mistakes of the algorithm grows only logarithmically with the input dimension. fl P. Auer is supported by grant J01028-MAT of the Fonds zur Forderung der wissenschaftlichen Forschung, Austria. y M. K. <p> Consider the following by now standard on-line learning model <ref> [Lit89, Lit88, Vov90, CBFH + 94] </ref>. Learning proceeds in trials. In trial t 1 the algorithm is presented with an instance ~x t (in our case an n-dimensional binary vector) that is used to produce a binary prediction y t . <p> Winnow can be tuned as a function of k so that it makes at most O (A + k ln (n=k)) mistakes on any sequence of examples where the best disjunction makes at most A attribute errors <ref> [Lit88] </ref>. We give a randomized version of Winnow and give improved tunings of the original algorithm. <p> In contrast the potential function used for the analysis of Winnow <ref> [Lit88, Lit89] </ref> that is also used in this paper is the following generalization 3 of relative entropy [Cov65]: P n In the case of linear regression a framework was developed [KW94] for deriving updates from the potential function used in the amortized analysis. <p> This method was previously used for developing noise robust algorithms for predicting 3 For this potential function the weights must be positive. Negative weights are handled via a reduction <ref> [Lit88, Lit89, KW94] </ref>. nearly as well as the best discretized d-dimensional axis--parallel box [MW95, Aue93] or as well as the best pruning of a decision tree [HS95]. In these cases a multiplicative algorithm maintains one weight for each of the exponentially many basic concepts. <p> The potential/distance function used for the previous analysis of Win now <ref> [Lit88, Lit89, Lit91] </ref> is the following generalization of relative entropy to arbitrary non-negative weight vectors: D ( ~w; ~u) = i=1 w i u i + u i ln w i : By taking derivatives it is easy to see that the distance is minimal and equal to 0 if and
Reference: [Lit89] <author> N. Littlestone. </author> <title> Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. </title> <type> PhD thesis, Technical Report UCSC-CRL-89-11, </type> <institution> University of California Santa Cruz, </institution> <year> 1989. </year>
Reference-contexts: 1 Introduction One of the most significant successes of the Computational Learning Theory community has been Littlestone's formalization of an on-line model of learning and the development of his algorithm Winnow for learning disjunctions <ref> [Lit89, Lit88] </ref>. The key feature of Winnow is that when learning disjunctions, the number of mistakes of the algorithm grows only logarithmically with the input dimension. fl P. Auer is supported by grant J01028-MAT of the Fonds zur Forderung der wissenschaftlichen Forschung, Austria. y M. K. <p> Consider the following by now standard on-line learning model <ref> [Lit89, Lit88, Vov90, CBFH + 94] </ref>. Learning proceeds in trials. In trial t 1 the algorithm is presented with an instance ~x t (in our case an n-dimensional binary vector) that is used to produce a binary prediction y t . <p> In contrast the potential function used for the analysis of Winnow <ref> [Lit88, Lit89] </ref> that is also used in this paper is the following generalization 3 of relative entropy [Cov65]: P n In the case of linear regression a framework was developed [KW94] for deriving updates from the potential function used in the amortized analysis. <p> This method was previously used for developing noise robust algorithms for predicting 3 For this potential function the weights must be positive. Negative weights are handled via a reduction <ref> [Lit88, Lit89, KW94] </ref>. nearly as well as the best discretized d-dimensional axis--parallel box [MW95, Aue93] or as well as the best pruning of a decision tree [HS95]. In these cases a multiplicative algorithm maintains one weight for each of the exponentially many basic concepts. <p> The potential/distance function used for the previous analysis of Win now <ref> [Lit88, Lit89, Lit91] </ref> is the following generalization of relative entropy to arbitrary non-negative weight vectors: D ( ~w; ~u) = i=1 w i u i + u i ln w i : By taking derivatives it is easy to see that the distance is minimal and equal to 0 if and
Reference: [Lit91] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 147-156, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: In some sense our algorithm compresses n weights to only n weights. At this point we don't have a computational interpretation of our weights. Such an interpretation was only found for the single literal (expert) case [CBFHW94]. As Littlestone <ref> [Lit91] </ref> we use an amortized analysis with an entropic potential function to obtain our worst-case loss bounds. However besides the more careful tuning of the bounds we take the amortized analysis method a significant step further by proving mistake bounds of our algorithm as compared to the best shifting disjunction. <p> a learning algorithm L on an example se quence S is the number of misclassifications M (L; S) = t=1 where y t is the prediction of the learning algorithm L in trial t. 2 The algorithm We present algorithm SWIN, see Figure 1, an extension of Littlestone's Winnow2 algorithm <ref> [Lit91] </ref>. Our extension incorporates a randomization of the algorithm, and it guarantees a lower bound on the weights used by the algorithm. The algorithm maintains a vector of n weights for the n attributes. <p> The potential/distance function used for the previous analysis of Win now <ref> [Lit88, Lit89, Lit91] </ref> is the following generalization of relative entropy to arbitrary non-negative weight vectors: D ( ~w; ~u) = i=1 w i u i + u i ln w i : By taking derivatives it is easy to see that the distance is minimal and equal to 0 if and
Reference: [LW94] <author> N. Littlestone and M. K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108(2) </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: For many other standard algorithms such as the Perceptron Algorithm [Ros58], the number of mistakes can grow linearly in the dimension [KW95]. In the meantime a number of algorithms similar to Winnow have been developed that also show the logarithmic growth of the loss bounds in the dimension <ref> [LW94, Vov90, CBFH + 94, HKW94, KW94] </ref>. <p> These algorithms use n experts [CBFH + 94]. Each expert simply computes the value of a particular k-literal disjunction and one weight is kept per expert. This amounts to expanding the n-dimensional Boolean inputs into n Boolean inputs and then using single literals (experts) <ref> [LW94, Vov90, CBFH + 94] </ref> as the comparison class instead of k-literal monotone disjunctions. The expected number of mistakes of the probabilistic algorithm is at most Q + p where Q is a bound on the number of classification errors of the best k-literal disjunction. <p> Our extension of Winnow2 simply adds a step to the original algorithm that resets a weight to fi=n whenever it drops below this boundary. Similar methods for lower bounding the weights were used in the algorithm WML of <ref> [LW94] </ref> which was designed for predicting as well as the best shifting single literal/expert. In addition to generalizing the work of [LW94] to arbitrary size disjunctions we were able to optimize the constant in the leading term of the mistake bound of Winnow and develop a probabilistic version of the algorithm. <p> Similar methods for lower bounding the weights were used in the algorithm WML of <ref> [LW94] </ref> which was designed for predicting as well as the best shifting single literal/expert. In addition to generalizing the work of [LW94] to arbitrary size disjunctions we were able to optimize the constant in the leading term of the mistake bound of Winnow and develop a probabilistic version of the algorithm. In [HW95] the work of [LW94] was generalized in a different direction. <p> In addition to generalizing the work of <ref> [LW94] </ref> to arbitrary size disjunctions we were able to optimize the constant in the leading term of the mistake bound of Winnow and develop a probabilistic version of the algorithm. In [HW95] the work of [LW94] was generalized in a different direction. The focus there is to predict as well as the best shifting expert, where well is measured in terms of other loss functions than the discrete loss (counting mistakes) which is the loss function used in this paper. <p> The updates of the weights are performed in two steps. The first step is the original WINNOW update, and the second step guarantees that no weight is smaller than fi n for some parameter fi (the same approach was taken in <ref> [LW94] </ref>). Observe that the weights are changed only if the probability of making a mistake was non-zero. For the deterministic algorithm this means that the weights are changed only if the algorithm made a mistake. Furthermore the i-th weight is modified only if x t;i = 1.
Reference: [MW95] <author> M. Maass and K. Warmuth, M. </author> <title> Efficient learning with virtual threshold gates. </title> <booktitle> In Proc. 12th International Conf. on Machine Learning, </booktitle> <pages> pages 378-386, </pages> <address> San Francisco, CA, July 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This method was previously used for developing noise robust algorithms for predicting 3 For this potential function the weights must be positive. Negative weights are handled via a reduction [Lit88, Lit89, KW94]. nearly as well as the best discretized d-dimensional axis--parallel box <ref> [MW95, Aue93] </ref> or as well as the best pruning of a decision tree [HS95]. In these cases a multiplicative algorithm maintains one weight for each of the exponentially many basic concepts. However for the above examples, the multiplicative algorithms with the exponentially many weights can still be simulated efficiently.
Reference: [Ros58] <author> F. Rosenblatt. </author> <title> The perceptron: A probabilistic model for information storage and organization in the brain. </title> <journal> Psych. Rev., </journal> <volume> 65 </volume> <pages> 386-407, </pages> <year> 1958. </year> <note> (Reprinted in Neurocomputing (MIT Press, 1988).). </note>
Reference-contexts: Auer is supported by grant J01028-MAT of the Fonds zur Forderung der wissenschaftlichen Forschung, Austria. y M. K. Warmuth acknowledges the support of the NSF grant IRI-9123692. For many other standard algorithms such as the Perceptron Algorithm <ref> [Ros58] </ref>, the number of mistakes can grow linearly in the dimension [KW95]. In the meantime a number of algorithms similar to Winnow have been developed that also show the logarithmic growth of the loss bounds in the dimension [LW94, Vov90, CBFH + 94, HKW94, KW94]. <p> Winnow is an algorithm for learning arbitrary linear threshold functions and our methods for tracking the best disjunction still need to be generalized to learning this more general class of concepts. There is a natural competitor to Winnow which is the well known Perceptron algorithm <ref> [Ros58] </ref> for learning linear threshold functions. This algorithm does additive instead of multiplicative updates. The classical Perceptron Convergence Theorem gives a mistake bound for this algorithm [DH73, Hay93]. The proof of this theorem can also be seen as an amortized analysis.
Reference: [Vov90] <author> V. Vovk. </author> <title> Aggregating strategies. </title> <booktitle> In Proc. 3rd Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 371-383. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: For many other standard algorithms such as the Perceptron Algorithm [Ros58], the number of mistakes can grow linearly in the dimension [KW95]. In the meantime a number of algorithms similar to Winnow have been developed that also show the logarithmic growth of the loss bounds in the dimension <ref> [LW94, Vov90, CBFH + 94, HKW94, KW94] </ref>. <p> Consider the following by now standard on-line learning model <ref> [Lit89, Lit88, Vov90, CBFH + 94] </ref>. Learning proceeds in trials. In trial t 1 the algorithm is presented with an instance ~x t (in our case an n-dimensional binary vector) that is used to produce a binary prediction y t . <p> These algorithms use n experts [CBFH + 94]. Each expert simply computes the value of a particular k-literal disjunction and one weight is kept per expert. This amounts to expanding the n-dimensional Boolean inputs into n Boolean inputs and then using single literals (experts) <ref> [LW94, Vov90, CBFH + 94] </ref> as the comparison class instead of k-literal monotone disjunctions. The expected number of mistakes of the probabilistic algorithm is at most Q + p where Q is a bound on the number of classification errors of the best k-literal disjunction. <p> Again the basic building block is a simple on-line algorithm that uses multiplicative weight updates <ref> [Vov90, HKW94] </ref> but now the predictions and the feedback in each trial are real-valued and lie in the interval [0; 1]. The class of loss functions includes the natural loss functions of log loss, square loss and Hellinger loss.
References-found: 20

