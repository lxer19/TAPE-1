URL: http://www.cs.ubc.ca/spider/cebly/Papers/map.ps
Refering-URL: http://www.cs.ubc.ca/spider/cebly/papers.html
Root-URL: 
Email: fcebly,brafmang@cs.ubc.ca  
Title: Planning with Concurrent Interacting Actions  
Author: Craig Boutilier and Ronen I. Brafman 
Address: Vancouver, B.C., Canada V6T 1Z4  
Affiliation: Computer Science Department University of British Columbia  
Date: August, 1997  
Note: To appear, Proc. 14th National Conf. on AI (AAAI-97),Providence,  
Abstract: In order to generate plans for agents with multiple actuators or agent teams, we must be able to represent and plan using concurrent actions with interacting effects. Historically, this has been considered a challenging task that could require a temporal planner. We show that, with simple modifications, the STRIPS action representation language can be used to represent concurrent interacting actions. Moreover, current algorithms for partial-order planning require only small modifications in order to handle this language and produce coordinated multiagent plans. These results open the way to partial order planners for cooperative multiagent systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Blum and M. L. Furst. </author> <title> Fast planning through planning graph analysis. </title> <booktitle> In Proc. Fourteenth International Joint Conference on AI (IJCAI-95), </booktitle> <address> pp.1636-1642, Montreal, </address> <year> 1995. </year>
Reference-contexts: Section 5 concludes the paper. A longer version of this paper [3] contains an examination of the use of dynamic Bayes nets for representing (possibly probabilistic) actions in multiagent as the situation calculus [16] and dynamic Bayes nets [6, 4]. 4 Moreover, other planning algorithms, (e.g., <ref> [1, 9] </ref>) should prove amenable to extension to multiagent planning using similar ideas. (define (operator pickup) :params (?a1 ?x) :pre (and (inroom ?a1 ?r1) (inroom block ?r1) (handempty ?a1) (onfloor ?x)) :conc (not (= ?a1 ?a2)):(not (pickup ?a2 ?x)) :eff (and (not (handempty ?a1) (not (onfloor ?x)) (holding ?a1 Block)))) domains, <p> In fact, certain non-concurrency constraints are more naturally described using such resource lists than with the general method proposed here. Augmenting our language with such lists is straightforward. Apart from traditional nonlinear planners like UCPOP, newer planning algorithms, such as Graphplan <ref> [1] </ref> or Kautz and Selman's stochastic planning approach [9], can also be readily adapted to handle our multiagent representation language. In particular, Kautz and Selman's stochastic planner [9] can be viewed as using a one step planner as a subroutine.
Reference: [2] <author> C. Boutilier. </author> <title> Planning, learning and coordination in multia gent decision processes. </title> <booktitle> In Proc. Sixth Conference on Theoretical Aspects of Rationality and Knowledge (TARK-96), </booktitle> <address> pp.195-210, Amsterdam, </address> <year> 1996. </year>
Reference-contexts: An important research issue is how such plans can be generated and executed in a distributed fashion. This is an important question, addressed to some extent in the DAI literature, but for which adequate answers are still at large. Certain related issues are addressed in <ref> [2, 5] </ref>. The integration of classical planning with the more challenging aspects of mul-tiagent systems (coordination, bargaining, etc.) should prove especially interesting [8]. Acknowledgments: This work was partially funded through IRIS project IC-7 and NSERC research grant OGP0121843.
Reference: [3] <author> C. Boutilier and R. I. Brafman. </author> <title> Partial order multiagent planning and interacting actions. </title> <type> Tech. report, </type> <institution> University of British Columbia, Vancouver, </institution> <year> 1997 </year> <month> (forthcoming). </month>
Reference-contexts: In Section 4 we describe the Partial Order Multiagent Planning algorithm (POMP), a modified version of the UCPOP algorithm that can be used to generate multiagent plans. Section 5 concludes the paper. A longer version of this paper <ref> [3] </ref> contains an examination of the use of dynamic Bayes nets for representing (possibly probabilistic) actions in multiagent as the situation calculus [16] and dynamic Bayes nets [6, 4]. 4 Moreover, other planning algorithms, (e.g., [1, 9]) should prove amenable to extension to multiagent planning using similar ideas. (define (operator pickup) <p> We discuss the use of dynamic Bayes nets and the advantages they offer as an action representation method for multiagent systems in <ref> [3] </ref>. rent action conditions) or to disallow concurrent execution (by imposing non-concurrency conditions). We assume all action descriptions are consistent in the sequel. Several interesting issues arise in the specification of actions for multiple agents. <p> The latter differs from the standard promotion technique used in POP: it allows A t to be ordered concurrently with A c , not just after A c . 9 8 A treatment of the more general UCPOP algorithm appears in <ref> [3] </ref>, but is essentially similar. 9 If we wish to exclude actions that negate some precondition of To appear, Proc. 14th National Conf. on AI (AAAI-97),Providence, August, 1997 POMP (hA; O; L; NC; Bi,agenda) Termination: If agenda is empty, return hA; O; L; NC; Bi.
Reference: [4] <author> C. Boutilier and M. Goldszmidt. </author> <title> The frame problem and Bayesian network action representations. </title> <booktitle> In Proc. Eleventh Biennial Canadian Conference on Artificial Intelligence, </booktitle> <address> pp.69-83, Toronto, </address> <year> 1996. </year>
Reference-contexts: Section 5 concludes the paper. A longer version of this paper [3] contains an examination of the use of dynamic Bayes nets for representing (possibly probabilistic) actions in multiagent as the situation calculus [16] and dynamic Bayes nets <ref> [6, 4] </ref>. 4 Moreover, other planning algorithms, (e.g., [1, 9]) should prove amenable to extension to multiagent planning using similar ideas. (define (operator pickup) :params (?a1 ?x) :pre (and (inroom ?a1 ?r1) (inroom block ?r1) (handempty ?a1) (onfloor ?x)) :conc (not (= ?a1 ?a2)):(not (pickup ?a2 ?x)) :eff (and (not (handempty <p> the axiomatizer to recognize the conflict and state the true effect if a and b are performed concurrently (by imposing conditional effects with concur 6 In the case of multiple clauses, the disjointness restriction can be relaxed if the effects are independent, much like in a Bayes net action description <ref> [4] </ref>. We discuss the use of dynamic Bayes nets and the advantages they offer as an action representation method for multiagent systems in [3]. rent action conditions) or to disallow concurrent execution (by imposing non-concurrency conditions). We assume all action descriptions are consistent in the sequel.
Reference: [5] <author> R. I. Brafman and Y. Shoham. </author> <title> Knowledge considerations in robotics and distribution of robotic tasks. </title> <booktitle> In Proc. Fourteenth International Joint Conference on AI (IJCAI-95), </booktitle> <address> pp.96-102, Montreal, </address> <year> 1995. </year>
Reference-contexts: An important research issue is how such plans can be generated and executed in a distributed fashion. This is an important question, addressed to some extent in the DAI literature, but for which adequate answers are still at large. Certain related issues are addressed in <ref> [2, 5] </ref>. The integration of classical planning with the more challenging aspects of mul-tiagent systems (coordination, bargaining, etc.) should prove especially interesting [8]. Acknowledgments: This work was partially funded through IRIS project IC-7 and NSERC research grant OGP0121843.
Reference: [6] <author> T. Dean and K. </author> <title> Kanazawa. Persistence and probabilistic projection. </title> <journal> IEEE Trans. on Systems, Man and Cybernetics, </journal> <volume> 19(3) </volume> <pages> 574-585, </pages> <year> 1989. </year>
Reference-contexts: Section 5 concludes the paper. A longer version of this paper [3] contains an examination of the use of dynamic Bayes nets for representing (possibly probabilistic) actions in multiagent as the situation calculus [16] and dynamic Bayes nets <ref> [6, 4] </ref>. 4 Moreover, other planning algorithms, (e.g., [1, 9]) should prove amenable to extension to multiagent planning using similar ideas. (define (operator pickup) :params (?a1 ?x) :pre (and (inroom ?a1 ?r1) (inroom block ?r1) (handempty ?a1) (onfloor ?x)) :conc (not (= ?a1 ?a2)):(not (pickup ?a2 ?x)) :eff (and (not (handempty
Reference: [7] <author> B. R. Donald, J. Jennings, and D. </author> <title> Rus. Information invari ants for cooperating autonomous mobile robots. </title> <booktitle> In Proc. Intl. Symp. on Robotics Research, </booktitle> <year> 1993. </year>
Reference-contexts: Surprisingly, despite the recent interest in multiagent applicationsfor instance, in robotics <ref> [7, 10] </ref> and distributed AI [8]very little research addresses the MAP problem. 2 Some authors (see, e.g., [15]) have considered the representation of concurrent actions and a number of contemporary planners can handle concurrent noninteracting actions to a certain degree.
Reference: [8] <author> E. Ephrati and J. S. Rosenschein. </author> <title> Divide and conquer in mul tiagent planning. </title> <booktitle> In Proc. Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <address> pp.375-380, Seattle, </address> <year> 1994. </year>
Reference-contexts: Certain related issues are addressed in [2, 5]. The integration of classical planning with the more challenging aspects of mul-tiagent systems (coordination, bargaining, etc.) should prove especially interesting <ref> [8] </ref>. Acknowledgments: This work was partially funded through IRIS project IC-7 and NSERC research grant OGP0121843.
Reference: [9] <author> H. Kautz and B. Selman. </author> <title> Pushing the envelope: Planning, propositional logic, and stochastic search. </title> <booktitle> In Proc. Thirteenth National Conference on AI (AAAI-96), </booktitle> <address> pp.1194-1201, Port-land, OR, </address> <year> 1996. </year>
Reference-contexts: Section 5 concludes the paper. A longer version of this paper [3] contains an examination of the use of dynamic Bayes nets for representing (possibly probabilistic) actions in multiagent as the situation calculus [16] and dynamic Bayes nets [6, 4]. 4 Moreover, other planning algorithms, (e.g., <ref> [1, 9] </ref>) should prove amenable to extension to multiagent planning using similar ideas. (define (operator pickup) :params (?a1 ?x) :pre (and (inroom ?a1 ?r1) (inroom block ?r1) (handempty ?a1) (onfloor ?x)) :conc (not (= ?a1 ?a2)):(not (pickup ?a2 ?x)) :eff (and (not (handempty ?a1) (not (onfloor ?x)) (holding ?a1 Block)))) domains, <p> In fact, certain non-concurrency constraints are more naturally described using such resource lists than with the general method proposed here. Augmenting our language with such lists is straightforward. Apart from traditional nonlinear planners like UCPOP, newer planning algorithms, such as Graphplan [1] or Kautz and Selman's stochastic planning approach <ref> [9] </ref>, can also be readily adapted to handle our multiagent representation language. In particular, Kautz and Selman's stochastic planner [9] can be viewed as using a one step planner as a subroutine. Such a planner is simple to construct whether one uses the standard STRIPS representation or our richer language. <p> Augmenting our language with such lists is straightforward. Apart from traditional nonlinear planners like UCPOP, newer planning algorithms, such as Graphplan [1] or Kautz and Selman's stochastic planning approach <ref> [9] </ref>, can also be readily adapted to handle our multiagent representation language. In particular, Kautz and Selman's stochastic planner [9] can be viewed as using a one step planner as a subroutine. Such a planner is simple to construct whether one uses the standard STRIPS representation or our richer language. Once this planner exists, the algorithm behaves the same whatever the underlying language.
Reference: [10] <author> O. Khatib, K. Yokoi, K. Chang, D. Ruspini, R. Holmberg, A. Casal, and A. Baader. </author> <title> Force strategies for cooperative tasks in multiple mobile manipulation systems. </title> <booktitle> In Int. Symp. of Robotics Research, </booktitle> <year> 1995. </year>
Reference-contexts: Surprisingly, despite the recent interest in multiagent applicationsfor instance, in robotics <ref> [7, 10] </ref> and distributed AI [8]very little research addresses the MAP problem. 2 Some authors (see, e.g., [15]) have considered the representation of concurrent actions and a number of contemporary planners can handle concurrent noninteracting actions to a certain degree.
Reference: [11] <author> C. A. Knoblock. </author> <title> Generating parallel execution plans with a partial-order planner. </title> <booktitle> In Proc. Third Intl. Conf. on AI Planning Systems (AIPS '94), </booktitle> <year> 1994. </year>
Reference-contexts: However, the prevailing wisdom seems to suggest that temporal planners are required to adequately deal with general MAP problems (see, e.g., Knoblock's discussion of this in <ref> [11] </ref>). Certainly time plays a role in planningin any planner, the idea that sequences of actions occur embodies an implicit notion of time. However, we disagree that time in multiagent planning must be dealt with in a more explicit fashion than in single-agent planning. <p> The set of linearizations can be seen as the semantics of a nonlinear plan in some 7 Concurrent execution has also been considered in this context for non-interacting actions; see <ref> [11] </ref> for a discussion. To appear, Proc. 14th National Conf. on AI (AAAI-97),Providence, August, 1997 sense; a (consistent) nonlinear plan satisfies a goal set G, given starting state s, if any linearization is guaranteed to satisfy G. <p> To appear, Proc. 14th National Conf. on AI (AAAI-97),Providence, August, 1997 tions should or should not be scheduled concurrently with the current action in order to achieve a desired effect. There is a close connection between this type of specification and Knoblock's approach to generating parallel execution plans <ref> [11] </ref>. Knoblock adds a list to the action description that describes the resources used by the action: actions that require the same resource (e.g., access to a database) cannot be scheduled at the same time. Hence, Knoblock's resource list actually characterizes a form of non-concurrency constraints.
Reference: [12] <author> A. L. Lansky. </author> <title> Localized Event-Based Reasoning for Multia gent Domains. </title> <type> Tech. Report 423, </type> <institution> SRI International, </institution> <year> 1988. </year>
Reference-contexts: The main aim of this paper is to demonstrate that a form of the 1 Copyright c fl1997, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. 2 Lansky's work is one exception, but it does not build on conventional planning techniques <ref> [12] </ref>. MAP problem can be solved using very simple extensions to existing STRIPS representations and (single-agent) planners like UCPOP [14]. We provide a representation for interacting actions and a MAP algorithm that requires no explicit representation of time.
Reference: [13] <author> Y. Moses and M. Tennenholtz. </author> <title> Multi-entity models. </title> <journal> Machine Intelligence, </journal> <volume> 14 </volume> <pages> 63-88, </pages> <year> 1995. </year>
Reference-contexts: For these reasons, we desire a more distributed representation of actions, as in the multi-entity model of <ref> [13] </ref>.
Reference: [14] <author> J. S. Penberthy and D. S. Weld. Ucpop: </author> <title> A sound, complete, partial order planner for adl. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proc. Third Intl. Conf. </booktitle> <address> (KR-92), pp.103-114, Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: All rights reserved. 2 Lansky's work is one exception, but it does not build on conventional planning techniques [12]. MAP problem can be solved using very simple extensions to existing STRIPS representations and (single-agent) planners like UCPOP <ref> [14] </ref>. We provide a representation for interacting actions and a MAP algorithm that requires no explicit representation of time. The central issue in multiagent planning lies in the fact that individual agent actions do interact. <p> In fact, it might come as a surprise that solving both problems requires only a small number of changes to existing nonlinear planners, such as UCPOP <ref> [14] </ref>. 4 The main addition to the STRIPS representation for action a is a concurrent action list: this describes restrictions on the actions that can (or cannot) be executed concurrently in order for a to have the specified effect (indeed, a can have a number of different conditional effects depending on <p> By convention, each action schema will have as its first argument a free variable denoting the acting agent (this is typically not needed in single-agent domains). The STRIPS representation can be enhanced using a more expressive language. For instance, UCPOP <ref> [14] </ref> allows a form of universal quantification in the action description and conditional effects. We do not discuss quantification here, but we will consider conditional effects. We consider a simple extension of STRIPS for actions whose effects can be influenced by the concurrent execution of other actions. <p> a set of action instances, together with various strict ordering constraints (i.e., using the relations &lt; and &gt;) on the ordering of these actions, as well as codesignation and non-codesignation constraints on the values of variables appearing in these actions, forcing them to have the same or different values, respectively <ref> [17, 14] </ref>. A nonlinear plan of this sort represents its set of possible linearizations, the set of totally ordered plans formed from its action instances that do not violate any of the ordering, codesignation and non-codesignation constraints. 7 We say a nonlinear plan is consistent if it has some linearization.
Reference: [15] <author> R. Reiter. </author> <title> Natural actions, concurrency and continuous time in the situation c alculus. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proc. Fifth Intl. Conf. </booktitle> <address> (KR-96), </address> <year> 1996. </year>
Reference-contexts: Surprisingly, despite the recent interest in multiagent applicationsfor instance, in robotics [7, 10] and distributed AI [8]very little research addresses the MAP problem. 2 Some authors (see, e.g., <ref> [15] </ref>) have considered the representation of concurrent actions and a number of contemporary planners can handle concurrent noninteracting actions to a certain degree. However, the prevailing wisdom seems to suggest that temporal planners are required to adequately deal with general MAP problems (see, e.g., Knoblock's discussion of this in [11]).
Reference: [16] <author> R. Reiter. </author> <title> The frame problem in the situation calculus: A sim ple solution (sometimes) and a completeness result for goal regression. </title> <editor> In V. Lifschitz, editor, </editor> <booktitle> Artificial Intelligence and Mathematical Theory of Computation (Papers in Honor of John McCarthy), </booktitle> <pages> pages 359-380. </pages> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1991. </year>
Reference-contexts: Section 5 concludes the paper. A longer version of this paper [3] contains an examination of the use of dynamic Bayes nets for representing (possibly probabilistic) actions in multiagent as the situation calculus <ref> [16] </ref> and dynamic Bayes nets [6, 4]. 4 Moreover, other planning algorithms, (e.g., [1, 9]) should prove amenable to extension to multiagent planning using similar ideas. (define (operator pickup) :params (?a1 ?x) :pre (and (inroom ?a1 ?r1) (inroom block ?r1) (handempty ?a1) (onfloor ?x)) :conc (not (= ?a1 ?a2)):(not (pickup ?a2
Reference: [17] <author> D. S. Weld. </author> <title> An introduction to least commitment planning. </title> <journal> AI Magazine, </journal> <volume> Winter </volume> 1994 27-61, 1994. 
Reference-contexts: Clearly, the concurrency conditions (not (pickup ?a2 ?s)) and (pickup ?a2 ?s) can be used to distinguish 5 The general concepts and notation to follow, apart from specific multiagent extensions, draws heavily on Weld's excellent survey of partial order planning <ref> [17] </ref>. <p> a set of action instances, together with various strict ordering constraints (i.e., using the relations &lt; and &gt;) on the ordering of these actions, as well as codesignation and non-codesignation constraints on the values of variables appearing in these actions, forcing them to have the same or different values, respectively <ref> [17, 14] </ref>. A nonlinear plan of this sort represents its set of possible linearizations, the set of totally ordered plans formed from its action instances that do not violate any of the ordering, codesignation and non-codesignation constraints. 7 We say a nonlinear plan is consistent if it has some linearization. <p> We note that in order to execute such a plan in a coordinated fashion the agents will need some synchronization mechanism. This issue is not dealt with in this paper. 4 Planning with Concurrent Actions The POMP algorithm, a version of Weld's POP algorithm <ref> [17] </ref> modified to handle concurrent actions, is shown in Figure 3. 8 To keep the discussion brief, we first describe POMP without considering conditional effects. <p> The agenda initially contains all pairs hQ; A 1 i such that Q is a goal state conjunct. This specification of the initial agenda is identical to that used in POP <ref> [17] </ref>. Finally, we note that the choose operator, which appears in the Action Selection and Concurrent Action Selection steps, denotes nondeterministic choice. Again, this device is just that used in POP to make algorithm specification independent of the search strategy actually used for planning. <p> Demotion and promotion can be used to handle NC-threats much like they handle more conventional threats. Notice that although the set NC contains negative (inequality) constraints, they will ultimately be grounded in the set of positive constraints in O. Following the approach of <ref> [17] </ref>, we do not consider an action to be a threat if some of its variables can be consistently instantiated in a manner that would remove the threat. We can prove the following: Theorem POMP is sound and complete. <p> Our solution involves the addition of a concurrent action list to the standard action description, specifying which ac 12 Confrontation is a threat removal strategy used in the context of conditional actions (see <ref> [17] </ref>). 13 In anticipation of a subsequent step, we use variable a2 in the plan diagram instead of a4, since they will soon be unified.
References-found: 17

