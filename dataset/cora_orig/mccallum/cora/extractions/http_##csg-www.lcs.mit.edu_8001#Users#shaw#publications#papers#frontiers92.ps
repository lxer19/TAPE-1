URL: http://csg-www.lcs.mit.edu:8001/Users/shaw/publications/papers/frontiers92.ps
Refering-URL: http://csg-www.lcs.mit.edu:8001/Users/shaw/publications/
Root-URL: 
Title: Performance of Data-Parallel Primitives on the EM-4 Dataflow Parallel Supercomputer distinguishing feature in running data-parallel
Author: Andrew Shaw Yuetsu Kodama Mitsuhisa Sato Shuichi Sakai Yoshinori Yamaguchi 
Note: EM-4's  
Affiliation: MIT, Electrotechnical Laboratory  
Abstract: We have implemented seven data-parallel primitives on the hybrid dataflow/von Neumann parallel computer EM-4. To evaluate the performance of these primitives, we compare them to identical primitives running on a CM-200 SIMD parallel computer. For integer arithmetic element-wise operations, EM-4 is faster than the CM-200 when two or more operations can be combined. For communications operations, EM-4 has significantly higher performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Guy E. Blelloch, Charles E. Leiserson, Bruce M. Maggs, Greg C. Plaxton, Stephen J. Smith, and Marco Zagha. </author> <title> A Comparison of Sorting Algorithms for the Connection Machine CM-2. </title> <booktitle> In Proceedings of the Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1991. </year>
Reference-contexts: In order to give a sense of how efficiently the radix sort was written for the CM-200, we compare the speed with the vendor-provided system sort. This system sort is significantly faster than the system sort described in <ref> [1] </ref>, due to a rewrite of the router microcode which improved the router speed by a factor of two, as well as the higher clock speed of the CM-200 compared to the CM-2. 6 Related work Chatterjee [2] describes the loop fusion optimization applied to data-parallel codes, and the extensi bility
Reference: [2] <author> Siddhartha Chatterjee. </author> <title> Compiling Data-Parallel Programs for Efficient Execution on Shared-Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: The startup cost of the element-wise performance of the EM-4 includes the overhead to allocate a vector with as the destination of the operator, and the cost to deallocate the vector. An important compiler optimization for a MIMD machine like the EM-4 is loop fusion. <ref> [2] </ref> gives an algorithm for performing loop fusion automatically on data-parallel programs. Loop fusion can eliminate the need for intermediate result arrays as well as amortize loop overhead by combining the bodies of two loops into one loop. <p> Radix Sort Array Size 2048 8192 32768 CM-200 166.0 58.6 35.2 System Sort CM-200 64.5 26.8 21.6 Performance is in microseconds/element/processor/key-size 5 Radix sort performance We have written a compiler for a small data-parallel language that is similar to Vcode <ref> [2] </ref>. The compiler generates C code with library calls to the communications subprimitives the compiler is relatively new, so we expect improvements as optimizations are added. To evaluate an application using the data-parallel primitives, we wrote a small radix sort program for the EM-4 and the CM-200. <p> This system sort is significantly faster than the system sort described in [1], due to a rewrite of the router microcode which improved the router speed by a factor of two, as well as the higher clock speed of the CM-200 compared to the CM-2. 6 Related work Chatterjee <ref> [2] </ref> describes the loop fusion optimization applied to data-parallel codes, and the extensi bility of the optimization to scan, reduce, and address generation for permutation operations, as well as for element-wise operations. Most of the performance data in [2] is from a small-scale shared memory Encore Multimax, and performance of communications <p> speed of the CM-200 compared to the CM-2. 6 Related work Chatterjee <ref> [2] </ref> describes the loop fusion optimization applied to data-parallel codes, and the extensi bility of the optimization to scan, reduce, and address generation for permutation operations, as well as for element-wise operations. Most of the performance data in [2] is from a small-scale shared memory Encore Multimax, and performance of communications operations are very good because of the single bus shared memory, but the architecture is not scalable.
Reference: [3] <author> William J. Dally. </author> <title> A Universal Parallel Computer Architecture. </title> <booktitle> In Proceedings of the International Conference on Fifth Generation Computer Systems, </booktitle> <pages> pages 746-758, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: However, conventional processors are not designed for communications. A high bandwidth, low latency network cannot mask the communications deficiencies of a sequential processor if the processor requires hundreds or thousands of cycles to access the network, due to a poor processor/network interface <ref> [3] </ref> [9]. One of the primary advantages of dataflow computers is the integration of the processor into the network. fl address: MIT Laboratory for Computer Science, 545 Technology Square, Cambridge, MA 02139, USA email: shaw@lcs.mit.edu Dataflow processors are designed to directly send and dispatch messages to and from the network.
Reference: [4] <author> Philip J. Hatcher and Michael J. Quinn. </author> <title> Data-Parallel Programming on MIMD Computers. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Most of the performance data in [2] is from a small-scale shared memory Encore Multimax, and performance of communications operations are very good because of the single bus shared memory, but the architecture is not scalable. Hatcher and Quinn <ref> [4] </ref> have implemented a data-parallel compiler for both scalable distributed memory machines such as the iPSC and the nCube, as well as for shared memory machines such as the Sequent Symmetry.
Reference: [5] <author> W. Daniel Hillis and Guy L. Steele Jr. </author> <title> Data Parallel Algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 29(12), </volume> <month> December </month> <year> 1986. </year>
Reference-contexts: To evaluate an application using the data-parallel primitives, we wrote a small radix sort program for the EM-4 and the CM-200. For the CM-200, we used *Lisp. The parallel radix sort algorithm is taken from <ref> [5] </ref>: the *Lisp and V versions of each program are virtually identical, except that in the *Lisp version, side-effecting optimizations are used when appropriate. The identical algorithm was used for both the EM-4 and the CM-200, except where side-effecting optimizations were used for the CM-200.
Reference: [6] <author> Hiroaki Ishihata, Takeshi Horie, Satoshi Inano, Toshiyuki Shimizu, Sadayuki Kato, and Morio Ikesaka. </author> <title> Third Generation Message Passing Computer AP1000. </title> <booktitle> In Proceedings of the International Symposium on Supercomputing, </booktitle> <address> Fukuoka, Japan, </address> <pages> pages 46-55. </pages> <publisher> Kyushu University Press, </publisher> <month> November </month> <year> 1991. </year>
Reference-contexts: Machines like the CM-5 or the AP1000 cannot afford to implement these sub-primitives using their general routing networks, because their network interfaces require 3.1 microseconds [9] and 6.9 microseconds <ref> [6] </ref> respectively, per message. In addition, because the AP1000 uses a mesh network, network latency increases as the square root of the number of processors instead of logarithmically.
Reference: [7] <author> S. Sakai, Y Yamaguchi, K. Hiraki, Y. Kodama, and T. Yuba. </author> <title> An Architectural of a Dataflow Single Chip Processor. </title> <booktitle> In Proceedings of the 16th International Conference on Computer Architecture, </booktitle> <pages> pages 46-53, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: To evaluate the advantanges and disadvantages of running data-parallel codes on a dataflow computer, we have implemented a small data-parallel system on EM-4, an 80 processor prototype of a hybrid dataflow/von Neumann parallel supercomputer which will eventually contain 16,384 processors <ref> [7] </ref>. EM-4 overcomes one of the biggest problems of dataflow processors poor sequential performance by combining the sequential ability of a von Neumann RISC processor with the network interface ability of a dataflow processor. <p> low latency, high bandwidth network, global barrier and other scan-like operations can be performed using the general message routing network: special barrier and scan hardware is not necessary. 2 EM-4 EM-4 is a parallel hybrid dataflow/von Neumann computer; an 80 processor prototype of EM-4 has been functional since April 1990 <ref> [7] </ref>.
Reference: [8] <author> Mitsuhisa Sato, Yuetsu Kodama, Shuichi Sakai, Yoshi-nori Yamaguchi, and Yasuhito Koumura. </author> <title> Thread-based Programming for the EM-4 Hybrid Dataflow Machine. </title> <booktitle> In Proceedings of the 19th International Conference on Computer Architecture, </booktitle> <pages> pages 362-365, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Peak network message output performance is 60.9 Mbytes/s/pe, or one 39 bit word every cycle. EM-4 has a peak performance of 1 GIPS and peak message output rate of 4.9 Gbytes/s. 2.1 Programming EM-4 EM-4 can be programmed with the EM-4 assembler or the EM-4 C compiler <ref> [8] </ref>. There is no support for automatic parallelization: parallelism must be made explicit through forking processes on other processors.
Reference: [9] <author> Thorsten von Eicken, David E. Culler, Seth Copen Goldstein, and Klaus Erik Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proceedings of the 19th International Conference on Computer Architecture, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: However, conventional processors are not designed for communications. A high bandwidth, low latency network cannot mask the communications deficiencies of a sequential processor if the processor requires hundreds or thousands of cycles to access the network, due to a poor processor/network interface [3] <ref> [9] </ref>. One of the primary advantages of dataflow computers is the integration of the processor into the network. fl address: MIT Laboratory for Computer Science, 545 Technology Square, Cambridge, MA 02139, USA email: shaw@lcs.mit.edu Dataflow processors are designed to directly send and dispatch messages to and from the network. <p> Machines like the CM-5 or the AP1000 cannot afford to implement these sub-primitives using their general routing networks, because their network interfaces require 3.1 microseconds <ref> [9] </ref> and 6.9 microseconds [6] respectively, per message. In addition, because the AP1000 uses a mesh network, network latency increases as the square root of the number of processors instead of logarithmically.
References-found: 9

