URL: http://polaris.cs.uiuc.edu/reports/1193.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Experience in the Automatic Parallelization of Four Perfect-Benchmark Programs  
Author: Rudolf Eigenmann, Jay Hoeflinger, Zhiyuan Li, and David Padua 
Address: Urbana, Illinois  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Abstract: This paper discusses the techniques used to hand-parallelize, for the Alliant FX/80, four Fortran programs from the Perfect-Benchmark suite. The paper also includes the execution times of the programs before and after the transformations. The four programs considered here were not effectively parallelized by the automatic translators available to the authors. However, most of the techniques used for hand parallelization, and perhaps all of them, have wide applicability and can be incorporated into existing translators. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred Aho and Jeffrey Ullman. </author> <title> The Theory of Parsing, Translation, </title> <journal> and Compiling, </journal> <volume> Vol. 2. </volume> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1973. </year>
Reference-contexts: Many of the loops we parallelized contain subroutine calls. As a result, definitions and uses of the candidate arrays had to be searched across procedure bounds. 2.3. Generalized Induction Variables The sequence of values that an induction variable receives throughout the execution of a loop form an arithmetic progression <ref> [1] </ref>. Most often, a new value is assigned to an induction variable, say V, in statements of the form V = V + K where K is a value that remains constant throughout the execution of the loop.
Reference: [2] <author> Utpal Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer. </publisher> <address> Boston, MA. </address> <year> 1988. </year>
Reference: [3] <author> George Cybenko, Lyle Kipp, Lynn Pointer and David Kuck. </author> <title> Supercomputer Performance Evaluation and the Perfect Benchmarks TM . Proceedings of ICS, </title> <address> Amsterdam, Netherlands, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: 1. Introduction It is by now widely accepted that in many real-life applications, supercomputers have been unable to deliver a reasonable fraction of their peak performance. An illustration of this is provided by the Perfect Benchmark programs <ref> [3] </ref>, many of which effectively use less than 1% of the computational resources available in the most powerful supercomputers.
Reference: [4] <author> Rudolf Eigenmann, Jay Hoeflinger, Greg Jaxon, Zhiyuan Li and David Padua. </author> <title> Restructuring Fortran Programs for Cedar. </title> <booktitle> Proc. of the Int. Conf. on Parallel Processing, </booktitle> <pages> pp. I 57-66, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: In this paper we present some evidence to back this claim. During the last couple of years, our group at CSRD has developed a modified version of the KAP parallelizer with optimizations for the Cedar machine <ref> [4] </ref>. We ran several simple kernels through our parallelizer and the results were satisfactory. However, when we hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh This work was supported by the U.S. Department of Energy under grant no.
Reference: [5] <author> Mark D. Guzzi, David A. Padua, Jay P. Hoeflinger and Duncan H. Lawrie. </author> <title> Cedar Fortran and Other Vector and Parallel Fortran Dialects. </title> <booktitle> Jour. of Supercomputing, </booktitle> <volume> Vol. 4, No. 1, </volume> <pages> pp. 37-62, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Unfortunately, today we lack techniques to decide which potential dependences to test at runtime. 2.2. Array Privatization Many of the recently-developed parallel Fortran extensions such as Cedar Fortran <ref> [5] </ref>, the IBM parallel Fortran, and the Parallel Computing Forum (PCF) Fortran include parallel loop constructs with private declarations. A copy of each private item is allocated for each processor cooperating in the execution of the loop.
Reference: [6] <author> David Kuck, Edward Davidson, Duncan Lawrie and Ahmed Sameh. </author> <title> Parallel Supercomputing Today and the Cedar Approach. In: Experimental Parallel Computing Architectures, </title> <editor> J. J. Dongarra, ed. </editor> <publisher> Elsevier Science Publishers B.V. (North-Holland), </publisher> <address> New York, NY, </address> <pages> pp. 1-20, </pages> <year> 1987. </year>
Reference-contexts: We concentrated our work on loop parallelism because most of the existing compiler methodology is aimed at loop parallelization. Because hand parallelization is cumbersome, we decided in this first experiment not to use Cedar <ref> [6] </ref> as our target machine but rather to use the Alliant FX/80 which is the main building block of Cedar and therefore has a simpler organization than the complete system. The Alliant FX/80 is an eight-processor shared-memory multiprocessor which includes pipelined units to process vector instructions.
Reference: [7] <author> Zhiyuan Li. </author> <title> Compiler Algorithms for Event Variable Synchronization. </title> <booktitle> Proceedings of ICS 91, </booktitle> <pages> pp. 85-95, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: This transformation was applied to a loop of the program TRACK and it accelerated the program by a factor of 1.8. A related transformation strategy is described in <ref> [7] </ref>. 2.5. Unordered Critical Sections and Parallel Reductions The techniques described in this section allow the transformation of do loops into parallel form by exploiting the fact that we can reorder the execution of certain operations even thougth they are involved in data dependences.
Reference: [8] <author> David Padua and Michael Wolfe. </author> <title> Advanced Compiler Optimizations for Supercomputers. </title> <journal> Communications of the ACM, </journal> <volume> Vol. 29, No. 12, </volume> <pages> pp. 1184-1201. </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Compiler Techniques In the discussion below, we assume that the reader is familiar with basic parallelizing compiler concepts including the notion of dependence, dependence analysis techniques and some basic transformations. Introductory material on parallelizing compilers can be found in <ref> [8] </ref>, [9], and [11]. Also, all the parallel programs presented in the examples below use extensions similar to those described in the preliminary draft of the X3H5 ANSI committee developing parallel constructs for high level programming languages. 2.1.
Reference: [9] <author> Michael Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press. </publisher> <address> Boston, MA. </address> <year> 1989. </year>
Reference-contexts: Compiler Techniques In the discussion below, we assume that the reader is familiar with basic parallelizing compiler concepts including the notion of dependence, dependence analysis techniques and some basic transformations. Introductory material on parallelizing compilers can be found in [8], <ref> [9] </ref>, and [11]. Also, all the parallel programs presented in the examples below use extensions similar to those described in the preliminary draft of the X3H5 ANSI committee developing parallel constructs for high level programming languages. 2.1.
Reference: [10] <author> Chuan-Qi Zhu and Pen-Chung Yew. </author> <title> A Scheme to Enforce Data Dependence on Large Multiprocessor Systems. </title> <journal> IEEE Trans. on Software Eng., </journal> <volume> Vol. SE-13, No. 6, </volume> <pages> pp. 726-739, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: As can be inferred from the discussion that follows it is not difficult to extend this transformation if x appears in other statements but only on the left-hand side. The technique, however, will not work if x also appears on the right-hand side (see <ref> [10] </ref> for a discussion of this case). As in the previous case, a doacross transformation could be used. However, the resulting loop may not be efficient if funct cannot be analyzed at compile-time.

References-found: 10

