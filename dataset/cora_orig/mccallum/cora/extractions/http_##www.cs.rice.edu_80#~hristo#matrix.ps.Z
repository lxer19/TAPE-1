URL: http://www.cs.rice.edu:80/~hristo/matrix.ps.Z
Refering-URL: http://www.cs.rice.edu:80/~hristo/publications.html
Root-URL: 
Title: Methods for implementing linear algebra algorithms on high performance architectures  
Author: L. Aleksandrov M. Candev H. Djidjev 
Abstract: In this paper we consider the data distribution and data movement issues related to the solution of the basic linear algebra problems on high performance systems. The algorithms we discuss in details are the Gauss and Gausss-Jordan methods for solving a system of linear equations, the Cholesky's algorithm for LL T factorization, and QR-factorization algorithm using Householder transformations. It is shown that all those algorithm can be executed efficiently, with partial pivoting, on a parallel system with simple and regular links. A detailed implementation of the algorithms is described on a systolic-type architecture using a simple parallel language. Both the theoretical analysis and the simulation results show speedups on moderately large problems close to the optimal.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Aleksandrov and H. Djidjev, </author> <title> Factorization of Symmetric Positive Definite Matrices on a Systolic Processor, </title> <booktitle> Proc. of the IFIP WG 10.3, Working Conference on Parallel Processing, </booktitle> <address> Pisa, I April, </address> <year> 1988, </year> <title> in Parallel Processing, </title> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: Consequently, it has been shown that other basic linear algebra problems as L T L factorization, QR factorization, have efficient solutions on the processor <ref> [1, 4] </ref>. Since our architecture is simpler than most of the commercially available parallel computers, our algorithms can be easily transformed into efficient implementations on other parallel computers, achieving close to optimal speedup. <p> The implementations presented in the next section, including Gauss-elimination type algorithms, Cholesky and Householder factorizations are derived from this general scheme. Alternative schemes are also possible and competitive <ref> [1] </ref>. Let us describe the arrangement of the data during the implementation of M b . Assume that the basic memories are divided into equal parts capable to store one block-row ~ A i of A.
Reference: [2] <author> L. Aleksandrov and H. Djidjev, </author> <title> Algorithms for a Specialized Matrix Systolic Processor, </title> <booktitle> SIAM/SIAG Second Intern. Conf. on Vector and Par. Comp., </booktitle> <address> Tromso, Norway, </address> <year> 1988. </year>
Reference-contexts: Originally, the processor was designed to implement efficiently algorithms based on Gauss elimination with partial pivoting as LU -factorization, solving systems of linear equations, matrix inversions, etc., see <ref> [2, 3] </ref>. Consequently, it has been shown that other basic linear algebra problems as L T L factorization, QR factorization, have efficient solutions on the processor [1, 4].
Reference: [3] <author> L. Aleksandrov and H. Djidjev, </author> <title> Solving Systems of Linear Equations on a Systolic Processor, Tec. </title> <type> Rep. 1, </type> <institution> Center of Informatics and Computer Technology, BAS, Sofia, </institution> <year> 1988. </year>
Reference-contexts: Originally, the processor was designed to implement efficiently algorithms based on Gauss elimination with partial pivoting as LU -factorization, solving systems of linear equations, matrix inversions, etc., see <ref> [2, 3] </ref>. Consequently, it has been shown that other basic linear algebra problems as L T L factorization, QR factorization, have efficient solutions on the processor [1, 4].
Reference: [4] <author> L. Aleksandrov and M. Candev, </author> <title> Householder QR-Decomposition on a Specialized Systolic Processor, Advances in Parallel Algorithms, </title> <editor> I. Dimov and O. Tonev (Eds.), </editor> <publisher> IOS Press, </publisher> <address> Amsterdam, </address> <year> 1994, </year> <pages> pp. 3-10. </pages>
Reference-contexts: Consequently, it has been shown that other basic linear algebra problems as L T L factorization, QR factorization, have efficient solutions on the processor <ref> [1, 4] </ref>. Since our architecture is simpler than most of the commercially available parallel computers, our algorithms can be easily transformed into efficient implementations on other parallel computers, achieving close to optimal speedup.
Reference: [5] <author> M. Annaratone et al., </author> <title> Warp Architecture and Implementation, </title> <booktitle> Proc. 13th Int'l Symposium on Computer Architecture, </booktitle> <publisher> Computer Society Press, </publisher> <address> Silver Spring, Md., </address> <year> 1986, </year> <pages> pp. 346-356. 24 </pages>
Reference: [6] <author> C. Bischof, </author> <title> A Block QR Factorization Algorithm Using Restricted Pivoting, </title> <booktitle> Proc. Supercomputing'89, Nevada, </booktitle> <pages> pp. 248-256. </pages>
Reference: [7] <author> C. Bischof, </author> <title> Incremental Condition Estimation, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 11 (1990), </volume> <pages> pp. 312-322. </pages>
Reference: [8] <author> C. Bischof and C. Van Loan, </author> <title> The WY Representation for Products of Householder Matrices, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 8 (1987), </volume> <pages> pp. </pages> <month> s2-s13. </month>
Reference-contexts: The fifth example concerns ortogonalization. We present an efficient implementation of the Householder QR-factorization algorithm for a rectangular full-rank matrix. Notably, the implementation was obtained by the aid of a modification of a recently discovered in <ref> [8, 21] </ref> block version of Householder factorization, that is consistent with our general scheme. We describe each of the algorithms and implementations in a separate subsection. Our presentation follows closely the framework and notations from the previous section. We begin with a short formulation of the considered linear algebra problem. <p> The key-stone of that implementation is so called WY-representation <ref> [8] </ref> for products of Householder matrices and its compact version, proposed in [21]. Let A 2 R MfiN , M N be a full-rank matrix. <p> According to our approach we need a block version of Algorithm 4.5.1 that will allow us to apply our major scheme, as described in Sectiom 3. For full-rank matrices such a block version has 21 been proposed in <ref> [8] </ref>. It is based on so called WY-representation of products of Householder matrices. Subsequently, in [21] a compact WY-representation which reduces the space requirements has been presented.
Reference: [9] <author> P. </author> <title> Bjorstad, </title> *****, <booktitle> Parallel Computing 5 (1987), </booktitle> <pages> 3. </pages>
Reference: [10] <institution> Computer 20 (1987), </institution> <note> no. 7, July 1987 (Special Issue on Systolic Arrays). </note>
Reference: [11] <author> J. Dongarra and R. Hiromoto, </author> *****, <booktitle> Parallel Computing 1 (1984), </booktitle> <pages> 133. </pages>
Reference: [12] <author> J. Dongara and S. Eisenstat, </author> <title> Squeezing the Most out of an Algorithm in Cray Fortran, </title> <journal> ACM Trans. Math. </journal> <volume> Software 10 (1984), </volume> <pages> pp. 216-230. </pages>
Reference: [13] <author> J.Dongara, L.Kaufman, and S.Hammarling, </author> <title> Squeezing the Most out of Eigenvalue Solvers on High Performance Computers, </title> <note> Thechnical Memorandum 46 (1985), </note> <institution> Mathematics and Comp. Sci. Div., Argone National Lab., Argonne, </institution> <address> IL 60439. </address>
Reference: [14] <editor> B. Drake et al., </editor> *****, <booktitle> Computer 20 (1987), </booktitle> <pages> 45. </pages>
Reference: [15] <author> J. Fortes and B. Wah, </author> <title> Systolic Arrays | from Concept to Implementation, </title> <booktitle> Computer 20 (1987), </booktitle> <pages> 12. </pages>
Reference: [16] <author> D. Fousler and R. Shreiber, </author> *****, <note> Computer 20 (1987), 35. </note>
Reference: [17] <author> G. Golub and C. Van Loan, </author> <title> Matrix Computations, </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, MD, </address> <year> 1989. </year>
Reference-contexts: Generally, for a given implementation we are going to evaluate the number of machine cycles need for its execution on the processor and to compare that number to the number of flops (floating point operations see <ref> [17] </ref>) in the original sequentional algorithm. Following the widely accepted terminology, we are going to speak for rinning times instead of speaking for number of cycles, operations or flops. <p> The problem of QR-factorization of A is to compute an orthogonal matrix Q 2 R MfiM and an upper triangular matrix R 2 R MfiN such that A = QR. We begin by presenting the well-known Householder QR-factorization algorithm <ref> [17] </ref>.
Reference: [18] <author> H. Kung and C. Leiserson, </author> <title> Systolic Arrays (for VLSI), Sparse Matrix Proceedings, </title> <publisher> SIAM, </publisher> <year> 1978, </year> <pages> pp. 256-282. </pages>
Reference-contexts: In order to provide detailed implementation and efficiency analysis, we use a concrete parallel architecture that is characterized with simple and regular links between the processors and systolic-like communications. Our study shows that an appropriate architecture may include a systolic array (SA) consisting of a 2-dimensional mesh of processors <ref> [18] </ref> as a basic computational unit. The other computational unit is a general-purpose processing element (arithmetic-logic unit | ALU). ALU is intended to implement specific operations as finding pivots and divisions in Gauss algorithm, square roots in Cholesky algorithm, computing of reflection vectors in Householder algorithm, 1 and etc.
Reference: [19] <author> W.-T. Lin and C.-Z. Chin, </author> <title> A Reconfigurable Processor Array Based on the Linc Chip, </title> <editor> in W. Moore, A. McCabe, R. Urquhart (eds.), </editor> <title> Systolic Arrays, Adam Hilger, </title> <address> Bristol, </address> <year> 1987. </year>
Reference: [20] <author> W. Moore, A. McCabe, and R. Urquhart (eds.), </author> <title> Systolic Arrays, Adam Hilger, </title> <address> Bristol, </address> <year> 1987. </year>
Reference: [21] <author> R. Schreiber and C. Van Loan, </author> <title> A Storage-Efficient WY Representation for Products of Householder transformations, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 10 (1989), </volume> <pages> pp. 53-57. </pages>
Reference-contexts: The fifth example concerns ortogonalization. We present an efficient implementation of the Householder QR-factorization algorithm for a rectangular full-rank matrix. Notably, the implementation was obtained by the aid of a modification of a recently discovered in <ref> [8, 21] </ref> block version of Householder factorization, that is consistent with our general scheme. We describe each of the algorithms and implementations in a separate subsection. Our presentation follows closely the framework and notations from the previous section. We begin with a short formulation of the considered linear algebra problem. <p> The key-stone of that implementation is so called WY-representation [8] for products of Householder matrices and its compact version, proposed in <ref> [21] </ref>. Let A 2 R MfiN , M N be a full-rank matrix. The problem of QR-factorization of A is to compute an orthogonal matrix Q 2 R MfiM and an upper triangular matrix R 2 R MfiN such that A = QR. <p> For full-rank matrices such a block version has 21 been proposed in [8]. It is based on so called WY-representation of products of Householder matrices. Subsequently, in <ref> [21] </ref> a compact WY-representation which reduces the space requirements has been presented.

References-found: 21

