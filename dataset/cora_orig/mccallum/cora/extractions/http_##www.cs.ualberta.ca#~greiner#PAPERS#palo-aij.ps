URL: http://www.cs.ualberta.ca/~greiner/PAPERS/palo-aij.ps
Refering-URL: http://www.cs.ualberta.ca/~greiner/PAPERS/
Root-URL: 
Email: greiner@scr.siemens.com  
Title: PALO: A Probabilistic Hill-Climbing Algorithm  
Author: Russell Greiner 
Date: 84:1-2 (July 1996), p. 177-204.  
Note: (609) 734-3627 Appears in Artificial Intelligence,  
Address: Princeton, NJ 08540  
Affiliation: Siemens Corporate Research,  
Abstract: Many learning systems search through a space of possible performance elements, seeking an element whose expected utility, over the distribution of problems, is high. As the task of finding the globally optimal element is often intractable, many practical learning systems instead hill-climb to a local optimum. Unfortunately, even this is problematic as the learner typically does not know the underlying distribution of problems, which it needs to determine an element's expected utility. This paper addresses the task of approximating this hill-climbing search when the utility function can only be estimated by sampling. We present a general algorithm, palo, that returns an element that is, with provably high probability, essentially a local optimum. We then demonstrate the generality of this algorithm by presenting three distinct applications, that respectively find an element whose efficiency, accuracy or completeness is nearly optimal. These results suggest approaches to solving the utility problem from explanation-based learning, the multiple extension problem from nonmonotonic reason ing and the tractability/completeness tradeoff problem from knowledge representation.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. </author> <title> Proof verification and hardness of approximation problems. </title> <booktitle> In FOCS, </booktitle> <year> 1992. </year>
Reference-contexts: Our performance elements, however, will have to solve an entire ensemble of problems. To specify which element is best overall, we must therefore consider the distribution of problems that our performance elements will encounter. We model this using a stationary probability function, P r : Q 7! <ref> [0; 1] </ref>, where P r [ q i ] denotes the probability that the problem q i is selected. We then define the expected utility of a performance element in the obvious 3 We assume that Q is countable for purely pedagogical reasons. <p> Our goal is to identify the priority ordering that is accurate most often. As before, this depends on the distribution of queries, which unfortunately is not known a priori; and moreover, the task of identifying this optimal ordering of the hypotheses is NP-complete (and worse, not even approximatable <ref> [1] </ref>), even if we knew the distribution, even in the simplistic situation that we have been considering, where every derivation involves exactly one hypothesis, etc. [32]. Once again, palo 1 is designed to deal with this situation.
Reference: [2] <author> P. Auer, R. Holte, and W. Maass. </author> <title> Theory and applications of agnoistic PAC-learning with small decision trees. </title> <booktitle> In Proceedings of the Twelfth International Machine Learning Conference, </booktitle> <year> 1995. </year>
Reference-contexts: The conditions above specify situations where palo will not work effectively. There are also situations where palo should not be used. For example, there is no need to use the weak hill-climbing method if there is a known efficient techniques for computing the global optimum; cf., <ref> [78, 2] </ref>.
Reference: [3] <author> D. A. Berry and B. Fristedt. </author> <title> Bandit Problems: Sequential Allocation of Experiments. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: Moreover, this also means that palo will usually require a smaller total number of samples; see Note N-Palo5 in Section 4. Incremental Algorithms: Many other methods attempt to make effective use of the training samples; cf., reinforcement learning algorithms [50, 76] and systems that address the "bandit problem" <ref> [3, 64] </ref>. Each of these systems also makes a sequence of decisions, attempting to maximize its total reward. Such systems tend to run continuously, making successive decisions; and they are often evaluated in terms of the number of mistakes they make over their entire learning+performance lifetimes.
Reference: [4] <author> M. Boddy and T. Dean. </author> <title> Solving time dependent planning problems. </title> <type> Technical report, </type> <institution> Brown University, </institution> <year> 1988. </year>
Reference-contexts: As such, it also resembles anytime algorithms <ref> [4, 16] </ref>, but differs from standard anytime algorithms by terminating on reaching a 2 A less major difference is that the composer system, like the Hoeffding Race and fl-ie systems mentioned above, qualifies as a "wrapper" learner [48, 10], as composer views each performance element as a black box, whose behavior
Reference: [5] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: The palo 1 algorithm uses these equations and the values of ( fi j ; fi 0 ; i ) to determine both how confident we should be that C ( fi 0 ) &gt; C ( fi j ) (Lines hL3i and hL5i) and whether 5 See <ref> [5, p. 12] </ref>. N.b., these inequalities do not require that the underlying distributions be normal; instead, they hold for any arbitrary bounded distribution.
Reference: [6] <author> L. Booker, D. Goldberg, and J. Holland. </author> <title> Classifier systems and genetic algorithms. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):235-282, </volume> <month> Sept. </month> <year> 1989. </year>
Reference-contexts: A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop [44], genetic algorithms <ref> [6] </ref> and c4.5 [68], use this approach, as do many speedup learning methods; see especially [28]. <p> As mentioned above, many learning systems attempt to address this challenge, of finding an element whose expected behavior is optimal; see for example the learning procedures used by symbolic classifiers [68], neural nets [44] and genetic algorithms <ref> [6] </ref>. Each of these systems uses a set of training samples to estimate the distribution, then uses this information to determine when one element is superior to another. Most systems do this implicitly, and heuristically.
Reference: [7] <author> A. Borgida and D. Etherington. </author> <title> Hierarchical knowledge bases and efficient disjunctive reasoning. </title> <booktitle> In Proceedings of KR-89, </booktitle> <pages> pages 33-43, </pages> <address> Toronto, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: N-Cat3. This compilation work is obviously related to the work on "vividization" and "approximation" <ref> [56, 7, 20, 15, 47] </ref>, which also try to transform a given intractable theory into a representation that admits more efficient, if less categorical, reasoning.
Reference: [8] <author> E. Boros, Y. Crama, and P. Hammer. </author> <title> Polynomial-time inference of all valid implications for horn and related formulae. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 1 </volume> <pages> 21-32, </pages> <year> 1990. </year>
Reference-contexts: We can, however, guarantee that each of palo 1 's iterations will be polytime if the F [ fh i g j= ? q k computation is polytime (e.g., if we are dealing with propositional Horn theories or propositional 2-CNF, etc. <ref> [8] </ref>). N-Acc5. Recall that, in general, we need to compute the values of c (t ij ( ` ); q) c ( ` ; q) for each t ij in T A .
Reference: [9] <author> G. Brewka. </author> <title> Preferred subtheories: An extended logical framework for default reasoning. </title> <booktitle> In Proceedings of IJCAI-89, </booktitle> <pages> pages 1043-48, </pages> <address> Detroit, </address> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: We focus on stratified Theorist-style performance elements [66] <ref> [67, 9, 79] </ref>, where each PALO: A Probabilistic Hill-Climbing Algorithm 16 element fi = hF ; H; i is a triple, composed of a (consistent) set of facts F , a set of allowed hypotheses H (each a simple type of default [69]) and a specific priority ordering of the hypotheses.
Reference: [10] <author> R. Caruana and D. Freitag. </author> <title> Greedy attribute selection. </title> <booktitle> In Proceedings of the Eleventh International Machine Learning Conference, </booktitle> <pages> pages 28-36, </pages> <address> N.J., 1994. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: As such, it also resembles anytime algorithms [4, 16], but differs from standard anytime algorithms by terminating on reaching a 2 A less major difference is that the composer system, like the Hoeffding Race and fl-ie systems mentioned above, qualifies as a "wrapper" learner <ref> [48, 10] </ref>, as composer views each performance element as a black box, whose behavior can be sampled, but whose internals are unavailable.
Reference: [11] <author> H. Chernoff. </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sums of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 </volume> <pages> 493-507, </pages> <year> 1952. </year> <title> PALO: A Probabilistic Hill-Climbing Algorithm 29 </title>
Reference-contexts: Hoeffding's inequality <ref> [45, 11] </ref> bounds the probable rate of convergence: the probability that "Y n is more than + fl" goes to 0 exponentially fast as n increases; and, for a fixed n, exponentially as fl increases.
Reference: [12] <author> W. F. Clocksin and C. S. Mellish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: write a palo-like that used an annealing process to climb downhill occasionally; however, this system would not satisfy the useful specifications presented in Theorem 1. 3 Framework To illustrate the relevant concepts, consider the following example: A pure Prolog program will return a set of answers to each query posed <ref> [12] </ref>. We can form new programs by rearranging the order of the clauses. While these programs will return the same set of answers, they can require differing amounts of time to find the first answer to each query. <p> N-Eff2. This class of performance elements corresponds to many standard problem solvers, including Prolog <ref> [12] </ref>; see also [24]. We can also use these inference graphs to describe operators working in state spaces; here each internal arc of the inference graph corresponds to an operator invocation and each leaf arc to a general "probabilistic experiment".
Reference: [13] <author> W. W. Cohen. </author> <title> Learning from textbook knowledge: A case study. </title> <booktitle> In Proceeding of AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: N-Acc6. This paper considers only one type of transformation to convert one theory into another | viz., by rearranging the set of hypotheses. There are many other approaches, e.g., by eliminating some inappropriate sets of hypotheses <ref> [13, 82] </ref>, or by modifying the antecedents of individual rules [65], etc. Each of these approaches can be viewed as using a set of transformations to navigate around a space of interrelated theories.
Reference: [14] <author> S. A. Cook. </author> <title> The complexity of theorem-proving procedures. </title> <booktitle> In STOC71, </booktitle> <pages> pages 151-58, </pages> <year> 1971. </year>
Reference-contexts: time returning the correct answer; or even allow it to be wrong in some instances [34]. 5.3 Improving Categoricity The task of determining whether a query is entailed by a theory is known to be intractable if the theory is a general propositional theory (assuming P 6= N P ) <ref> [14, 23] </ref>.
Reference: [15] <author> M. Dalal and D. Etherington. </author> <title> Tractable approximate deduction using limited vocabulary. </title> <booktitle> In Proceedings of CSCSI-92, </booktitle> <address> Vancouver, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: N-Cat3. This compilation work is obviously related to the work on "vividization" and "approximation" <ref> [56, 7, 20, 15, 47] </ref>, which also try to transform a given intractable theory into a representation that admits more efficient, if less categorical, reasoning.
Reference: [16] <author> T. Dean and M. Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <pages> pages 49-54, </pages> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: As such, it also resembles anytime algorithms <ref> [4, 16] </ref>, but differs from standard anytime algorithms by terminating on reaching a 2 A less major difference is that the composer system, like the Hoeffding Race and fl-ie systems mentioned above, qualifies as a "wrapper" learner [48, 10], as composer views each performance element as a black box, whose behavior
Reference: [17] <author> G. DeJong. </author> <booktitle> AAAI workshop on Explanation-Based Learning. Sponsored by AAAI, </booktitle> <year> 1988. </year>
Reference-contexts: 1 Introduction Many learning tasks can be viewed as a search through a space of possible performance elements seeking an element that is optimal, based on some utility measure. As examples, inductive systems seek classifiers whose classifications are optimally accurate, and many explanation-based learning <ref> [17, 60] </ref> and chunking [55] systems seek problem solvers that are optimally efficient [59, 30].
Reference: [18] <author> W. F. Dowling and J. H. Gallier. </author> <title> Linear time algorithms for testing the satisfiability of propositional horn formula. </title> <journal> Journal of Logic Programming, </journal> <volume> 3 </volume> <pages> 267-84, </pages> <year> 1984. </year>
Reference-contexts: It can, however, be performed efficiently if the theory contains only Horn clauses <ref> [18] </ref>. 13 Selman and Kautz [72] use this observation to define a particular "knowledge compilation" method: Given a general propositional theory , their compiler computes a pair of "bracketing" Horn theories S and W , with the property S j= j= W ; we call each such S a "Strengthening" of <p> Moreover, these tests are linear in the sizes of and S (respectively, and W ), provided : is Horn <ref> [18] </ref>. 14 ) Otherwise, if W 6j= and S j= , fi returns IDK. Notice this compiled system is usually tractable, 15 yet can deal with an arbitrary propositional theory.
Reference: [19] <author> J. Doyle and R. Patil. </author> <title> Two theses of knowledge representation: Language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3), </volume> <year> 1991. </year>
Reference-contexts: Second, in the interest of producing an empirically effective system, composer also makes other simplifying assumptions; for example, it does not make palo's conservative (but mathematically necessary) assumption that the errors on successive hill-climbs will add. 2 "Rationality": Doyle and Patil <ref> [19] </ref> recently argued against the standard practice of using worst case analyses to decide amongst different possible performance elements, and instead advocated using an expected case analysis.
Reference: [20] <author> D. W. Etherington, A. Borgida, R. J. Brachman, and H. Kautz. </author> <title> Vivid knowledge and tractable reasoning: Preliminary report. </title> <booktitle> In Proceedings of IJCAI-89, </booktitle> <pages> pages 1146-52, </pages> <year> 1989. </year>
Reference-contexts: N-Cat3. This compilation work is obviously related to the work on "vividization" and "approximation" <ref> [56, 7, 20, 15, 47] </ref>, which also try to transform a given intractable theory into a representation that admits more efficient, if less categorical, reasoning.
Reference: [21] <author> O. Etzioni. </author> <title> Tractable decision-analytic control. </title> <booktitle> In Proceedings of KR-89, </booktitle> <address> Toronto, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: Many other systems are similarly motivated by this issue of computational effectiveness | i.e., what is the best performance the system can exhibit, given only limited computational resources; cf., the works by Horovitz [46], Etzioni <ref> [21] </ref> and Russell, Subramanian and Parr [70]. These other systems, however, either assume that the utilities of the various elements are immediately available, or supply statistical methods for estimating these utilities for all of the elements (akin to the Hoeffding Race and fl-ie framework mentioned above).
Reference: [22] <author> P. Fong. </author> <title> A quantitative study of hypotheis selection. </title> <booktitle> In Proceedings of the Twelfth International Machine Learning Conference, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Their "Hoeffding Race" approach attempts to reduce the total number of element-sample evaluations by removing an element as soon as it is statistically clear that this element will not be the optimum. Fong <ref> [22] </ref> presents a different, more mathematically rigorous, solution to the problem of reducing the number of element-sample evaluations, by specifying which single element should deal with each sample. The resulting "fl-ie" framework extends Kaelbling's ie system [50].
Reference: [23] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: time returning the correct answer; or even allow it to be wrong in some instances [34]. 5.3 Improving Categoricity The task of determining whether a query is entailed by a theory is known to be intractable if the theory is a general propositional theory (assuming P 6= N P ) <ref> [14, 23] </ref>. <p> Proof: K-Weak is clearly in NP, as we need only guess a potential weakening, and confirm its coverage. To show K-Weak is NP-hard, we reduce the NP-complete sat task to it <ref> [23] </ref>: Given any boolean formula for sat, let be the set of its clauses, and let K = 2, f = 1 and the set of sample S = f q&:q g be a single unsatisfiable proposition.
Reference: [24] <author> M. R. Genesereth and N. J. Nilsson. </author> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1987. </year>
Reference-contexts: N-Eff2. This class of performance elements corresponds to many standard problem solvers, including Prolog [12]; see also <ref> [24] </ref>. We can also use these inference graphs to describe operators working in state spaces; here each internal arc of the inference graph corresponds to an operator invocation and each leaf arc to a general "probabilistic experiment".
Reference: [25] <author> A. Goldberg. </author> <title> An average case complexity analysis of the satisfiability problem. </title> <booktitle> In Proceedings of the 4th Workshop on Automated Deduction, </booktitle> <pages> pages 1-6, </pages> <address> Austin, TX, </address> <year> 1979. </year>
Reference-contexts: This "average case analysis" differs from several other approaches as, for example, we are not assuming that this distribution of problems will be uniform <ref> [25] </ref>, nor that it will necessarily correspond to any particular collection of "benchmark challenge problems" [52]. N-Palo2. A "0-local optimum" corresponds exactly to the standard notion of local optimum; hence our "*-local optimum" (condition 2 of Theorem 1) generalizes local optimality.
Reference: [26] <author> I. J. </author> <title> Good. Twenty-seven principles of rationality. </title> <editor> In V. P. Godambe and D. A. Sprott, editors, </editor> <title> Foundations of Statistical Inference. </title> <publisher> Holt, Rinehart and Winston, </publisher> <address> Toronto, </address> <year> 1971. </year>
Reference-contexts: We view our approach, as embodied in the palo system, as addressing exactly those questions. Moreover, our palo exhibits a type of "Type II rationality" <ref> [26] </ref>, as it seeks an element whose expected utility is optimal, subject to the resource constraint of spending only a feasible amount of time to find such an element.
Reference: [27] <author> J. Gratch, S. Chien, and G. DeJong. </author> <title> Improving learning performance through rational resource allocation. </title> <booktitle> In Proceedings of AAAI-94, </booktitle> <pages> pages 576-581, </pages> <address> Seattle, WA, </address> <year> 1994. </year> <title> PALO: A Probabilistic Hill-Climbing Algorithm 30 </title>
Reference-contexts: Most systems do this implicitly, and heuristically. By contrast, our palo system performs an explicit statistical test to determine, with prescribed confidence, when one element is superior to another. As such, it is very similar to the composer system of Gratch, deJong and Chien <ref> [28, 29, 27] </ref>. composer differs from palo in two significant ways. First, composer will use all available samples when hill-climbing.
Reference: [28] <author> J. Gratch and G. DeJong. </author> <title> A hybrid approach to guaranteed effective control strategies. </title> <booktitle> In Proceedings of IWML-91, </booktitle> <pages> pages 509-513, </pages> <address> Evanston, Illinois, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop [44], genetic algorithms [6] and c4.5 [68], use this approach, as do many speedup learning methods; see especially <ref> [28] </ref>. Unfortunately, few existing systems guarantee that each hill-climbing step is even an improvement, meaning the final element is not always even superior to the initial one, much less an optimum in the space of elements. <p> Most systems do this implicitly, and heuristically. By contrast, our palo system performs an explicit statistical test to determine, with prescribed confidence, when one element is superior to another. As such, it is very similar to the composer system of Gratch, deJong and Chien <ref> [28, 29, 27] </ref>. composer differs from palo in two significant ways. First, composer will use all available samples when hill-climbing.
Reference: [29] <author> J. Gratch and G. Dejong. COMPOSER: </author> <title> A probabilistic solution to the utility problem in speed-up learning. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <year> 1992. </year>
Reference-contexts: Most systems do this implicitly, and heuristically. By contrast, our palo system performs an explicit statistical test to determine, with prescribed confidence, when one element is superior to another. As such, it is very similar to the composer system of Gratch, deJong and Chien <ref> [28, 29, 27] </ref>. composer differs from palo in two significant ways. First, composer will use all available samples when hill-climbing.
Reference: [30] <author> R. Greiner. </author> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <journal> Artificial Intelligence, </journal> <volume> 50(1) </volume> <pages> 95-116, </pages> <year> 1991. </year>
Reference-contexts: As examples, inductive systems seek classifiers whose classifications are optimally accurate, and many explanation-based learning [17, 60] and chunking [55] systems seek problem solvers that are optimally efficient <ref> [59, 30] </ref>. <p> This leads to the second problem: unfortunately, the task of identifying the globally optimal element, even given the correct distribution information, is intractable for many spaces of elements <ref> [30, 42] </ref>. A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop [44], genetic algorithms [6] and c4.5 [68], use this approach, as do many speedup learning methods; see especially [28]. <p> Moreover, the task of finding the globally optimal strategy is NP-hard <ref> [30] </ref>.
Reference: [31] <author> R. Greiner. </author> <title> PALO algorithms. </title> <type> Technical report, </type> <institution> Siemens Corporate Research, </institution> <year> 1993. </year>
Reference-contexts: The technical note <ref> [31] </ref> presents various other palo i algorithms, which differ from palo 1 in small, but significant, ways. <p> In particular, any of these palo i systems can be used to address any of these applications.) We <ref> [31] </ref> empirically tested these different palo i systems in several different contexts, and found that the palo 1 system discussed here was usually the best, in terms of the utility of its final performance element, as a function of the empirical sample complexity.
Reference: [32] <author> R. Greiner. </author> <title> The challenge of revising impure theories. </title> <booktitle> In Proceedings of the Twelfth International Machine Learning Conference, </booktitle> <year> 1995. </year>
Reference-contexts: unfortunately is not known a priori; and moreover, the task of identifying this optimal ordering of the hypotheses is NP-complete (and worse, not even approximatable [1]), even if we knew the distribution, even in the simplistic situation that we have been considering, where every derivation involves exactly one hypothesis, etc. <ref> [32] </ref>. Once again, palo 1 is designed to deal with this situation.
Reference: [33] <author> R. Greiner. </author> <title> The complexity of theory revision. </title> <booktitle> In Proceedings of IJCAI-95, </booktitle> <year> 1995. </year>
Reference-contexts: In some simple cases, we may be able to identify (an approximation to) the globally optimal element with high probability; cf., the pao algorithm discussed in [38]. In almost all cases, however, this identification task is intractable, and not even approximatable <ref> [33] </ref>. Here again it makes sense to use a hill-climbing system like palo 1 to identify an element that is close to a local optimum, with high probability. (Of course, this local optimality will be based on the classes of transformations used to define the space of theories, etc.) N-Acc7.
Reference: [34] <author> R. Greiner and C. Elkan. </author> <title> Measuring and improving the effectiveness of representations. </title> <booktitle> In Proceedings of IJCAI-91, </booktitle> <pages> pages 518-24, </pages> <address> Sydney, Australia, </address> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: This would allow the user to prefer, for example, a performance system that returns IDK in complex situations, rather than spend a long time returning the correct answer; or even allow it to be wrong in some instances <ref> [34] </ref>. 5.3 Improving Categoricity The task of determining whether a query is entailed by a theory is known to be intractable if the theory is a general propositional theory (assuming P 6= N P ) [14, 23].
Reference: [35] <author> R. Greiner and R. Isukapalli. </author> <title> Learning to select useful landmarks. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <note> accepted subject to modifications. </note>
Reference-contexts: More recently, however, we found that palo 1N worked effectively in one particular context; see <ref> [35] </ref>. 6.2 Limitations The examples discussed in Section 5 illustrate the versatility and generality of the palo objective, of identifying a performance element whose expected utility, over an arbitrary (but stationary) distribution of problems, is optimal.
Reference: [36] <author> R. Greiner and I. Jurisica. </author> <title> A statistical approach to solving the EBL utility problem. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <address> San Jose, </address> <year> 1992. </year>
Reference-contexts: By contrast, palo will sometimes examine the internals of the performance elements, and use this structural information to efficiently determine the scores of the neighboring elements; see Section 5.1 and <ref> [36] </ref>. <p> Using G A , for example, a 3 encodes the "take some blood" operator, and a 5 encodes the experiment that succeeds if the patient tests positive on bt#1, and so forth. N-Eff3. In <ref> [36] </ref>, we discuss how this instantiation of the palo 1 algorithm fits into the framework of "explanation-based learning" systems, and show in particular, how our framework provides a mathematical basis for [59]'s "utility analysis".
Reference: [37] <author> R. Greiner and P. Orponen. </author> <title> Probably approximately optimal derivation strategies. </title> <editor> In J. Allen, R. Fikes, and E. Sandewall, editors, </editor> <booktitle> Proceedings of KR-91, </booktitle> <address> Rochester, NJ, </address> <month> Apr. </month> <title> 1991. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We must also define S to be a set of subsets of N , where the query processor would have to reach each member of some s 2 S for the derivation to succeed. This extension leads to additional complications in specifying strategies; see also <ref> [37, Appendix A] </ref>. It is also trivial to extend these definitions to accommodate more complicated f () cost functions, which can allow the cost of traversing an arc to depend on other factors | e.g., the success or failure of that traversal, which other arcs have already been traversed, etc.
Reference: [38] <author> R. Greiner and P. Orponen. </author> <title> Probably approximately optimal satisficing strategies. </title> <journal> Artificial Intelligence, </journal> <note> Fall 1995. to appear. </note>
Reference-contexts: I gratefully acknowledge receiving many helpful comments from William Cohen, Dale Schuurmans and the anonymous referees. 1 PALO: A Probabilistic Hill-Climbing Algorithm 2 a particular scoring function, averaged over the distribution of samples (or goals, queries, problems, . . . ) that will be seen <ref> [42, 38] </ref>. There are at least two problems with implementing such a learning system: First, we need to know the distribution of samples to determine which element is optimal; unfortunately, this information is usually unknown. <p> In some simple cases, we may be able to identify (an approximation to) the globally optimal element with high probability; cf., the pao algorithm discussed in <ref> [38] </ref>. In almost all cases, however, this identification task is intractable, and not even approximatable [33].
Reference: [39] <author> R. Greiner and D. Schuurmans. </author> <title> Learning useful horn approximations. </title> <editor> In B. Nebel, C. Rich, and W. Swartout, editors, </editor> <booktitle> Proceedings of KR-92, </booktitle> <address> San Mateo, CA, Oct. 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: There is, of course, the additional challenge of keeping the total number of clauses bounded; this forces the transformations to remove a clause from the current approximation, to make room for each proposed addition. PALO: A Probabilistic Hill-Climbing Algorithm 22 We discuss these transformations in detail in <ref> [39] </ref>, and also present a palo 1 -ish algorithm, called AdComp, that hill-climbs in both spaces, to find both a near-optimal strengthening and a near-optimal weakening. <p> her c i (hS; Wi; ) utility function; we could then use a palo-like system to climb in the space of such performance elements (which differ in their way of handling the "W 6j= and S j= " situation), in parallel with its search for good weakenings and strengthenings; see <ref> [39] </ref>. N-Cat3. This compilation work is obviously related to the work on "vividization" and "approximation" [56, 7, 20, 15, 47], which also try to transform a given intractable theory into a representation that admits more efficient, if less categorical, reasoning.
Reference: [40] <author> B. Grosof. </author> <title> Generalizing prioritization. </title> <booktitle> In Proceedings of KR-91, </booktitle> <pages> pages 289-300, </pages> <address> Boston, </address> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: N-Acc3. The description so far assumes that every ordering of hypotheses is meaningful. In some contexts, there may already be a meaningful partial ordering of the hypotheses, perhaps based on specificity or some other criteria <ref> [40] </ref>.
Reference: [41] <author> S. Hanks and D. McDermott. </author> <title> Default reasoning, nonmonotonic logics, and the frame problem. </title> <booktitle> In Proceedings of AAAI-86, </booktitle> <pages> pages 328-333, </pages> <address> Philadelphia, </address> <month> Aug. </month> <year> 1986. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; we would, of course, like to return only that one solution. This is the essence of the "multiple extension" problem in knowledge representation <ref> [69, 41, 63] </ref>, and corresponds to the "bias" and "multiple explanation" problems in machine learning [61, 77, 71, 42] and "reference class" problem in statistics [54, 57].
Reference: [42] <author> D. Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> pages 177-221, </pages> <year> 1988. </year>
Reference-contexts: I gratefully acknowledge receiving many helpful comments from William Cohen, Dale Schuurmans and the anonymous referees. 1 PALO: A Probabilistic Hill-Climbing Algorithm 2 a particular scoring function, averaged over the distribution of samples (or goals, queries, problems, . . . ) that will be seen <ref> [42, 38] </ref>. There are at least two problems with implementing such a learning system: First, we need to know the distribution of samples to determine which element is optimal; unfortunately, this information is usually unknown. <p> This leads to the second problem: unfortunately, the task of identifying the globally optimal element, even given the correct distribution information, is intractable for many spaces of elements <ref> [30, 42] </ref>. A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop [44], genetic algorithms [6] and c4.5 [68], use this approach, as do many speedup learning methods; see especially [28]. <p> Unfortunately, only (at most) one of these solutions is correct; we would, of course, like to return only that one solution. This is the essence of the "multiple extension" problem in knowledge representation [69, 41, 63], and corresponds to the "bias" and "multiple explanation" problems in machine learning <ref> [61, 77, 71, 42] </ref> and "reference class" problem in statistics [54, 57]. This subsection addresses this problem by seeking a credulous system, related to the given initial default theory, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [43] <author> D. Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> <volume> 100 </volume> <pages> 78-150, </pages> <year> 1992. </year>
Reference-contexts: is constrained, perhaps by being known to be Gaussian, etc.; these variants may be more sample efficient. (See the palo 1N system mentioned above.) 6.3 Contributions This paper first poses two of the problems that can arise in learning systems that seek a performance element whose expected utility is optimal <ref> [43, 80] </ref>: viz., that the distribution information (which is required to determine which element is optimal) is usually unknown, and that finding a globally optimal performance element can be intractable.
Reference: [44] <author> G. Hinton. </author> <title> Connectionist learning procedures. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):185-234, </volume> <month> Sept. </month> <year> 1989. </year> <title> PALO: A Probabilistic Hill-Climbing Algorithm 31 </title>
Reference-contexts: A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop <ref> [44] </ref>, genetic algorithms [6] and c4.5 [68], use this approach, as do many speedup learning methods; see especially [28]. <p> As mentioned above, many learning systems attempt to address this challenge, of finding an element whose expected behavior is optimal; see for example the learning procedures used by symbolic classifiers [68], neural nets <ref> [44] </ref> and genetic algorithms [6]. Each of these systems uses a set of training samples to estimate the distribution, then uses this information to determine when one element is superior to another. Most systems do this implicitly, and heuristically.
Reference: [45] <author> W. Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58(301) </volume> <pages> 13-30, </pages> <month> Mar. </month> <year> 1963. </year>
Reference-contexts: Hoeffding's inequality <ref> [45, 11] </ref> bounds the probable rate of convergence: the probability that "Y n is more than + fl" goes to 0 exponentially fast as n increases; and, for a fixed n, exponentially as fl increases.
Reference: [46] <author> E. J. Horovitz. </author> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <booktitle> In Uncertainty in Artificial Intelligence 3, </booktitle> <address> Amsterdam, 1987. </address> <publisher> North Holland. </publisher>
Reference-contexts: Many other systems are similarly motivated by this issue of computational effectiveness | i.e., what is the best performance the system can exhibit, given only limited computational resources; cf., the works by Horovitz <ref> [46] </ref>, Etzioni [21] and Russell, Subramanian and Parr [70]. These other systems, however, either assume that the utilities of the various elements are immediately available, or supply statistical methods for estimating these utilities for all of the elements (akin to the Hoeffding Race and fl-ie framework mentioned above).
Reference: [47] <author> T. Imielinski. </author> <title> Domain abstraction and limited reasoning. </title> <booktitle> In Proceedings of IJCAI-87, </booktitle> <pages> pages 997-1003, </pages> <address> Milan, </address> <month> Aug. </month> <year> 1987. </year>
Reference-contexts: N-Cat3. This compilation work is obviously related to the work on "vividization" and "approximation" <ref> [56, 7, 20, 15, 47] </ref>, which also try to transform a given intractable theory into a representation that admits more efficient, if less categorical, reasoning.
Reference: [48] <author> G. H. John, R. Kohavi, and K. Pfleger. </author> <title> Irrelevant features and the subset selection problem. </title> <booktitle> In Proceedings of the Eleventh International Machine Learning Conference, </booktitle> <pages> pages 121-129, </pages> <address> N.J., 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: As such, it also resembles anytime algorithms [4, 16], but differs from standard anytime algorithms by terminating on reaching a 2 A less major difference is that the composer system, like the Hoeffding Race and fl-ie systems mentioned above, qualifies as a "wrapper" learner <ref> [48, 10] </ref>, as composer views each performance element as a black box, whose behavior can be sampled, but whose internals are unavailable.
Reference: [49] <author> I. Jurisica. </author> <title> Query optimization for knowledge base management systems; A machine learning approach. </title> <type> Master's thesis, </type> <institution> Department of Computer Science, University of Toronto, Toronto, </institution> <address> Ontario, </address> <year> 1992. </year>
Reference-contexts: That paper also provides a battery of empirical evidence which demonstrate that palo 1 0 can work effectively. Jurisica <ref> [49] </ref> presents an extensive body of related results. N-Eff4. To illustrate palo 1 's effectiveness, consider again the graph shown in Figure 2, and assume each arc has unit cost | i.e., f i = f (a i ) = 1.
Reference: [50] <author> L. P. Kaelbling. </author> <title> Learning in Embedded Systems. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Fong [22] presents a different, more mathematically rigorous, solution to the problem of reducing the number of element-sample evaluations, by specifying which single element should deal with each sample. The resulting "fl-ie" framework extends Kaelbling's ie system <ref> [50] </ref>. Combinatorial Space ) Hill-Climbing: These approaches work when there is an explicit representation of all possible performance elements. In many cases, however, there are an implicitly-defined combinatorial number of elements. <p> Moreover, this also means that palo will usually require a smaller total number of samples; see Note N-Palo5 in Section 4. Incremental Algorithms: Many other methods attempt to make effective use of the training samples; cf., reinforcement learning algorithms <ref> [50, 76] </ref> and systems that address the "bandit problem" [3, 64]. Each of these systems also makes a sequence of decisions, attempting to maximize its total reward.
Reference: [51] <author> H. Kautz and B. Selman. </author> <title> Speeding inference by acquiring new concepts. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <address> San Jose, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: N-Cat1. Selman and Kautz [72] prove that there is a unique optimal weakening, w s , which corresponds to the set of all horn implicates of the initial theory. Unfortunately, this w s can be exponentially larger than the original theory <ref> [51] </ref>.
Reference: [52] <author> R. M. Keller. </author> <title> Defining operationality for explanation-based learning. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <pages> pages 482-87, </pages> <address> Seattle, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: This "average case analysis" differs from several other approaches as, for example, we are not assuming that this distribution of problems will be uniform [25], nor that it will necessarily correspond to any particular collection of "benchmark challenge problems" <ref> [52] </ref>. N-Palo2. A "0-local optimum" corresponds exactly to the standard notion of local optimum; hence our "*-local optimum" (condition 2 of Theorem 1) generalizes local optimality.
Reference: [53] <author> S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. </author> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220 </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference-contexts: PALO: A Probabilistic Hill-Climbing Algorithm 5 point of diminishing returns. "Probabilistic Hill-climbing": Finally, as the phrase "probabilistic hill-climbing" may suggest "simulated annealing" <ref> [53] </ref> to many readers, it is worth explicitly distinguishing these different ideas: The general simulated annealing process assumes that the quality measure used to compare different elements is accurate; its use of "probabilistic" refers to the stochastic way in which simulated annealing probabilistically decides whether to climb "downhill", in an attempt
Reference: [54] <author> H. Kyburg. </author> <title> The reference class. </title> <journal> Philosophy of Science, </journal> <volume> 50, </volume> <year> 1982. </year>
Reference-contexts: This is the essence of the "multiple extension" problem in knowledge representation [69, 41, 63], and corresponds to the "bias" and "multiple explanation" problems in machine learning [61, 77, 71, 42] and "reference class" problem in statistics <ref> [54, 57] </ref>. This subsection addresses this problem by seeking a credulous system, related to the given initial default theory, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [55] <author> J. E. Laird, A. Newell, and P. S. Rosenbloom. </author> <title> SOAR: An architecture of general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(3), </volume> <year> 1987. </year>
Reference-contexts: 1 Introduction Many learning tasks can be viewed as a search through a space of possible performance elements seeking an element that is optimal, based on some utility measure. As examples, inductive systems seek classifiers whose classifications are optimally accurate, and many explanation-based learning [17, 60] and chunking <ref> [55] </ref> systems seek problem solvers that are optimally efficient [59, 30].
Reference: [56] <author> H. Levesque. </author> <title> Making believers out of computers. </title> <journal> Artificial Intelligence, </journal> <volume> 30(1) </volume> <pages> 81-108, </pages> <month> Oct. </month> <year> 1986. </year>
Reference-contexts: N-Cat3. This compilation work is obviously related to the work on "vividization" and "approximation" <ref> [56, 7, 20, 15, 47] </ref>, which also try to transform a given intractable theory into a representation that admits more efficient, if less categorical, reasoning.
Reference: [57] <author> R. Loui. </author> <title> Computing reference classes. </title> <booktitle> In AAAI Workshop on Uncertainty. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> St Paul, </address> <year> 1988. </year>
Reference-contexts: This is the essence of the "multiple extension" problem in knowledge representation [69, 41, 63], and corresponds to the "bias" and "multiple explanation" problems in machine learning [61, 77, 71, 42] and "reference class" problem in statistics <ref> [54, 57] </ref>. This subsection addresses this problem by seeking a credulous system, related to the given initial default theory, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [58] <author> O. Maron and A. Moore. </author> <title> Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation. </title> <booktitle> In Advances in Neural Information Processing Systems 6. </booktitle> <publisher> Morgan Kaufmann, </publisher> <month> April </month> <year> 1994. </year>
Reference-contexts: In general, each such learning system must evaluate each of N performance elements for each of k training samples. Maron and Moore <ref> [58] </ref> describe a system that works when there is a relatively small, and explicit, set of elements, meaning the N fi k "element-sample evaluations" can be performed explicitly.
Reference: [59] <author> S. Minton. </author> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Hingham, MA, </address> <year> 1988. </year>
Reference-contexts: As examples, inductive systems seek classifiers whose classifications are optimally accurate, and many explanation-based learning [17, 60] and chunking [55] systems seek problem solvers that are optimally efficient <ref> [59, 30] </ref>. <p> It also describes the statistical tool used to determine whether the result of a proposed modification is better than the original performance element; this tool can be viewed as a mathematically rigorous version of Minton's "utility analysis" <ref> [59] </ref>. Section 5 demonstrates the generality of our approach by presenting three different applications of the palo system, each using its own set of transformations to find a near-optimal element within its particular set of performance elements, where optimality is defined in terms of efficiency, accuracy or completeness, respectively.
Reference: [60] <author> S. Minton, J. Carbonell, C. Knoblock, D. Kuokka, O. Etzioni, and Y. Gil. </author> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):63-119, </volume> <month> Sept. </month> <year> 1989. </year> <title> PALO: A Probabilistic Hill-Climbing Algorithm 32 </title>
Reference-contexts: 1 Introduction Many learning tasks can be viewed as a search through a space of possible performance elements seeking an element that is optimal, based on some utility measure. As examples, inductive systems seek classifiers whose classifications are optimally accurate, and many explanation-based learning <ref> [17, 60] </ref> and chunking [55] systems seek problem solvers that are optimally efficient [59, 30].
Reference: [61] <author> T. M. Mitchell. </author> <title> The need for bias in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Laboratory for Computer Science Research, </institution> <month> May </month> <year> 1980. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; we would, of course, like to return only that one solution. This is the essence of the "multiple extension" problem in knowledge representation [69, 41, 63], and corresponds to the "bias" and "multiple explanation" problems in machine learning <ref> [61, 77, 71, 42] </ref> and "reference class" problem in statistics [54, 57]. This subsection addresses this problem by seeking a credulous system, related to the given initial default theory, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [62] <author> T. M. Mitchell, S. Mahadevan, and L. I. Steinberg. </author> <title> LEAP: A learning apprentice for VLSI design. </title> <booktitle> In Proceedings of IJCAI-85, </booktitle> <pages> pages 573-80, </pages> <address> Los Angeles, </address> <month> Aug. </month> <year> 1985. </year>
Reference-contexts: Moreover, this system can often work unobtrusively <ref> [62] </ref>, passively gathering the statistics it needs by simply watching a performance element solve problems relevant to a user's applications. Here, the incremental cost of palo's hill-climbing, over the cost of simply solving performance problems, can be very minor. <p> The samples that palo 1 uses may be produced by a user of the performance system, who is simply asking questions relevant to her current applications; here, palo 1 is unobtrusively gathering statistics as the user is solving her own problems <ref> [62] </ref>.
Reference: [63] <author> P. Morris. </author> <title> Curing anomalous extensions. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <pages> pages 437-42, </pages> <address> Seattle, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; we would, of course, like to return only that one solution. This is the essence of the "multiple extension" problem in knowledge representation <ref> [69, 41, 63] </ref>, and corresponds to the "bias" and "multiple explanation" problems in machine learning [61, 77, 71, 42] and "reference class" problem in statistics [54, 57].
Reference: [64] <author> K. S. Narendra and M. A. L. Thathachar. </author> <title> Learning automata: an introduction. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1989. </year>
Reference-contexts: Moreover, this also means that palo will usually require a smaller total number of samples; see Note N-Palo5 in Section 4. Incremental Algorithms: Many other methods attempt to make effective use of the training samples; cf., reinforcement learning algorithms [50, 76] and systems that address the "bandit problem" <ref> [3, 64] </ref>. Each of these systems also makes a sequence of decisions, attempting to maximize its total reward. Such systems tend to run continuously, making successive decisions; and they are often evaluated in terms of the number of mistakes they make over their entire learning+performance lifetimes.
Reference: [65] <author> D. Ourston and R. J. Mooney. </author> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66(2) </volume> <pages> 273-310, </pages> <year> 1994. </year>
Reference-contexts: N-Acc6. This paper considers only one type of transformation to convert one theory into another | viz., by rearranging the set of hypotheses. There are many other approaches, e.g., by eliminating some inappropriate sets of hypotheses [13, 82], or by modifying the antecedents of individual rules <ref> [65] </ref>, etc. Each of these approaches can be viewed as using a set of transformations to navigate around a space of interrelated theories. We can then consider the same objective described above: to identify the element in the implied space that has the highest expected accuracy.
Reference: [66] <author> D. Poole, R. Goebel, and R. Aleliunas. </author> <title> Theorist: A logical reasoning system for default and diagnosis. </title> <editor> In N. Cercone and G. McCalla, editors, </editor> <booktitle> The Knowledge Frontier: Essays in the Representation of Knowledge, </booktitle> <pages> pages 331-52, </pages> <address> New York, 1987. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: We focus on stratified Theorist-style performance elements <ref> [66] </ref> [67, 9, 79], where each PALO: A Probabilistic Hill-Climbing Algorithm 16 element fi = hF ; H; i is a triple, composed of a (consistent) set of facts F , a set of allowed hypotheses H (each a simple type of default [69]) and a specific priority ordering of the
Reference: [67] <author> T. C. Przymusinski. </author> <title> On the declarative semantics of stratified deductive databases and logic programs. </title> <editor> In J. Minker, editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, </booktitle> <pages> pages 193-216, </pages> <address> Los Altos, CA, 1987. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: We focus on stratified Theorist-style performance elements [66] <ref> [67, 9, 79] </ref>, where each PALO: A Probabilistic Hill-Climbing Algorithm 16 element fi = hF ; H; i is a triple, composed of a (consistent) set of facts F , a set of allowed hypotheses H (each a simple type of default [69]) and a specific priority ordering of the hypotheses.
Reference: [68] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: A common response is to build a system that hill-climbs towards a local optimum. Many well-known inductive learning systems, including backprop [44], genetic algorithms [6] and c4.5 <ref> [68] </ref>, use this approach, as do many speedup learning methods; see especially [28]. Unfortunately, few existing systems guarantee that each hill-climbing step is even an improvement, meaning the final element is not always even superior to the initial one, much less an optimum in the space of elements. <p> As mentioned above, many learning systems attempt to address this challenge, of finding an element whose expected behavior is optimal; see for example the learning procedures used by symbolic classifiers <ref> [68] </ref>, neural nets [44] and genetic algorithms [6]. Each of these systems uses a set of training samples to estimate the distribution, then uses this information to determine when one element is superior to another. Most systems do this implicitly, and heuristically.
Reference: [69] <author> R. Reiter. </author> <title> Nonmonotonic reasoning. </title> <booktitle> In Annual Review of Computing Sciences, </booktitle> <volume> volume 2, </volume> <pages> pages 147-87. </pages> <publisher> Annual Reviews Incorporated, </publisher> <address> Palo Alto, </address> <year> 1987. </year>
Reference-contexts: other trials over different inference graphs, and with diverse initial performance elements and values for * and ffi, illustrate how overly-conservative palo 1 's statistical tests are. 5.2 Improving Accuracy A default theory can be ambiguous, as it can produce many individually plausible but collectively incompatible solutions to certain queries <ref> [69] </ref>. Unfortunately, only (at most) one of these solutions is correct; we would, of course, like to return only that one solution. <p> Unfortunately, only (at most) one of these solutions is correct; we would, of course, like to return only that one solution. This is the essence of the "multiple extension" problem in knowledge representation <ref> [69, 41, 63] </ref>, and corresponds to the "bias" and "multiple explanation" problems in machine learning [61, 77, 71, 42] and "reference class" problem in statistics [54, 57]. <p> We focus on stratified Theorist-style performance elements [66] [67, 9, 79], where each PALO: A Probabilistic Hill-Climbing Algorithm 16 element fi = hF ; H; i is a triple, composed of a (consistent) set of facts F , a set of allowed hypotheses H (each a simple type of default <ref> [69] </ref>) and a specific priority ordering of the hypotheses.
Reference: [70] <author> S. Russell, D. Subramanian, and R. Parr. </author> <title> Provably bounded optimal agents. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <address> Chamberry, </address> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: Many other systems are similarly motivated by this issue of computational effectiveness | i.e., what is the best performance the system can exhibit, given only limited computational resources; cf., the works by Horovitz [46], Etzioni [21] and Russell, Subramanian and Parr <ref> [70] </ref>. These other systems, however, either assume that the utilities of the various elements are immediately available, or supply statistical methods for estimating these utilities for all of the elements (akin to the Hoeffding Race and fl-ie framework mentioned above).
Reference: [71] <author> S. J. Russell and B. N. Grosof. </author> <title> A declarative approach to bias in concept learning. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <pages> pages 505-10, </pages> <address> Seattle, WA, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; we would, of course, like to return only that one solution. This is the essence of the "multiple extension" problem in knowledge representation [69, 41, 63], and corresponds to the "bias" and "multiple explanation" problems in machine learning <ref> [61, 77, 71, 42] </ref> and "reference class" problem in statistics [54, 57]. This subsection addresses this problem by seeking a credulous system, related to the given initial default theory, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [72] <author> B. Selman and H. Kautz. </author> <title> Knowledge compilation using horn approximations. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <pages> pages 904-09, </pages> <address> Anaheim, </address> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: It can, however, be performed efficiently if the theory contains only Horn clauses [18]. 13 Selman and Kautz <ref> [72] </ref> use this observation to define a particular "knowledge compilation" method: Given a general propositional theory , their compiler computes a pair of "bracketing" Horn theories S and W , with the property S j= j= W ; we call each such S a "Strengthening" of the initial theory , and <p> Using Equation 2, we can then define C c ( hS; Wi ) to be the expected value of c c (hS; Wi; ). Our goal is to determine the approximation hS; Wi with the largest C c ( ) value. As before, this task is intractable (see <ref> [72] </ref>) and depends on the distribution, suggesting yet again that we use the palo 1 system. <p> Now write = H [ N , where H is the subset of 's clauses that are Horn and N = ffl i g m i=1 is its non-Horn subset. Selman and Kautz <ref> [72] </ref> prove that each optimal strengthening is of the form S o = H [ 0 N , where each fl 0 2 0 N is a horn-strengthening of some fl 2 N . <p> N-Cat1. Selman and Kautz <ref> [72] </ref> prove that there is a unique optimal weakening, w s , which corresponds to the set of all horn implicates of the initial theory. Unfortunately, this w s can be exponentially larger than the original theory [51]. <p> This motivates us to use palo 1 for this subtask as well. The space of transformations is more complicated to describe, however. <ref> [72] </ref> provides an (exponential time) algorithm lub for computing the optimal weakening w s . In essence, this algorithm iteratively attempts to resolve each horn clause with each non-horn clause, and adds in each successful resolvent, after removing all subsumed clauses.
Reference: [73] <author> L. Shastri. </author> <title> Default reasoning in semantic networks: A formalization of recognition and inheritance. </title> <journal> Artificial Intelligence, </journal> <volume> 39 </volume> <pages> 283-355, </pages> <year> 1989. </year>
Reference-contexts: Observe finally that fl (fi; t (fi)) 2 for all fi 2 S fi and all t 2 T A . N-Acc1. The motivation underlying this work is similar to the research of Shastri <ref> [73] </ref> and others, who also use probabilistic information to find an ordering of the given default rules.
Reference: [74] <author> H. A. Simon and J. B. Kadane. </author> <title> Optimal problem-solving search: All-or-none solutions. </title> <journal> Artificial Intelligence, </journal> <volume> 6 </volume> <pages> 235-247, </pages> <year> 1975. </year>
Reference-contexts: (The instantiations of these parameters are summarized in Table 2.) For pedagogical reasons, each subsection begins with a quick simplistic description of its application, and then provides notes that describe how to build a more comprehensive system. 5.1 Improving Efficiency Many derivation processes can be viewed as a satisficing search <ref> [74] </ref> through a given graph structure. <p> Each strategy will find an answer, if one exists. As this is a satisficing search, all answers are equally acceptable <ref> [74] </ref>, which means that all strategies are equally accurate. We therefore consider the costs of the strategies, preferring the one whose expected cost is minimal.
Reference: [75] <author> D. E. Smith. </author> <title> Controlling backward inference. </title> <journal> Artificial Intelligence, </journal> <volume> 39(2) </volume> <pages> 145-208, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: We can use these values to compute the expected costs of the various strategies <ref> [75] </ref>: C ( fi 0 ) = 5:792, C ( fi 1 ) = 5:069, C ( fi 2 ) = 3:840 and C ( fi 3 ) = 3:140.
Reference: [76] <author> R. S. Sutton, </author> <title> editor. </title> <journal> Machine Learning, </journal> <volume> volume 8. </volume> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year> <title> Special Issue on Reinforcement Learning. PALO: A Probabilistic Hill-Climbing Algorithm 33 </title>
Reference-contexts: Moreover, this also means that palo will usually require a smaller total number of samples; see Note N-Palo5 in Section 4. Incremental Algorithms: Many other methods attempt to make effective use of the training samples; cf., reinforcement learning algorithms <ref> [50, 76] </ref> and systems that address the "bandit problem" [3, 64]. Each of these systems also makes a sequence of decisions, attempting to maximize its total reward.
Reference: [77] <author> P. E. Utgoff. </author> <title> Shift of Bias for Inductive Concept Learning. </title> <type> PhD thesis, </type> <institution> Rutgers, Laboratory for Computer Science Research, </institution> <month> Oct. </month> <year> 1984. </year>
Reference-contexts: Unfortunately, only (at most) one of these solutions is correct; we would, of course, like to return only that one solution. This is the essence of the "multiple extension" problem in knowledge representation [69, 41, 63], and corresponds to the "bias" and "multiple explanation" problems in machine learning <ref> [61, 77, 71, 42] </ref> and "reference class" problem in statistics [54, 57]. This subsection addresses this problem by seeking a credulous system, related to the given initial default theory, that is "optimally correct"; i.e., which produces the correct answer most often.
Reference: [78] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-42, </pages> <year> 1984. </year>
Reference-contexts: There are, of course, standard statistical techniques that use the set of observed samples to estimate the needed information; and several classes of learning systems have incorporated these techniques. For example, many "PAC-learning" systems <ref> [78] </ref> use these estimates to identify an element that is, with high probability, approximately a global optimum. This leads to the second problem: unfortunately, the task of identifying the globally optimal element, even given the correct distribution information, is intractable for many spaces of elements [30, 42]. <p> The conditions above specify situations where palo will not work effectively. There are also situations where palo should not be used. For example, there is no need to use the weak hill-climbing method if there is a known efficient techniques for computing the global optimum; cf., <ref> [78, 2] </ref>.
Reference: [79] <author> P. van Arragon. </author> <title> Nested default reasoning with priority levels. </title> <booktitle> In Proceedings of CSCSI-90, </booktitle> <pages> pages 77-83, </pages> <address> Ottawa, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: We focus on stratified Theorist-style performance elements [66] <ref> [67, 9, 79] </ref>, where each PALO: A Probabilistic Hill-Climbing Algorithm 16 element fi = hF ; H; i is a triple, composed of a (consistent) set of facts F , a set of allowed hypotheses H (each a simple type of default [69]) and a specific priority ordering of the hypotheses.
Reference: [80] <author> V. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: is constrained, perhaps by being known to be Gaussian, etc.; these variants may be more sample efficient. (See the palo 1N system mentioned above.) 6.3 Contributions This paper first poses two of the problems that can arise in learning systems that seek a performance element whose expected utility is optimal <ref> [43, 80] </ref>: viz., that the distribution information (which is required to determine which element is optimal) is usually unknown, and that finding a globally optimal performance element can be intractable.
Reference: [81] <author> D. Vormittag. </author> <title> Evaluating answers to questions, </title> <month> May </month> <year> 1991. </year> <type> Bachelors Thesis, </type> <institution> University of Toronto. </institution>
Reference-contexts: As another situation, we may be able to rank responses in terms of their precision: e.g., knowing that the cost of watch 7 is $2;000 is more precise than knowing only that watch 7 is expensive <ref> [81] </ref>.) We have also assumed that all queries are equally important; i.e., a wrong answer to any query "costs" us the same 1, whether we are asking for the location of a salt-shaker, or of a stalking tiger.
Reference: [82] <author> J. Wong. </author> <title> Improving the accuracy of a representational system, </title> <month> May </month> <year> 1991. </year> <type> Bachelors Thesis, </type> <institution> University of Toronto. </institution>
Reference-contexts: N-Acc6. This paper considers only one type of transformation to convert one theory into another | viz., by rearranging the set of hypotheses. There are many other approaches, e.g., by eliminating some inappropriate sets of hypotheses <ref> [13, 82] </ref>, or by modifying the antecedents of individual rules [65], etc. Each of these approaches can be viewed as using a set of transformations to navigate around a space of interrelated theories.
References-found: 82

