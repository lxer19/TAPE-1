URL: http://www.cs.iastate.edu/~honavar/Papers/diagnosis.ps
Refering-URL: http://www.cs.iastate.edu/~cs474/weekly.html
Root-URL: 
Email: balakris@cs.iastate.edu, honavar@cs.iastate.edu  
Title: Intelligent Diagnosis Systems  
Author: Karthik Balakrishnan Vasant Honavar 
Note: 1 This research was partially supported through grants from the John Deere Foundation and the National Science Foundation (NSF IRI-9409580) to Vasant Honavar.  
Web: http://www.cs.iastate.edu/~honavar/aigroup.html  
Address: Ames, Iowa 50011-1040, U.S.A.  
Affiliation: Artificial Intelligence Research Group Department of Computer Science Iowa State University  
Abstract-found: 0
Intro-found: 1
Reference: <author> Buchanan, B. G., & Wilkins, D. C. (eds). </author> <year> (1993). </year> <title> Readings in Knowledge Acquisition. </title> <address> Palo Alto, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Chen, C-H., & Honavar, V. </author> <year> (1995). </year> <title> A Neural Memory Architecture for Content as Well as Address-Based Storage and Recall. </title> <journal> Connection Science, </journal> <volume> 7, </volume> <pages> 293-312. </pages>
Reference: <author> Chen, C-H., & Honavar, V. </author> <year> (1996). </year> <title> A Neural Architecture for High-Speed Database Query Processing. </title> <journal> Microcomputer Applications, </journal> <volume> 15, </volume> <pages> 7-13. </pages>
Reference: <author> Dean, T., Allen, J., & Aloimonos, Y. </author> <year> (1995). </year> <booktitle> Artificial Intelligence Theory and Practice. </booktitle> <address> Redwood City, CA: Benjamin/Cummings. </address>
Reference: <author> Dempster, A. </author> <year> (1968). </year> <title> A Generalization of Bayesian Inference. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> 30 (Series B), </volume> <pages> 205-247. </pages> <note> 37 Duda, </note> <author> R. O., & Hart, P. E. </author> <year> (1973). </year> <title> Pattern Classification and Scene Analysis. </title> <address> New York: </address> <publisher> John Wiley. </publisher>
Reference: <author> Durkin, J. </author> <year> (1994). </year> <title> Expert Systems Design and Development. </title> <address> New York, NY: </address> <publisher> Macmillan Publishing Company. </publisher>
Reference: <editor> Fayyad, U., Piatetsky-Shapiro, G., Smyth, P., & Uthurusamy, R. (eds). </editor> <booktitle> (1996). Advances in Knowledge Discovery and Data Mining. </booktitle> <address> Cambridge, MA. </address> <publisher> To appear: MIT Press. </publisher>
Reference: <author> Forbus, K. D., & de Kleer, J. </author> <year> (1993). </year> <title> Building Problem Solvers. </title> <address> Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: Based on further information (e.g., concerning the functioning of the headlights), one could possibly diagnose the exact cause. This is the principle behind model-based diagnosis systems (Durkin, 1994; Mozetic, 1992; Puppe, 1993). Reason maintenance systems <ref> (Forbus & de Kleer, 1993) </ref> can be used in model-based diagnosis and one such approach is illustrated in section 5. In many practical scenarios precise models of the domain may be unavailable. <p> Since these assumptions have to be retracted, we remove H from A. Once these assumptions are retracted from the database, we can add the new fact q to D without introducing any contradictions. Such a system can be easily adapted for diagnosis <ref> (Forbus & de Kleer, 1993) </ref>. The database D, in this case, is composed of a set C of facts describing the behavior of the system being diagnosed in terms of its components, and a set A of assumptions about the proper functioning of the components. <p> In addition, the computation of all diagnoses for an observed fault is known to be computationally intractable which makes this procedure impractical for most real-world 12 diagnosis applications. One alternative is to use focusing mechanisms for computing just a few of the probable diagnoses <ref> (Forbus & de Kleer, 1993) </ref>. Another possibility is to use known polynomial-time algorithms for computing the first k diagnoses (for a given k) (Mozetic, 1992). <p> If adequately complete and precise knowledge of the operating principles of the domain is available, it can be used to develop causal models which can support a model-based approach to diagnosis <ref> (Forbus & de Kleer, 1993) </ref>. In the absence of such a causal model, if the knowledge necessary for diagnosis can be acquired from human experts, it would be possible, at least in principle, to build a knowledge-based system or an expert system for diagnosis (Durkin, 1994; Puppe, 1993; Stefik, 1995).
Reference: <author> Fu, K. S. </author> <year> (1982). </year> <title> Syntactic Pattern Recognition and Applications. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall. </publisher>
Reference: <author> Fukunaga, K. </author> <year> (1990). </year> <title> Introduction to Statistical Pattern Recognition. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> Gallant, S. </author> <year> (1993). </year> <title> Neural Network Learning and Expert Systems. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Ginsberg, M. </author> <year> (1993). </year> <booktitle> Essentials of Artificial Intelligence. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: This done, he makes up his mind to get her a nice pair of earrings. This is an instance of assumption-based reasoning that can be performed by an ATMS. We will describe one such ATMS formulation based on Ginsberg <ref> (Ginsberg, 1993) </ref>, and use it to illustrate the process of model-based diagnosis. But first, some essential details. Suppose we have a database D of rules describing our domain.
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Algorithms in Search, Optimization and Machine Learning. </title> <address> New York, NY: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Gonzalez, R. C., & Thomason, M. G. </author> <year> (1978). </year> <title> Syntactic Pattern Recognition: An Introduction. </title> <address> Reading, MA: </address> <publisher> Addison Wesley. </publisher>
Reference: <editor> Goonatilake, S., & Khebbal, S. (eds). </editor> <year> (1995). </year> <title> Intelligent Hybrid Systems. </title> <address> West Sussex: </address> <publisher> John Wiley. </publisher>
Reference: <author> Hassoun, M. H. </author> <year> (1995). </year> <booktitle> Fundamentals of Artificial Neural Networks. </booktitle> <address> Boston, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Hebb, D. O. </author> <year> (1949). </year> <title> The Organization of Behavior. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Holland, J. </author> <year> (1992). </year> <booktitle> Adaptation in Natural and Artificial Systems. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Honavar, V. </author> <year> (1994). </year> <title> Toward Learning Systems That Integrate Different Strategies and Representations. Pages 561-580 of: Honavar, </title> <editor> V., & Uhr, L. (eds), </editor> <title> Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. </title> <address> San Diego, CA: </address> <publisher> Academic Press. 38 Honavar, </publisher> <editor> V., & Miller, L. </editor> <year> (1997). </year> <title> Automated Knowledge Acquisition from Heterogeneous Distributed Data and Knowledge Sources. </title> <note> To appear. </note>
Reference: <author> Honavar, V., & Uhr, L. </author> <year> (1993). </year> <title> Generative Learning Structures and Processes for Generalized Connectionist Networks. </title> <journal> Information Sciences, </journal> <volume> 70, </volume> <pages> 75-108. </pages>
Reference: <author> Honavar, V., & Uhr, L. (eds). </author> <year> (1994). </year> <title> Artificial Intelligence and Neural Networks Steps toward Principled Integration. </title> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference: <author> Hutchinson, A. </author> <year> (1994). </year> <title> Algorithmic Learning. </title> <address> New York, NY: </address> <publisher> Oxford University Press. </publisher>
Reference: <author> Kolodner, J. </author> <year> (1993). </year> <title> Case-Based Reasoning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: A simple example of an expert system for diagnosis is presented in section 4. One approach which attempts to circumvent the difficult task of extracting and codifying the domain knowledge of the expert relies on building a large repository of sample diagnoses or cases <ref> (Kolodner, 1993) </ref>. When presented with a diagnostic problem the system attempts to solve it by identifying one or more scenarios with known diagnoses from its repository of cases. Unlike model-based systems and expert systems, case-based systems neither model the domain knowledge nor the diagnostic reasoning of the domain expert. <p> diagnosis. 6 CASE-BASED REASONING SYSTEMS In case-based reasoning (CBR) systems (Schank & Abelson, 1977; Schank, 1982) knowledge is stored in the form of cases, where a case is defined as a contextualized piece of knowledge representing an experience that teaches a lesson fundamental to achieving the goals of the reasoner <ref> (Kolodner, 1993) </ref>. Thus, a case can be thought of as a situation that was experienced in the past and resulted in some relevant action. The cases are stored in a library, indexed appropriately to facilitate efficient retrieval of the cases. <p> In many practical scenarios, knowledge elicitation from experts may not be feasible. However, it might be possible to obtain a large sample of diagnoses performed by domain experts. These may be stored in a case library and used by case-based reasoning (CBR) systems <ref> (Kolodner, 1993) </ref>. One can view such a system as performing a form of rote learning or memorization. In recent years, much AI research has focused on automating the knowledge acquisition process by using machine learning techniques (Gallant, 1993; Hassoun, 1995; 34 Honavar, 1994; Langley, 1995; Mitchell, 1997; Ripley, 1996).
Reference: <editor> Koza, J. </editor> <booktitle> (1992). Genetic Programming. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: In addition, evolutionary algorithms (Goldberg, 1989; Holland, 1992; Mitchell, 1996) can be used to search for target concepts in appropriately expressed concept spaces (e.g., decision trees, neural networks, LISP programs, etc.). Examples of evolutionary induction of LISP programs appear in <ref> (Koza, 1992) </ref>, while induction of neural networks is discussed in (Patel & Honavar, 1997). Apart from inductive learning, deductive or analytical learning algorithms (Langley, 1995; Mitchell, 1997) are also of interest.
Reference: <author> Kung, S. Y. </author> <year> (1993). </year> <title> Digital Neural Networks. </title> <address> New York: </address> <publisher> Prentice-Hall. </publisher>
Reference: <author> Langley, P. </author> <year> (1995). </year> <title> Elements of Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kauffman. </publisher>
Reference: <author> Lavrac, N., & Dzeroski, S. </author> <year> (1994). </year> <title> Inductive Logic Programming Techniques and Applications. </title> <address> New York: </address> <publisher> Ellis Horwood. </publisher>
Reference-contexts: Besides the inductive approaches discussed in this paper, a number of other inductive learning paradigms exist, which we have not examined in this paper because 35 of space constraints. These include: inductive logic programming <ref> (Lavrac & Dzeroski, 1994) </ref> (wherein knowledge is represented the form of logic programs), automata induction (Parekh & Honavar, 1997) (wherein knowledge is represented in the form of finite-state automata), etc.
Reference: <author> Luger, G. F., & Stubblefield, W. A. </author> <year> (1993). </year> <booktitle> Artificial Intelligence. </booktitle> <address> New York, NY: Benjamin/Cummings. </address>
Reference: <author> Medsker, L. </author> <year> (1994). </year> <title> Hybrid Neural Network and Expert Systems. </title> <address> New York: </address> <publisher> Kluwer. </publisher>
Reference: <author> Michalewicz, Z. </author> <year> (1992). </year> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Berlin: Springer-Verlag. </publisher>
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> Theory and Methodology of Inductive Learning. </title> <editor> In: Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (eds), </editor> <booktitle> Machine Learning AnArtificial Intelligence Approach. </booktitle> <address> Palo Alto, CA: </address> <publisher> Tioga. </publisher>
Reference: <author> Miclet, L. </author> <year> (1986). </year> <title> Structural methods in pattern recognition. </title> <address> New York, NY: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Mitchell, M. </author> <year> (1996). </year> <title> An Introduction to Genetic Algorithms. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Mitchell, T. </author> <year> (1997). </year> <title> Machine Learning. </title> <publisher> McGraw Hill. (forthcoming). </publisher>
Reference: <author> Mozetic, I. </author> <year> (1992). </year> <title> Model-Based Diagnosis: An Overview. Pages 419-430 of: </title> <editor> Marik, V., Stepankova., O., & Trappl, R. (eds), </editor> <booktitle> Advanced Topics in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag. 39 Natarajan, B. </publisher> <year> (1991). </year> <title> Machine Learning: A Theoretical Approach. </title> <address> Palo Alto, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Consider a scenario in which a model of the domain is available. Such a model explicitly represents the structure of the system, i.e., its constituent components and their organization <ref> (Mozetic, 1992) </ref>. A diagnosis problem arises when the system's observed behavior conflicts with the system's expected behavior, and the task is to identify the (faulty) system component (s) that explain the anomaly. <p> One alternative is to use focusing mechanisms for computing just a few of the probable diagnoses (Forbus & de Kleer, 1993). Another possibility is to use known polynomial-time algorithms for computing the first k diagnoses (for a given k) <ref> (Mozetic, 1992) </ref>. Alternatively, one might use a hybrid approach which refines partial or incomplete model-based diagnostic knowledge into heuristic diagnosis rules through inductive learning (see sections 7-10 below).
Reference: <author> Parekh, R.G., & Honavar, V. </author> <year> (1997). </year> <title> Automata Induction, Grammar Inference, and Language Acquisition. </title> <editor> In: Dale, Moisl, & Somers (eds), </editor> <booktitle> Handbook of Natural Language Processing. </booktitle> <address> New York, </address> <note> To appear.: Marcel Dekker. </note>
Reference-contexts: Besides the inductive approaches discussed in this paper, a number of other inductive learning paradigms exist, which we have not examined in this paper because 35 of space constraints. These include: inductive logic programming (Lavrac & Dzeroski, 1994) (wherein knowledge is represented the form of logic programs), automata induction <ref> (Parekh & Honavar, 1997) </ref> (wherein knowledge is represented in the form of finite-state automata), etc. In addition, evolutionary algorithms (Goldberg, 1989; Holland, 1992; Mitchell, 1996) can be used to search for target concepts in appropriately expressed concept spaces (e.g., decision trees, neural networks, LISP programs, etc.).
Reference: <author> Parekh, R.G., Yang, J., & Honavar, V. </author> <year> (1997). </year> <title> Multi-Category Constructive Neural Network Learning Algorithms for Real-Valued Pattern Classification. </title> <institution> Ames, Iowa: </institution> <type> Tech. Rep. </type> <institution> ISU-CS-TR 97-01, Department of Computer Science, Iowa State University. </institution>
Reference-contexts: Besides the inductive approaches discussed in this paper, a number of other inductive learning paradigms exist, which we have not examined in this paper because 35 of space constraints. These include: inductive logic programming (Lavrac & Dzeroski, 1994) (wherein knowledge is represented the form of logic programs), automata induction <ref> (Parekh & Honavar, 1997) </ref> (wherein knowledge is represented in the form of finite-state automata), etc. In addition, evolutionary algorithms (Goldberg, 1989; Holland, 1992; Mitchell, 1996) can be used to search for target concepts in appropriately expressed concept spaces (e.g., decision trees, neural networks, LISP programs, etc.).
Reference: <author> Patel, M., & Honavar, V. (eds). </author> <year> (1997). </year> <title> Evolutionary Synthesis of Neural Systems. </title> <address> Cambridge, MA. </address> <publisher> To appear.: MIT Press. </publisher>
Reference-contexts: Examples of evolutionary induction of LISP programs appear in (Koza, 1992), while induction of neural networks is discussed in <ref> (Patel & Honavar, 1997) </ref>. Apart from inductive learning, deductive or analytical learning algorithms (Langley, 1995; Mitchell, 1997) are also of interest. Essentially, these are knowledge compilation techniques which abstract (or generalize) and store the results of computationally expensive deductive inferences used in solving specific instances of a problem.
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Puppe, F. </author> <year> (1993). </year> <title> Systematic Introduction to Expert Systems Knowledge Representations and Problem Solving Methods. </title> <publisher> Berlin: Springer-Verlag. </publisher>
Reference: <author> Quinlan, R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Inductive approaches are particularly suited for domains in which principles are hard to formalize (weather prediction, medical diagnosis etc.) or where experts are few (space exploration etc.). Some widely used inductive learning systems include those based on decision trees <ref> (Quinlan, 1993) </ref> (see section 8), neural networks (Gallant, 1993; Hassoun, 1995) (see section 9), and statistical pattern classification (Duda & Hart, 1973; Fukunaga, 1990; Ripley, 1996) (see section 10). 4 EXPERT SYSTEMS Expert systems (Durkin, 1994; Puppe, 1993; Stefik, 1995) are programs that model the expertise (knowledge) and reasoning capabilities of <p> In what follows, we will restrict ourselves to a few simple examples of inductive learning systems that are well-suited for diagnosis applications. These are: decision trees, some simple classes of artificial neural networks (or connectionist networks), and some elementary statistical approaches. 8 DECISION TREES The ID3 algorithm <ref> (Quinlan, 1993) </ref> provides a way to learn classification rules represented in the form of a decision tree. A decision tree consists of leaf nodes that are class names and internal nodes that represent tests on symptoms (also termed attributes), with a branch for each possible outcome of the test. <p> In addition to their greater likelihood of generalization, small decision trees require fewer attribute tests on average, leading to reduced computational cost of classification. The general idea behind the ID3 <ref> (Quinlan, 1993) </ref> algorithm is to recursively select attributes that yields the maximum possible amount of information (in the technical sense of the term used by Shannon in his development of information theory) on the average, for unambiguously classifying the training examples. <p> Compared to other inference procedures (deduction and abduction systems), decision trees are much faster to execute. Some drawbacks associated with the use of decision tree construction algorithms such as ID3 and some possible remedies are documented in <ref> (Quinlan, 1993) </ref>. Decision trees have been extended to handle continuous attribute ranges in the form of discretized, multi-valued intervals. <p> This is necessary to avoid overly detailed descriptions that essentially amount to memorization of the training data (with the resulting problem of poor generalization). Decision tree learning algorithms like ID3, induce classification rules and represent them conveniently as trees. Several decision tree learning algorithms are available in the literature <ref> (Quinlan, 1993) </ref>. They are particularly well-suited for domains in which instances can be described using a finite number of attributes, each of which takes on one of a finite set of values. Extensions that can handle continuous-valued attributes have recently become available.
Reference: <author> Rich, E., & Knight, K. </author> <year> (1991). </year> <booktitle> Aritificial Intelligence. </booktitle> <address> New York, NY: </address> <publisher> McGraw-Hill. </publisher>
Reference: <author> Ripley, B. </author> <year> (1996). </year> <title> Pattern Recognition and Neural Networks. </title> <address> New York, NY: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Although several approaches to attribute selection have been developed in the literature, most of them work well only with linear classifiers but not with nonlinear classifiers (e.g., neural networks) <ref> (Ripley, 1996) </ref>. In addition, these techniques fail to deal with multiple selection criteria (e.g., classification accuracy, feature measurement cost, etc.) which might be desirable in many applications (e.g., the medical diagnosis).
Reference: <author> Russell, S., & Norvig, P. </author> <year> (1995). </year> <title> Artificial Intelligence A Modern Approach. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: For example, P (x 1 jC i ; x 2 ) = P (x 1 jC i ) implying that the symptoms x 1 and x 2 are independent given that class C i is observed (or suspected) <ref> (Russell & Norvig, 1995) </ref>. With such assumptions, Bayes rule for an m category problem involving 3 observations can be reduced to the expression in Eq. (9).
Reference: <author> Schank, R. </author> <year> (1982). </year> <title> Dynamic Memory: A theory of learning in computers and people. </title> <address> New York, NY: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Schank, R., & Abelson, R. </author> <year> (1977). </year> <title> Scripts, plans, goals and understanding. </title> <address> Northvale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Shafer, G. </author> <year> (1976). </year> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton, </publisher> <address> NJ: </address> <publisher> Princeton University Press. </publisher>
Reference: <author> Shannon, C. </author> <year> (1948). </year> <title> A Mathematical Theory of Communication. </title> <journal> Bell System Technical Journal, 27(July and October), </journal> <pages> 379-423, 623-656. </pages>
Reference-contexts: However, this approach can be extended naturally to multiple classes as will be demonstrated using the automobile diagnosis example. ID3 computes the expected information (number of yes/no questions that need to be asked) required to classify the examples in the training set, which can be shown to be (refer <ref> (Shannon, 1948) </ref> for details): I (n 1 ; n 2 ) = n 1 + n 2 n 1 + n 2 n 1 + n 2 n 1 + n 2 (1) where n 1 and n 2 are the number of examples in the training set that belong to
Reference: <author> Shavlik, J. </author> <year> (1994). </year> <title> A Framework for Combining Symbolic and Neural Learning. Pages 561-580 of: Honavar, </title> <editor> V., & Uhr, L. (eds), </editor> <title> Artificial Intelligence and Neural Networks: Steps Toward Principled Integration. </title> <address> San Diego, CA: </address> <publisher> Academic Press. 40 Shavlik, </publisher> <editor> J., & Dietterich, T. (eds). </editor> <booktitle> (1990). Readings in Machine Learning. </booktitle> <address> Palo Alto, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For instance, knowledge available in the form of a decision tree or a set of rules can be encoded into a neural network for further refinement through learning from examples. An example of this approach is offered by <ref> (Shavlik, 1994) </ref>. This approach allows the rules of expert systems to be mapped into neural network architectures, thereby permitting the system to cope with changes in diagnostic knowledge.
Reference: <author> Simon, H. A. </author> <year> (1983). </year> <title> Why should machines learn? In: </title> <editor> Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (eds), </editor> <booktitle> Machine Learning AnArtificial Intelligence Approach. </booktitle> <address> Palo Alto, CA: </address> <publisher> Tioga. </publisher>
Reference: <author> Stefik, M. </author> <year> (1995). </year> <title> Introduction to Knowledge Systems. </title> <address> Palo Alto, CA: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference: <author> Sun, R., & Bookman, L. (eds). </author> <year> (1994). </year> <title> Computational Architectures Integrating Symbolic and Neural Processes. </title> <address> New York: </address> <publisher> Kluwer. </publisher>
Reference: <author> Tanimoto, S. L. </author> <year> (1995). </year> <title> Elements of Artificial Intelligence Using Common Lisp. </title> <address> New York: </address> <publisher> Computer Science Press. </publisher>
Reference-contexts: Other, not necessarily statistical, techniques for reasoning under uncertainty include Dempster-Schafer calculus, fuzzy logic, and related methods <ref> (Tanimoto, 1995) </ref>. Dempster-Schafer theory is designed to deal with the distinction between uncertainty and ignorance. It is used to calculate the probability that the evidence (or observation) supports a conclusion, rather than the probability of the conclusion itself. It differs from probabilistic reasoning systems in this important regard.
Reference: <author> Uhr, L. </author> <year> (1973). </year> <title> Pattern Recognition, </title> <booktitle> Learning and Thought. </booktitle> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall. </publisher>
Reference: <author> Winston, P. </author> <year> (1992). </year> <booktitle> Artificial Intelligence. </booktitle> <address> New York, NY: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Yang, J., & Honavar, V. </author> <year> (1997). </year> <title> Feature Subset Selection Using a Genetic Algorithm. </title> <note> To appear. </note>
Reference-contexts: A recent approach to the attribute-selection problem uses evolutionary algorithms to select a relevant subset of attributes under a variety of cost and performance constraints <ref> (Yang & Honavar, 1997) </ref>. Our discussion of knowledge acquisition in this paper has assumed that the necessary knowledge and data are available in highly structured formats defined by the instance representation languages used by the individual learning algorithms.
Reference: <author> Zadeh, L. </author> <year> (1965). </year> <title> Fuzzy Sets. </title> <journal> Information and Control, </journal> <volume> 8, </volume> <pages> 338-353. </pages>
Reference: <author> Zimmermann, H. </author> <year> (1991). </year> <title> Fuzzy Set Theory And Its Applications. Second edn. </title> <address> Dor-drecht, The Netherlands: </address> <publisher> Kluwer. </publisher> <pages> 41 </pages>
References-found: 58

