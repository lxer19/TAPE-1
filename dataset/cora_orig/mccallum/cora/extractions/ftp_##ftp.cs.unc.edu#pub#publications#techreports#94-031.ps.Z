URL: ftp://ftp.cs.unc.edu/pub/publications/techreports/94-031.ps.Z
Refering-URL: ftp://ftp.cs.unc.edu/pub/publications/techreports/FILE.html
Root-URL: http://www.cs.unc.edu
Title: UNC is an Equal Opportunity/Affirmative Action Institution. U N I V E R S I
Author: L L U M Warren Robinett Richard Holloway 
Note: This research was supported by the following grants: ARPA DABT 63-93-C-0048, NSF Cooperative Agreement ASC-8920219, and ARPA "Science and Technology Center for Computer Graphics and Scientific Visualization", ONR N00014-86-K-0680, and NIH 5-R24-RR-02170.  
Address: #3175, Sitterson Hall UNC-Chapel Hill Chapel Hill, NC 27599-3175  
Affiliation: Department of Computer Science CB  
Date: LIBERTAS  September, 1994  
Pubnum: TR94-031  Project  
Abstract-found: 0
Intro-found: 0
Reference: <author> Blanchard, C., S. Burgess, Y. Harvill, J. Lanier, A. Lasko, M. Oberman, M. Teitel. </author> <year> (1990). </year> <title> Reality Built for Two: A Virtual Reality Tool. </title> <booktitle> Proc. 1990 Workshop on Interactive 3D Graphics, </booktitle> <pages> 35-36. </pages>
Reference-contexts: VPL Research of Redwood City, California, began selling a commercial 2-user HMD system, called "Reality Built for 2," in 1989 <ref> (Blanchard, Burgess, Harvill, Lanier, Lasko, Oberman, & Teitel, 1990) </ref>. A prototype see-through HMD targeted for manufacturing applications was built at Boeing in 1992 (Caudell & Mizell, 1992). Its display algorithm and the measurement of the parameters of this algorithm is discussed in (Janin, Mizell & Caudell, 1993).
Reference: <author> Brooks, F.P., Jr. </author> <year> (1989). </year> <title> Course #29: Implementing and interacting with real-time virtual worlds. </title> <note> Course Notes: SIGGRAPH '89. </note>
Reference-contexts: A CS diagram for an early version of the UNC VR software was presented in <ref> (Brooks, 1989) </ref> and a later version in (Robinett & Holloway, 1992). We represent a typical multiple-user VR system with the following graph: Right Eye n Right Screen n Room n Head n Left Eye n Left Screen n World Hand n Object 1 Object k . . . .
Reference: <author> Buchroeder, R. A., Seeley, G. W., & Vukobradatovich, D. </author> <year> (1981). </year> <title> Design of a Catadioptric VCASS Helmet-Mounted Display. </title> <institution> Optical Sciences Center, University of Arizona, </institution> <note> under contract to the U.S. </note> <institution> Air Force Armstrong Aerospace Medical Research Laboratory, Wright Patterson Air Force Base, Dayton, Ohio, AFAMRL-TR-81-133. CAE. </institution> <year> (1986). </year> <title> Introducing the visual display system that you wear. </title> <publisher> CAE Electronics, Ltd., C.P. </publisher> <address> 1800 Saint-Laurent, Quebec, Canada H4L 4X4. </address>
Reference-contexts: It incorporated a head tracker, and could create the illusion of a surrounding 3D computer graphic environment. The graphics used were very simple monochrome 3D wire-frame images. The VCASS program at Wright-Patterson Air Force Base built many HMD prototypes as experimental pilot helmets <ref> (Buchroeder, Seeley, & Vukobradatovitch, 1981) </ref>. The Virtual Environment Workstation project at NASA Ames Research Center put together an HMD system in the mid-80's (Fisher, McGreevy, Humphries, & Robinett, 1986). Some of the early work on the display transform presented in this paper was done there.
Reference: <author> Caudell, T.P. and D.W. Mizell. </author> <year> (1992). </year> <title> Augmented reality: an application of heads-up display technology to manual manufacturing processes. </title> <booktitle> Proc. Hawaii International Conference on System Sciences. </booktitle>
Reference-contexts: VPL Research of Redwood City, California, began selling a commercial 2-user HMD system, called "Reality Built for 2," in 1989 (Blanchard, Burgess, Harvill, Lanier, Lasko, Oberman, & Teitel, 1990). A prototype see-through HMD targeted for manufacturing applications was built at Boeing in 1992 <ref> (Caudell & Mizell, 1992) </ref>. Its display algorithm and the measurement of the parameters of this algorithm is discussed in (Janin, Mizell & Caudell, 1993). Many other labs have set up HMD systems in the last few years.
Reference: <author> Cooke, J.M., M.J. Zyda, D.R. Pratt, and R.B. McGhee. </author> <year> (1992). </year> <title> NPSNET: Flight simulation dynamic modeling using quaternions. </title> <type> Presence 1(4). </type>
Reference-contexts: Again, this aspect of the VQS representation was motivated by the application to VR systems, which deal exclusively with 3D CSs. The advantages of the unit quaternion for representing 3D rotation are described in (Shoemake, 1985), (Funda, Taylor, & Paul, 90) and <ref> (Cooke, Zyda, Pratt & McGhee, 1992) </ref>.
Reference: <author> Craig, John. </author> <year> (1986). </year> <title> Introduction to robotics. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass. </address>
Reference-contexts: While geometric transformations have also been treated at length in both the computer graphics and robotics fields (Foley, van Dam, Feiner, & Hughes, 90), <ref> (Craig, 86) </ref>, (Paul, 81), these treatments are not geared toward the subtleties of stereoscopic viewing in a head-mounted display. Therefore, we hope this paper will be useful for those who want to implement the display code for a VR system. 3 .
Reference: <author> Fisher, S.S., McGreevy, M., Humphries, J., & Robinett, W. </author> <year> (1986). </year> <title> Virtual Environment Display System. </title> <booktitle> Proc. 1986 Workshop on Interactive 3D Graphics, </booktitle> <pages> 77-87. </pages>
Reference-contexts: The graphics used were very simple monochrome 3D wire-frame images. The VCASS program at Wright-Patterson Air Force Base built many HMD prototypes as experimental pilot helmets (Buchroeder, Seeley, & Vukobradatovitch, 1981). The Virtual Environment Workstation project at NASA Ames Research Center put together an HMD system in the mid-80's <ref> (Fisher, McGreevy, Humphries, & Robinett, 1986) </ref>. Some of the early work on the display transform presented in this paper was done there. Several see-through HMDs were built at the University of North Carolina, along with supporting graphics hardware, starting in 1986 (Holloway, 1987).
Reference: <author> Foley, J., A. van Dam, S. Feiner, J. Hughes. </author> <year> (1990). </year> <title> Computer Graphics: </title> <booktitle> Principles and Practice (2nd ed.). </booktitle> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Reading MA. </address> <pages> 222-226. </pages>
Reference-contexts: Display software was written to make these HMD systems function, but except for the Boeing HMD, we are not aware of any detailed, general description of the display transformation for HMD systems. While geometric transformations have also been treated at length in both the computer graphics and robotics fields <ref> (Foley, van Dam, Feiner, & Hughes, 90) </ref>, (Craig, 86), (Paul, 81), these treatments are not geared toward the subtleties of stereoscopic viewing in a head-mounted display. Therefore, we hope this paper will be useful for those who want to implement the display code for a VR system. 3 . <p> Definitions We will use the symbol T A_B to denote a transformation from coordinate system B to coordinate system A. This notation is similar to the notation T A B used in <ref> (Foley, van Dam, Feiner, & Hughes, 90) </ref>. We use the term A_B transform interchangeably with the symbol T A_B . Points will be represented as column vectors. <p> The other transform which it is convenient to further decompose is the Screen_Eye transform T S_E , which can be broken down into T S_E = T S_US T US_N T N_E (6.3) T S_US is the optical distortion correction transformation, T US_N is the 3D viewport transformation described in <ref> (Foley, van Dam, Feiner, & Hughes, 1990) </ref>, and T N_E is the normalizing perspective transformation. The 3D viewport transformation is the standard one normally used in computer graphics. <p> This usually requires an off-center perspective projection, since the user's eye is generally not lined up with the center of the screen in an HMD. perspective projection and is similar to that used in <ref> (Foley, van Dam, Feiner, & Hughes, 1990) </ref>. 1 9 VRP z near z p w x X - Z x cw screen image far clipping plane near plane FOV FOV In this diagram, the screen image defines the plane of projection and the eye is at the origin looking along the
Reference: <author> Fuchs, H., J. Poulton, J. Eyles, T. Greer, J. Goldfeather, D. Ellsworth, S. Molnar, G. </author> <title> Turk, </title> <publisher> B. </publisher>
Reference: <author> Tebbs and L. Israel. </author> <year> (1989). </year> <title> A heterogeneous multiprocessor graphics system using processor-enhanced memories. </title> <booktitle> Computer Graphics: Proceedings of SIGGRAPH '89. </booktitle> <address> 23:4:79 88. </address>
Reference: <author> Funda, Janez, R H Taylor, R P Paul. </author> <year> 1990. </year> <title> On homogeneous transforms, quaternions, and computational efficiency. </title> <journal> IEEE Trans. on robotics and automation. </journal> <volume> v6n3. </volume> <month> June. </month>
Reference-contexts: Again, this aspect of the VQS representation was motivated by the application to VR systems, which deal exclusively with 3D CSs. The advantages of the unit quaternion for representing 3D rotation are described in (Shoemake, 1985), <ref> (Funda, Taylor, & Paul, 90) </ref> and (Cooke, Zyda, Pratt & McGhee, 1992).
Reference: <author> Janin, A.L., D.W. Mizell and T.P. Caudell. </author> <year> (1993). </year> <title> Calibration of head-mounted displays for augmented reality applications. </title> <booktitle> IEEE Virtual Reality Annual International Symposium, </booktitle> <address> Seattle WA. 3 0 Holloway, R.L. </address> <year> (1987). </year> <type> Head-Mounted Display Technical Report. Technical report #TR87-015, </type> <institution> Dept. of Computer Science, University of North Carolina at Chapel Hill. </institution>
Reference-contexts: A prototype see-through HMD targeted for manufacturing applications was built at Boeing in 1992 (Caudell & Mizell, 1992). Its display algorithm and the measurement of the parameters of this algorithm is discussed in <ref> (Janin, Mizell & Caudell, 1993) </ref>. Many other labs have set up HMD systems in the last few years. <p> We believe, however, that accurate rendering of scenes in VR will become more important in the future as precision tasks are undertaken with HMDs. With see-through HMDs in particular, the need to accurately register virtual objects with the real world will demand accurate rendering <ref> (Janin, Mizell & Caudell, 1993) </ref>. What follows is a brief description of the distortion problem and one model for correcting it in software, with pointers to other papers on the subject.
Reference: <author> Holloway, R., H. Fuchs, W. Robinett. </author> <year> (1991). </year> <institution> Virtual-worlds research at the University of North Carolina at Chapel Hill. Proc. Computer Graphics 91. </institution> <address> London, England. </address>
Reference-contexts: For concreteness, we discuss the implementation of this display algorithm on the UNC VR system. The UNC VR software is based on a software library called Vlib. Vlib was designed by both authors and implemented by Holloway in early 1991. A brief overview is given in <ref> (Holloway, Fuchs & Robinett, 1991) </ref>. Vlib was originally written for use with PPHIGS, the graphics library for Pixel-Planes 5 (Fuchs, Poulton, Eyles, Greer, Goldfeather, Ellsworth, Molnar, Turk, Tebbs, & Israel, 1989), the graphics computer in the UNC VR system.
Reference: <author> Paul, Richard. </author> <year> (1981). </year> <title> Robot manipulators: Mathematics, programming, and control. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass. </address>
Reference-contexts: While geometric transformations have also been treated at length in both the computer graphics and robotics fields (Foley, van Dam, Feiner, & Hughes, 90), (Craig, 86), <ref> (Paul, 81) </ref>, these treatments are not geared toward the subtleties of stereoscopic viewing in a head-mounted display. Therefore, we hope this paper will be useful for those who want to implement the display code for a VR system. 3 .
Reference: <author> Pique, M. </author> <year> (1980). </year> <title> Nested Dynamic Rotations for Computer Graphics. M.S. </title> <type> Thesis, </type> <institution> University of North Carolina, Chapel Hill, NC. </institution>
Reference-contexts: The composition of two transforms is given by: T A_C = T A_B T B_C (3.2) and transforms a point in coordinate system C into coordinate system A. Note that the subscripts cancel, as in <ref> (Pique, 1980) </ref>, which makes complicated transforms easier to derive.
Reference: <author> Robinett,W., and J.P. Rolland. </author> <year> (1992). </year> <title> A computational model for the stereoscopic optics of a head-mounted display. Presence, </title> <type> 1(1). </type> <note> Also UNC Technical Report TR91-009. </note>
Reference: <author> Robinett, W., and R. Holloway. </author> <year> (1992). </year> <title> Implementation of flying, scaling, </title> <booktitle> and grabbing in virtual worlds. ACM Symposium on Interactive 3D Graphics, </booktitle> <address> Cambridge MA, </address> <month> March. </month>
Reference-contexts: A CS diagram for an early version of the UNC VR software was presented in (Brooks, 1989) and a later version in <ref> (Robinett & Holloway, 1992) </ref>. We represent a typical multiple-user VR system with the following graph: Right Eye n Right Screen n Room n Head n Left Eye n Left Screen n World Hand n Object 1 Object k . . . . <p> Exactly how these variables must be modified to implement the operations of flying through a virtual world, tilting the world, scaling the world, and grabbing virtual objects is discussed in detail in <ref> (Robinett & Holloway, 1992) </ref>. 7 . 3 Tracker-Base_Room Transform (Mounting Position of Tracker Base) The Tracker-Base_Room transform T TB_R = [v TB_R , q TB_R , 1] describes the position and orientation of the tracker base (often a transmitter) within the physical room where the VR system 1 6 is set <p> What follows is a brief description of the distortion problem and one model for correcting it in software, with pointers to other papers on the subject. As detailed in <ref> (Robinett & Rolland, 1992) </ref>, in systems with optical distortion, the magnification of a point in the image is a function of its distance from the optical axis. <p> Another approach is to use the exact closed-form solution to the third-order equation, as is done in (Rolland & Hopkins, 1993). Finally, a third-order approximation to the inverse gives a reasonable fit for many systems, and is described in <ref> (Robinett & Rolland, 1992) </ref>. The second method has been implemented at UNC for Pixel-Planes 5 by Anselmo Lastra, Jannick Rolland, and Terry Hopkins. We present the third method because of its algorithmic simplicity.
Reference: <author> Rolland, J. P., D. Ariely & W. Gibson. </author> <year> (1993). </year> <title> Towards quantifying depth and size perception in 3D virtual environments. </title> <note> To be published in Presence. Also Technical Report #TR93-044, </note> <institution> Dept. of Computer Science, University of North Carolina at Chapel Hill. </institution>
Reference-contexts: Wide-eyed and narrow-eyed people will perceive the same scene in an HMD to have different absolute sizes and distances <ref> (Rolland, Ariely, & Gibson, 1993) </ref>. To avoid this problem, the IPD for each user needs to be measured (with a device such as an optician uses) and the user's IPD needs to be entered into a calibration file specific to that user. <p> Another approach is to use the exact closed-form solution to the third-order equation, as is done in <ref> (Rolland & Hopkins, 1993) </ref>. Finally, a third-order approximation to the inverse gives a reasonable fit for many systems, and is described in (Robinett & Rolland, 1992). The second method has been implemented at UNC for Pixel-Planes 5 by Anselmo Lastra, Jannick Rolland, and Terry Hopkins. <p> of optical distortion normalized coefficient for predistortion normalizing radius in pixels * optical axis in screen coordinates (assuming 640 x 512 frame buffer viewport resolution) Table 8.1 Parameters of Vlib display transformation Many of the optical parameters listed were measured by Jannick Rolland of UNC, and some are derived in <ref> (Rolland & Hopkins, 1993) </ref>. The value for k pd was derived numerically. The paraxial * The normalizing radius used here is the distance in pixels from the optical axis to the top or bottom of the screen; the choice was arbitrary. <p> The value for k pd was derived numerically. The paraxial * The normalizing radius used here is the distance in pixels from the optical axis to the top or bottom of the screen; the choice was arbitrary. For simplicity, these figures neglect the pixel cropping problem detailed in <ref> (Rolland & Hopkins, 1993) </ref>. 2 8 and distorted figures are given for the window parameters since there is no single correct value for systems without distortion correction.
Reference: <author> Rolland, J. P. & T. Hopkins. </author> <year> (1993). </year> <title> A method of computational correction for optical distortion in head-mounted displays. </title> <type> Technical Report #TR93-045, </type> <institution> Computer Science Department, University of North Carolina at Chapel Hill. </institution> <note> (Available via anonymous ftp from ftp.cs.unc.edu.) </note> <author> Shoemake, K. </author> <year> (1985). </year> <title> Animating rotations using quaternion curves. </title> <booktitle> Computer Graphics: Proc. of SIGGRAPH '85. </booktitle> <pages> pp. 245-254. </pages> <institution> Silicon Graphics. </institution> <year> (1991). </year> <title> GL Reference Manual. Silicon Graphics, </title> <publisher> Inc., </publisher> <address> Mountain View CA. </address>
Reference-contexts: Wide-eyed and narrow-eyed people will perceive the same scene in an HMD to have different absolute sizes and distances <ref> (Rolland, Ariely, & Gibson, 1993) </ref>. To avoid this problem, the IPD for each user needs to be measured (with a device such as an optician uses) and the user's IPD needs to be entered into a calibration file specific to that user. <p> Another approach is to use the exact closed-form solution to the third-order equation, as is done in <ref> (Rolland & Hopkins, 1993) </ref>. Finally, a third-order approximation to the inverse gives a reasonable fit for many systems, and is described in (Robinett & Rolland, 1992). The second method has been implemented at UNC for Pixel-Planes 5 by Anselmo Lastra, Jannick Rolland, and Terry Hopkins. <p> of optical distortion normalized coefficient for predistortion normalizing radius in pixels * optical axis in screen coordinates (assuming 640 x 512 frame buffer viewport resolution) Table 8.1 Parameters of Vlib display transformation Many of the optical parameters listed were measured by Jannick Rolland of UNC, and some are derived in <ref> (Rolland & Hopkins, 1993) </ref>. The value for k pd was derived numerically. The paraxial * The normalizing radius used here is the distance in pixels from the optical axis to the top or bottom of the screen; the choice was arbitrary. <p> The value for k pd was derived numerically. The paraxial * The normalizing radius used here is the distance in pixels from the optical axis to the top or bottom of the screen; the choice was arbitrary. For simplicity, these figures neglect the pixel cropping problem detailed in <ref> (Rolland & Hopkins, 1993) </ref>. 2 8 and distorted figures are given for the window parameters since there is no single correct value for systems without distortion correction.
Reference: <author> Sutherland, I. E. </author> <year> (1968). </year> <title> A head-mounted three-dimensional display. </title> <booktitle> 1968 Fall Joint Computer Conference, AFIPS Conference Proceedings, </booktitle> <volume> 33, </volume> <pages> 757-764. VPL. </pages> <year> (1989). </year> <title> VPL EyePhone Operations Manual. VPL Research, </title> <address> 656 Bair Island Rd., Suite 304, Redwood City, California 94063, p. B-4. </address>
Reference-contexts: In doing so, we will introduce the vector-quaternion-scalar (VQS) representation for 3D transformations and will argue that this data structure is well suited for VR software. 2 . Related Work Sutherland built the first computer-graphics-driven HMD in 1968 <ref> (Sutherland, 1968) </ref>. One version of it was stereoscopic, with both a mechanical and a software adjustment for interpupillary distance. It incorporated a head tracker, and could create the illusion of a surrounding 3D computer graphic environment. The graphics used were very simple monochrome 3D wire-frame images.
Reference: <author> Woodson, W. E. </author> <year> (1981). </year> <title> Human factors design handbook. </title> <publisher> McGraw-Hill. </publisher>
Reference-contexts: CS, not vice versa.) Thus, for a given interpupillary distance (IPD), using the Head coordinate system described in Table 6.2 we have v LE_H = ( +IPD/2, 0, 0) There are considerable individual differences among the IPDs of adults, with 95% falling in the range from 49 to 75 mm <ref> (Woodson, 1981) </ref>. Wide-eyed and narrow-eyed people will perceive the same scene in an HMD to have different absolute sizes and distances (Rolland, Ariely, & Gibson, 1993).
References-found: 21

