URL: http://www.acm.org/jacm/papers/jacm968.ps
Refering-URL: http://www.acm.org/jacm/Upcoming.html
Root-URL: 
Title: Efficient Descriptor-Vector Multiplications in Stochastic Automata Networks  i=1  
Author: Paulo Fernandes Brigitte Plateau and William J. Stewart N X n i 
Keyword: Key words: Markov chains, Stochastic automata networks, Generalized tensor algebra, Vector-descriptor multiplication. IMAG-LMC  
Address: 38041 Grenoble cedex, France  Raleigh, N.C. 27695-8206, USA  
Affiliation: des Mathematiques  Department of Computer Science N. Carolina State University  
Note: N  100 rue  Research supported by the (CNRS INRIA INPG UJF) joint project Apache, and CAPES-COFECUB Agreement (Project 140/93).  Research supported in part by NSF (DDM-8906248 and CCR-9413309).  
Date: January 13, 1998  
Abstract: This paper examines numerical issues in computing solutions to networks of stochastic automata. It is well-known that when the matrices that represent the automata contain only constant values, the cost of performing the operation basic to all iterative solution methods, that of matrix-vector multiply, is given by where n i is the number of states in the i th automaton and N is the number of automata in the network. We introduce the concept of a generalized tensor product and prove a number of lemmas concerning this product. The result of these lemmas allows us to show that this relatively small number of operations is sufficient in many practical cases of interest in which the automata contain functional and not simply constant transitions. Furthermore, we show how the automata should be ordered to achieve this.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Abderezak. </author> <title> Resolution des Modeles Markoviens sur Machines a Memoires Distribuees. </title> <institution> These de Docteur de l'Institut National Polytechnique de Grenoble, </institution> <month> 21 September </month> <year> 1992, </year> <institution> Grenoble, France. </institution>
Reference-contexts: We simply point out a recent paper, [10], which provides vector and parallel algorithms for simple tensor products (when the automata are independent) and the PhD thesis, <ref> [1] </ref>, in which certains aspects of implementing the SAN software package, PEPS, [25], in parallel are discussed. 2 Basic Properties of Tensor Algebra Define two matrices A and B as follows: A = a 11 a 12 ! 0 @ b 21 b 22 b 23 b 24 1 A : <p> The operators and are not commutative. However, we shall have need of a pseudo-commutativity property that may be formalized as follows. Let be a permutation of the set of integer <ref> [1; 2; : : :; N ] </ref>. Then there exists a permutation matrix, P , of order Q N i=1 n i , such that N O A (k) = P k=1 : A proof of this property may be found in [24] wherein P is explicitly given. <p> Lemma 5.7 (GTP: Pseudo-Commutativity) Let be a permutation of the integers <ref> [1; 2; : : : ; N ] </ref>, then there exists a permutation matrix, P of order Q N i=1 n i , such that O N A (k) [A (1) ; : : : ; A (N) ] = P g k=1 : Proof: To prove this lemma we need <p> ; each block may in turn be viewed as formed from n 2 square blocks each of size Q N To refer to an individual element of X we use the notation x f (i 1 ;:::;i N );(j 1 ;:::;j N )g where i m ; j m 2 <ref> [1; : : :; n m ] </ref> and (i m ; j m ) indicates the position of the element in the m-th embedded block. Let be a permutation of the integer [1; 2; : : :; N ]. <p> Let be a permutation of the integer <ref> [1; 2; : : :; N ] </ref>. Then the individual elements of X may also be referenced with respect to this permutation and its corresponding embedded block structure. <p> Then the individual elements of X may also be referenced with respect to this permutation and its corresponding embedded block structure. We have x f (i 1 ;:::;i N ) ;(j 1 ;:::;j N ) g where i m ; j m 2 <ref> [1; : : :; n (m) ] </ref> 21 Nothing prevents us from mixing these two possibilities. <p> (i 1 ;:::;i N );(j 1 ;:::;j N )g = k=1 (k) (1) (N) Similarly, we may write the elements of X g k=1 as N Y a i (k) j (k) (a i 1 ; : : : ; a i n ): Since (k) is a bijection of <ref> [1; 2; : : :; N ] </ref>, a simple change of variable allows us to write the elements of X as N Y a i k j k (a i 1 ; : : : ; a i n ): (16) The proof of the lemma follows directly from equations (14),
Reference: [2] <author> K. </author> <month> Atif. </month> <institution> Modelisation du Parallelisme et de la Synchronisation. These de Docteur de l'Institut National Polytechnique de Grenoble, </institution> <month> 24 September </month> <year> 1992, </year> <institution> Grenoble, France. </institution>
Reference-contexts: In SANs, it is possible to make use use of symmetries as well as lumping 2 and various superpositioning of the automata to reduce the computational burden, <ref> [2, 9, 28] </ref>. Furthermore, in [16], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks. <p> The operators and are not commutative. However, we shall have need of a pseudo-commutativity property that may be formalized as follows. Let be a permutation of the set of integer <ref> [1; 2; : : :; N ] </ref>. Then there exists a permutation matrix, P , of order Q N i=1 n i , such that N O A (k) = P k=1 : A proof of this property may be found in [24] wherein P is explicitly given. <p> Lemma 5.7 (GTP: Pseudo-Commutativity) Let be a permutation of the integers <ref> [1; 2; : : : ; N ] </ref>, then there exists a permutation matrix, P of order Q N i=1 n i , such that O N A (k) [A (1) ; : : : ; A (N) ] = P g k=1 : Proof: To prove this lemma we need <p> Let be a permutation of the integer <ref> [1; 2; : : :; N ] </ref>. Then the individual elements of X may also be referenced with respect to this permutation and its corresponding embedded block structure. <p> (i 1 ;:::;i N );(j 1 ;:::;j N )g = k=1 (k) (1) (N) Similarly, we may write the elements of X g k=1 as N Y a i (k) j (k) (a i 1 ; : : : ; a i n ): Since (k) is a bijection of <ref> [1; 2; : : :; N ] </ref>, a simple change of variable allows us to write the elements of X as N Y a i k j k (a i 1 ; : : : ; a i n ): (16) The proof of the lemma follows directly from equations (14),
Reference: [3] <author> F. Baccelli, A. Jean-Marie and I. Mitrani, </author> <title> Editors, Quantitative Methods in Parallel Systems, Part I : Stochastic Process Algebras; Basic Research Series, </title> <publisher> Springer, </publisher> <year> 1995. </year>
Reference-contexts: The development of languages for specifying stochastic process algebras is mainly concerned with structural properties of the nets (compositionality, equivalence, etc.) and with the mapping of these specifications onto Markov chains for the computation of performance measures <ref> [20, 3, 7] </ref>. Although a SAN may be viewed as a stochastic process algebra, its original purpose was to provide an efficient and convenient methodology for the study of quantitive rather than structural properties of complex systems, [23].
Reference: [4] <author> G. Balbo, S.Bruell and M. Sereno. </author> <title> Arrival Theorems for Product-form Stochastic Petri Nets; Proc. </title> <booktitle> of ACM Sigmetrics Conference 1994, Nashville, </booktitle> <pages> pp. 87-97, </pages> <year> 1994. </year>
Reference-contexts: In [18], reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings. In [12], nearly independent subnets are exploited in an iterative procedure in which a global solution is obtained from partial solutions. In <ref> [6, 4] </ref> product forms are found in Petri nets models, using, in the first, the state space structure and in the second, flow properties. We note in passing that SANs can inherit from these results.
Reference: [5] <author> C. Berge. Graphes et Hypergraphes. Dunod, Paris, </author> <year> 1970. </year> <month> 32 </month>
Reference-contexts: Thus G contains an arc from node i to node j if and only if automaton A (i) depends on automaton A (j) . Let T be a cutset of the cycles of G, <ref> [5] </ref>. Then T is a set of nodes of G with the property that G T does not contain a cycle where G T is the graph of G with all arcs that lead into the nodes of T removed.
Reference: [6] <author> R. Boucherie. </author> <title> A Characterization of Independence for Competing Markov Chains with Applications to Stochastic Petri Nets. </title> <journal> IEEE Transactions on Soft. Eng., </journal> <volume> Vol 20, </volume> <pages> pp. 536-544, </pages> <year> 1994. </year>
Reference-contexts: In [18], reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings. In [12], nearly independent subnets are exploited in an iterative procedure in which a global solution is obtained from partial solutions. In <ref> [6, 4] </ref> product forms are found in Petri nets models, using, in the first, the state space structure and in the second, flow properties. We note in passing that SANs can inherit from these results.
Reference: [7] <author> P. Buchholz. </author> <title> Equivalence Relations for Stochastic Automata Networks. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: The development of languages for specifying stochastic process algebras is mainly concerned with structural properties of the nets (compositionality, equivalence, etc.) and with the mapping of these specifications onto Markov chains for the computation of performance measures <ref> [20, 3, 7] </ref>. Although a SAN may be viewed as a stochastic process algebra, its original purpose was to provide an efficient and convenient methodology for the study of quantitive rather than structural properties of complex systems, [23].
Reference: [8] <author> P. Buchholz. </author> <title> Aggregation and Reduction Techniques for Hierarchical GCSPNs. </title> <booktitle> Proceedings of the 5th International Workshop on Petri Nets and Performance Models, </booktitle> <address> Toulouse, France, </address> <publisher> IEEE Press, </publisher> <pages> pp. 216-225, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Furthermore, in [16], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks. For example, in <ref> [8, 9, 11, 17, 27, 29] </ref>, equivalence relations and symmetries are used to decrease the computational burden of obtaining performance indices. In [18], reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings.
Reference: [9] <author> P. Buchholz. </author> <title> Hierarchical Markovian Models Symmetries and Aggregation; Modelling Techniques and Tools for Computer Performance Evaluation, </title> <editor> Ed. R. Pooley, J.Hillston, </editor> <publisher> Edinburgh, Scotland, </publisher> <pages> pp. 234-246, </pages> <year> 1992. </year>
Reference-contexts: In SANs, it is possible to make use use of symmetries as well as lumping 2 and various superpositioning of the automata to reduce the computational burden, <ref> [2, 9, 28] </ref>. Furthermore, in [16], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks. <p> Furthermore, in [16], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks. For example, in <ref> [8, 9, 11, 17, 27, 29] </ref>, equivalence relations and symmetries are used to decrease the computational burden of obtaining performance indices. In [18], reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings.
Reference: [10] <author> P.Buis and W. Dyksen. </author> <title> Efficient Vector and Parallel Manipulation of Tensor Products. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> Vol. 22, </volume> <pages> pp. 18-23, </pages> <year> 1996. </year>
Reference-contexts: This is followed by some numerical experiments in Section 7 and our conclusions in Section 8. Although it is likely to be an important area for future research, we do not in this paper consider parallel or distributed versions of our algorithms. We simply point out a recent paper, <ref> [10] </ref>, which provides vector and parallel algorithms for simple tensor products (when the automata are independent) and the PhD thesis, [1], in which certains aspects of implementing the SAN software package, PEPS, [25], in parallel are discussed. 2 Basic Properties of Tensor Algebra Define two matrices A and B as follows:
Reference: [11] <author> G. Chiola, C. Dutheillet, G. Franceschinis and S. Haddad. </author> <title> Stochastic Well-Formed Colored Nets and Symmetric Modeling Applications. </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol 42, No. 11, </volume> <pages> pp. 1343-1360, </pages> <year> 1993. </year>
Reference-contexts: Furthermore, in [16], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks. For example, in <ref> [8, 9, 11, 17, 27, 29] </ref>, equivalence relations and symmetries are used to decrease the computational burden of obtaining performance indices. In [18], reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings.
Reference: [12] <author> G. Ciardo and K. Trivedi. </author> <title> Solution of Large GSPN Models. Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Marcel Dekker Publisher, </publisher> <address> New York, </address> <pages> pp. 565-595, </pages> <year> 1991. </year>
Reference-contexts: In [18], reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings. In <ref> [12] </ref>, nearly independent subnets are exploited in an iterative procedure in which a global solution is obtained from partial solutions. In [6, 4] product forms are found in Petri nets models, using, in the first, the state space structure and in the second, flow properties.
Reference: [13] <author> M. Davio. </author> <title> Kronecker Products and Shu*e Algebra. </title> <journal> IEEE Trans. Comput, </journal> <volume> Vol. C-30, No. 2, </volume> <pages> pp. 1099-1109, </pages> <year> 1981. </year>
Reference-contexts: Further information concerning the properties of tensor algebra may be found in Davio <ref> [13] </ref>. 3 Stochastic Automata Networks We consider a stochastic automata network that consists of N individual stochastic automata that act more or less independently of each other. <p> Remark: A direct consequence of these two lemmas is that for matrix with constant entries, the following product is commutative, (See also <ref> [13] </ref>). This property does not hold for matrices with functional entries.
Reference: [14] <author> S. Donatelli. </author> <title> Superposed Stochastic Automata: A Class of Stochastic Petri Nets with Parallel Solution and Distributed State Space. </title> <journal> Performance Evaluation, </journal> <volume> Vol. 18, </volume> <pages> pp. 21-36, </pages> <year> 1993. </year>
Reference-contexts: The conditions apply only to SANs with no synchronizing events. The first example considered in this paper, an example of resource sharing, has a product form solution, [26]. Finally, in <ref> [14] </ref> it is shown that the tensor structure of the transition matrix may be extracted from a stochastic Petri net, and in [21] that this can be used efficiently to work with the reachable state space in an iterative procedure.
Reference: [15] <author> P. Fernandes, B. Plateau and W.J. Stewart. </author> <title> Numerical Issues for Stochastic Automata Networks. </title> <note> INRIA Research Report No. 2938, July 1996. Available in potscript form by anonymous ftp from: ftp.inria.fr </note>
Reference-contexts: The use of functions may simplify the generation of complex state spaces and permit the efficient implementation of predicates that authorize the firing of transitions. Then, in the interests of numerical efficiency, it is possible, as shown in <ref> [15] </ref>, to automatically group automata in order to obtain the same model with fewer but larger automata. Collapsing the SAN into one group (the extreme case) is equivalent to building the complete transition matrix of the underlying Markov process. <p> In the extreme case, it completely eliminates all three. It has a negative effect: the memory needed to store the grouped SAN descriptor is increased. There is clearly a memory/time trade-off, as shown in <ref> [15] </ref>, when using a grouped tensor product approach. This trade-off can only be resolved, in a 12 practical sense, by testing each option in terms of the cost of the appropriately sized vector--matrix products. <p> Further details may be found in <ref> [15] </ref>. The general tendency is that as automata are pulled together into fewer, but larger groups, CPU time decreases and memory (for the descriptor) increases. In the first case, P = 13, the CPU time decreases right from the beginning because grouping removes function evaluations.
Reference: [16] <author> J-M. Fourneau and F. Quessette. </author> <title> Graphs and Stochastic Automata Networks. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: In SANs, it is possible to make use use of symmetries as well as lumping 2 and various superpositioning of the automata to reduce the computational burden, [2, 9, 28]. Furthermore, in <ref> [16] </ref>, structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks.
Reference: [17] <author> G. Franceschinis and R. Muntz. </author> <title> Computing Bounds for the Performance Indices of Quasi-lumpable Stochastic Well-Formed Nets. </title> <booktitle> Proceedings of the 5th International Workshop on Petri Nets and Performance Models, </booktitle> <address> Toulouse, France, </address> <publisher> IEEE Press, </publisher> <pages> pp. 148-157, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Furthermore, in [16], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks. For example, in <ref> [8, 9, 11, 17, 27, 29] </ref>, equivalence relations and symmetries are used to decrease the computational burden of obtaining performance indices. In [18], reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings.
Reference: [18] <author> W. Henderson and D. Lucic. </author> <title> Aggregation and Disaggregation through Insensitivity in Stochastic Petri Nets; Performance Evaluation, </title> <journal> Vol. </journal> <volume> 17, </volume> <pages> pp. 91-114, </pages> <year> 1993. </year>
Reference-contexts: We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks. For example, in [8, 9, 11, 17, 27, 29], equivalence relations and symmetries are used to decrease the computational burden of obtaining performance indices. In <ref> [18] </ref>, reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings. In [12], nearly independent subnets are exploited in an iterative procedure in which a global solution is obtained from partial solutions.
Reference: [19] <author> H. Hermanns and M. Rettelbach. </author> <title> Syntax, Semantics, Equivalences, and Axioms for MTIPP. </title> <booktitle> Proc. of the 2nd Workshop on Process Algebras and Performance Modelling, </booktitle> <editor> U. Herzog, M. Rettelbach, Editors, Arbeitsberichte, </editor> <volume> Band 27, No. 4, </volume> <pages> Erlangen, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Stochastic Automata Networks and the related concept of Stochastic Process Algebras, (SPA), have become a hot topic of research in recent years. This research has focused on areas such as the development of languages for specifying SANs and their ilk, <ref> [19, 20] </ref>, and on the development of suitable solution methods that can operate on the transition matrix given as a compact SAN descriptor.
Reference: [20] <author> J. Hillston. </author> <title> Computational Markovian Modelling using a Process Algebra. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: Stochastic Automata Networks and the related concept of Stochastic Process Algebras, (SPA), have become a hot topic of research in recent years. This research has focused on areas such as the development of languages for specifying SANs and their ilk, <ref> [19, 20] </ref>, and on the development of suitable solution methods that can operate on the transition matrix given as a compact SAN descriptor. <p> The development of languages for specifying stochastic process algebras is mainly concerned with structural properties of the nets (compositionality, equivalence, etc.) and with the mapping of these specifications onto Markov chains for the computation of performance measures <ref> [20, 3, 7] </ref>. Although a SAN may be viewed as a stochastic process algebra, its original purpose was to provide an efficient and convenient methodology for the study of quantitive rather than structural properties of complex systems, [23].
Reference: [21] <author> P. Kemper. </author> <title> Closing the Gap between Classical and Tensor Based Iteration Techniques. Computations with Markov Chains; Proceedings of the 2nd International Meeting on the Numerical Solution of Markov Chains, </title> <editor> W.J. Stewart, Ed., </editor> <publisher> Kluwer International Publishers, </publisher> <address> Boston, </address> <year> 1995. </year>
Reference-contexts: The first example considered in this paper, an example of resource sharing, has a product form solution, [26]. Finally, in [14] it is shown that the tensor structure of the transition matrix may be extracted from a stochastic Petri net, and in <ref> [21] </ref> that this can be used efficiently to work with the reachable state space in an iterative procedure. Once the number of states has effectively been fixed, the problem of memory and computation time still must be addressed, for the number of states left may still be large.
Reference: [22] <author> B. </author> <title> Plateau. On the Stochastic Structure of Parallelism and Synchronization Models for Distributed Algorithms. </title> <booktitle> Proc. ACM Sigmetrics Conference on Measurement and Modelling of Computer Systems, </booktitle> <address> Austin, Texas, </address> <month> August </month> <year> 1985. </year> <month> 33 </month>
Reference-contexts: Then, the part of the global infinitesimal generator that consists uniquely of local transitions may be obtained by forming the tensor sum of the matrices Q (1) (2) (N) a general rule, it is shown in <ref> [22] </ref>, that stochastic automata networks may always be treated by separating out the local transitions, handling these in the usual fashion by means of a tensor sum and then incorporating the sum of two additional tensor products per synchronizing event.
Reference: [23] <author> B. Plateau and K. Atif. </author> <title> Stochastic Automata Network for Modelling Parallel Systems. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. 17, No. 10, </volume> <pages> pp. 1093-1108, </pages> <year> 1991. </year>
Reference-contexts: Although a SAN may be viewed as a stochastic process algebra, its original purpose was to provide an efficient and convenient methodology for the study of quantitive rather than structural properties of complex systems, <ref> [23] </ref>. Nevertheless, computational results such as those presented in this paper can also be applied in the context of stochastic process algebras. <p> This shows that Theorem 5.2 is only needed when the routing probabilities associated with a synchronizing event are functional and result in cycles within the functional dependency graph, (which we suspect to be rather rare). For SANs in discrete-time, <ref> [23] </ref>, it seems that we may not be so fortunate since cycles in the functional dependency graph of the tensor product tend to occur rather more often. 27 7 Numerical Experiments Our purpose in this section is to provide a measure of the cost of using the SAN methodology. <p> experiments respectively. 7.1 Experiment Set #1 The first set of experiments has two objectives: * To examine the benefits of using a sparse format as compared to a full storage format. * To compare the method presented in this paper for handling functions with the decompo sition approach discussed in <ref> [23] </ref>. For these experiments, the value of N in the Mutex example was taken to be 14 and the value of P was assigned the values P = 14, 13, 8, 1. <p> The difference is due to the fact that in both methods, the diagonal is extracted and treated apart. So the gain is visible, the sparse version takes advantage of the zeros in the diagonal. In the column "PEPS/Old version", the function handling procedure described in <ref> [23] </ref> is used to handle the functions. The results are significantly worse except in the case when P = 1. In this case, the reachable state space is very small, and so the decompositional method of handling functions results in a small number of functionless terms.
Reference: [24] <author> B. Plateau and J.M. Fourneau. </author> <title> A Methodology for Solving Markov Models of Parallel Systems. </title> <journal> Journal of Parallel and Distributed Computing. </journal> <volume> Vol. 12, </volume> <pages> pp. 370-387, </pages> <year> 1991. </year>
Reference-contexts: Then there exists a permutation matrix, P , of order Q N i=1 n i , such that N O A (k) = P k=1 : A proof of this property may be found in <ref> [24] </ref> wherein P is explicitly given. Further information concerning the properties of tensor algebra may be found in Davio [13]. 3 Stochastic Automata Networks We consider a stochastic automata network that consists of N individual stochastic automata that act more or less independently of each other. <p> This is the concept behind the extended tensor algebraic approach, <ref> [24] </ref>. The descriptor is still written as in equation (3), but now the elements of Q (i) j may be functions. This means that it is necessary to track elements that are functions and to substitute (or recompute) the appropriate numerical value each time the functional rate is needed. <p> A proof of the theorem is given in <ref> [24] </ref> and is based on the following tensor product decomposition. y = x fi N N Y I n 1 I n i1 Q (i) I n i+1 I n N N Y I 1:i1 Q (i) I i+1:N : (4) The individual terms within the product, (i.e., the I 1:i1 <p> =n i iterations, and the outermost i loop is executed N times, the total operation count is given by N X Q N n i n 2 N Y n i fi i=1 23 2 This complexity result improves upon previous results given in the paper by Fourneau et al., <ref> [24] </ref>. For example, given a tensor product with two terms, we have A (1) g A (2) [A (1) ] with a complexity of n 1 n 2 (n 1 + n 2 ) given by Theorem 5.1, whereas previously using the procedures given in [24] the complexity is n 1 <p> paper by Fourneau et al., <ref> [24] </ref>. For example, given a tensor product with two terms, we have A (1) g A (2) [A (1) ] with a complexity of n 1 n 2 (n 1 + n 2 ) given by Theorem 5.1, whereas previously using the procedures given in [24] the complexity is n 1 n 2 (n 1 + n 1 n 2 ). Naturally, this generalizes to the case of m terms. <p> The first of these may be thought of as representing the actual transitions and their rates, and the second corresponds to an updating of the diagonal elements in the infinitesimal generator to reflect these transitions. 26 More detailed information may be found in <ref> [24] </ref>.
Reference: [25] <author> B. Plateau, J.M. Fourneau and K.H. Lee. PEPS: </author> <title> A Package for Solving Complex Markov Models of Parallel Systems. </title> <editor> In R. Puigjaner, D. Potier, Eds., </editor> <title> Modelling Techniques and Tools for Computer Performance Evaluation, </title> <address> Spain, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: We simply point out a recent paper, [10], which provides vector and parallel algorithms for simple tensor products (when the automata are independent) and the PhD thesis, [1], in which certains aspects of implementing the SAN software package, PEPS, <ref> [25] </ref>, in parallel are discussed. 2 Basic Properties of Tensor Algebra Define two matrices A and B as follows: A = a 11 a 12 ! 0 @ b 21 b 22 b 23 b 24 1 A : The tensor product C = A B is given by C = <p> As we have mentioned before, no one approach will work best in all modelling situations, but each has its niche, and we wish to use these experiments to identify and to a certain extent quantify, the advantages of the SAN approach. The software package PEPS, <ref> [25] </ref>, was used to generate the results concerning both the sparse matrix approach and those concerning SANs. All experiments were run on an IBM RS6000-370 under AIX version 4.2 with 96 Mbytes of RAM and 230 Mbytes of virtual memory.
Reference: [26] <author> B. Plateau and W.J. Stewart. </author> <title> Stochastic Automata Networks: Product Forms and Iterative Solutions. </title> <note> INRIA Research Report No. 2939, July 1996. Available in potscript form by anonymous ftp from: ftp.inria.fr </note>
Reference-contexts: In [6, 4] product forms are found in Petri nets models, using, in the first, the state space structure and in the second, flow properties. We note in passing that SANs can inherit from these results. For example, in <ref> [26] </ref>, the results of Boucherie are extended and applied to determine sufficient conditions for a SAN to have a product form. This is accomplished by working on the global balance equations and seeking out sufficient conditions on the functional transition rates to obtain a product form solution. <p> The conditions apply only to SANs with no synchronizing events. The first example considered in this paper, an example of resource sharing, has a product form solution, <ref> [26] </ref>. Finally, in [14] it is shown that the tensor structure of the transition matrix may be extracted from a stochastic Petri net, and in [21] that this can be used efficiently to work with the reachable state space in an iterative procedure.
Reference: [27] <author> W.H. Sanders and J.F. Meyer. </author> <title> Reduced Base Model Construction Methods for Stochastic Activity Networks, </title> <journal> IEEE Jour. on Selected Areas in Communication, </journal> <volume> Vol. 9, No. 1, </volume> <pages> pp. 25-36, </pages> <year> 1991. </year>
Reference-contexts: Furthermore, in [16], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks. For example, in <ref> [8, 9, 11, 17, 27, 29] </ref>, equivalence relations and symmetries are used to decrease the computational burden of obtaining performance indices. In [18], reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings.
Reference: [28] <author> M. Siegle. </author> <title> On Efficient Markov Modelling. </title> <booktitle> In Proc. QMIPS Workshop on Stochastic Petri Nets, </booktitle> <pages> pp. 213-225, </pages> <address> Sophia-Antipolis, France, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: In SANs, it is possible to make use use of symmetries as well as lumping 2 and various superpositioning of the automata to reduce the computational burden, <ref> [2, 9, 28] </ref>. Furthermore, in [16], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks.
Reference: [29] <author> C. Simone and M.A. Marsan. </author> <title> The Application of the EB-Equivalence Rules to the Structural Reduction of GSPN Models. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 15, No. 3, </volume> <pages> pp. 296-302, </pages> <year> 1991. </year>
Reference-contexts: Furthermore, in [16], structural properties of the Markov chain graph (specificially the occurrence of cycles) are used to compute steady state solutions. We point out that similar, and even more extensive results have previously been developed in the context of Petri nets and stochastic activity networks. For example, in <ref> [8, 9, 11, 17, 27, 29] </ref>, equivalence relations and symmetries are used to decrease the computational burden of obtaining performance indices. In [18], reduction techniques for Petri nets are used in conjunction with insensitivity results to enable all computations to be performed on a reduced set of markings.
Reference: [30] <author> W.J. Stewart. </author> <title> An Introduction to the Numerical Solution of Markov Chains, </title> <publisher> Princeton University Press, </publisher> <address> New Jersey, </address> <year> 1994. </year>
Reference: [31] <author> W.J. Stewart. marca: </author> <title> Markov Chain Analyzer. </title> <journal> IEEE Computer Repository No. </journal> <volume> R76 232, </volume> <year> 1976. </year> <note> Also IRISA Publication Interne No. 45, </note> <institution> Universite de Rennes, France. </institution>
Reference-contexts: We refer to this latter as the sparse matrix approach and use a procedure in C++ inspired from the software package Marca, <ref> [31] </ref>. As we have mentioned before, no one approach will work best in all modelling situations, but each has its niche, and we wish to use these experiments to identify and to a certain extent quantify, the advantages of the SAN approach.
Reference: [32] <author> W.J. Stewart, K. Atif and B. </author> <title> Plateau. The Numerical Solution of Stochastic Automata Networks. </title> <journal> European Journal of Operations Research, </journal> <volume> Vol. 86, No. 3, </volume> <pages> pp. 503-525, </pages> <year> 1995. </year> <month> 34 </month>
Reference-contexts: The number of iterations needed to compute the solution to a required accuracy depends on the method chosen. In a previous paper, <ref> [32] </ref>, it was shown how projection methods such as Arnoldi and GMRES could be used to substantially reduce the number of iterations needed when compared with the basic power method. <p> Notice also that the state space represented in the matrix Q may contain unreachable 6 states. For more information on the structure and properties of these matrices, the interested reader is invited to consult <ref> [32] </ref>. The computational burden imposed by synchronizing events is two-fold. First, the number of terms in the descriptor is increased, | two for each synchronizing event. A second and even greater burden is that the simple form of the solution, as a tensor product of independent solutions, no longer holds. <p> products, is unchanged and hence the results presented in this paper remain valid and useful. 4 Computing Probability Distributions When the global infinitesimal generator of a SAN is available only in the form of a SAN descriptor, equation (3), the numerical methods most suitable to obtaining probability distributions are iterative, <ref> [32] </ref>. Thus, the underlying operation, whether we wish to compute the stationary distribution, or the transient solution at any time t, is the product of a vector with a matrix. <p> With functional rates, the elements in the matrices may change according to their context so that this same savings is not always possible. It was previously observed in <ref> [32] </ref> that in the case of two automata A and B with matrix representations A and B [A] respectively, where to anticipate the introduction of some new notation, B [A] indicates that the matrix B contains elements that may be a function of the state of A, the number of multiplications
References-found: 32

