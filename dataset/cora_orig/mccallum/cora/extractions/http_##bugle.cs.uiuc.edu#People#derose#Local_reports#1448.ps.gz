URL: http://bugle.cs.uiuc.edu/People/derose/Local_reports/1448.ps.gz
Refering-URL: http://bugle.cs.uiuc.edu/People/derose/falcon_publications.html
Root-URL: http://www.cs.uiuc.edu
Title: In  FALCON: A MATLAB Interactive Restructuring Compiler  
Author: C.-H. Huang, P.Sadayappan, U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua L. DeRose, K. Gallivan, E. Gallopoulos, B. Marsolf and D. Padua 
Address: 1308 West Main Street Urbana, Illinois 61801  
Date: September 1995  
Affiliation: Columbus OH.)  Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Note: (Editors), Languages and Compilers for Parallel Computing, pages 269-288. Springer-Verlag, August 1995. (8th International Workshop, LCPC'95,  
Pubnum: CSRD Report No. 1448  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> Aho, A., Sethi, R., and Ullman, J. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: Type Inference To generate Fortran declarations and to support structure selection, the system infers variable properties. Although described separately here, shape and structure inference work in coordination with the coverage analysis discussed in the previous subsection. Variable properties are estimated using a forward/backward scheme <ref> [1] </ref>. For type inference, we use a type algebra similar to the one described in [28] for SETL. This algebra operates on the type of the MATLAB objects and is implemented using tables for all operations.
Reference: 2. <author> Amarasinghe, S. P., Anderson, J. M., Lam, M. S., and Lim, A. W. </author> <title> An Overview of a Compiler for Scalable Parallel Machines. In Languages and Compilers for Parallel Computing (August 1993), </title> <editor> U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, Eds., </editor> <publisher> Springer-Verlag, </publisher> <pages> pp. 253-272. </pages> <booktitle> 6th International Workshop, </booktitle> <address> Portland, Oregon. </address>
Reference-contexts: This difficulty holds true even when the objective is to develop code for a single target machine. Several approaches to facilitate the development and maintenance of parallel code are currently under study. One approach is the automatic translation of conventional programming languages, notably Fortran, into parallel form. SUIF <ref> [2] </ref>, a compiler developed at Stanford, and Parafrase-2 [27] and Polaris [25], developed at Illinois, are examples of this first approach. Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions.
Reference: 3. <institution> Applied Parallel Research. </institution> <note> FORGE Explorer User's Guide. Placerville, Cal-ifornia, 1995. Version 2.0. </note>
Reference-contexts: There has been some work on interactive program restructuring and there are some commercially available interactive Fortran restructurers, such as FORGE <ref> [3] </ref>. Also, restructuring of high-level operators has been discussed in the literature [4, 12], although there are no widely-used systems that apply these types of transformations, as no system today includes capabilities for algebraic, control structure, and library selection transformations.
Reference: 4. <author> Backus, J. </author> <title> Can Programming Be Liberated from the Von Neumann Style? A Functional Style and Its Algebra of Programs. </title> <journal> Communications of the ACM 21, </journal> <month> 8 (August </month> <year> 1978), </year> <pages> 613-641. </pages>
Reference-contexts: There has been some work on interactive program restructuring and there are some commercially available interactive Fortran restructurers, such as FORGE [3]. Also, restructuring of high-level operators has been discussed in the literature <ref> [4, 12] </ref>, although there are no widely-used systems that apply these types of transformations, as no system today includes capabilities for algebraic, control structure, and library selection transformations. We are planning on implementing several restructuring techniques for complex transformations on the code.
Reference: 5. <author> Barrett, R., Berry, M., Chan, T., Demmel, J., Donato, J., Dongarra, J., Eijkhout, V., Pozo, R., Romine, C., and van der Vorst, H. </author> <title> Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods. </title> <publisher> SIAM, </publisher> <year> 1993. </year>
Reference-contexts: The main characteristic of these programs is that none of the variables are referenced or assigned using indices (i.e. only array operations on whole arrays are present). These code segments correspond to the following algorithms presented in <ref> [5] </ref> for the iterative solution of linear systems: the Conjugate Gradient method (CG), the Quasi-Minimal Residual method (QMR), and the Successive Overrelaxation method (SOR). The programs were tested using a 420fi420 stiffness matrix from the Harwell-Boeing Test Set.
Reference: 6. <author> Blume, W., and Eigenmann, R. </author> <title> The Range Test: A Dependence Test for Symbolic, Non-linear Expressions. </title> <booktitle> In Proceedings of Supercomputing '94 (November 1994), </booktitle> <pages> pp. 528-537. </pages>
Reference-contexts: It also makes use of a number of conventional analysis algorithms, including induction variable recognition [18] to compute upper and lower bounds of these variables, and propagation of the range of values of scalars and of those arrays used as subscripts <ref> [6, 13] </ref>. This analysis is performed interprocedurally whenever the modules referenced in the program are available to the system. In the case of intrinsic functions, information on the elements accessed are available in a database that is consulted during the computation of ranges.
Reference: 7. <author> Bodin, F., Beckman, P., Gannon, D., Narayana, S., and Yang, S. </author> <title> Distributed pC++: Basic Ideas for an Object Parallel Language. </title> <booktitle> In OON-SKI'93 Proceedings of the First Annual Object-Oriented Numerics Conference (April 1993), </booktitle> <pages> pp. 1-24. </pages>
Reference-contexts: Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran [19] and pC++ <ref> [7] </ref>. Finally, a third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel.
Reference: 8. <author> Budd, T. </author> <title> An APL Compiler. </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: Previous work on type inference has been done for several high-level languages. In particular, type inference techniques developed for SETL [28] and APL <ref> [8, 11] </ref> Fig. 1. Program development environment. are most relevant to our work. These two languages are similar to MATLAB in that they can be executed interactively, are usually interpreted, and operate on aggregate data structures. <p> This last problem, which seems to be ignored by current APL compilers <ref> [8, 11] </ref>, is illustrated by the pseudocode segment in Figure 2. In this case, the compiler needs to determine if the partial assignment to A is a subrange of the previous definitions of the variable. If not, reallocating A may be necessary.
Reference: 9. <author> Carr, S., and Kennedy, K. </author> <title> Compiler Blockability of Numerical Algorithms. </title> <booktitle> In Proceedings, Supercomputing '92 (November 1992), </booktitle> <pages> pp. 114-124. </pages>
Reference-contexts: These additional operations were generated by utilizing the definition of the transform; they would not have been apparent by just examining the code. This utilization of algebraic information is being performed not only by algorithm developers, but is also being explored by compiler writers <ref> [9] </ref>. The transformations will be based on patterns that the system can recognize in the code and on the replacements for these patterns. The developer will be able to select a segment of code and the system will indicate which patterns match the segment.
Reference: 10. <author> Char, B. W., Geddes, K. O., Gonnet, G. H., Leong, B. L., Monagan, M. B., and Watt, S. M. </author> <title> Maple V Language Reference Manual. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Algebraic Restructuring This part of the system will use the algebraic rules defined for the variables, whether they are scalars, vectors, or matrices, to restructure the operations performed on the variables. To perform such manipulations, symbolic computation tools, such as Maple <ref> [10] </ref>, can be employed. In some cases, applying these rules may be similar to the standard loop-based restructuring strategies used by conventional restructuring compilers, such as loop blocking. However, we also want to be able to handle special matrix classes and more complex operators.
Reference: 11. <author> Ching, W.-M. </author> <title> Program Analysis and Code Generation in an APL/370 Compiler. </title> <journal> IBM Journal of Research and Development 30:6 (November 1986), </journal> <pages> 594-602. </pages>
Reference-contexts: Previous work on type inference has been done for several high-level languages. In particular, type inference techniques developed for SETL [28] and APL <ref> [8, 11] </ref> Fig. 1. Program development environment. are most relevant to our work. These two languages are similar to MATLAB in that they can be executed interactively, are usually interpreted, and operate on aggregate data structures. <p> This last problem, which seems to be ignored by current APL compilers <ref> [8, 11] </ref>, is illustrated by the pseudocode segment in Figure 2. In this case, the compiler needs to determine if the partial assignment to A is a subrange of the previous definitions of the variable. If not, reallocating A may be necessary.
Reference: 12. <author> Cook Jr., G. O. </author> <title> ALPAL A Tool for the Development of Large-Scale Simulation Codes. </title> <type> Tech. rep., </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> August </month> <year> 1988. </year> <note> Technical Report UCID-21482. </note>
Reference-contexts: Examples include High Performance Fortran [19] and pC++ [7]. Finally, a third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel. Examples of this approach are //ELLPACK [20], developed at Purdue, AL-PAL <ref> [12] </ref>, developed at Lawrence Livermore Laboratories, and EXTENT [15], developed at Ohio State University. FALCON is a programming environment that includes capabilities for interactive and automatic transformations at both the operation-level and the function- or algorithmic-level. <p> There has been some work on interactive program restructuring and there are some commercially available interactive Fortran restructurers, such as FORGE [3]. Also, restructuring of high-level operators has been discussed in the literature <ref> [4, 12] </ref>, although there are no widely-used systems that apply these types of transformations, as no system today includes capabilities for algebraic, control structure, and library selection transformations. We are planning on implementing several restructuring techniques for complex transformations on the code.
Reference: 13. <author> Cousot, P., and Halbwachs, N. </author> <title> Automatic Discovery of Linear Restraints Among Variables of a Program. </title> <booktitle> In Proceedings of the 5th Anual ACM Symposium on Principles of Programming Languages (1978), </booktitle> <pages> pp. 84-97. </pages>
Reference-contexts: It also makes use of a number of conventional analysis algorithms, including induction variable recognition [18] to compute upper and lower bounds of these variables, and propagation of the range of values of scalars and of those arrays used as subscripts <ref> [6, 13] </ref>. This analysis is performed interprocedurally whenever the modules referenced in the program are available to the system. In the case of intrinsic functions, information on the elements accessed are available in a database that is consulted during the computation of ranges.
Reference: 14. <author> Cytron, R., Ferrante, J., Rosen, B. K., Wegman, M. N., and Zadeck, F. K. </author> <title> Efficiently Computing Static Single Assignment Form and the Control Dependence Graph. </title> <journal> ACM Transactions on Programming Language and Systems 13, </journal> <month> 4 (October </month> <year> 1991), </year> <pages> 451-490. </pages>
Reference-contexts: The use of this high-level information should greatly increase the accuracy of the analysis over the approach used in conventional high-level language compilers, where only the information from elementary operations is used. Use-Definition Coverage The MATLAB program is internally represented in Static Single Assignment (SSA) form <ref> [14] </ref>. This is a convenient representation for many of the analysis algorithms that are implemented. In the SSA representation, it is evident which definitions affect (or cover) a particular use of a scalar variable. Using this information, it is easy to perform variable renaming and pri-vatization.
Reference: 15. <author> Dai, D. L., Gupta, S. K. S., Kaushik, S. D., Lu, J. H., Singh, R. V., Huang, C.-H., Sadayappan, P., and Johnson, R. W. </author> <title> EXTENT: A Portable Programming Environment for Designing and Implementing High-Performance Block-Recursive Algorithms. </title> <booktitle> In Proceedings of Supercomputing '94 (November 1994), </booktitle> <pages> pp. 49-58. </pages>
Reference-contexts: Finally, a third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel. Examples of this approach are //ELLPACK [20], developed at Purdue, AL-PAL [12], developed at Lawrence Livermore Laboratories, and EXTENT <ref> [15] </ref>, developed at Ohio State University. FALCON is a programming environment that includes capabilities for interactive and automatic transformations at both the operation-level and the function- or algorithmic-level.
Reference: 16. <author> DeRose, L., Gallivan, K., Gallopoulos, E., Marsolf, B., and Padua, D. </author> <title> An Environment for the Rapid Prototyping and Development of Numerical Programs and Libraries for Scientific Computation. </title> <booktitle> In Proc. of the DAGS'94 Symposium: Parallel Computation and Problem Solving Environments (Dartmouth College, </booktitle> <month> July </month> <year> 1994), </year> <editor> F. Makedon, </editor> <publisher> Ed., </publisher> <pages> pp. 11-25. </pages>
Reference-contexts: This environment supports the development of high-performance numerical programs and libraries, combining the transformation and analysis techniques used in restructuring compilers with the algebraic techniques used by developers to express and manipulate their algorithms in an intuitively useful manner <ref> [16] </ref>. As we envision it, the development process should start with a simple prototype of the algorithm and then continue with a sequence of automatic and interactive transformations until an effective program or routine is obtained.
Reference: 17. <author> Gallivan, K., and Marsolf, B. </author> <title> Practical Issues Related to Developing Object-Oriented Numerical Libraries. </title> <booktitle> In OON-SKI'94 Proceedings of the Second Annual Object-Oriented Numerics Conference (April 1994), </booktitle> <pages> pp. 93-106. </pages>
Reference-contexts: Pattern for loop interchange. Primitive-set Translation Primitive-set translation can also be used to translate the code to the level of numerical operations that work best for the target machine and application <ref> [17] </ref>. Instead of dealing with the code only at a matrix operation level, this phase will be able to decompose the algorithms to matrix-vector operations and vector-vector operations; or, in some circumstances, it will form higher-level operations by combining multiple lower-level operations.
Reference: 18. <author> Gerlek, M. P., Stoltz, E., and Wolfe, M. </author> <title> Beyond Induction Variables: Detecting and Classifying Sequences Using a Demand-driven SSA Form. </title> <note> ACM TOPLAS (to appear). </note>
Reference-contexts: The strategy uses data flow analysis to determine which definitions cover the uses of array elements. It also makes use of a number of conventional analysis algorithms, including induction variable recognition <ref> [18] </ref> to compute upper and lower bounds of these variables, and propagation of the range of values of scalars and of those arrays used as subscripts [6, 13]. This analysis is performed interprocedurally whenever the modules referenced in the program are available to the system.
Reference: 19. <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <month> May </month> <year> 1993. </year> <note> Version 1.0. </note>
Reference-contexts: Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran <ref> [19] </ref> and pC++ [7]. Finally, a third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel.
Reference: 20. <author> Houstis, E. N., Rice, J. R., Chrisochoides, N. P., Karathanasis, H. C., Pa-pachiou, P. N., Samartzis, M. K., Vavalis, E. A., Wang, K. Y., and Weer-awarana, S. </author> <title> //ELLPACK: A Numerical Simulation Programming Environment for Parallel MIMD Machines. </title> <booktitle> In Proceedings 1990 International Conference on Supercomputing (1990), </booktitle> <pages> pp. 96-107. </pages>
Reference-contexts: Examples include High Performance Fortran [19] and pC++ [7]. Finally, a third approach is to accept a very high-level description of the mathematical problem to be solved and automatically compute the solution in parallel. Examples of this approach are //ELLPACK <ref> [20] </ref>, developed at Purdue, AL-PAL [12], developed at Lawrence Livermore Laboratories, and EXTENT [15], developed at Ohio State University. FALCON is a programming environment that includes capabilities for interactive and automatic transformations at both the operation-level and the function- or algorithmic-level.
Reference: 21. <author> Kuck and Associates, Inc. </author> <title> KAP User's Guide, </title> <booktitle> 4th ed. </booktitle> <address> Savoy, IL 61874, </address> <year> 1987. </year>
Reference-contexts: Furthermore, the code generator will also produce a MATLAB program. The actual generation of parallel code will be done by a restructuring compiler, such as Polaris [25] or KAP <ref> [21] </ref>. Our system facilitates the translation into parallel form by annotating the target Fortran program and by using array operations whenever possible. Furthermore, the Fortran restructurer should be capable of applying transformations automatically whenever possible, thereby saving the user of the interactive restructurer additional work.
Reference: 22. <author> The Math Works, Inc. </author> <title> MATLAB, High-Performance Numeric Computation and Visualization Software. User's Guide, </title> <year> 1992. </year>
Reference-contexts: The ideal interactive array language should be easy to learn and capable of accessing powerful graphics and other I/O facilities. We are using an existing language in order to shorten the learning curve for our system and give us immediate access to existing support routines. APL and MATLAB <ref> [22] </ref> are the most widely used interactive array languages today. We have chosen MAT-LAB because it is the more popular of the two and has a conventional syntax that facilitates learning it. In MATLAB, as in any interactive array language, the type, rank and shape of variables are dynamically determined.
Reference: 23. <author> Mathews, J. H. </author> <title> Numerical Methods for Mathematics, </title> <booktitle> Science and Engineering, 2nd ed. </booktitle> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: using Simpson's rule a 1 Dim. (7) Dirichlet solution to Laplace's equation a 26 fi 26 Crank-Nicholson solution to the heat equation a 321 fi 321 Finite difference solution to the wave equation a 321 fi 321 Computation of the inverse Hilbert matrix c 180 fi 180 Source: a From <ref> [23] </ref>; b Colleagues; c The MathWorks Inc, as a M-File (invhilb.m). Table 2. List of test programs for indexed variables SPARCstation 10 Convex C-240 Algorithm MATLAB F 90 Speedup MATLAB F 90 Speedup QL method 8.8 3.17 2.8 NA NA NA 3D-Surface 17.1 2.95 5.8 NA NA NA Inc.
Reference: 24. <author> Muraoka, Y., and Kuck, D. J. </author> <title> On the Time Required for a Sequence of Matrix Products. </title> <journal> Communications of the ACM 16, </journal> <month> 1 (January </month> <year> 1973), </year> <pages> 22-26. </pages>
Reference-contexts: For example, A fl B may be possible whereas B fl A may not be possible. Furthermore, the order in which matrix operations are performed can have a significant effect on the number of operations to be performed <ref> [24] </ref>. Consider the multiplication of x T i A i x T j A j (a) i = v T Y i = 2v i x T x T j A j j v i i (b) Fig. 3.
Reference: 25. <author> Padua, D., Eigenmann, R., Hoeflinger, J., Petersen, P., Tu, P., Weath-erford, S., and Faigin, K. </author> <title> Polaris: A New-Generation Parallelizing Compiler for MPP's. </title> <type> Tech. rep., </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> June </month> <year> 1993. </year> <note> CSRD Report No. 1306. </note>
Reference-contexts: Several approaches to facilitate the development and maintenance of parallel code are currently under study. One approach is the automatic translation of conventional programming languages, notably Fortran, into parallel form. SUIF [2], a compiler developed at Stanford, and Parafrase-2 [27] and Polaris <ref> [25] </ref>, developed at Illinois, are examples of this first approach. Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran [19] and pC++ [7]. <p> The code generator makes use of the information gathered by the program analysis phase to generate a Fortran 90 program or routine. Furthermore, the code generator will also produce a MATLAB program. The actual generation of parallel code will be done by a restructuring compiler, such as Polaris <ref> [25] </ref> or KAP [21]. Our system facilitates the translation into parallel form by annotating the target Fortran program and by using array operations whenever possible. Furthermore, the Fortran restructurer should be capable of applying transformations automatically whenever possible, thereby saving the user of the interactive restructurer additional work.
Reference: 26. <author> Padua, D., and Wolfe, M. </author> <title> Advanced Compiler Optimizations for Supercomputers. </title> <journal> Communications of the ACM 29, </journal> <month> 12 (December </month> <year> 1986), </year> <pages> 1184-1201. </pages>
Reference-contexts: In Figure 6, a pattern for interchanging loops shows how certain dependence conditions can be placed on the matching of the loop body. In this example, the loops can be interchanged only if the data dependences do not contain a direction vector of the form &lt;,&gt; <ref> [26] </ref>. REPLACE INTEGER i,j do i = 1:n &lt;BODY&gt; WHERE no-match-direction-vector ("&lt;; &gt;", dependence (&lt;BODY&gt;)) END end WITH INTEGER i,j do j = 1:n &lt;BODY&gt; end END Fig. 6. Pattern for loop interchange.
Reference: 27. <author> Polychronopoulos, C., Girkar, M., Haghighat, M. R., Lee, C.-L., Leung, B., and Schouten, D. </author> <title> Parafrase-2: A New Generation Parallelizing Compiler. </title> <booktitle> In Proceedings of 1989 Int'l. Conference on Parallel Processing, </booktitle> <address> St. Charles, IL (August 1989), </address> <booktitle> vol. II, </booktitle> <pages> pp. 39-48. </pages>
Reference-contexts: Several approaches to facilitate the development and maintenance of parallel code are currently under study. One approach is the automatic translation of conventional programming languages, notably Fortran, into parallel form. SUIF [2], a compiler developed at Stanford, and Parafrase-2 <ref> [27] </ref> and Polaris [25], developed at Illinois, are examples of this first approach. Another approach is to extend conventional languages with simple annotations and parallel constructs. This second approach also involves the development of translation techniques for the extensions. Examples include High Performance Fortran [19] and pC++ [7].
Reference: 28. <author> Schwartz, J. T. </author> <title> Automatic Data Structure Choice in a Language of a Very High Level. </title> <booktitle> Communications of the ACM 18 (1975), </booktitle> <pages> 722-728. </pages>
Reference-contexts: Previous work on type inference has been done for several high-level languages. In particular, type inference techniques developed for SETL <ref> [28] </ref> and APL [8, 11] Fig. 1. Program development environment. are most relevant to our work. These two languages are similar to MATLAB in that they can be executed interactively, are usually interpreted, and operate on aggregate data structures. <p> Although described separately here, shape and structure inference work in coordination with the coverage analysis discussed in the previous subsection. Variable properties are estimated using a forward/backward scheme [1]. For type inference, we use a type algebra similar to the one described in <ref> [28] </ref> for SETL. This algebra operates on the type of the MATLAB objects and is implemented using tables for all operations. Each node, of the graph representing the program, contains attribute fields to store inference information.
Reference: 29. <author> Tu, P., and Padua, D. </author> <title> Automatic Array Privatization. In Languages and Compilers for Parallel Computing (August 1993), </title> <editor> U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, Eds., </editor> <publisher> Springer-Verlag, </publisher> <pages> pp. 500-521. </pages> <booktitle> 6th International Workshop, </booktitle> <address> Portland, </address> <month> Oregon. </month> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: We make use of some of the techniques developed for these two languages and extend them, with techniques originally developed for Fortran, to analyze array accesses within loops and represent the information gathered in a compact form <ref> [29] </ref>. These techniques are necessary for MATLAB, since arrays are often built using Fortran-like loops and assignments that may be distributed across several sections of the code. In contrast, the techniques developed for APL assume that arrays are usually built by a single high-level array operation. <p> In this case, the compiler needs to estimate the maximum value of k to avoid the overhead of dynamic allocation for every iteration of the loop. We plan to attack the problem of array definition coverage using the analysis techniques described in <ref> [29] </ref>. These have proven quite effective in detecting pri-vatizable arrays in Fortran programs and should be at least equally effective in this context. The strategy uses data flow analysis to determine which definitions cover the uses of array elements.
References-found: 29

