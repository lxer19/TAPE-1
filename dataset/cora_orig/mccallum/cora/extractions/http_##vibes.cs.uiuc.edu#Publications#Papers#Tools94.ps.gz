URL: http://vibes.cs.uiuc.edu/Publications/Papers/Tools94.ps.gz
Refering-URL: http://vibes.cs.uiuc.edu/Publications/publications.htm
Root-URL: http://www.cs.uiuc.edu
Title: Experimental Analysis of Parallel Systems: Techniques and Open Problems  
Author: Daniel A. Reed 
Address: Urbana, Illinois 61801 USA  
Affiliation: Department of Computer Science University of Illinois  
Abstract: Massively parallel systems pose daunting performance instrumentation and data analysis problems. Balancing instrumentation detail, application perturbation, data reduction costs, and presentation complexity requires a mix of science, engineering, and art. This paper surveys current techniques for performance instrumentation and data presentation, illustrates one approach to tool extensibility, and discusses the implications of massive parallelism for performance analysis environ ments. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Arendt, J. W. </author> <title> Parallel Genome Sequence Comparison Using an iPSC/2 with a Concurrent File System. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: Similarly, changing an array data distribution might increase data locality in a code region. As a feasibility test of real-time adaptive control, we have constructed a prototype system [19] that extracts performance data from a parallel genome sequencing code <ref> [1] </ref> and transmits that data to an immersive virtual world that is a three-dimensional generalization of a two-dimensional scatterplot matrix [4].
Reference: 2. <author> Aydt, R. A. SDDF: </author> <title> The Pablo Self-Describing Data Format. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: The environment consists of three primary components, an extensible data capture library and associated graphical instrumentation tools, a data meta-format <ref> [2] </ref> that describes the structure of performance data records without constraining their contents, and a graphical data analysis toolkit that allows users to quickly prototype performance data reductions. 4.1 Software Instrumentation As Figure 1 suggests, the Pablo instrumentation software captures dynamic performance data via instrumented source code that is linked with <p> As an example, x4.4 briefly describes our early attempt to integrate the Pablo performance analysis environment with the Rice Fortran D compiler by exploiting the Pablo SDDF data format <ref> [2, 19] </ref> to describe compiler transformations. 5.3 Scalability The lure of scalable parallel computer systems is their ability to execute the same code on tens, hundreds, or thousands of processors.
Reference: 3. <author> Chapman, B., Mehrotra, P., and Zima, H. </author> <title> Programming in Vienna Fortran. </title> <booktitle> Scientific Programming 1, 1 (Fall 1992), </booktitle> <pages> 31-50. </pages>
Reference-contexts: Although correlating dynamic performance data and application source code may be burdensome for some developers of message passing codes, it is extraordinarily difficult when using a data parallel programming model such as that provided by Fortran D [7], Vienna Fortran <ref> [3] </ref>, or High-Performance Fortran (HPF) [11]. These and other data parallel languages raise the programming level from explicit interprocessor communication to operations on arrays and array sections, creating a large semantic gap between the application programming model and the machine execution model.
Reference: 4. <author> Cleveland, W. S., and MiGill, M. E., Eds. </author> <title> Dynamic Graphics for Statistics. </title> <publisher> Wadsworth & Brooks/Cole, </publisher> <year> 1988. </year>
Reference-contexts: As a feasibility test of real-time adaptive control, we have constructed a prototype system [19] that extracts performance data from a parallel genome sequencing code [1] and transmits that data to an immersive virtual world that is a three-dimensional generalization of a two-dimensional scatterplot matrix <ref> [4] </ref>. Though a head-mounted display that shows stereo projections of the dynamic data and three-dimensional audio cues that augment graphics with sound, the user can explore the dynamic data and, using a mouse with a three-dimensional tracker, directly control the granularity of the sequencing code's input/output operations.
Reference: 5. <author> Graham, S., Kessler, P., and McKusick, M. </author> <title> gprof: A Call Graph Execution Profiler. </title> <booktitle> In Proceedings of the SIGPLAN '82 Symposium on Compiler Construction (Boston, </booktitle> <address> MA, </address> <month> June </month> <year> 1982), </year> <journal> Association for Computing Machinery, </journal> <pages> pp. 120-126. </pages>
Reference-contexts: Most are variants of four simple techniques: profiling, counting, interval timing, and event tracing. Each has different strengths and weaknesses, each strikes a different balance among dynamic detail, instrumentation overhead, and implementation complexity, and each can be implemented in a variety of ways. Profiling <ref> [5] </ref> is by far the most common instrumentation and data reduction technique. In its standard implementation, the program counter is sampled at fixed intervals, and a histogram of program counter values is constructed.
Reference: 6. <author> Heath, M. T., and Etheridge, J. A. </author> <title> Visualizing the Performance of Parallel Programs. </title> <booktitle> IEEE Software (Sept. </booktitle> <year> 1991), </year> <pages> 29-39. </pages>
Reference-contexts: color code or gray scale indicates the data volume in bytes. 6 Unless the code is large and complex, with many types of messages generated by multiple computation phases, most users have a mental model of the expected interprocessor communication (e.g., ring or nearest neighbor on a grid) 6 ParaGraph <ref> [6] </ref>, Intel's ParAide [12, 22] and many other tools contain similar displays. and can associate observed patterns with source code locations.
Reference: 7. <author> Hiranandani, S., Kennedy, K., and Tseng, C.-W. </author> <title> Compiler Optimizations for Fortran D on MIMD Distributed-Memory Machines. </title> <booktitle> In Supercomputing '91 (Nov. </booktitle> <year> 1991), </year> <pages> pp. 86-100. </pages>
Reference-contexts: Although correlating dynamic performance data and application source code may be burdensome for some developers of message passing codes, it is extraordinarily difficult when using a data parallel programming model such as that provided by Fortran D <ref> [7] </ref>, Vienna Fortran [3], or High-Performance Fortran (HPF) [11]. These and other data parallel languages raise the programming level from explicit interprocessor communication to operations on arrays and array sections, creating a large semantic gap between the application programming model and the machine execution model. <p> Although these protocols can range from simple to complex, the owner-computes rule <ref> [7] </ref> is one of the best known. Under owner-computes, the processor whose memory contains an array element, the "owner," is responsible for computing any modifications to that array element.
Reference: 8. <author> Hiranandani, S., Kennedy, K., and Tseng, C.-W. </author> <title> Preliminary Experiences with the Fortran D Compiler. </title> <booktitle> In Supercomputing '93 (Nov. </booktitle> <year> 1993), </year> <pages> pp. 338-350. </pages>
Reference-contexts: In most data parallel languages, array distribution constructs allow users to specify data placement across the distributed memories of the parallel machine. Given the data distribution directives, compilers translate array operations into codes that contain explicit message passing. As an example, Figure 8 shows a Fortran D code fragment <ref> [8] </ref> with the arrays uu and uud distributed by blocks in the first dimension. 7 parameter (n$proc = 8) common /vars/ uu (64,64,64) decomposition d (64,64,64) align uu, uud with d distribute d (block,:,:) do 41 j=1,64 uud (i,j,1) = c79dz*(uu (i,j,2) - uu (i,j,64)) uud (i,j,2) = c79dz*(uu (i,j,3) -
Reference: 9. <author> Hollingsworth, J. K., and Miller, B. P. </author> <title> Parallel Program Performance Met-rics: A Comparison and Validation. </title> <booktitle> In Supercomputing '92 (Nov. </booktitle> <year> 1992), </year> <pages> pp. 4-13. </pages>
Reference-contexts: The computational cost of data reductions must not 2 A count of basic blocks is the best known example. be excessive, and graphical displays of performance data, if used, must scale to thousands of processors. As an example, critical path calculations <ref> [9] </ref>, which identify the path through an event trace that most limits the computation, do not scale well. The computation cost becomes prohibitive with large event traces and large numbers of processors.
Reference: 10. <author> Hollingsworth, J. K., and Miller, B. P. </author> <title> Dynamic Control of Performance Monitoring on Large Scale Parallel Systems. </title> <booktitle> In 7th ACM International Conference on Supercomputing (July 1993), </booktitle> <pages> pp. 185-194. </pages>
Reference-contexts: Instead, if one views the execution of a parallel program as a temporal data base [23], performance tuning becomes a set of temporal queries, with performance data capture driven by the needs of the queries <ref> [10] </ref>. Not only does this reduce the volume of captured performance data by limiting the code locations and time intervals when data is needed, it also focuses the performance analysis software design on design of effective, high-level performance queries.
Reference: 11. <author> HPFF. </author> <title> High-Performance Fortran Language Specfication, Version 1.0. </title> <type> Tech. rep., </type> <institution> High Performance Fortran Forum, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Although correlating dynamic performance data and application source code may be burdensome for some developers of message passing codes, it is extraordinarily difficult when using a data parallel programming model such as that provided by Fortran D [7], Vienna Fortran [3], or High-Performance Fortran (HPF) <ref> [11] </ref>. These and other data parallel languages raise the programming level from explicit interprocessor communication to operations on arrays and array sections, creating a large semantic gap between the application programming model and the machine execution model.
Reference: 12. <author> Intel. </author> <title> Application Tool User's Guide. </title> <institution> Intel Supercomputer Systems Division, Beaverton, Oregon, </institution> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: gray scale indicates the data volume in bytes. 6 Unless the code is large and complex, with many types of messages generated by multiple computation phases, most users have a mental model of the expected interprocessor communication (e.g., ring or nearest neighbor on a grid) 6 ParaGraph [6], Intel's ParAide <ref> [12, 22] </ref> and many other tools contain similar displays. and can associate observed patterns with source code locations.
Reference: 13. <author> Jain, A. K., and Dubes, R. C. </author> <title> Algorithms for Clustering Data. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: Moreover, as the computation evolves, the metric values and processor locations change. Finally, because most computations are iterative, the processor positions often trace approximately closed curves in the metric space. By using a partitional clustering scheme <ref> [13] </ref> to periodically identify processor behavioral outliers (i.e., singleton clusters) and representatives from larger clusters, one can dramatically reduce the volume of performance data that must be captured | as the number of processors increases, the number of clusters grows quite slowly.
Reference: 14. <author> Kohr, D. R., Zhang, X., Rahman, M., and Reed, D. A. </author> <title> A Performance Study of an object-Oriented Parallel Operating System. </title> <booktitle> In 27th Hawaii International Conference on System Sciences (Jan. </booktitle> <year> 1994). </year>
Reference-contexts: For example, showing detailed, dynamic data on cache utilization is only meaningful if the user both understands the implications of this data and has some mechanism to affect change (e.g., by modifying data structure format or reference patterns). Similarly, operating system performance data <ref> [21, 14] </ref>, though invaluable to an operating system designer or system tuner, may be of little help to an application developer. Even application performance data must be related to the application code and data structures in ways that the application developer can understand and exploit to improve performance.
Reference: 15. <author> Madhyastha, T. M., and Reed, D. A. </author> <title> A Framework for Sonification Design. In Data Sonification, </title> <editor> G. Kramer, Ed. </editor> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1994. </year>
Reference-contexts: The details of file input/output, storage allocation, and module execution scheduling are isolated in the environment infrastructure. The user specifies the desired data transformations and presentations by interactively connecting analysis, data display, and sonification <ref> [15, 16] </ref> modules to form a directed acyclic graph, then selecting the SDDF data records to be processed by each data analysis module. All data passed among modules in the configured data analysis graph is encapsulated in the self-describing data format.
Reference: 16. <author> Madhyastha, T. M., and Reed, D. A. </author> <title> Data Sonification: </title> <note> Do You See What I Hear? IEEE Software (submitted for publication 1994). </note>
Reference-contexts: However, like visualization and graphics, sonification and music differ in important ways, and sonification idioms are beginning to emerge <ref> [16] </ref>. Regardless of the data presentation idiom, massive parallelism imposes constraints not present on the analysis and presentation of performance data from single processor systems. <p> The details of file input/output, storage allocation, and module execution scheduling are isolated in the environment infrastructure. The user specifies the desired data transformations and presentations by interactively connecting analysis, data display, and sonification <ref> [15, 16] </ref> modules to form a directed acyclic graph, then selecting the SDDF data records to be processed by each data analysis module. All data passed among modules in the configured data analysis graph is encapsulated in the self-describing data format.
Reference: 17. <author> Reed, D. A. </author> <title> Performance Instrumentation Techniques for Parallel Systems. In Models and Techniques for Performance Evaluation of Computer and Communications Systems, </title> <editor> L. Donatiello and R. Nelson, Eds. </editor> <booktitle> Springer-Verlag Lecture Notes in Computer Science, </booktitle> <year> 1993. </year>
Reference-contexts: Of these, the most important is a high-resolution, low-overhead global clock. Without a high-resolution global clock, it is not possible to correlate events that occur on disparate processors. The result is causality violations <ref> [17] </ref> | progenitor events on one processor appear to have occurred after their progeny on another processor.
Reference: 18. <author> Reed, D. A., Aydt, R. A., Madhyastha, T. M., Noe, R. J., Shields, K. A., and Schwartz, B. W. </author> <title> An Overview of the Pablo Performance Analysis environment. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: Below, we describe the Pablo Performance Analysis Environment 4 <ref> [20, 19, 18] </ref>, a software system designed to provide portable, yet extensible, capture, re 3 As an example, the communication matrix of Figure 7 requires O (N 2 ) pixels to show the communication pattern among O (N ) processors.
Reference: 19. <author> Reed, D. A., Aydt, R. A., Noe, R. J., Roth, P. C., Shields, K. A., Schwartz, B. W., and Tavera, L. F. </author> <title> Scalable Performance Analysis: The Pablo Performance Analysis Environment. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference, </booktitle> <editor> A. Skjellum, Ed. </editor> <publisher> IEEE Computer Society, </publisher> <year> 1993. </year>
Reference-contexts: Below, we describe the Pablo Performance Analysis Environment 4 <ref> [20, 19, 18] </ref>, a software system designed to provide portable, yet extensible, capture, re 3 As an example, the communication matrix of Figure 7 requires O (N 2 ) pixels to show the communication pattern among O (N ) processors. <p> During program execution, the instrumentation code generates performance data that can either be recorded by the data capture library or extracted as it is generated <ref> [19] </ref>. Source code instrumentation points can be specified by manually modifying the source code to call the data capture library, or interactively by using the graphical instrumentation interface and the instrumenting parser. The instrumenting parser identifies instrumentable source code constructs and passes this information to the graphical instrumentation interface. <p> As an example, x4.4 briefly describes our early attempt to integrate the Pablo performance analysis environment with the Rice Fortran D compiler by exploiting the Pablo SDDF data format <ref> [2, 19] </ref> to describe compiler transformations. 5.3 Scalability The lure of scalable parallel computer systems is their ability to execute the same code on tens, hundreds, or thousands of processors. <p> Finally, if the computation has multiple phases, each with a different bottleneck, multiple profiles per processor, each for a different phase, can be used to enable and disable instrumentation. Dynamic statistical clustering <ref> [19] </ref> is one possible mechanism for automatically identifying behavioral equivalence classes. In Figure 11, each processor's position in space is defined by the current values of two performance metrics. Because the dimensionality of the metric space grows with the number of met-rics, visually identifying processor clusters becomes problematic. <p> Simply put, the SPMD programming model, common to both explicit message passing and compiler-synthesized codes, encourages behavioral regularity; anomalies (e.g., denormalized arithmetic) usually arise due to either programming error or unexpected data variability. Preliminary experiments <ref> [19] </ref> suggest that dynamic clustering has great promise, but several research questions must first be resolved: the balance between clustering computation costs and data extraction over head, clustering interval size and its relation to computation phase changes, cluster representative selection and cluster weighting, similarity measures for cluster identification, and accommodating measurement <p> For example, changing the granularity of work distribution from an application's centralized task queue might reduce contention or improve load balance. Similarly, changing an array data distribution might increase data locality in a code region. As a feasibility test of real-time adaptive control, we have constructed a prototype system <ref> [19] </ref> that extracts performance data from a parallel genome sequencing code [1] and transmits that data to an immersive virtual world that is a three-dimensional generalization of a two-dimensional scatterplot matrix [4].
Reference: 20. <author> Reed, D. A., Olson, R. D., Aydt, R. A., Madhyastha, T. M., Birkett, T., Jensen, D. W., Nazief, B. A. A., and Totty, B. K. </author> <title> Scalable Performance Environments for Parallel Systems. </title> <booktitle> In Proceedings of the Sixth Distributed Memory Computing Conference (1991), </booktitle> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Below, we describe the Pablo Performance Analysis Environment 4 <ref> [20, 19, 18] </ref>, a software system designed to provide portable, yet extensible, capture, re 3 As an example, the communication matrix of Figure 7 requires O (N 2 ) pixels to show the communication pattern among O (N ) processors.
Reference: 21. <author> Reed, D. A., and Rudolph, D. C. </author> <title> Experiences with Hypercube Operating System Instrumentation. </title> <note> International Journal of High-Speed Computing (Dec. </note> <year> 1989), </year> <pages> 517-542. </pages>
Reference-contexts: By inserting calls to a system clock in code, one can measure the amount of time spent in particular code fragments. By accumulating interval sums and counts, a measured, rather than sampled, profile results. Finally, event tracing <ref> [21] </ref> is potentially the most invasive, and the most detailed, of the four performance measurement techniques. Like counting and interval timing, the target code must be modified to include software instrumentation. However, rather than counting or timing event occurrences, event tracing generates a timestamped record each time an event occurs. <p> For example, showing detailed, dynamic data on cache utilization is only meaningful if the user both understands the implications of this data and has some mechanism to affect change (e.g., by modifying data structure format or reference patterns). Similarly, operating system performance data <ref> [21, 14] </ref>, though invaluable to an operating system designer or system tuner, may be of little help to an application developer. Even application performance data must be related to the application code and data structures in ways that the application developer can understand and exploit to improve performance. <p> For example, if tasks are statically assigned to processors, as is common on distributed memory parallel systems, operating system instrumentation is unlikely to substantially perturb the system and application behavior <ref> [21] </ref>. In contrast, on a cache-coherent, shared-memory parallel system with dynamic task scheduling, perturbing the task schedule can have profound effects.
Reference: 22. <author> Ries, B., Anderson, R., Auld, W., Breazeal, D., Callaghan, K., Richards, E., and Smith, W. </author> <title> The Paragon Performance Monitoring Environment. </title> <booktitle> In Proceedings of Supercomputing '93 (Nov. </booktitle> <year> 1993), </year> <pages> pp. 850-859. </pages>
Reference-contexts: gray scale indicates the data volume in bytes. 6 Unless the code is large and complex, with many types of messages generated by multiple computation phases, most users have a mental model of the expected interprocessor communication (e.g., ring or nearest neighbor on a grid) 6 ParaGraph [6], Intel's ParAide <ref> [12, 22] </ref> and many other tools contain similar displays. and can associate observed patterns with source code locations.
Reference: 23. <author> Snodgrass, R. </author> <title> A Relational Approach to Monitoring Complex Systems. </title> <journal> ACM Transactions on Computer Systems 6, </journal> <month> 2 (May </month> <year> 1988), </year> <pages> 157-196. </pages>
Reference-contexts: Instead, if one views the execution of a parallel program as a temporal data base <ref> [23] </ref>, performance tuning becomes a set of temporal queries, with performance data capture driven by the needs of the queries [10].
References-found: 23

