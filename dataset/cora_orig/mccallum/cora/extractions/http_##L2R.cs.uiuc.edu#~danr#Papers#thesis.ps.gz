URL: http://L2R.cs.uiuc.edu/~danr/Papers/thesis.ps.gz
Refering-URL: http://L2R.cs.uiuc.edu/~danr/L2R.html
Root-URL: http://www.cs.uiuc.edu
Title: Learning in Order to Reason  
Author: Dan Roth 
Degree: A thesis presented by  to The Division of Applied Sciences in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the subject of  
Date: January, 1995  
Address: Cambridge, Massachusetts  
Affiliation: Computer Science Harvard University  
Abstract-found: 0
Intro-found: 1
Reference: <author> AI. </author> <year> 1980. </year> <note> Special issue on non-monotonic logic. Artificial Intelligence, 13(1,2). </note>
Reference: <author> Alon, N., J. Bruck, J. Naor, M. Naor, and R. Roth. </author> <year> 1992. </year> <title> Construction of asymptotically good low-rate error-correcting codes through pseudo-random graphs. </title> <journal> IEEE Transactions on information theory, </journal> <volume> 38(2) </volume> <pages> 509-516. </pages>
Reference-contexts: An (n; k)-universal set is a set of assignments fd 1 ; : : : d t g f0; 1g n such that every subset of k variables assumes all of its 2 k possible assignments in the d i 's. It is known <ref> (Alon et al., 1992) </ref> that for k = log n one can construct (n; k)-universal sets of polynomial size. Claim 4.5.2 (Bshouty (1993a)) Let B be an (n; k)-universal set. Then B is a basis for any kCNF KB.
Reference: <author> Amsterdam, J. </author> <year> 1988. </year> <title> Extending the Valiant learning model. </title> <booktitle> In Proceeding of the Fifth International Workshop on Machine Learning, </booktitle> <pages> pages 364-375, </pages> <month> June. </month>
Reference-contexts: Oracles that seem to be useful for that are example oracles that supply examples restricted to satisfy a specific context (e.g., "I am in Boston"), partial assignments oracles and more selective oracles <ref> (Amsterdam, 1988) </ref>. We show later, in Chapter 4, how our study of exact reasoning applies also to reasoning within varying context, and in Chapter 6 we extend it to discuss partial assignment oracles.
Reference: <author> Angluin, D. </author> <year> 1988. </year> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <month> April. </month>
Reference-contexts: The function h is restricted to be a Horn disjunction. We note that these are not all the oracles a learner can use when learning a function. For example, the oracles "incomplete membership queries" (Angluin and Slonim, 1991) "faulty example oracles" <ref> (Angluin and Laird, 1988) </ref> "malicious example oracles" (Valiant, 1985; Kearns and Li, 1988), "statistical queries oracle" (Kearns, 1993) are also studied in the literature and can be used here as well. The Reasoning oracles we introduce next model the case where an agent learns from mistakes it makes while reasoning. <p> GoTo 2 9. Return = [ b2B b Reasoning Phase: Answer queries by performing model-based reasoning on = [ b2B b EX D (f ) sufficiently many times. This simulation builds on the standard simulation of Equivalence Query Oracle by calls to Example Oracle <ref> (Angluin, 1988) </ref> and uses some nice properties of the reasoning with models framework.
Reference: <author> Angluin, D. </author> <year> 1992. </year> <title> Computational learning theory: Survey and selected bibliography. </title> <booktitle> In Proceedings of the Twenty-Fourth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 351-369, </pages> <month> May. </month>
Reference: <author> Angluin, D. and P. Laird. </author> <year> 1988. </year> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370. </pages>
Reference-contexts: The function h is restricted to be a Horn disjunction. We note that these are not all the oracles a learner can use when learning a function. For example, the oracles "incomplete membership queries" (Angluin and Slonim, 1991) "faulty example oracles" <ref> (Angluin and Laird, 1988) </ref> "malicious example oracles" (Valiant, 1985; Kearns and Li, 1988), "statistical queries oracle" (Kearns, 1993) are also studied in the literature and can be used here as well. The Reasoning oracles we introduce next model the case where an agent learns from mistakes it makes while reasoning. <p> GoTo 2 9. Return = [ b2B b Reasoning Phase: Answer queries by performing model-based reasoning on = [ b2B b EX D (f ) sufficiently many times. This simulation builds on the standard simulation of Equivalence Query Oracle by calls to Example Oracle <ref> (Angluin, 1988) </ref> and uses some nice properties of the reasoning with models framework.
Reference: <author> Angluin, D. and D. K. Slonim. </author> <year> 1991. </year> <title> Learning monotone DNF with an incomplete membership oracle. </title> <booktitle> In Proceedings of COLT '91, </booktitle> <pages> pages 139-146. </pages> <note> Morgan Kaufmann. (To appear in Machine Learning.). </note>
Reference-contexts: The function h is restricted to be a Horn disjunction. We note that these are not all the oracles a learner can use when learning a function. For example, the oracles "incomplete membership queries" <ref> (Angluin and Slonim, 1991) </ref> "faulty example oracles" (Angluin and Laird, 1988) "malicious example oracles" (Valiant, 1985; Kearns and Li, 1988), "statistical queries oracle" (Kearns, 1993) are also studied in the literature and can be used here as well.
Reference: <author> Bacchus, F. </author> <year> 1990. </year> <title> Representing and Reasoning With Probabilistic Knowledge: A Logical Approach to Probabilities. </title> <publisher> MIT Press. </publisher>
Reference: <author> Bacchus, F., A. Grove, J. Y. Halpern, and D. Koller. </author> <year> 1992. </year> <title> From statistics to beliefs. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 602-608. </pages>
Reference: <author> Bacchus, F., A. Grove, J. Y. Halpern, and D. Koller. </author> <year> 1993. </year> <title> Statistical foundations for default reasoning. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 563-569. </pages>
Reference: <author> Beeri, C., M. Dowd, R. Fagin, and R. Statman. </author> <year> 1984. </year> <title> On the structure of Armstorng relations for functional dependencies. </title> <journal> Journal of the ACM, </journal> <volume> 31(1) </volume> <pages> 30-46. </pages>
Reference: <author> Birnbaum, L. </author> <year> 1991. </year> <title> Response to Nilsson's "logic and artificial intelligence". </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 57-79. </pages>
Reference-contexts: we believe, as if the only way to develop a precise and theoretically sound theory of reasoning is by studying knowledge representations within the knowledge-based systems framework (or even within the logic approach to knowledge representation), and any other approach, not following these lines, is a "scruffy" type of approach <ref> (Birnbaum, 1991) </ref>. However, the approach developed in this thesis suggests an "operational" approach to studying reasoning, that is nevertheless rigorous and amenable to analysis.
Reference: <author> Blum, A., R. Khardon, A. Kushilevitz, L. Pitt, and D. Roth. </author> <year> 1994. </year> <booktitle> On learning read-k satisfy-j DNF. In Proceedings of the Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 110-117. </pages> <note> (Submitted for publication). </note>
Reference-contexts: It turns out that most of the existing learning algorithms for Boolean functions studied in computational learning theory (see, e.g., <ref> (Blum et al., 1994) </ref>, for a survey) can be extended with little effort to learning algorithms over f0; 1; flg n .
Reference: <author> Blumer, A., A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <year> 1987. </year> <title> Occam's razor. </title> <journal> Information Processing Letters, </journal> <volume> 24 </volume> <pages> 377-380, </pages> <month> April. </month>
Reference-contexts: Learning to reason is possible for arbitrary world and query languages given that the queries are fair. We note, that the above algorithm highlights another difference between learning to reason and learning to classify. In the learning to classify approach the above argument yields the result on "Occam" algorithms <ref> (Blumer et al., 1987) </ref>. Namely, if you take a big enough sample and find a small enough consistent hypothesis then you have learned to classify. Unfortunately, in many cases, the problem of finding a consistent hypothesis is hard.
Reference: <author> Brachman, R. and H. Levesque. </author> <year> 1984. </year> <title> The tractability of subsumption in frame-based description languages. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 34-37. </pages>
Reference: <author> Brooks, R. A. </author> <year> 1991. </year> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 139-159. </pages>
Reference-contexts: The effect of this is two-fold: 45 (1) Syntactic: Since the reasoning task is a "stand alone" process, one has to define a rigid representation language with which reasoning problems are presented to the reasoner <ref> (Brooks, 1991) </ref>. (2) Performance: The performance criterion for the behavior of an intelligent sys tem is irrespective of the world it functions in. In this chapter we embark on developing a new framework for the study of Reasoning. <p> First, we show that reasoning with model-based representations enjoy some desirable robustness properties, which logical representations lack, and that they support incremental reasoning. Moreover, the results illustrate and aid in formalizing the notion of "intelligence is in the eye of the beholder" <ref> (Brooks, 1991) </ref>. Using a model-based representation, our agent behaves logically, even though her knowledge representation consists of a set of models and not a logical formula and she does not use any logic or "theorem proving".
Reference: <author> Bshouty, N. H. </author> <year> 1993a. </year> <title> Exact learning via the monotone theory. </title> <booktitle> In Proceedings of the IEEE Symp. on Foundation of Computer Science, </booktitle> <pages> pages 302-311, </pages> <address> Palo Alto, CA. </address>
Reference-contexts: In Section 4.1 we introduce some notations and present the monotone theory, a characterization of Boolean functions introduced in <ref> (Bshouty, 1993a) </ref>, which we use in many of our technical results. In the main section of this chapter, Section 4.2, we consider the deduction problem. We introduce the set of characteristic models and analyze the correctness and efficiency of model-based deduction with this set. <p> Finally, in Section 4.8 we conclude by showing how model-based representations support an incremental view of reasoning. 4.1 Monotone Theory In this section we introduce the notations, definitions and results of the Monotone Theory of Boolean functions, introduced by Bshouty <ref> (Bshouty, 1993a) </ref>. Definition 4.1.1 (Order) We denote by the usual partial order on the lattice f0; 1g n , the one induced by the order 0 &lt; 1. That is, for x; y 2 f0; 1g n , x y if and only if 8i; x i y i . <p> Proof: The Learning to Reason algorithm learns a model-based representation for the target function f and then uses model-based reasoning to answer queries with respect to it. In <ref> (Bshouty, 1993a) </ref> an algorithm is developed that uses an Equivalence Query oracle and a Membership Query Oracle to learn an exact representation of any function f 2 CN F " DN F . <p> As a byproduct of this algorithm, the set of all minimal models with respect to a basis B of f is produced. Using this set of models , model-based reasoning, via Theorem 4.2.1, gives the result for relevant queries. Also, given basis B, the algorithm developed in <ref> (Bshouty, 1993a) </ref> produces as a byproduct the set of minimal models of f with respect to B, provided that f has small DNF. Combining this with Theorem 4.2.5 we get the result for common queries. <p> We believe that this property is useful for a Learning to Reason algorithm. We now present the algorithms. Both are based on a modified version of Bshouty's algorithm to learn Boolean functions via the monotone theory <ref> (Bshouty, 1993a) </ref>. 5.2.1 Exact Learning to Reason Let B be a basis for the class of queries Q. The algorithm collects a set of models = [ b2B b , the set of locally minimal assignments of f with respect to B. <p> It seems as if this is unavoidable also in the case of functions defined over f0; 1; flg n . In (Bshouty, 1993b) it is shown how to extend the monotone theory <ref> (Bshouty, 1993a) </ref> to hold for functions defined over a larger alphabet.
Reference: <author> Bshouty, N. H. </author> <year> 1993b. </year> <title> Exact learning via the monotone theory. </title> <note> Long Version of (Bshouty, 1993a). Unpublished. </note>
Reference-contexts: It seems as if this is unavoidable also in the case of functions defined over f0; 1; flg n . In <ref> (Bshouty, 1993b) </ref> it is shown how to extend the monotone theory (Bshouty, 1993a) to hold for functions defined over a larger alphabet. <p> It is shown in <ref> (Bshouty, 1993b) </ref> that for the monotone theory to hold the partial order defined on f0; 1; flg must have one minimal element and two maximal elements. Thus the 0th partial order is: 0 &lt; 0 1, 0 &lt; 0 fl, fl and 1 are incomparable.
Reference: <author> Cadoli, M. </author> <year> 1993. </year> <title> Semantical and computational aspects of Horn approximations. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 39-44, </pages> <month> August. </month>
Reference: <author> Carnap, R. </author> <year> 1950. </year> <title> Logical Foundations of Probability. </title> <publisher> University of Chicago Press, Chicago. </publisher>
Reference: <author> Cohen, W. W. </author> <year> 1994. </year> <title> Pac-learning nondeterminate clauses. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 676-681. </pages>
Reference-contexts: The second issue concerns using learning procedures that output only "approximate" representations. For example, pac learning has been accepted as a good measure of learning even when learning for the purpose of performing reasoning (e.g. when learning logic programs <ref> (Cohen, 1994) </ref>).
Reference: <author> Cooper, F. G. </author> <year> 1990. </year> <title> The computational complexity of probabilistic inference using Bayesian belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 393-405. </pages>
Reference-contexts: Moreover, for every fixed * &gt; 0, approximating this probability within 2 n 1* (where n is the size of the network) is NP-hard. Proof: The proof is based on the reduction from <ref> (Cooper, 1990) </ref>. <p> j2 (1 j m), define the conditional probabilities by: P (c j = T ju 1 j = v 2 ) = 1 if the assignment u 1 j = v 1 ; u 2 j = v 2 satisfies c j 0 otherwise 5 This is not possible in <ref> (Cooper, 1990) </ref>, since the results there hinge on the hardness of solving satisfiability, which can be done in polynomial time for 2MONCNF. 21 Finally, the conditional probability for the edges coming into the node Y is defined by ( 0 otherwise It is easy to see that the structure (V; E; <p> Moreover, for every fixed * &gt; 0, approximating this probability within 2 n 1* (where n is the size of the network) is NP-hard. Finally we note that as in <ref> (Cooper, 1990) </ref>, this reduction can be modified to hold for restricted network topology (limited in-degree, out-degree, etc.) Further restrictions to the topologies of the network can be utilized if we reduce problems of counting satisfying assignments of syntactically restricted CNF formulae to that of computing the probability that a node in
Reference: <author> Dagum, P. and M. Luby. </author> <year> 1993. </year> <title> Approximating probabilistic inference in Bayesian belief networks is NP-hard. </title> <journal> Artificial Intelligence, </journal> <volume> 60 </volume> <pages> 141-153. </pages> <note> 124 Dechter, </note> <author> R. </author> <year> 1992. </year> <title> Constraint networks. </title> <editor> In G. S. Shapiro, editor, </editor> <booktitle> Encyclopedia of Artificial Intelligence. </booktitle> <publisher> John Wiley and Sons. </publisher>
Reference: <author> Dechter, R. and J. Pearl. </author> <year> 1988. </year> <title> Network-based heuristics for constraint-satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 1-38. </pages>
Reference-contexts: These techniques require, in the worst case, exponential search time, and analyzing those techniques in order to get some performance guarantees is usually hard. We exemplify how the counting point of view taken here can be used to evaluate one class of heuristics <ref> (Dechter and Pearl, 1988) </ref> and restrict its feasibility. Dechter and Pearl suggest to use counting to guide the search according to an estimate of the confidence we have that a specific solution can be extended further to a full solution.
Reference: <author> Dechter, R. and J. Pearl. </author> <year> 1992. </year> <title> Structure identification in relational data. </title> <journal> Artificial Intelligence, </journal> <volume> 58 </volume> <pages> 237-270. </pages>
Reference-contexts: This can be argued from the fact that the set of models of any Horn formula is closed under intersection (bitwise "and") (see, e.g., <ref> (Dechter and Pearl, 1992) </ref>). Therefore, the size of lub n is exponential in the number n of variables. This question is partially addressed in (Greiner and Schuurmans, 1992), where learning techniques are used to find a locally-optimal approximation. <p> A constraint satisfaction problem <ref> (Dechter, 1992) </ref> involves a set of n variables x 1 ; : : : ; x n having domains D 1 ; : : : ; D n , where each D i defines the set of values that variable x i may assume. <p> In Section 4.5 we discuss applications of the our theory to particular propositional languages, other than Horn, and summarize the results on model-based deduction. We also show how the techniques presented here can be used to solve an open question about structure identification <ref> (Dechter and Pearl, 1992) </ref>. In Section 4.6 we consider the problem of performing abduction using a model-based approach and show that for any propositional knowledge base, using a model-based representation yields an abductive explanation in time that is polynomial in the size of the representation. <p> These observations imply that our results hold for these restricted first order logic formalizations, where the polynomial bounds are relative to the number of variables in the propositional domain. 4.5.3 Structure Identification We briefly describe another application of model based reasoning. Dechter and Pearl investigate in <ref> (Dechter and Pearl, 1992) </ref> the problem of identifying tractable classes of CNF formulas. In particular they consider the following problem: Given a set of models, can one: 1. Find a Horn theory f such that f = , if one exists. 2. <p> Find a Horn theory f such that f = , if one exists. 2. Find a Horn theory f such that f and there is no Horn function g such that g f . In <ref> (Dechter and Pearl, 1992) </ref> it is shown ("Horn theories are identifiable", Corollary 4.11) that when is a set of models of a Horn theory, a theory f can be found in time polynomial in jj.
Reference: <author> Doyle, J. and R. Patil. </author> <year> 1991. </year> <title> Two theses of knowledge representation: language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 261-297. </pages>
Reference-contexts: We comment that the approach of "restricting the world" has been criticized also on the grounds that existing results do not meet the strong tractability requirements for commonsense reasoning as described, for example, in (Shastri, 1993)), even though (as argued, for example, in <ref> (Doyle and Patil, 1991) </ref>) the inference deals with limited expressiveness and is sometimes restricted in implausible ways. Our use of restricted queries is motivated also by computational results we present in the first part of the thesis. <p> None of these works meet the strong tractability requirements for common-sense reasoning as described, for example, in (Shastri, 1993)), even though, (as argued, for example, in <ref> (Doyle and Patil, 1991) </ref>) the inference deals with limited expressiveness and is sometimes restricted in implausible ways. An additional motivation for this work is the current disconnected state of the fields of learning and reasoning. <p> We comment that this approach of "restricting the world" has been criticized also on the grounds that existing results do not meet the strong tractability requirements for commonsense reasoning as described, for example, in (Shastri, 1993)), even though (as argued, for example, in <ref> (Doyle and Patil, 1991) </ref>) the inference deals with limited expressiveness and is sometimes restricted in implausible ways. The main interest in model-based representation arises from its computational efficiency.
Reference: <author> Etherington, D., A. Borgida, R. Brachman, and H. Kautz. </author> <year> 1989. </year> <title> Vivid knowledge and tractable reasoning: Preliminary report. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence. </booktitle>
Reference: <author> Etherington, D. W. </author> <year> 1988. </year> <title> Reasoning With Incomplete Information. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Frazier, M. and L. Pitt. </author> <year> 1993. </year> <title> Learning from entailment: An application to propositional Horn sentences. </title> <booktitle> In Proceedings of the International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Garey, M. and D. Johnson. </author> <year> 1979. </year> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco. </address>
Reference-contexts: Proof: We use the "blow-up" technique introduced in (Jerrum, Valiant, and Vazi-rani, 1986), to reduce the problem of approximating the number of independent sets in G to the k-INDEPENDENT-SET problem <ref> (Garey and Johnson, 1979) </ref>. Given G (V; E), where jV j = n, we construct a graph G 0 (V 0 ; E 0 ) such that approximating the number independent sets in G 0 to within 2 n 1* can be used to solve k-INDEPENDENT-SET in G.
Reference: <author> Geffner, H. </author> <year> 1990. </year> <title> Default Reasoning: Casual and Conditional Theories. </title> <publisher> MIT Press. </publisher>
Reference-contexts: As argued in (Geffner, 1990; Pearl, 1988), no general method exists, according to which one can rank defaults. The only way to figure out why and when certain defaults are preferred to others is to understand what the defaults say about the world. While the probabilistic approach taken in <ref> (Geffner, 1990) </ref> presents an important step in this direction, it still suffers from some of the same problems (e.g., (Geffner, 1994)), and of course, is infeasible computationally. <p> This is discussed in the default reasoning literature as the issue of causality. The following example is taken from <ref> (Geffner, 1990) </ref>. Example 6.3.7 (Causality) We get up in the morning and want to drive to work. When we get to the car, however, we notice that we left the lights on the previous night.
Reference: <author> Geffner, H. </author> <year> 1994. </year> <title> Causal default reasoning: </title> <booktitle> Principles and algorithms. In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 245-250. </pages>
Reference-contexts: While the probabilistic approach taken in (Geffner, 1990) presents an important step in this direction, it still suffers from some of the same problems (e.g., <ref> (Geffner, 1994) </ref>), and of course, is infeasible computationally. Unlike previous theories of reasoning in the presence of incomplete information, we are not interested in providing a theory of defaults, but rather a theory of inference. Defaults do not exist in the world.
Reference: <author> Goldszmidt, M. and J. Pearl. </author> <year> 1991. </year> <title> System Z+: A formalism for reasoning with variable strength defaults. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 399-404. </pages>
Reference: <author> Greiner, R. and D. Schuurmans. </author> <year> 1992. </year> <title> Learning useful Horn approximations. </title> <booktitle> In Proceedings of the International Conference on the Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 383-392. </pages>
Reference-contexts: This can be argued from the fact that the set of models of any Horn formula is closed under intersection (bitwise "and") (see, e.g., (Dechter and Pearl, 1992)). Therefore, the size of lub n is exponential in the number n of variables. This question is partially addressed in <ref> (Greiner and Schuurmans, 1992) </ref>, where learning techniques are used to find a locally-optimal approximation. However, in (Greiner and Schuurmans, 1992), as is done in general in the theory of Horn approximations, an approximation is defined in terms of containment, (that is, logical strength), and there is no guarantee that this approximation <p> Therefore, the size of lub n is exponential in the number n of variables. This question is partially addressed in <ref> (Greiner and Schuurmans, 1992) </ref>, where learning techniques are used to find a locally-optimal approximation. However, in (Greiner and Schuurmans, 1992), as is done in general in the theory of Horn approximations, an approximation is defined in terms of containment, (that is, logical strength), and there is no guarantee that this approximation is "close" to the optimal one, nor that the optimal one approximates the original theory within
Reference: <author> Grove, A., J. Y. Halpern, and D. Koller. </author> <year> 1992. </year> <title> Asymptotic conditional probabilities for first-order logic. </title> <booktitle> In ACM Symp. of the Theory of Computing, </booktitle> <volume> number 24, </volume> <pages> pages 294-305. </pages>
Reference-contexts: * &gt; 0, approximating this probability within 2 n 1* is NP-hard. 2.3.2 Bayesian Belief Networks Bayesian belief networks provide a natural method for representing probabilistic dependencies among a set of variables and are considered an efficient and expres 3 The first order version of this problem was considered in <ref> (Grove, Halpern, and Koller, 1992) </ref> where it was shown that almost all problems one might want to ask are highly undecidable.
Reference: <author> Hanks, S. and D. McDermott. </author> <year> 1986. </year> <title> Default reasoning, nonmonotonic logics, and the frame problem. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 328-333. </pages> <address> 125 Haussler, D. </address> <year> 1987. </year> <title> Bias, version spaces and Valiant's learning framework. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 324-336, </pages> <institution> University of California, Irvine, </institution> <month> June. </month>
Reference-contexts: While the standard non-monotonic reasoning formalisms do not capture the desirable behavior, that things stay as they are <ref> (Hanks and McDermott, 1986) </ref>, our representation of incomplete information does. If we don't know of the existence of the attribute cut the wires it will not be part of the attribute function representation for starts.
Reference: <author> Holtzman, S. </author> <year> 1989. </year> <title> Intelligent Decision Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: We keep the same loose interpretation in the rest of the chapter. 19 sive language for representing knowledge in many domains <ref> (Holtzman, 1989) </ref>. We consider here the class of multiple connected belief network, i.e., networks that contain at least one pair of nodes (variables) that have more than one undirected path connecting them.
Reference: <author> Jerrum, M. R., L. G. Valiant, and V. V. Vazirani. </author> <year> 1986. </year> <title> Random generation of combinatorial structures from a uniform distribution. </title> <journal> Theoretical Computer Science, </journal> <volume> 43 </volume> <pages> 169-188. </pages>
Reference-contexts: It is possible, though, for a #P-complete problem, even if its underlying decision problem is easy, to resist even an efficient approximate solution. An example for that was given in <ref> (Jerrum, Valiant, and Vazirani, 1986) </ref>, and in this chapter we exhibit further examples of this phenomenon. We prove, for various propositional languages for which solving satisfiability is easy, that it is NP-hard to approximate the number of satisfying assignments even in a very weak sense. <p> We note that a related class of problems of interest to AI, that of randomly generating solutions from a uniform distribution, was shown in <ref> (Jerrum, Valiant, and Vazirani, 1986) </ref> to be equivalent to randomized approximate counting, for a wide class of problems. (All natural problems considered here, e.g., finding satisfying assignments of Boolean formulae and various graph problems are in this class.) It is therefore enough, from the computational complexity point of view, to consider <p> This can easily be handled as we do below). Notice that the rewriting technique used in (5) of that theorem does not extend for approximations. The next lemma provides the main step in the proof of (1). The proof is based on the "blow-up" technique developed in <ref> (Jerrum, Valiant, and Vazirani, 1986) </ref>. The lemma is a variant of one that appears in (Sinclair, 1988). Lemma 2.5.3 For any *, approximating the number of independent sets of a graph on n vertices within 2 n 1* is NP-hard. <p> The lemma is a variant of one that appears in (Sinclair, 1988). Lemma 2.5.3 For any *, approximating the number of independent sets of a graph on n vertices within 2 n 1* is NP-hard. Proof: We use the "blow-up" technique introduced in <ref> (Jerrum, Valiant, and Vazi-rani, 1986) </ref>, to reduce the problem of approximating the number of independent sets in G to the k-INDEPENDENT-SET problem (Garey and Johnson, 1979).
Reference: <author> Johnson-Laird, P. N. </author> <year> 1983. </year> <title> Mental Models. </title> <publisher> Harvard Press. </publisher>
Reference: <author> Johnson-Laird, P. N. and R. M. J. Byrne. </author> <year> 1991. </year> <title> Deduction. </title> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Karp, R.M. and M. Luby. </author> <year> 1983. </year> <title> Monte-carlo algorithms for enumeration and reliability problems. </title> <booktitle> In IEEE Symp. of Foundation of Computer Science, </booktitle> <volume> number 24, </volume> <pages> pages 56-64. </pages>
Reference: <author> Kautz, H., M. Kearns, and B. Selman. </author> <year> 1993. </year> <title> Reasoning with characteristic models. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 34-39. </pages>
Reference-contexts: We give application of the theory to other problems in reasoning, and in particular show that the theory developed here generalizes the model-based approach to reasoning with Horn theories <ref> (Kautz, Kearns, and Selman, 1993) </ref>, and captures even the notion of reasoning with Horn-approximations (Selman and Kautz, 1991). Finally, we discuss some robustness issues of model-based representations and show how they support an incremental approach to reasoning. <p> In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning mentioned above, is somewhat related to Minsky's frames-theory (Minsky, 1975) and has already been studied in a narrower context in <ref> (Kautz, Kearns, and Selman, 1993) </ref>. The problem KB j= ff can be approached using the following model-based strategy: Algorithm MBR: Test Set: A set S of possible assignments. <p> We then prove the necessity of a complete set of characteristic models to performing exact deduction. In Section 4.3 we show that in the special case of Horn theories our theory reduces to the work in <ref> (Kautz, Kearns, and Selman, 1993) </ref>. The complexity of model-based reasoning is directly related to the number of models in the representation. <p> This issue is investigated in Section 4.4, where we compare this size of the model based representation of a Boolean function with the size of other representations of the same function. In particular, our results characterize the Horn theories for which the approach suggested in <ref> (Kautz, Kearns, and Selman, 1993) </ref> is useful and explain the phenomena observed there, regarding the relative sizes of the logical formula representation and model-based representation of KB. <p> We further discuss the issue of answering all CNF queries. In <ref> (Kautz, Kearns, and Selman, 1993) </ref> the deduction theorem was extended to answer any such query. This extension relies on a special property of Horn formulas and does not hold in the general case. We give an example that explains this phenomenon. <p> If x k is the only variable that appears un-negated in C then C is falsified by b (k) . 4.3.1 Characteristic Models In order to relate to the results from <ref> (Kautz, Kearns, and Selman, 1993) </ref> we need a few definitions presented there. <p> Based on this characterization of Horn theories, it is clear that if KB is a Horn theory and M KB any subset of models, then closure (M ) closure (KB) = KB. In <ref> (Kautz, Kearns, and Selman, 1993) </ref> it is shown that if we take M = char H (KB), then we get closure (char H (KB)) = closure (KB) = KB: In particular, Equation 4.5 implies that char H (KB) is the smallest subset of KB with that property. <p> While we have shown that our model-based representation coincides with that of <ref> (Kautz, Kearns, and Selman, 1993) </ref> it turns out that the ability to answer any query relies on a 72 special characteristic of Horn theories, and does not generalize to other propositional theories. We next give a counterexample that exemplifies this. The deduction scheme in (Kautz, Kearns, and Selman, 1993) when ff <p> model-based representation coincides with that of <ref> (Kautz, Kearns, and Selman, 1993) </ref> it turns out that the ability to answer any query relies on a 72 special characteristic of Horn theories, and does not generalize to other propositional theories. We next give a counterexample that exemplifies this. The deduction scheme in (Kautz, Kearns, and Selman, 1993) when ff is a general CN F expression, utilizes the following theorem 5 . Theorem 4.3.4 Let KB be a Horn theory and ff any disjunction. <p> KB j= ff 1 ff 2 if and only if KB j= ff 1 and KB j= ff 2 . Observation (2) implies that it is enough to consider queries that are disjunctions. Given ff, the deduction scheme in <ref> (Kautz, Kearns, and Selman, 1993) </ref> decomposes it into the Horn disjunction fi i s and tests deduction against the fi i s. By Theorem 4.3.4, at least one of the fi i s is implied by KB. <p> It is therefore important to compare this size with the size of other representations of the same function. In the previous section we have shown that our model-based representation is the same as that of <ref> (Kautz, Kearns, and Selman, 1993) </ref> when the theory is Horn. In (Kautz, Kearns, and Selman, 1993) examples are given for large Horn theories with a small set of characteristic models and vice versa, but it was not yet understood when and why it happens. <p> It is therefore important to compare this size with the size of other representations of the same function. In the previous section we have shown that our model-based representation is the same as that of <ref> (Kautz, Kearns, and Selman, 1993) </ref> when the theory is Horn. In (Kautz, Kearns, and Selman, 1993) examples are given for large Horn theories with a small set of characteristic models and vice versa, but it was not yet understood when and why it happens. <p> The other direction is however not true (i.e., there are Horn theories with a small set of characteristic models but an exponential size DNF). We start with a bound on the size of the model-based representation. 5 This theorem follows from McKinsey's proof of Claim 4.3.2. In <ref> (Kautz, Kearns, and Selman, 1993) </ref> it is derived, in a different way, using a completeness theorem for resolution given in (Slage, Chang, and Lee, 1969) (see also (Khardon and Roth, 1994d) for a discussion). 73 Lemma 4.4.1 Let B be a basis for the knowledge base KB, and denote by jDNF <p> The same arguments hold for any b-monotone function with respect to the order relation b (one can simply rename the variables) and therefore jmin b (f )j = jDN F (f )j. Claim 4.4.2 explains the two examples in <ref> (Kautz, Kearns, and Selman, 1993) </ref>. Both examples are 1 n -monotone Horn functions, one has a small DNF and the other has an exponentially large DNF. We note that exponential size model-based representations are not restricted to happen in b-monotone functions. <p> For (ii) notice that if the query ff is a Horn query, then model based reasoning with is correct, by Theorem 4.2.5. For correct reasoning with general queries, it is possible to use the reasoning algorithm from <ref> (Kautz, Kearns, and Selman, 1993) </ref>. 4.6 Abduction with Models We consider in this section the question of performing abduction using a model-based representation. In (Kautz, Kearns, and Selman, 1993) it is shown that for a Horn theory KB, abduction can be done in polynomial time using characteristic models, although using formula <p> For correct reasoning with general queries, it is possible to use the reasoning algorithm from <ref> (Kautz, Kearns, and Selman, 1993) </ref>. 4.6 Abduction with Models We consider in this section the question of performing abduction using a model-based representation. In (Kautz, Kearns, and Selman, 1993) it is shown that for a Horn theory KB, abduction can be done in polynomial time using characteristic models, although using formula based representation the problem is NP-Hard (Sel-man, 1990). <p> One may therefore talk about "positive explanations" instead of explanations. We nevertheless continue with the term explanation. 79 Thus, abduction involves tests for entailment and consistency, but also a search for an explanation that passes both tests. We now show how one can use the algorithm from <ref> (Kautz, Kearns, and Selman, 1993) </ref> for any propositional theory KB. Theorem 4.6.1 Let KB be a background propositional theory with a basis B, let A be an assumption set and q be a query. Let B H = fx 2 f0; 1g n jweight (x) n 1g. <p> Let B H = fx 2 f0; 1g n jweight (x) n 1g. Then, using the set of characteristic models = B [B H KB one can find an abductive explanation of q in time polynomial in jj and jAj. Proof: We use the algorithm Explain suggested in <ref> (Kautz, Kearns, and Selman, 1993) </ref> for the case of a Horn knowledge base. For a Horn theory KB the algorithm uses the set char H (KB) = B H KB defined in Section 4.3.
Reference: <author> Kautz, H., M. Kearns, and B. Selman. </author> <year> 1994. </year> <title> Horn approximations of empirical data. </title> <journal> Artificial Intelligence. Forthcoming. </journal>
Reference-contexts: Therefore, for all the 2 jSj 1 queries ff s , reasoning with approximate theories returns "don't know". In <ref> (Kautz, Kearns, and Selman, 1994) </ref> it is shown that, for a family of propositional languages L which consists of kHorn formulae (all Horn formulae with up to k literals in a clause), one can construct examples of theories for which j lub n j is exponential in the number of variables, <p> Thus it motivates an investigation in the direction of reasoning with restricted queries, where it might be possible to avoid these difficulties. Indeed, in <ref> (Kautz and Selman, 1994) </ref> an experimental analysis is presented in which, under severe restrictions on the classes of queries allowed, reasoning with approximate theories is shown to succeed on a large percentage of the queries.
Reference: <author> Kautz, H. and B. Selman. </author> <year> 1991. </year> <title> A general framework for knowledge compilation. </title> <booktitle> In Proceedings of the International Workshop on Processing Declarative Knowledge, </booktitle> <address> Kaiserlautern, Germany, </address> <month> July. </month>
Reference-contexts: We give application of the theory to other problems in reasoning, and in particular show that the theory developed here generalizes the model-based approach to reasoning with Horn theories (Kautz, Kearns, and Selman, 1993), and captures even the notion of reasoning with Horn-approximations <ref> (Selman and Kautz, 1991) </ref>. Finally, we discuss some robustness issues of model-based representations and show how they support an incremental approach to reasoning. Learning to Reason: Deduction In Chapter 5 we exhibit the computational advantages of the Learning to Reason approach. <p> In this section we show that if B is a basis for the class G of queries, we can answer those queries even when B is not a basis for the knowledge base KB. In order to do that we use the notion of the least upper bound (LUB) <ref> (Selman and Kautz, 1991) </ref> of KB in the class of functions with basis B, which we have already introduced and discussed in Section 2.3.3. To facilitate the presentation we first recall the definition of a theory approximation and prove an important property of this notion.
Reference: <author> Kautz, H. and B. Selman. </author> <year> 1992. </year> <title> Forming concepts for fast inference. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 786-793. </pages>
Reference-contexts: Nevertheless, one might hope that there is a basis for which least upper bounds will always have small representations in some (maybe other) form that admits fast reasoning. Kautz and Selman <ref> (Kautz and Selman, 1992) </ref> show that for Horn representations this is not the case. In particular they show that unless NP non-uniform P there exists a function whose Horn LUB does not have a short representation that allows for efficient reasoning.
Reference: <author> Kautz, H. and B. Selman. </author> <year> 1994. </year> <title> An empirical evaluation of knowledge compilation by theory approximation. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 155-161. </pages>
Reference-contexts: Therefore, for all the 2 jSj 1 queries ff s , reasoning with approximate theories returns "don't know". In <ref> (Kautz, Kearns, and Selman, 1994) </ref> it is shown that, for a family of propositional languages L which consists of kHorn formulae (all Horn formulae with up to k literals in a clause), one can construct examples of theories for which j lub n j is exponential in the number of variables, <p> Thus it motivates an investigation in the direction of reasoning with restricted queries, where it might be possible to avoid these difficulties. Indeed, in <ref> (Kautz and Selman, 1994) </ref> an experimental analysis is presented in which, under severe restrictions on the classes of queries allowed, reasoning with approximate theories is shown to succeed on a large percentage of the queries.
Reference: <author> Kavvadias, D., C. Papadimitriou, and M. Siedri. </author> <year> 1993. </year> <title> On Horn envelopes and hypergraph transversals. </title> <booktitle> In International Symposium on Algorithms and Computation, ISAAC, </booktitle> <pages> pages 399-405. </pages> <publisher> Springer-Verlag. </publisher> <address> LCNS 762. </address>
Reference-contexts: Claim 4.1.5 suggests a simple way for computing the basis for a given query, as required in (1). The problem of computing additional characteristic models, however, is in general a hard problem that we do not address here. (See, <ref> (Kavvadias, Papadimitriou, and Siedri, 1993) </ref>). Neither do we consider computing additional models in an on-line process performed for each query. At this point we assume that the knowledge base is given in the form of its set of characteristic models.
Reference: <author> Kearns, M. </author> <year> 1992. </year> <title> Oblivious pac learning of concepts hierarchies. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 215-222. </pages>
Reference-contexts: In particular, since the number of samples required is polynomial, the procedure is polynomial. It is important not to confuse this approach of sampling from D, the distribution that governs the occurrences of instances in the world, with sampling approaches 3 A similar, more sophisticated approach was developed in <ref> (Kearns, 1992) </ref> for the case in which both the knowledge base and the queries are learned concepts in the pac sense. <p> For example, pac learning has been accepted as a good measure of learning even when learning for the purpose of performing reasoning (e.g. when learning logic programs (Cohen, 1994)). As we have observed in this chapter (and see also <ref> (Kearns, 1992) </ref>) learning algorithms with guaranteed pac performance may yield erroneous reasoning behavior unless they have an additional property: the hypothesis KB must be a subset of the function W (or at least a subset of its least upper bound). <p> In many cases, reasoning with "acceptable" defaults leads to unacceptable conclusions. Problems occur whenever default interact, and in most cases they can be characterized as problems of distinguishing "good" defaults from "bad" ones. 6 It is possible that a better framework to discuss here is that of agnostic learning <ref> (Kearns, Schapire, and Sellie, 1992) </ref>.
Reference: <author> Kearns, M. </author> <year> 1993. </year> <title> Efficient noise-tolerant learning from statistical queries. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 392-401. </pages> <note> 126 Kearns, </note> <author> M. and M. Li. </author> <year> 1988. </year> <title> Learning in the presence of malicious errors. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 267-280, </pages> <address> Chicago, Illinois, </address> <month> May. </month>
Reference-contexts: We give application of the theory to other problems in reasoning, and in particular show that the theory developed here generalizes the model-based approach to reasoning with Horn theories <ref> (Kautz, Kearns, and Selman, 1993) </ref>, and captures even the notion of reasoning with Horn-approximations (Selman and Kautz, 1991). Finally, we discuss some robustness issues of model-based representations and show how they support an incremental approach to reasoning. <p> We note that these are not all the oracles a learner can use when learning a function. For example, the oracles "incomplete membership queries" (Angluin and Slonim, 1991) "faulty example oracles" (Angluin and Laird, 1988) "malicious example oracles" (Valiant, 1985; Kearns and Li, 1988), "statistical queries oracle" <ref> (Kearns, 1993) </ref> are also studied in the literature and can be used here as well. The Reasoning oracles we introduce next model the case where an agent learns from mistakes it makes while reasoning. <p> In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning mentioned above, is somewhat related to Minsky's frames-theory (Minsky, 1975) and has already been studied in a narrower context in <ref> (Kautz, Kearns, and Selman, 1993) </ref>. The problem KB j= ff can be approached using the following model-based strategy: Algorithm MBR: Test Set: A set S of possible assignments. <p> We then prove the necessity of a complete set of characteristic models to performing exact deduction. In Section 4.3 we show that in the special case of Horn theories our theory reduces to the work in <ref> (Kautz, Kearns, and Selman, 1993) </ref>. The complexity of model-based reasoning is directly related to the number of models in the representation. <p> This issue is investigated in Section 4.4, where we compare this size of the model based representation of a Boolean function with the size of other representations of the same function. In particular, our results characterize the Horn theories for which the approach suggested in <ref> (Kautz, Kearns, and Selman, 1993) </ref> is useful and explain the phenomena observed there, regarding the relative sizes of the logical formula representation and model-based representation of KB. <p> We further discuss the issue of answering all CNF queries. In <ref> (Kautz, Kearns, and Selman, 1993) </ref> the deduction theorem was extended to answer any such query. This extension relies on a special property of Horn formulas and does not hold in the general case. We give an example that explains this phenomenon. <p> If x k is the only variable that appears un-negated in C then C is falsified by b (k) . 4.3.1 Characteristic Models In order to relate to the results from <ref> (Kautz, Kearns, and Selman, 1993) </ref> we need a few definitions presented there. <p> Based on this characterization of Horn theories, it is clear that if KB is a Horn theory and M KB any subset of models, then closure (M ) closure (KB) = KB. In <ref> (Kautz, Kearns, and Selman, 1993) </ref> it is shown that if we take M = char H (KB), then we get closure (char H (KB)) = closure (KB) = KB: In particular, Equation 4.5 implies that char H (KB) is the smallest subset of KB with that property. <p> While we have shown that our model-based representation coincides with that of <ref> (Kautz, Kearns, and Selman, 1993) </ref> it turns out that the ability to answer any query relies on a 72 special characteristic of Horn theories, and does not generalize to other propositional theories. We next give a counterexample that exemplifies this. The deduction scheme in (Kautz, Kearns, and Selman, 1993) when ff <p> model-based representation coincides with that of <ref> (Kautz, Kearns, and Selman, 1993) </ref> it turns out that the ability to answer any query relies on a 72 special characteristic of Horn theories, and does not generalize to other propositional theories. We next give a counterexample that exemplifies this. The deduction scheme in (Kautz, Kearns, and Selman, 1993) when ff is a general CN F expression, utilizes the following theorem 5 . Theorem 4.3.4 Let KB be a Horn theory and ff any disjunction. <p> KB j= ff 1 ff 2 if and only if KB j= ff 1 and KB j= ff 2 . Observation (2) implies that it is enough to consider queries that are disjunctions. Given ff, the deduction scheme in <ref> (Kautz, Kearns, and Selman, 1993) </ref> decomposes it into the Horn disjunction fi i s and tests deduction against the fi i s. By Theorem 4.3.4, at least one of the fi i s is implied by KB. <p> It is therefore important to compare this size with the size of other representations of the same function. In the previous section we have shown that our model-based representation is the same as that of <ref> (Kautz, Kearns, and Selman, 1993) </ref> when the theory is Horn. In (Kautz, Kearns, and Selman, 1993) examples are given for large Horn theories with a small set of characteristic models and vice versa, but it was not yet understood when and why it happens. <p> It is therefore important to compare this size with the size of other representations of the same function. In the previous section we have shown that our model-based representation is the same as that of <ref> (Kautz, Kearns, and Selman, 1993) </ref> when the theory is Horn. In (Kautz, Kearns, and Selman, 1993) examples are given for large Horn theories with a small set of characteristic models and vice versa, but it was not yet understood when and why it happens. <p> The other direction is however not true (i.e., there are Horn theories with a small set of characteristic models but an exponential size DNF). We start with a bound on the size of the model-based representation. 5 This theorem follows from McKinsey's proof of Claim 4.3.2. In <ref> (Kautz, Kearns, and Selman, 1993) </ref> it is derived, in a different way, using a completeness theorem for resolution given in (Slage, Chang, and Lee, 1969) (see also (Khardon and Roth, 1994d) for a discussion). 73 Lemma 4.4.1 Let B be a basis for the knowledge base KB, and denote by jDNF <p> The same arguments hold for any b-monotone function with respect to the order relation b (one can simply rename the variables) and therefore jmin b (f )j = jDN F (f )j. Claim 4.4.2 explains the two examples in <ref> (Kautz, Kearns, and Selman, 1993) </ref>. Both examples are 1 n -monotone Horn functions, one has a small DNF and the other has an exponentially large DNF. We note that exponential size model-based representations are not restricted to happen in b-monotone functions. <p> For (ii) notice that if the query ff is a Horn query, then model based reasoning with is correct, by Theorem 4.2.5. For correct reasoning with general queries, it is possible to use the reasoning algorithm from <ref> (Kautz, Kearns, and Selman, 1993) </ref>. 4.6 Abduction with Models We consider in this section the question of performing abduction using a model-based representation. In (Kautz, Kearns, and Selman, 1993) it is shown that for a Horn theory KB, abduction can be done in polynomial time using characteristic models, although using formula <p> For correct reasoning with general queries, it is possible to use the reasoning algorithm from <ref> (Kautz, Kearns, and Selman, 1993) </ref>. 4.6 Abduction with Models We consider in this section the question of performing abduction using a model-based representation. In (Kautz, Kearns, and Selman, 1993) it is shown that for a Horn theory KB, abduction can be done in polynomial time using characteristic models, although using formula based representation the problem is NP-Hard (Sel-man, 1990). <p> One may therefore talk about "positive explanations" instead of explanations. We nevertheless continue with the term explanation. 79 Thus, abduction involves tests for entailment and consistency, but also a search for an explanation that passes both tests. We now show how one can use the algorithm from <ref> (Kautz, Kearns, and Selman, 1993) </ref> for any propositional theory KB. Theorem 4.6.1 Let KB be a background propositional theory with a basis B, let A be an assumption set and q be a query. Let B H = fx 2 f0; 1g n jweight (x) n 1g. <p> Let B H = fx 2 f0; 1g n jweight (x) n 1g. Then, using the set of characteristic models = B [B H KB one can find an abductive explanation of q in time polynomial in jj and jAj. Proof: We use the algorithm Explain suggested in <ref> (Kautz, Kearns, and Selman, 1993) </ref> for the case of a Horn knowledge base. For a Horn theory KB the algorithm uses the set char H (KB) = B H KB defined in Section 4.3.
Reference: <author> Kearns, M. J. and R. E. Schapire. </author> <year> 1990. </year> <title> Efficient distribution-free learning of probabilistic concepts. </title> <booktitle> In Proceedings of the Thirty-First Annual Symposium on Foundations of Computer Science, </booktitle> <volume> volume I, </volume> <pages> pages 382-391. </pages> <publisher> IEEE. </publisher>
Reference-contexts: In particular, we do not need to assume that there exists a consistent world W . In Section 6.5 we 4 In general, we might want to consider the case where x j depends probabilistically on the other attributes, possibly as a p-concept <ref> (Kearns and Schapire, 1990) </ref>. This is more reminiscent of the knowledge representation discussed in (Valiant, 1994a). In this chapter we restrict the discussion to deterministic representations. 5 We note that this look somewhat similar, but is different than the work on Boolean dependencies in Database theory.
Reference: <author> Kearns, M. J., R. E. Schapire, and L. M. Sellie. </author> <year> 1992. </year> <title> Toward efficient agnostic learning. </title> <booktitle> In Proc. 5th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 341-352. </pages> <publisher> ACM Press, </publisher> <address> New York, NY. </address>
Reference-contexts: In particular, since the number of samples required is polynomial, the procedure is polynomial. It is important not to confuse this approach of sampling from D, the distribution that governs the occurrences of instances in the world, with sampling approaches 3 A similar, more sophisticated approach was developed in <ref> (Kearns, 1992) </ref> for the case in which both the knowledge base and the queries are learned concepts in the pac sense. <p> For example, pac learning has been accepted as a good measure of learning even when learning for the purpose of performing reasoning (e.g. when learning logic programs (Cohen, 1994)). As we have observed in this chapter (and see also <ref> (Kearns, 1992) </ref>) learning algorithms with guaranteed pac performance may yield erroneous reasoning behavior unless they have an additional property: the hypothesis KB must be a subset of the function W (or at least a subset of its least upper bound). <p> In many cases, reasoning with "acceptable" defaults leads to unacceptable conclusions. Problems occur whenever default interact, and in most cases they can be characterized as problems of distinguishing "good" defaults from "bad" ones. 6 It is possible that a better framework to discuss here is that of agnostic learning <ref> (Kearns, Schapire, and Sellie, 1992) </ref>.
Reference: <author> Khardon, R., H. Mannila, and D. Roth. </author> <year> 1994. </year> <title> Armstorng relations for Boolean dependencies. </title> <note> In preparation. </note>
Reference-contexts: Our results have some immediate implications in this domain which we develop elsewhere <ref> (Khardon, Mannila, and Roth, 1994) </ref>. 61 model-based reasoning is feasible. This view can be contrasted with an orthogonal line of research, which aims at identifying classes of worlds of limited expressiveness with which one can perform theorem proving efficiently with respect to all queries. <p> In this chapter we restrict the discussion to deterministic representations. 5 We note that this look somewhat similar, but is different than the work on Boolean dependencies in Database theory. The subtle differences in the definitions result in different theories. See <ref> (Khardon, Mannila, and Roth, 1994) </ref> for a discussion of Boolean dependencies in Databases. 102 discuss other knowledge representations and reasoning tasks associated with them, and compare them to the attribute-function representation.
Reference: <author> Khardon, R. and D. Roth. </author> <year> 1994a. </year> <title> Exploiting relevance through model-based reasoning. </title> <booktitle> In AAAI Fall Symposium on Relevance, </booktitle> <pages> pages 109-114. </pages>
Reference-contexts: We view this oracle as the main avenue of interaction with the world: the type of interaction which occurs in random situations. As discussed in Chapter 4 (and, more explicitly, in <ref> (Khardon and Roth, 1994a) </ref>), in situations constrained to satisfy some context condition (e.g., Q = fx 1 = we are in Bostong or Q = fx 1 ^ x 2 ! x 3 g), the occurrences of observations is not governed by D any more, but by some other distribution D
Reference: <author> Khardon, R. and D. Roth. </author> <year> 1994b. </year> <title> Learning to reason. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 682-687. </pages> <note> Submitted for publication. Full version: Technical Report TR-02-94, </note> <institution> Aiken Computation Lab., Harvard University, </institution> <month> January </month> <year> 1994. </year>
Reference: <author> Khardon, R. and D. Roth. </author> <year> 1994c. </year> <title> Learning to reason with a restricted view. </title> <type> Manuscript. </type>
Reference-contexts: A vector is total (total example, total assignment) if every variable is known (i.e., assigned value from f0; 1g). Consider a positive example v 2 f0; 1; flg n which is only partially specified. 1 This approach is further developed in <ref> (Khardon and Roth, 1994c) </ref> where other results in this line are presented. 96 There are various ways in which we can interpret the meaning that v conveys on W . Consider, for example, the following two interpretations: 1. <p> Note that, when defining the example oracle EX D (f ), D is now a probability distribution over f0; 1; flg n . The partial assignment interpretations defined above have some very interesting properties with respect to logical implication, function evaluation etc., that we do not discuss here (See <ref> (Khardon and Roth, 1994c) </ref> for details.). In this section we present only one example, in order to illustrate a case of "Learning to Reason without Reasoning", and to contrast this approach with the approach developed in the rest of the chapter. <p> Clearly z 0 is in k f and C z (u) = 0. The previous theorem shows that given f we can generate a new model based representation, k f , by projecting on all possible subsets of size k of the variables. In <ref> (Khardon and Roth, 1994c) </ref> this problem, as well as other problems in this approach are discussed further and in particular, it is shown that this is essentially the most one can do with partial assignment-based representations. 2 Note that, according to its construction, these partial assignments should be considered using the <p> The "Learning to Reason without Reasoning" result with kCNF queries described above is just one interesting example. Other, positive and negative results in this line are described in <ref> (Khardon and Roth, 1994c) </ref> and we will not describe these here. <p> In this sense, the treatment we suggest in this chapter is at least as general as the one hinted upon in Section 6.1 (and elaborated on in <ref> (Khardon and Roth, 1994c) </ref>). We show now that it is actually strictly more expressive than the interpretations discussed earlier in Section 6.1. Consider first the universal interpretation.
Reference: <author> Khardon, R. and D. Roth. </author> <year> 1994d. </year> <title> A note on Horn theories. </title> <type> Manuscript. </type>
Reference-contexts: Formally, char H (KB) = fu 2 KB j u 62 closure (KB n fug) g: (4.5) The following claim should be attributed to McKinsey (1943) (note that the definitions there are different; an adaptation of this proof to the propositional terminology can be found in <ref> (Khardon and Roth, 1994d) </ref>). A different proof of this property is given by Dechter and Pearl (1992). Claim 4.3.2 (McKinsey (1943)) A theory is Horn if and only if its set of models is closed under intersection. <p> In (Kautz, Kearns, and Selman, 1993) it is derived, in a different way, using a completeness theorem for resolution given in (Slage, Chang, and Lee, 1969) (see also <ref> (Khardon and Roth, 1994d) </ref> for a discussion). 73 Lemma 4.4.1 Let B be a basis for the knowledge base KB, and denote by jDNF (KB)j the size of its DN F representation.
Reference: <author> Khardon, R. and D. Roth. </author> <year> 1994e. </year> <title> Reasoning with models. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 1148-1153. </pages> <note> Submitted for publication. Full version: Technical Report TR-01-94, </note> <institution> Aiken Computation Lab., Harvard University, </institution> <month> January </month> <year> 1994. </year>
Reference: <author> Kirsh, D. </author> <year> 1991. </year> <title> Foundations of AI: the big issues. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 3-30. </pages>
Reference-contexts: As a matter of fact, in a review paper for a special issue of the Artificial Intelligence Journal dedicated to the foundations of AI <ref> (Kirsh, 1991) </ref>, it is stated that many schools of research in Artificial Intelligence consider the principle "Learning can be added later" as one of their fundamental abstract assumptions. Computational considerations, however, render this self-contained approach to reasoning inadequate for commonsense reasoning. <p> While the central role of learning in cognition is acknowledged by many, most lines of research nevertheless study the phenomenon of "learning" separately from that of "reasoning". In contrast to the "Learning can be added later" approach referred to above <ref> (Kirsh, 1991) </ref>, we argue in this thesis that if one wants to develop computational models that account for the flexibility, adaptability and speed of reasoning, a central question to consider is how the intelligent system acquires its knowledge and how this process, of interaction with its environment, influences the performance of <p> Early theories of intelligent systems, however, had assumed that cognition (namely, computational processes like reasoning, language recognition, object identification and other "higher level" cognitive tasks) can be studied separately from learning (See <ref> (Kirsh, 1991) </ref> for a discussion of this issue.). Reasoning in intelligent systems has been studied mostly in the knowledge-based system framework (McCarthy, 1958).
Reference: <author> Kolaitis, P. G. and C. Papadimitriou. </author> <year> 1988. </year> <title> Some computational aspects of circumscription. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 465-469. </pages>
Reference: <author> Kosslyn, S. M. </author> <year> 1983. </year> <title> Image and Mind. </title> <publisher> Harvard Press. </publisher>
Reference: <author> Kraus, S., D. Lehmann, and M. Magidor. </author> <year> 1990. </year> <title> Preferential models and cumulative logics. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 167-207. </pages>
Reference: <author> Kushilevitz, E. and D. Roth. </author> <year> 1993. </year> <title> On learning visual concepts and DNF formulae. </title> <booktitle> In Proceedings of the ACM Workshop on Computational Learning Theory '93, </booktitle> <pages> pages 317-326. </pages> <note> Morgan Kaufmann. To appear in Machine Learning, </note> <month> June </month> <year> 1995. </year>
Reference-contexts: We discuss next the learnability of attribute functions for the case of learning Boolean function with examples only and learning with membership queries. 6.4.1 Learning to Classify over f0; 1; flg n Learning from Examples Only Given the extensive existing literature on learning Boolean functions from examples (see, e.g., <ref> (Kushilevitz and Roth, 1993) </ref>) it is sufficient for our purposes here to argue that those algorithms apply also for the learnability of functions f : f0; 1; flg n ! f0; 1g: Consider for example the standard elimination algorithm for learning conjunctions (Valiant, 1984). <p> From then on, it (1) adds to the conjunction only newly observed attributes, and (2) uses elimination over the set of known attributes, as is done in the usual elimination algorithm. Using the techniques 11 introduced in <ref> (Kushilevitz and Roth, 1993) </ref> we can show how to learn kDNF and kCNF formulae over f0; 1; flg n , for any fixed k. <p> A similar argument shows that kCNF is learnable. As shown in <ref> (Kushilevitz and Roth, 1993) </ref> all the function classes that are polynomially explainable are learnable in the presence of various types of noise, to support a desirable property mentioned earlier. (See the discussion after Example 6.3.1.) To summarize, Theorem 6.4.1 Let F be the class of all conjunctions, disjunctions, kCNF and kDNF
Reference: <author> Levesque, H. </author> <year> 1986. </year> <title> Making believers out of computers. </title> <journal> Artificial Intelligence, </journal> <volume> 30 </volume> <pages> 81-108. </pages>
Reference-contexts: We then argue that this behavior supports the incremental view of reasoning we develop in this thesis. Reasoning within Context It has been argued that in real life situations, one normally completes a lot of missing "context" information when answering queries <ref> (Levesque, 1986) </ref>.
Reference: <author> Levesque, H. </author> <year> 1992. </year> <title> Is reasoning too hard ? In Proceeding of the 3rd NEC research Symposium. </title>
Reference: <author> Levesque, H. and R. Brachman. </author> <year> 1987. </year> <title> Expressiveness and tractability in knowledge representation and reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 3 </volume> <pages> 78-93. </pages>
Reference: <author> Littlestone, N. </author> <year> 1989. </year> <title> Mistake bounds and logarithmic linear-threshold learning algorithms. </title> <type> Ph.D. thesis, </type> <address> U. C. Santa Cruz, </address> <month> March. </month>
Reference-contexts: In this section we observe that in this case, the algorithm can be used to construct a Learn to Reason algorithm. Let A be a mistake bound algorithm and assume it has been used long enough to guarantee pac performance <ref> (Littlestone, 1989) </ref>. In the case it has used up all of its 57 mistakes on negative examples (i.e., on assignments outside of W ), the hypothesis it uses is a "learn from below" hypothesis, and we can reason with it and succeed on all (W; *)-fair queries. <p> taken from some class F of Boolean functions with domain f0; 1; flg n1 . (Notice that this does not even imply that W is consistent.) As performance criteria we will use the criteria accepted in computational learning theory, namely, either the pac criterion (Valiant, 1984) or the mistake-bound criterion <ref> (Littlestone, 1989) </ref>.
Reference: <author> Makinson, D. </author> <year> 1989. </year> <title> General theory of cumulative inference. </title> <editor> In M. Ginsberg M. Reinfrank, J. de Kleer and E. Sandewall, editors, </editor> <booktitle> Non-Monotonic Reasoning. Proceedings of the Second International Workshop on Non-Monotonic Reasoning. </booktitle> <publisher> Springer Verlag. </publisher>
Reference: <author> Mannila, H. and K. J. Raiha. </author> <year> 1986. </year> <title> Design by example: An application of Armstrong relations. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33(2) </volume> <pages> 126-141. </pages>
Reference: <author> McCarthy, J. </author> <year> 1958. </year> <title> Programs with common sense. </title> <editor> In R. Brachman and H. Levesque, editors, </editor> <booktitle> Readings in Knowledge Representation, 1985. </booktitle> <publisher> Morgan-Kaufmann. </publisher>
Reference-contexts: Based on this and on "our introspective views of our own mental structure", as stated by McCarthy and Hayes (1969), a research program, the knowledge-based system approach <ref> (McCarthy, 1958) </ref>, was launched and is today the generally accepted framework for reasoning in intelligent systems. The idea is to store the knowledge in some representation language with a well defined meaning assigned to its sentences. <p> Reasoning in intelligent systems has been studied mostly in the knowledge-based system framework <ref> (McCarthy, 1958) </ref>. There, it is assumed that the knowledge is given to the system, stored in some representation language with a well defined meaning, and that there is a reasoning mechanism, that can be used to determine what can be inferred from the sentences in the KB.
Reference: <author> McCarthy, J. </author> <year> 1980. </year> <title> Circumscription a form of non-monotonic reasoning. </title> <journal> Artificial Intelligence, 13(1,2). </journal>
Reference: <author> McCarthy, J. </author> <year> 1986. </year> <title> Application of circumscription to formalizing common sense. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 89-116. </pages>
Reference: <author> McCarthy, J. and P. Hayes. </author> <year> 1969. </year> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence 4. </booktitle> <publisher> Edinburgh University Press. </publisher>
Reference-contexts: R. Frish, What Little I Remember, 1979 In previous chapters we have introduced the knowledge-based system approach to reasoning. There, knowledge is stored in some representation language with a well defined meaning, and the emphasis is on the comprehensibility 1 of the stored knowledge <ref> (McCarthy and Hayes, 1969) </ref>. Levesque (1986; 1992) argues that reasoning with a more direct representation is easier and better suits commonsense reasoning. He suggests to represent the knowledge base KB in a vivid form, one that bears a strong and direct relationship to the real world. <p> This is related to the frame problem in AI, which is concerned with how to indicate which aspects of the world do not change when an action takes place <ref> (McCarthy and Hayes, 1969) </ref>. While the standard non-monotonic reasoning formalisms do not capture the desirable behavior, that things stay as they are (Hanks and McDermott, 1986), our representation of incomplete information does.
Reference: <author> McKinsey, J. C. C. </author> <year> 1943. </year> <title> The decision problem for some classes of sentences without quantifier. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 8(3) </volume> <pages> 61-76. </pages>
Reference: <author> Minsky, M. </author> <year> 1975. </year> <title> A framework for representing knowledge. </title> <editor> In P. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill. </publisher> <editor> Also in R. Brachman and H. Levesque, </editor> <booktitle> Readings in Knowledge Representation, </booktitle> <year> 1985. </year>
Reference-contexts: In the AI community this approach can be seen as an example of Levesque's notion of "vivid" reasoning mentioned above, is somewhat related to Minsky's frames-theory <ref> (Minsky, 1975) </ref> and has already been studied in a narrower context in (Kautz, Kearns, and Selman, 1993). The problem KB j= ff can be approached using the following model-based strategy: Algorithm MBR: Test Set: A set S of possible assignments. <p> This abstraction has been been criticized by many (e.g., <ref> (Minsky, 1975) </ref>) on the ground that it cannot support non-monotonic reasoning. Indeed, it is widely acknowledged today that a large part of our everyday reasoning involves arriving at conclusions that are not logically entailed by our "theory" of the world.
Reference: <author> Montanari, U. </author> <year> 1974. </year> <title> Networks of constraint: Fundamental properties and applications to picture processing. </title> <journal> Inf. Sci., </journal> <volume> 7 </volume> <pages> 95-132. </pages>
Reference-contexts: However, even finding one solution of a constraint satisfaction problem is known to be hard in general, as discussed above, and different heuristics techniques have 8 Not every n-ary relation can be represented by a network of binary constraints with n-variables <ref> (Montanari, 1974) </ref>. 9 We comment, though, that Valiant's results ((Valiant, 1979b), Fact 7) imply that under simple conditions (e.g., when finding one solution is easy and the problem satisfies a form of self-reducibility), enumerating the solutions is polynomial in their number even when the counting problem is hard.
Reference: <author> Moses, Y. and M. Tennenholtz. </author> <year> 1993. </year> <title> Off-line reasoning for on-line efficiency. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 490-495, </pages> <month> August. </month> <note> 128 Nilsson, </note> <author> N. J. </author> <year> 1986. </year> <title> Probabilistic logic. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 71-87. </pages>
Reference: <author> Orponen, P. </author> <year> 1990. </year> <title> Dempster`s rule of combination is #P-complete. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 245-253. </pages>
Reference: <author> Papadimitriou, C. H. </author> <year> 1991. </year> <title> On selecting a satisfying truth assignment. </title> <booktitle> In Proc. 32nd Ann. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 163-169. </pages>
Reference-contexts: There are various ways of formalizing a preference ordering among models. One well known method used is circumscription, in which minimal models are preferred (McCarthy, 1980; McCarthy, 1986) (A propositional version of circumscription is discussed in <ref> (Papadimitriou, 1991) </ref>.). Another method to define preferred models is discussed in (Selman and Kautz, 1990; Papadimitriou, 1991). In this approach the goal is to find a model of the theory that is maximal with respect to a partial order defined on the models by the default rules.
Reference: <author> Pearl, J. </author> <year> 1988. </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: For definitions and an elaborate discussion of Bayesian belief networks, the expressiveness of this representation, and the type of inference one can utilize using it, see <ref> (Pearl, 1988) </ref>. A Bayesian belief network (causal network) consists of a graphical structure augmented by a set of probabilities. The graphical structure is a directed acyclic graph (DAG) in which nodes represent random variables (domain variables) and edges represent the existence of direct causal influence between the linked variables. <p> These techniques require, in the worst case, exponential search time, and analyzing those techniques in order to get some performance guarantees is usually hard. We exemplify how the counting point of view taken here can be used to evaluate one class of heuristics <ref> (Dechter and Pearl, 1988) </ref> and restrict its feasibility. Dechter and Pearl suggest to use counting to guide the search according to an estimate of the confidence we have that a specific solution can be extended further to a full solution. <p> of the problem of selecting a model.) In this chapter we develop a model-based approach to commonsense reasoning, in which the knowledge base is represented as a set of models (satisfying assignments) 1 This emphasis is true not only for the logical, but also for probabilistic approaches to reasoning, e.g., <ref> (Pearl, 1988) </ref>, but we restrict ourselves here to the logical approach. 60 of the world rather then a logical formula describing it.
Reference: <author> Pearl, J. </author> <year> 1990. </year> <title> Reasoning with belief functions: An analysis of compatibility. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 4 </volume> <pages> 343-389. </pages>
Reference: <author> Poole, D. </author> <year> 1993. </year> <title> On the hardness of approximate reasoning. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 607-612, </pages> <month> August. </month>
Reference-contexts: The first might include constraining the distributions we can represent in our belief networks (e.g., <ref> (Poole, 1993) </ref>), while the second could imply studying restrictions on the type of queries we need to respond to. This is motivated also by the results in Section 2.3.3 that suggest that a possible approach to allow for efficient reasoning might be to constrain the queries (rather than the "world").
Reference: <author> Provan, J. S. and M. O. Ball. </author> <year> 1983. </year> <title> The complexity of counting cuts and of computing the probability that a graph is connected. </title> <journal> SIAM Journal of Computing, </journal> <volume> 12(4) </volume> <pages> 777-788, </pages> <month> November. </month>
Reference-contexts: Theorem 2.2.1 [Hardness of Exact Counting] Let 2 L be a propositional formula on n variables. If L is one of the following propositional languages, counting the number of satisfying assignments of is complete for #P: (1) L = 2MONCNF (Valiant, 1979b) (2) L = 2BPMONCNF <ref> (Provan and Ball, 1983) </ref> (3) L = 2HORN (4) L = 3-2HORN (5) L = 4-2MON Theorem 2.2.2 [Hardness of Approximation] Let 2 L be a propositional formula on n variables, and let * &gt; 0 be any constant. <p> following propositional languages, counting the number of satisfying assignments of is complete for #P: (1) L = 2MONCNF (2) L = 2BPMONCNF (3) L = 2HORN (4) L = 3-2HORN (5) L = 4-2MON Proof: (1) and (2) are well known: (1) is proved in (Valiant, 1979b); (2) is from <ref> (Provan and Ball, 1983) </ref>. We can get (3) From (2), by negating all the variables in one of the bipartite sets. To prove (4), given a formula in 2HORN we rewrite it, without changing the number of solutions, as a 3-2HORN formula.
Reference: <author> Provan, M. G. </author> <year> 1990. </year> <title> A logical-based analysis of Dempster-Shafer theory. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 4 </volume> <pages> 451-498. </pages>
Reference: <author> Provan, M. G. </author> <year> 1992. </year> <title> The validity of Dempster-Shafer belief functions. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 6 </volume> <pages> 389-399. </pages>
Reference: <author> Reiter, R. </author> <year> 1980. </year> <title> A logic for default reasoning. </title> <journal> Artificial Intelligence, 13(1,2). </journal>
Reference: <author> Reiter, R. </author> <year> 1987. </year> <title> Nonmonotonic reasoning. </title> <booktitle> In Annual Reviews of Computer Science. </booktitle> <pages> pages 147-188. </pages>
Reference-contexts: In this section we show that if we add a few base assignments to our basis, the algorithm presented there works in the general case too. Abduction is the task of finding a minimal explanation to some observation. Formally <ref> (Reiter and De Kleer, 1987) </ref>, the reasoner is given a knowledge base KB (the background theory), a set of propositional letters 9 A (the assumption set), and a query letter q. An explanation of q is a minimal subset E A such that 1. <p> KB ^ (^ x2E x) j= q and 9 The task of abduction is normally defined with arbitrary literals for explanations. For Horn theories explanations turn out to be composed of positive literals (this can be concluded from Corollary 4 in <ref> (Reiter and De Kleer, 1987) </ref>). Here we restrict ourselves to explanations composed of positive literals (by allowing only positive literals in the assumption set) when using general theories. One may therefore talk about "positive explanations" instead of explanations.
Reference: <author> Reiter, R. and J. De Kleer. </author> <year> 1987. </year> <title> Foundations of assumption-based truth maintenance systems. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 183-188. </pages>
Reference-contexts: In this section we show that if we add a few base assignments to our basis, the algorithm presented there works in the general case too. Abduction is the task of finding a minimal explanation to some observation. Formally <ref> (Reiter and De Kleer, 1987) </ref>, the reasoner is given a knowledge base KB (the background theory), a set of propositional letters 9 A (the assumption set), and a query letter q. An explanation of q is a minimal subset E A such that 1. <p> KB ^ (^ x2E x) j= q and 9 The task of abduction is normally defined with arbitrary literals for explanations. For Horn theories explanations turn out to be composed of positive literals (this can be concluded from Corollary 4 in <ref> (Reiter and De Kleer, 1987) </ref>). Here we restrict ourselves to explanations composed of positive literals (by allowing only positive literals in the assumption set) when using general theories. One may therefore talk about "positive explanations" instead of explanations.
Reference: <author> Reiter, R. and Criscuolo G. </author> <year> 1981. </year> <title> On interacting defaults. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 270-276. </pages>
Reference-contexts: attribute adult in a simple way. 8 We could disjunct it with the attribute function from Example 6.3.1, but will assume, for clarity, that those are different agents. 109 We note that most non-monotonic logics in AI require the explicit addition of preferences in order to deal with interacting defaults <ref> (Reiter and G., 1981) </ref>. In Section 6.3.1 we discuss model preferences approaches and compare them to our approach. In some cases, not only is there more information relevant to predicting one attribute than to others, as above, but some of the information might even mislead the prediction of some attributes.
Reference: <author> Roth, D. </author> <year> 1993. </year> <title> On the hardness of approximate reasoning. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 613-618, </pages> <month> August. </month> <note> To Appear in Artificial Intelligence Journal, </note> <year> 1995. </year>
Reference-contexts: We discuss next the learnability of attribute functions for the case of learning Boolean function with examples only and learning with membership queries. 6.4.1 Learning to Classify over f0; 1; flg n Learning from Examples Only Given the extensive existing literature on learning Boolean functions from examples (see, e.g., <ref> (Kushilevitz and Roth, 1993) </ref>) it is sufficient for our purposes here to argue that those algorithms apply also for the learnability of functions f : f0; 1; flg n ! f0; 1g: Consider for example the standard elimination algorithm for learning conjunctions (Valiant, 1984). <p> From then on, it (1) adds to the conjunction only newly observed attributes, and (2) uses elimination over the set of known attributes, as is done in the usual elimination algorithm. Using the techniques 11 introduced in <ref> (Kushilevitz and Roth, 1993) </ref> we can show how to learn kDNF and kCNF formulae over f0; 1; flg n , for any fixed k. <p> A similar argument shows that kCNF is learnable. As shown in <ref> (Kushilevitz and Roth, 1993) </ref> all the function classes that are polynomially explainable are learnable in the presence of various types of noise, to support a desirable property mentioned earlier. (See the discussion after Example 6.3.1.) To summarize, Theorem 6.4.1 Let F be the class of all conjunctions, disjunctions, kCNF and kDNF
Reference: <author> Roth, D. </author> <year> 1994. </year> <title> Learning to reason with incomplete information. </title> <type> Manuscript. </type>
Reference-contexts: Our results have some immediate implications in this domain which we develop elsewhere <ref> (Khardon, Mannila, and Roth, 1994) </ref>. 61 model-based reasoning is feasible. This view can be contrasted with an orthogonal line of research, which aims at identifying classes of worlds of limited expressiveness with which one can perform theorem proving efficiently with respect to all queries. <p> In this chapter we restrict the discussion to deterministic representations. 5 We note that this look somewhat similar, but is different than the work on Boolean dependencies in Database theory. The subtle differences in the definitions result in different theories. See <ref> (Khardon, Mannila, and Roth, 1994) </ref> for a discussion of Boolean dependencies in Databases. 102 discuss other knowledge representations and reasoning tasks associated with them, and compare them to the attribute-function representation.
Reference: <author> Schuurmans, D. and R. Greiner. </author> <year> 1994. </year> <title> Learning default concepts. </title> <booktitle> In Proceedings of the Tenth Canadian Conference on Artificial Intelligence (CSCSI-94). 129 Selman, B. </booktitle> <year> 1990. </year> <title> Tractable Default Reasoning. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, University of Toronto. </institution>
Reference-contexts: The work that is most relevant to our current study is that of Schuurmans and Greiner <ref> (Schuurmans and Greiner, 1994) </ref>. This paper studies the problem of learning "default concepts", from partial assignments that are classified as either positive or negative examples. <p> In this model, examples are drawn according to some probability distribution, and then a (probabilistic or arbitrary) "blocking process" hides some of the attributes. (This corresponds to the existential interpretation from above.) There are some major differences between our approach and the approach suggested 118 in <ref> (Schuurmans and Greiner, 1994) </ref>. The main difference is that they are interested in learning "default concepts" over f0; 1g n in order to augment a knowledge base, and then reason with it using an existing default reasoning formalism.
Reference: <author> Selman, B. and H. Kautz. </author> <year> 1990. </year> <title> Model-preference default theories. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 287-322. </pages>
Reference-contexts: This corresponds to assigning the value "true" to the attribute "here" for the purpose of answering the question. Sometimes we need a more expressive language to describe our assumptions regarding the current context and assume, say, that some rule applies <ref> (Selman and Kautz, 1990) </ref>. For example, we may assume (in the "conference" context) that if someone has a car, then it is a rental car.
Reference: <author> Selman, B. and H. Kautz. </author> <year> 1991. </year> <title> Knowledge compilation using Horn approximations. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 904-909. </pages>
Reference-contexts: We give application of the theory to other problems in reasoning, and in particular show that the theory developed here generalizes the model-based approach to reasoning with Horn theories (Kautz, Kearns, and Selman, 1993), and captures even the notion of reasoning with Horn-approximations <ref> (Selman and Kautz, 1991) </ref>. Finally, we discuss some robustness issues of model-based representations and show how they support an incremental approach to reasoning. Learning to Reason: Deduction In Chapter 5 we exhibit the computational advantages of the Learning to Reason approach. <p> In this section we show that if B is a basis for the class G of queries, we can answer those queries even when B is not a basis for the knowledge base KB. In order to do that we use the notion of the least upper bound (LUB) <ref> (Selman and Kautz, 1991) </ref> of KB in the class of functions with basis B, which we have already introduced and discussed in Section 2.3.3. To facilitate the presentation we first recall the definition of a theory approximation and prove an important property of this notion.
Reference: <author> Shafer, G. </author> <year> 1990. </year> <title> Perspectives of the theory and practice of belief functions. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 4 </volume> <pages> 323-362. </pages>
Reference: <author> Shastri, L. </author> <year> 1993. </year> <title> A computational model of tractable reasoning taking inspiration from cognition. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 202-207, </pages> <month> August. </month>
Reference-contexts: We comment that the approach of "restricting the world" has been criticized also on the grounds that existing results do not meet the strong tractability requirements for commonsense reasoning as described, for example, in <ref> (Shastri, 1993) </ref>), even though (as argued, for example, in (Doyle and Patil, 1991)) the inference deals with limited expressiveness and is sometimes restricted in implausible ways. Our use of restricted queries is motivated also by computational results we present in the first part of the thesis. <p> None of these works meet the strong tractability requirements for common-sense reasoning as described, for example, in <ref> (Shastri, 1993) </ref>), even though, (as argued, for example, in (Doyle and Patil, 1991)) the inference deals with limited expressiveness and is sometimes restricted in implausible ways. An additional motivation for this work is the current disconnected state of the fields of learning and reasoning. <p> We comment that this approach of "restricting the world" has been criticized also on the grounds that existing results do not meet the strong tractability requirements for commonsense reasoning as described, for example, in <ref> (Shastri, 1993) </ref>), even though (as argued, for example, in (Doyle and Patil, 1991)) the inference deals with limited expressiveness and is sometimes restricted in implausible ways. The main interest in model-based representation arises from its computational efficiency.
Reference: <author> Shoham, Y. </author> <year> 1988. </year> <title> Reasoning about Change. </title> <publisher> MIT Press. </publisher>
Reference-contexts: First, prediction tasks seem to be fairly general; combining and chaining prediction tasks might be sufficient to deal with reasoning in the temporal domain <ref> (Shoham, 1988) </ref> and to reason about action. Second, the general reasoning task implies some uniformity in the representation, in the sense that we can, in principle, answer queries with respect to all attributes.
Reference: <author> Sinclair, A. </author> <year> 1988. </year> <title> Randomized Algorithms for Counting and Generating Combinatorial Structures. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, University of Edinburgh. </institution>
Reference-contexts: The next lemma provides the main step in the proof of (1). The proof is based on the "blow-up" technique developed in (Jerrum, Valiant, and Vazirani, 1986). The lemma is a variant of one that appears in <ref> (Sinclair, 1988) </ref>. Lemma 2.5.3 For any *, approximating the number of independent sets of a graph on n vertices within 2 n 1* is NP-hard.
Reference: <author> Slage, J.R., C.L. Chang, and R.C.T. Lee. </author> <year> 1969. </year> <title> Completeness theorems for semantic resolution in consequence finding. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 281-285, </pages> <month> August. </month>
Reference-contexts: We start with a bound on the size of the model-based representation. 5 This theorem follows from McKinsey's proof of Claim 4.3.2. In (Kautz, Kearns, and Selman, 1993) it is derived, in a different way, using a completeness theorem for resolution given in <ref> (Slage, Chang, and Lee, 1969) </ref> (see also (Khardon and Roth, 1994d) for a discussion). 73 Lemma 4.4.1 Let B be a basis for the knowledge base KB, and denote by jDNF (KB)j the size of its DN F representation.
Reference: <author> Spirtes, P., C. Glymour, and R. Scheines. </author> <year> 1993. </year> <title> Causation, Prediction, and Search. </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Much of the work on detecting causality (e.g., <ref> (Spirtes, Glymour, and Scheines, 1993) </ref>) is concerned with this issue.
Reference: <author> Stockmeyer, L. </author> <year> 1985. </year> <title> On approximation algorithms for #P. </title> <journal> SIAM Journal of Computing, </journal> <volume> 14 </volume> <pages> 849-861. </pages>
Reference: <author> Toda, S. </author> <year> 1989. </year> <title> On the computational power of PP and P. </title> <booktitle> In IEEE Symp. of Foundation of Computer Science, </booktitle> <volume> number 30, </volume> <pages> pages 514-519. </pages>
Reference: <author> Touretzky, D. </author> <year> 1986. </year> <title> The Mathematics of Inheritance Systems. </title> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Touretzky, D., J. Horty, and R. Thomason. </author> <year> 1987. </year> <title> A clash of intuitions: The current state of nonmonotonic multiple inheritance systems. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Moreover, the study of reasoning in the presence of incomplete information within the knowledge-based systems framework has shown that even capturing what people view as plausible patterns of reasoning is not easy (see, e.g., <ref> (Touretzky, Horty, and Thomason, 1987) </ref>, "A clash of intuitions"). Most formalisms, in order to capture some aspects of "default" reasoning, had to give up others. <p> Moreover, some studies of reasoning in the presence of incomplete information within the knowledge-based systems framework have shown that capturing even what people view as plausible patterns of reasoning is not easy (see, e.g., <ref> (Touretzky, Horty, and Thomason, 1987) </ref>). Most formalisms, in attempting to capture some aspects of "default" reasoning give up on others. Multiple levels of specificity of information, irrelevant information and conflicting defaults are among the aspects that the various formalisms have found difficult to reconcile.
Reference: <author> Valiant, L. G. </author> <year> 1979a. </year> <title> The complexity of computing the permanent. </title> <journal> Theoretical Computer Science, </journal> <volume> 8 </volume> <pages> 189-201. </pages>
Reference-contexts: two approximation algorithms A and B are poly-nomially related when A, a relative approximation algorithm for the probability P that is polynomial in ffi, can be simulated in polynomial time to yield B, which relatively approximates P 0 , and is also polynomial in ffi, and vice versa. 1 In <ref> (Valiant, 1979a) </ref> the definition is given in terms of "counting Turing machines". 14 Assume we can approximate M 1 and M 2 to within ffi. That is, we can find M 0 0 such that M 0 0 0 0 2 .
Reference: <author> Valiant, L. G. </author> <year> 1979b. </year> <title> The complexity of enumeration and reliability problems. </title> <journal> SIAM Journal of Computing, </journal> <volume> 8 </volume> <pages> 410-421. </pages> <note> 130 Valiant, </note> <author> L. G. </author> <year> 1984. </year> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November. </month>
Reference-contexts: Proofs are given in the Section 2.5. Theorem 2.2.1 [Hardness of Exact Counting] Let 2 L be a propositional formula on n variables. If L is one of the following propositional languages, counting the number of satisfying assignments of is complete for #P: (1) L = 2MONCNF <ref> (Valiant, 1979b) </ref> (2) L = 2BPMONCNF (Provan and Ball, 1983) (3) L = 2HORN (4) L = 3-2HORN (5) L = 4-2MON Theorem 2.2.2 [Hardness of Approximation] Let 2 L be a propositional formula on n variables, and let * &gt; 0 be any constant. <p> L is one of the following propositional languages, counting the number of satisfying assignments of is complete for #P: (1) L = 2MONCNF (2) L = 2BPMONCNF (3) L = 2HORN (4) L = 3-2HORN (5) L = 4-2MON Proof: (1) and (2) are well known: (1) is proved in <ref> (Valiant, 1979b) </ref>; (2) is from (Provan and Ball, 1983). We can get (3) From (2), by negating all the variables in one of the bipartite sets. To prove (4), given a formula in 2HORN we rewrite it, without changing the number of solutions, as a 3-2HORN formula.
Reference: <author> Valiant, L. G. </author> <year> 1985. </year> <title> Learning disjunctions of conjunctions. </title> <booktitle> In Proceedings of the International Joint Conference of Artificial Intelligence, </booktitle> <pages> pages 560-566. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Valiant, L. G. </author> <year> 1994a. </year> <title> Circuits of the Mind. </title> <publisher> Oxford University Press, </publisher> <month> November. </month>
Reference-contexts: In our approach, a world representation is not known to the agent who is trying to access it via some reasonable interface, acquiring information that allows her to answer queries correctly and efficiently. This work is similar in spirit to the Neuroidal model developed by Valiant <ref> (Valiant, 1994a) </ref>. The model developed there provides a more comprehensive approach to cognition and, akin to our approach, it views learning as an integral and crucial part of the process. There, the reasoner reasons from a learned knowledge base, a complex circuit, and this can be modeled by our framework. <p> approach, which can be studied also in the more general representations studied previously in the thesis, we prefer to discuss the attribute-function representation here since this may be a better starting point for a more formal investigation of these questions in other models and in particular, in Valiant's neuroidal model <ref> (Valiant, 1994a) </ref>. In the next section we discuss a slightly different approach from that in the rest of this chapter. The approach discussed is simply an extension of the Learning to Reason approach that can handle partial assignments in the input. <p> In Section 6.5 we 4 In general, we might want to consider the case where x j depends probabilistically on the other attributes, possibly as a p-concept (Kearns and Schapire, 1990). This is more reminiscent of the knowledge representation discussed in <ref> (Valiant, 1994a) </ref>. In this chapter we restrict the discussion to deterministic representations. 5 We note that this look somewhat similar, but is different than the work on Boolean dependencies in Database theory. The subtle differences in the definitions result in different theories. <p> We do not know of any "traditional" formalism that can handle in a satisfying way (efficiently, or even qualitatively) all the aspects presented by those examples. We note, though, that our first example is a variant of an example considered in <ref> (Valiant, 1994a) </ref>, and that all the examples we consider here could be 106 considered also in the Rationality framework (Valiant, 1994b) and be implemented in principle on the Neuroidal Model (Valiant, 1994a). <p> We note, though, that our first example is a variant of an example considered in <ref> (Valiant, 1994a) </ref>, and that all the examples we consider here could be 106 considered also in the Rationality framework (Valiant, 1994b) and be implemented in principle on the Neuroidal Model (Valiant, 1994a). A (partial) list of other papers that have discussed (a subset of) these examples includes (Bacchus et al., 1993; Etherington, 1988; Geffner, 1990; Reiter, 1980; Reiter and G., 1981; Selman, 1990; Touretzky, Horty, and Thomason, 1987).
Reference: <author> Valiant, L. G. </author> <year> 1994b. </year> <title> Rationality. </title> <type> Technical Report TR-32-94, </type> <institution> Aiken Computation Lab., Harvard University, </institution> <month> November. </month>
Reference-contexts: Our treatment of incomplete information in this part of the thesis follows the suggestion made in <ref> (Valiant, 1994b) </ref>. <p> In this chapter we formalize this intuition and use it to develop a theory that supports efficient reasoning with incomplete information. Our treatment of incomplete information follows the suggestion made in <ref> (Valiant, 1994b) </ref>. <p> 1 ^ x 2 ! x 3 g), the occurrences of observations is not governed by D any more, but by some other distribution D Q which is the distribution we see by filtering out all those observations that do not satisfy Q. (We follow here the formulation suggested in <ref> (Valiant, 1994b) </ref>). We denote this oracle by EX (D Q ). <p> We note, though, that our first example is a variant of an example considered in (Valiant, 1994a), and that all the examples we consider here could be 106 considered also in the Rationality framework <ref> (Valiant, 1994b) </ref> and be implemented in principle on the Neuroidal Model (Valiant, 1994a). A (partial) list of other papers that have discussed (a subset of) these examples includes (Bacchus et al., 1993; Etherington, 1988; Geffner, 1990; Reiter, 1980; Reiter and G., 1981; Selman, 1990; Touretzky, Horty, and Thomason, 1987).
Reference: <author> Valiant, L. G. and V. V. Vazirani. </author> <year> 1986. </year> <title> NP is as easy as detecting unique solutions. </title> <journal> Theoretical Computer Science, </journal> <volume> 47 </volume> <pages> 85-93. 131 </pages>
Reference-contexts: It is possible, though, for a #P-complete problem, even if its underlying decision problem is easy, to resist even an efficient approximate solution. An example for that was given in <ref> (Jerrum, Valiant, and Vazirani, 1986) </ref>, and in this chapter we exhibit further examples of this phenomenon. We prove, for various propositional languages for which solving satisfiability is easy, that it is NP-hard to approximate the number of satisfying assignments even in a very weak sense. <p> We note that a related class of problems of interest to AI, that of randomly generating solutions from a uniform distribution, was shown in <ref> (Jerrum, Valiant, and Vazirani, 1986) </ref> to be equivalent to randomized approximate counting, for a wide class of problems. (All natural problems considered here, e.g., finding satisfying assignments of Boolean formulae and various graph problems are in this class.) It is therefore enough, from the computational complexity point of view, to consider <p> This can easily be handled as we do below). Notice that the rewriting technique used in (5) of that theorem does not extend for approximations. The next lemma provides the main step in the proof of (1). The proof is based on the "blow-up" technique developed in <ref> (Jerrum, Valiant, and Vazirani, 1986) </ref>. The lemma is a variant of one that appears in (Sinclair, 1988). Lemma 2.5.3 For any *, approximating the number of independent sets of a graph on n vertices within 2 n 1* is NP-hard. <p> The lemma is a variant of one that appears in (Sinclair, 1988). Lemma 2.5.3 For any *, approximating the number of independent sets of a graph on n vertices within 2 n 1* is NP-hard. Proof: We use the "blow-up" technique introduced in <ref> (Jerrum, Valiant, and Vazi-rani, 1986) </ref>, to reduce the problem of approximating the number of independent sets in G to the k-INDEPENDENT-SET problem (Garey and Johnson, 1979). <p> Given a CNF knowledge base, even with the added information that it has a short DNF, the reasoning problem is still hard. This is so since it is NP-hard to find a satisfying assignment for a CNF expression even if one knows that it has exactly one satisfying assignment <ref> (Valiant and Vazirani, 1986) </ref>.
References-found: 109

