URL: http://www.cs.columbia.edu/~simonb/papers/thesis.ps.gz
Refering-URL: http://www.cs.columbia.edu/~simonb/
Root-URL: http://www.cs.columbia.edu
Title: Design and Evaluation of Feature Detectors  
Author: Simon Baker 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the Graduate School of Arts and Sciences  
Date: 1998  
Affiliation: Columbia University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> I.E. Abdou and W.K. Pratt. </author> <title> Quantitative design and evaluation of enhancement/thresholding edge detectors. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 67(5) </volume> <pages> 753-763, </pages> <month> May </month> <year> 1979. </year>
Reference-contexts: In Cartesian coordinates, this corresponds to using the weighting function w (x; y) = 1=(x 2 + y 2 ) 1=2 . Another example of the use of non-uniformly weighted L 2 norms is <ref> [1] </ref>. In this paper, Abdou and Pratt mention that weighting the pixels so as to reduce the influence of pixels that are distant from the center pixel improves Pratt's Figure of Merit [100], but few details are given. <p> Naturally, there is an inherent trade off between these two measures, as is seen for example in [6]. These two measures are of fundamental importance in most applications and have been widely studied, including in [36], <ref> [1] </ref>, [80], [103], and [32] Parameter Estimation Accuracy: Another fundamental class of measures consists of those that assess the accuracy with which the parameters of the feature (e.g. orientation, sub-pixel localization, and step magnitude) are estimated. These measures are important for any application that actually uses the feature parameters. <p> These measures are important for any application that actually uses the feature parameters. These measures have also been widely studied, including in [31], <ref> [1] </ref>, [11], [94], and [114]. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. <p> These measures have also been widely studied, including in [31], <ref> [1] </ref>, [11], [94], and [114]. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. Canny's optimality criterion can be regarded as another example, combining a robustness component and a localization accuracy component, with a third component that penalizes multiple responses to the same edge [20] [27]. Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. <p> There are at least four ways of estimating the measures in the absence of ground truth: Mathematical Analysis: If the feature detection algorithm is simple enough, it is sometimes possible to derive analytical expressions for some of the performance measures. For example, Abdou and Pratt <ref> [1] </ref> analyze the robustness of several simple edge detectors, Berzins [11] analyzes the localization estimation of a Laplacian edge detector, and Ramesh and Haralick [103] analyze the robustness and parameter estimation accuracy of two different detectors. <p> Statistical Tests: A solution to the first of these two problems is to use numerical techniques instead of analytical ones. Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, [36], [31], <ref> [1] </ref>, [95], [80], and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap. <p> After computing the coefficients c ij for every manifold sample point using the method described above, I randomly generated a sequence of ideal feature instances. The normalized parameters A and B of the feature were generated uniformly at random in the interval <ref> [0; 1] </ref>. To generate the unnormalized parameters, a point on the manifold was chosen uniformly at random and its un-normalized parameters used. Then I generated the ideal feature using the feature and sensor models described above. <p> One example is FDR p fi CPE 1p , where p 2 <ref> [0; 1] </ref> is a number that can be used to adjust the relative importance of feature detection robustness and parameter estimation accuracy.
Reference: [2] <author> J.F. Abramatic. </author> <title> Why the simplest "Hueckel" edge detector is a Roberts operator. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 17 </volume> <pages> 79-83, </pages> <year> 1981. </year>
Reference-contexts: Some of these studies have attempted to show the similarities of specific detectors. For example, both Rosenfeld [107] and Abramatic <ref> [2] </ref> studied the Hueckel [50] and Roberts [105] detectors. They showed that if the Hueckel operator is implemented in a 2fi2 window, it turns out to be the same as a variant of the Roberts' 24 cross operator.
Reference: [3] <author> A.C. Aitken. </author> <title> On least squares and linear combinations of observations. </title> <journal> Proceedings of the Royal Society of Edinburgh A, </journal> <volume> 55 </volume> <pages> 42-47, </pages> <year> 1934. </year>
Reference-contexts: So, finding the optimal weighting function corresponds to selecting the weighting function that gives the best linear unbiased estimate of the solution to a weighted least squares problem [63] [99]. The answer to this problem was found by Aitken in <ref> [3] </ref>. The optimal weighting function is: w (n; m) = Var [(n; m)] where Var [(n; m)] = E [ 2 (n; m)] E [(n; m)] 2 is the variance of the noise in pixel (n; m). This result assumes that the noise in each pixel in independent.
Reference: [4] <author> S. Baker and S.K. Nayar. </author> <title> Algorithms for pattern rejection. </title> <booktitle> In Proceedings of the 13th International Conference on Pattern Recognition, volume II Track B, </booktitle> <pages> pages 869-874, </pages> <address> Vienna, Austria, </address> <month> August </month> <year> 1996. </year> <month> IAPR. </month>
Reference-contexts: Further, the search does not need to be performed at every pixel. Amongst other techniques, I use a pattern rejection algorithm <ref> [4] </ref> [5] to eliminate a vast majority of pixels without even needing to project fully into the low dimensional subspace. Such a rejection scheme is effective since most pixels in an image will typically not exhibit the feature of interest. <p> Since the distance from the subspace 59 is approximately a lower bound on the distance from the manifold, the pixel can be eliminated if the input is too far from the subspace. Finally, using the pattern rejection techniques in <ref> [4] </ref> and [5], it is even possible to eliminate most of the cost of computing the distance to the K-L subspace. Parallel Implementation: Feature detection is inherently a parallelizable task because a detector can be applied to each pixel independently.
Reference: [5] <author> S. Baker and S.K. Nayar. </author> <title> Pattern rejection. </title> <booktitle> In Proceedings of the 1996 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 544-549, </pages> <address> San Francisco, California, June 1996. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Further, the search does not need to be performed at every pixel. Amongst other techniques, I use a pattern rejection algorithm [4] <ref> [5] </ref> to eliminate a vast majority of pixels without even needing to project fully into the low dimensional subspace. Such a rejection scheme is effective since most pixels in an image will typically not exhibit the feature of interest. <p> Since the distance from the subspace 59 is approximately a lower bound on the distance from the manifold, the pixel can be eliminated if the input is too far from the subspace. Finally, using the pattern rejection techniques in [4] and <ref> [5] </ref>, it is even possible to eliminate most of the cost of computing the distance to the K-L subspace. Parallel Implementation: Feature detection is inherently a parallelizable task because a detector can be applied to each pixel independently.
Reference: [6] <author> S. Baker, S.K. Nayar, and H. Murase. </author> <title> Parametric feature detection. </title> <journal> International Journal of Computer Vision, </journal> <volume> 27(1) </volume> <pages> 27-50, </pages> <year> 1998. </year> <month> 154 </month>
Reference-contexts: Naturally, there is an inherent trade off between these two measures, as is seen for example in <ref> [6] </ref>. <p> Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, [36], [31], [1], [95], [80], and <ref> [6] </ref>. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap.
Reference: [7] <author> D.F. Barbe. </author> <title> Charge-Coupled Devices. </title> <publisher> Springer-Verlag, </publisher> <year> 1980. </year>
Reference-contexts: First, the light flux falling on each sensor element is averaged, or integrated. If the pixels are rectangular <ref> [7] </ref> [85], the averaging function is simply the rectangular function [15]: a (x; y) = w x w y 1 x; w y where w x and w y are the x and y dimensions of the pixel. Second, the pixels are sampled.
Reference: [8] <author> P.R. Beaudet. </author> <title> Rotational invariant image operators. </title> <booktitle> In Proceedings of the 4th International Conference on Pattern Recognition, </booktitle> <pages> pages 579-583, </pages> <address> Tokyo, Japan, </address> <year> 1978. </year>
Reference-contexts: Perhaps the first differential invariant corner detector was the Beaudet detector <ref> [8] </ref>.
Reference: [9] <author> S. Becker and Jr. </author> <title> V.M. Bove. Semiautomatic 3-D model extraction from uncalibrated 2-D camera views. </title> <booktitle> In Proceedings of SPIE Visual Data Exploration and Analysis II, </booktitle> <volume> volume 2410, </volume> <pages> pages 447-461, </pages> <address> San Jose, California, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: If a shorter focal length was ever needed, Tsai's algorithm could easily be used to compensate for any noticeable radial distortion. Finally, note that measures 123 similar to my global measures of coherence have actually been used in the past to perform camera calibration for the radial distortion <ref> [9] </ref> [18]. 6.3.2 Efficient Computation using Monte Carlo Since the number of detected edges is usually at most n = 10 3 , it is possible to compute the first three measures by simply enumerating all pairs of edges.
Reference: [10] <author> F. Bergholm. </author> <title> Edge focusing. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(6) </volume> <pages> 726-741, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: The primary goal of scale space theory, at least as far as feature detection is concerned, is to combine the outputs of operators at multiple scales in a coherent manner [79]. A number of attempts have been made at studying the output of detectors across scales, including, <ref> [10] </ref>, [61], and [30]. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. <p> A number of attempts have been made at studying the output of detectors across scales, including, <ref> [10] </ref>, [61], and [30]. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions.
Reference: [11] <author> V. Berzins. </author> <title> Accuracy of Laplacian edge detectors. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 27 </volume> <pages> 195-210, </pages> <year> 1984. </year>
Reference-contexts: Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] [54], accuracy <ref> [11] </ref> [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> These measures are important for any application that actually uses the feature parameters. These measures have also been widely studied, including in [31], [1], <ref> [11] </ref>, [94], and [114]. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. <p> For example, Abdou and Pratt [1] analyze the robustness of several simple edge detectors, Berzins <ref> [11] </ref> analyzes the localization estimation of a Laplacian edge detector, and Ramesh and Haralick [103] analyze the robustness and parameter estimation accuracy of two different detectors. <p> Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions. He proceeded to show how the systematic bias of the Laplacian of Gaussian can be corrected. A related study, with somewhat different goals, is that of Berzins <ref> [11] </ref>. A very important issue related to that of scale is the information content of edges. One of the major reasons for detecting edges is their supposedly high information content [70].
Reference: [12] <author> R.A. Boie, I.J. Cox, and P. Rehak. </author> <title> On optimum edge recognition using matched filters. </title> <booktitle> In Proceedings of the 1986 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 100-108, </pages> <year> 1986. </year>
Reference-contexts: Canny's first two criteria correspond directly to these aspects of performance: Good Detection: "There should be a low probability of failing to mark real edge points (ie. false negatives) and low probability of falsely marking non edge points (ie. false positives)" <ref> [12] </ref>. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). Therefore, he used the SNR as his first optimality criterion. Good Localization: "The points marked by the operator should be as close as possible to the center of the true edge" [12]. <p> positives)" <ref> [12] </ref>. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). Therefore, he used the SNR as his first optimality criterion. Good Localization: "The points marked by the operator should be as close as possible to the center of the true edge" [12]. Canny derived an estimate of the root mean squared (RMS) displacement of an ideal edge perturbed with independently and identically distributed Gaussian noise, and used it as his second optimality criterion. In [20], Canny initially tried to optimize the product of these first two criteria. <p> In particular, it tends to produce many local maxima in the vicinity of noisy step edges [35]. Hence, Canny introduced a third optimality criteria to address this problem: Few Multiple Responses: For an ideal detector, there should be "only one response to a single edge" <ref> [12] </ref>. Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. 18 2.3.2 Deriving the Optimal Filter There are various different ways of combining Canny's three criteria. <p> The most well known are the three criteria proposed by Canny in [20]: Good Detection: "There should be a low probability of failing to mark real edge points (ie. false negatives) and low probability of falsely marking non-edge points (ie. false positives)" <ref> [12] </ref>. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). Hence, he used the SNR as his first optimality criterion. 90 Good Localization: "The points marked by the operator should be as close as possible to the center of the true edge" [12]. <p> <ref> [12] </ref>. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). Hence, he used the SNR as his first optimality criterion. 90 Good Localization: "The points marked by the operator should be as close as possible to the center of the true edge" [12]. Canny derived an estimate of the root mean squared (RMS) displacement of an ideal edge perturbed with independently and identically distributed Gaussian noise, and used it as his second optimality criterion. Few Multiple Responses: For an ideal detector, there should be "only one response to a single edge" [12]. <p> edge" <ref> [12] </ref>. Canny derived an estimate of the root mean squared (RMS) displacement of an ideal edge perturbed with independently and identically distributed Gaussian noise, and used it as his second optimality criterion. Few Multiple Responses: For an ideal detector, there should be "only one response to a single edge" [12]. Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], [109], and [97]. <p> "only one response to a single edge" <ref> [12] </ref>. Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection.
Reference: [13] <author> M. Born and E. Wolf. </author> <title> Principles of Optics. </title> <publisher> Permagon Press, </publisher> <year> 1965. </year>
Reference-contexts: Hence, I develop an approach that can handle spatially varying blur. The defocus factor can be approximated by a pillbox function 36 <ref> [13] </ref>, the optical transfer function by the square of the first-order Bessel function of the first kind [13], and the blurring due to imperfections in the feature by a Gaussian [60]. <p> Hence, I develop an approach that can handle spatially varying blur. The defocus factor can be approximated by a pillbox function 36 <ref> [13] </ref>, the optical transfer function by the square of the first-order Bessel function of the first kind [13], and the blurring due to imperfections in the feature by a Gaussian [60].
Reference: [14] <author> A.C. Bovik, T.S. Huang, and D.C. Munson Jr. </author> <title> Nonparametric tests for edge detection in noise. </title> <journal> Pattern Recognition, </journal> <volume> 19(3) </volume> <pages> 209-219, </pages> <year> 1986. </year>
Reference-contexts: In [42], Haralick proposed an edge detector using the F -statistic to test the statistical significance of the difference between the parameters of the best fitting sloped surfaces in neighboring pixels. Bovik et al. <ref> [14] </ref> proposed three different statistical tests for edge detection, two based upon linear rank sums and one based upon fitting order statistics.
Reference: [15] <author> R.N. Bracewell. </author> <title> The Fourier Transform and Its Applications. </title> <address> McGraw Hill, </address> <note> second edition edition, 1978. 155 </note>
Reference-contexts: First, the light flux falling on each sensor element is averaged, or integrated. If the pixels are rectangular [7] [85], the averaging function is simply the rectangular function <ref> [15] </ref>: a (x; y) = w x w y 1 x; w y where w x and w y are the x and y dimensions of the pixel. Second, the pixels are sampled.
Reference: [16] <author> M. Brady. </author> <title> Computational approaches to image understanding. </title> <journal> Computing Surveys, </journal> <volume> 14(1) </volume> <pages> 2-71, </pages> <month> March </month> <year> 1982. </year>
Reference-contexts: In particular, I concentrate on work performed since 1975. Much of the earlier work is covered by existing surveys such as those by Davis [26] and Brady <ref> [16] </ref>. The best sources of information about developments since 1975 are modern texts such as Pratt [100], Nalwa [79], and Faugeras [35]. I classify feature detectors into four major types: (1) model matching detectors, (2) differential invariant detectors, (3) optimal filtering detectors, and (4) statistical detectors.
Reference: [17] <author> M.J. Brooks. </author> <title> Rationalizing edge detectors. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 8 </volume> <pages> 277-285, </pages> <year> 1978. </year>
Reference-contexts: Such papers include [117], [71], and [41]. 2.2.1 Surface Fitting Differential Invariant Detectors One way to describe the intensity values in a feature window "is to fit a surface to the data and use the derivatives of the surface as characteristic descriptors" <ref> [17] </ref>. The major contribution of [17] was to show that a number of early edge detectors can be regarded as doing exactly this. <p> Such papers include [117], [71], and [41]. 2.2.1 Surface Fitting Differential Invariant Detectors One way to describe the intensity values in a feature window "is to fit a surface to the data and use the derivatives of the surface as characteristic descriptors" <ref> [17] </ref>. The major contribution of [17] was to show that a number of early edge detectors can be regarded as doing exactly this. <p> In [67] and [68], Lunscher and Beddoes presented a unified view of the Marr-Hildreth detector [70] and the detector of Shanmugam et al. [111]. Other authors have attempted to unify entire classes of detectors. Both Brooks <ref> [17] </ref> and Haralick [42] tried to provide a unified view of model matching and surface fitting differential invariant detectors through the surface fitting step inherent in both types of detector. Torre and Poggio presented a unified theory of differential invariant detector through regularization theory [115].
Reference: [18] <author> D.C. Brown. </author> <title> Close-range camera calibration. </title> <booktitle> In Symposium on close-range photogrametry, </booktitle> <address> Urbana, Illinois, </address> <month> January </month> <year> 1971. </year>
Reference-contexts: If a shorter focal length was ever needed, Tsai's algorithm could easily be used to compensate for any noticeable radial distortion. Finally, note that measures 123 similar to my global measures of coherence have actually been used in the past to perform camera calibration for the radial distortion [9] <ref> [18] </ref>. 6.3.2 Efficient Computation using Monte Carlo Since the number of detected edges is usually at most n = 10 3 , it is possible to compute the first three measures by simply enumerating all pairs of edges.
Reference: [19] <author> D.J. Bryant and D.W. Bouldin. </author> <title> Evaluation of edge operators using relative and absolute grading. </title> <booktitle> In Proceedings of the IEEE Conference on Pattern Recognition and Image Processing, </booktitle> <pages> pages 138-145, </pages> <address> Chicago, IL, </address> <year> 1979. </year>
Reference-contexts: An alternative approach is to apply a number of detectors and use the consensus as the ground truth <ref> [19] </ref>. However, the assumption that the consensus gives a good estimate of the ground ruth is questionable.
Reference: [20] <author> J. Canny. </author> <title> A computational approach to edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8(6) </volume> <pages> 679-698, </pages> <month> November </month> <year> 1986. </year>
Reference-contexts: However, the window could be approximately circular, and might contain anywhere from 4 to 100 pixels. In particular, I explicitly rule out all feature aggregation and adaptive thresholding algorithms. The most well known example of such a technique is Canny's hysteresis <ref> [20] </ref>. Many such techniques dramatically improve the performance of all feature detectors. Here, I am solely interested in how well feature detection can be performed without them. <p> Various optimality criteria have been proposed in the literature, however the most well known and thoroughly studied are the three criteria proposed by Canny in <ref> [20] </ref>. The remainder of this section is organized as follows. I begin in Section 2.3.1 by describing Canny's three optimality criteria. In Section 2.3.2, I discuss the various ways that these criteria have been combined and the alternative approaches that have be used to optimize them. <p> Canny derived an estimate of the root mean squared (RMS) displacement of an ideal edge perturbed with independently and identically distributed Gaussian noise, and used it as his second optimality criterion. In <ref> [20] </ref>, Canny initially tried to optimize the product of these first two criteria. The optimal filter is the matched filter, or difference of boxes operator [35]. Unfortunately, this detector is well known to perform quite poorly. <p> Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. Canny's optimality criterion can be regarded as another example, combining a robustness component and a localization accuracy component, with a third component that penalizes multiple responses to the same edge <ref> [20] </ref> [27]. Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition [47], structure from motion [112], industrial inspection [114], and boundary extraction [56] [90]. <p> Torre and Poggio presented a unified theory of differential invariant detector through regularization theory [115]. Further, Torre and Poggio also examined the relationship between Laplacian edge detectors such as [70] and second directional derivative operators such as <ref> [20] </ref> and [42]. 2.6.2 Sensor Modeling and Sub-Pixel Localization Most of the previous work on feature detection has assumed that the artifacts introduced by the imaging system are negligible and can be ignored. One exception is [94]. <p> Nalwa simply suggested that the image is sub-sampled. Another example of sensor modeling is [97]. Petrou and Kittler argue that ideal step edges do not occur in real images. Instead, real edges are actually ramp edges. They follow the approach of Canny <ref> [20] </ref> and derive optimal filters for ramp edges, which they claim yield better performance than filters designed for ideal step edges. <p> In particular, in their Laplacian of Gaussian detector, the standard deviation of the Guassian is used to control the scale by changing the amount of blurring. Later, Canny used the same technique to define the scale of his detector <ref> [20] </ref>. Moreover, an entire theory of scale space has been developed, beginning with the work of Witken [118] and then of Koenderink [60]. These initial papers established the desirable properties of the Gaussian smoothing for scale space. <p> In Section 3.4, I describe the detection al 34 gorithm in detail. In particular, I describe manifold sampling, the coarse-to-fine search, and the use of rejection techniques. In the following chapter, I present experimental results obtained for the five example features, including comparisons with a Canny-like operator <ref> [20] </ref> and the Nalwa-Binford [80] detector. 3.2 Parametric Feature Representation I begin this section by first introducing the notion of a parametric scene feature. I then describe my model of the imaging system, and how this model leads to imaged features being represented as parametric manifolds. <p> In both cases, I compare the step edge detector developed in the previous chapter with a Canny-like operator <ref> [20] </ref> and the Nalwa-Binford [80] detector. In doing so, the aim is to demonstrate that the parametric manifold step edge detector performs comparably to these well known and highly regarded detectors. I also compare the performance of the parametric manifold technique across the five example features. <p> This implementation is publically available on the Web from the URL http://www.cs.curtin.edu.au/ ~ geoff/. Geoff West's implementation only computes the Gaussian smoothed gradient, which I simply threshold to detect edges. For simplicity, I do not find the zero crossing of the second directional derivative. Neither do I perform hysteresis <ref> [20] </ref> since it uses information derived from neighboring windows, something I explicitly outlawed in this thesis. 63 positives against false negatives. For each detector, the result is a curve parameterized by the threshold inherent in that detector. The closer a curve lies to the origin, the better the performance. <p> The most well known are the three criteria proposed by Canny in <ref> [20] </ref>: Good Detection: "There should be a low probability of failing to mark real edge points (ie. false negatives) and low probability of falsely marking non-edge points (ie. false positives)" [12]. Canny argued that both of these criteria are strongly correlated with the signal to noise ratio (SNR). <p> In Section 5.3.3, I discuss how these three optimality criteria can be combined. I do not consider the "Few Multiple Responses" criterion in this paper since its introduction in <ref> [20] </ref> was for technical reasons, rather than 91 because it is a fundamental element of feature detection performance. 5.3.1 Feature Detection Robustness Feature detection is not robust, both when the detector misses features (false negatives), and when the detector mistakenly detects features that are not present (false positives). <p> After taking into account both parameter normalization and dimension reduction, the optimality criteria become extremely complex. Even Canny resorted to a numerical algorithm to optimize his relatively simple optimality criterion for arbitrary features <ref> [20] </ref>. Here, I follow the same approach. If there are N pixels in the discrete feature window S, the optimization is N 1 dimensional rather than N dimensional because the optimality criteria are unchanged if the weighting function is multiplied by a positive constant. <p> The optimal weighting function for the parameter estimation accuracy of the sub-pixel localization of the step edge is presented in Figure 5.1 (a). The overall form of this optimal weighting function is as expected. Intuitively, the center-most pixels are the most important when estimating sub-pixel localization <ref> [20] </ref>. Hence, it is to be expected that they should be given more weight. The results in Figure 5.1 (c) for the combined parameter estimation accuracy of the corner are also in agreement with intuition. Here, the central pixels do not change much as the parameters of the corner vary. <p> terms in the quadratic form, the noise model would have to be generalized to model correlation 105 of the noise across the pixels. 5.5.2 Relationship with Canny I now discuss the relationship between the approach described in this chapter and the optimal filtering approach to edge detection best exemplified by <ref> [20] </ref>. <p> On the other hand, Canny <ref> [20] </ref> studied the selection of the filter f (x) that optimizes the performance of a 1-D step edge detector that declares edges at local maxima of: Z +W I (a + x) f (x) dx (5.28) where I (x) is the continuous 1-D input image and W is the width of <p> So, if there is a sub-pixel localization parameter, model matching implicitly performs the same local non-maximum suppression that the Canny detector does. If there is a rotation parameter, model matching also optimizes over it. There is no equivalent in <ref> [20] </ref> because the formulation is entirely 1-D. Note, however, that steerable filters provide a way of optimizing over the rotation parameter [37]. A final difference is the normalization of the image data. <p> A number of post-processing and feature aggregation algorithms have been proposed in the literature, perhaps the most well known being Canny's adaptive thresholding technique, hysteresis <ref> [20] </ref>. In this thesis, I focused exclusively on how well feature detection can be performed without using such techniques.
Reference: [21] <author> S. Castan, J. Zhao, and J. Shen. </author> <title> New edge detection methods based on exponential filter. </title> <booktitle> In Proceedings of the 10th International Conference on Pattern Recognition, </booktitle> <pages> pages 709-711, </pages> <year> 1990. </year>
Reference-contexts: For example, its efficiency [22] [54], accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. For example, Modestino and Fries [72] investigated least mean square filters for the Laplacian, and Castan et al. <ref> [21] </ref> used the Symmetric Exponential Filter with both the gradient and the second directional derivative in the direction of the gradient. Hashimoto and Sklansky [41] and Weiss [117] both just considered the problem of computing the partial derivatives, as opposed to edge detection per se.
Reference: [22] <author> J.S. Chen, A. Huertas, and G. Medioni. </author> <title> Fast convolution with Laplacian-of-Gaussian masks. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 9(4) </volume> <pages> 584-590, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency <ref> [22] </ref> [54], accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> Other examples of recursive filtering include the Modestino and Fries detector [72] and the Sarkar and Boyer detector [109]. 26 Another example of an efficient filtering technique is the approach of Chen et al. <ref> [22] </ref>, a technique that was later refined by Sotak and Boyer [54]. Chen et al. [22] proposed decomposing the Laplacian of Gaussian operator [70] into the product of a Gaussian with smaller standard deviation, and a Laplacian of Gaussian with standard deviation chosen to make up the difference. <p> Other examples of recursive filtering include the Modestino and Fries detector [72] and the Sarkar and Boyer detector [109]. 26 Another example of an efficient filtering technique is the approach of Chen et al. <ref> [22] </ref>, a technique that was later refined by Sotak and Boyer [54]. Chen et al. [22] proposed decomposing the Laplacian of Gaussian operator [70] into the product of a Gaussian with smaller standard deviation, and a Laplacian of Gaussian with standard deviation chosen to make up the difference.
Reference: [23] <author> K. Cho, P. Meer, and J. Cabrera. </author> <title> Performance assessment through bootstrap. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> 19(11) 1185-1198, November 1997. 
Reference-contexts: A number of papers have performed statistical tests using synthetically generated data, including, [36], [31], [1], [95], [80], and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. <ref> [23] </ref>, is to use a statistical technique known as bootstrap. Bootstrap, although it can be applied to real image data, still makes several 23 strong assumptions about the nature of a feature and the noise processes.
Reference: [24] <author> C. Coehlo, A. Heller, J.L. Mundy, D.A. Forsyth, and A. Zisserman. </author> <title> An experimental evaluation of projective invariants. </title> <editor> In J.L Mundy and A. Zisserman, </editor> <title> 156 editors, Geometric Invariants for Machine Vision, </title> <booktitle> chapter 4, </booktitle> <pages> pages 87-104. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants <ref> [24] </ref>, object recognition [47], structure from motion [112], industrial inspection [114], and boundary extraction [56] [90]. Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] [121].
Reference: [25] <author> J.B. Conway. </author> <title> A Course in Functional Analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: I now introduce weighted L 2 norms as a class of possible matching functions to choose from. Every measure w on the pixels leads to a different L 2 norm, denoted by either L 2 (w) or k k w <ref> [25] </ref>. A measure is defined by the weight w = w (n; m) 0 that it assigns to each of the pixels (n; m) 2 S.
Reference: [26] <author> L.S. Davis. </author> <title> A survey of edge detection techniques. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 4 </volume> <pages> 248-270, </pages> <year> 1975. </year>
Reference-contexts: In particular, I concentrate on work performed since 1975. Much of the earlier work is covered by existing surveys such as those by Davis <ref> [26] </ref> and Brady [16]. The best sources of information about developments since 1975 are modern texts such as Pratt [100], Nalwa [79], and Faugeras [35]. I classify feature detectors into four major types: (1) model matching detectors, (2) differential invariant detectors, (3) optimal filtering detectors, and (4) statistical detectors.
Reference: [27] <author> D. Demigny and T. Kamle. </author> <title> A discrete expression for Canny's criteria for step edge detector performance evaluation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> 19(11) 1199-1211, November 1997. 
Reference-contexts: Another optimal (IIR) filter is the Sarkar-Boyer detector [109]. Rather than using Canny's third criterion, Sarkar and Boyer used a slightly different criterion designed to measure the likelihood of spurious responses to noise. Finally, Demigny and Kamle <ref> [27] </ref> derived discrete versions of Canny's three criteria and used them to compare the performance of various step edge detectors. 2.3.3 Other Optimality Criteria Several other optimality criteria have been proposed. <p> Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. Canny's optimality criterion can be regarded as another example, combining a robustness component and a localization accuracy component, with a third component that penalizes multiple responses to the same edge [20] <ref> [27] </ref>. Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition [47], structure from motion [112], industrial inspection [114], and boundary extraction [56] [90]. <p> Instead, real edges are actually ramp edges. They follow the approach of Canny [20] and derive optimal filters for ramp edges, which they claim yield better performance than filters designed for ideal step edges. Finally, Demigny and Kamle <ref> [27] </ref> derived discrete (ie. pixel based) versions of Canny's three optimality criteria. 25 They used these criteria to compare the performance of various edge detectors. 2.6.3 Efficient Filtering There are a number of techniques that can be used to implement 2-D filtering operations efficiently.
Reference: [28] <author> R. Deriche. </author> <title> Optimal edge detection using recursive filtering. </title> <booktitle> In Proceedings of the First International Conference on Computer Vision, </booktitle> <pages> pages 501-505, </pages> <year> 1987. </year>
Reference-contexts: Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], <ref> [28] </ref>, [29], [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection.
Reference: [29] <author> R. Deriche. </author> <title> Using Canny's criteria to derive a recursively implemented optimal edge detector. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1 </volume> <pages> 167-187, </pages> <year> 1987. </year>
Reference-contexts: As discussed by Faugeras in [35], this method naturally corresponds to the use of a filter with finite extent. On the other hand, Deriche considers infinite impulse response (IIR) filters by allowing the width of the Canny filter to tend to infinity <ref> [29] </ref>. The result is a filter with a better value for the product of Canny's first two optimality criteria [35]. Note that Deriche's IIR filter can be implemented very efficiently using recursive filtering [29]. See Section 2.6.3 for more details. <p> infinite impulse response (IIR) filters by allowing the width of the Canny filter to tend to infinity <ref> [29] </ref>. The result is a filter with a better value for the product of Canny's first two optimality criteria [35]. Note that Deriche's IIR filter can be implemented very efficiently using recursive filtering [29]. See Section 2.6.3 for more details. A number of other authors have studied Canny's three criteria, and variants thereof. Rather than considering the product of the first two criteria while keeping the third one fixed, Spacek chose to optimize the product of all three criteria [113]. <p> If the z-transform of the filter also happens to be of this form, it can be implemented using the recursive relationship. A constant amount of computation is needed per pixel to implement these recursive relationships. For example, the infinite Deriche filter <ref> [29] </ref> can be implemented with 5 additions and 5 multiplications per pixel [35]. <p> Canny derived an estimate for the expected distance between adjacent edges and used it as his third optimality criterion. Besides Canny, a number of other authors have studied his three criteria, and variants thereof, combining them in various ways. See, for example, [12], [113], [28], <ref> [29] </ref>, [109], and [97]. Other optimality criteria that have been considered include the energy in the vicinity of the edge [111] [66] [67] [68] and the Discriminative Signal to Noise Ratio [104]. See Section 2.3 for more discussion of optimal edge detection.
Reference: [30] <author> R. Deriche and G. Giraudon. </author> <title> A computational approach for corner and vertex detection. </title> <journal> International Journal of Computer Vision, </journal> <volume> 10(2) </volume> <pages> 101-124, </pages> <year> 1993. </year>
Reference-contexts: Nevatia found that using a subspace with too low a dimension does indeed reduce the performance of a detector. 2.2 Differential Invariant Feature Detectors The second major class of feature detectors consists of those based upon differential invariants. Well known examples include the Deriche corner detector <ref> [30] </ref>, the Haralick step edge detector [44], and the Marr-Hildreth step edge detector [70]. As indicated by the name, these detectors base their detection decisions upon differential invariants estimated from the image data. <p> Invariant Corner Detectors Whereas much of the literature on edge detection has concentrated on how to compute the three major differential invariants (the gradient, the Laplacian, and the second directional derivative in the direction of the gradient), the work on corner detection has largely focused on the differential invariants themselves <ref> [30] </ref>. Perhaps the first differential invariant corner detector was the Beaudet detector [8]. <p> A number of attempts have been made at studying the output of detectors across scales, including, [10], [61], and <ref> [30] </ref>. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions. <p> of attempts have been made at studying the output of detectors across scales, including, [10], [61], and <ref> [30] </ref>. Bergholm [10] tracked edges across scales to obtain high localization accuracy and also to restore junctions. Korn [61] studied the selection of the appropriate scale at which to apply detectors. Finally, Deriche [30] studied the affects of scale space smoothing on the localization of corners and junctions. He proceeded to show how the systematic bias of the Laplacian of Gaussian can be corrected. A related study, with somewhat different goals, is that of Berzins [11]. <p> Most existing corner detectors are based upon differential invariant based measures of curvature <ref> [30] </ref>, but Rohr [106] recently proposed a parametric model matching approach to corner detection. The simplest way to think about a corner is as the intersection of two non-parallel step edges.
Reference: [31] <author> E.S. Deutsch and J.R. Fram. </author> <title> A quantitative study of the orientation bias of some edge detector schemes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 27(3) </volume> <pages> 205-213, </pages> <month> March </month> <year> 1978. </year>
Reference-contexts: These measures are important for any application that actually uses the feature parameters. These measures have also been widely studied, including in <ref> [31] </ref>, [1], [11], [94], and [114]. 21 Combinations of Robustness and Parameter Estimation: A third class of measures consists of those that are simple combinations of the above two types. Perhaps the most well known example is Pratt's Figure of Merit [1] [95]. <p> Statistical Tests: A solution to the first of these two problems is to use numerical techniques instead of analytical ones. Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, [36], <ref> [31] </ref>, [1], [95], [80], and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap.
Reference: [32] <author> S. Dougherty and K.W. Bowyer. </author> <title> Objective evaluation of edge detectors using a formally defined framework. </title> <booktitle> In Proceedings of the 1998 Workshop on 157 Empirical Evaluation Techniques in Computer Vision, </booktitle> <pages> pages 211-234, </pages> <address> Santa Barbara, California, June 1998. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: Naturally, there is an inherent trade off between these two measures, as is seen for example in [6]. These two measures are of fundamental importance in most applications and have been widely studied, including in [36], [1], [80], [103], and <ref> [32] </ref> Parameter Estimation Accuracy: Another fundamental class of measures consists of those that assess the accuracy with which the parameters of the feature (e.g. orientation, sub-pixel localization, and step magnitude) are estimated. These measures are important for any application that actually uses the feature parameters. <p> In fact, in a recent paper in which this approach is taken, Dougherty and Bowyer allowed the human to mask out any regions for which it was too difficult for the human to say which pixels contain edges <ref> [32] </ref>. An alternative approach is to apply a number of detectors and use the consensus as the ground truth [19]. However, the assumption that the consensus gives a good estimate of the ground ruth is questionable. <p> The benchmarks are less representative of more qualitative tasks such as object recognition, segmentation, and edge grouping. Other evaluation techniques have been proposed that are somewhat more suited to such tasks, including <ref> [32] </ref>, [47], [121], and [57]. My benchmarks are meant to supplement, not replace, these existing techniques. Note that several new evaluation techniques for quantitative applications, such as structure from motion [112] and industrial inspection [114], have been proposed recently. <p> In this section, I describe how one of these thresholds can be left unset. The performance of each edge detector is then characterized by a curve parameterized by the free threshold. In <ref> [32] </ref>, Dougherty and Bowyer used a generalization of this technique to allow more than one threshold to be left unspecified. <p> In fact, in a recent paper in which edge detectors are evaluated by getting a human to mark the edges in an image by hand, Dougherty and Bowyer allowed the human to mask out certain regions as too difficult for the human to say which pixels contain edges <ref> [32] </ref>. The three major advantages of using global measures of coherence are: 1. They use a very large number of real images.
Reference: [33] <author> L. Dreschler and H.H. Nagel. </author> <title> On the selection of critical points and local curvature extrema of region boundaries for interframe matching. </title> <booktitle> In Proceedings of the 6th International Conference on Pattern Recognition, </booktitle> <pages> pages 542-544, </pages> <year> 1982. </year>
Reference-contexts: Two corner detectors closely related to the Kitchen-Rosenfeld detector are the Dreschler-Nagel detector <ref> [33] </ref> and the Zuniga-Haralick detector [123]. Nagel 15 showed that the Dreschler-Nagel detector and the Kitchen-Rosenfeld detector are equivalent if the heuristic of nonmaximum suppression along the gradient is applied to the gradient before multiplying by the gradient magnitude [76].
Reference: [34] <author> J. Elder and S. Zucker. </author> <title> Scale space localization blur and contour-based image coding. </title> <booktitle> In Proceedings of the 1996 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 27-34, </pages> <address> San Francisco, California, June 1996. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: However, recently counterexamples have been found to the most general statement of the problem 28 by Meyer, as described by Mallat in [69]. In spite of this result, a number of algorithms have been proposed to invert the edge detection process that work very well in practice [69] <ref> [34] </ref>. 29 Chapter 3 Parametric Feature Detection 3.1 Introduction As can be seen from the literature survey in Chapter 2, the most frequently studied image feature is the step edge.
Reference: [35] <author> O.D. Faugeras. </author> <title> Three-dimensional Computer Vision: A Geometric Viewpoint. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Introduction Feature detection is one of the fundamental tasks in computer vision. It has received widespread coverage in both the research literature and in vision textbooks such as [48], <ref> [35] </ref>, and [79]. Some of the major applications of feature detection include: Stereo: One of the most popular methods of performing correspondence matching along epipolar lines consists of matching detected edge features. Object Recognition: Many object recognition algorithms start by detecting edge or corner features. <p> In particular, I concentrate on work performed since 1975. Much of the earlier work is covered by existing surveys such as those by Davis [26] and Brady [16]. The best sources of information about developments since 1975 are modern texts such as Pratt [100], Nalwa [79], and Faugeras <ref> [35] </ref>. I classify feature detectors into four major types: (1) model matching detectors, (2) differential invariant detectors, (3) optimal filtering detectors, and (4) statistical detectors. From Section 2.1 to Section 2.4, I cover each of these four types of detector in turn. <p> This filtering step 13 can be regarded as implicitly interpolating the image data to create a continuous surface. For this reason, there is a close relationship with surface fitting differential invariant detectors. As pointed out by Faugeras in <ref> [35] </ref>, surface fitting can also be regarded as another form of regularization To design a filtering differential invariant detector, decisions must be made on two major points: (1) the shape of the filter, and (2) the differential invariant. <p> The second method of computing the differential invariants in the previous section was by filtering. Optimal filtering edge detectors operate by declaring edges at local "extrema in the output of the convolution of the image with a [filter]" of an appropriate shape <ref> [35] </ref>. Then, the key question for optimal filtering detectors is the shape of filter. <p> In [20], Canny initially tried to optimize the product of these first two criteria. The optimal filter is the matched filter, or difference of boxes operator <ref> [35] </ref>. Unfortunately, this detector is well known to perform quite poorly. In particular, it tends to produce many local maxima in the vicinity of noisy step edges [35]. <p> The optimal filter is the matched filter, or difference of boxes operator <ref> [35] </ref>. Unfortunately, this detector is well known to perform quite poorly. In particular, it tends to produce many local maxima in the vicinity of noisy step edges [35]. Hence, Canny introduced a third optimality criteria to address this problem: Few Multiple Responses: For an ideal detector, there should be "only one response to a single edge" [12]. <p> Canny himself optimized the product of the first two criteria, while keeping the third one fixed. As discussed by Faugeras in <ref> [35] </ref>, this method naturally corresponds to the use of a filter with finite extent. On the other hand, Deriche considers infinite impulse response (IIR) filters by allowing the width of the Canny filter to tend to infinity [29]. <p> On the other hand, Deriche considers infinite impulse response (IIR) filters by allowing the width of the Canny filter to tend to infinity [29]. The result is a filter with a better value for the product of Canny's first two optimality criteria <ref> [35] </ref>. Note that Deriche's IIR filter can be implemented very efficiently using recursive filtering [29]. See Section 2.6.3 for more details. A number of other authors have studied Canny's three criteria, and variants thereof. <p> One example of a paper that uses the fast Fourier transform to implement a filtering operation efficiently is Shanmugam et al. [111]. Another technique, that can often be even more efficient than Fourier domain processing, is recursive filtering [100] <ref> [35] </ref>. Perhaps even more importantly, recursive filtering can be used to implement certain infinite impulse response (IIR) filters, which otherwise could only be truncated and approximated as a finite input response (FIR) filter. Recursive filtering is based upon a recursive relationship between the filtered image and the input image. <p> A constant amount of computation is needed per pixel to implement these recursive relationships. For example, the infinite Deriche filter [29] can be implemented with 5 additions and 5 multiplications per pixel <ref> [35] </ref>. Other examples of recursive filtering include the Modestino and Fries detector [72] and the Sarkar and Boyer detector [109]. 26 Another example of an efficient filtering technique is the approach of Chen et al. [22], a technique that was later refined by Sotak and Boyer [54]. <p> Given just one of the detected edges e i = (x i ; y i ; i ) 2 E, it is possible to estimate the line that of all the edges lie on. In the projective geometric notation of <ref> [35] </ref>, the vector representation of this line is: L i l 1 i ; l 3 T = ( sin i ; cos i ; x i sin i y i cos i ) : (6.2) A minor difficulty that needs to be addressed at this point is that equality is <p> i ; l 3 T = ( sin i ; cos i ; x i sin i y i cos i ) : (6.2) A minor difficulty that needs to be addressed at this point is that equality is only defined up to a constant multiplicative factor in projective spaces <ref> [35] </ref>. There are two aspects to this problem: Sign of L i : Adding 180 ffi to i does not change the line, but reverses the sign of L i . <p> 0 (6.18) where x = (x; y; 1) T is a homogeneous vector of image coordinates, and: A = B B B @ 1 1 1 1 1 1 1 C C C (6.19) is a 3 fi 3 symmetric matrix, as usual only defined up to a scale factor <ref> [35] </ref>. So, the matrix A has just five independent parameters.
Reference: [36] <author> J.R. Fram and E.S. Deutsch. </author> <title> On the quantitative evaluation of edge detection schemes and their comparison with human performance. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 24(6) </volume> <pages> 616-628, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: Naturally, there is an inherent trade off between these two measures, as is seen for example in [6]. These two measures are of fundamental importance in most applications and have been widely studied, including in <ref> [36] </ref>, [1], [80], [103], and [32] Parameter Estimation Accuracy: Another fundamental class of measures consists of those that assess the accuracy with which the parameters of the feature (e.g. orientation, sub-pixel localization, and step magnitude) are estimated. These measures are important for any application that actually uses the feature parameters. <p> Statistical Tests: A solution to the first of these two problems is to use numerical techniques instead of analytical ones. Then, the complexity of the detector does not cause a problem. A number of papers have performed statistical tests using synthetically generated data, including, <ref> [36] </ref>, [31], [1], [95], [80], and [6]. However, these approaches still have the limitation that they use ideal models of both the signals and the noise. A partial solution, recently proposed by Cho et al. [23], is to use a statistical technique known as bootstrap. <p> Although nearly all feature detection papers do this, they typically do it in a very informal manner. It is possible to perform such a comparison in a more formal way, as was done in <ref> [36] </ref> and [47]. Even when done scientifically, such techniques still have the inherent weakness that they rely upon the subjective opinion of humans who can bring higher level processing to bear.
Reference: [37] <author> W.T. Freeman and E.H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 891-906, </pages> <year> 1991. </year>
Reference-contexts: If there is a rotation parameter, model matching also optimizes over it. There is no equivalent in [20] because the formulation is entirely 1-D. Note, however, that steerable filters provide a way of optimizing over the rotation parameter <ref> [37] </ref>. A final difference is the normalization of the image data.
Reference: [38] <author> K. Fukunaga. </author> <title> Introduction to Statistical Pattern Recognition. </title> <publisher> Academic Press, </publisher> <year> 1990. </year> <month> 158 </month>
Reference-contexts: 2 10 norms were used to define the best fitting polynomial surface that is subsequently differentiated to estimate the differential invariants. 2.1.4 Dimension Reduction Since weighted L 2 norms are derived from underlying Hilbert spaces, it is possible to apply dimension reduction techniques, such as the Karhunen-Loeve (K-L) expansion [89] <ref> [38] </ref>, to improve the efficiency of feature detection. The use of the K-L expansion was first proposed for feature detection by Hummel [52]. Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as [122] and [81]. <p> This idea was first explored by Hummel [52] and later by Lenz [64]. See Section 2.1.4 for a discussion of the use of dimension reduction in feature detection. If correlation between feature instances is the preferred measure of similarity, the Karhunen-Loeve (K-L) expansion <ref> [38] </ref> [89] yields the optimal subspace. The covariance matrix C = E q [(F E q [F ])(F E q [F ]) T ] represents the correlation between the pixels in the different feature instances.
Reference: [39] <author> M. Gennert. </author> <title> Detecting half-edges and vertices in images. </title> <booktitle> In Proceedings of the 1986 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 552-557, </pages> <year> 1986. </year>
Reference-contexts: Hashimoto and Sklansky [41] considered the Wiener filter, and Weiss [117] studied filters that preserve the derivatives of polynomials of a certain degree. A final example of a filtering based differential invariant detector is the half edge and vertex detector of <ref> [39] </ref>. Here, Gennert uses a modified directional derivative of a Gaussian operator to create an edge detector that performs more robustly at vertices and corners.
Reference: [40] <author> A.K. Griffith. </author> <title> Mathematical models for automatic line detection. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20(1) </volume> <pages> 62-80, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: A decision rule is then used to decide whether to detect the feature or not. Probably the first statistical feature detector is that of Griffith <ref> [40] </ref>. The Griffith detector was designed to detect boundary features, which can be either simple lines or simple edges. The non-features modeled include homogeneous regions, skewed lines, and parts of lines.
Reference: [41] <author> M. Hahsimoto and J. Sklansky. </author> <title> Multiple-order derivatives for detecting local image characteristics. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 39 </volume> <pages> 28-55, </pages> <year> 1987. </year>
Reference-contexts: Afterwards, in Section 2.2.3, I discuss differential invariant approaches to corner detection. Finally, note that a small number of papers have focused on how to estimate the partial derivatives required by differential invariant feature detectors, rather than on feature detection itself. Such papers include [117], [71], and <ref> [41] </ref>. 2.2.1 Surface Fitting Differential Invariant Detectors One way to describe the intensity values in a feature window "is to fit a surface to the data and use the derivatives of the surface as characteristic descriptors" [17]. <p> Naturally, other choices are possible. For example, Modestino and Fries [72] investigated least mean square filters for the Laplacian, and Castan et al. [21] used the Symmetric Exponential Filter with both the gradient and the second directional derivative in the direction of the gradient. Hashimoto and Sklansky <ref> [41] </ref> and Weiss [117] both just considered the problem of computing the partial derivatives, as opposed to edge detection per se. Hashimoto and Sklansky [41] considered the Wiener filter, and Weiss [117] studied filters that preserve the derivatives of polynomials of a certain degree. <p> Hashimoto and Sklansky <ref> [41] </ref> and Weiss [117] both just considered the problem of computing the partial derivatives, as opposed to edge detection per se. Hashimoto and Sklansky [41] considered the Wiener filter, and Weiss [117] studied filters that preserve the derivatives of polynomials of a certain degree. A final example of a filtering based differential invariant detector is the half edge and vertex detector of [39].
Reference: [42] <author> R.M. Haralick. </author> <title> Edge and region analysis for digital image data. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 12 </volume> <pages> 60-73, </pages> <year> 1980. </year>
Reference-contexts: The non-features modeled include homogeneous regions, skewed lines, and parts of lines. Later, Nahi and Jahanshahi developed an edge detector using a replacement processes to model image formation as the replacement of a background process with an object process [77]. In <ref> [42] </ref>, Haralick proposed an edge detector using the F -statistic to test the statistical significance of the difference between the parameters of the best fitting sloped surfaces in neighboring pixels. <p> In [67] and [68], Lunscher and Beddoes presented a unified view of the Marr-Hildreth detector [70] and the detector of Shanmugam et al. [111]. Other authors have attempted to unify entire classes of detectors. Both Brooks [17] and Haralick <ref> [42] </ref> tried to provide a unified view of model matching and surface fitting differential invariant detectors through the surface fitting step inherent in both types of detector. Torre and Poggio presented a unified theory of differential invariant detector through regularization theory [115]. <p> Torre and Poggio presented a unified theory of differential invariant detector through regularization theory [115]. Further, Torre and Poggio also examined the relationship between Laplacian edge detectors such as [70] and second directional derivative operators such as [20] and <ref> [42] </ref>. 2.6.2 Sensor Modeling and Sub-Pixel Localization Most of the previous work on feature detection has assumed that the artifacts introduced by the imaging system are negligible and can be ignored. One exception is [94]. In this paper, Pedersini et al. are interested in maximizing the sub-pixel localization accuracy.
Reference: [43] <author> R.M. Haralick. </author> <title> Ridges and valleys on digital images. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 22 </volume> <pages> 28-38, </pages> <year> 1983. </year>
Reference-contexts: These zero crossings correspond to local maxima of the first order directional derivative taken in the direction of the gradient and are computed from the best fitting cubic surface. In a related paper <ref> [43] </ref>, Haralick used a surface fitting approach to estimate the zero crossings of the first directional derivative in the direction that extremizes the second directional derivative. Haralick argues that these feature points correspond to ridges and valleys.
Reference: [44] <author> R.M. Haralick. </author> <title> Digital step edges from zero crossing of second directional derivatives. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6(1) </volume> <pages> 58-68, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: Well known examples include the Deriche corner detector [30], the Haralick step edge detector <ref> [44] </ref>, and the Marr-Hildreth step edge detector [70]. As indicated by the name, these detectors base their detection decisions upon differential invariants estimated from the image data. <p> For example, Haralick proposed an edge detector that detects edges at negatively slopped zero crossings of the second directional derivative, taken in the direction of the gradient <ref> [44] </ref>. These zero crossings correspond to local maxima of the first order directional derivative taken in the direction of the gradient and are computed from the best fitting cubic surface.
Reference: [45] <author> C. Harris. </author> <title> Determination of ego-motion from matched points. </title> <booktitle> In Proceddings of the 3rd Alvey Vision Conference, </booktitle> <address> Cambridge, UK, </address> <year> 1987. </year>
Reference-contexts: Shah and Jain showed that the Zuniga-Haralick detector is the same as the Kitchen-Rosenfeld detector divided by the magnitude of the gradient [110]. Finally, another corner detector is the Plessey corner detector <ref> [45] </ref>. The Plessey detector is based upon first order invariants of a smoothed image. An explanation of the Plessey detector in terms of differential geometry was later provided by Nobel [84]. 2.3 Optimal Filtering Feature Detectors In the previous section, I discussed differential invariant approaches to feature detection.
Reference: [46] <author> R. </author> <title> Hartley. A Gaussian-weighted multiresolution edge detector. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 30 </volume> <pages> 70-83, </pages> <year> 1985. </year>
Reference-contexts: This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed [50], including [88], [52], [74], and <ref> [46] </ref>. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. <p> Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz [64]. Morgenthaler [74] generalized the approach of Hummel to detect step edges superimposed on a low order polynomial, rather than on a constant function. Finally, Hartley <ref> [46] </ref> redesigned the Hueckel edge detector to use a Gaussian weighted L 2 norm for the matching function, as was suggested in the appendix of [51]. Probably the most sophisticated model matching edge detector is the Nalwa-Binford detector [80]. <p> In [51], the weighting function remains the same to allow a closed form solution for the best fitting parameters. In the appendix, however, Hueckel suggests that a Gaussian weighting function may be more appropriate. Few other detectors actually use non-uniform weighting functions. An exception is Hartley <ref> [46] </ref>, who followed Hueckel's suggestion and used a Gaussian weighting function. Lenz [64] concentrates on the Euclidean L 2 norm, but extends some of his results to the uniformly weighted L 2 norm in polar coordinates. <p> On the other hand, if the nearest manifold point is too far away, no feature is detected. This statement of the feature detection problem was first proposed by Hueckel [50], and was subsequently used by O'Gorman [88], Hummel [52], Hartley <ref> [46] </ref>, and Nalwa and Binford [80] for the detection of step edges. Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64].
Reference: [47] <author> M.D. Heath, S. Sarkar, T. Sanocki, and K.W. Bowyer. </author> <title> A robust visual method for assessing the relative performance of edge-detection algorithms. </title> <journal> IEEE 159 Transactions on Pattern Analysis and Machine Intelligence, </journal> 19(12) 1338-1359, December 1997. 
Reference-contexts: In the second part, I describe how the measures can be evaluated. For a slightly different categorization of previous work on the evaluation of feature detectors, the reader is referred to <ref> [47] </ref>. 2.5.1 Performance Measures Most of the measures of performance can be placed into one of five categories: Feature Detection Robustness: The first category consists of measures that attempt to characterize how likely the detector is to miss a feature that appears in the image (a false negative), and those that <p> Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition <ref> [47] </ref>, structure from motion [112], industrial inspection [114], and boundary extraction [56] [90]. Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] [121]. <p> Although nearly all feature detection papers do this, they typically do it in a very informal manner. It is possible to perform such a comparison in a more formal way, as was done in [36] and <ref> [47] </ref>. Even when done scientifically, such techniques still have the inherent weakness that they rely upon the subjective opinion of humans who can bring higher level processing to bear. <p> Of the four evaluation methodologies described in Section 2.5.2, the only one that has actually been used by a significant number of authors is subjective human evaluation. In particular, <ref> [47] </ref> contains a survey of recent articles on edge detection. None of the twenty-one papers considered used any other method of performance evaluation. Subjective human comparison consists of simply applying the detectors to a small number of images and then displaying the output edge maps for evaluation by a human. <p> The benchmarks are less representative of more qualitative tasks such as object recognition, segmentation, and edge grouping. Other evaluation techniques have been proposed that are somewhat more suited to such tasks, including [32], <ref> [47] </ref>, [121], and [57]. My benchmarks are meant to supplement, not replace, these existing techniques. Note that several new evaluation techniques for quantitative applications, such as structure from motion [112] and industrial inspection [114], have been proposed recently. <p> For a measure of performance to be useful, there must be a marked difference between the performance of the best and worst detectors. One criticism that could be made of several recent performance evaluation papers such as <ref> [47] </ref> is that by only testing supposedly good detectors, the full range of performance was never completely sampled. The results presented in [47] show that the detectors perform fairly similarly. <p> One criticism that could be made of several recent performance evaluation papers such as <ref> [47] </ref> is that by only testing supposedly good detectors, the full range of performance was never completely sampled. The results presented in [47] show that the detectors perform fairly similarly. It is then unclear whether this is because the detectors are similar in quality, or whether the evaluation methodology is incapable of ever widely separating good detectors from bad ones.
Reference: [48] <author> B.K.P. Horn. </author> <title> Robot Vision. </title> <publisher> McGraw Hill, </publisher> <year> 1996. </year>
Reference-contexts: Introduction Feature detection is one of the fundamental tasks in computer vision. It has received widespread coverage in both the research literature and in vision textbooks such as <ref> [48] </ref>, [35], and [79]. Some of the major applications of feature detection include: Stereo: One of the most popular methods of performing correspondence matching along epipolar lines consists of matching detected edge features. Object Recognition: Many object recognition algorithms start by detecting edge or corner features. <p> It is known that irradiance on the image plane is proportional to scene radiance <ref> [48] </ref>.
Reference: [49] <author> J.S. Huang and D.H. Tseng. </author> <title> Statistical theory of edge detection. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 43 </volume> <pages> 337-346, </pages> <year> 1988. </year>
Reference-contexts: Bovik et al. [14] proposed three different statistical tests for edge detection, two based upon linear rank sums and one based upon fitting order statistics. Finally, Huang and Tseng <ref> [49] </ref> proposed a statistical theory of edge detection based upon the change-point problem. 20 2.5 Evaluation of Feature Detectors In the first part of this section, I present the various measures of performance that have been proposed in the literature, without discussing how, or even whether, they can actually be evaluated.
Reference: [50] <author> M.H. Hueckel. </author> <title> An operator which locates edges in digitized pictures. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 18(1) </volume> <pages> 113-125, </pages> <month> January </month> <year> 1971. </year>
Reference-contexts: From Section 2.1 to Section 2.4, I cover each of these four types of detector in turn. Afterwards, I discuss the evaluation of feature detectors in Section 2.5 and several other important issues in Section 2.6. 2.1 Model Matching Feature Detectors Model matching feature detectors, such as <ref> [50] </ref>, [51], [80], and [106], are one of the predominant types of detector, as categorized by Nalwa [79]. The basis of a model matching detector is an ideal parametric model of the feature. <p> Sometimes the choice of the matching function is an explicit part of the feature definition, whereas for other detectors the choice is simply implicit in the final design of the detector. 2.1.1 Model Matching Step Edge Detectors The first model matching detector was Hueckel's step edge detector <ref> [50] </ref>. The most important issue for Hueckel was to find a closed form solution for the model parameters that give the closest match to the image data. <p> This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed <ref> [50] </ref>, including [88], [52], [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. <p> This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed <ref> [50] </ref>, including [88], [52], [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz [64]. <p> For example, Hueckel [51] generalized his step edge detector of <ref> [50] </ref> to detect a six parameter line in addition to the original four parameter step edge. Another example is Rohr's corner and Y-junction detector [106]. <p> Most existing detectors use the Euclidean L 2 norm, often without any discussion of the decision, including [88], [52], [74], [122], [80], and [106]. Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel <ref> [50] </ref>. In the continuous domain of [50], Hueckel used the weighting function w (x; y) = [1 (x 2 + y 2 )] 1=2 ; where (x; y) are coordinates relative to the center of a circular window with unit radius. <p> Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel <ref> [50] </ref>. In the continuous domain of [50], Hueckel used the weighting function w (x; y) = [1 (x 2 + y 2 )] 1=2 ; where (x; y) are coordinates relative to the center of a circular window with unit radius. <p> The use of the K-L expansion was first proposed for feature detection by Hummel [52]. Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as [122] and [81]. More ad-hoc dimension reduction was incorporated into earlier detectors, beginning with Hueckel <ref> [50] </ref>, but also including Morgenthaler [74]. The effect on performance of using a subspace with very low dimension was investigated empirically by Nevatia in [82]. <p> Some of these studies have attempted to show the similarities of specific detectors. For example, both Rosenfeld [107] and Abramatic [2] studied the Hueckel <ref> [50] </ref> and Roberts [105] detectors. They showed that if the Hueckel operator is implemented in a 2fi2 window, it turns out to be the same as a variant of the Roberts' 24 cross operator. <p> On the other hand, if the nearest manifold point is too far away, no feature is detected. This statement of the feature detection problem was first proposed by Hueckel <ref> [50] </ref>, and was subsequently used by O'Gorman [88], Hummel [52], Hartley [46], and Nalwa and Binford [80] for the detection of step edges. Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. <p> The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64]. See Section 2.1 for more discussion of these so called model-matching feature detectors. Hueckel <ref> [50] </ref> and Hummel [52] both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest point on the manifold. To make their derivations possible, they used simplified feature models and completely neglected sensing effects. <p> Dramatic dimension reduction is possible because most features have significant structure and inherent symmetries. In practice, the dimension of the subspace required turns out to be in the range 5-15. Dimension reduction was first used in feature detection by Hueckel <ref> [50] </ref>. See Section 2.1.4 for a review of the use of dimension reduction in feature detection. To perform the search for the closest point on the manifold, I use a coarse-to-fine algorithm that exploits the local smoothness of the feature manifolds to find the closest sample point very quickly. <p> Parametric models of step edges date back to the work of Hueckel <ref> [50] </ref>. Since then, the edge has been studied in more depth than any other visual feature. See Chapter 2 for a comprehensive review of the feature detection literature. Figures 3.1 (a) and 3.1 (b) show isometric and plan views of the step edge model that I used. <p> See Chapter 2 for a comprehensive review of the feature detection literature. Figures 3.1 (a) and 3.1 (b) show isometric and plan views of the step edge model that I used. This model is a generalization of the models used in <ref> [50] </ref>, [52], and [64]. It is closest to the one used by Nalwa and Binford [80] in terms of the number and type of parameters, but differs slightly in its treatment of smoothing and blurring effects. <p> This figure is by no means the best that can be achieved in terms of efficiency: Pattern Rejection: The coarse-to-fine search does not need to be applied at every pixel in the image. This observation is almost as old as edge detection itself and is explicitly mentioned in <ref> [50] </ref>. Combining a variety of techniques, I have already reduced the time to process a 512 fi 480 image to less than a minute. I first threshold on the total coordinate variance -2 computed during parameter normalization.
Reference: [51] <author> M.H. Hueckel. </author> <title> A local visual operator which recognizes edges and lines. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20(4) </volume> <pages> 634-647, </pages> <month> October </month> <year> 1973. </year>
Reference-contexts: From Section 2.1 to Section 2.4, I cover each of these four types of detector in turn. Afterwards, I discuss the evaluation of feature detectors in Section 2.5 and several other important issues in Section 2.6. 2.1 Model Matching Feature Detectors Model matching feature detectors, such as [50], <ref> [51] </ref>, [80], and [106], are one of the predominant types of detector, as categorized by Nalwa [79]. The basis of a model matching detector is an ideal parametric model of the feature. <p> Finally, Hartley [46] redesigned the Hueckel edge detector to use a Gaussian weighted L 2 norm for the matching function, as was suggested in the appendix of <ref> [51] </ref>. Probably the most sophisticated model matching edge detector is the Nalwa-Binford detector [80]. Nalwa and Binford used a much more realistic edge model than previous detectors. <p> The six masks can be regarded as a very simple edge model, and selecting the mask with the strongest response as finding the best fitting model instance. 2.1.2 Other Model Matching Detectors Model matching detectors have been proposed for several other types of features. For example, Hueckel <ref> [51] </ref> generalized his step edge detector of [50] to detect a six parameter line in addition to the original four parameter step edge. Another example is Rohr's corner and Y-junction detector [106]. <p> The justifications provided for this choice were: (1) the weighting function 9 should be continuous, including at the periphery of the window, and (2) the value of the weighting function should decrease monotonically with distance from the center of the window. In <ref> [51] </ref>, the weighting function remains the same to allow a closed form solution for the best fitting parameters. In the appendix, however, Hueckel suggests that a Gaussian weighting function may be more appropriate. Few other detectors actually use non-uniform weighting functions. <p> This statement of the feature detection problem was first proposed by Hueckel [50], and was subsequently used by O'Gorman [88], Hummel [52], Hartley [46], and Nalwa and Binford [80] for the detection of step edges. Hueckel <ref> [51] </ref> applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64]. See Section 2.1 for more discussion of these so called model-matching feature detectors. <p> The projection onto the first two eigenvectors is similar; it is approximately a circle in both cases. 3.3.3 The Symmetric Line A line can be thought of as a pair of parallel step edges separated by a short distance w, the width of the line <ref> [51] </ref>. The line model which I used is illustrated in the line is symmetric. It is possible to generalize this model to lines with different intensities on the two sides of the line by adding one more parameter [51]. <p> edges separated by a short distance w, the width of the line <ref> [51] </ref>. The line model which I used is illustrated in the line is symmetric. It is possible to generalize this model to lines with different intensities on the two sides of the line by adding one more parameter [51].
Reference: [52] <author> R.A. Hummel. </author> <title> Feature detection using basis functions. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 9 </volume> <pages> 40-55, </pages> <year> 1979. </year>
Reference-contexts: This subspace is spanned by a set of low order polynomials, and was chosen to reduce high frequency noise. A number of similar approaches and enhancements followed [50], including [88], <ref> [52] </ref>, [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. <p> A number of similar approaches and enhancements followed [50], including [88], <ref> [52] </ref>, [74], and [46]. O'Gorman's major contribution in [88] was to improve the 7 efficiency of [50] by using a low dimensional basis of Walsh functions. Hummel [52] applied the Karhunen-Loeve expansion [89] instead of Hueckel's ad-hoc dimension reduction. Further analysis of the application of the Karhunen-Loeve expansion to feature detection was subsequently performed by Lenz [64]. <p> Instead they used a numerical algorithm. Step edges can occur in 3-D volumetric data as well as in 2-D images. Zucker and Hummel [122] generalized Hummel's 2-D step edge detector <ref> [52] </ref> to detect step edges in volumetric data. Some of Lenz's results in [64] concerning the application of the Karhunen-Loeve expansion are also applicable to 3-D edge models. Finally, note that the Nevatia-Babu detector [83] can be regarded as a primitive kind of model matching detector. <p> Most existing detectors use the Euclidean L 2 norm, often without any discussion of the decision, including [88], <ref> [52] </ref>, [74], [122], [80], and [106]. Non-uniformly weighted L 2 norms have been used in a small number of detectors. The first use dates back to the work of Hueckel [50]. <p> The use of the K-L expansion was first proposed for feature detection by Hummel <ref> [52] </ref>. Subsequently, the K-L expansion was studied by Lenz [64], and used in a number of other detectors such as [122] and [81]. More ad-hoc dimension reduction was incorporated into earlier detectors, beginning with Hueckel [50], but also including Morgenthaler [74]. <p> On the other hand, if the nearest manifold point is too far away, no feature is detected. This statement of the feature detection problem was first proposed by Hueckel [50], and was subsequently used by O'Gorman [88], Hummel <ref> [52] </ref>, Hartley [46], and Nalwa and Binford [80] for the detection of step edges. Hueckel [51] applied the same formulation to line detection 32 and Rohr [106] used it to detect corners. <p> The same approach generalizes to 3-dimensional data, as was used by Zucker and Hummel [122] and by Lenz [64]. See Section 2.1 for more discussion of these so called model-matching feature detectors. Hueckel [50] and Hummel <ref> [52] </ref> both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest point on the manifold. To make their derivations possible, they used simplified feature models and completely neglected sensing effects. My view of feature detection is radically different. <p> This idea was first explored by Hummel <ref> [52] </ref> and later by Lenz [64]. See Section 2.1.4 for a discussion of the use of dimension reduction in feature detection. If correlation between feature instances is the preferred measure of similarity, the Karhunen-Loeve (K-L) expansion [38] [89] yields the optimal subspace. <p> See Chapter 2 for a comprehensive review of the feature detection literature. Figures 3.1 (a) and 3.1 (b) show isometric and plan views of the step edge model that I used. This model is a generalization of the models used in [50], <ref> [52] </ref>, and [64]. It is closest to the one used by Nalwa and Binford [80] in terms of the number and type of parameters, but differs slightly in its treatment of smoothing and blurring effects. <p> Moreover, to avoid the unnecessary non-linearities induced by a square window, I used a disc shaped one. In Figure 3.1 (c), I display the eight most prominent eigenvectors, ordered by their eigenvalues. The similarity between the first four eigenvectors and the ones derived analytically by Hummel in <ref> [52] </ref> is immediate. Notice, however, that while the eigenvectors of [52] are radially symmetric, the ones in Figure 3.1 (c) are not. This is to be expected since the introduction of the parameters and breaks the radial symmetry of Hummel's edge model. <p> In Figure 3.1 (c), I display the eight most prominent eigenvectors, ordered by their eigenvalues. The similarity between the first four eigenvectors and the ones derived analytically by Hummel in <ref> [52] </ref> is immediate. Notice, however, that while the eigenvectors of [52] are radially symmetric, the ones in Figure 3.1 (c) are not. This is to be expected since the introduction of the parameters and breaks the radial symmetry of Hummel's edge model. While the eigenvectors in 45 A and A + B. <p> The step edge manifold is parameterized by orientation and sub-pixel localization for a fixed blurring value and is displayed in a 3-D subspace constructed using the first three K-L eigenvectors. 46 <ref> [52] </ref> are optimal for the edge model used there, Figure 3.1 (c) shows that they are not optimal for my, more realistic, edge model. <p> To reduce the residual to 10% three eigenvectors are needed, and to reduce it further to 2% eight eigenvectors must be used. These results represent a compression factor in the range 5-15. As a result, the efficiency of feature detection is greatly enhanced. In <ref> [52] </ref>, Hummel derives the result that the eigenvalues for his continuous step edge model should decay like 1=n 2 . The results in Figure 3.1 (d) are consistent with this prediction. <p> By plotting n against n on logarithmic scales and fitting a straight line to the curve, I found that the eigenvalues initially decay like 1=n 2 . However, because I am working in R N rather than the infinite dimensional continuous domain considered in <ref> [52] </ref>, the rate of decay increases for larger n. The step edge manifold is displayed in Figure 3.1 (e). Naturally, I only display a projection of it into a 3-D subspace. The subspace chosen is the one spanned by the three most prominent eigenvectors.
Reference: [53] <author> B.F. Logan Jr. </author> <title> Information in the zero crossings of bandpass signals. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 56(4) </volume> <pages> 487-510, </pages> <month> April </month> <year> 1977. </year>
Reference-contexts: A number of positive results have been found in which it has been shown that the zero crossings at multiple scales are complete for large classes of images <ref> [53] </ref> [120] [115]. However, recently counterexamples have been found to the most general statement of the problem 28 by Meyer, as described by Mallat in [69].
Reference: [54] <author> G.E. Sotak Jr. and K.L. Boyer. </author> <title> The Laplacian-of-Gaussian kernal: A formal analysis and design procedure for fast, accurate convolution and full-frame output. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 48 </volume> <pages> 147-189, </pages> <year> 1989. </year>
Reference-contexts: Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] <ref> [54] </ref>, accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> Perhaps the most popular choices have been the Gaussian filter and the Laplacian. Laplacian of Gaussian detectors date back to the Marr-Hildreth detector [70]. Since then, the Laplacian of Gaussian has been studied in great depth. For example, its efficiency [22] <ref> [54] </ref>, accuracy [11] [54], information content [69] [70], and topological properties [115] have all been investigated. Naturally, other choices are possible. <p> Other examples of recursive filtering include the Modestino and Fries detector [72] and the Sarkar and Boyer detector [109]. 26 Another example of an efficient filtering technique is the approach of Chen et al. [22], a technique that was later refined by Sotak and Boyer <ref> [54] </ref>. Chen et al. [22] proposed decomposing the Laplacian of Gaussian operator [70] into the product of a Gaussian with smaller standard deviation, and a Laplacian of Gaussian with standard deviation chosen to make up the difference.
Reference: [55] <author> G. </author> <title> Kanizsa. Subjective contours. </title> <journal> Scientific American, </journal> <volume> 234(4) </volume> <pages> 48-52, </pages> <year> 1976. </year>
Reference-contexts: unsuitable because: (1) it is a tedious task and hence error prone, and (2) humans can bring higher level processing to bear, and so there is no guarantee that what is perceived is actually present in the local image data, as is demonstrated 22 by phenomena such as subjective contours <ref> [55] </ref>. In fact, in a recent paper in which this approach is taken, Dougherty and Bowyer allowed the human to mask out any regions for which it was too difficult for the human to say which pixels contain edges [32].
Reference: [56] <author> T. Kanungo, M.Y. Jaisimha, J. Palmer, and R.M. Haralick. </author> <title> A methodology for quantitative performance evaluation of detection algorithms. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 4(12) </volume> <pages> 1667-1673, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: Performance of Applications: The fourth class consists of measures that directly assess the performance of applications. Examples include, the computation of projective invariants [24], object recognition [47], structure from motion [112], industrial inspection [114], and boundary extraction <ref> [56] </ref> [90]. Local Measures of Coherence: The fifth and final class consists of measures that are based upon desirable local properties of the output feature map, for example, continuation and thinness [57] [95] [121].
References-found: 56

