URL: http://www.cs.huji.ac.il/~feit/parsched/p-97-8.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~feit/parsched/parsched97.html
Root-URL: http://www.cs.huji.ac.il
Email: feparsons,kcsg@cs.utoronto.ca  
Title: Implementing Multiprocessor Scheduling Disciplines  
Author: Eric W. Parsons and Kenneth C. Sevcik 
Address: Toronto, Canada  
Affiliation: Computer Systems Research Institute University of  
Abstract: An important issue in multiprogrammed multiprocessor systems is the scheduling of parallel jobs. Consequently, there has been a considerable amount of analytic research in this area recently. A frequent criticism, however, is that proposed disciplines that are studied analytically are rarely ever implemented and even more rarely incorporated into commercial scheduling software. In this paper, we seek to bridge this gap by describing how at least one commercial scheduling system, namely Platform Computing's Load Sharing Facility, can be extended to support a wide variety of new scheduling disciplines. We then describe the design and implementation of a number of multiprocessor scheduling disciplines, each differing considerably in terms of the type of preemption that is assumed to be available and in terms of the flexibility allowed in allocating processors. In evaluating the performance of these disciplines, we find that preemption can significantly reduce overall response times, but that the performance of disciplines that must commit to allocations when a job is first activated can be significantly affected by transient loads.
Abstract-found: 1
Intro-found: 1
Reference: [BG96] <author> Timothy B. Brecht and Kaushik Guha. </author> <title> Using parallel program characteristics in dynamic processor allocation policies. Performance Evaluation, </title> 27&28:519-539, 1996. 
Reference-contexts: either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E <ref> [BG96] </ref> yes yes no BUDDY,EPOCH [MZ95] no no yes MPA [PS96b, PS96a] no yes yes LSF-MALL-AD (SUBSET) either either either Table 1: Representative set of disciplines that have been proposed and evaluated in the literature.
Reference: [CMV94] <author> Su-Hui Chiang, Rajesh K. Manshara-mani, and Mary K. Vernon. </author> <title> Use of application characteristics and limited preemption for run-to-completion parallel processor scheduling policies. </title> <booktitle> In Proceedings of the 1994 ACM SIGMETRICS Conference on Measurement and Mod-elling of Computer Systems, </booktitle> <pages> pages 33-44, </pages> <year> 1994. </year>
Reference-contexts: The third observation is that workloads found in practice tend to have a very high degree of variability in the amount of computational work (also known as service demand ) <ref> [CMV94, FN95, Gib96] </ref>. In other words, most jobs have very small service demands but a few jobs can run for a very long time. <p> preemption. 3 Some rigid schedulers do use service-demand information if available, but this distinction is not shown in this table. 3 Rigid Adaptive Work Speedup Memory RTC RTC [ZM90] A+,A+&mM [Sev89] yes min/max no NQS PWS [GST91] no no no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF <ref> [CMV94] </ref> yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable <p> service-demand information if available, but this distinction is not shown in this table. 3 Rigid Adaptive Work Speedup Memory RTC RTC [ZM90] A+,A+&mM [Sev89] yes min/max no NQS PWS [GST91] no no no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF <ref> [CMV94] </ref> yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no
Reference: [FN95] <author> Dror G. Feitelson and Bill Nitzberg. </author> <title> Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/860. </title> <editor> In Dror G. Feitelson and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 949, </volume> <pages> pages 337-360. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: The third observation is that workloads found in practice tend to have a very high degree of variability in the amount of computational work (also known as service demand ) <ref> [CMV94, FN95, Gib96] </ref>. In other words, most jobs have very small service demands but a few jobs can run for a very long time.
Reference: [FR92] <author> Dror G. Feitelson and Larry Rudolph. </author> <title> Gang scheduling performance benefits for fine-grain synchronization. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16 </volume> <pages> 306-318, </pages> <year> 1992. </year>
Reference-contexts: This can either result in large context-switch overheads or wasted processor cycles. In general, a single thread is associated with each processor, an approach which is known as coordinated or gang scheduling <ref> [Ous82, FR92] </ref>.
Reference: [Gib96] <author> Richard Gibbons. </author> <title> A historical application profiler for use by parallel schedulers. </title> <type> Master's thesis, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1996. </year> <month> 16 </month>
Reference-contexts: The third observation is that workloads found in practice tend to have a very high degree of variability in the amount of computational work (also known as service demand ) <ref> [CMV94, FN95, Gib96] </ref>. In other words, most jobs have very small service demands but a few jobs can run for a very long time. <p> can be defined by assigning processors to the corresponding queues using the LSF queue administration tools. (Normally, each discipline uses a single queue for processor information.) The extension library described here has also been used by Gibbons in studying a number of rigid scheduling disciplines, including two variants of EASY <ref> [Lif95, SCZL96, Gib96, Gib97] </ref>. One of the goals of Gibbons' work was to determine whether historical information about a job could be exploited in scheduling. He found that, for many workloads, historical information could provide up to 75% of the benefits of having perfect information. <p> He then adapted the original EASY discipline to take into account this knowledge and showed how performance could be improved. The historical database and details of the scheduling disciplines studied by Gibbons are described elsewhere <ref> [Gib96, Gib97] </ref>. The high-level organization of the scheduling extension library (not including the historical database) is shown in Figure 2. The extension process contains the extension library and each of the disciplines configured for the system.
Reference: [Gib97] <author> Richard Gibbons. </author> <title> A historical ap-plication profiler for use by parallel schedulers. </title> <editor> In Dror G. Feitelson and Larry Rudolph, editors, </editor> <booktitle> Proceedings of the Third Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: can be defined by assigning processors to the corresponding queues using the LSF queue administration tools. (Normally, each discipline uses a single queue for processor information.) The extension library described here has also been used by Gibbons in studying a number of rigid scheduling disciplines, including two variants of EASY <ref> [Lif95, SCZL96, Gib96, Gib97] </ref>. One of the goals of Gibbons' work was to determine whether historical information about a job could be exploited in scheduling. He found that, for many workloads, historical information could provide up to 75% of the benefits of having perfect information. <p> He then adapted the original EASY discipline to take into account this knowledge and showed how performance could be improved. The historical database and details of the scheduling disciplines studied by Gibbons are described elsewhere <ref> [Gib96, Gib97] </ref>. The high-level organization of the scheduling extension library (not including the historical database) is shown in Figure 2. The extension process contains the extension library and each of the disciplines configured for the system.
Reference: [GST91] <author> Dipak Ghosal, Guiseppe Serazzi, and Satish K. Tripathi. </author> <title> The processor working set and its use in scheduling multiprocessor systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(5) </volume> <pages> 443-453, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: As a result, providing the scheduler with some flexibility in allocating processors can significantly improve overall performance <ref> [GST91, Sev94, NSS93, RSD + 94] </ref>. In most systems, users specify precisely the number of processors which should be allocated to each job, a practice that is known as rigid scheduling. <p> literature, but we find it more convenient to treat it as a type of preemption. 3 Some rigid schedulers do use service-demand information if available, but this distinction is not shown in this table. 3 Rigid Adaptive Work Speedup Memory RTC RTC [ZM90] A+,A+&mM [Sev89] yes min/max no NQS PWS <ref> [GST91] </ref> no no no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF [CMV94] yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no
Reference: [GTS91] <author> Anoop Gupta, Andrew Tucker, and Luis Stevens. </author> <title> Making effective use of shared-memory multiprocessors: The process control approach. </title> <type> Technical Report CSL-TR-91-475A, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: preemption, the size of a job's processor allocation may be changed after it has begun execution, a feature that normally requires explicit support within the application. 2 In the process control approach, the application must be designed to to adapt dynamically to changes in processor allocation while it is running <ref> [TG89, GTS91, NVZ96] </ref>. As this type of support is uncommon, a simpler strategy may be to rely on application-level checkpointing, often used by long-running jobs to tolerate system failures.
Reference: [Hen95] <author> Robert L. Henderson. </author> <title> Job scheduling under the portable batch system. </title> <editor> In Dror G. Feitelson and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 949, </volume> <pages> pages 279-294. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: On the other hand, most research results support the need for both preemption and mechanisms for adjusting processor allocations of jobs. Given that a number of high-performance computing centers have begun to develop their own scheduling software <ref> [Hen95, Lif95, SCZL96, WMKS96] </ref>, it is clear that existing commercial scheduling software is often inadequate. To support these centers, however, mechanisms to extend existing systems with external (customer-provided) policies are starting to become available in commercial software [SCZL96].
Reference: [Hot96a] <author> Steven Hotovy. </author> <title> Private communication, </title> <month> November </month> <year> 1996. </year>
Reference-contexts: for jobs are drawn from a hyper-exponential distribution, with mean of 8000 seconds (2.2 hours) and coefficient of variation (CV) of 4, a distribution whose median is 2985 seconds. 8 The parameters are consistent with measurements made over the past year at the Cornell Theory Center (scaled to 128 processors) <ref> [Hot96b, Hot96a] </ref>.
Reference: [Hot96b] <author> Steven Hotovy. </author> <title> Workload evolution on the Cornell Theory Center IBM SP-2. </title> <editor> In Dror G. Feitelson and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 1162, </volume> <pages> pages 27-40. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: for jobs are drawn from a hyper-exponential distribution, with mean of 8000 seconds (2.2 hours) and coefficient of variation (CV) of 4, a distribution whose median is 2985 seconds. 8 The parameters are consistent with measurements made over the past year at the Cornell Theory Center (scaled to 128 processors) <ref> [Hot96b, Hot96a] </ref>.
Reference: [Lif95] <author> David A. Lifka. </author> <title> The ANL/IBM SP scheduling system. </title> <editor> In Dror G. Feit-elson and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 949, </volume> <pages> pages 295-303. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: On the other hand, most research results support the need for both preemption and mechanisms for adjusting processor allocations of jobs. Given that a number of high-performance computing centers have begun to develop their own scheduling software <ref> [Hen95, Lif95, SCZL96, WMKS96] </ref>, it is clear that existing commercial scheduling software is often inadequate. To support these centers, however, mechanisms to extend existing systems with external (customer-provided) policies are starting to become available in commercial software [SCZL96]. <p> The disciplines proposed in this paper are highlighted in italics. (A more complete version of this table can be found elsewhere [Par97].) LoadLeveler is a commercial scheduling system designed primarily for the IBM SP-2 system. A recent extension to LoadLeveler that has become popular is EASY <ref> [Lif95, SCZL96] </ref>. This is a rigid RTC scheduler that uses execution-time information provided by the user to offer both greater predictability and better system utilization. <p> do use service-demand information if available, but this distinction is not shown in this table. 3 Rigid Adaptive Work Speedup Memory RTC RTC [ZM90] A+,A+&mM [Sev89] yes min/max no NQS PWS [GST91] no no no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF [CMV94] yes no no EASY <ref> [Lif95] </ref> AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no <p> can be defined by assigning processors to the corresponding queues using the LSF queue administration tools. (Normally, each discipline uses a single queue for processor information.) The extension library described here has also been used by Gibbons in studying a number of rigid scheduling disciplines, including two variants of EASY <ref> [Lif95, SCZL96, Gib96, Gib97] </ref>. One of the goals of Gibbons' work was to determine whether historical information about a job could be exploited in scheduling. He found that, for many workloads, historical information could provide up to 75% of the benefits of having perfect information.
Reference: [MT90] <author> Silvano Martello and Paolo Toth. </author> <title> Knapsack Problems: Algorithms and Computer Implementations. </title> <publisher> Wiley & Sons, </publisher> <year> 1990. </year>
Reference-contexts: This approach minimizes both the processor and memory occupancy in a distributed-memory environment, leading to the highest possible sustainable throughput [PS96a]. The SUBSET variant seeks to improve the efficiency by which processors are utilized by applying an algorithm known as a subset-sum algorithm <ref> [MT90] </ref>. The basic principle is that, if jobs are selected so as to maximize the sum of minimum processor allocations, then that will lead to the fewest number of "excess" processors.
Reference: [MVZ93] <author> Cathy McCann, Raj Vaswani, and John Zahorjan. </author> <title> A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(2) </volume> <pages> 146-178, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF [CMV94] yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob <ref> [MVZ93] </ref> FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH [MZ95] no no yes MPA [PS96b, PS96a] no yes yes LSF-MALL-AD (SUBSET) either either either Table 1: Representative set <p> no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition <ref> [TG89, MVZ93] </ref> no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH [MZ95] no no yes MPA [PS96b, PS96a] no yes yes LSF-MALL-AD (SUBSET) either either either Table 1: Representative set of disciplines that have been proposed and evaluated in the literature.
Reference: [MZ94] <author> Cathy McCann and John Zahorjan. </author> <title> Processor allocation policies for message-passing parallel computers. </title> <booktitle> In Proceedings of the 1994 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 19-32, </pages> <year> 1994. </year>
Reference-contexts: In general, a single thread is associated with each processor, an approach which is known as coordinated or gang scheduling [Ous82, FR92]. Sometimes, however, it is possible to multiplex threads of the same job on a reduced number of processors and still achieve good performance <ref> [MZ94] </ref>. (In the latter case, it is still assumed that only threads from a single job are simultaneously active on any given processor.) Second, jobs generally make more efficient use of the processing resources given smaller processors allocations. <p> avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no FOLD,EQUI <ref> [MZ94] </ref> no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH [MZ95] no no yes MPA [PS96b, PS96a] no yes yes LSF-MALL-AD (SUBSET) either either either Table 1: Representative set of disciplines that have been proposed and evaluated in the literature.
Reference: [MZ95] <author> Cathy McCann and John Zahorjan. </author> <title> Scheduling memory constrained jobs on distributed memory parallel computers. </title> <booktitle> In Proceedings of the 1995 ACM SIG-METRICS Joint International Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 208-219, </pages> <year> 1995. </year>
Reference-contexts: [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH <ref> [MZ95] </ref> no no yes MPA [PS96b, PS96a] no yes yes LSF-MALL-AD (SUBSET) either either either Table 1: Representative set of disciplines that have been proposed and evaluated in the literature. <p> Minimum processor allocation sizes are uniformly chosen from one to sixteen processors, and maximum sizes are set at sixteen. 9 This distribution is similar to those used in previous studies in this area <ref> [PS96a, MZ95, Set95] </ref>. The processor allocation size used for rigid disciplines is chosen from a uniform distribution between the minimum and the maximum processor allocations for the job.
Reference: [NSS93] <author> Vijay K. Naik, Sanjeev K. Setia, and Mark S. Squillante. </author> <title> Performance analysis of job scheduling policies in parallel supercomputing environments. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 824-833, </pages> <year> 1993. </year>
Reference-contexts: As a result, providing the scheduler with some flexibility in allocating processors can significantly improve overall performance <ref> [GST91, Sev94, NSS93, RSD + 94] </ref>. In most systems, users specify precisely the number of processors which should be allocated to each job, a practice that is known as rigid scheduling.
Reference: [NVZ96] <author> Thu D. Nguyen, Raj Vaswani, and John Zahorjan. </author> <title> Using runtime measured workload characteristics in parallel processor scheduling. </title> <editor> In Dror G. Feitel-son and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 1162, </volume> <pages> pages 175-199. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: preemption, the size of a job's processor allocation may be changed after it has begun execution, a feature that normally requires explicit support within the application. 2 In the process control approach, the application must be designed to to adapt dynamically to changes in processor allocation while it is running <ref> [TG89, GTS91, NVZ96] </ref>. As this type of support is uncommon, a simpler strategy may be to rely on application-level checkpointing, often used by long-running jobs to tolerate system failures.
Reference: [Ous82] <author> John K. Ousterhout. </author> <title> Scheduling techniques for concurrent systems. </title> <booktitle> In Proceedings of the 3rd International Conference on Distributed Computing (ICDCS), </booktitle> <pages> pages 22-30, </pages> <month> October </month> <year> 1982. </year>
Reference-contexts: This can either result in large context-switch overheads or wasted processor cycles. In general, a single thread is associated with each processor, an approach which is known as coordinated or gang scheduling <ref> [Ous82, FR92] </ref>. <p> Rigid Adaptive Work Speedup Memory RTC RTC [ZM90] A+,A+&mM [Sev89] yes min/max no NQS PWS [GST91] no no no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF [CMV94] yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) <ref> [Ous82] </ref> LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH [MZ95] <p> min/max no NQS PWS [GST91] no no no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF [CMV94] yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) <ref> [Ous82] </ref> LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH [MZ95] no no yes MPA [PS96b, PS96a] no yes yes LSF-MALL-AD (SUBSET)
Reference: [Par97] <author> Eric W. Parsons. </author> <title> Using Knowledge of Job Characteristics in Multiprogrammed Multiprocessor Scheduling. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1997. </year>
Reference-contexts: The disciplines proposed in this paper are highlighted in italics. (A more complete version of this table can be found elsewhere <ref> [Par97] </ref>.) LoadLeveler is a commercial scheduling system designed primarily for the IBM SP-2 system. A recent extension to LoadLeveler that has become popular is EASY [Lif95, SCZL96]. This is a rigid RTC scheduler that uses execution-time information provided by the user to offer both greater predictability and better system utilization. <p> at lighter loads, since at heavy loads, jobs seldom receive many more processors than their minimum allocation. 10 Such a two-speedup-class workload appears to be supported by data from the Cornell Theory Center if we examine the amount of CPU time consumed by each job relative to its elapsed time <ref> [Par97] </ref>. 12 Discipline No Knowledge Service-Demand Speedup Both MRT Makespan MRT Makespan MRT Makespan MRT Makespan LSF-RTC 5853 147951 4040 140342 5279 130361 5627 143507 LSF-RTC-ADSUBSET 8264 76637 8410 81767 8039 73324 8074 75340 LSF-PREEMPT 5793 145440 5039 143686 5280 130314 5028 143631 LSF-PREEMPT-AD &gt; 2293 &gt; 219105 (2) 1078 127204
Reference: [PL96] <author> Jim Pruyne and Miron Livny. </author> <title> Managing checkpoints for parallel programs. </title> <editor> In Dror G. Feitelson and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 1162, </volume> <pages> pages 140-154. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <month> 17 </month>
Reference-contexts: In message-passing systems, operating-system support for migration is not usually provided, 2 but checkpointing can often be employed in-stead. 1 For example, the Condor system provides a transparent checkpointing facility for parallel applications that use either MPI or PVM <ref> [PL96] </ref>.
Reference: [PS95] <author> Eric W. Parsons and Kenneth C. Sev--cik. </author> <title> Multiprocessor scheduling for high-variability service time distributions. </title> <editor> In Dror G. Feitelson and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 949, </volume> <pages> pages 127-145. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Run-to-completion (RTC) disciplines exhibit very high response times because once a long-running job is dispatched, short jobs must wait a considerable amount of time before processors become available. Preemption can significantly reduce the mean response times of these workloads relative to run-to-completion disciplines <ref> [PS95] </ref>. Unlike the sequential case, preemption of parallel jobs can be quite expensive and complex to support. Fortunately, results indicate that preemption does not need to be invoked frequently to be useful, since only long-running jobs ever need to be preempted.
Reference: [PS96a] <author> Eric W. Parsons and Kenneth C. Sev-cik. </author> <title> Benefits of speedup knowledge in memory-constrained multiprocessor scheduling. Performance Evaluation, </title> 27&28:253-272, 1996. 
Reference-contexts: either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH [MZ95] no no yes MPA <ref> [PS96b, PS96a] </ref> no yes yes LSF-MALL-AD (SUBSET) either either either Table 1: Representative set of disciplines that have been proposed and evaluated in the literature. Disci plines presented in this paper are italicized and have the prefix "LSF-"; for the adaptive ones, a regular and a "SUBSET" version are provided. <p> If speedup information information is available, the scheduler allocates each leftover processor, in turn, to the job whose efficiency will be highest after the allocation. This approach minimizes both the processor and memory occupancy in a distributed-memory environment, leading to the highest possible sustainable throughput <ref> [PS96a] </ref>. The SUBSET variant seeks to improve the efficiency by which processors are utilized by applying an algorithm known as a subset-sum algorithm [MT90]. <p> Minimum processor allocation sizes are uniformly chosen from one to sixteen processors, and maximum sizes are set at sixteen. 9 This distribution is similar to those used in previous studies in this area <ref> [PS96a, MZ95, Set95] </ref>. The processor allocation size used for rigid disciplines is chosen from a uniform distribution between the minimum and the maximum processor allocations for the job. <p> It has been shown previously that performance benefits of knowing speedup information can only be obtained if a large fraction of the total work in the workload has good speedup, and moreover, if larger-sized jobs tend to have better speedup than smaller-sized ones <ref> [PS96a] </ref>. As such, we let 75% of the jobs have good speedup, where 99.9% of the work is perfectly parallelizable (corresponding to a speedup of 114 on 128 processors).
Reference: [PS96b] <author> Eric W. Parsons and Kenneth C. Sevcik. </author> <title> Coordinated allocation of memory and processors in multiprocessors. </title> <booktitle> In Proceedings of the 1996 ACM SIGMETRICS Conference on Measurement and Mod-elling of Computer Systems, </booktitle> <pages> pages 57-67, </pages> <year> 1996. </year>
Reference-contexts: either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH [MZ95] no no yes MPA <ref> [PS96b, PS96a] </ref> no yes yes LSF-MALL-AD (SUBSET) either either either Table 1: Representative set of disciplines that have been proposed and evaluated in the literature. Disci plines presented in this paper are italicized and have the prefix "LSF-"; for the adaptive ones, a regular and a "SUBSET" version are provided.
Reference: [RSD + 94] <author> E. Rosti, E. Smirni, L. W. Dowdy, G. Serazzi, and B. M. Carlson. </author> <title> Robust partitioning policies of multiprocessor systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 141-165, </pages> <year> 1994. </year>
Reference-contexts: As a result, providing the scheduler with some flexibility in allocating processors can significantly improve overall performance <ref> [GST91, Sev94, NSS93, RSD + 94] </ref>. In most systems, users specify precisely the number of processors which should be allocated to each job, a practice that is known as rigid scheduling. <p> convenient to treat it as a type of preemption. 3 Some rigid schedulers do use service-demand information if available, but this distinction is not shown in this table. 3 Rigid Adaptive Work Speedup Memory RTC RTC [ZM90] A+,A+&mM [Sev89] yes min/max no NQS PWS [GST91] no no no LSF Equal,IP <ref> [RSD + 94] </ref> no no no LoadLeveler SDF [CMV94] yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws
Reference: [SCZL96] <author> Joseph Skovira, Waiman Chan, Honbo Zhou, and David Lifka. </author> <title> The EASY-LoadLeveler API project. </title> <editor> In Dror G. Fei-telson and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 1162, </volume> <pages> pages 41-47. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: On the other hand, most research results support the need for both preemption and mechanisms for adjusting processor allocations of jobs. Given that a number of high-performance computing centers have begun to develop their own scheduling software <ref> [Hen95, Lif95, SCZL96, WMKS96] </ref>, it is clear that existing commercial scheduling software is often inadequate. To support these centers, however, mechanisms to extend existing systems with external (customer-provided) policies are starting to become available in commercial software [SCZL96]. <p> To support these centers, however, mechanisms to extend existing systems with external (customer-provided) policies are starting to become available in commercial software <ref> [SCZL96] </ref>. This allows new scheduling policies to be easily implemented, without having to re-implement much of the base functionality typically found in this type of software. The primary objective of this paper is to help bridge the gap between some of the analytic research and practical implementations of scheduling disciplines. <p> The disciplines proposed in this paper are highlighted in italics. (A more complete version of this table can be found elsewhere [Par97].) LoadLeveler is a commercial scheduling system designed primarily for the IBM SP-2 system. A recent extension to LoadLeveler that has become popular is EASY <ref> [Lif95, SCZL96] </ref>. This is a rigid RTC scheduler that uses execution-time information provided by the user to offer both greater predictability and better system utilization. <p> can be defined by assigning processors to the corresponding queues using the LSF queue administration tools. (Normally, each discipline uses a single queue for processor information.) The extension library described here has also been used by Gibbons in studying a number of rigid scheduling disciplines, including two variants of EASY <ref> [Lif95, SCZL96, Gib96, Gib97] </ref>. One of the goals of Gibbons' work was to determine whether historical information about a job could be exploited in scheduling. He found that, for many workloads, historical information could provide up to 75% of the benefits of having perfect information.
Reference: [Set95] <author> Sanjeev K. Setia. </author> <title> The interaction between memory allocations and adaptive partitioning in message-passing multiprocessors. </title> <editor> In Dror G. Feitelson and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 949, </volume> <pages> pages 146-164. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Minimum processor allocation sizes are uniformly chosen from one to sixteen processors, and maximum sizes are set at sixteen. 9 This distribution is similar to those used in previous studies in this area <ref> [PS96a, MZ95, Set95] </ref>. The processor allocation size used for rigid disciplines is chosen from a uniform distribution between the minimum and the maximum processor allocations for the job.
Reference: [Sev89] <author> Kenneth C. Sevcik. </author> <title> Characterizations of parallelism in applications and their use in scheduling. </title> <booktitle> In Proceedings of the 1989 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 171-180, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: often termed dynamic partitioning in the literature, but we find it more convenient to treat it as a type of preemption. 3 Some rigid schedulers do use service-demand information if available, but this distinction is not shown in this table. 3 Rigid Adaptive Work Speedup Memory RTC RTC [ZM90] A+,A+&mM <ref> [Sev89] </ref> yes min/max no NQS PWS [GST91] no no no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF [CMV94] yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched
Reference: [Sev94] <author> K. C. Sevcik. </author> <title> Application scheduling and processor allocation in multiprogrammed parallel processing systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 107-140, </pages> <year> 1994. </year>
Reference-contexts: As a result, providing the scheduler with some flexibility in allocating processors can significantly improve overall performance <ref> [GST91, Sev94, NSS93, RSD + 94] </ref>. In most systems, users specify precisely the number of processors which should be allocated to each job, a practice that is known as rigid scheduling.
Reference: [ST93] <author> Sanjeev Setia and Satish Tripathi. </author> <title> A comparative analysis of static processor partitioning policies for parallel computers. </title> <booktitle> In Proceedings of the International Workshop on Modeling and Simulation of Computer and Telecommunication Systems (MASCOTS), </booktitle> <pages> pages 283-286, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: If service-demand information is provided to the sched-uler, then jobs are scanned in order of increasing service demand, resulting in a shortest processing time (SPT) discipline (again with skipping). The LSF-RTC-AD discipline is very similar to the ASP discipline proposed by Setia et al. <ref> [ST93] </ref>, except that jobs are selected for execution differently because the LSF-based disciplines take into account memory requirements of jobs (and hence cannot be called ASP).
Reference: [TG89] <author> Andrew Tucker and Anoop Gupta. </author> <title> Process control and scheduling issues for multiprogrammed shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 159-166, </pages> <year> 1989. </year>
Reference-contexts: preemption, the size of a job's processor allocation may be changed after it has begun execution, a feature that normally requires explicit support within the application. 2 In the process control approach, the application must be designed to to adapt dynamically to changes in processor allocation while it is running <ref> [TG89, GTS91, NVZ96] </ref>. As this type of support is uncommon, a simpler strategy may be to rely on application-level checkpointing, often used by long-running jobs to tolerate system failures. <p> no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin [ZM90] no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition <ref> [TG89, MVZ93] </ref> no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH [MZ95] no no yes MPA [PS96b, PS96a] no yes yes LSF-MALL-AD (SUBSET) either either either Table 1: Representative set of disciplines that have been proposed and evaluated in the literature.
Reference: [WMKS96] <author> Michael Wan, Regan Moore, George Kremenek, and Ken Steube. </author> <title> A batch scheduler for the Intel Paragon with a non-contiguous node allocation algorithm. </title> <editor> In Dror G. Feitelson and Larry Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 1162, </volume> <pages> pages 48-64. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: On the other hand, most research results support the need for both preemption and mechanisms for adjusting processor allocations of jobs. Given that a number of high-performance computing centers have begun to develop their own scheduling software <ref> [Hen95, Lif95, SCZL96, WMKS96] </ref>, it is clear that existing commercial scheduling software is often inadequate. To support these centers, however, mechanisms to extend existing systems with external (customer-provided) policies are starting to become available in commercial software [SCZL96].
Reference: [ZM90] <author> John Zahorjan and Cathy McCann. </author> <title> Processor scheduling in shared memory multiprocessors. </title> <booktitle> In Proceedings of the 1990 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 214-225, </pages> <year> 1990. </year> <month> 18 </month>
Reference-contexts: preemption is often termed dynamic partitioning in the literature, but we find it more convenient to treat it as a type of preemption. 3 Some rigid schedulers do use service-demand information if available, but this distinction is not shown in this table. 3 Rigid Adaptive Work Speedup Memory RTC RTC <ref> [ZM90] </ref> A+,A+&mM [Sev89] yes min/max no NQS PWS [GST91] no no no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF [CMV94] yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either <p> NQS PWS [GST91] no no no LSF Equal,IP [RSD + 94] no no no LoadLeveler SDF [CMV94] yes no no EASY [Lif95] AVG,Adapt-AVG [CMV94] no avg no LSF-RTC LSF-RTC-AD (SUBSET) either either either Preemption simple Cosched (matrix) [Ous82] LSF-PREEMPT LSF-PREEMPT AD (SUBSET) either either either migratable Cosched (other) [Ous82] Round-Robin <ref> [ZM90] </ref> no no no RRJob [MVZ93] FB-ASP,FB-PWS no pws no LSF-MIG LSF-MIG-AD (SUBSET) either either either malleable Equi/Dynamic Partition [TG89, MVZ93] no no no FOLD,EQUI [MZ94] no no no (not applicable) W&E [BG96] yes yes no BUDDY,EPOCH [MZ95] no no yes MPA [PS96b, PS96a] no yes yes LSF-MALL-AD (SUBSET) either either
References-found: 33

