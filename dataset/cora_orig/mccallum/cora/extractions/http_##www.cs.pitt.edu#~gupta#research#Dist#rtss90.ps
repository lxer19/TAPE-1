URL: http://www.cs.pitt.edu/~gupta/research/Dist/rtss90.ps
Refering-URL: http://www.cs.pitt.edu/~gupta/research/dist.html
Root-URL: 
Email: psg@philabs.philips.com gupta@cs.pitt.edu  
Title: Applying Compiler Techniques to Scheduling in Real-Time Systems  
Author: Prabha Gopinath Rajiv Gupta 
Address: Alumni Hall 345 Scarborough Road Univ. of Pittsburgh Briarcliff Manor, NY 10510 Pittsburgh, PA 15260  
Affiliation: Philips Laboratories Dept. of Computer Sc. North American Philips Corp.  
Abstract: Worst case scheduling techniques for real-time applications often result in severe underutilization of the processor resources since most tasks finish in much less time than their anticipated worst-case execution times. In this paper we describe compiler-based techniques that classify the application code on the basis of predictability and monotonicity, introduce measurement code fragments at selected points in the application code, and use the results of run-time measurements to dynamically adapt worst-case schedules. This results in better utilization of the system and early failure detection and recovery. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Gopinath and R. Gupta, </author> <title> "Compiler Assisted Adaptive Scheduling in Real-time Systems," </title> <booktitle> The Seventh IEEE Workshop on Real-Time Operating Systems and Software, Real-Time Systems Newsletter, </booktitle> <volume> Vol. 6, No. 2, </volume> <pages> pages 62-69, </pages> <institution> University of Virginia, Charlottesville, Virginia, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: Optional tasks can be viewed as Monotonically improving upon the result generated by the mandatory subtask. 1.3 Compiler Assisted Adaptive Scheduling Our technique of dealing with the problem of scheduling tasks in real-time systems is called Compiler Assisted Adaptive Scheduling (CAADS) <ref> [1] </ref>. This may briefly be described as follows. The compiler examines the application code and inserts measurement code at appropriate boundaries. The measurement code enables execution times of the various parts of the program to be determined at run-time.
Reference: [2] <author> D. Haban and K.G. Shin, </author> <title> "Application of Real-Time Monitoring to Scheduling Tasks with Random Execution Times," </title> <booktitle> Proc. the 10th IEEE Real-Time Systems Symposium, </booktitle> <address> pp.172-183, </address> <year> 1989. </year>
Reference-contexts: In the first project, Haban and Shin use a real-time monitor consisting of dedicated hardware and software to affect the scheduling of tasks <ref> [2, 3] </ref>. The monitor is installed as a part of the real-time system. A task in the system is divided by the programmer into n disjoint partitions based on its structure.
Reference: [3] <author> D. Haban and K.G. Shin, </author> <title> "Monitoring Distributed Real-Time Systems and its Application," </title> <booktitle> Proc. 6th IEEE Real-Time Operating Systems Workshop, </booktitle> <year> 1989. </year>
Reference-contexts: The severity of the failure depends on whether the constraints were hard or soft. fl This work was done while the author was at Philips Laboratories. 1 A more complete taxonomy of time related notations can be found in the work by Haban and Shin <ref> [3] </ref>. The traditional approach to handling these problems is to design cyclical schedulers to manage the execution of concurrent processes; the worst case execution times are assumed to be known a priori, either from profiling runs, instruction counting, or educated guesses, and an execution timeline is manually laid out. <p> In the first project, Haban and Shin use a real-time monitor consisting of dedicated hardware and software to affect the scheduling of tasks <ref> [2, 3] </ref>. The monitor is installed as a part of the real-time system. A task in the system is divided by the programmer into n disjoint partitions based on its structure.
Reference: [4] <author> D.J. Kuck, R.H. Kuhn, D.A. padua, B. Lea-sure, and M. Wolfe, </author> <title> "Dependence Graphs and Compiler Iptimizations," </title> <booktitle> Proc. 8th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-218, </pages> <year> 1981. </year>
Reference-contexts: As expected the overall computation is predictable and monotonic since it contains no conditionals and the loop is monotonic. containing a conditional. Owing to the presence of the if-statement this code fragment has an unpredi-catable execution time. 2.3 Code Reordering The compiler reorders the statements <ref> [4] </ref> of a task according to the following principles. The unpredictable computations should be performed before the predictable computations for two reasons. Firstly, if these computations execute in time much less than their WETs then the time savings can be used to adapt the schedules to accommodate additional tasks.
Reference: [5] <author> K-J. Lin, S. Natarajan, and J.W.S. Liu, </author> <title> "Imprecise Results: Utilizing Partial Computations in Real-Time Systems," </title> <booktitle> Proc. 7th IEEE Real-Time Systems Symposium, </booktitle> <address> pp.210-217, </address> <year> 1987. </year>
Reference-contexts: These savings are compared to the resource sharing delays and used to make scheduling decisions. The second project that influenced us, the Quartz Project at Univ. of Illinois, uses the notion of Imprecise Computations <ref> [5, 7] </ref>. In this method results of a poorer quality are tolerated to ensure that hard real-time tasks are able to meet their deadlines.
Reference: [6] <author> K.J. Lin and S. Natarajan, </author> <title> "Expressing and Maintaining Timing Constraints in FLEX," </title> <booktitle> Proc. 9th IEEE Real-Time Systems Symposium, </booktitle> <address> pp.96-105, </address> <month> Dec. </month> <year> 1988. </year>
Reference-contexts: We hope to achieve most of the benefits of imprecision through the use of compile-time directives and compiler assistance rather than with a special-purpose programming language <ref> [6] </ref>. Thus our approach may also be used to revitalize "dusty-deck" programs.
Reference: [7] <author> J.W.S. Liu, K.J. Lin, C.L. Liu, and C.W. Gear, </author> <title> "Research on Imprecise Computations in Project Quartz," </title> <booktitle> Proc. of 1989 Workshop on Operating systems for Mission Critical Computing, </booktitle> <institution> IDA, ONR, Univ. of Maryland, </institution> <year> 1989. </year>
Reference-contexts: These savings are compared to the resource sharing delays and used to make scheduling decisions. The second project that influenced us, the Quartz Project at Univ. of Illinois, uses the notion of Imprecise Computations <ref> [5, 7] </ref>. In this method results of a poorer quality are tolerated to ensure that hard real-time tasks are able to meet their deadlines.
Reference: [8] <author> V. Sarkar, </author> <title> "Determining Average Program Execution Times and their Variance," </title> <booktitle> Proc. SIG-PLAN Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 298-312, </pages> <year> 1989. </year>
Reference-contexts: The value of identifying partitions as being either predictable or unpredictable lies in the fact that the compiler can use this information to reorder code (subject to data dependence constraints) and to select points in the program at which execution time measurements should be made. In <ref> [8] </ref>, Sarkar presents a general framework for measuring 2 for sequential programs. Execution time measurements for individual statements and execution counts for the statements are obtained through profiling. Using this information the compiler computes execution times and variances for groups of statements and eventually the entire program.
Reference: [9] <author> L. Sha and J. Goodenough, </author> <title> "Real-Time Scheduling Theory and ADA," </title> <booktitle> Computer, </booktitle> <pages> pages 53-62, </pages> <month> April </month> <year> 1990. </year> <title> A. Attribute Grammar of CALL </title>
Reference-contexts: While this solution does ensure that the specific set of processes meet their deadlines there are several obvious problems with such an approach. As pointed out by Sha and Goodenough <ref> [9] </ref> it does not scale conveniently as the system gets larger. It is an extremely painful procedure to lay out a schedule that attempts to fit processes into time slots while at the same time ensuring that critical sections do not overlap.
References-found: 9

