URL: http://www.cs.technion.ac.il/~shaulm/papers/ml89-dido.ps
Refering-URL: http://www.cs.technion.ac.il/~shaulm/research.html
Root-URL: 
Title: UNCERTAINTY BASED SELECTION OF LEARNING EXPERIENCES  FOR SELECTING EXPERIENCES  
Author: Paul D. Scott Shaul Markovitch 
Note: STRATEGIES  TABLE 1  
Address: 2001,Commonwealth Blvd.,Ann Arbor, Michigan 48105  
Affiliation: Center for Machine Intelligence  
Abstract: The training experiences needed by a learning system may be selected by either an external agent or the system itself. We show that knowledge of the current state of the learner's representation, which is not available to an external agent, is necessary for selection of informative experiences. Hence it is advantageous if a learning system can select its own experiences. We show that the uncertainty of the current representation can be used as a heuristic to guide selection of experiences, and describe results obtained with DIDO, an inductive learning system we have developed using an uncertainty based selection heuristic. It has long been recognized that the speed with which a system learns is strongly influenced by the particular selection of experiences, from the space of all possible experiences, that the system receives. For example, Winston (1975) showed that 'near misses' (training examples that lie just outside the boundaries of the concept to be learned) greatly facilitate the speed with which his program learns new concepts. Some experiences will lead to major changes in a learning system's representation of its domain, others will lead only to minor changes, while the rest will produce no change at all. Experiences that lead to representation changes are called informative experiences. The goal of experience selection is to produce as high a proportion of informative experiences as possible. On many machine learning systems, experience selection is carried out by an external agent, usually called a teacher 2 . However such an external agent does not have all the knowledge needed to select the most informative experiences. How informative a particular experience will be to a learning system depends upon both the domain about which the system is learning, and the current state of the system's representation of that domain. An external agent may have knowledge of the domain, but does not normally have direct access to the current state of the representation. The importance of the latter is demonstrated by the results shown in Table 1 which were obtained by selecting training examples for the candidate elimination algorithm (Mitchell, 1977) using three simple strategies. The Random (examples selected completely at random) and Balanced (equal numbers of positive and negative examples selected at random) strategies do not use knowledge of the current representation. In contrast, the Asking strategy selects random examples of concepts which have not yet been eliminated from the version space. Examples were classified as informative if they resulted in a reduction of the version space. The means given were the average of 50 runs with different target concepts (See Scott 1989 for further details). These results demonstrate that making use of knowledge of the current representation can drastically reduce the number of experiences needed to learn a concept by increasing the proportion of informative examples selected. 1 Some of the work reported in this paper was supported by NSF Grant # MCS-8203956. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Carbonell,J. & Gill,Y., </author> <year> 1987, </year> <title> Learning By Experimentation, </title> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <address> UC Irvine, </address> <month> June </month> <year> 1987. </year> <month> Lenat,D. </month> <year> 1982, </year> <title> AM: Discovery in Mathematics and Heuristic Search . In Davis,R. </title> & <booktitle> Lenat,D.B. , Knowledge-based Systems in Artificial Intelligence, </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York. Markovitch,S. & Scott,P.D. </address> , <year> 1989, </year> <title> "Information Filters and Their Implementation in the Syllog System", </title> <note> Proc. 6th International Workshop on Machine Learning. (Also available as CMI Tech Report CMI-89-006). </note>
Reference: <author> Mitchell,T.M., </author> <year> 1977, </year> <title> Version Spaces: A Candidate Elimination Approach to Rule Learning, </title> <booktitle> Proceedings Fifth International Joint Conference on Artificial Intelligence, </booktitle> <address> Cambridge, Mass. </address> <pages> pp 305-310. </pages>
Reference: <author> Mitchell,T.M., Utgoff,P.E. & Banerji,R., </author> <year> 1983, </year> <title> Learning by Experimentation: Acquiring and Refining Problem Solving Heuristics. In Machine Learning eds Michalski, </title> <editor> Carbonell & Mitchell, </editor> <publisher> Tioga Press (1983). </publisher>
Reference: <author> Ritchie,G.D. & Hanna,F.K., </author> <year> 1984, </year> <title> AM: A Case Study in AI Methodology, </title> <note> Artificial Intelligence 23 pp 249-268. </note>
Reference: <author> Scott,P.D., </author> <year> 1989, </year> <title> When Is Asking Better Than Being Told?, </title> <note> Center for Machine Intelligence Technical Report CMI-89-012. </note>
Reference: <author> Scott,P.D. & Markovitch,S., </author> <year> 1989, </year> <title> Learning Novel Domains Through Curiosity and Conjecture, </title> <journal> Proc. IJCAI-89, 11th International Joint Conference on Artificial Intelligence. </journal> <note> (Also available as CMI Tech Report CMI-89-010). </note>
Reference: <author> Scott,P.D. & Markovitch,S., </author> <year> 1988, </year> <title> Learning Through Curiosity and Conjecture, </title> <type> CMI Tech Report #030988. </type> <institution> Shannon ,C.E& W.Weaver, </institution> <year> 1949, </year> <title> The Mathematical Theory of Communication, </title> <publisher> University of Illinois Press. </publisher>
Reference: <author> Winston,P.H., </author> <year> 1975, </year> <title> Learning Structural Descriptions from Examples , In The Psychology of Computer Vision ed P.H.Winston, </title> <publisher> McGraw-Hill. </publisher>
References-found: 8

