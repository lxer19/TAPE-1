URL: http://www.graphics.cornell.edu/~srm/publications/CIC-invlig.ps.gz
Refering-URL: http://www.graphics.cornell.edu/~srm/publications/CIC-invlig-abstract.html
Root-URL: http://www.cs.brown.edu/
Title: Inverse Lighting for Photography  
Author: Stephen R. Marschner Donald P. Greenberg 
Address: Ithaca, New York  
Affiliation: Cornell University Program of Computer Graphics  
Date: November 1997  
Note: Presented at the IS&T/SID Fifth Color Imaging Conference,  
Abstract: We introduce a technique for improving photographs using inverse lighting, a new process based on algorithms developed in computer graphics for computing the reflection of light in 3D space. From a photograph and a 3D surface model for the object pictured, inverse lighting estimates the directional distribution of the incident light. We then use this information to process the photograph digitally to alter the lighting on the object. Inverse lighting is a specific example of the general idea of inverse rendering. This refers to the practice of using the methods of computer graphics, which normally are used to render images from scene information, to infer scene information from images. Our system uses physically based rendering technology to construct a linear least squares system that we solve to find the lighting. As an application, the results are then used to simulate a change in the incident light in the photograph. An implementation is described that uses 3D models from a laser range scanner and photographs from a high-resolution color CCD camera. We demonstrate the system on a simple test object and a human face. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. M. Airey, J. H. Rohlf, and F. P. Brooks, Jr. </author> <title> Towards image realism with interactive update rates in complex virtual building environments. </title> <booktitle> In 1990 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 4150. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> March </month> <year> 1990. </year>
Reference-contexts: Other uses of the linearity of rendering include representing the phases of sunlight using basis images [8] and work involving lighting design for opera [3] and real time building walkthroughs <ref> [1] </ref>. 2. Inverse Lighting The problem of inverse lighting can be stated as follows: given a photograph of an object, a 3D model of that object (including its reflectance), and a description of the camera, determine the incident light distribution.
Reference: [2] <author> T. Beier and S. Neely. </author> <title> Feature based image metamorphosis. </title> <booktitle> In Computer Graphics (SIGGRAPH '92 Proceedings), </booktitle> <pages> pages 3542, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: This only approximates the geometry and reflectance of the real subjects, because skin is not a diffuse reflector, and a face is not rigidthe shape changes with facial expression. To accommodate the difference in geometry, we applied an image warp to the rendered images <ref> [2] </ref>; this lets us take advantage of our 3D information while keeping the features in the model and photograph in correspondence. Also, we filtered the geometry to include only skin areas, since the scanner does not record useful data in the hair.
Reference: [3] <author> J. Dorsey, J. Arvo, and D. Greenberg. </author> <title> Interactive design of complex time dependent lighting. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 15(2):2636, </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: One application is lighting design [10, 7], in which a configuration of lights is computed from a specification of desired illumination. Other uses of the linearity of rendering include representing the phases of sunlight using basis images [8] and work involving lighting design for opera <ref> [3] </ref> and real time building walkthroughs [1]. 2. Inverse Lighting The problem of inverse lighting can be stated as follows: given a photograph of an object, a 3D model of that object (including its reflectance), and a description of the camera, determine the incident light distribution.
Reference: [4] <author> A. S. Glassner. </author> <title> Principles of Digital Image Synthesis. </title> <publisher> Mor-gan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1995. </year>
Reference-contexts: We can think of this light as being emitted by a large sphere surrounding the object. The mathematical form of the answer is a function L : S 2 ! IR. We approach inverse lighting using the same framework many have used for physically based rendering. A rendering algorithm <ref> [4] </ref> is a program for generating synthetic images from scene descriptions. Such a program takes three inputs: a description of the relevant light-reflecting surfaces, a description of the light that illuminates the surfaces, and a description of a camera. <p> The lambertian model for surface reflectance that we used for this work is too simple; real surfaces, including the examples shown here, have more complex behavior. Many models for reflectance exist <ref> [4, 6] </ref>, and our system can handle non-lambertian models without modification. We used a very simple basis for L, with piecewise constant functions distributed uniformly. Smoother functions or specialized bases that concentrate detail in areas of importance might be more successful. 6.
Reference: [5] <author> G. Golub and C. Van Loan. </author> <title> Matrix Computations (3rd ed.). </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <year> 1996. </year>
Reference-contexts: We used a linear least squares algorithm with first-order linear regularization [9], and an optimization using the generalized singular value decomposition <ref> [5] </ref> to allow the regularization parameter to be adjusted interactively. The process of inverse lighting is summarized in Figure 1. First, the renderer is given the camera, the 3D model, and each of the basis lights, and it produces a set of basis images.
Reference: [6] <author> P. Hanrahan and W. Krueger. </author> <title> Reflection from layered surfaces due to subsurface scattering. </title> <booktitle> In Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <pages> pages 165174, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: The lambertian model for surface reflectance that we used for this work is too simple; real surfaces, including the examples shown here, have more complex behavior. Many models for reflectance exist <ref> [4, 6] </ref>, and our system can handle non-lambertian models without modification. We used a very simple basis for L, with piecewise constant functions distributed uniformly. Smoother functions or specialized bases that concentrate detail in areas of importance might be more successful. 6.
Reference: [7] <author> J. K. Kawai, J. S. Painter, and M. F. Cohen. </author> <title> Radioptimizationgoal based rendering. </title> <booktitle> In Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <pages> pages 147154, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Solving for lighting in an inverse system is not new to computer graphics, although it may be new to photography. One application is lighting design <ref> [10, 7] </ref>, in which a configuration of lights is computed from a specification of desired illumination. Other uses of the linearity of rendering include representing the phases of sunlight using basis images [8] and work involving lighting design for opera [3] and real time building walkthroughs [1]. 2.
Reference: [8] <author> J. S. Nimeroff, E. Simoncelli, and J. Dorsey. </author> <title> Efficient re-rendering of naturally illuminated environments. </title> <booktitle> In Fifth Eurographics Workshop on Rendering, </booktitle> <pages> pages 359 373, </pages> <address> Darmstadt, Germany, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: One application is lighting design [10, 7], in which a configuration of lights is computed from a specification of desired illumination. Other uses of the linearity of rendering include representing the phases of sunlight using basis images <ref> [8] </ref> and work involving lighting design for opera [3] and real time building walkthroughs [1]. 2.
Reference: [9] <author> W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing (2nd ed.). </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cam-bridge, </address> <year> 1992. </year>
Reference-contexts: We used a linear least squares algorithm with first-order linear regularization <ref> [9] </ref>, and an optimization using the generalized singular value decomposition [5] to allow the regularization parameter to be adjusted interactively. The process of inverse lighting is summarized in Figure 1.
Reference: [10] <author> C. Shoeneman, J. Dorsey, B. Smits, J. Arvo, and D. Green-berg. </author> <title> Painting with light. </title> <booktitle> In Computer Graphics (SIG-GRAPH '93 Proceedings), </booktitle> <pages> pages 143146, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Solving for lighting in an inverse system is not new to computer graphics, although it may be new to photography. One application is lighting design <ref> [10, 7] </ref>, in which a configuration of lights is computed from a specification of desired illumination. Other uses of the linearity of rendering include representing the phases of sunlight using basis images [8] and work involving lighting design for opera [3] and real time building walkthroughs [1]. 2.
References-found: 10

