URL: ftp://www.cs.rutgers.edu/pub/technical-reports/dcs-tr-338.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: 
Title: Using Aspect Graphs to Control the Recovery and Tracking of Deformable Models  
Author: Sven J. Dickinson Dimitri Metaxas 
Date: December 2-3, 1995.)  
Note: Appears in International Journal of Pattern Recognition and Artificial Intelligence, Vol. 11, No. 1, February, 1997, pp 115-142. (special issue containing selected papers from the Workshop on Spatial Computing: Representation, Interpretation and Applications, Curtin  
Address: New Brunswick, NJ 08903  Philadelphia, PA 19104-6389  Australia,  
Affiliation: Department of Computer Science and Rutgers Center for Cognitive Science (RuCCS) Rutgers University  Department of Computer and Information Science University of Pennsylvania  University of Technology, Perth, Western  
Abstract: Active or deformable models have emerged as a popular modeling paradigm in computer vision. These models have the flexibility to adapt themselves to the image data, offering the potential for both generic object recognition and non-rigid object tracking. Because these active models are underconstrained, however, deformable shape recovery often requires manual segmentation or good model initialization, while active contour trackers have been able to track only an object's translation in the image. In this paper, we report our current progress in using a part-based aspect graph representation of an object [14] to provide the missing constraints on data-driven deformable model recovery and tracking processes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barr. </author> <title> Superquadrics and angle-preserving transformations. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 1 </volume> <pages> 11-23, </pages> <year> 1981. </year>
Reference-contexts: though our technique for defining T is independent of the primitive e = (e 1 ; e 2 ; e 3 ) &gt; to which it is applied, we will use superquadric ellipsoid primitives due to their suitability in vision applications. 12 We first consider the case of superquadric ellipsoids <ref> [1] </ref>, which are given by the following formula: e = a B B B a 1 C u * 2 * 1 S v a 3 S u 1 C C A where =2 u =2 and v &lt; , and where S w * = sgn (sin w)j sin wj
Reference: [2] <author> T. J. Broida, S. Chandrashekhar, and R. Chellappa. </author> <title> Recursive 3-D motion estimation from a monocular image sequence. </title> <journal> IEEE Transactions on Aerospace and Electronic Systems, </journal> <volume> 26(4) </volume> <pages> 639-656, </pages> <year> 1990. </year>
Reference-contexts: from stereo images are sufficient to update the positions, orientations, and shapes of the models in 3-D; no costly feature extraction or correspondence is necessary. 6.1 Tracking and Prediction Kalman filtering techniques have been applied in the vision literature for the estimation of dynamic features [7] and rigid motion parameters <ref> [17, 2] </ref> of objects from image sequences. We use a Kalman filter to estimate the object's shape and motion in a sequence of images.
Reference: [3] <author> M. Chan, D. Metaxas, and S. Dickinson. </author> <title> A new approach to tracking 3-D objects in 2-D image sequences. </title> <booktitle> In Proceedings, AAAI '94, </booktitle> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The added contours are automatically "pulled apart" to ensure that they do not converge to the same image edge; final position of the new edge is shown in frame 90. 27 6 Quantitative Shape Tracking Our approach to quantitative tracking <ref> [3, 4] </ref> makes use of our frameworks for qualitative and quantitative shape recovery described in previous sections, as well as a physics-based framework for quantitative motion estimation [22].
Reference: [4] <author> M. Chan, D. Metaxas, and S. Dickinson. </author> <title> Physics-based tracking of 3-D objects in 2-D image sequences. </title> <booktitle> In Proceedings, 12 International Conference on Pattern Recognition, </booktitle> <pages> pages 326-330, </pages> <address> Jerusalem, Israel, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: The added contours are automatically "pulled apart" to ensure that they do not converge to the same image edge; final position of the new edge is shown in frame 90. 27 6 Quantitative Shape Tracking Our approach to quantitative tracking <ref> [3, 4] </ref> makes use of our frameworks for qualitative and quantitative shape recovery described in previous sections, as well as a physics-based framework for quantitative motion estimation [22].
Reference: [5] <author> R. Cipolla and A. Blake. </author> <title> Motion planning using image divergence and deformation. </title> <editor> In A. Blake and A. Yuille, editors, </editor> <booktitle> Active Vision, </booktitle> <pages> pages 189-201. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: These data-driven approaches to shape tracking track the silhouette of a blob in 2-D (or surface of a blob in 3-D), e.g., [18, 6, 24]. Although 2-D translation can be recovered and, in some cases, translation in depth (e.g., <ref> [5] </ref>), lack of any model information prevents the recovery of rotation in depth and the detection of occlusion. 2 3 4 In this paper, we show how an object representation integrating object-centered volumet-ric part models and viewer-centered part aspects, introduced in [14], can be used to provide strong constraints on the
Reference: [6] <author> R. Curven, A. Blake, and R. Cipolla. </author> <title> Parallel implementation of lagrangian dynamics for real-time snakes. </title> <booktitle> In Proceedings, British Machine Vision Conference (BMVC '91), </booktitle> <pages> pages 27-35, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: These data-driven approaches to shape tracking track the silhouette of a blob in 2-D (or surface of a blob in 3-D), e.g., <ref> [18, 6, 24] </ref>.
Reference: [7] <author> R. Deriche and O. Faugeras. </author> <title> Tracking line segments. </title> <journal> Image and Vision Computing, </journal> <volume> 8(4) </volume> <pages> 261-270, </pages> <year> 1990. </year>
Reference-contexts: between frames, local forces derived from stereo images are sufficient to update the positions, orientations, and shapes of the models in 3-D; no costly feature extraction or correspondence is necessary. 6.1 Tracking and Prediction Kalman filtering techniques have been applied in the vision literature for the estimation of dynamic features <ref> [7] </ref> and rigid motion parameters [17, 2] of objects from image sequences. We use a Kalman filter to estimate the object's shape and motion in a sequence of images.
Reference: [8] <author> S. Dickinson. </author> <title> The recovery and recognition of three-dimensional objects using part-based aspect matching. </title> <type> Technical Report CAR-TR-572, </type> <institution> Center for Automation Research, University of Maryland, </institution> <year> 1991. </year>
Reference-contexts: The ambiguous mappings between the levels of the aspect hierarchy are captured in a set of upward and downward conditional probabilities, mapping boundary groups to faces, faces to aspects, and aspects to volumes <ref> [8] </ref>. The probabilities are estimated from a frequency analysis of features viewed over a sampled viewing sphere centered on each of the volumetric classes. The representation for aspects has a tremendous impact on the coverage of the 3-D part classes.
Reference: [9] <author> S. Dickinson. </author> <title> Part-based modeling and qualitative recognition. </title> <editor> In A. Jain and P. Flynn, editors, </editor> <title> Three-Dimensional Object Recognition Systems, Advances in Image Communication and Machine Vision Series. </title> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1993. </year> <month> 36 </month>
Reference-contexts: This representation, combining both object-centered and viewer-centered models, forms the backbone of our qualitative shape recovery and object recognition (both top-down and bottom-up) paradigms, reported in <ref> [16, 15, 9, 10] </ref>. In the following sections, we will see how this same representation can be used to constrain the recovery and tracking of deformable models from both 2-D and 3-D image data. <p> Details of these strategies will not be presented here, and can be found in <ref> [16, 15, 9, 10] </ref>. 7 3 Shape Recovery from a 2-D Image In [16, 15, 9, 10], we outlined techniques for recovering and recognizing 3-D objects from a single 2-D image. <p> Details of these strategies will not be presented here, and can be found in <ref> [16, 15, 9, 10] </ref>. 7 3 Shape Recovery from a 2-D Image In [16, 15, 9, 10], we outlined techniques for recovering and recognizing 3-D objects from a single 2-D image. Although the technique segments the scene into a set of qualitatively-defined parts, no metric information is recovered for the parts nor is the 3-D position and orientation of the parts recovered. <p> Using our qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part <ref> [16, 15, 9, 10] </ref>. In addition, the extracted qualitative volumes explicitly define a mapping between the image faces in their projected aspects and the 3-D surfaces on the quantitative models. Moreover, the extracted volumes can be used to immediately constrain many of the global deformation parameters.
Reference: [10] <author> S. Dickinson, H. Christensen, J. Tsotsos, and G. Olofsson. </author> <title> Active object recognition integrating attention and viewpoint control. </title> <booktitle> In Proceedings, </booktitle> <address> ECCV '94, Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: This representation, combining both object-centered and viewer-centered models, forms the backbone of our qualitative shape recovery and object recognition (both top-down and bottom-up) paradigms, reported in <ref> [16, 15, 9, 10] </ref>. In the following sections, we will see how this same representation can be used to constrain the recovery and tracking of deformable models from both 2-D and 3-D image data. <p> Details of these strategies will not be presented here, and can be found in <ref> [16, 15, 9, 10] </ref>. 7 3 Shape Recovery from a 2-D Image In [16, 15, 9, 10], we outlined techniques for recovering and recognizing 3-D objects from a single 2-D image. <p> Details of these strategies will not be presented here, and can be found in <ref> [16, 15, 9, 10] </ref>. 7 3 Shape Recovery from a 2-D Image In [16, 15, 9, 10], we outlined techniques for recovering and recognizing 3-D objects from a single 2-D image. Although the technique segments the scene into a set of qualitatively-defined parts, no metric information is recovered for the parts nor is the 3-D position and orientation of the parts recovered. <p> Using our qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part <ref> [16, 15, 9, 10] </ref>. In addition, the extracted qualitative volumes explicitly define a mapping between the image faces in their projected aspects and the 3-D surfaces on the quantitative models. Moreover, the extracted volumes can be used to immediately constrain many of the global deformation parameters. <p> However, by only allowing high-scoring volumes to constrain the fitting process, the chances of letting any region segmentation problems affect the fitting process is low. In fact, low-scoring volumes can be used to guide the sensor to acquire a higher-scoring volume <ref> [10] </ref>. 5 Qualitative Shape Tracking There are two ways in which an object can be tracked. <p> When such an event is detected, a signal describing the event is sent to the symbolic tracker. 5.2 Symbolic Tracker The symbolic tracker tracks movement from one node to another in a representation called the aspect prediction graph <ref> [10] </ref>. Each of the nodes in this representation, derived from an aspect graph [19] and the aspect hierarchy, represents a topologically different viewpoint of the object, while arcs between nodes specify the visual events or changes in image topology between nodes. The role of the symbolic tracker is to: 1. <p> Our goal has been to explore a number of closely-related object recognition behaviors that must be addressed by an active agent in a dynamic environment. Our object representation has so far provided a common framework for novel algorithms for these and other behaviors (e.g., active object recognition <ref> [10] </ref>).
Reference: [11] <author> S. Dickinson, P. Jasiobedzki, H. Christensen, and G. Olofsson. </author> <title> Qualitative tracking of 3-D objects using active contour networks. </title> <booktitle> In Proceedings, IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: In this section, we describe our approach to qualitative shape tracking, while in the next section, we address the problem of quantitative shape tracking. Our approach to qualitative object tracking, as shown in Figure 13, combines a symbolic tracker and an image tracker <ref> [11] </ref>.
Reference: [12] <author> S. Dickinson and D. Metaxas. </author> <title> Integrating qualitative and quantitative shape recovery. </title> <journal> International Journal of Computer Vision, </journal> <volume> 13(3) </volume> <pages> 1-20, </pages> <year> 1994. </year>
Reference-contexts: Details of the algorithm can be found in <ref> [21, 12] </ref>. 8 9 10 11 3.1 The Geometry of the Deformable Model Geometrically, the quantitative shape models that we recover are closed surfaces in space whose intrinsic (material) coordinates are u = (u; v), defined on a domain [25, 12]. <p> Details of the algorithm can be found in [21, 12]. 8 9 10 11 3.1 The Geometry of the Deformable Model Geometrically, the quantitative shape models that we recover are closed surfaces in space whose intrinsic (material) coordinates are u = (u; v), defined on a domain <ref> [25, 12] </ref>.
Reference: [13] <author> S. Dickinson, D. Metaxas, and A. Pentland. </author> <title> Constrained recovery of deformable models from range data. </title> <booktitle> In Proceedings, 2nd International Workshop on Visual Form, </booktitle> <address> Capri, Italy, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Furthermore, by adding face attributes such as mean and Gaussian curvature, we can effectively prune many of the mappings from boundary groups to faces, faces to aspects, and aspects to volumes. We call the new aspect hierarchy, the range aspect hierarchy <ref> [13] </ref>. 19 (a) (b) We demonstrate our approach by recovering the two parts in the range image shown in invoked the expected object recognition mode to first search for the best instance of a block. to infer the block are highlighted in the image.
Reference: [14] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> A representation for qualitative 3-D object recognition integrating object-centered and viewer-centered models. </title> <editor> In K. Leibovic, editor, </editor> <title> Vision: A Convergence of Disciplines. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: recovered and, in some cases, translation in depth (e.g., [5]), lack of any model information prevents the recovery of rotation in depth and the detection of occlusion. 2 3 4 In this paper, we show how an object representation integrating object-centered volumet-ric part models and viewer-centered part aspects, introduced in <ref> [14] </ref>, can be used to provide strong constraints on the recovery and tracking of 3-D shape using deformable models. <p> application to both shape recovery and tracking can overcome the limitations of the deformable model shape recovery and tracking approaches described above. 2 A Parts-Based Aspect Representation In this section, we briefly review a representation which models an object's 3-D shape in terms of a set of qualitatively-defined volumetric parts <ref> [14] </ref>. This representation, combining both object-centered and viewer-centered models, forms the backbone of our qualitative shape recovery and object recognition (both top-down and bottom-up) paradigms, reported in [16, 15, 9, 10]. <p> dimensions down to two, but incur the cost of having to store many different views for each object. 5 In order to meet the goals of qualitative object modeling and matching, we first model objects as object-centered constructions of volumetric parts chosen from some arbitrary, finite set of part classes <ref> [14] </ref>. It is at the volumetric part modeling level, that we invoke the concept of viewer-centered modeling.
Reference: [15] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> From volumes to views: An approach to 3-D object recognition. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 55(2) </volume> <pages> 130-154, </pages> <year> 1992. </year>
Reference-contexts: This representation, combining both object-centered and viewer-centered models, forms the backbone of our qualitative shape recovery and object recognition (both top-down and bottom-up) paradigms, reported in <ref> [16, 15, 9, 10] </ref>. In the following sections, we will see how this same representation can be used to constrain the recovery and tracking of deformable models from both 2-D and 3-D image data. <p> Details of these strategies will not be presented here, and can be found in <ref> [16, 15, 9, 10] </ref>. 7 3 Shape Recovery from a 2-D Image In [16, 15, 9, 10], we outlined techniques for recovering and recognizing 3-D objects from a single 2-D image. <p> Details of these strategies will not be presented here, and can be found in <ref> [16, 15, 9, 10] </ref>. 7 3 Shape Recovery from a 2-D Image In [16, 15, 9, 10], we outlined techniques for recovering and recognizing 3-D objects from a single 2-D image. Although the technique segments the scene into a set of qualitatively-defined parts, no metric information is recovered for the parts nor is the 3-D position and orientation of the parts recovered. <p> Using our qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part <ref> [16, 15, 9, 10] </ref>. In addition, the extracted qualitative volumes explicitly define a mapping between the image faces in their projected aspects and the 3-D surfaces on the quantitative models. Moreover, the extracted volumes can be used to immediately constrain many of the global deformation parameters.
Reference: [16] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> 3-D shape recovery using distributed aspect matching. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(2) </volume> <pages> 174-198, </pages> <year> 1992. </year>
Reference-contexts: This representation, combining both object-centered and viewer-centered models, forms the backbone of our qualitative shape recovery and object recognition (both top-down and bottom-up) paradigms, reported in <ref> [16, 15, 9, 10] </ref>. In the following sections, we will see how this same representation can be used to constrain the recovery and tracking of deformable models from both 2-D and 3-D image data. <p> Details of these strategies will not be presented here, and can be found in <ref> [16, 15, 9, 10] </ref>. 7 3 Shape Recovery from a 2-D Image In [16, 15, 9, 10], we outlined techniques for recovering and recognizing 3-D objects from a single 2-D image. <p> Details of these strategies will not be presented here, and can be found in <ref> [16, 15, 9, 10] </ref>. 7 3 Shape Recovery from a 2-D Image In [16, 15, 9, 10], we outlined techniques for recovering and recognizing 3-D objects from a single 2-D image. Although the technique segments the scene into a set of qualitatively-defined parts, no metric information is recovered for the parts nor is the 3-D position and orientation of the parts recovered. <p> Using our qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part <ref> [16, 15, 9, 10] </ref>. In addition, the extracted qualitative volumes explicitly define a mapping between the image faces in their projected aspects and the 3-D surfaces on the quantitative models. Moreover, the extracted volumes can be used to immediately constrain many of the global deformation parameters.
Reference: [17] <author> E. D. Dickmanns and Volker Graefe. </author> <title> Applications of dynamic monocular machine vision. </title> <journal> Machine Vision and Applications, </journal> <volume> 1 </volume> <pages> 241-261, </pages> <year> 1988. </year>
Reference-contexts: from stereo images are sufficient to update the positions, orientations, and shapes of the models in 3-D; no costly feature extraction or correspondence is necessary. 6.1 Tracking and Prediction Kalman filtering techniques have been applied in the vision literature for the estimation of dynamic features [7] and rigid motion parameters <ref> [17, 2] </ref> of objects from image sequences. We use a Kalman filter to estimate the object's shape and motion in a sequence of images.
Reference: [18] <author> M. Kass, A. Witkin, and D. Terzopolous. Snakes: </author> <title> Active contour models. </title> <journal> Internation Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 321-331, </pages> <year> 1988. </year>
Reference-contexts: The approaches to shape recovery are exemplified by the class of deformable or active model recovery techniques, in which a model contour (in 2-D) or surface (in 3-D) adapts itself to the image data under the influence of "forces" exerted by the image data <ref> [18, 26, 27, 25] </ref>. As shown in Figure 1, points on the model are "pulled" towards corresponding (e.g., closest) data points in the image, with the integrity of the model often maintained by giving the model physical properties such as mass, stiffness, and damping. <p> These data-driven approaches to shape tracking track the silhouette of a blob in 2-D (or surface of a blob in 3-D), e.g., <ref> [18, 6, 24] </ref>. <p> The AAG is initially created from the contours belonging to a recovered aspect, and consists of a network of active contours (snakes) <ref> [18] </ref>.
Reference: [19] <author> J. Koenderink and A. van Doorn. </author> <title> The internal representation of solid shape with respect to vision. </title> <journal> Biological Cybernetics, </journal> <volume> 32 </volume> <pages> 211-216, </pages> <year> 1979. </year> <month> 37 </month>
Reference-contexts: It is at the volumetric part modeling level, that we invoke the concept of viewer-centered modeling. Traditional aspect graph representations of 3-D objects model an entire object with a set of aspects (or views), each defining a topologically distinct view of an object in terms of its visible surfaces <ref> [19] </ref>. Our approach differs in that we use aspects to represent a (typically small) set of volumetric parts from which objects appearing in our image database are constructed, rather than representing the entire object directly. <p> Each of the nodes in this representation, derived from an aspect graph <ref> [19] </ref> and the aspect hierarchy, represents a topologically different viewpoint of the object, while arcs between nodes specify the visual events or changes in image topology between nodes. The role of the symbolic tracker is to: 1.
Reference: [20] <author> D. Metaxas. </author> <title> Physics-based modeling of nonrigid objects for vision and graphics. </title> <type> Ph.D. thesis, </type> <institution> Dept. of Computer Science, Univ. of Toronto, </institution> <year> 1992. </year>
Reference-contexts: We set up a noninertial, model-centered reference frame <ref> [20] </ref>, and express these positions as: x = c + Rp; (2) where c (t) is the origin of at the center of the model, and the orientation of is given by the rotation matrix R (t). <p> deformations d are necessary to capture object shape details, we use the finite element theory and express the local deformations as d = Sq d ; (9) where S is the shape matrix whose entries are the finite element shape functions, and q d are the model's nodal local displacements <ref> [20] </ref>. 3.2 Simplified Numerical Simulation When fitting the quantitative model to visual data, our goal is to recover q = (q &gt; c ; q &gt; s ; q &gt; the vector of degrees of freedom of the model.
Reference: [21] <author> D. Metaxas and S. Dickinson. </author> <title> Integration of quantitative and qualitative techniques for deformable model fitting from orthographic, perspective, and stereo projections. </title> <booktitle> In Proceedings, Fourth International Conference on Computer Vision, </booktitle> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Details of the algorithm can be found in <ref> [21, 12] </ref>. 8 9 10 11 3.1 The Geometry of the Deformable Model Geometrically, the quantitative shape models that we recover are closed surfaces in space whose intrinsic (material) coordinates are u = (u; v), defined on a domain [25, 12].
Reference: [22] <author> D. Metaxas and D. Terzopoulos. </author> <title> Shape and nonrigid motion estimation through physics-based synthesis. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <month> June </month> <year> 1993. </year>
Reference-contexts: image edge; final position of the new edge is shown in frame 90. 27 6 Quantitative Shape Tracking Our approach to quantitative tracking [3, 4] makes use of our frameworks for qualitative and quantitative shape recovery described in previous sections, as well as a physics-based framework for quantitative motion estimation <ref> [22] </ref>. To be able to track multiple objects, initialization of the models is performed in the first frame of the sequence based on our quantitative shape recovery process. <p> u + g + PH &gt; V 1 (z h ( ^ u)); (12) where u = ( _ q &gt; ; q &gt; ) &gt; and matrices F; H; g; P; V are associated with the model dynamics, the error in the given data, and the measurement noise statistics <ref> [22] </ref>. Since we are measuring local short range forces directly from the image potential, the term z h ( ^ u) represents the 2-D image forces.
Reference: [23] <author> A. Pentland and S. Sclaroff. </author> <title> Closed-form solutions for physically based shape modeling and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 715-729, </pages> <year> 1991. </year>
Reference-contexts: In addition, such techniques often require a manual segmentation of an object into parts to which models are fitted, e.g., [26]. If the models are not properly initialized, a canonical fit may not be possible, e.g., <ref> [23] </ref>. These limitations are a consequence of using such unconstrained models. Data-driven, deformable models have also been applied to the problem of tracking both 2-D and 3-D shapes. <p> the faces exert external global deformation forces on the model. 2 In Section 6, we will see how Equation (10) is also used in object tracking. 15 3.4 Model Initialization One of the major limitations of previous deformable model fitting approaches is their dependence on model initialization and prior segmentation <ref> [27, 25, 23] </ref>. Using our qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part [16, 15, 9, 10].
Reference: [24] <author> D. Terzopolous and R. Szeliski. </author> <title> Tracking with kalman snakes. </title> <editor> In A. Blake and A. Yuille, editors, </editor> <booktitle> Active Vision, </booktitle> <pages> pages 3-21. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: These data-driven approaches to shape tracking track the silhouette of a blob in 2-D (or surface of a blob in 3-D), e.g., <ref> [18, 6, 24] </ref>.
Reference: [25] <author> D. Terzopoulos and D. Metaxas. </author> <title> Dynamic 3D models with local and global deformations: Deformable superquadrics. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 703-714, </pages> <year> 1991. </year>
Reference-contexts: The approaches to shape recovery are exemplified by the class of deformable or active model recovery techniques, in which a model contour (in 2-D) or surface (in 3-D) adapts itself to the image data under the influence of "forces" exerted by the image data <ref> [18, 26, 27, 25] </ref>. As shown in Figure 1, points on the model are "pulled" towards corresponding (e.g., closest) data points in the image, with the integrity of the model often maintained by giving the model physical properties such as mass, stiffness, and damping. <p> For example, such techniques often assume that the bounding contour of a region belongs to the object, a problem when the object is occluded. Furthermore, focusing only on an object's silhouette assumes 3-D models with rotational symmetry, i.e., no surface discontinuities, e.g., <ref> [25] </ref>. In addition, such techniques often require a manual segmentation of an object into parts to which models are fitted, e.g., [26]. If the models are not properly initialized, a canonical fit may not be possible, e.g., [23]. These limitations are a consequence of using such unconstrained models. <p> Details of the algorithm can be found in [21, 12]. 8 9 10 11 3.1 The Geometry of the Deformable Model Geometrically, the quantitative shape models that we recover are closed surfaces in space whose intrinsic (material) coordinates are u = (u; v), defined on a domain <ref> [25, 12] </ref>. <p> This allows us, through the apparatus of Lagrangian dynamics, to arrive at a set of equations of motion governing the behavior of our model under the action of externally applied forces. The Lagrange equations of motion take the form <ref> [25] </ref>: M q + D _ q + Kq = g q + f q ; (10) where M, D, and K are the mass, damping, and stiffness matrices, respectively, where g q are inertial (centrifugal and Coriolis) forces arising from the dynamic coupling between the local and global degrees of <p> We convert the external forces to generalized forces f q which act on the generalized coordinates of the model <ref> [25] </ref>. We apply forces to the model based on differences between the model's projected points and points on the recovered aspect's contours. <p> the faces exert external global deformation forces on the model. 2 In Section 6, we will see how Equation (10) is also used in object tracking. 15 3.4 Model Initialization One of the major limitations of previous deformable model fitting approaches is their dependence on model initialization and prior segmentation <ref> [27, 25, 23] </ref>. Using our qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part [16, 15, 9, 10].
Reference: [26] <author> D. Terzopoulos, A. Witkin, and M. Kass. </author> <title> Symmetry-seeking models and 3d object recovery. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1 </volume> <pages> 211-221, </pages> <year> 1987. </year>
Reference-contexts: The approaches to shape recovery are exemplified by the class of deformable or active model recovery techniques, in which a model contour (in 2-D) or surface (in 3-D) adapts itself to the image data under the influence of "forces" exerted by the image data <ref> [18, 26, 27, 25] </ref>. As shown in Figure 1, points on the model are "pulled" towards corresponding (e.g., closest) data points in the image, with the integrity of the model often maintained by giving the model physical properties such as mass, stiffness, and damping. <p> Furthermore, focusing only on an object's silhouette assumes 3-D models with rotational symmetry, i.e., no surface discontinuities, e.g., [25]. In addition, such techniques often require a manual segmentation of an object into parts to which models are fitted, e.g., <ref> [26] </ref>. If the models are not properly initialized, a canonical fit may not be possible, e.g., [23]. These limitations are a consequence of using such unconstrained models. Data-driven, deformable models have also been applied to the problem of tracking both 2-D and 3-D shapes.
Reference: [27] <author> D. Terzopoulos, A. Witkin, and M. Kass. </author> <title> Constraints on deformable models: Recovering 3d shape and nonrigid motion. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 91-123, </pages> <year> 1988. </year> <month> 38 </month>
Reference-contexts: The approaches to shape recovery are exemplified by the class of deformable or active model recovery techniques, in which a model contour (in 2-D) or surface (in 3-D) adapts itself to the image data under the influence of "forces" exerted by the image data <ref> [18, 26, 27, 25] </ref>. As shown in Figure 1, points on the model are "pulled" towards corresponding (e.g., closest) data points in the image, with the integrity of the model often maintained by giving the model physical properties such as mass, stiffness, and damping. <p> the faces exert external global deformation forces on the model. 2 In Section 6, we will see how Equation (10) is also used in object tracking. 15 3.4 Model Initialization One of the major limitations of previous deformable model fitting approaches is their dependence on model initialization and prior segmentation <ref> [27, 25, 23] </ref>. Using our qualitative shape recovery process as a front end, we first segment the data into parts, and for each part, we identify the relevant non-occluded data belonging to the part [16, 15, 9, 10]. <p> A modal node is made active if: 1) it lies on the occluding contour of the model from that viewpoint <ref> [27] </ref>, or 2) the local surface curvature at the node is sufficiently large and the node is visible. Visibility of the nodes can be determined in two ways.
References-found: 27

