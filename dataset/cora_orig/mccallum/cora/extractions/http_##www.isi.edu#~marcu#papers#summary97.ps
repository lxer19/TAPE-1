URL: http://www.isi.edu/~marcu/papers/summary97.ps
Refering-URL: http://www.isi.edu/~marcu/papers.html
Root-URL: http://www.isi.edu
Email: marcu@cs.toronto.edu  
Title: From discourse structures to text summaries  
Author: Daniel Marcu 
Address: Toronto, Ontario Canada M5S 3G4  
Affiliation: Department of Computer Science University of Toronto  
Abstract: We describe experiments that show that the concepts of rhetorical analysis and nu-clearity can be used effectively for determining the most important units in a text. We show how these concepts can be implemented and we discuss results that we obtained with a discourse-based summa rization program.
Abstract-found: 1
Intro-found: 1
Reference: <author> Barzilay, Regina and Michael Elhadad. </author> <year> 1997. </year> <title> Using Lexical Chains for Text Summarization. </title> <booktitle> In Proceedings of the ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarization. </booktitle>
Reference: <author> Baxendale, P.B. </author> <year> 1958. </year> <title> Machine-made index for technical literature an experiment. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 2 </volume> <pages> 354-361. </pages>
Reference: <author> Chou Hare, Victoria and Kathleen M. Borchardt. </author> <year> 1984. </year> <title> Direct instruction of summarization skills. </title> <journal> Reading Research Quarterly, </journal> <volume> 20(1) </volume> <pages> 62-78, </pages> <month> Fall. </month>
Reference: <author> Cochran, W.G. </author> <year> 1950. </year> <title> The comparison of percentages in matched samples. </title> <journal> Biometrika, </journal> <volume> 37 </volume> <pages> 256-266. </pages>
Reference-contexts: To compute a reliability figure, we followed the same methodology as Passonneau and Litman (1993) and Hearst (1994) and applied the Cochran's Q summary statistics to our data <ref> (Cochran, 1950) </ref>. Cochran's test assumes that a set of judges make binary decisions with respect to a dataset. The null hypothesis is that the number of judges that take the same decision is randomly distributed.
Reference: <author> Edmundson, </author> <title> H.P. 1968. New methods in automatic extracting. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 16(2) </volume> <pages> 264-285, </pages> <month> April. </month>
Reference-contexts: Determining the salient parts is considered to be achievable because one or more of the following assumptions hold: (i) important sentences in a text contain words that are used frequently (Luhn, 1958; Edmundson, 1968); (ii) important sentences contain words that are used in the title and section headings <ref> (Edmundson, 1968) </ref>; (iii) important sentences are located at the beginning or end of paragraphs (Baxen-dale, 1958); (iv) important sentences are located at posi tions in a text that are genre dependent these positions can be determined automatically, through training techniques (Lin and Hovy, 1997); (v) important sentences use bonus words such
Reference: <author> Gale, William, Kenneth W. Church, and David Yarowsky. </author> <year> 1992. </year> <title> Estimating upper and lower bounds on the performance of word-sense disambiguation programs. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL-92), </booktitle> <pages> pages 249-256. </pages>
Reference: <author> Garner, Ruth. </author> <year> 1982. </year> <title> Efficient text summarization: costs and benefits. </title> <journal> Journal of Educational Research, </journal> <volume> 75 </volume> <pages> 275-279. </pages>
Reference: <author> Hearst, Marti. </author> <year> 1994. </year> <title> Multi-paragraph segmentation of expository text. </title> <booktitle> In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 9-16, </pages> <address> Las Cruces, New Mexico, </address> <month> June 27-30. </month>
Reference: <author> Johnson, Ronald E. </author> <year> 1970. </year> <title> Recall of prose as a function of structural importance of linguistic units. </title> <journal> Journal of Verbal Learning and Verbal Behaviour, </journal> <volume> 9 </volume> <pages> 12-20. </pages>
Reference: <author> Krippendorff, Klaus. </author> <year> 1980. </year> <title> Content analysis: An Introduction to its Methodology. </title> <publisher> Sage Publications, </publisher> <address> Bev-erly Hills, CA. </address>
Reference: <author> Lin, Chin-Yew. </author> <year> 1995. </year> <title> Knowledge-based automatic topic identification. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL-95), </booktitle> <pages> pages 308-310, </pages> <address> Cambridge, Mas-sachusetts, </address> <month> June 26-30. </month>
Reference: <author> Lin, Chin-Yew and Eduard Hovy. </author> <year> 1997. </year> <title> Identifying topics by position. </title> <booktitle> In Proceedings of the Fifth Conference on Applied Natural Language Processing (ANLP-97), </booktitle> <pages> pages 283-290, </pages> <address> Washington, DC, </address> <month> March 31 - April 3. </month>
Reference-contexts: words that are used in the title and section headings (Edmundson, 1968); (iii) important sentences are located at the beginning or end of paragraphs (Baxen-dale, 1958); (iv) important sentences are located at posi tions in a text that are genre dependent these positions can be determined automatically, through training techniques <ref> (Lin and Hovy, 1997) </ref>; (v) important sentences use bonus words such as greatest and significant or indicator phrases such as the main aim of this paper and the purpose of this article, while non-important sentences use stigma words such as hardly and impossible (Edmundson, 1968; Rush, Salvador, and Zamora, 1971); (vi)
Reference: <author> Luhn, </author> <title> H.P. 1958. The automatic creation of literature abstracts. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 2(2) </volume> <pages> 159-165, </pages> <month> April. </month>
Reference: <author> Mann, William C. and Sandra A. Thompson. </author> <year> 1988. </year> <title> Rhetorical structure theory: Toward a functional theory of text organization. </title> <booktitle> Text, </booktitle> <volume> 8(3) </volume> <pages> 243-281. </pages>
Reference-contexts: discuss results that we obtained with a discourse-based summarization program. 2 From discourse trees to summaries an empirical view 2.1 Introduction Researchers in computational linguistics (Mann and Thompson, 1988; Matthiessen and Thompson, 1988; Sparck Jones, 1993) have long speculated that the nuclei that pertain to a rhetorical structure tree (RS-tree) <ref> (Mann and Thompson, 1988) </ref> constitute an adequate summariza Unit Judges Analysts Program 1 2 3 4 5 6 7 8 9 10 11 12 13 1 2 2 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 2 4 2 1 2 2 2 2
Reference: <author> Marcu, Daniel. </author> <year> 1996. </year> <title> Building up rhetorical structure trees. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), </booktitle> <volume> volume 2, </volume> <pages> pages 1069-1074, </pages> <address> Portland, Oregon, </address> <month> August 4-8,. </month>
Reference-contexts: Currently, the rank assignment for each textual unit in an RS-tree is done entirely on the basis of the maximal depth in the tree where that unit is salient <ref> (Marcu, 1996) </ref>. Our data seem to support the fact that there exists a correlation also between the types of relations that are used to connect various textual units and the importance of those units in a text.
Reference: <author> Marcu, Daniel. </author> <year> 1997a. </year> <title> The rhetorical parsing of natural language texts. </title> <booktitle> In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL/EACL-97), </booktitle> <address> Madrid, Spain, </address> <month> July 7-10. </month>
Reference: <author> Marcu, Daniel. </author> <year> 1997b. </year> <title> The rhetorical parsing, summarization, and generation of natural language texts. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, University of Toronto, Forthcoming. </institution>
Reference-contexts: The mathematical foundations of the rhetorical parsing algorithm rely on a first-order formalization of valid text structures <ref> (Marcu, 1997b) </ref>. The assumptions of the formalization are the following. 1. The elementary units of complex text structures are non-overlapping spans of text. 2. Rhetorical, coherence, and cohesive relations hold between textual units of various sizes. 3. Relations can be partitioned into two classes: paratactic and hypotac-tic. <p> The rhetorical parsing algorithm, which is outlined in figure 1, is based on a comprehensive corpus analysis of more than 450 discourse markers and 7900 text fragments (see <ref> (Marcu, 1997b) </ref> for details). When given a text, the rhetorical parser determines first the discourse markers and the elementary units that make up that text. The parser uses then the information derived from the corpus analysis in order to hypothesize rhetorical relations among the elementary units. <p> For example, the program treats units 13, 14, and 15 as one elementary unit. However, as we argue in <ref> (Marcu, 1997b) </ref>, the corpus analysis on which our parser is built supports the observation that, in most cases, the global structure of the RS-tree is not affected by the inability of the rhetorical parser to uncover all clauses in a text most of the clauses that are not uncovered are nuclei <p> Due to the differences between English and Japanese, it was impossible for us to compare Ono's summarizer with ours. Fundamental differences concerning the assumptions that underlie Ono's work and ours are discussed at length in <ref> (Marcu, 1997b) </ref>. Unit type Recall Precision Clauses Random 25.7 25.7 Microsoft 28 26 Summarizer Our summarizer 53 50 Analysts 56 66 Sentences Random 38.4 38.4 Microsoft 41 39 Summarizer Our summarizer 66 68 Analysts 67.5 78.5 Table 3: An evaluation of our summarization program.
Reference: <author> Matthiessen, Christian and Sandra A. Thompson. </author> <year> 1988. </year> <title> The structure of discourse and `subordination'. </title> <editor> In J. Haiman and S.A. Thompson, editors, </editor> <title> Clause combining in grammar and discourse, </title> <booktitle> volume 18 of Typological Studies in Language. </booktitle> <publisher> John Benjamins Publishing Company, </publisher> <pages> pages 275-329. </pages>
Reference: <author> Ono, Kenji, Kazuo Sumita, and Seiji Miike. </author> <year> 1994. </year> <title> Abstract generation based on rhetorical structure extraction. </title> <booktitle> In Proceedings of the International Conference on Computational Linguistics (Coling-94), </booktitle> <pages> pages 344-348, </pages> <address> Japan. </address>
Reference: <author> Paice, Chris D. </author> <year> 1990. </year> <title> Constructing literature abstracts by computer: techniques and prospects. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 26(1) </volume> <pages> 171-186. </pages>
Reference: <author> Passonneau, Rebecca J. and Diane J. Litman. </author> <year> 1993. </year> <title> Intention-based segmentation: human reliability and correlation with linguistic cues. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 148-155, </pages> <address> Ohio, </address> <month> June 22-26. </month>
Reference: <author> Rush, J.E., R. Salvador, and A. Zamora. </author> <year> 1971. </year> <title> Automatic abstracting and indexing. Production of indicative abstracts by application of contextual inference and syntactic coherence criteria. </title> <journal> Journal of American Society for Information Sciences, </journal> <volume> 22(4) </volume> <pages> 260-274. </pages>
Reference: <author> Sherrard, Carol. </author> <year> 1989. </year> <title> Teaching students to summarize: Applying textlinguistics. System, </title> <type> 17(1). </type>
Reference: <author> Skorochodko, E.F. </author> <year> 1971. </year> <title> Adaptive method of automatic abstracting and indexing. </title> <booktitle> In Information Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 1179-1182. </pages> <publisher> North-Holland Publishing Company. </publisher>
Reference: <author> Sparck Jones, Karen. </author> <year> 1993. </year> <title> What might be in a summary? In Information Retrieval 93: </title> <booktitle> Von der Modellierung zur Anwendung, </booktitle> <pages> pages 9-26, </pages> <address> Univer-sitatsverlag Konstanz. </address>
Reference: <author> Winograd, Peter N. </author> <year> 1984. </year> <title> Strategic difficulties in summarizing texts. </title> <journal> Reading Research Quaterly, </journal> <volume> 19(4) </volume> <pages> 404-425, </pages> <month> Summer. </month>
Reference-contexts: Chou Hare and Borchardt, 1984; Sherrard, 1989) that there exists a certain degree of disagreement between readers with respect to the importance that they assign to various textual units and that the disagreement is dependent on the quality of the text and the comprehension and summarization skills of the readers <ref> (Winograd, 1984) </ref>. In an attempt to produce an adequate reference set of data, we selected for our experiment five texts from Scientific American that we considered to be well-written. The texts ranged in size from 161 to 725 words.
References-found: 26

