URL: http://www.cs.purdue.edu/homes/ayg/publications/ps/a3.ps
Refering-URL: http://www.cs.purdue.edu/homes/ayg/publications/work.html
Root-URL: http://www.cs.purdue.edu
Title: A 3 A Simple and Asymptotically Accurate Model for Parallel Computation  
Author: A. Grama and V. Kumar S. Ranka V. Singh 
Note: faster and simpler.  
Address: 30 Saw Mill River Road Minneapolis, MN 55455 Gainesville, FL 32611 Hawthorne, NY 10532  
Affiliation: Computer Science Computer Science IBM Watson Research Ctr. Univ. Minnesota Univ. Florida  
Abstract: Many parallel algorithm design models have been proposed for abstracting a large class of parallel architectures. However, all of these models potentially make inaccurate asymptotic performance predictions that may be too optimistic or too pessimistic depending on the circumstances. We propose a new, simpler parallel model called A 3 (Approximate Model for Analysis of Aggregate Communication Operations) that provides asymptotically accurate time estimates for a wide class of parallel programs that are based on aggregate communication operations. Accuracy is attained (1) by making the model sensitive to the structure of aggregate data communication operations and (2) by classifying these aggregate communication operations into those that are cross-section bandwidth sensitive and those that are not. We note that algorithms expressed exclusively using those aggregate communication operations that are cross-section bandwidth insensitive have the same time complexity across a wide range of architectures. Other algorithms (using aggregate communication operations sensitive to cross-section bandwidth) may have different time complexity but their implementations may still be portable and possibly optimal across a wide range of architectures as long as fly This work was supported by Army Research Office contract DA/DAAH04-95-1-0538, and by Army High Performance Computing Research Center under the auspices of the Department of the Army, Army Research Laboratory cooperative agreement number DAAH04-95-2-0003/contract number DAAH04-95-C-0008, the content of which does not necessarily reflect the position or the policy of the government, and no official endorsement should be inferred. Related papers are available via WWW at URL: http://www.cs.umn.edu/users/kumar/papers.html. fl The work of Sanjay Ranka was supported in part by AFMC and ARPA under contract #F19628-94-C-0057. The content of the information does not necessarily reflect the position or the policy of the Government and no official endorsement should be inferred. tions customized to each architecture. We note that the simpler, asymptotically accurate algorithm analysis facilitated by A 3 can make algorithm design much they use a library of aggregate communication opera
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, A. K. Chandra, and M. Snir. </author> <title> Communication complexity of PRAMs. </title> <type> Technical Report RC 14998 (No.64644), </type> <institution> IBM T.J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <year> 1989. </year>
Reference-contexts: If in a PRAM algorithm, all processors require access to different locations that happen to be within a same memory block on a practical parallel computer, then all these accesses will happen serially. Many models have been designed that remove various drawbacks of the PRAM model <ref> [1, 6, 11, 13, 9, 2, 17] </ref> But most of these models fail to promote either the bulk access locality or the data volume locality. <p> The LogP model [4] tries to address the shortcomings of earlier models such as PRAM [13, 9], LPRAM <ref> [1] </ref>, BPRAM [2], HPRAM [11], YPRAM [6], and BSP [17]. A comprehensive discussion of these models and their relationship to each other is provided in [10].
Reference: [2] <author> A. Agarwal, A. K. Chandra, and M. Snir. </author> <title> On communication latency in PRAM computations. </title> <type> Technical Report RC 14973 (No.66882), </type> <institution> IBM T.J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <year> 1989. </year>
Reference-contexts: If in a PRAM algorithm, all processors require access to different locations that happen to be within a same memory block on a practical parallel computer, then all these accesses will happen serially. Many models have been designed that remove various drawbacks of the PRAM model <ref> [1, 6, 11, 13, 9, 2, 17] </ref> But most of these models fail to promote either the bulk access locality or the data volume locality. <p> The LogP model [4] tries to address the shortcomings of earlier models such as PRAM [13, 9], LPRAM [1], BPRAM <ref> [2] </ref>, HPRAM [11], YPRAM [6], and BSP [17]. A comprehensive discussion of these models and their relationship to each other is provided in [10].
Reference: [3] <author> Guy E. Blelloch, Siddhartha Chatterjee, Jonathan C. Hardwick, Jay Sipelstein, and Marco Zagha. </author> <title> Implementation of a portable nested data-parallel language. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 4-14, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Since the communication involves more than a single pair of processors (aggregates or groups), such communication operations are also referred to as aggregate or collective communication operations. All parallel programs written in data-parallel languages such as HPF and NESL <ref> [3] </ref> fall in this category. Programs based on MPI that use only collective communication operations also fall in this category. The A 3 model presented in this paper is suitable for the class of synchronous algorithms.
Reference: [4] <author> D. Culler, R. Karp, D. Patterson, and et al. </author> <title> Logp: Towards a realistic model of parallel computation. </title> <booktitle> In Principles and Practices of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Many models have been designed that remove various drawbacks of the PRAM model [1, 6, 11, 13, 9, 2, 17] But most of these models fail to promote either the bulk access locality or the data volume locality. The LogP model <ref> [4] </ref> tries to address the shortcomings of earlier models such as PRAM [13, 9], LPRAM [1], BPRAM [2], HPRAM [11], YPRAM [6], and BSP [17]. A comprehensive discussion of these models and their relationship to each other is provided in [10].
Reference: [5] <author> W. J. Dally. </author> <title> Analysis of k-ary n-cube interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: The per-word transfer time t w is determined by the link bandwidth. Lower degree networks typically have higher link bandwidth (and consequently lower t w ). This is because the individual channels can be made fatter for the same overall cost <ref> [12, 5] </ref>. The per-word transfer time t w is often higher than t c , the time to do a unit computation on data available in the cache. The per-hop component t h d can often be subsumed into the startup time t s without significant loss of accuracy.
Reference: [6] <author> Pilar de la Torre and Clyde P. Kruskal. </author> <title> Towards a single model of efficient computation in real parallel machines. </title> <booktitle> In Future Generation Computer Systems, </booktitle> <pages> pages 395 - 408, 8(1992). </pages>
Reference-contexts: If in a PRAM algorithm, all processors require access to different locations that happen to be within a same memory block on a practical parallel computer, then all these accesses will happen serially. Many models have been designed that remove various drawbacks of the PRAM model <ref> [1, 6, 11, 13, 9, 2, 17] </ref> But most of these models fail to promote either the bulk access locality or the data volume locality. <p> The LogP model [4] tries to address the shortcomings of earlier models such as PRAM [13, 9], LPRAM [1], BPRAM [2], HPRAM [11], YPRAM <ref> [6] </ref>, and BSP [17]. A comprehensive discussion of these models and their relationship to each other is provided in [10]. In the spectrum of abstract to practical parallel computers, the LogP model comes closer to practical computers compared to earlier models including its starting point-the BSP model.
Reference: [7] <author> Ian Foster. </author> <title> Designing and Building Parallel Programs. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1995. </year>
Reference-contexts: transit time for messages, given by t h d + t w m, can be effectively masked by overlapping it with computation at source and destination processors. 3 Existing Models for Parallel Compu tation The method of analyzing precise communication cost presented in Section 2 is used extensively by practitioners <ref> [12, 8, 7] </ref>. If the parallel algorithm is such that the network remains lightly loaded (for a wide range of architectures), then the communication costs given by this model are also largely architecture independent.
Reference: [8] <author> G. C. Fox, M. Johnson, G. Lyzenga, S. W. Otto, J. Salmon, and D. Walker. </author> <title> Solving Problems on Concurrent Processors: </title> <journal> Vol. </journal> <volume> 1. </volume> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: transit time for messages, given by t h d + t w m, can be effectively masked by overlapping it with computation at source and destination processors. 3 Existing Models for Parallel Compu tation The method of analyzing precise communication cost presented in Section 2 is used extensively by practitioners <ref> [12, 8, 7] </ref>. If the parallel algorithm is such that the network remains lightly loaded (for a wide range of architectures), then the communication costs given by this model are also largely architecture independent. <p> However, based on our experience such cases are infrequent <ref> [12, 8] </ref>. One example if the butterfly shift operation in which each processor P sends data to processors P + 2 i or P 2 i . For different values of i and different mappings of virtual processors to physical processors, this operation can be bandwidth sensitive or insensitive.
Reference: [9] <author> P. B. Gibbons. </author> <title> A more practical PRAM model. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 158-168, </pages> <year> 1989. </year>
Reference-contexts: If in a PRAM algorithm, all processors require access to different locations that happen to be within a same memory block on a practical parallel computer, then all these accesses will happen serially. Many models have been designed that remove various drawbacks of the PRAM model <ref> [1, 6, 11, 13, 9, 2, 17] </ref> But most of these models fail to promote either the bulk access locality or the data volume locality. <p> The LogP model [4] tries to address the shortcomings of earlier models such as PRAM <ref> [13, 9] </ref>, LPRAM [1], BPRAM [2], HPRAM [11], YPRAM [6], and BSP [17]. A comprehensive discussion of these models and their relationship to each other is provided in [10].
Reference: [10] <author> Ananth Grama, Vipin Kumar, Sanjay Ranka, and Vineet Singh. </author> <title> On architecture independent models for parallel program design. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1996. </year>
Reference-contexts: The LogP model [4] tries to address the shortcomings of earlier models such as PRAM [13, 9], LPRAM [1], BPRAM [2], HPRAM [11], YPRAM [6], and BSP [17]. A comprehensive discussion of these models and their relationship to each other is provided in <ref> [10] </ref>. In the spectrum of abstract to practical parallel computers, the LogP model comes closer to practical computers compared to earlier models including its starting point-the BSP model. <p> In other cases, it yields lower bounds on the communication time for the operation. 5 Analysis of Algorithms In this section, we present results of a sample analysis of parallel dense matrix-matrix product. (The reader is referred to <ref> [10] </ref> for a more extensive analytical study of parallel algorithms for sample sort and Gaussian elimination.) We compare the A 3 and LogP models to the accurate model. We show that the A 3 model yields accurate asymptotic estimates of communication overhead. <p> We show that the A 3 model yields accurate asymptotic estimates of communication overhead. The LogP model fails to do so for the mesh. This is true of the other algorithms discussed in <ref> [10] </ref> as well. Furthermore, although it may seem that the LogP model gives accurate runtimes for the hypercube, it gives no hints about placement of tasks on processors. Randomly placing subtasks on processors may cause contention over the network, degradation of performance, and worse runtimes.
Reference: [11] <author> T. Heywood and S. Ranka. </author> <title> A practical hierarchical model of parallel computation. i. the model. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16(3) </volume> <pages> 212-32, </pages> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: If in a PRAM algorithm, all processors require access to different locations that happen to be within a same memory block on a practical parallel computer, then all these accesses will happen serially. Many models have been designed that remove various drawbacks of the PRAM model <ref> [1, 6, 11, 13, 9, 2, 17] </ref> But most of these models fail to promote either the bulk access locality or the data volume locality. <p> The LogP model [4] tries to address the shortcomings of earlier models such as PRAM [13, 9], LPRAM [1], BPRAM [2], HPRAM <ref> [11] </ref>, YPRAM [6], and BSP [17]. A comprehensive discussion of these models and their relationship to each other is provided in [10]. In the spectrum of abstract to practical parallel computers, the LogP model comes closer to practical computers compared to earlier models including its starting point-the BSP model.
Reference: [12] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Algorithm Design and Analysis. </title> <publisher> Benjamin Cummings/ Addison Wesley (ISBN 0 8053-3170-0), </publisher> <address> Redwod City, </address> <year> 1994. </year>
Reference-contexts: The per-word transfer time t w is determined by the link bandwidth. Lower degree networks typically have higher link bandwidth (and consequently lower t w ). This is because the individual channels can be made fatter for the same overall cost <ref> [12, 5] </ref>. The per-word transfer time t w is often higher than t c , the time to do a unit computation on data available in the cache. The per-hop component t h d can often be subsumed into the startup time t s without significant loss of accuracy. <p> transit time for messages, given by t h d + t w m, can be effectively masked by overlapping it with computation at source and destination processors. 3 Existing Models for Parallel Compu tation The method of analyzing precise communication cost presented in Section 2 is used extensively by practitioners <ref> [12, 8, 7] </ref>. If the parallel algorithm is such that the network remains lightly loaded (for a wide range of architectures), then the communication costs given by this model are also largely architecture independent. <p> For a more detailed description of these operations, the reader is referred to Kumar et al. <ref> [12] </ref> and Shankar and Ranka [15, 16]. Personalized communica tion appears in such applications as matrix transpose, hash joins, and Fast Fourier Transforms. Broadcasts and scans are ubiquitous. NEWS communication is required in finite difference and finite element methods, and a variety of image processing applications. <p> Broadcasts and scans are ubiquitous. NEWS communication is required in finite difference and finite element methods, and a variety of image processing applications. The performance properties of aggregate communication operations can be ascertained from the underlying data movement. We first briefly discuss a widely used <ref> [12] </ref> accurate cost model, and then present a new, simpler cost model called A 3 that can be applied in the presence of adequate slack. We will demonstrate in Section 5 the use of these models for performance prediction. <p> We assume knowledge of the algorithms used for basic communication operations. Whereas this knowledge is not necessary for analyzing algorithms in our framework, it is necessary for analyzing them for the LogP model. The reader is referred to <ref> [12] </ref> for detailed descriptions of these analyses. For the LogP model, we assume that the overhead o is small and that the gap g &gt; o. This allows us overlap of computation and communication where feasible. <p> Although, a large majority of parallel algorithms are synchronous, there is a class of algorithms that does not fit into this framework nicely. Examples of such applications are in discrete event simulation and branch-and-bound tree search <ref> [12] </ref>. There is also a possible loss in efficiency resulting from organizing parallel algorithms as synchronous algorithms based on aggregate communication operations. Further more, the A 3 model is not applicable for cases when the slack is small. <p> However, based on our experience such cases are infrequent <ref> [12, 8] </ref>. One example if the butterfly shift operation in which each processor P sends data to processors P + 2 i or P 2 i . For different values of i and different mappings of virtual processors to physical processors, this operation can be bandwidth sensitive or insensitive.
Reference: [13] <author> A. G. Ranade. </author> <title> How to emulate shared memory. </title> <booktitle> In Proceedings of the 28th IEEE Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 185 - 194, </pages> <year> 1987. </year>
Reference-contexts: If in a PRAM algorithm, all processors require access to different locations that happen to be within a same memory block on a practical parallel computer, then all these accesses will happen serially. Many models have been designed that remove various drawbacks of the PRAM model <ref> [1, 6, 11, 13, 9, 2, 17] </ref> But most of these models fail to promote either the bulk access locality or the data volume locality. <p> The LogP model [4] tries to address the shortcomings of earlier models such as PRAM <ref> [13, 9] </ref>, LPRAM [1], BPRAM [2], HPRAM [11], YPRAM [6], and BSP [17]. A comprehensive discussion of these models and their relationship to each other is provided in [10].
Reference: [14] <author> S. Ranka, R. V. Shankar, and K. A. Alsabti. </author> <title> Many-to-many personalized communication with bounded traffic. </title> <booktitle> In Proceedings. Frontiers '95. The Fifth Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <month> 6-9 Feb. </month> <year> 1995. </year>
Reference-contexts: However, there are no known algorithms that can perform the permutation in this time even on fi (p) cross-section bandwidth networks such as hypercubes for fixed values of m 2 . The transportation primitive of Shankar and Ranka <ref> [14, 15, 16] </ref> performs this permutation in fi (m) time but it requires m to grow as fi (p). 3 Now consider an adaptation of these models for a mesh. <p> In our model, we remedy this by classifying redistributions into categories and assigning appropriate costs 2 If the message size m grows as fi (log p), then it is possible to perform the permutation in fi (m) time [17] 3 The transportation primitive of Shankar and Ranka <ref> [14] </ref> requires m to grow as fi (p 2 ). This can be reduced to fi (p) by increasing the number of stages at the expense of higher constants. to them on k:d cubes. <p> A slack of fi (p) is adequate for all cases illustrated in Table 1. In many of these cases, a lower slack is adequate. For some other aggregate communication operations, the slack required may be higher. For example, the transportation primitive of Shankar and Ranka <ref> [14] </ref> requires a slack of O (p 2 ) per processor. This can be reduced to O (p) per processor by increasing the number of stages resulting in higher constants. Most other aggregate communication operations require less slack than the transportation primitive.
Reference: [15] <author> R. Shankar and S. Ranka. </author> <title> Random data access on a coarse grained parallel machine i. one-to-one mappings. </title> <type> Technical report, </type> <institution> School of Computer and Information Science, Syracuse University, Syracuse, </institution> <address> NY, 13244, </address> <month> October </month> <year> 1994. </year> <note> A short version of the paper appeared in the Proceedings of First International Workshop on Parallel Processing, </note> <institution> Bangalore, India, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: However, there are no known algorithms that can perform the permutation in this time even on fi (p) cross-section bandwidth networks such as hypercubes for fixed values of m 2 . The transportation primitive of Shankar and Ranka <ref> [14, 15, 16] </ref> performs this permutation in fi (m) time but it requires m to grow as fi (p). 3 Now consider an adaptation of these models for a mesh. <p> For a more detailed description of these operations, the reader is referred to Kumar et al. [12] and Shankar and Ranka <ref> [15, 16] </ref>. Personalized communica tion appears in such applications as matrix transpose, hash joins, and Fast Fourier Transforms. Broadcasts and scans are ubiquitous. NEWS communication is required in finite difference and finite element methods, and a variety of image processing applications.
Reference: [16] <author> R. Shankar and S. Ranka. </author> <title> Random data access on a coarse grained parallel machine ii. one-to-many and many-to-one mappings. </title> <type> Technical report, </type> <institution> School of Computer and Information Science, Syracuse University, Syracuse, </institution> <address> NY, 13244, </address> <month> October </month> <year> 1994. </year> <note> A short version of the paper appeared in the Proceedings of Symposium of Parallel and Distributed Processing, </note> <year> 1994. </year>
Reference-contexts: However, there are no known algorithms that can perform the permutation in this time even on fi (p) cross-section bandwidth networks such as hypercubes for fixed values of m 2 . The transportation primitive of Shankar and Ranka <ref> [14, 15, 16] </ref> performs this permutation in fi (m) time but it requires m to grow as fi (p). 3 Now consider an adaptation of these models for a mesh. <p> For a more detailed description of these operations, the reader is referred to Kumar et al. [12] and Shankar and Ranka <ref> [15, 16] </ref>. Personalized communica tion appears in such applications as matrix transpose, hash joins, and Fast Fourier Transforms. Broadcasts and scans are ubiquitous. NEWS communication is required in finite difference and finite element methods, and a variety of image processing applications.
Reference: [17] <author> L. G. Valiant. </author> <title> General purpose parallel architectures. </title> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <year> 1990. </year>
Reference-contexts: If in a PRAM algorithm, all processors require access to different locations that happen to be within a same memory block on a practical parallel computer, then all these accesses will happen serially. Many models have been designed that remove various drawbacks of the PRAM model <ref> [1, 6, 11, 13, 9, 2, 17] </ref> But most of these models fail to promote either the bulk access locality or the data volume locality. <p> The LogP model [4] tries to address the shortcomings of earlier models such as PRAM [13, 9], LPRAM [1], BPRAM [2], HPRAM [11], YPRAM [6], and BSP <ref> [17] </ref>. A comprehensive discussion of these models and their relationship to each other is provided in [10]. In the spectrum of abstract to practical parallel computers, the LogP model comes closer to practical computers compared to earlier models including its starting point-the BSP model. <p> In our model, we remedy this by classifying redistributions into categories and assigning appropriate costs 2 If the message size m grows as fi (log p), then it is possible to perform the permutation in fi (m) time <ref> [17] </ref> 3 The transportation primitive of Shankar and Ranka [14] requires m to grow as fi (p 2 ). This can be reduced to fi (p) by increasing the number of stages at the expense of higher constants. to them on k:d cubes.
References-found: 17

