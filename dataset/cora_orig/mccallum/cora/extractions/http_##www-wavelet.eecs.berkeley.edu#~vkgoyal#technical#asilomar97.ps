URL: http://www-wavelet.eecs.berkeley.edu/~vkgoyal/technical/asilomar97.ps
Refering-URL: http://www-wavelet.eecs.berkeley.edu/~vkgoyal/technical/asilomar97.html
Root-URL: 
Email: E-mail: v.goyal@ieee.org, Martin.Vetterli@de.epfl.ch  
Title: Computation-Distortion Characteristics of JPEG Encoding and Decoding  
Author: Vivek K Goyal Martin Vetterli ; 
Note: To appear in Proc. 31st Asilomar Conf. on Signals, Systems, and Computers, November 1997. c fl1997 IEEE.  
Address: F ed erale de Lausanne, Switzerland  
Affiliation: 1 Dept. of Electrical Engineering and Computer Sciences University of California, Berkeley 2 Laboratoire de Communications Audiovisuelles Ecole Polytechnique  
Abstract: A distortion-computation function D(C) is defined as the minimum expected distortion in computing some quantity using an algorithm from a predefined set of algorithms while using no more than C computational units. When the computational problem is to encode at rate R, this gives slices of a computation-rate-distortion surface. This framework is used in the analysis of a family of JPEG coders that use output-pruned DCT calculations in place of some full DCT calculations. For encoding the Lena image at 0.5 bits/pixel, this yields a 30% reduction in complexity while lowering the PSNR by only 0.4 dB. The decoding complexity can be similarly reduced. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. The Wadsworth Statistics/Probability Series. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA, </address> <year> 1984. </year>
Reference-contexts: Figure 2 shows an output pruned DCT where only the first two coefficients (X [0] and X <ref> [1] </ref>) are desired. Because of the shapes of the regions considered (see Figure 1), we always require the k lowest frequency DCT coefficients, 1 k 8. The computational complexities for these output-pruned 1-D DCTs are given in Table 1. <p> of the 192 multi The full signal flow graph is from [11, p. 61] and represents a decimation-in-frequency algorithm. (Boxes represent multiplications other than by 1 and subtractions are not distinguished from additions.) The dotted curves represent calculations that can be eliminated because we desire only X [0] and X <ref> [1] </ref>. The computational complexity is reduced from 12 multiplications and 29 additions for the full calculation to 7 multiplications and 20 additions. plications for a full 8 fi 8 DCT. The situation is very similar for decoding. <p> minimize J = R + D, where R is the entropy coded rate, D is the distortion, and controls the trade-off between R and D. (Optimality is within the set of all subtrees of the original tree.) The pruning uses the greedy algorithm of Breiman, Freidman, Olshen, and Stone (BFOS) <ref> [1] </ref> which in general is not optimal, but is optimal in this case because the objective functions are monotonic, affine tree functionals [3].
Reference: [2] <author> A. Buzo, A. H. Gray, Jr., R. M. Gray, and J. D. Markel. </author> <title> Speech coding based upon vector quantization. </title> <journal> IEEE Trans. Acoust. Speech Signal Proc., </journal> <volume> ASSP-28:562-574, </volume> <month> Oct. </month> <year> 1980. </year>
Reference-contexts: In tree-structured VQ (TSVQ) <ref> [2] </ref>, a binary tree is constructed with a codeword at each node. In the encoding process, one starts at the root of the tree and iteratively traverses the branch to the child node whose codeword is closest to the source vector. Coding terminates when a leaf node is reached.
Reference: [3] <author> P. A. Chou, T. Lookabaugh, and R. M. Gray. </author> <title> Optimal pruning with applications to tree-structured source coding and modeling. </title> <journal> IEEE Trans. Info. Theory, </journal> <volume> IT-35(2):299-315, </volume> <month> Mar. </month> <year> 1989. </year>
Reference-contexts: This paper reviews the framework from [6] in Section 2 and then applies this framework to JPEG encoding and decoding in Section 3. Another application relevant to image coding, namely to entropy pruned tree-structured vector quantization <ref> [3] </ref>, is briefly outlined in Section 4. 2 Computation-Rate-Distortion Framework Let P be a set of computational problems which are posed according to some underlying probability distribution and let be a distortion measure on approximate solutions to problems in P. <p> Therefore to have variable computational load requires varying the vector dimension. 3 This is not pursued here. In contrast to the case of full-search VQ, the complexity of entropy pruned tree-structured VQ (EPTSVQ) <ref> [3] </ref> is not determinable from the output rate. <p> R and D. (Optimality is within the set of all subtrees of the original tree.) The pruning uses the greedy algorithm of Breiman, Freidman, Olshen, and Stone (BFOS) [1] which in general is not optimal, but is optimal in this case because the objective functions are monotonic, affine tree functionals <ref> [3] </ref>. Assuming a pair of distance determinations and a comparison takes one unit of computation, the average computational complexity of TSVQ encoding is the weighted average of the depths of the leaf nodes.
Reference: [4] <author> T. M. Cover and J. A. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Then, define the distortion computation function at rate R by D R (C) = inf E (x; ^x); where `(^x) is the length of the representation of ^x in bits. Notice that in contrast to the definition of a rate distortion function <ref> [4] </ref>, we do not use the mutual information between x and ^x. Doing so would implicitly assume that the entropy coding of ^x is ideal; instead, we would like to remain open to the possibility that the entropy coding is included in the computational cost.
Reference: [5] <author> M. J. Gormish and J. T. Gill. </author> <title> Computation-rate-distortion in transform coders for image compression. </title> <booktitle> In Proc. SPIE Conf. Image and Video Proc., volume 1903, </booktitle> <pages> pages 146-152, </pages> <year> 1993. </year>
Reference-contexts: Varying the parameter R yields a computation-rate-distortion surface. This framework was introduced in [6]. That paper provided a detailed comparison of the use of the Karhunen-Loeve Transform (KLT) and the Discrete Cosine Transform (DCT) for transform coding of a Gauss-Markov source. In this same context, Gormish and Gill <ref> [5] </ref> made earlier mention of the concept of a computation-rate-distortion surface, though in an operational sense. A few properties are obvious. D (C) must be nonincreasing and D R (C) must be nonincreasing with respect to both R and C.
Reference: [6] <author> V. K. Goyal and M. Vetterli. </author> <title> Computation-distortion characteristics of block transform coding. </title> <booktitle> In Proc. IEEE Int. Conf. Acoust., Speech, and Signal Proc., </booktitle> <pages> pages 2729-2732, </pages> <address> Mu-nich, Germany, </address> <month> Apr. </month> <year> 1997. </year>
Reference-contexts: In a recent paper <ref> [6] </ref>, we introduced a flexible framework for systematically studying the trade-off between computational complexity and coding performance. The value of the framework itself is to provide a common vocabulary; it does not intrinsically aid in the analysis. <p> This paper reviews the framework from <ref> [6] </ref> in Section 2 and then applies this framework to JPEG encoding and decoding in Section 3. <p> Doing so would implicitly assume that the entropy coding of ^x is ideal; instead, we would like to remain open to the possibility that the entropy coding is included in the computational cost. Varying the parameter R yields a computation-rate-distortion surface. This framework was introduced in <ref> [6] </ref>. That paper provided a detailed comparison of the use of the Karhunen-Loeve Transform (KLT) and the Discrete Cosine Transform (DCT) for transform coding of a Gauss-Markov source.
Reference: [7] <author> K. Lengwehasatit. </author> <type> Personal communication. </type> <month> October </month> <year> 1997. </year>
Reference-contexts: The approximate DCT considered here forces longer runs of zeros and hence gets good coding efficiency. Output pruning is not the optimal way to produce the desired 1-D DCT algorithms, but was done for conceptual transparency and so that the set of algorithms A could be precisely defined. Lengwehasatit <ref> [7] </ref> has provided the operation counts for hand-optimized algorithms which assume integer valued inputs and use some bit shifting. These operation counts are given in Table 2 and yield the D (C) curves in Figure 5. <p> Operation counts to compute the first k coefficents of a length-8 DCT <ref> [7] </ref>. for JPEG encoding of Lena with computation counts from Table 2. clearly easiest to handle, assuming that they can be identified efficiently.
Reference: [8] <author> K. Lengwehasatit and A. Ortega. </author> <title> DCT computation with minimal average number of operations. </title> <booktitle> In Proc. SPIE Conf. on Vis. Commun. and Image Proc., volume 3024, </booktitle> <address> San Jose, California, </address> <month> Feb. </month> <year> 1997. </year>
Reference-contexts: Operation counts to compute the first k coefficents of a length-8 DCT [7]. for JPEG encoding of Lena with computation counts from Table 2. clearly easiest to handle, assuming that they can be identified efficiently. Lengwehasatit and Ortega <ref> [8, 9] </ref> have developed a decoder which classifies blocks based on their patterns of zero and non-zero coefficients and uses inverse DCT algorithms optimized for each class. The definitions of the classes themselves have been computationally optimized, including the cost of classifying.
Reference: [9] <author> K. Lengwehasatit and A. Ortega. </author> <title> Distortion/decoding time tradeoffs in software DCT-based image coding. </title> <booktitle> In Proc. IEEE Int. Conf. Acoust., Speech, and Signal Proc., </booktitle> <volume> volume 4, </volume> <pages> pages 2725-2728, </pages> <address> Munich, Germany, </address> <month> Apr. </month> <year> 1997. </year>
Reference-contexts: Operation counts to compute the first k coefficents of a length-8 DCT [7]. for JPEG encoding of Lena with computation counts from Table 2. clearly easiest to handle, assuming that they can be identified efficiently. Lengwehasatit and Ortega <ref> [8, 9] </ref> have developed a decoder which classifies blocks based on their patterns of zero and non-zero coefficients and uses inverse DCT algorithms optimized for each class. The definitions of the classes themselves have been computationally optimized, including the cost of classifying.
Reference: [10] <author> K. Ramchandran and M. Vetterli. </author> <title> Rate-distortion optimal fast thresholding with complete JPEG/MPEG decoder compatibility. </title> <journal> IEEE Trans. Image Proc., </journal> <volume> IP-3(5):700-704, </volume> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Because of the runlength and entropy coding used in JPEG, even when a high frequency DCT coefficient has a nonzero quantized value, coding that coefficient (as opposed to rounding it to zero) may not be wise in a rate-distortion sense <ref> [10] </ref>. The approximate DCT considered here forces longer runs of zeros and hence gets good coding efficiency. Output pruning is not the optimal way to produce the desired 1-D DCT algorithms, but was done for conceptual transparency and so that the set of algorithms A could be precisely defined.
Reference: [11] <author> K. R. Rao and P. Yip. </author> <title> Discrete Cosine Transform: Algorithms, Advantages, Applications. </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: Triangular regions are motivated by the zigzag scanning of AC coefficients. The DCT calculation itself is done separably using output pruned decimation-in-frequency 1-D DCT algorithms, by which we mean decimation in frequency length-8 DCT algorithms <ref> [11] </ref> which are simplified because only a subset of the eight coefficients are desired. Figure 2 shows an output pruned DCT where only the first two coefficients (X [0] and X [1]) are desired. <p> This is roughly two-thirds of the 192 multi The full signal flow graph is from <ref> [11, p. 61] </ref> and represents a decimation-in-frequency algorithm. (Boxes represent multiplications other than by 1 and subtractions are not distinguished from additions.) The dotted curves represent calculations that can be eliminated because we desire only X [0] and X [1].
References-found: 11

