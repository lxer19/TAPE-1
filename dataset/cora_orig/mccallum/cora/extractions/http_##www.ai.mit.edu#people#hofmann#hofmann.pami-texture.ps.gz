URL: http://www.ai.mit.edu/people/hofmann/hofmann.pami-texture.ps.gz
Refering-URL: http://www.ai.mit.edu/people/hofmann/
Root-URL: 
Email: email: hofmann@ai.mit.edu, fjan,jbg@cs.uni- bonn.de  
Title: Unsupervised Texture Segmentation in a Deterministic Annealing Framework  
Author: Thomas Hofmann Jan Puzicha, and Joachim M. Buhmann Rheinische Friedrich-Wilhelms-Universitat 
Date: May 14, 1998  
Note: to appear in: IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 1998.  
Web: WWW: http://www-dbv.cs.uni-bonn.de  
Address: D-53117 Bonn, Germany  Cambridge, MA 02139  
Affiliation: Institut fur Informatik III, Romerstrae 164  Center for Biological and Computational Learning Department of Brain and Cognitive Sciences Massachusetts Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Jain and F. Farrokhnia, </author> <title> "Unsupervised texture segmentation using Gabor filters," </title> <journal> Pattern Recognition, </journal> <volume> vol. 24, no. 12, </volume> <pages> pp. 1167-1186, </pages> <year> 1991. </year>
Reference-contexts: As a consequence, these approaches have to solve the difficult problem of specifying a metric that appropriately represents visual dissimilarities between textures in the chosen feature space <ref> [1, 2] </ref>. In contrast to this widely appreciated approach, we follow the ideas of Geman et al. [3] to avoid a vector space representation by utilizing non-parametric statistical tests. <p> Alternatively radial symmetric functions could be used, e.g., Gaussians decaying with r . The autocorrelation function of the Gabor wavelet coefficients varies with a typical length scale which is determined by the scale of the texture and the filter width. Following <ref> [1] </ref> the window size for each filter is thus chosen proportional to r . <p> In the mean-field approximation Q M is chosen to be the space of all factorial distributions Q M = Q 2 P M : Q (M) = i=1 -=1 ) The q i- 2 <ref> [0; 1] </ref> are N K parameters, which uniquely determine Q. The above approximation yields a procedure which is known as mean-field annealing, since it combines the mean-field approximation with the annealing principle [8, 14]. <p> IEEE PAMI, 1998, to appear. 13 pro B using 3-7 clusters and complexity costs with c = 100=N . sented cost functions. An answer is given by comparing minimal cost configurations with known ground truth. As an independent reference algorithm, we have re-implemented the method of Jain & Farrokhnia <ref> [1] </ref>, which clusters feature vectors extracted from Gabor filter responses (Gabor Feature Clustering, GFC). This method uses the absolute value of the hyperbolic tangens of the real part of the Gabor filters, which are further smoothed by a Gaussian filter. <p> We have chosen a deterministic annealing algorithm for clustering of vectorial data due to Rose et.al. [11], which was empirically found to yield slightly better results than the K-means algorithm proposed in <ref> [1] </ref>. Both algorithms optimize the same cost function, H km (M; D), but the deterministic annealing implementation converges to superior minima. In order to obtain comparable results we used the same 12 Gabor filters and extracted feature vectors on the same 64 fi 64 regular sub-lattice of sites.
Reference: [2] <author> J. Mao and A. Jain, </author> <title> "Texture classification and segmentation using multiresolution simultaneous autoregressive models," </title> <journal> Pattern Recognition, </journal> <volume> vol. 25, </volume> <pages> pp. 173-188, </pages> <year> 1992. </year>
Reference-contexts: As a consequence, these approaches have to solve the difficult problem of specifying a metric that appropriately represents visual dissimilarities between textures in the chosen feature space <ref> [1, 2] </ref>. In contrast to this widely appreciated approach, we follow the ideas of Geman et al. [3] to avoid a vector space representation by utilizing non-parametric statistical tests.
Reference: [3] <author> D. Geman, S. Geman, C. Graffigne, and P. Dong, </author> <title> "Boundary detection by constrained optimization," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 12, </volume> <pages> pp. 609-628, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: As a consequence, these approaches have to solve the difficult problem of specifying a metric that appropriately represents visual dissimilarities between textures in the chosen feature space [1, 2]. In contrast to this widely appreciated approach, we follow the ideas of Geman et al. <ref> [3] </ref> to avoid a vector space representation by utilizing non-parametric statistical tests. As we will show, statistical tests are reliable measures of local texture similarity which are generally applicable and do not require the usual substantial parameter tuning. <p> This paper provides novel contributions to all three challenges: Section 2 deals with the extraction of proximity data from a Gabor image representation. On the basis of empirical performance comparisons we favor the 2 -statistic over the Kolmogorov-Smirnov test proposed in <ref> [3] </ref>. In Section 3, we derive a novel class of clustering objective functions with fundamental invariance properties. As it turns out, the key idea is to choose an appropriate normalization in measuring cluster compactness. <p> In Section 3, we derive a novel class of clustering objective functions with fundamental invariance properties. As it turns out, the key idea is to choose an appropriate normalization in measuring cluster compactness. The main property, which distinguishes our approach from other graph partitioning schemes <ref> [3, 4, 5] </ref>, is shift invariance, i.e., invari-ance with respect to additive shifts of the proximity scale. In particular, this yields a natural generalization of the K-means cost function [6] to proximity data. <p> We apply a statistical test d based on the distribution of coefficients in either window, i.e., D (r) Several non-parametric test statistics are available for the two-sample problem [28]. We have examined the performance of the mutual information [4], the Kolmogorov-Smirnov statistic <ref> [3, 29] </ref>, tests of the Cramer/von Mises type, and the 2 -statistics in detail [30, 31]. Empirically, the 2 test and the mutual information test have been shown to yield the best results. <p> A convenient way to represent sparse proximity matrices are weighted loop-free graphs G = (V; E; D) with vertices V = f1; : : : ; N g, edges E V fi V and weights D ij for edges e = (i; j). Following <ref> [3] </ref> we call the index sets N i = fj : (i; j) 2 Eg the neighborhood of site ~x i and define N i to consist of the four connected neighborhood of ~x i in the image and a larger number of random neighbors. 3 Clustering of Proximity Data As <p> A weighting proportional to the number of known dissimilarities in a cluster, H gp (M; D) = -=1 Q -B - = -=1 (i;j)2V M i- M j-D ij , corresponds to the standard cost function for graph partitioning problems and has been proposed in <ref> [3] </ref> for texture segmentation, but does not result in a shift-invariant function. 4. <p> For example, H gp applied to graphs with non-negative weights favors equipartition-ings, whereas in the opposite case the formation of large clusters is advantageous. Indeed, T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 7 it has been noticed before <ref> [3] </ref> that the data have to be shifted adequately in order to keep the right balance between negative and positive contributions. <p> probability to be assigned to the same texture, which is reflected by the choice H top (M) = t P K P N P j2T i (1 M j-) : We have furthermore added some hard constraints about valid image partitionings, excluding very small and thin regions as described in <ref> [3] </ref>. Since additional hard constraints restrict the development of efficient optimization algorithms and may lead to forbiddingly heavy computational load [32], we enforce these constraints in a separate post-processing stage which follows the clustering procedure and determines the closest valid partitioning by eliminating components and smoothing borders, if necessary.
Reference: [4] <author> T. Ojala, M. Pietikainen, and D. Harwood, </author> <title> "A comparative study of texture measures with classification based feature distributions," </title> <journal> Pattern Recognition, </journal> <volume> vol. 29, no. 1, </volume> <pages> pp. 51-59, </pages> <year> 1996. </year>
Reference-contexts: In Section 3, we derive a novel class of clustering objective functions with fundamental invariance properties. As it turns out, the key idea is to choose an appropriate normalization in measuring cluster compactness. The main property, which distinguishes our approach from other graph partitioning schemes <ref> [3, 4, 5] </ref>, is shift invariance, i.e., invari-ance with respect to additive shifts of the proximity scale. In particular, this yields a natural generalization of the K-means cost function [6] to proximity data. <p> We apply a statistical test d based on the distribution of coefficients in either window, i.e., D (r) Several non-parametric test statistics are available for the two-sample problem [28]. We have examined the performance of the mutual information <ref> [4] </ref>, the Kolmogorov-Smirnov statistic [3, 29], tests of the Cramer/von Mises type, and the 2 -statistics in detail [30, 31]. Empirically, the 2 test and the mutual information test have been shown to yield the best results.
Reference: [5] <author> J. Shi and J. Malik, </author> <title> "Normalized cuts and image segmentation," </title> <booktitle> in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'97), </booktitle> <pages> pp. 731-737, </pages> <year> 1997. </year> <title> T. Hofmann et.al.: Unsupervised Texture Segmentation. </title> <journal> IEEE PAMI, </journal> <note> 1998, to appear. 25 </note>
Reference-contexts: In Section 3, we derive a novel class of clustering objective functions with fundamental invariance properties. As it turns out, the key idea is to choose an appropriate normalization in measuring cluster compactness. The main property, which distinguishes our approach from other graph partitioning schemes <ref> [3, 4, 5] </ref>, is shift invariance, i.e., invari-ance with respect to additive shifts of the proximity scale. In particular, this yields a natural generalization of the K-means cost function [6] to proximity data. <p> For completeness, we mention the proposal made in <ref> [5] </ref> called normalized cut with an objective function given by H nc (M; D) = P K P (i;j)2V M iD ij which is not of the type defined in (4) and is also not shift invariant.
Reference: [6] <author> J. MacQueen, </author> <title> "Some methods for classification and analysis of multivariate observa tions," </title> <booktitle> in Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability, </booktitle> <pages> pp. 281-297, </pages> <year> 1967. </year>
Reference-contexts: The main property, which distinguishes our approach from other graph partitioning schemes [3, 4, 5], is shift invariance, i.e., invari-ance with respect to additive shifts of the proximity scale. In particular, this yields a natural generalization of the K-means cost function <ref> [6] </ref> to proximity data. Section 4 presents an introduction to the concept of deterministic annealing, a general framework to derive efficient heuristic algorithms for a variety of problems in combinatorial optimization and computer vision.
Reference: [7] <author> C. Peterson and B. Soderberg, </author> <title> "A new method for mapping optimisation problems onto neural networks," </title> <journal> International Journal of Neural Systems, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 3-22, </pages> <year> 1989. </year>
Reference-contexts: Section 4 presents an introduction to the concept of deterministic annealing, a general framework to derive efficient heuristic algorithms for a variety of problems in combinatorial optimization and computer vision. Deterministic Annealing has been applied to the traveling salesman problem <ref> [7] </ref>, graph partitioning [8], quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching [9, 10], vector quantization [11, 12], surface reconstruction [13], image restoration [14, 15], and edge detection [16].
Reference: [8] <author> D. van den Bout and T. Miller, </author> <title> "Graph partitioning using annealed neural networks," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 192-203, </pages> <year> 1990. </year>
Reference-contexts: Section 4 presents an introduction to the concept of deterministic annealing, a general framework to derive efficient heuristic algorithms for a variety of problems in combinatorial optimization and computer vision. Deterministic Annealing has been applied to the traveling salesman problem [7], graph partitioning <ref> [8] </ref>, quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching [9, 10], vector quantization [11, 12], surface reconstruction [13], image restoration [14, 15], and edge detection [16]. <p> The above approximation yields a procedure which is known as mean-field annealing, since it combines the mean-field approximation with the annealing principle <ref> [8, 14] </ref>. The advantage of annealing in the context of deterministic or mean-field annealing is to track solutions from high temperatures where F T is convex, to low temperatures where we can canonically recover a local minimum of H. <p> Theorem 1 is an extension of the results obtained in <ref> [8] </ref> for the graph partitioning cost function H gp . <p> Most of the work on mean-field annealing has either favored the synchronous update (e.g., [39, 20, 40]) or has at least been indifferent to this distinction (e.g., <ref> [8, 14, 16] </ref>). The synchronous scheme has the advantage of being amenable to a parallel implementation as already proposed by [39].
Reference: [9] <author> A. Yuille, </author> <title> "Generalized deformable models, </title> <journal> statistical physics, and matching prob lems," Neural Computation, </journal> <volume> vol. 2, </volume> <pages> pp. 1-24, </pages> <year> 1990. </year>
Reference-contexts: Deterministic Annealing has been applied to the traveling salesman problem [7], graph partitioning [8], quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching <ref> [9, 10] </ref>, vector quantization [11, 12], surface reconstruction [13], image restoration [14, 15], and edge detection [16]. A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17].
Reference: [10] <author> S. Gold and A. Rangarajan, </author> <title> "A graduated assignment algorithm for graph matching," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 18, no. 4, </volume> <pages> pp. 377-388, </pages> <year> 1996. </year>
Reference-contexts: Deterministic Annealing has been applied to the traveling salesman problem [7], graph partitioning [8], quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching <ref> [9, 10] </ref>, vector quantization [11, 12], surface reconstruction [13], image restoration [14, 15], and edge detection [16]. A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17].
Reference: [11] <author> K. Rose, E. Gurewitz, and G. Fox, </author> <title> "Vector quantization by deterministic annealing," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 38, no. 4, </volume> <pages> pp. 1249-1257, </pages> <year> 1992. </year>
Reference-contexts: Deterministic Annealing has been applied to the traveling salesman problem [7], graph partitioning [8], quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching [9, 10], vector quantization <ref> [11, 12] </ref>, surface reconstruction [13], image restoration [14, 15], and edge detection [16]. A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle [18, 19, 20, 21] to obtain compu-tationally tractable algorithms. <p> While the general convergence results for simulated annealing [37] demonstrate the universality of this optimization principle, the inherently slow convergence of stochastic techniques compared to deterministic algorithms is perceived as a major disadvantage. Therefore, we advocate to use a different, purely deterministic approach known as deterministic annealing <ref> [11] </ref>. Deterministic annealing combines the advantages of a temperature controlled continuation method with a fast, purely deterministic computational scheme. To stress the general ability to canonically derive heuristic algorithms for partitioning problems, we abstract from the details of H and present results which apply to arbitrary partitioning objective functions. <p> The texture segmentation problem is then formulated as a clustering problem of the resulting normalized feature vectors according to a K-means clustering criterion. We have chosen a deterministic annealing algorithm for clustering of vectorial data due to Rose et.al. <ref> [11] </ref>, which was empirically found to yield slightly better results than the K-means algorithm proposed in [1]. Both algorithms optimize the same cost function, H km (M; D), but the deterministic annealing implementation converges to superior minima.
Reference: [12] <author> J. Buhmann and H. Kuhnel, </author> <title> "Vector quantization with complexity costs," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 39, </volume> <pages> pp. 1133-1145, </pages> <year> 1993. </year>
Reference-contexts: Deterministic Annealing has been applied to the traveling salesman problem [7], graph partitioning [8], quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching [9, 10], vector quantization <ref> [11, 12] </ref>, surface reconstruction [13], image restoration [14, 15], and edge detection [16]. A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle [18, 19, 20, 21] to obtain compu-tationally tractable algorithms.
Reference: [13] <author> D. Geiger and F. Girosi, </author> <title> "Parallel and deterministic algorithms from MRF's: Surface reconstruction," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <pages> pp. 401-412, </pages> <year> 1991. </year>
Reference-contexts: Deterministic Annealing has been applied to the traveling salesman problem [7], graph partitioning [8], quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching [9, 10], vector quantization [11, 12], surface reconstruction <ref> [13] </ref>, image restoration [14, 15], and edge detection [16]. A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle [18, 19, 20, 21] to obtain compu-tationally tractable algorithms.
Reference: [14] <author> G. Bilbro, W. Snyder, S. Garnier, and J. Gault, </author> <title> "Mean field annealing: A formal ism for constructing GNC-like algorithms," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 3, no. 1, </volume> <year> 1992. </year>
Reference-contexts: Deterministic Annealing has been applied to the traveling salesman problem [7], graph partitioning [8], quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching [9, 10], vector quantization [11, 12], surface reconstruction [13], image restoration <ref> [14, 15] </ref>, and edge detection [16]. A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle [18, 19, 20, 21] to obtain compu-tationally tractable algorithms. <p> The above approximation yields a procedure which is known as mean-field annealing, since it combines the mean-field approximation with the annealing principle <ref> [8, 14] </ref>. The advantage of annealing in the context of deterministic or mean-field annealing is to track solutions from high temperatures where F T is convex, to low temperatures where we can canonically recover a local minimum of H. <p> Most of the work on mean-field annealing has either favored the synchronous update (e.g., [39, 20, 40]) or has at least been indifferent to this distinction (e.g., <ref> [8, 14, 16] </ref>). The synchronous scheme has the advantage of being amenable to a parallel implementation as already proposed by [39].
Reference: [15] <author> J. Zhang, </author> <title> "The mean field theory in EM procedures for blind Markov random fields," </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 27-40, </pages> <year> 1993. </year>
Reference-contexts: Deterministic Annealing has been applied to the traveling salesman problem [7], graph partitioning [8], quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching [9, 10], vector quantization [11, 12], surface reconstruction [13], image restoration <ref> [14, 15] </ref>, and edge detection [16]. A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle [18, 19, 20, 21] to obtain compu-tationally tractable algorithms.
Reference: [16] <author> J. Zerubia and R. Chellappa, </author> <title> "Mean field annealing using compound Gauss-Markov random fields for edge detection and image estimation," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 4, no. 4, </volume> <pages> pp. 703-709, </pages> <year> 1993. </year>
Reference-contexts: Deterministic Annealing has been applied to the traveling salesman problem [7], graph partitioning [8], quadratic assignment and graph T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching [9, 10], vector quantization [11, 12], surface reconstruction [13], image restoration [14, 15], and edge detection <ref> [16] </ref>. A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle [18, 19, 20, 21] to obtain compu-tationally tractable algorithms. <p> Most of the work on mean-field annealing has either favored the synchronous update (e.g., [39, 20, 40]) or has at least been indifferent to this distinction (e.g., <ref> [8, 14, 16] </ref>). The synchronous scheme has the advantage of being amenable to a parallel implementation as already proposed by [39].
Reference: [17] <author> T. Hofmann and J. Buhmann, </author> <title> "Pairwise data clustering by deterministic annealing," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 19, no. 1, </volume> <pages> pp. 1-14, </pages> <year> 1997. </year>
Reference-contexts: Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 2 matching [9, 10], vector quantization [11, 12], surface reconstruction [13], image restoration [14, 15], and edge detection [16]. A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in <ref> [17] </ref>. More specifically, we use mean-field theory as an approximation principle [18, 19, 20, 21] to obtain compu-tationally tractable algorithms. Astonishingly, deterministic annealing algorithms have only been derived independently for highly specific optimization instances despite these widespread research activities.
Reference: [18] <author> C. Peterson and J. Anderson, </author> <title> "A mean field theory learning algorithm for neural networks," </title> <journal> Complex Systems, </journal> <volume> vol. 1, </volume> <pages> pp. 995-1019, </pages> <year> 1987. </year>
Reference-contexts: A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle <ref> [18, 19, 20, 21] </ref> to obtain compu-tationally tractable algorithms. Astonishingly, deterministic annealing algorithms have only been derived independently for highly specific optimization instances despite these widespread research activities. As a major contribution we derive a generic algorithm for the complete class of unconstrained partitioning and clustering cost functions.
Reference: [19] <author> D. Geiger and F. Girosi, </author> <title> "Coupled Markov random fields and mean field theory," </title> <booktitle> in Advances in Neural Information Processing Systems 2, </booktitle> <pages> pp. 660-667, </pages> <year> 1990. </year> <title> T. Hofmann et.al.: Unsupervised Texture Segmentation. </title> <journal> IEEE PAMI, </journal> <note> 1998, to appear. 26 </note>
Reference-contexts: A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle <ref> [18, 19, 20, 21] </ref> to obtain compu-tationally tractable algorithms. Astonishingly, deterministic annealing algorithms have only been derived independently for highly specific optimization instances despite these widespread research activities. As a major contribution we derive a generic algorithm for the complete class of unconstrained partitioning and clustering cost functions.
Reference: [20] <author> G. Bilbro and W. Snyder, </author> <title> "Mean field approximation minimizes relative entropy," </title> <journal> Journal of the Optical Society of America, </journal> <volume> vol. 8, no. 2, </volume> <year> 1989. </year>
Reference-contexts: A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle <ref> [18, 19, 20, 21] </ref> to obtain compu-tationally tractable algorithms. Astonishingly, deterministic annealing algorithms have only been derived independently for highly specific optimization instances despite these widespread research activities. As a major contribution we derive a generic algorithm for the complete class of unconstrained partitioning and clustering cost functions. <p> The approximation quality can be expressed (though not efficiently computed) in terms of the cross entropy, F T (Q) F T (P H ) = 1 T I (QjjP H ), which establishes the equivalence of minimizing the generalized free energy and minimizing the cross entropy to the Gibbs distribution <ref> [20] </ref>. Stationary conditions for (10) yield a system of coupled transcendental, so-called mean-field equations, which can be efficiently solved by a convergent iteration scheme. The following statements which are proven in the appendix summarize the most important results for factorial distributions. <p> Most of the work on mean-field annealing has either favored the synchronous update (e.g., <ref> [39, 20, 40] </ref>) or has at least been indifferent to this distinction (e.g., [8, 14, 16]). The synchronous scheme has the advantage of being amenable to a parallel implementation as already proposed by [39].
Reference: [21] <author> J. Zhang, </author> <title> "The application of the Gibbs-Bogoliubov-Feynman inequality in mean field calculations for Markov random fields," </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 5, no. 7, </volume> <pages> pp. 1208-1214, </pages> <year> 1996. </year>
Reference-contexts: A deterministic annealing approach for clustering and visualization of complete proximity data has been presented in [17]. More specifically, we use mean-field theory as an approximation principle <ref> [18, 19, 20, 21] </ref> to obtain compu-tationally tractable algorithms. Astonishingly, deterministic annealing algorithms have only been derived independently for highly specific optimization instances despite these widespread research activities. As a major contribution we derive a generic algorithm for the complete class of unconstrained partitioning and clustering cost functions.
Reference: [22] <author> S. Geman and D. Geman, </author> <title> "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 6, no. 6, </volume> <pages> pp. 721-741, </pages> <year> 1984. </year>
Reference-contexts: As a major contribution we derive a generic algorithm for the complete class of unconstrained partitioning and clustering cost functions. This includes a general convergence proof for asynchronous update schemes and a clarification of the intrinsic relationship between mean-field annealing and simulated annealing by Monte Carlo Gibbs sampling <ref> [22] </ref>. 2 Image Representation and Proximity Evaluation The differential structure of an image I (~x) is completely extracted by convolving the image with the Gaussian filter family [23]. <p> For a given site visitation schedule the Gibbs sampler <ref> [22] </ref> is defined by the finite transition probabilities S t (s i (M; ~e -) ; M) = P K ; where g i= H (s i (M; ~e -)) (8) and i = v (t). <p> The basic idea of annealing is to use Monte Carlo sampling, but to gradually lower the temperature T (t), on which the transition probabilities depend. It has been proven <ref> [22] </ref>, that for a logarithmic annealing schedule T (t) = c=(1 + log t) the Gibbs sampler converges in probability to the uniform distribution on the global minima of H. <p> for all according to (13) update q (i)- for all according to (13) UNTIL converged T T; 0 &lt; &lt; 1 the cost function into a sum of clique potentials and recalculate at each step all potentials of cliques to which site ~x i with i = v (t) belongs <ref> [22] </ref>. This procedure is not efficient for the normalized clustering objective functions, since the assignments enter in the denominator. <p> Four new cost functions have been derived from the principles of scale- and shift-invariance. These objective functions as well as the unnormalized graph partitioning cost function proposed in <ref> [22] </ref> have been empirically compared on a large dataset of textured images to evaluate their advantages and disadvantages. The new objective functions have been demonstrated to be substantially superior compared to the unnor-malized objective function and the GFC-algorithm.
Reference: [23] <author> H. Romeny, ed., </author> <title> Geometry-Driven Diffusion in Computer Vision. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: proof for asynchronous update schemes and a clarification of the intrinsic relationship between mean-field annealing and simulated annealing by Monte Carlo Gibbs sampling [22]. 2 Image Representation and Proximity Evaluation The differential structure of an image I (~x) is completely extracted by convolving the image with the Gaussian filter family <ref> [23] </ref>. In many applications, however, it is convenient to use filters, which are tuned to the features of interest, e.g., a particular spatial frequency ~ k. This tuning operation can be formalized [24] and leads in the case of frequency tuning to the family of complex Gabor filters [23] G (~x; <p> filter family <ref> [23] </ref>. In many applications, however, it is convenient to use filters, which are tuned to the features of interest, e.g., a particular spatial frequency ~ k. This tuning operation can be formalized [24] and leads in the case of frequency tuning to the family of complex Gabor filters [23] G (~x; ; ~ k) = 2 e i ~ k t ~x ; (1) where denotes a scale parameter depending on k. Gabor filters essentially perform a local Fourier analysis and are optimally localized in the sense of the fundamental uncertainty relation [25].
Reference: [24] <author> L. Florack, B. t. Haar Romeny, J. Koenderink, and M. Viergever, </author> <title> "Families of tuned scale-space kernels," </title> <booktitle> in Proceedings of the 2nd European Conference on Computer Vision (G. </booktitle> <editor> Sandini, ed.), </editor> <booktitle> Lecture Notes in Computer Science 588, </booktitle> <address> (Berlin), </address> <pages> pp. 19-23, </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: In many applications, however, it is convenient to use filters, which are tuned to the features of interest, e.g., a particular spatial frequency ~ k. This tuning operation can be formalized <ref> [24] </ref> and leads in the case of frequency tuning to the family of complex Gabor filters [23] G (~x; ; ~ k) = 2 e i ~ k t ~x ; (1) where denotes a scale parameter depending on k.
Reference: [25] <author> J. Daugman, </author> <title> "Uncertainty relation for resolution in space, spatial frequency, and ori entation optimized by two-dimensional visual cortical filters," </title> <journal> Journal of the Optical Society Am. A, </journal> <volume> vol. 2, no. 7, </volume> <pages> pp. 1160-1169, </pages> <year> 1985. </year>
Reference-contexts: Gabor filters essentially perform a local Fourier analysis and are optimally localized in the sense of the fundamental uncertainty relation <ref> [25] </ref>. In addition to the theoretical justification in a scale space framework, Gabor filters have empirically proven to possess excellent discrimination properties for a wide range of textures [26, 27].
Reference: [26] <author> A. Bovik, M. Clark, and W. Geisler, </author> <title> "Multichannel texture analysis using localized spatial filters," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 12, </volume> <pages> pp. 55-73, </pages> <year> 1990. </year>
Reference-contexts: Gabor filters essentially perform a local Fourier analysis and are optimally localized in the sense of the fundamental uncertainty relation [25]. In addition to the theoretical justification in a scale space framework, Gabor filters have empirically proven to possess excellent discrimination properties for a wide range of textures <ref> [26, 27] </ref>. The multi-scale representation of images with a Gabor filter bank is especially useful for unsupervised texture segmentation, where little is known a priori about the characteristic frequencies of occurring textures.
Reference: [27] <author> I. Fogel and D. Sagi, </author> <title> "Gabor filters as texture discriminators," </title> <journal> Biological Cybernetics, </journal> <volume> vol. 61, </volume> <pages> pp. 103-113, </pages> <year> 1989. </year>
Reference-contexts: Gabor filters essentially perform a local Fourier analysis and are optimally localized in the sense of the fundamental uncertainty relation [25]. In addition to the theoretical justification in a scale space framework, Gabor filters have empirically proven to possess excellent discrimination properties for a wide range of textures <ref> [26, 27] </ref>. The multi-scale representation of images with a Gabor filter bank is especially useful for unsupervised texture segmentation, where little is known a priori about the characteristic frequencies of occurring textures.
Reference: [28] <author> B. W. Lindgren, </author> <title> Statistical Theory. </title> <publisher> MacMillan Publishing, </publisher> <editor> third ed., </editor> <year> 1976. </year>
Reference-contexts: We apply a statistical test d based on the distribution of coefficients in either window, i.e., D (r) Several non-parametric test statistics are available for the two-sample problem <ref> [28] </ref>. We have examined the performance of the mutual information [4], the Kolmogorov-Smirnov statistic [3, 29], tests of the Cramer/von Mises type, and the 2 -statistics in detail [30, 31]. Empirically, the 2 test and the mutual information test have been shown to yield the best results.
Reference: [29] <author> T. Hofmann, J. Puzicha, and J. Buhmann, </author> <title> "Unsupervised segmentation of textured images by pairwise data clustering," </title> <booktitle> in Proceedings of the IEEE International Conference on Image Processing, </booktitle> <pages> pp. III: 137-140, </pages> <year> 1996. </year>
Reference-contexts: We apply a statistical test d based on the distribution of coefficients in either window, i.e., D (r) Several non-parametric test statistics are available for the two-sample problem [28]. We have examined the performance of the mutual information [4], the Kolmogorov-Smirnov statistic <ref> [3, 29] </ref>, tests of the Cramer/von Mises type, and the 2 -statistics in detail [30, 31]. Empirically, the 2 test and the mutual information test have been shown to yield the best results. <p> We have investigated Minkowski norms D ij = P (r) p 1=p ; including the limiting case of the maximum norm (p = 1) as utilized in <ref> [29] </ref>. The Minkowski norm for small p is less sensitive to differences in single channels and the choice of p = 1 empirically showed the best performance. Moreover, p = 1 is the natural choice for independent channel distributions.
Reference: [30] <author> T. Hofmann, J. Puzicha, and J. Buhmann, </author> <title> "A deterministic annealing framework for unsupervised texture segmentation," </title> <type> Tech. Rep. </type> <institution> IAI-TR-96-2, Institut fur Informatik III, </institution> <year> 1996. </year>
Reference-contexts: We have examined the performance of the mutual information [4], the Kolmogorov-Smirnov statistic [3, 29], tests of the Cramer/von Mises type, and the 2 -statistics in detail <ref> [30, 31] </ref>. Empirically, the 2 test and the mutual information test have been shown to yield the best results. <p> Stationary conditions for (10) yield a system of coupled transcendental, so-called mean-field equations, which can be efficiently solved by a convergent iteration scheme. The following statements which are proven in the appendix summarize the most important results for factorial distributions. A more detailed presentation can be found in <ref> [30, 38] </ref>. T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 10 Theorem 1 Let H be an arbitrary partitioning cost function, H : M ! IR. <p> General bounds as well as higher order corrections of the approximation error can be obtained by a Taylor expansion around hMi Q . The technical details can be found in <ref> [30] </ref>. T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 12 5 Results Several questions are empirically investigated in the following subsections. Sect. 5.1 addresses data extraction and modeling issues, including performance studies for a large database of textured images with known ground truth.
Reference: [31] <author> J. Puzicha, T. Hofmann, and J. Buhmann, </author> <title> "Non-parametric similarity measures for unsupervised texture segmentation and image retrieval," </title> <booktitle> in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'97), </booktitle> <pages> pp. 267-272, </pages> <year> 1997. </year> <title> T. Hofmann et.al.: Unsupervised Texture Segmentation. </title> <journal> IEEE PAMI, </journal> <note> 1998, to appear. 27 </note>
Reference-contexts: We have examined the performance of the mutual information [4], the Kolmogorov-Smirnov statistic [3, 29], tests of the Cramer/von Mises type, and the 2 -statistics in detail <ref> [30, 31] </ref>. Empirically, the 2 test and the mutual information test have been shown to yield the best results.
Reference: [32] <author> T.-S. Lee, D. Mumford, and A. Yuille, </author> <title> "Texture segmentation by minimizing vector valued energy-functionals: The coupled membrane model," </title> <booktitle> in Proceedings of the Second European Conference on Computer Vision (ECCV) (G. Sandini, </booktitle> <publisher> ed.), </publisher> <pages> pp. 165-183, </pages> <year> 1992. </year>
Reference-contexts: Since additional hard constraints restrict the development of efficient optimization algorithms and may lead to forbiddingly heavy computational load <ref> [32] </ref>, we enforce these constraints in a separate post-processing stage which follows the clustering procedure and determines the closest valid partitioning by eliminating components and smoothing borders, if necessary.
Reference: [33] <author> S. Kirkpatrick, C. Gelatt, and M. Vecchi, </author> <title> "Optimization by simulated annealing," </title> <journal> Science, </journal> <volume> vol. 220, no. 4598, </volume> <pages> pp. 671-680, </pages> <year> 1983. </year>
Reference-contexts: Alternatively, the graph definition could be extended to cover the reflexive case to get a true identity. T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 8 4 Clustering Algorithms In seminal papers Kirkpatrick et al. <ref> [33] </ref> and, independently, Cerny [34] have proposed the stochastic optimization strategy Simulated Annealing. Simulated Annealing determines solutions to combinatorial optimization problems by a random search, which is formally modeled by an inhomogeneous discrete-time Markov chain.
Reference: [34] <author> V. Cerny, </author> <title> "Thermodynamical approach to the travelling salesman problem," </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> vol. 45, </volume> <pages> pp. 41-51, </pages> <year> 1985. </year>
Reference-contexts: Alternatively, the graph definition could be extended to cover the reflexive case to get a true identity. T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 8 4 Clustering Algorithms In seminal papers Kirkpatrick et al. [33] and, independently, Cerny <ref> [34] </ref> have proposed the stochastic optimization strategy Simulated Annealing. Simulated Annealing determines solutions to combinatorial optimization problems by a random search, which is formally modeled by an inhomogeneous discrete-time Markov chain.
Reference: [35] <author> E. </author> <title> Jaynes, </title> <journal> "Information theory and statistical mechanics," Physical Review, </journal> <volume> vol. 106, no. 4, </volume> <pages> pp. 620-630, </pages> <year> 1957. </year>
Reference-contexts: An important extremal property of the Gibbs distribution is the fact, that it maximizes the entropy for fixed expected costs, c.f. <ref> [35] </ref>.
Reference: [36] <author> J. Besag, </author> <title> "On the statistical analysis of dirty pictures," </title> <journal> Journal of the Royal Statis tical Society, Series B, </journal> <volume> vol. 48, </volume> <pages> pp. 25-37, </pages> <year> 1986. </year>
Reference-contexts: Of course, in practice annealing schedules always use a decay rate for T , which is too fast to guarantee convergence to a global minimum. For the zero temperature limit a deterministic greedy optimization algorithm known as Iterative Conditional Mode (ICM) <ref> [36] </ref> is obtained. While the general convergence results for simulated annealing [37] demonstrate the universality of this optimization principle, the inherently slow convergence of stochastic techniques compared to deterministic algorithms is perceived as a major disadvantage.
Reference: [37] <author> B. Hajek, </author> <title> "Cooling schedules for optimal annealing," Mathematics of Operation Re search, </title> <journal> vol. </journal> <volume> 13, </volume> <pages> pp. 311-324, </pages> <year> 1988. </year>
Reference-contexts: For the zero temperature limit a deterministic greedy optimization algorithm known as Iterative Conditional Mode (ICM) [36] is obtained. While the general convergence results for simulated annealing <ref> [37] </ref> demonstrate the universality of this optimization principle, the inherently slow convergence of stochastic techniques compared to deterministic algorithms is perceived as a major disadvantage. Therefore, we advocate to use a different, purely deterministic approach known as deterministic annealing [11].
Reference: [38] <author> J. Puzicha, T. Hofmann, and J. Buhmann, </author> <title> "Deterministic annealing: Fast physical heuristics for real time optimization of large systems.," </title> <booktitle> in Proceedings of the 15th IMACS World Congress on Scientific Computation, Modelling and Applied Mathematics, </booktitle> <year> 1997. </year>
Reference-contexts: Stationary conditions for (10) yield a system of coupled transcendental, so-called mean-field equations, which can be efficiently solved by a convergent iteration scheme. The following statements which are proven in the appendix summarize the most important results for factorial distributions. A more detailed presentation can be found in <ref> [30, 38] </ref>. T. Hofmann et.al.: Unsupervised Texture Segmentation. IEEE PAMI, 1998, to appear. 10 Theorem 1 Let H be an arbitrary partitioning cost function, H : M ! IR.
Reference: [39] <author> J. Hopfield and D. Tank, </author> <title> "Neural computation of decisions in optimisation problems," </title> <journal> Biological Cybernetics, </journal> <volume> vol. 52, </volume> <pages> pp. 141-152, </pages> <year> 1985. </year>
Reference-contexts: Most of the work on mean-field annealing has either favored the synchronous update (e.g., <ref> [39, 20, 40] </ref>) or has at least been indifferent to this distinction (e.g., [8, 14, 16]). The synchronous scheme has the advantage of being amenable to a parallel implementation as already proposed by [39]. <p> Most of the work on mean-field annealing has either favored the synchronous update (e.g., [39, 20, 40]) or has at least been indifferent to this distinction (e.g., [8, 14, 16]). The synchronous scheme has the advantage of being amenable to a parallel implementation as already proposed by <ref> [39] </ref>. On the other hand it has commonly been observed that synchronous updating may lead to instabilities, a fact that has recently been investigated more systematically for a simple Ising system based on the contraction mapping theorem [40].
Reference: [40] <author> J. Zhang, </author> <title> "The convergence of mean field procedures for MRF's," </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 5, no. 12, </volume> <pages> pp. 1662-1665, </pages> <year> 1991. </year>
Reference-contexts: Most of the work on mean-field annealing has either favored the synchronous update (e.g., <ref> [39, 20, 40] </ref>) or has at least been indifferent to this distinction (e.g., [8, 14, 16]). The synchronous scheme has the advantage of being amenable to a parallel implementation as already proposed by [39]. <p> On the other hand it has commonly been observed that synchronous updating may lead to instabilities, a fact that has recently been investigated more systematically for a simple Ising system based on the contraction mapping theorem <ref> [40] </ref>. The asynchronous update scheme in contrast is guaranteed to converge for arbitrary partitioning objective functions. Corollary 2 establishes a tight relationship between the quantities g i= H (s i (M; ~e - )) involved in implementing the Gibbs sampler in (9) and the mean-field equations.
Reference: [41] <author> P. Brodatz, </author> <title> Textures: A Photographic Album for Artists and Designers. </title> <address> New York: </address> <publisher> Dover Publications, </publisher> <year> 1966. </year>
Reference-contexts: Sect. 5.3 shows results on representative examples of real-world images. 5.1 Texture Segmentation by Sparse Clustering To empirically test the segmentation algorithms on a wide range of textures we selected a representative set of 86 micro-patterns from the Brodatz texture album <ref> [41] </ref>. 5 A database of random mixtures (512 fi 512 pixels each) containing 100 entities of five textures each (as depicted in Fig. 1 (a) and Fig. 2 (a)) was constructed from this collection of Brodatz textures.
Reference: [42] <author> B. Manjunath and W. Ma, </author> <title> "Texture features for browsing and retrieval of image data," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <year> 1996. </year>
Reference-contexts: To compare the 2 -statistics to other state-of-the-art dissimilarity measures based on a vector space representation, we have implemented the parametric Weighted Mean Variance (WMV) measure proposed in <ref> [42] </ref>. For empirical means r i ; r j and standard deviations r i ; r distance is defined by D (r) j r i r j j j r i r j j j ( r )j ; where () denotes the standard deviation of the respective entity. <p> As reported in <ref> [42] </ref> this measure based on a Gabor filter image representation outperforms several other parametric models and was chosen because of its competitiveness. Table 1 summarizes the obtained mean and median values for all cost functions under consideration evaluated on the database of mixture images with five textures each.
Reference: [43] <author> R. Navarro, O. Nestares, J. Portilla, and A. Tabernero, </author> <title> "Several experiments on texture analysis, coding and synthesis by Gabor wavelets," </title> <type> Tech. Rep. 52, </type> <institution> Instituto de Optica Daza de Valdes de Madrid, </institution> <year> 1994. </year>
Reference-contexts: As can be seen in Fig. 2 the misclassified sites mainly correspond to errors at texture borders, which contain more then one texture. Misclassifications at the boundary are unavoidable due to the support of Gabor filters <ref> [43] </ref>, as statistics from different textures are mixed. The post-processing step improves the segmentations by a significant noise reduction. T. Hofmann et.al.: Unsupervised Texture Segmentation.
Reference: [44] <author> T. Hofmann, J. Puzicha, and J. Buhmann, </author> <title> "An optimization approach to unsuper vised hierarchical texture segmentation," </title> <booktitle> in Proceedings of the IEEE International Conference on Image Processing (ICIP'97), </booktitle> <pages> pp. 213-217, </pages> <year> 1997. </year>
Reference-contexts: We believe a hierarchical clustering model to be more appropriate for many purposes and have extended our work in that direction in more recent publications <ref> [44] </ref>. 5.2 Mean-field Approximation and Gibbs Sampling Another important question is concerned with the quality of deterministic annealing algorithms compared to stochastic procedures.
Reference: [45] <author> J. Puzicha and J. Buhmann, </author> <title> "Multiscale annealing for real-time unsupervised texture segmentation," </title> <type> Tech. Rep. </type> <note> IAI-97-4, Institut fur Informatik III (a short version appeared in: Proc. ICCV'98, pp. 267-273), 1997. </note> <author> T. Hofmann et.al.: </author> <title> Unsupervised Texture Segmentation. </title> <journal> IEEE PAMI, </journal> <note> 1998, to appear. 28 </note>
Reference-contexts: In a follow up study both, deterministic annealing and ICM, have been substantially accelerated using the concept of multiscale optimization. The resulting optimization times are in the range of less then 5 seconds 8 for the examples shown here without loss in performance quality <ref> [45] </ref>. In Fig. 9 deterministic annealing is compared with the ICM algorithm and the Gibbs 8 For deterministic annealing on a SUN UltraSparc, less then 2 seconds for ICM. The multiscale annealing scheme is not directly applicable for stochastic Gibbs sampling. T. Hofmann et.al.: Unsupervised Texture Segmentation.
Reference: [46] <author> J. Buhmann, W. Burgard, A. Cremers, D. Fox, T. Hofmann, F. Schneider, I. Strikos, and S. Thrun, </author> <title> "The mobile robot RHINO," </title> <journal> AI Magazin, </journal> <volume> vol. 16, no. 1, </volume> <year> 1995. </year>
Reference-contexts: The image partitioning is visualized in (d) - (g). in autonomous robotics and the presented algorithms have been implemented on the autonomous robot RHINO <ref> [46] </ref>. An example image of a typical office environment is presented in Fig. 12. The achieved segmentation is both visually and semantically satisfying.
References-found: 46

