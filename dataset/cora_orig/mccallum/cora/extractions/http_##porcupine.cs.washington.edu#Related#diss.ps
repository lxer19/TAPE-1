URL: http://porcupine.cs.washington.edu/Related/diss.ps
Refering-URL: http://porcupine.cs.washington.edu/Related/
Root-URL: http://www.cs.washington.edu
Title: ProCons Investigation of Distributed Consensus Algorithms  
Author: Tor E. Faegri 
Date: June 6, 1994  
Affiliation: University of Glasgow  
Abstract-found: 0
Intro-found: 1
Reference: [ABND90] <author> H. Attiya, A. Bar-Noy, and D Dolev. </author> <title> Sharing memory robustly in message passing systems. </title> <booktitle> In Proceedings of the Ninth Annual ACM Symphosium on Principles of Distributed Computing, </booktitle> <pages> pages 363-382, </pages> <address> New York, 1990. </address> <publisher> ACM, ACM Press. </publisher>
Reference-contexts: Number of tolerable failures. A consensus algorithm will usually have a maximum number of faults it can tolerate, while still being able to reach a correct consensus. For example, in a message passing system, using a technique called altruism <ref> [ABND90] </ref> in combination with quorum consensus (majority voting), where fewer than half the processing element population are allowed to fail, consensus can be guaranteed. Other techniques can be applied to increase the number of tolerable failures, e.g. message authentication. Algorithm correctness.
Reference: [BM93] <author> Ozalp Babaoglu and Keith Marzullo. </author> <title> Consistent global states of distributed systems: Fundamental concepts and mechanisms. In Sape Mullender, editor, Distributed Systems, </title> <publisher> ACM Press Frontier Series, </publisher> <pages> chapter 4, pages 55-96. </pages> <publisher> Addison-Wesley, </publisher> <address> second edition, </address> <year> 1993. </year>
Reference-contexts: Obviously, no processing element in the system will ever have direct access to the current global state, because message delays and uncertainties with respect to speed of the processing elements make any remote observation obsolete, incomplete or inconsistent just after it has been made <ref> [BM93] </ref>. For the algorithm to make any conclusions about the global state, reasoning on the currently available data must be performed. Each processing element must, using the currently locally available information (messages received, expected messages 19 not received), construct what it believes is the global state.
Reference: [Boo91] <author> Grady Booch. </author> <title> Object-Oriented Design with Applications. </title> <publisher> Benjamin Cummings, </publisher> <year> 1991. </year>
Reference-contexts: The notation for class and object diagrams is the one presented in <ref> [Boo91] </ref>. A high level conceptual illustration is shown in figure 5.1. The system makes it easy to implement and simulate other consensus algorithms.
Reference: [BT89] <author> Dimitri P. Bertsekas and John N. Tsitsiklis. </author> <title> Parallel and Distributed Computation. </title> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: Different solutions to this problem have been proposed, e.g. algorithms that assume certain network structures, and others that are based on tokens passed among the PE population, recording the states at each. The reader might want to look up chapter 8.1 of <ref> [BT89] </ref> for a thorough description. 22 A solution. Under the assumption that the process of sending and receiving a message is atomic, a simple solution to this problem is simply to count the number of messages in transit.
Reference: [CF88] <author> R. Cole and Clare Foxcroft. </author> <title> An experiment in clock syncronisation. </title> <journal> The Computer Journal, </journal> <volume> 31(6) </volume> <pages> 496-502, </pages> <year> 1988. </year>
Reference-contexts: There are several alternative approaches to the problem. One of them is described below. Synchronizing the local clocks. In system where message delays can be expected to have an upper bound, a clock source can be used <ref> [CF88] </ref>.
Reference: [CGK88] <author> I. Cidon, I. Gopal, and S. Kutten. </author> <title> New models and algorithms for future networks. </title> <booktitle> In Proceedings of the Seventh Annual ACM Symphosium on Principles of Distributed Computing, </booktitle> <pages> pages 75-89, </pages> <address> Toronto,Ontario,Canada, </address> <month> August </month> <year> 1988. </year> <title> ACM, </title> <publisher> ACM Press. </publisher>
Reference-contexts: This has led to a search for new and better ways to exploit these new networks. A fairly easily readable paper on this issue is <ref> [CGK88] </ref>.
Reference: [DDS87] <author> D. Dolev, C. Dwork, and L. Stockmeyer. </author> <title> On the minimal syncronism needed for distributed consensus. </title> <journal> Journal of the ACM, </journal> <volume> 34(1) </volume> <pages> 77-97, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: The communication system only allows a node to send a message to one node at a time. Broadcast messages. The communication system allows a process to send a message to all the other processes in one operation. 1 See [LMF88] 2 But still reasonable in most cases. 3 See <ref> [DDS87] </ref> for a more detailed categorization 18 Bounded message delay. If the system can guarantee that a message sent into the network will arrive with a finite number of time steps, the message delay is said to be bounded. Unbounded message delay. <p> This also leads to another problem, different processing elements constructing different global states. The possibility of reaching agreement on a global state, is dependent on the system model, see section 3.2. It is also dependent on how many failures, and which types of failures the system should handle. In <ref> [DDS87] </ref> it is shown that deterministic consensus is possible in these three system models: 1. PEs are synchronous, and there is a maximum message delay ffi; 2.
Reference: [DIM91] <author> S. Dolev, A. Israeli, and S Moran. </author> <title> Uniform dynamic self-stabilizing leader election. </title> <booktitle> In Lecture Notes in Computer Science, Distributed Algorithms, </booktitle> <pages> pages 167-179, </pages> <address> Delphi, Greeze, </address> <month> October </month> <year> 1991. </year> <note> Springer-Verlag. </note>
Reference-contexts: Each algorithm is usually tailored for a specific system model, and makes use the different services available to them. The algorithm presented below is very simple, but will nevertheless do the job quite efficiently. Other, more complex algorithms for leader election are presented in <ref> [DIM91] </ref> and [HT88]. Algorithm outline. This algorithm is found in [Mat91]. The algorithm is fairly simple, and is based on the fact that every processing element has a unique id, and that there is a total ordering of these ids.
Reference: [Ezh88] <author> P.D. Ezhilchelvan. </author> <title> With less malicious byzantine generals: Agreement algorithms under value faults. </title> <type> Technical Report 252, </type> <institution> University of Newcastle upon Tyne, </institution> <month> January </month> <year> 1988. </year>
Reference-contexts: Arbitrary, Malicious or Byzantine. The processing element fails by acting in an arbitrary manner. It might even act maliciously, (known as being Byzantine, after the Byzantine generals problem), in which case it can try to betray other processing elements. See <ref> [Ezh88] </ref> for more details. This is the most general failure models, and allows for all possible failures at a PE. General Omission. The processing element occasionally omits to send and/or receive messages. Receive Omission. Processing element occasionally omits to receive messages. Send Omission. Processing element occasionally omits to send messages. <p> If some assumptions about the "maliciousness" of the processing elements are made, and a authentication mechanism is used to verify the sending processing element, the result from the report by <ref> [Ezh88] </ref> suggests that a consensus is possible when only two processing entities are non-faulty, i.e. are acting non-maliciously. Applications. A Byzantine agreement algorithm is strictly speaking necessary in any fault tolerant system.
Reference: [FLM85] <author> M. Fisher, N. Lynch, and M. Merritt. </author> <title> Impossibility of distributed consensus with one faulty process. </title> <journal> Journal of the ACM, </journal> <volume> 32(2) </volume> <pages> 374-382, </pages> <month> April </month> <year> 1985. </year> <month> 48 </month>
Reference-contexts: Secondly, if the node really is crashed, or the communication link has failed, that fact should become part of the global state, but if either are just slow, they should probably be given a little less to do. This simple fact forms the basis for the proof found in <ref> [FLM85] </ref>, which states that no processor failures can be tolerated in a truly asyncrhonous system if we want to garantee a consensus using a deterministic algorithm. <p> It is indeed a large and complex area within computing, and a large number of research publications are being published, but by referring to the material referenced in the survey, the reader should get enough pointers to further investigations. In particular, the articles <ref> [FLM85] </ref> and [TS92] are specially recommended as introductory reading. 26 Chapter 4 User Guide This chapter will explain how the algorithm visualization tool developed for the ProCons project can be used.
Reference: [Gra88] <author> Jim Gray. </author> <title> The cost of messages. </title> <booktitle> In Proceedings of the Seventh Annual ACM Symphosium on Principles of Distributed Computing, </booktitle> <pages> pages 1-7, </pages> <address> Toronto,Ontario,Canada, </address> <month> August </month> <year> 1988. </year> <title> ACM, </title> <publisher> ACM Press. </publisher>
Reference-contexts: So it is quite obvious that even in loosely coupled message passing systems, there are big differences. The difference might imply that different algorithms should be used in the different environments. In <ref> [Gra88] </ref> Jim Gray measures the cost of sending messages in number of machine instructions per message. More precicely: The cost of sending a message is measured in the number of instructions needed to generate the bit pattern on the physical communication link.
Reference: [Har92] <author> Samuel P Harbison. </author> <title> Modula-3. </title> <publisher> Prentice-Hall, </publisher> <year> 1992. </year>
Reference-contexts: Implementing a new algorithms requires the following: 1. Some knowledge of the software system. In particular an understanding of the message passing mechanism, and the interface to the simulation control is vital. 2. Knowledge of Modula-3. See <ref> [Har92] </ref> for a good tutorial of the language. 3. Thorough knowledge of the algorithm being implemented. It is easy to overlook details in a specification of an algorithm, something that could lead to extra work needed in the implementation. Message passing mechanism. <p> send (self : T; msg : message.T; t : Time.Seconds) : BOOLEAN; The procedure send hence accepts a message and a timeout value as input parameters, and returns the outcome of the message transfer as a TRUE or FALSE value, meaning success (ACK received) and failure (timeout) respectively. 1 See <ref> [Har92] </ref> for description. 31 PROCEDURE receive (self : T) : message.T; The procedure receive hence accepts no parameters, and returns a reference to a message.T instance or NIL if a message was available or not available respectively.
Reference: [HT88] <author> M. Huang and S. Teng. </author> <title> Secure and verifiable schemes for election and general distributed computing problems. </title> <booktitle> In Proceedings of the Seventh Annual ACM Symphosium on Principles of Distributed Computing, </booktitle> <pages> pages 182-196, </pages> <address> Toronto,Ontario,Canada, </address> <month> August </month> <year> 1988. </year> <title> ACM, </title> <publisher> ACM Press. </publisher>
Reference-contexts: Each algorithm is usually tailored for a specific system model, and makes use the different services available to them. The algorithm presented below is very simple, but will nevertheless do the job quite efficiently. Other, more complex algorithms for leader election are presented in [DIM91] and <ref> [HT88] </ref>. Algorithm outline. This algorithm is found in [Mat91]. The algorithm is fairly simple, and is based on the fact that every processing element has a unique id, and that there is a total ordering of these ids.
Reference: [HT93] <author> Vassos Hadzilacos and Sam Toueg. </author> <title> Fault-tolerant broadcasts and related problems. In Sape Mullender, editor, Distributed Systems, </title> <publisher> ACM Press Frontier Series, </publisher> <pages> chapter 5, pages 97-146. </pages> <publisher> Addison-Wesley, </publisher> <address> second edition, </address> <year> 1993. </year>
Reference-contexts: There exist other kinds of algorithms which rely on probabilities and randomization that can offer consensus in these cases, but these were outside the scope of this survey. The reader might want to refer to <ref> [HT93] </ref> for some more information on this. Fortunately, by making some small "optimistic 2 " assumptions about e.g. message delays, deterministic agreement protocols can be derived that can tolerate failures.
Reference: [Jai91] <author> Raj Jain. </author> <title> The Art of Computer Systems Performance Analysis. </title> <publisher> Wiley Professional Computing. Wiley, </publisher> <year> 1991. </year>
Reference-contexts: Lastly, fault tolerant algorithms should take into account the fairly high failure rate in typical WANs | the least reliable component in a distributed system. 4 This section is partly based on material found in <ref> [Jai91] </ref> 25 The message passing paradigm. Some algorithms depend heavily on the use of broadcasting. This may involve several rounds of distributing messages to each PE in the network.
Reference: [LMF88] <author> N. Lynch, Y. Mansour, </author> <title> and A Fekete. The data link layer: Two impossibility results. </title> <booktitle> In Proceedings of the Seventh Annual ACM Symphosium on Principles of Distributed Computing, </booktitle> <pages> pages 149-170, </pages> <address> Toronto,Ontario,Canada, </address> <month> August </month> <year> 1988. </year> <title> ACM, </title> <publisher> ACM Press. </publisher>
Reference-contexts: Point-to-point messages. The communication system only allows a node to send a message to one node at a time. Broadcast messages. The communication system allows a process to send a message to all the other processes in one operation. 1 See <ref> [LMF88] </ref> 2 But still reasonable in most cases. 3 See [DDS87] for a more detailed categorization 18 Bounded message delay. If the system can guarantee that a message sent into the network will arrive with a finite number of time steps, the message delay is said to be bounded.
Reference: [LSP82] <author> L. Lamport, R. Shostak, and M. Pease. </author> <title> The byzantine generals problem. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 4(3) </volume> <pages> 382-401, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: Assumptions. There is no consensus algorithm that can withstand failures from arbitrarily many processing elements. Even a Byzantine agreement algorithm has a limit to how many failures it can handle. Lamport, Shostak and Pease showed in <ref> [LSP82] </ref> that if more than a third of the processing elements acted maliciously, no consensus algorithm was able to guarantee consensus among the "honest" processing elements. <p> Algorithms. Most algorithms that solve the Byzantine Generals problem rely on broadcasting messages in several rounds. One algorithm for solving this problem is given in <ref> [LSP82] </ref>. This algorithm uses message broadcasts in several rounds, to achieve consensus among the PEs. The algorithm is rather complex, and I leave it to the reader to convince themselves about its correctness. 23 3.4.4 Leader Election Background.
Reference: [Mat91] <author> Friedemann Mattern. </author> <title> Distributed control algorithms (selected topics). </title> <type> Technical Report A04/91, </type> <institution> Universitat des Saarlandes, Im Stadtwald 36, D 6600 Saarbrucken, Fed.Rep.Germany, </institution> <year> 1991. </year>
Reference-contexts: This can be done by keeping track of the number of messages sent and received for every processing element in the system. This has to be done in two rounds, in order to catch up messages being sent after the first counting. This method is described in detail in <ref> [Mat91] </ref> chapter 3.1. 3.4.3 Byzantine Generals Problem Background. This is one of the most widely discussed problems within distributed computing. It is probably due to the fact that once this problem is solved, then so are all other consensus problems. <p> The algorithm presented below is very simple, but will nevertheless do the job quite efficiently. Other, more complex algorithms for leader election are presented in [DIM91] and [HT88]. Algorithm outline. This algorithm is found in <ref> [Mat91] </ref>. The algorithm is fairly simple, and is based on the fact that every processing element has a unique id, and that there is a total ordering of these ids. The processing element with the highest id value is elected as the leader.
Reference: [TS92] <author> John Turek and Dennis Shasha. </author> <title> The many faces of consensus in distributed systems. </title> <booktitle> Computer, </booktitle> <pages> pages 8-17, </pages> <month> June </month> <year> 1992. </year> <month> 49 </month>
Reference-contexts: Applications. A Byzantine agreement algorithm is strictly speaking necessary in any fault tolerant system. To diagnose a probably faulty system, no assumptions whatsoever can be made on the behaviour of the processing elements. The Byzantine failure model was originally used for modelling of hardware failures in avionics sensors <ref> [TS92] </ref>, but it has gained a lot of attention for its applicability to software failures as well. Algorithms. Most algorithms that solve the Byzantine Generals problem rely on broadcasting messages in several rounds. One algorithm for solving this problem is given in [LSP82]. <p> It is indeed a large and complex area within computing, and a large number of research publications are being published, but by referring to the material referenced in the survey, the reader should get enough pointers to further investigations. In particular, the articles [FLM85] and <ref> [TS92] </ref> are specially recommended as introductory reading. 26 Chapter 4 User Guide This chapter will explain how the algorithm visualization tool developed for the ProCons project can be used.
References-found: 19

