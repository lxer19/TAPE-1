URL: http://cuiwww.unige.ch/~chopard/Genetics/mouloud.ps
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Genetic Programming Methodology, Parallelization and Applications  par  
Author: Dpartement d informatique Prof. P. Zanella Dr. B. Chopard THSE Mouloud OUSSAIDNE de Tizi-Ouzou (Kabylie), Algrie Thse N o GENVE 
Date: 1997  
Affiliation: UNIVERSIT DE GENVE FACULT DES SCIENCES  prsente la Facult des sciences de lUniversit de Genve pour obtenir le grade de Docteur s sciences mention Informatique  Atelier de reproduction de la section de physique  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> Baker, J. </author> <year> 1985. </year> <title> Adaptative Selection Methods for Genetic Algorithms. </title> <booktitle> Proc. 1st ICGA, </booktitle> <month> June </month> <year> 1985. </year>
Reference-contexts: However, the most serious objection to ranking is that it violates the schema theorem: the average of the rank of the individuals that sample a particular schemata does not correspond to the rank of the schemas average fitness [14]. - Baker <ref> [1] </ref> used a linear curve for the allocation of trials.
Reference: [2] <author> Davis, L. </author> <year> 1991. </year> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: By mimicking this process, genetic algorithms are able to evolve solutions to real world problems, if they have been suitably encoded. The basic principles of GAs were first laid down rigourously by Holland [5], and are well described in many texts ( <ref> [2] </ref> , [4] and [10] ). In nature, individuals in a population compete with each other for resources. Also, members of the same species often compete to attract a mate. Those individuals which are most succesful in surviving and attracting mates will have relatively large number of offspring.
Reference: [3] <author> De Jong, K. </author> <year> 1975. </year> <title> The Analysis and behaviour of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1975. </year>
Reference-contexts: DeJong <ref> [3] </ref> investigated the effectiveness of multiple-point crossover, and concluded that 2-point crossover gives an improvement, but that adding further crossover points reduces the performance of the GA. In fact, the problem with adding additional crossover points is that building blocks are more likely to be disrupted. <p> Convergence is the progression towards increasing uniformity. A gene is said to have converged when 95% of the population share the same value <ref> [3] </ref>. The population is said to have converged when all of the genes have converged. As the population converges, the average fitness will approach that of the best individual. 1.9 Parent selection techniques Parent selection is the task of allocating reproductive opportunities to each individual.
Reference: [4] <author> Goldberg, D.E. </author> <year> 1989. </year> <title> Genetic Algorithms in search, optimization and machine learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: By mimicking this process, genetic algorithms are able to evolve solutions to real world problems, if they have been suitably encoded. The basic principles of GAs were first laid down rigourously by Holland [5], and are well described in many texts ( [2] , <ref> [4] </ref> and [10] ). In nature, individuals in a population compete with each other for resources. Also, members of the same species often compete to attract a mate. Those individuals which are most succesful in surviving and attracting mates will have relatively large number of offspring. <p> The process is repeated with the parents exchanged to produce the second offspring. A new crossover mask is randomly generated for each pair of parents. Offspring therefore contain a mixture of genes from each parent. fig 5: Uniform crossover - Goldberg <ref> [4] </ref> describes a rather different crossover operator, partially matched crossover (PMX), for use in order-based problems. In an order based problem, such as the travelling salesman problem, gene values are fixed, and the fitness depends on the order in which they appear. <p> The simplest variant of fitness-proportionate selection, roulette-wheel selection <ref> [4] </ref> [11], chooses individuals through PopulationSize simulated spins of a roulette wheel. The roulette wheel contains one slot for each population element. The size of each slot is directly proportional to its respective .
Reference: [5] <author> Holland, J.H. </author> <year> 1975. </year> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> University of Michigan Press, </publisher> <year> 1975. </year>
Reference-contexts: By mimicking this process, genetic algorithms are able to evolve solutions to real world problems, if they have been suitably encoded. The basic principles of GAs were first laid down rigourously by Holland <ref> [5] </ref>, and are well described in many texts ( [2] , [4] and [10] ). In nature, individuals in a population compete with each other for resources. Also, members of the same species often compete to attract a mate. <p> These parameters (known as genes) are joined together to form a string of values (often referred to as a chromosome). Holland <ref> [5] </ref> first showed that a convenient problem representation is to use a binary alphabet for the string. For example, if our problem is to maximise a function of three variables, F (x, y, z), we might represent each variable by a 10-bit binary number.
Reference: [6] <author> Holland, J.H. </author> <year> 1992. </year> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Therefore, highly fit, short defining length, low-order schemata, otherwise known as building blocks, are likely to proliferate from generation to generation. From this fact comes the claim that GAs process building blocks, also known as useful schemata. Holland <ref> [6] </ref> estimates that while a GA processes n strings each generation, it processes on the order of useful schemata. He called this phenomena implicit parallelism.
Reference: [7] <author> Kirkpatrick, S., Gelatt C.D. and Vecchi M.P. </author> <year> 1983. </year> <title> Optimization by Simulated Annealing. </title> <journal> Science, </journal> <volume> 220, </volume> <month> 671 </month> <year> (1983). </year>
Reference-contexts: Once one peak has been located, the hill-climb is started again, but with another, randomly chosen, starting point. This technique (iterated search) has the advantage of simplicity and can perform well if the function does not have too many local maxima. 1.14.3 Simulated annealing This technique, invented by Kirkpatrick <ref> [7] </ref> , is essentially a modified version of hill-climbing. The simulated annealing algorithm starts with choosing an initial configuration at random and calculates its fitness F. Then generates a new state and calculates its fitness F.
Reference: [8] <author> Manderick, B. and Spiessens P. </author> <year> 1989. </year> <title> Fine Grained Parallel Genetic Algorithms. </title> <booktitle> Proc. 3rd ICGA, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: The entire cycle then repeats. After few generations, there emerge many small subpopulations of similar strings with similar fitness values. These subpopulations are just as separate islands. This kind of separation is referred to as isolation by distance. Manderick & Spiessens <ref> [8] </ref> proposed another fine-grained genetic algorithm which also assigns one individual to each processor. In this algorithm, the individuals of the population are placed on a planar grid and selection and mating are restricted to small neighborhoods on page 18 that grid.
Reference: [9] <author> Muhlenbein, H. </author> <year> 1991. </year> <title> Evolution in Time and Space - The Parallel Genetic Algorithm. Foundations of genetic algorithms, </title> <editor> G. Rawlins, ed. </editor> <publisher> Morgan-Kaufmann. </publisher>
Reference-contexts: Each processor can pick the best string in its local neighborhood to mate with, or alternatively, some form of local probabilistic selection could be used. In either case, only one offspring is produced and becomes the new resident at that processor. Muhlenbeins parallel, distributed GA (PGA) <ref> [9] </ref> places individuals on a two-dimensional grid, one individual per grid element or node. PGA works by hill-climbing to local maxima, then hopping to others via crossover. Each individual does the selection by itself. It looks for a partner in its neighborhood only, then performs crossover.
Reference: [10] <author> Michalewicz, Z. </author> <year> 1992. </year> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: By mimicking this process, genetic algorithms are able to evolve solutions to real world problems, if they have been suitably encoded. The basic principles of GAs were first laid down rigourously by Holland [5], and are well described in many texts ( [2] , [4] and <ref> [10] </ref> ). In nature, individuals in a population compete with each other for resources. Also, members of the same species often compete to attract a mate. Those individuals which are most succesful in surviving and attracting mates will have relatively large number of offspring. <p> In combinatorial optimisation problems, such as the construction of school timetables, most points in the search space often represent invalid chromosomes and hence have zero real value. Nevertheless, special-purpose codings and genetic operators can be devised such that all generated solutions are viable <ref> [10] </ref>. 1.5 Reproduction During the reproduction phase of the GA, individuals are selected from the population and recombined, producing offspring which will comprise the next generation. Parents are selected randomly from the population using a scheme which favours the most fit individuals.
Reference: [11] <author> Oussaidne, M. and Chopard B. </author> <year> 1994. </year> <title> Optimisation des expressions arithmtiques sur une machine massivement parallle en utilisant un algorithme gntique, </title> <booktitle> SIPAR-Workshop on Parallel and Distributed Computing, </booktitle> <institution> university of Fribourg, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: The simplest variant of fitness-proportionate selection, roulette-wheel selection [4] <ref> [11] </ref>, chooses individuals through PopulationSize simulated spins of a roulette wheel. The roulette wheel contains one slot for each population element. The size of each slot is directly proportional to its respective .
Reference: [12] <author> Syswerda, G. </author> <year> 1989. </year> <title> Uniform Crossover in Genetic Algorithms. </title> <booktitle> Proc. 3rd ICGA, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Traditionally, a generation gap of 1 (the whole population) is replaced in each generation. Syswerda <ref> [12] </ref> introduced steady-state replacement where only a few (typically two) individuals, in each generation, are replaced. In steady-state replacement, two parents are selected for reproduction and produce offspring that are immediately placed back into the population.
Reference: [13] <author> Tanese, R. </author> <year> 1989. </year> <title> Distributed Genetic Algorithms. </title> <booktitle> Proc. 3rd ICGA, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: One way to evolve these strings is to break the total population down into subpopulations of 100 strings each. Each one of these subpopulations could then be evolved using a canonical genetic algorithm. Occasionally, the subpopulations would swap a few strings. This migration allows subpopulations to share genetic material <ref> [13] </ref>. Assume for a moment that one executes 16 separate genetic algorithms, each using a population of 100 strings without migration. In this case, 16 independent searches occur. This technique is sometimes called partitioned GA. The partitioned GA is highly redundant.
Reference: [14] <author> Whitley, D. </author> <year> 1989. </year> <title> The GENITOR Algorithm and Selection Pressure: Why Rank-Based Allocation of Reproductive Trials Is Best. </title> <booktitle> Proc. 3rd ICGA, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: However, the most serious objection to ranking is that it violates the schema theorem: the average of the rank of the individuals that sample a particular schemata does not correspond to the rank of the schemas average fitness <ref> [14] </ref>. - Baker [1] used a linear curve for the allocation of trials. <p> This can be expressed as follows. yielding - Whitley <ref> [14] </ref> used a ranked-based allocation of reproductive trials which is similar to Bakers linear ranking. (c) - In tournament selection, a group of individuals is selected from the population with a uniform random probability distribution.

References-found: 14

