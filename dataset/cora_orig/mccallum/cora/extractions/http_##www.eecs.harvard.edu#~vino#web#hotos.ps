URL: http://www.eecs.harvard.edu/~vino/web/hotos.ps
Refering-URL: http://www.eecs.harvard.edu/~vino/web/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: margog@das.harvard.edu  
Title: The Case for Geographical Push-Caching  
Author: James Gwertzman, Margo Seltzer 
Address: fgwertzma,  
Affiliation: Harvard University  
Abstract: Most existing wide-area caching schemes are client initiated. Decisions on when and where to cache information are made without the benefit of the server's global knowledge of the situation. We believe that the server should play a role in making these caching decisions, and we propose geographical push-caching as a way of bringing the server back into the loop. The World Wide Web is an excellent example of a wide-area system that will benefit from geographical push-caching, and we present an architecture that allows a Web server to autonomously replicate HTML pages. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Berners-Lee, R. Cailliau, J-F. Groff, and B. Poller-mann. </author> <title> World-wide web: The information universe. </title> <journal> Electronic Networking Research, Applications and Policy, </journal> <volume> 2(1) </volume> <pages> 52-58, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction The World-Wide Web <ref> [1] </ref> operates for the most part as a cache-less distributed system. When two neighboring clients retrieve a document from the same server, the document is sent twice. This is inefficient, especially considering the ease with which Web browsers allow users to transfer large multimedia documents.
Reference: [2] <author> Matthew A. </author> <title> Blaze. Caching in large-scale distributed file systems. </title> <type> Technical Report TR-397-92, </type> <institution> Princeton University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: As for resource location, there are several groups work 2 network bandwidth. ing on this problem. Until this problem is solved we are using a technique proposed by Blaze <ref> [2] </ref>, which we call the "1-800 technique". Clients "call" the primary server to ask for the "server nearest you." This is not elegant, but it works because latency is currently more critical than bandwidth. <p> Several groups are working on similar problems, but none that we know of are working on server-initiated caching. The Harvest system [3] in particular incorporates an object caching subsystem that provides a hierarchically organized means for efficiently retrieving Internet objects such as FTP and HTML files. Blaze <ref> [2] </ref> has addressed caching in a large-scale system. His research focused on distributed file systems, but can be applied to FTP or the Web. Finally, the Alex system [4] was designed to provide a means of caching FTP files.
Reference: [3] <author> C. Mic Bowman, Peter B. Danzig, Darren R. Hardy, Udi Manber, and Mich ael F. Schwartz. Harvest: </author> <title> A scalable, customizable discovery and access system. </title> <type> Technical Report CU-CS-732-94, </type> <institution> University of Col-orado, Boulder, </institution> <year> 1994. </year>
Reference-contexts: Several groups are working on similar problems, but none that we know of are working on server-initiated caching. The Harvest system <ref> [3] </ref> in particular incorporates an object caching subsystem that provides a hierarchically organized means for efficiently retrieving Internet objects such as FTP and HTML files. Blaze [2] has addressed caching in a large-scale system. His research focused on distributed file systems, but can be applied to FTP or the Web.
Reference: [4] <author> Vincent Cate. </author> <title> Alex A global filesystem. </title> <booktitle> In USENIX File Systems Workshop Proceedings, </booktitle> <pages> pages 1-12, </pages> <address> Ann Arbor, MI, May 21 - 22 1992. </address> <publisher> USENIX. </publisher>
Reference-contexts: Since weak-consistency should be acceptable for the Web, we are using a scheme developed for the Alex <ref> [4] </ref> file system. With the exception of dynamic pages (these will be addressed separately) we expect the Web to obey the same principle as FTP: the older a file is, the less likely it is to be modified. <p> Blaze [2] has addressed caching in a large-scale system. His research focused on distributed file systems, but can be applied to FTP or the Web. Finally, the Alex system <ref> [4] </ref> was designed to provide a means of caching FTP files. Of these three systems, Blaze's design comes closest to our own since it supports replication when demand becomes too high, and because it lets clients use any nearby cache.
Reference: [5] <author> Alan Emtage and Peter Deutsch. </author> <title> Archie an electronic directory service for the internet. </title> <booktitle> In Proceedings of the USENIX Winter Conference. USENIX, </booktitle> <month> January </month> <year> 1992. </year>
Reference-contexts: We expect our results to be applicable to any wide-area distributed system, however; not just the World Wide Web. One application for geographical push-caching that we have in mind is to replicate not only data files but also services themselves. A good example would be Archie <ref> [5] </ref>, whose load problems are notorious. If Archie were to be written in a machine-independent network-service scripting language (e.g. Tcl [8]), its code could be replicated and cached just like a Web file.
Reference: [6] <author> Ari Luotonen and Kevin Altis. </author> <title> World-wide web proxies. </title> <booktitle> In Computer Networks and ISDN systems. First International Conference on the World-Wide Web, </booktitle> <publisher> Elsevier Science BV, </publisher> <year> 1994. </year> <note> available from 'http://www.cern.ch/ PapersWWW94/ luotonen.ps'. </note>
Reference-contexts: To combat this problem, some Web browsers have begun to add local client caches. These prevent the same client from transferring the same document twice. Some networks are also beginning to add Web proxies <ref> [6, 7] </ref> that prevent two clients on the same campus network from transferring the same document twice. The problem with both these schemes is that they are myopic. A client cache does not help a neighboring computer, and a campus proxy does not help a neighboring campus. <p> The modified server is responsible for tracking geographical access information for its files and for accepting and offering cached replicas of other files. This can be done by modifying a proxy server, such as the CERN proxy server <ref> [6] </ref>, to accept files for replication using a modified POST request. The replication service keeps track of modified HTTP servers that are willing to serve replicated files, the amount of available free space on each server, and each server's average load.
Reference: [7] <author> Mosaic-x@ncsa.uiuc.edu. </author> <title> Using proxy gateways. World-Wide Web. </title> <note> available from 'http://www.ncsa.uiuc.edu/ SDG/Software/ Mosaic/ Docs/ proxy-gateways.html'. </note>
Reference-contexts: To combat this problem, some Web browsers have begun to add local client caches. These prevent the same client from transferring the same document twice. Some networks are also beginning to add Web proxies <ref> [6, 7] </ref> that prevent two clients on the same campus network from transferring the same document twice. The problem with both these schemes is that they are myopic. A client cache does not help a neighboring computer, and a campus proxy does not help a neighboring campus.
Reference: [8] <author> John K. Ousterhout. </author> <title> Tcl: An embeddable command language. </title> <booktitle> In USENIX Conference Proceedings, </booktitle> <pages> pages 133-146, </pages> <address> Washington, D.C., </address> <month> January 22-26 </month> <year> 1990. </year> <booktitle> USENIX. </booktitle>
Reference-contexts: One application for geographical push-caching that we have in mind is to replicate not only data files but also services themselves. A good example would be Archie [5], whose load problems are notorious. If Archie were to be written in a machine-independent network-service scripting language (e.g. Tcl <ref> [8] </ref>), its code could be replicated and cached just like a Web file.
Reference: [9] <author> Nicolas Pioch. Le weblouvre. </author> <note> World-Wide Web. http: //mistral.enst.fr/ pioch/louvre/louvre.shtml. 4 </note>
Reference-contexts: Likewise, server-initiated caching can not cope very well with sudden, localized jumps in popularity, but is best suited to handling long-term file request trends. We close with this reminder of why server-initiated caching is necessary, taken from the Web home page of the WebLouvre <ref> [9] </ref>. Note: Starting end of October 1994, we are currently experiencing severe network problems on our 256 Kb school Internet connection. Please be understanding! I am still looking for a site willing to mirror the WebLouvre exhibit (30 Mb in all), preferably in the USA.
References-found: 9

