URL: http://www.cs.berkeley.edu/~zhendong/ps/ISCA94-branch.ps
Refering-URL: http://http.cs.berkeley.edu/~zhendong/cs252/ref.html
Root-URL: 
Email: (Email:fcalder,grunwaldg@cs.colorado.edu)  
Phone: 430,  
Title: Fast Accurate Instruction Fetch and Branch Prediction  
Author: Brad Calder and Dirk Grunwald 
Address: Campus Box  Boulder, CO 80309-0430  
Affiliation: Department of Computer Science,  University of Colorado,  
Abstract: Accurate branch prediction is critical to performance; mispre-dicted branches mean that ten's of cycles may be wasted in superscalar architectures. Architectures combining very effective branch prediction mechanisms coupled with modified branch target buffers (BTB's) have been proposed for wide-issue processors. These mechanisms require considerable processor resources. Concurrently, the larger address space of 64-bit architectures introduce new obstacles and opportunities. A larger address space means branch target buffers become more expensive. In this paper, we show how a combination of less expensive mechanisms can achieve better performance than BTB's. This combination relies on a number of design choices described in the paper. We used trace-driven simulation to show that our proposed design, which uses fewer resources, offers better performance than previously proposed alternatives for most programs, and indicate how to further improve this design. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Ball and J. R. Larus. </author> <title> Branch prediction for free. </title> <booktitle> In 1993 SIGPLAN Confernce on Programming Language Design and Implementation. ACM, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time hueristics <ref> [1, 10, 13, 17] </ref> to profile-based methods [7, 13, 19]. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use hueristics based on the direction of the branch target (forward or backward) or instruction opcode.
Reference: [2] <author> Brian Bray and M. J. Flynn. </author> <title> Strategies for branch target buffers. </title> <booktitle> In 24th Workshop on Microprogramming and Microarchitecture, </booktitle> <pages> pages 42-49. </pages> <publisher> ACM, ACM, </publisher> <year> 1991. </year>
Reference-contexts: In the compiler we used, indirect jumps are used both to implement indirect function calls and some switch statements. 5 Improvements to BTB Architectures Our goal is to understand the performance improvement of various branch architectures; this requires a metric to compare one architecture to another. In <ref> [2] </ref>, Bray and Flynn state: Past attention in BTB design focused on hit rate to describe the performance, but hit rate is not all that important. How often the instruction fetch unit predicts the correct address is the important performance issue. <p> We profile the program behavior, recording the most likely direction for each branch and then modify the program binary to favor `not taken' branches. Pettis [16] and Bray <ref> [2] </ref> have performed similar transformations, but for different goals and with different outcomes. Before leaving the BTB based architecture, a final observation regarding the C++ programs we traced is in order.
Reference: [3] <author> Brad Calder and Dirk Grunwald. </author> <title> Branch alignment. </title> <type> Technical report, </type> <institution> Univ. of Colorado, </institution> <year> 1993. </year> <note> (In Preperation). </note>
Reference-contexts: However, note that espresso benefits from the improved branch prediction available in the GAg method. With this type of BTB organization, it becomes very useful to have programs with many `not taken' branches. In a related paper <ref> [3] </ref>, we show how programs can be restructured to accomplish this and the impact it has on branch architectures. We profile the program behavior, recording the most likely direction for each branch and then modify the program binary to favor `not taken' branches.
Reference: [4] <author> Brad Calder and Dirk Grunwald. </author> <title> Reducing indirect function call overhead in c++ programs. </title> <booktitle> In Conference Record of the 21st Annual ACM Symposium on Principles of ProgrammingLanguages, </booktitle> <month> January </month> <year> 1994. </year>
Reference-contexts: 1 Introduction During a related study on the architectural features used by object-oriented languages, such as C++, we examined several branch architectures to see how many optimizations a compiler would have to perform to efficiently execute object-oriented programs <ref> [4, 5] </ref>. We assumed future processors would be pipelined superscalar architectures and would need to drastically reduce the occurence of pipeline stalls for efficient execution. Conventional processor architectures, particularly superscalar designs, are extremely sensitive to control flow changes. <p> If the program has not been profiled, or this is an inter-segment branch, the program will always mispredict indirect branches. Profile-based prediction of indirect function calls has been shown to be effective and important for the C++ programming language <ref> [4] </ref>, where such branchs occur frequently. We assume return instructions use a 32-entry return address stack for predicting the branch address. <p> The return stack avoids most return mispredictions. If we have previously executed the program, we can use profile based indirect jump prediction <ref> [4] </ref>. In Table 5, we use the profile information from the same input to predict the indirect jumps. The BTB-based architectures can predict indirect jumps without profiling. <p> The BTB would only store indirect jumps, and could be very small, particularly if we could include only indirect jumps that are difficult to predict statically. The smaller BTB will probably not increase the overall processor cycle time. In related work <ref> [4] </ref>, we found that indirect jumps in many programs can be accurately predicted using profile information. For example, we encountered 547 unique indirect jumps when tracing idl, but all of these are easy to predict.
Reference: [5] <author> Brad Calder, Dirk Grunwald, and Benjamin Zorn. </author> <title> Quantifying behavioral differences between C and C++ programs. </title> <type> Technical Report CU-CS-698, </type> <institution> Univ. of Colorado-Boulder, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: 1 Introduction During a related study on the architectural features used by object-oriented languages, such as C++, we examined several branch architectures to see how many optimizations a compiler would have to perform to efficiently execute object-oriented programs <ref> [4, 5] </ref>. We assumed future processors would be pipelined superscalar architectures and would need to drastically reduce the occurence of pipeline stalls for efficient execution. Conventional processor architectures, particularly superscalar designs, are extremely sensitive to control flow changes. <p> We selected these programs because we found that the SPECint92 suite did not typify the behavior seen in C++ programs <ref> [5] </ref>, and our original goal was to understand the impact of branch architectures on C++ programs. For these alternate programs, we used sizable inputs we hoped would exercise a large part of the program. Table 1 shows the basic statistics for the programs we instrumented.
Reference: [6] <author> David R. Ditzel and Hubert R. McLellan. </author> <title> Branch folding in the CRISP microprocessor: Reducing branch delay to zero. </title> <booktitle> In 14th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 2-9. </pages> <publisher> ACM, ACM, </publisher> <month> June </month> <year> 1987. </year>
Reference-contexts: Every direct branch within that 2 n instruction span can only branch within that span. To branch outside that span, a indirect jump must be used. This idea is not new a similar mechanism is used in the Crisp processor <ref> [6] </ref>. In that architecture a branch destination is included in every decoded instruction, resulting in very large instructions - 192 bits. However, the decoded instruction cache must updated on each cycle; this may limit the processor cycle time.
Reference: [7] <author> J. A. Fisher and S. M. Freudenberger. </author> <title> Predicting conditional branch directions from previous runs of a program. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 85-95, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time hueristics [1, 10, 13, 17] to profile-based methods <ref> [7, 13, 19] </ref>. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use hueristics based on the direction of the branch target (forward or backward) or instruction opcode.
Reference: [8] <author> David R. Kaeli and Philip G. Emma. </author> <title> Branch history table prdiction of moving target branches due to subroutine returns. </title> <booktitle> In 18th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 34-42. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: For function calls (either direct or indirect), the previous function address is stored in the `destination' field of the BTB. This can also be done for return instructions, but a return stack <ref> [8] </ref> is much more accurate. When using a return stack the BTB provides no useful information for returns, but it does indicate the instruction is a return instruction so the return stack can be used, avoiding the misfetch penalty. <p> With a BTB, an indirect procedure call can be predicted about as accurately as a conditional branch, and a return-stack <ref> [8] </ref> predicts returns very accurately without using the BTB. Thus, programs such as db++ and idl, which perform a tremendous number of function calls have the lowest BEP of our sample programs.
Reference: [9] <author> Manolis G. H. Katevenis. </author> <title> Reduced Instruction Set Computer Architecture for VLSI. ACM Doctoral Dissertation Award Series. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: Each branch can directly address instructions at address P C 2 n1 2 n1 . For simplicity, we assume the program counter is always aligned on instruction boundaries, since we are chiefly concerned with architectures with fixed-width instructions. Katevenis <ref> [9] </ref> proposed several branch encodings where the branch displacement field contains the least significant bits of the branch target address. Figure 2 (b), shows one such encoding.
Reference: [10] <author> Johnny K. F. Lee and Alan Jay Smith. </author> <title> Branch prediction strategies and branch target buffer design. </title> <journal> IEEE Computer, </journal> <volume> ??(??):6-22, </volume> <month> January </month> <year> 1984. </year>
Reference-contexts: Originally, BTB's were used as a mechanism for branch prediction, effectively predicting the prior behavior of a branch even small BTB's were found to be very effective <ref> [10, 15, 17] </ref>. More recently, there has been considerable interest in using BTB's to reduce instruction misfetch penalties; for example Yeh et al [21] propose using a very large BTB to improve prediction accuracy and reduce misfetch penalties. <p> Their mechanism is a logical continuation of currently proposed and implemented designs. There are two sources of pipeline stalls we want to remove. The first is the instruction misfetch penalty. This can be done a number of ways; e.g, by using branch delay slots [13] or branch target buffers <ref> [10, 11, 15, 17] </ref>. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched. <p> Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time hueristics <ref> [1, 10, 13, 17] </ref> to profile-based methods [7, 13, 19]. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use hueristics based on the direction of the branch target (forward or backward) or instruction opcode. <p> A BTB can be used to predict conditional branches by storing a destination address and predicting that instruction is executed. The destination address can either be updated on each branch or two-bit saturating counters <ref> [10] </ref> can be used to improve prediction accuracy. By coupling the branch prediction information with the BTB, we avoid both misfetch and misprediction penalties; however, we can only do this for branches that have been entered in the BTB. <p> The most common variants of this design are 1-bit techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit techniques that yield much better performance for programs with loops <ref> [10, 13, 17] </ref>. The advantage of the pattern history tables is that they keep track of very little information per conditional branch site and are very effective in practice. More recently Pan et al [14] and Yeh and Patt [20, 22] have proposed branch-correlation or two-level branch prediction mechanisms.
Reference: [11] <author> David J. Lilja. </author> <title> Reducing the branch penalty in pipelined processors. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 47-55, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: There are a number of mechanisms to ameliorate the effect of uncertain control flow changes, including static and dynamic branch prediction, branch target buffers, delayed branches, prefetching both targets, early branch resolution, branch bypassing and prepare-to-branch mechanisms <ref> [11] </ref>. Likewise, there are a variety of mechanisms to reduce the instruction mispredict penalty, including delayed branches, where the instruction following a branch is either always executed or conditionally executed (squashed) depending on the branch target or a condition code, and branch target buffers. <p> Their mechanism is a logical continuation of currently proposed and implemented designs. There are two sources of pipeline stalls we want to remove. The first is the instruction misfetch penalty. This can be done a number of ways; e.g, by using branch delay slots [13] or branch target buffers <ref> [10, 11, 15, 17] </ref>. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched.
Reference: [12] <author> Scott McFarling. </author> <title> Combining branch predictors. </title> <address> TN 36, DEC-WRL, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This is used as an index into the 4096-entry table, much as the program counter is used in the previous method. This provides contextual information about particular patterns of branches. Other methods combine the pattern register with other information. McFarling <ref> [12] </ref> xor's the program counter with the history register, scattering the table references and slightly improving performance. Yeh and Patt [22] propose a number of alternatives. We focus on their `PAs' method, since they found it to be most effective. Each branch in the BTB has a unique history register.
Reference: [13] <author> Scott McFarling and John Hennessy. </author> <title> Reducing the cost of branches. </title> <booktitle> In 13th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 396-403. </pages> <publisher> ACM, </publisher> <year> 1986. </year>
Reference-contexts: Their mechanism is a logical continuation of currently proposed and implemented designs. There are two sources of pipeline stalls we want to remove. The first is the instruction misfetch penalty. This can be done a number of ways; e.g, by using branch delay slots <ref> [13] </ref> or branch target buffers [10, 11, 15, 17]. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched. <p> Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time hueristics <ref> [1, 10, 13, 17] </ref> to profile-based methods [7, 13, 19]. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use hueristics based on the direction of the branch target (forward or backward) or instruction opcode. <p> Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time hueristics [1, 10, 13, 17] to profile-based methods <ref> [7, 13, 19] </ref>. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use hueristics based on the direction of the branch target (forward or backward) or instruction opcode. <p> The most common variants of this design are 1-bit techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit techniques that yield much better performance for programs with loops <ref> [10, 13, 17] </ref>. The advantage of the pattern history tables is that they keep track of very little information per conditional branch site and are very effective in practice. More recently Pan et al [14] and Yeh and Patt [20, 22] have proposed branch-correlation or two-level branch prediction mechanisms.
Reference: [14] <author> S.-T. Pan, K. So, and J. T. Rahmeh. </author> <title> Improving the accuracy of dynamic branch prediction using branch correlation. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 76-84, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: The advantage of the pattern history tables is that they keep track of very little information per conditional branch site and are very effective in practice. More recently Pan et al <ref> [14] </ref> and Yeh and Patt [20, 22] have proposed branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally combine the history of several recent branches to predict the outcome of an incipient branch. <p> When predicting the outcome of a particular branch, bits &lt;5:2&gt; of the program counter and bits &lt;5:0&gt; of the history register form a ten-bit index into the 1024-entry history table; the history table contains 2048 bits. In this paper, we are primarily concerned with 2-level prediction methods; see <ref> [14, 20, 22] </ref> for details on their design. The problem with using only a 2-level prediction method is that one cannot avoid the fetch penalty associated with identifying what type of break has occurred and computing its target address. <p> However, the information in the PHT could have been used to predict the branch with more accuracy, avoiding some branch mispredict penalties. If we used a single pattern history register, as originally proposed by Pan <ref> [14] </ref>, we can use the PHT to predict the branch whether it is in the BTB or not. In a comparison of prediction methods [22],Yeh et al compared this method (which they termed the `GAg' method) and other prediction methods.
Reference: [15] <author> Chris Perleberg and Alan Jay Smith. </author> <title> Branch target buffer design and optimization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(4) </volume> <pages> 396-412, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Originally, BTB's were used as a mechanism for branch prediction, effectively predicting the prior behavior of a branch even small BTB's were found to be very effective <ref> [10, 15, 17] </ref>. More recently, there has been considerable interest in using BTB's to reduce instruction misfetch penalties; for example Yeh et al [21] propose using a very large BTB to improve prediction accuracy and reduce misfetch penalties. <p> Their mechanism is a logical continuation of currently proposed and implemented designs. There are two sources of pipeline stalls we want to remove. The first is the instruction misfetch penalty. This can be done a number of ways; e.g, by using branch delay slots [13] or branch target buffers <ref> [10, 11, 15, 17] </ref>. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched.
Reference: [16] <author> Karl Pettis and Robert C. Hansen. </author> <title> Profile guided code positioning. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 16-27. </pages> <publisher> ACM, ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: In a related paper [3], we show how programs can be restructured to accomplish this and the impact it has on branch architectures. We profile the program behavior, recording the most likely direction for each branch and then modify the program binary to favor `not taken' branches. Pettis <ref> [16] </ref> and Bray [2] have performed similar transformations, but for different goals and with different outcomes. Before leaving the BTB based architecture, a final observation regarding the C++ programs we traced is in order.
Reference: [17] <author> J. E. Smith. </author> <title> A study of branch prediction strategies. </title> <booktitle> In 8th Annual International Symposium of Computer Architecture. ACM, </booktitle> <year> 1981. </year>
Reference-contexts: Originally, BTB's were used as a mechanism for branch prediction, effectively predicting the prior behavior of a branch even small BTB's were found to be very effective <ref> [10, 15, 17] </ref>. More recently, there has been considerable interest in using BTB's to reduce instruction misfetch penalties; for example Yeh et al [21] propose using a very large BTB to improve prediction accuracy and reduce misfetch penalties. <p> Their mechanism is a logical continuation of currently proposed and implemented designs. There are two sources of pipeline stalls we want to remove. The first is the instruction misfetch penalty. This can be done a number of ways; e.g, by using branch delay slots [13] or branch target buffers <ref> [10, 11, 15, 17] </ref>. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched. <p> Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time hueristics <ref> [1, 10, 13, 17] </ref> to profile-based methods [7, 13, 19]. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use hueristics based on the direction of the branch target (forward or backward) or instruction opcode. <p> The most common variants of this design are 1-bit techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit techniques that yield much better performance for programs with loops <ref> [10, 13, 17] </ref>. The advantage of the pattern history tables is that they keep track of very little information per conditional branch site and are very effective in practice. More recently Pan et al [14] and Yeh and Patt [20, 22] have proposed branch-correlation or two-level branch prediction mechanisms.
Reference: [18] <author> Amitabh Srivastava and Alan Eustace. </author> <title> Atom: A system for building customized program analysis tools. </title> <address> TN 41, DEC-WRL, </address> <month> January </month> <year> 1994. </year> <note> (To appear in PLDI'94). </note>
Reference-contexts: Other studies have noted that FORTRAN programs have very predictable branches, and there is little one can do to improve that prediction; we simulated the SPECfp92 benchmarks and found that was true. We omit the results due to space. We used ATOM <ref> [18] </ref> to instrument the programs; due to the structure of ATOM, we did not need to record traces and could trace very long-running programs. The programs were compiled on a DEC 3000-400 using either the DEC C compiler or DEC C++ compiler. All programs were compiled with standard optimization (-O).
Reference: [19] <author> D. W. Wall. </author> <title> Limits of instruction-level parallelism. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 176-188, </pages> <address> Boston, Mass., </address> <year> 1991. </year>
Reference-contexts: Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time hueristics [1, 10, 13, 17] to profile-based methods <ref> [7, 13, 19] </ref>. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use hueristics based on the direction of the branch target (forward or backward) or instruction opcode.
Reference: [20] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> Alternative implementations of two-level adaptive branch predictions. </title> <booktitle> In 19th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 124-134, </pages> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: Each BTB entry also contains a per-basic block pattern history register, used to index into a 2-level branch history table <ref> [20, 22] </ref>. Architectures using BTB's can issue a large number of instructions per cycle because of accurate branch and fetch prediction. However, BTB's lead to a complex architecture. In this paper, we show how to achieve the same or better performance using simpler techniques. <p> The advantage of the pattern history tables is that they keep track of very little information per conditional branch site and are very effective in practice. More recently Pan et al [14] and Yeh and Patt <ref> [20, 22] </ref> have proposed branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally combine the history of several recent branches to predict the outcome of an incipient branch. The simplest example is the so-called degenerate method of Pan et al. <p> When predicting the outcome of a particular branch, bits &lt;5:2&gt; of the program counter and bits &lt;5:0&gt; of the history register form a ten-bit index into the 1024-entry history table; the history table contains 2048 bits. In this paper, we are primarily concerned with 2-level prediction methods; see <ref> [14, 20, 22] </ref> for details on their design. The problem with using only a 2-level prediction method is that one cannot avoid the fetch penalty associated with identifying what type of break has occurred and computing its target address.
Reference: [21] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comprehensive instruction fetch mechanism for a processor supporting speculative execution. </title> <booktitle> In 19th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 129-139, </pages> <address> Portland, Or, </address> <month> December </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: More recently, there has been considerable interest in using BTB's to reduce instruction misfetch penalties; for example Yeh et al <ref> [21] </ref> propose using a very large BTB to improve prediction accuracy and reduce misfetch penalties. In fact, their BTB records a multitude of useful information to support wide-issue processors. Wide-issue processors fetch multiple instructions, roughly the size of a basic block. <p> This is why BTB's are useful for eliminating instruction misfetch penalties, and why some architectures combine both BTB's and these accurate prediction mechanisms. 3 A BTB-based instruction Fetch Architecture instruction fetch architecture suggested by Yeh and Patt <ref> [21] </ref>. The current instruction address is concurrently offered to the instruction cache (not shown), providing the actual instruction, and to the BTB. A 32-entry return address stack handles return instructions. There are three important types of branches: direct or indirect branches, conditional branches and function returns. <p> Depending on the predicted outcome, the stored `destination' (which is always the `taken' address) or the fall-through address is used to fetch the next instruction. Then, the history table is updated; this can occur several cycles later with little penalty see <ref> [21] </ref> for more details. The critical path in this architecture is for conditional branches. The processor must offer the PC to the BTB, extract the destination and prediction fields and use this to select the appropriate destination address. <p> However, this binds us to a specific misfetch and misprediction penalty we have assumed a one cycle misfetch penalty and a five cycle misprediction penalty. We simulated the BTB-based architecture as proposed by Yeh & Patt <ref> [21] </ref>. We choose their model because it has been described clearly and in depth, making it easier to duplicate their simulations. Despite that we are simulating a different base architecture and used different compilers than used in [21], our results for their architecture reflect the performance noted in [21]. 5.1 Decoupled <p> We simulated the BTB-based architecture as proposed by Yeh & Patt <ref> [21] </ref>. We choose their model because it has been described clearly and in depth, making it easier to duplicate their simulations. Despite that we are simulating a different base architecture and used different compilers than used in [21], our results for their architecture reflect the performance noted in [21]. 5.1 Decoupled Prediction and Fall Throughs One of the disadvantages of a coupled pattern history register, as used in the BTB-based architecture, is that a branch may not be in the BTB. <p> & Patt <ref> [21] </ref>. We choose their model because it has been described clearly and in depth, making it easier to duplicate their simulations. Despite that we are simulating a different base architecture and used different compilers than used in [21], our results for their architecture reflect the performance noted in [21]. 5.1 Decoupled Prediction and Fall Throughs One of the disadvantages of a coupled pattern history register, as used in the BTB-based architecture, is that a branch may not be in the BTB.
Reference: [22] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comparison of dynamic branch predictors that use two levels of branch history. </title> <booktitle> In 20th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 257-266, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: Each BTB entry also contains a per-basic block pattern history register, used to index into a 2-level branch history table <ref> [20, 22] </ref>. Architectures using BTB's can issue a large number of instructions per cycle because of accurate branch and fetch prediction. However, BTB's lead to a complex architecture. In this paper, we show how to achieve the same or better performance using simpler techniques. <p> The advantage of the pattern history tables is that they keep track of very little information per conditional branch site and are very effective in practice. More recently Pan et al [14] and Yeh and Patt <ref> [20, 22] </ref> have proposed branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally combine the history of several recent branches to predict the outcome of an incipient branch. The simplest example is the so-called degenerate method of Pan et al. <p> This provides contextual information about particular patterns of branches. Other methods combine the pattern register with other information. McFarling [12] xor's the program counter with the history register, scattering the table references and slightly improving performance. Yeh and Patt <ref> [22] </ref> propose a number of alternatives. We focus on their `PAs' method, since they found it to be most effective. Each branch in the BTB has a unique history register. <p> When predicting the outcome of a particular branch, bits &lt;5:2&gt; of the program counter and bits &lt;5:0&gt; of the history register form a ten-bit index into the 1024-entry history table; the history table contains 2048 bits. In this paper, we are primarily concerned with 2-level prediction methods; see <ref> [14, 20, 22] </ref> for details on their design. The problem with using only a 2-level prediction method is that one cannot avoid the fetch penalty associated with identifying what type of break has occurred and computing its target address. <p> In a comparison of prediction methods <ref> [22] </ref>,Yeh et al compared this method (which they termed the `GAg' method) and other prediction methods. They found that storing prediction registers in the BTB gave a higher prediction accuracy [22]; however, they did not account for the differences between misfetch and misprediction. In Table 2 we show more detailed metrics for the organization found to have the best prediction accuracy in [22] (PAs (6,16)) and the simpler method that can use the pattern history register even when the branch is <p> They found that storing prediction registers in the BTB gave a higher prediction accuracy <ref> [22] </ref>; however, they did not account for the differences between misfetch and misprediction. In Table 2 we show more detailed metrics for the organization found to have the best prediction accuracy in [22] (PAs (6,16)) and the simpler method that can use the pattern history register even when the branch is not located in the BTB (GAg). In the PAs method, if a branch is not in the BTB, we use a static backward-taken/forward-not-taken prediction.
References-found: 22

