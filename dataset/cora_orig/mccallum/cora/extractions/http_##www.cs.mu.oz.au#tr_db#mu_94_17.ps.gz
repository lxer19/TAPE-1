URL: http://www.cs.mu.oz.au/tr_db/mu_94_17.ps.gz
Refering-URL: http://www.cs.mu.oz.au/tr_db/TR.html
Root-URL: 
Title: Searching Large Lexicons for Partially Specified Terms using Compressed Inverted Files  
Author: Justin Zobel Alistair Moffat Ron Sacks-Davis 
Abstract: There are several advantages to be gained by storing the lexicon of a full text database in main memory. In this paper we describe how to use a compressed inverted file index to search such a lexicon for entries that match a pattern or partially specified term. Our experiments show that this method provides an effective compromise between speed and space, running orders of magnitude faster than brute force search, but requiring less memory than other pattern-matching data structures; indeed, in some cases requiring less memory than would be consumed by a single pointer to each string. The pattern search method is based on text indexing techniques and is a successful adaptation of inverted files to main memory databases. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho and M.J. Corasick. </author> <title> Fast pattern matching: An aid to bibliographic search. </title> <journal> Communications of the ACM, </journal> <volume> 18(6) </volume> <pages> 333-340, </pages> <year> 1975. </year>
Reference-contexts: This requires only that it be possible to traverse the lexicon in some orderly fashion: the lexicon does not have to be sorted, and no additional structures are needed. To effect the pattern matching itself, finite automata techniques <ref> [1] </ref> such as the UNIX regex package can be used.
Reference: [2] <author> T.C. Bell, A. Moffat, C.G. Nevill-Manning, I.H. Witten, and J. Zobel. </author> <title> Data compression in full-text retrieval systems. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 44(9) </volume> <pages> 508-531, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: One possible application for extra memory is to store a comprehensive compression model for the text of the document collection, thereby substantially increasing the effective capacity of the storage devices being used <ref> [2, 4] </ref>. Another possibility is to store the lexicon of the collection in main memory, eliminating the disk accesses needed to search for query terms and improving query performance [25]. Here we examine a further facility that can be provided if the lexicon is held in memory.
Reference: [3] <author> A. Bookstein and S.T. Klein. </author> <title> Generative models for bitmap sets with compression applications. </title> <booktitle> In Proc. 14'th ACM-SIGIR Conference on Information Retrieval, </booktitle> <pages> pages 63-71, </pages> <address> Chicago, </address> <year> 1991. </year>
Reference-contexts: For this reason, compression of inverted lists, or equivalently bitmaps, has been analysed by many authors, include Fraenkel & Klein [9] and Bookstein & Klein <ref> [3] </ref>. Our presentation is based on that of Moffat & Zobel [18], who compare a variety of bitmap compression techniques.
Reference: [4] <author> A. Bookstein, S.T. Klein, and D.A. Ziff. </author> <title> A systematic approach to compressing a full-text retrieval system. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 28(6) </volume> <pages> 795-806, </pages> <year> 1992. </year>
Reference-contexts: One possible application for extra memory is to store a comprehensive compression model for the text of the document collection, thereby substantially increasing the effective capacity of the storage devices being used <ref> [2, 4] </ref>. Another possibility is to store the lexicon of the collection in main memory, eliminating the disk accesses needed to search for query terms and improving query performance [25]. Here we examine a further facility that can be provided if the lexicon is held in memory.
Reference: [5] <author> P. Bratley and Y. Choueka. </author> <title> Processing truncated terms in document retrieval systems. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 18(5) </volume> <pages> 257-266, </pages> <year> 1982. </year>
Reference-contexts: This gain is because, in most of our sample queries, all of the first few characters are specified. Bratley & Choueka <ref> [5] </ref> have generalised this method, and proposed a permuted dictionary mechanism for processing partially specified terms in database queries.
Reference: [6] <author> G.V. Cormack, R.N.S. Horspool, and M. Kaiserwerth. </author> <title> Practical perfect hashing. </title> <journal> Computer Journal, </journal> <volume> 28(1) </volume> <pages> 54-55, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Even more effective would be the use of a minimal perfect hash function on the n-grams <ref> [6, 8] </ref>. This would allow the N n space required by the n-grams to be reduced to about 4N bits, at little or no cost in lookup time. We did not explore this option, but it would be worth considering for a production implementation on a static lexicon.
Reference: [7] <author> P. Elias. </author> <title> Universal codeword sets and representations of the integers. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-21(2):194-203, </volume> <month> March </month> <year> 1975. </year>
Reference-contexts: Converting to a list of gaps does not in itself yield any compression, but does expose patterns that can be exploited for compression purposes. A simple method for representing the list of gaps is to use the codes for integers described by Elias <ref> [7] </ref>.
Reference: [8] <author> E.A. Fox, L.S. Heath, Q. Chen, and A.M. Daoud. </author> <title> Practical minimal perfect hash functions for large databases. </title> <journal> Communications of the ACM, </journal> <volume> 35(1) </volume> <pages> 105-121, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Even more effective would be the use of a minimal perfect hash function on the n-grams <ref> [6, 8] </ref>. This would allow the N n space required by the n-grams to be reduced to about 4N bits, at little or no cost in lookup time. We did not explore this option, but it would be worth considering for a production implementation on a static lexicon.
Reference: [9] <author> A.S. Fraenkel and S.T. Klein. </author> <title> Novel compression of sparse bit-strings| Preliminary report. </title> <editor> In A. Apostolico and Z. Galil, editors, </editor> <booktitle> Combinatorial Algorithms on Words, Volume 12, NATO ASI Series F, </booktitle> <pages> pages 169-183, </pages> <address> Berlin, 1985. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: For this reason, compression of inverted lists, or equivalently bitmaps, has been analysed by many authors, include Fraenkel & Klein <ref> [9] </ref> and Bookstein & Klein [3]. Our presentation is based on that of Moffat & Zobel [18], who compare a variety of bitmap compression techniques. <p> The C ffi code is longer than the C fl code for some values of x smaller than 15, but thereafter C ffi is never worse. The C fl and C ffi codes are instances of a more general coding paradigm as follows <ref> [9, 18] </ref>. Let V be a (possibly infinite) vector of positive integers v i , i 1, where P v i N , the number of items being indexed.
Reference: [10] <author> R.G. Gallager and D.C. Van Voorhis. </author> <title> Optimal source codes for geometrically distributed integer alphabets. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-21(2):228-230, </volume> <month> March </month> <year> 1975. </year>
Reference-contexts: use the vector V G = (b; b; b; b; b; : : :), where b = 0:69N=p and p is the number of runlengths in the inverted list; this gives the family of infinite Huffman codes described by Golomb [11] and analysed in detail by Gallager and Van Voorhis <ref> [10] </ref>. This scheme gives good compression when the indexed data is randomly distributed, and thus is good for unsorted lexicons. Results of application of these schemes to lexicon indexing are shown in Section 5.
Reference: [11] <author> S.W. Golomb. </author> <title> Run-length encodings. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-12(3):399-401, </volume> <month> July </month> <year> 1966. </year> <month> 21 </month>
Reference-contexts: Another scheme is to use the vector V G = (b; b; b; b; b; : : :), where b = 0:69N=p and p is the number of runlengths in the inverted list; this gives the family of infinite Huffman codes described by Golomb <ref> [11] </ref> and analysed in detail by Gallager and Van Voorhis [10]. This scheme gives good compression when the indexed data is randomly distributed, and thus is good for unsorted lexicons. Results of application of these schemes to lexicon indexing are shown in Section 5.
Reference: [12] <author> G. Gonnet and R. Baeza-Yates. </author> <title> Handbook of data structures and algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <note> second edition, </note> <year> 1991. </year>
Reference-contexts: For the 9,933 Kb TREC lexicon, for example, the permuted lexicon is 117,281 Kb, reducing to a minimum of 52,743 Kb after prefix-omission; and this figure does not include the pointer array that is required to access the structure. Following the approach of Gonnet & Baeza-Yates <ref> [12] </ref>, we note that it is more effective to use a variant of this method in which the permuted lexicon is an array of pointers, one to each character position in the original lexicon. <p> As can be seen, queries are answered in milliseconds rather than seconds. This scheme is therefore at the other extreme to brute force search, with rapid lookup but substantial space overheads. Patricia tries based on the semi-infinite strings in the lexicon are a generalisation of this approach <ref> [12, 15, 19] </ref>. In these methods the sequence of words is considered to be a contiguous string; the trie is used to determine the positions in the string at which a given substring occurs.
Reference: [13] <editor> D.K. Harman, editor. </editor> <booktitle> Proc. TREC Text Retrieval Conference, </booktitle> <address> Gaithersburg, Maryland, </address> <month> November </month> <year> 1992. </year> <note> National Institute of Standards Special Publication 500-207. </note>
Reference-contexts: Bible, the complete lexicon of the 4.4 Mb King James version of the Bible, with original case preserved; Macq, the set of lowercase terms used in the 1990 edition of the Macquarie Encyclopedic Thesaurus; and TREC , the lexicon of 1,079,291 articles totalling 3 Gb extracted from the TIPSTER collection <ref> [13] </ref>, again with original case preserved. The parameters of these lexicons are shown in Table 1. The "Size" figures in the first row include all of the characters of the words comprising the lexicon, plus one overhead byte per word for termination.
Reference: [14] <author> ISO. </author> <title> Commands for interactive text searching, </title> <note> 1988. Draft International Standard ISO/DIS 8777. </note>
Reference-contexts: For example, one might specify lab*r in a query to cover both British and American spellings or the word labour. Standard languages for interactive text retrieval include pattern-matching constructs such as wild characters and other forms of partial specification of query terms <ref> [14] </ref>. Certainly, if the lexicon is available in main memory it can be scanned using normal pattern matching techniques to locate partially specified terms. For all but very small lexicons, however, linear search is prohibitively expensive and is not a viable option.
Reference: [15] <author> E.M. McCreight. </author> <title> A space-economical suffix tree construction algorithm. </title> <journal> Journal of the ACM, </journal> <volume> 23(2) </volume> <pages> 262-272, </pages> <month> April </month> <year> 1976. </year>
Reference-contexts: As can be seen, queries are answered in milliseconds rather than seconds. This scheme is therefore at the other extreme to brute force search, with rapid lookup but substantial space overheads. Patricia tries based on the semi-infinite strings in the lexicon are a generalisation of this approach <ref> [12, 15, 19] </ref>. In these methods the sequence of words is considered to be a contiguous string; the trie is used to determine the positions in the string at which a given substring occurs.
Reference: [16] <author> A. Moffat. </author> <title> Economical inversion of large text files. </title> <journal> Computing Systems, </journal> <volume> 5(2) </volume> <pages> 125-139, </pages> <year> 1992. </year>
Reference-contexts: In Table 5 we show sizes of n-gram inverted file indexes for unsorted lexicons for n from 2 to 4. We also show, for n = 3, the time to create the index using an in-memory two-pass technique <ref> [16] </ref>. As n was increased, the creation times grew more slowly than did the size of the index, and times were dominated by the need to process the lexicon, which is independent of n.
Reference: [17] <author> A. Moffat and J. Zobel. </author> <title> Self-indexing inverted files for fast text retrieval. </title> <journal> ACM Transactions on Information Systems. </journal> <note> (To appear). </note>
Reference-contexts: Nonetheless all of the item numbers in each inverted list must be decoded, since compression prohibits random access|the whole list must be decoded to access an item number near the end. 9 This problem can be overcome by explicitly including pointers in each inverted list <ref> [17] </ref>. These pointers take the form of "skips" along the inverted list and allow blocks of item numbers to be either decoded or skipped, depending on whether they might contain an item number that is in the intersection. <p> The expected number of answers can be used to determine an optimum block length for a given inverted list, to minimise decoding time <ref> [17] </ref>. In the general case the number of answers is unknown, but performance is reasonably insensitive to the exact number of answers expected, and as we show for the special case of n-gram indexing there are circumstances in which the number of answers is given. <p> In the context of thresholds, the number of answers to be identified by processing the index is known, so the block sizes to be skipped can be optimised to give minimum total decoding time <ref> [17] </ref>. The cost of skipping is that the addition of skips increases index size, and the greater the number of expected answers, the more skips are added. Thus the savings from skipping will be greatest with small thresholds: more decoding will be avoided and indexes will be smaller.
Reference: [18] <author> A. Moffat and J. Zobel. </author> <title> Parameterised compression for sparse bitmaps. </title> <editor> In N. Belkin, P. Ingwersen, and A.M. Pejtersen, editors, </editor> <booktitle> Proc. ACM-SIGIR International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 274-285, </pages> <address> Copenhagen, June 1992. </address> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: For this reason, compression of inverted lists, or equivalently bitmaps, has been analysed by many authors, include Fraenkel & Klein [9] and Bookstein & Klein [3]. Our presentation is based on that of Moffat & Zobel <ref> [18] </ref>, who compare a variety of bitmap compression techniques. In all of these schemes decompression is fast|about 400 Kb of compressed data can be decompressed in a second on the Sun SPARC 10 that we have used for all of these experiments. <p> The C ffi code is longer than the C fl code for some values of x smaller than 15, but thereafter C ffi is never worse. The C fl and C ffi codes are instances of a more general coding paradigm as follows <ref> [9, 18] </ref>. Let V be a (possibly infinite) vector of positive integers v i , i 1, where P v i N , the number of items being indexed. <p> One scheme, due to Teuhola [22], is to use the vector V T = (b; 2b; 4b; 8b; 16b; : : :) ; where each list has an associated b value. An appropriate choice of b is the median runlength in the list <ref> [18] </ref>, again with k coded in unary. This scheme gives good compression because it exploits clustering, a phenomenon that is particularly likely when the strings in the lexicon are sorted, since the same substrings will occur in many consecutive strings.
Reference: [19] <author> D.R. Morrison. </author> <title> Patricia|Practical algorithm to retrieve information coded in alphanumeric. </title> <journal> Journal of the ACM, </journal> <volume> 15(4) </volume> <pages> 514-534, </pages> <year> 1968. </year>
Reference-contexts: As can be seen, queries are answered in milliseconds rather than seconds. This scheme is therefore at the other extreme to brute force search, with rapid lookup but substantial space overheads. Patricia tries based on the semi-infinite strings in the lexicon are a generalisation of this approach <ref> [12, 15, 19] </ref>. In these methods the sequence of words is considered to be a contiguous string; the trie is used to determine the positions in the string at which a given substring occurs.
Reference: [20] <author> O. Owolabi and D.R. McGregor. </author> <title> Fast approximate string matching. </title> <journal> Software| Practice and Experience, </journal> <volume> 18 </volume> <pages> 387-393, </pages> <year> 1988. </year>
Reference-contexts: Owolabi & McGregor have proposed a string search mechanism which, like the system we describe, uses an n-gram index to locate matching strings <ref> [20] </ref>. Their index is a form of signature file, with a bitmap in which columns correspond to n-grams and rows correspond to lexicon entries. We discuss the performance of this mechanism later. 4 Inverted file text indexing In this section we describe inverted file text indexing techniques. <p> A simple blocking scheme is to divide the ordinal number of each lexicon entry by a fixed blocking factor B to give the ordinal number of the containing block, so that each block contains B entries; a similar scheme has also been suggested by Owolabi & McGregor <ref> [20] </ref>. This method allows the lexicon entries to be stored individually, and a simple deblocking step is required to find individual words. <p> These results are a substantial improvement on those of Owolabi & McGregor, who, for an index of roughly 90% (in our framework) and a lexicon of 20,000 words, require 0.5 to 1 second per query on a Sun 3/60 <ref> [20] </ref>; on the same hardware, our implementation is about ten times faster for a lexicon and index of this size. Other blocking schemes are possible. Blocks could be fixed length, containing a variable number of words.
Reference: [21] <author> C.E. Shannon. </author> <title> A mathematical theory of communication. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 27 </volume> <pages> 379-423, 623-656, </pages> <year> 1948. </year>
Reference-contexts: In this index, the queryable entities are n-grams, that is, all n character substrings of the words in the lexicon. The concept of n-grams has been attributed to Shannon <ref> [21] </ref>, and can also be used for tasks such as string distance measurement [23, 24]. Given an inverted file of n-grams, it is straightforward to retrieve strings that match a pattern. First, all of the n-grams in the pattern must be extracted.
Reference: [22] <author> J. Teuhola. </author> <title> A compression method for clustered bit-vectors. </title> <journal> Information Processing Letters, </journal> <volume> 7(6) </volume> <pages> 308-311, </pages> <month> October </month> <year> 1978. </year>
Reference-contexts: The effectiveness of compression for an inverted list will vary with the choice of vector. One scheme, due to Teuhola <ref> [22] </ref>, is to use the vector V T = (b; 2b; 4b; 8b; 16b; : : :) ; where each list has an associated b value. An appropriate choice of b is the median runlength in the list [18], again with k coded in unary.
Reference: [23] <author> E. Ukkonen. </author> <title> Approximate string matching with q-grams and maximal matches. </title> <journal> Theoretical Computer Science, </journal> <volume> 92 </volume> <pages> 191-211, </pages> <year> 1992. </year>
Reference-contexts: In this index, the queryable entities are n-grams, that is, all n character substrings of the words in the lexicon. The concept of n-grams has been attributed to Shannon [21], and can also be used for tasks such as string distance measurement <ref> [23, 24] </ref>. Given an inverted file of n-grams, it is straightforward to retrieve strings that match a pattern. First, all of the n-grams in the pattern must be extracted.
Reference: [24] <author> J. Zobel and P. </author> <title> Dart. Approximate string matching for large lexicons. </title> <booktitle> In Australian Computer Science Conference, </booktitle> <pages> pages 379-390, </pages> <address> Christchurch, New Zealand, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: In this index, the queryable entities are n-grams, that is, all n character substrings of the words in the lexicon. The concept of n-grams has been attributed to Shannon [21], and can also be used for tasks such as string distance measurement <ref> [23, 24] </ref>. Given an inverted file of n-grams, it is straightforward to retrieve strings that match a pattern. First, all of the n-grams in the pattern must be extracted. <p> They can also be used for approximate matching|to find strings of similar but not identical spelling|and indeed appear to be the best approximate matching method <ref> [24] </ref>. 5.1 Naive inverted file n-gram indexing We first investigate indexes for unsorted lexicons, using as the only "improvement" the compression methods described in Section 4.1, without skipping. In Table 5 we show sizes of n-gram inverted file indexes for unsorted lexicons for n from 2 to 4.
Reference: [25] <author> J. Zobel, A. Moffat, and R. Sacks-Davis. </author> <title> An efficient indexing technique for full-text database systems. </title> <editor> In L.-Y. Yuan, editor, </editor> <booktitle> Proc. International Conference on Very Large Databases, </booktitle> <pages> pages 352-362, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year> <month> 22 </month>
Reference-contexts: Another possibility is to store the lexicon of the collection in main memory, eliminating the disk accesses needed to search for query terms and improving query performance <ref> [25] </ref>. Here we examine a further facility that can be provided if the lexicon is held in memory. The lexicon, which is part of the index, is a structure containing all of the words occurring in the database.
References-found: 25

