URL: http://www.ai.univie.ac.at/~juffi/publications/chess-ws.ps.gz
Refering-URL: http://www.ai.univie.ac.at/~juffi/lig/lig-bib.html
Root-URL: 
Email: E-mail: juffi@ai.univie.ac.at  
Title: Knowledge Discovery in Chess Databases: A Research Proposal  
Author: Johannes F urnkranz 
Address: Schottengasse 3, A-1010 Wien, Austria  
Affiliation: Austrian Research Institute for Artificial Intelligence  
Abstract: In this paper we argue that chess databases have a significant potential as a test-bed for techniques in the area of Knowledge Discovery in Databases (KDD). Conversely, we think that research in Artificial Intelligence has not yet come up with reasonable solutions for the knowledge representation and reasoning problems that are posed by knowledge-based computer chess programs, and consequently argue that KDD techniques could be useful for the advancement of various types of knowledge-based computer chess systems. Although we cannot present any concrete results, we hope to outline some fruitful directions for further research and exchange of ideas between the KDD and computer chess communities.
Abstract-found: 1
Intro-found: 1
Reference: [ Agrawal et al., 1995 ] <author> Rakesh Agrawal, Heikki Mannila, Ramakrishnan Srikant, Hannu Toivonen, and A. Inkeri Verkamo. </author> <title> Fast discovery of association rules. In U.M. </title> <editor> Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthu-rusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 307328. </pages> <publisher> AAAI Press, </publisher> <year> 1995. </year>
Reference-contexts: This tradition has carried over to KDD, but there are a a variety of other approaches with different aims. For example, the discovery of association rules <ref> [ Agrawal et al., 1995 ] </ref> or general dependencies [ Mannila and Raiha, 1994; Pfahringer and Kramer, 1995 ] might find interesting applications in chess databases for discovering typical piece-patterns, such as In many cases when white castles queen-sides, he will sooner or later play h4..
Reference: [ Bain and Srinivasan, 1995 ] <author> Michael Bain and Ashwin Srinivasan. </author> <title> Inductive logic programming with large-scale unstructured data. </title> <editor> In K. Furukawa, D. Michie, and S. Muggleton, editors, </editor> <booktitle> Machine Intelligence 14, </booktitle> <pages> pages 233267. </pages> <publisher> Oxford University Press, </publisher> <year> 1995. </year>
Reference-contexts: DUCE structured the KPa7KR task into a hierarchy of 13 concepts defined by a total of 553 rules. Shapiro's solution, however, consisted of 9 concepts with only 225 rules. Nevertheless DUCE's solution was found to be meaningful for a chess expert. [ Bain, 1994 ] and <ref> [ Bain and Srinivasan, 1995 ] </ref> tried to learn rules that predict the number of plies to a win with optimal play on both sides in the KRK endgame.
Reference: [ Bain, 1994 ] <author> Micheal Bain. </author> <title> Learning Logical Exceptions in Chess. </title> <type> PhD thesis, </type> <institution> Department of Statistics and Modelling Science, University of Strathclyde, </institution> <address> Scotland, </address> <year> 1994. </year>
Reference-contexts: DUCE structured the KPa7KR task into a hierarchy of 13 concepts defined by a total of 553 rules. Shapiro's solution, however, consisted of 9 concepts with only 225 rules. Nevertheless DUCE's solution was found to be meaningful for a chess expert. <ref> [ Bain, 1994 ] </ref> and [ Bain and Srinivasan, 1995 ] tried to learn rules that predict the number of plies to a win with optimal play on both sides in the KRK endgame.
Reference: [ Bratko and Michie, 1980 ] <author> Ivan Bratko and Donald Michie. </author> <title> A representation of pattern-knowledge in chess endgames. </title> <editor> In M.R.B. Clarke, editor, </editor> <booktitle> Advances in Computer Chess 2, </booktitle> <pages> pages 3154. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1980. </year>
Reference-contexts: The aim of this project was the development of an abstract programming language that would allow a chess master to advice a playing program in terms of this language. Many formalisms have subsequently been developed in the same spirit <ref> [ Bratko and Michie, 1980; George and Schaeffer, 1990 ] </ref> , most of them limited to certain endgames (see [ Michie and Bratko, 1991 ] for a bibliography).
Reference: [ Caruana and Freitag, 1994 ] <author> Rich Caruana and Dayne Fre-itag. </author> <title> Greedy attribute selection. In W.W. </title> <editor> Cohen and H. Hirsh, editors, </editor> <booktitle> Proceedings of the 11th International Conference on Machine Learning (ML-94), </booktitle> <pages> pages 2836, </pages> <address> New Brunswick, NJ, 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A systematic investigation of the various options in this or a similar task is certainly a promising endeavor. 3.4 Irrelevant Features A common problem in KDD is that the data sets usually contain many irrelevant features. This problem is typically solved with techniques for feature subset selection <ref> [ Caruana and Freitag, 1994; John et al., 1994 ] </ref> , i.e., techniques that filter out those attributes of the training set that appear to be irrelevant for the learning problem at hand.
Reference: [ Clarke, 1977 ] <author> M. R. B. Clarke. </author> <title> A quantitative study of king and pawn against king. </title> <editor> In M.R.B. Clarke, editor, </editor> <booktitle> Advances in Computer Chess, </booktitle> <pages> pages 108118. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1977. </year>
Reference-contexts: The earliest work on learning from a chess database is reported in [ Michalski and Negri, 1977 ] , where the inductive rule learning algorithm AQ [ Michalski, 1969 ] is applied to the KPK database described in <ref> [ Clarke, 1977 ] </ref> . The positions in the database were coded into 17 attributes describing important relations between the pieces. In this representation, rules with 80% predictive accuracy were learned from about 250 training examples. [ Quinlan, 1983 ] describes several experiments for learning rules for the KRKN endgame.
Reference: [ De Raedt and Van Laer, 1995 ] <author> Luc De Raedt and Wim Van Laer. </author> <title> Inductive constraint logic. </title> <booktitle> In Proceedings of the 5th Workshop on Algorithmic Learning Theory (ALT-95). </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: For this purpose, we generated 100 games of a player using an optimal strategy (rook side) vs. a player that plays randomly. From all positions and their associated optimal moves and bad mistakes (dropping the rook or stale-mating), we had the ILP system ICL <ref> [ De Raedt and Van Laer, 1995 ] </ref> learn predicates that check whether a given move is optimal or a bad mistake.
Reference: [ De Raedt, 1995 ] <editor> Luc De Raedt, editor. </editor> <booktitle> Advances in Inductive Logic Programming, volume 32 of Frontiers in Artificial Intelligence and Applications. </booktitle> <publisher> IOS Press, </publisher> <year> 1995. </year>
Reference-contexts: Most available chess databases, like the KRKN and the KRKPa7 datasets from the UCI repository of machine learning databases, conform to this format. However, research in the field of Inductive Logic Programming (ILP) <ref> [ Muggleton, 1992; De Raedt, 1995 ] </ref> has lead to the development of algorithms that are able to make use of background knowledge in full first-order horn-clause logic. Roughly speaking, these algorithms are concerned with the induction of PROLOG programs.
Reference: [ Donninger, 1996 ] <author> Chrilly Donninger. CHE: </author> <title> A graphical language for expressing chess knowledge. </title> <journal> ICCA Journal, </journal> <volume> 19(4):234241, </volume> <year> 1996. </year>
Reference-contexts: The last point is particularly important for KDD purposes, because there must be efficient ways for evaluating potential tests in discovered rules in order to allow efficient knowledge discovery in large-scale databases. <ref> [ Donninger, 1996 ] </ref> shows a promising step into the right direction by providing a very efficient interpreter of an extensible language for expressing certain characteristics of a board position. <p> However, the motivation to investigate such approaches has significantly declined with the somewhat unexpected success of brute-force programs. Some authors have investigated approaches to incorporate strategic long-term knowledge into conventional chess programs <ref> [ Kaindl, 1982; Opdahl and Tessem, 1994; Donninger, 1996 ] </ref> , 1 In the following, an optimal playing strategy refers to one that will lead to mate in the minimum number of moves. 2 See ICCA Journal 15 (4):235236, 1992. but the investigation of knowledge-based chess programs has practically come to
Reference: [ Fayyad et al., 1995 ] <editor> U.M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors. </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, </address> <year> 1995. </year>
Reference-contexts: Other techniques are able to discover temporal patterns [ Padmanabhan and Tuzhilin, 1996 ] or interesting deviations from the norm [ Klosgen, 1995 ] . For an excellent collection of papers on various KDD techniques consult <ref> [ Fayyad et al., 1995 ] </ref> .
Reference: [ Fayyad et al., 1996 ] <editor> Usama Fayyad, Gregory Piatetsky-Shapiro, and Padhraic Smyth. </editor> <title> From data mining to knowledge discovery in databases. </title> <journal> AI Magazine, </journal> <volume> 17(3):3754, </volume> <month> Fall </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Knowledge Discovery in Databases (KDD) or Data Mining is a rapidly growing research area which focuses on the discovery of useful and understandable pieces of knowledge from databases <ref> [ Frawley et al., 1992; Fayyad et al., 1996 ] </ref> . On the other hand, the rapid increase in computing power of personal computers and the simultaneous fall of hardware prices had a considerable impact on the chess playing community. <p> This type of knowledge can be elegantly coded into a relational first-order logic representation. 3.3 Data Selection An important step in the KDD process <ref> [ Fayyad et al., 1996 ] </ref> , that is widely neglected in KDD research, is the step of data selection, i.e., the creation of a training set from the raw data, which is suitable for the selected data mining technique.
Reference: [ Frawley et al., 1992 ] <author> William J. Frawley, Gregory Piatetsky-Shapiro, and Christopher J. Matheus. </author> <title> Knowledge discovery in databases: An overview. </title> <journal> AI Magazine, </journal> <volume> 13(3):5770, </volume> <month> Fall </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Knowledge Discovery in Databases (KDD) or Data Mining is a rapidly growing research area which focuses on the discovery of useful and understandable pieces of knowledge from databases <ref> [ Frawley et al., 1992; Fayyad et al., 1996 ] </ref> . On the other hand, the rapid increase in computing power of personal computers and the simultaneous fall of hardware prices had a considerable impact on the chess playing community.
Reference: [ Furnkranz and De Raedt, 1997 ] <author> Johannes Furnkranz and Luc De Raedt. </author> <title> Learning playing strategies from chess endgame databases: An ILP approach. </title> <note> In preparation, </note> <year> 1997. </year>
Reference-contexts: In <ref> [ Furnkranz and De Raedt, 1997 ] </ref> we have tried to use the same database (with slightly more complex background knowledge) for learning a playing strategy from the database. <p> It would be rewarding to develop algorithms for automatically discovering playing strategies for such endgames (see [ Muggleton, 1988 ] and <ref> [ Furnkranz and De Raedt, 1997 ] </ref> for some preliminary work). Such strategies could be both, easily implemented into a computer program as well as enrich the state-of-the-art of endgame theory.
Reference: [ Furnkranz, 1996 ] <author> Johannes Furnkranz. </author> <title> Machine learning in computer chess: The next generation. </title> <journal> ICCA Journal, </journal> <volume> 19(3):147160, </volume> <month> September </month> <year> 1996. </year>
Reference-contexts: In short, we will try to argue that chess is an interesting test-bed for ideas in the field of Knowledge Discovery in Databases. 2 Previous Work on KDD and Chess There are a variety of approaches that employ machine learning techniques in the domain of chess <ref> [ Furnkranz, 1996 ] </ref> . Several of them can be viewed in the KDD framework. This section will briefly discuss previous work that aimed at discovering chess knowledge from databases.
Reference: [ Furnkranz, 1997 ] <author> Johannes Furnkranz. </author> <title> Dimensionality reduction in ILP: A call to arms. </title> <booktitle> Submitted to the IJCAI-97 Workshop on Frontiers of Inductive Logic Programming, </booktitle> <year> 1997. </year>
Reference-contexts: In particular, equivalents of feature subset selection for inductive logic programming algorithms, a research area which has not yet received the attention that it deserves <ref> [ Furnkranz, 1997 ] </ref> , could be nicely studied in relational classification tasks in the domain of chess. 3.5 Noise Another issue that is usually of considerable importance is noise in the data. Noise is a commonly used term for all sorts of errors and inconsistencies in the data.
Reference: [ George and Schaeffer, 1990 ] <author> Micheal George and Jonathan Schaeffer. </author> <title> Chunking for experience. </title> <journal> ICCA Journal, </journal> <volume> 13(3):123132, </volume> <year> 1990. </year>
Reference-contexts: The aim of this project was the development of an abstract programming language that would allow a chess master to advice a playing program in terms of this language. Many formalisms have subsequently been developed in the same spirit <ref> [ Bratko and Michie, 1980; George and Schaeffer, 1990 ] </ref> , most of them limited to certain endgames (see [ Michie and Bratko, 1991 ] for a bibliography).
Reference: [ Hsu et al., 1990 ] <author> Feng-hsiung Hsu, Thomas S. Ananthara-man, Murray S. Campbell, and Andreas Nowatzyk. </author> <title> A grandmaster chess machine. </title> <publisher> Scientific American, </publisher> <address> 263(4):4450, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: These techniques are usually concerned with the adjustment of numerical weights and cannot be considered to be at the core of KDD research. The most notable approach is the work of <ref> [ Hsu et al., 1990 ] </ref> , where statistical techniques and limited look-ahead were combined to tune the weights of their world championship program DEEP THOUGHT to yield optimal performance in a database of grandmaster moves.
Reference: [ John et al., 1994 ] <author> George H. John, Ron Kohavi, and Karl Pfleger. </author> <title> Irrelevant features and the subset selection problem. In W.W. </title> <editor> Cohen and H. Hirsh, editors, </editor> <booktitle> Proceedings of the 11th International Conference on Machine Learning (ML-94), </booktitle> <pages> pages 121129, </pages> <address> New Brunswick, NJ, 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A systematic investigation of the various options in this or a similar task is certainly a promising endeavor. 3.4 Irrelevant Features A common problem in KDD is that the data sets usually contain many irrelevant features. This problem is typically solved with techniques for feature subset selection <ref> [ Caruana and Freitag, 1994; John et al., 1994 ] </ref> , i.e., techniques that filter out those attributes of the training set that appear to be irrelevant for the learning problem at hand.
Reference: [ Kaindl, 1982 ] <author> Hermann Kaindl. </author> <title> Positional long-range planning in computer chess. </title> <editor> In M. R. B. Clarke, editor, </editor> <booktitle> Advances in Computer Chess 3, </booktitle> <pages> pages 145167. </pages> <publisher> Pergamon Press, </publisher> <year> 1982. </year>
Reference-contexts: However, the motivation to investigate such approaches has significantly declined with the somewhat unexpected success of brute-force programs. Some authors have investigated approaches to incorporate strategic long-term knowledge into conventional chess programs <ref> [ Kaindl, 1982; Opdahl and Tessem, 1994; Donninger, 1996 ] </ref> , 1 In the following, an optimal playing strategy refers to one that will lead to mate in the minimum number of moves. 2 See ICCA Journal 15 (4):235236, 1992. but the investigation of knowledge-based chess programs has practically come to
Reference: [ Kerner, 1994 ] <author> Yaakov Kerner. </author> <title> Case-based evaluation in computer chess. </title> <editor> In M. Keane, J.P. Haton, and M. Man-ago, editors, </editor> <booktitle> Topics in Case-Based Reasoning (EWCBR-94), Lecture Notes in Artificial Intelligence, </booktitle> <address> Berlin, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: has recognized the potential of such programs, and has created the The Best Annotation Award which will be awarded annually for the best computer-generated annotation of a chess game. 2 Some preliminary work on using case-based reasoning for a strategic analysis of a given chess position can be found in <ref> [ Kerner, 1994; 1995 ] </ref> .
Reference: [ Kerner, 1995 ] <author> Yaakov Kerner. </author> <title> Learning strategies for explanation patterns: Basic game patterns with application to chess. </title> <editor> In A. Aamodt and M. Veloso, editors, </editor> <booktitle> Proceedings of the 1st International Conference on Case-Based Reasoning (ICCBR-95), Lecture Notes in Artificial Intelligence, </booktitle> <address> Berlin, 1995. </address> <publisher> Springer-Verlag. </publisher>
Reference: [ Klosgen, 1995 ] <author> Willi Klosgen. </author> <title> Efficient discovery of interesting statements in databases. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 4(1):5369, </volume> <year> 1995. </year>
Reference-contexts: Other techniques are able to discover temporal patterns [ Padmanabhan and Tuzhilin, 1996 ] or interesting deviations from the norm <ref> [ Klosgen, 1995 ] </ref> . For an excellent collection of papers on various KDD techniques consult [ Fayyad et al., 1995 ] .
Reference: [ Mannila and Raiha, 1994 ] <author> Heikki Mannila and K.-J. Raiha. </author> <title> Algorithms for inferring functional dependencies from relations. </title> <journal> Data & Knowledge Engineering, </journal> <volume> 12:8399, </volume> <year> 1994. </year>
Reference-contexts: This tradition has carried over to KDD, but there are a a variety of other approaches with different aims. For example, the discovery of association rules [ Agrawal et al., 1995 ] or general dependencies <ref> [ Mannila and Raiha, 1994; Pfahringer and Kramer, 1995 ] </ref> might find interesting applications in chess databases for discovering typical piece-patterns, such as In many cases when white castles queen-sides, he will sooner or later play h4..
Reference: [ Matheus, 1989 ] <author> Christopher J. Matheus. </author> <title> A constructive in-duction framework. </title> <booktitle> In Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <pages> pages 474475, </pages> <year> 1989. </year>
Reference-contexts: In machine learning the autonomous introduction of new concepts during the learning phase is commonly known as constructive induction <ref> [ Matheus, 1989 ] </ref> . Using constructive induction DUCE reduces the role of the chess expert to a mere evaluator of the suggested concepts instead of an inventor of new concepts. DUCE structured the KPa7KR task into a hierarchy of 13 concepts defined by a total of 553 rules.
Reference: [ Michalski and Negri, 1977 ] <author> R. Michalski and P. Negri. </author> <title> An experiment on inductive learning in chess endgames. </title> <editor> In Elcock and D. Michie, editors, </editor> <booktitle> Machine Intelligence 8, </booktitle> <pages> pages 175192. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1977. </year>
Reference-contexts: Additional attributes that encode potentially useful patterns like kings' opposition or the distance between certain pieces must be provided to the learning system. The earliest work on learning from a chess database is reported in <ref> [ Michalski and Negri, 1977 ] </ref> , where the inductive rule learning algorithm AQ [ Michalski, 1969 ] is applied to the KPK database described in [ Clarke, 1977 ] . The positions in the database were coded into 17 attributes describing important relations between the pieces.
Reference: [ Michalski, 1969 ] <author> Ryszard S. Michalski. </author> <title> On the quasi-minimal solution of the covering problem. </title> <booktitle> In Proceedings of the 5th International Symposium on Information Processing (FCIP-69), volume A3 (Switching Circuits), </booktitle> <pages> pages 125128, </pages> <address> Bled, Yugoslavia, </address> <year> 1969. </year>
Reference-contexts: Additional attributes that encode potentially useful patterns like kings' opposition or the distance between certain pieces must be provided to the learning system. The earliest work on learning from a chess database is reported in [ Michalski and Negri, 1977 ] , where the inductive rule learning algorithm AQ <ref> [ Michalski, 1969 ] </ref> is applied to the KPK database described in [ Clarke, 1977 ] . The positions in the database were coded into 17 attributes describing important relations between the pieces.
Reference: [ Michie and Bratko, 1991 ] <author> Donald Michie and Ivan Bratko. </author> <title> Comments to 'chunking for experience'. </title> <journal> ICCA Journal, </journal> <volume> 18(1):18, </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: Many formalisms have subsequently been developed in the same spirit [ Bratko and Michie, 1980; George and Schaeffer, 1990 ] , most of them limited to certain endgames (see <ref> [ Michie and Bratko, 1991 ] </ref> for a bibliography).
Reference: [ Morales, 1996 ] <author> Eduardo Morales. </author> <title> Learning playing strategies in chess. </title> <booktitle> Computational Intelligence, </booktitle> <address> 12(1):6587, </address> <year> 1996. </year>
Reference-contexts: Roughly speaking, these algorithms are concerned with the induction of PROLOG programs. The ability to use background knowledge in the form of PROLOG clauses allows systems such as PAL <ref> [ Morales, 1996 ] </ref> to formulate rules with complex predicates in the background knowledge. The rules may even employ a limited look-ahead by including conditions like make_move (Side,Piece,From,To,Pos,NewPos) and looking for discriminating patterns in the new position that results from the specified move.
Reference: [ Muggleton, 1988 ] <author> Stephen Muggleton. </author> <title> Inductive acquisition of chess strategies. </title> <editor> In J. E. Hayes, D. Michie, and J. Richards, editors, </editor> <booktitle> Machine Intelligence 11, chapter 17, </booktitle> <pages> pages 375387. </pages> <publisher> Clarendon Press, </publisher> <year> 1988. </year>
Reference-contexts: It would be rewarding to develop algorithms for automatically discovering playing strategies for such endgames (see <ref> [ Muggleton, 1988 ] </ref> and [ Furnkranz and De Raedt, 1997 ] for some preliminary work). Such strategies could be both, easily implemented into a computer program as well as enrich the state-of-the-art of endgame theory.
Reference: [ Muggleton, 1990 ] <author> Stephen Muggleton. </author> <title> Inductive Acquisition of Expert Knowledge. </title> <publisher> Turing Institute Press. Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Thus there have been several attempts to automate this process. [ Paterson, 1983 ] tried to automatically structure the KPK endgame using a clustering algorithm. The results have been negative, as the found hierarchy had no meaning to human experts. <ref> [ Muggleton, 1990 ] </ref> has applied DUCE to the KPa7KR task studied by [ Shapiro, 1987 ] . DUCE is a machine learning algorithm that is able to autonomously suggest high-level concepts to the user.
Reference: [ Muggleton, 1992 ] <author> Stephen H. Muggleton, </author> <title> editor. Inductive Logic Programming. </title> <publisher> Academic Press Ltd., </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: Most available chess databases, like the KRKN and the KRKPa7 datasets from the UCI repository of machine learning databases, conform to this format. However, research in the field of Inductive Logic Programming (ILP) <ref> [ Muggleton, 1992; De Raedt, 1995 ] </ref> has lead to the development of algorithms that are able to make use of background knowledge in full first-order horn-clause logic. Roughly speaking, these algorithms are concerned with the induction of PROLOG programs.
Reference: [ Nunn, 1992 ] <author> John Nunn. </author> <title> Secrets of Rook Endings. </title> <address> Batsford, </address> <year> 1992. </year>
Reference-contexts: GM John Nunn's effort to manually extract some of the knowledge that is implicitly contained in these databases resulted in a series of widely acknowledged endgame books <ref> [ Nunn, 1992; 1994b; 1995 ] </ref> , but Nunn readily admitted that he does not yet understand all aspects of the databases he analyzed [ Nunn, 1994a ] .
Reference: [ Nunn, 1994a ] <author> John Nunn. </author> <title> Extracting information from endgame databases. </title> <editor> In H. J. van den Herik, I. S. Her-schberg, and J. W. H. M. Uiterwijk, editors, </editor> <booktitle> Advances in Computer Chess 7, pages 1934. </booktitle> <institution> University of Limburg, </institution> <year> 1994. </year>
Reference-contexts: John Nunn's effort to manually extract some of the knowledge that is implicitly contained in these databases resulted in a series of widely acknowledged endgame books [ Nunn, 1992; 1994b; 1995 ] , but Nunn readily admitted that he does not yet understand all aspects of the databases he analyzed <ref> [ Nunn, 1994a ] </ref> . It would be rewarding to develop algorithms for automatically discovering playing strategies for such endgames (see [ Muggleton, 1988 ] and [ Furnkranz and De Raedt, 1997 ] for some preliminary work).
Reference: [ Nunn, 1994b ] <author> John Nunn. </author> <title> Secrets of Pawnless Endings. </title> <address> Batsford, </address> <year> 1994. </year>
Reference: [ Nunn, 1995 ] <author> John Nunn. </author> <title> Secrets of Minor-Piece Endings. </title> <address> Batsford, </address> <year> 1995. </year>
Reference: [ Opdahl and Tessem, 1994 ] <author> Andreas L. Opdahl and Bjornar Tessem. </author> <title> Long-term planning in computer chess. </title> <editor> In H. J. van den Herik, I. S. Herschberg, and J. W. H. M. Uiter-wijk, editors, </editor> <booktitle> Advances in Computer Chess 7. </booktitle> <institution> University of Limburg, </institution> <year> 1994. </year>
Reference-contexts: However, the motivation to investigate such approaches has significantly declined with the somewhat unexpected success of brute-force programs. Some authors have investigated approaches to incorporate strategic long-term knowledge into conventional chess programs <ref> [ Kaindl, 1982; Opdahl and Tessem, 1994; Donninger, 1996 ] </ref> , 1 In the following, an optimal playing strategy refers to one that will lead to mate in the minimum number of moves. 2 See ICCA Journal 15 (4):235236, 1992. but the investigation of knowledge-based chess programs has practically come to
Reference: [ Padmanabhan and Tuzhilin, 1996 ] <author> B. Padmanabhan and A. Tuzhilin. </author> <title> Pattern discovery in temporal databases: A temporal logic approach. </title> <editor> In E. Simoudis, J. Han, and U.M. Fayyad, editors, </editor> <booktitle> Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 351354, </pages> <address> Portland, OR, 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Other techniques are able to discover temporal patterns <ref> [ Padmanabhan and Tuzhilin, 1996 ] </ref> or interesting deviations from the norm [ Klosgen, 1995 ] . For an excellent collection of papers on various KDD techniques consult [ Fayyad et al., 1995 ] .
Reference: [ Paterson, 1983 ] <author> A. Paterson. </author> <title> An attempt to use CLUSTER to synthesise humanly intelligible subproblems for the KPK chess endgame. </title> <type> Technical Report UIUCDCS-R-83-1156, </type> <institution> University of Illinois, Urbana, IL, </institution> <year> 1983. </year>
Reference-contexts: However, the problem of decomposing the search space into easily manageable subproblems again is a task that requires extensive collaboration with a human expert. Thus there have been several attempts to automate this process. <ref> [ Paterson, 1983 ] </ref> tried to automatically structure the KPK endgame using a clustering algorithm. The results have been negative, as the found hierarchy had no meaning to human experts. [ Muggleton, 1990 ] has applied DUCE to the KPa7KR task studied by [ Shapiro, 1987 ] .
Reference: [ Pfahringer and Kramer, 1995 ] <author> Bernhard Pfahringer and Stefan Kramer. </author> <title> Compression-based evaluation of partial determinations. In U.M. </title> <editor> Fayyad and R. Uthurusamy, editors, </editor> <booktitle> Proceedings of the 1st International Conference on Knowledge Discovery and Data Mining (KDD-95), </booktitle> <pages> pages 234239, </pages> <address> Montreal, Canada, 1995. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: This tradition has carried over to KDD, but there are a a variety of other approaches with different aims. For example, the discovery of association rules [ Agrawal et al., 1995 ] or general dependencies <ref> [ Mannila and Raiha, 1994; Pfahringer and Kramer, 1995 ] </ref> might find interesting applications in chess databases for discovering typical piece-patterns, such as In many cases when white castles queen-sides, he will sooner or later play h4..
Reference: [ Quinlan, 1983 ] <author> J. Ross Quinlan. </author> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 463482. </pages> <publisher> Tioga, </publisher> <address> Palo Alto, </address> <year> 1983. </year>
Reference-contexts: The positions in the database were coded into 17 attributes describing important relations between the pieces. In this representation, rules with 80% predictive accuracy were learned from about 250 training examples. <ref> [ Quinlan, 1983 ] </ref> describes several experiments for learning rules for the KRKN endgame. More specifically, he used his decision tree learning algorithm ID3 to discover recognition rules for positions of the KRKN endgame that are lost-in-2-ply and lost-in-3-ply respectively.
Reference: [ Roycroft, 1988 ] <author> A. J. Roycroft. </author> <title> Expert against oracle. </title> <editor> In J. E. Hayes, D. Michie, and J. Richards, editors, </editor> <booktitle> Machine Intelligence 11, </booktitle> <pages> pages 347373. </pages> <publisher> Oxford University Press, Oxford, </publisher> <address> UK, </address> <year> 1988. </year>
Reference-contexts: As an example consider the KBBKN endgame, which was considered to be a draw for a long time, and was shown to be a win in at most 66 moves for all but some trivial cases <ref> [ Roycroft, 1988 ] </ref> . On the other hand, many of these endgame databases are not thoroughly understood by human experts. <p> The most famous example are the attempts of grandmasters to defeat a perfect KQKR database within 50 moves or the attempt of an endgame specialist to defeat a perfect database in the almost undocumented and very difficult KBBKN endgame <ref> [ Roycroft, 1988 ] </ref> .
Reference: [ Sammut, 1996 ] <author> Claude Sammut. </author> <title> Automatic construction of reactive control systems using symbolic machine learning. </title> <journal> Knowledge Engineering Review, </journal> <volume> 11(1):2742, </volume> <year> 1996. </year>
Reference-contexts: The learned rules were rather complicated, because the provided background knowledge was at a fairly low level of abstraction (distances between pieces). All in all, the results had a striking similarity with results obtained in the area of behavioral cloning <ref> [ Sammut, 1996 ] </ref> . The approaches discussed so far induced concepts from simple endgame databases and suitable background knowledge. Databases of middle-game positions or entire games have so far only been used for the tuning of evaluation functions.
Reference: [ Shapiro and Michie, 1986 ] <author> Alen D. Shapiro and Donald Michie. </author> <title> A self commenting facility for inductively synthesized endgame expertise. </title> <editor> In D. F. Beal, editor, </editor> <booktitle> Advances in Computer Chess 4, </booktitle> <pages> pages 147165. </pages> <publisher> Pergamon, Oxford, </publisher> <year> 1986. </year>
Reference-contexts: This rule-debugging process was aided by a self-commenting facility that displayed traces of the classification rules in plain English <ref> [ Shapiro and Michie, 1986 ] </ref> . A similar semi-autonomous process for refining the attribute set was used in [ Weill, 1994 ] to generate decision trees for the KQKQ endgame.
Reference: [ Shapiro and Niblett, 1982 ] <author> Alen D. Shapiro and Tim Niblett. </author> <title> Automatic induction of classification rules for a chess endgame. </title> <editor> In M. R. B. Clarke, editor, </editor> <booktitle> Advances in Computer Chess 3, </booktitle> <pages> pages 7392. </pages> <publisher> Pergamon, Oxford, </publisher> <year> 1982. </year>
Reference-contexts: However, no results from this endeavor have been published. A severe problem with this and similar experiments was that, although the derived decision trees were shown to be correct and faster in classification than extensive search algorithms, they were also incomprehensible to chess experts. <ref> [ Shapiro and Niblett, 1982 ] </ref> tried to alleviate this problem by decomposing it into a hierarchy of smaller sub-problems that could be tackled independently. A set of rules was induced for each of the sub-problems which together yielded a more understandable result.
Reference: [ Shapiro, 1987 ] <author> Alen D. Shapiro. </author> <title> Structured Induction in Expert Systems. </title> <publisher> Turing Institute Press. Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: A set of rules was induced for each of the sub-problems which together yielded a more understandable result. This process of structured induction has been employed to learn correct classification procedures for the KPK and the KPa7KR endgames <ref> [ Shapiro, 1987 ] </ref> . An endgame expert helped to structure the search space and to design the relevant attributes. The rules for the KPa7KR endgames were generated without using a database as an oracle. <p> The results have been negative, as the found hierarchy had no meaning to human experts. [ Muggleton, 1990 ] has applied DUCE to the KPa7KR task studied by <ref> [ Shapiro, 1987 ] </ref> . DUCE is a machine learning algorithm that is able to autonomously suggest high-level concepts to the user.
Reference: [ Tesauro, 1995 ] <author> Gerald Tesauro. </author> <title> Temporal difference learning and TD-Gammon. </title> <journal> Communications of the ACM, </journal> <volume> 38(3):5868, </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: However, with the success of Tesauro's backgammon player, research in this area shifted gradually from tuning on databases to tuning by self-play via temporal-difference learning <ref> [ Tesauro, 1995 ] </ref> . 3 Why Chess for KDD? Many of the datasets that have been extensively studied in inductive symbolic machine learning have become standard benchmark problems.
Reference: [ Thompson, 1996 ] <author> Ken Thompson. </author> <title> 6-piece endgames. </title> <journal> ICCA Journal, </journal> <volume> 19(4):215226, </volume> <year> 1996. </year>
Reference-contexts: Every commercial chess playing program has access to huge opening databases. All endgames with up to 5 pieces are available on three CD-Roms and certain types of 6-piece endgames are on the way. These endgames, however, already pose serious challenges to commonly available storage media <ref> [ Thompson, 1996 ] </ref> . A simple 3-piece endgame database already has about 64 3 entries (including some illegal positions), which are usually stored in a highly compressed format (for example by using board symmetries). 3.2 Background Knowledge Most KDD techniques assume a data representation in the so-called attribute-value format.
Reference: [ Verhoef and Wesselius, 1987 ] <author> T. F. Verhoef and J. H. Wes-selius. Two-ply KRKN: </author> <title> Safely overtaking Quinlan. </title> <journal> ICCA Journal, </journal> <volume> 10(4):181190, </volume> <year> 1987. </year>
Reference-contexts: From less than 10% of the possible KRKN positions, ID3 was able to derive a tree that committed only 2 errors on a test set of 10,000 randomly chosen positions (these errors were later corrected in <ref> [ Verhoef and Wesselius, 1987 ] </ref> ). Quinlan noted that this achievement was only possible with a careful choice of the attributes that were used to represent the positions. Finding the right set of attributes for the lost-in-2-ply task required three weeks.
Reference: [ Weill, 1994 ] <author> Jean-Christophe Weill. </author> <title> How hard is the correct coding of an easy endgame. </title> <editor> In H. J. van den Herik, I. S. Herschberg, and J. W. H. M. Uiterwijk, editors, </editor> <booktitle> Advances in Computer Chess 7, </booktitle> <pages> pages 163176. </pages> <institution> University of Limburg, </institution> <year> 1994. </year>
Reference-contexts: This rule-debugging process was aided by a self-commenting facility that displayed traces of the classification rules in plain English [ Shapiro and Michie, 1986 ] . A similar semi-autonomous process for refining the attribute set was used in <ref> [ Weill, 1994 ] </ref> to generate decision trees for the KQKQ endgame. However, the problem of decomposing the search space into easily manageable subproblems again is a task that requires extensive collaboration with a human expert.
Reference: [ Zobrist and Carlson, 1973 ] <author> Albert L. Zobrist and Fred-eric R. Carlson. </author> <title> An advice-taking chess computer. </title> <publisher> Scientific American, </publisher> <pages> pages 93105, </pages> <month> June </month> <year> 1973. </year>
Reference-contexts: Quinlan's work on the KRKN database has nicely illustrated the need for an appropriate vocabulary for learning (see section 2). However, such a knowledge representation formalism for chess concepts could also contribute significantly to computer chess in general. This has already been recognized in <ref> [ Zobrist and Carlson, 1973 ] </ref> , where an advice-taking chess program is described. The aim of this project was the development of an abstract programming language that would allow a chess master to advice a playing program in terms of this language.
References-found: 50

