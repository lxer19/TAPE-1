URL: http://charm.cs.uiuc.edu/version2/papers/PerFeedbackICPP94.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/PerFeedbackICPP94.html
Root-URL: http://www.cs.uiuc.edu
Email: email: sinhajkale@cs.uiuc.edu  
Title: A framework for intelligent performance feedback  
Author: Amitabh B. Sinha Laxmikant V. Kale 
Keyword: performance feedback, object-based, message-driven, intelligent anal ysis, post-mortem  
Address: Urbana. Urbana, IL 61801.  
Affiliation: Department of Computer Science, University of Illinois,  
Abstract: The significant gap between peak and realized performance of parallel machines motivates the need for performance analysis. Contemporary tools provide only generic measurement, rather than program-specific information and analysis. An object-oriented and message-driven language, such as Charm, presents opportunities for both program-specific feedback and automatic performance analysis We present a framework in which specific and intelligent feedback can be given to the user about their parallel program. The framework will use information about the parallel program generated at compile-time and at run-time to analyze its performance using general expertise and specific algorithms in performance analysis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kale L.V. </author> <title> The Chare Kernel Parallel Programming System Programming System. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: It is essential to have a language with an adequately rich set of primitives, which provide the performance analysis system with a refined understanding of the events that occur during the execution of a program and their potential impact on performance. We have chosen Charm <ref> [1] </ref>, a portable, object-based, and message-driven 1 parallel programming language, as the base language. The object-oriented and message-driven execution model of Charm provides a great deal of specific information about parallel programs written in Charm.
Reference: [2] <author> A. B. Sinha and L. V. Kale. </author> <title> A load balancing strategy for prioritized execution of tasks. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: On arrival at the destination process the associated code-block is automatically executed by the system. 1 specific information about Charm programs. The display and analysis components are part of the performance feedback tool called Projections. A preliminary version of Projections is described in <ref> [2, 3] </ref>. It had only a limited display capability: that of showing information about system attributes, such as utilization and number of parallel objects created. The display component added in the new version of Projections provides specific information about application program attributes. <p> We describe these components in more detail in this section. 5.1 The display component A preliminary version of the display component of Projections was presented in <ref> [2, 3] </ref>. The display component provides the user with a mechanism to view: 1. System specific performance information. This includes properties of system, such as busy time, queue lengths, creation and processing of messages, and creation of new tasks.
Reference: [3] <author> L. V. Kale and A. B. Sinha. </author> <title> Projections: a preliminary performance tool for charm. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: On arrival at the destination process the associated code-block is automatically executed by the system. 1 specific information about Charm programs. The display and analysis components are part of the performance feedback tool called Projections. A preliminary version of Projections is described in <ref> [2, 3] </ref>. It had only a limited display capability: that of showing information about system attributes, such as utilization and number of parallel objects created. The display component added in the new version of Projections provides specific information about application program attributes. <p> We describe these components in more detail in this section. 5.1 The display component A preliminary version of the display component of Projections was presented in <ref> [2, 3] </ref>. The display component provides the user with a mechanism to view: 1. System specific performance information. This includes properties of system, such as busy time, queue lengths, creation and processing of messages, and creation of new tasks.
Reference: [4] <author> L. V. Kale and A. B. Sinha. </author> <title> Information sharing in parallel programs. </title> <booktitle> In International Parallel Processing Symposium, </booktitle> <month> April, </month> <year> 1994. </year>
Reference-contexts: A chare that is created without any specified placement is automatically placed under the control of the dynamic load balancing strategy which specifies its placement. Shared variables and their access: In previous work <ref> [4] </ref>, we have discussed the motivation and details for providing a limited number of specific information sharing mechanisms in Charm. <p> In such cases, it might be better to make the variable into an entry in a distributed table. * If a monotonic variable is updated frequently, the spanning tree <ref> [4] </ref> implementation should be chosen. However, if it is updated rarely then the flooding [4] implementation should be chosen. * If a large number of entries in the distributed table are accessed only once, and if the entries were located on a processor distinct from the one that inserted it into <p> In such cases, it might be better to make the variable into an entry in a distributed table. * If a monotonic variable is updated frequently, the spanning tree <ref> [4] </ref> implementation should be chosen. However, if it is updated rarely then the flooding [4] implementation should be chosen. * If a large number of entries in the distributed table are accessed only once, and if the entries were located on a processor distinct from the one that inserted it into the table, or the one that accessed it, the cost of insert is the
Reference: [5] <author> A. Gursoy and L. V. Kale. Dagger: </author> <title> Combining the benefits of synchronous and asynchronous communication styles. </title> <type> Technical Report 93-3, </type> <institution> Parallel Programming Laboratory, Department of Computer Science, University of Illinois, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Synchronization characteristics: The synchronization requirements of a Charm program are not easily available either statically or dynamically. However, information about object-level synchronization can be acquired automatically in Dagger <ref> [5] </ref>, which is a high-level notation on top of Charm. Dagger allows the user to easily express synchronization even in asynchronous message-driven execution models. Further, system-level (across all objects) synchronization can be identified if a known library such as the reduction library is used.
Reference: [6] <author> Terry Disz and Ewing Lusk. </author> <title> A graphical tool for observing the behavior of parallel logic programs. </title> <type> Technical Report CSRD 746, </type> <institution> Argonne National Laboratory, </institution> <month> February </month> <year> 1988. </year>
Reference-contexts: Our current analysis component consists of critical path analysis and some granularity and placement analysis. We are in the process of implementing other portions of the decision-tree. 3 This view is inspired by the performance tool developed at the Argonne National Laboratory called Upshot <ref> [6] </ref>. 8 9 The process of analysis is designed to be iterative.
Reference: [7] <author> Leah H. Jamieson. </author> <title> Characterizing parallel algorithms. </title> <editor> In Leah H. Jamieson, Dennis Gannon, and Robert J. Douglass, editors, </editor> <title> The characteristics of parallel algorithms. </title> <publisher> The MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: This could be overcome if the tool had additional information of the structure of the object itself, such as that provided by the Dagger notation. 7 Discussion and future work In previous work, Jamieson <ref> [7] </ref> has used the characteristics of parallel algorithms, in conjunction with the characteristics of parallel architectures, to provide an understanding of how well the algorithm is suited to different architectures.
Reference: [8] <author> Jeffrey K. Hollingsworth and Barton P. Miller. </author> <title> Dynamic control of performance monitoring on large scale parallel systems. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <month> July 19-23 </month> <year> 1994. </year> <month> 14 </month>
Reference-contexts: Recently, Hollingsworth and Miller <ref> [8] </ref>, have developed an approach called the W 3 model, which attempts to reduce the amount of data traced for parallel 12 program execution 13 program performance analysis by intelligently activating the trace dynamically when and where it's needed.
References-found: 8

