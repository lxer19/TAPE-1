URL: ftp://ftp.cs.arizona.edu/reports/1994/TR94-33.ps.Z
Refering-URL: http://www.cs.arizona.edu/schooner/html-files/publications.html
Root-URL: http://www.cs.arizona.edu
Title: CONSTRUCTING SCIENTIFIC APPLICATIONS FROM HETEROGENEOUS RESOURCES  
Author: Patrick T. Homer 
Degree: (Ph.D. Dissertation)  
Note: This work supported in part by the National Science Foundation under grant ASC-9204021 and by the National Aeronautics and Space Administration under GSRP grant NGT-50966.  
Address: Tucson, Arizona 85721  
Affiliation: Department of Computer Science THE UNIVERSITY OF ARIZONA  
Date: December 1, 1994  
Pubnum: TR 94-33  
Abstract-found: 0
Intro-found: 1
Reference: [Allen82] <editor> M.P. Allen and D.J. Tildesley. </editor> <booktitle> Computer simulation of liquids. CCP5 Quarterly 6, </booktitle> <month> 4 </month> <year> (1982). </year>
Reference-contexts: This requires no change to the network and only one AVS module. 4.3 Molecular Dynamics This program computes constant energy-volume-number particle dynamics for Lennard-Jones 12-6 interparticle forces using an algorithm based on <ref> [Allen82] </ref>. On each time step, it advances the positions of the particles, and then computes the forces among the particles, and the kinetic energy and thermodynamics of the system. The particles reside in a unit cube and their initial positions are uniformly distributed within the cube.
Reference: [Almes85] <author> G.T. Almes, A.P. Black, E.D. Lazowska, and J.D. Noe. </author> <title> The Eden system: A technical review. </title> <journal> IEEE Transactions on Software Engineering SE-11, </journal> <month> 1 (January </month> <year> 1985), </year> <pages> 43-59. </pages>
Reference-contexts: Additional optimizations to improve performance are discussed in Chapter 7. 3.6 Other RPC Systems Many RPC systems have been developed since the original work described in [Nelson81]. Most offer features similar to Schooners RPC, including external data representations, specification languages, and stub compilers <ref> [Almes85, Birrell84, Sun90, Xerox81] </ref>.
Reference: [Ananda92] <author> A.L. Ananda, B.H. Tay, and E.K. Koh. </author> <title> A survey of asynchronous remote procedure calls. </title> <booktitle> Operating Systems Review 26, </booktitle> <month> 2 (April </month> <year> 1992), </year> <pages> 92-109. </pages>
Reference-contexts: The disadvantages listed in the previous section for system RPCs also apply to both of these systems. 3.6.3 Asynchronous RPC A number of RPC systems have been implemented that change the semantics of the remote procedure call to increase the concurrency of the client-server pair <ref> [Ananda92] </ref>. The goal is to allow parallel execution of the client and server, specifically by allowing the client to continue executing after invoking the service rather than blocking until receiving the reply from the server. An example of such a system is ASTRA [Ananda91].
Reference: [Ananda91] <author> A.L. Ananda, B.H. Tay and E.K. Koh. </author> <title> ASTRAAn asynchronous remote procedure call facility. </title> <booktitle> Proceedings of the 11th International Conference on Distributed Computing Systems, </booktitle> <address> Arlington TX (May 1991), </address> <pages> 172-179. </pages>
Reference-contexts: The goal is to allow parallel execution of the client and server, specifically by allowing the client to continue executing after invoking the service rather than blocking until receiving the reply from the server. An example of such a system is ASTRA <ref> [Ananda91] </ref>. This system uses a reliable delivery system to guarantee delivery of the invocation message, and to retain the ordering of invocations at the server. The procedure invocation returns a unique identifier to the client that can later be used to claim the reply from the server.
Reference: [Andrews87] <author> G.R. Andrews, R.D. Schlichting, R. Hayes, and T.D.M. Purdin. </author> <title> The design of the Saguaro distributed operating system. </title> <journal> IEEE Transactions on Software Engineering SE-13, </journal> <month> 1 (January </month> <year> 1987), </year> <pages> 104-118. </pages>
Reference-contexts: Each service can also be used for other purposes as well; for example, the UTS type specification language has also been used as the basis for a command language interpreter <ref> [Andrews87] </ref>. Table 3-1 outlines the steps required to adapt an application to utilize Schooners facilities, illustrating the role played by each service.
Reference: [AVS92] <author> Advanced Visual Systems Inc. </author> <title> AVS Developers Guide (Release 4.0), Part number: 320-0013-02, Rev B, Advanced Visual Systems Inc., </title> <address> Waltham, Mass., </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Incremental changes to the system have been made including additions to UTS and the list of supported machines. Finally, a review of related RPC systems was provided. 56 57 Chapter 4 SCHOONER/AVS META-COMPUTATIONS The basic Schooner system has been combined with the AVS scientific visualization system <ref> [AVS92] </ref> to create a software platform for executing meta-computations that allows the user to monitor and steer scientific simulations. <p> Work on the simulation executive is also underway. The focus in this effort is on providing sophisticated capabilities to interact with codes, as well as the ability to substitute different codes at varying degrees of fidelity. A scientific visualization system such as AVS <ref> [AVS92] </ref> or Khoros [Rasure91, Mercurio92] will likely form a major component of the finished product. The simulation executive is a meta-computation that must support diverse software and hardware elements on local and wide-area networks. The user should see a single integrated tool, not individual codes that execute in isolation.
Reference: [Becker94] <author> T. Becker. </author> <title> Application-transparent fault tolerance in distributed systems. </title> <booktitle> Proceedings of the 2nd International Workshop on Configurable Distributed Systems, </booktitle> <address> Pittsburgh, PA (March 1994), </address> <pages> 36-45. </pages>
Reference-contexts: In addition to the configuration features needed for an interconnection system, many systems also support the ability to automatically update software for different target machines [Callahan91], and fault-tolerance features such as restarting components when failures occur and 36 providing atomic actions in the communications layer <ref> [Becker94] </ref>. While interesting in their own context, these features are not necessary in an interconnection system. For example, [Zimmerman94] describes a system that supports the initial configuration and subsequent re-configuration of long-running applications.
Reference: [Beguelin91] <author> A. Beguelin, J.J. Dongarra, G.A. Geist, R. Manchek, </author> <title> and V.S. Sunderam. Graphical development tools for network-based concurrent supercomputing. </title> <booktitle> Supercomputing 91, </booktitle> <address> Albuquerque, NM (November 1991), </address> <pages> 435-444. </pages>
Reference-contexts: categories based on the specific goals of each: Message passing systems that are designed to facilitate the implementation of parallel algo rithms, Systems that seek to automatically recognize heterogeneity in an application, and Systems that provide configuration management capabilities for distributed computations. 2.1 Message Passing Systems Systems such as PVM <ref> [Sunderam90, Beguelin91] </ref>, p4 [Butler92], APPL [Quealy93], Zipcode [Skjellum93] and others, are representative of a class of systems that provides general support for constructing parallel programs using a collection of (in some cases, heterogeneous) machines. 2.1.1 PVM PVM provides a set of library routines, callable from C or FORTRAN programs, that implements: <p> Within this model, however, parallel algorithms can be used by encapsulating the parallel algorithm inside a component, as illustrated in Figure 3-2. These parallel algorithms can execute on specialized hardware such as hypercubes, or could even be realized using a system such as PVM on a collection of workstations <ref> [Sunderam90, Beguelin91] </ref>. In either case, the role of Schooner is to connect the procedure to the other parts of the application. <p> Once those are complete, the ow becomes single-threaded again for the reply back to the AVS co-routine. Recently, the neural net code has been ported to run on an Intel Paragon using Intels message library, and on a cluster of Sun workstations using the PVM message-passing system <ref> [Sunderam90, Beguelin91] </ref>. Both of these versions employ the same parallel algorithm as the Sequent version, but make use of messages to exchange boundary values between the processes. Multiple implementations provide greater exibility when running experiments.
Reference: [Bergman91] <author> L. Bergman, H. Braun, A. Kolawa, A. Kuppermann, R. Mechoso, P. Messina and J. Morrison. </author> <title> CASA Gigabit Network Testbed: 1991 Annual Report. CCSF-3-91, Caltech Concurrent Supercomputing Facilities, </title> <institution> California Institute of Technology, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Both of these characteristics are approached but not fully realized in existing systems. A specific example of this class of application is the global climate modelling project [Mechoso92, Mechoso91] being done as part of the CASA gigabit network testbed <ref> [Bergman91] </ref>. This project has two goals. The first is to improve two global models, one modelling atmospheric circulation and the other oceanic circulation.
Reference: [Bershad87] <author> B.N. Bershad, D.T. Ching, E.D. Lazowska, J. Sanislo, and M. Schwartz. </author> <title> A remote procedure call facility for interconnecting heterogeneous computer systems. </title> <journal> IEEE Transactions on Software Engineering SE-13, </journal> <month> 8 (August </month> <year> 1987), </year> <pages> 880-894. </pages>
Reference-contexts: Most offer features similar to Schooners RPC, including external data representations, specification languages, and stub compilers [Almes85, Birrell84, Sun90, Xerox81]. Several of these systems also emphasize heterogeneity, including Matchmaker [Jones85], Horus [Gibbons87], HRPC (Heterogeneous RPC) <ref> [Bershad87] </ref> and Cicero/Nestor [Huang94]. 3.6.1 Basic RPC Paradigm Most RPC systems use a client-server paradigm, where the client is the process requesting a service by initiating the RPC and the server is the process that will carry out the service. <p> In particular, systems that support heterogeneity and those supporting a variation on RPC known as asynchronous RPC. 3.6.2 RPC Systems that Support Heterogeneity HRPC (Heterogeneous RPC) provided the basis for the Heterogeneous Computer Systems (HCS) project at the University of Washington <ref> [Bershad87] </ref>. The overall goal of HCS is to provide a way to simplify the interconnection of heterogeneous computer systems. HRPC is the cornerstone of the effort, providing a client/server interface for a variety of machines and operating systems.
Reference: [Birrell84] <author> A.D. Birrell and B.J. Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Transactions on Computer Systems 2, </journal> <month> 1 (Feb. </month> <year> 1984), </year> <pages> 39-59. </pages>
Reference-contexts: Additional optimizations to improve performance are discussed in Chapter 7. 3.6 Other RPC Systems Many RPC systems have been developed since the original work described in [Nelson81]. Most offer features similar to Schooners RPC, including external data representations, specification languages, and stub compilers <ref> [Almes85, Birrell84, Sun90, Xerox81] </ref>.
Reference: [Black87] <author> A. Black, N.C. Hutchinson, E. Jul, H. Levy, and L. Carter. </author> <title> Distribution and abstract types in Emerald. </title> <journal> IEEE Transactions on Software Engineering SE-13, </journal> <month> 1 (January </month> <year> 1987), </year> <pages> 65-76. </pages>
Reference-contexts: There is one stub compiler for each supported programming language. Currently, Schooner has stub compilers for C and FORTRAN; various versions of the predecessor MLP system also supported Pascal, Icon [Griswold90], and Emerald <ref> [Black86, Black87, Hayes90] </ref>. After stubs for a component are generated from the specification, they are compiled using the appropriate language processor. The resulting object module is then linked with the users code, the UTS libraries, and the Schooner runtime support libraries to produce an executable.
Reference: [Black86] <author> A. Black, N.C. Hutchinson, E. Jul, and H. Levy. </author> <title> Object structure in the Emerald system. </title> <booktitle> Proceedings of the Conference on Object-Oriented Programming Systems, Languages and Applications, </booktitle> <month> (October </month> <year> 1986), </year> <pages> 78-86. </pages>
Reference-contexts: There is one stub compiler for each supported programming language. Currently, Schooner has stub compilers for C and FORTRAN; various versions of the predecessor MLP system also supported Pascal, Icon [Griswold90], and Emerald <ref> [Black86, Black87, Hayes90] </ref>. After stubs for a component are generated from the specification, they are compiled using the appropriate language processor. The resulting object module is then linked with the users code, the UTS libraries, and the Schooner runtime support libraries to produce an executable.
Reference: [Butler92] <author> R. Butler and E. Lusk. </author> <title> Users Guide to the p4 Parallel Programming System. </title> <type> Technical Report ANL-92/17. </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory. </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: the specific goals of each: Message passing systems that are designed to facilitate the implementation of parallel algo rithms, Systems that seek to automatically recognize heterogeneity in an application, and Systems that provide configuration management capabilities for distributed computations. 2.1 Message Passing Systems Systems such as PVM [Sunderam90, Beguelin91], p4 <ref> [Butler92] </ref>, APPL [Quealy93], Zipcode [Skjellum93] and others, are representative of a class of systems that provides general support for constructing parallel programs using a collection of (in some cases, heterogeneous) machines. 2.1.1 PVM PVM provides a set of library routines, callable from C or FORTRAN programs, that implements: asynchronous message passing
Reference: [Callahan91] <author> J.R. Callahan and J.M. Purtilo. </author> <title> A packaging system for heterogeneous execution environments. </title> <journal> IEEE Transactions on Software Engineering 17, </journal> <month> 6 (June </month> <year> 1991), </year> <pages> 626-635. </pages>
Reference-contexts: In addition to the configuration features needed for an interconnection system, many systems also support the ability to automatically update software for different target machines <ref> [Callahan91] </ref>, and fault-tolerance features such as restarting components when failures occur and 36 providing atomic actions in the communications layer [Becker94]. While interesting in their own context, these features are not necessary in an interconnection system. <p> The ability to place extra processes in the software bus also allows for profiling and network monitoring. The Polygen system <ref> [Callahan91] </ref> uses Polylith to provide a higher-level packaging service that builds the binaries for each module of the application. A module is created for the intended architecture by linking its object form with the appropriate stubs, conversion routines, and communication libraries.
Reference: [Chen93] <author> S. Chen, M.M. Eshaghian, A. Khokhar, and M.E. Shaaban. </author> <title> A selection theory and methodology for heterogeneous supercomputing. </title> <booktitle> Proceedings: Workshop on Heterogeneous Processing, </booktitle> <address> Newport Beach, CA (April 1993), </address> <pages> 15-22. </pages>
Reference-contexts: programmer familiar with the parallel constructs used in the message-passing libraries, this is not too difficult, but it can be a serious drawback for someone wanting to connect a collection of vector codes. 2.2 Systems That Recognize Heterogeneity Exploiting heterogeneity in scientific applications is the goal of several research projects <ref> [Chen93, Freund93, Khokhar93, Wang92] </ref>. These projects strive to recognize the inherent heterogeneity within the application and (in some cases, automatically) partition the algorithm to run on a collection of heterogeneous processors. <p> This last case occurs, for example, with two CM-2 machines containing differing numbers of processors. AOST attempts to identify these situations and generate a mapping that makes best use of available resources. HOST (Heterogeneous OST) <ref> [Chen93] </ref> extends the OST and AOST to situations in which the code blocks contain heterogeneous subtasks. It attempts to find fine-grain mappings onto the heterogeneous processor suite that will minimize the execution time. HOST uses a hierarchical arrangement of available processors.
Reference: [Claus92] <author> R.W. Claus, A.L. Evans, and G.J. Follen. </author> <title> Multidisciplinary propulsion pimulation using NPSS. </title> <booktitle> 4th AIAA/USAF/NASA/OAI Symposium on Multi-disciplinary Analysis and Optimization, </booktitle> <address> Cleveland, OH (September 1992). </address>
Reference-contexts: Unfortunately, this can result in unexpected interactions between components that may not be discovered until a prototype engine is constructed. The NASA Numerical Propulsion System Simulation (NPSS) project is an effort to improve the jet engine design process through the use of advanced computer hardware and software <ref> [Claus91, Claus92] </ref>. NPSS is moving in two directions. One is the application of parallel computing technology to the design of improved numeric models for the various components of a jet engine, seeking both shorter execution time and improved model accuracy. <p> The Chapter also highlighted the principal changes in Schooners implementation to support these features. 90 91 Chapter 6 NPSS CASE STUDY The Numerical Propulsion System Simulation (NPSS) project aims to reduce the high cost of designing and implementing new propulsion technologies by using computer simulation <ref> [Claus91, Claus92] </ref>. Specifically, the project, which is part of the High Performance Computing and Communications (HPCC) initiative [HPCC94], involves developing both computational codes to model various engine components, and a simulation executive to control the simulation and provide a platform for modelling interactions among components.
Reference: [Claus91] <author> R.W. Claus, A.L. Evans, J.K. Lylte, and L.D. Nichols. </author> <title> Numerical propulsion system simulation. </title> <booktitle> Computing Systems in Engineering 2, </booktitle> <month> 4 (April </month> <year> 1991), </year> <pages> 357-364. </pages>
Reference-contexts: Unfortunately, this can result in unexpected interactions between components that may not be discovered until a prototype engine is constructed. The NASA Numerical Propulsion System Simulation (NPSS) project is an effort to improve the jet engine design process through the use of advanced computer hardware and software <ref> [Claus91, Claus92] </ref>. NPSS is moving in two directions. One is the application of parallel computing technology to the design of improved numeric models for the various components of a jet engine, seeking both shorter execution time and improved model accuracy. <p> The Chapter also highlighted the principal changes in Schooners implementation to support these features. 90 91 Chapter 6 NPSS CASE STUDY The Numerical Propulsion System Simulation (NPSS) project aims to reduce the high cost of designing and implementing new propulsion technologies by using computer simulation <ref> [Claus91, Claus92] </ref>. Specifically, the project, which is part of the High Performance Computing and Communications (HPCC) initiative [HPCC94], involves developing both computational codes to model various engine components, and a simulation executive to control the simulation and provide a platform for modelling interactions among components.
Reference: [CLIPS] <author> CLIPS Reference Manual, </author> <title> Basic Programming Guide. Software Technology Branch, </title> <type> 126 Lyndon B. </type> <institution> Johnson Space Center. </institution> <note> CLIPS Version 5.1, September 10, </note> <year> 1991. </year>
Reference-contexts: The user adds callback functions where necessary to perform application specific tasks associated with the controls. CLIPS, an expert system toolkit, is being integrated into the monitoring tool through the callback functions <ref> [CLIPS] </ref>. The initial goals of the monitoring project are to report the residual a measure of how well ADPAC is converging detect warnings, and report final results of the ADPAC run.
Reference: [Douglis91] <author> F. Douglis and J. Ousterhout. </author> <title> Transparent process migration: Design alternatives and the Sprite implementation. </title> <journal> SoftwarePractice and Experience 21, </journal> <month> 8 (August </month> <year> 1991), </year> <pages> 757-785. </pages>
Reference-contexts: This requires saving the complete state of the process, transferring the state to the new host, instantiating the process, and restoring its state. Several projects have addressed process migration. One is described in <ref> [Douglis91] </ref>, which 77 summarizes the issues involved in process migration and describes an implementation of this feature in the Sprite distributed operating system [Ousterhout88]. This implementation migrates the process state and associated execution environment, including, for example, open file pointers and the contents of virtual memory pages.
Reference: [Freund93] <author> R.F. Freund and H.J. Siegel. </author> <title> Guest editors introduction: </title> <booktitle> Heterogeneous processing. IEEE Computer 26, </booktitle> <month> 6 (June </month> <year> 1993), </year> <pages> 13-17. </pages>
Reference-contexts: programmer familiar with the parallel constructs used in the message-passing libraries, this is not too difficult, but it can be a serious drawback for someone wanting to connect a collection of vector codes. 2.2 Systems That Recognize Heterogeneity Exploiting heterogeneity in scientific applications is the goal of several research projects <ref> [Chen93, Freund93, Khokhar93, Wang92] </ref>. These projects strive to recognize the inherent heterogeneity within the application and (in some cases, automatically) partition the algorithm to run on a collection of heterogeneous processors.
Reference: [Freund89] <author> R.F. Freund. </author> <title> Optimal selection theory for superconcurrency. </title> <booktitle> Supercomputing 89, </booktitle> <month> (November </month> <year> 1989), </year> <pages> 699-703. </pages>
Reference-contexts: The system will then map a particular algorithm, or portion of an algorithm, onto a less suitable processor in situations where the most appropriate processor is better employed on another piece of the problem. 2.2.2 Optimal Selection Theory The Optimal Selection Theory (OST) <ref> [Freund89] </ref> is a tool for selecting the optimal configuration of machines when executing an application consisting of a heterogeneous collection of algorithms. The approach assumes an application is subdivided into code segments, each of which can have a different programming model, and thus a different preferred machine architecture.
Reference: [Gibbons87] <author> P.B. Gibbons. </author> <title> A stub generator for multilanguage RPC in heterogeneous environments. </title> <journal> IEEE Transactions on Software Engineering SE-13, </journal> <month> 1 (January </month> <year> 1987), </year> <pages> 77-87. </pages>
Reference-contexts: Most offer features similar to Schooners RPC, including external data representations, specification languages, and stub compilers [Almes85, Birrell84, Sun90, Xerox81]. Several of these systems also emphasize heterogeneity, including Matchmaker [Jones85], Horus <ref> [Gibbons87] </ref>, HRPC (Heterogeneous RPC) [Bershad87] and Cicero/Nestor [Huang94]. 3.6.1 Basic RPC Paradigm Most RPC systems use a client-server paradigm, where the client is the process requesting a service by initiating the RPC and the server is the process that will carry out the service.
Reference: [Grimshaw93] <author> A.S. Grimshaw. </author> <title> Easy-to-use object-oriented parallel processing with Mentat. </title> <booktitle> Computer 26, </booktitle> <month> 5 (May </month> <year> 1993), </year> <pages> 39-51. </pages>
Reference-contexts: The resulting distributed programs are statically defined at runtime. However, this has been extended to allow a type of dynamic configuration based on lazy instantiation avoiding the creation of component instances until actually invoked and by allowing recursive descriptions. As another example, the Mentat Programming Language (MPL) <ref> [Grimshaw93] </ref> has configuration aspects. MPL uses annotations to C++ to achieve high performance on parallel architectures. MPL uses compiler techniques to automatically recognize parallel constructs within an object and map the object onto multiple processors. Configuration is also supported through annotations the programmer can add to the MPL source.
Reference: [Griswold90] <author> R. Griswold and M. Griswold. </author> <title> The Icon Programming Language, </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, New Jersey, </address> <year> 1990. </year>
Reference-contexts: There is one stub compiler for each supported programming language. Currently, Schooner has stub compilers for C and FORTRAN; various versions of the predecessor MLP system also supported Pascal, Icon <ref> [Griswold90] </ref>, and Emerald [Black86, Black87, Hayes90]. After stubs for a component are generated from the specification, they are compiled using the appropriate language processor. The resulting object module is then linked with the users code, the UTS libraries, and the Schooner runtime support libraries to produce an executable.
Reference: [Hall93] <author> E. J. Hall, R. A. Delaney, and J. L. Bettner. </author> <title> Investigation of Advanced Counterrotation Blade Configuration Concepts for High Speed Turboprop Systems, Task 5 Unsteady Counterrotation Ducted Propfan Analysis Computer Program Users Manual, </title> <institution> NASA CR-187125, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: This section outlines this initial experiment, then reports on the changes now being implemented as a result of the lessons learned from the two sub-projects. The fan component chosen for integration into TESS is the Advanced Ducted Propfan Analysis Code (ADPAC) <ref> [Hall93] </ref>. Originally developed for the study of high-speed ducted propfan aircraft propulsion systems, ADPAC has become a general solver for turbomachinery components.
Reference: [Hayes90] <author> R. Hayes, N.C. Hutchinson, and R.D. Schlichting. </author> <title> Integrating Emerald into a system for mixed-language programming. </title> <booktitle> Computer Languages 15, 2 (1990), </booktitle> <pages> 95-108. </pages>
Reference-contexts: There is one stub compiler for each supported programming language. Currently, Schooner has stub compilers for C and FORTRAN; various versions of the predecessor MLP system also supported Pascal, Icon [Griswold90], and Emerald <ref> [Black86, Black87, Hayes90] </ref>. After stubs for a component are generated from the specification, they are compiled using the appropriate language processor. The resulting object module is then linked with the users code, the UTS libraries, and the Schooner runtime support libraries to produce an executable.
Reference: [Hayes89] <author> R. Hayes. UTS: </author> <title> A Type System for Facilitating Data Communication, </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Arizona, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: There are four, mostly orthogonal, parts to Schooner: a specification language, an intermediate data representation and accompanying data exchange library, a set of stub compilers, and a runtime support system. The Universal Type 25 System (UTS) provides both the specification language and the intermediate data representation <ref> [Hayes89] </ref>. The specification language is machine and language-independent and is used to describe the interface for each component application. The UTS intermediate data representation provides a medium for exchanging data across machine architectures and handling data structure differences among languages. <p> have included the addition of a number of machines to the list of supported machines, and additions to the UTS specification language and the corresponding changes to the stub compilers and UTS library. 3.4.1 Adding Machines to Schooner The predecessor MLP system supported Sun workstations and the Digital VAX architecture <ref> [Hayes89] </ref>. In the course of constructing Schooner, a number of machines have been added, including the Cray YMP, Convex C2x0 series, SGI and Stardent graphics workstations, IBM RS/ 6000 class architectures (including both workstations and the SP-1 and SP-2 parallel processor), the Sequent Symmetry and the Intel Paragon.
Reference: [Hayes88] <author> R. Hayes, S. Manweiler, and R.D. Schlichting. </author> <title> A simple system for constructing distributed, mixed-language programs. </title> <journal> SoftwarePractice and Experience 18, </journal> <month> 7 (July </month> <year> 1988), </year> <pages> 641-660. </pages>
Reference-contexts: It provides the user with a means of integrating the various components into the meta-computation, and provides the underlying communication and management support. The Schooner system grew out of the MLP system <ref> [Hayes87, Hayes88] </ref>. MLP implemented similar RPC functionality that was capable of spanning a collection of heterogeneous machines connected by a local area network. In particular, the UTS system that formed the heart of MLP comprises a significant piece of Schooner.
Reference: [Hayes87] <author> R. Hayes and R.D. Schlichting. </author> <title> Facilitating mixed language programming in distributed systems. </title> <journal> IEEE Transactions on Software Engineering SE-13, </journal> <month> 12 (December </month> <year> 1987), </year> <pages> 1254-1264. </pages>
Reference-contexts: It provides the user with a means of integrating the various components into the meta-computation, and provides the underlying communication and management support. The Schooner system grew out of the MLP system <ref> [Hayes87, Hayes88] </ref>. MLP implemented similar RPC functionality that was capable of spanning a collection of heterogeneous machines connected by a local area network. In particular, the UTS system that formed the heart of MLP comprises a significant piece of Schooner.
Reference: [Hofmeister93] <author> C. Hofmeister, E. White, and J.M. Purtilo. Surgeon: </author> <title> A packager for dynamically reconfigurable distributed applications. </title> <journal> IEE Software Engineering Journal 8, </journal> <volume> 2, </volume> <pages> 95-101. </pages>
Reference-contexts: The system works well, but requires considerable support from the Sprite kernel and does not support cross-architecture migration. Another project, Surgeon, is studying the problem of process migration in the context of heterogeneous distributed applications <ref> [Hofmeister93] </ref>. Surgeon is layered on top of the Polylith/ Polygen system that was described in Chapter 2. The project has demonstrated a limited ability to migrate processes under certain constraints, such as the use of atomic actions to send and receive messages.
Reference: [Homer94a] <author> P.T. Homer and R.D. Schlichting. </author> <title> A software platform for constructing scientific applications from heterogeneous resources. </title> <journal> Journal of Parallel and Distributed Computing 21, </journal> <month> (June </month> <year> 1994), </year> <pages> 301-315. </pages>
Reference-contexts: This facility allows the user to exercise more interactive control, which can be especially useful for adapting the application to changes in requirements or execution environments. This chapter describes the basic Schooner system, which provides full interconnection capabilities together with static configuration support <ref> [Homer94a] </ref>. The static configuration support is modeled after the normal method of executing an application from the command line.
Reference: [Homer94b] <author> P.T. Homer and R.D. Schlichting. </author> <title> Using Schooner to support distribution and heterogeneity in the Numerical Propulsion System Simulation project. </title> <journal> ConcurrencyPractice and Experience 6, </journal> <month> 4 (June </month> <year> 1994) </year> <month> 271-287. </month>
Reference-contexts: Schooner is being used in conjunction with an execution framework provided by AVS to form a simple simulation executive that approaches the capabilities required by NPSS <ref> [Homer94b] </ref>.
Reference: [Homer94c] <author> P.T. Homer and R.D. Schlichting. </author> <title> Configuring scientific applications in a heterogeneous distributed system. </title> <booktitle> Proceedings of the 2nd International Workshop on Configurable Distributed Systems, </booktitle> <address> Pittsburgh, PA (March 1994), </address> <pages> 159-168. </pages>
Reference-contexts: To be fully useful, such changes should be possible from within the meta-computation itself, as well as by direct intervention of the user during a run. This allows maximum exibility in adapting the meta-computation to conditions that vary between different execution runs <ref> [Homer94c] </ref>. 5.2.2 Possible Approaches As with concurrency, one option is to not provide support for dynamic configuration. This has several drawbacks, but chief among them is inexibility.
Reference: [HPCC94] <author> High Performance Computing and Communications: </author> <booktitle> Technology for the National Information Infrastructure. Supplement to the Presidents Fiscal Year 1995 Budget. Committee on Information and Communication (CIC) of the National Science and Technology Council (NSTC). </booktitle>
Reference-contexts: Specifically, the project, which is part of the High Performance Computing and Communications (HPCC) initiative <ref> [HPCC94] </ref>, involves developing both computational codes to model various engine components, and a simulation executive to control the simulation and provide a platform for modelling interactions among components. Codes have already been written for a number of engine components, with others currently under development.
Reference: [Huang94] <author> Y. Huang and C.V. Ravishankar. </author> <title> Designing an agent synthesis system for cross-RPC communication. </title> <journal> IEEE Transactions on Software Engineering 20, </journal> <month> 3 (March </month> <year> 1994), </year> <pages> 188-198. </pages>
Reference-contexts: Most offer features similar to Schooners RPC, including external data representations, specification languages, and stub compilers [Almes85, Birrell84, Sun90, Xerox81]. Several of these systems also emphasize heterogeneity, including Matchmaker [Jones85], Horus [Gibbons87], HRPC (Heterogeneous RPC) [Bershad87] and Cicero/Nestor <ref> [Huang94] </ref>. 3.6.1 Basic RPC Paradigm Most RPC systems use a client-server paradigm, where the client is the process requesting a service by initiating the RPC and the server is the process that will carry out the service.
Reference: [Hutchinson91] <author> N.C. Hutchinson and L.L. Peterson. </author> <title> The x-kernel: An architecture for implementing network protocols. </title> <journal> IEEE Transactions on Software Engineering 17, </journal> <month> 1 (January </month> <year> 1991), </year> <pages> 64-76. </pages>
Reference-contexts: Finally, one area that has not seen significant improvement since the original MLP work is the communication libraries. Support can be added to take better advantage of high-bandwidth networks. For example, developing a version of Schooner that uses the x-kernel <ref> [Hutchinson91] </ref> 111 on Mach would provide both a faster interface to existing networks and facilitate easier experimentation with emerging high-performance network protocols. Another extension would allow components to choose the best protocol to use for each procedure call.
Reference: [Jones85] <editor> M.B. Jones, R.F. Rashid and M.R. Thompson. Matchmaker: </editor> <title> An interface specification language for distributed processing. </title> <booktitle> Proceedings of the 12th Symposium on Principles 127 of Programming Languages, </booktitle> <address> New Orleans, </address> <month> LA (January </month> <year> 1985), </year> <pages> 225-235. </pages>
Reference-contexts: Most offer features similar to Schooners RPC, including external data representations, specification languages, and stub compilers [Almes85, Birrell84, Sun90, Xerox81]. Several of these systems also emphasize heterogeneity, including Matchmaker <ref> [Jones85] </ref>, Horus [Gibbons87], HRPC (Heterogeneous RPC) [Bershad87] and Cicero/Nestor [Huang94]. 3.6.1 Basic RPC Paradigm Most RPC systems use a client-server paradigm, where the client is the process requesting a service by initiating the RPC and the server is the process that will carry out the service.
Reference: [Kernighan88] <author> B.W. Kernighan and D.M. Ritchie. </author> <title> The C Programming Language, second edition, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: The original decision to include only double-precision was in keeping with the Kernighan and Ritchie C specification <ref> [Kernighan88] </ref>, which requires that values of both oat and double types passed as arguments be coerced to double for the call. With the addition of Fortran to Schooner and the development of the ANSI C specification, this practice is not longer adequate.
Reference: [Khokhar93] <author> A.A. Khokhar, V.K. Prasanna, M.E. Shaaban and C. Wang. </author> <title> Heterogeneous computing: Challenges and opportunities. </title> <booktitle> IEEE Computer 26, </booktitle> <month> 6 (June </month> <year> 1993), </year> <pages> 18-27. </pages>
Reference-contexts: Clearly, such an approach is awkward at best. This dissertation proposes that scientific applications requiring heterogeneous resources be constructed as heterogeneous distributed programs, or metacomputations <ref> [Khokhar93] </ref>, composed of multiple software modules executing on different types of machines. In addition to presenting this model, a software infrastructure called Schooner that supports the construction of programs according to this model is described. <p> programmer familiar with the parallel constructs used in the message-passing libraries, this is not too difficult, but it can be a serious drawback for someone wanting to connect a collection of vector codes. 2.2 Systems That Recognize Heterogeneity Exploiting heterogeneity in scientific applications is the goal of several research projects <ref> [Chen93, Freund93, Khokhar93, Wang92] </ref>. These projects strive to recognize the inherent heterogeneity within the application and (in some cases, automatically) partition the algorithm to run on a collection of heterogeneous processors.
Reference: [Magee94] <author> J. Magee, N. Dulay, and J. Kramer. </author> <title> A consturctive development environment for parallel and distributed programs. </title> <booktitle> Proceedings of the 2nd International Workshop on Configurable Distributed Systems, </booktitle> <address> Pittsburgh, PA (March 1994), </address> <pages> 4-14. </pages>
Reference-contexts: The system can detect faults and re-configure the application by transferring the saved state of a component to a new host and re-starting it there. The Regis programming environment is similar in its support for C++ and the use of a specification language, called Darwin <ref> [Magee94] </ref>. Regis, however, concentrates on the communication needs of the components. The user is responsible for developing the functionality for the component. Darwin is then used to describe the communication needs of each component.
Reference: [Mechoso92] <author> C.R. Mechoso, C.-C. Ma, J.D. Farrara, J.A. Spahr, and R.W. Moore. </author> <title> Distributing a climate model across gigabit networks. </title> <booktitle> Proceedings of the 1st International Symposium on High-Performance Distributed Computing, </booktitle> <address> Syracuse, NY (September 1992), </address> <pages> 16-25. </pages>
Reference-contexts: Second, it should include the ability to monitor and steer the simulation through, for example, a graphical interface. Both of these characteristics are approached but not fully realized in existing systems. A specific example of this class of application is the global climate modelling project <ref> [Mechoso92, Mechoso91] </ref> being done as part of the CASA gigabit network testbed [Bergman91]. This project has two goals. The first is to improve two global models, one modelling atmospheric circulation and the other oceanic circulation.
Reference: [Mechoso91] <author> C.R. Mechoso, C.-C. Ma, J.D. Farrara, J.A. Spahr and R.W. Moore. </author> <title> Distribution of a climate model across high-speed networks. </title> <booktitle> Proceedings Supercomputing 91, Albu-querque, NM (November 1991), </booktitle> <pages> 253-260. </pages>
Reference-contexts: Second, it should include the ability to monitor and steer the simulation through, for example, a graphical interface. Both of these characteristics are approached but not fully realized in existing systems. A specific example of this class of application is the global climate modelling project <ref> [Mechoso92, Mechoso91] </ref> being done as part of the CASA gigabit network testbed [Bergman91]. This project has two goals. The first is to improve two global models, one modelling atmospheric circulation and the other oceanic circulation.
Reference: [Mercurio92] <author> P.J. Mercurio. Khoros. </author> <title> Pixel 3, </title> <booktitle> 2 (March/April 1992), </booktitle> <pages> 28-33. </pages>
Reference-contexts: Work on the simulation executive is also underway. The focus in this effort is on providing sophisticated capabilities to interact with codes, as well as the ability to substitute different codes at varying degrees of fidelity. A scientific visualization system such as AVS [AVS92] or Khoros <ref> [Rasure91, Mercurio92] </ref> will likely form a major component of the finished product. The simulation executive is a meta-computation that must support diverse software and hardware elements on local and wide-area networks. The user should see a single integrated tool, not individual codes that execute in isolation.
Reference: [Morris86] <author> J.H. Morris, M. Satyanarayanan, M.H. Conner, J.H. Howard, D.S. Rosenthal, and F.D. Smith. Andrew: </author> <title> A distributed personal computing environment. </title> <journal> Communications of the ACM 29, </journal> <month> 3 (Mar. </month> <year> 1986), </year> <pages> 184-201. </pages>
Reference-contexts: To provide a service to many clients concurrently, multiple instances of a server may exist, each bound to one client. The canonical example is a distributed file system, such as Suns Network File System [Sun90] and the Andrew File System <ref> [Morris86] </ref>. In the basic design, each host in the system provides a server to manage the files resident on the host. A client opens a file through an RPC to the appropriate server.
Reference: [MPI94] <author> Message Passing Interface Forum. </author> <title> Document for a Standard Message-Passing Interface. </title> <address> March 22, </address> <year> 1994. </year>
Reference-contexts: particular, the shared memory and monitor commands are not available to FORTRAN programs, even though message passing within a FORTRAN process cluster is still implemented using shared memory. 2.1.4 MPI The success of message passing systems for implementing parallel algorithms has lead to creation of a standard Message-Passing Interface (MPI) <ref> [MPI94] </ref>. This effort has recently resulted 31 in a standard that specifies both C and FORTRAN interfaces to a system that supports process clusters, asynchronous message passing including broadcast and multicast, and a collection of global data reduction operations.
Reference: [Nelson81] <author> B.J. Nelson. </author> <title> Remote Procedure Call. </title> <type> Ph.D. Dissertation, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1981. </year> <note> Xerox PARC Technical Report CSL-81-9. </note>
Reference-contexts: Additional optimizations to improve performance are discussed in Chapter 7. 3.6 Other RPC Systems Many RPC systems have been developed since the original work described in <ref> [Nelson81] </ref>. Most offer features similar to Schooners RPC, including external data representations, specification languages, and stub compilers [Almes85, Birrell84, Sun90, Xerox81].
Reference: [Ousterhout88] <author> J.K. Ousterhout, A.R. Cherenson, F. Douglis, M.N. Nelson, and B.B. Welch. </author> <title> The Sprite network operating system. </title> <booktitle> Computer 21, </booktitle> <month> 2 (February </month> <year> 1988), </year> <pages> 23-36. </pages>
Reference-contexts: Several projects have addressed process migration. One is described in [Douglis91], which 77 summarizes the issues involved in process migration and describes an implementation of this feature in the Sprite distributed operating system <ref> [Ousterhout88] </ref>. This implementation migrates the process state and associated execution environment, including, for example, open file pointers and the contents of virtual memory pages. The system works well, but requires considerable support from the Sprite kernel and does not support cross-architecture migration.
Reference: [Postel81] <author> Jon Postel. </author> <title> Transmission Control ProtocolDARPA Internet Program Ptotocol Specification, </title> <type> RFC 793, </type> <institution> Network Information Center, SRI International, </institution> <address> Menlo Park, CA, </address> <month> September </month> <year> 1981. </year>
Reference-contexts: The receive operation is structured analogously. The Schooner communication subsystem currently supports message passing using either TCP virtual circuits <ref> [Postel81] </ref> or UDP datagrams [Postel80]. The choice is made by the user when the Schooner program is started.
Reference: [Postel80] <author> Jon Postel. </author> <title> User Datagram Protocol, </title> <type> RFC 768, </type> <institution> Network Information Center, SRI International, </institution> <address> Menlo Park, CA, </address> <month> August </month> <year> 1980. </year>
Reference-contexts: The receive operation is structured analogously. The Schooner communication subsystem currently supports message passing using either TCP virtual circuits [Postel81] or UDP datagrams <ref> [Postel80] </ref>. The choice is made by the user when the Schooner program is started.
Reference: [Purtilo94] <author> J.M. Purtilo. </author> <title> The POLYLITH software bus. </title> <journal> ACM Transactions on Programming Languages and Systems 16, </journal> <month> 1 (January </month> <year> 1994), </year> <pages> 151-174. </pages>
Reference-contexts: The next section describes one project that comes closer to meeting the goals outlined in Chapter 1 for an interconnection system by accommodating heterogeneity in both programming languages and machine architectures. 2.3.2 Polylith and Polygen The Polylith system supports configuration through the use of a module interconnection language (MIL) <ref> [Purtilo94] </ref>. Each module to be included in a computation has a specification in MIL, called a primitive specification, that describes resources defined within the module and resources the module will need from other sources.
Reference: [Quealy93] <author> A. Quealy, G.L. Cole, and R.A. Blech. </author> <title> Portable Programming on Parallel/Networked Computers Using the Application Portable Parallel Library (APPL). </title> <type> NASA Technical Memorandum 106238, </type> <month> July </month> <year> 1993. </year>
Reference-contexts: goals of each: Message passing systems that are designed to facilitate the implementation of parallel algo rithms, Systems that seek to automatically recognize heterogeneity in an application, and Systems that provide configuration management capabilities for distributed computations. 2.1 Message Passing Systems Systems such as PVM [Sunderam90, Beguelin91], p4 [Butler92], APPL <ref> [Quealy93] </ref>, Zipcode [Skjellum93] and others, are representative of a class of systems that provides general support for constructing parallel programs using a collection of (in some cases, heterogeneous) machines. 2.1.1 PVM PVM provides a set of library routines, callable from C or FORTRAN programs, that implements: asynchronous message passing between processes,
Reference: [Rasure91] <author> J. Rasure and C. Williams. </author> <title> An integrated visual language and software development environment. </title> <journal> Journal of Visual Languages and Computing 2, </journal> <year> (1991), </year> <pages> 217-246. </pages>
Reference-contexts: Work on the simulation executive is also underway. The focus in this effort is on providing sophisticated capabilities to interact with codes, as well as the ability to substitute different codes at varying degrees of fidelity. A scientific visualization system such as AVS [AVS92] or Khoros <ref> [Rasure91, Mercurio92] </ref> will likely form a major component of the finished product. The simulation executive is a meta-computation that must support diverse software and hardware elements on local and wide-area networks. The user should see a single integrated tool, not individual codes that execute in isolation.
Reference: [Reed94] <author> J.A. Reed and A.A. Afjeh. </author> <title> Distributed and parallel programming in support of zooming in numerical propulsion system simulation, </title> <booktitle> OAI/OSC/NASA Symposium on Application of Parallel and Distributed Computing, </booktitle> <address> Columbus, OH, </address> <month> (April </month> <year> 1994). </year>
Reference-contexts: Thus far, tests have been conducted using as many as eight runs of ADPAC to create each constant-speed performance maps, and the solution appears to be a satisfactory one <ref> [Reed94] </ref>. To shorten the overall time for the simulation, the multiple ADPAC runs can be performed in parallel when the necessary computational resources are available.
Reference: [Reed93] <author> J.A. Reed. </author> <title> Development of an interactive graphical aircraft propulsion system simulator. </title> <institution> Master of Science Thesis, University of Toledo, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: Schooner, in turn, provides the ability to perform the actual computation 95 associated with a modulethat is, the simulation code itselfon a remote, potentially heterogeneous, machine. The executive is being tested using the Turbofan Engine System Simulator (TESS), a complete one-dimensional transient thermodynamic aircraft engine simulation <ref> [Reed93] </ref>. TESS represents each of the principal components of an engine as an AVS module. An engine is constructed in the AVS Network Editor by connecting the modules to represent the airow through the engine. Figure 6-1 shows an AVS network for modeling an F100 engine using TESS.
Reference: [Skjellum93] <author> A. Skjellum. </author> <title> Scalable libraries in a heterogeneous environment. </title> <booktitle> Proceedings of the 2nd International Symposium on High-Performance Distributed Computing, </booktitle> <address> Spokane, WA (July 1993), </address> <pages> 13-20. </pages>
Reference-contexts: each: Message passing systems that are designed to facilitate the implementation of parallel algo rithms, Systems that seek to automatically recognize heterogeneity in an application, and Systems that provide configuration management capabilities for distributed computations. 2.1 Message Passing Systems Systems such as PVM [Sunderam90, Beguelin91], p4 [Butler92], APPL [Quealy93], Zipcode <ref> [Skjellum93] </ref> and others, are representative of a class of systems that provides general support for constructing parallel programs using a collection of (in some cases, heterogeneous) machines. 2.1.1 PVM PVM provides a set of library routines, callable from C or FORTRAN programs, that implements: asynchronous message passing between processes, broadcast/multicast communication,
Reference: [Sun90] <author> Sun Microsystems, Inc. </author> <title> Network Programming Guide (Revision A). Part number 800-3850-10. Sun Microsystems, </title> <publisher> Inc., </publisher> <address> Mountain View, CA, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: Broadcast is supported by using a distinguished destination address in the send operation to indicate that it is sent to all processes. There are no inherent limits on the size of messages exchanged between machines. Differences in data representation between machines are handled in PVM using Sun XDR <ref> [Sun90] </ref> as an intermediate representation, with a collection of library routines provided to convert standard data types. These calls are inserted by the user prior to a send or after a receive. A PVM program executes on a virtual machine that is created from a collection of (possibly heterogeneous) machines. <p> Additional optimizations to improve performance are discussed in Chapter 7. 3.6 Other RPC Systems Many RPC systems have been developed since the original work described in [Nelson81]. Most offer features similar to Schooners RPC, including external data representations, specification languages, and stub compilers <ref> [Almes85, Birrell84, Sun90, Xerox81] </ref>. <p> To provide a service to many clients concurrently, multiple instances of a server may exist, each bound to one client. The canonical example is a distributed file system, such as Suns Network File System <ref> [Sun90] </ref> and the Andrew File System [Morris86]. In the basic design, each host in the system provides a server to manage the files resident on the host. A client opens a file through an RPC to the appropriate server.
Reference: [Sunderam90] <author> V. S. Sunderam. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency Practice and Experience 2, </journal> <month> 4 (December </month> <year> 1990), </year> <pages> 315-339. </pages>
Reference-contexts: categories based on the specific goals of each: Message passing systems that are designed to facilitate the implementation of parallel algo rithms, Systems that seek to automatically recognize heterogeneity in an application, and Systems that provide configuration management capabilities for distributed computations. 2.1 Message Passing Systems Systems such as PVM <ref> [Sunderam90, Beguelin91] </ref>, p4 [Butler92], APPL [Quealy93], Zipcode [Skjellum93] and others, are representative of a class of systems that provides general support for constructing parallel programs using a collection of (in some cases, heterogeneous) machines. 2.1.1 PVM PVM provides a set of library routines, callable from C or FORTRAN programs, that implements: <p> Within this model, however, parallel algorithms can be used by encapsulating the parallel algorithm inside a component, as illustrated in Figure 3-2. These parallel algorithms can execute on specialized hardware such as hypercubes, or could even be realized using a system such as PVM on a collection of workstations <ref> [Sunderam90, Beguelin91] </ref>. In either case, the role of Schooner is to connect the procedure to the other parts of the application. <p> Once those are complete, the ow becomes single-threaded again for the reply back to the AVS co-routine. Recently, the neural net code has been ported to run on an Intel Paragon using Intels message library, and on a cluster of Sun workstations using the PVM message-passing system <ref> [Sunderam90, Beguelin91] </ref>. Both of these versions employ the same parallel algorithm as the Sequent version, but make use of messages to exchange boundary values between the processes. Multiple implementations provide greater exibility when running experiments.
Reference: [TAE] <institution> Transportable Applications Environment Plus. </institution> <note> Programmers Manual, Version 5.2. </note> <institution> Goddard Space Flight Center, National Aeronautics and Space Administration. </institution> <month> 128 December </month> <year> 1992. </year>
Reference-contexts: The code is written in FORTRAN and has been ported to a variety of machines including Cray YMP, Convex C240, and IBM RS/6000 and SGI workstations. 6.3.1 Monitoring ADPAC The monitoring tool of the meta-computation consists of an interface constructed using the TAE+ Graphical User Interface toolkit <ref> [TAE] </ref>. TAE+ facilitates the construction of X-window GUIs by providing a workbench that the programmer can use to create windows and position controls. TAE+ then generates the code for creating the windows and builds an event loop to handle events to/from the controls within the windows.
Reference: [Wang92] <author> M. Wang, S. Kim, M.A. Nichols, R.F. Freund, H.J. Siegel, </author> <title> and W.G. Nation. Augmenting the optimal selection theory for superconcurrency. </title> <booktitle> Proceedings of the 1st Workshop on Heterogeneous Processing, </booktitle> <address> Beverly Hills, CA (March 1992), </address> <pages> 13-21. </pages>
Reference-contexts: programmer familiar with the parallel constructs used in the message-passing libraries, this is not too difficult, but it can be a serious drawback for someone wanting to connect a collection of vector codes. 2.2 Systems That Recognize Heterogeneity Exploiting heterogeneity in scientific applications is the goal of several research projects <ref> [Chen93, Freund93, Khokhar93, Wang92] </ref>. These projects strive to recognize the inherent heterogeneity within the application and (in some cases, automatically) partition the algorithm to run on a collection of heterogeneous processors. <p> It is also possible to impose a constraint, such as cost, on the performance goal. The basic OST theory has been extended in several ways. AOST (Augmented OST) <ref> [Wang92] </ref> extends the theory to consider the problem of assigning code blocks within segments when there are not enough machines of the optimal type, but additional machines of a non-optimal type are available.
Reference: [Weems93] <author> C.C. Weems, Jr. </author> <title> Image understanding: A driving application for research in heterogeneous parallel processing. </title> <booktitle> Proceedings of the 2nd Workshop on Heterogeneous Processing, </booktitle> <address> Newport Beach, CA (April 1993), </address> <pages> 119-126. </pages>
Reference-contexts: The large computational requirements have fueled a drive toward parallel processing; however, the variety of algorithms employed has made any one type of parallel architecture unsuitable for solving the overall problem. Thus, image understanding has become a motivating application for work in recognizing heterogeneity <ref> [Weems93] </ref>. There are three commonly accepted categories for describing the processing necessary in image understanding. At the low level, the work is image oriented, concentrating primarily on the pixels. The work may involve operations applied to all the pixels in the image, or to certain subsets.
Reference: [Xerox81] <institution> Xerox Corp. </institution> <month> Courier: </month> <title> The Remote Procedure Call Protocol. Xerox System Integration Standard XSIS 038112, </title> <institution> Xerox Corp., Stamford CT, </institution> <month> December </month> <year> 1981. </year>
Reference-contexts: Additional optimizations to improve performance are discussed in Chapter 7. 3.6 Other RPC Systems Many RPC systems have been developed since the original work described in [Nelson81]. Most offer features similar to Schooners RPC, including external data representations, specification languages, and stub compilers <ref> [Almes85, Birrell84, Sun90, Xerox81] </ref>.
Reference: [Zimmerman94] <author> M. Zimmermann and O. Drobnik. </author> <title> Specification and implementation of reconfigurable distributed applications. </title> <booktitle> Proceedings of the 2nd International Workshop on Configurable Distributed Systems, </booktitle> <address> Pittsburgh, PA (March 1994), </address> <pages> 23-34. </pages>
Reference-contexts: While interesting in their own context, these features are not necessary in an interconnection system. For example, <ref> [Zimmerman94] </ref> describes a system that supports the initial configuration and subsequent re-configuration of long-running applications. The system uses C++ and a specification technique to support the integration of application and management functionality into each component.
References-found: 63

