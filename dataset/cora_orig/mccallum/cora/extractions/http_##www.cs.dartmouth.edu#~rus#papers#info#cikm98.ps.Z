URL: http://www.cs.dartmouth.edu/~rus/papers/info/cikm98.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~rus/papers/info/info.html
Root-URL: http://www.cs.dartmouth.edu
Title: Static and Dynamic Information Organization with Star Clusters  
Author: Javed Aslam Katya Pelekhov Daniela Rus 
Address: Hanover, NH 03755  
Affiliation: Department of Computer Science Dartmouth College  
Abstract: In this paper we present a system for static and dynamic information organization and show our evaluations of this system on TREC data. We introduce the off-line and on-line star clustering algorithms for information organization. Our evaluation experiments show that the offline star algorithm outperforms the single link and average link clustering algorithms. Since the star algorithm is also highly efficient and simple to implement, we advocate its use for tasks that require clustering, such as information organization, browsing, filtering, routing, topic tracking, and new topic detection. 
Abstract-found: 1
Intro-found: 1
Reference: [AB84] <author> M. Aldenderfer and R. Blashfield, </author> <title> Cluster Analysis, </title> <type> Sage, Beverly Hills, </type> <year> 1984. </year>
Reference-contexts: Since the star algorithm is also highly efficient and simple to implement, we advocate its use for tasks that require clustering, such as information organization, routing, topic tracking, and new topic detection. 1.1 Previous Work There has been extensive research on clustering and applications to many domains <ref> [HS86, AB84] </ref>. For a good overview see [JD88]. For a good overview of using clustering in information retrieval see [Wil88].
Reference: [All95] <author> J. Allan. </author> <title> Automatic hypertext construction. </title> <type> PhD thesis. </type> <institution> Department of Computer Science, Cornell University, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: This organization system was used for the experiments described in this paper. It consists of an augmented version of the Smart system <ref> [Sal91, All95] </ref>, a user interface we have designed, and an implementation of the star algorithm on top of Smart. To index the documents we used the Smart search engine with a cosine normalization weighting scheme. <p> These views provide users with summaries of the data at different levels of detail (text, document and topic) and facilitate browsing by topic structure. The connected graph view (inspired by <ref> [All95] </ref>) has nodes corresponding to the retrieved documents. The nodes are placed in a circle, with nodes corresponding to the same cluster placed together. Gaps between the nodes allow us to identify clusters easily. Edges between nodes are color coded according to the similarity between the documents.
Reference: [All98] <author> J. Allan, </author> <type> Personal communication, </type> <month> March </month> <year> 1998. </year>
Reference-contexts: Unlike the star algorithm, single and average link algorithms do not allow overlapping clusters. It has been suggested <ref> [All98] </ref> that the differences in performance may be attributed to the effects of overlapping rather than to the actual properties of the algorithm. To investigate this issue we conducted the same experiments using a version of the star clustering algorithm that eliminates the overlapping clusters.
Reference: [APR98] <author> J. Aslam, K. Pelekhov, and D. </author> <title> Rus, Generating, visualizing, and evaluating high-accuracy clusters for information organization, in Principles of Digital Document Processing, </title> <editor> eds. </editor> <address> C. </address> <note> Nicholas, Lecture Notes in Computer Science, Sprinter Verlag 1998 (to appear). Also available as Technical Report PCS-TR97-319, </note> <institution> Department of Computer Science, Dartmouth, </institution> <year> 1997. </year>
Reference-contexts: However, since the number of topics in a dynamic information systems is not generally known a priori, a fixed number of clusters cannot generate a natural partition of the information. 1.2 Our Work Our work on clustering presented in this paper and in <ref> [APR98] </ref> describes a simple incremental algorithm, provides positive evidence for the cluster hypothesis, and shows promise for on-line tasks that require dynamically adjusting the topic content of a collection such as filtering, browsing, new topic detection and topic tracking. <p> The star algorithm is based on a greedy cover of the thresholded similarity graph by star-shaped subgraphs; the algorithm itself is summarized in Figure 1. The star algorithm is very efficient. In <ref> [APR98] </ref> we show that the star algorithm can be correctly implemented in such a way that given a thresholded similarity graph G , the running time of the algorithm is fi (V + E ), linear in the size of the input graph. 2.2 Cluster Quality In this section, we argue
Reference: [APR97] <author> J. Aslam, K. Pelekhov, and D. </author> <title> Rus, Computing Dense Clusters On-line for Information Organization, </title> <type> Technical Report PCS-TR97-324, </type> <institution> Department of Computer Science, Dartmouth, </institution> <year> 1997. </year>
Reference-contexts: We further undertook a study to determine the expected similarity between two satellite vertices. Under the assumption that "similar" documents are essentially "random" perturbations of one another in an appropriate vector space, we have proven the following <ref> [APR97] </ref>: Theorem 2 Let G be a similarity graph and let S 1 and S 2 be two satellites in the same star in G . <p> Let ff be a vertex to be added to G, and let L be the list of vertices in G which are adjacent to ff. The algorithm in <ref> [APR97] </ref> for a more detailed correctness argument. 3.2 Analysis We have shown that the star cover produced by the online star algorithm is correct in that it is identical to the star cover produced by the off-line algorithm (or one of the correct covers, if more than one exists) [APR97]. <p> in <ref> [APR97] </ref> for a more detailed correctness argument. 3.2 Analysis We have shown that the star cover produced by the online star algorithm is correct in that it is identical to the star cover produced by the off-line algorithm (or one of the correct covers, if more than one exists) [APR97]. Furthermore, the on-line star algorithm is very efficient. In our initial tests, we have implemented the on-line star algorithm using a heap for the priority queue and simple linked lists for the various lists required. <p> This is due partly to the fact that relatively few stars exist at any given time (as compared to the number of vertices or edges in the thresholded similarity graph) and partly to the fact that the likelihood of breaking any individual star is also small <ref> [APR97] </ref>.
Reference: [Bol95] <author> B. Bollobas, </author> <title> Random Graphs, </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1995. </year>
Reference: [Bur95] <author> R. Burgin, </author> <title> The retrieval effectiveness of five clustering algorithms as a function of indexing exhaustively, </title> <journal> Journal of American Society for Information Science </journal> 46(8:562-572, 1995. 
Reference-contexts: methods fairly, each of the methods was run in such a way so as to produce the "best" possible cluster with respect to a given topic, as defined by the E (p; r) measure above. (This is in keeping with previous comparative analyses of clustering methods; see, for example, Burgin <ref> [Bur95] </ref> and Shaw [Sha93].) In the case of the single link and star cover algorithms, the algorithms were run using a range of thresholds, and the best cluster obtained over all thresholds was returned. (One can view the clustering obtained with respect to a given threshold as a "slice" within a
Reference: [Can93] <author> F. </author> <title> Can, Incremental clustering for dynamic information processing, </title> <journal> in ACM Transactions on Information Systems, </journal> <volume> no. 11, pp143-164, </volume> <year> 1993. </year>
Reference: [CCFM97] <author> M. Charikar, C. Chekuri, T. Feder, and R. Motwani, </author> <title> Incremental clustering and dynamic information retrieval, </title> <booktitle> in Proceedings of the 29 th Symposium on Theory of Computing, </booktitle> <year> 1997. </year>
Reference-contexts: Systems like Scatter/Gather [CKP93] provide a mechanism for user-driven organization of data into a fixed number of clusters, but user feedback is required and the computed clusters do not have accuracy guarantees. Scatter/Gather uses fractionation to compute nearest-neighbor clusters. In a recent paper, Charika et al. <ref> [CCFM97] </ref> consider a dynamic clustering algorithm to partition a collection of text documents into a fixed number of clusters. <p> We propose an off-line algorithm for clustering static information and an on-line version of this algorithm for clustering dynamic information. These two algorithms compute clusters induced by the natural topic structure of the space. Thus, this work is different than <ref> [CKP93, CCFM97] </ref> in that we do not impose a fixed number of clusters as a constraint on the solution. As a result, we can guarantee a lower bound on the topic similarity between the documents in each cluster.
Reference: [Cro80] <author> W. B. Croft. </author> <title> A model of cluster searching based on classification. </title> <journal> Information Systems, </journal> <volume> 5 </volume> <pages> 189-195, </pages> <year> 1980. </year>
Reference-contexts: Efforts have been made to determine whether the cluster hypothesis is valid. Voorhees [Voo85] discusses a way of evaluating whether the cluster hypothesis holds and shows negative results. Croft <ref> [Cro80] </ref> describes a method for bottom-up cluster search that could be shown to outperform a full ranking system for the Cranfield collection. The single link method [Cro77] does not provide any guarantees for the topic similarity within a cluster.
Reference: [Cro77] <author> W. B. Croft. </author> <title> Clustering large files of documents using the single-link method. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> pp189-195, </volume> <month> November </month> <year> 1977. </year>
Reference-contexts: Voorhees [Voo85] discusses a way of evaluating whether the cluster hypothesis holds and shows negative results. Croft [Cro80] describes a method for bottom-up cluster search that could be shown to outperform a full ranking system for the Cranfield collection. The single link method <ref> [Cro77] </ref> does not provide any guarantees for the topic similarity within a cluster. Jardine and van Rijsber-gen [JR71] show some evidence that search results could be improved by clustering. <p> Finally, we provide experimental data for off-line and online topic organization. In particular, our off-line results on a TREC collection indicate that star covers exhibit significant performance improvements over either the single link <ref> [Cro77] </ref> or average link [Voo85] methods (21.6% and 16.2% improvements, respectively, with respect to a common cluster quality measure) without sacrificing simplicity or efficiency. 1.3 Utility Our algorithms for organizing information systems can be used in several ways. <p> A selection made in one window is simultaneously reflected in the others. 2.5 Performance Comparison with Two Clustering Algorithms In order to evaluate the performance of our system, we tested the star algorithm against two classic clustering algorithms: the single link method <ref> [Cro77] </ref> and the average link method [Voo85]. We used data from the TREC-6 conference as our testing medium. The TREC collection contains a set of 130,471 documents of which 21,694 have been ascribed relevance data with respect to 47 topics.
Reference: [CKP93] <author> D. Cutting, D. Karger, and J. Pedersen. </author> <title> Constant interaction-time Scatter/Gather browsing of very large document collections. </title> <booktitle> In Proceedings of the 16 th SIGIR, </booktitle> <year> 1993. </year>
Reference-contexts: The single link method [Cro77] does not provide any guarantees for the topic similarity within a cluster. Jardine and van Rijsber-gen [JR71] show some evidence that search results could be improved by clustering. Hearst and Pedersen [HP96] re-examine the cluster hypothesis by focusing on the Scatter/Gather system <ref> [CKP93] </ref> and conclude that it holds for browsing tasks. Systems like Scatter/Gather [CKP93] provide a mechanism for user-driven organization of data into a fixed number of clusters, but user feedback is required and the computed clusters do not have accuracy guarantees. Scatter/Gather uses fractionation to compute nearest-neighbor clusters. <p> Jardine and van Rijsber-gen [JR71] show some evidence that search results could be improved by clustering. Hearst and Pedersen [HP96] re-examine the cluster hypothesis by focusing on the Scatter/Gather system <ref> [CKP93] </ref> and conclude that it holds for browsing tasks. Systems like Scatter/Gather [CKP93] provide a mechanism for user-driven organization of data into a fixed number of clusters, but user feedback is required and the computed clusters do not have accuracy guarantees. Scatter/Gather uses fractionation to compute nearest-neighbor clusters. <p> We propose an off-line algorithm for clustering static information and an on-line version of this algorithm for clustering dynamic information. These two algorithms compute clusters induced by the natural topic structure of the space. Thus, this work is different than <ref> [CKP93, CCFM97] </ref> in that we do not impose a fixed number of clusters as a constraint on the solution. As a result, we can guarantee a lower bound on the topic similarity between the documents in each cluster.
Reference: [FG88] <author> T. Feder and D. Greene, </author> <title> Optimal algorithms for approximate clustering, </title> <booktitle> in Proceedings of the 20 th Symposium on Theory of Computing, </booktitle> <pages> pp 434-444, </pages> <year> 1988. </year>
Reference: [HP96] <author> M. Hearst and J. Pedersen. </author> <title> Reexamining the cluster hypothesis: </title> <booktitle> Scatter/Gather on Retrieval Re sults. In Proceedings of the 19 th SIGIR, </booktitle> <year> 1996. </year>
Reference-contexts: The single link method [Cro77] does not provide any guarantees for the topic similarity within a cluster. Jardine and van Rijsber-gen [JR71] show some evidence that search results could be improved by clustering. Hearst and Pedersen <ref> [HP96] </ref> re-examine the cluster hypothesis by focusing on the Scatter/Gather system [CKP93] and conclude that it holds for browsing tasks.
Reference: [HS86] <author> D. Hochbaum and D. Shmoys, </author> <title> A unified approach to approximation algorithms for bottleneck problems, </title> <journal> Journal of the ACM, </journal> <volume> no. 33, pp533-550, </volume> <year> 1986. </year>
Reference-contexts: Since the star algorithm is also highly efficient and simple to implement, we advocate its use for tasks that require clustering, such as information organization, routing, topic tracking, and new topic detection. 1.1 Previous Work There has been extensive research on clustering and applications to many domains <ref> [HS86, AB84] </ref>. For a good overview see [JD88]. For a good overview of using clustering in information retrieval see [Wil88].
Reference: [JD88] <author> A. Jain and R. Dubes. </author> <title> Algorithms for Clustering Data, </title> <publisher> Prentice Hall 1988. </publisher>
Reference-contexts: For a good overview see <ref> [JD88] </ref>. For a good overview of using clustering in information retrieval see [Wil88]. The use of clustering in information retrieval was mostly driven by the cluster hypothesis [Rij79] which states that relevant documents tend to be more closely related to each other than to non-relevant documents. <p> In this setting we used the star algorithm to find a set of star centers, then partitioned a collection by assigning a document to the closest star center. This methodology has been used before <ref> [JD88] </ref>. We note that the difference in results between star with overlapping clusters and star without overlapping clusters is very small. Both algorithms still outperform single link and average link (See Figure 4). Each subcollection of 1,000 documents corresponded to an individual experiment.
Reference: [JR71] <author> N. Jardine and C.J. van Rijsbergen. </author> <title> The use of hierarchical clustering in information retrieval, </title> <booktitle> Information Storage and Retrieval, </booktitle> <volume> 7 </volume> <pages> 217-240, </pages> <year> 1971. </year>
Reference-contexts: Croft [Cro80] describes a method for bottom-up cluster search that could be shown to outperform a full ranking system for the Cranfield collection. The single link method [Cro77] does not provide any guarantees for the topic similarity within a cluster. Jardine and van Rijsber-gen <ref> [JR71] </ref> show some evidence that search results could be improved by clustering. Hearst and Pedersen [HP96] re-examine the cluster hypothesis by focusing on the Scatter/Gather system [CKP93] and conclude that it holds for browsing tasks.
Reference: [KP93] <author> G. Kortsarz and D. Peleg. </author> <title> On choosing a dense subgraph. </title> <booktitle> In Proceedings of the 34th Annual Symposium on Foundations of Computer Science (FOCS), </booktitle> <year> 1993. </year>
Reference: [LLR95] <author> N. Linial, E. London, and Y. Rabinovich. </author> <title> The geometry of graphs and some of its algorithmic applications. </title> <type> Combinatorica 15(2) </type> <pages> 215-245, </pages> <year> 1995. </year>
Reference-contexts: This setting provides a good placement when the number of clusters returned by the algorithm is small. This algorithm is fast, and its running time does not depend on the number of clusters. When the number of clusters is large, the ellipsoid-based method for Euclidean graph em-beddings described in <ref> [LLR95] </ref> can be used instead. All three views and a title window allow the user to select an individual document or a cluster.
Reference: [LY94] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <journal> Journal of the ACM 41, </journal> <pages> 960-981, </pages> <year> 1994. </year>
Reference-contexts: To compute accurate clusters, we formalize the clustering problem as one of covering a thresholded similarity graph by cliques. Covering by cliques is NP-complete and thus intractable for large document collections. Recent graph-theoretic results have shown that the problem cannot even be approximated in polynomial time <ref> [LY94, Zuc93] </ref>. We instead use a cover by dense subgraphs that are star-shaped 1 , where the covering can be computed off-line for static data and on-line for dynamic data. We show that the off-line and on-line algorithms produce high-quality clusters very efficiently. <p> Unfortunately, this approach is not tractable computa-tionally. For real corpora, similarity graphs can be very large. The clique cover problem is NP-complete, and it does not admit polynomial-time approximation algorithms <ref> [LY94, Zuc93] </ref>. While we cannot perform a clique cover nor even approximate such a cover, we can instead cover our graph by dense subgraphs. What we lose in intra-cluster similarity guarantees, we gain in computational efficiency.
Reference: [Rij79] <editor> C.J. van Rijsbergen. </editor> <booktitle> Information Retrieval. </booktitle> <address> But-terworths, London, </address> <year> 1979. </year>
Reference-contexts: For a good overview see [JD88]. For a good overview of using clustering in information retrieval see [Wil88]. The use of clustering in information retrieval was mostly driven by the cluster hypothesis <ref> [Rij79] </ref> which states that relevant documents tend to be more closely related to each other than to non-relevant documents. Efforts have been made to determine whether the cluster hypothesis is valid. Voorhees [Voo85] discusses a way of evaluating whether the cluster hypothesis holds and shows negative results. <p> Two issues immediately arise: first, how does one measure the "quality" of a cluster to determine which is "best"; and second, how does one appropriately generate clusters from which to choose. To measure the quality of a cluster, we use the common E measure <ref> [Rij79] </ref> as defined below E (p; r) = 1 1=p + 1=r where p and r are the standard precision and recall of the cluster with respect to the set of documents relevant to the topic.
Reference: [Sal89] <author> G. Salton. </author> <title> Automatic Text Processing: the transformation, analysis, and retrieval of information by computer, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: We measure the similarity between two documents by using the cosine metric in the vector space model of the Smart information retrieval system <ref> [Sal89, Sal91] </ref>. G is a complete graph with edges of varying weight.
Reference: [Sal91] <author> G. Salton. </author> <title> The Smart document retrieval project. </title> <booktitle> In Proceedings of the Fourteenth Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp 356-358. </pages>
Reference-contexts: Yet another type of stories make previous reportings obsolete. The news focus changes regularly with this flow of information. In such dynamic systems, users need to locate information quickly and efficiently. Current information systems such as Inquery [Tur90], Smart <ref> [Sal91] </ref> and Alta Vista provide some simple automation by computing ranked (sorted) lists of documents, but it is ineffective for users to scan a list of hundreds of document titles. <p> We measure the similarity between two documents by using the cosine metric in the vector space model of the Smart information retrieval system <ref> [Sal89, Sal91] </ref>. G is a complete graph with edges of varying weight. <p> This organization system was used for the experiments described in this paper. It consists of an augmented version of the Smart system <ref> [Sal91, All95] </ref>, a user interface we have designed, and an implementation of the star algorithm on top of Smart. To index the documents we used the Smart search engine with a cosine normalization weighting scheme.
Reference: [Sha86] <author> W. Shaw, </author> <title> On the foundation of evaluation, </title> <journal> Journal of the American Society for Information Science, </journal> <volume> vol 37, </volume> <pages> pp 346-348, </pages> <year> 1986. </year>
Reference: [Sha93] <author> W. Shaw, </author> <title> Controlled and uncontrolled subject de-scriptions in the CF database: a comparison of optimal cluster-based retrieval results, </title> <booktitle> Information Processing and Management, </booktitle> <volume> vol. 29, </volume> <pages> pp 751-763, </pages> <year> 1993. </year>
Reference-contexts: of the methods was run in such a way so as to produce the "best" possible cluster with respect to a given topic, as defined by the E (p; r) measure above. (This is in keeping with previous comparative analyses of clustering methods; see, for example, Burgin [Bur95] and Shaw <ref> [Sha93] </ref>.) In the case of the single link and star cover algorithms, the algorithms were run using a range of thresholds, and the best cluster obtained over all thresholds was returned. (One can view the clustering obtained with respect to a given threshold as a "slice" within a hierarchical clustering over
Reference: [SJJ70] <author> K. Spark Jones and D. Jackson. </author> <title> The use of automatically-obtained keyword classifications for information retrieval. </title> <booktitle> Information Storage and Retrieval, </booktitle> <volume> 5 </volume> <pages> 174-201, </pages> <year> 1970. </year>
Reference-contexts: Such clustered data is useful for narrowing down the database over which detailed queries can be formulated. As a post-processor, this system classifies the retrieved data into clusters that capture topic categories and subcategories. The on-line algorithm can be used for 1 In <ref> [SJJ70] </ref> stars were also identified to be potentially useful for clustering. constructing self-organizing information systems, for routing problems, for topic detection, and for topic tracking. 2 Off-line Information Organization In this section, we begin by presenting an efficient algorithm for off-line organization of information.
Reference: [Tur90] <author> H. </author> <title> Turtle. Inference networks for document retrieval. </title> <type> PhD thesis. </type> <institution> University of Massachusetts, Amherst, </institution> <year> 1990. </year>
Reference-contexts: Some stories are new while other stories are follow-ups on previous stories. Yet another type of stories make previous reportings obsolete. The news focus changes regularly with this flow of information. In such dynamic systems, users need to locate information quickly and efficiently. Current information systems such as Inquery <ref> [Tur90] </ref>, Smart [Sal91] and Alta Vista provide some simple automation by computing ranked (sorted) lists of documents, but it is ineffective for users to scan a list of hundreds of document titles.
Reference: [vRC75] <author> C.J. van Rijsbergen and B. Croft, </author> <title> Document clustering: an evaluation of some experiments with the Cranfield 1400 collection, </title> <booktitle> Information Processing and Management, </booktitle> <volume> 11, </volume> <pages> 171-182. </pages>
Reference: [Voo85] <author> E. Voorhees. </author> <title> The effectiveness and efficiency of agglomerative hierarchical clustering in document retrieval, </title> <type> PhD Thesis, </type> <institution> Department of Computer Science, Cornell University 1985, </institution> <note> available as TR 85-705. </note>
Reference-contexts: The use of clustering in information retrieval was mostly driven by the cluster hypothesis [Rij79] which states that relevant documents tend to be more closely related to each other than to non-relevant documents. Efforts have been made to determine whether the cluster hypothesis is valid. Voorhees <ref> [Voo85] </ref> discusses a way of evaluating whether the cluster hypothesis holds and shows negative results. Croft [Cro80] describes a method for bottom-up cluster search that could be shown to outperform a full ranking system for the Cranfield collection. <p> Finally, we provide experimental data for off-line and online topic organization. In particular, our off-line results on a TREC collection indicate that star covers exhibit significant performance improvements over either the single link [Cro77] or average link <ref> [Voo85] </ref> methods (21.6% and 16.2% improvements, respectively, with respect to a common cluster quality measure) without sacrificing simplicity or efficiency. 1.3 Utility Our algorithms for organizing information systems can be used in several ways. <p> A selection made in one window is simultaneously reflected in the others. 2.5 Performance Comparison with Two Clustering Algorithms In order to evaluate the performance of our system, we tested the star algorithm against two classic clustering algorithms: the single link method [Cro77] and the average link method <ref> [Voo85] </ref>. We used data from the TREC-6 conference as our testing medium. The TREC collection contains a set of 130,471 documents of which 21,694 have been ascribed relevance data with respect to 47 topics. These 21,694 documents were partitioned into 22 separate subcol-lections of approximately 1,000 documents each.
Reference: [Voo85] <author> E. Voorhees. </author> <title> The cluster hypothesis revisited. </title> <booktitle> In Proceedings of the 8 th SIGIR, </booktitle> <pages> pp 95-104, </pages> <year> 1985. </year>
Reference-contexts: The use of clustering in information retrieval was mostly driven by the cluster hypothesis [Rij79] which states that relevant documents tend to be more closely related to each other than to non-relevant documents. Efforts have been made to determine whether the cluster hypothesis is valid. Voorhees <ref> [Voo85] </ref> discusses a way of evaluating whether the cluster hypothesis holds and shows negative results. Croft [Cro80] describes a method for bottom-up cluster search that could be shown to outperform a full ranking system for the Cranfield collection. <p> Finally, we provide experimental data for off-line and online topic organization. In particular, our off-line results on a TREC collection indicate that star covers exhibit significant performance improvements over either the single link [Cro77] or average link <ref> [Voo85] </ref> methods (21.6% and 16.2% improvements, respectively, with respect to a common cluster quality measure) without sacrificing simplicity or efficiency. 1.3 Utility Our algorithms for organizing information systems can be used in several ways. <p> A selection made in one window is simultaneously reflected in the others. 2.5 Performance Comparison with Two Clustering Algorithms In order to evaluate the performance of our system, we tested the star algorithm against two classic clustering algorithms: the single link method [Cro77] and the average link method <ref> [Voo85] </ref>. We used data from the TREC-6 conference as our testing medium. The TREC collection contains a set of 130,471 documents of which 21,694 have been ascribed relevance data with respect to 47 topics. These 21,694 documents were partitioned into 22 separate subcol-lections of approximately 1,000 documents each.
Reference: [Wil88] <author> P. Willett. </author> <title> Recent trends in hierarchical document clustering: A critical review. </title> <booktitle> Information Processing and Management, </booktitle> <address> 24:(5):577-597, </address> <year> 1988. </year>
Reference-contexts: For a good overview see [JD88]. For a good overview of using clustering in information retrieval see <ref> [Wil88] </ref>. The use of clustering in information retrieval was mostly driven by the cluster hypothesis [Rij79] which states that relevant documents tend to be more closely related to each other than to non-relevant documents. Efforts have been made to determine whether the cluster hypothesis is valid.
Reference: [Wor71] <author> S. Worona. </author> <title> Query clustering in a large document space. </title> <editor> In Ed. G. Salton, </editor> <booktitle> The SMART Retrieval System, </booktitle> <pages> pp 298-310. </pages> <publisher> Prentice-Hall, </publisher> <year> 1971. </year>
Reference: [Zuc93] <author> D. Zuckerman. </author> <title> NP-complete problems have a version that's hard to approximate. </title> <booktitle> In Proceedings of the Eight Annual Structure in Complexity Theory Conference, IEEE Computer Society, </booktitle> <pages> 305-312, </pages> <year> 1993. </year>
Reference-contexts: To compute accurate clusters, we formalize the clustering problem as one of covering a thresholded similarity graph by cliques. Covering by cliques is NP-complete and thus intractable for large document collections. Recent graph-theoretic results have shown that the problem cannot even be approximated in polynomial time <ref> [LY94, Zuc93] </ref>. We instead use a cover by dense subgraphs that are star-shaped 1 , where the covering can be computed off-line for static data and on-line for dynamic data. We show that the off-line and on-line algorithms produce high-quality clusters very efficiently. <p> Unfortunately, this approach is not tractable computa-tionally. For real corpora, similarity graphs can be very large. The clique cover problem is NP-complete, and it does not admit polynomial-time approximation algorithms <ref> [LY94, Zuc93] </ref>. While we cannot perform a clique cover nor even approximate such a cover, we can instead cover our graph by dense subgraphs. What we lose in intra-cluster similarity guarantees, we gain in computational efficiency.
References-found: 33

