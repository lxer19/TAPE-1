URL: http://www.ai.mit.edu/~edelman/mirror/robot-tr.ps.Z
Refering-URL: http://www.ai.mit.edu/~edelman/archive.html
Root-URL: 
Email: Internet: ishay@isaac.cs.technion.ac.il tamar@wisdom.weizmann.ac.il edelman@wisdom.weizmann.ac.il  
Title: Learning to Grasp Using Visual Information  
Author: Ishay Kamon, Tamar Flash, Shimon Edelman 
Date: May 18, 1994  
Address: Rehovot 76100, Israel  
Affiliation: Dept. of Applied Mathematics and Computer Science The Weizmann Institute of Science  
Abstract: A scheme for learning to grasp objects using visual information is presented. A system is considered that coordinates a parallel-jaw gripper (hand) and a camera (eye). Given an object, and considering its geometry, the system chooses grasping points, and performs the grasp. The system learns while performing grasping trials. For each grasp we store location parameters that code the locations of the grasping points, quality parameters that are relevant features for the assessment of grasp quality, and the grade. We learn two separate subproblems: (1) to choose grasping points, and (2) to predict the quality of a given grasp. The location parameters are used to locate grasping points on new target objects. We consider a function from the quality parameters to the grade, learn the function from examples, and later use it to estimate grasp quality. In this way grasp quality for novel situations can be generalized and estimated. An experimental setup using an AdeptOne manipulator to test this scheme was developed. Given an object, the system takes one image of it with a stationary top- view camera, uses the image to choose two grasping points on the boundary, performs a grasping trial with a parallel-jaw gripper, and assigns a grade to the trial using an additional side-mounted camera. The system has demonstrated an ability to grasp a relatively wide variety of objects, and its performance improves with experience appreciably after a small number of trials. 
Abstract-found: 1
Intro-found: 1
Reference: [BB82] <author> D. Ballard and C. Brown. </author> <title> Computer Vision. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersy, </address> <year> 1982. </year>
Reference-contexts: To calculate the transformation, we use four points as examples, and find their locations in both image and robot coordinates. We then solve a system of equations, as described in Ballard and Brown <ref> [BB82, pages 481-484] </ref>. The calibration was performed once.
Reference: [Bla92] <author> A. Blake. </author> <title> Computational modelling of hand-eye coordination. </title> <journal> Phil. Trans. R. Soc. London, </journal> <volume> 337 </volume> <pages> 351-360, </pages> <year> 1992. </year>
Reference-contexts: Previous work may be divided into two main approaches: * The analytic approach takes a model of the target object, and finds optimal grasping points on it, relative to some criteria for optimality (see Nguyen [Ngu88], Markenscoff and Papadimitriu [MP89], Faverjon and Ponce [FP91] and Blake <ref> [Bla92] </ref>). In the context of learning we examine the function f 1 : S 7! A s:t: G is maximized where S = State (sensory information), A = Action, and G = Grade (quality of the action). <p> Finding good grasps for this kind of shapes is difficult. There are several algorithms that solve the problem of finding stable two-fingered grasp for 2D objects (see Nguyen [Ngu88], Markenscoff and Papadimitriu [MP89], Faverjon and Ponce [FP91] and Blake <ref> [Bla92] </ref>). These algorithms require the shape of the target object, which is represented as a polygon or a smooth curve, and perform non trivial geometrical analysis. There are objects that do not have a stable two-fingered grasp. 2. Uncertainty about the object's characteristics.
Reference: [DS88] <author> G. Dunn and J. Segen. </author> <title> Automatic discovery of robotic grasp configurations. </title> <booktitle> In Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 396-401, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: The function f 2 : S fi A 7! G is studied. Relatively a few works have dealt with the problem of learning to grasp. Dunn and Segen <ref> [DS88] </ref> presented a system that first tried to recognize its target object using a stored library. If the object was recognized, the stored grasp was applied to it. For an unknown object, the system tried to grasp it by trial and error. <p> After thinning, every pixel in the boundary has exactly two neighbors. 9 (quality measure) depends on the difference between the minimal height and the optimal height. 3.2.2 Automatic Grading To estimate the quality of a grasp, we used the minimal height of the object (see <ref> [DS88] </ref>). If the object is held firmly, its height is above a certain value. If the object slides, its minimal height is lower. The grade given is lower when the minimal height is lower (see figure 6). <p> The system generalized among objects. These results have demonstrated better performance compared to previous studies that have dealt with the same problem: Dunn and Segen <ref> [DS88] </ref> and Tan [Tan90] used three target objects each, and Salganicoff [Sal92] considered only cylinders and boxes. None of the previous studies presented an improvement of grasping performance over a continuous session of work. <p> Appendix B Safety Checks Given two grasping points on the image boundary, we verify that the open gripper does not collide with the object before reaching the grasping points (see <ref> [DS88] </ref>). We use two tests : 1. The distance between the grasping points does not exceed the opening of the gripper. 2. The fingers do not collide with the object.
Reference: [FIH91] <author> C. Francois, K. Ikeuchi, and M. Herbert. </author> <title> A three-finger gripper for manipula-tion in unstructured environments. </title> <booktitle> In Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 2261-2266, </pages> <year> 1991. </year>
Reference-contexts: This formulation is called reinforcement learning. * The comparative approach generates a set of candidate grasps, evaluates the quality of each grasp and chooses the best candidate (see Wolter et al. [WVW85], Gatrell [Gat89], and Francois et al. <ref> [FIH91] </ref>). The function f 2 : S fi A 7! G is studied. Relatively a few works have dealt with the problem of learning to grasp. Dunn and Segen [DS88] presented a system that first tried to recognize its target object using a stored library.
Reference: [FP91] <author> B. Faverjon and J. Ponce. </author> <title> On computing two-finger force-closure grasps on curved 2d objects. </title> <booktitle> In Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 424-429, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Previous work may be divided into two main approaches: * The analytic approach takes a model of the target object, and finds optimal grasping points on it, relative to some criteria for optimality (see Nguyen [Ngu88], Markenscoff and Papadimitriu [MP89], Faverjon and Ponce <ref> [FP91] </ref> and Blake [Bla92]). In the context of learning we examine the function f 1 : S 7! A s:t: G is maximized where S = State (sensory information), A = Action, and G = Grade (quality of the action). <p> Finding good grasps for this kind of shapes is difficult. There are several algorithms that solve the problem of finding stable two-fingered grasp for 2D objects (see Nguyen [Ngu88], Markenscoff and Papadimitriu [MP89], Faverjon and Ponce <ref> [FP91] </ref> and Blake [Bla92]). These algorithms require the shape of the target object, which is represented as a polygon or a smooth curve, and perform non trivial geometrical analysis. There are objects that do not have a stable two-fingered grasp. 2. Uncertainty about the object's characteristics.
Reference: [Gat89] <author> L. Gatrell. </author> <title> Cad-based grasp synthesis utilizing polygons,edges and vertexes. </title> <booktitle> In Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 184-189, </pages> <year> 1989. </year>
Reference-contexts: This formulation is called reinforcement learning. * The comparative approach generates a set of candidate grasps, evaluates the quality of each grasp and chooses the best candidate (see Wolter et al. [WVW85], Gatrell <ref> [Gat89] </ref>, and Francois et al. [FIH91]). The function f 2 : S fi A 7! G is studied. Relatively a few works have dealt with the problem of learning to grasp. Dunn and Segen [DS88] presented a system that first tried to recognize its target object using a stored library.
Reference: [Hor86] <author> B. Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: The object shape is smoothed, using local considerations. The planar center of mass is found by averaging the (x; y) coordinates of the object pixels. The axis of the least second moment is found, by using the method described in Horn <ref> [Hor86, page 53] </ref>. The boundary of the object is marked forming a closed curve. We mark off pixels in the boundary that are not necessary for connectivity.
Reference: [MP89] <author> X. Markenscoff and C.H. Papadimitriou. </author> <title> Optimum grip of a polygon. </title> <journal> International Journal of Robotics research, </journal> <volume> 8(2) </volume> <pages> 17-29, </pages> <year> 1989. </year>
Reference-contexts: Previous work may be divided into two main approaches: * The analytic approach takes a model of the target object, and finds optimal grasping points on it, relative to some criteria for optimality (see Nguyen [Ngu88], Markenscoff and Papadimitriu <ref> [MP89] </ref>, Faverjon and Ponce [FP91] and Blake [Bla92]). In the context of learning we examine the function f 1 : S 7! A s:t: G is maximized where S = State (sensory information), A = Action, and G = Grade (quality of the action). <p> Finding good grasps for this kind of shapes is difficult. There are several algorithms that solve the problem of finding stable two-fingered grasp for 2D objects (see Nguyen [Ngu88], Markenscoff and Papadimitriu <ref> [MP89] </ref>, Faverjon and Ponce [FP91] and Blake [Bla92]). These algorithms require the shape of the target object, which is represented as a polygon or a smooth curve, and perform non trivial geometrical analysis. There are objects that do not have a stable two-fingered grasp. 2. Uncertainty about the object's characteristics.
Reference: [Ngu88] <author> V. D. Nguyen. </author> <title> Constructing force-closure grasps. </title> <journal> International Journal of Robotics research, </journal> <volume> 7(3) </volume> <pages> 3-16, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: In the context of grasping, this corresponds to learning to improve the grasp quality. Previous work may be divided into two main approaches: * The analytic approach takes a model of the target object, and finds optimal grasping points on it, relative to some criteria for optimality (see Nguyen <ref> [Ngu88] </ref>, Markenscoff and Papadimitriu [MP89], Faverjon and Ponce [FP91] and Blake [Bla92]). In the context of learning we examine the function f 1 : S 7! A s:t: G is maximized where S = State (sensory information), A = Action, and G = Grade (quality of the action). <p> Finding good grasps for this kind of shapes is difficult. There are several algorithms that solve the problem of finding stable two-fingered grasp for 2D objects (see Nguyen <ref> [Ngu88] </ref>, Markenscoff and Papadimitriu [MP89], Faverjon and Ponce [FP91] and Blake [Bla92]). These algorithms require the shape of the target object, which is represented as a polygon or a smooth curve, and perform non trivial geometrical analysis. There are objects that do not have a stable two-fingered grasp. 2.
Reference: [Sal92] <author> M. Salganicoff. </author> <title> Learning and Forgetting for Perception-Action : A Projection Pursuit and Density Adaptivr Approach. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, School of Engineering and Applied Sciencs, Computer and Information Science Department, </institution> <year> 1992. </year>
Reference-contexts: The system generalized among objects. These results have demonstrated better performance compared to previous studies that have dealt with the same problem: Dunn and Segen [DS88] and Tan [Tan90] used three target objects each, and Salganicoff <ref> [Sal92] </ref> considered only cylinders and boxes. None of the previous studies presented an improvement of grasping performance over a continuous session of work. The results support the argument that a single image may be sufficient for grasping a 3D object, under reasonable assumptions.
Reference: [SB92] <editor> M. Salganicoff and Ruzena K. Bajcsy. </editor> <title> Robotic sensory learning in continuous domains. </title> <booktitle> Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <month> may </month> <year> 1992. </year>
Reference-contexts: In the working stage, a sequence of actions was planned, and the target object was recognized and grasped. No generalization of new objects was performed in those systems. Salganicoff and Bajcsy <ref> [SB92] </ref> presented a general framework for learning sensorimotor tasks, considering the function f 2 : S fi A 7! G and suggesting to approximate it from examples.
Reference: [Tan90] <author> M. Tan. </author> <title> CSL: A cost sensitive learning system for sensing and grasping objects. </title> <booktitle> In Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 858-863, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Dunn and Segen [DS88] presented a system that first tried to recognize its target object using a stored library. If the object was recognized, the stored grasp was applied to it. For an unknown object, the system tried to grasp it by trial and error. Tan <ref> [Tan90] </ref> used a set of features to distinguish among objects. In the training stage, some measurements were taken for several objects, and a decision tree was built, making it possible to distinguish among the objects. <p> The system generalized among objects. These results have demonstrated better performance compared to previous studies that have dealt with the same problem: Dunn and Segen [DS88] and Tan <ref> [Tan90] </ref> used three target objects each, and Salganicoff [Sal92] considered only cylinders and boxes. None of the previous studies presented an improvement of grasping performance over a continuous session of work.
Reference: [WVW85] <author> J.D. Wolter, R.A. Volz, and A.C. Woo. </author> <title> Automatic generation of gripping positions. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 15(2):204213, </volume> <month> april </month> <year> 1985. </year> <month> 32 </month>
Reference-contexts: This formulation is called reinforcement learning. * The comparative approach generates a set of candidate grasps, evaluates the quality of each grasp and chooses the best candidate (see Wolter et al. <ref> [WVW85] </ref>, Gatrell [Gat89], and Francois et al. [FIH91]). The function f 2 : S fi A 7! G is studied. Relatively a few works have dealt with the problem of learning to grasp.
References-found: 13

