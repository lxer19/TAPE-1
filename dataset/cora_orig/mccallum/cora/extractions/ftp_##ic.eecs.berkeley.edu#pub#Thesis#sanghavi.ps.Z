URL: ftp://ic.eecs.berkeley.edu/pub/Thesis/sanghavi.ps.Z
Refering-URL: http://www-cad.eecs.berkeley.edu:80/Respep/Research/Thesis/thesis.html
Root-URL: 
Title: High Performance Verification Algorithms  
Author: by Jagesh V. Sanghavi 
Degree: B.Tech. (Indian Institute of Technology, Bombay) 1989 M.S. (University of California at Berkeley, California) 1993 A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Engineering Electrical Engineering and Computer Sciences in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA at BERKELEY Committee in charge: Professor Alberto L. Sangiovanni-Vincentelli Professor Robert K. Brayton Professor Phillip Colella  
Date: 1996  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> The National Technology Roadmap for Semiconductors. Semiconductor Industry Association, </institution> <year> 1994. </year>
Reference-contexts: INTRODUCTION 20 semiconductor generation. Continuation of Moore's law is the fundamental assumption made by Semiconductor Industry Association in charting the course of semiconductor technology over the next five generations <ref> [1] </ref>. The National Technology Roadmap for Semiconductors predicts that the device dimension of 0.35 micron in the year 1995 will continue to shrink at a rate of 0.7x every three years to 0.07 micron in the year 2010 (see Figure 1.11). Miniaturization creates new opportunities as well as new challenges.
Reference: [2] <author> A. L. </author> <title> Sangiovanni-Vincentelli. </title> <booktitle> Circuit Simulation, </booktitle> <pages> pages 19-113. </pages> <year> 1981. </year>
Reference-contexts: To an analog circuit designer, verification usually means SPICEing <ref> [75, 2] </ref> the circuit to see that it has desired output waveforms for a given set of inputs. In the design of microprocessors, verification means running a very large suite of regression vectors to make sure that the new design is bug-to-bug compatible with the previous generation.
Reference: [3] <author> S. B. Akers. </author> <title> Binary Decision Diagrams. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-37:509-516, </volume> <month> June </month> <year> 1978. </year>
Reference-contexts: Finally, in Section 2.10, we conclude and outline the direction of future work. 2.1 Introduction 2.1.1 Binary Decision Diagrams and Formal Verification The idea to represent a logic function by a BDD, a directed acyclic graph, was presented in the seminal paper by Akers <ref> [3] </ref>. The use of BDD was popularized by Bryant [16], who imposed the ordering constraints on variables of the logic function to make its BDD canonical and presented manipulation algorithms with polynomial complexity in the BDD size. <p> At the heart of a cycle-based simulator is an algorithm for function evaluation of combinational logic. Therefore, the performance of a cycle-based simulator depends on how fast it can evaluate a set of combinational logic functions. 3.2 Previous Work The idea to use a decision diagram <ref> [3, 16] </ref> to evaluate a logic function is quite simple. Conceptually, a decision diagram encodes truth table of a logic function. For a specific input combination, a logic function is evaluated by traversing a path in the decision diagram from its root to a leaf.
Reference: [4] <author> N. R. Aluru. </author> <title> Parallel and Stabilized Finite Element Methods for Hydrodynamic Transport Model of Semiconductor Devices. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1995. </year>
Reference-contexts: However, the method offers an interesting possibility as its memory requirement are modest and it demonstrates very high degree of parallelism. Brown et al. [15] report parallel solution of device equations using topologically rectangular finite element grid. Aluru <ref> [4] </ref> present stabilized finite element method for hydrodynamic transport model for semiconductor devices. The algorithm is parallelized on message passing multiprocessors such as iPSC/860, Touchstone Delta, and IBM SP-1. Tai et al. [95] present parallel in time algorithm for transient simulation of Semiconductor-On-Insulator (SOI) devices.
Reference: [5] <author> Thomas E. Anderson, David E. Culler, and David A. Patterson. </author> <title> A Case for NOW: Network of Workstations. </title> <type> Technical Report UCB/ERL M94/58, </type> <institution> Electronics Research Lab, Univ. of California, Berkeley, </institution> <address> CA 94720, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: We have implemented a breadth-first algorithm that uses remote CHAPTER 2. HIGH PERFORMANCE BDD ALGORITHMS 58 memory pager [39] on a Myrinet [11] connected prototype cluster of four workstations. The remote memory pager uses the idle main memories of workstations on the network <ref> [5] </ref> instead of the local disk for backing the main memory of the local workstation. 2.8 Experimental Results for the Breadth-First BDD Package We have implemented the algorithms for one workstation in a comprehensive BDD package - Cal package.
Reference: [6] <author> D. Antoniadis, S. Hansen, and R. Dutton. </author> <title> SUPREM II-A Program for IC Process Modeling and Simulation. </title> <type> Technical Report Stanford Technical Report 5019-2, </type> <institution> Stanford University, </institution> <month> May </month> <year> 1977. </year>
Reference-contexts: The process simulator is a prediction tool that helps estimate various device geometries and dopant distribution profiles using the process parameters such as the temperature, the pressure, the dopant dosage, etc. SUPREM III <ref> [6, 55] </ref> is one of most popular process simulation tools used to design IC processes. At the next higher level, one is concerned with the design of semiconductor devices. The objective in the device design is to optimize the performance of a device within the constraints of the technology.
Reference: [7] <author> Pranav Ashar and Matthew Cheong. </author> <title> Efficient Breadth-First Manipulation of Binary Decision Diagrams. </title> <booktitle> In The Proceedings International Conference on Computer-Aided Design, </booktitle> <pages> pages 622-627, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: The algorithms described in this chapter extend CHAPTER 1. INTRODUCTION 23 the ideas presented by Ochi et al. [77, 78] and Ashar et al. <ref> [7] </ref>. The new techniques based on the iterative breadth-first algorithm enable manipulation of very large BDDs by localizing the memory accesses. <p> The work presented in this chapter is based on the iterative breadth-first BDD manipulation technique pioneered by Ochi et al. [77, 78] and improved by Ashar et al. <ref> [7] </ref>. <p> HIGH PERFORMANCE BDD ALGORITHMS 26 within the main memory, the new package shows an improvement of upto a factor of 1.5 over the depth-first package. A black-box comparison shows that the new package is faster by a factor of 4.4x over the breadth-first implementation by Ashar et al. <ref> [7] </ref>. In addition to a comprehensive package on a single workstation, we present distributed BDD algorithm on a Network Of Workstations (NOW). <p> Fourth, it checks for redundant nodes during the REDUCE phase for the current index by accessing each REQUEST with the cofactor index. Unfortunately, it is observed that the QRBDD is several times larger than the corresponding BDD <ref> [7] </ref>. The additional nodes make this approach impractical for manipulating very large BDDs for the following reasons. First, it increases the amount of computation. Second, additional memory requirement puts a limit of size of BDD that can be manipulated. <p> Third, even if additional memory requirement is met, the algorithm may lead to page faults if the BDD size is less than the main memory capacity and QRBDD size exceeds the main memory capacity. 2.2.3 The Breadth-First BDD Algorithm of Ashar and Cheong Ashar and Cheong <ref> [7] </ref> use a BLOCK-INDEX table to determine the variable index from a BDD pointer by performing an associative lookup. Since this solution employs BDDs (as opposed CHAPTER 2. <p> The limitation of this approach is that it incurs significant bookkeeping overheads. to process THEN and ELSE cofactors separately for each REQUEST node. For BDDs that fit within the main memory, it is about a factor of 2.65 slower than the depth-first BDD manipulation algorithm <ref> [7] </ref>. 2.3 Improved Breadth-First BDD Algorithm Our approach to variable index determination problem differs from the previous approaches of Ashar et al. and Ochi et al. in the following aspects: 1. A new BDD node data structure is introduced to determine the variable index while preserving the locality of accesses. <p> We use same dfs-ordering in SIS to order the variables for both Long's package and our package. The number of BDD nodes needed to represent a particular circuit may be significantly different from those reported in literature (e.g. <ref> [7] </ref>) due to a different variable ordering. However, this issue is orthogonal to demonstrating the performance of our package. <p> We observe that we have been able to build BDDs with more than 23 million nodes in less than nine hours. We made black box comparison with best reported BFS algorithm <ref> [7] </ref> on Sun Sparc2 CHAPTER 2.
Reference: [8] <author> Pranav Ashar and Sharad Malik. </author> <title> Fast Functional Simulation Using Branching Programs. </title> <booktitle> In The Proceedings International Conference on Computer-Aided Design, </booktitle> <pages> pages 408-412, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: It appears that the work did not receive its due attention because of difficulties in managing large BDDs. A decade after the publication of idea to use decision diagram for logic function evaluation, it has once again caught attention of several researchers <ref> [8, 73] </ref>. The resurgence of the basic idea is due to increasing importance of cycle based logic simulation to improve the design turnaround time. In new approaches for decision diagram based logic simulators, an important extension is evaluation of several logic functions simultaneously. <p> In new approaches for decision diagram based logic simulators, an important extension is evaluation of several logic functions simultaneously. We describe how several logic functions are evaluated simulatenously in Section 3.3. The approach presented by Ashar et al. <ref> [8] </ref>, continue to use a branching program. However, an attempt is made to limit the size of the branching program by introducing intermediate evaluation points.
Reference: [9] <author> A. Barkatullah, W. Koe, H. Naik, and N. </author> <title> Zaidi. Pre-silicon validation of pentium cpu. In Hot Chips V, 1993. BIBLIOGRAPHY 144 </title>
Reference-contexts: A hardware emulator employs a large number of Field Programmable Gate Arrays (FPGAs) that can be configured to represent the design. Unfortunately, the process of mapping the design onto a hardware emulator may require an effort which is equivalent to the design effort for a medium sized chip <ref> [9] </ref>. Although formal methods have found application in the design verification process, they are restricted to verifying specific properties and combinational portion of logic circuits [74], hence, they tend to complement simulation and not replace it.
Reference: [10] <author> Jochen Bern, Christoph Meinel, and Anna Slobodova. </author> <title> Efficient OBDD based Boolean Manipulation in CAD beyond Current Limits. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 408-413, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The size of a BDD depends on the ordering of logic function variables; therefore, several static and dynamic variable ordering have been proposed to reduce the BDD size [72, 90]. Several variations of BDD data structure that relax the ordering constraint while retaining the canonicity property have been proposed <ref> [10, 46, 35] </ref> to reduce the BDD size. Reinterpreting the nodes of the directed acyclic graph to consider different function decomposition has been proposed [60, 36] to reduce the BDD size. These heuristic helps reduce the size of the BDDs by about 35-50%.
Reference: [11] <author> N. Boden, D. Cohen, R. Felderman, A. Kulawik, et al. Myrinet: </author> <title> a gigabit-per-second local area network. </title> <journal> IEEE Micro, </journal> <volume> 15 </volume> <pages> 29-36, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: We have implemented a breadth-first algorithm that uses remote CHAPTER 2. HIGH PERFORMANCE BDD ALGORITHMS 58 memory pager [39] on a Myrinet <ref> [11] </ref> connected prototype cluster of four workstations.
Reference: [12] <author> Z. Bozkus, S. Ranka, and G. Fox. </author> <title> Benchmarking the CM-5 multicomputer. </title> <booktitle> In IEEE 4th Symp. on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 100-107, </pages> <year> 1992. </year>
Reference-contexts: The partition number generated by the partitioner for each subdomain is also used as the processor number. The fat tree network of the CM-5 minimizes the maximum distance between processors <ref> [12] </ref>.
Reference: [13] <author> Karl S. Brace, Richard L. Rudell, and Randal E. Bryant. </author> <title> Efficient Implementation of a BDD Package. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 40-45, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: In addition to custom memory management, the package uses complement pointers <ref> [13] </ref> and garbage collection to conserve the memory.
Reference: [14] <author> M. A. Breuer and A. D. Friedman. </author> <title> Diagnosis and Reliable Design of Digital Systems. </title> <publisher> Computer Science Press, </publisher> <year> 1976. </year>
Reference-contexts: Although formal methods have found application in the design verification process, they are restricted to verifying specific properties and combinational portion of logic circuits [74], hence, they tend to complement simulation and not replace it. A conventional, gate-level, event-driven logic simulation algorithm <ref> [76, 14] </ref> is based on evaluating a logic gate for a change on its inputs. Signals are propagated from inputs to outputs of a combinational logic block by evaluating output of a gate if a signal on its input wire changes.
Reference: [15] <author> A. Brown, A. Asenov, S. Roy, and J. Barker. </author> <title> Parallel 3D finite element power semiconductor device simulator based on topologically rectangular grid. </title> <booktitle> In Proceedings of 6th International Conference on Simulation of Semiconductor Devices and Processes, </booktitle> <publisher> Erlangen, Germany, </publisher> <pages> pages 336-339, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: The main limitation of the algorithm is increase in the amount of computation required resulting in long elapsed time. However, the method offers an interesting possibility as its memory requirement are modest and it demonstrates very high degree of parallelism. Brown et al. <ref> [15] </ref> report parallel solution of device equations using topologically rectangular finite element grid. Aluru [4] present stabilized finite element method for hydrodynamic transport model for semiconductor devices. The algorithm is parallelized on message passing multiprocessors such as iPSC/860, Touchstone Delta, and IBM SP-1.
Reference: [16] <author> Randal E. Bryant. </author> <title> Graph-based Algorithms for Boolean Function Manipulation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35:677-691, </volume> <month> August </month> <year> 1986. </year>
Reference-contexts: The use of BDD was popularized by Bryant <ref> [16] </ref>, who imposed the ordering constraints on variables of the logic function to make its BDD canonical and presented manipulation algorithms with polynomial complexity in the BDD size. <p> At the heart of a cycle-based simulator is an algorithm for function evaluation of combinational logic. Therefore, the performance of a cycle-based simulator depends on how fast it can evaluate a set of combinational logic functions. 3.2 Previous Work The idea to use a decision diagram <ref> [3, 16] </ref> to evaluate a logic function is quite simple. Conceptually, a decision diagram encodes truth table of a logic function. For a specific input combination, a logic function is evaluated by traversing a path in the decision diagram from its root to a leaf.
Reference: [17] <author> Randal E. Bryant. </author> <title> Binary Decision Diagrams and Beyond: Enabling Technologies for Formal Verification. </title> <booktitle> In The Proceedings International Conference on Computer-Aided Design, </booktitle> <pages> pages 236-243, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: Due to canonicity and polynomial manipulation algorithms, BDD has emerged as a key data structure for formal verification of integrated circuits and systems <ref> [17] </ref>. We define a BDD in terms of a related entity an ordered binary decision tree, a binary tree representing a logic function for an ordering relation among its variables.
Reference: [18] <author> J. Burch, E. Clarke, D. Long, and K. McMillan. </author> <title> Symbolic Model Checking for Sequential Circuit Verification. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 13(4) </volume> <pages> 401-424, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Combination verification related heuristics make use recursive learning by combining structural and functional information to limit the BDD size [89, 59]. Property verification related heuristics are perhaps the broadest class of heuristics that make use of attributes of underlying mathematical model <ref> [29, 100, 18, 94] </ref> to reduce the BDD size. 2.1.2 Limitations of Conventional BDD Manipulation Algorithms In contrast to approaches that reduce the BDD size to make it fit within the main memory, the goal of this work is to build and manipulate very large BDDs that exceed the main memory
Reference: [19] <author> Doug Burger, Alian Kagi, and James Goodman. </author> <title> Memory Bandwidth Limitations of Future Microprocessors. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: The actual chasm in memory and processor performance is much wider as memory performance has increased at less than 10% per year whereas processor performance has increased at about 50% per year since 1986. Several researchers predict memory bandwidth to limit the performance of the future microprocessors <ref> [106, 19] </ref>. The disparity between DRAM and processor performance is also evidenced by extensive use of caches. In 1980, most of microprocessor designs did not have caches. In 1996, most of microprocessor designs have two levels of caches.
Reference: [20] <author> E. Buturla, P. Cottrell, B. Grossman, and A. Salsburg. </author> <title> Finite element analysis of semiconductor devices: The FIELDAY program. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 25 </volume> <pages> 218-239, </pages> <year> 1981. </year> <note> BIBLIOGRAPHY 145 </note>
Reference-contexts: Since finite difference grids can only allow modeling of rectangular device boundaries and internal interfaces, prismatic meshes are used to allow finer control of grid density in two dimensions since the 3-D grid is a tensor product of a 1-D and 2-D triangular grid. FIELDAY <ref> [20] </ref>, SIERRA [24], and HFIELDS [25] use this discretization grids. The FIELDAY program from IBM performs one, two, or three dimensional analysis using prismatic grids. The FIELDAY program uses Finite Element Method for the solution of the device equations.
Reference: [21] <author> C. Fiduccia and R. Mattheyses. </author> <title> A Linear-Time Heuristic for Improving Network Partitions. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 175-181, </pages> <year> 1982. </year>
Reference-contexts: The basic idea is to first swap nodes near the boundary and gradually move in until the desired sum of node degrees balance is obtained. The Geometrical partition is simple and efficient. It can be adapted to meet a set of partitioning objectives. Topographical Partitioner The Fiduccia-Mattheyses algorithm <ref> [21] </ref>, which is an improvement of a local search algorithm first presented by [105], is used to implement a topographical partitioner [62].
Reference: [22] <author> C. Pommerell and W. Fichtner. PILS: </author> <title> An Iterative Linear Solver Package for Ill-Conditioned Systems. </title> <booktitle> In The Proceedings of Supercomputing, </booktitle> <pages> pages 588-599, </pages> <year> 1991. </year>
Reference-contexts: SECOND uses the irregular grid generated by OMEGA and iterative linear solver PILS <ref> [22] </ref>. SECOND is implemented to run on a single processor workstation or on a vector supercomputer such as Cray Y-MP. We have chosen to improve the performance of Preconditioned CGS based three di CHAPTER 4. <p> SEMICONDUCTOR DEVICE SIMULATION 132 tioning for ECL and LOCOS examples with the geometrical partitioner. The results are shown in should be pointed out that PILS is a highly optimized sequential solver <ref> [22] </ref>. 4.7.3 CGS with Preconditioning ILU with Magnitude Threshold Fill-ins In implementing the preconditioner on the CM-5, we observed that any variation of the sequential FBS produced unsatisfactory results even with different variations of ordering schemes.
Reference: [23] <author> D. Y. Cheng, C. G. Hwang, and R. W. Dutton. PISCES-MC: </author> <title> a multiwindow, multimethod 2-D device simulator. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 7 </volume> <pages> 1017-1026, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 21 1.4.3 Performance Demands Let us take a closer look at how miniaturization of semiconductor devices impact some of most computationally expensive verification tasks that are addressed in this thesis. The device design requires extensive modeling and simulation of a semiconductor device to predict its behavior <ref> [91, 49, 23] </ref>. A semiconductor device is modeled mathematically by a set of coupled partial differential equations.
Reference: [24] <author> J. Chern, J. Maeda, L. Arledge, and P. Yang. </author> <title> SIERRA A 3-D Device Simulator for Reliability Modeling. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 8 </volume> <pages> 516-527, </pages> <year> 1989. </year>
Reference-contexts: Since finite difference grids can only allow modeling of rectangular device boundaries and internal interfaces, prismatic meshes are used to allow finer control of grid density in two dimensions since the 3-D grid is a tensor product of a 1-D and 2-D triangular grid. FIELDAY [20], SIERRA <ref> [24] </ref>, and HFIELDS [25] use this discretization grids. The FIELDAY program from IBM performs one, two, or three dimensional analysis using prismatic grids. The FIELDAY program uses Finite Element Method for the solution of the device equations.
Reference: [25] <author> P. Ciampolini, A. Pierantoni, M. Melanotte, C. Cecchetti, C. Lombardi, and G. Baccarani. </author> <title> Realistic Device Simulation in Three Dimensions. </title> <booktitle> In Proceeding of IEDM, </booktitle> <pages> pages 131-134, </pages> <year> 1989. </year>
Reference-contexts: FIELDAY [20], SIERRA [24], and HFIELDS <ref> [25] </ref> use this discretization grids. The FIELDAY program from IBM performs one, two, or three dimensional analysis using prismatic grids. The FIELDAY program uses Finite Element Method for the solution of the device equations.
Reference: [26] <author> P. Conti, N. Hitschfeld, and W. Fichtner. </author> <title> Omega An Octree-Based Mixed Element Grid Allocator for the Simulation of Complex 3-D Device Structures. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 10 </volume> <pages> 1231-1241, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The parallel CGS with per processor LU preconditioning is faster than PILS with Incomplete LU preconditioning by a factor of 38.3. The chapter is based on the extension of work on irregular grid generation by Conti et al. <ref> [26] </ref> and irregular grid device simulator on a single workstation by Heiser et al. [49]. <p> We present algorithms for three dimensional drift-diffusion device simulation on a Connection Machine 5 (CM-5) [58] that uses an irregular grid automatically generated by the OMEGA program <ref> [26, 53] </ref>. We address the issues of partitioning the computing load effectively among processors and meeting the communication requirements efficiently to achieve a high performance parallel implementation. <p> Toyabe et al. also use tensor product grids, which allows them to achieve very high vectorization ratio on vector supercomputers. Prismatic grids allow control of grid density only in two dimensions. This limitation of prismatic grids are overcome by Octree based mixed element grid generator OMEGA <ref> [26, 53] </ref>. The previous work on a single processor machine, which shares several concepts and algorithms with the work on parallel processors presented here, is presented by Heiser et al. [49] in SECOND, which is a general purpose, three dimensional device simulator. <p> For spatial discretization, a grid consisting of a mixture of triangular and rectangular pyramids and prisms as provided by the grid generator OMEGA <ref> [26, 53] </ref> is used. Figure 4.1 shows CHAPTER 4.
Reference: [27] <institution> Thinking Machines Corporation. </institution> <note> CMMD Reference Manual. </note> <year> 1992. </year>
Reference-contexts: The algorithms are implemented using the C programming language with the CMMD 3.0 communications library <ref> [27] </ref>.
Reference: [28] <institution> Thinking Machines Corporation. </institution> <type> Connection Machine CM-5 Technical Summary. </type> <year> 1993. </year>
Reference-contexts: Each compute node is a 32 MHz Sparc2 processor running at 32 MIPS with up to 32 MB of main memory. Compute nodes are interconnected by three separate networks: data network, control network, and diagnostic network. The data network is a two thickened fat tree <ref> [28, 64] </ref> with latency of 10s (2s 70s) and bandwidth of 8 10 MB per second.
Reference: [29] <author> O. Coudert and J. C. Madre. </author> <title> A Unified Framework for the Formal Verification of Sequential Circuits. </title> <booktitle> In The Proceedings International Conference on Computer-Aided Design, </booktitle> <pages> pages 126-129, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Combination verification related heuristics make use recursive learning by combining structural and functional information to limit the BDD size [89, 59]. Property verification related heuristics are perhaps the broadest class of heuristics that make use of attributes of underlying mathematical model <ref> [29, 100, 18, 94] </ref> to reduce the BDD size. 2.1.2 Limitations of Conventional BDD Manipulation Algorithms In contrast to approaches that reduce the BDD size to make it fit within the main memory, the goal of this work is to build and manipulate very large BDDs that exceed the main memory
Reference: [30] <author> W. Coughran, M. Pinto, and R. Smith. </author> <title> Adaptive Grid Generation for VLSI Device Simulation. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 10 </volume> <pages> 1159-1275, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: However, the rectangular grids suffer from several drawbacks. The applicability of rectangular grids is restricted since it can only model rectangular device boundaries and internal interfaces. It is also wasteful since the grids usually extend into quasi-neutral region. Coughran et al. <ref> [30] </ref> present an example for simulating a diagonal alpha particle track in two dimension that require over 2,000,000 grid points. The limitations of rectangular grids are overcome by the irregular grids, which allow CHAPTER 4. SEMICONDUCTOR DEVICE SIMULATION 99 flexibility in the local control of grid density.
Reference: [31] <author> D. Culler, J. Singh, and A. Goopta. </author> <title> Parallel Computer Architecture. </title> <type> unpublished draft, </type> <year> 1996. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 8 1.2 Parallel Computing 1.2.1 Hit or Near Miss A parallel computer is a collection of processing elements that cooperate and communicate to solve large problems fast [40]. Parallel computing provides several new opportunities to maximize performance within the constraints imposed by technology and cost <ref> [31] </ref>. Parallel computing is considered inevitable due to combination of following reasons. First, the rate of microprocessor performance improvement is slowing down. The microprocessor clock speed is expected to grow at slower than historical rates. <p> Wide range of choices for each of the subsystem components and variety of options in their organization has been a fertile ground for research on parallel computers. Historically, this flexibility has led to divergent architectures with no predictable pattern of growth <ref> [31] </ref>. Therefore, we have witnessed a plethora of parallel architectures, but dearth of parallel software. A closer look at evolutionary trends for each of the subsystems point to the convergence of parallel architectural models.
Reference: [32] <author> D. Bailey. </author> <title> Twelve Ways to Fool the Masses when Giving Performance Results on Parallel Computers. </title> <booktitle> Supercomputing Review, </booktitle> <address> IV(8), </address> <month> August </month> <year> 1991. </year>
Reference-contexts: The amount of serial work may be constant or increasing very slowly with the problem size, hence increasing the problem size decreases the fraction of serial computation, thereby, improving the chances for obtaining high speedups <ref> [32] </ref>. Efficiency E is a metric related to the speedup; it is an indicator of amount of time spent by each processor for doing useful work. E = N For a constant problem size, the efficiency of an algorithm decreases with increase in the number of processors.
Reference: [33] <author> D. Bursky. </author> <title> Combo RISC CPU and DRAM solves data bandwidth issues. </title> <booktitle> Electronic Design, </booktitle> <pages> pages 67-68, </pages> <month> March </month> <year> 1996. </year> <note> BIBLIOGRAPHY 146 </note>
Reference-contexts: For application that exhibit little or no correlation between addresses, the caches serve no useful purpose. The processor, memory system, and compiler complexity has increased tremendously in the effort to close the processor / DRAM performance gap. Integration of processor and DRAM on the same chip <ref> [33] </ref> is tauted to bridge the performance gap by increasing the memory bandwidth. Highly competitive, $50 billion, commodity DRAM market may offer enormous economic inertia to such a revolutionary change. Technologically, semiconductor processing recipe for DRAM and microprocessor fabrication are quite different.
Reference: [34] <author> D. Scharfetter and H. Gummel. </author> <title> Large-Signal Analysis of a Silicon Read Diode Oscillator. </title> <journal> IEEE Transactions on Electronic Devices, </journal> <volume> 16 </volume> <pages> 64-77, </pages> <year> 1969. </year>
Reference-contexts: The Scharfetter-Gummel method <ref> [34] </ref> along with the box method [102] is then used to obtain the discrete equations. These nonlinear equations are solved using either a fully-coupled or a decoupled Newton method. Trapezoidal/backward difference formula is used for time integration.
Reference: [35] <author> D. Sieling and I. Wegener. </author> <title> Graph-driven OBDDs ANew Data Structure for Boolean Functions. </title> <booktitle> Theoretical Computer Science, </booktitle> <year> 1995. </year>
Reference-contexts: The size of a BDD depends on the ordering of logic function variables; therefore, several static and dynamic variable ordering have been proposed to reduce the BDD size [72, 90]. Several variations of BDD data structure that relax the ordering constraint while retaining the canonicity property have been proposed <ref> [10, 46, 35] </ref> to reduce the BDD size. Reinterpreting the nodes of the directed acyclic graph to consider different function decomposition has been proposed [60, 36] to reduce the BDD size. These heuristic helps reduce the size of the BDDs by about 35-50%.
Reference: [36] <author> R. Drechsler, A. Sarabi, M. Theobald, B. Becker, and M. Perkowski. </author> <title> Efficient Representation and Manipulation of Switching Functions based on Ordered Kronecker Functional Decision Diagrams. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 415-419, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Several variations of BDD data structure that relax the ordering constraint while retaining the canonicity property have been proposed [10, 46, 35] to reduce the BDD size. Reinterpreting the nodes of the directed acyclic graph to consider different function decomposition has been proposed <ref> [60, 36] </ref> to reduce the BDD size. These heuristic helps reduce the size of the BDDs by about 35-50%. The heuristics based on exploiting the nature of the specific formal verification task can be further classified as 1. combinational verification related and 2. property verification related.
Reference: [37] <author> E. Cerny and J. Gecsei. </author> <title> Simulation of MOS Circuits by Decision Diagrams. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> CAD-4(4), </volume> <month> October </month> <year> 1985. </year>
Reference-contexts: At each node along the path, the decision on which edge to follow next is based on the value of a variable or a set of variables. Cerny et al. <ref> [37] </ref> pioneered the use of decision diagrams to simulate MOS circuits. A decision diagram was used to represent the function of a switch-level digital MOS circuit.
Reference: [38] <author> E. Cuthill and J. McKee. </author> <title> Reducing the Bandwidth of Sparse Symmetric Matrices. </title> <booktitle> In Proceeding of 24th National Conference of the Association of Computing Machinery, </booktitle> <pages> pages 157-172, </pages> <year> 1969. </year>
Reference-contexts: The ordering of processors affects the convergence behavior and also determines the amount of parallelism. In addition to the ordering algorithms mentioned above, we also implemented maximum degree for ordering processors to increase the sources of parallelism in computing ILU. Cuthill-McKee algorithm <ref> [38] </ref> orders the grid nodes by traversing the grid graph in a breadth-first order starting from a seed node. It was found by George et al. [45] that reversing the order improves the total storage and the number of arithmetic operations required for decomposition.
Reference: [39] <author> Eric Anderson. </author> <title> Network RAM. </title> <type> personal communication, </type> <year> 1996. </year>
Reference-contexts: Although we have a working implementation that demonstrates the basic principles, it is a better option to push the task of managing collective memories to the operating system. We have implemented a breadth-first algorithm that uses remote CHAPTER 2. HIGH PERFORMANCE BDD ALGORITHMS 58 memory pager <ref> [39] </ref> on a Myrinet [11] connected prototype cluster of four workstations.
Reference: [40] <author> G. Almasi and A. Gottlieb. </author> <title> Highly Parallel Computing. </title> <address> Benjamin-Cummings, Redwood, CA, </address> <year> 1989. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 8 1.2 Parallel Computing 1.2.1 Hit or Near Miss A parallel computer is a collection of processing elements that cooperate and communicate to solve large problems fast <ref> [40] </ref>. Parallel computing provides several new opportunities to maximize performance within the constraints imposed by technology and cost [31]. Parallel computing is considered inevitable due to combination of following reasons. First, the rate of microprocessor performance improvement is slowing down.
Reference: [41] <author> J. Gasbarro. </author> <title> The Rambus Memory System. </title> <booktitle> In International Workshop on Memory Technology, Design, and Testing, </booktitle> <pages> pages 94-96, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Cache DRAMs have been designed to integrate a small amount of SRAM cache on a DRAM chip resulting in faster access time for accesses that hit in the cache. Rambus <ref> [41] </ref> offers a radical solution to improving the performance of memory system by specifying devices, interface, protocol, and clocking scheme tightly integrating several aspects of memory system.
Reference: [42] <author> Al Geist, Adam Beguelin, Jack Dongarra, Weicheng Jiang, Robert Manchek, and Vaidy Sunderam. </author> <title> PVM 3 User's Guide and Reference Manual. </title> <institution> Oak Ridge National Laboratory, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: This environment contains approximately 60 workstations with 64MB (about 40MB available) main memory and 256MB (about 200MB available) disk space and MIPS-R4000 processor. We have used PVM <ref> [42, 43] </ref> (Parallel Virtual Machine) software to provide the communication between the workstations in the cluster during a BDD operation.
Reference: [43] <author> Al Geist, Adam Beguelin, Jack Dongarra, Weicheng Jiang, Robert Manchek, and Vaidy Sunderam. </author> <title> PVM: Parallel Virtual Machine. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: This environment contains approximately 60 workstations with 64MB (about 40MB available) main memory and 256MB (about 200MB available) disk space and MIPS-R4000 processor. We have used PVM <ref> [42, 43] </ref> (Parallel Virtual Machine) software to provide the communication between the workstations in the cluster during a BDD operation.
Reference: [44] <author> Gene Amdahl. </author> <title> Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities. </title> <booktitle> In AFIPS Spring Joint Computer Conference, </booktitle> <pages> pages 483-485, </pages> <year> 1967. </year>
Reference-contexts: Then the total available speedup S is limited by Amdahl's law <ref> [44] </ref> which roughly states that the speedup can not exceed the reciprocal of fraction of serial computation. S = (T s + T p =N ) where T s and T p represent time for serial and parallel computations respectively.
Reference: [45] <author> Alan George. </author> <title> Computer Implementation of Finite Element Method. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1971. </year> <note> BIBLIOGRAPHY 147 </note>
Reference-contexts: Cuthill-McKee algorithm [38] orders the grid nodes by traversing the grid graph in a breadth-first order starting from a seed node. It was found by George et al. <ref> [45] </ref> that reversing the order improves the total storage and the number of arithmetic operations required for decomposition. The resulting algorithm is called Reverse Cuthill-McKee algorithm. Given a graph G, the minimum degree algorithm, selects a node n with minimum degree to be numbered next.
Reference: [46] <author> J. Gergov and C. Meinel. </author> <title> Efficient Boolean Manipulation with OBDDs can be extended to FBDDs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 43(10) </volume> <pages> 1197-1209, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: The size of a BDD depends on the ordering of logic function variables; therefore, several static and dynamic variable ordering have been proposed to reduce the BDD size [72, 90]. Several variations of BDD data structure that relax the ordering constraint while retaining the canonicity property have been proposed <ref> [10, 46, 35] </ref> to reduce the BDD size. Reinterpreting the nodes of the directed acyclic graph to consider different function decomposition has been proposed [60, 36] to reduce the BDD size. These heuristic helps reduce the size of the BDDs by about 35-50%.
Reference: [47] <author> Wilsin Gosti. </author> <title> Breadth-First BDD Dynamic Variable Reordering. In report for EE219 class project, </title> <institution> University of California at Berkeley, Berkeley, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: In Figure 2.33, we provide the overhead for the Multiway-And operation, for various values of pipe-depth. We observe the memory overhead incurred increases with increase in pipedepth. 2.8.6 Dynamic Variable Ordering The sifting algorithm for dynamic variable ordering <ref> [47] </ref> is invoked after output BDDs for the combinational network are created. The results are shown in Figure 2.34. The sifting algorithm for the breadth-first algorithm takes significantly longer than the algorithm implemented as a part of Long's package.
Reference: [48] <author> H. Van der Vorst. </author> <title> Bi-CGSTAB: a fast and smoothly converging variant of Bi-CG for the solution of nonsymmetric linear systems. </title> <journal> SIAM Journal of Scientific and Statistical Computing, </journal> <volume> 13 </volume> <pages> 631-644, </pages> <year> 1992. </year>
Reference-contexts: It is worthwhile to point out several interesting parallel approaches, which use different algorithmic approach to solve the partial differential equations modeling semiconductor devices. Odanaka et al. [79] present iterative BiCGSTAB <ref> [48] </ref> algorithm combined with splitting-up operator method for incomplete factorization of the sparse matrices arising from the device equations. The authors report over 90% efficiency of a 256 processor machine. The high parallel efficiency is quite remarkable. <p> Modifications of the classical conjugate gradient method such as CGS [80] and BiCGSTAB <ref> [48] </ref> have emerged as preferred solution techniques for drift-diffusion device simulation. We have implemented a preconditioned CGS algorithm that shows rapid and robust convergence behavior. 4.4 Exploiting Memory Hierarchy The preconditioned CGS algorithm is shown in Figure 4.3.
Reference: [49] <author> G. Heiser, C. Pommerell, J. Weis, and W. Fichtner. </author> <title> Three-Dimensional Numerical Semiconductor Device Simulation: Algorithms, Architectures, Results. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 10 </volume> <pages> 1218-1230, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 21 1.4.3 Performance Demands Let us take a closer look at how miniaturization of semiconductor devices impact some of most computationally expensive verification tasks that are addressed in this thesis. The device design requires extensive modeling and simulation of a semiconductor device to predict its behavior <ref> [91, 49, 23] </ref>. A semiconductor device is modeled mathematically by a set of coupled partial differential equations. <p> The miniaturization of semiconductor devices require three dimensional analysis to accurately model device phenomena such as parasitic effects, CMOS latchup, and DRAM upset caused by ionizing radiation. However, three dimensional analysis is very expensive <ref> [49] </ref>. To obtain a rough idea on the enormity of the computational requirement, consider the following statistics for a typical simulation run. The three dimensional device analysis requires solution to a sequence of a set of 150,000 to 300,000 linears equations for each time point. <p> The chapter is based on the extension of work on irregular grid generation by Conti et al. [26] and irregular grid device simulator on a single workstation by Heiser et al. <ref> [49] </ref>. The new contributions are as follows: 1) methodology, algorithms, and implementation of the linear solver on a scalable parallel computer [92, 98]. and 2) general paradigm to optimize the memory performance of a sequence of linear algebra operations with specific application to improving the CHAPTER 4. <p> This limitation of prismatic grids are overcome by Octree based mixed element grid generator OMEGA [26, 53]. The previous work on a single processor machine, which shares several concepts and algorithms with the work on parallel processors presented here, is presented by Heiser et al. <ref> [49] </ref> in SECOND, which is a general purpose, three dimensional device simulator. SECOND uses the irregular grid generated by OMEGA and iterative linear solver PILS [22]. SECOND is implemented to run on a single processor workstation or on a vector supercomputer such as Cray Y-MP. <p> Trapezoidal/backward difference formula is used for time integration. The asymmetric linear system of equations is solved using an iterative linear system solver with preconditioning. The general solution approach is shown in Figure 4.2. Matrix generation and linear system solution are the computationally expensive steps of the solution process. <ref> [49] </ref> states that for a typical sequential 3-D simulation with a number of grid points of the order of 100,000, between 70 and 90% of the total simulation time is used to solve linear systems. <p> Hence, for the current implementation, linear device matrices are currently generated with the sequential program called Second <ref> [49] </ref> Box discretization produces coupling between different grid points only if the points are neighbors. Hence, the linear system resulting from the Newton scheme is very sparse with about eight block nonzeroes per row. Each grid node maps into three rows of the matrix. <p> If a Cray-2 is used to run PILS, a 40x performance improvement over Sparc workstation performance is obtained <ref> [49] </ref> Hence, it can be concluded that a 128 node CM-5 with no vector units will exceed Cray-2 performance for large irregular grid semiconductor drift-diffusion device simulations. MFLOPS ratings for the solution of device matrices are not useful. <p> The parallel algorithm will require more total floating point operations to converge since parallelization degrades the quality of the preconditioner. The current implementation uses a sequential matrix generator which takes 10-30% of the total sequential CPU time <ref> [49] </ref> This should be easy to parallelize since the communication requirement is the same as the matrix times vector operation. 138 Chapter 5 Conclusions and Future Work 5.1 Conclusions The performance demand of verification algorithms is very high.
Reference: [50] <author> B. P. Herndon, N. R. Aluru, A. Raefsky, R. Goossens, K. Law, and R. W. Dutton. </author> <title> A Methodology for Parallelizing PDE Solvers. </title> <booktitle> In SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <year> 1995. </year>
Reference-contexts: The PISCES code for two-dimensional device simulation uses prismatic grid. The existing public domain linear solver in PISCES is reported to be replaced by a parallel direct linear solver based on the work of Lucas [67] to create a parallel version PISCES-MP <ref> [50, 51] </ref>. Unfortunately, the direct method for solving linear system is unsuitable for three-dimensional simulation. Further, the direct method are very difficult to parallelize. Therefore, it is difficult to achieve very good performance improvement on a large scale parallel computer.
Reference: [51] <author> B. P. Herndon, A. Raefsky, and R. Goossens. </author> <title> PISCES MP Adaptation of Dusty Decks for Multiprocessing. </title> <booktitle> In Proceedings of NASECODE VII, </booktitle> <year> 1992. </year>
Reference-contexts: The PISCES code for two-dimensional device simulation uses prismatic grid. The existing public domain linear solver in PISCES is reported to be replaced by a parallel direct linear solver based on the work of Lucas [67] to create a parallel version PISCES-MP <ref> [50, 51] </ref>. Unfortunately, the direct method for solving linear system is unsuitable for three-dimensional simulation. Further, the direct method are very difficult to parallelize. Therefore, it is difficult to achieve very good performance improvement on a large scale parallel computer.
Reference: [52] <author> N. Hitschfeld, P. Conti, and W. Fichtner. </author> <title> Grid Generation for 3-D Nonplanar Semiconductor Device Structures. </title> <booktitle> In SISDEP Proceedings, </booktitle> <volume> volume 4, </volume> <pages> pages 165-169, </pages> <year> 1991. </year>
Reference-contexts: The nonbipartite matching based scheduling algorithm presented above can also be used for meeting the communication needs for evaluating the Jacobian. CHAPTER 4. SEMICONDUCTOR DEVICE SIMULATION 127 4.6 Experimental Results for Exploiting Memory Hierarchy 4.6.1 Benchmark Examples and Computing Environment Several device structures described in <ref> [52] </ref> are used in this study. ECL is a trench-isolated bipolar transistor, LOCOS is a short channel MOS transistor with surrounding locos isolation, and MCT is a MOS-controlled Thyristor with integrated MOS controlled n+ emitter shorts and a bipolar gate.
Reference: [53] <author> N. Hitschfeld, P. Conti, and W. Fichtner. </author> <title> Mixed Element Trees: A Generalization of Modified Octrees for the Generation of Meshes for the Simulation of Complex 3-D Semiconductor Device Structures. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 12 </volume> <pages> 1714-1725, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: We present algorithms for three dimensional drift-diffusion device simulation on a Connection Machine 5 (CM-5) [58] that uses an irregular grid automatically generated by the OMEGA program <ref> [26, 53] </ref>. We address the issues of partitioning the computing load effectively among processors and meeting the communication requirements efficiently to achieve a high performance parallel implementation. <p> Toyabe et al. also use tensor product grids, which allows them to achieve very high vectorization ratio on vector supercomputers. Prismatic grids allow control of grid density only in two dimensions. This limitation of prismatic grids are overcome by Octree based mixed element grid generator OMEGA <ref> [26, 53] </ref>. The previous work on a single processor machine, which shares several concepts and algorithms with the work on parallel processors presented here, is presented by Heiser et al. [49] in SECOND, which is a general purpose, three dimensional device simulator. <p> For spatial discretization, a grid consisting of a mixture of triangular and rectangular pyramids and prisms as provided by the grid generator OMEGA <ref> [26, 53] </ref> is used. Figure 4.1 shows CHAPTER 4.
Reference: [54] <author> N. Hitschfeld, K. Kells, and P. Conti. </author> <title> Omega 3.0 User's Guide. ETH-Zentrum, </title> <address> Zurich, </address> <year> 1991. </year>
Reference-contexts: loop */ foreach ( timepoint in the transient simulation ) /* Newton-Raphson loop */ while ( nonlinear equations not converged ) evaluate the equations for the Jacobian and right-hand side vector solve the associated linear system post-processing of results an ECL device with non-rectangular boundaries which is described further in <ref> [54] </ref>. The Scharfetter-Gummel method [34] along with the box method [102] is then used to obtain the discrete equations. These nonlinear equations are solved using either a fully-coupled or a decoupled Newton method. Trapezoidal/backward difference formula is used for time integration.
Reference: [55] <author> C. Ho, J. Plummer, S. Hansen, and R. Dutton. </author> <title> VLSI Process Modeling - SUPREM III. </title> <journal> IEEE Transactions on Electronic Devices, </journal> <volume> ED-30(11):1438-1453, </volume> <month> November </month> <year> 1983. </year>
Reference-contexts: The process simulator is a prediction tool that helps estimate various device geometries and dopant distribution profiles using the process parameters such as the temperature, the pressure, the dopant dosage, etc. SUPREM III <ref> [6, 55] </ref> is one of most popular process simulation tools used to design IC processes. At the next higher level, one is concerned with the design of semiconductor devices. The objective in the device design is to optimize the performance of a device within the constraints of the technology.
Reference: [56] <author> Horst Simon. </author> <title> Partitioning of Unstructured Problems for Parallel Processing. </title> <journal> Computing Systems in Engineering, </journal> <volume> 2 </volume> <pages> 135-148, </pages> <year> 1991. </year>
Reference-contexts: Ten trials are executed for each partitioning result in order to desensitize the partitioning outcome from the random initial guess. A 5% maximum load balance deviation tolerance is used for each binary partition. Spectral Partitioner The spectral partitioner <ref> [56] </ref> is based on the computation of the second largest eigenvalue and the corresponding eigenvector of the Laplacian matrix of the connectivity graph. The connectivity graph is the device mesh structure. Given a graph G (V; E) with the set of vertices V and the CHAPTER 4.
Reference: [57] <author> I. Duff and G. Meurant. </author> <title> The Effect of Ordering on Preconditioned Conjugate Gradients. </title> <booktitle> In BIT, </booktitle> <pages> pages 635-657, </pages> <year> 1989. </year> <note> BIBLIOGRAPHY 148 </note>
Reference-contexts: The amount of fill-in ignored influences the convergence behavior the number of CGS iterations required for convergence. The amount of fill-in determines the efficiency of FBS the time required to perform each CGS iteration. We have investigated use of Reverse Cuthill-McKee and Minimum Degree ordering algorithms <ref> [57] </ref> for ordering grid nodes within each processor. For a sequential preconditioner such as sequential ILU, ordering of processors is another factor to be considered. The ordering of processors affects the convergence behavior and also determines the amount of parallelism. <p> Again, the best results are still obtained with perfect node load balance. Effects of Ordering As mentioned earlier, the Reverse Cuthill-Mckee, minimum degree, and maximum degree algorithms <ref> [57] </ref> are implemented for ordering processors and grid nodes within each processor. No ordering is needed for the processors since the links across processors during preconditioning have been removed for parallel execution.
Reference: [58] <author> J. Palmer and G. Steele Jr. </author> <title> Connection Machine Model CM-5 System Overview. </title> <booktitle> In IEEE 4th Symp. on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 474-483, </pages> <year> 1992. </year>
Reference-contexts: We present algorithms for three dimensional drift-diffusion device simulation on a Connection Machine 5 (CM-5) <ref> [58] </ref> that uses an irregular grid automatically generated by the OMEGA program [26, 53]. We address the issues of partitioning the computing load effectively among processors and meeting the communication requirements efficiently to achieve a high performance parallel implementation.
Reference: [59] <author> J. Jain, R. Mukherjee, and M. Fujita. </author> <title> Advanced Verification Techniques based on Learning. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 420-426, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The heuristics based on exploiting the nature of the specific formal verification task can be further classified as 1. combinational verification related and 2. property verification related. Combination verification related heuristics make use recursive learning by combining structural and functional information to limit the BDD size <ref> [89, 59] </ref>.
Reference: [60] <author> U. Kebschull, E. Schubert, and W. Rosentiel. </author> <title> Multilevel Logic based on Functional Decision Diagram. </title> <booktitle> In The Proceedings European Design Automation Conference, </booktitle> <pages> pages 43-47, </pages> <year> 1992. </year>
Reference-contexts: Several variations of BDD data structure that relax the ordering constraint while retaining the canonicity property have been proposed [10, 46, 35] to reduce the BDD size. Reinterpreting the nodes of the directed acyclic graph to consider different function decomposition has been proposed <ref> [60, 36] </ref> to reduce the BDD size. These heuristic helps reduce the size of the BDDs by about 35-50%. The heuristics based on exploiting the nature of the specific formal verification task can be further classified as 1. combinational verification related and 2. property verification related.
Reference: [61] <author> Shinji Kimura and Edmund M. Clarke. </author> <title> A Parallel Algorithm for Constructing Binary Decision Diagrams. </title> <booktitle> In The Proceedings International Conference on Computer Design, </booktitle> <pages> pages 220-223, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: We use an extension of breadth-first algorithm to use total main memory and disk space of a NOW. The previous work has focused on parallelizing the BDD algorithm on multiprocessors. The algorithm proposed by Kimura and Clark <ref> [61] </ref> uses a shared memory multiprocessor that allow uniform access time to the main memory. The algorithm proposed by Parsuram [81] uses shared address space abstraction for a distributed memory multiprocessor. The parallel BDD algorithm proposed by Stornetta and Brewer [99] executes multiple threads on a distributed memory parallel machine.
Reference: [62] <author> C. J. Kring. </author> <title> Partitioning electronic systems into a hierarchy of packaging. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, </institution> <year> 1994. </year>
Reference-contexts: The Geometrical partition is simple and efficient. It can be adapted to meet a set of partitioning objectives. Topographical Partitioner The Fiduccia-Mattheyses algorithm [21], which is an improvement of a local search algorithm first presented by [105], is used to implement a topographical partitioner <ref> [62] </ref>. The basic algorithm is an iterative heuristic that reduces the number of edges cut in each pass while maintaining the difference between number of nodes in each partition within a specified tolerance. The complexity of each pass is linear in the size of the graph.
Reference: [63] <author> M. Kumanoya, T. Ogawa, Y. Konishi, and K. Dosaka. </author> <title> Trends in high-speed DRAM architectures. </title> <journal> IEICE Transactions on Electronics, </journal> <volume> E79-C:472-481, </volume> <month> April </month> <year> 1996. </year>
Reference-contexts: The cycle time for DRAM has reduced from 250ns to 90ns in the last 10 CHAPTER 1. INTRODUCTION 4 years. To compensate for the low rate of access time and cycle time improvement for standard DRAMs, innovative operating modes, novel memory architectures, and application-specific DRAMs have emerged <ref> [63] </ref>. Page mode exploits the internal organization of DRAM to reduce the cycle time between successive accesses to the same page. Nibble mode is also based on exploiting the internal DRAM organization; it can supply three extra bits from sequential location for every row access.
Reference: [64] <author> T. T. Kwan, B. K. Totty, and D. A. Reed. </author> <title> Communication and Computation Performance of CM-5. </title> <booktitle> In The Proceedings of Supercomputing, </booktitle> <year> 1993. </year>
Reference-contexts: Each compute node is a 32 MHz Sparc2 processor running at 32 MIPS with up to 32 MB of main memory. Compute nodes are interconnected by three separate networks: data network, control network, and diagnostic network. The data network is a two thickened fat tree <ref> [28, 64] </ref> with latency of 10s (2s 70s) and bandwidth of 8 10 MB per second. <p> The data network is a two thickened fat tree [28, 64] with latency of 10s (2s 70s) and bandwidth of 8 10 MB per second. Control network used in broadcast and global synchronization operation has latency of 2s and bandwidth of 800 Kbytes per second <ref> [64] </ref>. 1.3 Performance Performance, the key issue in verification, is measured by the total elapsed time to complete the task. Traditional analysis of algorithms takes a hundred thousand feet view of the computing landscape.
Reference: [65] <author> C. Leiserson, Z. Abuhamdeh, D. Douglas, C. Feynman, M. Ganmukhi, J. Hill, W. Hillis, B. Kuszmau, M. Pierre, D. Wells, M. Wong, S. Yang, and R. Zak. </author> <title> The Network Architecture of CM-5. </title> <booktitle> In Symposium on Parallel and Distributed Algorithms, </booktitle> <pages> pages 272-285, </pages> <year> 1992. </year>
Reference-contexts: In our case, the implementation substrate is CM-5, each compute node of which is a Sparc2 microprocessor with 8MB to 32MB of main memory; the compute nodes are interconnected using a high bandwidth, low latency fat-tree data network and a binary control network <ref> [65] </ref>.
Reference: [66] <author> David E. </author> <title> Long. ROBDD Package. </title> <institution> Carnegie Mellon University, Pittsburgh, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: The following set of experiments are carried out to demonstrate the performance of our BDD package: 1. Creating output BDDs of circuits: For comparing the performance of our package with a depth-first BDD package, we use Long's package <ref> [66] </ref>. We compare the time taken to create the BDDs for the outputs of circuits. The number of nodes in the BDDs range from a few thousands to tens of millions. 2. Demonstrating performance improvement due to superscalarity. 3. Demonstrating performance improvement due to pipelining. 4. <p> A complete package that consists of the whole suite of BDD operations based on these techniques is developed. We demonstrate the performance of our package by 1) comparing with state-of-the-art BDD package <ref> [66] </ref>, and 2) performing a comprehensive set of experiments to substantiate the capability of our approach. We show that our package provides competitive performance on small examples and a performance ratio of upto 100 on large examples.
Reference: [67] <author> R. F. Lucas. </author> <title> Solving Planar System of Equations on Distributed Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1987. </year>
Reference-contexts: The PISCES code for two-dimensional device simulation uses prismatic grid. The existing public domain linear solver in PISCES is reported to be replaced by a parallel direct linear solver based on the work of Lucas <ref> [67] </ref> to create a parallel version PISCES-MP [50, 51]. Unfortunately, the direct method for solving linear system is unsuitable for three-dimensional simulation. Further, the direct method are very difficult to parallelize. Therefore, it is difficult to achieve very good performance improvement on a large scale parallel computer.
Reference: [68] <author> A. Lumsdaine, M. Reichelt, J. Squyres, and J. White. </author> <title> Accelerated waveform methods for parallel transient simulation of semiconductor devices. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 15 </volume> <pages> 716-726, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: Tai et al. [95] present parallel in time algorithm for transient simulation of Semiconductor-On-Insulator (SOI) devices. This approach to partition across time is an interesting contrast to the approach presented in this chapter which partitions the space. Lumsdaine et al. <ref> [68] </ref> present accelerated waveform relaxation (WR) algorithm to perform parallel transient simulation on both a network of workstations and a scalable parallel computer IBM SP-2. The authors present several techniques to accelerate the rate of convergence for the waveform relaxation method.
Reference: [69] <author> M. Berger and S. Bokhari. </author> <title> A Partitioning Strategy for Non-uniform Problems on Multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <note> C-36:570-580, 1987. BIBLIOGRAPHY 149 </note>
Reference-contexts: The node and edge load balance approximate the balance of computational load among processors. The number of processor neighbors and total edges cut approximate the communication balance and total communication volume. We investigate the geometrical, topographical, and spectral partitioning heuristics that recursively bipartition <ref> [69] </ref> the graph representing the input grid structure. Each partitioner has strengths and weaknesses based on the parameters presented above. The relative importance of each parameter can be determined by the total elapsed time for the solution using each partitioner.
Reference: [70] <author> M. Flynn. </author> <title> Some Computer Organizations and their Effectiveness. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-21:948-960, </volume> <year> 1972. </year>
Reference-contexts: Therefore, parallel computing provides a road to high performance that is simple is concept but challenging in implementation. 1.2.2 Taxonomy The idea of using multiple processors to increase performance is so simple and compelling that it dates back to the earliest days of electronic computers. Flynn <ref> [70] </ref> proposed a classification of all computers by looking at parallelism in instruction and data streams. All computers are placed in one of the four categories. Single Instruction stream / Single Data stream (SISD) single processor computers.
Reference: [71] <author> M. Thurner and S. Selberherr. </author> <title> The extension of MINIMOS to three dimensional simulationr program. </title> <booktitle> In NASECODE V, </booktitle> <pages> pages 327-332, </pages> <year> 1987. </year>
Reference-contexts: Further, new algorithms are presented to achieve the robust solution without compromising the potential gains due to parallelism. 4.2 Previous Work The 3-D rectangular (finite difference) grids, which is a tensor product of three 1-D grids, are used in several device simulators such as CADDETH [101], MINIMOS <ref> [71] </ref>, SITAR [103], STRIDE [108]. The regularity of grid results in the ease of implementation. The earlier work on three dimensional device simulation presented by tomacruz et al. [97] on CM-5 parallel processors is limited to the use of rectangular grids.
Reference: [72] <author> S. Malik, A. R. Wang, R. K. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Logic Verification using Binary Decision Diagrams in a Logic Synthesis Environment. </title> <booktitle> In The Proceedings International Conference on Computer-Aided Design, </booktitle> <pages> pages 6-9, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: The size of a BDD depends on the ordering of logic function variables; therefore, several static and dynamic variable ordering have been proposed to reduce the BDD size <ref> [72, 90] </ref>. Several variations of BDD data structure that relax the ordering constraint while retaining the canonicity property have been proposed [10, 46, 35] to reduce the BDD size.
Reference: [73] <author> P. McGeer, K. McMillan, A. Saldanha, A. L. Sangiovanni-Vincentelli, and P. Scaglia. </author> <title> Fast discrete function evaluation using decision diagrams. </title> <booktitle> In The Proceedings International Conference on Computer-Aided Design, </booktitle> <year> 1995. </year>
Reference-contexts: In chapter 3, we present cycle-based logic simulation algorithm that exploit memory hierarchy and parallel computing to achieve performance improvement. The ideas described here improve the algorithms based on decision diagram to perform fast logic function evaluation. presented by McGeer et al. <ref> [73] </ref>. The first contribution of this chapter is identification of memory related issues that limit simulation algorithm performance. Several techniques are presented to reduce the size of the memory required by the algorithm. <p> At the heart of cycle-based simulation is algorithm for fast evaluation of combinational logic function. We present new decision diagram based fast logic function evaluation algorithms. This work is based on extension of ideas presented by McGeer et al. <ref> [73] </ref>. The original decision diagram based function evaluation algorithm presented by McGeer et al. attempted to minimize the number of instructions. The objective to minimize the number of instructions resulted in very large data sets. <p> In Section 3.2, we present previous work based on use of decision diagrams for logic function evaluation. In Section 3.3, we present relevant implementation details to identify the reason for large data sets in the early version of PRESTISSIMO <ref> [73] </ref>, cycle-based simulator by McGeer et al. In Section 3.4, we present techniques to reduce its memory requirements. In section 3.5, we present algorithms to perform several logic function evaluations in parallel. <p> It appears that the work did not receive its due attention because of difficulties in managing large BDDs. A decade after the publication of idea to use decision diagram for logic function evaluation, it has once again caught attention of several researchers <ref> [8, 73] </ref>. The resurgence of the basic idea is due to increasing importance of cycle based logic simulation to improve the design turnaround time. In new approaches for decision diagram based logic simulators, an important extension is evaluation of several logic functions simultaneously. <p> It is likely that a instruction fetch would result in a cache miss which places severe limitation on its performance of the algorithm. CHAPTER 3. CYCLE BASED LOGIC SIMULATION 77 McGeer et al. <ref> [73] </ref>, independently, presented fast logic function evaluation algorithm that uses an array to embed a decision diagram and a custom program to perform a sequence of lookups in this array. <p> Since the idea to use decision diagrams to evaluate logic functions is as simple as it is elegant, the key to its performance in practice depends on the details of the implementation. PRESTISSIMO cycle based logic simulator <ref> [73] </ref> represents a logic function by a Quasi-Reduced Multivalued Decision Diagram (QRMDD). <p> The maximum number of QRMDD nodes is limited to 2 16 . To make sure CHAPTER 3. CYCLE BASED LOGIC SIMULATION 83 that QRMDD size does not exceed 2 16 , it is possible to introduce intermediate evaluation points as explained in <ref> [73] </ref>. The flexibility to group any combination of primary outputs and next state variables results in a reduction in the total memory utilization.
Reference: [74] <author> K. L. McMillan. </author> <title> Fitting formal methods into the design cycle. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <year> 1994. </year>
Reference-contexts: Although formal methods have found application in the design verification process, they are restricted to verifying specific properties and combinational portion of logic circuits <ref> [74] </ref>, hence, they tend to complement simulation and not replace it. A conventional, gate-level, event-driven logic simulation algorithm [76, 14] is based on evaluating a logic gate for a change on its inputs.
Reference: [75] <author> L. Nagel. </author> <title> SPICE2: A Computer Program to Simulate Semiconductor Circuits. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, </institution> <year> 1975. </year>
Reference-contexts: To an analog circuit designer, verification usually means SPICEing <ref> [75, 2] </ref> the circuit to see that it has desired output waveforms for a given set of inputs. In the design of microprocessors, verification means running a very large suite of regression vectors to make sure that the new design is bug-to-bug compatible with the previous generation. <p> At the next higher level, one is concerned with the design of analog circuits such as digital-to-analog converters, analog-to-digital converters, voltage controlled oscillators, amplifiers, current mirrors, digital switching circuits, etc. The goal is to obtain the desired electrical behavior CHAPTER 1. INTRODUCTION 19 of the circuit. SPICE <ref> [75] </ref> is the most popular circuit simulator for the design of analog circuits. At the next higher level, one is concerned with the design of logic circuits. At the logic design level, the circuit is modeled by an interconnection of boolean gates.
Reference: [76] <author> A. R. </author> <title> Newton. The simulation of large scale integrated circuits. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, </institution> <year> 1978. </year>
Reference-contexts: Although formal methods have found application in the design verification process, they are restricted to verifying specific properties and combinational portion of logic circuits [74], hence, they tend to complement simulation and not replace it. A conventional, gate-level, event-driven logic simulation algorithm <ref> [76, 14] </ref> is based on evaluating a logic gate for a change on its inputs. Signals are propagated from inputs to outputs of a combinational logic block by evaluating output of a gate if a signal on its input wire changes.
Reference: [77] <author> H. Ochi, N. Ishiura, and S. Yajima. </author> <title> Breadth-First Manipulation of SBDD of Boolean Functions for Vector Processing. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 413-416, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: The algorithms described in this chapter extend CHAPTER 1. INTRODUCTION 23 the ideas presented by Ochi et al. <ref> [77, 78] </ref> and Ashar et al. [7]. The new techniques based on the iterative breadth-first algorithm enable manipulation of very large BDDs by localizing the memory accesses. <p> The work presented in this chapter is based on the iterative breadth-first BDD manipulation technique pioneered by Ochi et al. <ref> [77, 78] </ref> and improved by Ashar et al. [7].
Reference: [78] <author> H. Ochi, K. Yasuoka, and S. Yajima. </author> <title> Breadth-First Manipulation of Very Large Binary-Decision Diagrams. </title> <booktitle> In The Proceedings International Conference on Computer-Aided Design, </booktitle> <pages> pages 48-55, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The algorithms described in this chapter extend CHAPTER 1. INTRODUCTION 23 the ideas presented by Ochi et al. <ref> [77, 78] </ref> and Ashar et al. [7]. The new techniques based on the iterative breadth-first algorithm enable manipulation of very large BDDs by localizing the memory accesses. <p> The work presented in this chapter is based on the iterative breadth-first BDD manipulation technique pioneered by Ochi et al. <ref> [77, 78] </ref> and improved by Ashar et al. [7]. <p> In order to preserve the locality of references, it is important to determine the variable index of a BDD node without actually fetching it from the memory. 2.2.2 The Breadth-First BDD Algorithm of Ochi, Yasuoka, and Yajima The algorithm proposed by Ochi, Yasuoka, and Yajima <ref> [78] </ref> use a variant of BDDs - Quasi-Reduced BDDs (QRBDD) to preserve the locality of references. A QRBDD is obtained from a ordered binary decision tree of a function by merging isomorphic subgraphs. A QRBDD, unlike a BDD, retain the nodes with identical children.
Reference: [79] <author> S. Odanaka and T. Nogi. </author> <title> Massively parallel computation using a splitting-up operator method for three-dimensional device simulation. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 14 </volume> <pages> 824-832, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: It is worthwhile to point out several interesting parallel approaches, which use different algorithmic approach to solve the partial differential equations modeling semiconductor devices. Odanaka et al. <ref> [79] </ref> present iterative BiCGSTAB [48] algorithm combined with splitting-up operator method for incomplete factorization of the sparse matrices arising from the device equations. The authors report over 90% efficiency of a 256 processor machine. The high parallel efficiency is quite remarkable.
Reference: [80] <author> P. Sonneveld. </author> <title> CGS, A Fast Lanczos-type Solver for Non-symmetric Linear Systems. </title> <journal> SIAM Journal of Scientific and Statistical Computing, </journal> <volume> 10 </volume> <pages> 36-52, </pages> <year> 1989. </year> <note> BIBLIOGRAPHY 150 </note>
Reference-contexts: Modifications of the classical conjugate gradient method such as CGS <ref> [80] </ref> and BiCGSTAB [48] have emerged as preferred solution techniques for drift-diffusion device simulation. We have implemented a preconditioned CGS algorithm that shows rapid and robust convergence behavior. 4.4 Exploiting Memory Hierarchy The preconditioned CGS algorithm is shown in Figure 4.3.
Reference: [81] <author> Yegnashankar Parsuram. </author> <title> Parallel Implementation of BDD Algorithms on Connection Machine. </title> <type> Master's thesis, </type> <institution> Dept. of Electrical and Computer Engineering, Syracuse University, </institution> <year> 1993. </year>
Reference-contexts: The previous work has focused on parallelizing the BDD algorithm on multiprocessors. The algorithm proposed by Kimura and Clark [61] uses a shared memory multiprocessor that allow uniform access time to the main memory. The algorithm proposed by Parsuram <ref> [81] </ref> uses shared address space abstraction for a distributed memory multiprocessor. The parallel BDD algorithm proposed by Stornetta and Brewer [99] executes multiple threads on a distributed memory parallel machine. All of these algorithms use a dedicated parallel processor to speedup the BDD computation.
Reference: [82] <author> David A. Patterson and John L. Hennessy. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufman, </publisher> <address> first edition, </address> <year> 1990. </year>
Reference-contexts: Therefore, the recursive depth-first traversal leads to an extremely disorderly memory access pattern. In a typical computer system, the memory is organized hierarchically with smaller, faster, and more expensive (per byte) memory closer to the processor <ref> [82] </ref>. A simplified memory hierarchy consists of processor registers, several levels of on- and off-chip caches (SRAM), the main memory (DRAM), and a hard disk. The important characteristics of each memory system component are given in Figure 2.4. <p> The cost of a cache miss on a modern microprocessor can vary from 5 to 25 cycles and a TLB miss can potentially cost three times as much; further, this performance gap is increasing as processors become faster and memory performance is not keeping up <ref> [82] </ref>. TLB miss can occur even if the data is available in the cache. Typical cache sizes are 64KB to 128KB on the microprocessors, therefore, we see degradation in performance due to cache misses when the working set of the cycle simulation program exceeds the size of the data cache.
Reference: [83] <author> David A. Patterson and John L. Hennessy. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufman, </publisher> <address> second edition, </address> <year> 1996. </year>
Reference-contexts: Therefore, the clock rate is only a partial indicator of microprocessor's voracious appetite for crunching instructions and data. The performance growth rate for microprocessors is quoted to be around 50% per year <ref> [83] </ref>. 1.1.2 DRAMs For the last two decades, DRAM has been the driver for the new generation of semiconductor technology. The DRAM capacity has quadrupled every three years due to finer linewidths, larger chip area, and advances in the design of basic DRAM cells.
Reference: [84] <author> M. Pinto, C. Rafferty, H. Yeager, and R. Dutton. PISCES - IIB. </author> <type> Technical report, </type> <institution> Stanford University Integrated Circuit Laboratory Technical Report, </institution> <year> 1985. </year>
Reference-contexts: The goal is to obtain desired device parameters such as the threshold voltage for a MOS transistor and the beta of a BJT, and desired electrical characteristics of a device such as current-voltage characteristics and transient response. PISCES <ref> [84] </ref> is a device simulation tool that takes as its input device geometry, dopant distribution profile, and bias conditions to produce as its output the device characteristics and device parameters.
Reference: [85] <author> J. Pleumeekers, C. Simon, and S. Mottet. </author> <title> Investigation into the properties of the explicit method for the resolution of the semiconductor device equations. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 14 </volume> <pages> 459-463, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: The authors report over 90% efficiency of a 256 processor machine. The high parallel efficiency is quite remarkable. However, it is important to consider the overall performance improvement compared to the best sequential algorithm running on a single processor workstation. Pleumeekers et al. <ref> [85] </ref> investigate the use of explicit method for solving the device equations. The main limitation of the algorithm is increase in the amount of computation required resulting in long elapsed time.
Reference: [86] <author> R. Dutton. </author> <title> Algorithms and TCAD Software using Parallel Computation. </title> <booktitle> In VPAD Proceedings, </booktitle> <pages> pages 10-12, </pages> <year> 1993. </year>
Reference-contexts: Exploiting the memory hierarchy on each compute node of the parallel processor is another avenue to boost the overall performance. The rectangular spatial discretization grids have been natural choice for simulating 3-D devices on a parallel computer <ref> [107, 97, 108, 86] </ref>. The most important reason is the ease of parallel implementation afforded by the regularity of the grid structure: it is easy to balance the computational load among the processors, and it is easy to schedule the interprocessor communication due to regularity of communication patterns.
Reference: [87] <author> R. Sites and A. </author> <title> Perl. PatchWrx-A Dynamic Execution Tracing Tool. </title> <note> submitted to SIGMET-RICS, </note> <year> 1996. </year>
Reference-contexts: Replacement and write policies are also carefully chosen. In addition to integration of caches on a microprocessor, the cache sizes have also increased over the last ten years. For some applications, caches are shown not to be useful <ref> [87] </ref>. The results are reported on a quad instruction issue, 300MHz Alpha 21164 with two level of on-chip caches: first-level CHAPTER 1. INTRODUCTION 7 instruction and data caches 8KB each and second-level unified 96KB cache.
Reference: [88] <author> Rajeev Ranjan, Jagesh Sanghavi, Robert Brayton, and Alberto Sangiovanni-Vincentelli. </author> <title> Binary Decision Diagrams on Network of Workstations. </title> <booktitle> In The Proceedings International Conference on Computer Design, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: A network of workstations provides a collection of main memories and disks, which can be used effectively to create and manipulate very large BDDs <ref> [88] </ref>. The design of a BDD algorithm on a NOW should recognize that time to access datum from a remote memory by performing a network transaction is 10,000 to 50,000 times more expensive than time to access data from the local main memory.
Reference: [89] <author> S. Reddy, W. Kunz, and D. Pradhan. </author> <title> Novel Verification Framework Combining Structural and OBDD Methods in a Synthesis Environment. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 414-419, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The heuristics based on exploiting the nature of the specific formal verification task can be further classified as 1. combinational verification related and 2. property verification related. Combination verification related heuristics make use recursive learning by combining structural and functional information to limit the BDD size <ref> [89, 59] </ref>.
Reference: [90] <author> R. Rudell. </author> <title> Dynamic Variable Ordering for Binary Decision Diagrams. </title> <booktitle> In The Proceedings International Conference on Computer-Aided Design, </booktitle> <pages> pages 42-47, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The size of a BDD depends on the ordering of logic function variables; therefore, several static and dynamic variable ordering have been proposed to reduce the BDD size <ref> [72, 90] </ref>. Several variations of BDD data structure that relax the ordering constraint while retaining the canonicity property have been proposed [10, 46, 35] to reduce the BDD size. <p> Further, the best order may change during different stages of execution of the application. Ordering variables dynamically as a means to trade-off computation to reclaim memory is considered as an important feature in the state-of-the-art BDD package <ref> [90] </ref>. A variable is identified uniquely with its id. The position of a variable in the ordering relation determines its index. <p> Demonstrating performance improvement due to pipelining. 4. Performance comparison for various BDD operations: We compare the performance of various BDD operations in our package with those in Long's package. We show that even for small and medium sized examples, our algorithms have competitive performance. 5. Performance of sift algorithm <ref> [90] </ref> for dynamic variable ordering We integrated our package with the synthesis tool SIS [93].
Reference: [91] <author> S. Selberherr. </author> <title> Analysis and Simulation of Semiconductor Devices. </title> <publisher> Springer-Verlag, Wien, </publisher> <address> Austria, </address> <year> 1984. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 21 1.4.3 Performance Demands Let us take a closer look at how miniaturization of semiconductor devices impact some of most computationally expensive verification tasks that are addressed in this thesis. The device design requires extensive modeling and simulation of a semiconductor device to predict its behavior <ref> [91, 49, 23] </ref>. A semiconductor device is modeled mathematically by a set of coupled partial differential equations. <p> The new methods significantly faster in a loosely coupled message passing environment, hence they are ideal candidates for exploiting a network of workstations. 4.3 Problem Definition and Solution Approach The time-dependent drift-diffusion model of semiconductor devices, based on the Poisson equation and the continuity equations for electrons and holes <ref> [91] </ref>, is used in this work: r: (* s r ) = q (p n + N + a ) @t CHAPTER 4.
Reference: [92] <author> Jagesh Sanghavi, Eric Tomacruz, and Alberto Sangiovanni-Vincentelli. </author> <title> Massively Parallel Device Simulation using Irregular Grids. </title> <booktitle> In NUPAD V, </booktitle> <pages> pages 141-144, </pages> <year> 1994. </year> <note> BIBLIOGRAPHY 151 </note>
Reference-contexts: The new contributions are as follows: 1) methodology, algorithms, and implementation of the linear solver on a scalable parallel computer <ref> [92, 98] </ref>. and 2) general paradigm to optimize the memory performance of a sequence of linear algebra operations with specific application to improving the CHAPTER 4. SEMICONDUCTOR DEVICE SIMULATION 97 performance of CGS loop.
Reference: [93] <author> E. M. Sentovich, K. J. Singh, L. Lavagno, C. Moon, R. Murgai, A. Saldanha, H. Savoj, P. R. Stephan, R. K. Brayton, and A. L. Sangiovanni-Vincentelli. </author> <title> SIS: A System for Sequential Circuit Synthesis. </title> <type> Technical Report UCB/ERL M92/41, </type> <institution> Electronics Research Lab, Univ. of California, Berkeley, </institution> <address> CA 94720, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: We show that even for small and medium sized examples, our algorithms have competitive performance. 5. Performance of sift algorithm [90] for dynamic variable ordering We integrated our package with the synthesis tool SIS <ref> [93] </ref>. In addition to using standard ISCAS and MCNC benchmark examples for the set of experiments, we use a circuit generator to create a series of sub-networks in order to systematically analyze the performance of our algorithms as BDD size increases.
Reference: [94] <author> T. R. Shiple, R. Hojati, A. L. Sangiovanni-Vincentelli, and R. K. Brayton. </author> <title> Heuristic Minimization of BDDs Using Don't Cares. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: Combination verification related heuristics make use recursive learning by combining structural and functional information to limit the BDD size [89, 59]. Property verification related heuristics are perhaps the broadest class of heuristics that make use of attributes of underlying mathematical model <ref> [29, 100, 18, 94] </ref> to reduce the BDD size. 2.1.2 Limitations of Conventional BDD Manipulation Algorithms In contrast to approaches that reduce the BDD size to make it fit within the main memory, the goal of this work is to build and manipulate very large BDDs that exceed the main memory
Reference: [95] <author> G. Tai, C. Korman, and I. Mayergoyz. </author> <title> A parallel-in-time method for the transient simulation of SOI devices with drain current overshoots. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 13 </volume> <pages> 1035-1044, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Brown et al. [15] report parallel solution of device equations using topologically rectangular finite element grid. Aluru [4] present stabilized finite element method for hydrodynamic transport model for semiconductor devices. The algorithm is parallelized on message passing multiprocessors such as iPSC/860, Touchstone Delta, and IBM SP-1. Tai et al. <ref> [95] </ref> present parallel in time algorithm for transient simulation of Semiconductor-On-Insulator (SOI) devices. This approach to partition across time is an interesting contrast to the approach presented in this chapter which partitions the space.
Reference: [96] <author> Thorsten Helmut von Eicken. </author> <title> Active messages: an efficient communication architecture for multiprocessors. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, </institution> <year> 1993. </year>
Reference-contexts: All the comparisons are with with the fastest breadth-first code running on the MIPS DEC 5000 workstations. The NRAM uses 4 workstations; the client main memory is 30Mbytes and 3 servers have main memory of 40Mbytes each. The remote memory pager for NRAM uses active-messages <ref> [96] </ref> as the basic communication primitive. For C6288 subcircuits with less than 3 million nodes, the speedup is due to faster pro CHAPTER 2.
Reference: [97] <author> E. Tomacruz, J. Sanghavi, and A. Sangiovanni-Vincentelli. </author> <title> Algorithms for Drift-Diffusion Device Simulation Using Massively Parallel Processors. </title> <journal> IEICE Transactions on Electronics, </journal> <volume> E77-C:248-254, </volume> <month> February </month> <year> 1994. </year>
Reference-contexts: SEMICONDUCTOR DEVICE SIMULATION 97 performance of CGS loop. The development of the linear solver for irregular grids on a scalable parallel computer draws on our previous work on use of regular grids on CM-2 [107] and CM-5 <ref> [97] </ref>. The chapter is organized as follows. In Section 4.1, we present an introduction to the semiconductor device simulation and outline some of the challenges. In Section 4.2, we present the previous work on 3-D device simulation. In Section 4.3, we define the problem and present the overall solution approach. <p> Exploiting the memory hierarchy on each compute node of the parallel processor is another avenue to boost the overall performance. The rectangular spatial discretization grids have been natural choice for simulating 3-D devices on a parallel computer <ref> [107, 97, 108, 86] </ref>. The most important reason is the ease of parallel implementation afforded by the regularity of the grid structure: it is easy to balance the computational load among the processors, and it is easy to schedule the interprocessor communication due to regularity of communication patterns. <p> The regularity of grid results in the ease of implementation. The earlier work on three dimensional device simulation presented by tomacruz et al. <ref> [97] </ref> on CM-5 parallel processors is limited to the use of rectangular grids. It is easy to partition the rectangular grids into domains with roughly equal size. <p> The STRIDE code is another example of a tensor product grid device simulator that has been parallelized on a message passing multiprocessors. The algorithms used in STRIDE [108] are similar to those presented in <ref> [97] </ref>. The linear solution algorithm is based on conjugate gradient like method with preconditioning. The authors report that as the size of the problem increases CHAPTER 4. SEMICONDUCTOR DEVICE SIMULATION 100 the computational time grows at 1/3-power of the grid size. <p> The node with the minimum degree is used as the starting node for the reverse Cuthill-Mckee ordering. Both ordering schemes maintain a significant portion of coupling between nodes when fill-ins are allowed. Maintaining the coupling of nodes for rectangular grids has been illustrated by <ref> [97] </ref> to give the best preconditioners. This also appears to be a good criteria for irregular grids. 4.7.4 Scalability number of processors in the machine. The figure shows the increase in efficiency as the problem size becomes larger.
Reference: [98] <author> Eric Tomacruz, Jagesh Sanghavi, and Alberto Sangiovanni-Vincentelli. </author> <title> A Parallel Iterative Linear Solver for Solving Irregular Grid Semiconductor Device Matrices. </title> <booktitle> In The Proceedings of Supercomputing, </booktitle> <pages> pages 24-33, </pages> <year> 1994. </year>
Reference-contexts: The new contributions are as follows: 1) methodology, algorithms, and implementation of the linear solver on a scalable parallel computer <ref> [92, 98] </ref>. and 2) general paradigm to optimize the memory performance of a sequence of linear algebra operations with specific application to improving the CHAPTER 4. SEMICONDUCTOR DEVICE SIMULATION 97 performance of CGS loop.
Reference: [99] <author> Tony Stornetta and Forrest Brewer. </author> <title> Implementation of an Efficient Parallel BDD Package. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: The algorithm proposed by Kimura and Clark [61] uses a shared memory multiprocessor that allow uniform access time to the main memory. The algorithm proposed by Parsuram [81] uses shared address space abstraction for a distributed memory multiprocessor. The parallel BDD algorithm proposed by Stornetta and Brewer <ref> [99] </ref> executes multiple threads on a distributed memory parallel machine. All of these algorithms use a dedicated parallel processor to speedup the BDD computation. The random access pattern of depth-first algorithm translates to remote memory accesses for distributed memory machine.
Reference: [100] <author> H. Touati, H. Savoj, B. Lin, R. K. Brayton, and A. L. Sangiovanni-Vincentelli. </author> <title> Implicit State Enumeration of Finite State Machines using BDD's. </title> <booktitle> In The Proceedings International Conference on Computer-Aided Design, </booktitle> <pages> pages 130-133, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Combination verification related heuristics make use recursive learning by combining structural and functional information to limit the BDD size [89, 59]. Property verification related heuristics are perhaps the broadest class of heuristics that make use of attributes of underlying mathematical model <ref> [29, 100, 18, 94] </ref> to reduce the BDD size. 2.1.2 Limitations of Conventional BDD Manipulation Algorithms In contrast to approaches that reduce the BDD size to make it fit within the main memory, the goal of this work is to build and manipulate very large BDDs that exceed the main memory
Reference: [101] <author> T. Toyabe, H. Masuda, Y. Aoki, J. Shukuri, and T. Hagiwara. </author> <title> Three dimensional device simulator CADDETH with highly convergent matrix solution algorithms. </title> <journal> IEEE Transactions on Electronic Devices, </journal> <volume> ED-32:2038-2044, </volume> <year> 1985. </year>
Reference-contexts: Further, new algorithms are presented to achieve the robust solution without compromising the potential gains due to parallelism. 4.2 Previous Work The 3-D rectangular (finite difference) grids, which is a tensor product of three 1-D grids, are used in several device simulators such as CADDETH <ref> [101] </ref>, MINIMOS [71], SITAR [103], STRIDE [108]. The regularity of grid results in the ease of implementation. The earlier work on three dimensional device simulation presented by tomacruz et al. [97] on CM-5 parallel processors is limited to the use of rectangular grids. <p> Unfortunately, the direct method for solving linear system is unsuitable for three-dimensional simulation. Further, the direct method are very difficult to parallelize. Therefore, it is difficult to achieve very good performance improvement on a large scale parallel computer. Toyabe et al. <ref> [101] </ref> from Hitachi were first to report CG-based methods for solving the non-symmetric linear systems. Since then, several new CG-based iterative methods have evolved. The Preconditioned Conjugate Gradient Squared (CGS) has found the most widespread use for the solution of linear system encountered in three dimensional device simulation.
Reference: [102] <author> R. Varga. </author> <title> Matrix Iterative Analysis. </title> <publisher> Prentice-Hall, </publisher> <year> 1962. </year> <note> BIBLIOGRAPHY 152 </note>
Reference-contexts: The Scharfetter-Gummel method [34] along with the box method <ref> [102] </ref> is then used to obtain the discrete equations. These nonlinear equations are solved using either a fully-coupled or a decoupled Newton method. Trapezoidal/backward difference formula is used for time integration. The asymmetric linear system of equations is solved using an iterative linear system solver with preconditioning.
Reference: [103] <author> W. Bergner and R. Kircher. </author> <title> SITAR An efficient 3D-simulator for optimization of nonplanar trench structures. </title> <booktitle> In Proceedings of SISDEP 3, </booktitle> <pages> pages 165-174, </pages> <year> 1988. </year>
Reference-contexts: Further, new algorithms are presented to achieve the robust solution without compromising the potential gains due to parallelism. 4.2 Previous Work The 3-D rectangular (finite difference) grids, which is a tensor product of three 1-D grids, are used in several device simulators such as CADDETH [101], MINIMOS [71], SITAR <ref> [103] </ref>, STRIDE [108]. The regularity of grid results in the ease of implementation. The earlier work on three dimensional device simulation presented by tomacruz et al. [97] on CM-5 parallel processors is limited to the use of rectangular grids.
Reference: [104] <author> W. Daniel Hillis. </author> <title> The Connection Machine. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: At one extreme, we have several tens of thousands of processing elements, each of which is very simple. Since each processor requires a small silicon real estate, tens of them can be integrated on a single chip. For example, Connection Machine 2 (CM-2) <ref> [104] </ref>, a previous generation parallel computer, has up to 65536 processors, 16 of which can fit on a single chip. Each processor is bit serial with clock rates of 7 to 10MHz and a small amount (64Kbit to 1024Kbit) of local memory.
Reference: [105] <author> W. Kernighan and S. Lin. </author> <title> An Efficient Heuristic Procedure for Partitioning Graphs. </title> <journal> Bell System Technical Journal, </journal> <pages> pages 291-307, </pages> <month> February </month> <year> 1970. </year>
Reference-contexts: The Geometrical partition is simple and efficient. It can be adapted to meet a set of partitioning objectives. Topographical Partitioner The Fiduccia-Mattheyses algorithm [21], which is an improvement of a local search algorithm first presented by <ref> [105] </ref>, is used to implement a topographical partitioner [62]. The basic algorithm is an iterative heuristic that reduces the number of edges cut in each pass while maintaining the difference between number of nodes in each partition within a specified tolerance.
Reference: [106] <author> W.A. Wulf and S. A. McKee. </author> <title> Hitting the memory wall: implications are obvious. </title> <journal> Computer Architecture News, </journal> <volume> 23(1) </volume> <pages> 20-24, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: The actual chasm in memory and processor performance is much wider as memory performance has increased at less than 10% per year whereas processor performance has increased at about 50% per year since 1986. Several researchers predict memory bandwidth to limit the performance of the future microprocessors <ref> [106, 19] </ref>. The disparity between DRAM and processor performance is also evidenced by extensive use of caches. In 1980, most of microprocessor designs did not have caches. In 1996, most of microprocessor designs have two levels of caches.
Reference: [107] <author> D. Webber, E. Tomacruz, R. Guerrieri, T. Toyabe, and A. Sangiovanni-Vincentelli. </author> <title> A Massively Parallel Algorithm for Three-Dimensional Device Simulation. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 10 </volume> <pages> 1201-1209, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: SEMICONDUCTOR DEVICE SIMULATION 97 performance of CGS loop. The development of the linear solver for irregular grids on a scalable parallel computer draws on our previous work on use of regular grids on CM-2 <ref> [107] </ref> and CM-5 [97]. The chapter is organized as follows. In Section 4.1, we present an introduction to the semiconductor device simulation and outline some of the challenges. In Section 4.2, we present the previous work on 3-D device simulation. <p> Exploiting the memory hierarchy on each compute node of the parallel processor is another avenue to boost the overall performance. The rectangular spatial discretization grids have been natural choice for simulating 3-D devices on a parallel computer <ref> [107, 97, 108, 86] </ref>. The most important reason is the ease of parallel implementation afforded by the regularity of the grid structure: it is easy to balance the computational load among the processors, and it is easy to schedule the interprocessor communication due to regularity of communication patterns.
Reference: [108] <author> K. Wu, G. Chin, and R. Dutton. </author> <title> A STRIDE Towards Practical 3-D Device Simulation - Numerical and Visualization Considerations. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 10 </volume> <pages> 1132-1140, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Exploiting the memory hierarchy on each compute node of the parallel processor is another avenue to boost the overall performance. The rectangular spatial discretization grids have been natural choice for simulating 3-D devices on a parallel computer <ref> [107, 97, 108, 86] </ref>. The most important reason is the ease of parallel implementation afforded by the regularity of the grid structure: it is easy to balance the computational load among the processors, and it is easy to schedule the interprocessor communication due to regularity of communication patterns. <p> new algorithms are presented to achieve the robust solution without compromising the potential gains due to parallelism. 4.2 Previous Work The 3-D rectangular (finite difference) grids, which is a tensor product of three 1-D grids, are used in several device simulators such as CADDETH [101], MINIMOS [71], SITAR [103], STRIDE <ref> [108] </ref>. The regularity of grid results in the ease of implementation. The earlier work on three dimensional device simulation presented by tomacruz et al. [97] on CM-5 parallel processors is limited to the use of rectangular grids. <p> The STRIDE code is another example of a tensor product grid device simulator that has been parallelized on a message passing multiprocessors. The algorithms used in STRIDE <ref> [108] </ref> are similar to those presented in [97]. The linear solution algorithm is based on conjugate gradient like method with preconditioning. The authors report that as the size of the problem increases CHAPTER 4. SEMICONDUCTOR DEVICE SIMULATION 100 the computational time grows at 1/3-power of the grid size.
References-found: 108

