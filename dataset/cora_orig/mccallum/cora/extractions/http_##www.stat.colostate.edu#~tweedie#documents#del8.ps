URL: http://www.stat.colostate.edu/~tweedie/documents/del8.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Perfect Sampling of Harris Recurrent Markov Chains  
Author: J.N. Corcoran and R. L. Tweedie 
Note: An application of the simpler algorithm to storage models is given.  
Date: January 15, 1998  
Affiliation: Colorado State University  
Abstract: We develop an algorithm for simulating "perfect" random samples from the invariant measure of a Harris recurrent Markov chain. The method uses backward coupling of embedded regeneration times, and works most effectively for finite chains and for stochastically monotone chains even on continuous spaces, where paths may be sandwiched below "upper" and "lower" processes. Examples show that more naive approaches to constructing such bounding processes may be considerably biased, but that the algorithm can be simplified in certain cases to make it easier to run. We give explicit analytic bounds on the backward coupling times in the stochastically monotone case. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Asmussen. </author> <title> Applied Probability and Queues. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: The SRS approach is based on the fact that one can construct a probability space (; F ; P), an independent and identically distributed sequence f~ n g 1 n=1 of Uniform <ref> [0; 1] </ref> random variables, and a measurable function f : X fi [0; 1] ! X such that X satisfies the recursion X 0 = x 0 ; X n+1 = f (X n ; ~ n ); n 0; (2) and has transition probabilities P (x; ). <p> The SRS approach is based on the fact that one can construct a probability space (; F ; P), an independent and identically distributed sequence f~ n g 1 n=1 of Uniform <ref> [0; 1] </ref> random variables, and a measurable function f : X fi [0; 1] ! X such that X satisfies the recursion X 0 = x 0 ; X n+1 = f (X n ; ~ n ); n 0; (2) and has transition probabilities P (x; ). <p> Hence U n is indeed an upper process. We can now define the algorithm for generating a perfect sample from . Monotone Coupling Algorithm: 4 The stochastically monotone algorithm 9 1. For each n = 1; 2; : : :, generate independent Uniform <ref> [0; 1] </ref> variables ~ n ; " n ; 2. For each n = 1; 2; : : :, choose n U 0 = K and simulate the upper process f n U k g n 3. <p> If m l 62 fm 1 ; m 2 ; : : : ; m l1 g draw " m l ~ Uniform <ref> [0; 1] </ref>: note that we do not need to draw the " n until we are in C. 3. <p> Excessive input is considered overflow and cannot be saved for future use. Between arrivals, content is released deterministically at rate r (u). The Markov chain embedded just prior to arrival times satisfies the well known PASTA property <ref> [1] </ref> which ensures that its stationary distribution is identical to the stationary distribution of the continuous time chain. We shall consider specifically the case r (u) = u. With this release rule, it is easy to see that (f0g) = 0, so that normal regeneration at zero does not apply. <p> The mean value of T obtained from 10,000 independent backward couplings is 9.2 embedded time steps. In other words, on average, the upper process started from K = 10 has reached the small set C = <ref> [0; 1] </ref> and the "-coin has turned up a head after approximately nine steps. FIGURE 5 NEAR HERE To get an analytic bound on the order of convergence of our algorithm, we begin by noting that if we are outside [0; 1], the storage model reaches [0; 1] more quickly than <p> K = 10 has reached the small set C = <ref> [0; 1] </ref> and the "-coin has turned up a head after approximately nine steps. FIGURE 5 NEAR HERE To get an analytic bound on the order of convergence of our algorithm, we begin by noting that if we are outside [0; 1], the storage model reaches [0; 1] more quickly than the model with constant unit release rate (r (x) = 1), by stochastic comparison. Thus it suffices to analyze this simpler model to get bounds. <p> small set C = <ref> [0; 1] </ref> and the "-coin has turned up a head after approximately nine steps. FIGURE 5 NEAR HERE To get an analytic bound on the order of convergence of our algorithm, we begin by noting that if we are outside [0; 1], the storage model reaches [0; 1] more quickly than the model with constant unit release rate (r (x) = 1), by stochastic comparison. Thus it suffices to analyze this simpler model to get bounds. <p> To bound the regeneration times using Theorem 5.1 we need to find a Foster- Lyapunov function V : X ! [1; 1) satisfying P fl V C V + b1l C ; (29) 6 A Finite Storage Model 16 where C = <ref> [0; 1] </ref>, b &lt; 1, and C &lt; 1; and where P fl is the law of the embedded chain of the infinite K, unit release model. We assume, without loss of generality, that V (x) 1 on C. <p> We assume, without loss of generality, that V (x) 1 on C. In this case we have that P fl (x; dy) = P fl (x; 0) = where d = max (0; x y). If we let V (x) = fl x for x 62 C = <ref> [0; 1] </ref>, then for 1 &lt; fl &lt; e , we have that P fl V (x) = log fl+ + 1 i + log fl+fl log fl+ + 1 + log fl+fl fl V (x) When = 1 and = 2, we have that C (1; 2; fl) achieves a <p> After similar computations for x 2 C = <ref> [0; 1] </ref>, we get that b 2:4.
Reference: [2] <author> A.A. Borovkov. </author> <title> Asymptotic Methods in Queueing Theory. </title> <publisher> John Wiley and Sons, </publisher> <address> Chich-ester New York Toronto, </address> <year> 1984. </year>
Reference-contexts: In order to do this we first briefly describe the "stochastic recursive sequence" (SRS) coupling construction framework which forms the basis of the Propp-Wilson algorithm in [17]. 2 Stochastic Recursive Sequences and Backward Coupling 2 This was developed in the form below by Borovkov and Foss <ref> [2, 7, 4] </ref>. The SRS construction enables us to use deterministic sample path arguments which are particularly suited to a simulation environment, and more details are in [8].
Reference: [3] <author> A.A. Borovkov and S.G. Foss. </author> <title> Stochastically recursive sequences and their generalizations. </title> <journal> Siberian Adv. Math., </journal> <volume> 2 </volume> <pages> 16-81, </pages> <year> 1992. </year>
Reference-contexts: we implement the method in practice for a storage system with no minimal element. 2 Stochastic Recursive Sequences and Backward Coupling We consider a Markov chain on a state space X, which we assume is a separable metric space (although this restriction could be relaxed as noted on p.18 of <ref> [3] </ref>). Since we are concerned with sample path behaviour, we write X = fX n g 1 n=0 for the version of the chain starting at x 0 (which may be fixed or random); versions starting with other initial values will be distinguished by other notation when they occur.
Reference: [4] <author> A.A. Borovkov and S.G. Foss. </author> <title> Two ergodicity criteria for stochastically recursive sequences. </title> <journal> Acta Applic. Math, </journal> <volume> 34 </volume> <pages> 125-134, </pages> <year> 1994. </year>
Reference-contexts: In order to do this we first briefly describe the "stochastic recursive sequence" (SRS) coupling construction framework which forms the basis of the Propp-Wilson algorithm in [17]. 2 Stochastic Recursive Sequences and Backward Coupling 2 This was developed in the form below by Borovkov and Foss <ref> [2, 7, 4] </ref>. The SRS construction enables us to use deterministic sample path arguments which are particularly suited to a simulation environment, and more details are in [8].
Reference: [5] <author> J.A. Fill. </author> <title> An interruptible algorithm for perfect sampling via Markov chains. </title> <journal> Ann. Appl. Probab., </journal> <volume> 7, </volume> <year> 1997. </year> <note> (Accepted for publication). </note>
Reference-contexts: These were sparked by the seminal paper of Propp and Wilson [17], and several variations and extensions of this idea have appeared since <ref> [5, 8, 9, 11, 10, 12, 15, 16] </ref>. These ideas have proven effective in areas such as statistical physics, spatial point processes and operations research, where they provide simple and powerful alternatives to methods based on iterating P n , for example.
Reference: [6] <author> J.A. Fill and M. Machida. </author> <title> "stochastic monotonicity and realizable monotonicity. </title> <note> In preparation. </note>
Reference-contexts: By monotonicity of R, in general f R (x; ) is also monotone in x and we will assume this. Rather surprisingly, it has recently been noted that if the space is only partially ordered this may not be the case in some pathological circumstances <ref> [6] </ref>; hence this is not a trivial assumption.
Reference: [7] <author> S.G. Foss. </author> <title> On ergodicity conditions in multi-server queues. </title> <journal> Siberian Math. J., </journal> <volume> 24 </volume> <pages> 168-175, </pages> <year> 1983. </year>
Reference-contexts: In order to do this we first briefly describe the "stochastic recursive sequence" (SRS) coupling construction framework which forms the basis of the Propp-Wilson algorithm in [17]. 2 Stochastic Recursive Sequences and Backward Coupling 2 This was developed in the form below by Borovkov and Foss <ref> [2, 7, 4] </ref>. The SRS construction enables us to use deterministic sample path arguments which are particularly suited to a simulation environment, and more details are in [8].
Reference: [8] <author> S.G. Foss and R.L. Tweedie. </author> <title> Perfect simulation and backward coupling. Stochastic Models. </title> <note> To appear (Preprint at http://www.stats.bris.ac.uk/MCMC/). </note>
Reference-contexts: These were sparked by the seminal paper of Propp and Wilson [17], and several variations and extensions of this idea have appeared since <ref> [5, 8, 9, 11, 10, 12, 15, 16] </ref>. These ideas have proven effective in areas such as statistical physics, spatial point processes and operations research, where they provide simple and powerful alternatives to methods based on iterating P n , for example. <p> The SRS construction enables us to use deterministic sample path arguments which are particularly suited to a simulation environment, and more details are in <ref> [8] </ref>. <p> Using shift operators we define as in <ref> [8] </ref> the minimal backward coupling time -(X) by -(X) = minfm 0 : n 1 X n 1 = n 2 X n 2 8n 1 ; n 2 mg 1: (3) Any integer-valued random variable - 1 is a backward coupling time for X if f- mg ) f n <p> If one has a successful backward coupling time, then one can give a constructive approach showing that there exists a stationary version of the chain X. We have from Theorem 3.1 of <ref> [8] </ref> the following: 3 Algorithms for Harris chains 3 Theorem 2.1 Let be a successful backward coupling time. Put e X 0 = - X and define e X n = n e X 0 for n 2 ZZ. <p> (x) starting, not at time zero, but at time T , have the same value at time zero, then as is shown in Theorem 1 of Propp and Wilson [17], this common value is a perfect draw from : and such a T (called a "vertical" backward coupling time in <ref> [8] </ref>) is indeed a backward coupling time as described above. Intuitively, it is clear why this result holds with such a random time T . For consider a chain starting at 1 with the stationary distribution . At every iteration it maintains the distribution . <p> Since this couples chains from all starting points, it is a vertical coupling time. Conversely, in <ref> [8] </ref> we show that when any backward coupling occurs using a vertical backward coupling time, the chain must in fact be uniformly ergodic, with (5) holding for some " X ; ' and k. Thus in some ways this coupler is the canonical coupler for such a "vertical" situation. <p> However, if we take C to be some proper subset, it still follows that the algorithm as described above using the family X (x) will lead to a "vertical" backward coupling time, and thus from Theorem 4.2 of <ref> [8] </ref> the chain must in fact be uniformly ergodic (although with the construction of upper and lower processes this may be avoidable, as noted in the next section). Even for uniformly ergodic chains, however, we may gain in two ways by introducing the Harris coupling algorithm. <p> Correct 0.6045 0.0387 0.3568 Correct 0.6072 0.0366 0.3562 Correct 0.5963 0.0358 0.3679 Incorrect simplified 0.5639 0.0358 0.4003 Incorrect simplified 0.5708 0.0309 0.3983 Incorrect simplified 0.5501 0.0352 0.4147 Incorrect simplified 0.5595 0.0361 0.4044 Incorrect simplified 0.5713 0.0339 0.3948 True values 0.6000 0.0364 0.3636 5.3 Analytic bounds on rates of convergence In <ref> [8] </ref> the rates of convergence of successful backward coupling times are related to those of forward coupling times. <p> Theorem 5.1 Let A; B be such that E [e A e T ] B (23) where e T is the first regeneration in C for the chain X n . Then when x 0 = 0, E [e AT fl Proof From Theorems 6.1 and 6.3 of <ref> [8] </ref> we have that (24) holds for any A; B such that E [e Aet ] B (25) 6 A Finite Storage Model 14 where e t is the forward coupling time of W and a stationary chain f W, given by (22).
Reference: [9] <author> S.G. Foss, R.L. Tweedie, and J. Corcoran. </author> <title> Simulating the invariant measures of Markov chains using horizontal backward coupling at regeneration times. Prob.Eng.Inf.Sci. (accepted subject to revision). </title>
Reference-contexts: These were sparked by the seminal paper of Propp and Wilson [17], and several variations and extensions of this idea have appeared since <ref> [5, 8, 9, 11, 10, 12, 15, 16] </ref>. These ideas have proven effective in areas such as statistical physics, spatial point processes and operations research, where they provide simple and powerful alternatives to methods based on iterating P n , for example.
Reference: [10] <author> O. Haggstrom and K. Nelander. </author> <title> Exact sampling from anti-monotone systems. </title> <institution> Chalmers University of Technology Department of Mathematics Research Report 1997-03, </institution> <year> 1997. </year> <note> (Preprint at http://www.stats.bris.ac.uk/MCMC/). </note>
Reference-contexts: These were sparked by the seminal paper of Propp and Wilson [17], and several variations and extensions of this idea have appeared since <ref> [5, 8, 9, 11, 10, 12, 15, 16] </ref>. These ideas have proven effective in areas such as statistical physics, spatial point processes and operations research, where they provide simple and powerful alternatives to methods based on iterating P n , for example.
Reference: [11] <author> O. Haggstrom, M.N.M. van Liesholt, and J. Mtller. </author> <title> Characterisation results and Markov chain Monte Carlo algorithms including exact simulation for some spatial point processes. </title> <institution> Aalborg University Department of Mathematics Research Report R-96-2040, </institution> <year> 1996. </year> <note> (Preprint at http://www.stats.bris.ac.uk/MCMC/). </note>
Reference-contexts: These were sparked by the seminal paper of Propp and Wilson [17], and several variations and extensions of this idea have appeared since <ref> [5, 8, 9, 11, 10, 12, 15, 16] </ref>. These ideas have proven effective in areas such as statistical physics, spatial point processes and operations research, where they provide simple and powerful alternatives to methods based on iterating P n , for example.
Reference: [12] <author> W.S. Kendall. </author> <title> Perfect simulation for the area-interaction point process. In C.C. </title> <editor> Heyde and L. Accardi, editors, </editor> <title> Probability Perspectives, page (to appear). </title> <publisher> World Scientific Press, </publisher> <address> Singapore, </address> <year> 1996. </year>
Reference-contexts: These were sparked by the seminal paper of Propp and Wilson [17], and several variations and extensions of this idea have appeared since <ref> [5, 8, 9, 11, 10, 12, 15, 16] </ref>. These ideas have proven effective in areas such as statistical physics, spatial point processes and operations research, where they provide simple and powerful alternatives to methods based on iterating P n , for example. <p> Subtle constructions of such processes occur in point process models <ref> [12] </ref> and storage models [13], for models demonstrably not uniformly ergodic. 3.2 A general Harris chain algorithm If the chain is not uniformly ergodic, one cannot assume that the minorization (5) holds for all x. <p> When the upper or lower process is not simply the chain itself run from a maximal or minimal point then other processes may be designed, as developed in, for example, Kendall <ref> [12] </ref> and Mtller [15]. In the latter, this is exploited to show that if there is a time in the past from which the upper and lower processes are within * at time 0, then all paths [and hence in particular any stationary-start path] is sandwiched into that *-set.
Reference: [13] <author> R.B. Lund and D.B. Wilson. </author> <title> Perfect simulation of invariant measures in storage and network theory. </title> <note> (in preparation). </note>
Reference-contexts: Subtle constructions of such processes occur in point process models [12] and storage models <ref> [13] </ref>, for models demonstrably not uniformly ergodic. 3.2 A general Harris chain algorithm If the chain is not uniformly ergodic, one cannot assume that the minorization (5) holds for all x. <p> We shall consider specifically the case r (u) = u. With this release rule, it is easy to see that (f0g) = 0, so that normal regeneration at zero does not apply. For x 2 (0; K], it is shown in <ref> [13] </ref> that the density p of the stationary distribution is given by x (fi 1 1) e x 0 x (fi 1 1) e x dx and in general the denominator cannot be integrated. <p> FIGURES 3 AND 4 NEAR HERE Note that the assumption of the finiteness of the dam height may not be critical: it can probably be replaced with the upper process of Lund and Wilson <ref> [13] </ref>, but we do not add this extra order of complication here. 6.2 Bounds On Convergence Rates In this section we assess empirically how long one must run the algorithm for the storage model example in Section 6.1, and we compare this with the analytic bounds of Theorem 5.1. release shown
Reference: [14] <author> S. P. Meyn and R. L. Tweedie. </author> <title> Markov Chains and Stochastic Stability. </title> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: Weaker definitions of Harris recurrence can be used, and simple sufficient conditions for Harris recurrence exist also (see <ref> [14] </ref>), but this definition gives no loss of generality. Our goal then is to draw values from the invariant measure . <p> Suppose the chain satisfies the uniform minorization condition P k (x; ) " X '( ); x 2 X (5) for some probability measure ' and some 0 &lt; " X 1. Such chains are "uniformly ergodic" and have a number of desirable properties <ref> [14, Chapter 16] </ref>; and in particular they are Harris chains with finite invariant measures. <p> is minorized for some 0 &lt; " &lt; 1 and for some density ', but only on C: that is, P k (x; dy) "'(dy); x 2 C: (7) It is known that for aperiodic Harris chains, every set with (A) &gt; 0 contains a small set of positive -measure <ref> [14] </ref>. In what follows we will assume that C is such a set with k = 1: this ensures aperiodicity also, and is sometimes called the strongly aperiodic case. Now consider the Nummelin splitting construction [14], in which we construct sample paths by using the transition law P (x; ) for <p> Harris chains, every set with (A) &gt; 0 contains a small set of positive -measure <ref> [14] </ref>. In what follows we will assume that C is such a set with k = 1: this ensures aperiodicity also, and is sometimes called the strongly aperiodic case. Now consider the Nummelin splitting construction [14], in which we construct sample paths by using the transition law P (x; ) for x 2 C c , but each time x 2 C we draw a sequence " n of i.i.d. uniform random variables, and a sequence V n of i.i.d. variables with law '; if 3 <p> The stochastic recursive sequence formulation of the chain using splitting <ref> [14] </ref> is then given by X n+1 = &lt; f (X n ; ~ n ) X n &gt; c; f ' (~ n ) X n c; H n = 0 We now construct an upper process for the bivariate chain Z n = fX n ; " n g
Reference: [15] <author> Jesper Mtller. </author> <title> Perfect simulation of conditionally specified models. </title> <journal> J. Roy. Statist. Soc. Ser. B, </journal> <note> 1997. (accepted for publication: Preprint at http://www.stats.bris.ac.uk/MCMC/). </note>
Reference-contexts: These were sparked by the seminal paper of Propp and Wilson [17], and several variations and extensions of this idea have appeared since <ref> [5, 8, 9, 11, 10, 12, 15, 16] </ref>. These ideas have proven effective in areas such as statistical physics, spatial point processes and operations research, where they provide simple and powerful alternatives to methods based on iterating P n , for example. <p> When the upper or lower process is not simply the chain itself run from a maximal or minimal point then other processes may be designed, as developed in, for example, Kendall [12] and Mtller <ref> [15] </ref>. In the latter, this is exploited to show that if there is a time in the past from which the upper and lower processes are within * at time 0, then all paths [and hence in particular any stationary-start path] is sandwiched into that *-set.
Reference: [16] <author> D.J. Murdoch and P.J. Green. </author> <title> Exact sampling from a continuous state space. </title> <journal> Scand. J. Statist. </journal> <note> to appear (Preprint at http://www.stats.bris.ac.uk/MCMC/). </note>
Reference-contexts: These were sparked by the seminal paper of Propp and Wilson [17], and several variations and extensions of this idea have appeared since <ref> [5, 8, 9, 11, 10, 12, 15, 16] </ref>. These ideas have proven effective in areas such as statistical physics, spatial point processes and operations research, where they provide simple and powerful alternatives to methods based on iterating P n , for example. <p> This idea has been used by Murdoch and Green <ref> [16] </ref> when the whole space is small (so that the chain is uniformly ergodic), and their result can be seen as a special case of our method. <p> In what follows, we will use minorization methods to develop a version of the algorithm that can be applied to more general Harris chains. 3 Algorithms for Harris chains 3.1 Uniformly minorized chains We first describe a construction described in Murdoch and Green <ref> [16] </ref>, who call this the "multigamma" coupler. Suppose the chain satisfies the uniform minorization condition P k (x; ) " X '( ); x 2 X (5) for some probability measure ' and some 0 &lt; " X 1. <p> Clearly one can construct an SRS representation for this chain, as given in <ref> [16] </ref>, and although this is more complicated, it is clear how the joint distributions will interact: in particular, if " n+1 " X it follows that the value of X n+1 is V n+1 independent of X n .
Reference: [17] <author> J.G. Propp and D.B. Wilson. </author> <title> Exact sampling with coupled Markov chains and applications to statistical mechanics. Random Structures and Algorithms, </title> <booktitle> 9 </booktitle> <pages> 223-252, </pages> <year> 1996. </year> <note> References 19 </note>
Reference-contexts: These were sparked by the seminal paper of Propp and Wilson <ref> [17] </ref>, and several variations and extensions of this idea have appeared since [5, 8, 9, 11, 10, 12, 15, 16]. <p> Our goal then is to draw values from the invariant measure . In order to do this we first briefly describe the "stochastic recursive sequence" (SRS) coupling construction framework which forms the basis of the Propp-Wilson algorithm in <ref> [17] </ref>. 2 Stochastic Recursive Sequences and Backward Coupling 2 This was developed in the form below by Borovkov and Foss [2, 7, 4]. The SRS construction enables us to use deterministic sample path arguments which are particularly suited to a simulation environment, and more details are in [8]. <p> If we can find a time T such that all of the chains X (x) starting, not at time zero, but at time T , have the same value at time zero, then as is shown in Theorem 1 of Propp and Wilson <ref> [17] </ref>, this common value is a perfect draw from : and such a T (called a "vertical" backward coupling time in [8]) is indeed a backward coupling time as described above. Intuitively, it is clear why this result holds with such a random time T . <p> For this to be practicable we need to ensure that T is indeed finite. Propp and Wilson <ref> [17] </ref> show that this occurs for irreducible aperiodic finite space chains, and for a number of stochastically monotone chains possessing maximal and minimal elements.
Reference: [18] <author> G.O. Roberts and R.L. Tweedie. </author> <title> Bounds on regeneration times and convergence rates of markov chains. </title> <note> (submitted for publication). References 20 References 21 References 22 fl fi </note>
Reference-contexts: But if we take x 0 = 0, then X is always below e X. It follows that when C = [0; c] this coupling time is just the first regeneration time starting from , as stated. ut Expressions for A; B in (23) are found explicitly in <ref> [18] </ref>, and bounds in terms of drift functions are given there also. <p> Define e T as the time of the first regeneration according to the distribution ' in the forward setting, e T = minfn 1 : X n 2 C and X n+1 ~ 'g: By Theorems 2.1 and 2.2 of Roberts and Tweedie <ref> [18] </ref>, we have an upper bound on the generating function of e T given by E [fi C (1") ) (fi) for 1 fi e fi fl where V := E [V ] + (C)b= C , (fi) = log fi= log (1= C ), " is from the minorization condi <p> Finally we note that using Theorem 4.1 of <ref> [18] </ref>, we have E [T fl ] [" 1 log ((1 ") 1 J) + log V ]= log 1 = 73:2 which can be compared with the computed means of around 9 for these parameters.
References-found: 18

