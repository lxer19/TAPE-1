URL: ftp://ftp.cs.washington.edu/tr/1994/10/UW-CSE-94-10-03.PS.Z
Refering-URL: http://www.cs.washington.edu/research/arch/sim-opt.html
Root-URL: 
Title: Optimistic Trace-driven Simulation  
Author: Xiaohan Qin and Jean-Loup Baer 
Note: This work was supported by the National Science Foundation under Grants CCR-91-23308 and CCR 94-01689  
Date: October 14, 1994  
Address: Seattle, Wa, 98195  
Affiliation: Department of Computer Science and Engineering, FR-35 University of Washington  
Abstract: Parallel simulation of multiprocessor architectures is a promising direction because a parallel system provides the high computation and storage capabilities that are required by detailed architectural simulation. Additionally, the behavior of the target system exhibits natural parallelism. In this paper, we consider the evaluation of the memory hierarchy of multiprocessor systems via parallel trace-driven simulation. We present a Time Warp-like parallel trace-driven simulation algorithm and data structures. The overhead components of the optimistic algorithm as well as a number of optimization strategies are discussed. The performance of the optimistic parallel simulator as implemented on a KSR-2 is reported. Our results show that significant speedup can be achieved for applications which have good data locality. As the amount of shared references misses increases, the frequent communication and synchronization overhead inherent in the applications limits also the speedup of the parallel trace-driven simula tion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anonymous. </author> <title> A Parallel Trace-driven Simulator: Implementation and Performance. </title> <booktitle> Proceedings of International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1994, </year> <pages> 314-318. </pages>
Reference-contexts: Processes communicate through timestamped messages. When a process receives a message anterior to its own (virtual) time that would have affected its state, it rolls back to the time of the message and reexecutes its simulation from thereon. In <ref> [1] </ref>, we have experimentally studied a conservative parallel trace-driven simulation algorithm proposed by Lin et al [12]. Each simulation process (processor and cache simu lator) receives as input a trace consisting of the private and shared references of a physical process. <p> We focus our attention on snoopy shared-bus systems although the simulation techniques described in this paper can be easily adapted to systems that are directory-based and use other types of interconnection network. The input to the simulation, as in <ref> [1] </ref>, is multiprocessor traces a set of memory address trace files. In the multiprocessor traces, memory references can be divided into two types: private references and shared references with only the shared references having potential effects on the status of other processors' caches. <p> The second observation is that in three cases out of four, the exception being Water, the speedups decrease with the communication requirements of the protocol (look at Table 4 in a row-wise fashion). While in the conservative approach <ref> [1] </ref> the speedups always show a monotonic decrease from the protocol with the least communication (Berkeley) to the one with the most (Firefly), this is no longer the case in the optimistic simulation.
Reference: [2] <author> Anonymous. </author> <title> A Comparative Study of Conservative and Optimistic Trace-driven Simulation. </title> <note> Submitted for publication. </note>
Reference-contexts: The optimistic simulation paradigm can take advantage of this weak ordering constraint. On the other hand, the conservative simulation does not carry the overheads of state saving and rollback. A qualitative and quantitative comparison of the two approaches can be found in a companion paper <ref> [2] </ref>. 5 STATE ENVIRONMENT EVENTS Cache State Accounting Data OMQTBIMQNMQ LS NextInMsg NextRef Top NextOutMsg NMQ: New Message Queue IMQ: Incoming Message Queue OMQ: Outgoing Message Queue TB: Trace Buffer LS: Log Stack NextInMsg: the Next Incoming Message NextOutMsg: the Next Outgoing Message NextRef: the Next Memory Reference 3 Data Structures
Reference: [3] <author> J. Archibald and J.-L. Baer. </author> <title> Cache Coherence Protocols: Evaluation Using a Multiprocessor Simulation Model. </title> <journal> ACM Transactions on Computer Systems, Vol.4, </journal> <volume> No.4, </volume> <month> November </month> <year> 1986, </year> <pages> 273-298. </pages>
Reference-contexts: These messages simulate the interactions dictated by a given cache coherence protocol. The specific cache coherency protocol governs the types of the messages that are gen erated. For example, consider simulating the Berkeley protocol <ref> [3] </ref>. When a process C i encounters a shared write miss at time t it will generate a message of type Invalidation and timestamp t, and broadcast it to all the other processes so that the latter can take appropriate action. <p> C i can continue its simulation while the message is broadcast. On the other hand, if a receiving process C j was ahead of C i (i.e., C j 's simulation time was larger than t), a rollback might be needed. In the case of the Firefly protocol <ref> [3] </ref>, a message of type Request would be broadcast and C i could not proceed until some (at worst all) other processes respond. <p> In order to test the viability of optimistic parallel trace-driven simulation, we have looked at three cache coherence protocols: Berkeley, Illinois, and Firefly <ref> [3] </ref>.
Reference: [4] <author> R.E. Bryant. </author> <title> Simulation of Packet Communications Architecture Computer Systems. </title> <publisher> MIT-LCS-TR-188, MIT, </publisher> <year> 1977. </year> <month> 18 </month>
Reference-contexts: A fundamental difference between the two approaches is that in a conservative simulation, correct computation is guaranteed at an arbitrary point of the simulation, while in an optimistic simulation speculative errors may occur, but they will be corrected before the simulation completes. Chandy-Misra-Bryant methods <ref> [6, 4] </ref> are the best-known conservative methods. In this mode, a process needs to frequently synchronize and exchange "time" information with other processes in order to decide whether it is safe to execute the next event in its input queue.
Reference: [5] <author> D. Chaiken, C. Fields, K. Kurihara and A. Agarwal. </author> <title> Directory-Based Cache Coherence in Large-Scale Multiprocessors. </title> <booktitle> Computer, </booktitle> <address> Vol.23, No.6, </address> <month> June </month> <year> 1990, </year> <pages> 49-58. </pages>
Reference-contexts: In this paper, we consider the evaluation of the memory hierarchy of multiprocessor systems via parallel trace-driven simulation. Trace-driven simulation is used very often to simulate the effects of various cache coherence protocols, cache configurations and organizations, and can also take into account the network topology and its parameters <ref> [5] </ref>. Parallel simulation methods can be broadly classified into two categories [8]: conservative methods and optimistic methods.
Reference: [6] <author> K.M. Chandy and J. Misra. </author> <title> A Case Study in Design and Verification of Distributed Programs. </title> <journal> IEEE Trans. on Software and Engineering, </journal> <volume> Vol. 5, No.9, </volume> <month> September </month> <year> 1979, </year> <pages> 440-452. </pages>
Reference-contexts: A fundamental difference between the two approaches is that in a conservative simulation, correct computation is guaranteed at an arbitrary point of the simulation, while in an optimistic simulation speculative errors may occur, but they will be corrected before the simulation completes. Chandy-Misra-Bryant methods <ref> [6, 4] </ref> are the best-known conservative methods. In this mode, a process needs to frequently synchronize and exchange "time" information with other processes in order to decide whether it is safe to execute the next event in its input queue.
Reference: [7] <author> S.J. Eggers, D.R. Keppel, E.J. Koldinger and H.M. Levy. </author> <title> Techniques for Efficient Inline Tracing on a Shared-Memory Multiprocessor. </title> <booktitle> 1990 ACM Sigmetrics conference on Measurement and Modeling of Computer Systems, </booktitle> <year> 1990, </year> <pages> 37-47. </pages>
Reference-contexts: selected because they are "real applications", the proportion of shared references misses varies from application to application so that we can examine the performance of optimistic trace-driven simulation as a function of the overhead of communication and synchronization, and the traces were already collected on the Sequent system using MPTrace <ref> [7] </ref>. Table 3 shows the memory access characteristics of the four applications. All of the above applications have 12 input trace files. The data given in Table 3 are average numbers for the multiple trace streams of one application.
Reference: [8] <author> R. Fujimoto. </author> <title> Parallel Discrete Event Simulation. </title> <journal> Communication of the ACM, </journal> <volume> Vol. 33, No. 10, </volume> <month> Oct. </month> <year> 1990, </year> <pages> 30-53. </pages>
Reference-contexts: Trace-driven simulation is used very often to simulate the effects of various cache coherence protocols, cache configurations and organizations, and can also take into account the network topology and its parameters [5]. Parallel simulation methods can be broadly classified into two categories <ref> [8] </ref>: conservative methods and optimistic methods. A fundamental difference between the two approaches is that in a conservative simulation, correct computation is guaranteed at an arbitrary point of the simulation, while in an optimistic simulation speculative errors may occur, but they will be corrected before the simulation completes. <p> We close this Section by briefly contrasting the conservative approach to trace-driven simulation with the optimistic one. Conservative methods always carry the overhead of synchronization to make certain that causality constraints <ref> [8] </ref> are satisfied. Only correct states are generated during the simulation. The conservative simulation insists on a total time order in which events are simulated. In the case of a cache simulation, only partial orders are required.
Reference: [9] <author> D. Jefferson. </author> <title> Virtual Time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 7, No. 3, </volume> <month> July </month> <year> 1985, </year> <pages> 404-425. </pages>
Reference-contexts: Deadlock happens when all the processes are blocked. In an implementation with deadlock avoidance this will occur only at the end of the simulation. Other implementations favor a detection and recovery scheme. The best-known optimistic method is Time Warp <ref> [9] </ref>. Processes in the optimistic simulation maintain and advance independently their own simulated (virtual) time. Processes communicate through timestamped messages. <p> State vectors and incoming and outgoing messages for each process must be saved in order to be able to recover from erroneous computations. This memory need could eventually lead to a costly paging activity. Jefferson <ref> [9] </ref> observed that at any time during simulation, there exists a global virtual time (GV T ) such that all saved events and states with timestamps earlier than GV T will no longer be used. Such memory, called fossil, can therefore be reclaimed.
Reference: [10] <author> David Jefferson. </author> <title> Virtual Time II: Storage Management in Distributed Simulation. </title> <booktitle> Proceedings of 9th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1990, </year> <pages> 75-90. </pages>
Reference-contexts: In the worst case, it is possible that a fast process consumes all of its memory buffer while no memory space is safe to reclaim due to a large discrepancy among the local clocks. Jefferson <ref> [10] </ref> proposed a cancelback protocol as a complementary method for memory recollection. The gist of the protocol is that, when a process runs out of memory and fossil collection fails to release any memory, the process will cause itself to rollback.
Reference: [11] <institution> Kendall Square Research. Technical Summary. </institution> <year> 1992. </year>
Reference: [12] <author> Y-B Lin, E. D. Lazowska and J-L Baer. </author> <title> Parallel Trace-Driven Simulation of Multiprocessor Cache Performance: Algorithms and Analysis. Progress in Simulation, Vol.1 No.1, </title> <publisher> Ablex Publishing, </publisher> <year> 1992, </year> <pages> 44-80. </pages>
Reference-contexts: In [1], we have experimentally studied a conservative parallel trace-driven simulation algorithm proposed by Lin et al <ref> [12] </ref>. Each simulation process (processor and cache simu lator) receives as input a trace consisting of the private and shared references of a physical process.
Reference: [13] <author> Y-B. Lin and E. D. Lazowska. </author> <title> Determining the Global Virtual Time in a Distributed Simulation. </title> <type> Tech Report 90-01-02. </type> <institution> Dept. of Computer Science. University of Wash-ington, </institution> <year> 1990. </year>
Reference-contexts: Such memory, called fossil, can therefore be reclaimed. The computation of GV T in a shared memory system is easier than in a distributed environment. There is no transient message 2 problem <ref> [13] </ref> because, in a shared memory environment, as soon as a process finishes sending a message (write to memory), this message is immediately accessible in another process's new message queue. Furthermore, processes are not allowed to advance their local clock when the signal for computing GV T is asserted. <p> Furthermore, processes are not allowed to advance their local clock when the signal for computing GV T is asserted. This eliminates the simultaneous report problem <ref> [13] </ref>.
Reference: [14] <author> P. Reiher, R Fujimoto, S. Bellenot and D. </author> <title> Jeffson Cancellation Strategies in Optimistic Execution Systems. </title> <booktitle> SCS Multiconference on Distributed Simulation, </booktitle> <year> 1990, </year> <pages> 112-121. </pages>
Reference-contexts: Lazy cancellation in some cases can reduce the number of anti-messages and positive messages. On the other hand, postponing anti-messages may allow erroneous computations of other processes to spread further than they would under aggressive cancellation. Reiher et al <ref> [14] </ref> have compared the two cancellation strategies and found that realistic applications perform reasonably well using either strategy, but somewhat better with lazy cancellation. An important argument for lazy cancellation in our context is that the states of cache lines are independent of each other.
Reference: [15] <author> J. P. Singh, W. D. Weber and A. Gupta. </author> <title> SPLASH: Stanford Parallel Applications for Shared-Memory. Computer Architecture News, </title> <address> Vol.20, No.1, </address> <month> March </month> <year> 1992, </year> <pages> 5-44. 19 </pages>
Reference-contexts: They are Water, Locus, Mp3D and Maxflow. The first three are in the Splash benchmark suite <ref> [15] </ref>. Water is a scientific application which simulates the evolution of a system of water molecules in the liquid state. Locus is a commercial quality VLSI standard cell router. Mp3d solves problem in rarefied fluid flow simulation. <p> The first observation is that the simulation speedups of the four applications decrease (look at Table 4 in a column-wise fashion) as the shared reference miss ratios increase (cf. Table 3). This is consistent with the results obtained (for the 3 Splash benchmarks) on a real bus-based machine <ref> [15] </ref> although the differences in the simulation are more pronounced.
References-found: 15

