URL: http://www.cs.tamu.edu/faculty/rwerger/pubs/1450.ps.gz
Refering-URL: http://www.cs.tamu.edu/faculty/rwerger/pubs/
Root-URL: http://www.cs.tamu.edu
Title: c  
Author: flCopyright by Lawrence Rauchwerger 
Date: 1995  
Abstract-found: 0
Intro-found: 1
Reference: [Abr94] <author> S. Abraham. </author> <title> Private communication, </title> <year> 1994. </year>
Reference-contexts: However, this is acceptable (even desirable) as long as these iterations are guaranteed 2 This fact was noted by Santosh Abraham <ref> [Abr94] </ref>. 23 to be executed on the same processor in the same order. Therefore, if each processor keeps a record of the iterations that it executes during the RPD test, this information could be used to statically schedule the future parallel execution of the loop.
Reference: [AC86] <author> Arvind and D. Culler. </author> <title> Dataflow architectures. </title> <type> Technical report, </type> <institution> Laboratory for Computer Science, M.I.T, </institution> <address> Cambridge, MA, </address> <month> February </month> <year> 1986. </year> <pages> Memo 226-5. </pages>
Reference-contexts: Later more aggressive designs have incorporated a full-empty bit [Smi87] to enforce data dependences on the fly. This type of memory structure has been exploited by the data-flow computing model <ref> [AC86, AI86, AN86] </ref> in quite an original way. It is probably also the most fundamental model of exploiting parallelism. Another hardware approach that is useful for run-time parallelization was taken by the Cedar project with its hardware synchronization primitives [ZYL83, ZY84, TZY84].
Reference: [AI86] <author> Arvind and R. </author> <title> Iannucci. Two fundamental issues in multiprocessing. </title> <type> Technical report, </type> <institution> Laboratory for Computer Science, M.I.T, </institution> <address> Cambridge, MA, </address> <month> July </month> <year> 1986. </year> <pages> Memo 226-5. </pages>
Reference-contexts: Later more aggressive designs have incorporated a full-empty bit [Smi87] to enforce data dependences on the fly. This type of memory structure has been exploited by the data-flow computing model <ref> [AC86, AI86, AN86] </ref> in quite an original way. It is probably also the most fundamental model of exploiting parallelism. Another hardware approach that is useful for run-time parallelization was taken by the Cedar project with its hardware synchronization primitives [ZYL83, ZY84, TZY84].
Reference: [AKPW83] <author> J. R. Allen, K. Kennedy, C. Porterfield, and J. Warren. </author> <title> Conversion of control dependence to data dependence. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 177-189, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: The general strategy of our methods is a fairly straightforward demand driven forward substitution of all the variables on the RHS, a process by which all control flow dependences are substituted by data dependences as described in <ref> [AKPW83, TP93] </ref>. Once this expression of the RHS is obtained it can be analyzed and validated by the methods described in the previous section.
Reference: [All86] <institution> Alliant Computer Systems Corporation. FX/Series Architecture Manual, </institution> <year> 1986. </year>
Reference-contexts: a parallelizing compilation is, to a certain degree, a reverse engineering job we want to rediscover the original intent, algorithm, of the programmer. 52 Chapter 5 Experimental Results for the LRPD Test 5.1 Experimental Setup We will present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 <ref> [All86] </ref>) and 14 processors (Alliant FX/2800 [All91]) using a Fortran implementation of our run-time library. This library consists of subroutines that can be called to perform the different phases of the test (backup, analysis, restoration). <p> could be overlapped with other portions of the program-thereby more fully exploiting the processing power of the machine (of course support for MIMD execution is highly desirable in this case). 6.5 Experimental Results In this section we present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 <ref> [All86] </ref>) and 14 processors (Alliant FX/2800 [All91]). However, we remark that the results scale with the number of processors and the data size and thus they may be extrapolated for massively parallel processors (MPPs), the actual target of our run-time methods. <p> This iteration must be found so that any iterations that need to be undone can be identified. On computers, such as the Alliant <ref> [All86] </ref>, in which iterations are issued in order, the test L [vpn] &gt; i is unnecessary. In order to terminate the parallel loop cleanly before all iterations have been executed, a QUIT operation similar to the one on Alliant computers [All86] could be used. <p> On computers, such as the Alliant <ref> [All86] </ref>, in which iterations are issued in order, the test L [vpn] &gt; i is unnecessary. In order to terminate the parallel loop cleanly before all iterations have been executed, a QUIT operation similar to the one on Alliant computers [All86] could be used. Once a QUIT command is issued by an iteration, all iterations with loop counters less than that of the issuing iteration will be initiated and completed, but no iterations with larger loop counters will be begun. <p> the cost of creating these copies is not too great, this technique should maximize the potential gains attainable from parallel execution, while, at the same time, minimizing the costs. 8.9 Experimental Results In this section we present experimental results obtained on a modestly parallel machine with 8 processors (Alliant FX/80 <ref> [All86] </ref>) using a Fortran implementation of our methods. It should be pointed out that our results scale with the number of processors and the data size and that they should be extrapolated for MPPs, the actual target of our methods.
Reference: [All91] <institution> Alliant Computers Systems Corporation. Alliant FX/2800 Series System Description, </institution> <year> 1991. </year>
Reference-contexts: certain degree, a reverse engineering job we want to rediscover the original intent, algorithm, of the programmer. 52 Chapter 5 Experimental Results for the LRPD Test 5.1 Experimental Setup We will present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 [All86]) and 14 processors (Alliant FX/2800 <ref> [All91] </ref>) using a Fortran implementation of our run-time library. This library consists of subroutines that can be called to perform the different phases of the test (backup, analysis, restoration). There are specialized routines for the different cases that have to be tested (privatization, reduction, output dependences, etc.). <p> of the program-thereby more fully exploiting the processing power of the machine (of course support for MIMD execution is highly desirable in this case). 6.5 Experimental Results In this section we present experimental results obtained on two modestly parallel machines with 8 (Alliant FX/80 [All86]) and 14 processors (Alliant FX/2800 <ref> [All91] </ref>). However, we remark that the results scale with the number of processors and the data size and thus they may be extrapolated for massively parallel processors (MPPs), the actual target of our run-time methods.
Reference: [AN86] <author> Arvind and R. Nikhil. </author> <title> Executing a program on the mit tagged-token dataflow architecture. </title> <type> Technical report, </type> <institution> Laboratory for Computer Science, M.I.T, </institution> <address> Cambridge, MA, </address> <month> February </month> <year> 1986. </year> <pages> Memo 226-5. </pages>
Reference-contexts: Later more aggressive designs have incorporated a full-empty bit [Smi87] to enforce data dependences on the fly. This type of memory structure has been exploited by the data-flow computing model <ref> [AC86, AI86, AN86] </ref> in quite an original way. It is probably also the most fundamental model of exploiting parallelism. Another hardware approach that is useful for run-time parallelization was taken by the Cedar project with its hardware synchronization primitives [ZYL83, ZY84, TZY84].
Reference: [AP87] <author> T. Allen and D. A. Padua. </author> <title> Debugging fortran on a shared-memory machine. </title> <booktitle> In Proceedings of the 1987 International Conference on Parallel Processing, </booktitle> <pages> pages 721-727, </pages> <address> St. Charles, IL, </address> <year> 1987. </year>
Reference-contexts: Padua et al. <ref> [AP87, EGP92] </ref> discuss methods that statically analyze the source program, and meth ods that analyze an execution trace of the program.
Reference: [Ban88] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer. </publisher> <address> Boston, MA., </address> <year> 1988. </year>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [Ban88, KKP + 81, PW86, Wol89, Zim91] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [PW86, KKP + 81, Ban88, Wol89, Zim91] </ref> (see Chapter 2 for a brief introduction to data dependence issues). do i = 1, n if (f (i) .eq. true) then exit A [i] = 2*A [i] enddo (a) if (f (i) .eq. true) then exit s4: tmp = A [2*i] s6: A
Reference: [BCFH89] <author> M. Burke, R. Cytron, J. Ferrante, and W. Hsieh. </author> <title> Automatic generation of nested, fork-join parallelism. </title> <journal> Journal of Supercomputing, </journal> <pages> pages 71-88, </pages> <year> 1989. </year>
Reference-contexts: Privatization creates, whenever correct, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [PW86, BCFH89, Li92, MAL92, TP92, TP93] </ref>).
Reference: [BCK + 89] <author> M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue, S. Orzag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, and J. Martin. </author> <title> The PERFECT club benchmarks: Effective performance evaluation of supercomputers. </title> <type> Technical Report CSRD-827, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <month> May </month> <year> 1989. </year> <month> 122 </month>
Reference-contexts: However, we remark that our results scale with the number of processors and the data size and thus they could be extrapolated for massively parallel processors (MPPs), the actual target of our run-time methods. We considered seven do loops from the PERFECT Benchmarks <ref> [BCK + 89] </ref> that could not be parallelized by any compiler available to us. Our results are summarized in Table 5.1. <p> To demonstrate that the new methods can achieve speedups, we applied them to three loops contained in the PERFECT Benchmarks <ref> [BCK + 89] </ref> that could not be parallelized by any compiler available to us. <p> The reason that larger 77 speedups were not obtained is that the loop is heavily imbalanced due to the blocked nature of the algorithm used in MA28. 6.5.2.1 Parallelizing Benchmark Loops We applied the methods to three loops contained in the PERFECT Benchmarks <ref> [BCK + 89] </ref> that could not be parallelized by any compiler available to us. In the analysis phase of the inspector it was found that one of the loops was fully parallel, and that the other two could be transformed into doalls by privatizing the shared array under test. <p> We considered five while loops that could not be parallelized by any compiler available to us; two loops are from the PERFECT Benchmarks <ref> [BCK + 89] </ref>, two loops are from MA28, a sparse non-symmetric linear solver [Duf77], and one loop is extracted from MCSPARSE, a parallel version of a non-symmetric sparse linear systems solver [GMW89, GMW91]. Our results are summarized in Table 8.9.
Reference: [BE92] <author> W. Blume and R. Eigenmann. </author> <title> Performance Analysis of Parallelizing Compilers on the Perfect Benchmarks T M Programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(6) </volume> <pages> 643-656, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: simulations and computation will be dynamic in nature and will only increase the fraction of statically non-analyzable codes (currently estimated to be over 50%) Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by some new methods <ref> [BE92, CPHL94, EHLP91] </ref>. 4 We need techniques that let us access the information necessary to decide if a loop is parallel and perform parallelizing transformations. The only time this data is available is during program execution, at run-time.
Reference: [BEH + 94] <author> William Blume, Rudolf Eigenmann, Jay Hoeflinger, David Padua, Paul Petersen, Lawrence Rauchwerger, and Peng Tu. </author> <title> Automatic Detection of Parallelism: A Grand Challenge for High-Performance Computing. </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> 2(3) </volume> <pages> 37-47, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: Just as important is the fact that parallel systems don't run only newly written applications. There is an enormous body of existing software that must be ported and perform well on these new systems. One solution is to rewrite the so named 'legacy' programs <ref> [BEH + 94] </ref>, but this could prove to be prohibitively expensive. The alternative is to automatically transform them for concurrent execution by means of a restructuring or parallelizing compiler.
Reference: [BMO90] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The Program Dependence Web: a Representation Supporting Control Data- and Demand-Driven Interpretation of Imperative Languages. </title> <booktitle> In Proceedings of the SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: What is known, however, is the set of all possible RHS forms, which can be computed by following all potential paths in the control flow graph. A direct approach uses a gated static single assignment (GSSA) <ref> [BMO90, TP94] </ref> representation of the program. In such a representation, scalar variables are assigned only once.
Reference: [BS90] <author> H. Berryman and J. Saltz. </author> <title> A manual for PARTI runtime primitives. </title> <type> Interim Report 90-13, </type> <institution> ICASE, </institution> <year> 1990. </year>
Reference-contexts: Global parallelization, i.e., deeply nested loops containing subroutine calls, is quite often not possible because inter-procedural analysis generates extremely complex expressions that are in the end intractable although statically defined. This thesis will present several new run-time methods some are improvements of previous ones <ref> [BS90, LZ93, MP87, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref> and others represent represent totally new approaches. They collectively constitute an effective framework for run-time parallelization. In the next sections we will be mostly concerned with the parallelism detection side of the compiler. <p> This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> Thus, if, as would be natural, each processor were assigned one iteration of the outer loop, we would have precisely the situation described above. 7.2.2 Methods for Loops Without Output Dependences The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [BS90, SM91, SMC89, SMC91, WSHB91] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences.
Reference: [CKS78] <author> S. C. Chen, D. J. Kuck, and A. H. Sameh. </author> <title> Practical parallel band triangular solvers. </title> <journal> ACM Transaction on Mathematical Software, </journal> <volume> 4(1) </volume> <pages> 270-277, </pages> <month> September </month> <year> 1978. </year>
Reference-contexts: Although the concurrent evaluation of recurrences is in general not possible, some special cases lend themselves to either full or partial parallelization. There are parallel algorithms to solve simple inductions (the case of do loops) [WL90] and associative recurrences <ref> [CKS78, LF80, Kru85, Kru86] </ref> but the evaluation of general recurrences has always been of a sequential nature.
Reference: [CPHL94] <author> W. J. Camp, S. J. Plimpton, B. A. Hendrickson, and R. W. Leland. </author> <title> Massively parallel methods for engineering and science problems. </title> <journal> Comm. ACM, </journal> <volume> 37(4) </volume> <pages> 31-41, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: simulations and computation will be dynamic in nature and will only increase the fraction of statically non-analyzable codes (currently estimated to be over 50%) Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by some new methods <ref> [BE92, CPHL94, EHLP91] </ref>. 4 We need techniques that let us access the information necessary to decide if a loop is parallel and perform parallelizing transformations. The only time this data is available is during program execution, at run-time.
Reference: [CYT94] <author> D. K. Chen, P. C. Yew, and J. Torrellas. </author> <title> An efficient algorithm for the run-time parallelization of doacross loops. </title> <booktitle> In Proceedings of Supercomputing 1994, </booktitle> <pages> pages 518-527, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Global parallelization, i.e., deeply nested loops containing subroutine calls, is quite often not possible because inter-procedural analysis generates extremely complex expressions that are in the end intractable although statically defined. This thesis will present several new run-time methods some are improvements of previous ones <ref> [BS90, LZ93, MP87, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref> and others represent represent totally new approaches. They collectively constitute an effective framework for run-time parallelization. In the next sections we will be mostly concerned with the parallelism detection side of the compiler. <p> This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> The loop is executed in parallel using synchronization (full/empty bits) to enforce flow dependences. To our knowledge, this is the only other run-time privatization technique except [RP94a, RP94b]. 85 Recently, Chen, Yew, and Torrellas <ref> [CYT94] </ref> proposed an inspector that has a private phase and a merging phase. In the private phase, the loop is chunked and each processor builds a list of all the accesses to each memory location for its assigned iterations. <p> The offending addresses which are used out of order are stored until all potential hazards have been cleared. If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) <ref> [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87] </ref>, are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) <ref> [CYT94, LZ93, Pol88, SM91, SMC91, ZY87] </ref>. <p> requires restricts privatizes optimal sequential global type of or finds Method schedule portions synchron loop reductions Rauchwerger/Amato/Padua [RAP95] Yes No No No P,R Zhu/Yew [ZY87] No 1 No Yes 2 No No Midkiff/Padua [MP87] Yes No Yes 2 No No Krothapalli/Sadayappan [KS88] No 3 No Yes 2 No P Chen/Yew/Torrellas <ref> [CYT94] </ref> No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et al. [SMC91] Yes Yes 4 Yes Yes 5 No Leung/Zahorjan [LZ93] Yes No Yes Yes 5 No Polychronopoulous [Pol88] No No No No No Rauchwerger/Padua [RP94a, RP94b] No 6 No No No P,R
Reference: [DS90] <author> A. Dinning and E. Schonberg. </author> <title> An empirical comparison of monitoring algorithms for access anomaly detection. </title> <booktitle> In Proc. of 2-nd ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming (PPOPP), </booktitle> <pages> pages 1-10, </pages> <year> 1990. </year>
Reference-contexts: Since not all anomalies can be detected stat ically, and execution traces can require prohibitive amounts of memory, run-time access anomaly detection methods that minimize memory requirements are desirable <ref> [Sch89, DS90, NR88] </ref>. In fact, a run-time anomaly detection method proposed by Snir, and optimized by Schonberg [Sch89], bears similarities to the version of the doall test presented in Chapter 2 (i.e., the version without the privatization).
Reference: [Duf77] <author> I. S. Duff. </author> <title> Ma28- a set of fortran subroutines for sparse unsymmetric linear equations. </title> <type> Technical Report AERE R8730, </type> <address> HMSO, London, </address> <year> 1977. </year>
Reference-contexts: By applying the new methods to such access patterns, we can re-confirm the conclusions reached above using synthetic reference patterns. For this purpose we have chosen a loop out of MA28, a blocked sparse UN-symmetric linear solver <ref> [Duf77] </ref>. Loop MA30cd/DO 120 performs the forward-backward substitution in the final phase of the blocked sparse linear system solver (MA28). We selected this loop because it can generate many diverse access patterns when using the Harwell-Boeing matrices as input. <p> We considered five while loops that could not be parallelized by any compiler available to us; two loops are from the PERFECT Benchmarks [BCK + 89], two loops are from MA28, a sparse non-symmetric linear solver <ref> [Duf77] </ref>, and one loop is extracted from MCSPARSE, a parallel version of a non-symmetric sparse linear systems solver [GMW89, GMW91]. Our results are summarized in Table 8.9. For each method applied to a loop, we give the speedup that was obtained, and, mention whether backups and time-stamping were necessary.
Reference: [EGP92] <author> Perry Emrath, Sanjoy Ghosh, and David Padua. </author> <title> Detecting Nondeterminacy in Parallel Programs. </title> <journal> IEEE Software, </journal> <pages> pages 69-77, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Padua et al. <ref> [AP87, EGP92] </ref> discuss methods that statically analyze the source program, and meth ods that analyze an execution trace of the program.
Reference: [EHLP91] <author> Rudolf Eigenmann, Jay Hoeflinger, Zhiyuan Li, and David Padua. </author> <title> Experience in the Automatic Parallelization of Four Perfect-Benchmark Programs. </title> <booktitle> Lecture Notes in Com 123 puter Science 589. Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <pages> pages 65-83, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: simulations and computation will be dynamic in nature and will only increase the fraction of statically non-analyzable codes (currently estimated to be over 50%) Thus, in order to realize the full potential of parallel computing it has become clear that static (compile-time) analysis must be complemented by some new methods <ref> [BE92, CPHL94, EHLP91] </ref>. 4 We need techniques that let us access the information necessary to decide if a loop is parallel and perform parallelizing transformations. The only time this data is available is during program execution, at run-time. <p> Our interest in identifying fully parallel loops is motivated by the fact that they arise frequently in real programs: From an analysis of the manual parallelization of the PERFECT suite <ref> [EHLP91] </ref> it has been found that most of the DO loops (75%) are fully parallelizable and that they often represent almost all sequential execution time of the programs. <p> One typical method for the case of commutative reductions is to transform the do loop into a doall and enclose the access to the reduction variable in an unordered critical section <ref> [EHLP91, Zim91] </ref> a section of code guarded by a lock unlock operation which allows mutually 9 exclusive operations on the shared variable. Drawbacks of this method are that it is not always scalable and requires synchronizations which can be very expensive in large multiprocessor systems.
Reference: [GCM + 94] <author> D.M. Gallagher, W. Y. Chen, S. A. Malke, J.G. Gyllenhaal, and Wen mei W. Hwu. </author> <title> Dynamic memory disambiguation using the memory conflict buffer. </title> <booktitle> In Proc. 21st Ann. Int'l Symp. Computer Architecture, </booktitle> <pages> pages 183-195, </pages> <address> Chicago, IL, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: Another significant contribution to this field has been done by Alex Nicolau in [Nic89]. The idea of run-time disambiguation has been more recently used in optimizing codes for instruction level parallelism <ref> [HSS94, GCM + 94] </ref>. Their idea is to speculatively execute code very aggressively (out of order) inspite of the fact that some memory locations (few) could cause unsatisfied data dependences. The offending addresses which are used out of order are stored until all potential hazards have been cleared.
Reference: [GMW89] <author> K. Gallivan, B. Marsolf, and H. Wijshoff. </author> <title> A large-grain parallel sparse system solver. </title> <booktitle> In Proc. Fourth SIAM Conf. on Parallel Proc. for Scient. Comp., </booktitle> <pages> pages 23-28, </pages> <address> Chicago, IL, </address> <year> 1989. </year>
Reference-contexts: loops that could not be parallelized by any compiler available to us; two loops are from the PERFECT Benchmarks [BCK + 89], two loops are from MA28, a sparse non-symmetric linear solver [Duf77], and one loop is extracted from MCSPARSE, a parallel version of a non-symmetric sparse linear systems solver <ref> [GMW89, GMW91] </ref>. Our results are summarized in Table 8.9. For each method applied to a loop, we give the speedup that was obtained, and, mention whether backups and time-stamping were necessary. Whenever necessary, we performed a simple preventive backup of the variables potentially written in the loop.
Reference: [GMW91] <author> K. A. Gallivan, B. A. Marsolf, and H. A. G. Wijshoff. </author> <title> MCSPARSE: A parallel sparse unsymmetric linear system solver. </title> <type> Technical Report 1142, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <year> 1991. </year>
Reference-contexts: loops that could not be parallelized by any compiler available to us; two loops are from the PERFECT Benchmarks [BCK + 89], two loops are from MA28, a sparse non-symmetric linear solver [Duf77], and one loop is extracted from MCSPARSE, a parallel version of a non-symmetric sparse linear systems solver <ref> [GMW89, GMW91] </ref>. Our results are summarized in Table 8.9. For each method applied to a loop, we give the speedup that was obtained, and, mention whether backups and time-stamping were necessary. Whenever necessary, we performed a simple preventive backup of the variables potentially written in the loop.
Reference: [GPHL90] <author> M. Guzzi, D. Padua, J. Hoeflinger, and D. Lawrie. </author> <title> Cedar fortran and other vector and parallel fortran dialects. </title> <journal> J. Supercomput., </journal> <volume> 4(1) </volume> <pages> 37-62, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: In addition, in order to analyze the overhead incurred by the methods, we applied them to different access patterns taken from loops in the PERFECT Benchmarks and to synthetic access patterns generated to test their behavior in various situations. The methods were implemented in Cedar Fortran <ref> [GPHL90] </ref>. The inspector was essentially as described in Section 6.2. In particular, we implemented the bucket sort version using separate pR 74 and pH data structures for each processor.
Reference: [Har86] <author> W. L. Harrison, III. </author> <title> Compiling Lisp for Evaluation on a Tightly Coupled Multiprocessor. </title> <type> Technical Report 565, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <month> March, </month> <year> 1986. </year>
Reference-contexts: These new parallel constructs could be called while-doall, while-doacross, and while-doany and could prove useful in the parallel programming (manual parallelization) of applications. The methods described here extend previous works <ref> [Har86, WL90] </ref> in that they: 1. can handle remainder variant termination conditions, 2. can test at run-time for cross-iteration data dependences in the remainder, 3. do not require work and storage for saving the values computed in the recurrence, 4. support both static and dynamic scheduling, and 5. present a comprehensive <p> We present some experimental results in Section 8.9. In Section 8.10 we discuss related work. 8.2 Transforming While Loops for Parallel Execution While loops have often been treated by parallelizing compilers as an intrinsically sequential constructs because their iteration space is unknown <ref> [Har86] </ref>. A related case which is generally also handled sequentially by compilers is the do loop with a conditional exit. In this paper we propose techniques that can be used to execute such loops in parallel. <p> In fact, the author mentions that if the chunk sizes become too small, then the result might be an "inefficient restructured version of the loop that contains too little parallelism to recover the expense [invested]" <ref> [Har86] </ref>. We note that when the entire list resides in a single chunk (i.e., an array), then this method is equivalent to the method we describe in Section 8.3.2 for associative recurrences, i.e., loop distribution together with a parallel prefix computation to evaluate the dispatcher in parallel. <p> When the terminator is RI and it is known that there are no cross-iteration data dependences in the loop, they suggest using the naive form of loop distribution mentioned in Section 8.3.3 (also implicit in <ref> [Har86] </ref>), i.e., first a sequential while loop evaluates the dispatcher and stores its values in an array, and then the loop iterations are performed in parallel using this array. For the case of RV termination conditions no methods have been proposed in the past.
Reference: [Har89] <author> Luddy Harrison. </author> <title> The Interprocedural Analysis and Automatic Parallelization of Scheme Programs. </title> <type> PhD thesis, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: In [TLS90] the authors have proposed some methods for achieving vector-like performance on multiple issue pipelined machines. They do not try to address the problem for large multiprocessors. Some techniques for solving certain types of recurrences in parallel were proposed by Harrison in <ref> [Har89] </ref> for Lisp-like languages. His main goal was to parallelize list operations (e.g., traversing a linked lists). Generally, his methods assume that the terminator is RI and it is known that there are no cross-iteration dependences in the loop.
Reference: [HP90] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantatative Approach. </title> <publisher> Morgan Kauffman, </publisher> <address> San Mateo,CA, </address> <year> 1990. </year>
Reference-contexts: One simple method, referred to as General-1, is to serialize the accesses to the next () operation. This technique is equivalent to hardware pipelining which has been well studied in the literature <ref> [HP90] </ref>. The cost of synchronization and the limited amount of parallelism may make this scheme unattractive.
Reference: [HSS94] <author> A.S. Huang, G. Slavenburg, and J.P. Shen. </author> <title> Speculative disambiguation: A compilation technique for dynamic memory disambiguation. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 200-210, </pages> <address> Chicago, IL, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: Another significant contribution to this field has been done by Alex Nicolau in [Nic89]. The idea of run-time disambiguation has been more recently used in optimizing codes for instruction level parallelism <ref> [HSS94, GCM + 94] </ref>. Their idea is to speculatively execute code very aggressively (out of order) inspite of the fact that some memory locations (few) could cause unsatisfied data dependences. The offending addresses which are used out of order are stored until all potential hazards have been cleared.
Reference: [Jef85] <author> D. R. Jefferson. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <year> 1985. </year>
Reference-contexts: Another difference is that the doall test is optimized especially for loops, and access anomaly detection methods must handle any type of concurrent thread in a parallel program. Optimistic Execution A concept related to the speculative approach proposed in this thesis is virtual time first introduced in <ref> [Jef85] </ref> and defined as " ... paradigm for organizing and synchronizing distributed systems.... [It] provides a flexible abstraction of real time in much the same way that virtual memory provides an abstraction of real memory.
Reference: [KKP + 81] <author> D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe. </author> <title> Dependence graphs and compiler optimizations. </title> <booktitle> In Proceedings of the 8th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-218, </pages> <month> January </month> <year> 1981. </year> <month> 124 </month>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [Ban88, KKP + 81, PW86, Wol89, Zim91] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [PW86, KKP + 81, Ban88, Wol89, Zim91] </ref> (see Chapter 2 for a brief introduction to data dependence issues). do i = 1, n if (f (i) .eq. true) then exit A [i] = 2*A [i] enddo (a) if (f (i) .eq. true) then exit s4: tmp = A [2*i] s6: A
Reference: [KM90] <author> K. Kennedy and K. S. McKinley. </author> <title> Loop distribution with arbitrary control flow. </title> <booktitle> In Supercomputing, </booktitle> <pages> pages 407-416, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: It is important to remark here that if the statements computing the addresses of the shared variables being tested and those that use it are strongly connected in the dependence graph, a proper distribution is not possible <ref> [KM90] </ref>. This fact limits the applicability (generality) of all 'inspector/executor' run-time techniques.
Reference: [Kru85] <author> C. Kruskal. </author> <title> Efficient parallel algorithms for graph problems. </title> <booktitle> In Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1985. </year>
Reference-contexts: Drawbacks of this method are that it is not always scalable and requires synchronizations which can be very expensive in large multiprocessor systems. A scalable method can be obtained by noting that a reduction operation is an associative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [Kru85, Kru86, Lei92] </ref>. <p> Although the concurrent evaluation of recurrences is in general not possible, some special cases lend themselves to either full or partial parallelization. There are parallel algorithms to solve simple inductions (the case of do loops) [WL90] and associative recurrences <ref> [CKS78, LF80, Kru85, Kru86] </ref> but the evaluation of general recurrences has always been of a sequential nature.
Reference: [Kru86] <author> C. Kruskal. </author> <title> Efficient parallel algorithms for graph problems. </title> <booktitle> In Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 869-876, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Drawbacks of this method are that it is not always scalable and requires synchronizations which can be very expensive in large multiprocessor systems. A scalable method can be obtained by noting that a reduction operation is an associative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [Kru85, Kru86, Lei92] </ref>. <p> Although the concurrent evaluation of recurrences is in general not possible, some special cases lend themselves to either full or partial parallelization. There are parallel algorithms to solve simple inductions (the case of do loops) [WL90] and associative recurrences <ref> [CKS78, LF80, Kru85, Kru86] </ref> but the evaluation of general recurrences has always been of a sequential nature.
Reference: [KS88] <author> V. Krothapalli and P. Sadayappan. </author> <title> An approach to synchronization of parallel computing. </title> <booktitle> In Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <pages> pages 573-581, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> An advantage of this method is reduced memory requirements: it uses only a shadow version of the shared array under scrutiny whereas all other methods (except [Pol88, RP94a, RP94b]) unroll the loop and store all the accesses to the shared array. Krothapalli and Sadayappan <ref> [KS88] </ref> proposed a run-time scheme for removing anti and output dependences from loops. Their scheme includes a parallel inspector that determines the number of accesses to each memory location using critical sections as in the method of Zhu and Yew (and is thus sensitive to hotspots). <p> The offending addresses which are used out of order are stored until all potential hazards have been cleared. If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) <ref> [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87] </ref>, are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> in which the access anomaly occurred. 87 obtains contains requires restricts privatizes optimal sequential global type of or finds Method schedule portions synchron loop reductions Rauchwerger/Amato/Padua [RAP95] Yes No No No P,R Zhu/Yew [ZY87] No 1 No Yes 2 No No Midkiff/Padua [MP87] Yes No Yes 2 No No Krothapalli/Sadayappan <ref> [KS88] </ref> No 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et al. [SMC91] Yes Yes 4 Yes Yes 5 No Leung/Zahorjan [LZ93] Yes No Yes Yes 5 No Polychronopoulous [Pol88] No No No No No
Reference: [Lei92] <author> F. Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: Drawbacks of this method are that it is not always scalable and requires synchronizations which can be very expensive in large multiprocessor systems. A scalable method can be obtained by noting that a reduction operation is an associative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [Kru85, Kru86, Lei92] </ref>. <p> The counting in Step 2 (a) can be done in parallel by giving each processor s=p values to add within its private memory, and then summing the p resulting values in global storage, which takes O (s=p + log p) time <ref> [Lei92] </ref>. The comparisons in Step 2 (b) and 2 (d) of the A w and A r (A np ) shadow arrays take O (s=p + log p) time. Again, if s na, then the complexity can be reduced to O (na=p + log p) by using hash tables. <p> Since A w and tm (A) are computed during the test itself, the only additional information needed is the prefix sums, which can be computed in time O (s=p + log p) by recursive doubling <ref> [Lei92] </ref>. In fact, the prefix sums can be computed at the same time that tm (A) is accumulated without much extra work. <p> The cost of these searches can be reduced from p to O (log p) using a standard parallel divide-and-conquer "pair-wise" merging approach <ref> [Lei92] </ref>, where p is the total number of processors. 66 of the do loop in (a) is shown in (b). The markwrite (markread) operation adds a record to the processor's array pR (if its not a duplicate), and updates the hierarchy vector pH appropriately. <p> In particular, using the bucket sort implementation, each processor spends constant time on each of its O (a) accesses in the marking phase, and the analysis phase takes time O (a log p) using a parallel divide-and-conquer pair-wise merging strategy <ref> [Lei92] </ref>.
Reference: [LF80] <author> R. Ladner and M. Fisher. </author> <title> Parallel prefix computation. </title> <journal> J. ACM, </journal> <pages> pages 831-838, </pages> <year> 1980. </year>
Reference-contexts: Although the concurrent evaluation of recurrences is in general not possible, some special cases lend themselves to either full or partial parallelization. There are parallel algorithms to solve simple inductions (the case of do loops) [WL90] and associative recurrences <ref> [CKS78, LF80, Kru85, Kru86] </ref> but the evaluation of general recurrences has always been of a sequential nature.
Reference: [Li92] <author> Zhiyuan Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 313-322, </pages> <year> 1992. </year>
Reference-contexts: Privatization creates, whenever correct, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [PW86, BCFH89, Li92, MAL92, TP92, TP93] </ref>).
Reference: [LZ93] <author> S. Leung and J. Zahorjan. </author> <title> Improving the performance of runtime parallelization. </title> <booktitle> In 4th PPOPP, </booktitle> <pages> pages 83-91, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Global parallelization, i.e., deeply nested loops containing subroutine calls, is quite often not possible because inter-procedural analysis generates extremely complex expressions that are in the end intractable although statically defined. This thesis will present several new run-time methods some are improvements of previous ones <ref> [BS90, LZ93, MP87, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref> and others represent represent totally new approaches. They collectively constitute an effective framework for run-time parallelization. In the next sections we will be mostly concerned with the parallelism detection side of the compiler. <p> This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> It is imperative that the marking loop be parallel, for otherwise it defeats the purpose of run-time parallelization <ref> [LZ93, SM91] </ref>. (Below, we mention some special circumstances in which speedups might still be obtained using a sequential marking loop.) A parallel marking loop can be obtained if the source loop can be distributed into a loop computing 72 the addresses of the array under test and another loop which uses <p> parallelization technique of Saltz and Mirchandaney [SM91], in which processors are assigned iterations in a wrapped manner, and busy-waits are used to ensure that values have been produced before they are used (again, this is only possible if the original loop has no output dependences). 86 Recently, Leung and Zahorjan <ref> [LZ93] </ref> have proposed some other methods of parallelizing the inspector of Saltz et al. These techniques are also restricted to loops with no output dependences. <p> The offending addresses which are used out of order are stored until all potential hazards have been cleared. If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) <ref> [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87] </ref>, are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops <ref> [LZ93, SM91, SMC91] </ref>, have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) <ref> [CYT94, LZ93, Pol88, SM91, SMC91, ZY87] </ref>. <p> Yes 2 No No Midkiff/Padua [MP87] Yes No Yes 2 No No Krothapalli/Sadayappan [KS88] No 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et al. [SMC91] Yes Yes 4 Yes Yes 5 No Leung/Zahorjan <ref> [LZ93] </ref> Yes No Yes Yes 5 No Polychronopoulous [Pol88] No No No No No Rauchwerger/Padua [RP94a, RP94b] No 6 No No No P,R Table 7.1 A comparison of run-time parallelization techniques for do loops.
Reference: [MAL92] <author> D. E. Maydan, S. P. Amarasinghe, and M. S. Lam. </author> <title> Data dependence and data-flow analysis of arrays. </title> <booktitle> In Proceedings 5th Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: Privatization creates, whenever correct, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [PW86, BCFH89, Li92, MAL92, TP92, TP93] </ref>).
Reference: [MCH + 92] <author> S. A. Mahlke, W. Y. Chen, W. W. Hwu, B. R. Rau, and M. S. Schl ansker. </author> <title> Sentinel scheduling for VLIW and superscalar processors. </title> <booktitle> In Proceedings of 5th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: However, in this case the compiler could predict the number of iterations using branch statistics, where the branch is on the termination condition of the while loop. Although the application is different, this in not a new idea since branch speculation has been used effectively in superscalar compilers <ref> [MCH + 92, SLH90, TLS90] </ref>. Since branch statistics have already been collected for many benchmarks, these collection mechanisms are available. 8.8 Strategies for Applying the Techniques In the previous section we discussed the speedups and potential slowdowns that can be expected when using our techniques for parallelizing while loops.
Reference: [MP87] <author> Samuel Midkiff and David Padua. </author> <title> Compiler Algorithms for Synchronization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(12):1485-1495, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: Global parallelization, i.e., deeply nested loops containing subroutine calls, is quite often not possible because inter-procedural analysis generates extremely complex expressions that are in the end intractable although statically defined. This thesis will present several new run-time methods some are improvements of previous ones <ref> [BS90, LZ93, MP87, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref> and others represent represent totally new approaches. They collectively constitute an effective framework for run-time parallelization. In the next sections we will be mostly concerned with the parallelism detection side of the compiler. <p> This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> Midkiff and Padua <ref> [MP87] </ref> extended this method to allow concurrent reads from a memory location in multiple iterations. Due to the compare-and-swap synchronizations, this method runs the risk of a severe degradation in performance for access patterns containing hot spots (i.e., many accesses to the same memory location). <p> The offending addresses which are used out of order are stored until all potential hazards have been cleared. If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) <ref> [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87] </ref>, are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> to identify the point in the parallel execution in which the access anomaly occurred. 87 obtains contains requires restricts privatizes optimal sequential global type of or finds Method schedule portions synchron loop reductions Rauchwerger/Amato/Padua [RAP95] Yes No No No P,R Zhu/Yew [ZY87] No 1 No Yes 2 No No Midkiff/Padua <ref> [MP87] </ref> Yes No Yes 2 No No Krothapalli/Sadayappan [KS88] No 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et al. [SMC91] Yes Yes 4 Yes Yes 5 No Leung/Zahorjan [LZ93] Yes No Yes Yes 5
Reference: [MP94] <author> Jose E. Moreira and Constantine D. Polychronopoulos. </author> <title> Autoscheduling in a Distributed Shared-Memory Environment . Technical Report 1373, </title> <institution> Univ of Illinois at Urbana-Champaign, Cntr for Supercomputing Res & Dev, </institution> <month> June </month> <year> 1994. </year> <month> 125 </month>
Reference-contexts: it is desirable to interleave the scheduler and the executor, i.e., overlap the scheduler's wavefront computations with the actual execution of the ready iterations. 73 This can either be achieved with a dynamic partition of the processors among these two tasks (see Section 6.3) or with a dynamic ready queue <ref> [MP94, PBK93] </ref>. Schedule reuse and decoupling the inspector/scheduler and the executor. Thus far, we have assumed that our methods must be used each time a loop is executed in order to determine a parallel execution schedule for the loop.
Reference: [Nic89] <author> A. Nicolau. </author> <title> Run-time disambiguation: coping with statically unpredictable dependen-cies. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(5) </volume> <pages> 663-678, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Dependences are detected using shadow versions of the variables, either sequentially, or in parallel with the aid of critical sections as in [ZY87]. Another significant contribution to this field has been done by Alex Nicolau in <ref> [Nic89] </ref>. The idea of run-time disambiguation has been more recently used in optimizing codes for instruction level parallelism [HSS94, GCM + 94]. Their idea is to speculatively execute code very aggressively (out of order) inspite of the fact that some memory locations (few) could cause unsatisfied data dependences.
Reference: [NR88] <author> I. Nudler and L. Rudolph. </author> <title> Tools for the efficient developement of efficient parallel programs. </title> <booktitle> In Proc. 1st Israeli Conference on Computer System Engineering, </booktitle> <year> 1988. </year>
Reference-contexts: Since not all anomalies can be detected stat ically, and execution traces can require prohibitive amounts of memory, run-time access anomaly detection methods that minimize memory requirements are desirable <ref> [Sch89, DS90, NR88] </ref>. In fact, a run-time anomaly detection method proposed by Snir, and optimized by Schonberg [Sch89], bears similarities to the version of the doall test presented in Chapter 2 (i.e., the version without the privatization).
Reference: [PBK93] <author> Constantine Polychronopoulos, Nawaf Bitar, and Steve Kleiman. nanoThreads: </author> <title> A User-Level Threads Architecture. </title> <booktitle> Proc. of the 1993 Int'l. Conf. on Parallel Computing Technologies, </booktitle> <address> Moscow, Russia, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: it is desirable to interleave the scheduler and the executor, i.e., overlap the scheduler's wavefront computations with the actual execution of the ready iterations. 73 This can either be achieved with a dynamic partition of the processors among these two tasks (see Section 6.3) or with a dynamic ready queue <ref> [MP94, PBK93] </ref>. Schedule reuse and decoupling the inspector/scheduler and the executor. Thus far, we have assumed that our methods must be used each time a loop is executed in order to determine a parallel execution schedule for the loop.
Reference: [Pol88] <author> C. Polychronopoulos. </author> <title> Compiler Optimizations for Enhancing Parallelism and Their Imp act on Architecture Design. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-37(8):991-1004, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> However, when there are no hot spots and the critical path length is very small, then this method should perform well. An advantage of this method is reduced memory requirements: it uses only a shadow version of the shared array under scrutiny whereas all other methods (except <ref> [Pol88, RP94a, RP94b] </ref>) unroll the loop and store all the accesses to the shared array. Krothapalli and Sadayappan [KS88] proposed a run-time scheme for removing anti and output dependences from loops. <p> Other methods In contrast to the above methods which place iterations in the lowest possible wavefront, Polychronopolous <ref> [Pol88] </ref> gives a method where wavefronts are maximal sets of contiguous iterations with no cross-iteration dependences. Dependences are detected using shadow versions of the variables, either sequentially, or in parallel with the aid of critical sections as in [ZY87]. <p> The offending addresses which are used out of order are stored until all potential hazards have been cleared. If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) <ref> [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87] </ref>, are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components <ref> [Pol88, SM91, SMC91] </ref>, and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) <ref> [CYT94, LZ93, Pol88, SM91, SMC91, ZY87] </ref>. <p> Yes 2 No No Krothapalli/Sadayappan [KS88] No 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et al. [SMC91] Yes Yes 4 Yes Yes 5 No Leung/Zahorjan [LZ93] Yes No Yes Yes 5 No Polychronopoulous <ref> [Pol88] </ref> No No No No No Rauchwerger/Padua [RP94a, RP94b] No 6 No No No P,R Table 7.1 A comparison of run-time parallelization techniques for do loops. In the table entries, P and R show that the method identities privatizable and reduction variables, respectively.
Reference: [PW86] <author> D. A. Padua and M. J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM, </journal> <volume> 29 </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Techniques addressing the issue of data dependence analysis have been studied extensively over the last two decades <ref> [PW86, Wol89] </ref> but parallelizing compilers cannot perform a meaningful data dependence analysis and extract a significant fraction of the available parallelism in a loop if it has a complex and/or statically insufficiently defined access pattern. Unfortunately irregular programs, as previously defined, represent a large part of all scientific applications. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [Ban88, KKP + 81, PW86, Wol89, Zim91] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). <p> Privatization creates, whenever correct, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [PW86, BCFH89, Li92, MAL92, TP92, TP93] </ref>). <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [PW86, KKP + 81, Ban88, Wol89, Zim91] </ref> (see Chapter 2 for a brief introduction to data dependence issues). do i = 1, n if (f (i) .eq. true) then exit A [i] = 2*A [i] enddo (a) if (f (i) .eq. true) then exit s4: tmp = A [2*i] s6: A
Reference: [RAP95] <author> L. Rauchwerger, N. Amato, and D. Padua. </author> <title> Run-time methods for parallelizing partially parallel loops. </title> <type> Technical report, </type> <institution> CSRD, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: Generally, access anomaly detection techniques seek to identify the point in the parallel execution in which the access anomaly occurred. 87 obtains contains requires restricts privatizes optimal sequential global type of or finds Method schedule portions synchron loop reductions Rauchwerger/Amato/Padua <ref> [RAP95] </ref> Yes No No No P,R Zhu/Yew [ZY87] No 1 No Yes 2 No No Midkiff/Padua [MP87] Yes No Yes 2 No No Krothapalli/Sadayappan [KS88] No 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et
Reference: [RDN93] <author> L. Rauchwerger, P. Dubey, and R. Nair. </author> <title> Measuring Limits of Parallelism and Characterizing Its Vulnerability. </title> <booktitle> Proceedings of 26th Annual Int'l Symp. on Microarchitecture, </booktitle> <pages> pages 105-117, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Through compiler (static and run-time) analysis we can find several nested levels of parallelism (e.g., nested parallel loops) and we have to find a policy based on which we can decide at which physical level it can be exploited from instruction level on a superscalar node <ref> [RDN93] </ref> to groups of nodes (clusters) and reaching the entire computer system. Optimization through Feedback * The use of statistics for feedback during current execution or future invocations of the program has to be studied. Speculations about parallelism can be biased favorably if previous experience could be used.
Reference: [RP94a] <author> L. Rauchwerger and D. Padua. </author> <title> The privatizing doall test: A run-time technique for doall loop identification and array privatization. </title> <booktitle> In Proceedings of the 1994 International Conference on Supercomputing, </booktitle> <pages> pages 33-43, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> These graphs show that the speedup scales with the number of processors and is a significant percentage of the ideal speedup. Below, we discuss each loop in more detail. We remark here that these loops could also be identified by the LRPD test <ref> [RP94a, RP94b] </ref>, a run-time test for identifying fully parallel loops, or loops that can be transformed into doalls using privatization and reduction parallelization. An advantage of the LRPD test is that it has a smaller overhead than the methods we present here. <p> However, when there are no hot spots and the critical path length is very small, then this method should perform well. An advantage of this method is reduced memory requirements: it uses only a shadow version of the shared array under scrutiny whereas all other methods (except <ref> [Pol88, RP94a, RP94b] </ref>) unroll the loop and store all the accesses to the shared array. Krothapalli and Sadayappan [KS88] proposed a run-time scheme for removing anti and output dependences from loops. <p> The loop is executed in parallel using synchronization (full/empty bits) to enforce flow dependences. To our knowledge, this is the only other run-time privatization technique except <ref> [RP94a, RP94b] </ref>. 85 Recently, Chen, Yew, and Torrellas [CYT94] proposed an inspector that has a private phase and a merging phase. In the private phase, the loop is chunked and each processor builds a list of all the accesses to each memory location for its assigned iterations. <p> 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et al. [SMC91] Yes Yes 4 Yes Yes 5 No Leung/Zahorjan [LZ93] Yes No Yes Yes 5 No Polychronopoulous [Pol88] No No No No No Rauchwerger/Padua <ref> [RP94a, RP94b] </ref> No 6 No No No P,R Table 7.1 A comparison of run-time parallelization techniques for do loops. In the table entries, P and R show that the method identities privatizable and reduction variables, respectively. <p> In Chapters 2 and 3, we have proposed a run-time technique, called the Privatizing doall test (PD test) <ref> [RP94a] </ref> and the more powerful LRPD test [RP95], for detecting the presence of cross-iteration dependences in a loop. This test was originally presented as a method to test at run-time whether a do loop was fully parallel, i.e., whether it could be executed as a doall.
Reference: [RP94b] <author> Lawrence Rauchwerger and David Padua. </author> <title> The LRPD Test: Speculative Run-Time Parallelization of Loops with Privatization and Reduction Parallelization. </title> <type> Technical Report 1390, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing Res. & Dev., </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: If a marking loop cannot be extracted, then the compiler must choose between sequential execution and a speculative parallel execution <ref> [RP94b] </ref>. At Run-Time. 1. At run-time (and possibly also at compile-time) an evaluation of the storage requirements of the methods is performed. <p> These graphs show that the speedup scales with the number of processors and is a significant percentage of the ideal speedup. Below, we discuss each loop in more detail. We remark here that these loops could also be identified by the LRPD test <ref> [RP94a, RP94b] </ref>, a run-time test for identifying fully parallel loops, or loops that can be transformed into doalls using privatization and reduction parallelization. An advantage of the LRPD test is that it has a smaller overhead than the methods we present here. <p> However, when there are no hot spots and the critical path length is very small, then this method should perform well. An advantage of this method is reduced memory requirements: it uses only a shadow version of the shared array under scrutiny whereas all other methods (except <ref> [Pol88, RP94a, RP94b] </ref>) unroll the loop and store all the accesses to the shared array. Krothapalli and Sadayappan [KS88] proposed a run-time scheme for removing anti and output dependences from loops. <p> The loop is executed in parallel using synchronization (full/empty bits) to enforce flow dependences. To our knowledge, this is the only other run-time privatization technique except <ref> [RP94a, RP94b] </ref>. 85 Recently, Chen, Yew, and Torrellas [CYT94] proposed an inspector that has a private phase and a merging phase. In the private phase, the loop is chunked and each processor builds a list of all the accesses to each memory location for its assigned iterations. <p> 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et al. [SMC91] Yes Yes 4 Yes Yes 5 No Leung/Zahorjan [LZ93] Yes No Yes Yes 5 No Polychronopoulous [Pol88] No No No No No Rauchwerger/Padua <ref> [RP94a, RP94b] </ref> No 6 No No No P,R Table 7.1 A comparison of run-time parallelization techniques for do loops. In the table entries, P and R show that the method identities privatizable and reduction variables, respectively.
Reference: [RP94c] <author> Lawrence Rauchwerger and David A. Padua. </author> <title> Parallelizing WHILE Loops for Multiprocessor Systems. </title> <type> Technical Report 1349, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing Res.and Dev., </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: We will limit our discussion below to two input sets: gemat12, which generates 4929 iterations, and bp 1600, which generates 822 iterations. After extracting and precomputing the linear recurrences from the source loop (based on the methods described in <ref> [RP94c] </ref>), we generated a fully parallel inspector and applied our methods to compute an optimal parallel execution schedule for the loop. From the data obtained we constructed the parallelism profiles depicted in Figures 6.5 and 6.6. These profiles depict the size of the wavefronts of the optimal parallel execution schedule.
Reference: [RP95] <author> Lawrence Rauchwerger and David A. Padua. </author> <title> The LRPD Test: Speculative Run-Time Parallelization of Loops with Privatization and Reduction Parallelization. </title> <booktitle> In Proceed 126 ings of the SIGPLAN 1995 Conference on Programming Language Design and Imple--mentation, </booktitle> <address> La Jolla, CA, </address> <pages> pages 218-232, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: In Chapters 2 and 3, we have proposed a run-time technique, called the Privatizing doall test (PD test) [RP94a] and the more powerful LRPD test <ref> [RP95] </ref>, for detecting the presence of cross-iteration dependences in a loop. This test was originally presented as a method to test at run-time whether a do loop was fully parallel, i.e., whether it could be executed as a doall.
Reference: [SBV95] <author> G. S. Sohi, S. Breach, and S. </author> <title> Vajapeyam. </title> <booktitle> Multiscalar processors. In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 414-425, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Some of the latest ones (e.g. PA-RISC from Hewlett Packard) are using a tagged register file that allows speculative loads and enforce flow-dependences. Finally we should mention the new approach taken by G. Sohi at the University of Wisconsin <ref> [SBV95] </ref>. It is a speculative approach for executing iterations of a loop in parallel across multiple functional units.
Reference: [Sch89] <author> E. Schonberg. </author> <title> On-the-fly detection of access anomalies. </title> <booktitle> In Proceedings of the SIGPLAN 1989 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 285-297, </pages> <address> Portland, Oregon, </address> <year> 1989. </year>
Reference-contexts: Since not all anomalies can be detected stat ically, and execution traces can require prohibitive amounts of memory, run-time access anomaly detection methods that minimize memory requirements are desirable <ref> [Sch89, DS90, NR88] </ref>. In fact, a run-time anomaly detection method proposed by Snir, and optimized by Schonberg [Sch89], bears similarities to the version of the doall test presented in Chapter 2 (i.e., the version without the privatization). <p> Since not all anomalies can be detected stat ically, and execution traces can require prohibitive amounts of memory, run-time access anomaly detection methods that minimize memory requirements are desirable [Sch89, DS90, NR88]. In fact, a run-time anomaly detection method proposed by Snir, and optimized by Schonberg <ref> [Sch89] </ref>, bears similarities to the version of the doall test presented in Chapter 2 (i.e., the version without the privatization). However, in order to identify the point in the execution in which the anomaly occurred, their methods [Sch89] require much more memory than the doall test, e.g., viewed in the framework <p> fact, a run-time anomaly detection method proposed by Snir, and optimized by Schonberg <ref> [Sch89] </ref>, bears similarities to the version of the doall test presented in Chapter 2 (i.e., the version without the privatization). However, in order to identify the point in the execution in which the anomaly occurred, their methods [Sch89] require much more memory than the doall test, e.g., viewed in the framework of the doall test, a separate shadow array for each iteration in a loop must be maintained.
Reference: [SLH90] <author> M. D. Smith, M. S. Lam, and M. A. Horowitz. </author> <title> Boosting beyond static scheduling in a superscalar processor. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 344-354, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: However, in this case the compiler could predict the number of iterations using branch statistics, where the branch is on the termination condition of the while loop. Although the application is different, this in not a new idea since branch speculation has been used effectively in superscalar compilers <ref> [MCH + 92, SLH90, TLS90] </ref>. Since branch statistics have already been collected for many benchmarks, these collection mechanisms are available. 8.8 Strategies for Applying the Techniques In the previous section we discussed the speedups and potential slowdowns that can be expected when using our techniques for parallelizing while loops.
Reference: [SM91] <author> J. Saltz and R. Mirchandaney. </author> <title> The preprocessed doacross loop. In Dr. </title> <editor> H.D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 174-178. </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Vol. </title> <booktitle> II Software. </booktitle>
Reference-contexts: Global parallelization, i.e., deeply nested loops containing subroutine calls, is quite often not possible because inter-procedural analysis generates extremely complex expressions that are in the end intractable although statically defined. This thesis will present several new run-time methods some are improvements of previous ones <ref> [BS90, LZ93, MP87, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref> and others represent represent totally new approaches. They collectively constitute an effective framework for run-time parallelization. In the next sections we will be mostly concerned with the parallelism detection side of the compiler. <p> This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> It is imperative that the marking loop be parallel, for otherwise it defeats the purpose of run-time parallelization <ref> [LZ93, SM91] </ref>. (Below, we mention some special circumstances in which speedups might still be obtained using a sequential marking loop.) A parallel marking loop can be obtained if the source loop can be distributed into a loop computing 72 the addresses of the array under test and another loop which uses <p> This is similar to the private marking phase of our inspector except that they serialize read accesses (i.e., they have a list instead of the dependence graph). Next, the lists for each memory location are linked across processors using a global Zhu/Yew algorithm [ZY87]. Their scheduler/executor uses doacross parallelization <ref> [SM91] </ref>, i.e., iterations are started in a wrapped manner and processors busy wait until their operands are ready. Although this scheme potentially has less communication overhead than [ZY87], it is still sensitive to hot spots and there are cases (e.g., doalls) in which it proves inferior to [ZY87]. <p> Thus, if, as would be natural, each processor were assigned one iteration of the outer loop, we would have precisely the situation described above. 7.2.2 Methods for Loops Without Output Dependences The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [BS90, SM91, SMC89, SMC91, WSHB91] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences. <p> The inspector computation (the topological sort) can be parallelized somewhat using the DOACROSS parallelization technique of Saltz and Mirchandaney <ref> [SM91] </ref>, in which processors are assigned iterations in a wrapped manner, and busy-waits are used to ensure that values have been produced before they are used (again, this is only possible if the original loop has no output dependences). 86 Recently, Leung and Zahorjan [LZ93] have proposed some other methods of <p> The offending addresses which are used out of order are stored until all potential hazards have been cleared. If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) <ref> [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87] </ref>, are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops <ref> [LZ93, SM91, SMC91] </ref>, have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components <ref> [Pol88, SM91, SMC91] </ref>, and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) <ref> [CYT94, LZ93, Pol88, SM91, SMC91, ZY87] </ref>. <p> or finds Method schedule portions synchron loop reductions Rauchwerger/Amato/Padua [RAP95] Yes No No No P,R Zhu/Yew [ZY87] No 1 No Yes 2 No No Midkiff/Padua [MP87] Yes No Yes 2 No No Krothapalli/Sadayappan [KS88] No 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney <ref> [SM91] </ref> No 3 No Yes Yes 5 No Saltz et al. [SMC91] Yes Yes 4 Yes Yes 5 No Leung/Zahorjan [LZ93] Yes No Yes Yes 5 No Polychronopoulous [Pol88] No No No No No Rauchwerger/Padua [RP94a, RP94b] No 6 No No No P,R Table 7.1 A comparison of run-time parallelization techniques
Reference: [SMC89] <author> J. Saltz, R. Mirchandaney, and K. Crowley. </author> <title> The doconsider loop. </title> <booktitle> In Proceedings of the 1989 International Conference on Supercomputing, </booktitle> <pages> pages 29-40, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Global parallelization, i.e., deeply nested loops containing subroutine calls, is quite often not possible because inter-procedural analysis generates extremely complex expressions that are in the end intractable although statically defined. This thesis will present several new run-time methods some are improvements of previous ones <ref> [BS90, LZ93, MP87, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref> and others represent represent totally new approaches. They collectively constitute an effective framework for run-time parallelization. In the next sections we will be mostly concerned with the parallelism detection side of the compiler. <p> This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> Thus, if, as would be natural, each processor were assigned one iteration of the outer loop, we would have precisely the situation described above. 7.2.2 Methods for Loops Without Output Dependences The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [BS90, SM91, SMC89, SMC91, WSHB91] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences.
Reference: [SMC91] <author> J. Saltz, R. Mirchandaney, and K. Crowley. </author> <title> Run-time parallelization and scheduling of loops. </title> <journal> IEEE Trans. Comput., </journal> <volume> 40(5), </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: Global parallelization, i.e., deeply nested loops containing subroutine calls, is quite often not possible because inter-procedural analysis generates extremely complex expressions that are in the end intractable although statically defined. This thesis will present several new run-time methods some are improvements of previous ones <ref> [BS90, LZ93, MP87, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref> and others represent represent totally new approaches. They collectively constitute an effective framework for run-time parallelization. In the next sections we will be mostly concerned with the parallelism detection side of the compiler. <p> This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> This is a simple illustration of the schedule reuse technique, in which a correct execution schedule is determined once, and subsequently reused if all of the defining conditions remain invariant (see, e.g., Saltz et al. <ref> [SMC91] </ref>). If it can be determined at compile time that the data access pattern is invariant across different executions of the same loop, then no additional computation is required. <p> In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> Given the original, or source loop, most of these techniques generate inspector code that analyzes, at run-time, the cross-iteration dependences in the loop, and scheduler/executor code that schedules and executes the loop iterations using the dependence information extracted by the inspector <ref> [SMC91] </ref>. While in the previous chapters we have presented an algorithm to parallelize loops that are, or can be made fully parallel (doall), in this chapter we give a new inspector/scheduler/executor method for finding an optimal parallel execution schedule for a partially parallel loop. <p> This is a simple illustration of the schedule reuse technique, in which a correct execution schedule is determined once, and subsequently reused if all of the defining conditions remain invariant (see, e.g., Saltz et al. <ref> [SMC91] </ref>). If it can be determined at compile time that the data access pattern is invariant across different executions of the same loop, then no additional computation is required. <p> Thus, if, as would be natural, each processor were assigned one iteration of the outer loop, we would have precisely the situation described above. 7.2.2 Methods for Loops Without Output Dependences The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [BS90, SM91, SMC89, SMC91, WSHB91] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences. <p> In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences. In <ref> [SMC91] </ref>, the inspector constructs stages that respect the flow dependences by performing a sequential topological sort of the accesses in the loop. The executer enforces any anti-dependences by using old and new versions of each variable. <p> The offending addresses which are used out of order are stored until all potential hazards have been cleared. If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) <ref> [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87] </ref>, are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops <ref> [LZ93, SM91, SMC91] </ref>, have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components <ref> [Pol88, SM91, SMC91] </ref>, and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) <ref> [CYT94, LZ93, Pol88, SM91, SMC91, ZY87] </ref>. <p> No No No P,R Zhu/Yew [ZY87] No 1 No Yes 2 No No Midkiff/Padua [MP87] Yes No Yes 2 No No Krothapalli/Sadayappan [KS88] No 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et al. <ref> [SMC91] </ref> Yes Yes 4 Yes Yes 5 No Leung/Zahorjan [LZ93] Yes No Yes Yes 5 No Polychronopoulous [Pol88] No No No No No Rauchwerger/Padua [RP94a, RP94b] No 6 No No No P,R Table 7.1 A comparison of run-time parallelization techniques for do loops.
Reference: [Smi87] <author> B. J. Smith. </author> <title> A pipelined, shared resource mimd computer. </title> <booktitle> In Proceedings of the 1978 International Conference on Parallel Processing, </booktitle> <year> 1987. </year>
Reference-contexts: During the 1960s, relatively simple run-time techniques, used to detect parallelism between scalar operations, were implemented in the hardware of the CDC 6600 and the IBM 360/91 [Tho71, Tom67]. Later more aggressive designs have incorporated a full-empty bit <ref> [Smi87] </ref> to enforce data dependences on the fly. This type of memory structure has been exploited by the data-flow computing model [AC86, AI86, AN86] in quite an original way. It is probably also the most fundamental model of exploiting parallelism.
Reference: [Tho71] <author> J. E. Thornton. </author> <title> Design of a Computer:The Control Data 6600. </title> <type> Scott, </type> <institution> Foresman, Glenview, Illinois, </institution> <year> 1971. </year>
Reference-contexts: During the 1960s, relatively simple run-time techniques, used to detect parallelism between scalar operations, were implemented in the hardware of the CDC 6600 and the IBM 360/91 <ref> [Tho71, Tom67] </ref>. Later more aggressive designs have incorporated a full-empty bit [Smi87] to enforce data dependences on the fly. This type of memory structure has been exploited by the data-flow computing model [AC86, AI86, AN86] in quite an original way.
Reference: [TLS90] <author> P. Tirumalai, M. Lee, and M. Schlansker. </author> <title> Parallelization of loops with exits on pipelined architectures. </title> <booktitle> In Supercomputing, </booktitle> <month> November </month> <year> 1990. </year>
Reference-contexts: However, in this case the compiler could predict the number of iterations using branch statistics, where the branch is on the termination condition of the while loop. Although the application is different, this in not a new idea since branch speculation has been used effectively in superscalar compilers <ref> [MCH + 92, SLH90, TLS90] </ref>. Since branch statistics have already been collected for many benchmarks, these collection mechanisms are available. 8.8 Strategies for Applying the Techniques In the previous section we discussed the speedups and potential slowdowns that can be expected when using our techniques for parallelizing while loops. <p> Note that the available parallelism, and therefore our obtained speedup, is strongly dependent on the data input. 8.10 Related Work We can find in the literature several efforts in improving the performance of the while loop execution. In <ref> [TLS90] </ref> the authors have proposed some methods for achieving vector-like performance on multiple issue pipelined machines. They do not try to address the problem for large multiprocessors. Some techniques for solving certain types of recurrences in parallel were proposed by Harrison in [Har89] for Lisp-like languages.
Reference: [Tom67] <author> R. M. Tomasulo. </author> <title> An efficient algorithm for exploiting multiple arithmetic units. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 11 </volume> <pages> 25-33, </pages> <month> January </month> <year> 1967. </year>
Reference-contexts: During the 1960s, relatively simple run-time techniques, used to detect parallelism between scalar operations, were implemented in the hardware of the CDC 6600 and the IBM 360/91 <ref> [Tho71, Tom67] </ref>. Later more aggressive designs have incorporated a full-empty bit [Smi87] to enforce data dependences on the fly. This type of memory structure has been exploited by the data-flow computing model [AC86, AI86, AN86] in quite an original way.
Reference: [TP92] <author> P. Tu and D. Padua. </author> <title> Array privatization for shared and distributed memory machines. </title> <booktitle> In Proceedings 2nd Workshop on Languages, Compilers, and Run-Time Environments for Distributed Memory Machines, </booktitle> <month> September </month> <year> 1992. </year> <month> 127 </month>
Reference-contexts: Privatization creates, whenever correct, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [PW86, BCFH89, Li92, MAL92, TP92, TP93] </ref>).
Reference: [TP93] <author> P. Tu and D. Padua. </author> <title> Automatic array privatization. </title> <booktitle> In Proceedings 6th Annual Work--shop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Privatization creates, whenever correct, for each processor cooperating on the execution of the loop, private copies of program variables that give rise to anti or output dependences (see, e.g., <ref> [PW86, BCFH89, Li92, MAL92, TP92, TP93] </ref>). <p> The general strategy of our methods is a fairly straightforward demand driven forward substitution of all the variables on the RHS, a process by which all control flow dependences are substituted by data dependences as described in <ref> [AKPW83, TP93] </ref>. Once this expression of the RHS is obtained it can be analyzed and validated by the methods described in the previous section.
Reference: [TP94] <author> Peng Tu and David Padua. </author> <title> GSA based demand-driven symbolic analysis. </title> <type> Technical Report 1339, </type> <institution> University of Illinois at Urbana-Champaign, Cntr for Supercomputing Res & Dev, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: What is known, however, is the set of all possible RHS forms, which can be computed by following all potential paths in the control flow graph. A direct approach uses a gated static single assignment (GSSA) <ref> [BMO90, TP94] </ref> representation of the program. In such a representation, scalar variables are assigned only once.
Reference: [TZY84] <author> Peiyi Tang, Chuan-Qi Zhu, and Pen-Chung Yew. </author> <title> An Implementation of Cedar Synchronization Primitives. </title> <type> Technical Report 431, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Sci., </institution> <month> April 3, </month> <year> 1984. </year>
Reference-contexts: It is probably also the most fundamental model of exploiting parallelism. Another hardware approach that is useful for run-time parallelization was taken by the Cedar project with its hardware synchronization primitives <ref> [ZYL83, ZY84, TZY84] </ref>. Today, microprocessors are all implementing hardware schemes that permit out-of-order execution while enforcing data dependences. Some of the latest ones (e.g. PA-RISC from Hewlett Packard) are using a tagged register file that allows speculative loads and enforce flow-dependences.
Reference: [Vla82] <author> A. Vladimirescu. </author> <title> LSI Circuit Simulation on Vector Computers. </title> <type> PhD thesis, </type> <institution> Electronics Research Laboratory, University of California, Berkeley, </institution> <month> October </month> <year> 1982. </year> <note> Technical Rept. No. UCB/ERL M82/75. </note>
Reference-contexts: It is important to note that the loop in Fig. 3.5 exemplifies the type of loop found in the SPICE2G6 program (subroutine LOAD) which can account for 70% of the sequential execution time (Its vectorization has been studied before in <ref> [Vla82] </ref>). Finally we mention that reductions such as min, max, etc., would first have to be syntactically pattern matched, and then substituted by the min and max functions. From this perspective, they are more difficult to recognize than simpler arithmetic reductions.
Reference: [Wei84] <author> Mark Weiser. </author> <title> Program slicing. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 10(4) </volume> <pages> 352-357, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: But a relatively simple analysis the compiler can remove duplication. In certain nested loops slicing analysis <ref> [Wei84] </ref> could generate whole sections of arrays that need to be marked. This could either only improve locality or result in a different implementation of the doall test altogether. Instead of using shadow arrays or shadow hash-tables we could use shadow intervals and interval arithmetic for our analysis.
Reference: [WL90] <author> Youfeng Wu and Ted G. Lewis. </author> <title> Parallelizing while loops. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, volume II, Software, </booktitle> <pages> pages 1-8, </pages> <year> 1990. </year>
Reference-contexts: Although the concurrent evaluation of recurrences is in general not possible, some special cases lend themselves to either full or partial parallelization. There are parallel algorithms to solve simple inductions (the case of do loops) <ref> [WL90] </ref> and associative recurrences [CKS78, LF80, Kru85, Kru86] but the evaluation of general recurrences has always been of a sequential nature. <p> These new parallel constructs could be called while-doall, while-doacross, and while-doany and could prove useful in the parallel programming (manual parallelization) of applications. The methods described here extend previous works <ref> [Har86, WL90] </ref> in that they: 1. can handle remainder variant termination conditions, 2. can test at run-time for cross-iteration data dependences in the remainder, 3. do not require work and storage for saving the values computed in the recurrence, 4. support both static and dynamic scheduling, and 5. present a comprehensive <p> The only previous work of which we are aware (except some early work by [Wol89]) for paral-lelizing while loops in languages such as FORTRAN for multiprocessors is due to Wu and Lewis <ref> [WL90] </ref>. One method they propose is to pipeline the loop by executing it in doacross fashion, and to enforce any cross-iteration data dependences with explicit synchronization operations.
Reference: [Wol89] <author> M. Wolfe. </author> <title> Optimizing Compilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference-contexts: Techniques addressing the issue of data dependence analysis have been studied extensively over the last two decades <ref> [PW86, Wol89] </ref> but parallelizing compilers cannot perform a meaningful data dependence analysis and extract a significant fraction of the available parallelism in a loop if it has a complex and/or statically insufficiently defined access pattern. Unfortunately irregular programs, as previously defined, represent a large part of all scientific applications. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [Ban88, KKP + 81, PW86, Wol89, Zim91] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). <p> To aid our analysis of the dispatching recurrence, it is convenient to extract, at least conceptually, this recurrence from the original while loop by distributing <ref> [Wol89] </ref> the original loop into two do loops with conditional exits: 1. A loop that evaluates the terms of the dispatcher (recurrence) and any termination condition that is strongly connected to the dispatcher. 2. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [PW86, KKP + 81, Ban88, Wol89, Zim91] </ref> (see Chapter 2 for a brief introduction to data dependence issues). do i = 1, n if (f (i) .eq. true) then exit A [i] = 2*A [i] enddo (a) if (f (i) .eq. true) then exit s4: tmp = A [2*i] s6: A <p> The only previous work of which we are aware (except some early work by <ref> [Wol89] </ref>) for paral-lelizing while loops in languages such as FORTRAN for multiprocessors is due to Wu and Lewis [WL90]. One method they propose is to pipeline the loop by executing it in doacross fashion, and to enforce any cross-iteration data dependences with explicit synchronization operations.
Reference: [Wol92] <author> M. Wolfe. Doany: </author> <title> Not just another parallel loop. </title> <booktitle> In Proceedings 5th Annual Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <volume> volume 757. </volume> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: In other words the program is designed to be insensitive to the order in which the columns and rows of the matrix are searched for the pivot. Originally, only the row search was parallelized by applying a technique equivalent to a doany construct <ref> [Wol92] </ref>, leaving the traversal of columns in a sequential while loop. We fused the two loops, effectively implementing a new While Doany parallel construct. Through this technique we were able to parallelize the pivot search across the whole matrix.
Reference: [WSHB91] <author> J. Wu, J. Saltz, S. Hiranandani, and H. Berryman. </author> <title> Runtime compilation methods for multicomputers. In Dr. </title> <editor> H.D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 26-30. </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Vol. </title> <booktitle> II Software. </booktitle>
Reference-contexts: Global parallelization, i.e., deeply nested loops containing subroutine calls, is quite often not possible because inter-procedural analysis generates extremely complex expressions that are in the end intractable although statically defined. This thesis will present several new run-time methods some are improvements of previous ones <ref> [BS90, LZ93, MP87, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref> and others represent represent totally new approaches. They collectively constitute an effective framework for run-time parallelization. In the next sections we will be mostly concerned with the parallelism detection side of the compiler. <p> This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> Thus, if, as would be natural, each processor were assigned one iteration of the outer loop, we would have precisely the situation described above. 7.2.2 Methods for Loops Without Output Dependences The problem of analyzing and scheduling loops at run-time has been studied extensively by Saltz et al. <ref> [BS90, SM91, SMC89, SMC91, WSHB91] </ref>. In most of these methods, the original source loop is transformed into an inspector, which performs some run-time data dependence analysis and constructs a (preliminary) schedule, and an executor, which performs the scheduled work. The original source loop is assumed to have no output dependences.
Reference: [Zim91] <author> H. Zima. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <address> New York, New York, </address> <year> 1991. </year>
Reference-contexts: In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [Ban88, KKP + 81, PW86, Wol89, Zim91] </ref>. There are three possible types of dependences between two statements that access the same memory location: flow (read after write), anti (write after read), and output (write after write). <p> One typical method for the case of commutative reductions is to transform the do loop into a doall and enclose the access to the reduction variable in an unordered critical section <ref> [EHLP91, Zim91] </ref> a section of code guarded by a lock unlock operation which allows mutually 9 exclusive operations on the shared variable. Drawbacks of this method are that it is not always scalable and requires synchronizations which can be very expensive in large multiprocessor systems. <p> So far the problem of reduction variable recognition has been handled at compile-time by syntactically pattern matching the loop statements with a template of a generic reduction, and then performing a data dependence analysis of the variable under scrutiny to validate it as a reduction variable <ref> [Zim91] </ref>. There are two major shortcomings of such pattern matching identification methods. 1. The data dependence analysis necessary to qualify a statement as a reduction cannot be performed statically in the presence of input-dependent access patterns. 2. <p> In order to determine whether or not the execution order of the data accesses affects the semantics of the loop, the data dependence relations between the statements in the loop body must be analyzed <ref> [PW86, KKP + 81, Ban88, Wol89, Zim91] </ref> (see Chapter 2 for a brief introduction to data dependence issues). do i = 1, n if (f (i) .eq. true) then exit A [i] = 2*A [i] enddo (a) if (f (i) .eq. true) then exit s4: tmp = A [2*i] s6: A
Reference: [ZY84] <author> Chuan-Qi Zhu and Pen-Chung Yew. </author> <title> A Synchronization Scheme and Its Applications for Large Multiprocessor Systems. </title> <booktitle> Fourth Int'l. Conference on Distributed Computing Systems, </booktitle> <pages> pages 486-493, </pages> <month> May, </month> <year> 1984. </year> <month> 128 </month>
Reference-contexts: It is probably also the most fundamental model of exploiting parallelism. Another hardware approach that is useful for run-time parallelization was taken by the Cedar project with its hardware synchronization primitives <ref> [ZYL83, ZY84, TZY84] </ref>. Today, microprocessors are all implementing hardware schemes that permit out-of-order execution while enforcing data dependences. Some of the latest ones (e.g. PA-RISC from Hewlett Packard) are using a tagged register file that allows speculative loads and enforce flow-dependences.
Reference: [ZY87] <author> C. Zhu and P. C. Yew. </author> <title> A scheme to enforce data dependence on large multiprocessor systems. </title> <journal> IEEE Trans. Softw. Eng., </journal> <volume> 13(6) </volume> <pages> 726-739, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: Global parallelization, i.e., deeply nested loops containing subroutine calls, is quite often not possible because inter-procedural analysis generates extremely complex expressions that are in the end intractable although statically defined. This thesis will present several new run-time methods some are improvements of previous ones <ref> [BS90, LZ93, MP87, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref> and others represent represent totally new approaches. They collectively constitute an effective framework for run-time parallelization. In the next sections we will be mostly concerned with the parallelism detection side of the compiler. <p> This method is centered around the possibility of extracting an inspector loop that analyzes the data access pattern "off-line," i.e., without side effects <ref> [BS90, LZ93, MP87, RP94a, SM91, SMC89, SMC91, WSHB91, ZY87, CYT94] </ref>. <p> In case of larger parallel machines this result would be tilted even more in favor of speculative parallelization. 57 58 59 60 Chapter 6 Run-Time Methods for Parallelizing Partially Parallel Loops 6.1 Introduction The majority of the previous work <ref> [BS90, CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC89, SMC91, WSHB91, ZY87] </ref> in the domain of run-time parallelization has concentrated on developing run-time methods for constructing execution schedules for partially parallel loops, i.e., loops whose parallelization requires synchronization to ensure that the iterations are executed in the correct order. <p> A high level comparison of the various methods is given in Table 7.1. 7.2.1 Methods Utilizing Critical Sections One of the first run-time methods for scheduling partially parallel loops was proposed by Zhu and Yew <ref> [ZY87] </ref>. It computes the wavefronts one after another using a method similar to the simple scheduler described in Section 6.3.1. <p> This is similar to the private marking phase of our inspector except that they serialize read accesses (i.e., they have a list instead of the dependence graph). Next, the lists for each memory location are linked across processors using a global Zhu/Yew algorithm <ref> [ZY87] </ref>. Their scheduler/executor uses doacross parallelization [SM91], i.e., iterations are started in a wrapped manner and processors busy wait until their operands are ready. Although this scheme potentially has less communication overhead than [ZY87], it is still sensitive to hot spots and there are cases (e.g., doalls) in which it proves <p> Next, the lists for each memory location are linked across processors using a global Zhu/Yew algorithm <ref> [ZY87] </ref>. Their scheduler/executor uses doacross parallelization [SM91], i.e., iterations are started in a wrapped manner and processors busy wait until their operands are ready. Although this scheme potentially has less communication overhead than [ZY87], it is still sensitive to hot spots and there are cases (e.g., doalls) in which it proves inferior to [ZY87]. <p> Although this scheme potentially has less communication overhead than <ref> [ZY87] </ref>, it is still sensitive to hot spots and there are cases (e.g., doalls) in which it proves inferior to [ZY87]. For example, consider a loop with cpl = p and dependence distance p as well, i.e., r 0 a = p and u a = n=p so that each processor's iterations access the same set of n=p distinct memory locations. <p> Dependences are detected using shadow versions of the variables, either sequentially, or in parallel with the aid of critical sections as in <ref> [ZY87] </ref>. Another significant contribution to this field has been done by Alex Nicolau in [Nic89]. The idea of run-time disambiguation has been more recently used in optimizing codes for instruction level parallelism [HSS94, GCM + 94]. <p> The offending addresses which are used out of order are stored until all potential hazards have been cleared. If an error is detected repair code will backtrack and restart from that point. In summary, the previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) <ref> [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87] </ref>, are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) [CYT94, LZ93, Pol88, SM91, SMC91, ZY87]. <p> previous run-time methods for parallelizing loops rely heavily on global synchronizations (communication) [CYT94, KS88, LZ93, MP87, Pol88, SM91, SMC91, ZY87], are applicable only to restricted types of loops [LZ93, SM91, SMC91], have significant sequential components [Pol88, SM91, SMC91], and/or do not extract the maximum available parallelism (they make conservative assumptions) <ref> [CYT94, LZ93, Pol88, SM91, SMC91, ZY87] </ref>. <p> Generally, access anomaly detection techniques seek to identify the point in the parallel execution in which the access anomaly occurred. 87 obtains contains requires restricts privatizes optimal sequential global type of or finds Method schedule portions synchron loop reductions Rauchwerger/Amato/Padua [RAP95] Yes No No No P,R Zhu/Yew <ref> [ZY87] </ref> No 1 No Yes 2 No No Midkiff/Padua [MP87] Yes No Yes 2 No No Krothapalli/Sadayappan [KS88] No 3 No Yes 2 No P Chen/Yew/Torrellas [CYT94] No 1;3 No Yes No No Saltz/Mirchandaney [SM91] No 3 No Yes Yes 5 No Saltz et al. [SMC91] Yes Yes 4 Yes Yes
Reference: [ZYL83] <author> Chuan-Qi Zhu, Pen-Chung Yew, and Duncan H. Lawrie. </author> <title> Preliminary Design Specification of the Global Network. </title> <type> Technical Report 374, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Sci., </institution> <month> May 5, </month> <year> 1983. </year> <month> 129 </month>
Reference-contexts: It is probably also the most fundamental model of exploiting parallelism. Another hardware approach that is useful for run-time parallelization was taken by the Cedar project with its hardware synchronization primitives <ref> [ZYL83, ZY84, TZY84] </ref>. Today, microprocessors are all implementing hardware schemes that permit out-of-order execution while enforcing data dependences. Some of the latest ones (e.g. PA-RISC from Hewlett Packard) are using a tagged register file that allows speculative loads and enforce flow-dependences.
References-found: 79

