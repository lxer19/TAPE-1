URL: http://www.cs.wisc.edu/~zhang/sigmodworkshop.ps
Refering-URL: http://www.cs.wisc.edu/~zhang/
Root-URL: 
Email: zhang@cs.wisc.edu  raghu@cs.wisc.edu  miron@cs.wisc.edu  
Title: Interactive Classification of Very Large Datasets with BIRCH  
Author: Tian Zhang Raghu Ramakrishnan Miron Livny 
Affiliation: Computer Sciences Dept. Univ. of Wisconsin-Madison  Computer Sciences Dept. Univ. of Wisconsin-Madison  Computer Sciences Dept. Univ. of Wisconsin-Madison  
Abstract: Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters in a multi-dimensional dataset. Prior work has mostly been in the Statistics and Machine Learning communities, and does not adequately address the problem of large datasets and minimization of I/O costs. BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), is a data clustering algorithm especially suitable for very large datasets. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points. BIRCH can typically find a good clustering with a single scan of the data, and improve the clustering quality further with a few additional scans. It adjusts dynamically to the input dataset to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). In this paper, we demonstrate that BIRCH can be integrated with a data visualization environment (DEVise) to form an highly interactive and iterative data classification tool for classifying real images. The classification includes multiple interactive and iterative steps, and they are (1) feature selection and weighting, (2) clustering, and (3) visualizing. 
Abstract-found: 1
Intro-found: 1
Reference: [CKS88] <author> Peter Cheeseman, James Kelly, Matthew Self, et al., </author> <title> AutoClass : A Bayesian Classification System, </title> <booktitle> Proc. of the 5th Int'l Conf. on Machine Learning, </booktitle> <publisher> Morgan Kaufman, </publisher> <month> Jun. </month> <year> 1988. </year>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics [DH73, DJ80, Lee81, Mur83, Ols93], Machine Learning <ref> [CKS88, Fis87, Fis95, Leb87, SD90] </ref> and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [CLR95] <author> Michael Cheng, Miron Livny, and Raghu Ramakr-ishnan, </author> <title> Visual Analysis of Stream Data, </title> <booktitle> Proc. of IS&T/SPIE Conf. on Visual Data Exploration and Analysis, </booktitle> <address> San Jose, CA, </address> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: because of the rare misplacement problem that we mentioned in Section ??, which might not have been corrected in Phase 3 because the latter is applied on a coarse summary of the data. 7 Data Classification Tool with BIRCH and DEVise BIRCH and DEVise (A Data Exploration via Visualization Environment) <ref> [CLR95] </ref> are integrated as shown in data classification tool.
Reference: [DH73] <author> Richard Duda, and Peter E. Hart, </author> <title> Pattern Classification and Scene Analysis, </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics <ref> [DH73, DJ80, Lee81, Mur83, Ols93] </ref>, Machine Learning [CKS88, Fis87, Fis95, Leb87, SD90] and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [DJ80] <author> R. Dubes, and A.K. Jain, </author> <title> Clustering Methodologies in Exploratory Data Analysis Advances in Computers, Edited by M.C. </title> <journal> Yovits, </journal> <volume> Vol. 19, </volume> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year> <title> 5 filtered from the original image </title>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics <ref> [DH73, DJ80, Lee81, Mur83, Ols93] </ref>, Machine Learning [CKS88, Fis87, Fis95, Leb87, SD90] and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [EKX95a] <author> Martin Ester, Hans-Peter Kriegel, and Xiaowei Xu, </author> <title> A Database Interface for Clustering in Large Spatial Databases, </title> <booktitle> Proc. of 1st Int'l Conf. on Knowledge Discovery and Data Mining, </booktitle> <year> 1995. </year>
Reference-contexts: algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics [DH73, DJ80, Lee81, Mur83, Ols93], Machine Learning [CKS88, Fis87, Fis95, Leb87, SD90] and Databases <ref> [NH94, EKX95a, EKX95b] </ref> communities with different methods and different emphases. Previous approaches, probability-based (like most approaches in Machine 1 Learning) or distance-based (like the work in Statistics as well as Databases), do not adequately consider the case that the dataset can be too large to fit in main memory.
Reference: [EKX95b] <author> Martin Ester, Hans-Peter Kriegel, and Xi-aowei Xu, </author> <title> Knowledge Discovery in Large Spatial Databases: Focusing Techniques for Efficient Class Identification, </title> <booktitle> Proc. of 4th Int'l Symposium on Large Spatial Databases, </booktitle> <address> Portland, Maine, U.S.A., </address> <year> 1995. </year>
Reference-contexts: algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics [DH73, DJ80, Lee81, Mur83, Ols93], Machine Learning [CKS88, Fis87, Fis95, Leb87, SD90] and Databases <ref> [NH94, EKX95a, EKX95b] </ref> communities with different methods and different emphases. Previous approaches, probability-based (like most approaches in Machine 1 Learning) or distance-based (like the work in Statistics as well as Databases), do not adequately consider the case that the dataset can be too large to fit in main memory.
Reference: [Fis87] <author> Douglas H. Fisher, </author> <title> Knowledge Acquisition via Incremental Conceptual Clustering, </title> <journal> Machine Learning, </journal> <volume> 2(2), </volume> <year> 1987 </year>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics [DH73, DJ80, Lee81, Mur83, Ols93], Machine Learning <ref> [CKS88, Fis87, Fis95, Leb87, SD90] </ref> and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [Fis95] <author> Douglas H. Fisher, </author> <title> Iterative Optimization and Simplification of Hierarchical Clusterings, </title> <type> Technical Report CS-95-01, </type> <institution> Dept. of Computer Science, Vander-bilt University, </institution> <address> Nashville, TN 37235. </address>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics [DH73, DJ80, Lee81, Mur83, Ols93], Machine Learning <ref> [CKS88, Fis87, Fis95, Leb87, SD90] </ref> and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [GG92] <author> A. Gersho and R. Gray, </author> <title> Vector quantization and signal compression, </title> <address> Boston, Ma.: </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year>
Reference-contexts: Whatever the algorithm, it can be modified to utilize the information in the CF vectors of the CF tree. 4 DEVise Phase 4 is optional and entails the cost of additional passes over the data. It refines the clusters further by using the Lloyd-kind algorithm <ref> [GG92] </ref> to correct (hopefully minor and localized) inaccuracies that might have been caused because of the rare misplacement problem that we mentioned in Section ??, which might not have been corrected in Phase 3 because the latter is applied on a coarse summary of the data. 7 Data Classification Tool with
Reference: [KR90] <author> Leonard Kaufman, and Peter J. Rousseeuw, </author> <title> Finding Groups in Data An Introduction to Cluster Analysis, </title> <journal> Wiley Series in Probability and Mathematical Statistics, </journal> <year> 1990. </year>
Reference-contexts: An earlier paper about BIRCH has been accepted by SIGMOD 1996 and is to appear on Proc. of SIGMOD 1996. or maximizes the inter-cluster difference. This is a nonconvex discrete <ref> [KR90] </ref> optimization problem. Due to an abundance of local minima, there is typically no way to find a global optimal solution without trying all possible partitions.
Reference: [Leb87] <author> Michael Lebowitz, </author> <title> Experiments with Incremental Concept Formation : UNIMEM, </title> <booktitle> Machine Learning, </booktitle> <year> 1987. </year>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics [DH73, DJ80, Lee81, Mur83, Ols93], Machine Learning <ref> [CKS88, Fis87, Fis95, Leb87, SD90] </ref> and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [Lee81] <author> R.C.T.Lee, </author> <title> Clustering analysis and its applications, </title> <booktitle> Advances in Information Systems Science, Edited by J.T.Toum, </booktitle> <volume> Vol. 8, </volume> <pages> pp. 169-292, </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics <ref> [DH73, DJ80, Lee81, Mur83, Ols93] </ref>, Machine Learning [CKS88, Fis87, Fis95, Leb87, SD90] and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [Mur83] <author> F. Murtagh, </author> <title> A Survey of Recent Advances in Hierarchical Clustering Algorithms, </title> <journal> The Computer Journal, </journal> <year> 1983. </year>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics <ref> [DH73, DJ80, Lee81, Mur83, Ols93] </ref>, Machine Learning [CKS88, Fis87, Fis95, Leb87, SD90] and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [NH94] <author> Raymond T. Ng and Jiawei Han, </author> <title> Efficient and Effective Clustering Methods for Spatial Data Mining, </title> <booktitle> Proc. of VLDB, </booktitle> <year> 1994. </year>
Reference-contexts: algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics [DH73, DJ80, Lee81, Mur83, Ols93], Machine Learning [CKS88, Fis87, Fis95, Leb87, SD90] and Databases <ref> [NH94, EKX95a, EKX95b] </ref> communities with different methods and different emphases. Previous approaches, probability-based (like most approaches in Machine 1 Learning) or distance-based (like the work in Statistics as well as Databases), do not adequately consider the case that the dataset can be too large to fit in main memory.
Reference: [Ols93] <author> Clark F. Olson, </author> <title> Parallel Algorithms for Hierarchical Clustering, </title> <type> Technical Report, </type> <institution> Computer Science Division, Univ. of California at Berkeley, Dec.,1993. </institution>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics <ref> [DH73, DJ80, Lee81, Mur83, Ols93] </ref>, Machine Learning [CKS88, Fis87, Fis95, Leb87, SD90] and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [SD90] <author> Jude W. Shavlik, and Thomas G. Dietterich, </author> <title> editors, </title> <booktitle> Readings in Machine Learning, </booktitle> <publisher> Morgan Kauf-mann, </publisher> <year> 1990. </year>
Reference-contexts: Finally, BIRCH is the first clustering algorithm proposed in the database area that addresses the outlier problem (intuitively, data points that should be regarded as "noise") and proposes a plausible solution. 2 Relevant Research Data clustering has been studied in the Statistics [DH73, DJ80, Lee81, Mur83, Ols93], Machine Learning <ref> [CKS88, Fis87, Fis95, Leb87, SD90] </ref> and Databases [NH94, EKX95a, EKX95b] communities with different methods and different emphases.
Reference: [ZRL96] <author> Tian Zhang, Raghu Ramakrishnan, and Miron Livny, </author> <title> BIRCH: An Efficient Data Clustering Method for Very Large Databases, </title> <booktitle> to appear on Proc. of ACM SIGMOD Conf., </booktitle> <address> p103-114, </address> <month> June, </month> <year> 1996. </year> <month> 6 </month>
Reference-contexts: The I/O cost is linear in the size of the dataset: a single scan of the data yields a good clustering, and one or more additional passes can (optionally) be used to improve the quality further. Through the experiments in <ref> [ZRL96] </ref>, We argue that BIRCH is the best available clustering method for very large datasets in terms of time/space efficiency, data input order sensitivity, and clustering quality.
References-found: 17

