URL: http://www.cs.ucsb.edu/~schauser/papers/93-ifip.ps
Refering-URL: http://www.cs.ucsb.edu/~schauser/papers/
Root-URL: http://www.cs.ucsb.edu
Title: Two Fundamental Limits on Dataflow Multiprocessing  
Author: David E. Culler Klaus Erik Schauser Thorsten von Eicken 
Keyword: dataflow, multiprocessing, multithreading, latency tolerance, storage hierarchy, scheduling hierarchy.  
Abstract: Report No. UCB/CSD 92/716 Computer Science Division University of California, Berkeley Abstract: This paper examines the argument for dataflow architectures in Two Fundamental Issues in Multiprocessing[5]. We observe two key problems. First, the justification of extensive multithreading is based on an overly simplistic view of the storage hierarchy. Second, the local greedy scheduling policy embodied in dataflow is inadequate in many circumstances. A more realistic model of the storage hierarchy imposes significant constraints on the scheduling of computation and requires a degree of parsimony in the scheduling policy. In particular, it is important to establish a scheduling hierarchy that reflects the underlying storage hierarchy. However, even with this improvement, simple local scheduling policies are unlikely to be adequate. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. V. Adve and M. D. Hill. </author> <title> Weak Ordering ANew Definition. </title> <booktitle> In Proc. of the 17th Annual Int'l Symp. on Comp. Arch., </booktitle> <pages> pages 2-14, </pages> <address> Seattle, WA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: Correct treatment of write operations depends heavily on the consistency model assumed. However, even fairly weak consistency models <ref> [1] </ref> require an acknowledgement much like a read. 3 2.3 Extensions of the argument TFI considers two extremes: a conventional processor that idles on remote references and a multithreaded processor in saturation. Saturation occurs when v (R + S) R + L: Our model applies to intermediate design points.
Reference: [2] <author> A. Agarwal, B. Lim, D. Kranz, and J. Kubiatowicz. </author> <month> April: </month> <title> A processor architecture for multiprocessing. </title> <booktitle> In Proc. 17th Annual Int'l Symp. on Comp. Arch., </booktitle> <pages> pages 104-114, </pages> <address> Seattle, WA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: If multiple register sets are provided, then an inexpensive switch can be performed to other resident VPs, but switching to a non-resident VP will incur the cost of a register save/restore, and presumably a trap of some kind <ref> [13, 2] </ref>. In order to increase the number of resident VPs within a fixed number of registers, the number of registers per VP must be reduced [11]. In this case, the cost of data reorganization appears extra instructions to load and unload registers.
Reference: [3] <author> R. Alverson, D. Callahan, D. Cummings, Koblenz B., A. Porterfield, and B. Smith. </author> <title> The Tera Computer System. </title> <booktitle> In Proc. of 1990 Int'l Conf. on Supercomputing, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Switching on every load or on every instruction can be initiated much earlier in the pipeline. This is the primary motivation for interleaved pipelines, as in Hep [15], Tera <ref> [3] </ref>, and Monsoon [16]). However, in these machines there are really two kinds of switches. When the switch does not involve a remote access, the VP immediately re-enters the pipeline. On a remote reference the essential state of the VP is packaged and delivered into the network with the request. <p> Since the size of the top level of the storage hierarchy determines the amount of latency that can be effectively tolerated, what if the top level is simply eliminated? This is essentially the approach adopted in HEP [15] and Tera <ref> [3] </ref>, which use register addressing modes to access a sizable SRAM. The register access requires multiple cycles, but by interleaving VPs across multiple banks a new access can be initiated every cycle. The top level of the physical storage hierarchy contains only pipeline latches.
Reference: [4] <author> Arvind and R. A. </author> <title> Iannucci. A Critique of Multiprocessing von Neumann Style. </title> <booktitle> In Proc. of the 10th Annual Int'l Symp. on Comp. Arch., </booktitle> <address> Sweden, </address> <month> June </month> <year> 1983. </year>
Reference-contexts: 1 Introduction The advantages of dataflow architectures were argued persuasively in a seminal 1983 paper by Arvind and Iannucci <ref> [4] </ref> and in a 1987 revision entitled Two Fundamental Issues in Multiprocessing [5]. However, reality has proved less favorable to this approach than their arguments would suggest.
Reference: [5] <author> Arvind and R. A. </author> <title> Iannucci. Two Fundamental Issues in Multiprocessing. </title> <booktitle> In Proc. of DFVLR - Conf. 1987 on Par. Proc. in Science and Eng., </booktitle> <address> Bonn-Bad Godesberg, </address> <publisher> W. </publisher> <address> Germany, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: 1 Introduction The advantages of dataflow architectures were argued persuasively in a seminal 1983 paper by Arvind and Iannucci [4] and in a 1987 revision entitled Two Fundamental Issues in Multiprocessing <ref> [5] </ref>. However, reality has proved less favorable to this approach than their arguments would suggest. This motivates us to examine the line of reasoning that has driven dataflow architectures and fine-grain multithreading to understand where the argument went awry. We observe two key problems. <p> Thus, the cost of synchronization and the ability to tolerate latency are closely linked. If the latency is long compared to the time between remote references, the processor must issue additional remote references before the first completes. The processor must view the memory/communication system as a logical pipeline <ref> [5] </ref>. Multiple remote references may be outstanding at once. These requests are likely to complete out of order, since some will follow shorter paths in the network than others or encounter less contention. Therefore, a fairly general synchronization mechanism is required to coordinate each response with the appropriate request.
Reference: [6] <author> S. A. Brobst. </author> <title> Instruction scheduling and token storage requirements in a dataflow supercomputer. </title> <type> Master's thesis, </type> <institution> Dept. of EECS, MIT, </institution> <address> Cambridge, MA, </address> <month> May </month> <year> 1986. </year>
Reference-contexts: Once the number of VPs exceeds the capacity of the top level matching store, the synchronization cost increases dramatically, since some form of overflow store must be used <ref> [12, 6] </ref>. In dataflow models the problem is made more severe by the lack of distinction between long lived call-frame storage and short lived register storage.
Reference: [7] <author> D. Culler, A. Sah, K. Schauser, T. von Eicken, and J. Wawrzynek. </author> <title> Fine-grain Parallelism with Minimal Hardware Support: A Compiler-Controlled Threaded Abstract Machine. </title> <booktitle> In Proc. of 4th Int'l Conf. on Arch. Support for Prog. Lang. and Op. Sys., </booktitle> <address> Santa-Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Therefore, it is desirable to bias the scheduling towards switching among related VPs first. 7 4.1 The Threaded Abstract Machine The Threaded Abstract Machine (TAM) provides a well defined compilation framework in which the above optimizations are available <ref> [7] </ref>. It eliminates the notion of VPs multiplexed onto a physical processor and instead exposes the fixed physical processor resources. Furthermore, the scheduling of computation is exposed, allowing the compiler to favor switching among related computations or to take special action when this is not possible.
Reference: [8] <author> D. E. Culler. </author> <title> Multithreading: Fundamental Limits, Potential Gains, and Alternatives. </title> <booktitle> In Proc. of the Supercom-puting91 Workshop on Multithreading, </booktitle> <year> 1992. </year> <note> (to appear). </note>
Reference-contexts: A more detailed analytical model can be found in the references [18]. Also, we will optimistically assume that the network can support the remote request rate <ref> [8] </ref>. 2 We pose the argument in terms of reads, since the need to wait for the resulting data is obvious. Correct treatment of write operations depends heavily on the consistency model assumed.
Reference: [9] <author> D. E. Culler and Arvind. </author> <title> Resource Requirements of Dataflow Programs. </title> <booktitle> In Proc. of the 15th Annual Int'l Symp. on Comp. Arch., </booktitle> <pages> pages 141-150, </pages> <address> Hawaii, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: In dataflow models the problem is made more severe by the lack of distinction between long lived call-frame storage and short lived register storage. Throttling [17] and k-bounding <ref> [9] </ref> were introduced to constrain the parallelism in dataflow programs so that the VPs would fit within a modest matching store. The Hybrid proposal [14] makes a clear distinction between call-frame and register storage, and places the requirement that registers must be vacant at the point of a potential switch. <p> TAM exposes the scheduling queue, so the mechanism exists, however, it remains an open question how this high-level direction should be applied in a consistent manner. Acceleration of the local, naive dynamic scheduling mechansism through hardware enhancements has no impact on this fundamental problem. Work on k-bounded loops <ref> [9] </ref> and throttling [17] is a step in the right direction, but neither of these approaches has fully considered that scheduling of computation must compete for resources with the computation.
Reference: [10] <author> D. E. Culler and G. M. Papadopoulos. </author> <title> The Explicit Token Store. </title> <journal> Journal of Parallel and Distributed Computing, </journal> (10):289-308, January 1990. 
Reference-contexts: Thus, it is claimed that dataflow models provide superior latency tolerance. Arvind and Iannucci suggest that this advantage will carry forward to thread-based dataflow models, with no saving/restoring of state, e.g., Hybrid [14], SCB [19], and ETS <ref> [10] </ref>. Today, it is widely accepted that if chunks of computation are 2 assigned to processors then the latency on certain communication steps is neither long nor unpredictable.
Reference: [11] <author> W. Dally. </author> <title> Virtual Channel Flow Control. </title> <booktitle> In Proc. of the 17th Annual Int'l Symp. on Comp. Arch., </booktitle> <address> Seattle, WA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: In order to increase the number of resident VPs within a fixed number of registers, the number of registers per VP must be reduced <ref> [11] </ref>. In this case, the cost of data reorganization appears extra instructions to load and unload registers. The other latency tolerant proposals obscure the cost of synchronization more deeply, so more careful examination is required.
Reference: [12] <author> J. Gurd, C.C. Kirkham, and I. Watson. </author> <title> The Manchester Prototype Dataflow Computer. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 28(1) </volume> <pages> 34-52, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: Once the number of VPs exceeds the capacity of the top level matching store, the synchronization cost increases dramatically, since some form of overflow store must be used <ref> [12, 6] </ref>. In dataflow models the problem is made more severe by the lack of distinction between long lived call-frame storage and short lived register storage.
Reference: [13] <author> R. H. Halstead, Jr. and T. Fujita. MASA: </author> <title> a Multithreaded Processor Architecture for Parallel Symbolic Computing. </title> <booktitle> In Proc. of the 15th Int'l Symp. on Comp. Arch., </booktitle> <pages> pages 443-451, </pages> <year> 1988. </year>
Reference-contexts: If multiple register sets are provided, then an inexpensive switch can be performed to other resident VPs, but switching to a non-resident VP will incur the cost of a register save/restore, and presumably a trap of some kind <ref> [13, 2] </ref>. In order to increase the number of resident VPs within a fixed number of registers, the number of registers per VP must be reduced [11]. In this case, the cost of data reorganization appears extra instructions to load and unload registers.
Reference: [14] <author> R. A. </author> <title> Iannucci. Toward a Dataflow/von Neumann Hybrid Architecture. </title> <booktitle> In Proc. 15th Annual Int'l Symp. on Comp. Arch., </booktitle> <pages> pages 131-140, </pages> <address> Hawaii, </address> <month> May </month> <year> 1988. </year> <month> 13 </month>
Reference-contexts: Thus, it is claimed that dataflow models provide superior latency tolerance. Arvind and Iannucci suggest that this advantage will carry forward to thread-based dataflow models, with no saving/restoring of state, e.g., Hybrid <ref> [14] </ref>, SCB [19], and ETS [10]. Today, it is widely accepted that if chunks of computation are 2 assigned to processors then the latency on certain communication steps is neither long nor unpredictable. <p> Throttling [17] and k-bounding [9] were introduced to constrain the parallelism in dataflow programs so that the VPs would fit within a modest matching store. The Hybrid proposal <ref> [14] </ref> makes a clear distinction between call-frame and register storage, and places the requirement that registers must be vacant at the point of a potential switch. Thus, registers are saved and restored in defense as part of code generation.
Reference: [15] <author> H. F. Jordan. </author> <title> Performance Measurement on HEP A Pipelined MIMD Computer. </title> <booktitle> In Proc. of the 10th Annual Int'l Symp. on Comp. Arch., </booktitle> <address> Stockholm, Sweden, </address> <month> June </month> <year> 1983. </year>
Reference-contexts: Switching cheaply on a cache miss is rather difficult, for example, because the miss is discovered very late in the processor pipeline. Switching on every load or on every instruction can be initiated much earlier in the pipeline. This is the primary motivation for interleaved pipelines, as in Hep <ref> [15] </ref>, Tera [3], and Monsoon [16]). However, in these machines there are really two kinds of switches. When the switch does not involve a remote access, the VP immediately re-enters the pipeline. <p> Since the size of the top level of the storage hierarchy determines the amount of latency that can be effectively tolerated, what if the top level is simply eliminated? This is essentially the approach adopted in HEP <ref> [15] </ref> and Tera [3], which use register addressing modes to access a sizable SRAM. The register access requires multiple cycles, but by interleaving VPs across multiple banks a new access can be initiated every cycle. The top level of the physical storage hierarchy contains only pipeline latches.
Reference: [16] <author> G. M. Papadopoulos and D. E. Culler. Monsoon: </author> <title> an Explicit Token-Store Architecture. </title> <booktitle> In Proc. of the 17th Annual Int'l Symp. on Comp. Arch., </booktitle> <address> Seattle, WA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: Switching on every load or on every instruction can be initiated much earlier in the pipeline. This is the primary motivation for interleaved pipelines, as in Hep [15], Tera [3], and Monsoon <ref> [16] </ref>). However, in these machines there are really two kinds of switches. When the switch does not involve a remote access, the VP immediately re-enters the pipeline. On a remote reference the essential state of the VP is packaged and delivered into the network with the request. <p> Thus, registers are saved and restored in defense as part of code generation. The true synchronization cost is the accumulation of the artificial data movement. This is obscured in Hybrid by the inclusion of memory addressing modes. Monsoon <ref> [16] </ref> provides a similar two-level store with more of the traditional dataflow structure. It recognizes that the dataflow matching store must be large and implements it as a directly addressed static RAM under the ETS frame-based execution model.
Reference: [17] <author> C. A. Ruggiero. </author> <title> Throttle Mechanisms for the Manchester Dataflow Machine. </title> <type> PhD thesis, </type> <institution> University of Manch-ester, </institution> <address> Manchester M13 9PL, England, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: In dataflow models the problem is made more severe by the lack of distinction between long lived call-frame storage and short lived register storage. Throttling <ref> [17] </ref> and k-bounding [9] were introduced to constrain the parallelism in dataflow programs so that the VPs would fit within a modest matching store. <p> Acceleration of the local, naive dynamic scheduling mechansism through hardware enhancements has no impact on this fundamental problem. Work on k-bounded loops [9] and throttling <ref> [17] </ref> is a step in the right direction, but neither of these approaches has fully considered that scheduling of computation must compete for resources with the computation.
Reference: [18] <author> R. Saavedra-Barrerra, D. E. Culler, and T. von Eicken. </author> <title> Analysis of Multithreaded Architectures for Parallel Computing. </title> <booktitle> In Proceedings of the 2nd Annual Symp. on Par. Algorithms and Arch., </booktitle> <month> July </month> <year> 1990. </year>
Reference-contexts: A more detailed analytical model can be found in the references <ref> [18] </ref>. Also, we will optimistically assume that the network can support the remote request rate [8]. 2 We pose the argument in terms of reads, since the need to wait for the resulting data is obvious. Correct treatment of write operations depends heavily on the consistency model assumed.
Reference: [19] <author> S. Sakai, Y. Yamaguchi, K. Hiraki, Y. Kodama, and T. Yuba. </author> <title> An Architecture of a Dataflow Single Chip Processor. </title> <booktitle> In Proc. of the 16th Annual Int'l Symp. on Comp. Arch., </booktitle> <address> Jerusalem, Israel, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Thus, it is claimed that dataflow models provide superior latency tolerance. Arvind and Iannucci suggest that this advantage will carry forward to thread-based dataflow models, with no saving/restoring of state, e.g., Hybrid [14], SCB <ref> [19] </ref>, and ETS [10]. Today, it is widely accepted that if chunks of computation are 2 assigned to processors then the latency on certain communication steps is neither long nor unpredictable.
Reference: [20] <author> K. Schauser, D. Culler, and T. von Eicken. </author> <title> Compiler-controlled Multithreading for Lenient Parallel Languages. </title> <booktitle> In Proc. of the 1991 Conf. on Functional Prog. Lang. and Comp. Arch., </booktitle> <address> Cambridge, MA, </address> <month> Aug. </month> <year> 1991. </year> <month> 14 </month>
Reference-contexts: A TAM thread is a sequence of instructions that, once scheduled, executes to completion without suspension. To form threads, the compiler analyzes the control and data dependences, groups instructions that can be enabled together into partitions <ref> [20] </ref>, and forms TAM threads using traditional instruction scheduling and register allocation algorithms to maximize pipeline utilization. It is usually desirable to create as large threads as possible. Since a thread can never use the result of a remote reference it issues, the remote reference rate fundamentally limits thread size.
References-found: 20

