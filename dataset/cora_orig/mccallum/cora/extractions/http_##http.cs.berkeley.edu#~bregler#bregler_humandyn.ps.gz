URL: http://http.cs.berkeley.edu/~bregler/bregler_humandyn.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~bregler/pubs.html
Root-URL: 
Email: bregler@cs.berkeley.edu  
Title: Learning and Recognizing Human Dynamics in Video Sequences  
Author: Christoph Bregler 
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division University of California, Berkeley  
Date: June 1997  
Note: Proc. IEEE Conf. Comp. Vision and Pattern Recognition, San Juan, Puerto Rico,  
Abstract: This paper describes a probabilistic decomposition of human dynamics at multiple abstractions, and shows how to propagate hypotheses across space, time, and abstraction levels. Recognition in this framework is the succession of very general low level grouping mechanisms to increased specific and learned model based grouping techniques at higher levels. Hard decision thresholds are delayed and resolved by higher level statistical models and temporal context. Low-level primitives are areas of coherent motion found by EM clustering, mid-level categories are simple movements represented by dynamical systems, and high-level complex gestures are represented by Hidden Markov Models as successive phases of simple movements. We show how such a representation can be learned from training data, and apply it to the example of human gait recognition. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Serge Ayer and Harpreet S. Sawhney. </author> <title> Layered representation of motion video using robust maximum-likelihood estimation of mixture models and mdl encoding. </title> <booktitle> In Int. Conf. Computer Vision, </booktitle> <pages> pages 777-784, </pages> <address> Cambridge, MA., </address> <year> 1995. </year>
Reference-contexts: If the number of blobs is K, the domain of S (x; y) 2 f1; 2; :::; Kg. This leads to a representation that is already used in so called layered motion approaches <ref> [29, 17, 1] </ref>. Simultaneously the labels S (x; y) and the motion, color, and spatial parameters can be estimated using the Expectation Maximization (EM) maximum likelihood [9]. There are various ways to determine the number of layers K as well [1, 29]. <p> Simultaneously the labels S (x; y) and the motion, color, and spatial parameters can be estimated using the Expectation Maximization (EM) maximum likelihood [9]. There are various ways to determine the number of layers K as well <ref> [1, 29] </ref>. Our approach differs in the way it also incorporates past histories of groupings in earlier frames, and how it encodes spatial proximity. The set of blob hypotheses for a given image frame I (t) are represented as a mixture of multivariate Gaussians (t).
Reference: [2] <author> Y. Bar-Shalom and T. E. Fortmann. </author> <title> Tracking and Data Association. </title> <publisher> Academic Press, </publisher> <year> 1987. </year>
Reference-contexts: Kalman filters <ref> [2] </ref> are the obvious choice for computing such priors in a recursive way. The state space of the filter are the blob parameters (t).
Reference: [3] <author> M.J. Black and Y. Yacoob. </author> <title> Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: Some of these techniques use HMMs to cover the temporal structure. [22] propose a technique that looks for appearance based periodicity, and [11] measure spatio-temporal angle histograms to recognize hand gestures. Motion based recognition techniques were presented in <ref> [8, 10, 3] </ref>, and a system based on color blobs is described in [30]. Some systems ignore the low-level feature extraction and only focus on higher level representations and recognition strategies [6, 13].
Reference: [4] <author> A. Blake, M. Isard, and D. Reynard. </author> <title> Learning to track the visual motion of contours. </title> <editor> In J. </editor> <booktitle> Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: If it is known a-priori what specific motion is been tracked, better choices would be domain specific dynamical models learned from training data. The good performance of such models has been shown on spline based tracking of edge segments <ref> [4] </ref>. In our case, we don't know yet at this abstraction level which blob performs what specific motion. For example the lower leg segment during a certain phase of a running cycle complies to a different linear dynamical model then the upper arm segment during a different gesture. <p> A complex gesture word should be composed out of simple movemes. To compute the probability D m (t; k) that a certain blob k (t) belongs to one of the dynamical categories m, the following notation of a discrete 2nd order stochastic dynamical system is used <ref> [4] </ref>: Q (t) = A1 m Q (t 2) + A0 m Q (t 1) + B m w (11) The state variable Q (t) is the motion estimate of the specific blob k (t). w is the system noise, and C m = B m B T m is the <p> In this case, following log likelihood function is maximized for each interval (i.e. dynamical model) separately (using the notation in <ref> [4] </ref>): L linear (Q (t); Q (t + 1); :::; Q (t + d)j m ) = 2 n=t+2 (d 2) log jBj (15) Not knowing such a partition a-priori, we apply an iterative system identification technique, that is an extension of the Baum Welch HMM estimation algorithm [23] (another incarnation
Reference: [5] <author> A.F. Bobick and A.D. Wilson. </author> <title> A state-based technique for the summarization and recognition of gesture. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Systems that deal with real input data and edge fitting to explicit structural models are reported by [15, 25, 12, 24, 19]. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations <ref> [7, 5, 28, 31] </ref>. Some of these techniques use HMMs to cover the temporal structure. [22] propose a technique that looks for appearance based periodicity, and [11] measure spatio-temporal angle histograms to recognize hand gestures.
Reference: [6] <author> L.W. Campbell and A.F. Bobick. </author> <title> Recognition of human body motion using phase space constraints. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: Motion based recognition techniques were presented in [8, 10, 3], and a system based on color blobs is described in [30]. Some systems ignore the low-level feature extraction and only focus on higher level representations and recognition strategies <ref> [6, 13] </ref>. Most explicit model approaches assume certain domain constraints, like calibrated cameras, known background, initial pose, and uncluttered environments that make edge matching feasible. In contrast, most appearance based techniques do not impose such constraints but are very specialized to the given training data.
Reference: [7] <author> T.J. Darrell and A.P. Pentland. </author> <title> Classifying hand gestures with a view-based distributed representation. </title> <booktitle> In NIPS, </booktitle> <year> 1994. </year>
Reference-contexts: Systems that deal with real input data and edge fitting to explicit structural models are reported by [15, 25, 12, 24, 19]. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations <ref> [7, 5, 28, 31] </ref>. Some of these techniques use HMMs to cover the temporal structure. [22] propose a technique that looks for appearance based periodicity, and [11] measure spatio-temporal angle histograms to recognize hand gestures.
Reference: [8] <author> J.W. Davis and A.F. Bobick. </author> <title> Real-time recognition of activity using temporal templates. </title> <booktitle> In to appear in Workshop on Applications of Computer Vision, </booktitle> <year> 1996. </year>
Reference-contexts: Some of these techniques use HMMs to cover the temporal structure. [22] propose a technique that looks for appearance based periodicity, and [11] measure spatio-temporal angle histograms to recognize hand gestures. Motion based recognition techniques were presented in <ref> [8, 10, 3] </ref>, and a system based on color blobs is described in [30]. Some systems ignore the low-level feature extraction and only focus on higher level representations and recognition strategies [6, 13].
Reference: [9] <author> A.P. Dempster, N.M. Laird, and D.B. Rubin. </author> <title> Maximum likelihood from incomplete data via the em algorithm. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> 39(B), </volume> <year> 1977. </year>
Reference-contexts: This leads to a representation that is already used in so called layered motion approaches [29, 17, 1]. Simultaneously the labels S (x; y) and the motion, color, and spatial parameters can be estimated using the Expectation Maximization (EM) maximum likelihood <ref> [9] </ref>. There are various ways to determine the number of layers K as well [1, 29]. Our approach differs in the way it also incorporates past histories of groupings in earlier frames, and how it encodes spatial proximity. <p> The M-step then computes so-to-speak optical flow on these tile super-pixels. The next E-step refines the support maps, and the next M-step refines the motion parameters for the new support maps. It has been proved that the likelihood (2) is non-decreasing at each iteration <ref> [9] </ref>. If it does not increase, it is at a convergence point. models covering the lower and upper leg of a runner.
Reference: [10] <author> I.A. Essa and A.P. Pentland. </author> <title> Facial expression recognition using a dynamic model and motion energy. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: Some of these techniques use HMMs to cover the temporal structure. [22] propose a technique that looks for appearance based periodicity, and [11] measure spatio-temporal angle histograms to recognize hand gestures. Motion based recognition techniques were presented in <ref> [8, 10, 3] </ref>, and a system based on color blobs is described in [30]. Some systems ignore the low-level feature extraction and only focus on higher level representations and recognition strategies [6, 13].
Reference: [11] <author> W. Freeman and M. Roth. </author> <title> Orientation histograms for hand gesture recognition. </title> <booktitle> In International Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: Common representations are space-time curves [20], and appearance based representations [7, 5, 28, 31]. Some of these techniques use HMMs to cover the temporal structure. [22] propose a technique that looks for appearance based periodicity, and <ref> [11] </ref> measure spatio-temporal angle histograms to recognize hand gestures. Motion based recognition techniques were presented in [8, 10, 3], and a system based on color blobs is described in [30]. Some systems ignore the low-level feature extraction and only focus on higher level representations and recognition strategies [6, 13].
Reference: [12] <author> D.M. Gavrila and L.S. Davis. </author> <title> Towards 3-d model-based tracking and recognition of human movement: a multi-view approach. </title> <booktitle> In Proc. of the Int. Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <address> Zurich, </address> <year> 1995, 1995. </year>
Reference-contexts: The earliest computer vision attempt to recognize human movements was reported in O'Rouke and Badler [21] working on synthetic images using constraint satisfaction techniques. Systems that deal with real input data and edge fitting to explicit structural models are reported by <ref> [15, 25, 12, 24, 19] </ref>. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations [7, 5, 28, 31].
Reference: [13] <author> N. H. Goddard. </author> <title> The Perception of Articulated Motion: Recgonizing Moving Light Displays. </title> <type> PhD thesis, </type> <institution> Dept. of Comp.Sci., Univ. Rochester, </institution> <year> 1992. </year>
Reference-contexts: Motion based recognition techniques were presented in [8, 10, 3], and a system based on color blobs is described in [30]. Some systems ignore the low-level feature extraction and only focus on higher level representations and recognition strategies <ref> [6, 13] </ref>. Most explicit model approaches assume certain domain constraints, like calibrated cameras, known background, initial pose, and uncluttered environments that make edge matching feasible. In contrast, most appearance based techniques do not impose such constraints but are very specialized to the given training data.
Reference: [14] <author> Peter J. Green. </author> <title> On use of the EM algorithm for penalized likelihood estimation. </title> <journal> Journal of the Royal Statistical Society, B, </journal> <volume> 52(3) </volume> <pages> 443-452, </pages> <year> 1990. </year>
Reference-contexts: The mid-level grouping into dynamical categories is done 1 <ref> [14] </ref> have shown a straightforward method,how to extent EM for maximum a-posteriori (originally EM is only defined for maximum-likelihood without model priors).
Reference: [15] <author> D. Hogg. </author> <title> A program to see a walking person. </title> <journal> Image Vision Computing, </journal> <volume> 5(20), </volume> <year> 1983. </year>
Reference-contexts: The earliest computer vision attempt to recognize human movements was reported in O'Rouke and Badler [21] working on synthetic images using constraint satisfaction techniques. Systems that deal with real input data and edge fitting to explicit structural models are reported by <ref> [15, 25, 12, 24, 19] </ref>. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations [7, 5, 28, 31].
Reference: [16] <author> M. Isard and A. Blake. </author> <title> Contour tracking by stochasitc propagation of conditional density. </title> <booktitle> In Proc. </booktitle> <address> ECCV, </address> <year> 1996. </year>
Reference-contexts: Besides viewing this method of blob segmentation as a MAP-EM estimate, where the Kalman filter provides the priors, we also can present this method as propagating a multinomial distribution (mixtures of Gaussians) of the system state (t) through time. This has relationships with the recently proposed condensation tracker <ref> [16] </ref>. Making only generic assumtions about the domain, the dynamical system equation of the Kalman filter is chosen to be a constant velocity update of the motion and spatial parameters.
Reference: [17] <author> A. Jepson and M.J. Black. </author> <title> Mixture models for optical flow computation. </title> <booktitle> In Proc. IEEE Conf. Computer VIsion Pattern Recognition, </booktitle> <pages> pages 760-761, </pages> <address> New York, </address> <year> 1993. </year>
Reference-contexts: If the number of blobs is K, the domain of S (x; y) 2 f1; 2; :::; Kg. This leads to a representation that is already used in so called layered motion approaches <ref> [29, 17, 1] </ref>. Simultaneously the labels S (x; y) and the motion, color, and spatial parameters can be estimated using the Expectation Maximization (EM) maximum likelihood [9]. There are various ways to determine the number of layers K as well [1, 29].
Reference: [18] <author> G. Johansson. </author> <title> Visual perception of biological motion and a model for its analysis. </title> <journal> Perception and Psychophysics, </journal> <volume> 14 </volume> <pages> 201-211, </pages> <year> 1973. </year>
Reference-contexts: It was classified incorrectly as running. We are currently performing more experiments on larger datasets to further verify this very encouraging classification performance. 4 Related Work One influential paper to many other motion-based approaches is the classic Moving Light Display experiments by Johansson <ref> [18] </ref>. Seeing lights attached to the joints of an actor, human subjects were able to distinguish human gaits, dance styles, stair climbing, or even can identify gender or idendity.
Reference: [19] <author> M.K. Leung and Y.H. Yang. </author> <title> First sight: A human body outline labeling system. </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <volume> 17(4) </volume> <pages> 359-377, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: The earliest computer vision attempt to recognize human movements was reported in O'Rouke and Badler [21] working on synthetic images using constraint satisfaction techniques. Systems that deal with real input data and edge fitting to explicit structural models are reported by <ref> [15, 25, 12, 24, 19] </ref>. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations [7, 5, 28, 31].
Reference: [20] <author> S. A. Niyogi and E.H. Adelson. </author> <title> Analyzing and recognizing walking figures in xyt. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recogn., </journal> <pages> pages 469-474, </pages> <address> Seattle, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: Systems that deal with real input data and edge fitting to explicit structural models are reported by [15, 25, 12, 24, 19]. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves <ref> [20] </ref>, and appearance based representations [7, 5, 28, 31]. Some of these techniques use HMMs to cover the temporal structure. [22] propose a technique that looks for appearance based periodicity, and [11] measure spatio-temporal angle histograms to recognize hand gestures.
Reference: [21] <author> J. O'Rourke and N. I. Badler. </author> <title> Model-based image analysis of human motion using constraint propagation. </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <volume> 2(6) </volume> <pages> 522-536, </pages> <month> November </month> <year> 1980. </year>
Reference-contexts: Seeing lights attached to the joints of an actor, human subjects were able to distinguish human gaits, dance styles, stair climbing, or even can identify gender or idendity. The earliest computer vision attempt to recognize human movements was reported in O'Rouke and Badler <ref> [21] </ref> working on synthetic images using constraint satisfaction techniques. Systems that deal with real input data and edge fitting to explicit structural models are reported by [15, 25, 12, 24, 19]. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences.
Reference: [22] <author> R. Polana and R. Nelson. </author> <title> Detecting activities. </title> <journal> In Proc. IEEE Com-put. Soc. Conf. Comput. Vision and Pattern Recogn., </journal> <year> 1993. </year>
Reference-contexts: Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations [7, 5, 28, 31]. Some of these techniques use HMMs to cover the temporal structure. <ref> [22] </ref> propose a technique that looks for appearance based periodicity, and [11] measure spatio-temporal angle histograms to recognize hand gestures. Motion based recognition techniques were presented in [8, 10, 3], and a system based on color blobs is described in [30].
Reference: [23] <author> L. R. Rabiner. </author> <title> A tutorial on hidden markov models and selected applications in speech recogntion. </title> <booktitle> In Readings in Speech Recogntion, </booktitle> <year> 1989. </year>
Reference-contexts: Unlike in the lower level groupings across space (x; y) in which we only compute a local maximum, we can compute across time t the global best segmentation using dynamic programming. The forward-backward <ref> [23] </ref> procedure provides a recursive (linear complexity over time) estimate that a complex motion model HMM i fits a track: P (HMM i j8mD m (t; k); :::D m (1; k)) = m (12) where ff (m; t) := P (D m (t; k)j8nD n (t1; k); :::D n (1; k); <p> notation in [4]): L linear (Q (t); Q (t + 1); :::; Q (t + d)j m ) = 2 n=t+2 (d 2) log jBj (15) Not knowing such a partition a-priori, we apply an iterative system identification technique, that is an extension of the Baum Welch HMM estimation algorithm <ref> [23] </ref> (another incarnation of EM). <p> of a set of M dynamical systems and the corresponding HMM: L hybrid (Q (1); :::; Q (T )j 1 ; :::; M ; TR HMM ) = log ( partition P (Q (1):::; Q (T )jpartition; 1 ; :::; M ) P (partitionjTR HMM )) (16) As shown in <ref> [23] </ref>, we don't need to sum over all possible partitions in (16) to converge to a local maximum of the log likelihood.
Reference: [24] <author> J.M. Regh and T. Kanade. </author> <title> Model-based tracking of self-occluding articulated objects. </title> <booktitle> In Proc. Int. Conf. Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: The earliest computer vision attempt to recognize human movements was reported in O'Rouke and Badler [21] working on synthetic images using constraint satisfaction techniques. Systems that deal with real input data and edge fitting to explicit structural models are reported by <ref> [15, 25, 12, 24, 19] </ref>. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations [7, 5, 28, 31].
Reference: [25] <author> K. Rohr. </author> <title> Incremental recognition of pedestrians from image sequences. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recogn., </journal> <pages> pages 8-13, </pages> <address> New York City, </address> <month> June, </month> <year> 1993. </year>
Reference-contexts: The earliest computer vision attempt to recognize human movements was reported in O'Rouke and Badler [21] working on synthetic images using constraint satisfaction techniques. Systems that deal with real input data and edge fitting to explicit structural models are reported by <ref> [15, 25, 12, 24, 19] </ref>. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations [7, 5, 28, 31].
Reference: [26] <author> J. Shi and C. Tomasi. </author> <title> Good features to track. </title> <booktitle> In CVPR, </booktitle> <year> 1994. </year>
Reference-contexts: Minimizing (9) is equivalent to computing the weighted means and covariances for support layer. (10) can be minimized using an extension of the Lucas-Kanade motion estimation described by Shi and Tomasi <ref> [26] </ref>. Our experiments have shown that with just a few E and M steps, we already converge to a stable estimate. The initialization of the EM algorithm is done by splitting up the image into equal tiles. These are the initial support maps.
Reference: [27] <author> E.P. Simoncelli, </author> <title> E.H. Adelson, and D.J. Heeger. Probability distributions of optical flow. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recogn., </journal> <year> 1991. </year>
Reference: [28] <author> T. Starner and A. Pentland. </author> <title> Visual recognition of american sign language using hidden markov models. </title> <booktitle> In Proc. of the Int. Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <address> Zurich, </address> <year> 1995, 1995. </year>
Reference-contexts: Systems that deal with real input data and edge fitting to explicit structural models are reported by [15, 25, 12, 24, 19]. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations <ref> [7, 5, 28, 31] </ref>. Some of these techniques use HMMs to cover the temporal structure. [22] propose a technique that looks for appearance based periodicity, and [11] measure spatio-temporal angle histograms to recognize hand gestures.
Reference: [29] <author> Y. Weiss and E.H. Adelson. </author> <title> A unified mixture framework for motion segmentation: Incorporating spatial coherence and estimating the number of models. </title> <booktitle> In CVPR, </booktitle> <year> 1996. </year>
Reference-contexts: If the number of blobs is K, the domain of S (x; y) 2 f1; 2; :::; Kg. This leads to a representation that is already used in so called layered motion approaches <ref> [29, 17, 1] </ref>. Simultaneously the labels S (x; y) and the motion, color, and spatial parameters can be estimated using the Expectation Maximization (EM) maximum likelihood [9]. There are various ways to determine the number of layers K as well [1, 29]. <p> Simultaneously the labels S (x; y) and the motion, color, and spatial parameters can be estimated using the Expectation Maximization (EM) maximum likelihood [9]. There are various ways to determine the number of layers K as well <ref> [1, 29] </ref>. Our approach differs in the way it also incorporates past histories of groupings in earlier frames, and how it encodes spatial proximity. The set of blob hypotheses for a given image frame I (t) are represented as a mixture of multivariate Gaussians (t).
Reference: [30] <author> C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <booktitle> In SPIE Conference on Integration Issues in Large Commercial Media Delivery Systems, </booktitle> <volume> volume 2615, </volume> <year> 1995. </year>
Reference-contexts: Motion based recognition techniques were presented in [8, 10, 3], and a system based on color blobs is described in <ref> [30] </ref>. Some systems ignore the low-level feature extraction and only focus on higher level representations and recognition strategies [6, 13]. Most explicit model approaches assume certain domain constraints, like calibrated cameras, known background, initial pose, and uncluttered environments that make edge matching feasible.
Reference: [31] <author> J. Yamato, J. Ohya, and K. Ishii. </author> <title> Recognizing human action in time sequential images using hidden markov models. </title> <booktitle> In CVPR, </booktitle> <year> 1993. </year>
Reference-contexts: Systems that deal with real input data and edge fitting to explicit structural models are reported by [15, 25, 12, 24, 19]. Techniques that don't use such explicit model knowledge are usually estimated from example image sequences. Common representations are space-time curves [20], and appearance based representations <ref> [7, 5, 28, 31] </ref>. Some of these techniques use HMMs to cover the temporal structure. [22] propose a technique that looks for appearance based periodicity, and [11] measure spatio-temporal angle histograms to recognize hand gestures.
References-found: 31

