URL: ftp://ftp.pmg.lcs.mit.edu/pub/thor/occ.ps
Refering-URL: http://www.pmg.lcs.mit.edu/~gruber/pubs.html
Root-URL: 
Email: fadya,gruber,liskov,umeshg@lcs.mit.edu  
Title: Efficient Optimistic Concurrency Control Using Loosely Synchronized Clocks  
Author: Atul Adya Robert Gruber Barbara Liskov Umesh Maheshwari 
Address: 545 Technology Square, Cambridge, MA 02139  
Affiliation: Laboratory for Computer Science, Massachusetts Institute of Technology,  
Date: May 1995  
Note: Appears in the Proceedings of the ACM SIGMOD International Conference on Management of Data, San Jose, CA,  
Abstract: This paper describes an efficient optimistic concurrency control scheme for use in distributed database systems in which objects are cached and manipulated at client machines while persistent storage and transactional support are provided by servers. The scheme provides both serializability and external consistency for committed transactions; it uses loosely synchronized clocks to achieve global serialization. It stores only a single version of each object, and avoids maintaining any concurrency control information on a per- object basis; instead, it tracks recent invalidations on a per-client basis, an approach that has low in-memory space overhead and no per-object disk overhead. In addition to its low space overheads, the scheme also performs well. The paper presents a simulation study that compares the scheme to adaptive callback locking, the best concurrency control scheme for client-server object-oriented database systems studied to date. The study shows that our scheme outperforms adaptive callback locking for low to moderate contention workloads, and scales better with the number of clients. For high contention workloads, optimism can result in a high abort rate; the scheme presented here is a first step toward a hybrid scheme that we expect to perform well across the full range of workloads. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Adya. </author> <title> Transaction Management for Mobile Objects using Optimistic Concurrency Control. </title> <type> Tech. Report MIT/LCS/TR626, </type> <institution> MIT Lab. for Computer Science, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: New persistent objects may be created as a result of the methods invoked by an application, and objects can migrate between servers. Both object creation and object migration require transaction support but we ignore them in this paper; see <ref> [1] </ref> for a discussion of these issues. To improve performance, methods are executed on the client machine using locally cached copies of objects. Objects are fetched from their servers when needed, and when an object is fetched, a number of related objects are prefetched [7]. <p> lower than the new threshold, provided they are committed or are read-only at this participant, A simple alternative to a threshold that lags behind the local time is to remove transactions from the VQ at their commit point and set the threshold to the timestamp of the latest committed transaction <ref> [1] </ref>. Given that the commit of a distributed transaction is preceded by phase one messages and log forces, chances are that this threshold level would be sufficiently behind the local time to allow transactions to pass the threshold check.
Reference: [2] <author> D. Agrawal, A. J. Bernstein, P. Gupta, and S. Sengupta. </author> <title> Distributed Multi-version Optimistic Concurrency Control with Reduced Rollback. </title> <journal> Distributed Computing, </journal> <volume> 2(1), </volume> <year> 1987. </year>
Reference-contexts: The scheme uses timestamps generated from local clocks to define the serial order of transactions; we assume clocks are loosely synchronized, which is the case in networks today [24]. This approach is simpler and cheaper than previous techniques <ref> [2, 6, 14, 25] </ref>; other techniques are discussed in Section 3.6. More importantly, timestamps allow us to truncate transaction history and still avoid spurious aborts. <p> If a transaction has not modified an object at any participant, we say it is read-only. For such transactions, no stable information needs to be logged and phase 2 is not required. Some other concurrency control schemes (e.g., callback locking and some multi-version schemes <ref> [2] </ref>) guarantee that all read-only transactions are serializable, so committing such transactions does not require any communication with the servers. Our scheme, however, does require validation for read-only transactions, and therefore phase 1 messages must be sent to the participants. <p> Since then a number of optimistic schemes have been discussed in the literature. Other distributed schemes achieve a global serialization order using atomic multicast [25] or logical clocks <ref> [2, 14] </ref>. Atomic multicast adds additional per-message overhead, while logical clocks must be explicitly managed as part of the two-phase commit, complicating the algorithm. <p> Optimistic schemes can be classified [17] into forward and backward validation schemes. Backward validation algorithms such as our scheme and those proposed in <ref> [2, 3, 6, 18, 19, 25] </ref> validate a transaction against already-committed transactions, while forward validation algorithms such as O2PL [10] validate a transaction against currently executing transactions. (Both approaches also validate against other validating transactions.) In a client-server system, forward validation requires a validating transaction to contact all clients that are <p> Previous optimistic schemes have largely ignored implementation issues regarding time and space overheads. Some schemes <ref> [2, 6, 18, 19] </ref> validate a transaction against all transactions serialized between its start and end times; a large amount of validation information must be stored to validate a long transaction. <p> Multi-version schemes <ref> [2, 3, 19] </ref> keep multiple versions of objects to provide a consistent view of the database to all active transactions, making validation unnecessary for read- only transactions. However, this approach has very high space overheads. <p> However, this approach has very high space overheads. It also still requires validation of read-write transactions (where our efficient scheme could be usefully applied). Most optimistic schemes store some concurrency control information per object (e.g., the scheme in <ref> [2] </ref> maintains two timestamp values with each version); we call this the version number approach. Space overhead for version numbers can be significant for small objects; e.g., most objects in the OO7 benchmark [5] are smaller than 100 bytes; an 8 byte version number would add 8% overhead.
Reference: [3] <author> P. Butterworth, A. Otis, and J. Stein. </author> <title> The Gemstone Database Management System. </title> <journal> CACM, </journal> <volume> 34(10), </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: Optimistic schemes can be classified [17] into forward and backward validation schemes. Backward validation algorithms such as our scheme and those proposed in <ref> [2, 3, 6, 18, 19, 25] </ref> validate a transaction against already-committed transactions, while forward validation algorithms such as O2PL [10] validate a transaction against currently executing transactions. (Both approaches also validate against other validating transactions.) In a client-server system, forward validation requires a validating transaction to contact all clients that are <p> Multi-version schemes <ref> [2, 3, 19] </ref> keep multiple versions of objects to provide a consistent view of the database to all active transactions, making validation unnecessary for read- only transactions. However, this approach has very high space overheads.
Reference: [4] <author> M. Carey, M. Franklin, and M. Zaharioudakis. </author> <title> Fine-Graned Sharing in a Page Server OODBMS. </title> <booktitle> In Proceedings of the 1994 ACM SIGMOD, </booktitle> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Our storage requirements are roughly equivalent to those of distributed pessimistic schemes; we compare them to the storage requirements of other optimistic schemes in Section 3.6. The best concurrency control method proposed for client- server object-oriented systems prior to our work is adaptive callback locking <ref> [4] </ref>. Our technique outperforms adaptive callback locking in workloads in which there is low to moderate contention; we present the results of simulation studies that show this in Section 4. The reason for our good performance is that we send fewer concurrency control messages than other schemes. <p> Carey, Franklin, and Zaharioudakis <ref> [4] </ref> demonstrated through simulation that ACBL outperforms non-adaptive callback schemes. Earlier, Franklin and Carey [9, 10] used simulation to explore a number of different schemes, and concluded that a nonadaptive callback scheme was the best overall choice; since ACBL is even better, we decided to compare OCC directly with ACBL. <p> This approach is better than a pure page-based scheme because it avoids false conflicts, which lead to unnecessary waiting or aborts. It is better than a pure object- based scheme because it avoids sending multiple write lock 1 ACBL is the PS-AA scheme in <ref> [4] </ref>. 7 requests or multiple callbacks for objects in the same page for those cases where a single page-level lock or callback can be used. To compare OCC to ACBL, we designed a page-based variant of OCC that we call AOCC (adaptive OCC). <p> read or write access, some think time is charged at the client; this models local computation performed as part of the read or write. (The think times are per byte; multiply by 100 for the object size used here.) The workload settings shown are similar to the HOTCOLD workload in <ref> [4] </ref>, except for the addition of a 50 page shared region; thus we call this the SH/HOTCOLD workload. We added the shared region because we believe that both uniform and biased page sharing is likely to occur in real workloads.
Reference: [5] <author> M. J. Carey, D. J. DeWitt, and J. F. Naughton. </author> <title> The OO7 Benchmark. </title> <booktitle> In Proceedings of ACM SIGMOD, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Most optimistic schemes store some concurrency control information per object (e.g., the scheme in [2] maintains two timestamp values with each version); we call this the version number approach. Space overhead for version numbers can be significant for small objects; e.g., most objects in the OO7 benchmark <ref> [5] </ref> are smaller than 100 bytes; an 8 byte version number would add 8% overhead. Another potential problem with version numbers is that they are usually cached and uncached with the rest of their object state; missing version numbers would then require disk reads during validation.
Reference: [6] <author> S. Ceri and S. Owicki. </author> <title> On the Use of Optimistic Methods for Concurrency Control in Distributed Databases. </title> <booktitle> In Proceedings of the 6th Berkeley Workshop, </booktitle> <year> 1982. </year>
Reference-contexts: The scheme uses timestamps generated from local clocks to define the serial order of transactions; we assume clocks are loosely synchronized, which is the case in networks today [24]. This approach is simpler and cheaper than previous techniques <ref> [2, 6, 14, 25] </ref>; other techniques are discussed in Section 3.6. More importantly, timestamps allow us to truncate transaction history and still avoid spurious aborts. <p> Other distributed schemes achieve a global serialization order using atomic multicast [25] or logical clocks [2, 14]. Atomic multicast adds additional per-message overhead, while logical clocks must be explicitly managed as part of the two-phase commit, complicating the algorithm. The scheme described in <ref> [6] </ref> used the following approach: To validate a transaction T, a participant computes the set of other validating transactions that T conflicts with, waits for these to commit or abort, and then makes its commit decision. <p> Optimistic schemes can be classified [17] into forward and backward validation schemes. Backward validation algorithms such as our scheme and those proposed in <ref> [2, 3, 6, 18, 19, 25] </ref> validate a transaction against already-committed transactions, while forward validation algorithms such as O2PL [10] validate a transaction against currently executing transactions. (Both approaches also validate against other validating transactions.) In a client-server system, forward validation requires a validating transaction to contact all clients that are <p> Previous optimistic schemes have largely ignored implementation issues regarding time and space overheads. Some schemes <ref> [2, 6, 18, 19] </ref> validate a transaction against all transactions serialized between its start and end times; a large amount of validation information must be stored to validate a long transaction.
Reference: [7] <author> M. S. Day. </author> <title> Client Cache Management in a Distributed Object Database. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: To improve performance, methods are executed on the client machine using locally cached copies of objects. Objects are fetched from their servers when needed, and when an object is fetched, a number of related objects are prefetched <ref> [7] </ref>. The server tracks the objects in the client cache; for each client, it maintains a table called the cached set that records this information. The cached sets are used as part of transaction processing as discussed below; they are also used for other purposes, such as garbage collection [23].
Reference: [8] <author> K.P. Eswaran, J.N. Gray, R.A. Lorie, </author> <title> and I.L. Traiger. The Notion of Consistency and Predicate Locks in a Database System. </title> <journal> CACM, </journal> 19(11) 624-633, November 1976. <volume> 11 </volume>
Reference-contexts: This information is sent to the server along with the cached set; this allows the server to discard all entries from the invalid set that have been acknowledged by the front end. 3.6 Comparison with Other Optimistic Schemes Eswaran et al. <ref> [8] </ref>, and later Kung and Robinson [18], suggested the idea of using optimism for concurrency control. Since then a number of optimistic schemes have been discussed in the literature. Other distributed schemes achieve a global serialization order using atomic multicast [25] or logical clocks [2, 14].
Reference: [9] <author> M. Franklin. </author> <title> Caching and Memory Management in Client-Server Database Systems. </title> <type> Tech. Report (Ph.D.) 1168, </type> <institution> Computer Sciences Dept., Univ. of Wisconsin - Madison, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: Carey, Franklin, and Zaharioudakis [4] demonstrated through simulation that ACBL outperforms non-adaptive callback schemes. Earlier, Franklin and Carey <ref> [9, 10] </ref> used simulation to explore a number of different schemes, and concluded that a nonadaptive callback scheme was the best overall choice; since ACBL is even better, we decided to compare OCC directly with ACBL.
Reference: [10] <author> M. Franklin and M. Carey. </author> <title> Client-Server Caching Revisited. </title> <booktitle> In Proc. Int'l Workshop on Distributed Object Management, </booktitle> <address> Edmonton, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Optimistic schemes can be classified [17] into forward and backward validation schemes. Backward validation algorithms such as our scheme and those proposed in [2, 3, 6, 18, 19, 25] validate a transaction against already-committed transactions, while forward validation algorithms such as O2PL <ref> [10] </ref> validate a transaction against currently executing transactions. (Both approaches also validate against other validating transactions.) In a client-server system, forward validation requires a validating transaction to contact all clients that are caching updated objects, to obtain latches on the cached copies. <p> Carey, Franklin, and Zaharioudakis [4] demonstrated through simulation that ACBL outperforms non-adaptive callback schemes. Earlier, Franklin and Carey <ref> [9, 10] </ref> used simulation to explore a number of different schemes, and concluded that a nonadaptive callback scheme was the best overall choice; since ACBL is even better, we decided to compare OCC directly with ACBL.
Reference: [11] <author> S. Ghemawat. </author> <title> Main-Memory Log: A Simple Solution to the Disk Bottleneck. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, Forthcoming. </institution>
Reference-contexts: Installation of committed updates occurs out of a large in-memory commit log in our system, and can be scheduled very efficiently. (For the details of the in-memory log and the server's use of the disk, see <ref> [11] </ref>.) The register/unregister cost is used to model the work done at the server to update a client's cached set; lock maintenance is included in this registration cost for ACBL.
Reference: [12] <author> D. K. Gifford. </author> <title> Information Storage in a Decentralized Computer System. </title> <type> Tech. </type> <note> Report CSL-81-8, Xerox Parc, </note> <year> 1983. </year>
Reference-contexts: This paper presents an efficient concurrency control scheme for use in such a system. The scheme provides serializability for transactions, and also external consistency <ref> [12] </ref> so that transaction commit order as observed by clients is the This research was supported in part by the Advanced Research Projects Agency of the Department of Defense, monitored by the Office of Naval Research under contract N00014-91-J-4136, and in part by the National Science Foundation under Grant CCR-8822158. same
Reference: [13] <author> J. N. Gray. </author> <title> Notes on Database Operating Systems. </title> <editor> In R. Bayer, R. M. Graham, and G. Seegmuller, editors, </editor> <booktitle> Operating Systems: An Advanced Course, </booktitle> <pages> pages 394-481. </pages> <publisher> Springer-Verlag, </publisher> <year> 1979. </year>
Reference-contexts: This server commits the transaction unilaterally if it owns all objects used by the transaction. Otherwise, it acts as the coordinator of a commit protocol with the other owners, called the participants. We use a standard 2-phase protocol <ref> [13] </ref>. We describe the protocol briefly here to provide a context for our scheme. In phase 1, the coordinator sends prepare messages containing the validation and installation information to the participants. Each participant tries to validate the transaction; we will describe how validation works in Section 3.
Reference: [14] <author> R. E. Gruber. </author> <title> Optimistic Concurrency Control for Nested Distributed Transactions. </title> <type> Tech. Report MIT/LCS/TR-453, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: The scheme uses timestamps generated from local clocks to define the serial order of transactions; we assume clocks are loosely synchronized, which is the case in networks today [24]. This approach is simpler and cheaper than previous techniques <ref> [2, 6, 14, 25] </ref>; other techniques are discussed in Section 3.6. More importantly, timestamps allow us to truncate transaction history and still avoid spurious aborts. <p> Since then a number of optimistic schemes have been discussed in the literature. Other distributed schemes achieve a global serialization order using atomic multicast [25] or logical clocks <ref> [2, 14] </ref>. Atomic multicast adds additional per-message overhead, while logical clocks must be explicitly managed as part of the two-phase commit, complicating the algorithm.
Reference: [15] <author> R. E. Gruber. </author> <title> Temperature-Based Concurrency Control. </title> <booktitle> In Third IWOOOS, </booktitle> <pages> pages 230-232, </pages> <address> Asheville, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: Therefore, our approach is not appropriate when there is high contention. We plan to address this failing by using a hybrid scheme in which the system switches dynamically to a pessimistic approach for high-contention objects <ref> [15] </ref>. The design of the hybrid approach and its performance analysis is ongoing [16]. The remainder of the paper is organized as follows. Section 2 describes the environment for our work. Section 3 describes our algorithm and compares it to other work on optimistic concurrency control. <p> The resulting system should have better performance than a locking-only system, but with a much lower abort rate than a pure optimistic scheme. Our research into the design and performance evaluation of such a hybrid scheme is ongoing <ref> [15, 16] </ref>. Acknowledgements The authors are grateful to Dawson Engler, Wilson Hsieh, James O'Toole and the referees for their helpful comments.
Reference: [16] <author> R. E. Gruber. </author> <title> Temperature-Based Concurrency Control. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, Forthcoming. </institution>
Reference-contexts: Therefore, our approach is not appropriate when there is high contention. We plan to address this failing by using a hybrid scheme in which the system switches dynamically to a pessimistic approach for high-contention objects [15]. The design of the hybrid approach and its performance analysis is ongoing <ref> [16] </ref>. The remainder of the paper is organized as follows. Section 2 describes the environment for our work. Section 3 describes our algorithm and compares it to other work on optimistic concurrency control. Section 4 compares our performance to adaptive callback locking. <p> The resulting system should have better performance than a locking-only system, but with a much lower abort rate than a pure optimistic scheme. Our research into the design and performance evaluation of such a hybrid scheme is ongoing <ref> [15, 16] </ref>. Acknowledgements The authors are grateful to Dawson Engler, Wilson Hsieh, James O'Toole and the referees for their helpful comments.
Reference: [17] <author> T. Haerder. </author> <title> Observations on Optimistic Concurrency Control Schemes. </title> <journal> Information Systems, </journal> <volume> 9(2) </volume> <pages> 111-120, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: The scheme is an optimistic algorithm [18] that uses backward validation <ref> [17] </ref>. It performs better than other concurrency control algorithms for an important class of workloads when there is low to moderate contention between user transactions. <p> External consistency: The serialization order is such that, if transaction S committed before T began (in real time), S is ordered before T. Our scheme uses backward validation <ref> [17] </ref> to preserve consistency: a validating transaction T is checked against all transactions that have already validated successfully. This section describes how we perform validation. It assumes the validation algorithm is embedded in the commit protocol described in Section 2. <p> Our use of loosely synchronized clocks avoids all these problems; more importantly, it also allows us to make time-dependent decisions (e.g., about what transactions to remove from the transaction history). Optimistic schemes can be classified <ref> [17] </ref> into forward and backward validation schemes.
Reference: [18] <author> H. T. Kung and J. T. Robinson. </author> <title> On Optimistic Methods for Concurrency Control. </title> <journal> ACM TODS, </journal> <volume> 6(2) </volume> <pages> 213-226, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: The scheme is an optimistic algorithm <ref> [18] </ref> that uses backward validation [17]. It performs better than other concurrency control algorithms for an important class of workloads when there is low to moderate contention between user transactions. <p> This information is sent to the server along with the cached set; this allows the server to discard all entries from the invalid set that have been acknowledged by the front end. 3.6 Comparison with Other Optimistic Schemes Eswaran et al. [8], and later Kung and Robinson <ref> [18] </ref>, suggested the idea of using optimism for concurrency control. Since then a number of optimistic schemes have been discussed in the literature. Other distributed schemes achieve a global serialization order using atomic multicast [25] or logical clocks [2, 14]. <p> Optimistic schemes can be classified [17] into forward and backward validation schemes. Backward validation algorithms such as our scheme and those proposed in <ref> [2, 3, 6, 18, 19, 25] </ref> validate a transaction against already-committed transactions, while forward validation algorithms such as O2PL [10] validate a transaction against currently executing transactions. (Both approaches also validate against other validating transactions.) In a client-server system, forward validation requires a validating transaction to contact all clients that are <p> Previous optimistic schemes have largely ignored implementation issues regarding time and space overheads. Some schemes <ref> [2, 6, 18, 19] </ref> validate a transaction against all transactions serialized between its start and end times; a large amount of validation information must be stored to validate a long transaction.
Reference: [19] <author> M. Y. Lai and W. K. Wilkinson. </author> <title> Distributed Transaction Management in Jasmin. </title> <booktitle> In Tenth VLDB Conf., </booktitle> <month> August </month> <year> 1984. </year>
Reference-contexts: Optimistic schemes can be classified [17] into forward and backward validation schemes. Backward validation algorithms such as our scheme and those proposed in <ref> [2, 3, 6, 18, 19, 25] </ref> validate a transaction against already-committed transactions, while forward validation algorithms such as O2PL [10] validate a transaction against currently executing transactions. (Both approaches also validate against other validating transactions.) In a client-server system, forward validation requires a validating transaction to contact all clients that are <p> Previous optimistic schemes have largely ignored implementation issues regarding time and space overheads. Some schemes <ref> [2, 6, 18, 19] </ref> validate a transaction against all transactions serialized between its start and end times; a large amount of validation information must be stored to validate a long transaction. <p> Multi-version schemes <ref> [2, 3, 19] </ref> keep multiple versions of objects to provide a consistent view of the database to all active transactions, making validation unnecessary for read- only transactions. However, this approach has very high space overheads.
Reference: [20] <author> B. Liskov. </author> <title> Practical Uses of Synchronized Clocks in Distributed Systems. </title> <booktitle> In Tenth PODC Conf., </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Our use of synchronized clocks here is similar to their use in other distributed algorithms <ref> [20] </ref>, but to our knowledge this is the first time that they have been used in this way in a concurrency control scheme. The scheme has good performance in both space and time. <p> We maintain a stable threshold, which is always later than the timestamp of any transaction that has ever validated at the server. On recovery, the threshold is set to the logged value of the stable threshold. This technique is similar to that used for at-most-once messages in <ref> [20] </ref>. The stable threshold must be increased whenever the timestamp of a validating transaction is later than its current value.
Reference: [21] <author> B. Liskov. </author> <title> Preliminary Design of the Thor Object-Oriented Database System. Programming Methodology Memo 74, </title> <institution> MIT Lab. for Computer Science, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: Section 4 compares our performance to adaptive callback locking. We conclude with a discussion of what we have accomplished. 2 The Environment Our work has been done in the context of the Thor object- oriented database <ref> [21, 22] </ref>. Thor allows user applications to share a universe of persistent objects. Objects are encapsulated for safe sharing, and applications access them by invoking methods that observe or modify their object's state.
Reference: [22] <author> B. Liskov, R. Gruber, P. Johnson, and L. Shrira. </author> <title> A HighlyAvailable Object Repository for use in a Heterogeneous Distributed System. </title> <booktitle> In Proc. of the 4th Int'l Workshop on Persistent Object Systems, </booktitle> <pages> pages 255-266, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Section 4 compares our performance to adaptive callback locking. We conclude with a discussion of what we have accomplished. 2 The Environment Our work has been done in the context of the Thor object- oriented database <ref> [21, 22] </ref>. Thor allows user applications to share a universe of persistent objects. Objects are encapsulated for safe sharing, and applications access them by invoking methods that observe or modify their object's state.
Reference: [23] <author> U. Maheshwari and B. Liskov. </author> <title> Fault-Tolerant Distributed Garbage Collection in a Client-Server, Object-Oriented Database. </title> <booktitle> In Third PDIS Conference, </booktitle> <pages> pages 239-248, </pages> <address> Austin, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: The server tracks the objects in the client cache; for each client, it maintains a table called the cached set that records this information. The cached sets are used as part of transaction processing as discussed below; they are also used for other purposes, such as garbage collection <ref> [23] </ref>. The code that manages the cache on the client machine is part of Thor and is called a front end. Each server has a cache of objects in main memory, which it uses to satisfy fetch requests from clients. The organization is shown in Figure 1. <p> Failures are expected to be rare, and furthermore if a server cannot communicate with a client for some period of time (e.g., a few minutes), it shuts the client down; our shut down protocol is discussed in <ref> [23] </ref>. Thus, the memory requirements for validation are quite modest, modest enough that we can keep the needed information in primary memory. We require cached sets, invalid sets, and the VQ. We have already argued that the cached sets and invalid sets are small.
Reference: [24] <author> D. L. Mills. </author> <title> Network Time Protocol: Specification and Implementation. </title> <type> DARPA-Internet Report RFC 1059, DARPA, </type> <month> July </month> <year> 1988. </year>
Reference-contexts: The scheme uses timestamps generated from local clocks to define the serial order of transactions; we assume clocks are loosely synchronized, which is the case in networks today <ref> [24] </ref>. This approach is simpler and cheaper than previous techniques [2, 6, 14, 25]; other techniques are discussed in Section 3.6. More importantly, timestamps allow us to truncate transaction history and still avoid spurious aborts. <p> Loose synchronization implies that the clocks at different nodes in the network may differ by at most a small skew (say, a few tens of milliseconds). The presence of such clocks is a reasonable assumption for current systems; protocols such as the Network Time Protocol <ref> [24] </ref> provide such a facility.
Reference: [25] <author> E. Rahm and A. Thomasian. </author> <title> A New Distributed Optimistic Concurrency Control Method and a Comparison of its Performance with Two-Phase Locking. </title> <booktitle> In Proceedings of Tenth ICDCS, </booktitle> <year> 1990. </year>
Reference-contexts: The scheme uses timestamps generated from local clocks to define the serial order of transactions; we assume clocks are loosely synchronized, which is the case in networks today [24]. This approach is simpler and cheaper than previous techniques <ref> [2, 6, 14, 25] </ref>; other techniques are discussed in Section 3.6. More importantly, timestamps allow us to truncate transaction history and still avoid spurious aborts. <p> Since then a number of optimistic schemes have been discussed in the literature. Other distributed schemes achieve a global serialization order using atomic multicast <ref> [25] </ref> or logical clocks [2, 14]. Atomic multicast adds additional per-message overhead, while logical clocks must be explicitly managed as part of the two-phase commit, complicating the algorithm. <p> Optimistic schemes can be classified [17] into forward and backward validation schemes. Backward validation algorithms such as our scheme and those proposed in <ref> [2, 3, 6, 18, 19, 25] </ref> validate a transaction against already-committed transactions, while forward validation algorithms such as O2PL [10] validate a transaction against currently executing transactions. (Both approaches also validate against other validating transactions.) In a client-server system, forward validation requires a validating transaction to contact all clients that are
Reference: [26] <author> J. W. Stamos. </author> <title> A Low-Cost Atomic Commit Protocol. </title> <type> Tech. Report RJ7185, </type> <institution> IBM Almaden, </institution> <address> CA, </address> <month> December </month> <year> 1989. </year> <month> 12 </month>
Reference-contexts: Then it notifies the client of its decision. Note that the delay observed by the client before it can start the next transaction is due to phase 1 only; phase 2 happens in the background. Phase 1 includes two stable log updates, but the optimizations suggested by Stamos <ref> [26] </ref> can reduce this to a single log update. 2 In phase 2, the coordinator sends commit messages to the participants.
References-found: 26

