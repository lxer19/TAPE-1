URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/unlv.ps.gz
Refering-URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/irnew.html
Root-URL: 
Title: Corpus-Specific Stemming using Word Form Co-occurrence  
Author: W. Bruce Croft and Jinxi Xu 
Address: Amherst  
Affiliation: Computer Science Department University of Massachusetts,  
Abstract: Stemming is used in many information retrieval (IR) systems to reduce word forms to common roots. It is one of the simplest and most successful applications of natural language processing for IR. Current stemming algorithms are, however, either inflexible or difficult to adapt to the specific characteristics of a text corpus, except by the manual definition of exception lists. We propose a technique for using corpus-based word co-occurrence statistics to modify a stemmer. Experiments show that this technique is effective and is very suitable for query-based stemming. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Church and P. Hanks. </author> <title> Word association norms, mutual information, and lexicography. </title> <booktitle> In Proceedings of the 27th ACL Meeting, </booktitle> <pages> pages 76-83, </pages> <year> 1989. </year>
Reference-contexts: The basic hypothesis is that word forms that should be conflated for a given corpus will co-occur in documents from that corpus. Based on that hypothesis, we use a co-occurrence measure similar to the expected mutual information measure (EMIM <ref> [8, 1] </ref>) to modify conflation classes generated by the Porter stemmer. In query-based stemming, all decisions about word conflation are made when the query is formulated, rather than at document indexing time. <p> Examples of the latter are the word pairs "policy"/"police" and "addition"/"additive" for the Porter stemmer. The basic measure that is used to measure the significance of word form co-occurrence is a variation of EMIM <ref> [8, 1] </ref>.
Reference: [2] <author> D. </author> <title> Harman. </title> <booktitle> Overview of the first TREC conference. In Proceedings of the 16 th ACM SIGIR International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 36-47, </pages> <year> 1993. </year>
Reference-contexts: In the next section, we present statistics for some corpora. 4 Corpora and Conflation Classes The corpora that we use in these experiments are the West collection of law documents and the Wall St. Journal collection of newspaper articles <ref> [7, 2] </ref>. The statistics for these corpora and the associated queries and relevance judgements are shown in Table 1. Two sets of queries are used for the West collection. The first is where the queries are treated as a collection of individual words.
Reference: [3] <author> Y. Jing and W.B. Croft. </author> <title> An association thesaurus for information retrieval. </title> <booktitle> In Proceedings of RIAO 94, </booktitle> <year> 1994. </year> <note> to appear. </note>
Reference-contexts: The way we have chosen to do this is to use an "aggressive" stemmer (Porter) to identify words that may be conflated, and then use the corpus statistics to refine that conflation. 1 Jing and Croft <ref> [3] </ref> discuss a corpus-based technique for query expansion that produces significant effectiveness improvements 3 A problem with this approach is that if the aggressive stemmer is not aggressive enough, word pairs that should be conflated will be missed.
Reference: [4] <author> Robert Krovetz. </author> <title> Viewing morphology as an inference process. </title> <booktitle> In Proceedings of the 16 th International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 191-202, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Stemming is a common form of language processing in most information retrieval systems <ref> [4] </ref>. It is similar to the morphological processing used in natural language processing, but has somewhat different aims. In an information retrieval system, stemming is used to reduce different word forms to common roots, and thereby improve the ability of the system to match query and document vocabulary. <p> Despite these problems, recall/precision evaluations of the Porter stemmer show that it gives consistent (if rather small) performance benefits across a range of collections, and that it is better than most other stemmers. Krovetz <ref> [4] </ref> developed a new approach to stemming based on machine-readable dictionaries and well-defined rules for inflectional and derivational morphology. This stemmer (now called KSTEM) addresses many of the problems with the Porter stemmer, but does not produce consistently better recall/precision performance.
Reference: [5] <author> M. Porter. </author> <title> An algorithm for suffix stripping. </title> <booktitle> Program, </booktitle> <volume> 14(3) </volume> <pages> 130-137, </pages> <year> 1980. </year>
Reference-contexts: Stemming in English is usually done during document indexing by removing word endings or suffixes using tables of common endings and heuristics about when it is appropriate to remove them. One of the best-known stemmers used in experimental IR systems is the Porter stemmer <ref> [5] </ref>, which iteratively removes endings from a word until termination conditions are met. The Porter stemmer has a number of problems. It is difficult to understand and modify.
Reference: [6] <author> E. Riloff and W. Lehnert. </author> <title> Information extraction as a basis for high-precision text classification. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 12 </volume> <pages> 296-333, </pages> <year> 1994. </year>
Reference-contexts: For example, in looking for articles about terrorist incidents, the word "assassination" is very good at discriminating relevant from non-relevant documents, but the word "assassinations" is much less useful <ref> [6] </ref>. The main disadvantage of query-based stemming is that the queries become longer and will, therefore, take longer to process. The impact on response times will depend on the degree of query expansion.
Reference: [7] <author> Howard Turtle. </author> <title> Natural language vs. Boolean query evaluation: A comparison of retrieval performance. </title> <booktitle> In Proceedings ACM SIGIR 94, </booktitle> <pages> pages 212-220, </pages> <year> 1994. </year>
Reference-contexts: In the next section, we present statistics for some corpora. 4 Corpora and Conflation Classes The corpora that we use in these experiments are the West collection of law documents and the Wall St. Journal collection of newspaper articles <ref> [7, 2] </ref>. The statistics for these corpora and the associated queries and relevance judgements are shown in Table 1. Two sets of queries are used for the West collection. The first is where the queries are treated as a collection of individual words.
Reference: [8] <author> C.J. van Rijsbergen. </author> <note> Information Retrieval. Butterworths, second edition, </note> <year> 1979. </year>
Reference-contexts: The basic hypothesis is that word forms that should be conflated for a given corpus will co-occur in documents from that corpus. Based on that hypothesis, we use a co-occurrence measure similar to the expected mutual information measure (EMIM <ref> [8, 1] </ref>) to modify conflation classes generated by the Porter stemmer. In query-based stemming, all decisions about word conflation are made when the query is formulated, rather than at document indexing time. <p> Examples of the latter are the word pairs "policy"/"police" and "addition"/"additive" for the Porter stemmer. The basic measure that is used to measure the significance of word form co-occurrence is a variation of EMIM <ref> [8, 1] </ref>.

References-found: 8

