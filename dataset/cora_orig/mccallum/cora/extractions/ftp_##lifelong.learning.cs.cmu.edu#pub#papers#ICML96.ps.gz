URL: ftp://lifelong.learning.cs.cmu.edu/pub/papers/ICML96.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs/usr/josullvn/mosaic/research.html
Root-URL: 
Title: Integrating Initialization Bias and Search Bias in Neural Network Learning  
Author: Joseph O'Sullivan 
Note: This research is sponsored in part by the National Science Foundation under award IRI-9313367, and by the Wright Laboratory, Aeronautical Systems Center, Air Force Materiel Command, USAF, and the Advanced Research Projects Agency (ARPA) under grant number F33615-93-1-1330.  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: April 1996  
Pubnum: CMU-CS-95-???  
Abstract: The use of previously learned knowledge during learning has been shown to reduce the number of examples required for good generalization, and to increase robustness to noise in the examples. In reviewing various means of using learned knowledge from a domain to guide further learning in the same domain, two underlying classes are discerned. Methods which use previous knowledge to initialize a learner (as an initialization bias), and those that use previous knowledge to constrain a learner (as a search bias). We show such methods in fact exploit the same domain knowledge differently, and can complement each other. This is shown by presenting a combined approach which both initializes and constrains a learner. This combined approach is seen to outperform the individual methods under the conditions that accurate previously learned domain knowledge is available, and that there are irrelevant features in the domain representation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abu-Mostafa, Y. S. </author> <title> Hints. </title> <journal> Neural Computation, </journal> <volume> vol. 7 (1995), </volume> <pages> pp. 637-671. 9 </pages>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees [16], sets of propositional rules [20], finite state automata [11, 6] and chains of networks [13] are but a few. Techniques such as EBNN [10], hints <ref> [18, 1] </ref> and multi-task learning [3, 2] all view previously learned domain knowledge as a constraint for directing search. 1 (a) Knowledge as Search Bias (b) Knowledge as Initialization Bias When learning is considered as a search through the space of possible hypothesizes, prior knowledge can be used (a) to direct
Reference: [2] <author> Baxter, J. </author> <title> Learning Internal Representations. </title> <institution> The Flinders University of South Aus tralia, </institution> <year> 1994. </year>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees [16], sets of propositional rules [20], finite state automata [11, 6] and chains of networks [13] are but a few. Techniques such as EBNN [10], hints [18, 1] and multi-task learning <ref> [3, 2] </ref> all view previously learned domain knowledge as a constraint for directing search. 1 (a) Knowledge as Search Bias (b) Knowledge as Initialization Bias When learning is considered as a search through the space of possible hypothesizes, prior knowledge can be used (a) to direct the search or (b) to
Reference: [3] <author> Caruana, R. </author> <title> Learning Many Related Tasks At the Same Time With Backpropagation. </title> <booktitle> in: Advances in Neural Information Processing Systems 6. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees [16], sets of propositional rules [20], finite state automata [11, 6] and chains of networks [13] are but a few. Techniques such as EBNN [10], hints [18, 1] and multi-task learning <ref> [3, 2] </ref> all view previously learned domain knowledge as a constraint for directing search. 1 (a) Knowledge as Search Bias (b) Knowledge as Initialization Bias When learning is considered as a search through the space of possible hypothesizes, prior knowledge can be used (a) to direct the search or (b) to
Reference: [4] <author> Cohen, W. </author> <title> Compiling prior knowledge into an explicit bias. </title> <booktitle> in: Proceedings of the Ninth International Conference on Machine Learning. </booktitle> <address> Aberdeen, Scotland, </address> <year> 1992, </year> <pages> pp. 102-110. </pages> <month> Grendel. </month>
Reference-contexts: By considering the interactions between the initial state of a network and the training materials, they show that this possibility is always present. Frameworks which combine initialization and search biases have previously been proposed in theory revision systems, GRENDEL <ref> [4] </ref> being one example where this is explicitly noted but more examples exists in which both biases are present as a by-product of attempting to use all available prior knowledge (for instance, FOCL [12]).
Reference: [5] <author> Dietterich, T. G. </author> <title> Limitations of inductive learning. </title> <booktitle> in: Proceedings of the Sixth International Workshop on Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1989, </year> <pages> pp. 124-128. </pages>
Reference-contexts: 1 Introduction There are fundamental limits on the generalization accuracy that can be expected from a learner that learns just from examples <ref> [5, 15] </ref>. Such inductive learning methods operate by detecting statistical regularities in the training data. As the complexity of the learning task increases, it becomes increasingly difficult to generalize well [7, 21].
Reference: [6] <author> Frasconi, P., Gori, M., Maggini, M., and Soda, G. </author> <title> Unified Integration of Explicit Knowl edge and Learning by Example in Recurrent Networks. </title> <journal> IEEE Trans on Knowledge and Data Engineering, </journal> <year> 1993. </year>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees [16], sets of propositional rules [20], finite state automata <ref> [11, 6] </ref> and chains of networks [13] are but a few.
Reference: [7] <author> Haussler, D. </author> <title> Decision Theoretic Generalizations of the PAC Model for Neural Net and other Learning Applications. </title> <journal> Inform. Comput., </journal> <volume> vol. 100 (1992), </volume> <pages> pp. 78-150. </pages>
Reference-contexts: Such inductive learning methods operate by detecting statistical regularities in the training data. As the complexity of the learning task increases, it becomes increasingly difficult to generalize well <ref> [7, 21] </ref>. In many learning contexts, such as robot learning, it can be prohibitively expensive to gather a sufficient number of examples to ensure good generalization. To overcome this dilemma, prior knowledge can be used to bias the learning algorithm to favor hypothesizes consistent with the prior knowledge.
Reference: [8] <author> Hornik, K., Stinchcombe, M., and White, H. </author> <title> Multilayer Feedforward Networks are Universal Approximators. </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 2 (1989), </volume> <pages> pp. 359-366. </pages>
Reference-contexts: It is well known that networks with a single hidden layer using arbitrary squashing functions are capable of approximating any measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available <ref> [8] </ref>. Backpropagation [14] has been successfully applied to this problem. (a) Target (b) Domain of the form (X; Y ) ! F , and (b) typical approximate (and incorrect) domain knowledge we would wish the learner to utilize.
Reference: [9] <author> Krogh, A. and Hertz, J. A. </author> <title> A Simple Weight Decay Can Improve Generalization. </title> <booktitle> in: Advances in Neural Information Processing Systems 4, </booktitle> <editor> edited by J. E. Moody, S. J. Hanson, and R. P. Lipmann. </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1992, </year> <pages> pp. 950-957. </pages>
Reference-contexts: In these situations, there is little need for the network to have any generalization power. More realistically, where examples are few, the error term does not express a complete notion of generalization. Instead, biases such as a weight decay term <ref> [9] </ref> are used to help with generalization to unseen examples. 2 3.2 Training with an Initialization Bias Training with an initialization bias is simplified when the previously learned knowledge is available in the form of a neural network identical to that to be used the training of the target function. <p> This process is repeated with different random seeds several times for each methods, to reduce variance. In all algorithms, a weak weight decay term was used during training with the weights decayed towards zero. In general, this helps generalization <ref> [9] </ref> by favoring the development of the "simplest" solutions.
Reference: [10] <author> Mitchell, T. M. and Thrun, S. B. </author> <title> Learning Analytically and Inductively. in: Mind Matters: A Tribute to Allen Newell, edited by Steier and Mitchell. </title> <publisher> Erlbaum, </publisher> <year> 1995. </year>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees [16], sets of propositional rules [20], finite state automata [11, 6] and chains of networks [13] are but a few. Techniques such as EBNN <ref> [10] </ref>, hints [18, 1] and multi-task learning [3, 2] all view previously learned domain knowledge as a constraint for directing search. 1 (a) Knowledge as Search Bias (b) Knowledge as Initialization Bias When learning is considered as a search through the space of possible hypothesizes, prior knowledge can be used (a)
Reference: [11] <author> Onlin, C. W. and Giles, C. L. </author> <title> Training Second-Order Recurrent Neural Networks using Hints. </title> <booktitle> in: Proceedings of Ninth International Conference on Machine Learning, </booktitle> <editor> edited by S. D. and E. P. </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees [16], sets of propositional rules [20], finite state automata <ref> [11, 6] </ref> and chains of networks [13] are but a few.
Reference: [12] <author> Pazzani, M. J. and Kibler, D. </author> <title> The role of prior knowledge in inductive learning. </title> <journal> Ma chine Learning, </journal> <volume> vol. 9 (1992), </volume> <pages> pp. 54-97. </pages>
Reference-contexts: Frameworks which combine initialization and search biases have previously been proposed in theory revision systems, GRENDEL [4] being one example where this is explicitly noted but more examples exists in which both biases are present as a by-product of attempting to use all available prior knowledge (for instance, FOCL <ref> [12] </ref>).
Reference: [13] <author> Pratt, L. Y. </author> <title> Experiments on the Transfer of Knowledge between Neural Networks. in: Computational Learning Theory and Natural Learning Systems, Constraints and Prospects. </title> <publisher> MIT Press, </publisher> <year> 1994, </year> <pages> pp. 523-560. </pages>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees [16], sets of propositional rules [20], finite state automata [11, 6] and chains of networks <ref> [13] </ref> are but a few. <p> domain knowledge is of high quality, training with an initialization bias injects a good initial hypothesis into the network further examples move it to similar nearby hypothesizes, and overcome the weak weight decay term. 5 Related Work Reviews of specific methods for utilizing bias from prior knowledge are available in <ref> [19, 13] </ref>. 7 (a) Number of examples = 6 0 0.05 0.1 0.15 Error Worst Bad OK Good Best Quality of Domain Theory Domain + Search Bias + Initialization Bias Backpropagation (b) Number of examples = 42 few examples (b). The bars indicate confidence intervals. <p> The bars indicate confidence intervals. For comparison, the expected values of the domain theories alone are also plotted in each case. 8 Pratt has looked specifically at the issue of embedding initialization bias <ref> [13] </ref>. The experiments reported here differ from that work with higher dimensional input space, measurement of generalization performance on unseen data, but most significantly in the choice of evaluation metric.
Reference: [14] <author> Rumelhart, D. E., E.Hinton, G., and Williams, R. J. </author> <title> Learning internal representations by error propagation. </title> <booktitle> in: Parallel Distributed Processing. </booktitle> <volume> Vol I+II, </volume> <editor> edited by D. E. Rymelhart and J. L. McClelland. </editor> <publisher> MIT Press, </publisher> <year> 1986. </year> <month> 10 </month>
Reference-contexts: The challenge is how well can a network trained from a series of examples under a given algorithm generalize to new unseen examples. 3.1 Training without Previously Learned Knowledge Backpropagation <ref> [14] </ref>, probably the most widespread artificial neural network learning method, applies a gradient descent procedure on the weights of a multi-layer network. <p> It is well known that networks with a single hidden layer using arbitrary squashing functions are capable of approximating any measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available [8]. Backpropagation <ref> [14] </ref> has been successfully applied to this problem. (a) Target (b) Domain of the form (X; Y ) ! F , and (b) typical approximate (and incorrect) domain knowledge we would wish the learner to utilize.
Reference: [15] <author> Schaffer, C. </author> <title> Overfitting avoidance as bias. </title> <journal> Machine Learning, </journal> <volume> vol. 10 (1993), </volume> <pages> pp. 153 178. </pages>
Reference-contexts: 1 Introduction There are fundamental limits on the generalization accuracy that can be expected from a learner that learns just from examples <ref> [5, 15] </ref>. Such inductive learning methods operate by detecting statistical regularities in the training data. As the complexity of the learning task increases, it becomes increasingly difficult to generalize well [7, 21].
Reference: [16] <author> Sethi, I. K. </author> <title> Entropy Nets: From Decision Trees to Neural Networks. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 78 (1990), </volume> <pages> pp. 1605-1613. </pages>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees <ref> [16] </ref>, sets of propositional rules [20], finite state automata [11, 6] and chains of networks [13] are but a few.
Reference: [17] <author> Sharkey, N. E. and Sharkey, A. J. C. </author> <title> Adaptive generalisation and the transfer of knowl edge. </title> <journal> AI Review, </journal> <volume> vol. 7 (1993), </volume> <pages> pp. 313-328. </pages>
Reference-contexts: However, this paper does not explore as wide a range of domains. In addition, a focus of her study was upon how transfered weights could be retained during continued training. Conversely, we also expect and correct for poor domain knowledge. Sharkey & Sharkey <ref> [17] </ref> also point out why this is frequently necessary. When using just initial conditions as bias, negative measure of transfer effect are possible. By considering the interactions between the initial state of a network and the training materials, they show that this possibility is always present.
Reference: [18] <author> Suddarth, S. C. and Kergosien, Y. L. </author> <title> Rule-injection hints as a means of improving net work performance and learning time. </title> <booktitle> in: Proceedings of the EURASIP Workshop on Neural Networks, </booktitle> <address> EURASIP. Sesimbra, Portugal, </address> <year> 1990. </year>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees [16], sets of propositional rules [20], finite state automata [11, 6] and chains of networks [13] are but a few. Techniques such as EBNN [10], hints <ref> [18, 1] </ref> and multi-task learning [3, 2] all view previously learned domain knowledge as a constraint for directing search. 1 (a) Knowledge as Search Bias (b) Knowledge as Initialization Bias When learning is considered as a search through the space of possible hypothesizes, prior knowledge can be used (a) to direct
Reference: [19] <author> Thrun, S. </author> <title> Explanation-Based Neural Network Learning: A Lifelong Learning Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1996. </year> <note> to appear. </note>
Reference-contexts: Finally, the target network weights are refined to fit both the observed target value, and the target derivatives extracted from the explanation. A substantially more detailed description is available <ref> [19] </ref>. The training process of EBNN results in the minimization of a combined error function that extends the cost function of Backpropagation to also minimize the difference between the target network derivatives and those derivatives inferred from the explanation. <p> domain knowledge is of high quality, training with an initialization bias injects a good initial hypothesis into the network further examples move it to similar nearby hypothesizes, and overcome the weak weight decay term. 5 Related Work Reviews of specific methods for utilizing bias from prior knowledge are available in <ref> [19, 13] </ref>. 7 (a) Number of examples = 6 0 0.05 0.1 0.15 Error Worst Bad OK Good Best Quality of Domain Theory Domain + Search Bias + Initialization Bias Backpropagation (b) Number of examples = 42 few examples (b). The bars indicate confidence intervals.
Reference: [20] <author> Towell, G. G., Shavlik, J. W., and Noordewier, M. O. </author> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> in: Proceedings of AAAI-90. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1990, </year> <pages> pp. 861-866. </pages>
Reference-contexts: A large number of representations have been successfully using to initialize neural networks with prior knowledge; decision trees [16], sets of propositional rules <ref> [20] </ref>, finite state automata [11, 6] and chains of networks [13] are but a few.
Reference: [21] <author> Valiant, L. G. </author> <title> A Theory of the Learnable. </title> <journal> Comm. ACM, </journal> <volume> vol. 27 (1984), </volume> <pages> pp. 1134-1142. 11 </pages>
Reference-contexts: Such inductive learning methods operate by detecting statistical regularities in the training data. As the complexity of the learning task increases, it becomes increasingly difficult to generalize well <ref> [7, 21] </ref>. In many learning contexts, such as robot learning, it can be prohibitively expensive to gather a sufficient number of examples to ensure good generalization. To overcome this dilemma, prior knowledge can be used to bias the learning algorithm to favor hypothesizes consistent with the prior knowledge.
References-found: 21

