URL: http://www.cs.cmu.edu/afs/cs/usr/pstone/public/papers/97synthetic-challenge/synthetic-challenge.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs/usr/pstone/mosaic/pstone-papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: kitano@csl.sony.co.jp tambe@isi.edu pstone@cs.cmu.edu  mmv@cs.cmu.edu silco@ida.liu.se osawa@csl.sony.co.jp  matsubar@etl.go.jp noda@etl.go.jp asada@mech.eng.osaka-u.ac.jp  
Title: The RoboCup Synthetic Agent Challenge 97  
Author: Hiroaki Kitano Milind Tambe Peter Stone Manuela Veloso Silvia Coradeschi Eiichi Osawa Hitoshi Matsubara Itsuki Noda Minoru Asada 
Affiliation: Sony Computer Science Laboratory ISI/USC Carnegie Mellon University  Carnegie Mellon University Linkoeping University Sony Computer Science Laboratory  ElectroTechnical Laboratory ElectroTechnical Laboratory Osaka University  
Abstract: RoboCup Challenge offers a set of challenges for intelligent agent researchers using a friendly competition in a dynamic, real-time, multi-agent domain. While RoboCup in general envisions longer range challenges over the next few decades, RoboCup Challenge presents three specific challenges for the next two years: (i) learning of individual agents and teams; (ii) multi-agent team planning and plan-execution in service of teamwork; and (iii) opponent modeling. RoboCup Challenge provides a novel opportunity for machine learning, planning, and multi-agent researchers | it not only supplies a concrete domain to evalute their techniques, but also challenges researchers to evolve these techniques to face key constraints fundamental to this domain: real-time, uncertainty, and teamwork.
Abstract-found: 1
Intro-found: 1
Reference: [ Asada et al., 1997 ] <author> Asada, M., Kuniyoshi, M., Drogoul, A., Asama, H., Mataric, M., Duhaut, D., Stone, P., and Kitano, H., </author> <title> "The RoboCup Physical Agent Challenge: </title> <journal> Phase-I," </journal> <note> To appear in Applied Artificial Intelligence (AAI) Journal, </note> <year> 1997. </year>
Reference-contexts: The RoboCup Physical Agent Challenge intends to promote research using real robot, and thus requires longer-time frame for each challenge to be accomplished. Details of this challange is described in <ref> [ Asada et al., 1997 ] </ref> , and carried out together with the RoboCup Synthetic Agent Challenge but in more moderate timeframe. The Infrstructure Challenge will be presented to facilitate research to establish infrastructure aspect of RoboCup, AI, and robotics in general.
Reference: [ Cohen and Levesque, 1991 ] <author> Cohen, P. R. and Levesque, H. J., </author> <booktitle> "Confirmation and Joint Action", Proceedings of International Joint Conf. on Artificial Intelligence, </booktitle> <year> 1991. </year>
Reference-contexts: However, teamwork is more than a simple union of such flexible individual behaviors, even if coordinated. A now well-known example (originally from <ref> [ Cohen and Levesque, 1991 ] </ref> ) is ordinary traffic, which even though simultaneous and coordinated by traffic signs, is not teamwork. <p> Indeed, theories of teamwork point to novel mental constructs as underlying teamwork, such as team goals, team plans, mutual beliefs, and joint commitments <ref> [ Grosz, 1996; Cohen and Levesque, 1991 ] </ref> , lacking in current agent architectures. In particular, team goals, team plans or mutual beliefs are not explicitly represented; furthermore, concepts of team commitments are absent.
Reference: [ Firby, 1987 ] <author> Firby, J., </author> <title> "An investigation into reactive planning in complex domains", </title> <booktitle> Proceedings of National Conf. on Artificial Intelligence, </booktitle> <year> 1987. </year>
Reference-contexts: The dynamics of the domain caused by the unpredictable opponent actions make the situation considerably more difficult. A fundamental reason for these teamwork limitations is the current agent architectures. Architectures such as Soar [ Newell, 1990 ] , RAP <ref> [ Firby, 1987 ] </ref> , IRMA [ Pollack, 1991 ] , and BB1 [ Hayes-Roth et al., 1995 ] facilitate an in-dividual agent's flexible behaviors via mechanisms such as commitments and reactive plans. However, teamwork is more than a simple union of such flexible individual behaviors, even if coordinated.
Reference: [ Grosz, 1996 ] <author> Grosz, B., </author> <title> "Collaborating Systems", </title> <journal> AI magazine, </journal> <volume> 17, </volume> <year> 1996. </year>
Reference-contexts: Indeed, theories of teamwork point to novel mental constructs as underlying teamwork, such as team goals, team plans, mutual beliefs, and joint commitments <ref> [ Grosz, 1996; Cohen and Levesque, 1991 ] </ref> , lacking in current agent architectures. In particular, team goals, team plans or mutual beliefs are not explicitly represented; furthermore, concepts of team commitments are absent.
Reference: [ Hayes-Roth et al., 1995 ] <author> Hayes-Roth, B. and Brownston, L. and Gen, R. V., </author> <title> "Multiagent collaobration in directed improvisation", </title> <booktitle> Proceedings of International Conf. on Multi-Agent Systems, </booktitle> <year> 1995. </year>
Reference-contexts: A fundamental reason for these teamwork limitations is the current agent architectures. Architectures such as Soar [ Newell, 1990 ] , RAP [ Firby, 1987 ] , IRMA [ Pollack, 1991 ] , and BB1 <ref> [ Hayes-Roth et al., 1995 ] </ref> facilitate an in-dividual agent's flexible behaviors via mechanisms such as commitments and reactive plans. However, teamwork is more than a simple union of such flexible individual behaviors, even if coordinated.
Reference: [ Jennings, 1995 ] <author> Jennings, N., </author> <title> "Controlling cooperative problem solving in industrial multi-agent systems using joint intentions", </title> <journal> Artificial Intelligence, </journal> <volume> 75, ,195-240, </volume> <year> 1995. </year>
Reference: [ Kitano et al., 1997a ] <author> Kitano, H., Asada, M., Osawa, E., Noda, I., Kuniyoshi, Y., Matsubara, H., </author> <title> "RoboCup: The Robot World Cup Initiative", </title> <booktitle> Proc. of the First International Conference on Autonomous Agent (Agent-97), </booktitle> <year> 1997. </year>
Reference-contexts: 1 Introduction RoboCup (The World Cup Robot Soccer) is an attempt to promote AI and robotics research by providing a common task, Soccer, for evaluation of various theories, algorithms, and agent architectures <ref> [ Kitano, et al., 1995; Kitano et al., 1997a; 1997b ] </ref> . Defining a standard problem in which various approaches can be compared and progress can be measured provides fertile grounds for engineering research. Computer chess has been a symbolic example of the standard challenge problems.
Reference: [ Kitano et al., 1997b ] <author> Kitano, H., Asada, M., Osawa, E., Noda, I., Kuniyoshi, Y., Matsubara, H., </author> <title> "RoboCup: A Challenge Problem for AI", </title> <journal> AI Magazine, </journal> <volume> Vol. 18, No. 1, </volume> <year> 1997. </year>
Reference: [ Kitano, et al., 1995 ] <author> Kitano, H. and Asada, M. and Ku-niyoshi, Y. and Noda, I. and Osawa, E., </author> <title> "RoboCup: The Robot World Cup Initiative", </title> <booktitle> IJCAI-95 Workshop on Entertainment and AI/Alife, </booktitle> <year> 1995 </year>
Reference-contexts: 1 Introduction RoboCup (The World Cup Robot Soccer) is an attempt to promote AI and robotics research by providing a common task, Soccer, for evaluation of various theories, algorithms, and agent architectures <ref> [ Kitano, et al., 1995; Kitano et al., 1997a; 1997b ] </ref> . Defining a standard problem in which various approaches can be compared and progress can be measured provides fertile grounds for engineering research. Computer chess has been a symbolic example of the standard challenge problems.
Reference: [ Newell, 1990 ] <author> Newell, A., </author> <title> Unified Theories of Cognition, </title> <publisher> Harvard Univ. Press, </publisher> <address> Cambridge, Mass., </address> <year> 1990. </year>
Reference-contexts: Indeed, typical planners need significantly longer to find even a single valid plan. The dynamics of the domain caused by the unpredictable opponent actions make the situation considerably more difficult. A fundamental reason for these teamwork limitations is the current agent architectures. Architectures such as Soar <ref> [ Newell, 1990 ] </ref> , RAP [ Firby, 1987 ] , IRMA [ Pollack, 1991 ] , and BB1 [ Hayes-Roth et al., 1995 ] facilitate an in-dividual agent's flexible behaviors via mechanisms such as commitments and reactive plans.
Reference: [ Pollack, 1991 ] <author> Pollack, M., </author> <title> "The uses of plans", </title> <journal> Artificial Intelligence, </journal> <volume> 57, </volume> <year> 1992. </year>
Reference-contexts: The dynamics of the domain caused by the unpredictable opponent actions make the situation considerably more difficult. A fundamental reason for these teamwork limitations is the current agent architectures. Architectures such as Soar [ Newell, 1990 ] , RAP [ Firby, 1987 ] , IRMA <ref> [ Pollack, 1991 ] </ref> , and BB1 [ Hayes-Roth et al., 1995 ] facilitate an in-dividual agent's flexible behaviors via mechanisms such as commitments and reactive plans. However, teamwork is more than a simple union of such flexible individual behaviors, even if coordinated.
Reference: [ Stone and Veloso, 1997 ] <author> Stone, P. and Veloso, M., </author> <title> "A layered approach to learning client behaviors in the robocup soccer server," </title> <note> To appear in Applied Artificial Intelligence (AAI) Journal, </note> <year> 1997. </year>
Reference-contexts: Since such skills are challenging to hand-code, learning can be useful during a skill development phase. However, since the skills are invariant from game to game, there is no need to relearn them at the beginning of each new game <ref> [ Stone and Veloso, 1997 ] </ref> . Off-line collaborative learning by teams of agents: learning to pass and receive the ball. This type of skill is qualitatively different from the individual skills in that the behaviors of multiple agents must be coordinated. <p> As above, such coordination can carry over from game to game, thus allowing off-line learning techniques to be used <ref> [ Stone and Veloso, 1997 ] </ref> . On-line skill and collaborative learning: learning to play positions. Although off-line learning methods can be useful in the above cases, there may also be advantages to learning incrementally as well.
Reference: [ Tambe, 1996a ] <author> Tambe, M., </author> <title> "Tracking dynamic team activity", </title> <booktitle> Proceedings of National Conf. on Artificial Intelligence, </booktitle> <year> 1996. </year>
Reference: [ Tambe, 1996b ] <author> Tambe, M., </author> <title> "Teamwork in real-world, dynamic environments", </title> <booktitle> Proc. International Conf. on Multi-agent Systems, </booktitle> <year> 1996. </year>
Reference-contexts: These issues pose some fundamental challenges that will significantly advance the state of the art in agent modeling. In particular, previous work has mostly focused on plan recognition in static, single-agent domains, without real-time constraints. Only recently has attention shifted to dynamic, real-time environments, and modeling of multi-agent teamwork <ref> [ Tambe, 1996b ] </ref> . A realistic challenge for IJCAI-99 will be to aim for online tracking. Optimistically, we expect some progress towards on-line strategy recognition; off-line review will likely require further research beyond IJCAI-99.
Reference: [ Tambe et al., 1995 ] <author> Tambe, M. and Johnson, W. and Jones, R. and Koss, F. and Laird, J. and Rosenbloom, P. and Schwamb, K., </author> <title> "Intelligent agents for interactive simulation environments", </title> <journal> AI Magazine, </journal> <volume> 16, </volume> <year> 1995. </year>
Reference-contexts: RoboCup offers a software platform that forms the basis of the software or synthetic agent league. The goal is to enable a wider range of research in synthetic (or "virtual reality") environments, that are today proving to be critical in training, entertainment, and education <ref> [ Tambe et al., 1995 ] </ref> .
References-found: 15

