URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/dayne/www/ps/proposal.ps.Z
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/dayne/www/cv.html
Root-URL: 
Email: dayne@cs.cmu.edu  
Title: Machine Learning for Information Extraction from Online Documents  
Author: Dayne Freitag 
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: The field of information extraction (IE) is concerned with applying natural language processing (NLP) to extract essential details from text documents automatically. Recent results have demonstrated the viability of this idea for collections of journalistic prose in narrow domains. The idea's appeal and applicability, however, is much broader than work to date seems to imply. In particular, the online environment is a rich source of domains in which an IE system would prove useful. Examples include collections of medical diagnoses that have been transcribed for machine storage, Internet recipe collections, official university Web sites, and "bboard" seminar announcements. If IE is to have an impact, however, it must be possible to adapt to new domains with a minimum of manual tuning. Furthermore, traditional IE regards a document only as a grammatical object; this is too limiting and may lead to less accurate extraction than is possible when other kinds of information, such as mark-up or layout, are available. The ultimate goal of this research is a system of IE tools which is retargetable. Rather than manually optimize an extraction system for each new domain, it should be possible to bootstrap it by demonstrating extraction on sample documents. I intend to show that such a system can be built using machine learning methods. A major theme will be the use of as much document information as possible, linguistic and non-linguistic. I will investigate how multiple learners can be employed and their various biases exploited to maximize system performance.
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Proceedings of the Fourth Message Understanding Conference (MUC-4), </institution> <address> McLean, Virginia, June 1992. </address> <publisher> Morgan Kaufmann Publisher, Inc., </publisher> <address> San Fran-cisco. </address>
Reference-contexts: In terms of linguistic sophistication, the quintessential information extraction task, as defined for this young field, lies somewhere between information retrieval and full text understanding. 1.2.1 MUC Under ARPA's leadership the IE community has lately come of age, convening almost annually as the Message Understanding Conference (MUC) <ref> [1] </ref> [2]. At this conference, participants' systems are subjected to rigorous blind tests on text domains drawn from the real world. The performance of tested systems has shown enough promise, while leaving plenty of room for improvement, to excite considerable interest in the field. <p> In general, therefore, it seems desirable either to use such figures for strictly comparative purposes, or to interpret them with some application in mind. 3 follow therefore, I sample some of the systems described in <ref> [1] </ref> and [2] with this in mind. A survey of the field reveals strong systems which, to judge from their descriptions, contain no significant machine learning components.
Reference: [2] <institution> Proceedings of the Fifth Message Understanding Conference (MUC-5), Bal-timore, Maryland, </institution> <address> August 1993. </address> <publisher> Morgan Kaufmann Publisher, Inc., </publisher> <address> San Francisco. </address>
Reference-contexts: In terms of linguistic sophistication, the quintessential information extraction task, as defined for this young field, lies somewhere between information retrieval and full text understanding. 1.2.1 MUC Under ARPA's leadership the IE community has lately come of age, convening almost annually as the Message Understanding Conference (MUC) [1] <ref> [2] </ref>. At this conference, participants' systems are subjected to rigorous blind tests on text domains drawn from the real world. The performance of tested systems has shown enough promise, while leaving plenty of room for improvement, to excite considerable interest in the field. <p> In general, therefore, it seems desirable either to use such figures for strictly comparative purposes, or to interpret them with some application in mind. 3 follow therefore, I sample some of the systems described in [1] and <ref> [2] </ref> with this in mind. A survey of the field reveals strong systems which, to judge from their descriptions, contain no significant machine learning components.
Reference: [3] <author> Helena Ahonen and Heikki Mannila. </author> <title> Forming grammars for structured documents: an application of grammatical inference. </title> <editor> In Rafael C. Carrasco and Jose Oncina, editors, </editor> <title> Grammatical Inference and Applications: </title> <booktitle> Second International Colloquium, ICGI-94, </booktitle> <pages> pages 153-167. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1994. </year>
Reference-contexts: The idea of applying grammar inference to the analysis of document structure is not novel. Ahonen and Mannila, for example, consider the problem of inducing a regular grammar for document structure from examples, where examples are documents such as dictionaries, encyclopedias, and user manuals <ref> [3] </ref>. Rus and Summers [32] attempt to infer trees that represent document structure based on indentation profiles. In the same work, novel methods for detecting tables and figures from whitespace measurements are described. Hidden Markov Models (HMM) [28] perform a kind of stochastic grammar inference.
Reference: [4] <author> Douglas E. Appelt, Jerry R. Hobbs, John Bear, David Israel, Megumi Kameyama, and Mabry Tyson. </author> <title> SRI: description of the JV-FASTUS system used for MUC-5. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5), </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: This approach sees further development in the CIRCUS system [18], where textual triggers, as introduced in the FASTUS system <ref> [4] </ref>, are generalized into concept nodes: syntactic extraction patterns centered on individual words which are acquired through statistical analysis of a training corpus. This approach has proven successful and has lead to further interesting developments.
Reference: [5] <author> Chidanand Apte, Fred Damerau, and Sholom M. Weiss. </author> <title> Automated learning of decision rules for text categorization. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 12(3) </volume> <pages> 233-251, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The two formats are mutually exclusive and are visible under different document views; a disjunctive learner is a natural fit to this class of field. Several recent papers have demonstrated the effectiveness of rule-learning systems in text classification. Apte et al <ref> [5] </ref> describe SWAP-1, a rule induction system which performs well on several standard text classification problems. Cohen [11] explores the applicability of relational learning to text classification.
Reference: [6] <author> Stephanie E. August and Charles P. Dolan. </author> <title> Hughes Research Laboratories: description of the trainable text skimmer used for MUC-4. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference (MUC-4), </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: This first appears in the Hughes Trainable Text Skimmer, in which both a k-nearest neighbor and a Bayesian classifier are applied to the problem of estimating the likelihood that a text fragment is an instantiation of a target field <ref> [6] </ref>. This approach sees further development in the CIRCUS system [18], where textual triggers, as introduced in the FASTUS system [4], are generalized into concept nodes: syntactic extraction patterns centered on individual words which are acquired through statistical analysis of a training corpus. <p> Entries in such a database, which is often manually constructed, frequently contain semantic information which is used in further analysis [24] [41], or they provide authoritative forms for entities which have varying textual realizations [25]. Less typically, entries are patterns which are used directly for extraction [25] <ref> [6] </ref> [18].
Reference: [7] <author> Rafael C. Carrasco and Jose Oncina, </author> <title> editors. Grammatical Inference and Applications: </title> <booktitle> Second International Colloquium, </booktitle> <address> ICGI-94. </address> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1994. </year> <month> 15 </month>
Reference-contexts: Insofar as this is possible, such patterns might be learnable by a hidden Markov model. The problem of grammar inference has a rich history in computer science and continues to attract much interest [40] <ref> [7] </ref>. Although the general problem of inferring languages from examples is known to be quite hard, work continues on special language classes and heuristic methods with good empirical performance. The idea of applying grammar inference to the analysis of document structure is not novel.
Reference: [8] <author> Noam Chomsky. </author> <title> Syntactic Structures. </title> <publisher> Mouton & Co., </publisher> <year> 1957. </year>
Reference-contexts: Text is sequential at multiple levels of granularity. Although language itself is characterized by super-regular structure <ref> [8] </ref>, several of the MUC systems use finite-state grammar approximations based on [26], rather than general parsers.
Reference: [9] <author> P. Clark and R. Boswell. </author> <title> Rule induction with CN2: some recent improvements. </title> <editor> In Y. Kodratoff, editor, </editor> <booktitle> Machine Learning - EWSL-91, </booktitle> <pages> pages 151-163. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: We might expect that other useful aspects of written text, such as capitalization and punctuation patterns, can be modeled effectively under Markovian assumptions. 2.3.4 Relational Rule Inference Learners in this class, such as CN2 [10] <ref> [9] </ref> FOIL [27], and BRUTE [35], can be used both in performing sub-tasks and in the integration of predictions from other learners.
Reference: [10] <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-263, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: We might expect that other useful aspects of written text, such as capitalization and punctuation patterns, can be modeled effectively under Markovian assumptions. 2.3.4 Relational Rule Inference Learners in this class, such as CN2 <ref> [10] </ref> [9] FOIL [27], and BRUTE [35], can be used both in performing sub-tasks and in the integration of predictions from other learners.
Reference: [11] <author> William W. Cohen. </author> <title> Learning to classify English text with ILP methods. </title> <booktitle> Advances in Inductive Logic Programming, </booktitle> <year> 1995. </year>
Reference-contexts: Several recent papers have demonstrated the effectiveness of rule-learning systems in text classification. Apte et al [5] describe SWAP-1, a rule induction system which performs well on several standard text classification problems. Cohen <ref> [11] </ref> explores the applicability of relational learning to text classification. Because such learners express learned concepts directly in terms of features, rather than summing evidence over multiple features as, for example, a Bayesian learner, they perform well in cases where concepts can be expressed succinctly.
Reference: [12] <author> Jim Cowie, Louise Guthrie, Wang Jin, Rong Wang, Takahiro Wakao, James Pustejovsky, and Scott Waterman. CRL/Brandeis: </author> <title> description of the Diderot system as used for MUC-5. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5), </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: This problem can be tackled, for example, at the paragraph level, and standard statistical approaches can be applied <ref> [12] </ref>. Another common application of learning is language modeling (e.g., [41]) for the construction of probabilistic parsers. The most interesting learning developments, from the perspective of this thesis, involve the acquisition of probabilistic extraction patterns.
Reference: [13] <author> Dayne Freitag. </author> <title> Machine learning for information extraction from online documents: a preliminary experiment, </title> <year> 1996. </year>
Reference-contexts: Many information extraction problems have this quality; stereotypic language use in a particular domain permits a succinct description of extraction patterns. 3 Preliminary Results In work described at length elsewhere <ref> [13] </ref>, I implemented and tested learners from three of the four classes enumerated above: a dictionary learner, a vector-space learner, and a relational learner. Learner performance was compared on four fields from a single document collection consisting of 485 electronic seminar announcements.
Reference: [14] <author> Jerry R. Hobbs. </author> <title> The generic information extraction system. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5), </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: with the more NLP-oriented systems. 1.2.2 Current approaches According to an active member of the MUC community, the "generic" information extraction system is a pipeline of ten components, ranging from preprocessing modules and filters, to linguistic components for syntactic and semantic analysis, to post-processing modules which construct a final answer <ref> [14] </ref>. More interesting for this thesis than the identification of these components in MUC systems is their use of machine learning methods. In the paragraphs that 1 They also imply that it is hard to define the information extraction task in a domain-independent way.
Reference: [15] <author> Jerry R. Hobbs, Douglas Appelt, Mabry Tyson, John Bear, and David Israel. </author> <title> SRI International: description of the FASTUS system used for MUC-4. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference (MUC-4), </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: Among the competitive systems in this class are those which rely on semantic analysis, as in standard NLP [17] [16], and those which attempt a cheaper approach but still require considerable manual engineering <ref> [15] </ref>. The widest use of machine learning in the field appears to be in filtering, deciding which portions of a document to subject to expensive further analysis, and which to discard as irrelevant [20].
Reference: [16] <author> Paul S. Jacobs, George Krupka, Lisa Rau, Michael L. Mauldin, Teruko Mi-tamura, Tsuyoshi Kitani, Ira Sider, and Lois Childs. GE-CMU: </author> <title> description of the shogun system used for MUC-5. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5), </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: A survey of the field reveals strong systems which, to judge from their descriptions, contain no significant machine learning components. Among the competitive systems in this class are those which rely on semantic analysis, as in standard NLP [17] <ref> [16] </ref>, and those which attempt a cheaper approach but still require considerable manual engineering [15]. The widest use of machine learning in the field appears to be in filtering, deciding which portions of a document to subject to expensive further analysis, and which to discard as irrelevant [20].
Reference: [17] <author> George Krupka, Paul Jacobs, and Lisa Rau. GE NLToolset: </author> <title> description of the system as used for MUC-4. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference (MUC-4), </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: A survey of the field reveals strong systems which, to judge from their descriptions, contain no significant machine learning components. Among the competitive systems in this class are those which rely on semantic analysis, as in standard NLP <ref> [17] </ref> [16], and those which attempt a cheaper approach but still require considerable manual engineering [15]. The widest use of machine learning in the field appears to be in filtering, deciding which portions of a document to subject to expensive further analysis, and which to discard as irrelevant [20].
Reference: [18] <author> W. Lehnert, J. McCarthy, S. Soderland, E. Riloff, C. Cardie, J. Peterson, and F. Feng. UMass/Hughes: </author> <title> description of the CIRCUS system used for MUC-5. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5), </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: This first appears in the Hughes Trainable Text Skimmer, in which both a k-nearest neighbor and a Bayesian classifier are applied to the problem of estimating the likelihood that a text fragment is an instantiation of a target field [6]. This approach sees further development in the CIRCUS system <ref> [18] </ref>, where textual triggers, as introduced in the FASTUS system [4], are generalized into concept nodes: syntactic extraction patterns centered on individual words which are acquired through statistical analysis of a training corpus. This approach has proven successful and has lead to further interesting developments. <p> Entries in such a database, which is often manually constructed, frequently contain semantic information which is used in further analysis [24] [41], or they provide authoritative forms for entities which have varying textual realizations [25]. Less typically, entries are patterns which are used directly for extraction [25] [6] <ref> [18] </ref>.
Reference: [19] <author> David D. Lewis. </author> <title> An evaluation of phrasal and clustered representations on a text categorization task. </title> <booktitle> In 15th International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: It is longstanding practice within IR to represent documents for retrieval as vectors of real numbers where each number corresponds to a document term [39]. TFIDF [33] [34], the standard weighting scheme, has also been used in document classification (or categorization <ref> [19] </ref>). The accepted approach to vector-space document classification is based on work done originally by Rocchio [31]. This work is relevant to the extent that an extraction problem can be cast as a classification problem.
Reference: [20] <author> David D. Lewis. </author> <title> Text filtering in MUC-3 and MUC-4. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference (MUC-4), </booktitle> <month> June </month> <year> 1992. </year> <month> 16 </month>
Reference-contexts: The widest use of machine learning in the field appears to be in filtering, deciding which portions of a document to subject to expensive further analysis, and which to discard as irrelevant <ref> [20] </ref>. This problem can be tackled, for example, at the paragraph level, and standard statistical approaches can be applied [12]. Another common application of learning is language modeling (e.g., [41]) for the construction of probabilistic parsers.
Reference: [21] <author> David D. Lewis and William A. Gale. </author> <title> A sequential algorithm for training text classifiers. </title> <booktitle> In Proceedings of the 17th International Conference on Research and Development in Information Retrieval, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: Related to TFIDF-based methods are probabilistic techniques. A common approach is one involving Bayes Rule, which uses term occurrence information directly and assumes statistical independence among terms <ref> [21] </ref>. In this approach, hypotheses are document class assignments and the frequency of individual terms evidence for or against hypotheses. 2.3.3 Grammar Inference Many fields obey strict syntactic rules. For example, seminar times, expressed numerically (e.g., "4:30 p.m."), follow a very predictable pattern.
Reference: [22] <author> T. M. Mitchell. </author> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18 </volume> <pages> 203-226, </pages> <year> 1982. </year>
Reference-contexts: In parallel work, AutoSlog became CRYSTAL, which searches the space of candidate concept nodes more thoroughly, relying on a specific-to-general ordering in the spirit of the Version Space algorithm [36] <ref> [22] </ref>.
Reference: [23] <author> Elke Mittendorf and Peter Schauble. </author> <title> Document and passage retrieval based on hidden Markov models. </title> <booktitle> In Proceedings of the 17th International Conference on Research and Development in Information Retrieval, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: Model-merging methods, as commonly used in grammar inference, have been shown effective when used in connection with HMM's [38]. Although HMM's have been applied extensively to speech processing, they have seen little use with written text. (One exception is <ref> [23] </ref>, where it is argued that HMM's can be used to model text effectively for information retrieval.) Nevertheless, HMM's are a useful technique for the construction of higher-level feature detectors. Text is sequential at multiple levels of granularity.
Reference: [24] <author> Kazunori Muraki, Shinichi Doi, and Shinich Ando. </author> <title> NEC: description of the VENIEX system as used for MUC-5. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5), </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Known variously as a keyword "dictionary" or "lexicon," the notion of a simple component that holds domain-specific values is widespread in the MUC community. Entries in such a database, which is often manually constructed, frequently contain semantic information which is used in further analysis <ref> [24] </ref> [41], or they provide authoritative forms for entities which have varying textual realizations [25]. Less typically, entries are patterns which are used directly for extraction [25] [6] [18].
Reference: [25] <author> William W. Noah and Rollin V. Weeks. TRW: </author> <title> description of the DEFT system as used for MUC-5. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5), </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Entries in such a database, which is often manually constructed, frequently contain semantic information which is used in further analysis [24] [41], or they provide authoritative forms for entities which have varying textual realizations <ref> [25] </ref>. Less typically, entries are patterns which are used directly for extraction [25] [6] [18]. <p> Entries in such a database, which is often manually constructed, frequently contain semantic information which is used in further analysis [24] [41], or they provide authoritative forms for entities which have varying textual realizations <ref> [25] </ref>. Less typically, entries are patterns which are used directly for extraction [25] [6] [18].
Reference: [26] <author> Fernando Pereira. </author> <title> Finite-state approximations of grammars. </title> <booktitle> In Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 20-25, </pages> <address> Hidden Valley, Pennsylvania, </address> <year> 1990. </year>
Reference-contexts: Text is sequential at multiple levels of granularity. Although language itself is characterized by super-regular structure [8], several of the MUC systems use finite-state grammar approximations based on <ref> [26] </ref>, rather than general parsers.
Reference: [27] <author> J. R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <booktitle> Machine Learning, </booktitle> <year> 1990. </year>
Reference-contexts: We might expect that other useful aspects of written text, such as capitalization and punctuation patterns, can be modeled effectively under Markovian assumptions. 2.3.4 Relational Rule Inference Learners in this class, such as CN2 [10] [9] FOIL <ref> [27] </ref>, and BRUTE [35], can be used both in performing sub-tasks and in the integration of predictions from other learners.
Reference: [28] <author> L. R. Rabiner and B. H. Juang. </author> <title> An introduction to hidden Markov models. </title> <journal> IEEE ASSP Magazine, </journal> <pages> pages 4-16, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: Rus and Summers [32] attempt to infer trees that represent document structure based on indentation profiles. In the same work, novel methods for detecting tables and figures from whitespace measurements are described. Hidden Markov Models (HMM) <ref> [28] </ref> perform a kind of stochastic grammar inference. Model-merging methods, as commonly used in grammar inference, have been shown effective when used in connection with HMM's [38].
Reference: [29] <author> Ellen Riloff and Wendy Lehnert. </author> <title> Information extraction as a basis for high-precision text classification. </title> <journal> ACM Transactions on Information Systems, </journal> <year> 1994. </year>
Reference-contexts: Other interesting work on the same system involves using information extraction as a basis for document classification and using machine learning for co-reference resolution <ref> [29] </ref> [37]. 1.2.3 Departures from traditional IE Although much of the work described above serves as an inspiration for this proposal, our focus is different from that of "traditional" IE. All MUC domains require, and most systems fielded at MUC emphasize, a NLP-intensive 4 approach to extraction.
Reference: [30] <author> Ellen Riloff and Jay Shoen. </author> <title> Automatically acquiring conceptual patterns without an annotated corpus. </title> <booktitle> Proceedings of the Third Workshop on Very Large Corpora, </booktitle> <year> 1995. </year>
Reference-contexts: This collection was then manually reviewed to build the dictionary. This approach subsequently evolved in two distinct directions. AutoSlog became AutoSlog-TS, doing away with the need for an annotated corpus, relying instead on two document sets, relevant and irrelevant <ref> [30] </ref>. In parallel work, AutoSlog became CRYSTAL, which searches the space of candidate concept nodes more thoroughly, relying on a specific-to-general ordering in the spirit of the Version Space algorithm [36] [22].
Reference: [31] <author> J. Rocchio. </author> <title> Relevance feedback in information retrieval. In The SMART Retrieval System: Experiments in Automatic Document Processing. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1971. </year>
Reference-contexts: TFIDF [33] [34], the standard weighting scheme, has also been used in document classification (or categorization [19]). The accepted approach to vector-space document classification is based on work done originally by Rocchio <ref> [31] </ref>. This work is relevant to the extent that an extraction problem can be cast as a classification problem. If we regard the text fragments we get by sliding a fixed-size window over a document themselves as documents, we can apply these methods directly.
Reference: [32] <author> Daniela Rus and Kristen Summers. </author> <title> Using white space for automated document structuring. </title> <type> Technical Report TR94-1452, </type> <institution> Cornell University, </institution> <year> 1994. </year>
Reference-contexts: The idea of applying grammar inference to the analysis of document structure is not novel. Ahonen and Mannila, for example, consider the problem of inducing a regular grammar for document structure from examples, where examples are documents such as dictionaries, encyclopedias, and user manuals [3]. Rus and Summers <ref> [32] </ref> attempt to infer trees that represent document structure based on indentation profiles. In the same work, novel methods for detecting tables and figures from whitespace measurements are described. Hidden Markov Models (HMM) [28] perform a kind of stochastic grammar inference.
Reference: [33] <author> Gerard Salton, </author> <title> editor. The SMART Retrieval System: Experiments in Automatic Document Processing. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1971. </year>
Reference-contexts: Alternatively, the text segments can be treated as small documents for the purpose of TFIDF weighting and Rocchio-style prototyping. It is longstanding practice within IR to represent documents for retrieval as vectors of real numbers where each number corresponds to a document term [39]. TFIDF <ref> [33] </ref> [34], the standard weighting scheme, has also been used in document classification (or categorization [19]). The accepted approach to vector-space document classification is based on work done originally by Rocchio [31]. This work is relevant to the extent that an extraction problem can be cast as a classification problem.
Reference: [34] <author> Gerard Salton and Chris Buckley. </author> <title> Term weighting approaches in automatic text retrieval. </title> <type> Technical Report 87-881, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1987. </year>
Reference-contexts: Alternatively, the text segments can be treated as small documents for the purpose of TFIDF weighting and Rocchio-style prototyping. It is longstanding practice within IR to represent documents for retrieval as vectors of real numbers where each number corresponds to a document term [39]. TFIDF [33] <ref> [34] </ref>, the standard weighting scheme, has also been used in document classification (or categorization [19]). The accepted approach to vector-space document classification is based on work done originally by Rocchio [31]. This work is relevant to the extent that an extraction problem can be cast as a classification problem.
Reference: [35] <author> R. Segal and O. Etzioni. </author> <title> Learning decision lists using homogeneous rules. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: We might expect that other useful aspects of written text, such as capitalization and punctuation patterns, can be modeled effectively under Markovian assumptions. 2.3.4 Relational Rule Inference Learners in this class, such as CN2 [10] [9] FOIL [27], and BRUTE <ref> [35] </ref>, can be used both in performing sub-tasks and in the integration of predictions from other learners. At the sub-task level, they can be used effectively in conjunction with simple syntactic analysis because of their ability to form rules using multiple words and grammatical relations to express sophisticated grammatical patterns.
Reference: [36] <author> S. Soderland, D. Fisher, J. Aseltine, and W. Lehnert. </author> <title> CRYSTAL: Inducing a conceptual dictionary. </title> <booktitle> Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: In parallel work, AutoSlog became CRYSTAL, which searches the space of candidate concept nodes more thoroughly, relying on a specific-to-general ordering in the spirit of the Version Space algorithm <ref> [36] </ref> [22].
Reference: [37] <author> Stephen Soderland and Wendy Lehnert. Wrap-Up: </author> <title> a trainable discourse module for information extraction. </title> <journal> Journal of Artificial Intelligence Research, </journal> <year> 1994. </year>
Reference-contexts: Other interesting work on the same system involves using information extraction as a basis for document classification and using machine learning for co-reference resolution [29] <ref> [37] </ref>. 1.2.3 Departures from traditional IE Although much of the work described above serves as an inspiration for this proposal, our focus is different from that of "traditional" IE. All MUC domains require, and most systems fielded at MUC emphasize, a NLP-intensive 4 approach to extraction.
Reference: [38] <author> Andreas Stolcke and Stephen M. Omohundro. </author> <title> Best-first model merging for hidden Markov induction. </title> <type> Technical Report TR-94-003, </type> <institution> International Computer Science Institute, Berkeley, California, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: In the same work, novel methods for detecting tables and figures from whitespace measurements are described. Hidden Markov Models (HMM) [28] perform a kind of stochastic grammar inference. Model-merging methods, as commonly used in grammar inference, have been shown effective when used in connection with HMM's <ref> [38] </ref>.
Reference: [39] <author> C. J. van Rijsbergen. </author> <title> Information Retrieval. </title> <publisher> Butterworths, Inc., </publisher> <address> Boston, </address> <year> 1979. </year>
Reference-contexts: Alternatively, the text segments can be treated as small documents for the purpose of TFIDF weighting and Rocchio-style prototyping. It is longstanding practice within IR to represent documents for retrieval as vectors of real numbers where each number corresponds to a document term <ref> [39] </ref>. TFIDF [33] [34], the standard weighting scheme, has also been used in document classification (or categorization [19]). The accepted approach to vector-space document classification is based on work done originally by Rocchio [31].
Reference: [40] <author> Enrique Vidal. </author> <title> Grammatical inference: an introductory survey. </title> <editor> In Rafael C. Carrasco and Jose Oncina, editors, </editor> <title> Grammatical Inference and Applications: </title> <booktitle> Second International Colloquium, ICGI-94, </booktitle> <pages> pages 1-4. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1994. </year>
Reference-contexts: Insofar as this is possible, such patterns might be learnable by a hidden Markov model. The problem of grammar inference has a rich history in computer science and continues to attract much interest <ref> [40] </ref> [7]. Although the general problem of inferring languages from examples is known to be quite hard, work continues on special language classes and heuristic methods with good empirical performance. The idea of applying grammar inference to the analysis of document structure is not novel.
Reference: [41] <author> Ralph Weischedel, Damaris Ayuso, Sean Boisen, Heidi Fox, Robert In-gria, Tomoyoshi Matsukawa, Constantine Papageorgiou, Dawn MacLaugh-lin, Masaichiro Kitagawa, Tsutomu Sakai, June Abe, Hiroto Hosihi, Yoichi Miyamoto, and Scott Miller. BBS: </author> <title> description of the PLUM system as used for MUC-5. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5), </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: This problem can be tackled, for example, at the paragraph level, and standard statistical approaches can be applied [12]. Another common application of learning is language modeling (e.g., <ref> [41] </ref>) for the construction of probabilistic parsers. The most interesting learning developments, from the perspective of this thesis, involve the acquisition of probabilistic extraction patterns. <p> Known variously as a keyword "dictionary" or "lexicon," the notion of a simple component that holds domain-specific values is widespread in the MUC community. Entries in such a database, which is often manually constructed, frequently contain semantic information which is used in further analysis [24] <ref> [41] </ref>, or they provide authoritative forms for entities which have varying textual realizations [25]. Less typically, entries are patterns which are used directly for extraction [25] [6] [18].
Reference: [42] <author> Craig A. </author> <title> Will. Comparing human and machine performance for natural language information extraction: results for English microelectronics from the MUC-5 evaluation. </title> <booktitle> In Proceedings of the Fifth Message Understanding Conference (MUC-5), </booktitle> <month> August </month> <year> 1993. </year> <month> 18 </month>
Reference-contexts: A study involving the data from one domain used in MUC-5 suggested the gap between machine and human performance was about 20-30%; humans achieved 82% precision with 79% recall, while the best automatic systems got 57% precision with 53% recall <ref> [42] </ref>.
References-found: 42

