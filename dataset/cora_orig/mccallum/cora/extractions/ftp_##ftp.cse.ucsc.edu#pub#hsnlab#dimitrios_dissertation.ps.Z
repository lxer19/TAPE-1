URL: ftp://ftp.cse.ucsc.edu/pub/hsnlab/dimitrios_dissertation.ps.Z
Refering-URL: http://www.cse.ucsc.edu/research/hsnlab/publications/publications_sorted_by_subject.html
Root-URL: http://www.cse.ucsc.edu
Title: Traffic Scheduling in Packet-Switched Networks: Analysis, Design, and Implementation  
Author: Anujan Varma J.J. Garcia-Luna-Aceves Patrick E. Mantey Dean 
Degree: A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Computer Engineering by Dimitrios Stiliadis  The dissertation of Dimitrios Stiliadis is approved:  
Date: June 1996  
Affiliation: University of California Santa Cruz  of Graduate Studies and Research  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Adiseshu, G. Parulkar, and G. Varghese, </author> <title> "Reliable FIFO load balancing over multiple FIFO channels," </title> <type> tech. rep., </type> <institution> Washington University, St. Louis, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Credit counters are reset at the beginning of the frame to the maximum amount of traffic that the connection may transmit during a frame, and a connection is not eligible for service if its credit counter is zero. The simplicity of the algorithm allows a high-speed implementation <ref> [1, 55, 77, 81, 82] </ref>. As in stop-and-go queueing, the maximum delay is proportional to the maximum frame size. The requirement for a fine bandwidth allocation results in a large frame-size and thus high end-to-end delay bounds. Delay Earliest Due Date Delay-Earliest-Due-Date (Delay-EDD) belongs to the sorted priority service disciplines. <p> This deficit is then added to i in the next round while servicing traffic from connection i. Another variation of the round-robin service disciplines is the Surplus Round Robin (SRR) <ref> [1, 30] </ref>.
Reference: [2] <author> A. </author> <title> Alles, "ATM internetworking," </title> <type> tech. rep., </type> <institution> Cisco Systems, Inc., </institution> <note> http://www.cisco.com/warp/public/614/12.html, 1995. </note>
Reference-contexts: It is also apparent from the current trends of network design, that both open-loop and closed-loop methods of control will need to be integrated in the network in order to satisfy the different application requirements <ref> [2, 48, 105] </ref>. Open-loop control will be used for real-time applications and closed-loop control for data or non-real time traffic. However, the links are shared by the two types of control and thus only one traffic scheduling algorithm can be used.
Reference: [3] <author> Altera Corporation, </author> <title> FLEX 8000 Handbook, </title> <month> July </month> <year> 1994. </year>
Reference-contexts: FPGAs are ideally suited to building reconfigurable hardware systems. Devices such as the Altera FLEX family and the Xilinx FPGAs use RAM-based lookup tables as their basic logic element, thus allowing in-system configurability <ref> [3, 96] </ref>. FPGA-based prototyping aids are a valuable tool in hardware development. For example, the QuickTurn system, based on Xilinx FPGA devices, is widely used in the industry for hardware prototyping [95].
Reference: [4] <author> T. E. Anderson, S. S. Owicki, J. B. Saxe, and C. P. Thacker, </author> <title> "High speed switch scheduling for local area networks," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 11, </volume> <pages> pp. 319-52, </pages> <month> November </month> <year> 1993. </year> <note> Also as Digital Systems Research Center Technical Report, No. 99. </note>
Reference-contexts: The problem of switching the maximum number of packets in a crossbar with windowed or randomly accessed queues can be reduced to the matching problem in a bipartite graph <ref> [4] </ref>. The bipartite graph is constructed by representing each input port with a vertex in a first group and each output port with a vertex in a second group. <p> First, we restrict ourselves to input-buffered crossbar switches. Anderson et. al. <ref> [4] </ref> designed a maximal matching algorithm, called probabilistic iterative matching, for performing packet-scheduling in an input-buffered crossbar switch by finding maximal matchings in a bipartite graph [4]. The algorithm is simple and easily realizable in hardware. <p> First, we restrict ourselves to input-buffered crossbar switches. Anderson et. al. <ref> [4] </ref> designed a maximal matching algorithm, called probabilistic iterative matching, for performing packet-scheduling in an input-buffered crossbar switch by finding maximal matchings in a bipartite graph [4]. The algorithm is simple and easily realizable in hardware. Although probabilistic iterative matching is very efficient in keeping the output links utilized, it does not provide any mechanism for allocating the bandwidth of an output link among the input links with traffic directed to it. <p> We also assume the packets to be of fixed length, such as an ATM cell. The problem of switching the maximum number of packets in a crossbar with randomly accessed queues can be reduced to the matching problem in a bipartite graph <ref> [4] </ref>. The bipartite graph is constructed by representing each input port with a vertex in a first group and each output port with a vertex in a second group. <p> Anderson, Owicki, and Saxe designed an alternative to the optimal algorithm, called probabilistic iterative matching, for performing packet-scheduling in an input-buffered crossbar switch by finding maximal matchings in a bipartite graph <ref> [4] </ref>. The algorithm is simple and easily realizable in hardware. In this algorithm, scheduling of packets in each cycle is made through a sequence of three actions. First, each input sends request signals in parallel to every output port with which it could be matched. <p> Although finding a maximal matching using the probabilistic matching algorithm may, in the worst case, take N iterations, an average of O (log N ) iterations has been shown to 31 be sufficient <ref> [4] </ref>. Simulations have shown that the algorithm was able to find a maximal matching in a 16 fi 16 switch after 4 iterations over 99.9% of the time [4]. Because of the probabilistic nature of the algorithm, it can only provide probabilistic upper bounds on packet delays. <p> in the worst case, take N iterations, an average of O (log N ) iterations has been shown to 31 be sufficient <ref> [4] </ref>. Simulations have shown that the algorithm was able to find a maximal matching in a 16 fi 16 switch after 4 iterations over 99.9% of the time [4]. Because of the probabilistic nature of the algorithm, it can only provide probabilistic upper bounds on packet delays. Probabilistic iterative matching is very efficient in keeping the output links utilized. <p> In addition, in a network of switches, flows going through a large number of switches may receive considerably less bandwidth as compared to those going through a small number of switches <ref> [4] </ref>. Anderson, Owicki, and Saxe suggested two alternatives to probabilistic iterative matching for providing bandwidth guarantees [4]. The first is restricted to Constant Bit Rate 32 (CBR) traffic, where an explicit schedule of packet transmissions is constructed between input-output pairs taking into account the bandwidth demand of each flow. <p> In addition, in a network of switches, flows going through a large number of switches may receive considerably less bandwidth as compared to those going through a small number of switches <ref> [4] </ref>. Anderson, Owicki, and Saxe suggested two alternatives to probabilistic iterative matching for providing bandwidth guarantees [4]. The first is restricted to Constant Bit Rate 32 (CBR) traffic, where an explicit schedule of packet transmissions is constructed between input-output pairs taking into account the bandwidth demand of each flow. There are two problems with this approach. <p> Since the matching process is initiated by the outputs, it is possible that an input port is selected to receive the grant signal when it has no packets to transmit. This limits the maximum throughput of statistical matching to approximately 72% of the link capacity <ref> [4] </ref>. In addition, the algorithm involves computation of several probability distributions in each step, making its hardware implementation difficult. <p> The average number of iterations for probabilistic iterative matching to yield a maximal matching has been shown to be O (log 2 N ) <ref> [4] </ref>. This is because the number of unresolved requests is reduced by an average of at least 3 4 in each iteration. <p> Theorem 2.1: The average number of iterations to reach a maximal matching with weighted probabilistic iterative matching is within (log 2 N + 4=3) for an N -port switch. Proof: The proof is identical to that of Anderson, et. al. <ref> [4] </ref> except for the fact that not all requests submitted by input ports in each cycle participate in the matching process. Initially, a maximum of N 2 =4 requests is generated by the input ports. <p> With N 2 initial requests, the expected number of unresolved requests at the end of the ith iteration is no more than N 2 =4 i . The remainder of the proof follows the same steps as that of Anderson, et. al. <ref> [4] </ref>, and are therefore omitted. Thus, the expected value of the number of iterations to reach convergence does not exceed log 2 N + 4=3. <p> This causes the delay to be much higher compared to WPIM at low loads. Also, the maximum bandwidth utilization of statistical matching has been shown to be no more than 72% <ref> [4] </ref>. This causes the switch to saturate at a much lower load than in the case of WPIM, resulting in much higher delays at heavy load. <p> Observe that the misbehaving connection is able to use about 11% of the output bandwidth under statistical matching, although its reservation is only 5%. This is because our implementation of statistical matching employ two iterations, as discussed in <ref> [4] </ref>, which results in a higher service rate for input 4 than its reservation. Another advantage of weighted iterative matching is that it allows flexible allocation of bandwidth between real-time connections that require bandwidth guarantees and best-effort connections.
Reference: [5] <author> C. Aras, J. Kurose, D. Reeves, and H. Schulzrinne, </author> <title> "Real-time communications in packet-switched networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 82, </volume> <pages> pp. 122-139, </pages> <year> 1994. </year>
Reference-contexts: algorithms that can support all the diverse requirements of integrated-services networks that we describe in more detail in the next section. 1.3 A Common Framework There are several methods proposed in the literature for designing a scheduler architecture for an integrated-services network [8, 18, 28, 46, 82] (for a survey <ref> [5] </ref>). Most of these approaches are driven by the fact that real-time applications have stricter requirements from the network than data applications, and are based on the concept of static priorities. The basic concept is the assignment of different priorities to different types of applications. <p> If broadband packet networks were to ultimately replace circuit-switched networks, they will need to support a set of applications that can not accept any packet-losses or unpredictable delays. A good example was presented in <ref> [5] </ref>; distributed system applications for controlling nuclear or other sensitive equipment in real time can not tolerate any delayed or lost messages since they are critical to the safe operation of 229 the system. Similarly, emergency communications must be always carried out, even if the network utilization is sacrificed.
Reference: [6] <author> J. M. Arnold, D. A. Buell, and E. G. Davis, </author> <title> "Splash 2," </title> <booktitle> in Proceedings of the 4th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 316-324, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: For example, the QuickTurn system, based on Xilinx FPGA devices, is widely used in the industry for hardware prototyping [95]. Several other efforts have been reported in the literature for building reconfigurable hardware 196 systems for prototyping or emulation of complex systems such as SIMD architectures <ref> [6, 35] </ref>, MIMD parallel processors [10], neural networks [20], accelerators for scientific computation [66], and general-purpose coprocessors [12, 89]. In addition, advances in high-level hardware description languages and synthesis tools have significantly reduced the time for hardware system prototyping [65].
Reference: [7] <institution> ATM Forum, User-Network Interface 4.0. </institution>
Reference-contexts: This need, for a minimum bandwidth allocation for best-effort traffic, has been identified both by Clark et. al. in [18] as well as by the ATM Forum in the specification of the ABR traffic <ref> [7] </ref>. Some of the previous methods assumed that the highest-priority class is served 19 in a non-work-conserving manner, so that although it is guaranteed a portion of the link bandwidth, the lower priority classes will not be starved.
Reference: [8] <author> A. Banerjea, D. Ferrari, B. Mah, and M. Moran, </author> <title> "The Tenet real-time protocol suite: design, implementation, and experiences," </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> vol. 4, no. 1, </volume> <pages> pp. 1-10, </pages> <year> 1996. </year>
Reference-contexts: to bandwidth allocation algorithms and more specifically to algorithms that can support all the diverse requirements of integrated-services networks that we describe in more detail in the next section. 1.3 A Common Framework There are several methods proposed in the literature for designing a scheduler architecture for an integrated-services network <ref> [8, 18, 28, 46, 82] </ref> (for a survey [5]). Most of these approaches are driven by the fact that real-time applications have stricter requirements from the network than data applications, and are based on the concept of static priorities.
Reference: [9] <author> M. Barel, </author> <title> "Fast hardware random number generator for the Tausworthe sequence," </title> <booktitle> in Proceedings 16th Annual Simulation Symposium, </booktitle> <pages> pp. 121-135, </pages> <year> 1983. </year>
Reference-contexts: In addition, the random-number generator needs to be invoked multiple times for generating cells from the different virtual channels sharing the same input port. We use a parallel implementation of the Tausworthe random number generator to create a long uniformly distributed sequence <ref> [9, 76, 88] </ref>. Such a sequence can be converted to any 202 external host other distribution by a table lookup and interpolation. For example, the alias method can be used to generate any discrete random variate having a finite range of values [58, 61, 94].
Reference: [10] <author> L. Barroso, S. Iman, J. Jeong, K. Oner, K. Ramamurthy, and M. Dubois, </author> <title> "The USC multiprocessor testbed project: Project overview," </title> <type> Tech. Rep. 15, </type> <institution> University of Southern California, </institution> <year> 1994. </year>
Reference-contexts: Several other efforts have been reported in the literature for building reconfigurable hardware 196 systems for prototyping or emulation of complex systems such as SIMD architectures [6, 35], MIMD parallel processors <ref> [10] </ref>, neural networks [20], accelerators for scientific computation [66], and general-purpose coprocessors [12, 89]. In addition, advances in high-level hardware description languages and synthesis tools have significantly reduced the time for hardware system prototyping [65]. Models of the ATM switch architecture and associated hardware are developed in VHDL.
Reference: [11] <author> J. Bennett and H. Zhang, </author> <title> "WF 2 Q: Worst-case fair weighted fair queueing," </title> <booktitle> in Proceedings of INFOCOM 96, </booktitle> <pages> pp. 120-128, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: An improvement of Weighted Fair Queueing, referred to as Worst-case Weighted Fair Queueing (W 2 FQ) was recently proposed to improve even further the fairness properties of the algorithm <ref> [11] </ref>. In both approaches, a maximum of V events may be triggered in the GPS simulator during the transmission of one packet [57]. Thus, the process overhead for completing a scheduling decision is O (V ), making the implementation of the algorithm prohibitively expensive in most cases. <p> It is hoped that this framework will lead to the development of other scheduling algorithms in the future. Recently, a new algorithm was proposed for approximating Generalized-Processor Sharing, called Worst-Case Fair Weighted Fair Queueing <ref> [11] </ref>. This approach improves the discrepancy of the packet-by-packet algorithm from the fluid version. The algorithm, however, still requires parallel simulation of the fluid-model. A similar approach can be applied to the packet-by-packet version of any rate-proportional server, and to SPFQ in particular. <p> Extension of our work in this direction may yield fundamental results. 228 The framework of rate-proportional servers, introduced in Chapter 4, will likely lead to the development of other scheduling algorithms. For example, a new algorithm was recently proposed for approximating Generalized-Processor Sharing, called Worst-Case Fair Weighted Fair Queueing <ref> [11] </ref>. This approach improves the discrepancy of the packet-by-packet algorithm from the fluid version. The algorithm, however, still requires parallel simulation of the fluid model. A similar approach can be applied to the packet-by-packet version of any rate-proportional server, and to SPFQ in particular.
Reference: [12] <author> P. Bertin, D. Roncin, and J. Vuillemin, </author> <title> "Programmable active memories: a performance assessment," </title> <booktitle> in Proceedings of the International ACM/SIGDA Workshop on Field Programmable Gate Arrays, </booktitle> <pages> pp. 57-59, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: Several other efforts have been reported in the literature for building reconfigurable hardware 196 systems for prototyping or emulation of complex systems such as SIMD architectures [6, 35], MIMD parallel processors [10], neural networks [20], accelerators for scientific computation [66], and general-purpose coprocessors <ref> [12, 89] </ref>. In addition, advances in high-level hardware description languages and synthesis tools have significantly reduced the time for hardware system prototyping [65]. Models of the ATM switch architecture and associated hardware are developed in VHDL. Commercial hardware synthesis tools are used for mapping the VHDL models to the FPGAs.
Reference: [13] <author> D. Bertsekas and R. Gallager, </author> <title> Data networks. </title> <publisher> Prentice-Hall, </publisher> <year> 1987. </year>
Reference-contexts: Buffering is required in the intermediate nodes of the network to absorb traffic bursts and avoid packet losses. This approach is based on the key principle of statistical multiplexing <ref> [13] </ref>. However, it is apparent from the definition of statistical multiplexing, that although the network may operate efficiently in most cases, congestion may degrade its performance in either short or long intervals of time.
Reference: [14] <author> P. V. E. Boas, R. Kaas, and E. Zijlstra, </author> <title> "Design and implementation of an efficient priority queue," </title> <journal> Mathematical Systems Theory, </journal> <volume> vol. 10, </volume> <pages> pp. 99-127, </pages> <year> 1977. </year>
Reference-contexts: Traditional heap algorithms for insertion and deletion have a complexity of O (log 2 V ) for V virtual channels. There are a number of ways for reducing this complexity for ATM networks where timestamps take integer values in a finite range. A recursive algorithm was proposed in <ref> [14, 64, 69] </ref> for implementing add and delete operations in such a priority queue with O (log log V ) time complexity, where V is the number of elements in the queue.
Reference: [15] <author> F. Bonomi and K. Fendick, </author> <title> "The rate-based flow control framework for the available bit rate ATM service," </title> <journal> IEEE Network, </journal> <volume> vol. 9, </volume> <pages> pp. 25-39, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: End nodes probe the state of the network and adjust the application traffic so that they can receive a fair-share of the network resources without introducing congestion. Several methods have been proposed in the literature to detect the state of the network and notify the end 4 nodes <ref> [15, 42, 47, 56, 59, 72, 79] </ref>. 2 When the network is congested, sources are notified within a round-trip time and they reduce their transmission rate to alleviate congestion. Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. <p> The basic requirement imposed by these schemes is that the link bandwidth must be equally distributed among the competing streams based on the arrival patterns, congestion in downstream network nodes, or initial reservations. Finally, Bonomi and Fendick <ref> [15] </ref> claim that even rate-based flow control schemes such as the method adopted for the support of Available-Bit-Rate (ABR) traffic in ATM networks can see significant improvement in performance in terms of transient behavior, fairness and delay by the use of a sophisticated scheduling mechanism.
Reference: [16] <author> R. Brown, </author> <title> "Calendar queues: a fast 0(1) priority queue implementation for the simulation event set problem," </title> <journal> Communications of the ACM, </journal> <volume> vol. 31, </volume> <pages> pp. 1220-1227, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: The last two operations are identical for any sorted-priority architecture. A parallel implementation of these operations with O (1) time complexity by using a set of O (V ) simple processing elements has been shown <ref> [16, 17] </ref>. Frame-based algorithms such as Weighted Round Robin and Deficit Round Robin can be implemented in O (1) time, without any timestamp calculations. Unfortunately, these algorithms yield delay bounds that may grow linearly with the number of sessions sharing the outgoing link.
Reference: [17] <author> H. Chao and N. Uzun, </author> <title> "A VLSI sequencer chip for ATM traffic shaper and queue manager," </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 27, </volume> <pages> pp. 1634-1643, </pages> <month> November </month> <year> 1992. </year> <month> 231 </month>
Reference-contexts: The last two operations are identical for any sorted-priority architecture. A parallel implementation of these operations with O (1) time complexity by using a set of O (V ) simple processing elements has been shown <ref> [16, 17] </ref>. Frame-based algorithms such as Weighted Round Robin and Deficit Round Robin can be implemented in O (1) time, without any timestamp calculations. Unfortunately, these algorithms yield delay bounds that may grow linearly with the number of sessions sharing the outgoing link.
Reference: [18] <author> D. D. Clark, S. Shenker, and L. Zhang, </author> <title> "Supporting real-time applications in an integrated services packet network: Architecture and mechanism," </title> <booktitle> in Proceedings of ACM SIGCOMM '92, </booktitle> <pages> pp. 14-26, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Such an approach implies a connection-oriented network. Open-loop control is an efficient method of control for applications that require a constant flow of data with predictable delay and delay-jitter bounds, such as multimedia applications <ref> [18, 29, 44, 45, 71] </ref>. In such a network, the traffic scheduling algorithm is the method that dynamically allocates the network resources at each hop of the network, so that packets will see predictable delays in the network. <p> At the same time, the scheduling mechanism must not sacrifice the utilization of the link capacity in order to be able to provide this guaranteed performance <ref> [18] </ref>. In closed-loop control, the network operates like a feedback control system [56]. End nodes probe the state of the network and adjust the application traffic so that they can receive a fair-share of the network resources without introducing congestion. <p> to bandwidth allocation algorithms and more specifically to algorithms that can support all the diverse requirements of integrated-services networks that we describe in more detail in the next section. 1.3 A Common Framework There are several methods proposed in the literature for designing a scheduler architecture for an integrated-services network <ref> [8, 18, 28, 46, 82] </ref> (for a survey [5]). Most of these approaches are driven by the fact that real-time applications have stricter requirements from the network than data applications, and are based on the concept of static priorities. <p> Notice, that these simulation results depend on the characterization of the input traffic. However, as new types of applications are developed, such a characterization may be impossible. Clark et. al. follow a similar approach of characterizing traffic classes, although they use a different method for providing guarantees <ref> [18] </ref>. Under this architecture, there are again three classes of traffic. Guaranteed-delay traffic has always the highest priority. However, a 18 Weighted-Fair-Queueing scheduler is employed for providing isolation between connections belonging to this class. Adaptive applications form the second class, and use only the bandwidth left-over from the higher class. <p> At the same time, the delay and throughput bounds of higher priority classes are not sacrificed. This need, for a minimum bandwidth allocation for best-effort traffic, has been identified both by Clark et. al. in <ref> [18] </ref> as well as by the ATM Forum in the specification of the ABR traffic [7].
Reference: [19] <author> T. Cormen, C. Leiserson, and R. Rivest, </author> <title> Introduction to Algorithms. </title> <address> New York: McGraw Hill, </address> <year> 1989. </year>
Reference-contexts: Selection of the cell with the minimum timestamp for transmission: Since the cells are stored in a sorted-priority structure, the cell with the highest priority may be retrieved in O (log V ) time <ref> [19] </ref>. The last two operations are identical for any sorted-priority architecture. A parallel implementation of these operations with O (1) time complexity by using a set of O (V ) simple processing elements has been shown [16, 17].
Reference: [20] <author> C. Cox and W. Blanz, </author> <title> "GANGLION a fast field-programmable gate array implementation of a connectionist classifier," </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> vol. 27, </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: Several other efforts have been reported in the literature for building reconfigurable hardware 196 systems for prototyping or emulation of complex systems such as SIMD architectures [6, 35], MIMD parallel processors [10], neural networks <ref> [20] </ref>, accelerators for scientific computation [66], and general-purpose coprocessors [12, 89]. In addition, advances in high-level hardware description languages and synthesis tools have significantly reduced the time for hardware system prototyping [65]. Models of the ATM switch architecture and associated hardware are developed in VHDL.
Reference: [21] <author> R. Cruz, </author> <title> "A calculus for network delay. I. Network elements in isolation.," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 37, </volume> <pages> pp. 114-131, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Note, that isolation is necessary even when policing mechanisms are used to shape the flows at the entry point of the network, as the flows may accumulate burstiness within the network <ref> [21, 22] </ref>. 2. Low end-to-end delays: The algorithm must provide end-to-end delay guarantees for individual sessions. Note here, that in a work-conserving system, low end-to-end delays imply low buffer requirements for guaranteeing no packet losses. <p> The most common approach for bounding the burstiness of input traffic is by shaping through a leaky bucket [91]. Several previous studies have used this traffic model <ref> [21, 22, 70, 71] </ref>. We will use a more general approach and we will bound the worst-case service offered from the network to an application based on the scheduling algorithm used and without specifying the characteristics of the arrival traffic. <p> We also show how the latency parameter can be computed for a given scheduling algorithm by deriving the latencies of several well-known schedulers. Our approach in modeling the worst-case behavior of scheduling algorithms with respect to an end-to-end session is related to the work of Cruz <ref> [21, 22] </ref>, Zhang [101], and Parekh and Gallager [70, 71]. Cruz [21, 22] analyzed the end-to-end delay, buffer requirements, and internal network burstiness of sessions in an arbitrary topology network where all sources are leaky-bucket controlled. <p> Our approach in modeling the worst-case behavior of scheduling algorithms with respect to an end-to-end session is related to the work of Cruz <ref> [21, 22] </ref>, Zhang [101], and Parekh and Gallager [70, 71]. Cruz [21, 22] analyzed the end-to-end delay, buffer requirements, and internal network burstiness of sessions in an arbitrary topology network where all sources are leaky-bucket controlled.
Reference: [22] <author> R. Cruz, </author> <title> "A calculus for network delay. II. Network analysis," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 37, </volume> <pages> pp. 132-141, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Note, that isolation is necessary even when policing mechanisms are used to shape the flows at the entry point of the network, as the flows may accumulate burstiness within the network <ref> [21, 22] </ref>. 2. Low end-to-end delays: The algorithm must provide end-to-end delay guarantees for individual sessions. Note here, that in a work-conserving system, low end-to-end delays imply low buffer requirements for guaranteeing no packet losses. <p> The most common approach for bounding the burstiness of input traffic is by shaping through a leaky bucket [91]. Several previous studies have used this traffic model <ref> [21, 22, 70, 71] </ref>. We will use a more general approach and we will bound the worst-case service offered from the network to an application based on the scheduling algorithm used and without specifying the characteristics of the arrival traffic. <p> We also show how the latency parameter can be computed for a given scheduling algorithm by deriving the latencies of several well-known schedulers. Our approach in modeling the worst-case behavior of scheduling algorithms with respect to an end-to-end session is related to the work of Cruz <ref> [21, 22] </ref>, Zhang [101], and Parekh and Gallager [70, 71]. Cruz [21, 22] analyzed the end-to-end delay, buffer requirements, and internal network burstiness of sessions in an arbitrary topology network where all sources are leaky-bucket controlled. <p> Our approach in modeling the worst-case behavior of scheduling algorithms with respect to an end-to-end session is related to the work of Cruz <ref> [21, 22] </ref>, Zhang [101], and Parekh and Gallager [70, 71]. Cruz [21, 22] analyzed the end-to-end delay, buffer requirements, and internal network burstiness of sessions in an arbitrary topology network where all sources are leaky-bucket controlled. <p> We will now proceed to prove bounds on backlog and delay over multiple nodes. The straightforward approach would be to accumulate the maximum delays over each node. This approach was used by Cruz <ref> [22] </ref>. However, this method ignores the correlation between arrivals at two servers in series, and therefore results in very loose bounds.
Reference: [23] <author> R. Cruz, </author> <title> "Quality of service guarantees in virtual circuit switched networks," </title> <journal> IEEE Journal on Selected Areas In Communications, </journal> <volume> vol. 13, </volume> <pages> pp. 1048-1056, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: The bound on the service offered by an LR-server is based on the busy period. This is a more general approach than bounding the service offered by the server based on the concept of the backlogged period. An approach based on the latter was proposed in <ref> [23, 24] </ref> for providing QoS guarantees. This model bounds the service offered to a connection during one or more backlogged periods, thus providing a means to design a class of scheduling algorithms that can provide specific end-to-end delay guarantees.
Reference: [24] <author> R. Cruz and H. Liu, </author> <title> "End-to-end queueing delay in ATM networks," </title> <journal> Journal of High Speed Networks, </journal> <volume> vol. 2, no. 3, </volume> <pages> pp. 149-164, </pages> <year> 1994. </year>
Reference-contexts: The bound on the service offered by an LR-server is based on the busy period. This is a more general approach than bounding the service offered by the server based on the concept of the backlogged period. An approach based on the latter was proposed in <ref> [23, 24] </ref> for providing QoS guarantees. This model bounds the service offered to a connection during one or more backlogged periods, thus providing a means to design a class of scheduling algorithms that can provide specific end-to-end delay guarantees.
Reference: [25] <author> J. Davin and A. Heybey, </author> <title> "A simulation study of fair queueing and policy enforcement," </title> <journal> Computer Communication Review, </journal> <volume> vol. 20, </volume> <pages> pp. 23-29, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: Thus, the process overhead for completing a scheduling decision is O (V ), making the implementation of the algorithm prohibitively expensive in most cases. Self-Clocked Fair Queueing In order to reduce the complexity of Weighted Fair Queueing, an approximate implementation was proposed in <ref> [25, 37, 75] </ref> and was analyzed in [37] under the name Self-Clocked Fair Queueing (SCFQ). In this implementation, the timestamp of an arriving packet is computed based on the packet currently in service.
Reference: [26] <author> A. Demers, S. Keshav, and S. Shenker, </author> <title> "Analysis and simulation of a fair queueing algorithm," Internetworking: </title> <journal> Research and Experience, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 3-26, </pages> <year> 1990. </year>
Reference-contexts: Non-work-conserving algorithms are also used to control delay jitter by delaying packets that arrive early [93]. Work-conserving servers always have lower average delays than non-work-conserving servers. Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) [70], Weighted Fair Queueing <ref> [26] </ref>, VirtualClock [104], Delay-Earliest-Due-Date (Delay-EDD) [29], Weighted Round Robin [55], and Deficit Round Robin [81]. On the other hand, Hierarchical-Round-Robin (HRR) [51], Stop-and-Go queueing [36], and Jitter-Earliest-Due-Date [93] are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure [103]. <p> The worst-case service seen by an application will not be affected by the behavior of other connections. Generalized Processor Sharing Generalized-Processor-Sharing (GPS) is an ideal scheduling discipline <ref> [26, 70] </ref> (Figure 1.4). GPS multiplexing is defined with respect to a fluid-model, where packets are considered to be infinitely divisible. The share of bandwidth reserved by session i is represented by a real number i . <p> This results in perfect isolation, ideal fairness, and low end-to-end session delays. A packet-by-packet version of the algorithm, known as PGPS or Weighted Fair Queueing <ref> [26] </ref>, was defined in terms of a virtual clock that is increased with rate equal to 1 i2B (t;t) i A GPS system is simulated in parallel with the packet-by-packet system in order to identify the set of connections that are backlogged at each time. <p> However, it does not allow any flexibility in bandwidth allocation. In addition, the algorithm is incapable of providing fairness among the input ports transmitting to a common output port if their bandwidth demands are not identical. According to the criteria defined in <ref> [26] </ref>, a network is fair if every user is allocated exactly the bandwidth it requested; in addition, if a user is removed from the system, the extra bandwidth will be distributed equally among the other competing flows. <p> This follows from the fact that when all credits are satisfied, the algorithm reduces to simple iterative matching that allocates the bandwidth equally among all inputs requesting access to a given output port. In this sense, the algorithm meets the fairness criteria defined in <ref> [26, 72] </ref>. When an input-output connection increases its traffic rate, the performance of all others will be equally degraded, but they will still continue to receive at least their reserved bandwidth.
Reference: [27] <author> B. Dixon, </author> <title> "Concurrency in an O(log log N ) priority queue," </title> <booktitle> in Proceeding of Parallel and Distributed Computing. Theory and Practice. First Canada-France Conference, </booktitle> <pages> pp. 59-71, </pages> <year> 1994. </year>
Reference-contexts: In this algorithm D denotes the smallest interval between successive elements in the priority queue. Applying this algorithm to Frame-based Fair Queueing results in a complexity of O (log log F ), where F is the frame size. Furthermore, Dixon presented a method for pipelining such an algorithm <ref> [27] </ref>. Note that, in an N fi N output-buffered ATM switch, a maximum of N cells may be added to the priority list in one cell cycle while only one cell is selected for transmission.
Reference: [28] <author> D. Ferrari, A. Banerjea, and H. Zhang, </author> <title> "Network support for multimedia: A discussion of the Tenet approach," </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> vol. 26, no. 10, </volume> <pages> pp. 1267-80, </pages> <year> 1994. </year>
Reference-contexts: to bandwidth allocation algorithms and more specifically to algorithms that can support all the diverse requirements of integrated-services networks that we describe in more detail in the next section. 1.3 A Common Framework There are several methods proposed in the literature for designing a scheduler architecture for an integrated-services network <ref> [8, 18, 28, 46, 82] </ref> (for a survey [5]). Most of these approaches are driven by the fact that real-time applications have stricter requirements from the network than data applications, and are based on the concept of static priorities. <p> Finally, best-effort traffic uses only the bandwidth left over from the two higher priority classes. The Tenet approach attempts to provide a broad range of Quality-of-Service guarantees <ref> [28] </ref>. Specifically, it introduces three types of guarantees. Deterministic guarantees for the highest-level class by doing peak-rate allocations and using Delay-Earliest Due Date scheduling in the network. Re-shaping of the traffic of each connection is required at each switching point, making the implementation expensive.
Reference: [29] <author> D. Ferrari and D. Verma, </author> <title> "A scheme for real-time channel establishment in wide-area networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 8, </volume> <pages> pp. 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Such an approach implies a connection-oriented network. Open-loop control is an efficient method of control for applications that require a constant flow of data with predictable delay and delay-jitter bounds, such as multimedia applications <ref> [18, 29, 44, 45, 71] </ref>. In such a network, the traffic scheduling algorithm is the method that dynamically allocates the network resources at each hop of the network, so that packets will see predictable delays in the network. <p> Non-work-conserving algorithms are also used to control delay jitter by delaying packets that arrive early [93]. Work-conserving servers always have lower average delays than non-work-conserving servers. Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) [70], Weighted Fair Queueing [26], VirtualClock [104], Delay-Earliest-Due-Date (Delay-EDD) <ref> [29] </ref>, Weighted Round Robin [55], and Deficit Round Robin [81]. On the other hand, Hierarchical-Round-Robin (HRR) [51], Stop-and-Go queueing [36], and Jitter-Earliest-Due-Date [93] are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure [103]. According to this classification there are two main architectures: sorted-priority and frame-based. <p> This definition of Delay-EDD is from <ref> [29] </ref>. Notice that, according to this definition, all packets are assumed to have the same size.
Reference: [30] <author> S. Floyd, </author> <title> "Notes on guaranteed service in resource management." </title> <booktitle> Unpublished notes, </booktitle> <year> 1993. </year>
Reference-contexts: This deficit is then added to i in the next round while servicing traffic from connection i. Another variation of the round-robin service disciplines is the Surplus Round Robin (SRR) <ref> [1, 30] </ref>.
Reference: [31] <author> S. Fotedar, M. Gerla, P. Crocetti, and L. Fratta, </author> <title> "ATM virtual private networks," </title> <journal> Communications of the ACM, </journal> <volume> vol. 38, </volume> <pages> pp. 101-109, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Another extension is to study hierarchical scheduling. Broadband networks and especially ATM networks are expected to be designed in a hierarchical fashion based on the virtual-path concept. In addition, service providers are now studying the possibility of building Virtual Private Networks (VPNs) over ATM <ref> [31] </ref>. A subnetwork of virtual paths will be allocated to a specific customer over a wide area. In each of the end nodes, the customer will multiplex a number of virtual circuits to one virtual path. Other architectures consider also the possibility of virtual-circuit to virtual-path multiplexing [68].
Reference: [32] <author> R. Fujimoto, </author> <title> "Parallel event-driven simulation," </title> <journal> Communications of the ACM, </journal> <volume> vol. 33, </volume> <pages> pp. 30-53, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: One approach to improve the speed of the simulation is to resort to parallel or distributed simulation, but this is a relatively expensive option. In addition, the speedup obtained by parallelizing event-driven simulators may be small because of their inherently serial nature <ref> [32] </ref>. Communication and synchronization bottlenecks also limit the achievable speedup. To address this problem, we have developed a flexible hardware testbed for the simulation of ATM switches and networks.
Reference: [33] <author> L. Georgiadis, R. Guerin, and A. Parekh, </author> <title> "Optimal multiplexing on a single link: Delay and buffer requirements," </title> <booktitle> in Proceedings of INFOCOM'94, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Georgiadis et.al. have expanded this definition for networks with arbitrary packet sizes <ref> [33, 34] </ref>.
Reference: [34] <author> L. Georgiadis, R. Guerin, V. Peris, and K.N.Sivarajan, </author> <title> "Efficient network QoS provisioning based on per node traffic shaping," </title> <booktitle> in Proceedings of INFOCOM'96, </booktitle> <pages> pp. 102-110, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Georgiadis et.al. have expanded this definition for networks with arbitrary packet sizes <ref> [33, 34] </ref>.
Reference: [35] <author> M. Gokhale, W. Holmes, A. Kopser, S. Lucas, R. Minnich, D. Sweely, and D. Lopresti, </author> <title> "Building and using a highly parallel programmable logic array," </title> <journal> IEEE Computer, </journal> <volume> no. 24, </volume> <pages> pp. 81-89, </pages> <year> 1991. </year> <month> 232 </month>
Reference-contexts: For example, the QuickTurn system, based on Xilinx FPGA devices, is widely used in the industry for hardware prototyping [95]. Several other efforts have been reported in the literature for building reconfigurable hardware 196 systems for prototyping or emulation of complex systems such as SIMD architectures <ref> [6, 35] </ref>, MIMD parallel processors [10], neural networks [20], accelerators for scientific computation [66], and general-purpose coprocessors [12, 89]. In addition, advances in high-level hardware description languages and synthesis tools have significantly reduced the time for hardware system prototyping [65].
Reference: [36] <author> S. Golestani, </author> <title> "A framing strategy for congestion management," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 9, </volume> <pages> pp. 1064-1077, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Work-conserving servers always have lower average delays than non-work-conserving servers. Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) [70], Weighted Fair Queueing [26], VirtualClock [104], Delay-Earliest-Due-Date (Delay-EDD) [29], Weighted Round Robin [55], and Deficit Round Robin [81]. On the other hand, Hierarchical-Round-Robin (HRR) [51], Stop-and-Go queueing <ref> [36] </ref>, and Jitter-Earliest-Due-Date [93] are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure [103]. According to this classification there are two main architectures: sorted-priority and frame-based.
Reference: [37] <author> S. Golestani, </author> <title> "A self-clocked fair queueing scheme for broadband applications," </title> <booktitle> in Proceedings of IEEE INFOCOM '94, </booktitle> <pages> pp. 636-646, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Thus, the process overhead for completing a scheduling decision is O (V ), making the implementation of the algorithm prohibitively expensive in most cases. Self-Clocked Fair Queueing In order to reduce the complexity of Weighted Fair Queueing, an approximate implementation was proposed in <ref> [25, 37, 75] </ref> and was analyzed in [37] under the name Self-Clocked Fair Queueing (SCFQ). In this implementation, the timestamp of an arriving packet is computed based on the packet currently in service. <p> Self-Clocked Fair Queueing In order to reduce the complexity of Weighted Fair Queueing, an approximate implementation was proposed in [25, 37, 75] and was analyzed in <ref> [37] </ref> under the name Self-Clocked Fair Queueing (SCFQ). In this implementation, the timestamp of an arriving packet is computed based on the packet currently in service. <p> In addition, sessions should not be penalized for excess bandwidth they received while other 22 sessions were idle. Following Golestani's work <ref> [37] </ref>, we define the fairness parameter of a scheduling algorithm as the maximum difference between the normalized service received by two backlogged connections over an interval in which both are continuously backlogged. <p> However, this analysis does not apply to unfair algorithms like VirtualClock. In addition to the delay analysis, we also study the fairness characteristics of LR-schedulers. The fairness analysis was motivated by Golestani's work <ref> [37] </ref>, where a self-contained approach for fairness was defined. This approach is based on comparing the normalized service offered to any two connections that are continuously backlogged over an interval of time. We will analyze many well-known scheduling algorithms belonging to the LR class using this approach. <p> In this section we analyze the fairness characteristics of several well-known LR servers and compare them. The fairness parameter that we use is based on the definition presented by Golestani <ref> [37] </ref> for analysis of self-clocked fair queueing. Let us assume that W S i (t; t) is the service offered to connection i in the interval (t; t] by server S. <p> However, this condition cannot be met by any packet-by-packet algorithm since packets must be serviced exclusively. Therefore, in a packet by packet server, we can only require that the difference in normalized service received by the connections be bounded by a constant. Golestani <ref> [37] </ref> suggested use of the difference in normalized service offered to any two connections as the measure of fairness for the algorithm [37]. <p> Therefore, in a packet by packet server, we can only require that the difference in normalized service received by the connections be bounded by a constant. Golestani <ref> [37] </ref> suggested use of the difference in normalized service offered to any two connections as the measure of fairness for the algorithm [37]. <p> service that a session may receive in a PGPS server in excess of that in the GPS server, given by C i = min (V 1) Lmax i 1nV L n ) : It can be shown that the above bound is tight. 3.4.2 Fairness of Self-Clocked Fair Queueing Golestani <ref> [37] </ref> proved the following bound for SCFQ: F S = i L j : We now prove that this bound is tight by presenting an example where the bound is actually reached. <p> Thus, if we represent the total amount of service received by each session by a function, then these functions can be seen to grow at the same rate for each backlogged session. Golestani <ref> [37] </ref> introduced such a function and called it virtual time. Virtual time of a backlogged session is a function whose rate of growth at each instant is exactly the rate of normalized service provided to it by the scheduler at that instant.
Reference: [38] <author> S. Golestani, </author> <title> "Network delay analysis of a class of fair queueing algorithms," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 13, </volume> <pages> pp. 1057-70, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: The LR-class provides a more natural approach for analyzing the worst-case behavior of traffic-scheduling algorithms, independent of the scheduler architecture. Finally, Golestani recently presented a delay analysis of a class of fair-queueing algorithms including Self-Clocked Fair Queueing <ref> [38] </ref>. However, this analysis does not apply to unfair algorithms like VirtualClock. In addition to the delay analysis, we also study the fairness characteristics of LR-schedulers. The fairness analysis was motivated by Golestani's work [37], where a self-contained approach for fairness was defined. <p> A large value of maximum delay may lead to increased burstiness and buffer requirements within the network if the session is going through multiple hops. This is consistent with the result in Chapter 3 and <ref> [38] </ref> where it was shown that the maximum end-to-end delay for SCFQ increases with the number of connections sharing the outgoing link. On studying the average delays seen by the individual traffic sessions, it is easy to verify that the SPFQ algorithm gives results very similar to that of WFQ.
Reference: [39] <author> P. Goyal, S. Lam, and H. Vin, </author> <title> "Determining end-to-end delay bounds in heterogeneous networks," </title> <booktitle> in Proceedings of the 5th International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pp. 287-298, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Our approach differs from this work in that we consider the broader class of work-conserving schedulers in our analysis, and we do not assume any traffic re-shaping mechanisms within the network. Another model for delay-analysis based on a class of guaranteed-rate servers was presented in <ref> [39] </ref>. A potential disadvantage of this model, however, is that it is closely coupled with time-stamp based algorithms; the analysis of scheduling algorithms based on a different architecture is not straightforward.
Reference: [40] <author> P. Goyal and H. Vin, </author> <title> "Generalized guaranteed rate scheduling algorithms: A framework," </title> <type> Tech. Rep. </type> <institution> TR-95-30, Dept. of Computer Science, U. Texas at Austin, </institution> <year> 1995. </year>
Reference-contexts: However, they assume rate-controllers that shape the traffic to a specific rate both at the entrance of the network and in individual switches. 16 Specifically for the case of networks with constant packet sizes, it was shown in <ref> [40, 107] </ref> that if certain schedulability conditions are satisfied, then the Delay-EDD algorithm can be employed in a work-conserving network providing flexible delay-bounds to applications; these delay bounds are independent of the bandwidth allocation.
Reference: [41] <author> A. Greenberg and N. </author> <title> Madras, "How fair is fair queueing?," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> vol. 39, no. 3, </volume> <pages> pp. 568-598, </pages> <year> 1992. </year>
Reference-contexts: Therefore, ^ W F j (0; t ) (4.36) By adding eq.(4.35) and eq.(4.36), ^ W F j (0; t) (4.37) 132 We will now use the above lemma and a method similar to the one presented in <ref> [41, 73] </ref> for the WFQ server to find an upper bound for the amount of service a session may receive in PRPS as compared to that in the fluid server.
Reference: [42] <author> E. Hahne, </author> <title> "Round-robin scheduling for max-min fairness in data networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 9, </volume> <pages> pp. 1024-39, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: End nodes probe the state of the network and adjust the application traffic so that they can receive a fair-share of the network resources without introducing congestion. Several methods have been proposed in the literature to detect the state of the network and notify the end 4 nodes <ref> [15, 42, 47, 56, 59, 72, 79] </ref>. 2 When the network is congested, sources are notified within a round-trip time and they reduce their transmission rate to alleviate congestion. Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. <p> Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. We just note here that schemes such as packet-pair [56], hop-by-hop flow control [59], window-based methods as in <ref> [42] </ref>, congestion-oriented multipath routing [67] and even rate-based methods such as [62], all require a traffic scheduling discipline that can provide a fair-share of the link bandwidth to the competing connections.
Reference: [43] <author> D. Heyman, A.Tabatabai, and T. Lakshman, </author> <title> "Statistical analysis and simulation study of video teleconference traffic in ATM networks," </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <volume> vol. 2, </volume> <pages> pp. 49-59, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The local memory of each traffic generator module can be used for storing the necessary lookup tables. More complex traffic models, for example a video stream, that can be modeled using Markov chains can be synthesized by implementing the Markov chain in hardware <ref> [43] </ref>. In addition, if a more realistic traffic model is desired, traffic can be injected into the testbed from an external source.
Reference: [44] <author> J. Hyman, A. Lazar, and G. Pacifici, </author> <title> "MARS: the Magnet II real-time scheduling algorithm," </title> <booktitle> in Proceedings of SIGCOMM'91, </booktitle> <pages> pp. 285-93, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Such an approach implies a connection-oriented network. Open-loop control is an efficient method of control for applications that require a constant flow of data with predictable delay and delay-jitter bounds, such as multimedia applications <ref> [18, 29, 44, 45, 71] </ref>. In such a network, the traffic scheduling algorithm is the method that dynamically allocates the network resources at each hop of the network, so that packets will see predictable delays in the network. <p> In other words, a lower priority application may use some of the network resources, only if all higher priority applications are idle. In the next paragraphs we will outline some of these schemes. In the MARS system there are three basic traffic classes <ref> [44, 45, 46] </ref>. Guaranteed-delay connections belong in the highest priority class. Connections that only require bounds on packet-losses form the second class and best-effort traffic belongs to the third class. The system is capable of providing guarantees only to traffic classes and not individual connections.
Reference: [45] <author> J. Hyman, A. Lazar, and G. Pacifici, </author> <title> "Real-time scheduling with quality of service constraints," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 9, </volume> <pages> pp. 1052-63, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Such an approach implies a connection-oriented network. Open-loop control is an efficient method of control for applications that require a constant flow of data with predictable delay and delay-jitter bounds, such as multimedia applications <ref> [18, 29, 44, 45, 71] </ref>. In such a network, the traffic scheduling algorithm is the method that dynamically allocates the network resources at each hop of the network, so that packets will see predictable delays in the network. <p> In other words, a lower priority application may use some of the network resources, only if all higher priority applications are idle. In the next paragraphs we will outline some of these schemes. In the MARS system there are three basic traffic classes <ref> [44, 45, 46] </ref>. Guaranteed-delay connections belong in the highest priority class. Connections that only require bounds on packet-losses form the second class and best-effort traffic belongs to the third class. The system is capable of providing guarantees only to traffic classes and not individual connections.
Reference: [46] <author> J. Hyman, A. Lazar, and G. Pacifici, </author> <title> "Joint scheduling and admission control for ATS-based switching nodes," </title> <booktitle> in Proceedings of SIGCOMM'92, </booktitle> <pages> pp. 223-234, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: to bandwidth allocation algorithms and more specifically to algorithms that can support all the diverse requirements of integrated-services networks that we describe in more detail in the next section. 1.3 A Common Framework There are several methods proposed in the literature for designing a scheduler architecture for an integrated-services network <ref> [8, 18, 28, 46, 82] </ref> (for a survey [5]). Most of these approaches are driven by the fact that real-time applications have stricter requirements from the network than data applications, and are based on the concept of static priorities. <p> In other words, a lower priority application may use some of the network resources, only if all higher priority applications are idle. In the next paragraphs we will outline some of these schemes. In the MARS system there are three basic traffic classes <ref> [44, 45, 46] </ref>. Guaranteed-delay connections belong in the highest priority class. Connections that only require bounds on packet-losses form the second class and best-effort traffic belongs to the third class. The system is capable of providing guarantees only to traffic classes and not individual connections.
Reference: [47] <author> V. Jacobson, </author> <title> "Congestion avoidance and control," </title> <booktitle> in Proceedings of ACM SIG-COMM '88, </booktitle> <pages> pp. 314-29, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: End nodes probe the state of the network and adjust the application traffic so that they can receive a fair-share of the network resources without introducing congestion. Several methods have been proposed in the literature to detect the state of the network and notify the end 4 nodes <ref> [15, 42, 47, 56, 59, 72, 79] </ref>. 2 When the network is congested, sources are notified within a round-trip time and they reduce their transmission rate to alleviate congestion. Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. <p> Users may act in a selfish manner by trying to utilize as much of the available bandwidth as possible [80]. Higher level protocols such as TCP incorporate mechanisms to utilize the maximum available bandwidth <ref> [47] </ref>. In addition, some of the input ports of the switch may need to use more than 1=N of the output bandwidth; probabilistic iterative matching can only guarantee them 1=N of the output bandwidth.
Reference: [48] <author> R. Jain, </author> <title> "Myths about congestion management in high-speed networks," </title> <journal> Internetwork-ing: Research and Experience, </journal> <volume> vol. 3, </volume> <pages> pp. 101-113, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Mechanisms for controlling integrated-services packet networks, so that the network can satisfy the diverse QoS requirements of applications, still retaining high utilization, have become a major topic of research the recent past <ref> [48] </ref>. The proposed control mechanisms can be broadly classified into two categories | open-loop and closed loop. In open-loop control, each application at call-setup time specifies its traffic characteristics (peak rate, average rate, burstiness, etc.) and its service requirements ( delay, jitter, loss rate, etc.). <p> It is also apparent from the current trends of network design, that both open-loop and closed-loop methods of control will need to be integrated in the network in order to satisfy the different application requirements <ref> [2, 48, 105] </ref>. Open-loop control will be used for real-time applications and closed-loop control for data or non-real time traffic. However, the links are shared by the two types of control and thus only one traffic scheduling algorithm can be used.
Reference: [49] <author> D. Johnson, </author> <title> "A priority queue in which initialization and queue operations take o(log log d) time," </title> <journal> Mathematical Systems Theory, </journal> <volume> vol. 15, </volume> <pages> pp. 295-309, </pages> <year> 1982. </year>
Reference-contexts: A recursive algorithm was proposed in [14, 64, 69] for implementing add and delete operations in such a priority queue with O (log log V ) time complexity, where V is the number of elements in the queue. These algorithms were further refined by Johnson <ref> [49] </ref> who presented a non-recursive algorithm with O (log log D) complexity for the add and delete operations. In this algorithm D denotes the smallest interval between successive elements in the priority queue.
Reference: [50] <author> L. Kalampoukas, A. Varma, and K.K. Ramakrishnan, </author> <title> "An efficient rate allocation algorithm for packet-switched networks providing max-min fairness," </title> <booktitle> in Proceedings of the IFIP Sixth International Conference on High-Performance Networking (HPN '95), </booktitle> <pages> pp. 143-154, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: availability of the FAST-1 testbed has already led to the development of two switch algorithms that significantly improve upon the implementation complexity of previous algorithms | the Frame-based Fair Queueing (FFQ) scheduling algorithm that was described in the previous chapter, and a rate allocation algorithm for support of ABR service <ref> [50] </ref>. The remainder of this chapter is organized as follows: Section 6.1 describes the architecture of the FAST-1 system and its key components. Section 6.2 discusses example implementations of two traffic scheduling algorithms in FAST-1. <p> The utilizations of the rest of the modules were in all cases below 50%. Specifically, in the output module, only two of the four chips in the MCM device were used in the implementation. This allows room for implementing a rate allocation algorithm for ABR traffic <ref> [50] </ref>.
Reference: [51] <author> C. Kalmanek, H. Kanakia, and S. Keshav, </author> <title> "Rate controlled servers for very high-speed networks," </title> <booktitle> in IEEE Global Telecommunications Conference, </booktitle> <pages> pp. </pages> <address> 300.3.1-300.3.9, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: Work-conserving servers always have lower average delays than non-work-conserving servers. Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) [70], Weighted Fair Queueing [26], VirtualClock [104], Delay-Earliest-Due-Date (Delay-EDD) [29], Weighted Round Robin [55], and Deficit Round Robin [81]. On the other hand, Hierarchical-Round-Robin (HRR) <ref> [51] </ref>, Stop-and-Go queueing [36], and Jitter-Earliest-Due-Date [93] are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure [103]. According to this classification there are two main architectures: sorted-priority and frame-based.
Reference: [52] <author> M. Karol, K. Eng, and H. Obara, </author> <title> "Improving the performance of input-queued ATM packet switches," </title> <booktitle> in Proceedings of INFOCOM'92, </booktitle> <pages> pp. 110-115, </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1992. </year> <month> 233 </month>
Reference-contexts: When the scheduler has access to more than one packet in each input buffer, the throughput can be maximized by matching the packets stored in the input queues to output ports such that the largest possible number of packets is scheduled for transmission in each cycle <ref> [52] </ref>. The problem of switching the maximum number of packets in a crossbar with windowed or randomly accessed queues can be reduced to the matching problem in a bipartite graph [4].
Reference: [53] <author> M. J. Karol, M. G. Hluchyj, and S. P. Morgan, </author> <title> "Input versus output queueing on a space-division packet switch," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 35, </volume> <pages> pp. 1347-56, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: This list can be just considered as the representative schemes from different philosophies. 5 In general, switch architectures may be classified into two main categories based on whether packets are buffered at the inputs or the outputs of the switch <ref> [53] </ref> (Figure 1.1). <p> Head-of-line contention has been shown to reduce the throughput of a crossbar with input buffering to approximately 58% of its capacity when the traffic is uniformly distributed <ref> [53] </ref>. The performance of an input-buffered crossbar can be improved by allowing the switch to choose one of several packets in the queue to transmit in each cycle.
Reference: [54] <author> R. Karp, U. Vazirani, and V. Vazirani, </author> <title> "An optimal algorithm for on-line bipartite matching," </title> <booktitle> in Proceedings of 22nd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pp. 352-358, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Optimal algorithms exist for bipartite matching with complexity of O (N 2 ) where N is the number of ports of the switch <ref> [54, 87] </ref>. However, the time available to compute a matching in an ATM switch is limited to the transmission time of a cell | less than 3 s at SONET OC-3 speeds. This makes the use of an optimal algorithm almost impractical.
Reference: [55] <author> M. Katevenis, S. Sidiropoulos, and C. Courcoubetis, </author> <title> "Weighted round-robin cell multiplexing in a general-purpose ATM switch chip," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 9, </volume> <pages> pp. 1265-79, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Non-work-conserving algorithms are also used to control delay jitter by delaying packets that arrive early [93]. Work-conserving servers always have lower average delays than non-work-conserving servers. Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) [70], Weighted Fair Queueing [26], VirtualClock [104], Delay-Earliest-Due-Date (Delay-EDD) [29], Weighted Round Robin <ref> [55] </ref>, and Deficit Round Robin [81]. On the other hand, Hierarchical-Round-Robin (HRR) [51], Stop-and-Go queueing [36], and Jitter-Earliest-Due-Date [93] are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure [103]. According to this classification there are two main architectures: sorted-priority and frame-based. <p> Credit counters are reset at the beginning of the frame to the maximum amount of traffic that the connection may transmit during a frame, and a connection is not eligible for service if its credit counter is zero. The simplicity of the algorithm allows a high-speed implementation <ref> [1, 55, 77, 81, 82] </ref>. As in stop-and-go queueing, the maximum delay is proportional to the maximum frame size. The requirement for a fine bandwidth allocation results in a large frame-size and thus high end-to-end delay bounds. Delay Earliest Due Date Delay-Earliest-Due-Date (Delay-EDD) belongs to the sorted priority service disciplines. <p> Deficit Round Robin is a generalization of the Weighted-Round-Robin algorithm that was proposed in the context of ATM networks <ref> [55] </ref>. The latter assumes that packets from all connections have the same size and connections are serviced in a round-robin order. The time is split into frames of maximum size F and a connection is not allowed to send more than i packets during a frame period.
Reference: [56] <author> S. Keshav, </author> <title> "A control-theoretic approach to flow control," </title> <booktitle> in Proceedings of ACM SIGCOMM'91, </booktitle> <month> September </month> <year> 1991. </year>
Reference-contexts: At the same time, the scheduling mechanism must not sacrifice the utilization of the link capacity in order to be able to provide this guaranteed performance [18]. In closed-loop control, the network operates like a feedback control system <ref> [56] </ref>. End nodes probe the state of the network and adjust the application traffic so that they can receive a fair-share of the network resources without introducing congestion. <p> End nodes probe the state of the network and adjust the application traffic so that they can receive a fair-share of the network resources without introducing congestion. Several methods have been proposed in the literature to detect the state of the network and notify the end 4 nodes <ref> [15, 42, 47, 56, 59, 72, 79] </ref>. 2 When the network is congested, sources are notified within a round-trip time and they reduce their transmission rate to alleviate congestion. Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. <p> Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. We just note here that schemes such as packet-pair <ref> [56] </ref>, hop-by-hop flow control [59], window-based methods as in [42], congestion-oriented multipath routing [67] and even rate-based methods such as [62], all require a traffic scheduling discipline that can provide a fair-share of the link bandwidth to the competing connections.
Reference: [57] <author> S. Keshav, </author> <title> "On the efficient implementation of fair queueing," Internetworking: </title> <journal> Research and Experience, </journal> <volume> vol. 2, </volume> <pages> pp. 157-173, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: In both approaches, a maximum of V events may be triggered in the GPS simulator during the transmission of one packet <ref> [57] </ref>. Thus, the process overhead for completing a scheduling decision is O (V ), making the implementation of the algorithm prohibitively expensive in most cases.
Reference: [58] <author> R. Kronmal and A. Peterson, </author> <title> "On the alias method for generating random variables from a discrete distribution," </title> <journal> American Statistician, </journal> <volume> vol. 33, </volume> <pages> pp. 214-218, </pages> <year> 1979. </year>
Reference-contexts: Such a sequence can be converted to any 202 external host other distribution by a table lookup and interpolation. For example, the alias method can be used to generate any discrete random variate having a finite range of values <ref> [58, 61, 94] </ref>. The local memory of each traffic generator module can be used for storing the necessary lookup tables. More complex traffic models, for example a video stream, that can be modeled using Markov chains can be synthesized by implementing the Markov chain in hardware [43].
Reference: [59] <author> H. T. Kung, T. Blackwell, and A. Chapman, </author> <title> "Credit-based flow control for ATM networks: Credit update protocol, adaptive credit allocation, and statistical multiplexing," </title> <booktitle> in Proceedings of ACM SIGCOMM '94, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: End nodes probe the state of the network and adjust the application traffic so that they can receive a fair-share of the network resources without introducing congestion. Several methods have been proposed in the literature to detect the state of the network and notify the end 4 nodes <ref> [15, 42, 47, 56, 59, 72, 79] </ref>. 2 When the network is congested, sources are notified within a round-trip time and they reduce their transmission rate to alleviate congestion. Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. <p> Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. We just note here that schemes such as packet-pair [56], hop-by-hop flow control <ref> [59] </ref>, window-based methods as in [42], congestion-oriented multipath routing [67] and even rate-based methods such as [62], all require a traffic scheduling discipline that can provide a fair-share of the link bandwidth to the competing connections.
Reference: [60] <author> S. Lam and G. Xie, </author> <title> "Burst scheduling: Architecture and algorithm for switching packet video," </title> <booktitle> in Proceedings of INFOCOM'95, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Since the latencies of PGPS and VirtualClock are identical, the bound of (3.2) applies to VirtualClock as well; this is also in agreement with the results of Lam and Xie <ref> [60] </ref>. While we have verified that this improvement of L i = i in the delay bound is valid for all the LR servers we analyzed, whether this is true for all LR servers remains an open question.
Reference: [61] <author> A. Law and W. </author> <title> Kelton, Simulation Modeling & Analysis. </title> <address> Mc-Graw Hill, </address> <publisher> Inc., </publisher> <year> 1991. </year>
Reference-contexts: Such a sequence can be converted to any 202 external host other distribution by a table lookup and interpolation. For example, the alias method can be used to generate any discrete random variate having a finite range of values <ref> [58, 61, 94] </ref>. The local memory of each traffic generator module can be used for storing the necessary lookup tables. More complex traffic models, for example a video stream, that can be modeled using Markov chains can be synthesized by implementing the Markov chain in hardware [43].
Reference: [62] <author> S. Mascolo, D. Gavendish, and M. Gerla, </author> <title> "ATM rate based congestion control using a Smith predictor: An EPRCA implementation," </title> <booktitle> in Proceedings of INFOCOM'96, </booktitle> <pages> pp. 569-576, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. We just note here that schemes such as packet-pair [56], hop-by-hop flow control [59], window-based methods as in [42], congestion-oriented multipath routing [67] and even rate-based methods such as <ref> [62] </ref>, all require a traffic scheduling discipline that can provide a fair-share of the link bandwidth to the competing connections.
Reference: [63] <author> N. McKeown, V. Anantharam, and J. Walrand, </author> <title> "Achieving 100% throughput in an input-queued switch," </title> <booktitle> in Proceedings of INFOCOM'96, </booktitle> <pages> pp. 296-302, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: It has been shown, however, that when the inputs require a unequal portions of the output link bandwidth even a maximum matching can result in unfairness and instability <ref> [63] </ref>. In addition, none of the existing approaches for traffic scheduling in input-buffered 9 all packets arriving at the input ports are available immediately for transmission. switches incorporate any means for providing bandwidth guarantees. Thus, the offer no isolation for a traffic session from other, possibly misbehaving, sessions.
Reference: [64] <author> K. Mehlhorn, </author> <title> Data structures and algorithms. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: Traditional heap algorithms for insertion and deletion have a complexity of O (log 2 V ) for V virtual channels. There are a number of ways for reducing this complexity for ATM networks where timestamps take integer values in a finite range. A recursive algorithm was proposed in <ref> [14, 64, 69] </ref> for implementing add and delete operations in such a priority queue with O (log log V ) time complexity, where V is the number of elements in the queue.
Reference: [65] <author> G. </author> <title> Micheli, Synthesis and Optimization of Digital Circuits. </title> <booktitle> McGraw-Hill Series in Electrical and Computer Engineering, </booktitle> <year> 1994. </year>
Reference-contexts: In addition, advances in high-level hardware description languages and synthesis tools have significantly reduced the time for hardware system prototyping <ref> [65] </ref>. Models of the ATM switch architecture and associated hardware are developed in VHDL. Commercial hardware synthesis tools are used for mapping the VHDL models to the FPGAs.
Reference: [66] <author> S. Monaghan and P. Noakes, </author> <title> "Reconfigurable special-purpose hardware for scientific computation and simulation," </title> <journal> Computer & Control Engineering Journal, </journal> <volume> vol. 3, </volume> <pages> pp. 225-234, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Several other efforts have been reported in the literature for building reconfigurable hardware 196 systems for prototyping or emulation of complex systems such as SIMD architectures [6, 35], MIMD parallel processors [10], neural networks [20], accelerators for scientific computation <ref> [66] </ref>, and general-purpose coprocessors [12, 89]. In addition, advances in high-level hardware description languages and synthesis tools have significantly reduced the time for hardware system prototyping [65]. Models of the ATM switch architecture and associated hardware are developed in VHDL.
Reference: [67] <author> S. Murthy and J. Garcia-Luna-Aceves, </author> <title> "Congestion-oriented multipath routing," </title> <booktitle> in Proceedings of INFOCOM'96, </booktitle> <pages> pp. 1028-36, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. We just note here that schemes such as packet-pair [56], hop-by-hop flow control [59], window-based methods as in [42], congestion-oriented multipath routing <ref> [67] </ref> and even rate-based methods such as [62], all require a traffic scheduling discipline that can provide a fair-share of the link bandwidth to the competing connections.
Reference: [68] <author> R. Onvural, </author> <title> Asynchronous Transfer Mode Networks: Performance Issues, </title> <journal> ch. </journal> <volume> 6, </volume> <pages> pp. 191-200. </pages> <publisher> Artech House Inc., </publisher> <year> 1994. </year>
Reference-contexts: A subnetwork of virtual paths will be allocated to a specific customer over a wide area. In each of the end nodes, the customer will multiplex a number of virtual circuits to one virtual path. Other architectures consider also the possibility of virtual-circuit to virtual-path multiplexing <ref> [68] </ref>. The theory of LR-servers can be used to study end-to-end delays, burstiness, and buffer requirements in these architectures. A third extension of the theory of LR-servers is to study packet loss probabilities and end-to-end delay bounds if the buffers in the network are restricted.
Reference: [69] <author> P. Van Emde Boas, </author> <title> "Preserving order in a forest in less than logarithmic time," </title> <booktitle> in Proceedings of 16th IEEE Conference on Foundations of Computer Science, </booktitle> <pages> pp. 75-84, </pages> <year> 1975. </year>
Reference-contexts: Traditional heap algorithms for insertion and deletion have a complexity of O (log 2 V ) for V virtual channels. There are a number of ways for reducing this complexity for ATM networks where timestamps take integer values in a finite range. A recursive algorithm was proposed in <ref> [14, 64, 69] </ref> for implementing add and delete operations in such a priority queue with O (log log V ) time complexity, where V is the number of elements in the queue.
Reference: [70] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A generalized processor sharing approach to flow control the single node case," </title> <booktitle> in Proceedings of INFOCOM '92, </booktitle> <volume> vol. 2, </volume> <pages> pp. 915-924, </pages> <month> May </month> <year> 1992. </year> <month> 234 </month>
Reference-contexts: Non-work-conserving algorithms are also used to control delay jitter by delaying packets that arrive early [93]. Work-conserving servers always have lower average delays than non-work-conserving servers. Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) <ref> [70] </ref>, Weighted Fair Queueing [26], VirtualClock [104], Delay-Earliest-Due-Date (Delay-EDD) [29], Weighted Round Robin [55], and Deficit Round Robin [81]. On the other hand, Hierarchical-Round-Robin (HRR) [51], Stop-and-Go queueing [36], and Jitter-Earliest-Due-Date [93] are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure [103]. <p> The worst-case service seen by an application will not be affected by the behavior of other connections. Generalized Processor Sharing Generalized-Processor-Sharing (GPS) is an ideal scheduling discipline <ref> [26, 70] </ref> (Figure 1.4). GPS multiplexing is defined with respect to a fluid-model, where packets are considered to be infinitely divisible. The share of bandwidth reserved by session i is represented by a real number i . <p> The most common approach for bounding the burstiness of input traffic is by shaping through a leaky bucket [91]. Several previous studies have used this traffic model <ref> [21, 22, 70, 71] </ref>. We will use a more general approach and we will bound the worst-case service offered from the network to an application based on the scheduling algorithm used and without specifying the characteristics of the arrival traffic. <p> This results in perfect isolation, ideal fairness, and low end-to-end session delays. The VirtualClock algorithm <ref> [70, 104] </ref>, in contrast, does not bound the difference in service received by two backlogged sessions over an interval that is smaller than the backlogged period. <p> This is the result of the scheduler performing an averaging process on the rate of service provided to individual sessions trying to simulate a static TDM system. In VirtualClock, the averaging interval can be arbitrarily long. A typical example of the unfairness of VirtualClock is presented in Figure 1.5 <ref> [70, 104] </ref>. Assume that two connections share an outgoing link and are allocated equal shares of the link bandwidth. Assume each packet is of unit size and the rate of the server is also unity. <p> Our approach in modeling the worst-case behavior of scheduling algorithms with respect to an end-to-end session is related to the work of Cruz [21, 22], Zhang [101], and Parekh and Gallager <ref> [70, 71] </ref>. Cruz [21, 22] analyzed the end-to-end delay, buffer requirements, and internal network burstiness of sessions in an arbitrary topology network where all sources are leaky-bucket controlled. <p> Third, we estimate the latency parameters for the individual schedulers tightly, taking into account their internal structure. Thus, our approach, in general, provides much tighter end-to-end delay bounds for individual sessions. Parekh and Gallager analyzed the worst-case behavior of sessions in a network of GPS schedulers <ref> [70, 71] </ref> and derived upper bounds on end-to-end delay and internal burstiness of sessions. However, the analysis applies to a homogeneous network consisting of only GPS schedulers. Our analysis accommodates a broad range of scheduling algorithms and the 63 ability to combine the schedulers in arbitrary ways in a network. <p> In <ref> [70] </ref> it was proven that, if t F ; t P are the times that a packet finishes under WFQ and GPS, respectively, then t P t F + r 91 where r is the transmission rate of the server. <p> We have not yet found a formal proof on its validity for arbitrary LR servers. Notice also, that based on the analysis of LR-servers we can provide a tighter delay bound than the one reported in <ref> [70, 71] </ref>. Let us assume a network of K PGPS servers, where rate g m i is allocated to connection i at the m-th node. <p> However, WFQ also has the highest implementation complexity. VirtualClock has the same latency as WFQ, but is not a fair algorithm <ref> [70, 104] </ref>. Self-Clocked Fair Queueing and the round-robin schedulers provide bounded unfairness, but their latency is a function of the number of connections that share the output link. In a broadband network, the resulting end-to-end delay bounds may be prohibitively large. <p> Let us assume that the kth packet leaves the system under the PRPS service discipline at time t P k . The same packet leaves the RPS server at time t F k . Using a similar approach as the one used for GPS servers <ref> [70] </ref>, we can prove the following lemma: Lemma 4.3: For all packets in a packet-by-packet rate-proportional server, t P k + r Proof: Assume that a system-busy period starts in both servers at time 0.
Reference: [71] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A generalized processor sharing approach to flow control in integrated services networks: the multiple node case," </title> <booktitle> in Proceedings of INFOCOM '93, </booktitle> <volume> vol. 2, </volume> <pages> pp. 521-530, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Such an approach implies a connection-oriented network. Open-loop control is an efficient method of control for applications that require a constant flow of data with predictable delay and delay-jitter bounds, such as multimedia applications <ref> [18, 29, 44, 45, 71] </ref>. In such a network, the traffic scheduling algorithm is the method that dynamically allocates the network resources at each hop of the network, so that packets will see predictable delays in the network. <p> The most common approach for bounding the burstiness of input traffic is by shaping through a leaky bucket [91]. Several previous studies have used this traffic model <ref> [21, 22, 70, 71] </ref>. We will use a more general approach and we will bound the worst-case service offered from the network to an application based on the scheduling algorithm used and without specifying the characteristics of the arrival traffic. <p> Our approach in modeling the worst-case behavior of scheduling algorithms with respect to an end-to-end session is related to the work of Cruz [21, 22], Zhang [101], and Parekh and Gallager <ref> [70, 71] </ref>. Cruz [21, 22] analyzed the end-to-end delay, buffer requirements, and internal network burstiness of sessions in an arbitrary topology network where all sources are leaky-bucket controlled. <p> Third, we estimate the latency parameters for the individual schedulers tightly, taking into account their internal structure. Thus, our approach, in general, provides much tighter end-to-end delay bounds for individual sessions. Parekh and Gallager analyzed the worst-case behavior of sessions in a network of GPS schedulers <ref> [70, 71] </ref> and derived upper bounds on end-to-end delay and internal burstiness of sessions. However, the analysis applies to a homogeneous network consisting of only GPS schedulers. Our analysis accommodates a broad range of scheduling algorithms and the 63 ability to combine the schedulers in arbitrary ways in a network. <p> This approach was used by Cruz [22]. However, this method ignores the correlation between arrivals at two servers in series, and therefore results in very loose bounds. Tighter bounds can be provided by following the approach used by Parekh and Gallager <ref> [71] </ref> that tries to capture the behavior of a session over multiple nodes at the same time. 74 The only restrictions that we impose in the network is that all the servers belong to the LR class and that the traffic of session i under observation is shaped at the source <p> Since we assumed only that each of the servers in the network belongs to the LR class, these results are more general than the delay bounds due to Parekh and Gallager <ref> [71] </ref>. In the next section, we will show that all well-known work-conserving schedulers are in fact LR servers. Thus, our delay bound applies to almost any network of schedulers. <p> : (3.1) If we substitute the latency obtained for PGPS from eq. (3.8) in this expression, that is, fi i = L i = i + L max =r, we get i + (k 1) i L max ; (3.2) which agrees with the bound obtained by Parekh and Gallager <ref> [71] </ref> for a network of PGPS servers. Since the latencies of PGPS and VirtualClock are identical, the bound of (3.2) applies to VirtualClock as well; this is also in agreement with the results of Lam and Xie [60]. <p> We have not yet found a formal proof on its validity for arbitrary LR servers. Notice also, that based on the analysis of LR-servers we can provide a tighter delay bound than the one reported in <ref> [70, 71] </ref>. Let us assume a network of K PGPS servers, where rate g m i is allocated to connection i at the m-th node.
Reference: [72] <author> K. K. Ramakrishnan and R. Jain, </author> <title> "A binary feedback scheme for congestion avoidance in computer networks.," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 8, </volume> <pages> pp. 158-81, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: End nodes probe the state of the network and adjust the application traffic so that they can receive a fair-share of the network resources without introducing congestion. Several methods have been proposed in the literature to detect the state of the network and notify the end 4 nodes <ref> [15, 42, 47, 56, 59, 72, 79] </ref>. 2 When the network is congested, sources are notified within a round-trip time and they reduce their transmission rate to alleviate congestion. Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method. <p> This follows from the fact that when all credits are satisfied, the algorithm reduces to simple iterative matching that allocates the bandwidth equally among all inputs requesting access to a given output port. In this sense, the algorithm meets the fairness criteria defined in <ref> [26, 72] </ref>. When an input-output connection increases its traffic rate, the performance of all others will be equally degraded, but they will still continue to receive at least their reserved bandwidth.
Reference: [73] <author> J. Rexford, A. Greenberg, and F. Bonomi, </author> <title> "A fair leaky-bucket shaper for ATM networks." </title> <type> AT&T unpublished report. </type>
Reference-contexts: Therefore, ^ W F j (0; t ) (4.36) By adding eq.(4.35) and eq.(4.36), ^ W F j (0; t) (4.37) 132 We will now use the above lemma and a method similar to the one presented in <ref> [41, 73] </ref> for the WFQ server to find an upper bound for the amount of service a session may receive in PRPS as compared to that in the fluid server.
Reference: [74] <author> J. Rexford, A. Greenberg, and F. Bonomi, </author> <title> "Hardware efficient fair queueing architectures for high-speed networks," </title> <booktitle> in Proceedings of INFOCOM 96, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: The fixed size of the ATM cell allows potentials to be represented as integers, instead of the floating-point numbers required in the general implementation. This, in turn, allows an efficient hardware implementation of the priority queues. The idea of using integer timestamps was first proposed in <ref> [74] </ref>. Since the ATM cell has a fixed size, the unit of time is now chosen as 1=K times the transmission time of an ATM cell through the outgoing link, where K 1 is a suitable integer scaling constant.
Reference: [75] <author> J. Roberts, </author> <title> "Virtual spacing for flexible traffic control," </title> <journal> International Journal of Communication Systems, </journal> <volume> vol. 7, no. 4, </volume> <pages> pp. 307-18, </pages> <year> 1994. </year>
Reference-contexts: Thus, the process overhead for completing a scheduling decision is O (V ), making the implementation of the algorithm prohibitively expensive in most cases. Self-Clocked Fair Queueing In order to reduce the complexity of Weighted Fair Queueing, an approximate implementation was proposed in <ref> [25, 37, 75] </ref> and was analyzed in [37] under the name Self-Clocked Fair Queueing (SCFQ). In this implementation, the timestamp of an arriving packet is computed based on the packet currently in service.
Reference: [76] <author> J. Saarinen, J. Tomberg, L. Vehmanen, and K. Kaski, </author> <title> "VLSI implementation of Tausworthe random number generator for parallel processing environment," </title> <journal> IEEE Proceedings-E, </journal> <volume> vol. 138, </volume> <pages> pp. 138-146, </pages> <year> 1991. </year>
Reference-contexts: In addition, the random-number generator needs to be invoked multiple times for generating cells from the different virtual channels sharing the same input port. We use a parallel implementation of the Tausworthe random number generator to create a long uniformly distributed sequence <ref> [9, 76, 88] </ref>. Such a sequence can be converted to any 202 external host other distribution by a table lookup and interpolation. For example, the alias method can be used to generate any discrete random variate having a finite range of values [58, 61, 94].
Reference: [77] <author> D. Saha, S. Mukherjee, and S. Tripathi, </author> <title> "Carry-over round robin: a simple cell scheduling mechanism for ATM networks," </title> <booktitle> in Proceedings of INFOCOM'96, </booktitle> <pages> pp. 630-637, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Credit counters are reset at the beginning of the frame to the maximum amount of traffic that the connection may transmit during a frame, and a connection is not eligible for service if its credit counter is zero. The simplicity of the algorithm allows a high-speed implementation <ref> [1, 55, 77, 81, 82] </ref>. As in stop-and-go queueing, the maximum delay is proportional to the maximum frame size. The requirement for a fine bandwidth allocation results in a large frame-size and thus high end-to-end delay bounds. Delay Earliest Due Date Delay-Earliest-Due-Date (Delay-EDD) belongs to the sorted priority service disciplines. <p> Different characterizations of the traffic may be used to derive bounds on end-to-end delays and burstiness. The model will be general enough so that both deterministic <ref> [77, 91] </ref> as well as probabilistic [97, 98, 106] traffic characterizations may be used for the input-traffic. 1.3.2 Fairness Significant discrepancies may exist in the service provided to different sessions over the short term among scheduling algorithms.
Reference: [78] <author> H. Schwetman, </author> <note> CSIM Reference Manual, 1992. ACT-ST-252-87, Rev. 16. </note>
Reference-contexts: The software simulations were run on a DEC Alpha 3000/400 workstation with 92 Mbytes of main memory using a simulator written in CSIM <ref> [78] </ref>. For the weighted-round-robin algorithm we varied the number of VC groups from 4 to 32. The results are summarized in Table 6.1. If we assume that the output link speed is 155 Mbits/sec, the hardware simulation was running in almost real time.
Reference: [79] <author> S. Shenker, </author> <title> "A theoritical analysis of feedback flow control," </title> <booktitle> in Proceedings of SIG-COMM'90, </booktitle> <volume> vol. 20, </volume> <pages> pp. 156-165, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: End nodes probe the state of the network and adjust the application traffic so that they can receive a fair-share of the network resources without introducing congestion. Several methods have been proposed in the literature to detect the state of the network and notify the end 4 nodes <ref> [15, 42, 47, 56, 59, 72, 79] </ref>. 2 When the network is congested, sources are notified within a round-trip time and they reduce their transmission rate to alleviate congestion. Several of these methods depend or can significantly improve their performance by using a sophisticated traffic scheduling method.
Reference: [80] <author> S. Shenker, </author> <title> "Making greed work in networks: A game-theoretic analysis of switch service disciplines," </title> <booktitle> in Proceedings of ACM SIGCOMM '94, </booktitle> <pages> pp. 47-57, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: In 44 a real network, the traffic may exceed the capacity of the output link, either because of the burstiness of individual flows or because of greedy users. Users may act in a selfish manner by trying to utilize as much of the available bandwidth as possible <ref> [80] </ref>. Higher level protocols such as TCP incorporate mechanisms to utilize the maximum available bandwidth [47]. In addition, some of the input ports of the switch may need to use more than 1=N of the output bandwidth; probabilistic iterative matching can only guarantee them 1=N of the output bandwidth.
Reference: [81] <author> M. Shreedhar and G. Varghese, </author> <title> "Efficient fair queueing using deficit round robin," </title> <booktitle> in Proceedings of ACM SIGCOMM'95, </booktitle> <pages> pp. 231-242, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: Work-conserving servers always have lower average delays than non-work-conserving servers. Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) [70], Weighted Fair Queueing [26], VirtualClock [104], Delay-Earliest-Due-Date (Delay-EDD) [29], Weighted Round Robin [55], and Deficit Round Robin <ref> [81] </ref>. On the other hand, Hierarchical-Round-Robin (HRR) [51], Stop-and-Go queueing [36], and Jitter-Earliest-Due-Date [93] are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure [103]. According to this classification there are two main architectures: sorted-priority and frame-based. <p> Credit counters are reset at the beginning of the frame to the maximum amount of traffic that the connection may transmit during a frame, and a connection is not eligible for service if its credit counter is zero. The simplicity of the algorithm allows a high-speed implementation <ref> [1, 55, 77, 81, 82] </ref>. As in stop-and-go queueing, the maximum delay is proportional to the maximum frame size. The requirement for a fine bandwidth allocation results in a large frame-size and thus high end-to-end delay bounds. Delay Earliest Due Date Delay-Earliest-Due-Date (Delay-EDD) belongs to the sorted priority service disciplines. <p> Let t k indicate the time that a round finishes in the Deficit Round Robin algorithm. It has been shown in <ref> [81] </ref> that, if connection i is continuously backlogged in the interval (t; t k ] then at the end of the kth round, W i (t 0 ; t k ) k i D k For each interval of time (t k1 ; t k ], we can write t k <p> Let t 2 be time at which the packets of j finish service. Then, W j (t 1 ; t 2 ) i 1 (L j + i = i L j : 3.4.3 Fairness of a Round-Robin Scheduler Deficit Round Robin was proposed by Sreedhar and Varghese <ref> [81] </ref> as an O (1) algorithm for providing bandwidth guarantees in an output-buffered switch. Deficit Round Robin is a generalization of the Weighted-Round-Robin algorithm that was proposed in the context of ATM networks [55]. <p> It has been shown that, in the Deficit Round Robin algorithm, the difference in service offered to any two connections that have the same bandwidth reservation is bounded by 3 i , where i is the number of bytes allocated to these connections in each frame <ref> [81] </ref>. Here we extend the result to the case of two connections with arbitrary bandwidth allocations.
Reference: [82] <author> K. Sriram, </author> <title> "Methodologies for bandwidth allocation, transmission scheduling, and congestion avoidance in broadband ATM networks," </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> vol. 26, no. 1, </volume> <pages> pp. 43-59, </pages> <year> 1993. </year>
Reference-contexts: Credit counters are reset at the beginning of the frame to the maximum amount of traffic that the connection may transmit during a frame, and a connection is not eligible for service if its credit counter is zero. The simplicity of the algorithm allows a high-speed implementation <ref> [1, 55, 77, 81, 82] </ref>. As in stop-and-go queueing, the maximum delay is proportional to the maximum frame size. The requirement for a fine bandwidth allocation results in a large frame-size and thus high end-to-end delay bounds. Delay Earliest Due Date Delay-Earliest-Due-Date (Delay-EDD) belongs to the sorted priority service disciplines. <p> to bandwidth allocation algorithms and more specifically to algorithms that can support all the diverse requirements of integrated-services networks that we describe in more detail in the next section. 1.3 A Common Framework There are several methods proposed in the literature for designing a scheduler architecture for an integrated-services network <ref> [8, 18, 28, 46, 82] </ref> (for a survey [5]). Most of these approaches are driven by the fact that real-time applications have stricter requirements from the network than data applications, and are based on the concept of static priorities. <p> No guarantees are provided to best-effort traffic. Finally, Sriram proposes a unified scheduling architecture. This is the most general approach that identifies the need for a common scheduling mechanism, independent of static priorities <ref> [82] </ref>. According to this approach, there is a common weighted round-robin scheduler for all traffic classes. Guaranteed-delay applications are assigned to separate queues of the round-robin scheduler and receive a guaranteed portion of the output link bandwidth.
Reference: [83] <author> D. Stiliadis and A. Varma, </author> <title> "Providing bandwidth guarantees in an input-buffered crossbar switch," </title> <booktitle> in Proceedings of INFOCOM `95, </booktitle> <pages> pp. 960-968, </pages> <month> April </month> <year> 1995. </year>
Reference: [84] <author> D. Stiliadis and A. Varma, </author> <title> "Design and analysis of frame-based fair queueing: A new traffic scheduling algorithm for packet-switched networks," </title> <booktitle> in Proceedings of ACM SIGMETRICS '96, </booktitle> <pages> (http://www.cse.ucsc.edu/research/hsnlab/publications/), pp. 104-115, </pages> <month> May </month> <year> 1996. </year>
Reference: [85] <author> D. Stiliadis and A. Varma, </author> <title> "FAST: an FPGA-based simulation testbed for ATM networks," </title> <booktitle> in Proceedings of ICC'96, </booktitle> <month> June </month> <year> 1996. </year>
Reference: [86] <author> D. Stiliadis and A. Varma, </author> <title> "Latency-rate servers: A general model for analysis of traffic scheduling algorithms," </title> <booktitle> in Proceedings of IEEE INFOCOM '96, </booktitle> <pages> (http://www.cse.ucsc.edu/research/hsnlab/publications/), pp. 111-119, </pages> <month> April </month> <year> 1996. </year>
Reference: [87] <author> R. Tarjan, </author> <title> Data Structures and Network Algorithms. </title> <institution> Bell Laboratories, </institution> <year> 1983. </year>
Reference-contexts: Optimal algorithms exist for bipartite matching with complexity of O (N 2 ) where N is the number of ports of the switch <ref> [54, 87] </ref>. However, the time available to compute a matching in an ATM switch is limited to the transmission time of a cell | less than 3 s at SONET OC-3 speeds. This makes the use of an optimal algorithm almost impractical.
Reference: [88] <author> R. </author> <title> Tausworthe, "Random numbers generated by linear recurrence modulo two," </title> <journal> Mathematics of Computation, </journal> <volume> vol. 19, </volume> <pages> pp. 100-119, </pages> <year> 1965. </year> <month> 235 </month>
Reference-contexts: In addition, the random-number generator needs to be invoked multiple times for generating cells from the different virtual channels sharing the same input port. We use a parallel implementation of the Tausworthe random number generator to create a long uniformly distributed sequence <ref> [9, 76, 88] </ref>. Such a sequence can be converted to any 202 external host other distribution by a table lookup and interpolation. For example, the alias method can be used to generate any discrete random variate having a finite range of values [58, 61, 94].
Reference: [89] <author> D. A. Thomas, T. Petersen, and D. Van den Bout, </author> <title> "The Anyboard rapid prototyping environment," </title> <booktitle> in Advanced Research in VLSI, Proceedings of the 1991 UC Santa Cruz Conference, </booktitle> <pages> pp. 356-370, </pages> <year> 1991. </year>
Reference-contexts: Several other efforts have been reported in the literature for building reconfigurable hardware 196 systems for prototyping or emulation of complex systems such as SIMD architectures [6, 35], MIMD parallel processors [10], neural networks [20], accelerators for scientific computation [66], and general-purpose coprocessors <ref> [12, 89] </ref>. In addition, advances in high-level hardware description languages and synthesis tools have significantly reduced the time for hardware system prototyping [65]. Models of the ATM switch architecture and associated hardware are developed in VHDL. Commercial hardware synthesis tools are used for mapping the VHDL models to the FPGAs.
Reference: [90] <author> F. A. Tobagi, </author> <title> "Fast packet switch architectures for broadband integrated services digital networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 78, </volume> <pages> pp. 133-167, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: The common fabric types include shared memory, bus, crossbar, and multistage networks (for a survey, see <ref> [90] </ref>). We will restrict ourselves to a nonblocking switch architecture, most often implemented by a crossbar switching network.
Reference: [91] <author> J. Turner, </author> <title> "New directions in communications (or which way to the information age?)," </title> <journal> IEEE Communications Magazine, </journal> <volume> vol. 24, </volume> <pages> pp. 8-15, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: In order to provide a deterministic delay bound, it is necessary to bound the burstiness of the session at the input of the network. The most common approach for bounding the burstiness of input traffic is by shaping through a leaky bucket <ref> [91] </ref>. Several previous studies have used this traffic model [21, 22, 70, 71]. We will use a more general approach and we will bound the worst-case service offered from the network to an application based on the scheduling algorithm used and without specifying the characteristics of the arrival traffic. <p> Different characterizations of the traffic may be used to derive bounds on end-to-end delays and burstiness. The model will be general enough so that both deterministic <ref> [77, 91] </ref> as well as probabilistic [97, 98, 106] traffic characterizations may be used for the input-traffic. 1.3.2 Fairness Significant discrepancies may exist in the service provided to different sessions over the short term among scheduling algorithms.
Reference: [92] <author> A. Varma, L. Kalampoukas, D. Stiliadis, and Q. Jacobson, </author> <title> "The CPU Design Kit: An instructional prototyping platform for teaching processor design," </title> <type> tech. rep., </type> <institution> University of California, Santa Cruz, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: The local memory can now be used for temporary storage of incoming ATM cells before they are forwarded to the input modules. For this purpose we are using the "CPU Design Kit", as a general purpose PC-based FPGA board designed at the University of California, Santa Cruz <ref> [92] </ref>. This board consists of six FLEX 81500 devices with a total of 90; 000 usable gates, and can be programmed to provide the necessary interface operations (Figure 6.4).
Reference: [93] <author> D. Verma, D. Ferrari, and H. Zhang, </author> <title> "Guaranteeing delay jitter bounds in packet switching networks," </title> <booktitle> in Tricomm 91, </booktitle> <pages> pp. 35-43, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: When the transmission time of a packet is short, as is typically the case in an ATM network, however, such a policy is seldom justified. Non-work-conserving algorithms are also used to control delay jitter by delaying packets that arrive early <ref> [93] </ref>. Work-conserving servers always have lower average delays than non-work-conserving servers. Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) [70], Weighted Fair Queueing [26], VirtualClock [104], Delay-Earliest-Due-Date (Delay-EDD) [29], Weighted Round Robin [55], and Deficit Round Robin [81]. <p> Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) [70], Weighted Fair Queueing [26], VirtualClock [104], Delay-Earliest-Due-Date (Delay-EDD) [29], Weighted Round Robin [55], and Deficit Round Robin [81]. On the other hand, Hierarchical-Round-Robin (HRR) [51], Stop-and-Go queueing [36], and Jitter-Earliest-Due-Date <ref> [93] </ref> are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure [103]. According to this classification there are two main architectures: sorted-priority and frame-based.
Reference: [94] <author> A. Walker, </author> <title> "An efficient method for generating random variables with general distributions," </title> <journal> ACM Transactions on Math. Software, </journal> <volume> vol. 3, </volume> <pages> pp. 253-256, </pages> <year> 1977. </year>
Reference-contexts: Such a sequence can be converted to any 202 external host other distribution by a table lookup and interpolation. For example, the alias method can be used to generate any discrete random variate having a finite range of values <ref> [58, 61, 94] </ref>. The local memory of each traffic generator module can be used for storing the necessary lookup tables. More complex traffic models, for example a video stream, that can be modeled using Markov chains can be synthesized by implementing the Markov chain in hardware [43].
Reference: [95] <author> S. Walters, </author> <title> "Computer-aided prototyping of ASIC-based systems," </title> <booktitle> IEEE Design & Test of Computers, </booktitle> <pages> pp. 4-10, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: FPGA-based prototyping aids are a valuable tool in hardware development. For example, the QuickTurn system, based on Xilinx FPGA devices, is widely used in the industry for hardware prototyping <ref> [95] </ref>. Several other efforts have been reported in the literature for building reconfigurable hardware 196 systems for prototyping or emulation of complex systems such as SIMD architectures [6, 35], MIMD parallel processors [10], neural networks [20], accelerators for scientific computation [66], and general-purpose coprocessors [12, 89].
Reference: [96] <author> Xilinx, Inc., </author> <title> The Programmable Logic Data Book, </title> <year> 1994. </year>
Reference-contexts: FPGAs are ideally suited to building reconfigurable hardware systems. Devices such as the Altera FLEX family and the Xilinx FPGAs use RAM-based lookup tables as their basic logic element, thus allowing in-system configurability <ref> [3, 96] </ref>. FPGA-based prototyping aids are a valuable tool in hardware development. For example, the QuickTurn system, based on Xilinx FPGA devices, is widely used in the industry for hardware prototyping [95].
Reference: [97] <author> O. Yaron and M. Sidi, </author> <title> "Performance and stability of communication networks via robust exponential bounds," </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> vol. 1, </volume> <pages> pp. 372-385, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Different characterizations of the traffic may be used to derive bounds on end-to-end delays and burstiness. The model will be general enough so that both deterministic [77, 91] as well as probabilistic <ref> [97, 98, 106] </ref> traffic characterizations may be used for the input-traffic. 1.3.2 Fairness Significant discrepancies may exist in the service provided to different sessions over the short term among scheduling algorithms. Some schedulers may penalize sessions for service received in excess of their reservations at an earlier time. <p> Although the bounds derived for the end-to-end delays and buffer requirements hold only when the input traffic is leaky-bucket shaped, the same model can be used for analysis with other input-traffic models. For example the Exponentially-Bounded-Burstiness (EBB) model was used in <ref> [97, 98, 106] </ref> for analyzing the behavior of a GPS multiplexer. Future work will include the use of other traffic models for providing end-to-end delay guarantees in a network of LR servers. <p> An extension of this work will be to study the behavior of LR servers under a probabilistic traffic model. A statistical analysis of GPS multiplexing was presented in [98, 106]. This analysis was based on approximating input traffic by the Exponentially-Bounded-Burstiness model proposed by Yaron and Sidi in <ref> [97] </ref>. However, none of these studies can easily be extended to cover other schedulers. The LR model is much more general than GPS multiplexing and we can investigate whether these results can be expanded to the general class of LR servers. Another extension is to study hierarchical scheduling.
Reference: [98] <author> O. Yaron and M. Sidi, </author> <title> "Generalized processor sharing networks with exponentially bounded burstiness arrivals," </title> <booktitle> in Proceedings of INFOCOM '94, </booktitle> <pages> pp. 628-634, </pages> <publisher> IEEE, </publisher> <month> April </month> <year> 1994. </year>
Reference-contexts: Different characterizations of the traffic may be used to derive bounds on end-to-end delays and burstiness. The model will be general enough so that both deterministic [77, 91] as well as probabilistic <ref> [97, 98, 106] </ref> traffic characterizations may be used for the input-traffic. 1.3.2 Fairness Significant discrepancies may exist in the service provided to different sessions over the short term among scheduling algorithms. Some schedulers may penalize sessions for service received in excess of their reservations at an earlier time. <p> Although the bounds derived for the end-to-end delays and buffer requirements hold only when the input traffic is leaky-bucket shaped, the same model can be used for analysis with other input-traffic models. For example the Exponentially-Bounded-Burstiness (EBB) model was used in <ref> [97, 98, 106] </ref> for analyzing the behavior of a GPS multiplexer. Future work will include the use of other traffic models for providing end-to-end delay guarantees in a network of LR servers. <p> This can be a valuable tool in the analysis of real networks. An extension of this work will be to study the behavior of LR servers under a probabilistic traffic model. A statistical analysis of GPS multiplexing was presented in <ref> [98, 106] </ref>. This analysis was based on approximating input traffic by the Exponentially-Bounded-Burstiness model proposed by Yaron and Sidi in [97]. However, none of these studies can easily be extended to cover other schedulers.
Reference: [99] <author> D. Yates, J. Kurose, D. Towsley, and M. Hluchyj, </author> <title> "On per-session end-to-end delay distributions and the call admission problem for real-time applications with QoS requirements," </title> <booktitle> in Proceedings of SIGCOMM'93, </booktitle> <pages> pp. 2-12, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: It is possible that a large percentage of the traffic of the applications will see much lower delays with the given bandwidth and buffer allocations. The study in <ref> [99] </ref> pointed that worst-case bounds may be highly conservative as compared to the average performance. However, the analysis of the worst-case behavior is still important, for two main reasons: 1. The worst-case performance of the algorithm often provides good insight into the properties of the algorithms.
Reference: [100] <author> J. Yee and N. Gaarder, </author> <title> "Maximal average loss rates for a single GPS server system with finite buffers," </title> <booktitle> in Proceedings INFOCOM '95, IEEE, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Once we can bound the maximum delay and output burstiness in one node we can continue by analyzing networks of servers. Of course in the case where buffers are finite, packets may be lost. In <ref> [100] </ref> the idea of calculating maximal average loss probabilities is presented. Extension of our work in this direction may yield fundamental results. 228 The framework of rate-proportional servers, introduced in Chapter 4, will likely lead to the development of other scheduling algorithms.
Reference: [101] <author> H. Zhang, </author> <title> Service Disciplines for Packet-Switching Integrated-Services Networks. </title> <type> PhD thesis, </type> <institution> U.C. Berkeley, </institution> <year> 1992. </year>
Reference-contexts: We also show how the latency parameter can be computed for a given scheduling algorithm by deriving the latencies of several well-known schedulers. Our approach in modeling the worst-case behavior of scheduling algorithms with respect to an end-to-end session is related to the work of Cruz [21, 22], Zhang <ref> [101] </ref>, and Parekh and Gallager [70, 71]. Cruz [21, 22] analyzed the end-to-end delay, buffer requirements, and internal network burstiness of sessions in an arbitrary topology network where all sources are leaky-bucket controlled. <p> However, the analysis applies to a homogeneous network consisting of only GPS schedulers. Our analysis accommodates a broad range of scheduling algorithms and the 63 ability to combine the schedulers in arbitrary ways in a network. Zhang <ref> [101] </ref> derived end-to-end delay bounds for a class of non-work-conserving scheduling algorithms when traffic is re-shaped at each node of the network. This allows the delays of individual schedulers on the path to be accumulated in a simple manner.
Reference: [102] <author> H. Zhang, </author> <title> "Service disciplines for guaranteed performance service in packet-switching networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 83, </volume> <pages> pp. 1374-96, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: In a packet network with larger packet-sizes, such as the current Internet, the algorithm can be implemented in software. Several service disciplines are known in the literature for bandwidth allocation and transmission scheduling in output-buffered switches (for a survey see <ref> [102] </ref>). In general, schedulers can be characterized as work-conserving or non-work-conserving. A scheduler 10 is work-conserving if the server is never idle when a packet is buffered in the system. A non-work-conserving server may remain idle even if there are available packets to transmit.
Reference: [103] <author> H. Zhang and S. Keshav, </author> <title> "Comparison of rate based service disciplines," </title> <booktitle> in Proceedings of ACM SIGCOMM '91, </booktitle> <pages> pp. 113-122, </pages> <year> 1991. </year>
Reference-contexts: On the other hand, Hierarchical-Round-Robin (HRR) [51], Stop-and-Go queueing [36], and Jitter-Earliest-Due-Date [93] are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure <ref> [103] </ref>. According to this classification there are two main architectures: sorted-priority and frame-based. In a sorted-priority scheduler, there is a global variable | usually referred to as the virtual time | associated with each outgoing link of the switch. <p> If V is the maximum number of connections that may share an output link, the implementation of a scheduler based on the sorted-priority architecture involves three main steps for processing each cell <ref> [103] </ref>: 1. Calculation of the timestamp: The PGPS scheduler has the highest complexity in this respect, since a GPS scheduler must be simulated in parallel in order to update the virtual time. This simulation may result in a process overhead of O (V ) per packet transmission in the worst-case. <p> As we presented earlier, based on their internal architecture, traffic scheduling algorithms can be divided into two general classes <ref> [103] </ref> | frame-based and 210 sorted-priority. In this section, we describe an example implementation of one algorithm from each of these classes. The first model we consider is that of a 4 fi 4 output-buffered ATM switch with weighted round-robin scheduling.
Reference: [104] <author> L. Zhang, "VirtualClock: </author> <title> a new traffic control algorithm for packet switching networks," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 9, </volume> <pages> pp. 101-124, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Non-work-conserving algorithms are also used to control delay jitter by delaying packets that arrive early [93]. Work-conserving servers always have lower average delays than non-work-conserving servers. Examples of work-conserving schedulers include Generalized Processor Sharing (GPS) [70], Weighted Fair Queueing [26], VirtualClock <ref> [104] </ref>, Delay-Earliest-Due-Date (Delay-EDD) [29], Weighted Round Robin [55], and Deficit Round Robin [81]. On the other hand, Hierarchical-Round-Robin (HRR) [51], Stop-and-Go queueing [36], and Jitter-Earliest-Due-Date [93] are non-work-conserving schedulers. Another classification of schedulers is based on their internal structure [103]. <p> FCFS can not offer any finite deterministic bounds in terms of delay or delay jitter independent of the network state and the traffic characteristics of competing sessions. Virtual Clock Virtual clock was first proposed in <ref> [104] </ref>. The algorithm assigns to each packet a "virtual" transmission time, based on the measured arrival rate of previous packets and the average arrival rate that was specified by the user. VirtualClock can be seen as attempting to simulate a static TDM system. <p> This results in perfect isolation, ideal fairness, and low end-to-end session delays. The VirtualClock algorithm <ref> [70, 104] </ref>, in contrast, does not bound the difference in service received by two backlogged sessions over an interval that is smaller than the backlogged period. <p> This is the result of the scheduler performing an averaging process on the rate of service provided to individual sessions trying to simulate a static TDM system. In VirtualClock, the averaging interval can be arbitrarily long. A typical example of the unfairness of VirtualClock is presented in Figure 1.5 <ref> [70, 104] </ref>. Assume that two connections share an outgoing link and are allocated equal shares of the link bandwidth. Assume each packet is of unit size and the rate of the server is also unity. <p> However, WFQ also has the highest implementation complexity. VirtualClock has the same latency as WFQ, but is not a fair algorithm <ref> [70, 104] </ref>. Self-Clocked Fair Queueing and the round-robin schedulers provide bounded unfairness, but their latency is a function of the number of connections that share the output link. In a broadband network, the resulting end-to-end delay bounds may be prohibitively large.
Reference: [105] <author> L. Zhang, S. Deering, D. Estrin, S. Shenker, and D. Zappala, "RSVP: </author> <title> A new resource reservation protocol," </title> <journal> IEEE Network, </journal> <volume> vol. 7, </volume> <pages> pp. 8-18, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: It is also apparent from the current trends of network design, that both open-loop and closed-loop methods of control will need to be integrated in the network in order to satisfy the different application requirements <ref> [2, 48, 105] </ref>. Open-loop control will be used for real-time applications and closed-loop control for data or non-real time traffic. However, the links are shared by the two types of control and thus only one traffic scheduling algorithm can be used.
Reference: [106] <author> Z. Zhang, D. Towsley, and J. Kurose, </author> <title> "Statistical analysis of generalized processor sharing scheduling discipline," </title> <booktitle> in Proceedings of ACM SIGCOMM '94, </booktitle> <pages> pp. 68-77, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Different characterizations of the traffic may be used to derive bounds on end-to-end delays and burstiness. The model will be general enough so that both deterministic [77, 91] as well as probabilistic <ref> [97, 98, 106] </ref> traffic characterizations may be used for the input-traffic. 1.3.2 Fairness Significant discrepancies may exist in the service provided to different sessions over the short term among scheduling algorithms. Some schedulers may penalize sessions for service received in excess of their reservations at an earlier time. <p> Although the bounds derived for the end-to-end delays and buffer requirements hold only when the input traffic is leaky-bucket shaped, the same model can be used for analysis with other input-traffic models. For example the Exponentially-Bounded-Burstiness (EBB) model was used in <ref> [97, 98, 106] </ref> for analyzing the behavior of a GPS multiplexer. Future work will include the use of other traffic models for providing end-to-end delay guarantees in a network of LR servers. <p> This can be a valuable tool in the analysis of real networks. An extension of this work will be to study the behavior of LR servers under a probabilistic traffic model. A statistical analysis of GPS multiplexing was presented in <ref> [98, 106] </ref>. This analysis was based on approximating input traffic by the Exponentially-Bounded-Burstiness model proposed by Yaron and Sidi in [97]. However, none of these studies can easily be extended to cover other schedulers.
Reference: [107] <author> Q. Zheng and K. Shin, </author> <title> "On the ability of establishing real-time channels in point-to-point packet-switching networks," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 42, </volume> <pages> pp. 1096-1105, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: However, they assume rate-controllers that shape the traffic to a specific rate both at the entrance of the network and in individual switches. 16 Specifically for the case of networks with constant packet sizes, it was shown in <ref> [40, 107] </ref> that if certain schedulability conditions are satisfied, then the Delay-EDD algorithm can be employed in a work-conserving network providing flexible delay-bounds to applications; these delay bounds are independent of the bandwidth allocation. <p> However, there are two main problems with this approach: First, the complexity of the schedulability test is very high. As a result, some approximate methods were proposed in <ref> [107] </ref>; however, the price paid is in terms of reduced utilization of the output link. Second, a connection may not be accepted in the network even when the requested bandwidth is available.
References-found: 107

