URL: ftp://ftp.cs.washington.edu/tr/1992/03/UW-CSE-92-03-01.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-title.html
Root-URL: 
Title: Distributed Shared Memory with Versioned Objects  
Author: Michael J. Feeley and Henry M. Levy 
Note: To appear in the Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA)  This work was supported in part by the National Science Foundation under Grants No. CCR-8619663 and CCR-8907666, by the Washington Technology Center, and by the Digital Equipment Corporation Systems Research Center and External Research Program.  
Date: 92-03-01  October 1992  
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering, FR-35 University of Washington  
Pubnum: Technical Report  
Abstract: Distributed Object Memory (DOM) is an abstraction that represents a distributed-memory system as a single shared container of language-level objects. The goal of DOM is to simplify programming of parallel applications for such systems. All accesses to shared memory are made relative to objects that reside in one or more node-local memories. For example, in Amber, a DOM system for a network of workstations, remote references are transparent at the language level and are implemented using either remote procedure call or object replication and migration. While DOM can greatly simplify distribution for many application classes, it is not well suited for all domains (parallel-scientific codes, in particular). To address the shortcomings of DOM for such domains, we introduce Versioned DOM (VDOM). In VDOM a version number is associated with each object. Multiple versions of objects can coexist and may be cached in local memories as needed to in crease concurrency. Object coherence is driven by synchronization methods implicitly associated with each object. Explicit versioning is used as the basis for a memory consistency model that facilitates efficient fine-grain sharing of objects. The units of VDOM coherence are fragment objects, from which language-level objects are constructed; this fragmentation solves the false-sharing problem for language-level objects. The performance of VDOM primitives compared to standard DOM coherence is presented along with speedup results for two parallel applications implemented using VDOM. 
Abstract-found: 1
Intro-found: 1
Reference: [Adve & Hill 90] <author> Adve, S. V. and Hill, M. D. </author> <title> Weak ordering anew definition. </title> <booktitle> In Proc. 17th Annual Symposium on Computer Architecture, Computer Architecture News, </booktitle> <pages> pages 2-14. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Strict consistency can be unnecessarily costly in performance, because for predictable results, reads and writes to shared data must still be managed through critical sections. In a weak consistency model <ref> [Gharachorloo et al. 90, Adve & Hill 90] </ref>, the application makes synchronization requests (acquire and release) visible to the hardware or runtime system.
Reference: [Bal & Tanenbaum 88] <author> Bal, H. E. and Tanen-baum, A. S. </author> <title> Distributed programming with shared data. </title> <booktitle> In Proceedings of the International Conference on Computer Languages, </booktitle> <pages> pages 82-91, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Object-based models are naturally adapted to distributed systems. Examples of DOM systems include Amber [Chase et al. 89, Feeley et al. 91], Argus [Liskov 88], Emerald [Jul et al. 88] and Orca <ref> [Bal & Tanenbaum 88] </ref>. In contrast to these other distributed systems, the goal of Amber is to execute a single application that performs a parallel computation. However, all of these systems have provided memory consistency at the level of a language object.
Reference: [Birrell & Nelson 84] <author> Birrell, A. D. and Nelson, B. J. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 39-59, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: Access to objects is uniform: at the language level, local and remote objects are accessed in the same way. Remote references are handled by one of the coherence mechanisms supported by DOM, either by RPC-like <ref> [Birrell & Nelson 84] </ref> function shipping, or by restricted forms of data shipping. With function shipping, an operation on a remote object is completed by moving the invoking thread of control to the object's local node, where it performs the operation.
Reference: [Carter et al. 91] <author> Carter, J. B., Bennett, J. K., and Zwaenepoel, W. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the Thirteenth Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: DOM closes the gap between the coherence protocol and the application; objects provide the programmer with a natural way to convey information to the runtime system about the units of coherence (i.e., objects) and the coherence policy for their use <ref> [Carter et al. 91] </ref>. This is a key advantage of DOM over page-based systems. Since the object is an encapsulation of data and all references to it, coherence can be implicitly associated with each object's external interface, while DSM systems must rely on run-time detection of remote data references. <p> Among these are page-based systems <ref> [Li & Hudak 89, Carter et al. 91] </ref> and object-based systems (DOM) [Liskov 88, Jul et al. 88, Bal & Tanenbaum 88, Chase et al. 89]. <p> As a result, the coherence mechanisms of these systems typically must operate without this information, and as a result can suffer poor performance resulting from false sharing. In Munin <ref> [Carter et al. 91] </ref>, the user annotates data objects with type information that is used to select from one of eight different coherence policies through appropriate settings of seven coherence attributes.
Reference: [Chase et al. 89] <author> Chase, J. S., Amador, F. G., La-zowska, E. D., Levy, H. M., and Little-field, R. J. </author> <title> The Amber system: Parallel programming on a network of multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 147-158, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: expect that compiler optimization could be used to make this translation of coordinates as efficient as direct access to a contiguous array, however, these optimizations were done by hand in our implementation. 2.2 Programming in VDOM Our implementation of VDOM is built as an extension of the Amber DOM system <ref> [Chase et al. 89, Feeley et al. 91] </ref>, providing programmers with an additional set of predefined C++ classes. <p> VDOM, on the other hand, requires a bit more care in declaring shared data, but the application can avoid the need for costly run-time, on-demand coherence overhead. Object-based models are naturally adapted to distributed systems. Examples of DOM systems include Amber <ref> [Chase et al. 89, Feeley et al. 91] </ref>, Argus [Liskov 88], Emerald [Jul et al. 88] and Orca [Bal & Tanenbaum 88]. In contrast to these other distributed systems, the goal of Amber is to execute a single application that performs a parallel computation.
Reference: [Faust 90] <author> Faust, K. </author> <title> An empirical comparison of object mobility mechanisms. </title> <type> Master's thesis, </type> <institution> Department of Computer Science and Engineering, University of Washing-ton, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: The overhead associated with Amber's object migration data-shipping coherence is the 12.430 msec show for an object move. The performance of Amber's invalidation-based object-replication coherence mechanism <ref> [Faust 90] </ref> follows this in the figure. Accesses to a replicated object are from within either a ReadRun or a WriteRun. A ReadRun completes locally if the object is already cached in local memory (0.250 msec).
Reference: [Feeley et al. 91] <author> Feeley, M. J., Bershad, B. N., Chase, J. S., and Levy, H. M. </author> <title> Dynamic node reconfiguration in a parallel-distributed environment. </title> <booktitle> In Proceedings of the Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 114-121, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: expect that compiler optimization could be used to make this translation of coordinates as efficient as direct access to a contiguous array, however, these optimizations were done by hand in our implementation. 2.2 Programming in VDOM Our implementation of VDOM is built as an extension of the Amber DOM system <ref> [Chase et al. 89, Feeley et al. 91] </ref>, providing programmers with an additional set of predefined C++ classes. <p> VDOM, on the other hand, requires a bit more care in declaring shared data, but the application can avoid the need for costly run-time, on-demand coherence overhead. Object-based models are naturally adapted to distributed systems. Examples of DOM systems include Amber <ref> [Chase et al. 89, Feeley et al. 91] </ref>, Argus [Liskov 88], Emerald [Jul et al. 88] and Orca [Bal & Tanenbaum 88]. In contrast to these other distributed systems, the goal of Amber is to execute a single application that performs a parallel computation.
Reference: [Fox et al. 88] <author> Fox, G. C., Johnson, M. A., Lyzenga, G. A., Otto, S. W., Salmon, J. K., and Walker, D. W. </author> <title> Solving Problems on Concurrent Processors, volume I. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <note> 1988. </note> <author> [Gharachorloo et al. 90] Gharachorloo, K., Lenoski, D., Laudon, J., Gibbons, P., Gupta, A., and Hen-nessy, J. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proc. 17th Annual Symposium on Computer Architecture, Computer Architecture News, </booktitle> <pages> pages 15-26. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Speedup is very nearly linear, which means VDOM operations successfully hid network latency and provided sufficient concurrency. 4.3 Application 2: WaTor WaTor <ref> [Fox et al. 88] </ref> is a simulation of an ocean populated by minnows and sharks. The ocean is represented by a two dimensional grid of points. Each point may be empty or it may contain either a minnow or a shark. The algorithm proceeds in an iterative fashion.
Reference: [Habert 90] <author> Habert, S. </author> <title> Distributed shared memory in Amber. </title> <type> Technical report, </type> <institution> University of Washington, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: In this section we present the results of performance measurements. We first compare the overhead and latency of the primitive coherence operations for three systems: Amber DOM, our implementation of VDOM, and a page-based DSM integrated into a version of Amber <ref> [Habert 90] </ref>. Following this, we present performance results for two applications implemented in VDOM. 4.1 Micro Performance This section presents performance data for the basic operations of our implementation of VDOM. <p> The reason for this improvement is that the Release is asynchronous to threads on both the sending node and on the receiving node. DSM: The final set of performance results were obtained from a page-based DSM system built into Amber <ref> [Habert 90] </ref> and are presented for rough comparison to the object-based systems. It takes a total of 11.690 msec to replicate a remote page following a "read fault".
Reference: [Jul et al. 88] <author> Jul, E., Levy, H., Hutchinson, N., and Black, A. </author> <title> Fine-grained mobility in the Emerald system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 109-133, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Object-based models are naturally adapted to distributed systems. Examples of DOM systems include Amber [Chase et al. 89, Feeley et al. 91], Argus [Liskov 88], Emerald <ref> [Jul et al. 88] </ref> and Orca [Bal & Tanenbaum 88]. In contrast to these other distributed systems, the goal of Amber is to execute a single application that performs a parallel computation. However, all of these systems have provided memory consistency at the level of a language object.
Reference: [Li & Hudak 89] <author> Li, K. and Hudak, P. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: One solution to these problems is to provide distributed applications with a software-based, shared-memory abstraction. In Distributed Shared Memory (DSM) systems such as Ivy <ref> [Li & Hudak 89] </ref>, the application sees a single shared virtual address space, as if shared memory were provided by the hardware. DSM systems rely on standard memory management hardware to control coherence at the granularity of a page. <p> Among these are page-based systems <ref> [Li & Hudak 89, Carter et al. 91] </ref> and object-based systems (DOM) [Liskov 88, Jul et al. 88, Bal & Tanenbaum 88, Chase et al. 89].
Reference: [Liskov 88] <author> Liskov, B. </author> <title> Distributed programming in Argus. </title> <journal> Communications of the ACM, </journal> <volume> 31(3) </volume> <pages> 300-312, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: Object-based models are naturally adapted to distributed systems. Examples of DOM systems include Amber [Chase et al. 89, Feeley et al. 91], Argus <ref> [Liskov 88] </ref>, Emerald [Jul et al. 88] and Orca [Bal & Tanenbaum 88]. In contrast to these other distributed systems, the goal of Amber is to execute a single application that performs a parallel computation.
Reference: [Ousterhout 90] <author> Ousterhout, J. K. </author> <booktitle> Why aren't operating systems getting faster as fast as hardware? In Proceedings of the Summer 1990 USENIX Conference, </booktitle> <pages> pages 247-256, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: VDOM achieves similar performance to Munin for a wide range of sharing interactions without requiring a page fault, copy and compare, expensive operations whose performance will not scale with improvements in processors <ref> [Ousterhout 90] </ref>. VDOM, on the other hand, requires a bit more care in declaring shared data, but the application can avoid the need for costly run-time, on-demand coherence overhead. Object-based models are naturally adapted to distributed systems.
Reference: [Reed & Kanodia 79] <author> Reed, D. P. and Kanodia, R. K. </author> <title> Synchronization with eventcounts and sequencers. </title> <journal> Communications of the ACM, </journal> <volume> 22(2) </volume> <pages> 115-123, </pages> <month> February </month> <year> 1979. </year>
Reference-contexts: VDOM provides a multi-versioned abstraction of shared object memory. Doing this increases con-currency and provides a basis for the version consistency sharing model. Using multiple versions to improve the performance of read-only transactions is discussed in [Weihl 87]. Using version numbers as the basis for synchronization is similar to <ref> [Reed & Kanodia 79] </ref>, where it is shown that any high-level synchronization mechanism can be built from primitives based on eventcounts. VDOM builds upon this idea to incorporate synchronization directly with the data being shared.
Reference: [Schroeder et al. 85] <author> Schroeder, M. D., Gifford, D. K., and Needham, R. M. </author> <title> A caching file system for a programmer's workstation. </title> <booktitle> In Proceedings of the 10th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 25-35, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: In a distributed system, versioning also provides a means of latency hiding for eager updating of cached objects. The idea of using immutable objects to increase concurrency is exploited by both the Cedar distributed file system <ref> [Schroeder et al. 85] </ref> and the Cosmos distributed software development environment [Walpole et al. 89]. 2.1 Fragment Objects VDOM uses fragmented objects to solve the object-level false-sharing problem.
Reference: [Shapiro et al. 90] <author> Shapiro, M., Gourhant, Y., Habert, S., Mosseri, L., and Valot, C. </author> <title> SOS: An object-oriented operating system assessment and retrospectives. </title> <booktitle> Computing Systems, </booktitle> <year> 1990. </year>
Reference-contexts: The term "fragmented object" was introduce in another context as a way of representing a language-level object that is subdivided into parts that may be distributed in different ways <ref> [Shapiro et al. 90] </ref>. In VDOM, fragment objects are the basic atomic units of coherence. Language-level objects may be composed from any number of these fragment objects. For example, recall the sub-grid decomposition shown in Figure 1.
Reference: [Thacker et al. 88] <author> Thacker, C. P., Stewart, L. C., and Satterthwaite, Jr., E. H. Firefly: </author> <title> A multiprocessor workstation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(8) </volume> <pages> 909-920, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Amber is a DOM programming model that extends C++ with a set of classes providing objects with mobility primitives, light-weight threads, and synchronization primitives such as spinlocks, monitors, condition variables, and barriers. Amber runs on a network of Firefly multiprocessor workstations <ref> [Thacker et al. 88] </ref> running the Topaz operating system. All measurements were made on a network Fireflies connected by a 10-megabit/second Ethernet. Each workstation consists of four (3 MIP) C-VAX processors. In this section we present the results of performance measurements.
Reference: [Tomlinson & Scheevel 89] <author> Tomlinson, C. and Scheevel, M. </author> <title> Concurrent object-oriented programming languages. </title> <editor> In Kim, W. and Lochovsky, F. H., editors, </editor> <booktitle> Object-Oriented Concepts, Databases, and Applications, chapter 5, </booktitle> <pages> pages 79-124. </pages> <publisher> ACM Press, </publisher> <address> New York, New York, </address> <year> 1989. </year>
Reference-contexts: In this way, Acquire operations on remotely shared objects will complete locally whenever possible. 3.5 Version Consistency and Message Passing Version consistency shares some of the characteristic benefits of the message-passing programming paradigm <ref> [Tomlinson & Scheevel 89] </ref>. By using version numbers, the program achieves the same implicit synchronization found with message-passing; the consumer of a message can synchronize with its producer by issuing a blocking Re ceive that waits for the producer to Send the message.
Reference: [Walpole et al. 89] <author> Walpole, J., Blair, G. S., Ma-lik, J., and Nicol, J. R. </author> <title> A unifing model for consistent distributed software development environments. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <pages> pages 183-190, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: In a distributed system, versioning also provides a means of latency hiding for eager updating of cached objects. The idea of using immutable objects to increase concurrency is exploited by both the Cedar distributed file system [Schroeder et al. 85] and the Cosmos distributed software development environment <ref> [Walpole et al. 89] </ref>. 2.1 Fragment Objects VDOM uses fragmented objects to solve the object-level false-sharing problem. The term "fragmented object" was introduce in another context as a way of representing a language-level object that is subdivided into parts that may be distributed in different ways [Shapiro et al. 90].
Reference: [Weihl 87] <author> Weihl, W. E. </author> <title> Distributed version management for read-only actions. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(1):55-64, </volume> <month> January </month> <year> 1987. </year>
Reference-contexts: VDOM provides a multi-versioned abstraction of shared object memory. Doing this increases con-currency and provides a basis for the version consistency sharing model. Using multiple versions to improve the performance of read-only transactions is discussed in <ref> [Weihl 87] </ref>. Using version numbers as the basis for synchronization is similar to [Reed & Kanodia 79], where it is shown that any high-level synchronization mechanism can be built from primitives based on eventcounts. VDOM builds upon this idea to incorporate synchronization directly with the data being shared.
References-found: 20

