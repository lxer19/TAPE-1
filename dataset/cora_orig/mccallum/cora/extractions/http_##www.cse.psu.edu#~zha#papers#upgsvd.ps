URL: http://www.cse.psu.edu/~zha/papers/upgsvd.ps
Refering-URL: http://www.cse.psu.edu/~zha/papers.html
Root-URL: http://www.cse.psu.edu
Title: MODIFYING THE GENERALIZED SINGULAR VALUE DECOMPOSITION WITH APPLICATION IN DIRECTION-OF-ARRIVAL FINDING  
Author: HONGYUAN ZHA AND ZHENYUE ZHANG 
Keyword: Key Words. generalized SVD, updating, downdating, array signal processing  
Web: 65F15.  
Note: AMS subject classifications:  
Abstract: We consider updating and downdating problems for the generalized singular value decomposition (GSVD) of matrix pairs when new rows are added to one of the matrices or old rows are deleted. Two classes of algorithms are developed, one based on the CS decomposition formulation of the GSVD and the other based on the generalized eigenvalue decomposition formulation. In both cases we show that the updating and downdating problems can be reduced to a rank-one SVD updating problem. We also provide perturbation analysis for the cases when the added or deleted rows are subject to errors. Numerical experiments on direction-of-arrival (DOA) finding with colored noises are carried out to demonstrate the tracking ability of the algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. L. Barlow, H. Zha, </author> <title> and P.A. Yoon. Stable chasing algorithms for modifying complete and partial singular value decompositions. </title> <type> Technical Report CSE-93-004, </type> <institution> Department of Computer Science and Engineering, Pennsylvania State University, </institution> <year> 1993. </year>
Reference-contexts: follows, D = B B B @ s 1 a 2 b 2 a 2 b 3 a 2 b 4 a 2 b 5 s 3 a 4 b 4 a 4 b 5 s 5 C C C A This special structure has been explored by several authors <ref> [2, 1] </ref>. In the following, we will apply a sequence of Givens rotations to reduce D to upper bidiagonal form.
Reference: [2] <author> J. Daniel, W. B. Gragg, L. Kaufman, and G. W. Stewart. </author> <title> Reorthogonalization and stable algorithms for updating the Gram-Schmidt QR factorization. </title> <journal> Mathematics of Computation, </journal> <volume> 30 </volume> <pages> 772-795, </pages> <year> 1976. </year>
Reference-contexts: follows, D = B B B @ s 1 a 2 b 2 a 2 b 3 a 2 b 4 a 2 b 5 s 3 a 4 b 4 a 4 b 5 s 5 C C C A This special structure has been explored by several authors <ref> [2, 1] </ref>. In the following, we will apply a sequence of Givens rotations to reduce D to upper bidiagonal form. <p> ^ U 2 diag (0; ^ S) ^ V H ^ R ! We start with the QR downdating procedure, i.e., given the QR decomposition of (X H ; R H n ) H , we compute the QR decomposition of (X H 1 ; R H n ) H <ref> [2] </ref>. Write R n = QR = q H 1 0 ; where q H is the first row of Q. We can orthogonalize the last column (1; 0; ; 0) H in the augmented Q matrix against all the previous columns. <p> He wishes to thank Professor Ake Bjorck for his support and encouragement and Professor Lars Elden for helpful discussions. A. Downdating the QR decomposition. In this appendix, we briefly review the QR downdating procedure in <ref> [2] </ref>. Let A = a H Q 1 R; be the QR decomposition of A. We need to construct the QR decomposition of A 1 , the result of deleting the first row of A. <p> If kqk 2 = 1, then Q 1 is rank deficient, and so is A 1 . The appended column can be chosen to be of the form (0; h H ) H with h orthogonal to Q 1 as is suggested in <ref> [2] </ref>. However, as far as the downdating problem is concerned, there is no need to append a column. The QR decomposition of A 1 can be easily computed as follows.
Reference: [3] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland, 2nd edition, </address> <year> 1989. </year>
Reference-contexts: If X is augmented by a new snapshot x, we write the new matrix pair f (x; X H ) H ; R n g as follows 0 x H R n A = @ 0 Q 11 A x H Using the standard QR updating procedure <ref> [3] </ref>, we have R = J ^ R MODIFYING THE GENERALIZED SVD 5 where ^ R is upper triangular, and J is a sequence of Givens rotations that eliminate the row vector x H .
Reference: [4] <author> M. Gu and S. C. Eisenstat. </author> <title> Downdating the singular value decomposition. </title> <institution> Research Report DCS-RR-939, Computer Science Department, Yale University, </institution> <year> 1993. </year>
Reference-contexts: We notice that U 1 can be updated as ^ U 1 = diag (1; U 1 ) U (I M ; 0) H . MODIFYING THE GENERALIZED SVD 7 3.1.2. The secular equation method. The secular equation method was discussed in great detail in <ref> [4] </ref>. Here we only point out that the updating problem can be reduced to their formulation. <p> 0) = 1 0 0 diag (I j ; C) M+1 )P: The problem is reduced to the computation of the eigenvalues and eigenvectors of 0 diag (I j ; C) M+1 ) 1 0 0 diag (I j ; C) This is exactly the form given in (5.7) of <ref> [4] </ref>. 3.2. The downdating algorithm.
Reference: [5] <author> C. C. Paige. </author> <title> Computing the generalized singular value decomposition. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 7 </volume> <pages> 1126-1146, </pages> <year> 1986. </year>
Reference-contexts: Two classes of numerical algorithms for computing the GSVD, one based on the CS decomposition [11, 13], and the other based on implicit Jacobi rotations <ref> [5] </ref>, have been developed. In this paper, we will consider designing numerical algorithms for the problems of updating and downdating the GSVD when new rows are added or old ones deleted.
Reference: [6] <author> C. C. Paige and M. A. Saunders. </author> <title> Toward a generalized singular value decomposition. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 18 </volume> <pages> 398-405, </pages> <year> 1981. </year>
Reference-contexts: It was first proposed by Van Loan under the name B-SVD [12], and later on improved by Paige and Saunders in a formulation that is more suitable for numerical computations <ref> [6] </ref>. Two classes of numerical algorithms for computing the GSVD, one based on the CS decomposition [11, 13], and the other based on implicit Jacobi rotations [5], have been developed. <p> ; ; s i+j ); 0 &lt; s i+1 s i+j &lt; 1; c 2 i+1 = 1; ; c 2 i+j = 1; i:e:; C 2 + S 2 = I j : i; j; l are integer indices that are determined by the ranks of certain associated matrices <ref> [6] </ref>. For non-coherent signals, their covariance matrix R ss is non-singular.
Reference: [7] <author> R. Roy and T. Kailath. </author> <title> ESPRIT|estimation of signal parameters via rotational invariance techniques. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 37 </volume> <pages> 984-993, </pages> <year> 1989. </year>
Reference-contexts: The application we have in mind for these updating and downdating algorithms is DOA finding with colored noises in sensor array signal processing <ref> [8, 7] </ref>. There are many research activities in the past decade on the so-called subspace-based approach for DOA finding and spectral analysis which claim to have higher resolution than the conventional methods. <p> The noise covariance matrix is assumed to be known up to a constant multiple oe 2 . The matrix A contains the so-called steering vectors and is of full column rank. M is the number of sensors, and d the number of signals <ref> [7] </ref>. The objective is to estimate spanfAg, the so-called signal subspace and from which the direction-of-arrivals of the signals can be computed, given estimates of R xx and n . <p> Computing the signal subspace using the GSVD. In DOA finding, the snapshots or data vectors are generated by x t = As t + n t ; where s t is the vector containing the signals and n t is the noise vector <ref> [7] </ref>. Forming the covariance matrix of x t and assuming that the signals and noises are uncorrelated, we obtain R xx j Efx t x H t g = AEfs t s H t gA H + Efn t n t g; which gives (1.1). <p> The TLS-version of obtaining an estimate of the matrix is the following: compute the SVD of (A 1 ; A 2 ) = U V H ; V = (V ij ) i;j=1;2 ; then V 12 V 1 22 <ref> [7] </ref>. We notice that the structural elements of the matrix pair fR 1=2 1=2 n g used in the DOA computation are its generalized singular values (used to determine the number of signals d and oe), V and R.
Reference: [8] <author> R. O. Schmidt. </author> <title> A Signal Subspace Approach to Multiple Emitter Location and Spectral Estimation. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering, Stanford University, Stanford, </institution> <year> 1981. </year>
Reference-contexts: The application we have in mind for these updating and downdating algorithms is DOA finding with colored noises in sensor array signal processing <ref> [8, 7] </ref>. There are many research activities in the past decade on the so-called subspace-based approach for DOA finding and spectral analysis which claim to have higher resolution than the conventional methods.
Reference: [9] <author> J. Speiser. </author> <title> Linear algebra problems arising from signal processing. Invited Presentation 3, </title> <booktitle> SIAM Annual Meeting, </booktitle> <year> 1989. </year>
Reference-contexts: 1. Introduction. The generalized singular value decomposition (GSVD) is one of the essential matrix decompositions that has many applications in signal processing and system identification <ref> [9, 10, 14] </ref>. It was first proposed by Van Loan under the name B-SVD [12], and later on improved by Paige and Saunders in a formulation that is more suitable for numerical computations [6].
Reference: [10] <author> J. Speiser and C. Van Loan. </author> <title> Signal processing using the generalized singular value decomposition. </title> <booktitle> SPIE, Real Time Signal Processing VII, </booktitle> <volume> 495 </volume> <pages> 47-55, </pages> <year> 1984. </year>
Reference-contexts: 1. Introduction. The generalized singular value decomposition (GSVD) is one of the essential matrix decompositions that has many applications in signal processing and system identification <ref> [9, 10, 14] </ref>. It was first proposed by Van Loan under the name B-SVD [12], and later on improved by Paige and Saunders in a formulation that is more suitable for numerical computations [6]. <p> Here E fg denotes expectation operator. When n 6= I M , the GSVD of fR 1=2 1=2 n g 1 was used for the DOA finding <ref> [10, 14] </ref>.
Reference: [11] <author> G. W. Stewart. </author> <title> A method for computing the generalized singular value decomposition. </title> <editor> In B. Kagstrom and A. Ruhe, editors, </editor> <booktitle> Matrix Pencils, </booktitle> <pages> pages 207-220, </pages> <address> New York, 1983. </address> <publisher> Springer. </publisher>
Reference-contexts: It was first proposed by Van Loan under the name B-SVD [12], and later on improved by Paige and Saunders in a formulation that is more suitable for numerical computations [6]. Two classes of numerical algorithms for computing the GSVD, one based on the CS decomposition <ref> [11, 13] </ref>, and the other based on implicit Jacobi rotations [5], have been developed. In this paper, we will consider designing numerical algorithms for the problems of updating and downdating the GSVD when new rows are added or old ones deleted. <p> of the matrix pair fX; R n g, taking into account of the discussion in the last section, can be written as R n = U 1 diag (I j ; C)V H R U 2 diag (0; S)V H R It can be computed in the following two steps <ref> [11, 13] </ref>: first compute the QR decom position of R n = Q 11 where R is nonsingular and upper triangular.
Reference: [12] <author> C. F. Van Loan. </author> <title> Generalizing the singular value decomposition. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 13 </volume> <pages> 76-83, </pages> <year> 1976. </year>
Reference-contexts: 1. Introduction. The generalized singular value decomposition (GSVD) is one of the essential matrix decompositions that has many applications in signal processing and system identification [9, 10, 14]. It was first proposed by Van Loan under the name B-SVD <ref> [12] </ref>, and later on improved by Paige and Saunders in a formulation that is more suitable for numerical computations [6]. Two classes of numerical algorithms for computing the GSVD, one based on the CS decomposition [11, 13], and the other based on implicit Jacobi rotations [5], have been developed.
Reference: [13] <author> C. F. Van Loan. </author> <title> Computing the CS and the generalized singular value decompositions. </title> <journal> Nu-merische Mathematik, </journal> <volume> 46 </volume> <pages> 479-491, </pages> <year> 1985. </year>
Reference-contexts: It was first proposed by Van Loan under the name B-SVD [12], and later on improved by Paige and Saunders in a formulation that is more suitable for numerical computations [6]. Two classes of numerical algorithms for computing the GSVD, one based on the CS decomposition <ref> [11, 13] </ref>, and the other based on implicit Jacobi rotations [5], have been developed. In this paper, we will consider designing numerical algorithms for the problems of updating and downdating the GSVD when new rows are added or old ones deleted. <p> of the matrix pair fX; R n g, taking into account of the discussion in the last section, can be written as R n = U 1 diag (I j ; C)V H R U 2 diag (0; S)V H R It can be computed in the following two steps <ref> [11, 13] </ref>: first compute the QR decom position of R n = Q 11 where R is nonsingular and upper triangular.
Reference: [14] <author> C. F. Van Loan. </author> <title> A unitary method for the ESPRIT direction-of-arrival estimation algorithm. </title> <booktitle> SPIE Advanced Algorithms and Architectures for Signal Processing, </booktitle> <volume> 826 </volume> <pages> 170-176, </pages> <year> 1987. </year>
Reference-contexts: 1. Introduction. The generalized singular value decomposition (GSVD) is one of the essential matrix decompositions that has many applications in signal processing and system identification <ref> [9, 10, 14] </ref>. It was first proposed by Van Loan under the name B-SVD [12], and later on improved by Paige and Saunders in a formulation that is more suitable for numerical computations [6]. <p> Here E fg denotes expectation operator. When n 6= I M , the GSVD of fR 1=2 1=2 n g 1 was used for the DOA finding <ref> [10, 14] </ref>.
Reference: [15] <author> M. Wax and T. Kailath. </author> <title> Detection of signals by information theoretic criteria. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 33 </volume> <pages> 387-392, </pages> <year> 1985. </year>
Reference-contexts: More details on the detection schemes for the number of signals can be found in <ref> [15] </ref>. The rest of this section is devoted to outlining the total least squares (TLS) version of the ESPRIT algorithm for DOA finding. This particular variant will be used in the numerical simulations in section 6. For simplicity, we only consider the uniform linear array (ULA) case.
Reference: [16] <author> H. Zha. </author> <title> A two-way chasing scheme for reducing a symmetric arrowhead matrix to tridiagonal form. Numerical Linear Algebra with Applications, </title> <booktitle> 1 </booktitle> <pages> 49-57, </pages> <year> 1992. </year>
Reference-contexts: In the following, we will apply a sequence of Givens rotations to reduce D to upper bidiagonal form. We adapt the two-way chasing idea in <ref> [16] </ref>: the elements are chased away from the 2 For the purpose of DOA finding, we only need the SVD of either one of these two matrices. MODIFYING THE GENERALIZED SVD 6 upper-left and bottom-right corners, and the computational cost is roughly one half that of the one-way chasing procedure. <p> MODIFYING THE GENERALIZED SVD 6 upper-left and bottom-right corners, and the computational cost is roughly one half that of the one-way chasing procedure. For details, see <ref> [16] </ref>. As used conventionally "fi" represents a possible nonzero entry of a matrix; "" represents the entry to be zeroed out at the current step.
References-found: 16

