URL: http://polaris.cs.uiuc.edu/reports/1303.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Title: Automatic Array Privatization  
Author: Peng Tu and David Padua 
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Abstract: Array privatization is one of the most effective transformations for the exploitation of parallelism. In this paper, we present a technique for automatic array privatization. Our algorithm uses data flow analysis of array references to identify privatizable arrays intraprocedu-rally as well as interprocedurally. It employs static and dynamic resolution to determine the last value of a lived private array. We compare the result of automatic array privatization with that of manual array privatization and identify directions for future improvement. To enhance the effectiveness of our algorithm, we develop a goal directly technique to analysis symbolic variables in the present of conditional statements, loops and index arrays.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> B. Alpern, M. N. Wegman, and F. K. Zadeck. </author> <title> Detecting Equality of Variables in Programs. </title> <booktitle> In Proc. of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 1-11, </pages> <year> 1988. </year>
Reference-contexts: SSA is an intermediate representation of a program that has two useful properties: 1. Each use of a variable is reached by exactly one definition to that variable. 2. The program contains PHI functions that merge the values of a variable from a distinct incoming control-flow graph. <ref> [1, 15, 17] </ref> present various applications of SSA, and [7] deals with efficiently transforming programs into SSA form. 5.1 Determine Symbolic Value on Demand The SSA form can be used to track the value of symbolic variables on demand.
Reference: 2. <author> Utpal Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: Section 5 presents a goal-directed technique that uses the SSA form of a program to determine symbolic values in the presence of conditional statements, loops, and index arrays. Section 6 presents the conclusion. 2 Background Data dependence <ref> [2] </ref> specifies the precedence constraints in the execution of statements in a program due to data producer and consumer relationships. <p> When there is more than one subscript of A in P RI b (L), we need to test if there is dependence between each pair of subscripted variables. We can use the Banerjee Test <ref> [2] </ref> to determine if within the loop boundaries two references referred to the same location.
Reference: 3. <author> M. Burke, R. Cytron, J. Ferrante, and W. Hsieh. </author> <title> Automatic generation of nested, fork-join parallelism. </title> <journal> Journal of Supercomputing, </journal> <pages> pages 71-88, </pages> <year> 1989. </year>
Reference-contexts: This work is not necessarily representative of the positions or policies of the Army or the Government. Previous work on eliminating memory-related dependence focused on scalar expansion [19], scalar privatization <ref> [3] </ref>, scalar renaming [6], and array expansion [13] [9]. Recently there have been several papers on array privatization [11][12][16]. We present an algorithm for automatically generating an annotated parallel program from a sequential program represented by a control flow graph.
Reference: 4. <author> D. Callahan and K. Kennedy. </author> <title> Analysis of interprocedural side effects in a parallel programming environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: A range includes expressions for the lower bound, upper bound, and stride. The notion of subarray we use in this paper is an extension at the regular section used by others <ref> [4] </ref>. Using subarray, we can represent the triangular region and banded region, as well as the strip, grid, column, row, and block of an array.
Reference: 5. <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed-memory multi-processors. </title> <journal> Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <month> October </month> <year> 1988. </year>
Reference: 6. <author> Ron Cytron and Jeanne Ferante. </author> <title> What's in a Name? or The Value of Renaming for Parallelism Detection and Storage Allocation. </title> <booktitle> In Proc. 1987 International Conf. on Parallel Processing, </booktitle> <pages> pages 19-27, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: This work is not necessarily representative of the positions or policies of the Army or the Government. Previous work on eliminating memory-related dependence focused on scalar expansion [19], scalar privatization [3], scalar renaming <ref> [6] </ref>, and array expansion [13] [9]. Recently there have been several papers on array privatization [11][12][16]. We present an algorithm for automatically generating an annotated parallel program from a sequential program represented by a control flow graph.
Reference: 7. <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Each use of a variable is reached by exactly one definition to that variable. 2. The program contains PHI functions that merge the values of a variable from a distinct incoming control-flow graph. [1, 15, 17] present various applications of SSA, and <ref> [7] </ref> deals with efficiently transforming programs into SSA form. 5.1 Determine Symbolic Value on Demand The SSA form can be used to track the value of symbolic variables on demand.
Reference: 8. <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the automatic parallelization of four Perfect-Benchmark programs. </title> <booktitle> In Proc. 4-th Workshop on Programming Languages and Compilers for Parallel Computing. </booktitle> <publisher> Pitman/MIT Press, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: By providing a distinct instance of a variable to each processor, privatization can eliminate memory related dependence. Previous studies on the effectiveness of automatic program parallelization show that privatization is one of the most effective transformations for the exploitation of parallelism <ref> [8] </ref>. A related technique called expansion [13] transforms each reference to a particular scalar into a reference to a vector element in such a way that each thread accesses a different vector element. When applied to an array, expansion creates a new dimension for the array. <p> This work can potentially identify more private arrays than other algorithms can identify. To evaluate its effectiveness, we test the algorithm on the programs in the Perfect Benchmarks. We compare the automatic privatization with manual privatization described in a previous study <ref> [8] </ref>. We find that for further improvement, more sophisticated symbolic analysis techniques are needed. To facilitate further improvement, we develop a goal-directed technique to analyze symbolic variables in the present of conditional statements, loops, and index arrays. The rest of the paper is organized as follows. <p> We compared the number of private arrays found by the algorithm with that of the manual array privatization reported in <ref> [8] </ref>. The result is shown in Table 1. The first column reports the number of private arrays identified by both manual and automatic privatization. The second column reports the number of private arrays identified by manual privatization but not by automatic privatization. <p> The algorithm has been implemented in the POLARIS system to perform interpro-cedural array privatization. Our experiments have thus far indicated that the algorithms can privatize most of the arrays privatized by hand in <ref> [8] </ref>. To increase the coverage of the algorithms, it seems necessary to use more sophisticated techniques for determining the equivalence of symbolic variables, and interpro-cedural symbolic values and bounds propagation.
Reference: 9. <author> P. Feautrier. </author> <title> Array expansion. </title> <booktitle> In Proc. 1988 ACM Int'l Conf. on Supercomputing, </booktitle> <month> July </month> <year> 1988. </year>
Reference-contexts: This work is not necessarily representative of the positions or policies of the Army or the Government. Previous work on eliminating memory-related dependence focused on scalar expansion [19], scalar privatization [3], scalar renaming [6], and array expansion [13] <ref> [9] </ref>. Recently there have been several papers on array privatization [11][12][16]. We present an algorithm for automatically generating an annotated parallel program from a sequential program represented by a control flow graph.
Reference: 10. <author> High Performance Fortran Forum. </author> <title> High performance fortran language specification (draft). </title> <type> Technical report, </type> <institution> High Performance Fortran Forum, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: The conflict can be resolved by declaring A to be private to each iteration of loop S1. We add the following directives to the loop: C$DIR INDEPENDENT C$DIR PRIVATE A (1:N) C$DIR LAST VALUE A (1:N) WHEN (I.EQ.N) The INDEPENDENT directive is borrowed from HPF <ref> [10] </ref>. It specifies that the iterations of loop S1 are independent. There are two directives for a private array. The PRIVATE directive associates the privatizable arrays with each iteration of a loop.
Reference: 11. <author> Zhiyuan Li. </author> <title> Array privatization for parallel execution of loops. </title> <booktitle> In Proc. of ICS'92, </booktitle> <pages> pages 313-322, </pages> <year> 1992. </year>
Reference: 12. <author> D. E. Maydan, S. P. Amarasinghe, and M. S. Lam. </author> <title> Data dependence and data-flow analysis of arrays. </title> <booktitle> In Proc. 5rd Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: The algorithm has been implemented in the POLARIS parallelizing compiler. Our work on automatic array privatization presents the following new results: We use data flow-based analysis for array reference. Compared with the dependence analysis-based approach <ref> [12] </ref>, which has to employ parametric integer programming in its most general case, our approach is more efficient and can handle nonlinear subscripts that cannot be handled by integer programming.
Reference: 13. <author> D. Padua and M. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: By providing a distinct instance of a variable to each processor, privatization can eliminate memory related dependence. Previous studies on the effectiveness of automatic program parallelization show that privatization is one of the most effective transformations for the exploitation of parallelism [8]. A related technique called expansion <ref> [13] </ref> transforms each reference to a particular scalar into a reference to a vector element in such a way that each thread accesses a different vector element. When applied to an array, expansion creates a new dimension for the array. <p> This work is not necessarily representative of the positions or policies of the Army or the Government. Previous work on eliminating memory-related dependence focused on scalar expansion [19], scalar privatization [3], scalar renaming [6], and array expansion <ref> [13] </ref> [9]. Recently there have been several papers on array privatization [11][12][16]. We present an algorithm for automatically generating an annotated parallel program from a sequential program represented by a control flow graph.
Reference: 14. <author> A. Rogers and K. Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> In Proc. the SIGPLAN '89 Conference on Program Language Design and Implementation, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: In the transformed program, it is easy for them to allocate a register to a scalar X. The transformation can also reduce the amount of false sharing in multiprocessor caches. In a distributed memory system with owner computes rule [21][5] <ref> [14] </ref>, the transformed program effectively transfers the ownership of A (I) to iteration I; hence the processor scheduled to execute the iteration I can execute operations in S2 even if it does not own A (I). This transformation can facilitate data distribution to reduce communication and improve load balance [16].
Reference: 15. <author> B. K. Rosen, M. N. Wegman, and F. K. Zadeck. </author> <title> Global Value Numbers and Redundant Computation. </title> <booktitle> In Proc. of the 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 12-27, </pages> <year> 1988. </year>
Reference-contexts: SSA is an intermediate representation of a program that has two useful properties: 1. Each use of a variable is reached by exactly one definition to that variable. 2. The program contains PHI functions that merge the values of a variable from a distinct incoming control-flow graph. <ref> [1, 15, 17] </ref> present various applications of SSA, and [7] deals with efficiently transforming programs into SSA form. 5.1 Determine Symbolic Value on Demand The SSA form can be used to track the value of symbolic variables on demand.
Reference: 16. <author> Peng Tu and David Padua. </author> <title> Array privatization for shared and distributed memory machines. </title> <booktitle> In Proc. 2nd Workshop on Languages, Compilers, and Run-Time Environments for Distributed Memory Machines, to appear on ACM SIGPLAN Notices 1993, </booktitle> <month> September </month> <year> 1992. </year>
Reference-contexts: Because the access to a private variable is inherently local, privatization reduces the communication and facilitates data distribution. Since private instances of a variable are spread among all the active processors, privatization provides opportunities to spread computation among the processors and improve load balancing <ref> [16] </ref>. ? The research described was supported by Army contract DABT63-92-C-0033 and CSRD affiliate program from Motorola Corporation. This work is not necessarily representative of the positions or policies of the Army or the Government. <p> This transformation can facilitate data distribution to reduce communication and improve load balance <ref> [16] </ref>. For the purpose of eliminating memory-related dependence in this paper, the array A in the previous example need not be privatized. The condition for pri-vatization exists when different iterations of the loop access same location. This can be determined by examining P RI b (L).
Reference: 17. <author> M. N. Wegman and F. K. Zadeck. </author> <title> Constant propagation with conditional branches. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 181-210, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: SSA is an intermediate representation of a program that has two useful properties: 1. Each use of a variable is reached by exactly one definition to that variable. 2. The program contains PHI functions that merge the values of a variable from a distinct incoming control-flow graph. <ref> [1, 15, 17] </ref> present various applications of SSA, and [7] deals with efficiently transforming programs into SSA form. 5.1 Determine Symbolic Value on Demand The SSA form can be used to track the value of symbolic variables on demand.
Reference: 18. <author> Michael Wolfe. </author> <title> Beyond induction variables. </title> <booktitle> ACM PLDI'92, </booktitle> <year> 1992. </year>
Reference-contexts: Induction variable's last value can be determined using induction variable substitution technique such as presented in <ref> [18] </ref>. In this section, we will show a technique to estimate the bounds of monotonic variable. <p> In this example, we extend the PHI function to include loop label L3 in it to identify the loop control. Following the terminology used by Wolfe on induction variables <ref> [18] </ref>, L 2 will appear as a Strongly Connected Region (SCR) that includes a loop header PHI function and some conditional PHI functions. To find the upper bounds of L 2, we need to find the cycle with maximum increment to L 2 in the SCR.
Reference: 19. <author> Michael Joseph Wolfe. </author> <title> Optimizing supercompilers for supercomputers. </title> <type> Technical Report UIUCDCS-R-82-1105, </type> <institution> Department of Computer Science, University of Illinois, </institution> <month> October </month> <year> 1982. </year>
Reference-contexts: This work is not necessarily representative of the positions or policies of the Army or the Government. Previous work on eliminating memory-related dependence focused on scalar expansion <ref> [19] </ref>, scalar privatization [3], scalar renaming [6], and array expansion [13] [9]. Recently there have been several papers on array privatization [11][12][16]. We present an algorithm for automatically generating an annotated parallel program from a sequential program represented by a control flow graph.
Reference: 20. <author> Chuan-Qi Zhu and Pen-Chung Yew. </author> <title> A scheme to enforce data dependence on large multiprocessor systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 13(6) </volume> <pages> 726-739, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: A is still privatizable because it satisfies the privatizability conditions, but its last-value assignment cannot be determined at compile time. We use the key word DYNAMIC to specify that run-time resolution techniques such as synchronization variable <ref> [20] </ref> will have to be used for the array section A (2:N). These cases are termed dynamic last-value assignment. For instance, the compiler can associate the subarray A (2:N) with a synchronization variable last-iteration, which stores the last iteration that was written to A (2:N). <p> Another problem is that some complicated subscript expressions make it inefficient to compute at compile time which iteration will assign the last value. In these cases, we will use well-known run-time techniques such as <ref> [20] </ref> to resolve the output dependence. Our first step is to identify the private arrays that need dynamic last-value assignments because of conditional definition.
Reference: 21. <author> H. Zima, H.-J. Bast, and M. Gerndt. </author> <title> Superb: A tool for semi-automatic MIMD/SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6 </volume> <pages> 1-18, </pages> <year> 1988. </year>
Reference: 22. <author> Hans Zima and Barbara Chapman. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <year> 1991. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: A definition of variable v in a basic block S is said to be outward exposed if it is the last definition of v in S. A use of v is outward exposed if S does not contain a definition of v before this use <ref> [22] </ref>. Definition 4. Let S be a basic block and V AR be the set of scalar variables, subscripted variables, and subarrays in the program. Henceforth these are called variables. 1. DEF (S) := fv 2 V AR : v has an outward exposed definition in S g 2.
References-found: 22

