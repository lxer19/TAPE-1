URL: http://www.cs.princeton.edu/~appel/papers/smlnj.ps
Refering-URL: http://www.cs.princeton.edu/~appel/papers/
Root-URL: http://www.cs.princeton.edu
Title: Standard ML of New Jersey  
Author: Andrew W. Appel David B. MacQueen 
Date: June 1991  
Address: Princeton University,  
Affiliation: Princeton University  AT&T Bell Laboratories CS-TR-329-91, Dept. of Computer Science,  
Abstract: This paper appeared in Third Int'l Symp. on Prog. Lang. Implementation and Logic Programming, Springer-Verlag LNCS 528, pp. 1-13, August 1991. Abstract The Standard ML of New Jersey compiler has been under development for five years now. We have developed a robust and complete environment for Standard ML that supports the implementation of large software systems and generates efficient code. The compiler has also served as a laboratory for developing novel implementation techniques for a sophisticated type and module system, continuation based code generation, efficient pattern matching, and concurrent programming features. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew W. Appel. </author> <title> Runtime tags aren't necessary. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 2 </volume> <pages> 153-162, </pages> <year> 1989. </year>
Reference-contexts: The only reasons to have these tags are for the garbage collector (so it can understand how to traverse pointers and records) and for the polymorphic equality function. But it's possible to give the garbage collector a map of the type system <ref> [1] </ref>, so that it can figure out the types of runtime objects without tags and descriptors.
Reference: [2] <author> Andrew W. Appel. </author> <title> Simple generational garbage collection and fast allocation. </title> <journal> Software|Practice and Experience, </journal> <volume> 19(2) </volume> <pages> 171-183, </pages> <year> 1989. </year>
Reference-contexts: This means that the most important requirement for the runtime system is that it support fast storage allocation and fast garbage collection. To make heap allocations cheap, we use a generational copying garbage collector <ref> [2] </ref> and we keep the format of our runtime data simple [3].
Reference: [3] <author> Andrew W. Appel. </author> <title> A runtime system. </title> <booktitle> Lisp and Symbolic Computation, </booktitle> <pages> 3(343-380), </pages> <year> 1990. </year>
Reference-contexts: This means that the most important requirement for the runtime system is that it support fast storage allocation and fast garbage collection. To make heap allocations cheap, we use a generational copying garbage collector [2] and we keep the format of our runtime data simple <ref> [3] </ref>. Copying collection is attractive because the collector touches only the live data, and not the garbage; we can arrange that almost all of a particular region of memory is garbage, then just a few operations can reclaim a very large amount of storage. <p> This encourages a more side-effect-free, functional style of programming. In addition to the garbage collector, the runtime system provides an interface to operating system calls <ref> [3] </ref>. Higher-level services like buffered I/O are provided by a "standard library" written in Standard ML.
Reference: [4] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Thus, fi-reductions and other optimizations become much easier to specify and implement. The CPS notation [30] and our representation of it [5] are described elsewhere, as is a detailed description of optimization techniques and runtime representations for CPS <ref> [4] </ref>. We will just summarize the important points here. In continuation-passing style, each function can have several arguments (in contrast to ML, in which functions formally have only one parameter). Each of the actual parameters to a function must be atomic|a constant or a variable. <p> In fact, we investigated many different representational tricks on the spectrum between flat and linked closures [6], including tricks where we use the same closure record for several different functions with several different code-pointers <ref> [5, 4] </ref>. In a "traditional" compiler, these tricks make a significant difference. But in the CPS representation, it appears that the pattern of functions and variable access narrows the effective difference between these techniques, so that closure representation is not usually too important. <p> There are two aspects of closures that are important, however. We have recently shown that using linked or merged closures can cause a compiled program to use much more memory <ref> [4] </ref>. For example, a program compiled with flat closures might use O (N ) memory (i.e. simultaneous live data) on an input of size N , and the same program compiled with linked closures might use O (N 2 ). <p> After closure-conversion and before code generation we have a spill phase that rewrites the CPS expression to limit the number of free variables of any subexpression to less than the number of registers on the target machine <ref> [5, 4] </ref>. It turns out that very few functions require any such rewriting, especially on modern machines with 32 registers; five spills in 40,000 lines of code is typical. <p> This not only simplifies some aspects of our runtime system, but makes the use of first-class continuations (call-with-current-continuation) very efficient. Because all closures are put on the heap, however, SML/NJ allocates garbage-collected storage at a furious rate: one 32-bit word of storage for every five instructions executed, approximately <ref> [4] </ref>. This means that the most important requirement for the runtime system is that it support fast storage allocation and fast garbage collection. To make heap allocations cheap, we use a generational copying garbage collector [2] and we keep the format of our runtime data simple [3]. <p> Furthermore, we can perform this test in one single-cycle instruction by clever use of the overflow interrupt to initiate garbage collection <ref> [4] </ref>. Overall, garbage-collection overhead in Standard ML of New Jersey (with memory size equal to 5 times the amount of live data) is usually between 5 and 20%; this means that for each word of memory allocated, the amortized cost of collecting it is about 1/4 to 1 instruction. <p> The quality of our compiled code is extremely good, as figures 1 and 2 show. We tested Poly/ML [24] and SML/NJ on six real programs <ref> [4] </ref>, whose average size was about 2000 nonblank noncomment lines of source. Figure 1 shows the results on a SparcStation 2 (the only modern platform on which they both run).
Reference: [5] <author> Andrew W. Appel and Trevor Jim. </author> <title> Continuation-passing, closure-passing style. </title> <booktitle> In Sixteenth ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 293-302, </pages> <year> 1989. </year>
Reference-contexts: Thus, fi-reductions and other optimizations become much easier to specify and implement. The CPS notation [30] and our representation of it <ref> [5] </ref> are described elsewhere, as is a detailed description of optimization techniques and runtime representations for CPS [4]. We will just summarize the important points here. In continuation-passing style, each function can have several arguments (in contrast to ML, in which functions formally have only one parameter). <p> In fact, we investigated many different representational tricks on the spectrum between flat and linked closures [6], including tricks where we use the same closure record for several different functions with several different code-pointers <ref> [5, 4] </ref>. In a "traditional" compiler, these tricks make a significant difference. But in the CPS representation, it appears that the pattern of functions and variable access narrows the effective difference between these techniques, so that closure representation is not usually too important. <p> After closure-conversion and before code generation we have a spill phase that rewrites the CPS expression to limit the number of free variables of any subexpression to less than the number of registers on the target machine <ref> [5, 4] </ref>. It turns out that very few functions require any such rewriting, especially on modern machines with 32 registers; five spills in 40,000 lines of code is typical. <p> Thanks to Trevor Jim for helping to design the CPS representation <ref> [5] </ref>; and for implementing the match compiler and the original closure-converter, the original library of floating point functions, and the original assembly-language implementation of external primitive functions. Thanks to Bruce F.
Reference: [6] <author> Andrew W. Appel and Trevor T. Y. Jim. </author> <title> Optimizing closure environment representations. </title> <type> Technical Report 168, </type> <institution> Dept. of Computer Science, Princeton University, </institution> <year> 1988. </year>
Reference-contexts: In fact, we investigated many different representational tricks on the spectrum between flat and linked closures <ref> [6] </ref>, including tricks where we use the same closure record for several different functions with several different code-pointers [5, 4]. In a "traditional" compiler, these tricks make a significant difference.
Reference: [7] <author> Andrew W. Appel and David B. MacQueen. </author> <title> A Standard ML compiler. </title> <editor> In Gilles Kahn, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture (LNCS 274), </booktitle> <pages> pages 301-324. </pages> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: There were some unexpected interactions between the module system, type system, code generator, debugger, garbage collector, runtime data format, and hardware; and some things were much easier than expected. We wrote an early description of the compiler in the spring of 1987 <ref> [7] </ref>, but almost every component of the compiler has since been redesigned and reimplemented at least once, so it is worthwhile to provide an updated overview of the system and our implementation experience. <p> This is one of the advantages of ML: programs (and programmers) can migrate gradually to "functional" programming. Type checking The main type-checking algorithm has changed relatively little since our earlier description <ref> [7] </ref>. The representations of types, type constructors, and type variables have been cleaned up in various ways, but the basic algorithm for type checking is still based on a straightforward unification algorithm. <p> Instead, there is a very simple case statement that determines which constructor has been applied at top level in a given value. The pattern-matches of ML must be translated into discriminations on individual constructors. This is done as described in our previous paper <ref> [7] </ref>, though Bruce Duba has revised the details of the algorithm. The dynamic semantics of structures and functors are represented using the same lambda-language operators as for the records and functions of the core language.
Reference: [8] <author> Andrew W. Appel, James S. Mattson, and David R. Tarditi. </author> <title> A lexical analyzer generator for Standard ML. distributed with Standard ML of New Jersey, </title> <month> December </month> <year> 1989. </year>
Reference-contexts: In both of these components the code for semantic analysis was intermixed with the parsing code. This made error recovery difficult, and it was difficult to understand the syntax or semantics individually. We now have excellent tools <ref> [8, 32] </ref> for the automatic generation of lexical analyzers and error-correcting parsers. Syntactic error recovery is handled automatically by the parser generator, and semantic actions are only evaluated on correct (or corrected) parses. <p> Tolmach for the SML/NJ debugger [35], and for the new pure-functional style of static environments; and Adam T. Dingle for the debugger's Emacs interface. Thanks to James S. Mattson for the first version of the ML lexical analyzer generator; and to David R. Tarditi for making the lexer-generator production-quality <ref> [8] </ref>, for implementing a really first-class parser generator [32], for helping to implement the type-reconstruction algorithm used by the debugger [35], and for the the ML-to-C translator he implemented with Anurag Acharya and Peter Lee [31].
Reference: [9] <author> Andrew W. Appel and Zhong Shao. </author> <title> Callee-save registers in continuation-passing style. </title> <type> Technical Report CS-TR-326-91, </type> <institution> Princeton Univ. Dept. of Computer Science, Princeton, NJ, </institution> <month> June </month> <year> 1991. </year>
Reference-contexts: Thanks to Zhong Shao for the common-subexpression eliminator, as well as the callee-save convention that uses multiple-register continuations for faster procedure calls <ref> [9] </ref>. We thank Nick Rothwell and Mads Tofte for the initial implementation of the separate compilation mechanism, and Gene Rollins for his recent improvements. Finally we thank our user community that sends us bug reports, keeps us honest, and actually finds useful things to do with Standard ML.
Reference: [10] <author> David Berry. </author> <title> SML resources. sent to the SML mailing list by db@lfcs.ed.ac.uk, </title> <month> May </month> <year> 1991. </year>
Reference-contexts: Indeed, Poly/ML compiles about 43% faster (when it doesn't blow up); but SML/NJ programs run five times faster than Poly/ML programs, on the average (geometric mean). SML/NJ reportedly uses about 1.5 times as much heap space for execution <ref> [10] </ref>; and on a 68020-based platform (like a Sun-3), SML/NJ may not do relatively as well (since we don't generate really good code for that machine). So on obsolete machines with tiny memories, Poly/ML may do almost as well as SML/NJ. programming languages on a Knuth-Bendix benchmark.
Reference: [11] <author> CAML: </author> <title> The reference manual (version 2.3). </title> <institution> Projet Formel, INRIA-ENS, </institution> <month> June </month> <year> 1987. </year>
Reference-contexts: Since the program uses higher-order functions, Leroy had to do manual lambda-lifting to write the program in Lisp and C, and in some places had to use explicit closures (structures containing function-pointers). CAML is a different version of the ML language (i.e. not Standard ML) developed at INRIA <ref> [11] </ref>; CAML V2-6.1 is a native-code compiler that shares the LeLisp runtime system, and CAML Light [20] is a compiler with a byte-code interpreter written in C. SML/NJ x refers to Standard ML of New Jersey with all modules placed in "super-module" to allow cross-module optimization. calls.
Reference: [12] <author> Eric C. Cooper and J. Gregory Morrisett. </author> <title> Adding threads to Standard ML. </title> <type> Technical Report CMU-CS-90-186, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Two major concurrency systems have been implemented at this point: Concurrent ML by John Reppy [28] is based on CCS/CSP-style primitives (synchronous communication on typed channels) but introduces the novel idea of first-class events. ML Threads is a system designed by Eric Cooper and Greg Morrisett <ref> [12] </ref> that provides mutual exclusion primitives for synchronization. A version of ML Threads runs on shared-memory multiprocessors, where threads can be scheduled to run in parallel on separate physical processors.
Reference: [13] <author> N. G. deBruijn. </author> <title> Lambda calculus notation with nameless dummies, a tool for automatic formula manipulation. </title> <journal> Indag. Math., </journal> <volume> 34 </volume> <pages> 381-392, </pages> <year> 1972. </year>
Reference-contexts: Managing bound stamps was a source of complexity and bugs in the module system. The usual way of avoiding the complications of bound variables is to replace them with an indexing scheme, as is done with deBruijn indices in the lambda calculus <ref> [13] </ref>. Since in the symbol table part we already used indices into instantiation arrays to refer to volatile components, we can avoid the bound stamps by using this relativized symbol table alone to represent signatures.
Reference: [14] <author> Bruce Duba, Robert Harper, and David Mac--Queen. </author> <title> Typing first-class continuations in ML. </title> <booktitle> In Eighteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 163-173, </pages> <month> Jan </month> <year> 1991. </year>
Reference-contexts: Standard ML of New Jersey does quite well, especially on the RISC machine (the DECstation 5000 has a MIPS processor). 11 Continuations One of the more significant language innovations in Standard ML of New Jersey is typed first-class continuations <ref> [14] </ref>. <p> Thanks to Bruce F. Duba for improvements to the match compiler, the CPS constant-folding phase, the in-line expansion phase, the spill phase, and numerous other parts of the compiler; and for his part in the design of the call-with-current-continuation mechanism <ref> [14] </ref>. Thanks to James W. O'Toole who implemented the NS32032 code generator, and Norman Ramsey who implemented the MIPS code generator. We thank Andrew P. Tolmach for the SML/NJ debugger [35], and for the new pure-functional style of static environments; and Adam T. Dingle for the debugger's Emacs interface.
Reference: [15] <author> Carl A. Gunter, Elsa L. Gunter, and David B. Mac-Queen. </author> <title> An abstract interpretation for ML equality kinds. </title> <booktitle> In Theoretical Aspects of Computer Software. </booktitle> <publisher> Springer, </publisher> <month> September </month> <year> 1991. </year>
Reference-contexts: tags, so even with a sophisticated garbage collector they can't be done away with. (One alternative is to pass an equality-test function along with every value of an equality type, but this is also quite costly [36].) Finally, the treatment of equality types in Standard ML is irregular and incomplete <ref> [15] </ref>. The Definition categorizes type constructors as either "equality" or "nonequality" type constructors; but a more refined classification would more accurately specify the effects of the ref operator.
Reference: [16] <author> S. C. Johnson. </author> <title> Yacc yet another compiler compiler. </title> <type> Technical Report CSTR-32, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NJ, </address> <year> 1975. </year>
Reference-contexts: Each production of our grammar is annotated by a semantic action, roughly in the style made popular by YACC <ref> [16] </ref>. Our semantic actions are written like a denotational semantics or attribute grammar, where each fragment is a function that takes inherited attributes as parameters and returns synthesized attributes as results. Within the actions there are occasional side-effects; e.g. when the type-checker performs unification by the modification of ref-cells.
Reference: [17] <author> James William O'Toole Jr. </author> <title> Type abstraction rules for references: A comparison of four which have achieved noteriety. </title> <type> Technical Report 380, </type> <institution> MIT Lab. for Computer Science, </institution> <year> 1990. </year>
Reference-contexts: The weak typing scheme is fairly subtle and has been prone to bugs, so it is important that it be formalized and proven sound (as the Tofte scheme has been [Tofte-thesis]). There are several people currently working on formalizing the treatment used in the compiler <ref> [17, 38] </ref>. The weak polymorphism scheme currently used in Standard ML of New Jersey is not regarded as the final word on polymorphism and references. It shares with the imperative type variable scheme the fault that weak polymorphism propagates more widely than necessary. <p> This inessential weak polymorphism is particularly annoying when it interferes with the matching of a signature specification merely because of the use of an imperative style within a function's definition. Such implementation choices should be invisible in the type. Research continues on this problem <ref> [17, 22, 38] </ref>, but there is no satisfactory solution yet. The interface between the type checker and the parser is quite simple in most respects.
Reference: [18] <author> David Kranz. </author> <title> ORBIT: An optimizing compiler for Scheme. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1987. </year>
Reference-contexts: CPS is used because it has clean semantic properties (like -calculus), but it also matches the execution model of a von Neumann register machine: variables of the CPS correspond closely to registers on the machine, which leads to very efficient code generaton <ref> [18] </ref>. In the -language (with side-effecting operators) we must specify a call-by-value (strict) order of evaluation to really pin down the meaning of the program; this means that we can't simply do arbitrary fi-reductions (etc.) to partially evaluate and optimize the program. <p> For those functions whose call sites are all evident to the compiler (i.e. those functions that are not passed as parameters or stored into data structures), we can choose the register-bindings for formal parameters to eliminate any moves in at least one of the calls <ref> [18] </ref>. <p> Although most CPS-based compilers introduce a runtime stack anyway <ref> [30, 18] </ref>, we do not. Instead, we keep all closures (i.e. activation records) on the garbage-collected heap. This not only simplifies some aspects of our runtime system, but makes the use of first-class continuations (call-with-current-continuation) very efficient.
Reference: [19] <author> P. J. Landin. </author> <title> The mechanical evaluation of expressions. </title> <journal> Computer J., </journal> <volume> 6(4) </volume> <pages> 308-320, </pages> <year> 1964. </year>
Reference-contexts: But it's not necessary to keep the free variables (item 2) in any standard order; instead, g will simply pass f's closure-pointer as an extra argument to f, which will know how to extract its own free variables. This mechanism is quite old <ref> [19] </ref> and reasonably efficient. However, the introduction of closures is usually performed as part of machine-code generation; we have made it a separate phase that rewrites the CPS representation of the program to include closure records.
Reference: [20] <author> Xavier Leroy. </author> <title> The ZINC experiment: an economical implementation of the ML language. </title> <type> Technical Report No. 117, </type> <institution> INRIA, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: CAML is a different version of the ML language (i.e. not Standard ML) developed at INRIA [11]; CAML V2-6.1 is a native-code compiler that shares the LeLisp runtime system, and CAML Light <ref> [20] </ref> is a compiler with a byte-code interpreter written in C. SML/NJ x refers to Standard ML of New Jersey with all modules placed in "super-module" to allow cross-module optimization. calls.
Reference: [21] <author> Xavier Leroy. </author> <title> INRIA, </title> <type> personal communication, </type> <year> 1991. </year>
Reference-contexts: 6.2 6.2 CAML Light 0.2 28.3 6.5 SML/NJ 0.65 9.6 0.3 1.7 0.1 LeLisp 15.23 4.1 1.4 SunOS 3.5, cc -O 4.35 gcc 1.37.1, gcc -O 4.22 Ultrix 4.0, cc -O2 0.90 Xavier Leroy translated Gerard Huet's Knuth-Bendix program into several different languages, and ran them on two different machines <ref> [21] </ref>. This table shows non-gc run time and gc time in seconds for each version of the program. Since the program uses higher-order functions, Leroy had to do manual lambda-lifting to write the program in Lisp and C, and in some places had to use explicit closures (structures containing function-pointers).
Reference: [22] <author> Xavier Leroy and Pierre Weis. </author> <title> Polymorphic type inference and assignment. </title> <booktitle> In Eighteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <month> Jan </month> <year> 1991. </year>
Reference-contexts: This inessential weak polymorphism is particularly annoying when it interferes with the matching of a signature specification merely because of the use of an imperative style within a function's definition. Such implementation choices should be invisible in the type. Research continues on this problem <ref> [17, 22, 38] </ref>, but there is no satisfactory solution yet. The interface between the type checker and the parser is quite simple in most respects.
Reference: [23] <author> David B. MacQueen. </author> <title> The implementation of Standard ML modules. </title> <booktitle> In ACM Conf. on Lisp and Functional Programming, </booktitle> <pages> pages 212-223, </pages> <year> 1988. </year>
Reference-contexts: The main innovation of the second version factored signatures into a symbol table shared among all instances, and a small instantiation environment for each instance <ref> [23] </ref>. Experience with this version revealed problems that led to the third implementation developed in collaboration with Georges Gonthier and Damien Doligez. Representations At the heart of the module system are the internal representations of signatures, structures, and func-tors. <p> The instantiation environment is represented as a pair of arrays, one for type constructor components, the other for substructures. The static representation of a structure is essentially an environment (i.e., symbol table) containing bindings of types, variables, etc., and an identifying stamp <ref> [26, 33, 23] </ref>. In the second implementation a signature was represented as a "dummy" instance that differs from an ordinary structure in that its volatile components contain dummy or bound stamps and it carries some additional information specifying sharing constraints.
Reference: [24] <author> David C. J. Matthews. </author> <title> Papers on Poly/ML. </title> <type> Technical Report T.R. No. 161, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> February </month> <year> 1989. </year>
Reference-contexts: Our compiler's front end is quite carefully designed to be fast, but the back end needs (and is receiving) further work to make it compile faster. The quality of our compiled code is extremely good, as figures 1 and 2 show. We tested Poly/ML <ref> [24] </ref> and SML/NJ on six real programs [4], whose average size was about 2000 nonblank noncomment lines of source. Figure 1 shows the results on a SparcStation 2 (the only modern platform on which they both run).
Reference: [25] <author> Robin Milner and Mads Tofte. </author> <title> Commentary on Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1991. </year>
Reference: [26] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Standard ML of New Jersey is a compiler and programming environment for the Standard ML language <ref> [26] </ref> that has been continuously developed since early 1986. Our initial goal was to produce a working ML front end and interpreter for programming language research, but the scope of the project has expanded considerably. <p> This has greatly improved both the quality of the error messages and the robustness of the compiler on incorrect inputs. We remark that it would have been helpful if the definition of Standard ML <ref> [26] </ref> had included an LR (1) grammar for the language. There are two places in the ML grammar that appear not to be context free. <p> Standard ML of New Jersey implements a generalization of the imperative type variables described in the Definition <ref> [26, 34] </ref>. In our scheme, imperative type variables are replaced by weak type variables that have an associated degree of weakness: a nonnegative integer. <p> However, the interface between type checking and the parser is complicated by the problem of determining the scope or binding point of explicit type variables that appear in a program. The rather subtle scoping rules for these type variables <ref> [26, Section 4.6] </ref>[25, Section 4.4] force the parser to pass sets of type variables both upward and downward (as both synthesized and inherited attributes of phrases). <p> The instantiation environment is represented as a pair of arrays, one for type constructor components, the other for substructures. The static representation of a structure is essentially an environment (i.e., symbol table) containing bindings of types, variables, etc., and an identifying stamp <ref> [26, 33, 23] </ref>. In the second implementation a signature was represented as a "dummy" instance that differs from an ordinary structure in that its volatile components contain dummy or bound stamps and it carries some additional information specifying sharing constraints.
Reference: [27] <author> John H. Reppy. </author> <title> Asynchronous signals in Standard ML. </title> <type> Technical Report TR 90-1144, </type> <institution> Cornell University, Dept. of Computer Science, </institution> <address> Ithaca, NY, </address> <year> 1990. </year>
Reference-contexts: Since the overhead for calling a C function is rather high, we have implemented half a dozen frequently-used functions (e.g. allocation of an array or a string) in assembly language. There is also an ML interface to operating system signals <ref> [27] </ref> that uses the call/cc mechanism to bundle up the current state of execution into a "continuation;" to be resumed immediately, later (perhaps from another signal handler), never, or more than once. <p> This is the basis of the time travel capabilities of the debugger. It is well known that continuations are useful for implementing coroutines and for simulating parallel threads of control [37]. Using continuations in conjunction with the signal handling mechanisms implemented by John Reppy <ref> [27] </ref> (themselves expressed in terms of continuations), one can build light-weight process libraries with preemptive process scheduling entirely within Standard ML of New Jersey. <p> We would like to thank John H. Reppy for many improvements and rewrites of the runtime system, for designing and implementing the signal-handling mechanism <ref> [27] </ref>, improving the call/cc mechanism, designing the current mechanism for calls to C functions, implementing a sophisticated new garbage collector, generally making the runtime system more robust, and implementing the SPARC code generator; and for designing and implementing the Concurrent ML system [28] and its X-windows interface [29].
Reference: [28] <author> John H. Reppy. </author> <title> Concurrent programming with events. </title> <type> Technical report, </type> <institution> Cornell University, Dept. of Computer Science, </institution> <address> Ithaca, NY, </address> <year> 1990. </year>
Reference-contexts: The most complex part of the type-checking algorithm deals with weak polymorphism, a restricted form of polymorphism required to handle mutable values (references and arrays), exception transmission, and communication (in extensions like Concurrent ML <ref> [28] </ref>). Standard ML of New Jersey implements a generalization of the imperative type variables described in the Definition [26, 34]. In our scheme, imperative type variables are replaced by weak type variables that have an associated degree of weakness: a nonnegative integer. <p> Two major concurrency systems have been implemented at this point: Concurrent ML by John Reppy <ref> [28] </ref> is based on CCS/CSP-style primitives (synchronous communication on typed channels) but introduces the novel idea of first-class events. ML Threads is a system designed by Eric Cooper and Greg Morrisett [12] that provides mutual exclusion primitives for synchronization. <p> system, for designing and implementing the signal-handling mechanism [27], improving the call/cc mechanism, designing the current mechanism for calls to C functions, implementing a sophisticated new garbage collector, generally making the runtime system more robust, and implementing the SPARC code generator; and for designing and implementing the Concurrent ML system <ref> [28] </ref> and its X-windows interface [29]. Thanks to Trevor Jim for helping to design the CPS representation [5]; and for implementing the match compiler and the original closure-converter, the original library of floating point functions, and the original assembly-language implementation of external primitive functions. Thanks to Bruce F.
Reference: [29] <author> John H. Reppy and Emden R. Gansner. </author> <title> The eXene library manual. </title> <institution> Cornell Univ. Dept. of Computer Science, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: the signal-handling mechanism [27], improving the call/cc mechanism, designing the current mechanism for calls to C functions, implementing a sophisticated new garbage collector, generally making the runtime system more robust, and implementing the SPARC code generator; and for designing and implementing the Concurrent ML system [28] and its X-windows interface <ref> [29] </ref>. Thanks to Trevor Jim for helping to design the CPS representation [5]; and for implementing the match compiler and the original closure-converter, the original library of floating point functions, and the original assembly-language implementation of external primitive functions. Thanks to Bruce F.
Reference: [30] <author> Guy L. Steele. Rabbit: </author> <title> a compiler for Scheme. </title> <type> Technical Report AI-TR-474, </type> <institution> MIT, </institution> <year> 1978. </year>
Reference-contexts: In the conversion to CPS, all order-of-evaluation information is encoded in the chaining of function calls, and it doesn't matter whether we consider the CPS to be strict or non-strict. Thus, fi-reductions and other optimizations become much easier to specify and implement. The CPS notation <ref> [30] </ref> and our representation of it [5] are described elsewhere, as is a detailed description of optimization techniques and runtime representations for CPS [4]. We will just summarize the important points here. <p> Although most CPS-based compilers introduce a runtime stack anyway <ref> [30, 18] </ref>, we do not. Instead, we keep all closures (i.e. activation records) on the garbage-collected heap. This not only simplifies some aspects of our runtime system, but makes the use of first-class continuations (call-with-current-continuation) very efficient.
Reference: [31] <author> David R. Tarditi, Anurag Acharya, and Peter Lee. </author> <title> No assembly required: Compiling Standard ML to C. </title> <type> Technical Report CMU-CS-90-187, </type> <institution> Carnegie Mellon Univ., </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: One such project is the SML-to-C translator done by David Tarditi, Anurag Acharya, and Peter Lee at Carnegie Mellon <ref> [31] </ref>. This provides a very portable basis for running ML programs on a variety of hardware for which we do not yet have native code generators, with very respectable performance. Mads Tofte and Nick Rothwell implemented the first version of separate compilation for Standard ML of New Jersey. <p> Tarditi for making the lexer-generator production-quality [8], for implementing a really first-class parser generator [32], for helping to implement the type-reconstruction algorithm used by the debugger [35], and for the the ML-to-C translator he implemented with Anurag Acharya and Peter Lee <ref> [31] </ref>. We appreciate Lal George's teaching the code generator about floating point registers and making floating-point performance respectable; and his fixing of several difficult bugs not of his own cre ation.
Reference: [32] <author> David R. Tarditi and Andrew W. Appel. ML-Yacc, </author> <title> version 2.0. distributed with Standard ML of New Jersey, </title> <month> April </month> <year> 1990. </year>
Reference-contexts: In both of these components the code for semantic analysis was intermixed with the parsing code. This made error recovery difficult, and it was difficult to understand the syntax or semantics individually. We now have excellent tools <ref> [8, 32] </ref> for the automatic generation of lexical analyzers and error-correcting parsers. Syntactic error recovery is handled automatically by the parser generator, and semantic actions are only evaluated on correct (or corrected) parses. <p> Dingle for the debugger's Emacs interface. Thanks to James S. Mattson for the first version of the ML lexical analyzer generator; and to David R. Tarditi for making the lexer-generator production-quality [8], for implementing a really first-class parser generator <ref> [32] </ref>, for helping to implement the type-reconstruction algorithm used by the debugger [35], and for the the ML-to-C translator he implemented with Anurag Acharya and Peter Lee [31].
Reference: [33] <author> Mads Tofte. </author> <title> Operational Semantics and Polymorphic Type Inference. </title> <type> PhD thesis, </type> <institution> Edinburgh University, </institution> <year> 1988. </year> <month> CST-52-88. </month>
Reference-contexts: The instantiation environment is represented as a pair of arrays, one for type constructor components, the other for substructures. The static representation of a structure is essentially an environment (i.e., symbol table) containing bindings of types, variables, etc., and an identifying stamp <ref> [26, 33, 23] </ref>. In the second implementation a signature was represented as a "dummy" instance that differs from an ordinary structure in that its volatile components contain dummy or bound stamps and it carries some additional information specifying sharing constraints.
Reference: [34] <author> Mads Tofte. </author> <title> Type inference for polymorphic references. </title> <journal> Information and Computation, </journal> <volume> 89 </volume> <pages> 1-34, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Standard ML of New Jersey implements a generalization of the imperative type variables described in the Definition <ref> [26, 34] </ref>. In our scheme, imperative type variables are replaced by weak type variables that have an associated degree of weakness: a nonnegative integer.
Reference: [35] <author> Andrew P. Tolmach and Andrew W. Appel. </author> <title> Debugging Standard ML without reverse engineering. </title> <booktitle> In Proc. 1990 ACM Conf. on Lisp and Functional Programming, </booktitle> <pages> pages 1-12, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: They are used in the implementation of the interactive ML system to construct a barrier between user computation and the ML system. This makes it possible to export an executable image of a user function without including the ML compiler. Another application of continuations is Andrew Tolmach's replay debugger <ref> [35] </ref>, where they are used to save control states. This is the basis of the time travel capabilities of the debugger. It is well known that continuations are useful for implementing coroutines and for simulating parallel threads of control [37]. <p> Thanks to James W. O'Toole who implemented the NS32032 code generator, and Norman Ramsey who implemented the MIPS code generator. We thank Andrew P. Tolmach for the SML/NJ debugger <ref> [35] </ref>, and for the new pure-functional style of static environments; and Adam T. Dingle for the debugger's Emacs interface. Thanks to James S. Mattson for the first version of the ML lexical analyzer generator; and to David R. <p> Thanks to James S. Mattson for the first version of the ML lexical analyzer generator; and to David R. Tarditi for making the lexer-generator production-quality [8], for implementing a really first-class parser generator [32], for helping to implement the type-reconstruction algorithm used by the debugger <ref> [35] </ref>, and for the the ML-to-C translator he implemented with Anurag Acharya and Peter Lee [31]. We appreciate Lal George's teaching the code generator about floating point registers and making floating-point performance respectable; and his fixing of several difficult bugs not of his own cre ation.
Reference: [36] <author> Philip Wadler and Stephen Blott. </author> <title> How to make ad-hoc polymorphism less ad hoc. </title> <booktitle> In Sixteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 60-76, </pages> <month> Jan </month> <year> 1989. </year>
Reference-contexts: Yet the polymorphic equality function also uses these tags, so even with a sophisticated garbage collector they can't be done away with. (One alternative is to pass an equality-test function along with every value of an equality type, but this is also quite costly <ref> [36] </ref>.) Finally, the treatment of equality types in Standard ML is irregular and incomplete [15]. The Definition categorizes type constructors as either "equality" or "nonequality" type constructors; but a more refined classification would more accurately specify the effects of the ref operator.
Reference: [37] <author> Mitchell Wand. </author> <title> Continuation-based multiprocessing. </title> <booktitle> In Conf. Record of the 1980 Lisp Conf., </booktitle> <pages> pages 19-28, </pages> <month> August </month> <year> 1980. </year>
Reference-contexts: Another application of continuations is Andrew Tolmach's replay debugger [35], where they are used to save control states. This is the basis of the time travel capabilities of the debugger. It is well known that continuations are useful for implementing coroutines and for simulating parallel threads of control <ref> [37] </ref>. Using continuations in conjunction with the signal handling mechanisms implemented by John Reppy [27] (themselves expressed in terms of continuations), one can build light-weight process libraries with preemptive process scheduling entirely within Standard ML of New Jersey.
Reference: [38] <author> Andrew K. Wright and Matthias Felleisen. </author> <title> A syntactic approach to type soundness. </title> <type> Technical Report COMP TR91-160, </type> <institution> Rice University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: The weak typing scheme is fairly subtle and has been prone to bugs, so it is important that it be formalized and proven sound (as the Tofte scheme has been [Tofte-thesis]). There are several people currently working on formalizing the treatment used in the compiler <ref> [17, 38] </ref>. The weak polymorphism scheme currently used in Standard ML of New Jersey is not regarded as the final word on polymorphism and references. It shares with the imperative type variable scheme the fault that weak polymorphism propagates more widely than necessary. <p> This inessential weak polymorphism is particularly annoying when it interferes with the matching of a signature specification merely because of the use of an imperative style within a function's definition. Such implementation choices should be invisible in the type. Research continues on this problem <ref> [17, 22, 38] </ref>, but there is no satisfactory solution yet. The interface between the type checker and the parser is quite simple in most respects.
References-found: 38

