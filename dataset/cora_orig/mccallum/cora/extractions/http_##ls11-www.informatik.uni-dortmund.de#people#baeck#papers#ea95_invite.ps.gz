URL: http://ls11-www.informatik.uni-dortmund.de/people/baeck/papers/ea95_invite.ps.gz
Refering-URL: http://ls11-www.informatik.uni-dortmund.de/people/baeck/ea_general.html
Root-URL: http://ls11-www.informatik.uni-dortmund.de/people/baeck/ea_general.html
Title: Evolution Strategies: An Alternative Evolutionary Algorithm  
Author: Thomas Back 
Address: Joseph-von-Fraunhofer-Str. 20 D-44227 Dortmund  
Affiliation: Informatik Centrum Dortmund  
Abstract: In this paper, evolution strategies (ESs) | a class of evolutionary algorithms using normally distributed mutations, recombination, deterministic selection of the &gt; 1 best offspring individuals, and the principle of self-adaptation for the collective on-line learning of strategy parameters | are described by demonstrating their differences to genetic algorithms. By comparison of the algorithms, it is argued that the application of canonical genetic algorithms for continuous parameter optimization problems implies some difficulties caused by the encoding of continuous object variables by binary strings and the constant mutation rate used in genetic algorithms. Because they utilize a problem-adequate representation and a suitable self-adaptive step size control guaranteeing linear convergence for strictly convex problems, evolution strategies are argued to be more adequate for continuous problems. The main advantage of evolution strategies, the self-adaptation of strategy parameters, is explained in detail, and further components such as recombination and selection are described on a rather general level. Concerning theory, recent results regarding convergence velocity and global convergence of evolution strategies are briefly summarized, especially including the results for (,)-ESs with recombination. It turns out that the theoretical ground of ESs provides many more results about their behavior as optimization algorithms than available for genetic algorithms, and that ESs have all properties required for global optimization methods. The paper concludes by emphasizing the necessity for an appropriate step size control and the recommendation to avoid encoding mappings by using a problem-adequate representation of solutions within evolutionary algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. T. Alander. </author> <title> An indexed bibliography of genetic algorithms: </title> <type> Years 1957-1993. </type> <institution> Art of CAD Ltd, Espoo, Finland, </institution> <year> 1994. </year>
Reference-contexts: This implies an interpretation of adaptation as optimization in a changing environment | a problem which is handled well by GAs, ESs, and EP as well. In fact, most practical applications of GAs exploit their optimization capabilities (see the bibliography of Alander <ref> [1] </ref> for a collection of numerous applications of evolutionary algorithms, especially GAs).
Reference: 2. <author> Th. </author> <title> Back. Self-Adaptation in Genetic Algorithms. </title> <editor> In F. J. Varela and P. Bourgine, editors, </editor> <booktitle> Proceedings of the First European Conference on Artificial Life, </booktitle> <pages> pages 263-271. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Presently, a variety of further work clearly demonstrates that the general principle also works for the adaptation of other parameters such as crossover exchange probabilities [33], mutation rates in canonical genetic algorithms <ref> [2] </ref>, mutation rates in evolutionary programming for the evolution of finite state machines [19], mutation rates for discrete object variables in a hybrid algorithm of ES and GA [9, 39], and momentum adaptation in ESs [34].
Reference: 3. <author> Th. </author> <title> Back. Optimal mutation rates in genetic search. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-8. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: The Gray code does not introduce additional multimodality on the level of the decoding function, as the standard code typically does <ref> [3] </ref>. Fig. 2.: Comparison of the convergence velocity of a (15,100)-ES with n oe = 1, a (1,100)- GA with a mutation rate p m = 0:001, and a canonical GA with p m = 0:001, p c = 0:6, two-point crossover, and proportional selection. <p> This principle, which is not that simple to understand at first glance, is the topic of the next section. 1 I did not discuss this statement in sufficient detail here, but refer the reader to <ref> [3] </ref>, where the multimodality problem is analyzed. 2 The Tricky Step: Self-Adaptation In addition to the object variables x i 2 IR themselves, also the strategic meta-parameters | e.g., variances and covariances of a normal distribution for mutation | can be learned by evolutionary processes during the search. <p> of strategy parameters, which certainly offers a powerful alternative to the common utilization of a constant mutation rate in GAs | in fact, I have shown that for a simple pseudoboolean objective function, the optimal mutation rate critically depends on both search space dimension ` and distance to the optimum <ref> [3] </ref>. Concerning the theoretical understanding of ESs, it is undoubtedly true that, from the very beginning, much theoretical effort was invested to derive results concerning global convergence and convergence velocity, such that presently a relatively deep understanding of their working principles is available.
Reference: 4. <author> Th. </author> <title> Back. Evolutionary Algorithms in Theory and Practice. </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: If this is not the case, the following should be sufficiently general to provide at least an impression of the major principles and differences between the algorithms, or the reader might wish to consult a more technical overview article such as [10] or the in-depth introductions to evolutionary computation <ref> [4, 18] </ref>. Though it is often claimed that genetic algorithms are developed for solving adaptation rather than optimization problems (see e.g. [26, 27]), the distinction (if any) between both terms is neither obvious nor formally defined. <p> typically observed to yield better results than the standard binary code [14, 24]: The Gray code and bitwise mutation introduces a probability density function in the decoded object variable space that prefers smaller modificiations over large ones and therefore has some basic similarity to the normal distri bution in ESs <ref> [4, 24] </ref>. The Gray code does not introduce additional multimodality on the level of the decoding function, as the standard code typically does [3]. <p> Up to 2 n extrema are located in the search region jx i j . For the details of the matrices A and B as well as the vector ff, the reader is referred to <ref> [4] </ref>. Fig. 4.: Histogram of the final best objective function value obtained from a (15,100)-ES with n oe = 1 on the function after Fletcher and Powell. <p> the basic principle is extremely useful and widely applicable. 3 Completing the Evolution Strategy After describing the structure of individuals | a vector x 2 IR n of object variables and a vector oe of variances (and, for correlated mutations, a vector ff of rotation angles representing the covariances; see <ref> [4] </ref>) | and the principle of self-adaptation, especially regarding the mechanism of the mutation operator, only few remains to complete a standard (,)-ES algorithm.
Reference: 5. <author> Th. </author> <title> Back. Generalized convergence models for tournament- and (,)-selection. </title> <editor> In L. Eshelman, editor, </editor> <booktitle> Proceedings of the 6th International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-8. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, CA, </address> <year> 1995. </year>
Reference-contexts: The constant c 1; denotes the expectation of the maximum of stochastically independent standardized normally distributed random variables and reflects the strong relationship between (,)-selection and the theory of order statistics (see <ref> [5] </ref> for details). From equation (12), the optimal standard deviation oe fl = c 1; n and the resulting maximal relative progress E [P fl c 2 2n are easily obtained.
Reference: 6. <author> Th. Back, F. Hoffmeister, and H.-P. Schwefel. </author> <title> Applications of evolutionary algorithms. Report of the Systems Analysis Research Group SYS-2/92, </title> <institution> University of Dortmund, Department of Computer Science, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: Their usefulness, however, has been clearly demonstrated not only by an extensive comparison with a variety of traditional search methods [44], but also by a large number of practical applications in domains such as biology, chemistry, computer aided design, physics, medicine, production planning, etc. <ref> [6] </ref>. Acknowledgements The author gratefully acknowledges financial support by the project EVOALG, grant 01 IB 403 A from the German BMBF. EVOALG is a joint research project of the Informatik Centrum Dortmund (ICD), the Humboldt-Universitat zu Berlin, and Siemens AG Munich.
Reference: 7. <author> Th. Back and S. Khuri. </author> <title> An evolutionary heuristic for the maximum independent set problem. </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 531-535. </pages> <publisher> IEEE Press, </publisher> <year> 1994. </year>
Reference-contexts: It is even more surprising to see that many practical applications of GAs do not aim at solving strictly pseudoboolean optimization problems f : M f0; 1g ` ! IR ; (1) (which arise for a variety of combinatorial problems such as knapsacks [30], scheduling [29], graph problems <ref> [7, 28] </ref>, and others), but rather at solving problems of the form f : M IR n ! IR ; (2) which are naturally defined over a continuous, real-valued search space.
Reference: 8. <author> Th. Back, G. Rudolph, and H.-P. Schwefel. </author> <title> Evolutionary programming and evolution strategies: Similarities and differences. </title> <editor> In D. B. Fogel and W. Atmar, editors, </editor> <booktitle> Proceedings of the Second Annual Conference on Evolutionary Programming, </booktitle> <pages> pages 11-22. </pages> <booktitle> Evolutionary Programming Society, </booktitle> <address> San Diego, CA, </address> <year> 1993. </year>
Reference-contexts: While it was recently claimed by Voigt, Muhlenbein and Cvetkovic that linear convergence is the best one can achieve for evolutionary algorithms [48], Back, Rudolph and Schwefel have shown that evolution strategies and evolutionary programming are in fact able to achieve this convergence order <ref> [8] </ref>. <p> For elitist evolutionary algorithms, where the best parental solution is guaranteed to survive when no offspring individual represents an improvement of the currently best parent, global convergence with probability one holds under rather general conditions, provided the mutation step size is larger than zero (see [37] for GAs, <ref> [8] </ref> for ESs and EP), but the canonical GA lacks this property [37]. For evolution strategies, Rudolph recently demonstrated that the non-elitist (1,)-strategy converges globally with probability one if the objective function is stricly convex at least in a neighborhood around the globally optimal point [38]. <p> The convergence velocity ' (or its normalized counterpart ^' = 'n=r) is related to the relative progress according to E [P 1; ] = '=r = ^'=n, such that, using the asymptotic result c 1; p 2 ln <ref> [8] </ref>, one finally obtains ^' fl For the details of this derivation, the reader is referred to [45].
Reference: 9. <author> Th. Back and M. Schutz. </author> <title> Evolution strategies for mixed-integer optimization of optical multilayer systems. </title> <booktitle> In Proceedings of the 4th Annual Conference on Evolutionary Programming, </booktitle> <year> 1995. </year>
Reference-contexts: general principle also works for the adaptation of other parameters such as crossover exchange probabilities [33], mutation rates in canonical genetic algorithms [2], mutation rates in evolutionary programming for the evolution of finite state machines [19], mutation rates for discrete object variables in a hybrid algorithm of ES and GA <ref> [9, 39] </ref>, and momentum adaptation in ESs [34]. Fig. 5.: Progress rates for the (,100)-ES using optimally, precalculated oe i and the self-adaptive strategy. <p> As a rule of thumb, I personally claim that ESs should be applied in case of continuous problems whereas GAs serve most useful in case of pseudoboolean problems. Obviously, hybridizations of both algorithms are promising for the application to mixed-integer problems involving both discrete and continuous object variables (see <ref> [9] </ref> for an application of such a hybrid to optical filter design problems). Furthermore, GAs and ESs offer many possibilities for cross-fertilization by testing certain principles of one algorithm within the context of the other.
Reference: 10. <author> Th. Back and H.-P. Schwefel. </author> <title> An overview of evolutionary algorithms for parameter optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 1(1) </volume> <pages> 1-23, </pages> <year> 1993. </year>
Reference-contexts: If this is not the case, the following should be sufficiently general to provide at least an impression of the major principles and differences between the algorithms, or the reader might wish to consult a more technical overview article such as <ref> [10] </ref> or the in-depth introductions to evolutionary computation [4, 18]. Though it is often claimed that genetic algorithms are developed for solving adaptation rather than optimization problems (see e.g. [26, 27]), the distinction (if any) between both terms is neither obvious nor formally defined. <p> In order to avoid the overly technical details, I will not discuss the most general case of correlated mutations, where the full covariance matrix is subject to self-adaptation (see e.g. <ref> [10] </ref>), but restrict attention to the self-adaptation of n oe 2 f1; ng variances oe 2 i . <p> Recombination types on object variables and strategy parameters are usually different, and typical examples are discrete recombination (random exchanges between parents) for x i and intermediary recombination (arithmetic averaging) for oe i (see e.g. <ref> [10] </ref> for details). That's all to complete the ES | a lot of details have been added, but they are not mandatory for a working strategy (the details are described e.g. in [44], including reasons why they are incroporated into the algorithm).
Reference: 11. <author> H.-G. Beyer. </author> <title> Towards a theory of `evolution strategies' | Results from the N - dependent (,) and the multi-recombinant (=,)-theory. Report of the Systems Analysis Research Group SYS-5/94, </title> <institution> University of Dortmund, Department of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: of the average of the best offspring, the convergence velocity is given by the equation ^' (;) = ^oec ; 2 and one obtains the results ^oe fl = c ; (17) ^' fl 1 c 2 which asymptotically yields ^' fl (19) (c ; O ( ln =); see <ref> [11] </ref> for details). This result reflects the dominating impact of the selective pressure = for the convergence velocity. <p> involved in the creation of a single offspring) into account, Beyer and Rechenberg recently derived the equation ^' (;);%= I = ^oec =; 2 resulting in the optimal step size ^oe fl and the corresponding convergence velocity ^' fl = 2 =; (22) for intermediary recombination on the sphere model <ref> [11, 36] </ref>.
Reference: 12. <author> H.-G. Beyer. </author> <title> How GAs do NOT work. Understanding GAs without Schemata and Building Blocks. Report of the Systems Analysis Research Group SYS-2/95, </title> <institution> University of Dortmund, Department of Computer Science, </institution> <year> 1995. </year>
Reference-contexts: Also for discrete recombination, Beyer concludes that it works by implicitly performing a genetic repair, such that (by analogy with uniform crossover in GAs [47]), it is very likely that his results will also fundamentally change the direction of further theoretical research regarding GAs (see <ref> [12] </ref> for a summary). 5 So What ? The purpose of this article is not to compare ESs and GAs and to claim that the former or the latter are in some sense better or worse | both classes of evolutionary algorithms have their advantages, and both certainly have their preferable
Reference: 13. <author> H.-G. Beyer. </author> <title> Toward a theory of evolution strategies: On the benefits of sex | the (=; )-theory. </title> <journal> Evolutionary Computation, </journal> <volume> 3(1) </volume> <pages> 81-111, </pages> <year> 1995. </year>
Reference-contexts: In other words, recombination serves as a statistical error correction method, reducing the impact of the harmful part of mutations. This effect, called genetic repair by Beyer <ref> [13] </ref>, clarifies that the conjecture of the building block hypothesis that the combination of good partial solutions explains the advantage of recombination does not hold for ESs.
Reference: 14. <author> R. A. Caruna and J. D. Schaffer. </author> <title> Representation and hidden bias: Gray vs. binary coding for genetic algorithms. </title> <editor> In J. Laird, editor, </editor> <booktitle> Proceedings of the 5th International Conference on Machine Learning, </booktitle> <pages> pages 153-161. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: code and its impact on the search in combination with the mutation and recombination operators are known and provide some hints towards an explanation of the fact that canonical GAs are sometimes quite useful and the Gray code is typically observed to yield better results than the standard binary code <ref> [14, 24] </ref>: The Gray code and bitwise mutation introduces a probability density function in the decoded object variable space that prefers smaller modificiations over large ones and therefore has some basic similarity to the normal distri bution in ESs [4, 24].
Reference: 15. <editor> L. Davis, editor. </editor> <booktitle> Handbook of Genetic Algorithms. </booktitle> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Presently, some researchers circumvent the coding problem in genetic algorithms by recently developed real-coded "genetic algorithms" (e.g., the real-coded GAs of Davis, which adapt operator probabilities on the basis of the past usefulness of these operators in previous generations <ref> [15] </ref>), such that the gap between ESs and GAs becomes narrower. Like Michalewicz [32] and Davis [15], I prefer the point of view that the most problem-adequate representation of individuals should be used as a starting point for the development of an evolutionary heuristic. <p> coding problem in genetic algorithms by recently developed real-coded "genetic algorithms" (e.g., the real-coded GAs of Davis, which adapt operator probabilities on the basis of the past usefulness of these operators in previous generations <ref> [15] </ref>), such that the gap between ESs and GAs becomes narrower. Like Michalewicz [32] and Davis [15], I prefer the point of view that the most problem-adequate representation of individuals should be used as a starting point for the development of an evolutionary heuristic. Besides the representation, step size adaptation over the search process is a topic of major importance.
Reference: 16. <author> R. Fletcher and M. J. D. Powell. </author> <title> A rapidly convergent descent method for minimization. </title> <journal> Computer Journal, </journal> <volume> 6 </volume> <pages> 163-168, </pages> <year> 1963. </year>
Reference-contexts: It is almost impossible to assess the general convergence reliability of evolutionary algorithms, and any attempt to do so is necessarily restricted to a limited number of experiments on a limited number of practical problems or test problems. An interesting test problem which was introduced by Fletcher and Powell <ref> [16] </ref> as a typical representative of nonlinear parameter estimation problems will serve here as an example that reflects my personal experience of the comparative convergence reliability of evolution strategies and genetic algorithms | this assessment is based on personal experience, not on any measurable, general quantity.
Reference: 17. <author> D. B. Fogel. </author> <title> Evolving Artificial Intelligence. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> San Diego, CA, </address> <year> 1992. </year>
Reference-contexts: The choice of a logarithmic normal distribution for the mutation of mutation step sizes oe i is motivated by just empirical but nevertheless "naturally reasonable" arguments: 2 And, indepedently, of David B. Fogel, who reinvented the method in EP <ref> [17] </ref>. 3 The notation x N (i; oe 2 ) indicates x to be a realization of a random variable X which is normally distributed with expectation i and variance oe 2 . Amultiplicative modification preserves positive values.
Reference: 18. <author> D. B. Fogel. </author> <title> Evolutionary Computation: Toward a New Philosophy of Machine Intelligence. </title> <publisher> IEEE Press, </publisher> <address> Piscataway, NJ, </address> <year> 1995. </year>
Reference-contexts: Although these two different, independently developed branches of evolutionary computation are known since more than thirty years, genetic algorithms have gained much more interest during the past ten years than evolution strategies did. Evolutionary programming (EP) <ref> [18, 20] </ref>, the third main stream evolutionary algorithm, has strong similarities to evolution strategies and could be discussed here as well | but this is more adequately done by David B. Fogel, whose contribution in this volume is a must for every reader interested in evolutionary computation. <p> If this is not the case, the following should be sufficiently general to provide at least an impression of the major principles and differences between the algorithms, or the reader might wish to consult a more technical overview article such as [10] or the in-depth introductions to evolutionary computation <ref> [4, 18] </ref>. Though it is often claimed that genetic algorithms are developed for solving adaptation rather than optimization problems (see e.g. [26, 27]), the distinction (if any) between both terms is neither obvious nor formally defined.
Reference: 19. <editor> L. Fogel, D. B. Fogel, and P. J. Angeline. </editor> <title> A preliminary investigation on extending evolutionary programming to include self-adaptation on finite state machines. </title> <journal> Informatica, </journal> <volume> 18 </volume> <pages> 387-398, </pages> <year> 1994. </year>
Reference-contexts: Presently, a variety of further work clearly demonstrates that the general principle also works for the adaptation of other parameters such as crossover exchange probabilities [33], mutation rates in canonical genetic algorithms [2], mutation rates in evolutionary programming for the evolution of finite state machines <ref> [19] </ref>, mutation rates for discrete object variables in a hybrid algorithm of ES and GA [9, 39], and momentum adaptation in ESs [34]. Fig. 5.: Progress rates for the (,100)-ES using optimally, precalculated oe i and the self-adaptive strategy.
Reference: 20. <author> L. J. Fogel, A. J. Owens, and M. J. Walsh. </author> <title> Artificial Intelligence through Simulated Evolution. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: Although these two different, independently developed branches of evolutionary computation are known since more than thirty years, genetic algorithms have gained much more interest during the past ten years than evolution strategies did. Evolutionary programming (EP) <ref> [18, 20] </ref>, the third main stream evolutionary algorithm, has strong similarities to evolution strategies and could be discussed here as well | but this is more adequately done by David B. Fogel, whose contribution in this volume is a must for every reader interested in evolutionary computation.
Reference: 21. <author> D. E. Goldberg. </author> <title> Genetic algorithms in search, optimization and machine learning. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: of evolution strategies (ESs) [35, 36, 40, 44] (and, to make the reader curious of reading more about them), I take the freedom to start with a brief look at the global optimization problem and those evolutionary algorithms which are widely used to approximately solve this problem: Genetic algorithms (GAs) <ref> [21, 25] </ref>. Although these two different, independently developed branches of evolutionary computation are known since more than thirty years, genetic algorithms have gained much more interest during the past ten years than evolution strategies did. <p> In fact, although this linear convergence is not comparable to the convergence velocity of an evolution strategy, it may serve as a counterargument against the claim that recombination is the most important search operator in genetic algorithms and mutation plays only a minor role <ref> [21, 25] </ref> (minimum requirements for evolution are mutation and selection, not recombination !). <p> principles and their effectiveness for the purpose of optimization (see [46] for details regarding the contemporary ES). 4 Theory Traditional GA-theory, concentrating on the notion of schemata, building blocks, and the schema-theorem giving an upper bound on the expected number of instances of a schema at generation t + 1 <ref> [21, 25] </ref> does not yield any kind of constructive result regarding optimization properties such as global convergence or convergence velocity | and is therefore simply useless for such applications.
Reference: 22. <author> W. Gottschalk. </author> <title> Allgemeine Genetik. </title> <publisher> Georg Thieme Verlag, </publisher> <address> Stuttgart, 3 edition, </address> <year> 1989. </year>
Reference: 23. <author> S. Hahn, K. H. Becks, and A. Hemker. </author> <title> Optimizing monte carlo generator parameters using genetic algorithms. </title> <editor> In D. Perret-Gallix, editor, </editor> <booktitle> New Computing Techniques in Physics Research II | Proceedings 2nd International Workshop on Software Engineering, Artificial Intelligence and Expert Systems for High Energy and Nuclear Physics, </booktitle> <pages> pages 255-265, </pages> <address> La Londe-Les-Maures, France, </address> <month> January 13-18 </month> <year> 1992. </year> <title> World Scientific, </title> <address> Singapore, </address> <year> 1992. </year>
Reference-contexts: (I am always critical about applications where less than ten bits are used per object variable | but sometimes, when the precision of the object variables is a priori known to be limited, as in the case of some high energy physics experiments, this might also be an invaluable advantage <ref> [23] </ref>). The discretization of the search space introduced by the binary code implies that the genetic algorithm might fail to locate an optimal solution exactly just because this solution is not represented by any of the binary strings.
Reference: 24. <author> R. Hinterding, H. Gielewski, and T. C. Peachey. </author> <title> On the nature of mutation in genetic algorithms. </title> <editor> In L. Eshelman, editor, </editor> <booktitle> Genetic Algorithms: Proceedings of the 6th International Conference, </booktitle> <pages> pages 65-72. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, CA, </address> <year> 1995. </year>
Reference-contexts: code and its impact on the search in combination with the mutation and recombination operators are known and provide some hints towards an explanation of the fact that canonical GAs are sometimes quite useful and the Gray code is typically observed to yield better results than the standard binary code <ref> [14, 24] </ref>: The Gray code and bitwise mutation introduces a probability density function in the decoded object variable space that prefers smaller modificiations over large ones and therefore has some basic similarity to the normal distri bution in ESs [4, 24]. <p> typically observed to yield better results than the standard binary code [14, 24]: The Gray code and bitwise mutation introduces a probability density function in the decoded object variable space that prefers smaller modificiations over large ones and therefore has some basic similarity to the normal distri bution in ESs <ref> [4, 24] </ref>. The Gray code does not introduce additional multimodality on the level of the decoding function, as the standard code typically does [3].
Reference: 25. <author> J. H. Holland. </author> <title> Adaptation in natural and artificial systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: of evolution strategies (ESs) [35, 36, 40, 44] (and, to make the reader curious of reading more about them), I take the freedom to start with a brief look at the global optimization problem and those evolutionary algorithms which are widely used to approximately solve this problem: Genetic algorithms (GAs) <ref> [21, 25] </ref>. Although these two different, independently developed branches of evolutionary computation are known since more than thirty years, genetic algorithms have gained much more interest during the past ten years than evolution strategies did. <p> In fact, although this linear convergence is not comparable to the convergence velocity of an evolution strategy, it may serve as a counterargument against the claim that recombination is the most important search operator in genetic algorithms and mutation plays only a minor role <ref> [21, 25] </ref> (minimum requirements for evolution are mutation and selection, not recombination !). <p> principles and their effectiveness for the purpose of optimization (see [46] for details regarding the contemporary ES). 4 Theory Traditional GA-theory, concentrating on the notion of schemata, building blocks, and the schema-theorem giving an upper bound on the expected number of instances of a schema at generation t + 1 <ref> [21, 25] </ref> does not yield any kind of constructive result regarding optimization properties such as global convergence or convergence velocity | and is therefore simply useless for such applications.
Reference: 26. <author> K. A. De Jong. </author> <title> Are genetic algorithms function optimizers ? In R. </title> <editor> Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature 2, </booktitle> <pages> pages 3-13. </pages> <address> El-sevier, Amsterdam, </address> <year> 1992. </year>
Reference-contexts: Though it is often claimed that genetic algorithms are developed for solving adaptation rather than optimization problems (see e.g. <ref> [26, 27] </ref>), the distinction (if any) between both terms is neither obvious nor formally defined. Biologically, adaptation denotes a general advantage in efficiency of an individual over other members of the population, and the process of attaining this state (see [31], pp. 134-135).
Reference: 27. <author> K. A. De Jong. </author> <title> Genetic algorithms are NOT function optimizers. </title> <editor> In D. Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms 2, </booktitle> <pages> pages 5-17. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Though it is often claimed that genetic algorithms are developed for solving adaptation rather than optimization problems (see e.g. <ref> [26, 27] </ref>), the distinction (if any) between both terms is neither obvious nor formally defined. Biologically, adaptation denotes a general advantage in efficiency of an individual over other members of the population, and the process of attaining this state (see [31], pp. 134-135).
Reference: 28. <author> S. Khuri and Th. </author> <title> Back. An evolutionary heuristic for the minimum vertex cover problem. </title> <editor> In J. Kunze and H. Stoyan, editors, </editor> <booktitle> KI-94 Workshops (Extended Abstracts), </booktitle> <pages> pages 83-84. </pages> <institution> Gesellschaft fur Informatik e. V., Bonn, </institution> <year> 1994. </year>
Reference-contexts: It is even more surprising to see that many practical applications of GAs do not aim at solving strictly pseudoboolean optimization problems f : M f0; 1g ` ! IR ; (1) (which arise for a variety of combinatorial problems such as knapsacks [30], scheduling [29], graph problems <ref> [7, 28] </ref>, and others), but rather at solving problems of the form f : M IR n ! IR ; (2) which are naturally defined over a continuous, real-valued search space.
Reference: 29. <author> S. Khuri, Th. Back, and J. Heitkotter. </author> <title> An evolutionary approach to combinatorial optimization problems. </title> <editor> In D. Cizmar, editor, </editor> <booktitle> Proceedings of the 22nd Annual ACM Computer Science Conference, </booktitle> <pages> pages 66-73. </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: It is even more surprising to see that many practical applications of GAs do not aim at solving strictly pseudoboolean optimization problems f : M f0; 1g ` ! IR ; (1) (which arise for a variety of combinatorial problems such as knapsacks [30], scheduling <ref> [29] </ref>, graph problems [7, 28], and others), but rather at solving problems of the form f : M IR n ! IR ; (2) which are naturally defined over a continuous, real-valued search space.
Reference: 30. <author> S. Khuri, Th. Back, and J. Heitkotter. </author> <title> The zero/one multiple knapsack problem and genetic algorithms. </title> <editor> In E. Deaton, D. Oppenheim, J. Urban, and H. Berghel, editors, </editor> <booktitle> Proceedings of the 1994 ACM Symposium on Applied Computing, </booktitle> <pages> pages 188-193. </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: It is even more surprising to see that many practical applications of GAs do not aim at solving strictly pseudoboolean optimization problems f : M f0; 1g ` ! IR ; (1) (which arise for a variety of combinatorial problems such as knapsacks <ref> [30] </ref>, scheduling [29], graph problems [7, 28], and others), but rather at solving problems of the form f : M IR n ! IR ; (2) which are naturally defined over a continuous, real-valued search space.
Reference: 31. <author> E. Mayr. </author> <title> Toward a new Philosophy of Biology: Observations of an Evolutionist. </title> <publisher> The Belknap Press of Harvard University Press, </publisher> <address> Cambridge, MA, and London, GB, </address> <year> 1988. </year>
Reference-contexts: Biologically, adaptation denotes a general advantage in efficiency of an individual over other members of the population, and the process of attaining this state (see <ref> [31] </ref>, pp. 134-135). This implies an interpretation of adaptation as optimization in a changing environment | a problem which is handled well by GAs, ESs, and EP as well.
Reference: 32. <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1994. </year>
Reference-contexts: Like Michalewicz <ref> [32] </ref> and Davis [15], I prefer the point of view that the most problem-adequate representation of individuals should be used as a starting point for the development of an evolutionary heuristic. Besides the representation, step size adaptation over the search process is a topic of major importance.
Reference: 33. <institution> J. Obalek. Rekombinationsoperatoren fur Evolutionsstrategien. Diplomarbeit, Universitat Dortmund, Fachbereich Informatik, </institution> <year> 1994. </year>
Reference-contexts: Presently, a variety of further work clearly demonstrates that the general principle also works for the adaptation of other parameters such as crossover exchange probabilities <ref> [33] </ref>, mutation rates in canonical genetic algorithms [2], mutation rates in evolutionary programming for the evolution of finite state machines [19], mutation rates for discrete object variables in a hybrid algorithm of ES and GA [9, 39], and momentum adaptation in ESs [34].
Reference: 34. <author> A. Ostermeier. </author> <title> An evolution strategy with momentum adaptation of the random number distribution. </title> <editor> In R. Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature 2, </booktitle> <pages> pages 197-206. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: of other parameters such as crossover exchange probabilities [33], mutation rates in canonical genetic algorithms [2], mutation rates in evolutionary programming for the evolution of finite state machines [19], mutation rates for discrete object variables in a hybrid algorithm of ES and GA [9, 39], and momentum adaptation in ESs <ref> [34] </ref>. Fig. 5.: Progress rates for the (,100)-ES using optimally, precalculated oe i and the self-adaptive strategy.
Reference: 35. <author> I. Rechenberg. </author> <title> Evolutionsstrategie: Optimierung technischer Systeme nach Prinzi--pien der biologischen Evolution. </title> <address> Frommann-Holzboog, Stuttgart, </address> <year> 1973. </year>
Reference-contexts: 1 Optimization and Genetic Algorithms In contrast to the title and the overall intention of this article to provide an overview of evolution strategies (ESs) <ref> [35, 36, 40, 44] </ref> (and, to make the reader curious of reading more about them), I take the freedom to start with a brief look at the global optimization problem and those evolutionary algorithms which are widely used to approximately solve this problem: Genetic algorithms (GAs) [21, 25]. <p> On the contrary, ES-theory has always focused on these properties, and already Rechenberg calculated optimal step size and maximal convergence velocity of a (1+1)-ES for the corridor and sphere model <ref> [35] </ref>.
Reference: 36. <editor> I. Rechenberg. </editor> <booktitle> Evolutionsstrategie '94, volume 1 of Werkstatt Bionik und Evolu-tionstechnik. </booktitle> <address> frommann-holzboog, Stuttgart, </address> <year> 1994. </year>
Reference-contexts: 1 Optimization and Genetic Algorithms In contrast to the title and the overall intention of this article to provide an overview of evolution strategies (ESs) <ref> [35, 36, 40, 44] </ref> (and, to make the reader curious of reading more about them), I take the freedom to start with a brief look at the global optimization problem and those evolutionary algorithms which are widely used to approximately solve this problem: Genetic algorithms (GAs) [21, 25]. <p> involved in the creation of a single offspring) into account, Beyer and Rechenberg recently derived the equation ^' (;);%= I = ^oec =; 2 resulting in the optimal step size ^oe fl and the corresponding convergence velocity ^' fl = 2 =; (22) for intermediary recombination on the sphere model <ref> [11, 36] </ref>.
Reference: 37. <author> G. Rudolph. </author> <title> Convergence analysis of canonical genetic algorithms. </title> <journal> IEEE Transactions on Neural Networks, Special Issue on Evolutionary Computation, </journal> <volume> 5(1) </volume> <pages> 96-101, </pages> <year> 1994. </year>
Reference-contexts: For elitist evolutionary algorithms, where the best parental solution is guaranteed to survive when no offspring individual represents an improvement of the currently best parent, global convergence with probability one holds under rather general conditions, provided the mutation step size is larger than zero (see <ref> [37] </ref> for GAs, [8] for ESs and EP), but the canonical GA lacks this property [37]. For evolution strategies, Rudolph recently demonstrated that the non-elitist (1,)-strategy converges globally with probability one if the objective function is stricly convex at least in a neighborhood around the globally optimal point [38]. <p> guaranteed to survive when no offspring individual represents an improvement of the currently best parent, global convergence with probability one holds under rather general conditions, provided the mutation step size is larger than zero (see <ref> [37] </ref> for GAs, [8] for ESs and EP), but the canonical GA lacks this property [37]. For evolution strategies, Rudolph recently demonstrated that the non-elitist (1,)-strategy converges globally with probability one if the objective function is stricly convex at least in a neighborhood around the globally optimal point [38].
Reference: 38. <author> G. Rudolph. </author> <title> Convergence of non-elitist strategies. </title> <editor> In Z. Michalewicz, J. D. Schaf-fer, H.-P. Schwefel, D. B. Fogel, and H. Kitano, editors, </editor> <booktitle> Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 63-66. </pages> <publisher> IEEE Press, </publisher> <year> 1994. </year>
Reference-contexts: For evolution strategies, Rudolph recently demonstrated that the non-elitist (1,)-strategy converges globally with probability one if the objective function is stricly convex at least in a neighborhood around the globally optimal point <ref> [38] </ref>. For practical applications, however, it is not the global convergence with probability one that one is most interested in, but rather the capability of the algorithm to find a solution which is better than the solution known so far.
Reference: 39. <author> M. </author> <type> Schutz. </type> <institution> Eine Evolutionsstrategie fur gemischt-ganzzahlige Optimierungspro-bleme mit variabler Dimension. Diplomarbeit, Universitat Dortmund, Fachbereich Informatik, </institution> <year> 1994. </year>
Reference-contexts: general principle also works for the adaptation of other parameters such as crossover exchange probabilities [33], mutation rates in canonical genetic algorithms [2], mutation rates in evolutionary programming for the evolution of finite state machines [19], mutation rates for discrete object variables in a hybrid algorithm of ES and GA <ref> [9, 39] </ref>, and momentum adaptation in ESs [34]. Fig. 5.: Progress rates for the (,100)-ES using optimally, precalculated oe i and the self-adaptive strategy.
Reference: 40. <author> H.-P. Schwefel. </author> <title> Numerische Optimierung von Computer-Modellen mittels der Evolutionsstrategie, </title> <booktitle> volume 26 of Interdisciplinary Systems Research. </booktitle> <publisher> Birkhauser, </publisher> <address> Basel, </address> <year> 1977. </year>
Reference-contexts: 1 Optimization and Genetic Algorithms In contrast to the title and the overall intention of this article to provide an overview of evolution strategies (ESs) <ref> [35, 36, 40, 44] </ref> (and, to make the reader curious of reading more about them), I take the freedom to start with a brief look at the global optimization problem and those evolutionary algorithms which are widely used to approximately solve this problem: Genetic algorithms (GAs) [21, 25]. <p> This is the simple, but strikingly powerful idea of Schwefel 2 <ref> [40] </ref>, to search the space of solutions and strategy parameters in parallel and to enable a suitable adjustment and diversity of mutation parameters under arbitrary circumstances. <p> The values o 02 = 1 2n , o 2 2 n , and o 2 n of the variances were proposed by Schwefel (see <ref> [40] </ref>, p. 168) and result from partially theoretical investigations. The choice of a logarithmic normal distribution for the mutation of mutation step sizes oe i is motivated by just empirical but nevertheless "naturally reasonable" arguments: 2 And, indepedently, of David B.
Reference: 41. <editor> H.-P. Schwefel. </editor> <booktitle> Evolutionary learning optimum-seeking on parallel computer architectures. </booktitle> <editor> In A. Sydow, S. G. Tzafestas, and R. Vichnevetsky, editors, </editor> <booktitle> Proceedings of the International Symposium on Systems Analysis and Simulation 1988, I: Theory and Foundations, </booktitle> <pages> pages 217-225. </pages> <publisher> Akademie-Verlag, </publisher> <address> Berlin, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: Amultiplicative modification preserves positive values. The median of a multiplicative modification should equal one to guarantee that, on average, a multiplication by a value c occurs with the same probability as a multiplication by 1=c. Small modifications should occur more often than large ones. Extensive experimental investigations by Schwefel <ref> [41, 42, 44] </ref> clarified that this mechanism for self-adaptation is extremely robust with respect to the setting of the meta-parameters (or learning rates) o , o 0 , and o 0 , respectively.
Reference: 42. <author> H.-P. Schwefel. </author> <title> Imitating evolution: Collective, two-level learning processes. </title> <editor> In U. Witt, editor, </editor> <booktitle> Explaining Process and Change | Approaches to Evolutionary Economics, </booktitle> <pages> pages 49-63. </pages> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1992. </year>
Reference-contexts: Amultiplicative modification preserves positive values. The median of a multiplicative modification should equal one to guarantee that, on average, a multiplication by a value c occurs with the same probability as a multiplication by 1=c. Small modifications should occur more often than large ones. Extensive experimental investigations by Schwefel <ref> [41, 42, 44] </ref> clarified that this mechanism for self-adaptation is extremely robust with respect to the setting of the meta-parameters (or learning rates) o , o 0 , and o 0 , respectively.
Reference: 43. <author> H.-P. Schwefel. </author> <title> Natural evolution and collective optimum-seeking. </title> <editor> In A. Sydow, editor, </editor> <booktitle> Computational Systems Analysis: Topics and Trends, </booktitle> <pages> pages 5-14. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: To illustrate some of the insights regarding the self-adaptation of n oe = n variances in ESs, I will briefly discuss one of Schwefel's well-designed experiments, using the objective function F (x) = P n i <ref> [43] </ref>. For this function, each variable is differently scaled, such that self-adaptation requires to learn the scaling 4 of n different oe i . <p> parent and offspring population are different, the reduction from to individuals by selection (performed by just determ-4 Similarly, Schwefel utilized the sphere model for investigations regarding the self adaptation of n oe = 1 standard deviation, and the function F 0 (x) = i=1 j=1 j (9) for correlated mutations <ref> [43] </ref>. inistically choosing the best offspring as new parents) has to be compensated by a repeated application of either mutation or recombination to create individuals. In ESs, this is achieved by recombination, which generates one offspring individual from % (1 % ) randomly selected parent individuals per application.
Reference: 44. <author> H.-P. Schwefel. </author> <title> Evolution and Optimum Seeking. </title> <booktitle> Sixth-Generation Computer Technology Series. </booktitle> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: 1 Optimization and Genetic Algorithms In contrast to the title and the overall intention of this article to provide an overview of evolution strategies (ESs) <ref> [35, 36, 40, 44] </ref> (and, to make the reader curious of reading more about them), I take the freedom to start with a brief look at the global optimization problem and those evolutionary algorithms which are widely used to approximately solve this problem: Genetic algorithms (GAs) [21, 25]. <p> Amultiplicative modification preserves positive values. The median of a multiplicative modification should equal one to guarantee that, on average, a multiplication by a value c occurs with the same probability as a multiplication by 1=c. Small modifications should occur more often than large ones. Extensive experimental investigations by Schwefel <ref> [41, 42, 44] </ref> clarified that this mechanism for self-adaptation is extremely robust with respect to the setting of the meta-parameters (or learning rates) o , o 0 , and o 0 , respectively. <p> That's all to complete the ES | a lot of details have been added, but they are not mandatory for a working strategy (the details are described e.g. in <ref> [44] </ref>, including reasons why they are incroporated into the algorithm). <p> Their usefulness, however, has been clearly demonstrated not only by an extensive comparison with a variety of traditional search methods <ref> [44] </ref>, but also by a large number of practical applications in domains such as biology, chemistry, computer aided design, physics, medicine, production planning, etc. [6]. Acknowledgements The author gratefully acknowledges financial support by the project EVOALG, grant 01 IB 403 A from the German BMBF.
Reference: 45. <author> H.-P. Schwefel and Th. </author> <title> Back. Evolution strategies ii: Theoretical aspects. </title> <editor> In J. Periaux and G. Winter, editors, </editor> <booktitle> Genetic Algorithms in Engineering and Computer Science, chapter 7. </booktitle> <publisher> Wiley, </publisher> <address> Chichester, </address> <year> 1995. </year>
Reference-contexts: its normalized counterpart ^' = 'n=r) is related to the relative progress according to E [P 1; ] = '=r = ^'=n, such that, using the asymptotic result c 1; p 2 ln [8], one finally obtains ^' fl For the details of this derivation, the reader is referred to <ref> [45] </ref>.
Reference: 46. <author> H.-P. Schwefel and G. Rudolph. </author> <title> Contemporary evolution strategies. </title> <editor> In F. Moran, A. Moreno, J. J. Merelo, and P. Chacon, editors, </editor> <booktitle> Advances in Artificial Life. Third International Conference on Artificial Life, volume 929 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 893-907. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: number % of parents, a life span between the two extremes one ((,)-selection) and infinity ((+)-selection, where the parents are choosen out of offspring and old parents), and thus introduces a variety of new possibilities for experimental investigations of evolutionary principles and their effectiveness for the purpose of optimization (see <ref> [46] </ref> for details regarding the contemporary ES). 4 Theory Traditional GA-theory, concentrating on the notion of schemata, building blocks, and the schema-theorem giving an upper bound on the expected number of instances of a schema at generation t + 1 [21, 25] does not yield any kind of constructive result regarding
Reference: 47. <author> G. Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the 3rd International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: Also for discrete recombination, Beyer concludes that it works by implicitly performing a genetic repair, such that (by analogy with uniform crossover in GAs <ref> [47] </ref>), it is very likely that his results will also fundamentally change the direction of further theoretical research regarding GAs (see [12] for a summary). 5 So What ? The purpose of this article is not to compare ESs and GAs and to claim that the former or the latter are
Reference: 48. <author> H.-M. Voigt, H. Muhlenbein, and D. Cvetkovic. </author> <title> Fuzzy recombination for the breeder genetic algorithm. </title> <editor> In L. Eshelman, editor, </editor> <booktitle> Genetic Algorithms: Proceedings of the 6th International Conference, </booktitle> <pages> pages 104-111. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, CA, </address> <year> 1995. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: While it was recently claimed by Voigt, Muhlenbein and Cvetkovic that linear convergence is the best one can achieve for evolutionary algorithms <ref> [48] </ref>, Back, Rudolph and Schwefel have shown that evolution strategies and evolutionary programming are in fact able to achieve this convergence order [8].
References-found: 48

