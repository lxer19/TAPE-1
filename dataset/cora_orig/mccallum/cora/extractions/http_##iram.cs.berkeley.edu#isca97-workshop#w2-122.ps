URL: http://iram.cs.berkeley.edu/isca97-workshop/w2-122.ps
Refering-URL: http://iram.cs.berkeley.edu/isca97-workshop/
Root-URL: 
Email: ppram@c.csce.kyushu-u.ac.jp  
Title: On-Chip Memorypath Architectures for Parallel Processing RAM (PPRAM)  
Author: Hiroshi Miyajima, Koji Inoue, Koji Kaiy, and Kazuaki Murakami 
Web: http://kasuga.csce.kyushu-u.ac.jp/~ppram  
Address: 6-1 Kasuga-Koen, Kasuga, Fukuoka 816 JAPAN  
Affiliation: Department of Computer Science and Communication Engineering Kyushu University Institutes of Systems and Information Technologies/Kyushu)  
Abstract: This paper discusses on-chip memorypath architectures of merged DRAM/logic LSIs. Merged DRAM/logic LSIs have many benefits; higher memory bandwidth, lower memory latency, lower system power, and so on, and would also provide much freedom for the design of their memorypath architectures than conventional "separate DRAM+logic"-type systems. We show three on-chip mem-orypath architectures, and investigate the memory bandwidth requirement of these. And we focus on one of the architectures, and evaluate the impact of the actual memory bandwidth and the DRAM access latency upon the performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Burger, D., Goodman, J. R., and Kagi, A., </author> <title> "Memory Bandwidth Limitations of Future Microprocessors," </title> <booktitle> Proc. of the 23rd Annual International Symposium on Computer Architecture, </booktitle> <address> pp.78-89, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: There are at least two related work: Huang and Shen [4] studied the minimal required memory bandwidth for current processors. Burger, Goodman, and Kagi <ref> [1] </ref> studied the decomposition of execution time and the effective pin bandwidth for modern processors.
Reference: [2] <author> Burger, D., Kaxiras, S., and Goodman, J. R., </author> <title> "DataScalar Architectures," </title> <booktitle> Proceedings of 24th International Symposium on Computer Architecture, </booktitle> <month> Jun. </month> <year> 1997. </year>
Reference-contexts: High on-chip memory bandwidth would be exploited between the cache and the main memory on cache replacement. Examples are Kyushu University's PPRAM R [5], Mit-subishi's M32R/D [8], Sun's work [7], U. W. Madison's DataScalar <ref> [2] </ref>, and so on. (2) DRM architecture (Figure 1 (b)) DRM (Datapath Register- Main-memory) borrows the concept from the vector architectures with vector registers such as Cray-1. As shown in Figure 1 (b), the on-chip memorypath consists of datapath, registers, and DRAM main-memory.
Reference: [3] <author> Hill, M. D., Larus, J. R., Lebeck, A. R., Talluri, M., and Wood, D. A., "WARTS: </author> <title> Wisconsin Architectural Research Tool Set," </title> <address> http://www.cs.wisc.edu/ ~larus/warts.html, </address> <institution> University of Wisconsin Madi-son. </institution>
Reference-contexts: Table 2 shows the benchmark programs used and the corresponding IP C ideal reported in [11]. Table 2 also shows the RPI (memory References Per Instruction), which were obtained through our cache simulation using QPT and tychoII <ref> [3] </ref>. 1 The cache simulation assumed a direct-mapped D-cache with the cache size of 8K bytes and the line size of 32 bytes. 1 Though the IPC in [11] and our RPI were for MIPS and SPARC respectively, we assume that the difference is small and negligible.
Reference: [4] <author> Huang, A. S. and Shen, J. P., </author> <title> "A Limit Study of Local Memory Requirements Using Value Reuse Profiles," </title> <booktitle> Proceedings of the 28th Annual International Symposium on Microarchitecture, </booktitle> <address> pp.71-81, </address> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: There are at least two related work: Huang and Shen <ref> [4] </ref> studied the minimal required memory bandwidth for current processors. Burger, Goodman, and Kagi [1] studied the decomposition of execution time and the effective pin bandwidth for modern processors.
Reference: [5] <author> Murakami, K., Shirakawa, S., and Miyajima, H., </author> <title> "Parallel Processing RAM Chip with 256Mb DRAM and Quad Processors," </title> <booktitle> 1997 ISSCC Digest of Technical Papers, </booktitle> <address> pp.228-229, </address> <month> Feb. </month> <year> 1997. </year>
Reference-contexts: As shown in Figure 1 (a), the on-chip memorypath consists of data-path, registers, SRAM cache, and DRAM main-memory. High on-chip memory bandwidth would be exploited between the cache and the main memory on cache replacement. Examples are Kyushu University's PPRAM R <ref> [5] </ref>, Mit-subishi's M32R/D [8], Sun's work [7], U. W. Madison's DataScalar [2], and so on. (2) DRM architecture (Figure 1 (b)) DRM (Datapath Register- Main-memory) borrows the concept from the vector architectures with vector registers such as Cray-1. <p> Though Direct Rambus and SLDRAM will be able to provide 1.6GB/s in a couple of years, the memory bandwidth of 1.6GB/s is not necessarily sufficient for some applications. Note that PPRAM and IRAM could provide the on-chip memory bandwidth of higher than 1.6GB/s <ref> [5, 6] </ref>. 4.2 Program Execution Time We model the program execution time, or ET, as follows; ET = IC fi CP I fi CCT = IC fi (CP I ideal + CP I mem ) fi CCT = IC fi ( IP C ideal + CP I mem ) fi CCT;
Reference: [6] <author> Patterson, D., Anderson, T., Cardwell, N., Fromm, R., Keeton, K., Kozyrakis, C., Thomas, R., and Yelick, K., </author> <title> "Intelligent RAM (IRAM): Chips that remember and compute," </title> <booktitle> 1997 ISSCC Digest of Technical Papers, </booktitle> <address> pp.224-225, </address> <month> Feb. </month> <year> 1997. </year>
Reference-contexts: As shown in Figure 1 (b), the on-chip memorypath consists of datapath, registers, and DRAM main-memory. High on-chip memory bandwidth 1 would be exploited between the registers and the main memory on load/store operations. Examples include U .C. Berkeley's Vector IRAM <ref> [6] </ref>. (3) DM architecture (Figure 1 (c)) DM (Datapath - Main-memory) renews the obsolete vector architectures with no vector registers such as CDC Cyber. As shown in Figure 1 (c), the on-chip memory-path consists of datapath and DRAM main-memory only. <p> Though Direct Rambus and SLDRAM will be able to provide 1.6GB/s in a couple of years, the memory bandwidth of 1.6GB/s is not necessarily sufficient for some applications. Note that PPRAM and IRAM could provide the on-chip memory bandwidth of higher than 1.6GB/s <ref> [5, 6] </ref>. 4.2 Program Execution Time We model the program execution time, or ET, as follows; ET = IC fi CP I fi CCT = IC fi (CP I ideal + CP I mem ) fi CCT = IC fi ( IP C ideal + CP I mem ) fi CCT;
Reference: [7] <author> Saulsbury, A., Pong, F., and Nowatzyk, A., </author> <title> "Missing the Memory Wall: The Case for Processor/Memory 6 Integration," </title> <booktitle> Proc. of the 23rd Annual International Symposium on Computer Architecture, </booktitle> <address> pp.90-101, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: As shown in Figure 1 (a), the on-chip memorypath consists of data-path, registers, SRAM cache, and DRAM main-memory. High on-chip memory bandwidth would be exploited between the cache and the main memory on cache replacement. Examples are Kyushu University's PPRAM R [5], Mit-subishi's M32R/D [8], Sun's work <ref> [7] </ref>, U. W. Madison's DataScalar [2], and so on. (2) DRM architecture (Figure 1 (b)) DRM (Datapath Register- Main-memory) borrows the concept from the vector architectures with vector registers such as Cray-1. As shown in Figure 1 (b), the on-chip memorypath consists of datapath, registers, and DRAM main-memory.
Reference: [8] <author> Shimizu, T., et al. </author> <title> "A Multimedia 32b RISC Microprocessor with 16Mb DRAM," </title> <booktitle> Proceedings of the 1996 International Solid-State Circuits Conference, </booktitle> <address> pp.216-217, </address> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: As shown in Figure 1 (a), the on-chip memorypath consists of data-path, registers, SRAM cache, and DRAM main-memory. High on-chip memory bandwidth would be exploited between the cache and the main memory on cache replacement. Examples are Kyushu University's PPRAM R [5], Mit-subishi's M32R/D <ref> [8] </ref>, Sun's work [7], U. W. Madison's DataScalar [2], and so on. (2) DRM architecture (Figure 1 (b)) DRM (Datapath Register- Main-memory) borrows the concept from the vector architectures with vector registers such as Cray-1.
Reference: [9] <author> Shirakawa, S., Yoshii, T., Murakami, K., Na-gashima, U., Obara, S., Amisaki, T., Kitamura, K., Takashima, H., Tanabe, K., </author> <title> "The Architecture of a Molecular Orbital calculation Engine (MOE) (in Japanese)," </title> <type> Technical Report of IEICE, </type> <institution> CPSY96-46, pp.45-50, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: As shown in Figure 1 (c), the on-chip memory-path consists of datapath and DRAM main-memory only. High on-chip memory bandwidth would be exploited between the datapath and the main memory on every ALU operations. Examples include Kyushu University's PPRAM MOE <ref> [9] </ref> and PPRAM mpeg [10]. 3 Preliminary Evaluation of Mem orypath Architectures The characteristics of target applications would determine both which on-chip memorypath architectures should be employed and how the high on-chip memory bandwidth should be exploited.
Reference: [10] <author> Shirakawa, S., Iwashita, S., Miyajima, H., and Mu-rakami, K., </author> <title> "PPRAM mpeg : A PPRAM Design for MPEG Decoder (in Japanese)," </title> <type> IPSJ Technical Report, </type> <institution> ARC-111-30, </institution> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: As shown in Figure 1 (c), the on-chip memory-path consists of datapath and DRAM main-memory only. High on-chip memory bandwidth would be exploited between the datapath and the main memory on every ALU operations. Examples include Kyushu University's PPRAM MOE [9] and PPRAM mpeg <ref> [10] </ref>. 3 Preliminary Evaluation of Mem orypath Architectures The characteristics of target applications would determine both which on-chip memorypath architectures should be employed and how the high on-chip memory bandwidth should be exploited.
Reference: [11] <author> Wall, D. W., </author> <title> "Limits of Instruction-Level Parallelism," </title> <booktitle> Proc. of the Fourth Conference on Architectural Support for programming Languages and Operating Systems, </booktitle> <address> pp.176-188, </address> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: We will use the following three datapath models. All the models are borrowed from <ref> [11] </ref>, and they can execute upto 64 instructions in a single clock cycle if data dependences allow it. * Model I: The Great model in [11] with perfect branch prediction (bPerf), perfect indirect jump prediction (jPerf), perfect register renaming (rPerf), and perfect alias analysis (aPerf). * Model II: A model with <p> We will use the following three datapath models. All the models are borrowed from <ref> [11] </ref>, and they can execute upto 64 instructions in a single clock cycle if data dependences allow it. * Model I: The Great model in [11] with perfect branch prediction (bPerf), perfect indirect jump prediction (jPerf), perfect register renaming (rPerf), and perfect alias analysis (aPerf). * Model II: A model with 2-bit branch prediction with 2K-entry table (b2K), indirect jump prediction with 2K-entry table (j2K), register renaming with 256 general-purpose and 256 floating-point reg isters (r256), <p> Table 2 shows the benchmark programs used and the corresponding IP C ideal reported in <ref> [11] </ref>. Table 2 also shows the RPI (memory References Per Instruction), which were obtained through our cache simulation using QPT and tychoII [3]. 1 The cache simulation assumed a direct-mapped D-cache with the cache size of 8K bytes and the line size of 32 bytes. 1 Though the IPC in [11] <p> <ref> [11] </ref>. Table 2 also shows the RPI (memory References Per Instruction), which were obtained through our cache simulation using QPT and tychoII [3]. 1 The cache simulation assumed a direct-mapped D-cache with the cache size of 8K bytes and the line size of 32 bytes. 1 Though the IPC in [11] and our RPI were for MIPS and SPARC respectively, we assume that the difference is small and negligible.
Reference: [12] <author> Wulf, W. A. and McKee, S. A., </author> <title> "Hitting the Memory Wall: Implications of the Obvious," </title> <journal> ACM Computer Architecture News, vol.23, </journal> <volume> no.1, </volume> <month> Mar. </month> <year> 1995. </year> <month> 7 </month>
Reference-contexts: Namely, most of conventional "separate DRAM+logic"-type systems employ a traditional memorypath architecture: i.e., the memory hierarchy of "datapath - on-chip registers - on-chip SRAM cache - off-chip DRAM main-memory." The memory wall problem occurs between the on-chip SRAM cache and the off-chip DRAM main memory <ref> [12] </ref>.
References-found: 12

