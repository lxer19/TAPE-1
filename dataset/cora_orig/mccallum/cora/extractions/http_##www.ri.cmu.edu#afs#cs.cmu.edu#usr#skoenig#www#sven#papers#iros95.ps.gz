URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/usr/skoenig/www/sven/papers/iros95.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/usr/skoenig/www/sven/abstracts/iros95.html
Root-URL: 
Title: Experience with Rover Navigation for Lunar-Like Terrains  
Author: Reid Simmons, Eric Krotkov, Lonnie Chrisman, Fabio Cozman, Richard Goodwin, Martial Hebert, Lalitesh Katragadda, Sven Koenig, Gita Krishnaswamy, Yoshikazu Shinoda, and William Whittaker Paul Klarer 
Address: Pittsburgh, PA 15213  Albuquerque, NM 87185  
Affiliation: The Roboticss Institute, Carnegie Mellon University  Sandia National Laboratories  
Abstract: Reliable navigation is critical for a lunar rover, both for autonomous traverses and safeguarded, remote teleoperation. This paper describes an implemented system that has autonomously driven a prototype wheeled lunar rover over a kilometer in natural, outdoor terrain. The navigation system uses stereo terrain maps to perform local obstacle avoidance, and arbitrates steering recommendations from both the user and the rover. The paper describes the system architecture, each of the major components, and the experimental results to date. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Chatila, R. Alami, et al. </author> <title> Planet Exploration by Robots: From Mission Planning to Autonomous Navigation. </title> <booktitle> In Proc. Intl. Conf. on Advanced Robotics, </booktitle> <address> Tokyo, Japan, </address> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: The research reported here is a descendant of our previous work in rugged terrain navigation for legged rovers [15, 16]. Other efforts have taken similar approaches to navigation for wheeled planetary rovers <ref> [1, 3, 4, 5, 17] </ref>, including the use of obstacle avoidance using stereo vision. Our work is distinguished by its emphasis on long-distance traversal, mixed mode driving, and use of efficient stereo vision using only general-purpose processors.
Reference: [2] <author> F. Cozman and E. Krotkov. </author> <title> Mobile Robot Localization using a Computer Vision Sextant. </title> <booktitle> In Proc. IEEE Intl. Conf. on Robotics and Automation, </booktitle> <address> Nagoya, Japan, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Our research on position estimation techniques has concentrated on understanding and filtering sensors such as gyros and inclinometers, using sensor fusion to reduce uncertainty, and developing some novel techniques that involve skyline navigation and Sun tracking <ref> [2] </ref>. The lessons learned to date are informing our next round of development and experimentation. We are working to demonstrate multi-kilometer autonomous traverses and safeguarded teleoperation of up to 10 km, while increasing the complexity of the terrain traversed and the amount of time delay introduced in operating the rover.
Reference: [3] <author> J. Garvey, </author> <title> A Russian-American Planetary Rover Initiative, </title> <type> AIAA 93-4088, </type> <institution> Huntsville AL, </institution> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: The research reported here is a descendant of our previous work in rugged terrain navigation for legged rovers [15, 16]. Other efforts have taken similar approaches to navigation for wheeled planetary rovers <ref> [1, 3, 4, 5, 17] </ref>, including the use of obstacle avoidance using stereo vision. Our work is distinguished by its emphasis on long-distance traversal, mixed mode driving, and use of efficient stereo vision using only general-purpose processors.
Reference: [4] <author> E. Gat, R. Desai, et al. </author> <title> Behavior Control for Robotic Exploration of Planetary Surfaces. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10:4, </volume> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: The research reported here is a descendant of our previous work in rugged terrain navigation for legged rovers [15, 16]. Other efforts have taken similar approaches to navigation for wheeled planetary rovers <ref> [1, 3, 4, 5, 17] </ref>, including the use of obstacle avoidance using stereo vision. Our work is distinguished by its emphasis on long-distance traversal, mixed mode driving, and use of efficient stereo vision using only general-purpose processors.
Reference: [5] <author> B. Hotz, Z. Zhang and P. Fua. </author> <title> Incremental Construction of Local DEM for an Autonomous Planetary Rover. </title> <booktitle> In Proc. Workshop on Computer Vision for Space Applications, </booktitle> <address> Antibes France, </address> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: The research reported here is a descendant of our previous work in rugged terrain navigation for legged rovers [15, 16]. Other efforts have taken similar approaches to navigation for wheeled planetary rovers <ref> [1, 3, 4, 5, 17] </ref>, including the use of obstacle avoidance using stereo vision. Our work is distinguished by its emphasis on long-distance traversal, mixed mode driving, and use of efficient stereo vision using only general-purpose processors.
Reference: [6] <author> L. Katragadda, et al. </author> <title> Lunar Rover Initiative Preliminary Configuration Document, </title> <type> Tech. Report CMU-RI-TR-94-09, </type> <institution> Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: One promising, near-term scenario is to land a pair of rovers on the Moon, and to engage in a multi-year, 1000 kilometer traverse of historic sights, including Apollo 11, Surveyor 5, Ranger 8, Apollo 17 and Lunokhod 2 <ref> [6] </ref>. In this scenario, the rovers would be operated in either autonomous or safeguarded supervisory control modes, and would transmit continuous live video of their surroundings to operators on Earth.
Reference: [7] <author> L. Katragadda, J. Murphy and W. Whittaker. </author> <title> Rover Configuration for Entertainment-Based Lunar Excursion. </title> <booktitle> In Intl. Lunar Exploration Conference, </booktitle> <address> San Diego, CA, </address> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: We then describe the software system developed to drive the rover, and our experimental results. Finally, we address work that is still needed to enable a return to the Moon in this millennium. The Ratler While we are currently designing a new lunar rover <ref> [7] </ref>, we are using a vehicle designed and built by Sandia National Laboratories [11] as a testbed to develop the remote driving techniques needed for a lunar mission.
Reference: [8] <author> A. Kelly. </author> <title> A Partial Analysis of the High Speed Autonomous Navigation Problem. </title> <type> Tech Report CMU-RI-TR-94-16. </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: All these methods help to produce elevation maps that accurately reect the actual surrounding terrain, with only a few centimeters of error. Obstacle Avoidance Planner To decide where it is safe to drive, we have adapted techniques developed in ARPAs Unmanned Ground Vehicle (UGV) program for cross-country navigation <ref> [8] </ref>. The basic idea is to evaluate the hazards along a discrete number of paths (corresponding to a set of steering commands) that the rover could possibly follow in the next few seconds of travel.
Reference: [9] <author> E. Krotkov and M. Hebert, </author> <title> Mapping and Positioning for a Prototype Lunar Rover. </title> <booktitle> In Proc. IEEE Intl. Conf. on Robotics and Automation, </booktitle> <address> Nagoya, Japan, </address> <month> May </month> <year> 1995. </year> <note> [10]E. </note> <author> Krotkov, M. Hebert, M. Buffa, F. Cozman and L. Robert. </author> <title> Stereo Driving and Position Estimation for Autonomous Planetary Rovers. </title> <booktitle> In Proc. IARP Workshop on Robotics In Space, </booktitle> <address> Montreal, Canada, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: We have found this to be very important in practice, as the robots dead reckoning and path tracking ability are only fair, at best <ref> [9] </ref>. The path evaluations sent to the arbiter are also tagged with a robot pose. If the tagged pose differs significantly from the rovers current pose, then those path evaluations are ignored. <p> Early experiments tested the dead reckoning capability of the system and its ability to avoid discrete obstacles. After characterizing the response of the vehicle and improving the position estimation <ref> [9, 10] </ref>, the rover was able to navigate hundreds of meters with minimal human intervention. To date, our longest contiguous run has been 1,078 m, where 94% of the distance was traversed in autonomous mode and the rest in direct teleoperation mode.

References-found: 9

