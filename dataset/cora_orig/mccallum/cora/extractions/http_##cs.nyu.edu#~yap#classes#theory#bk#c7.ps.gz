URL: http://cs.nyu.edu/~yap/classes/theory/bk/c7.ps.gz
Refering-URL: http://cs.nyu.edu/~yap/classes/theory/bk/
Root-URL: http://www.cs.nyu.edu
Title: Chapter 7 Alternating  7.1 Introduction to computing with choice  
Note: 291  
Date: April 29, 1998  
Pubnum: Choices  
Abstract: The choice-mode of computation comes in two main flavors. The first, already illustrated in Chapter 1 (section 6.2), is based on probability. The second is a generalization of nondeterministism called alternation. Let us briefly see what an alternating computation looks like. Let ffi be the usual Turing transition table that has choice and let C 0 (w) denote the initial configuration of ffi on input w. For this illustration, assume that every computation path is finite; in particular, this implies that no configuration is repeated in a computation path. The computation tree T (w) = T ffi (w) is defined in the obvious way: the nodes of T (w) are configurations, with C 0 (w) as the root; if configuration C is a node of T (w) and C ` C 0 then C 0 is a child of C in T (w). Thus the leaves of T (w) are terminal configurations. The description of an alternating machine M amounts to specifying a transition table ffi together with an assignment fl of a Boolean function fl(q) 2 f^; _:g to each state q in ffi. This induces a Boolean value on each node of T (w) as follows: the leaves are assigned 1 or 0 depending on whether the configuration is accepting or not. If C is not a leaf, and q is the state in C, then we require that the number of children of C is equal to the arity of fl(q). For instance, if C has two children whose assigned values are x and y then C is assigend the value fl(q)(x; y). Finally we say M accepts w if the root C 0 (w) is assigned value 1. The reader will see that nondeterministic computation corresponds to the case where fl(q) = _ for all q. Since the introduction of alternating machines by Chandra, Kozen and Stockmeyer[3] in 1978, the concept has proven to be an extremely useful tool in complexity theory. The model of probabilistic machines we study was introduced by Gill[7]. Let us rephrase the description of probabilistic computation in chapter 1 in terms of assigning values to nodes of a computation tree. A probabilistic machine is formally 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Adleman and M. Loui. </author> <title> Space-bounded simulation of multitape Turing machines. </title> <journal> Math. Systems Theory, </journal> <volume> 14 </volume> <pages> 215-222, </pages> <year> 1981. </year>
Reference-contexts: We call any assignment of `values' to the nodes of a computation tree a valuation. 1 Intuitively, these values represent probabilities and lies in the unit interval <ref> [0; 1] </ref>. But because of infinite computation trees, we are forced to take as `values' any subinterval [a; b] of the unit interval [0; 1]. <p> We call any assignment of `values' to the nodes of a computation tree a valuation. 1 Intuitively, these values represent probabilities and lies in the unit interval <ref> [0; 1] </ref>. But because of infinite computation trees, we are forced to take as `values' any subinterval [a; b] of the unit interval [0; 1]. Such intervals represent uncertainty ranges in the probabilities. 1 The term `valuation' in algebra refers to a real function on a ring that satisfies certain axioms. <p> Infinite trees cannot be avoided in general; such is the case with space-bounded computations or with probabilistic choices. To see why infinite trees are problematic, recall that we want to systematically assign a value in <ref> [0; 1] </ref> to each node of T (x), in a bottom-up fashion. But if a node u of T (x) lies on an infinite path, it is not obvious what value to assign to u. Our solution [23] lies in assigning to u the smallest `confidence' interval I (u) [0; 1] <p> in <ref> [0; 1] </ref> to each node of T (x), in a bottom-up fashion. But if a node u of T (x) lies on an infinite path, it is not obvious what value to assign to u. Our solution [23] lies in assigning to u the smallest `confidence' interval I (u) [0; 1] guaranteed to contain the `true' value of u. This leads us to the following development of an interval algebra 3 . In the following, u; v; x; y, etc., denote real numbers in the unit interval [0, 1]. Let 2 This game model incorporates `partially-hidden information'. <p> This leads us to the following development of an interval algebra 3 . In the following, u; v; x; y, etc., denote real numbers in the unit interval <ref> [0, 1] </ref>. Let 2 This game model incorporates `partially-hidden information'. It will be clear that we could add partially-hidden information to choice machines too. 3 Interval arithmetic, a subject in numerical analysis, is related to our algebra but serves a rather different purpose. <p> We refer the reader to, for example, Moore [15]. 294 CHAPTER 7. ALTERNATING CHOICES denote the set of closed subintervals of <ref> [0; 1] </ref>. An interval [u; v] is exact if u = v, and we identify the exact interval [u; u] with the real number u. We call u and v (respectively) the upper and lower bounds of the interval [u; v]. The unit interval [0; 1] is also called bottom and <p> the set of closed subintervals of <ref> [0; 1] </ref>. An interval [u; v] is exact if u = v, and we identify the exact interval [u; u] with the real number u. We call u and v (respectively) the upper and lower bounds of the interval [u; v]. The unit interval [0; 1] is also called bottom and denoted ?. By an interval function we mean a function f : INT n ! INT, where n 0 denotes the arity of the function. We are interested in six interval functions. <p> For brevity, we suggest reading and as `prand' and `pror', respectively. We note that these 5 real functions can also be regarded as functions on <ref> [0; 1] </ref> (i.e., if their arguments are in [0; 1] then their values remain in [0; 1]). We may then extend them to the subintervals INT of the unit interval as follows. <p> For brevity, we suggest reading and as `prand' and `pror', respectively. We note that these 5 real functions can also be regarded as functions on <ref> [0; 1] </ref> (i.e., if their arguments are in [0; 1] then their values remain in [0; 1]). We may then extend them to the subintervals INT of the unit interval as follows. If ffi is any of these 5 functions, then we define [x; y] ffi [u; v] := [(x ffi u); (y ffi v)]: 7.2. <p> For brevity, we suggest reading and as `prand' and `pror', respectively. We note that these 5 real functions can also be regarded as functions on <ref> [0; 1] </ref> (i.e., if their arguments are in [0; 1] then their values remain in [0; 1]). We may then extend them to the subintervals INT of the unit interval as follows. If ffi is any of these 5 functions, then we define [x; y] ffi [u; v] := [(x ffi u); (y ffi v)]: 7.2. <p> INTERVAL ALGEBRA 295 For instance, [x; y] [u; v] = [xu; yv] and [x; y] ^ [u; v] = [min (x; u); min (y; v)]: Alternatively, for any continuous function f : <ref> [0; 1] </ref> ! [0; 1], we extend the range and domain of f from [0; 1] to INT by the definition f (I) = ff (x) : x 2 Ig. If f is also monotonic, this is equivalent to the above. <p> INTERVAL ALGEBRA 295 For instance, [x; y] [u; v] = [xu; yv] and [x; y] ^ [u; v] = [min (x; u); min (y; v)]: Alternatively, for any continuous function f : <ref> [0; 1] </ref> ! [0; 1], we extend the range and domain of f from [0; 1] to INT by the definition f (I) = ff (x) : x 2 Ig. If f is also monotonic, this is equivalent to the above. One easily verifies: Lemma 1 All five binary functions are commutative. <p> INTERVAL ALGEBRA 295 For instance, [x; y] [u; v] = [xu; yv] and [x; y] ^ [u; v] = [min (x; u); min (y; v)]: Alternatively, for any continuous function f : <ref> [0; 1] </ref> ! [0; 1], we extend the range and domain of f from [0; 1] to INT by the definition f (I) = ff (x) : x 2 Ig. If f is also monotonic, this is equivalent to the above. One easily verifies: Lemma 1 All five binary functions are commutative. With the exception of f , they are also associative. <p> To see this, use induction on i and the monotonicity lemma. Definition 6 From the compactness of the interval <ref> [0; 1] </ref>, we see that there exists a unique least upper bound Val defined by Val (C) = limft i (V ? )(C) : i 0g; for all C 2 . <p> Another fixed point valuation V 2 assigns each nodes in to 0 but the rest has value 1. But the least fixed point valuation V 0 assigns to the value ? to each node on the path and the value 1 to the rest. Definition 7 An interval I <ref> [0; 1] </ref> is a accepting if it is contained in the half-open interval ( 1 2 ; 1], i.e., I ( 1 2 ; 1]. It is rejecting if I [0; 1 2 ); it is undecided if it is neither accepting nor rejecting. 304 CHAPTER 7. <p> We leave the proof as an exercise. We now have the machinery to show that the language accepted by a B-choice machine M is recursively enumerable provided each function in B is computable. To be precise, assume a suitable subset X of <ref> [0; 1] </ref> consisting of all the `representable' numbers, and call an interval representable if its endpoints are representable. We assume 0; 1 2 X. We require X to be dense in [0; 1] (for example, X [0; 1] is the set of rational numbers or X is the set of "binary <p> To be precise, assume a suitable subset X of <ref> [0; 1] </ref> consisting of all the `representable' numbers, and call an interval representable if its endpoints are representable. We assume 0; 1 2 X. We require X to be dense in [0; 1] (for example, X [0; 1] is the set of rational numbers or X is the set of "binary rationals" which are rationals with finite binary expansion). <p> To be precise, assume a suitable subset X of <ref> [0; 1] </ref> consisting of all the `representable' numbers, and call an interval representable if its endpoints are representable. We assume 0; 1 2 X. We require X to be dense in [0; 1] (for example, X [0; 1] is the set of rational numbers or X is the set of "binary rationals" which are rationals with finite binary expansion). <p> It follows b T is accepting. Q.E.D. 7.4. BASIC RESULTS 313 Consequence of eliminating negation. This proof also shows that negation can be eliminated in alternating machines and in PAMs. With respect to SAMs without negation, the use of intervals in valuations can be replaced by ordinary numbers in <ref> [0; 1] </ref> provided we restrict attention to acceptance complexity. A valuation is now a mapping from (M) into [0; 1]. Likewise, a tree valuation assigns a real value in [0; 1] to each node in a complete computation tree. <p> With respect to SAMs without negation, the use of intervals in valuations can be replaced by ordinary numbers in <ref> [0; 1] </ref> provided we restrict attention to acceptance complexity. A valuation is now a mapping from (M) into [0; 1]. Likewise, a tree valuation assigns a real value in [0; 1] to each node in a complete computation tree. We now let V ? denote the valuation that assigns the value 0 to each configuration or node, as the case may be. <p> With respect to SAMs without negation, the use of intervals in valuations can be replaced by ordinary numbers in <ref> [0; 1] </ref> provided we restrict attention to acceptance complexity. A valuation is now a mapping from (M) into [0; 1]. Likewise, a tree valuation assigns a real value in [0; 1] to each node in a complete computation tree. We now let V ? denote the valuation that assigns the value 0 to each configuration or node, as the case may be. The operator t or t T on valuations is defined as before. <p> Convention for this chapter. In this chapter, we only consider alternating machines, PAMs and SAMs with no NOT-states. We are mainly interested in acceptance complexity. In this case, we may restrict valuations take values in <ref> [0; 1] </ref> instead of in INT (we call these real values probabilities). With this convention, the acceptance rule becomes: M accepts a word w iff the probability Val M (w) is greater than 1 2 . <p> Tompa and Dymond [6] obtained this result by adapting the result of Hopcroft, Paul and Valiant [12] showing DTIME (t) DSPACE (t= log t). Adleman and Loui <ref> [1] </ref> gave an interesting alternative proof of the Hopcroft-Paul-Valiant result. The Hopcroft, Paul and Valiant achievement showed for the first time that space is a more powerful resource than time in a "sufficiently" powerful model of computation (multi-tape Turing machines).
Reference: [2] <author> Laszlo Babai and Shlomo Moran. </author> <title> Arthur-Merlin games: a randomized proof system, and a hierarchy of complexity classes. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 36 </volume> <pages> 254-276, </pages> <year> 1988. </year>
Reference-contexts: This chapter focuses on alternation machines, leaving stochastic machines to the next chapter. Other choice modes. Other authors independently proposed a variety of computational modes that turn out to be special cases of our probabilistic-alternating mode: interactive proof systems (Goldwasser, Micali and Rackoff [8]), Arthur-Merlin games (Babai <ref> [2] </ref>), stochastic Turing machines (Papadimitriou [16]), probabilistic-nondeterministic machines (Goldwasser and Sipser [9]). In general, communication protocols and game playing models can be translated as choice machines. In particular, this holds for the probabilistic game automata (Condon and Ladner [4]) which generalize interactive proof systems and stochastic machines 2 .
Reference: [3] <author> A. Chandra, D. Kozen, and L. Stockmeyer. </author> <title> Alternation. </title> <journal> J. ACM, </journal> <volume> 28:1:114-133, </volume> <year> 1981. </year>
Reference-contexts: Finally we say M accepts w if the root C 0 (w) is assigned value 1. The reader will see that nondeterministic computation corresponds to the case where fl (q) = _ for all q. Since the introduction of alternating machines by Chandra, Kozen and Stockmeyer <ref> [3] </ref> in 1978, the concept has proven to be an extremely useful tool in complexity theory. The model of probabilistic machines we study was introduced by Gill [7]. Let us rephrase the description of probabilistic computation in chapter 1 in terms of assigning values to nodes of a computation tree. <p> Example 1 The strong 3-valued algebra described 7 by Chandra, Kozen and Stock-meyer <ref> [3] </ref> is a subalgebra of our interval algebra, obtained by restricting values to f0; 1; ?g. See figure 7.1 for its operation tables. They only were interested in the functions ^, _, :. Thus our interval algebra gives a model (interpretation) for this 3-valued algebra. <p> Q.E.D. One can view the theorem as yet another confirmation of Church's thesis. Our next result shows that negation : can be avoided in stochastic-alternating machines at the cost of an increase in the number of states. The following generalizes a result for alternation machines in <ref> [3] </ref>. <p> An immediate consequence of the above results is this: Corollary 25 (i) NSPACE (s) ATIME (s 2 ). (ii) PrTIME (n O (1) ) ATIME (n O (1) ) = PrA-TIME (n O (1) ) = PSPACE . Borodin <ref> [3] </ref> observed that Savitch's theorem is capable of generalization in another direction. Incorporating Borodin's idea to the previous theorem yields the following "super" Savitch's theorem. Recall the definition of alternating complexity in section 3. Theorem 26 Let t (n) &gt; n; s (n) and a (n) be any complexity functions.
Reference: [4] <author> A. Condon and R. Ladner. </author> <title> Probabilistic game automata. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 36 </volume> <pages> 452-489, </pages> <year> 1988. </year>
Reference-contexts: In general, communication protocols and game playing models can be translated as choice machines. In particular, this holds for the probabilistic game automata (Condon and Ladner <ref> [4] </ref>) which generalize interactive proof systems and stochastic machines 2 . Alternating machines are generalized to logical type machines (Hong [11]) where machine states can now be associated with any of the 16 Boolean functions on two variables.
Reference: [5] <author> Peter Crawley and Robert Dilworth. </author> <title> Algebraic theory of lattices. </title> <publisher> Prentice-Hall, </publisher> <year> 1973. </year>
Reference-contexts: For reference, we will call the lattice-theoretic ordering on INT. The negation function is not a complementation function (in the sense of Boolean algebra <ref> [5] </ref>) since neither I^:I = 0 nor 5 I_:I = 1 holds for all I 2 INT. However it is idempotent, ::I = I. Probabilistic-and and probabilistic-or can be recovered from each other in the presence of negation. <p> Lattice-theoretic notations can be found, for instance, in <ref> [5] </ref>. The lattice-theoretic properties are not essential for the development of our results. 5 We assume that : has higher precedence than the binary operators so we may omit parenthesis when convenient. 296 CHAPTER 7.
Reference: [6] <author> P. Dymond and M. Tompa. </author> <title> Speedups of deterministic machines by synchronous parallel machines. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 30 </volume> <pages> 149-161, </pages> <year> 1985. </year>
Reference-contexts: Tompa and Dymond <ref> [6] </ref> obtained this result by adapting the result of Hopcroft, Paul and Valiant [12] showing DTIME (t) DSPACE (t= log t). Adleman and Loui [1] gave an interesting alternative proof of the Hopcroft-Paul-Valiant result.
Reference: [7] <author> J. T. Gill. </author> <title> Computational complexity of probabilistic Turing machines. </title> <journal> SIAM J. Comp., </journal> <volume> 6(4) </volume> <pages> 675-695, </pages> <year> 1977. </year>
Reference-contexts: Since the introduction of alternating machines by Chandra, Kozen and Stockmeyer [3] in 1978, the concept has proven to be an extremely useful tool in complexity theory. The model of probabilistic machines we study was introduced by Gill <ref> [7] </ref>. Let us rephrase the description of probabilistic computation in chapter 1 in terms of assigning values to nodes of a computation tree. A probabilistic machine is formally 291 292 CHAPTER 7. ALTERNATING CHOICES a transition table ffi where each configuration spawns either zero or two children.
Reference: [8] <author> S. Goldwasser, Silvio Micali, and Charles Rackoff. </author> <title> The knowledge complexity of interactive proofs. </title> <booktitle> 17th ACM Symposium STOC, </booktitle> <pages> pages 291-304, </pages> <year> 1985. </year>
Reference-contexts: This chapter focuses on alternation machines, leaving stochastic machines to the next chapter. Other choice modes. Other authors independently proposed a variety of computational modes that turn out to be special cases of our probabilistic-alternating mode: interactive proof systems (Goldwasser, Micali and Rackoff <ref> [8] </ref>), Arthur-Merlin games (Babai [2]), stochastic Turing machines (Papadimitriou [16]), probabilistic-nondeterministic machines (Goldwasser and Sipser [9]). In general, communication protocols and game playing models can be translated as choice machines.
Reference: [9] <author> Shafi Goldwasser and Michael Sipser. </author> <title> Private coins versus public coins in interactive proof systems. </title> <booktitle> 18th ACM Symposium STOC, </booktitle> <pages> pages 59-68, </pages> <year> 1986. </year>
Reference-contexts: Other choice modes. Other authors independently proposed a variety of computational modes that turn out to be special cases of our probabilistic-alternating mode: interactive proof systems (Goldwasser, Micali and Rackoff [8]), Arthur-Merlin games (Babai [2]), stochastic Turing machines (Papadimitriou [16]), probabilistic-nondeterministic machines (Goldwasser and Sipser <ref> [9] </ref>). In general, communication protocols and game playing models can be translated as choice machines. In particular, this holds for the probabilistic game automata (Condon and Ladner [4]) which generalize interactive proof systems and stochastic machines 2 .
Reference: [10] <author> Albert G. Greenberg and Alan Weiss. </author> <title> A lower bound for probabilistic algorithms for finite state machines. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33 </volume> <pages> 88-105, </pages> <year> 1986. </year>
Reference-contexts: All other outcomes result in a tie. c. Repeat this experiment until we have at least D 0-wins or D 1-wins. We accept if and only if there is at least one 1-win and at least one 0-win. (For more information, see <ref> [10] </ref>.) [7.24] (Ruzzo, King) Show the following simulations among measures for alternat ing computation, as stated in the concluding section: for s (n) log n, A-SPACE-SIZE (s (n); z (n)) ATIME (s (n) log z (n)); A-SPACE-WIDTH (s (n); w (n)) = NSPACE (s (n)w (n)); A-SPACE-VISIT (s (n); v (n))
Reference: [11] <author> Jia-wei Hong. </author> <title> Computation: Computability, Similarity and Duality. </title> <booktitle> Research notices in theoretical Computer Science. </booktitle> <publisher> Pitman Publishing Ltd., </publisher> <address> London, 1986. </address> <publisher> (available from John Wiley & Sons, </publisher> <address> New York). 349 350 BIBLIOGRAPHY </address>
Reference-contexts: In general, communication protocols and game playing models can be translated as choice machines. In particular, this holds for the probabilistic game automata (Condon and Ladner [4]) which generalize interactive proof systems and stochastic machines 2 . Alternating machines are generalized to logical type machines (Hong <ref> [11] </ref>) where machine states can now be associated with any of the 16 Boolean functions on two variables.
Reference: [12] <author> J. E. Hopcroft, W. J. Paul, and L. G. Valiant. </author> <title> On time versus space. </title> <journal> Journal of the ACM, </journal> <volume> 24 </volume> <pages> 332-337, </pages> <year> 1977. </year>
Reference-contexts: Tompa and Dymond [6] obtained this result by adapting the result of Hopcroft, Paul and Valiant <ref> [12] </ref> showing DTIME (t) DSPACE (t= log t). Adleman and Loui [1] gave an interesting alternative proof of the Hopcroft-Paul-Valiant result.
Reference: [13] <author> Kimberley N. King. </author> <title> Measures of parallelism in alternating computation trees. </title> <booktitle> Proc. 13th ACM Symp. Theory of Computing, </booktitle> <pages> pages 189-201, </pages> <year> 1981. </year>
Reference-contexts: Other complexity measures for alternating machines have been studied. Ruzzo [20] studied the size (i.e., the number of nodes) of computation trees. In particular, he shows A-SPACE-SIZE (s (n); z (n)) ATIME (s (n) log z (n)): King <ref> [13] </ref> introduced other measures on computation trees: branching (i.e., the number of leaves), width (below), visit (the maximum number of nodes at any level).
Reference: [14] <author> Burkhard Monien and Ivan Hal Sudborough. </author> <title> On eliminating nondeterminism from Turing machines which use less than logarithm worktape space. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 71, </volume> <pages> pages 431-445, </pages> <address> Berlin, </address> <year> 1979. </year> <title> Springer-Verlag. </title> <booktitle> Proc. Symposium on Automata, Languages and Programming. </booktitle>
Reference-contexts: Consider what happens when s (n) &lt; log n. Savitch's proof method gives only the uninteresting result NSPACE (s) DSPACE (log 2 n). Monien and Sudborough <ref> [14] </ref> improved this so that for s (n) &lt; log n, NSPACE (s) DSPACE (s (n) log n): Using addressable-input alternating machines, Tompa [21] improved the Monien-Sudborough construction to obtain: NSPACE (s) ATIME (s (n)[s (n) + log n]) for all s (n).
Reference: [15] <author> R. E. Moore. </author> <title> Interval Analysis. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1966. </year>
Reference-contexts: Let 2 This game model incorporates `partially-hidden information'. It will be clear that we could add partially-hidden information to choice machines too. 3 Interval arithmetic, a subject in numerical analysis, is related to our algebra but serves a rather different purpose. We refer the reader to, for example, Moore <ref> [15] </ref>. 294 CHAPTER 7. ALTERNATING CHOICES denote the set of closed subintervals of [0; 1]. An interval [u; v] is exact if u = v, and we identify the exact interval [u; u] with the real number u.
Reference: [16] <author> Christos H. Papadimitriou. </author> <title> Games against nature. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 31 </volume> <pages> 288-301, </pages> <year> 1985. </year>
Reference-contexts: Other choice modes. Other authors independently proposed a variety of computational modes that turn out to be special cases of our probabilistic-alternating mode: interactive proof systems (Goldwasser, Micali and Rackoff [8]), Arthur-Merlin games (Babai [2]), stochastic Turing machines (Papadimitriou <ref> [16] </ref>), probabilistic-nondeterministic machines (Goldwasser and Sipser [9]). In general, communication protocols and game playing models can be translated as choice machines. In particular, this holds for the probabilistic game automata (Condon and Ladner [4]) which generalize interactive proof systems and stochastic machines 2 .
Reference: [17] <author> Michael S. Paterson. </author> <title> Tape bounds for time-bounded Turing machines. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 6 </volume> <pages> 116-124, </pages> <year> 1972. </year>
Reference-contexts: Adleman and Loui [1] gave an interesting alternative proof of the Hopcroft-Paul-Valiant result. The Hopcroft, Paul and Valiant achievement showed for the first time that space is a more powerful resource than time in a "sufficiently" powerful model of computation (multi-tape Turing machines). Earlier results by Paterson <ref> [17] </ref> already established such results for simple Turing machines, but the techniques were special to simple Turing machines. Paul and Reischuk extended the Hopcroft, Paul and Valiant result to alternating time, but their simulation needed alternating time t log log t= log t.
Reference: [18] <author> W. J. Paul, Ernst J. Praus, and Rudiger Reischuk. </author> <title> On alternation. </title> <journal> Acta Informatica, </journal> <volume> 14 </volume> <pages> 243-255, </pages> <year> 1980. </year>
Reference-contexts: It is a little harder (Exercise) to show the same for the stochastic choices ( f k ; k ; k ). A useful technical result is tape reduction for alternating machines. The following is from Paul, Praus and Reischuk <ref> [18] </ref>. Theorem 14 For any k-tape alternating machine M accepting in time-alternation (t (n); a (n)), there is a simple alternating machine N accepting the same language and time-alternation (O (t (n)); a (n) + O (1)).
Reference: [19] <author> W. J. Paul, R. E. Tarjan, and J. R. Celoni. </author> <title> Space bounds for a game on graphs. </title> <journal> Math. Systems Theory, </journal> <volume> 11 </volume> <pages> 239-251, </pages> <year> 1977. </year> <note> (See corrections in Math. Systems Theory, 11(1977)85.). </note>
Reference-contexts: Q.E.D. In conclusion, it should be noted the space bound just obtained is the best possible in the sense that (t= log t) is a lower bound on the worst case pebbling time for the class bounded in-degree graphs <ref> [19] </ref>. 7.9. ALTERNATING SPACE 339 7.9 Alternating Space We show two results from Chandra, Kozen and Stockmeyer that relate alternating space and deterministic time. Note that for a nondeterministic machine M, if there is an accepting path then there is one in which no configuration is repeated.
Reference: [20] <author> Walter L. Ruzzo. </author> <title> Tree-size bounded alternation. </title> <booktitle> Proc. 11th ACM Symp. Theory of Computing, </booktitle> <pages> pages 352-359, </pages> <year> 1979. </year>
Reference-contexts: Other complexity measures for alternating machines have been studied. Ruzzo <ref> [20] </ref> studied the size (i.e., the number of nodes) of computation trees.
Reference: [21] <author> Martin Tompa. </author> <title> An improvement on the extension of Savitch's theorem to small space bounds. </title> <type> Technical Report Technical Report No. </type> <institution> 79-12-01, Department of Computer Sci., Univ. of Washington, </institution> <year> 1979. </year>
Reference-contexts: Consider what happens when s (n) &lt; log n. Savitch's proof method gives only the uninteresting result NSPACE (s) DSPACE (log 2 n). Monien and Sudborough [14] improved this so that for s (n) &lt; log n, NSPACE (s) DSPACE (s (n) log n): Using addressable-input alternating machines, Tompa <ref> [21] </ref> improved the Monien-Sudborough construction to obtain: NSPACE (s) ATIME (s (n)[s (n) + log n]) for all s (n).
Reference: [22] <author> Klaus Weihrauch. </author> <title> Computability. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference-contexts: The reader familiar with Scott's theory of semantics will see many similarities. For relevant material, see <ref> [22] </ref>.
Reference: [23] <author> Chee K. Yap. </author> <title> On combining probabilistic and alternating machines. </title> <type> Technical report, </type> <institution> Univ. of Southern California, Comp. Sci. Dept., </institution> <month> January </month> <year> 1980. </year> <type> Technical Report. </type>
Reference-contexts: With this shift of perspective, we have almost accomplished the transition to a new syncretistic model that we call probabilistic-alternating machines. This model was first studied in <ref> [23] </ref>. <p> But if a node u of T (x) lies on an infinite path, it is not obvious what value to assign to u. Our solution <ref> [23] </ref> lies in assigning to u the smallest `confidence' interval I (u) [0; 1] guaranteed to contain the `true' value of u. This leads us to the following development of an interval algebra 3 .
References-found: 23

