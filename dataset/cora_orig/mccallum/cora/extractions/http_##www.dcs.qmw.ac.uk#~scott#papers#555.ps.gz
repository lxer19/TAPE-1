URL: http://www.dcs.qmw.ac.uk/~scott/papers/555.ps.gz
Refering-URL: http://www.dcs.qmw.ac.uk/~scott/papers/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The Application of Machine Learning Techniques to Time-Series Data  
Author: by Scott Mitchell 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Master  
Date: 1995  
Affiliation: of Computing and Mathematical Sciences at the University of Waikato  University of Waikato  
Abstract-found: 0
Intro-found: 1
Reference: <institution> Bibliography </institution>
Reference: [1] <author> D. W. Aha, D. Kibler, and M. K. Albert. </author> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 37-66, </pages> <year> 1991. </year>
Reference-contexts: Ting [38] has developed a composite learning scheme that partly alleviates the problem of small splits or small disjuncts. His method uses an instance-based learner <ref> [1] </ref> to classify test cases belonging to a small disjunct, otherwise the C4.5 decision tree is used. Both learners are trained in parallel on the same training 57 4. Results and Discussion set.
Reference: [2] <author> Lalit R. Bahl, Frederick Jelinek, and Robert L. Mercer. </author> <title> A maximum like-lyhood approach to continuous speech recognition. </title> <editor> In Alex Waibel and Kai-Fu Lee, editors, </editor> <booktitle> Readings in Speech Recognition, </booktitle> <pages> pages 308-319. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: The theory of HMMs first appeared in a series of classic papers by Baum and his colleagues during the late 1960's and early 1970's [3] and was extended into speech processing applications in the 1970's by Baker at CMU and Jelinek and others at IBM <ref> [2] </ref>. The following overview of HMM theory and applications is of necessity relatively brief. For a fuller introduction to the subject the reader should consult any of [32, 19, 31, 34].
Reference: [3] <author> L. E. Baum. </author> <title> An inequality and associated maximization technique in statistical estimation for probabilistic functions of Markov processes. </title> <journal> Inequalities, </journal> <volume> 3 </volume> <pages> 1-8, </pages> <year> 1972. </year>
Reference-contexts: Thus, a HMM performs a vary similar task to a conventional supervised learning scheme, with the exception that it works on time-series data. The theory of HMMs first appeared in a series of classic papers by Baum and his colleagues during the late 1960's and early 1970's <ref> [3] </ref> and was extended into speech processing applications in the 1970's by Baker at CMU and Jelinek and others at IBM [2]. The following overview of HMM theory and applications is of necessity relatively brief. <p> k fl t (i; k) b 0 expected number of times in state j and observing symbol v k expected number of times in state j = t:y t =k fl t (i; j) t=1 fl t (i; j) Equations 2.21 and 2.22 are both instances of the Baum-Welch algorithm <ref> [3] </ref>. Every such re-estimation of the model parameters is guaranteed to increase P (Oj), unless a critical pointa local or global maximumhas been reached, in which case the estimate remains the same. The literature presents a number of proofs of the Baum-Welch method, including [3, 20]. 20 3. <p> Every such re-estimation of the model parameters is guaranteed to increase P (Oj), unless a critical pointa local or global maximumhas been reached, in which case the estimate remains the same. The literature presents a number of proofs of the Baum-Welch method, including <ref> [3, 20] </ref>. 20 3. Experimental Methodology Chapter 3 Experimental Methodology A total of seven different experiments were performed on a database of dairy cow milking records supplied by the Dairying Research Corporation. The database tracks the performance of a small research dairy herd over part of the 1993-94 milking season.
Reference: [4] <author> Donald J. Berndt and James Clifford. </author> <title> Using dynamic time warping to find patterns in time series. </title> <editor> In Usama M. Fayyad and Ramasamy Uthurusamy, editors, </editor> <booktitle> Proceedings of KDD-94: AAAI-94 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 359-370, </pages> <address> Seattle, Washington, </address> <month> July-August </month> <year> 1994. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference-contexts: Humans are generally very good at detecting such patterns in time-series visually, but as with most such applications programming a machine to do so has proven to be a lot more difficult <ref> [4] </ref>. A large part of the difficulty lies in finding ways to detect and match patterns inexactlywith some notion of fuzziness to account for the inevitable noise and statistical variation in real-world data. Researchers in a number of fields have looked at this problem. <p> Researchers in a number of fields have looked at this problem. The most relevant work appears to be in the area of signal processing, and in particular speech recognition. Good speech recognition schemes can reliably match words from their vocabulary despite variations in timing and pronunciation <ref> [4] </ref>. Two of the most successful techniques used recently in speech applications are dynamic time warping (DTW) and hidden Markov models (HMMs). These are described in more detail below. 2.3.1 Dynamic Time Warping Dynamic time warping [33, 35] is a template-matching recognition method based around a dynamic programming algorithm.
Reference: [5] <author> Ronald J. Brachman and Tej Anand. </author> <title> The process of knowledge discovery in databases: A first sketch. </title> <editor> In Usama M. Fayyad and Ramasamy Uthu-rusamy, editors, </editor> <booktitle> Proceedings of KDD-94: AAAI-94 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 1-11, </pages> <address> Seattle, Washington, </address> <month> July-August </month> <year> 1994. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference-contexts: In these cases prior knowledge of the domain may be deficient or missing entirely. Finally, real databases are often enormouspotentially thousands of variables and tens of millions of records may be present. Brachman & Anand <ref> [5] </ref> consider the process of knowledge discovery as a human-centered task, with interaction between the user and machine at each step. They broadly divide the process into two partsa data analysis and knowledge acquisition stage, and an application to make use of the discovered knowledge.
Reference: [6] <author> J. Cendrowska. </author> <title> PRISM: An algorithm for inducing modular rules. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27(4) </volume> <pages> 349-370, </pages> <year> 1987. </year> <note> 68 BIBLIOGRAPHY </note>
Reference-contexts: Other schemes generate more useful descriptions which can be interpreted by human users. These include: Rules These are a popular form of knowledge representation as they resemble the way human experts tend to describe their knowledge of a domain. Rule representations range from simple if-then production rules <ref> [6] </ref> to more complex systems such as ripple-down rules and exception based schemes [9]. Decision trees and graphs The most basic form of decision graph is a simple binary tree, which is exactly equivalent to a set of if-then rules [28, 6] . <p> Rule representations range from simple if-then production rules [6] to more complex systems such as ripple-down rules and exception based schemes [9]. Decision trees and graphs The most basic form of decision graph is a simple binary tree, which is exactly equivalent to a set of if-then rules <ref> [28, 6] </ref> . Tree representations are not considered to be as comprehensible to humans as rules. However, newer schemes such as exception dags (directed acyclic graphs) [9] are claimed to be more natural and understandable representations. Concept hierarchies Here the data is classified into a tree of categories and sub-categories.
Reference: [7] <author> P. Cheeseman, J. Kelly, M. Self, J. Stutz, W. Taylor, and D. Freeman. Auto-Class: </author> <title> A Bayesian classification system. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 54-64, </pages> <address> San Mateo, California, 1988. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: In unsupervised learning, no prior classification is provided, and it is up to the learning scheme itself to generate one based on its analysis of the training data. Unsupervised schemes are often referred to as clustering schemes and are often closely related to statistical clustering methods <ref> [7, 12] </ref>. Similarity-based vs. Knowledge-based Similarity-based schemes form gener-alisations based solely on the similarities and differences found between the training examples. Knowledge-based learning makes use of a domain theory or background knowledge of the problem domain, usually supplied by an expert.
Reference: [8] <author> D. Fisher. </author> <title> Knowledge acquisition via incremental concept clustering. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 139-172, </pages> <year> 1987. </year>
Reference-contexts: The topmost level of the tree represents the broadest 5 2. Background and Review of Literature classification of the examples, this is, the most general description. Lower levels of the tree refine the initial classification, with the examples at the leaves of the tree having the most specific description <ref> [18, 8, 23] </ref>. A concept hierarchy differs from a decision tree in that examples may be placed at internal nodes of the concept tree. These examples are representative of more general relationships in the dataanomalous cases tend to be pushed down towards the leaves.
Reference: [9] <author> Brian R. Gaines. </author> <title> Exception dags as knowledge structures. </title> <editor> In Usama M. Fayyad and Ramasamy Uthurusamy, editors, </editor> <booktitle> Proceedings of KDD-94: AAAI-94 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 13-24, </pages> <address> Seat-tle, Washington, </address> <month> July-August </month> <year> 1994. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference-contexts: These include: Rules These are a popular form of knowledge representation as they resemble the way human experts tend to describe their knowledge of a domain. Rule representations range from simple if-then production rules [6] to more complex systems such as ripple-down rules and exception based schemes <ref> [9] </ref>. Decision trees and graphs The most basic form of decision graph is a simple binary tree, which is exactly equivalent to a set of if-then rules [28, 6] . Tree representations are not considered to be as comprehensible to humans as rules. <p> Tree representations are not considered to be as comprehensible to humans as rules. However, newer schemes such as exception dags (directed acyclic graphs) <ref> [9] </ref> are claimed to be more natural and understandable representations. Concept hierarchies Here the data is classified into a tree of categories and sub-categories. The topmost level of the tree represents the broadest 5 2. Background and Review of Literature classification of the examples, this is, the most general description.
Reference: [10] <author> Stephen R. Garner. </author> <title> ARFFthe WEKA dataset format. World Wide Web hypertext document at http://www.cs.waikato.ac.nz/ml/workbench/arff.html, 1994. </title>
Reference-contexts: The file was in a packed binary format that was very dependent on the architecture an IBM compatible PCand compilerBorland/Turbo Cused by the data acquisition system. On the other hand, the WEKA workbench requires its input files to use the locally developed ARFF (Attribute-Relation File Format) representation <ref> [10] </ref>. ARFF is a human-readable text based format that is only able to represent a single flat table in each file. It was therefore necessary to perform some structural conversion on the database to render it into a form acceptable to the workbench schemes.
Reference: [11] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley Publishing Company Inc., </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1989. </year>
Reference-contexts: The output of a learning scheme is then some form of structural description of a dataset, acquired from examples of that data [21]. The knowledge learned by a machine learning schemethe structural descriptions of the datacan be represented in different ways. Schemes such as genetic algorithms <ref> [11] </ref> or neural networks, mentioned above, generate implicit internal models of the data which are not easily understood by human beings or other machines. In this study we are concerned with being able to communicate the acquired knowledge to people, making the use of such schemes impractical.
Reference: [12] <author> S. Hansen and M. Bauer. </author> <title> Conceptual clustering, categorization and poly-morphy. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 343-372, </pages> <year> 1989. </year>
Reference-contexts: In unsupervised learning, no prior classification is provided, and it is up to the learning scheme itself to generate one based on its analysis of the training data. Unsupervised schemes are often referred to as clustering schemes and are often closely related to statistical clustering methods <ref> [7, 12] </ref>. Similarity-based vs. Knowledge-based Similarity-based schemes form gener-alisations based solely on the similarities and differences found between the training examples. Knowledge-based learning makes use of a domain theory or background knowledge of the problem domain, usually supplied by an expert.
Reference: [13] <author> Geoffrey Holmes, Andrew Donkin, and Ian H. Witten. WEKA: </author> <title> A machine learning workbench. </title> <type> Working Paper 94/9, </type> <institution> Department of Computer Science, University of Waikato, Hamilton, </institution> <address> New Zealand, </address> <month> July </month> <year> 1994. </year>
Reference: [14] <author> Marcel Holsheimer and Arno Siebes. </author> <title> Data mining: The search for knowledge in databases. </title> <type> Technical Report CS-R9406, </type> <institution> CWI, </institution> <address> Amsterdam, The Netherlands, </address> <year> 1994. </year>
Reference: [15] <author> Robert C. Holte. </author> <title> Very simple classification rules perform well on most commonly used datasets. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 63-91, </pages> <year> 1993. </year>
Reference-contexts: It is that accuracy that would be achieved by a nave learner that simply picks the majority class, and is often used as a standard against which new learning results are compared <ref> [15] </ref>. The baseline accuracy shown on the plots is that of the test data, which in all cases is the complete dataset. The baseline accuracy of many of the training sets is less than this value.
Reference: [16] <author> Willi Klosgen and Jan M. Zytkow. </author> <title> Machine discovery terminology. </title> <editor> In Usama M. Fayyad and Ramasamy Uthurusamy, editors, </editor> <booktitle> Proceedings of 69 BIBLIOGRAPHY KDD-94: AAAI-94 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 463-473, </pages> <address> Seattle, Washington, </address> <month> July-August </month> <year> 1994. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference-contexts: schemes are well suited to incremental learning, where new cases are assimilated without needed to re-process all previously seen examples. 2.2 Knowledge Discovery Knowledge discovery (KD) is concerned with the extraction of meaningful knowledge from collections of real-world data, and communicating the discovered knowledge to people in an understandable way <ref> [16] </ref>. Typical knowledge discovery systems combine techniques from machine learning, statistics, artificial intelligence and database technology. These systems move beyond conventional machine learning in that they seek to discover knowledge that is both meaningful and relevant to specific groups of target users in a particular appli 7 2. <p> Background and Review of Literature cation domain. The knowledge discovery process has been variously referred to as database mining or database exploration <ref> [21, 16] </ref>. Real-world data brings with it a new set of problems not generally faced in the idealised world of a pure machine learning task. Data is often noisy sometimes extremely soor poorly collected.
Reference: [17] <author> I. Kononenko and I. Bratko. </author> <title> Information-based evaluation criterion for classifier's performance. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 67-80, </pages> <year> 1991. </year>
Reference-contexts: The most common of these is the simple classification accuracythe percentage of correct classifications made on a set of test data. While it is a popular measure of performance, the classification accuracy is known to have several defects <ref> [25, 17] </ref>. More robust measures of classifier performance make use of measures such as the size of the descriptions, their complexity and other information-theoretic metrics in addition to the raw accuracy [17, 27]. 43 4. <p> While it is a popular measure of performance, the classification accuracy is known to have several defects [25, 17]. More robust measures of classifier performance make use of measures such as the size of the descriptions, their complexity and other information-theoretic metrics in addition to the raw accuracy <ref> [17, 27] </ref>. 43 4. Results and Discussion However, in the context of a real-world classification problem, human users of a discovery system are unlikely to be concerned with theoretical measures of classification complexity and information gain.
Reference: [18] <author> M. Lebowitz. </author> <title> Experiments with incremental concept formation: </title> <journal> UNI-MEM. Machine Learning, </journal> <volume> 2 </volume> <pages> 103-138, </pages> <year> 1987. </year>
Reference-contexts: The topmost level of the tree represents the broadest 5 2. Background and Review of Literature classification of the examples, this is, the most general description. Lower levels of the tree refine the initial classification, with the examples at the leaves of the tree having the most specific description <ref> [18, 8, 23] </ref>. A concept hierarchy differs from a decision tree in that examples may be placed at internal nodes of the concept tree. These examples are representative of more general relationships in the dataanomalous cases tend to be pushed down towards the leaves.
Reference: [19] <author> Kai-Fu Lee. </author> <title> Automatic Speech Recognition: The Development of the SPHINX System, </title> <booktitle> chapter 2, </booktitle> <pages> pages 17-43. </pages> <publisher> Kluwer Academic Publishing, </publisher> <address> Boston, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: The following overview of HMM theory and applications is of necessity relatively brief. For a fuller introduction to the subject the reader should consult any of <ref> [32, 19, 31, 34] </ref>. Markov Processes A Markov process consists of a finite set of states and a set of possible transitions between those states. At regular, discrete time intervals the system undergoes a change of state, possibly back to the same state.
Reference: [20] <author> Stephen E. Levinson, Lawrence R. Rabiner, and M. M. Sondhi. </author> <title> An introduction to the application of the theory of probabilistic functions on a Markov process to automatic speech recognition. </title> <journal> The Bell System Technical Journal, </journal> <volume> 62(4), </volume> <month> April </month> <year> 1983. </year>
Reference-contexts: Every such re-estimation of the model parameters is guaranteed to increase P (Oj), unless a critical pointa local or global maximumhas been reached, in which case the estimate remains the same. The literature presents a number of proofs of the Baum-Welch method, including <ref> [3, 20] </ref>. 20 3. Experimental Methodology Chapter 3 Experimental Methodology A total of seven different experiments were performed on a database of dairy cow milking records supplied by the Dairying Research Corporation. The database tracks the performance of a small research dairy herd over part of the 1993-94 milking season.
Reference: [21] <author> Robert J. McQueen, Stephen R. Garner, Craig G. Nevill-Manning, and Ian H. Witten. </author> <title> Applying machine learning to agricultural data. </title> <type> Working Paper 94/13, </type> <institution> Department of Computer Science, University of Waikato, Hamilton, </institution> <address> New Zealand, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: For the purposes of the applications and methods described in this report only those techniques that do generate symbolic representations of knowledge. The output of a learning scheme is then some form of structural description of a dataset, acquired from examples of that data <ref> [21] </ref>. The knowledge learned by a machine learning schemethe structural descriptions of the datacan be represented in different ways. Schemes such as genetic algorithms [11] or neural networks, mentioned above, generate implicit internal models of the data which are not easily understood by human beings or other machines. <p> These examples are representative of more general relationships in the dataanomalous cases tend to be pushed down towards the leaves. In a decision tree all of the examples are classified at the leaves. Machine learning schemes can be further compared along a number of different dimensions <ref> [21] </ref>. These dimensions tend to overlap to some extent but do provide a useful basis for comparison. Supervised vs. Unsupervised learning This is one of the most fundamental distinctions between learning methods. <p> Background and Review of Literature cation domain. The knowledge discovery process has been variously referred to as database mining or database exploration <ref> [21, 16] </ref>. Real-world data brings with it a new set of problems not generally faced in the idealised world of a pure machine learning task. Data is often noisy sometimes extremely soor poorly collected. <p> Experimental Methodology Thirdly, the cow definition table is staticit contains no temporal data, so including any of these attributes would introduce a lot of redundancy into the data set. Redundant data is generally more difficult for similarity based schemes to deal with <ref> [21] </ref> so should be avoided. Finally, the milking summary table might be useful to detect the occurrence of global events affecting the whole herd, but using it would introduce redundancies similar to the cow definition data.
Reference: [22] <author> Robert J. McQueen, Donna Neal, Rhys DeWar, and Stephen R. Garner. </author> <title> Preparing and processing relational data through the WEKA machine learning workbench. </title> <type> Working paper, </type> <institution> Department of Computer Science, University of Waikato, Hamilton, </institution> <address> New Zealand, </address> <year> 1994. </year>
Reference-contexts: The attribute selection includes variables present in the raw database and derived attributes generated from existing variables. In the case of a relational database such as the herd milking data, producing input for a learning scheme will almost always involve some kind of projection or flattening of the database <ref> [22] </ref>. It is important that as little information as possible is lost by this process. Initially, the only information available to guide the attribute selection process was the domain knowledge of the DRC researchers.
Reference: [23] <author> R. Michalski and R. Stepp. </author> <title> Learning from observation: Conceptual clustering. </title> <editor> In R. Michalski, R. Carbonell, and T. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 331-363. </pages> <publisher> Tioga Publishing Company, </publisher> <address> Palo Alto, California, </address> <year> 1983. </year>
Reference-contexts: The topmost level of the tree represents the broadest 5 2. Background and Review of Literature classification of the examples, this is, the most general description. Lower levels of the tree refine the initial classification, with the examples at the leaves of the tree having the most specific description <ref> [18, 8, 23] </ref>. A concept hierarchy differs from a decision tree in that examples may be placed at internal nodes of the concept tree. These examples are representative of more general relationships in the dataanomalous cases tend to be pushed down towards the leaves.
Reference: [24] <author> D. Michie. </author> <title> Methodologies from machine learning in data analysis and software. </title> <journal> The Computer Journal, </journal> <volume> 34(6) </volume> <pages> 559-565, </pages> <year> 1991. </year>
Reference-contexts: The fundamental goal of any machine learning algorithm is to discover meaningful or non-trivial relationships in a set of training data and produce a general-isation of these relationships that can be used to interpret new, unseen data. Michie <ref> [24] </ref> defines the learning process as follows: 4 2. Background and Review of Literature A learning system uses sample data to generate an updated basis for improved classification of subsequent data from the same source, and expresses the new basis in intelligible symbolic form.
Reference: [25] <author> John Mingers. </author> <title> An empirical comparison of pruning methods for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 227-243, </pages> <year> 1989. </year> <note> 70 BIBLIOGRAPHY </note>
Reference-contexts: These are described briefly below: C4.5 C4.5 [30] is a system for inducing rules and decision trees from a set of examples. Much of C4.5 is derived from Quinlan's earlier induction system, ID3 [28]. The basic ID3 algorithm has been tested and modified by numerous researchers since its invention <ref> [25, 39] </ref>. However, C4.5 adds several new and interesting features that are worth mentioning: * C4.5 uses a new gain ratio criterion for determining how to split the examples at each node of a decision tree. This removes ID3's strong bias towards tests with many outcomes. <p> The most common of these is the simple classification accuracythe percentage of correct classifications made on a set of test data. While it is a popular measure of performance, the classification accuracy is known to have several defects <ref> [25, 17] </ref>. More robust measures of classifier performance make use of measures such as the size of the descriptions, their complexity and other information-theoretic metrics in addition to the raw accuracy [17, 27]. 43 4.
Reference: [26] <author> John Mingers. </author> <title> An empirical comparison of selection measures for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 319-342, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: The gain ratio criterion selects a test that maximises the value of this ratio. According to Quinlan [30], the gain ratio criterion usually gives a better choice of test than the gain criterion used by ID3. However, Mingers <ref> [26] </ref> expresses some concern about the tendency of 51 4. Results and Discussion the gain ratio criterion to favour highly skewed partitionings of the examples.
Reference: [27] <author> Trevor J. Monk, R. Scott Mitchell, Lloyd A. Smith, and Geoffrey Holmes. </author> <title> Geometric comparison of classifications and rule sets. </title> <editor> In Usama M. Fayyad and Ramasamy Uthurusamy, editors, </editor> <booktitle> Proceedings of KDD-94: AAAI-94 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 395-406, </pages> <address> Seattle, Wash-ington, </address> <month> July-August </month> <year> 1994. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference-contexts: While it is a popular measure of performance, the classification accuracy is known to have several defects [25, 17]. More robust measures of classifier performance make use of measures such as the size of the descriptions, their complexity and other information-theoretic metrics in addition to the raw accuracy <ref> [17, 27] </ref>. 43 4. Results and Discussion However, in the context of a real-world classification problem, human users of a discovery system are unlikely to be concerned with theoretical measures of classification complexity and information gain.
Reference: [28] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Rule representations range from simple if-then production rules [6] to more complex systems such as ripple-down rules and exception based schemes [9]. Decision trees and graphs The most basic form of decision graph is a simple binary tree, which is exactly equivalent to a set of if-then rules <ref> [28, 6] </ref> . Tree representations are not considered to be as comprehensible to humans as rules. However, newer schemes such as exception dags (directed acyclic graphs) [9] are claimed to be more natural and understandable representations. Concept hierarchies Here the data is classified into a tree of categories and sub-categories. <p> These are described briefly below: C4.5 C4.5 [30] is a system for inducing rules and decision trees from a set of examples. Much of C4.5 is derived from Quinlan's earlier induction system, ID3 <ref> [28] </ref>. The basic ID3 algorithm has been tested and modified by numerous researchers since its invention [25, 39].
Reference: [29] <author> J. R. Quinlan. </author> <title> Learning logical relation from definitions. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: This is clearly not useful on time-series data, where a relation such as production this week is greater than production last week is both likely to occur and probably very relevant. Fortunately some similarity-based schemes, for instance Quinlan's FOIL (First Order Inductive Learner) <ref> [29] </ref> deal in first order logic and are capable of discovering these relationships. However, a scheme like FOIL can still only cope with simple inter-attribute relations, for example A 6= B or C &lt; D. <p> Similarly to pruned decision trees, C4.5's rules are derived from the unpruned tree and are roughly equivalent to pruned trees in terms of classification accuracy. FOIL FOIL (First Order Inductive Learner) is another scheme developed by J. R. Quin-lan at the University of Sydney <ref> [29] </ref>. It builds on concepts found in ID3 and Michalski's AQ to generate descriptions of logical relations using a subset of first-order logic. FOIL analyses a set of positive and negative examples of some relation and produces a structural description of the relation expressed as a set of Horn clauses.
Reference: [30] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1992. </year>
Reference-contexts: These are described briefly below: C4.5 C4.5 <ref> [30] </ref> is a system for inducing rules and decision trees from a set of examples. Much of C4.5 is derived from Quinlan's earlier induction system, ID3 [28]. The basic ID3 algorithm has been tested and modified by numerous researchers since its invention [25, 39]. <p> Secondly, the heuristic used by C4.5 to evaluate the quality of tests at decision tree branches may be partly to blame. By default C4.5 uses an information-theoretic heuristic, the gain ratio criterion <ref> [30] </ref>. This is the ratio of the information gained by partitioning a set of examples according to some test, to the potential amount of information that could be generated from the same partitioning. <p> Thus, for some test X, gain ratio (X) = info gain (X)=partition info (X) (4.1) which expresses the proportion of information generated by the partition that is useful for classification purposes. The gain ratio criterion selects a test that maximises the value of this ratio. According to Quinlan <ref> [30] </ref>, the gain ratio criterion usually gives a better choice of test than the gain criterion used by ID3. However, Mingers [26] expresses some concern about the tendency of 51 4. Results and Discussion the gain ratio criterion to favour highly skewed partitionings of the examples.
Reference: [31] <author> Lawrence R. Rabiner. </author> <title> A tutorial on hidden Markov models and selected applications in speech recognition. </title> <editor> In Alex Waibel and Kai-Fu Lee, editors, </editor> <booktitle> Readings in Speech Recognition, </booktitle> <pages> pages 267-296. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: The following overview of HMM theory and applications is of necessity relatively brief. For a fuller introduction to the subject the reader should consult any of <ref> [32, 19, 31, 34] </ref>. Markov Processes A Markov process consists of a finite set of states and a set of possible transitions between those states. At regular, discrete time intervals the system undergoes a change of state, possibly back to the same state.
Reference: [32] <author> Lawrence R. Rabiner and B-H Juang. </author> <title> Fundamentals of Speech Recognition, </title> <booktitle> chapter 6, </booktitle> <pages> pages 321-389. </pages> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Background and Review of Literature consideration <ref> [32] </ref>. The time series is characterised by a parametric statistical model which is configured so as to maximise the probability that the series could have been generated by that model. <p> The following overview of HMM theory and applications is of necessity relatively brief. For a fuller introduction to the subject the reader should consult any of <ref> [32, 19, 31, 34] </ref>. Markov Processes A Markov process consists of a finite set of states and a set of possible transitions between those states. At regular, discrete time intervals the system undergoes a change of state, possibly back to the same state. <p> Background and Review of Literature to an observable event. The output of the system is not random, making it unsuitable for many problems. A Hidden Markov model extends the system to include the case where the output produced is a probabilistic function of the state. Rabiner & Juang <ref> [32] </ref> describe the resulting system as a doubly embedded stochastic process with an underlying stochastic process that is not directly observable (it is hidden) but can be observed only through another set of stochastic processes that produce the sequence of observations.
Reference: [33] <author> Lawrence R. Rabiner and Stephen E. Levinson. </author> <title> Isolated and connected word recognitiontheory and selected applications. </title> <editor> In Alex Waibel and Kai-Fu Lee, editors, </editor> <booktitle> Readings in Speech Recognition, </booktitle> <pages> pages 115-153. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: Two of the most successful techniques used recently in speech applications are dynamic time warping (DTW) and hidden Markov models (HMMs). These are described in more detail below. 2.3.1 Dynamic Time Warping Dynamic time warping <ref> [33, 35] </ref> is a template-matching recognition method based around a dynamic programming algorithm. As such, DTW is a pattern matching method only, meaning that the templates must be generated externally, either by hand or using a discovery algorithm. 11 2.
Reference: [34] <author> Lawrence R. Rabiner, Jay G. Wilpon, and Frank K. Soong. </author> <title> High performance connected digit recognition using hidden Markov models. </title> <editor> In Alex Waibel and Kai-Fu Lee, editors, </editor> <booktitle> Readings in Speech Recognition, </booktitle> <pages> pages 320-331. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: The following overview of HMM theory and applications is of necessity relatively brief. For a fuller introduction to the subject the reader should consult any of <ref> [32, 19, 31, 34] </ref>. Markov Processes A Markov process consists of a finite set of states and a set of possible transitions between those states. At regular, discrete time intervals the system undergoes a change of state, possibly back to the same state.
Reference: [35] <author> Hiroaki Sakoe and Seibi Chiba. </author> <title> Dynamic programming algorithm optimization for spoken word recognition. </title> <editor> In Alex Waibel and Kai-Fu Lee, editors, </editor> <booktitle> Readings in Speech Recognition, </booktitle> <pages> pages 159-165. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1990. </year> <note> 71 BIBLIOGRAPHY </note>
Reference-contexts: Two of the most successful techniques used recently in speech applications are dynamic time warping (DTW) and hidden Markov models (HMMs). These are described in more detail below. 2.3.1 Dynamic Time Warping Dynamic time warping <ref> [33, 35] </ref> is a template-matching recognition method based around a dynamic programming algorithm. As such, DTW is a pattern matching method only, meaning that the templates must be generated externally, either by hand or using a discovery algorithm. 11 2.
Reference: [36] <author> Robert A. </author> <title> Sherlock. </title> <type> Private e-mail communication, </type> <month> February </month> <year> 1995. </year>
Reference-contexts: Researchers at the DRC have developed an advanced dairy cow milking systemthe Ruakura Milk Harvester (RMH)that is currently deployed on around 15 farms <ref> [36] </ref>. 21 3. Experimental Methodology Custom microcontroller hardware in each milking position is used to gather basic production and health-related data about each cow, at every milking. <p> The current system maintains animal and machine performance databases to a high level of reliability and allows the data to be displayed graphically. The next stage of development is to implement intelligent analyses of these databases to identify and report events of significance to the farmer as they occur <ref> [36] </ref>. Several examples of such events are described below: Detection of cows in heat. Most dairy herd reproduction in New Zealand is now performed via artificial insemination (AI), under the supervision of the Livestock Improvement Corporation.
Reference: [37] <author> Padhraic Smyth, Michael Burl, Usama Fayyad, and Pietro Perona. </author> <title> Knowledge discovery in large image databases: Dealing with uncertainties in ground truth. </title> <editor> In Usama M. Fayyad and Ramasamy Uthurusamy, editors, </editor> <booktitle> Proceedings of KDD-94: AAAI-94 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 109-120, </pages> <address> Seattle, Washington, </address> <month> July-August </month> <year> 1994. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference: [38] <author> Kai Ming Ting. </author> <title> The problem of small disjuncts: its remedy in decision trees. </title> <editor> In Ren ee Elio, editor, </editor> <booktitle> Proceedings of the Tenth Canadian Conference on Artificial Intelligence, </booktitle> <pages> pages 91-97, </pages> <address> Banff, Alberta, </address> <month> May </month> <year> 1994. </year> <booktitle> Canadian Society for Computational Studies of Intelligence. </booktitle>
Reference-contexts: Knowledge-based schemes which analyse a single example extensively are more prone to failure when faced with inconsistent data. As mentioned above, these distinctions are not orthogonal and there is much interest in hybrid schemes which combine several techniques to produce better overall performance <ref> [38] </ref>. Most schemes operate in batch mode, but it is also possible to have interactive learners, where the user serves as a teacher, explaining new examples to the machine when the data fails to fit its existing model of the domain. <p> A complete set of results for the experiments can be found in Appendix A. Several problems that arose during the experimental work are discussed further, in particular the problems of small disjuncts <ref> [38] </ref> and highly skewed class distributions. <p> Many of the small splits will disappear from the tree during pruning, with the small groups of positive examples from these decisions then incorrectly classified as negative. Ting <ref> [38] </ref> has developed a composite learning scheme that partly alleviates the problem of small splits or small disjuncts. His method uses an instance-based learner [1] to classify test cases belonging to a small disjunct, otherwise the C4.5 decision tree is used. <p> For the particular case of C4.5 it is possible that the parameters of the tree induction algorithm could be optimised on a case-by-case basis. In general however a more fundamental solution is required. As mentioned previously Ting <ref> [38] </ref> has obtained useful results with a composite scheme using a combination of C4.5 and an instance-based learner. The success of this composite learning technique makes it a good candidate for further research in this area. The rulesets generated by FOIL performed particularly well on training data.
Reference: [39] <author> Paul E. Utgoff. </author> <title> Incremental induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 161-186, </pages> <year> 1989. </year>
Reference-contexts: These are described briefly below: C4.5 C4.5 [30] is a system for inducing rules and decision trees from a set of examples. Much of C4.5 is derived from Quinlan's earlier induction system, ID3 [28]. The basic ID3 algorithm has been tested and modified by numerous researchers since its invention <ref> [25, 39] </ref>. However, C4.5 adds several new and interesting features that are worth mentioning: * C4.5 uses a new gain ratio criterion for determining how to split the examples at each node of a decision tree. This removes ID3's strong bias towards tests with many outcomes.
Reference: [40] <author> Rhys De War and Donna Liane Neal. </author> <title> WEKA machine learning project: Cow culling. </title> <type> Working Paper 94/12, </type> <institution> Department of Computer Science, University of Waikato, Hamilton, </institution> <address> New Zealand, </address> <year> 1994. </year>
Reference-contexts: C4.5's gain-ratio criterion reacts badly to this type of distribution and tends to build decision trees containing many small disjuncts, that perform poorly in testing. This type of highly skewed data has caused similar problems in other cases studies undertaken by the WEKA projects <ref> [40] </ref>. Clearly this is a common and significant problem when working with real-world datasets, and a methodology needs to be developed to address it. For the particular case of C4.5 it is possible that the parameters of the tree induction algorithm could be optimised on a case-by-case basis.
Reference: [41] <author> Steve J. Young. </author> <title> HTK: Hidden Markov Model Toolkit V1.2 Installation Guide. </title> <institution> Cambridge University Engineering Department Speech Group, </institution> <address> Cam-bridge, England, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: to investigate whether or not these techniques could be used to form useful descriptions of the multi-dimensional data in the herd milking database. 3.4.1 The Hidden Markov Model Toolkit (HTK) HTK is a comprehensive package of hidden Markov model research software developed by the Cambridge University Engineering Department Speech Group <ref> [41, 42] </ref>. The HTK system is intended primarily for speech recognition applications, and contains numerous features that are specific to this purpose. However, the heart of HTK is a reasonably general Markov modelling package that can in theory be used to model time-sequenced processes other than speech.
Reference: [42] <author> Steve J. Young. </author> <title> HTK: Hidden Markov Model Toolkit V1.2 Reference Manual. </title> <institution> Cambridge University Engineering Department Speech Group, </institution> <address> Cam-bridge, England, </address> <month> December </month> <year> 1990. </year> <title> 72 A. Experimental Results </title>
Reference-contexts: to investigate whether or not these techniques could be used to form useful descriptions of the multi-dimensional data in the herd milking database. 3.4.1 The Hidden Markov Model Toolkit (HTK) HTK is a comprehensive package of hidden Markov model research software developed by the Cambridge University Engineering Department Speech Group <ref> [41, 42] </ref>. The HTK system is intended primarily for speech recognition applications, and contains numerous features that are specific to this purpose. However, the heart of HTK is a reasonably general Markov modelling package that can in theory be used to model time-sequenced processes other than speech.
References-found: 43

