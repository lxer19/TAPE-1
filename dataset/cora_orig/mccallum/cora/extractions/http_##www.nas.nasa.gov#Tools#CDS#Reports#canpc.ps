URL: http://www.nas.nasa.gov/Tools/CDS/Reports/canpc.ps
Refering-URL: http://www.cs.washington.edu/education/courses/590o/
Root-URL: 
Title: A Simple and Efficient Process and Communication Abstraction for Network Operating Systems  
Author: David C. DiNucci 
Address: M/S T27A-2 Moffett Field, CA 94035-1000  
Affiliation: MRJ, Inc., NAS Systems Division NASA Ames Research Center,  
Abstract: Process and communication abstractions in current uniprocessor or SMP OSs are poorly suited for processors which may be connected by relatively high-latency, low-bandwidth interconnects. Cooperative Data Sharing (CDS) is a subroutine-level interface designed to target both shared-memory and distributed-memory multiprocessors. CDS1 supports a single simple communication abstraction in which data is not copied unless required by the user program or the target architecture, yet it still supports the use of data forwarding to compensate for high-latency interconnects (when the consuming process is known in advance) and/or remote retrieval of data for demand-driven applications. The ability to write portable heterogeneous programs is also supported, as is communication-initiated subroutine execution. Its utility and small size makes it well suited to partial kernel-level implementation.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, W. Zwaenepoel, "TreadMarks: </author> <title> Shared Memory Computing on Networks of Workstations", </title> <journal> IEEE Computer, </journal> <volume> Vol. 29,No. 2, </volume> <pages> pp. 18-28, </pages> <month> February </month> <year> 1996. </year>
Reference: 2. <author> W. C. Athas, C. Seitz, </author> <title> "Multicomputers: Message-Passing Concurrent Computers," </title> <note> Computer 21(8), pp 9-24 (August 1988) </note>
Reference-contexts: The concurrently-developed "Remote Queues" (RQ) system [4] similarly provides global access to queues. The communication model is also similar to that used in the Reactive Kernel (RK) <ref> [2] </ref> and Zipcode [18], with the addition of shared region access and remote region retrieval.
Reference: 3. <author> B. N. Bershad, M. J. Zekauskas, </author> <title> "Shared Memory Parallel Programming with Entry Consistency for Distributed Memory Multiprocessors", </title> <institution> CMU-CS-91-170, Carnegie Mellon University, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: In some other systems, like Mach <ref> [3] </ref> and Treadmarks [15], an MMU detects when one of the processes attempts to modify physically shared data, and a copy could be made at that time if necessary.
Reference: 4. <author> E. Brewer, F. Chong, L. Liu, S. Sharma, J. Kubiatowicz, </author> <title> "Remote Queues: Exposing Message Queues for Optimization and Atomicity", </title> <booktitle> SPAA `95, </booktitle> <address> Santa Barbara CA, </address> <publisher> ACM, pp.42-53 </publisher>
Reference-contexts: The handler model is similar to the hrecv function in the Intel NX library [12], and the notion of using high-priority messages as a replacement for interrupts was used in the Occam language [14]. The concurrently-developed "Remote Queues" (RQ) system <ref> [4] </ref> similarly provides global access to queues. The communication model is also similar to that used in the Reactive Kernel (RK) [2] and Zipcode [18], with the addition of shared region access and remote region retrieval.
Reference: 5. <author> H. K. J. Chu, </author> <title> "Zero-Copy TCP in Solaris", </title> <booktitle> Proc. USENIX 1996 Annual Technical Conf., </booktitle> <address> San Diego, </address> <month> January </month> <year> 1996, </year> <booktitle> USENIX </booktitle>
Reference-contexts: Some similarities also exist to Cooperative Shared Memory [11]. Tread-marks also has many similar goals to CDS1. Research on zero-copy communica Fig. 2. Bandwidths for various region sizes tion has also been performed by the traditional OS community in the context of TCP/IP <ref> [5] </ref>. The handler model is similar to the hrecv function in the Intel NX library [12], and the notion of using high-priority messages as a replacement for interrupts was used in the Occam language [14]. The concurrently-developed "Remote Queues" (RQ) system [4] similarly provides global access to queues.
Reference: 6. <author> D. DiNucci, </author> <note> "CDS", http://www.nas.nasa.gov/NAS/Tools/Projects/CDS/ </note>
Reference-contexts: This paper will describe an interface called CDS1, the kernel layer of a package called Cooperative Data Sharing, or CDS <ref> [6] </ref> [7], as a virtual machine which will allow the construction of multi-process programs which can portably and efficiently execute on one or more processors which may be very close (e.g. sharing memory) or very distant (e.g. over a wide-area network).
Reference: 7. <author> D. DiNucci, </author> <title> "Cooperative Data Sharing: A Layered Approach to an Architecture-Independent Message-Passing Interface", </title> <booktitle> 2nd MPI Developer's Conf., </booktitle> <address> Notre Dame, </address> <month> July </month> <year> 1996, </year> <journal> IEEE, </journal> <pages> pp. 58-65 </pages>
Reference-contexts: This paper will describe an interface called CDS1, the kernel layer of a package called Cooperative Data Sharing, or CDS [6] <ref> [7] </ref>, as a virtual machine which will allow the construction of multi-process programs which can portably and efficiently execute on one or more processors which may be very close (e.g. sharing memory) or very distant (e.g. over a wide-area network).
Reference: 8. <author> I. Foster, C. Kesselman, R. Olson, and S. Tuecke, </author> <title> "Nexus: An interoperability toolkit for parallel and distributed computer systems", </title> <institution> ANL/MCS-TM-189, Ar-gonne National Laboratory, </institution> <year> 1994. </year>
Reference-contexts: Generic Active Messages (GAM) [17] and Nexus <ref> [8] </ref> have traditional message-passing semantics, but are also designed as a substrate to higher-level interfaces. 7 Conclusions CDS1 demonstrates a single communication mechanism which possesses many of the advantages of both message-passing (e.g. compensation for latency by allowing producers to forward data to consumers, queuing of communication, and automatic handler invocation)
Reference: 9. <author> D. Gelernter, </author> <title> "Generative Communication in Linda", </title> <journal> ACM ToPLaS, </journal> <volume> 1 (1985), </volume> <pages> pp 80-112 </pages>
Reference-contexts: The communication model is also similar to that used in the Reactive Kernel (RK) [2] and Zipcode [18], with the addition of shared region access and remote region retrieval. Comparisons can also be made with the "Generative Communication" of Linda <ref> [9] </ref>, replacing associative matching with explicit association through cell names, though Linda does not facilitate the sharing of messages, the elimination of copying in shared memory, or the ability to explicitly forward messages to their destination.
Reference: 10. <author> A. Geist et. al, </author> <title> "PVM: Parallel Virtual Machine", </title> <publisher> MIT Press, </publisher> <year> 1994, </year> <note> ISBN 0-262-57108-0 </note>
Reference-contexts: Currently, the programmer is (and must be) cognizant of the individual machines and the individual copies of the operating system. Some higher-level tools, such as PVM <ref> [10] </ref> and P4, have been created atop traditional operating systems to help deal with the complexities of creating, managing, and communicating between processes on distributed processors, but they have succeeded in spite of their host operating systems rather than because of them, and their advantages are realized only during the time
Reference: 11. <author> M. Hill, J. Larus, S. Reinhardt and D. Wood, </author> <title> "Cooperative Shared Memory: Software and Hardware for Scalable Multiprocessors", </title> <journal> ACM TOCS, </journal> <volume> 11(4) </volume> <pages> 300-318, </pages> <month> Nov. </month> <year> 1993 </year>
Reference-contexts: Some similarities also exist to Cooperative Shared Memory <ref> [11] </ref>. Tread-marks also has many similar goals to CDS1. Research on zero-copy communica Fig. 2. Bandwidths for various region sizes tion has also been performed by the traditional OS community in the context of TCP/IP [5].
Reference: 12. <institution> Paragon User's Guide, Intel Corporation. </institution>
Reference-contexts: Tread-marks also has many similar goals to CDS1. Research on zero-copy communica Fig. 2. Bandwidths for various region sizes tion has also been performed by the traditional OS community in the context of TCP/IP [5]. The handler model is similar to the hrecv function in the Intel NX library <ref> [12] </ref>, and the notion of using high-priority messages as a replacement for interrupts was used in the Occam language [14]. The concurrently-developed "Remote Queues" (RQ) system [4] similarly provides global access to queues.
Reference: 13. <author> K. Johnson, M. F. Kaashoek, and D. Wallach, </author> <title> "CRL: High-Performance All-Software Distributed Shared Memory", </title> <type> TR LCS-TM-517, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: It is related to distributed shared-memory [16] with release consistency [15]. A similar approach was taken in the C Region Library (CRL) <ref> [13] </ref>, but queues and region pre-migration (i.e. where the data producer moves the data to the processor of the next consumer) are not available there and only SPMD applications are supported. Some similarities also exist to Cooperative Shared Memory [11]. Tread-marks also has many similar goals to CDS1.
Reference: 14. <author> G. Jones, M. </author> <title> Goldsmith, </title> <booktitle> "Programming in occam 2", Prentice-Hall (1988) </booktitle>
Reference-contexts: The handler model is similar to the hrecv function in the Intel NX library [12], and the notion of using high-priority messages as a replacement for interrupts was used in the Occam language <ref> [14] </ref>. The concurrently-developed "Remote Queues" (RQ) system [4] similarly provides global access to queues. The communication model is also similar to that used in the Reactive Kernel (RK) [2] and Zipcode [18], with the addition of shared region access and remote region retrieval.
Reference: 15. <author> P. Keleher, A. Cox, S. Dwarkadas, W. Zwaenepoel, </author> <title> "An Evaluation of Software-Based Release Consistent Protocols", </title> <note> to appear JPDC. </note>
Reference-contexts: In some other systems, like Mach [3] and Treadmarks <ref> [15] </ref>, an MMU detects when one of the processes attempts to modify physically shared data, and a copy could be made at that time if necessary. CDS1 instead simply requires the user to call a special function before modifying communicated data, after which any number of modifications can be made. <p> It is related to distributed shared-memory [16] with release consistency <ref> [15] </ref>. A similar approach was taken in the C Region Library (CRL) [13], but queues and region pre-migration (i.e. where the data producer moves the data to the processor of the next consumer) are not available there and only SPMD applications are supported.
Reference: 16. <author> K. Li, P. Hudak, </author> <title> "Memory Coherence in Shared Virtual Memory Systems", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4), </volume> <pages> pp 341-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: It is related to distributed shared-memory <ref> [16] </ref> with release consistency [15]. A similar approach was taken in the C Region Library (CRL) [13], but queues and region pre-migration (i.e. where the data producer moves the data to the processor of the next consumer) are not available there and only SPMD applications are supported.
Reference: 17. <author> L. Liu, D. Culler, </author> <title> "Evaluation of the Intel Paragon on Active Message Communication", </title> <booktitle> Proc. Intel Supercomputer Users Group (ISUG) Conf., </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Generic Active Messages (GAM) <ref> [17] </ref> and Nexus [8] have traditional message-passing semantics, but are also designed as a substrate to higher-level interfaces. 7 Conclusions CDS1 demonstrates a single communication mechanism which possesses many of the advantages of both message-passing (e.g. compensation for latency by allowing producers to forward data to consumers, queuing of communication, and
Reference: 18. <author> A. Skjellum, A., and C. H. </author> <title> Still, "Zipcode and the Reactive Kernel for the Caltech Intel Delta prototype and nCUBE/2," </title> <booktitle> in Proc. Sixth Dist. Memory Computing Conf. (DMCC6), </booktitle> <pages> pages 26-33. </pages> <publisher> IEEE Comp. Society, Los Alamitos, </publisher> <address> CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The concurrently-developed "Remote Queues" (RQ) system [4] similarly provides global access to queues. The communication model is also similar to that used in the Reactive Kernel (RK) [2] and Zipcode <ref> [18] </ref>, with the addition of shared region access and remote region retrieval.
Reference: 19. <author> M. Snir, S. Otto, S. Huss-Lederman, D. Walker, J. Dongarra, </author> <title> "MPI: The Complete Reference", </title> <publisher> MIT Press, </publisher> <year> 1994, </year> <note> ISBN 0-262-57104-8. </note>
Reference-contexts: The goal, then, is to extend the virtual machine abstraction supported by an operating system into one which can span several physical machines. Although tools like PVM and MPI <ref> [19] </ref> provide some experience on which to base some of the functionality required, these interfaces themselves are not suitable.
References-found: 19

