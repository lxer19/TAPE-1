URL: http://www.cs.msu.edu/~enbody/jpdc2.ps
Refering-URL: http://www.cs.msu.edu/~enbody/
Root-URL: http://www.cs.msu.edu
Email: crs@msu.edu, enbody@cps.msu.edu  petersen@kai.com  
Title: ASAT 07/03/96 Page 1 Managing the Overall Balance of Operating System Threads on a MultiProcessor
Author: Authors: Charles Severance and Richard Enbody Paul Petersen Kuck 
Note: This work is based on work supported by the National Science Foundation under Grant No MIP-0209402.  
Address: East Lansing, MI 48824  IL 61820,  
Affiliation: Department of Computer Science Michigan State University  and Associates, Champaign,  
Abstract: A multi-threaded runtime environment which supports lightweight threads can be used to support many aspects of parallel processing including: virtual processors, concurrent objects, and compiler runtime environments. This work focuses on the area of compiler runtime environments. Such a library must depend on the underlying thread mechanism provided by the operating system. Threads working on compute intensive tasks work best when there is one thread performing real work on each processor. Matching the number of running threads to the number of processors can yield both good wall-clock run time and good overall machine utilization. The challenge is to schedule threads to maintain one running thread per processor by dynamically adjusting the number of threads as the load on the machine changes. It is generally not efficient to involve the operating system during a thread switch between lightweight threads. As such, a lightweight thread run-time environemnt must operate within the parameters provided by the operating system. This work identifies the situations on a multiprocessing system when the operation of a lightweight thread environment might be negatively impacted by other threads running on the system. The performance impact of these other threads is measured. A solution called Automatic Self Allocating Threads (ASAT) is proposed as a way to balance the number of active threads across a multiprocessing system. Our approach is significant in that it is designed for a system running multiple jobs, and it considers the load of all running jobs in its thread allocation. In addition, the overhead of ASAT is sufficiently small so that the run times of all jobs improve when it is in use. The improvements are achieved by eliminating contention for resources by jobs on the system. Furthermore, our approach uses self-scheduling so it is implemented in a runtime environment rather than in an operating system. Finally, the self-scheduling means that jobs need not all be scheduled by ASAT. 
Abstract-found: 1
Intro-found: 1
Reference: [CSERArch] <author> Convex Computer Corporation, </author> <title> "Convex Architecture Reference Manual (C-Series)", Document DHW-300, </title> <month> April </month> <year> 1992. </year>
Reference-contexts: As we point out in this paper, not having a dedicated system can seriously degrade the effectiveness of the FTS approach. Other dynamic, runtime, thread management techniques which are geared toward compiler detected parallelism include: Automatic Self-Adjusting Processors (ASAP) from Convex <ref> [CSERArch] </ref> and Autotasking on Cray Research [Cray] computers. Convex ASAP is based on hardware extensions to the architecture and requires very little runtime library support. Cray's Autotasking is a software based approach and is supported in the runtime library and the operating system scheduler.
Reference: [CONEXMP] <author> Convex Computer Corporation, </author> <title> "Convex Architecture Reference Manual (Exemplar)", Document DHW-940, </title> <month> March </month> <year> 1993. </year>
Reference-contexts: A previous study of the feasibility of Automatic Self-Allocating Threads (ASAT) for the Convex Exemplar <ref> [CONEXMP] </ref> was done in [SevEn95]. 4 ASAT Design The general goal of our Automatic Self-Allocating Threads (ASAT) is to eliminate thread imbalance by detecting thrashing and then dynamically reducing the number of active threads to achieve balanced execution over the long term.
Reference: [Cray] <author> Cray Research, </author> <title> CF77 Compiling System, Volume 4: Parallel Processing Guide. </title>
Reference-contexts: As we point out in this paper, not having a dedicated system can seriously degrade the effectiveness of the FTS approach. Other dynamic, runtime, thread management techniques which are geared toward compiler detected parallelism include: Automatic Self-Adjusting Processors (ASAP) from Convex [CSERArch] and Autotasking on Cray Research <ref> [Cray] </ref> computers. Convex ASAP is based on hardware extensions to the architecture and requires very little runtime library support. Cray's Autotasking is a software based approach and is supported in the runtime library and the operating system scheduler. The Cray Autotasking product is similar to our work.
Reference: [Guide] <author> Kuck & Associates Inc., </author> <note> "Guide(tm) Reference Manual, Version 2.0",Document #9603002, </note> <month> March </month> <year> 1996. </year>
Reference-contexts: The three "approaches" are the same code rearranged slightly for different scheduling. All three represent the same amount of work. The experiments in this paper were performed using a experimental version of the Guide parallel programing environment from Kuck & Associates, Inc. <ref> [Guide] </ref>. In an ASAT run, the job makes a call to asat_adjust_threads before each instantiation of the parallel loop. As a result, the jobs with the smaller grainsize (defined below) will have proportionally more calls to asat_adjust_threads. The ASAT_EVAL_TIME parameter is set to one second.
Reference: [LiuSal92] <author> J. Liu, V. Saletore, T. Lewis, </author> <title> "Scheduling Parallel Loops with Variable Length Iteration Execution Times of Parallel Computers," </title> <booktitle> Proc. of ISMM 5th Int. Conf. on Parallel and Dist. Systems, </booktitle> <year> 1992. </year>
Reference-contexts: A number of scheduling techniques have been proposed and implemented. An excellent survey of these techniques is presented in [LiuSal93]. These techniques include Pure Self Scheduling (PSS), Chunk Self Scheduling (CSS), Guided Self Scheduling (GSS) [PolKuck87], Trapezoidal Self Scheduling (TSS) [TzenNi91], and Safe Self Scheduling (SSS) <ref> [LiuSal92] </ref>. The implementation of these techniques on most shared-memory parallel processors works with a fixed number of threads determined when the program is initially started. For the purpose of this paper, we call this technique Fixed Thread Scheduling (FTS).
Reference: [LiuSal93] <author> J. Liu, V. Saletore, </author> <title> "Self Scheduling on Distributed-Memory Machines," </title> <journal> IEEE Supercomputing'93, </journal> <pages> pp. 814-823, </pages> <year> 1993. </year>
Reference-contexts: The goal is to have balanced execution times on the processors while minimizing the overhead for partitioning the iterations. A number of scheduling techniques have been proposed and implemented. An excellent survey of these techniques is presented in <ref> [LiuSal93] </ref>. These techniques include Pure Self Scheduling (PSS), Chunk Self Scheduling (CSS), Guided Self Scheduling (GSS) [PolKuck87], Trapezoidal Self Scheduling (TSS) [TzenNi91], and Safe Self Scheduling (SSS) [LiuSal92].
Reference: [MoBo90] <author> J. C. Mogul and A. Borg, </author> <title> The Effect of Context Switches on Cache Performance, </title> <institution> DEC Western Research Laboratory TN-16, </institution> <month> Dec., </month> <year> 1990. </year> <note> http://www.research.digital.com/wrl/techreports/abstracts/TN-16.html </note>
Reference-contexts: In addition, they provide an excellent survey of related work. DO ITIME=1,INFINITY ... DO PARALLEL IPROB=1,PROBSIZE ... ENDDO ... ENDDO ASAT - 07/03/96 Page 3 As the speed of the CPU's has increased, the problem of a context switch corrupting cache has become an increasing performance impact. In <ref> [MoBo90] </ref>, when a compute-bound process was context switched on a cache-based system, the performance of the application was significantly impacted for the next 100,000 cycles after the process regained the processor. The context switch still had a small negative impact on performance up to 400,000 cycles after the context switch.
Reference: [PolKuck87] <author> C. Polychronopoulos, D. J. Kuck, </author> <title> "Guided Self Scheduling: A Practical Scheduling Scheme for Parallel Supercomputers," </title> <journal> IEEE Transactions on Computers, </journal> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: A number of scheduling techniques have been proposed and implemented. An excellent survey of these techniques is presented in [LiuSal93]. These techniques include Pure Self Scheduling (PSS), Chunk Self Scheduling (CSS), Guided Self Scheduling (GSS) <ref> [PolKuck87] </ref>, Trapezoidal Self Scheduling (TSS) [TzenNi91], and Safe Self Scheduling (SSS) [LiuSal92]. The implementation of these techniques on most shared-memory parallel processors works with a fixed number of threads determined when the program is initially started. For the purpose of this paper, we call this technique Fixed Thread Scheduling (FTS).
Reference: [SevEn95] <author> Severance C, Enbody R, Wallach S, </author> <title> Funkhouser B, </title> <booktitle> "Automatic Self Allocating Threads (ASAT) on the Convex Exemplar" Proceedings 1995 International Conference on Parallel Processing (ICPPP95), </booktitle> <month> August </month> <year> 1995, </year> <note> pages I-24 - I-31. </note>
Reference-contexts: A previous study of the feasibility of Automatic Self-Allocating Threads (ASAT) for the Convex Exemplar [CONEXMP] was done in <ref> [SevEn95] </ref>. 4 ASAT Design The general goal of our Automatic Self-Allocating Threads (ASAT) is to eliminate thread imbalance by detecting thrashing and then dynamically reducing the number of active threads to achieve balanced execution over the long term.
Reference: [SGIArch] <author> Silicon Graphics, Inc., </author> <title> "Symmetric Multiprocessing Systems," </title> <type> Technical Report, </type> <year> 1993. </year>
Reference-contexts: We study three techniques and compare them under a variety of system loads. We also vary the size of the applications tested. Experiment Description The experiments in this paper were generated on a four-processor SGI Challenge-L <ref> [SGIArch] </ref> with MIPS-R4400 processors running at 150Mhz with a combined memory of 384MB. Each R4400 has a 32K L1 Cache (16K instruction and 16K data), and a 1MB L2 cache.
Reference: [TukGup89] <author> A. Tucker and A. </author> <title> Gupta , "Process Control and Scheduling Issues for Multiprogrammed Shared-Memory Multiprocessors," </title> - <booktitle> ACM SOSP Conf.-, </booktitle> <year> 1989, </year> <editor> p. </editor> <volume> 159 - 166. </volume>
Reference-contexts: Our approach does not necessarily apply to all multi-threaded environments. Database or network server environments may want to have significantly more operating system threads than available processor resources in order to mask latencies due to I/O from the network, disk or other sources. 3 PREVIOUS WORK In <ref> [TukGup89] </ref> the problem of matching the overall systemwide number of threads to the number of processors was studied on an Encore Multimax. Their applications used explicit parallelism and a thread library. The thread library communicated with a central server to insure overall thread balance.

References-found: 11

