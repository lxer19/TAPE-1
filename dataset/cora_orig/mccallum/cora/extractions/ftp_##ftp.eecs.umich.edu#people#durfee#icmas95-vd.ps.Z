URL: ftp://ftp.eecs.umich.edu/people/durfee/icmas95-vd.ps.Z
Refering-URL: http://ai.eecs.umich.edu/diag/RMM.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fjmvidal,durfeeg@umich.edu  
Title: Recursive Agent Modeling Using Limited Rationality  
Author: Jose M. Vidal and Edmund H. Durfee 
Keyword: Algorithms for multi-agent interaction in time-constrained systems; Conceptual and theoretical  
Note: foundations of multi-agent systems.  
Address: Ann Arbor, Michigan 48109-2122.  
Affiliation: Artificial Intelligence Laboratory University of Michigan  
Abstract: We present an algorithm that an agent can use for determining which of its nested, recursive models of other agents are important to consider when choosing an action. Pruning away less important models allows an agent to take its "best" action in a timely manner, given its knowledge, computational capabilities, and time constraints. We describe a theoretical framework, based on situations, for talking about recursive agent models and the strategies and expected strategies associated with them. This framework allows us to rigorously define the gain of continuing deliberation versus taking action. The expected gain of computational actions is used to guide the pruning of the nested model structure. We have implemented our approach on a canonical multi-agent problem, the pursuit task, to illustrate how real-time, multi-agent decision-making can be based on a principled, combinatorial model. Test results show a marked decrease in deliberation time while maintaining a good performance level. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Durfee, E. H.; Gmytrasiewicz, P. J.; and Rosenschein, J. S. </author> <year> 1994. </year> <title> The utility of embedded communications and the emergence of protocols. </title> <booktitle> In Proceedings of the 13th International Distributed Artificial Intelligence Workshop. </booktitle>
Reference-contexts: Gmytrasiewicz, & Rosenschein 1994) (Gmytrasiewicz & Durfee 1993); relying on learned patterns of action <ref> (Sen & Durfee 1994) </ref> risks jumping to incorrect expectations when environmental variations occur; and using deeper models of other agents can be more accurate but extremely time-consuming (Gmytrasiewicz 1992). In this paper, we concentrate on coordinated decision-making using deeper, nested models of agents.
Reference: <author> Durfee, E. H.; Lee, J.; and Gmytrasiewicz, P. J. </author> <year> 1993. </year> <title> Overeager reciprocal rationality and mixed strategy equilibria. </title> <booktitle> In Proceedings of the eleventh National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: While each of these approaches has its merits, each also involves some cost or risk: effective communication requires careful decision-making about what to say, when to say it, and whether to trust what is heard (Durfee, fl Supported, in part, by NSF grant IRI-9158473. Gmytrasiewicz, & Rosenschein 1994) <ref> (Gmytrasiewicz & Durfee 1993) </ref>; relying on learned patterns of action (Sen & Durfee 1994) risks jumping to incorrect expectations when environmental variations occur; and using deeper models of other agents can be more accurate but extremely time-consuming (Gmytrasiewicz 1992).
Reference: <author> Gasser, L.; Rouquetter, N. F.; Hill, R. W.; and Lieb, J. </author> <year> 1989. </year> <title> Representing and using organizational knowledge in distributed ai systems. </title> <editor> In Gasser, L., and Huhns, M. N., eds., </editor> <booktitle> Distributed Artificial Intelligence, </booktitle> <volume> volume 2. </volume> <publisher> Morgan Kauffman Publishers. </publisher> <pages> 55-78. </pages>
Reference: <author> Gmytrasiewicz, P. J., and Durfee, E. H. </author> <year> 1993. </year> <title> Toward a theory of honesty and trust among communicating autonomous agents. Group Decision and Negotiation 2 </title> <type> 237-258. </type>
Reference-contexts: While each of these approaches has its merits, each also involves some cost or risk: effective communication requires careful decision-making about what to say, when to say it, and whether to trust what is heard (Durfee, fl Supported, in part, by NSF grant IRI-9158473. Gmytrasiewicz, & Rosenschein 1994) <ref> (Gmytrasiewicz & Durfee 1993) </ref>; relying on learned patterns of action (Sen & Durfee 1994) risks jumping to incorrect expectations when environmental variations occur; and using deeper models of other agents can be more accurate but extremely time-consuming (Gmytrasiewicz 1992).
Reference: <author> Gmytrasiewicz, P. J.; Durfee, E. H.; and Wehe, D. K. </author> <year> 1991. </year> <title> A decision-theoretic approach to coordinating multiagent interactions. </title> <booktitle> In Proceedings of the twelfth international joint conference on artificial intelligence. </booktitle>
Reference: <author> Gmytrasiewicz, P. J. </author> <year> 1992. </year> <title> A Decision-Theoretic Model of Coordination and Communication in Autonomous Systems (Reasoning Systems). </title> <type> Ph.D. Dissertation, </type> <institution> University of Michigan. </institution>
Reference-contexts: Gmytrasiewicz, & Rosenschein 1994) (Gmytrasiewicz & Durfee 1993); relying on learned patterns of action (Sen & Durfee 1994) risks jumping to incorrect expectations when environmental variations occur; and using deeper models of other agents can be more accurate but extremely time-consuming <ref> (Gmytrasiewicz 1992) </ref>. In this paper, we concentrate on coordinated decision-making using deeper, nested models of agents. Because these models allow an agent to fully represent and use all of its available knowledge about itself and others, the quality of its decision-making can be high.
Reference: <author> Korf, R. E. </author> <year> 1992. </year> <title> A simple solution to pursuit games. </title> <booktitle> In Proceedings of the 11th International Distributed Artificial Intelligence Workshop. </booktitle>
Reference-contexts: The pursuit task has been investigated in Distributed AI (DAI) and many different methods have been devised for solving it <ref> (Korf 1992) </ref> (Stephens & Merx 1990) (Levy & Rosenschein 1992). These either impose specific roles on the predators, spend much time computing, or fail because of lack of coordination.
Reference: <author> Levy, R., and Rosenschein, J. S. </author> <year> 1992. </year> <title> A game theo-retic approach to the pursuit problem. </title> <booktitle> In Proceedings of the 11th International Distributed Artificial Intelligence Workshop. </booktitle>
Reference-contexts: The pursuit task has been investigated in Distributed AI (DAI) and many different methods have been devised for solving it (Korf 1992) (Stephens & Merx 1990) <ref> (Levy & Rosenschein 1992) </ref>. These either impose specific roles on the predators, spend much time computing, or fail because of lack of coordination.
Reference: <author> Montgomery, T. A., and Durfee, E. H. </author> <year> 1990. </year> <title> Using mice to study intelligent dynamic coordination. </title> <booktitle> In Proceedings of IEEE Conference on Tools for AI. </booktitle>
Reference-contexts: The definition of what situations are similar is heuristic and determined by the programmer. Implementation of Pursuit Task The original algorithm has been implemented in a simulation of the pursuit task, using the MICE system <ref> (Montgomery & Durfee 1990) </ref>. The experiments showed some promising results. The overall performance of the agents was maintained while the total number of expanded nodes was reduced by an order of magnitude.
Reference: <author> Russell, S., and Wefald, E. </author> <year> 1991. </year> <title> Do The Right Thing. </title> <address> Cambridge, Massachusetts: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: The value of r can either be a situation (r 2 S) or, if the modeling agent has no more knowledge, it can be the Zero Knowledge strategy (r = ZK). Notation and Formalisms: Our implementation of limited rationality and our notation closely parallels Russell and Wefald's work <ref> (Russell & Wefald 1991) </ref>, although with some major differences as will be pointed out later. We define a partially expanded situation as a subset of a situation where only some of the nodes have been expanded.
Reference: <author> Sen, S., and Durfee, E. H. </author> <year> 1994. </year> <title> Adaptive surrogate agents. </title> <booktitle> In Proceedings of the 13th International Distributed Artificial Intelligence Workshop. </booktitle>
Reference-contexts: Gmytrasiewicz, & Rosenschein 1994) (Gmytrasiewicz & Durfee 1993); relying on learned patterns of action <ref> (Sen & Durfee 1994) </ref> risks jumping to incorrect expectations when environmental variations occur; and using deeper models of other agents can be more accurate but extremely time-consuming (Gmytrasiewicz 1992). In this paper, we concentrate on coordinated decision-making using deeper, nested models of agents.
Reference: <author> Stephens, L. M., and Merx, M. B. </author> <year> 1990. </year> <title> The effect of agent control strategy on the performance of a DAI pursuit problem. </title> <booktitle> In Proceedings of the 9th International Distributed Artificial Intelligence Workshop. </booktitle>
Reference-contexts: The pursuit task has been investigated in Distributed AI (DAI) and many different methods have been devised for solving it (Korf 1992) <ref> (Stephens & Merx 1990) </ref> (Levy & Rosenschein 1992). These either impose specific roles on the predators, spend much time computing, or fail because of lack of coordination.
Reference: <author> Vidal, J. M., and Durfee, E. H. </author> <year> 1994. </year> <title> Agent modeling methods using limited rationality. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> 1495. </pages>
References-found: 13

