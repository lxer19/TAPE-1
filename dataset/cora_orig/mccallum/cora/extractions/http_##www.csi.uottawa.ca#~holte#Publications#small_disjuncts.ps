URL: http://www.csi.uottawa.ca/~holte/Publications/small_disjuncts.ps
Refering-URL: http://www.csi.uottawa.ca/~holte/Publications/index.html
Root-URL: 
Title: Concept Learning and the Problem of Small  
Author: Robert C. Holte Liane E. Acker IBM-Austin Bruce W. Porter 
Note: Support for this research was provided by the Army Research Office under grant ARO-DAAG29-84-K-0060 and the National Science Foundation under grant IRI-8620052.  
Address: Ottawa, Canada K1N 6N5  Austin, Texas 78712  
Affiliation: Computer Science Dept. University of Ottawa  Department of Computer Sciences University of Texas at Austin  
Date: March 31, 1995  
Pubnum: Disjuncts  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [Ack88] <author> Liane E. Acker. </author> <title> Varying the degree of generalization in concept learning: An empirical study. </title> <type> Technical Report AI88-89, </type> <institution> Computer Sciences Department, University of Texas at Austin, </institution> <address> USA 78712, </address> <year> 1988. </year>
Reference-contexts: CN2, using each bias, was run on the training set. The definitions produced were evaluated using the entire dataset. This procedure was repeated for 9 independently drawn training sets. The cumulative results of these 9 runs are given in Table 4 (see <ref> [Ack88] </ref> for more details). CN2's original bias is the maximum generality bias. An inductive system using this bias, having decided to create a disjunct that matches a particular set of training examples, selects a maximally general disjunct that matches those examples and no others. <p> Appendix: The Sources of Data Used in Table 1 The definitions induced by METADENDRAL are from [BSW + 76]. The definitions induced by CN2 in the chess endgame domain are original <ref> [Ack88] </ref>. The definitions induced by CN2 in the lymphography domain were provided by Peter Clark, of the Turing Institute (Glasgow). Certain properties of these definitions are reported in [CN87]. In both these domains, there existed definitions based on several different training sets.
Reference: [BFOS84] <author> Leo Breiman, Jerome H. Friedman, Richard A. Olshen, and Charles J. Stone. </author> <title> Classification and Regression Trees. </title> <booktitle> Wadsworth International Group, </booktitle> <address> Belmont, California, </address> <year> 1984. </year>
Reference-contexts: 1 The Nmin parameter in CART <ref> [BFOS84] </ref> is this type of threshold. ASSISTANT [CKB87] specifies this threshold as a percentage of the original training set. <p> In both CART and ASSISTANT this cutoff is used in building a decision tree that is subsequently pruned. 5 Approach 2: Eliminate Undesirable Disjuncts Techniques that directly measure, or estimate, the significance and error rate of disjuncts are used in several systems (e.g., CN2, CART <ref> [BFOS84] </ref>, ASSISTANT [CKB87], and recent versions of ID3). These techniques reliably eliminate undesirable large disjuncts (i.e., ones that are not meaningful, or have a high error rate), but, as currently used, do not reliably eliminate undesirable small disjuncts.
Reference: [BPW87] <author> E. Ray Bareiss, Bruce W. Porter, and Craig C. Wier. Protos: </author> <title> An exemplar-based learning apprentice. In Pat Langley, editor, </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 12-23. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California, </address> <year> 1987. </year>
Reference-contexts: This gives larger values for coverage than alternative definitions, such as the number of examples matched by the disjunct and no other disjunct. The definitions induced by Protos were provided by Ray Bareiss, of Vanderbilt University. Certain properties of these definitions are reported in <ref> [BPW87] </ref>. Protos is an incremental, exemplar-based learning system. Unlike all the other systems surveyed, which are nonincre-mental and rule-based, Protos does not attempt to minimize the number of disjuncts in the definitions it produces.
Reference: [BSW + 76] <author> Bruce G. Buchanan, D.H. Smith, W.C. White, </author> <title> R.J. </title> <editor> Gritter, E.A. Feigenbaum, J. Lederberg, and Carl Djerassi. </editor> <title> Applications of artificial intelligence for chemical inference. 22. automatic rule formation in mass spectrometry by means of the Meta-DENDRAL program. </title> <journal> Journal of the American Chemical Society, </journal> <volume> 98(20) </volume> <pages> 6168-6178, </pages> <year> 1976. </year>
Reference-contexts: Appendix: The Sources of Data Used in Table 1 The definitions induced by METADENDRAL are from <ref> [BSW + 76] </ref>. The definitions induced by CN2 in the chess endgame domain are original [Ack88]. The definitions induced by CN2 in the lymphography domain were provided by Peter Clark, of the Turing Institute (Glasgow). Certain properties of these definitions are reported in [CN87].
Reference: [CKB87] <author> B. Cestnik, I. Kononenko, and I. Bratko. </author> <title> ASSISTANT 86: A knowledge-elicitation tool for sophisticated users. </title> <editor> In Ivan Bratko and Nada Lavrac, editors, </editor> <booktitle> Progress in Machine Learning, </booktitle> <pages> pages 31-45. </pages> <publisher> Sigma Press, </publisher> <address> Wilmslow, England, </address> <year> 1987. </year>
Reference-contexts: 1 The Nmin parameter in CART [BFOS84] is this type of threshold. ASSISTANT <ref> [CKB87] </ref> specifies this threshold as a percentage of the original training set. <p> In both CART and ASSISTANT this cutoff is used in building a decision tree that is subsequently pruned. 5 Approach 2: Eliminate Undesirable Disjuncts Techniques that directly measure, or estimate, the significance and error rate of disjuncts are used in several systems (e.g., CN2, CART [BFOS84], ASSISTANT <ref> [CKB87] </ref>, and recent versions of ID3). These techniques reliably eliminate undesirable large disjuncts (i.e., ones that are not meaningful, or have a high error rate), but, as currently used, do not reliably eliminate undesirable small disjuncts. <p> Error-Rate Estimation Error rate cannot be tested exactly: it can only be estimated. Like approximate tests of significance, techniques for estimating error rate are not entirely reliable for small disjuncts. 2 [Qui86, page 154]. The action taken in lieu of a significance test is not described. 6 For example, <ref> [CKB87] </ref> reports that the technique of Niblett and Bratko 3 "seems to make rather pessimistic estimation about the information contained in learning data (it overestimates the error rate of subtrees) ... post-pruning is too drastic when the number of learning examples per class per attribute is low." The Need for Both
Reference: [CN87] <author> Peter Clark and Tim Niblett. </author> <title> Induction in noisy domains. </title> <editor> In Ivan Bratko and Nada Lavrac, editors, </editor> <booktitle> Progress in Machine Learning, </booktitle> <pages> pages 11-30. </pages> <publisher> Sigma Press, </publisher> <address> Wilmslow, England, </address> <year> 1987. </year> <month> 13 </month>
Reference-contexts: The definitions induced by CN2 in the chess endgame domain are original [Ack88]. The definitions induced by CN2 in the lymphography domain were provided by Peter Clark, of the Turing Institute (Glasgow). Certain properties of these definitions are reported in <ref> [CN87] </ref>. In both these domains, there existed definitions based on several different training sets. These definitions varied, of course, in the number of disjuncts and the coverage of the disjuncts. Table 1 describes typical definitions. The definitions induced by AQ15 are from [Mic87], and those by AQ11 from [MC80]. <p> Most of these definitions had one disjunct. All definitions in the thyroid disease domain [KA87], the protein secondary structure domain [Kin87], and the breast cancer domain <ref> [CN87] </ref> have been excluded because their classification accuracy is not significantly better than that achieved by assigning every example to the most common class in the domain. All definitions created by CN2 in the primary tumor domain [CN87] have been excluded because their classification accuracy is well below 50%. <p> domain [KA87], the protein secondary structure domain [Kin87], and the breast cancer domain <ref> [CN87] </ref> have been excluded because their classification accuracy is not significantly better than that achieved by assigning every example to the most common class in the domain. All definitions created by CN2 in the primary tumor domain [CN87] have been excluded because their classification accuracy is well below 50%.
Reference: [CN89] <author> Peter Clark and Tim Niblett. </author> <title> The CN2 induction algorithm. </title> <booktitle> Machine Learning, </booktitle> <year> 1989. </year> <note> (to appear). </note>
Reference: [KA87] <author> Dennis Kibler and David W. Aha. </author> <title> Learning representative exemplars of concepts: An initial case study. In Pat Langley, editor, </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 24-30. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California, </address> <year> 1987. </year>
Reference-contexts: Most of these definitions had one disjunct. All definitions in the thyroid disease domain <ref> [KA87] </ref>, the protein secondary structure domain [Kin87], and the breast cancer domain [CN87] have been excluded because their classification accuracy is not significantly better than that achieved by assigning every example to the most common class in the domain.
Reference: [Kin87] <author> Ross D. King. </author> <title> An inductive learning approach to the problem of predicting a protein's secondary structure from its amino acid sequence. </title> <editor> In Ivan Bratko and Nada Lavrac, editors, </editor> <booktitle> Progress in Machine Learning, </booktitle> <pages> pages 230-250. </pages> <publisher> Sigma Press, </publisher> <address> Wilmslow, England, </address> <year> 1987. </year>
Reference-contexts: Most of these definitions had one disjunct. All definitions in the thyroid disease domain [KA87], the protein secondary structure domain <ref> [Kin87] </ref>, and the breast cancer domain [CN87] have been excluded because their classification accuracy is not significantly better than that achieved by assigning every example to the most common class in the domain.
Reference: [MC80] <author> R.S. Michalski and R.L. Chilausky. </author> <title> Knowledge acquisition by encoding expert rules versus computer induction from examples: A case study involving soybean pathology. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 12 </volume> <pages> 63-87, </pages> <year> 1980. </year>
Reference-contexts: In both these domains, there existed definitions based on several different training sets. These definitions varied, of course, in the number of disjuncts and the coverage of the disjuncts. Table 1 describes typical definitions. The definitions induced by AQ15 are from [Mic87], and those by AQ11 from <ref> [MC80] </ref>. AQ11 is the only system surveyed that produces definitions whose disjuncts overlap. Coverage, in this case, may be defined in several ways. Table 1 reports the total number of examples matched by a disjunct.
Reference: [Mic87] <author> R. S. Michalski. </author> <title> How to learn imprecise concepts: A method for employing a two-tiered knowledge representation in learning. In Pat Langley, editor, </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 50-58. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California, </address> <year> 1987. </year>
Reference-contexts: In both these domains, there existed definitions based on several different training sets. These definitions varied, of course, in the number of disjuncts and the coverage of the disjuncts. Table 1 describes typical definitions. The definitions induced by AQ15 are from <ref> [Mic87] </ref>, and those by AQ11 from [MC80]. AQ11 is the only system surveyed that produces definitions whose disjuncts overlap. Coverage, in this case, may be defined in several ways. Table 1 reports the total number of examples matched by a disjunct.
Reference: [Mit80] <author> Tom M. Mitchell. </author> <title> The need for biases in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Computer Science Department, Rutgers University, </institution> <address> New Jersey, </address> <year> 1980. </year>
Reference-contexts: That is, they will all have identical estimates of error rate, significance, entropy, and so on. To select among disjuncts that are indistinguishable on the basis of the training set, inductive systems employ an extra-evidential preference criterion, or "bias" <ref> [Mit80] </ref>. Definitions produced using different biases, will usually have different error rates and different distributions of errors across disjuncts. It is possible that the problem of error-prone small disjuncts is caused by the use of the "maximum generality" bias (defined below).
Reference: [Nib87] <author> Tim Niblett. </author> <title> Constructing decision trees in noisy domains. </title> <editor> In Ivan Bratko and Nada Lavrac, editors, </editor> <booktitle> Progress in Machine Learning, </booktitle> <pages> pages 67-78. </pages> <publisher> Sigma Press, </publisher> <address> Wilmslow, England, </address> <year> 1987. </year>
Reference-contexts: Others, such as ID3, refrain from testing the significance of small disjuncts 2 . In any case, the significance of small disjuncts is not reliably estimated, with the undesirable result that significant small disjuncts may be eliminated and insignificant ones retained. This problem is not insuperable: <ref> [Nib87] </ref> gives an exact test for significance. Error-Rate Estimation Error rate cannot be tested exactly: it can only be estimated. Like approximate tests of significance, techniques for estimating error rate are not entirely reliable for small disjuncts. 2 [Qui86, page 154]. <p> (it overestimates the error rate of subtrees) ... post-pruning is too drastic when the number of learning examples per class per attribute is low." The Need for Both Significance and Error-Rate Testing No existing system tests both significance and error rate. "Pre-pruning" systems use significance testing; "post-pruning" systems use error-estimation <ref> [Nib87] </ref>. Indeed, post-pruning systems have a rather strong disregard for the significance of disjuncts, their sole objective being to eliminate from a definition as many disjuncts as possible without suffering too great an increase in error rate. <p> 10 11 12 13 14 15 default Error Rate 18 0 0 3 2 42 8 0 2 0 5 9 0 0 12 48 Coverage 8 36 58 5 19 5 19 7 5 8 8 5 5 6 5 3 This and other error-estimation techniques are described in <ref> [Nib87, page 43] </ref>. 4 Clark and Niblett have observed empirically that rules of low entropy tend to have high significance ([CN87, page 18] mistakenly reports this as a relation between rules of high entropy and high significance).
Reference: [Qui86] <author> J. Ross Quinlan. </author> <title> The effect of noise on concept learning. </title> <editor> In J.G. Carbonell R.S. Michalski and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Approach, </booktitle> <volume> Volume II, </volume> <pages> pages 149-166. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California, </address> <year> 1986. </year>
Reference-contexts: This problem is not insuperable: [Nib87] gives an exact test for significance. Error-Rate Estimation Error rate cannot be tested exactly: it can only be estimated. Like approximate tests of significance, techniques for estimating error rate are not entirely reliable for small disjuncts. 2 <ref> [Qui86, page 154] </ref>.
Reference: [Sha87] <author> Alen D. Shapiro. </author> <title> Structured Induction in Expert Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: This result is relatively insensitive to the exact definition of "small". 11 Acknowledgements We are especially grateful to Peter Clark, of the Turing Institute (Glasgow), who provided the source for CN2, the definitions it produced on the lymphography dataset, and the KPa7KR dataset generated by Alen Shapiro <ref> [Sha87] </ref>. Peter also answered many questions, and gave helpful criticism of early drafts of this paper.
References-found: 15

