URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3442/3442.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: facharya, josephg@umiacs.umd.edu  
Title: An On-line Variable Length Binary Encoding 1  
Author: Tinku Acharya Joseph F. Ja Ja 
Address: College Park, MD 20742  
Affiliation: Institute for Systems Research and Institute for Advanced Computer Studies University of Maryland  
Abstract: We present a methodology of an on-line variable-length binary encoding of a set of integers. The basic principle of this methodology is to maintain the prefix property amongst the codes assigned on-line to a set of integers growing dynamically. The prefix property enables unique decoding of a string of elements from this set. To show the utility of this on-line variable length binary encoding, we apply this methodology to encode the LZW codes. Application of this encoding scheme significantly improves the compression achieved by the standard LZW scheme. This encoding can be applied in other compression schemes to encode the pointers using variable-length binary codes.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Storer, J. </author> <title> A."Data Compression: Methods and theory." </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction The basic idea behind any lossless data compression technique <ref> [1] </ref> is to reduce the redundancy in data representation. The two general categories of text compression techniques are statistical coding and dictionary coding. The statistical coding is based on the statistical probability of occurrence of the characters in the text, e.g. Huffman coding [2], Arithmetic coding [3] etc.
Reference: [2] <author> Huffman, </author> <title> D.,"A Method for the Construction of Minimum Redundancy Codes," </title> <journal> Proc. IRE, </journal> <volume> Vol. 40, </volume> <year> 1952, </year> <pages> pp. 1098-1101. </pages>
Reference-contexts: The two general categories of text compression techniques are statistical coding and dictionary coding. The statistical coding is based on the statistical probability of occurrence of the characters in the text, e.g. Huffman coding <ref> [2] </ref>, Arithmetic coding [3] etc. In dictionary coding, a dictionary of common words is generated such that the common words appearing in the text are replaced by their addresses in the dictionary.
Reference: [3] <author> Witten, I.H., Neal, R., and Cleary, </author> <title> J.G.,"Arithmetic coding for data compression," </title> <journal> Communication of the ACM, </journal> <volume> 30(6), </volume> <pages> 520-540, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: The two general categories of text compression techniques are statistical coding and dictionary coding. The statistical coding is based on the statistical probability of occurrence of the characters in the text, e.g. Huffman coding [2], Arithmetic coding <ref> [3] </ref> etc. In dictionary coding, a dictionary of common words is generated such that the common words appearing in the text are replaced by their addresses in the dictionary.
Reference: [4] <author> Ziv, J. and Lempel, </author> <title> A.,"A Universal Algorithm for Sequential Data Compression," </title> <journal> IEEE Trans. on Info. Theory, IT-23, </journal> <volume> 3, </volume> <month> May </month> <year> 1977, </year> <pages> pp. 337-343. </pages>
Reference-contexts: In dictionary coding, a dictionary of common words is generated such that the common words appearing in the text are replaced by their addresses in the dictionary. Most of the adaptive dictionary based text compression algorithms belong to a family of algorithms originated by Ziv and Lempel <ref> [4, 5] </ref>, popularly known as LZ coding. The basic concept of all the LZ coding algorithms is to replace the substrings (called phrases or words) with a pointer to where they have occurred earlier in the text.
Reference: [5] <author> Ziv, J., and Lempel, </author> <title> A.,"Compression of Individual Sequences Via Variable-rate Coding," </title> <journal> IEEE Trans. Info. Theory, </journal> <volume> IT-24, 5, </volume> <month> September </month> <year> 1978, </year> <pages> pp. 530-536. </pages>
Reference-contexts: In dictionary coding, a dictionary of common words is generated such that the common words appearing in the text are replaced by their addresses in the dictionary. Most of the adaptive dictionary based text compression algorithms belong to a family of algorithms originated by Ziv and Lempel <ref> [4, 5] </ref>, popularly known as LZ coding. The basic concept of all the LZ coding algorithms is to replace the substrings (called phrases or words) with a pointer to where they have occurred earlier in the text.
Reference: [6] <author> Bell, T. C., Cleary, J. G. and Witten, I. </author> <title> H.,"Text Compression," </title> <publisher> Prentice Hall, </publisher> <address> NJ, </address> <year> 1990. </year>
Reference-contexts: The basic concept of all the LZ coding algorithms is to replace the substrings (called phrases or words) with a pointer to where they have occurred earlier in the text. Different variations of these algorithms have been described in <ref> [6] </ref> which differ in the way the dictionary is referenced and how it is mapped onto a set of codes. This mapping is a code function to represent a pointer. The size of this pointer is usually fixed and determines the size of the dictionary.
Reference: [7] <author> Welch, </author> <title> T.,"A Technique for High-Performance Data Compression," </title> <journal> IEEE Computer, </journal> <volume> 17 (6), </volume> <pages> 8-19, </pages> <month> June </month> <year> 1984, </year> <pages> pp. 8-19. </pages>
Reference-contexts: This affects the compression performance at the beginning when more than half of the dictionary is empty. The most popular variation is the LZW algorithm <ref> [7] </ref> for text compression. We will describe a methodology of an on-line variable-length binary encoding of a set of integers and apply this methodology to the LZW codes to enhance the compression ratio. The variable-length on-line binary encoding scheme can be applied to other LZ encoding schemes as well. <p> This special case occurs whenever the input string contains a substring of the form K!K!K, where K! already appears in the trie. Here K is a single character from the alphabet and ! is a prefix string. This is explained in detail in the original paper of LZW <ref> [7] </ref>. If the original input string (S) contains a substring of this form, during the decoding operation of our proposed binary encoding, we will find that the decoded label from the binary tree is not yet created in the trie in the corresponding step (say step j).
Reference: [8] <author> Horspool, R. N.,"Improving LZW," </author> <booktitle> Data Compression Conference, </booktitle> <year> 1991, </year> <pages> pp. 332-341. 15 16 17 18 19 </pages>
Reference-contexts: As a result a large number of bits are used unnecessarily when the number of phrases into the dictionary is less than half of its maximum size. In the LZC algorithm (which is a variant of the LZW algorithm used in UNIX-Z compression), string numbers are output in binary <ref> [8] </ref>. The number of bits used to represent the string number in any step varies according to the number of phrases (say M ) currently contained in the dictionary.
References-found: 8

