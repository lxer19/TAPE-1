URL: http://www.ingber.com/asa92_saga.ps.Z
Refering-URL: http://www.ingber.com/
Root-URL: 
Email: ingber@alumni.caltech.edu  brosen@cis.udel.edu  
Title: GENETIC ALGORITHMS AND VERY FAST SIMULATED REANNEALING: A COMPARISON  
Author: LESTER INGBER Lester Ingber BRUCE ROSEN 
Address: P.O. Box 857, McLean, VA 22101, U.S.A.  19716, U.S.A.  
Affiliation: Research,  Department of Computer and Information Sciences, University of Delaware, Newark, DE  
Date: 16(11) 1992, 87-100.  
Note: Mathematical and Computer Modelling,  
Abstract: We compare Genetic Algorithms (GA) with a functional search method, Very Fast Simulated Reannealing (VFSR), that not only is efficient in its search strategy, but also is statistically guaranteed to find the function optima. GA previously has been demonstrated to be competitive with other standard Boltzmann-type simulated annealing techniques. Presenting a suite of six standard test functions to GA and VFSR codes from previous studies, without any additional fine tuning, strongly suggests that VFSR can be expected to be orders of magnitude more efficient than GA. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. Holland, </author> <title> Adaptation in Natural and Artificial Systems, </title> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> (1975). </year>
Reference-contexts: Should the rightmost bit of C be mutated, the global minimum will be found, and successive populations will converge to f (0000) = 0. The original concepts of Genetic Algorithms were developed by Holland <ref> [1] </ref>, and have been shown to provide near-optimal heuristics for information gathering in complex search spaces. <p> . -1 dy D D P G T (y ) , Genetic Algorithms & VFSR -6- Ingber & Rosen G T (y ) = 2 sgn (y ) ln (1 + |y |/T i ) . (15) i is generated from a u i from the uniform distribution u U <ref> [0, 1] </ref> , i i 1 )T i [(1 + 1/T i ) - 1] . (16) It is straightforward to calculate that for an annealing schedule for T i T i (k) = T 0i exp (-c i k ) , (17) a global minima statistically can be obtained.
Reference: 2. <author> A.D. Bethke, </author> <title> Genetic Algorithms as Function Optimizers, </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer and Communication Sciences, University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> (1981). </year>
Reference: 3. <author> K.A. De Jong, </author> <title> An Analysis of the Behavior of a Class of Genetic Adaptive system, </title> <type> Ph.D. Thesis, Report, </type> <institution> Department of Computer and Communication Sciences, University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> (1981). </year>
Reference-contexts: SIMULATION COMPARISONS 4.1. Test Functions We evaluated the two algorithms, VFSR and GA, on a set of six robust optimizing test functions. Functions 1-5, shown below, are De Jong's five function test bed and are typically used for GA benchmarking <ref> [3] </ref>. The performances of GA and their variations on these functions are well documented [5]. For consistency with [5], our GA runs were also simulated on the University of Califor nia at San Diego GENESIS 1.2 Genetic Algorithms simulator [18]. <p> Function f 4 is a noisy quartic function of 30 variables originally defined as f 4 ( x 1 , . . . , x 30 ) = j=1 4 + h, where h is produced by Gaussian noise with distribution n (0,1) <ref> [3] </ref>. While the intent of this function is to determine an optimizer's performance in the presence of noise, this func tion is perhaps awed, as no definite global minimum exists.
Reference: 4. <author> D.E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization & Machine Learning, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass, </address> <year> (1989). </year>
Reference: 5. <author> N.N. Schraudolph and R.K. Belew, </author> <title> Dynamic parameter encoding for genetic algorithms, </title> <type> Technical Report LAUR 90-2795, </type> <institution> Los Alamos National Laboratory, </institution> <address> Los Alamos, NM, </address> <year> (1990). </year>
Reference-contexts: A bit string of length four, when decoded, allows only 15 distinct values; gray cod ing is even more limited. Methods such as dynamic parameter encoding have addressed the former issue and have achieved good results on a variety of function optimization problems <ref> [5] </ref>. However, in the GA domain, the second deficiency has been largely unresolved. 3. VERY FAST SIMULATED REANNEALING An algorithm of Very Fast Simulated Reannealing (VFSR) has been developed to fit empirical data to a theoretical cost-function over a D-dimensional parameter-space [6]. <p> Functions 1-5, shown below, are De Jong's five function test bed and are typically used for GA benchmarking [3]. The performances of GA and their variations on these functions are well documented <ref> [5] </ref>. For consistency with [5], our GA runs were also simulated on the University of Califor nia at San Diego GENESIS 1.2 Genetic Algorithms simulator [18]. <p> Functions 1-5, shown below, are De Jong's five function test bed and are typically used for GA benchmarking [3]. The performances of GA and their variations on these functions are well documented <ref> [5] </ref>. For consistency with [5], our GA runs were also simulated on the University of Califor nia at San Diego GENESIS 1.2 Genetic Algorithms simulator [18].
Reference: 6. <author> L. Ingber, </author> <title> Very fast simulated re-annealing, </title> <journal> Mathl. Comput. </journal> <volume> Modelling 12 (8), </volume> <month> 967-973 </month> <year> (1989). </year>
Reference-contexts: However, in the GA domain, the second deficiency has been largely unresolved. 3. VERY FAST SIMULATED REANNEALING An algorithm of Very Fast Simulated Reannealing (VFSR) has been developed to fit empirical data to a theoretical cost-function over a D-dimensional parameter-space <ref> [6] </ref>. This methodology has been applied to several systems, ranging from combat analysis [7,8], to finance [9,10], to neuroscience [11,12]. This Section gives a self-contained description of VFSR. The general outline of presentation of simulated-annealing heuristics here closely follows that of Szu and Hartley [13]. 3.1. <p> Rather, this methodology can be readily extended to any problem for which a reasonable probability density h (x) can be formulated [15]. [The above Equations (1) and (6) correct Equations (1) and (6), resp., in the first VFSR paper <ref> [6] </ref>. Nothing else is affected in the rest of that paper.] 3.2. Fast Annealing (FA) It was also noted that this methodology can be readily extended to use any reasonable generating function g (x), without relying on the principles underlying the ergodic nature of statistical physics.
Reference: 7. <author> L. Ingber, H. Fujio, and M.F. Wehner, </author> <title> Mathematical comparison of combat computer models to exercise data, </title> <journal> Mathl. Comput. </journal> <volume> Modelling 15 (1), </volume> <month> 65-90 </month> <year> (1991). </year>
Reference: 8. <author> L. Ingber and D.D. Sworder, </author> <title> Statistical mechanics of combat with human factors, </title> <journal> Mathl. Comput. </journal> <volume> Modelling 15 (11), </volume> <month> 99-127 </month> <year> (1991). </year>
Reference: 9. <author> L. Ingber, </author> <title> Statistical mechanical aids to calculating term structure models, </title> <journal> Phys. Rev. </journal> <volume> A 42 (12), </volume> <month> 7057-7064 </month> <year> (1990). </year>
Reference: 10. <author> L. Ingber, M.F. Wehner, G.M. Jabbour, </author> <title> and T.M. Barnhill, Application of statistical mechanics methodology to term-structure bond-pricing models, </title> <journal> Mathl. Comput. </journal> <volume> Modelling 15 (11), </volume> <month> 77-98 </month> <year> (1991). </year>
Reference: 11. <author> L. Ingber, </author> <title> Statistical mechanics of neocortical interactions: A scaling paradigm applied to electroencephalography, </title> <journal> Phys. Rev. </journal> <volume> A 44 (6), </volume> <month> 4017-4060 </month> <year> (1991). </year>
Reference: 12. <author> L. Ingber, </author> <title> Generic mesoscopic neural networks based on statistical mechanics of neocortical interactions, </title> <journal> Phys. Rev. </journal> <volume> A 45 (4), </volume> <month> R2183-R2186 </month> <year> (1992). </year>
Reference: 13. <author> H. Szu and R. </author> <title> Hartley, Fast simulated annealing, </title> <journal> Phys. Lett. </journal> <note> A 122 (3-4), </note> <month> 157-162 </month> <year> (1987). </year>
Reference-contexts: This methodology has been applied to several systems, ranging from combat analysis [7,8], to finance [9,10], to neuroscience [11,12]. This Section gives a self-contained description of VFSR. The general outline of presentation of simulated-annealing heuristics here closely follows that of Szu and Hartley <ref> [13] </ref>. 3.1. Boltzmann Annealing (BA) Boltzmann annealing was essentially introduced as a Monte Carlo importance-sampling technique for doing large-dimensional path integrals arising in statistical physics problems [14]. <p> it suffices to obtain a global minimum of E (x) if T is selected to be not faster than T (k) = ln k For the purposes of this paper, a heuristic demonstration follows, to show that Equation (3) will suf fice to give a global minimum of E (x) <ref> [13] </ref>. <p> Specifically, it was noted that the Cauchy distribution has some definite advantages over the Boltzmann form <ref> [13] </ref>. The Cauchy distribution, g (x) = (D x 2 + T 2 ) (D+1)/2 Genetic Algorithms & VFSR -5- Ingber & Rosen has a fatter tail than the Gaussian form of the Boltzmann distribution, permitting easier access to test local minima in the search for the desired global minimum. <p> The method of FA is thus statistically seen to have an annealing schedule exponentially faster than the method of BA. This method has been tested in a variety of problems <ref> [13] </ref>. 3.3. Very Fast Annealing In a variety of physical problems we have a D-dimensional parameter-space. Different parameters have different finite ranges, fixed by physical considerations, and different annealing-time-dependent sensitivities, measured by the curvature of the cost-function at local minima.
Reference: 14. <author> N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller, and E. Teller, </author> <title> Equation of state calculations by fast computing machines, </title> <journal> J. Chem. Phys. </journal> <volume> 21 (6), </volume> <month> 1087-1092 </month> <year> (1953). </year>
Reference-contexts: The general outline of presentation of simulated-annealing heuristics here closely follows that of Szu and Hartley [13]. 3.1. Boltzmann Annealing (BA) Boltzmann annealing was essentially introduced as a Monte Carlo importance-sampling technique for doing large-dimensional path integrals arising in statistical physics problems <ref> [14] </ref>. This method was generalized to apply more generally to fitting non-convex cost-functions arising in a variety of problems, e.g., finding the optimal wiring for a densely wired computer chip [15]. <p> For BA, if T (k) is selected to be Equation (3), then Equation (1) gives S g k k 0 S 1/k = . (6) Although there are sound physical principles underlying the choices of Equations (1) and (2) <ref> [14] </ref>, it was noted that this method of finding the global minimum in x-space was not limited to physics examples requiring bona fide temperatures and energies.
Reference: 15. <author> S. Kirkpatrick, C.D. Gelatt, Jr., </author> <title> and M.P. Vecchi, Optimization by simulated annealing, </title> <booktitle> Science 220 (4598), </booktitle> <month> 671-680 </month> <year> (1983). </year>
Reference-contexts: This method was generalized to apply more generally to fitting non-convex cost-functions arising in a variety of problems, e.g., finding the optimal wiring for a densely wired computer chip <ref> [15] </ref>. The method of simulated annealing consists of three functional relationships. 1. g (x): Probability density of state-space of D parameters x = -x i 2. h (x): Probability density for acceptance of new cost-function given the just previous value. 3. <p> Rather, this methodology can be readily extended to any problem for which a reasonable probability density h (x) can be formulated <ref> [15] </ref>. [The above Equations (1) and (6) correct Equations (1) and (6), resp., in the first VFSR paper [6]. Nothing else is affected in the rest of that paper.] 3.2.
Reference: 16. <author> K. Binder and D. Stauffer, </author> <title> A simple introduction to Monte Carlo simulations and some specialized topics, in Applications of the Monte Carlo Method in Statistical Physics, (Edited by K. </title> <booktitle> Binder), </booktitle> <pages> pp. 1-36, </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> (1985). </year>
Reference-contexts: This essentially is the Boltzmann distribution contributing to the statistical mechanical partition function of the system <ref> [16] </ref>.
Reference: 17. <author> S. Geman and D. Geman, </author> <title> Stochastic relaxation, Gibbs distribution and the Bayesian restoration in images, </title> <journal> IEEE Trans. Patt. Anal. Mac. Int. </journal> <volume> 6 (6), </volume> <month> 721-741 </month> <year> (1984). </year>
Reference-contexts: This essentially is the Boltzmann distribution contributing to the statistical mechanical partition function of the system [16]. Given g ( x), it has been proven <ref> [17] </ref> that it suffices to obtain a global minimum of E (x) if T is selected to be not faster than T (k) = ln k For the purposes of this paper, a heuristic demonstration follows, to show that Equation (3) will suf fice to give a global minimum of E
Reference: 18. <author> N.N. Schraudolph and J.J. Grefenstette, </author> <title> A Users Guide to GAUCSD 1.2, </title> <type> Report, </type> <institution> University of Cal-ifornia at San Diego, La Jolla, </institution> <address> CA, </address> <year> (1991). </year>
Reference-contexts: The performances of GA and their variations on these functions are well documented [5]. For consistency with [5], our GA runs were also simulated on the University of Califor nia at San Diego GENESIS 1.2 Genetic Algorithms simulator <ref> [18] </ref>. We also choose function f 0 , the objective function of Corana et al [19], which contains a very large number of local minima, and is very difficult to optimize. <p> With regard to the Genetic Algorithm simulations, Genetic Algorithms have the problem of parameter estimation. Currently only heuristic estimates of parameters such as population size and string length were used in our simulations, and these parameter values were taken from <ref> [18] </ref>. When comparing the two algorithms, one should note that the GA and VFSR random number generator values differ almost immediately during the optimization. VFSR makes additional calls to the generator to incorporate noise into its decision process, making it difficult to rigidly compare performances.
Reference: 19. <author> A. Corana, M. Marchesi, C. Martini, and S. Ridella, </author> <title> Minimizing multimodal functions of continuous variables with the "simulated annealing" algorithm, </title> <journal> ACM Trans. Mathl. </journal> <volume> Software 13 (3), </volume> <month> 262-279 </month> <year> (1987). </year>
Reference-contexts: For consistency with [5], our GA runs were also simulated on the University of Califor nia at San Diego GENESIS 1.2 Genetic Algorithms simulator [18]. We also choose function f 0 , the objective function of Corana et al <ref> [19] </ref>, which contains a very large number of local minima, and is very difficult to optimize. The test suite was designed to test algorithms on functions that are: Continuous or Discontinuous Convex or Concave Unimodal or Multimodal Linear or Nonlinear Low Dimensional or High Dimensional Deterministic or Stochastic. <p> Function f 1 tests simple sum of squares with 1 minimum at x i = 0. The function f 2 is the classical function of Rosenbrock and Chebyquad in two dimensions that is unimodal, yet difficult to minimize <ref> [19] </ref>. The next function, f 3 , is the plateau function, gener ated as the sum of integer threshold values. The five dimensional space has one minimum and is discontinuous.
Reference: 20. <author> W.D. Hillis, </author> <title> The Connection Machine, </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> (1985). </year>
Reference-contexts: Howev er, a generation-performance plot would be a more accurate estimate of the power of the genetic algorithms, especially if the GA simulations were run on parallel hardware such as the Connection Machine <ref> [20] </ref>. Then all function evaluations (performed in one generation) could be evaluated in parallel. It should be noted that parallel processing of GA can lead to spurious correlations and premature convergence [21]. It should be noted in this context that VFSR also lends itself well to parallelization.
Reference: 21. <author> J.D. Schaffer, L.J. Eshelman, and D. Offutt, </author> <title> Spurious correlations and premature convergence in genetic algorithms, </title> <booktitle> in Foundations of Genetic Algorithms, (Edited by G. Rawlins), </booktitle> <pages> pp. 102-112, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> (1991). </year>
Reference-contexts: Then all function evaluations (performed in one generation) could be evaluated in parallel. It should be noted that parallel processing of GA can lead to spurious correlations and premature convergence <ref> [21] </ref>. It should be noted in this context that VFSR also lends itself well to parallelization. Blocks of random numbers can be generated in parallel, and then sequentially checked to determine a generating point satisfying all boundary conditions.

References-found: 21

