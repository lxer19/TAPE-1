URL: ftp://theory.lcs.mit.edu/pub/people/canetti/thesis.ps.Z
Refering-URL: http://theory.lcs.mit.edu/~canetti/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Studies in Secure Multiparty Computation and Applications  
Author: Ran Canetti 
Degree: Thesis for the Degree of DOCTOR of PHILOSOPHY by  
Date: June 1995 Revised: March 1996  
Address: Rehovot 76100, Israel  
Note: Submitted to the Scientific  
Affiliation: Department of Computer Science and Applied Mathematics The Weizmann Institute of Science  Council of The Weizmann Institute of Science  
Abstract-found: 0
Intro-found: 1
Reference: [AFL] <author> E. Arjomandi, M. Fischer and N. Lynch, </author> <title> "Efficiency of Synchronous Versus Asynchronous Distributed Systems", </title> <journal> Journal of the ACM, </journal> <volume> No. 3, Vol. 30, </volume> <year> 1983, </year> <pages> pp. 449-456. </pages>
Reference: [Aw] <author> B. Awerbuch, </author> <title> "The complexity of Network Synchronization", </title> <journal> JACM, </journal> <volume> Vol. 32, no. 4, </volume> <pages> pp. 804-823, </pages> <year> 1985. </year>
Reference-contexts: Furthermore, the order of the messages on a channel need not be preserved. If the adversary is eavesdropping, then any synchronous secure protocol can be run in an asynchronous network using any synchronizer (e.g. <ref> [Aw] </ref>). It can be seen that in this case, the security (in the synchronous sense, as defined in Chapter 2) of the protocol is maintained. However, asynchrony combined with the possibility of faults has devastating consequences on the computational capabilities of a network.
Reference: [Ba] <author> E. Bach, </author> <title> "How to generate factored random numbers", </title> <journal> SIAM J. on Comput., </journal> <volume> Vol. 17, No. 2, </volume> <year> 1988, </year> <pages> pp. 179-193. </pages>
Reference-contexts: The common domain, given security parameter n, is f0; 1g n . A permutation over f0; 1g n is chosen as follows. First choose a number N uniformly from [2 n1 : : : 2 n ], together with its factorization (via Bach's algorithm <ref> [Ba] </ref>).
Reference: [Be] <author> D. Beaver, </author> <title> "Foundations of Secure Interactive Computing", </title> <booktitle> CRYPTO, </booktitle> <year> 1991. </year>
Reference-contexts: Goldreich, Goldwasser and Linial study secure multiparty computation in the presence of insecure channels and computationally unlimited adversaries [GGL]. Ostrovsky and Yung study secure multiparty computation in the presence of secure channels and mobile adversaries [OY]. Micali and Rogaway [MR], and also Beaver <ref> [Be] </ref>, propose definitions for secure multiparty computation in the secure channels setting, in the presence of adaptive adversaries. 1.2 Defining secure multiparty computation 5 1.2 Defining secure multiparty computation We attempt at formulating coherent, lean, and usable definitions, that adequately capture our intuitive notion of security of protocols for multiparty computation <p> Our definitions build on previously known ideas. We first present these ideas, as well as a brief critique and comparison of relevant works. Next we present our interpretation and new ideas. Micali and Rogaway [MR], and independently Beaver <ref> [Be] </ref> introduced the following methodology for defining secure multiparty computation (or, more specifically, secure evaluation of a function whose inputs are distributed among the parties). First an ideal model for secure multiparty computation is formulated. <p> Loosely speaking, executing in the real-life setting is said to be "equivalent" to evaluating the function in the ideal model, if the same effect on the computation achieved by a real-life adversary can be also achieved by an ideal-mode adversary. The definitions in [MR] and <ref> [Be] </ref> differ in the notion of equivalence of computations. In [MR] the ideal-model adversary is required to very closely mimic the operation of the real-life adversary, down to precise details. <p> In particular, the ideal-model adversary is limited to creating a simulated environment for the real-life adversary (that looks the same as a real environment), via a special type of black-box simulation. In <ref> [Be] </ref> a different approach is pursued. First a general notion of comparing security of protocols is formulated, as follows. Consider two protocols ff and fi for computing the same function. <p> Put together, these constructions constitute an asynchronous (d n 3 e 1)-resilient BA protocol. We note that our (d n 3 e 1)-resilient AVSS scheme has applications in other contexts as well (for instance, in <ref> [BE, BKR] </ref>). We offer an intuitive exposition of the difficulties encountered in trying to devise an (d n 3 e 1)-resilient AVSS scheme. <p> Furthermore, for every 6 This problem of assuring a large intersection of the sets of a uniform collection was previously addressed by [Fe], as well as <ref> [BE] </ref>. Both works present partial solutions to this problem: let m = n t; Feldman [Fe] made sure that the intersection of the sets held by all the uncorrupted parties is of size fi (n) (but not necessarily m); Ben-Or and El-Yaniv [BE] made sure that the intersection of the sets <p> was previously addressed by [Fe], as well as <ref> [BE] </ref>. Both works present partial solutions to this problem: let m = n t; Feldman [Fe] made sure that the intersection of the sets held by all the uncorrupted parties is of size fi (n) (but not necessarily m); Ben-Or and El-Yaniv [BE] made sure that the intersection of the sets held by n 2t uncorrupted parties is of size at least m. 4.2 Primitives 58 Protocol ACS [m; M ](U i ) Party P i acts as follows, on inputs m; M and accumulative set U i . 1.
Reference: [BH] <author> D. Beaver and S. Haber, </author> <title> "Cryptographic Protocols Provably secure Against Dynamic Adversaries", </title> <booktitle> Eurocrypt, </booktitle> <year> 1992. </year>
Reference-contexts: In this case adaptively secure computation can be carried out, using known primitives, in all the settings discussed below <ref> [BH] </ref>. <p> Thus, all that ~ S needs to do is encrypt the messages it has obtained from S. 3.1 The problems in proving adaptive security: informal presentation 30 We remark that Beaver and Haber <ref> [BH] </ref> have suggested to solve this problem as follows. Instruct each party to erase (say, at the end of each round) all the information involved with encrypting and decrypting of messages. <p> Consequently, such "erasing" protocols can be shown adaptively secure in the computational setting. However, this approach is clearly not valid in the presence of semi-honest parties. In particular, it is not known whether the <ref> [BH] </ref> protocols (or any other previous protocols) are secure in the presence of non-erasing parties. Sketch of our solution.
Reference: [BR1] <author> M. Bellare and P. Rogaway, </author> <title> "Entity authentication and key distribution", </title> <booktitle> Advances in Cryptology: Proc. of Crypto 93, </booktitle> <month> August </month> <year> 1993, </year> <pages> pp. 232-249. </pages>
Reference-contexts: Namely, there exists a polytime algorithm that on input ; x 2 f0; 1g k outputs f (x). Pseudorandom function families and their cryptographic applications were introduced by Goldreich, Goldwasser and Micali [GGM2, GGM1]. Applications to practical key distribution and authentication protocols were shown by Bellare and Rogaway <ref> [BR1] </ref>. In [GGM2] it is shown how to construct pseudo-random functions from any pseudo-random generator, which in turn could be constructed from any one-way function [HILL].
Reference: [BR2] <author> M. Bellare and P. Rogaway, </author> <title> "Random oracles are practical: A paradigm for designing efficient protocols", </title> <booktitle> First ACM conf. on Computer and Comm. Security, </booktitle> <month> November </month> <year> 1993, </year> <pages> pp. 62-73. </pages>
Reference: [BT] <author> Josh Benaloh and Dwight Tunistra, </author> <title> "Receipt-Free Secret-Ballot Elections", </title> <booktitle> 26th STOC, </booktitle> <year> 1994, </year> <pages> pp. 544-552. </pages>
Reference: [BCG] <author> M. Ben-Or, R. Canetti and O. Goldreich, </author> <title> "Asynchronous Secure Computations", </title> <booktitle> 25th STOC, </booktitle> <year> 1993, </year> <pages> pp. 52-61. </pages>
Reference-contexts: This construction is min (r; d n 3 e 1)-resilient. (d n 4 e 1)- resilient AVSS schemes are presented in <ref> [Fe, BCG] </ref>. (The [BCG] scheme is presented in Section 4.4.) Up to now, no known AVSS scheme has been more than (d n 4 e 1)-resilient. In this chapter, we construct an (d n 3 e 1)-resilient AVSS scheme. <p> This construction is min (r; d n 3 e 1)-resilient. (d n 4 e 1)- resilient AVSS schemes are presented in [Fe, BCG]. (The <ref> [BCG] </ref> scheme is presented in Section 4.4.) Up to now, no known AVSS scheme has been more than (d n 4 e 1)-resilient. In this chapter, we construct an (d n 3 e 1)-resilient AVSS scheme.
Reference: [BE] <author> M. Ben-Or and R. El-Yaniv, </author> <title> "Interactive Consistency in Constant Time", </title> <note> submitted for publication, </note> <year> 1991. </year>
Reference-contexts: Goldreich, Goldwasser and Linial study secure multiparty computation in the presence of insecure channels and computationally unlimited adversaries [GGL]. Ostrovsky and Yung study secure multiparty computation in the presence of secure channels and mobile adversaries [OY]. Micali and Rogaway [MR], and also Beaver <ref> [Be] </ref>, propose definitions for secure multiparty computation in the secure channels setting, in the presence of adaptive adversaries. 1.2 Defining secure multiparty computation 5 1.2 Defining secure multiparty computation We attempt at formulating coherent, lean, and usable definitions, that adequately capture our intuitive notion of security of protocols for multiparty computation <p> Our definitions build on previously known ideas. We first present these ideas, as well as a brief critique and comparison of relevant works. Next we present our interpretation and new ideas. Micali and Rogaway [MR], and independently Beaver <ref> [Be] </ref> introduced the following methodology for defining secure multiparty computation (or, more specifically, secure evaluation of a function whose inputs are distributed among the parties). First an ideal model for secure multiparty computation is formulated. <p> Loosely speaking, executing in the real-life setting is said to be "equivalent" to evaluating the function in the ideal model, if the same effect on the computation achieved by a real-life adversary can be also achieved by an ideal-mode adversary. The definitions in [MR] and <ref> [Be] </ref> differ in the notion of equivalence of computations. In [MR] the ideal-model adversary is required to very closely mimic the operation of the real-life adversary, down to precise details. <p> In particular, the ideal-model adversary is limited to creating a simulated environment for the real-life adversary (that looks the same as a real environment), via a special type of black-box simulation. In <ref> [Be] </ref> a different approach is pursued. First a general notion of comparing security of protocols is formulated, as follows. Consider two protocols ff and fi for computing the same function. <p> Put together, these constructions constitute an asynchronous (d n 3 e 1)-resilient BA protocol. We note that our (d n 3 e 1)-resilient AVSS scheme has applications in other contexts as well (for instance, in <ref> [BE, BKR] </ref>). We offer an intuitive exposition of the difficulties encountered in trying to devise an (d n 3 e 1)-resilient AVSS scheme. <p> Furthermore, for every 6 This problem of assuring a large intersection of the sets of a uniform collection was previously addressed by [Fe], as well as <ref> [BE] </ref>. Both works present partial solutions to this problem: let m = n t; Feldman [Fe] made sure that the intersection of the sets held by all the uncorrupted parties is of size fi (n) (but not necessarily m); Ben-Or and El-Yaniv [BE] made sure that the intersection of the sets <p> was previously addressed by [Fe], as well as <ref> [BE] </ref>. Both works present partial solutions to this problem: let m = n t; Feldman [Fe] made sure that the intersection of the sets held by all the uncorrupted parties is of size fi (n) (but not necessarily m); Ben-Or and El-Yaniv [BE] made sure that the intersection of the sets held by n 2t uncorrupted parties is of size at least m. 4.2 Primitives 58 Protocol ACS [m; M ](U i ) Party P i acts as follows, on inputs m; M and accumulative set U i . 1.
Reference: [BGW] <author> M. Ben-Or, S. Goldwasser and A. Wigderson, </author> " <title> Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation", </title> <booktitle> 20th STOC, </booktitle> <year> 1988, </year> <pages> pp. 1-10. Bibliography 142 </pages>
Reference-contexts: In the case of Byzantine adversaries they show (d n 2 e 1)-secure protocols for computing any function. Their protocols can be shown secure in the presence of non-adaptive adversaries. Ben-Or, Goldwasser and Wigderson <ref> [BGW] </ref> (and, independently, Chaum, Crepeau and Damgard [CCD]) study secure multiparty computation in the secure channels setting. <p> We elaborate on this point in the sequel.) Therefore, the adversary is much more powerful in the presence of semi-honest parties. The more allowed "internal deviation" from the protocol, the stronger the adversary becomes. We first consider the secure channels setting. Here the <ref> [BGW, CCD] </ref> protocols can be proven adaptively secure in the presence of non-erasing parties (see Section 1.2.1). Fundamental problems arise when trying to prove adaptive security of protocols in the presence of more general types of semi-honest parties. We sketch these problems. <p> Subsequent to our work Ben-Or, Kelmer and Rabin showed, using very different constructions, how any function can be (d n 3 e 1)-securely computed in the presence of Byzantine adversaries, and with exponentially small probability of error [BKR]. Our constructions adapt the <ref> [BGW] </ref> synchronous constructions to an asynchronous environment. Furthermore, we develop several new tools which may be of separate interest. <p> We remark that the only purpose of the technical restrictions imposed on the operation of the simulator is to facilitate proving composition theorems (such as Theorem 3.4). In particular, black-box simulation is the only proof method currently known in the context of secure multiparty computation. The <ref> [BGW] </ref> protocols for computing any function can be proven secure, in the presence of non-erasing parties, using black-box simulators in probabilistic polynomial time. 4 For simplicity, we assume that the computed function is polynomially computable. <p> Adaptively secure protocols for computing any function exist in the presence of non-erasing parties (e.g., <ref> [BGW, CCD] </ref>). However, in contrast with popular belief, not every non-adaptively secure protocol is also adaptively secure in the presence of non-erasing parties. <p> It turns out that this can be done for the <ref> [BGW] </ref> protocols for computing any function in the presence of non-erasing parties. Thus, the [BGW] protocols are adaptively secure in the presence of non-erasing parties. We stress, however, that not every protocol which is secure against non-adaptive adversaries is also secure against adaptive adversaries. 1 In face of honest-looking parties. <p> It turns out that this can be done for the <ref> [BGW] </ref> protocols for computing any function in the presence of non-erasing parties. Thus, the [BGW] protocols are adaptively secure in the presence of non-erasing parties. We stress, however, that not every protocol which is secure against non-adaptive adversaries is also secure against adaptive adversaries. 1 In face of honest-looking parties. <p> Now, if this honest-looking variant of fi is shown secure via an efficient black-box simulation as described above, then the constructed simulator can be used to find claws between f 0 and f 1 . Similar honest-looking protocols can be constructed for the <ref> [BGW, CCD] </ref> protocols. Consequently, if claw-free pairs of permutations exist then adaptive security of the [BGW, CCD] protocols, in the presence of honest-looking parties, cannot be proven via black-box simulation. 1 See example in the third paragraph of the Introduction. 3.1 The problems in proving adaptive security: informal presentation 29 3.1.2 <p> Similar honest-looking protocols can be constructed for the <ref> [BGW, CCD] </ref> protocols. Consequently, if claw-free pairs of permutations exist then adaptive security of the [BGW, CCD] protocols, in the presence of honest-looking parties, cannot be proven via black-box simulation. 1 See example in the third paragraph of the Introduction. 3.1 The problems in proving adaptive security: informal presentation 29 3.1.2 Adaptive security in the computational setting In this subsection we sketch the extra difficulty encountered <p> In Subsection 3.3.2 we present our construction of non-committing encryption. We use the following result, attributed to <ref> [BGW, CCD] </ref>, as our starting point: 6 Theorem 3.3 The [BGW, CCD] protocols for computing any function of n inputs are (d n 3 e 1)-securely computable in a simulatable way, in the secure channels setting, in the presence of non-erasing parties and adaptive adversaries. 3.3.1 Adaptively secure computation given non-committing <p> In Subsection 3.3.2 we present our construction of non-committing encryption. We use the following result, attributed to <ref> [BGW, CCD] </ref>, as our starting point: 6 Theorem 3.3 The [BGW, CCD] protocols for computing any function of n inputs are (d n 3 e 1)-securely computable in a simulatable way, in the secure channels setting, in the presence of non-erasing parties and adaptive adversaries. 3.3.1 Adaptively secure computation given non-committing encryption Theorem 3.4 Let f be an n-ary function, t <p> Thus, ^ C C and jCj m. 4.3 Fail-Stop faults 59 2 4.3 Fail-Stop faults We show how to securely t-compute any function whose input is partitioned among n parties, when n 3t + 1 and the faults are Fail-Stop. Our costruction follows the outline of the first <ref> [BGW] </ref> construction (namely, the construction resilient against corrupted parties which only try to gather information but otherwise follow the protocol). <p> We describe how polynomial D () is generated. First, the parties generate a random polynomial H () of degree 2t and with H (0) = 0; namely, each party P i will have H (i). We first describe how the polynomial H () is shared in a synchronous setting <ref> [BGW] </ref>. Each party P i selects a random polynomial H i () of degree 2t with H i (0) = 0, and shares it among the parties; namely, each party P j receives H i (j). <p> This statement is formalized in Lemma 4.16 on page 70, and used in proving the security of the entire protocol. Let ~ d = D (1) : : : D (n), and let ~c = C (1) : : : C (n). <ref> [BGW] </ref> noted that there exists a fixed n fi n matrix M such that ~c = ~ dM . <p> Proposition 4.12 Let M be the n fi n matrix introduced in <ref> [BGW] </ref>. Then, the set of 2t-generated n-vectors is t-multipliable by M , when n 3t + 1. Proof: Recall that matrix M used in [BGW] is constructed as M = V 1 T V , where V is a (Vandermonde) n fi n matrix defined by V i;j = i j <p> Proposition 4.12 Let M be the n fi n matrix introduced in <ref> [BGW] </ref>. Then, the set of 2t-generated n-vectors is t-multipliable by M , when n 3t + 1. Proof: Recall that matrix M used in [BGW] is constructed as M = V 1 T V , where V is a (Vandermonde) n fi n matrix defined by V i;j = i j , and T is constructed by setting all but the first t + 1 rows of a Unit matrix to 0. (Let ~ d; <p> Set (C 0 ; fh i;j jj 2 C 0 g) =GShare [2t](0). Let d i = a i b i + j2C 0 h i;j . 2. Let M nfin be the matrix introduced in <ref> [BGW] </ref>. Set c i =MAT (d i ; M ). Output c i . Protocol FScompute [A](x i ) Party P i acts as follows, on local input x i , and given circuit A. 1. Set (C; fs i;j jj 2 Cg) =GShare [t](x i ). <p> Our AVSS scheme is resilient against t-limited (Byzantine) adversaries in a network of n parties, as long as n 4t + 1. Our construction uses ideas appearing in <ref> [BGW, FM, Fe] </ref>. In particular, [Fe] and [CR] describe different AVSS schemes, for n 4t + 1 and n 3t + 1, respectively (the [CR] scheme is presented in Chapter 5). <p> Finally, each party P i locally computes H (i) = j2C H j (i), and D (i) = A (i) B (i) + H (i). It remains to describe how each party P i shares its polynomial H i (). We use the <ref> [BGW] </ref> method. This method `has the effect' of sharing polynomial H i () in the `straightforward' way. <p> We prove this result in two steps. First we reduce the problem of secure computation in a synchronous network with n = 2t to the problem of secure computation in an asynchronous network with n = 3t. Next we use the results of <ref> [BGW] </ref> (and also Chor and Kushilevitz [CK]) that there exist functions that cannot be securely computed (or even approximated) when n 2t. Simple examples of such functions are the OR and AND functions of n boolean inputs. <p> Next we show, in Theorem 4.35, that there exist functions that cannot be d n 4 e-securely computed with no probability of error in an asynchronous network if general (Byzantine) adversaries are allowed. This proof is a generalization of a technique used in <ref> [BGW] </ref>. Both Theorems 4.34 and 4.35 apply even to non-adaptive adversaries. We remark that Ben-Or Kelmer and T. <p> This proof is a generalization of a technique used in [BGW]. Both Theorems 4.34 and 4.35 apply even to non-adaptive adversaries. We remark that Ben-Or Kelmer and T. Rabin [BKR] show, using techniques from <ref> [BGW, CCD, CR] </ref>, how any function can be asynchronously (d n 3 e 1)-securely computed, in the presence of Byzantine adversaries, with exponentially small (but positive) probability of either not terminating or having wrong outputs. For the proof, we use the following notations. <p> Informally, a protocol is t-private if every adversary gathers no information from executing the protocol, other than the output of the uncorrupted parties (namely the computed function value). Theorem 4.33 <ref> [BGW, CK] </ref>: For every n 2, there exist boolean functions f such that there is no synchronous d n 2 e-private protocol for n parties that approximates f . Some intuition for the proof of Theorem 4.33 follows. <p> outputs and the protocol is not 1-secure. 2 Remark: Using a technique similar to the technique of the above proof, it can be shown that there exist functions that cannot be securely computed in a synchronous network where a third of the parties are corrupted. (This result is stated in <ref> [BGW] </ref>.) Moreover, the result for the synchronous case is much stronger: consider a secure, synchronous protocol for computing the AND function of three variables (i.e., AND (x 1 ; x 2 ; x 3 ) = 1 iff x 1 = x 2 = x 3 = 1) in a network <p> Finally, to the best of our knowledge this is the first (and so far only) place where a full proof of security of a construction for securely computing any function appears, in any model of computation. In particular, a security proof of the <ref> [BGW] </ref> construction can be extracted from the proof presented here. The chapter on asynchronous Byzantine agreement (Chapter 5) applies ideas and techniques from secure multiparty computation to constructing the first asynchronous Byzantine agreement (BA) protocol with optimal resilience and polynomial complexity.
Reference: [BKR] <author> M. Ben-Or, B. Kelmer and T. Rabin, </author> <title> "Asynchronous Secure Computation with Optimal Resilience", </title> <booktitle> 13th PODC, 1994 pp. </booktitle> <pages> 183-192. </pages>
Reference-contexts: Subsequent to our work Ben-Or, Kelmer and Rabin showed, using very different constructions, how any function can be (d n 3 e 1)-securely computed in the presence of Byzantine adversaries, and with exponentially small probability of error <ref> [BKR] </ref>. Our constructions adapt the [BGW] synchronous constructions to an asynchronous environment. Furthermore, we develop several new tools which may be of separate interest. <p> Put together, these constructions constitute an asynchronous (d n 3 e 1)-resilient BA protocol. We note that our (d n 3 e 1)-resilient AVSS scheme has applications in other contexts as well (for instance, in <ref> [BE, BKR] </ref>). We offer an intuitive exposition of the difficulties encountered in trying to devise an (d n 3 e 1)-resilient AVSS scheme. <p> Furthermore, every uncorrupted party has C U fl i , where U fl i is the value of U i upon the completion of protocol . Before presenting our construction, let us remark that in <ref> [BKR] </ref> a simpler construction of an (d n 3 e 1)-reslient protocol for agreement on a core set is described. Furthermore, the [BKR] protocol runs in constant expected time. Let n 3t + 1. <p> Before presenting our construction, let us remark that in <ref> [BKR] </ref> a simpler construction of an (d n 3 e 1)-reslient protocol for agreement on a core set is described. Furthermore, the [BKR] protocol runs in constant expected time. Let n 3t + 1. Our construction, with parameters m and M , consists of two phases: Phase I: In the first phase, each party first waits until its dynamic input is of size m; then, it performs log 2 n iterations. <p> This proof is a generalization of a technique used in [BGW]. Both Theorems 4.34 and 4.35 apply even to non-adaptive adversaries. We remark that Ben-Or Kelmer and T. Rabin <ref> [BKR] </ref> show, using techniques from [BGW, CCD, CR], how any function can be asynchronously (d n 3 e 1)-securely computed, in the presence of Byzantine adversaries, with exponentially small (but positive) probability of either not terminating or having wrong outputs. For the proof, we use the following notations.
Reference: [BGH + 1] <author> R. Bird, I. Gopal, A. Herzberg, P. Janson, S. Kutten, R. Molva, and M. Yung, </author> <title> "A family of light-weight protocols for authentication and key distribution", </title> <note> Submitted to IEEE T. Networking, </note> <year> 1993. </year>
Reference-contexts: Security mechanisms, therefore, avoid sending 1.6 Proactive security: Maintaining security in the presence of transient faults 15 the password "on the clear". Instead, they use the user's password to derive a session key, with which they secure the communication. In both Kerberos [MNSS] and NetSP / KryptoKnight <ref> [BGH + 1] </ref>, this is done by using the password as a key for exchanging a random session key; this method also allows NetSP / KryptoKnight to authenticate the user automatically to additional systems (`single sign on').
Reference: [BGH + 2] <author> R. Bird, I. Gopal, A. Herzberg, P. Janson, S. Kutten, R. Molva, and M. Yung, </author> <title> "Systematic design of a family of attack-resistant authentication protocols", </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <note> 11(5) (Special issue on Secure Communications), June 1993, pp.679-693. See also a different version in Crypto 91. </note>
Reference-contexts: However, P i can, when unable to authenticate a user, compare each of the f j;0 (i) values with the user, e.g. using the 2PP protocol <ref> [BGH + 2] </ref>, without exposing any of the values. If there are more than half of the values which match, the server and the user may use the exclusive or of these values only.
Reference: [BM] <author> M. Blum, and S. Micali, </author> <title> "How to generate Cryptographically strong sequences of pseudo-random bits", </title> <journal> em SIAM J. on Computing, </journal> <volume> Vol. 13, </volume> <year> 1984, </year> <pages> pp. 850-864. </pages>
Reference-contexts: Such an initial set-up is not desirable in practice and does not resolve the theoretically important problem of dealing with a setting in which no secret information is shared a-priori. Our scheme uses a collection of trapdoor permutations together with a corresponding hard-core predicate <ref> [BM, Y2, GrL] </ref>.
Reference: [Br] <author> G. Bracha, </author> <title> "An Asynchronous b(n1)=3c-resilient Consensus Protocol", </title> <booktitle> 3rd PODC, </booktitle> <year> 1984, </year> <pages> pp. 154-162. </pages>
Reference-contexts: Furthermore, the impossibility result of Fischer, Lynch and Paterson for deterministic protocols [FLP] implies that any (randomized) protocol reaching BA must have non-terminating runs. Bracha describes an (d n 3 e 1)-resilient asynchronous BA protocol which runs in 2 fi (n) expected time <ref> [Br] </ref>. Feldman and Micali describe a synchronous (d n 3 e 1)-resilient BA protocol, which runs in constant expected time [FM]. Feldman [Fe] generalizes the [FM] construction to an asynchronous setting, yielding a constant expected time, (d n 4 e 1)-resilient asynchronous BA protocol. <p> Rabin [MRa2] describes an (d n 8 e 1)-resilient BA protocol that runs in constant expected time, provided that all the parties have access to a `global coin' (namely, a common source of randomness). Rabin's construction can be used in synchronous as well as asynchronous networks. Bracha <ref> [Br] </ref> improved the resilience of Rabin's protocol to d n 3 e 1. <p> We stress that although dummy ciphertexts appear 3 This "non-committing property" is reminiscent of the "Chameleon blobs" of <ref> [Br] </ref>. Those are commitment schemes where the recipient of a commitment c can generate by himself de-commitments of c to both 0 and 1. <p> If a uncorrupted party completed the protocol, with output m, then it has sent an (ECHO; m) message to all the parties, thus every uncorrupted party will complete the protocol with output m. 2 Bracha <ref> [Br] </ref> describes an (d n 3 e 1)-resilient Broadcast protocol for the Byzantine setting. For self-containment, we present Bracha's Byzantine Broadcast (BB) protocol in Figure 4-2. Convention: in the sequel, we use "party P received an m broadcast" to shorthand "party P completed a Broadcast protocol with output m". <p> All the computations in the sequel are done in F . The BA protocol employs the idea of using `common coins' to reach agreement, as follows. BA using Common Coin. This part of our protocol follows the constructions of Rabin, Bracha and Feldman <ref> [MRa2, Br, Fe] </ref>. The protocol proceeds in rounds. In each round, each party has a `modified input' value. In the first round, the modified input of each party is his local input. In each round the parties invoke two protocols, called Vote and Common Coin. <p> For self containment we sketch the [TRa, RB] construction in Figure 5-1. 1 5.3.2 Broadcast We use the same definition of Broeadcast as in Chapter 4 (see Section 4.2.2). We also use the elegant implementation of Bracha <ref> [Br] </ref>, described there. 5.4 Asynchronous Recoverable Sharing | A-RS Unlike synchronous systems, in an asynchronous system it is not possible to decide whether a party from which messages do not arrive is faulty or just slow.
Reference: [BCC] <author> G. Brassard, D. Chaum and C. Crepeau, </author> <title> "Minimum Disclosure Proofs of Knowledge", </title> <journal> Journal of Computing and System Sciences, </journal> <volume> Vol. 37, No. 2, </volume> <year> 1988, </year> <pages> pp. 156-189. </pages>
Reference: [C] <author> R. Canetti, </author> <title> "Asynchronous Secure Computation", </title> <type> Technical Report no. 755, </type> <institution> CS department, Technion, </institution> <year> 1992. </year>
Reference: [CDNO] <author> R. Canetti, C. Dwork, M. Naor and R. Ostrovsky, "Deniable Encryptions", </author> <type> manuscript. </type>
Reference: [CFGN] <author> R. Canetti, U. Feige, O. Goldreich and M. Naor, </author> <title> "Adaptively Secure Computation", </title> <booktitle> 28th STOC, </booktitle> <year> 1996. </year>
Reference: [CG] <author> R. Canetti and R. Genaro, </author> <title> "Deniable Multiparty Computation", </title> <type> manuscript. </type>
Reference: [CHH] <author> R. Canetti, S. Halevi and A. Herzberg, </author> <title> "How to Maintain Authenticated Communication in the Presence of Break-ins", </title> <type> manuscript. </type>
Reference-contexts: We hope and believe that this approach will become a standard in the effort to protect computer systems. In fact, a number of works have already followed this approach (e.g., <ref> [ChH, HJKY, CHH, HJJKY] </ref>). Subsequent and future work. We mention two directions for subsequent research. The first deals with an additional security requirements from multiparty protocols. Namely, we require that the computation will not leave a `trace' that can be later used against the parties. <p> For instance, the adversary may always prevent the parties from completing the computation, by simply not delivering messages.) A somewhat restricted definition, as well as a solution for a certain (quite powerful) adversary model is presented in <ref> [CHH] </ref>. Still, many questions remain open.
Reference: [CaH] <author> R. Canetti and A. Herzberg, </author> <title> "Maintaining security in the presence of transient faults", </title> <booktitle> Crypto' 94, </booktitle> <year> 1994, </year> <pages> pp. 425-439. </pages>
Reference: [CR] <author> R. Canetti and T. Rabin, </author> <title> "Optimal Asynchronous Byzantine Agreement", </title> <booktitle> 25th STOC, </booktitle> <year> 1993, </year> <pages> pp. 42-51. </pages>
Reference-contexts: Our constructions adapt the [BGW] synchronous constructions to an asynchronous environment. Furthermore, we develop several new tools which may be of separate interest. We describe a constant time, errorless Asynchronous Verifiable Secret Sharing (AVSS) scheme for n 4t+1. (different constructions <ref> [Fe, CR] </ref> have a small probability of error.) Our AVSS scheme employs a method for `on-line' error correcting of Generalized Reed Solomon codes, as well as a `specially tailored' approximation scheme for the maximum-clique problem in a graph. <p> Our AVSS scheme is resilient against t-limited (Byzantine) adversaries in a network of n parties, as long as n 4t + 1. Our construction uses ideas appearing in [BGW, FM, Fe]. In particular, [Fe] and <ref> [CR] </ref> describe different AVSS schemes, for n 4t + 1 and n 3t + 1, respectively (the [CR] scheme is presented in Chapter 5). However, in those schemes the parties have a small probability of error in reconstructing the secret (and in [CR] also a small probability of not terminating), whereas <p> Our construction uses ideas appearing in [BGW, FM, Fe]. In particular, [Fe] and <ref> [CR] </ref> describe different AVSS schemes, for n 4t + 1 and n 3t + 1, respectively (the [CR] scheme is presented in Chapter 5). However, in those schemes the parties have a small probability of error in reconstructing the secret (and in [CR] also a small probability of not terminating), whereas our scheme has no probability of error. <p> In particular, [Fe] and <ref> [CR] </ref> describe different AVSS schemes, for n 4t + 1 and n 3t + 1, respectively (the [CR] scheme is presented in Chapter 5). However, in those schemes the parties have a small probability of error in reconstructing the secret (and in [CR] also a small probability of not terminating), whereas our scheme has no probability of error. We describe our AVSS scheme as a preamble for our construction for Byzantine adversaries. <p> This proof is a generalization of a technique used in [BGW]. Both Theorems 4.34 and 4.35 apply even to non-adaptive adversaries. We remark that Ben-Or Kelmer and T. Rabin [BKR] show, using techniques from <ref> [BGW, CCD, CR] </ref>, how any function can be asynchronously (d n 3 e 1)-securely computed, in the presence of Byzantine adversaries, with exponentially small (but positive) probability of either not terminating or having wrong outputs. For the proof, we use the following notations.
Reference: [CCD] <author> D. Chaum, C. Crepeau and I Damgard, </author> <title> "Multiparty unconditionally secure protocols", </title> <booktitle> 20th STOC, </booktitle> <year> 1988, </year> <pages> pp. 11-19. </pages>
Reference-contexts: In the case of Byzantine adversaries they show (d n 2 e 1)-secure protocols for computing any function. Their protocols can be shown secure in the presence of non-adaptive adversaries. Ben-Or, Goldwasser and Wigderson [BGW] (and, independently, Chaum, Crepeau and Damgard <ref> [CCD] </ref>) study secure multiparty computation in the secure channels setting. They show that: (a) If the adversary is eavesdropping then there exist (d n 2 e 1)-secure protocols for computing any function. (b) if the adversary is Byzantine, then any function can be (d n 3 e 1)-securely computed. <p> We elaborate on this point in the sequel.) Therefore, the adversary is much more powerful in the presence of semi-honest parties. The more allowed "internal deviation" from the protocol, the stronger the adversary becomes. We first consider the secure channels setting. Here the <ref> [BGW, CCD] </ref> protocols can be proven adaptively secure in the presence of non-erasing parties (see Section 1.2.1). Fundamental problems arise when trying to prove adaptive security of protocols in the presence of more general types of semi-honest parties. We sketch these problems. <p> Adaptively secure protocols for computing any function exist in the presence of non-erasing parties (e.g., <ref> [BGW, CCD] </ref>). However, in contrast with popular belief, not every non-adaptively secure protocol is also adaptively secure in the presence of non-erasing parties. <p> Now, if this honest-looking variant of fi is shown secure via an efficient black-box simulation as described above, then the constructed simulator can be used to find claws between f 0 and f 1 . Similar honest-looking protocols can be constructed for the <ref> [BGW, CCD] </ref> protocols. Consequently, if claw-free pairs of permutations exist then adaptive security of the [BGW, CCD] protocols, in the presence of honest-looking parties, cannot be proven via black-box simulation. 1 See example in the third paragraph of the Introduction. 3.1 The problems in proving adaptive security: informal presentation 29 3.1.2 <p> Similar honest-looking protocols can be constructed for the <ref> [BGW, CCD] </ref> protocols. Consequently, if claw-free pairs of permutations exist then adaptive security of the [BGW, CCD] protocols, in the presence of honest-looking parties, cannot be proven via black-box simulation. 1 See example in the third paragraph of the Introduction. 3.1 The problems in proving adaptive security: informal presentation 29 3.1.2 Adaptive security in the computational setting In this subsection we sketch the extra difficulty encountered <p> In Subsection 3.3.2 we present our construction of non-committing encryption. We use the following result, attributed to <ref> [BGW, CCD] </ref>, as our starting point: 6 Theorem 3.3 The [BGW, CCD] protocols for computing any function of n inputs are (d n 3 e 1)-securely computable in a simulatable way, in the secure channels setting, in the presence of non-erasing parties and adaptive adversaries. 3.3.1 Adaptively secure computation given non-committing <p> In Subsection 3.3.2 we present our construction of non-committing encryption. We use the following result, attributed to <ref> [BGW, CCD] </ref>, as our starting point: 6 Theorem 3.3 The [BGW, CCD] protocols for computing any function of n inputs are (d n 3 e 1)-securely computable in a simulatable way, in the secure channels setting, in the presence of non-erasing parties and adaptive adversaries. 3.3.1 Adaptively secure computation given non-committing encryption Theorem 3.4 Let f be an n-ary function, t <p> This proof is a generalization of a technique used in [BGW]. Both Theorems 4.34 and 4.35 apply even to non-adaptive adversaries. We remark that Ben-Or Kelmer and T. Rabin [BKR] show, using techniques from <ref> [BGW, CCD, CR] </ref>, how any function can be asynchronously (d n 3 e 1)-securely computed, in the presence of Byzantine adversaries, with exponentially small (but positive) probability of either not terminating or having wrong outputs. For the proof, we use the following notations. <p> First, the dealer sends each party a share of the secret, as in the previous schemes. The parties will then `commit' to their shares by re-sharing them using AWSS. Next, the parties will make sure, using a cut-and-choose method (as in <ref> [CCD, Fe] </ref>), that enough AWSS-Sharings have been successful and that the `committed upon' shares indeed define a secret. We describe the scheme in some more detail. Full details appear in Figure 5-7. Sharing protocol. The dealer, sharing a secret s, chooses a random polynomial f (x) for s.
Reference: [CD] <author> B. Chor and C. Dwork, </author> <title> "Randomization in Byzantine Agreement", </title> <booktitle> Advances in Computing Research, </booktitle> <volume> Vol. 5, </volume> <year> 1989, </year> <pages> pp. 443-497. </pages>
Reference-contexts: The BA problem was extensively investigated in various adversary models (out of the ones characterized at the beginning of the introduction). We refer the interested reader to 1.5 Asynchronous Byzantine Agreement 11 the surveys of Fischer [F] and Chor and Dwork <ref> [CD] </ref>. However, despite extensive research a few important questions have remained open. One of these questions is the focus of this work. Bounds on the resilience of BA protocols were proved in [PSL]. <p> Feldman [Fe] generalizes the [FM] construction to an asynchronous setting, yielding a constant expected time, (d n 4 e 1)-resilient asynchronous BA protocol. All of these works allow computationally unbounded adversaries ([FM, Fe] assume secure channels). A long standing open question (cf. <ref> [FM, CD] </ref>) is whether there exists an (d n 3 e 1)- resilient asynchronous BA protocol with polynomial (time and message) complexity. We answer this question in the affirmative. We consider a completely asynchronous network of n parties with secure channels, and computationally unlimited, adaptive adversaries.
Reference: [CGMA] <author> B. Chor, S. Goldwasser, S. Micali and B. Awerbuch, </author> <title> "Verifiable Secret Sharing and Achieving Simultaneity in the Presence of Faults", </title> <booktitle> 26th FOCS, </booktitle> <year> 1985, </year> <pages> pp. 383-395. </pages>
Reference-contexts: The [FM] protocol for generating this `global coin' relies heavily on a Verifiable Secret Sharing (VSS) scheme. (The notion of VSS was introduced in <ref> [CGMA] </ref>.) Feldman [Fe] describes an asynchronous construction for `global coin' and BA, given an r-resilient Asynchronous VSS (AVSS) scheme.
Reference: [CK] <author> B. Chor and E. Kushilevitz, </author> <title> "A Zero-One Law for Boolean Privacy", </title> <journal> SIAM J. on Disc. Math., </journal> <volume> Vol. 4, no. 1, </volume> <year> 1991, </year> <note> pp.36-47. Bibliography 143 </note>
Reference-contexts: Goldwasser and Levin build on a long sequence of works studying the case of Byzantine adversaries limited to PPT, where a majority of the parties may be corrupted [GwL]. Chor and Kushilevitz study secure multiparty computation with corrupted majority of the parties in the secure channels setting <ref> [CK] </ref>. Goldreich, Goldwasser and Linial study secure multiparty computation in the presence of insecure channels and computationally unlimited adversaries [GGL]. Ostrovsky and Yung study secure multiparty computation in the presence of secure channels and mobile adversaries [OY]. <p> We prove this result in two steps. First we reduce the problem of secure computation in a synchronous network with n = 2t to the problem of secure computation in an asynchronous network with n = 3t. Next we use the results of [BGW] (and also Chor and Kushilevitz <ref> [CK] </ref>) that there exist functions that cannot be securely computed (or even approximated) when n 2t. Simple examples of such functions are the OR and AND functions of n boolean inputs. <p> protocol , input ~x, some set G of parties, two adversaries A and A 0 and some input ~x), then the output of the parties in G is identically distributed with adversaries A and A 0 . 4.6 Lower bounds 94 4.6.1 Fail-Stop adversaries We use the following result of <ref> [CK] </ref>. This result refers to synchronous networks where the adversaries are eavesdropping (namely, the corrupted parties only try to gather information, but otherwise follow the protocol). <p> Informally, a protocol is t-private if every adversary gathers no information from executing the protocol, other than the output of the uncorrupted parties (namely the computed function value). Theorem 4.33 <ref> [BGW, CK] </ref>: For every n 2, there exist boolean functions f such that there is no synchronous d n 2 e-private protocol for n parties that approximates f . Some intuition for the proof of Theorem 4.33 follows.
Reference: [CM] <author> B. Chor and L. Moscovici, </author> <title> "Solvability in Asynchronous Environments", </title> <booktitle> 30th FOCS, </booktitle> <year> 1989. </year>
Reference-contexts: Fischer, Lynch and Paterson [FLP] showed that deterministic protocols cannot achieve even the basic goal of Consensus in an asynchronous network in the presence of even one Fail-Stop fault. Consequently, every (randomized) protocol reaching Consensus must have some infinite runs (on every input). Chor and Moscovici <ref> [CM] </ref> characterized the possible "tasks" in the presence of t Fail-Stop faults: roughly speaking, the output of any computation, in the presence of t potential faults, cannot be based on more than n t of the inputs (since up to t parties may never join the computation). <p> by party P 1 will be the same as the fifth bit in the first message that party P 2 sent on its private channel to P 3 ... thus `breaking' the privacy of this channel. 3 Chor and Moscovici describe this property of the asynchronous model in more detail <ref> [CM] </ref>.
Reference: [ChH] <author> C. Chow and A. Herzberg, </author> <title> "A reconstructible proactive pseudo-randomness protocol", </title> <booktitle> Work in progress, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: We hope and believe that this approach will become a standard in the effort to protect computer systems. In fact, a number of works have already followed this approach (e.g., <ref> [ChH, HJKY, CHH, HJJKY] </ref>). Subsequent and future work. We mention two directions for subsequent research. The first deals with an additional security requirements from multiparty protocols. Namely, we require that the computation will not leave a `trace' that can be later used against the parties. <p> For instance, the adversary may always prevent the parties from completing the computation, by simply not delivering messages.) A somewhat restricted definition, as well as a solution for a certain (quite powerful) adversary model is presented in <ref> [CHH] </ref>. Still, many questions remain open.
Reference: [DP] <author> A. De-Santis and G. Persiano, </author> <title> "Zero-Knowledge proofs of knowledge without interaction", </title> <booktitle> 33rd FOCS, </booktitle> <pages> pp. 427-436, </pages> <year> 1992. </year>
Reference-contexts: The public description of f v is y 4 = g v . The `trapdoor' is u 4 = v 1 (modp 1). 10 A similar idea was used in <ref> [DP] </ref>. 3.4 Honest-looking parties 47 This construction has the following properties: * Although it is hard to compute f v if only p; g; y are known, it is easy to generate random elements x 2 R Z fl p together with f v (x): choose z 2 R Z fl
Reference: [DH] <author> W. Diffie and M. Hellman, </author> <title> "New directions in cryptography", </title> <journal> IEEE Trans. on Info. Theory, </journal> <volume> IT-22(6), </volume> <year> 1976, </year> <pages> pp. 644-654. </pages>
Reference: [Ed] <author> J. Edmonds, </author> <title> `Paths, Trees, and Flowers", </title> <journal> Canadian J. of Math., </journal> <volume> Vol.17, </volume> <year> 1965, </year> <pages> pp. 449-467. </pages>
Reference-contexts: We call such a pair of sets an (n; t)-star. In the rest of this section, we refer to the complementary graph only. In our procedure, we find a maximum matching in the graph (say, using <ref> [Ed] </ref> or [MV]). 18 Based on this matching, we compute sets C; D of nodes, and check whether (C; D) form an (n; t)-star in the graph.
Reference: [DDN] <author> D. Dolev, C. Dwork and M. Naor, </author> <title> "Non-malleable Cryptography", </title> <booktitle> 23rd STOC, </booktitle> <year> 1991. </year>
Reference: [ER] <author> M. Elchin and J. Rochlis, </author> <title> "With microscope and tweezers: An analysis of the internet virus of november 1988", </title> <booktitle> IEEE Symp. on Security and Privacy, </booktitle> <year> 1989, </year> <pages> pp. 326-343. </pages>
Reference-contexts: We use the generic term break-ins for all these attacks. Security administrators often find break-ins more alarming than external attacks, such as line tappings. Break-ins are often temporary, or transient (e.g., <ref> [ER] </ref>). Thus the paradigm of "bad once means bad forever" does not hold here. Still, known solutions to break-ins do not include mechanisms for taking advantage of possible automatic recovery of a component, in case that the fault is transient.
Reference: [EGL] <author> S. Even, O. Goldreich and A. Lempel, </author> <title> "A randomized protocol for signing contracts", </title> <journal> CACM, </journal> <volume> vol. 28, No. 6,1985, </volume> <pages> pp. 637-647. </pages>
Reference-contexts: We use Oblivious Transfer <ref> [MRa1, EGL] </ref> in our constructions. Oblivious Transfer (OT) is a protocol executed by a sender S with inputs s 1 and s 2 , and by a receiver R with input t 2 f1; 2g. <p> In particular S should not know whether R learns s 1 or s 2 . We are only concerned with the case where R is uncorrupted and non-erasing. We use the implementation of OT described in [GMW] (which in turn originates in <ref> [EGL] </ref>). This implementation has an additional property, discussed below, that is useful in our construction. For self containment we sketch, in Figure 3-5, the [GMW] protocol for OT of one bit. It can be easily verified that the receiver outputs the correct value of t in Step 4.
Reference: [Fe] <author> P. Feldman, </author> <title> "Asynchronous Byzantine Agreement in Constant Expected Time", </title> <type> unpublished manuscript, </type> <year> 1989. </year>
Reference-contexts: Our constructions adapt the [BGW] synchronous constructions to an asynchronous environment. Furthermore, we develop several new tools which may be of separate interest. We describe a constant time, errorless Asynchronous Verifiable Secret Sharing (AVSS) scheme for n 4t+1. (different constructions <ref> [Fe, CR] </ref> have a small probability of error.) Our AVSS scheme employs a method for `on-line' error correcting of Generalized Reed Solomon codes, as well as a `specially tailored' approximation scheme for the maximum-clique problem in a graph. <p> Bracha describes an (d n 3 e 1)-resilient asynchronous BA protocol which runs in 2 fi (n) expected time [Br]. Feldman and Micali describe a synchronous (d n 3 e 1)-resilient BA protocol, which runs in constant expected time [FM]. Feldman <ref> [Fe] </ref> generalizes the [FM] construction to an asynchronous setting, yielding a constant expected time, (d n 4 e 1)-resilient asynchronous BA protocol. All of these works allow computationally unbounded adversaries ([FM, Fe] assume secure channels). <p> The [FM] protocol for generating this `global coin' relies heavily on a Verifiable Secret Sharing (VSS) scheme. (The notion of VSS was introduced in [CGMA].) Feldman <ref> [Fe] </ref> describes an asynchronous construction for `global coin' and BA, given an r-resilient Asynchronous VSS (AVSS) scheme. <p> This construction is min (r; d n 3 e 1)-resilient. (d n 4 e 1)- resilient AVSS schemes are presented in <ref> [Fe, BCG] </ref>. (The [BCG] scheme is presented in Section 4.4.) Up to now, no known AVSS scheme has been more than (d n 4 e 1)-resilient. In this chapter, we construct an (d n 3 e 1)-resilient AVSS scheme. <p> With probability 1, all the uncorrupted parties eventually complete the protocol (i.e., terminate locally). * Correctness. All the uncorrupted parties that complete the protocol have an identical output. Furthermore, if all the uncorrupted parties have the same input, denoted , then all the uncorrupted parties output . Feldman <ref> [Fe] </ref> describes an (d n 4 e 1)-resilient asynchronous BA protocol, running in constant expected time 5 . (d n 3 e 1)-resilient Consensus can be reached by substituting the AVSS scheme in Chapter 5 by a simple secret sharing scheme. (For instance, use the scheme described in Section 4.3.) 5 <p> Furthermore, for every 6 This problem of assuring a large intersection of the sets of a uniform collection was previously addressed by <ref> [Fe] </ref>, as well as [BE]. Both works present partial solutions to this problem: let m = n t; Feldman [Fe] made sure that the intersection of the sets held by all the uncorrupted parties is of size fi (n) (but not necessarily m); Ben-Or and El-Yaniv [BE] made sure that the <p> Furthermore, for every 6 This problem of assuring a large intersection of the sets of a uniform collection was previously addressed by <ref> [Fe] </ref>, as well as [BE]. Both works present partial solutions to this problem: let m = n t; Feldman [Fe] made sure that the intersection of the sets held by all the uncorrupted parties is of size fi (n) (but not necessarily m); Ben-Or and El-Yaniv [BE] made sure that the intersection of the sets held by n 2t uncorrupted parties is of size at least m. 4.2 Primitives 58 <p> Our AVSS scheme is resilient against t-limited (Byzantine) adversaries in a network of n parties, as long as n 4t + 1. Our construction uses ideas appearing in <ref> [BGW, FM, Fe] </ref>. In particular, [Fe] and [CR] describe different AVSS schemes, for n 4t + 1 and n 3t + 1, respectively (the [CR] scheme is presented in Chapter 5). <p> Our AVSS scheme is resilient against t-limited (Byzantine) adversaries in a network of n parties, as long as n 4t + 1. Our construction uses ideas appearing in [BGW, FM, Fe]. In particular, <ref> [Fe] </ref> and [CR] describe different AVSS schemes, for n 4t + 1 and n 3t + 1, respectively (the [CR] scheme is presented in Chapter 5). <p> All the computations in the sequel are done in F . The BA protocol employs the idea of using `common coins' to reach agreement, as follows. BA using Common Coin. This part of our protocol follows the constructions of Rabin, Bracha and Feldman <ref> [MRa2, Br, Fe] </ref>. The protocol proceeds in rounds. In each round, each party has a `modified input' value. In the first round, the modified input of each party is his local input. In each round the parties invoke two protocols, called Vote and Common Coin. <p> Given that all the honest parties complete all Common Coin protocols they invoked, then each round of the Byzantine Agreement protocol terminates in constant time. Common Coin using AVSS. Our construction follows Feldman, and Feldman and Micali <ref> [Fe, FM] </ref>. The protocol proceeds roughly as follows. First, each party shares n random secrets using our AVSS scheme. Once a party is assured that enough secrets have been properly shared, he starts reconstructing the relevant secrets. <p> First, the dealer sends each party a share of the secret, as in the previous schemes. The parties will then `commit' to their shares by re-sharing them using AWSS. Next, the parties will make sure, using a cut-and-choose method (as in <ref> [CCD, Fe] </ref>), that enough AWSS-Sharings have been successful and that the `committed upon' shares indeed define a secret. We describe the scheme in some more detail. Full details appear in Figure 5-7. Sharing protocol. The dealer, sharing a secret s, chooses a random polynomial f (x) for s.
Reference: [FM] <author> P. Feldman and S. Micali, </author> <title> "An Optimal Algorithm For Synchronous Byzantine Agreement", </title> <booktitle> 20th STOC, </booktitle> <year> 1988, </year> <pages> pp. 148-161. </pages>
Reference-contexts: Bracha describes an (d n 3 e 1)-resilient asynchronous BA protocol which runs in 2 fi (n) expected time [Br]. Feldman and Micali describe a synchronous (d n 3 e 1)-resilient BA protocol, which runs in constant expected time <ref> [FM] </ref>. Feldman [Fe] generalizes the [FM] construction to an asynchronous setting, yielding a constant expected time, (d n 4 e 1)-resilient asynchronous BA protocol. All of these works allow computationally unbounded adversaries ([FM, Fe] assume secure channels). <p> Bracha describes an (d n 3 e 1)-resilient asynchronous BA protocol which runs in 2 fi (n) expected time [Br]. Feldman and Micali describe a synchronous (d n 3 e 1)-resilient BA protocol, which runs in constant expected time <ref> [FM] </ref>. Feldman [Fe] generalizes the [FM] construction to an asynchronous setting, yielding a constant expected time, (d n 4 e 1)-resilient asynchronous BA protocol. All of these works allow computationally unbounded adversaries ([FM, Fe] assume secure channels). <p> Feldman [Fe] generalizes the [FM] construction to an asynchronous setting, yielding a constant expected time, (d n 4 e 1)-resilient asynchronous BA protocol. All of these works allow computationally unbounded adversaries ([FM, Fe] assume secure channels). A long standing open question (cf. <ref> [FM, CD] </ref>) is whether there exists an (d n 3 e 1)- resilient asynchronous BA protocol with polynomial (time and message) complexity. We answer this question in the affirmative. We consider a completely asynchronous network of n parties with secure channels, and computationally unlimited, adaptive adversaries. <p> Bracha [Br] improved the resilience of Rabin's protocol to d n 3 e 1. Furthermore, He proposed a very simple (however inefficient) scheme for implementing `global coin'. (This inefficiency results in exponential running time.) The essence of the <ref> [FM] </ref> (d n 3 e 1)-resilient synchronous BA protocol is an efficient scheme for generating such a `global coin'; once this global coin is generated, the parties proceed in a similar manner to Rabin's and Bracha's protocols. The [FM] protocol for generating this `global coin' relies heavily on a Verifiable Secret <p> coin'. (This inefficiency results in exponential running time.) The essence of the <ref> [FM] </ref> (d n 3 e 1)-resilient synchronous BA protocol is an efficient scheme for generating such a `global coin'; once this global coin is generated, the parties proceed in a similar manner to Rabin's and Bracha's protocols. The [FM] protocol for generating this `global coin' relies heavily on a Verifiable Secret Sharing (VSS) scheme. (The notion of VSS was introduced in [CGMA].) Feldman [Fe] describes an asynchronous construction for `global coin' and BA, given an r-resilient Asynchronous VSS (AVSS) scheme. <p> Our AVSS scheme is resilient against t-limited (Byzantine) adversaries in a network of n parties, as long as n 4t + 1. Our construction uses ideas appearing in <ref> [BGW, FM, Fe] </ref>. In particular, [Fe] and [CR] describe different AVSS schemes, for n 4t + 1 and n 3t + 1, respectively (the [CR] scheme is presented in Chapter 5). <p> Given that all the honest parties complete all Common Coin protocols they invoked, then each round of the Byzantine Agreement protocol terminates in constant time. Common Coin using AVSS. Our construction follows Feldman, and Feldman and Micali <ref> [Fe, FM] </ref>. The protocol proceeds roughly as follows. First, each party shares n random secrets using our AVSS scheme. Once a party is assured that enough secrets have been properly shared, he starts reconstructing the relevant secrets.
Reference: [F] <author> M. Fischer, </author> <title> "The Consensus Problem in Unreliable Distributed System", </title> <type> Technical Report, </type> <institution> Yale University, </institution> <year> 1983. </year>
Reference-contexts: Still, privacy-maintaining primitives will play a key role in our construction. The BA problem was extensively investigated in various adversary models (out of the ones characterized at the beginning of the introduction). We refer the interested reader to 1.5 Asynchronous Byzantine Agreement 11 the surveys of Fischer <ref> [F] </ref> and Chor and Dwork [CD]. However, despite extensive research a few important questions have remained open. One of these questions is the focus of this work. Bounds on the resilience of BA protocols were proved in [PSL]. <p> The construction is quite involved, using many layers and techniques. The main technical contributions are, in our opinion, two: First, we adapt techniques from [RB, TRa] to construct the first Asynchronous Verifiable Secret Sharing (AVSS) scheme with optimal resilience. Next, we slightly modify the <ref> [F] </ref> scheme (which was never published and unaccessible) for reaching BA given an AVSS scheme, and present it in a (hopefully) readable way. Indeed, this work is the first accessible source to any asynchronous BA protocol with linear resilience and polynomial complexity.
Reference: [FLP] <author> M. Fischer, N. Lynch and M. Paterson, </author> <title> "Impossibility of Distributed Consensus with One Faulty Process", </title> <journal> JACM, </journal> <volume> Vol. 32, no. 2, </volume> <year> 1985, </year> <pages> pp. 374-382. </pages>
Reference-contexts: It can be seen that in this case, the security (in the synchronous sense, as defined in Chapter 2) of the protocol is maintained. However, asynchrony combined with the possibility of faults has devastating consequences on the computational capabilities of a network. Fischer, Lynch and Paterson <ref> [FLP] </ref> showed that deterministic protocols cannot achieve even the basic goal of Consensus in an asynchronous network in the presence of even one Fail-Stop fault. Consequently, every (randomized) protocol reaching Consensus must have some infinite runs (on every input). <p> Karlin and Yao [KY] generalized this result to randomized protocols. These results apply also to asynchronous networks. Furthermore, the impossibility result of Fischer, Lynch and Paterson for deterministic protocols <ref> [FLP] </ref> implies that any (randomized) protocol reaching BA must have non-terminating runs. Bracha describes an (d n 3 e 1)-resilient asynchronous BA protocol which runs in 2 fi (n) expected time [Br]. <p> We explicitly require Termination to stress the importance and delicacy of this requirement in an asynchronous setting. In particular, we note that Consensus is a (very limited) special case of secure computation. The <ref> [FLP] </ref> impossibility result for deterministic protocols implies that in an asynchronous network with potential faults there must exist non-terminating runs of any (randomized) protocol reaching Consensus.
Reference: [GJ] <author> M. R. Garey and D. S. Johnson, </author> <title> "Computers and Intractability : a guide to NP-Completeness", W.H. </title> <publisher> Freeman ed., </publisher> <address> N.Y., </address> <year> 1979. </year>
Reference-contexts: Namely, our procedure outputs either a star in the graph, or a message `star not found'; whenever the input graph contains a clique of size n t, then the procedure outputs a star in the graph. We follow an idea of Gabril, appearing in <ref> [GJ] </ref> p. 134. There, the following approxi 4.4 Asynchronous verifiable secret sharing 77 Protocol V-Recon [R](a i ) Code for party P i (on input a i , and with parameter R fP 1 ; : : : ; P n g): 7.
Reference: [G] <author> O. Goldreich, </author> <title> "Foundations of Cryptography (Fragments of a Book)", </title> <type> ed. </type> <institution> Dept. of Computer Science and Applied Mathemetics, Weizmann Institute, </institution> <year> 1995. </year>
Reference: [GGL] <author> O. Goldreich, S. Goldwasser, and N. Linial, </author> <title> "Fault-Tolerant Computation in the Full Information Model", </title> <booktitle> 32nd FOCS, </booktitle> <year> 1991, </year> <pages> pp. 447-457. </pages>
Reference-contexts: Chor and Kushilevitz study secure multiparty computation with corrupted majority of the parties in the secure channels setting [CK]. Goldreich, Goldwasser and Linial study secure multiparty computation in the presence of insecure channels and computationally unlimited adversaries <ref> [GGL] </ref>. Ostrovsky and Yung study secure multiparty computation in the presence of secure channels and mobile adversaries [OY].
Reference: [GGM1] <author> O. Goldreich, S. Goldwasser, and S. Micali, </author> <title> "On the cryptographic applications of random functions", </title> <booktitle> Advances in Cryptology: Proc. of Crypto 84, </booktitle> <year> 1984, </year> <pages> pp. 276-288. </pages>
Reference-contexts: A party is secure at a given round if it is uncorrupted at this round, and it has a secure channel to a party that was secure in the previous round. This channel has to be secure only during this round. Our construction is simple, using pseudorandom functions <ref> [GGM2, GGM1] </ref>. A standard cryptographic tool which is believed to behave as a pseudorandom function family is the Data Encryption Standard (DES). <p> We consider pseudorandom collections which are efficiently constructible. Namely, there exists a polytime algorithm that on input ; x 2 f0; 1g k outputs f (x). Pseudorandom function families and their cryptographic applications were introduced by Goldreich, Goldwasser and Micali <ref> [GGM2, GGM1] </ref>. Applications to practical key distribution and authentication protocols were shown by Bellare and Rogaway [BR1]. In [GGM2] it is shown how to construct pseudo-random functions from any pseudo-random generator, which in turn could be constructed from any one-way function [HILL].
Reference: [GGM2] <author> O. Goldreich, S. Goldwasser, and S. Micali, </author> <title> "How to construct random functions" J. </title> <journal> ACM, </journal> <volume> 33(4), </volume> <year> 1986, </year> <pages> pp. 792-807. </pages> <note> Extended abstract in FOCS84. </note>
Reference-contexts: A party is secure at a given round if it is uncorrupted at this round, and it has a secure channel to a party that was secure in the previous round. This channel has to be secure only during this round. Our construction is simple, using pseudorandom functions <ref> [GGM2, GGM1] </ref>. A standard cryptographic tool which is believed to behave as a pseudorandom function family is the Data Encryption Standard (DES). <p> We consider pseudorandom collections which are efficiently constructible. Namely, there exists a polytime algorithm that on input ; x 2 f0; 1g k outputs f (x). Pseudorandom function families and their cryptographic applications were introduced by Goldreich, Goldwasser and Micali <ref> [GGM2, GGM1] </ref>. Applications to practical key distribution and authentication protocols were shown by Bellare and Rogaway [BR1]. In [GGM2] it is shown how to construct pseudo-random functions from any pseudo-random generator, which in turn could be constructed from any one-way function [HILL]. <p> Pseudorandom function families and their cryptographic applications were introduced by Goldreich, Goldwasser and Micali [GGM2, GGM1]. Applications to practical key distribution and authentication protocols were shown by Bellare and Rogaway [BR1]. In <ref> [GGM2] </ref> it is shown how to construct pseudo-random functions from any pseudo-random generator, which in turn could be constructed from any one-way function [HILL].
Reference: [GILVZ] <author> O. Goldreich, R. Impagliazzo, L. Levin, R. Venkatesan and D. Zuckerman, </author> <title> "Security Preserving Amplification of Hardness", </title> <booktitle> FOCS 1990, </booktitle> <pages> pp. 318-326. Bibliography 144 </pages>
Reference-contexts: This yields a collection of "common-domain" permutations, fg fi : f0; 1g jfij 1-1 7! f0; 1g jfij g, which are weakly one-way. Employing amplification techniques (e.g., <ref> [Y2, GILVZ] </ref>) we obtain a proper common-domain system. 3.3 A solution for non-erasing parties 36 In the sequel we refer to common-domain trapdoor systems in a less formal way. <p> With non-negligible probability N is a product of two large primes. Thus, this construction yields a collection of common-domain permutations which are weakly one-way. Employing an amplification procedure (e.g., <ref> [Y2, GILVZ] </ref>) we obtain a proper common-domain system. This common-domain trapdoor system can be used as described in Section 3.3.2. However, here the key-generation stage can be simplified considerably. Observe that it is possible to choose a permutation from the above distribution without knowing its trapdoor.
Reference: [GrL] <author> O. Goldreich and L. Levin, </author> <title> "A Hard-Core Predicate to any One-Way Function", </title> <booktitle> 21st STOC, </booktitle> <year> 1989, </year> <pages> pp. 25-32. </pages>
Reference-contexts: Such an initial set-up is not desirable in practice and does not resolve the theoretically important problem of dealing with a setting in which no secret information is shared a-priori. Our scheme uses a collection of trapdoor permutations together with a corresponding hard-core predicate <ref> [BM, Y2, GrL] </ref>.
Reference: [GMW] <author> O. Goldreich, S. Micali and A. Wigderson, </author> <title> "How to Play any Mental Game", </title> <booktitle> 19th STOC, </booktitle> <year> 1987,pp. </year> <pages> 218-229. </pages>
Reference-contexts: Five years later, Goldreich, Micali and Wigderson showed how to securely compute any function whose inputs are divided among the parties, in a computational setting <ref> [GMW] </ref>. That is, in [GMW] a synchronous network of n parties is considered, where the communication channels are insecure, and the parties, as well as the adversary, are restricted to PPT. <p> Five years later, Goldreich, Micali and Wigderson showed how to securely compute any function whose inputs are divided among the parties, in a computational setting <ref> [GMW] </ref>. That is, in [GMW] a synchronous network of n parties is considered, where the communication channels are insecure, and the parties, as well as the adversary, are restricted to PPT. <p> In addition D publicizes the set S. Intuitively, this scheme lacks in security since S is public and jSj t t. Indeed, an adaptive adversary can easily find D's 2 We borrow the name from an earlier version of <ref> [GMW] </ref>, where it is used for different purposes. 1.3 Adaptively secure computation 8 secret, without corrupting D, by corrupting the parties in S. However, any non-adaptive adversary that does not corrupt D learns D's secret only if S happens to be identical to the pre-defined set of corrupted parties. <p> We sketch these problems. Finally we concentrate on the computational setting, and on non-erasing parties. Is adaptively secure computation possible in this scenario? This question has remained open since the result of <ref> [GMW] </ref>. We answer this question in the affirmative. The problems encountered, and our solution, are presented via the following transformation. <p> Some previous definitions of secure computation (e.g., <ref> [GMW] </ref>) partitioned the Security requirement into two separate requirements: (a) the output of the corrupted parties be equal in both scenarios, and (b) the output of the uncorrupted parties be equal in both scenarios. <p> The sender S should learn nothing from participating in the protocol. In particular S should not know whether R learns s 1 or s 2 . We are only concerned with the case where R is uncorrupted and non-erasing. We use the implementation of OT described in <ref> [GMW] </ref> (which in turn originates in [EGL]). This implementation has an additional property, discussed below, that is useful in our construction. For self containment we sketch, in Figure 3-5, the [GMW] protocol for OT of one bit. <p> We use the implementation of OT described in <ref> [GMW] </ref> (which in turn originates in [EGL]). This implementation has an additional property, discussed below, that is useful in our construction. For self containment we sketch, in Figure 3-5, the [GMW] protocol for OT of one bit. It can be easily verified that the receiver outputs the correct value of t in Step 4. <p> The simulator S proceeds as follows. First an invocation of the key generation protocol " G is simulated, in such a way that S knows both trapdoors f 1 a and f 1 b . (This can be done using the additional property of the <ref> [GMW] </ref> Oblivious Transfer protocol, as described above.) For each party P that A corrupts during this stage, S hands A the internal data held by P in the simulated interaction. <p> If A corrupts P r , then S corrupts P r in the ideal model, learns , and hands A the value f 1 r () for P s 's internal data. The validity of the simulation follows from Lemma 3.9 and from the properties of the <ref> [GMW] </ref> Oblivious Transfer protocol. 2 3.3.3 Alternative implementations of non-committing encryption We describe two alternative implementations of our non-committing encryption scheme, based on the RSA and DH assumptions, respectively.
Reference: [GwL] <author> S. Goldwasser, and L. Levin, </author> <title> "Fair Computation of General Functions in Presence of Immoral Majority", </title> <booktitle> CRYPTO, </booktitle> <year> 1990. </year>
Reference-contexts: We elaborate on this point in Chapter 3. Goldwasser and Levin build on a long sequence of works studying the case of Byzantine adversaries limited to PPT, where a majority of the parties may be corrupted <ref> [GwL] </ref>. Chor and Kushilevitz study secure multiparty computation with corrupted majority of the parties in the secure channels setting [CK]. Goldreich, Goldwasser and Linial study secure multiparty computation in the presence of insecure channels and computationally unlimited adversaries [GGL]. <p> We remark that Goldwasser and Levin take a slightly different approach at defining secure multiparty computation <ref> [GwL] </ref>. First they extract the `inevitable advantages' of the adversary in the ideal model (we briefly sketch these `inevitable advantages' below).
Reference: [HILL] <author> J. Hastad, R. Impagliazzo, L. Levin, and M. Luby, </author> <title> "Construction of pseudo-random generator from any one-way functions", </title> <type> Manuscript, </type> <note> see preliminary versions by Impagliazzo et al. in 21st STOC and Hastad in 22nd STOC, </note> <year> 1993. </year>
Reference-contexts: Applications to practical key distribution and authentication protocols were shown by Bellare and Rogaway [BR1]. In [GGM2] it is shown how to construct pseudo-random functions from any pseudo-random generator, which in turn could be constructed from any one-way function <ref> [HILL] </ref>. However, practitioners often trust and use much simpler constructions based on DES or other widely available cryptographic functions. 6.2 The Protocol In this section we describe the basic protocol. Several modifications useful for the application to secure sign-on are described in Section 6.4.
Reference: [HJJKY] <author> A. Herzberg, M. Jakonsson, S. Jarecki, H. Krawczyk and M. Yung, </author> <title> "Proactive Public-Key and Signature Systems", </title> <publisher> manusript. </publisher>
Reference-contexts: We hope and believe that this approach will become a standard in the effort to protect computer systems. In fact, a number of works have already followed this approach (e.g., <ref> [ChH, HJKY, CHH, HJJKY] </ref>). Subsequent and future work. We mention two directions for subsequent research. The first deals with an additional security requirements from multiparty protocols. Namely, we require that the computation will not leave a `trace' that can be later used against the parties.
Reference: [HJKY] <author> A. Herzberg, S. Jarecki, H. Krawczyk and M. Yung, </author> <title> "Proactive Secret Sharing or: How to Cope with Perpetual Leakage", </title> <booktitle> CRYPTO 1995. </booktitle>
Reference-contexts: We hope and believe that this approach will become a standard in the effort to protect computer systems. In fact, a number of works have already followed this approach (e.g., <ref> [ChH, HJKY, CHH, HJJKY] </ref>). Subsequent and future work. We mention two directions for subsequent research. The first deals with an additional security requirements from multiparty protocols. Namely, we require that the computation will not leave a `trace' that can be later used against the parties.
Reference: [IR] <author> R. Impagliiazzo and S. Rudich, </author> <title> "Limits on the provable consequences of one-way permutations", </title> <booktitle> 21th STOC, </booktitle> <year> 1989, </year> <pages> pp. 44-58. </pages>
Reference: [KY] <author> A. Karlin and A. Yao, </author> <title> "Probabilistic Lower Bounds for Byzantine Agreement", </title> <type> unpublished manuscript, </type> <year> 1986. </year>
Reference-contexts: One of these questions is the focus of this work. Bounds on the resilience of BA protocols were proved in [PSL]. There, it was showed that agreement cannot be reached by a deterministic protocol in an n-party synchronous network with d n 3 e Byzantine faults. Karlin and Yao <ref> [KY] </ref> generalized this result to randomized protocols. These results apply also to asynchronous networks. Furthermore, the impossibility result of Fischer, Lynch and Paterson for deterministic protocols [FLP] implies that any (randomized) protocol reaching BA must have non-terminating runs.
Reference: [LE] <author> T. A. Longstaff and S. E. Eugene, </author> <title> "Beyond preliminary analysis of the wank and oilz worms: A case of study of malicious code", </title> <journal> Computers and Security, </journal> <volume> 12(1), </volume> <year> 1993, </year> <pages> pp. 61-77. </pages>
Reference-contexts: An inherent property of all these scenarios is that once a party is corrupted it remains this way. As computer systems become more complex, internal attacks on systems (i.e., attacks that corrupt components within a system) become an even more important security threat (e.g., <ref> [LE, St] </ref>). Such attacks may be performed, for instance, by internal (human) fraud, operating system weaknesses, or Trojan horse software (e.g. viruses). We use the generic term break-ins for all these attacks. Security administrators often find break-ins more alarming than external attacks, such as line tappings.
Reference: [MS] <author> F. J. Macwiliams and N. J. A. Sloane, </author> <title> "The Theory of Error Correcting Codes", </title> <publisher> North-Holland, </publisher> <year> 1977. </year>
Reference: [MR] <author> S. Micali and P. Rogaway, </author> <title> "Secure Computation", </title> <note> in preparation. Preliminary version in CRYPTO 91. </note>
Reference-contexts: Goldreich, Goldwasser and Linial study secure multiparty computation in the presence of insecure channels and computationally unlimited adversaries [GGL]. Ostrovsky and Yung study secure multiparty computation in the presence of secure channels and mobile adversaries [OY]. Micali and Rogaway <ref> [MR] </ref>, and also Beaver [Be], propose definitions for secure multiparty computation in the secure channels setting, in the presence of adaptive adversaries. 1.2 Defining secure multiparty computation 5 1.2 Defining secure multiparty computation We attempt at formulating coherent, lean, and usable definitions, that adequately capture our intuitive notion of security of <p> Our definitions build on previously known ideas. We first present these ideas, as well as a brief critique and comparison of relevant works. Next we present our interpretation and new ideas. Micali and Rogaway <ref> [MR] </ref>, and independently Beaver [Be] introduced the following methodology for defining secure multiparty computation (or, more specifically, secure evaluation of a function whose inputs are distributed among the parties). First an ideal model for secure multiparty computation is formulated. <p> Loosely speaking, executing in the real-life setting is said to be "equivalent" to evaluating the function in the ideal model, if the same effect on the computation achieved by a real-life adversary can be also achieved by an ideal-mode adversary. The definitions in <ref> [MR] </ref> and [Be] differ in the notion of equivalence of computations. In [MR] the ideal-model adversary is required to very closely mimic the operation of the real-life adversary, down to precise details. <p> The definitions in <ref> [MR] </ref> and [Be] differ in the notion of equivalence of computations. In [MR] the ideal-model adversary is required to very closely mimic the operation of the real-life adversary, down to precise details. <p> Here we limit the ideal-model adversary A to black-box simulation of the real-life adversary. (A more precise definition of this simulation is presented in the sequel.) We note that our notion of black-box simulation is less restrictive than the <ref> [MR] </ref> notion. We remark that Goldwasser and Levin take a slightly different approach at defining secure multiparty computation [GwL]. First they extract the `inevitable advantages' of the adversary in the ideal model (we briefly sketch these `inevitable advantages' below). <p> Some previous definitions of secure computation (e.g., [GMW]) partitioned the Security requirement into two separate requirements: (a) the output of the corrupted parties be equal in both scenarios, and (b) the output of the uncorrupted parties be equal in both scenarios. However, as pointed out in <ref> [MR] </ref>, requiring (a) and (b) does not guarantee secure computation. 2.2 Semi-honest parties 20 2.2 Semi-honest parties We define semi-honest parties (or, equivalently, semi-honest protocols). We consider three alternative notions of semi-honesty. <p> Remark: Our convention that the real-life adversary outputs its entire view is important for clarifying how the following difficulty, pointed out in <ref> [MR] </ref>, is settled. Assume that the corrupted parties do not output their inputs and random inputs, and that the function f to be computed is pseudorandom.
Reference: [MV] <author> S. Micali and V. Vazirani, </author> <title> "An O( p jV j jEj) Algorithm for Finding Maximum Matching in General Graphs", </title> <booktitle> 21st FOCS, </booktitle> <year> 1980. </year>
Reference-contexts: We call such a pair of sets an (n; t)-star. In the rest of this section, we refer to the complementary graph only. In our procedure, we find a maximum matching in the graph (say, using [Ed] or <ref> [MV] </ref>). 18 Based on this matching, we compute sets C; D of nodes, and check whether (C; D) form an (n; t)-star in the graph.
Reference: [MNSS] <author> S. P. Miller, C. Neuman, J. I. Schiller, and J. H. Saltzer, </author> <title> "Kerberos authentication and authorization system", </title> <type> Project Athena Technical Plan. </type> <institution> Massachusetts Institute of Technology, </institution> <month> July </month> <year> 1987. </year>
Reference-contexts: Security mechanisms, therefore, avoid sending 1.6 Proactive security: Maintaining security in the presence of transient faults 15 the password "on the clear". Instead, they use the user's password to derive a session key, with which they secure the communication. In both Kerberos <ref> [MNSS] </ref> and NetSP / KryptoKnight [BGH + 1], this is done by using the password as a key for exchanging a random session key; this method also allows NetSP / KryptoKnight to authenticate the user automatically to additional systems (`single sign on').
Reference: [MT] <author> R. H. Morris and K. Thompson, </author> <title> "Unix password security", </title> <journal> Comm. ACM, </journal> <volume> 22(11), </volume> <month> November </month> <year> 1979, </year> <pages> pp. 594-597. </pages>
Reference-contexts: Fail-Stop adversaries (and also Byzantine adversaries, at the price of slightly compromising the security) could be tolerated by simple modifications. An application to Secure Sign-On. Unix and other operating systems provide security for the passwords by storing only a one-way function of the passwords on disk <ref> [MT] </ref>. This technique allows authentication of the users, secure against eavesdropping the password file. Session security is not provided if the communication channels are not secure. When constructing secure LAN systems, it is not realistic to assume that the underlying communication channels are secure.
Reference: [OY] <author> R. Ostrovsky and M. Yung, </author> <title> "How to withstand mobile virus attacks", </title> <booktitle> Proceedings of the 10 th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1991, </year> <pages> pp 51-59. </pages>
Reference-contexts: Goldreich, Goldwasser and Linial study secure multiparty computation in the presence of insecure channels and computationally unlimited adversaries [GGL]. Ostrovsky and Yung study secure multiparty computation in the presence of secure channels and mobile adversaries <ref> [OY] </ref>. <p> We stress that there may be no party that has never been infected! Secure multiparty computation in the presence of mobile adversaries was previously studied by Ostrovsky and Yung <ref> [OY] </ref>. We remark that here the notion of semi-honest parties (discussed in Section 1.2) is irrelevant, since all components are programmed and run by the same entity. In fact, erasing old data plays a key role in our constructions.
Reference: [PSL] <author> R. Pease, Shostak and L. Lamport, </author> <title> "Reaching Agreement in the Presence of Faults", </title> <journal> JACM, </journal> <volume> Vol. 27 No. 2, </volume> <year> 1980, </year> <pages> pp. 228-234. Bibliography 145 </pages>
Reference-contexts: A particularly interesting variant of this problem, introduced by Pease, Shostak and Lamport <ref> [PSL] </ref>, allows Byzantine adversaries. A standard formulation of this problem, called the Byzantine agreement (BA) problem, follows: design a protocol that allows the uncorrupted parties to agree on a common value. The agreed value should be the input value of one of the uncorrupted parties. <p> However, despite extensive research a few important questions have remained open. One of these questions is the focus of this work. Bounds on the resilience of BA protocols were proved in <ref> [PSL] </ref>. There, it was showed that agreement cannot be reached by a deterministic protocol in an n-party synchronous network with d n 3 e Byzantine faults. Karlin and Yao [KY] generalized this result to randomized protocols. These results apply also to asynchronous networks.
Reference: [MRa1] <author> M. Rabin, </author> <title> "How to exchange secrets by oblivious transfer", </title> <type> Tech. </type> <institution> Memo TR-81, Aiken Computation Laboratory, Harvard U., </institution> <year> 1981. </year>
Reference-contexts: We use Oblivious Transfer <ref> [MRa1, EGL] </ref> in our constructions. Oblivious Transfer (OT) is a protocol executed by a sender S with inputs s 1 and s 2 , and by a receiver R with input t 2 f1; 2g.
Reference: [MRa2] <author> M. Rabin, </author> <title> "Randomized Byzantine Generals", </title> <booktitle> 24th FOCS, </booktitle> <year> 1983, </year> <pages> pp. 403-409. </pages>
Reference-contexts: Given that all the uncorrupted parties have completed the protocol, they do so in constant expected time. The constructions we use in our protocol are of independent interest. Let us overview the chain of results leading to our result, and sketch the techniques used. Rabin <ref> [MRa2] </ref> describes an (d n 8 e 1)-resilient BA protocol that runs in constant expected time, provided that all the parties have access to a `global coin' (namely, a common source of randomness). Rabin's construction can be used in synchronous as well as asynchronous networks. <p> All the computations in the sequel are done in F . The BA protocol employs the idea of using `common coins' to reach agreement, as follows. BA using Common Coin. This part of our protocol follows the constructions of Rabin, Bracha and Feldman <ref> [MRa2, Br, Fe] </ref>. The protocol proceeds in rounds. In each round, each party has a `modified input' value. In the first round, the modified input of each party is his local input. In each round the parties invoke two protocols, called Vote and Common Coin.
Reference: [RB] <author> T. Rabin and M. Ben-Or, </author> <title> "Verifiable Secret Sharing and Multiparty Protocols with Honest Majority", </title> <booktitle> 21st STOC, </booktitle> <year> 1989, </year> <pages> pp. 73-85. </pages>
Reference-contexts: We overcome these difficulties by devising a tool, called Asynchronous Recoverable Sharing (A-RS), assuring that, with overwhelming probability, the shares of all the parties in the set C 1 (defined above) will be available in the reconstruction phase. The A-RS protocol uses a tool presented in <ref> [TRa, RB] </ref>, called Information Checking Protocol. Using A-RS as a primitive, we construct a secret sharing scheme, called Asynchronous Weak Secret Sharing (AWSS). Using AWSS, we construct our AVSS scheme. (Both the AWSS and the AVSS schemes generalize synchronous constructs introduced in [TRa, RB].) 1.6 Proactive security: Maintaining security in the <p> The A-RS protocol uses a tool presented in <ref> [TRa, RB] </ref>, called Information Checking Protocol. Using A-RS as a primitive, we construct a secret sharing scheme, called Asynchronous Weak Secret Sharing (AWSS). Using AWSS, we construct our AVSS scheme. (Both the AWSS and the AVSS schemes generalize synchronous constructs introduced in [TRa, RB].) 1.6 Proactive security: Maintaining security in the presence of transient faults Traditionally, cryptography is focused on protecting interacting parties (i.e., computers) against external malicious entities. Such cryptographic tasks include private communication over insecure channels, authentication of parties, unforgeable signatures, and general multiparty secure computation. <p> Thus, we get Theorem 3.1 If common-domain trapdoor systems exist, then there exist secure protocols for computing any (recursive) function in the computational setting, in the presence of non-erasing parties and adaptive adversaries that corrupt less than a third of the parties. We remark that, using standard constructs (e.g., <ref> [RB] </ref>), our protocols can be modified to withstand adversaries that corrupt less than half of the parties. Dealing with honest-looking parties. We also sketch a solution for the case of honest-looking parties, assuming, in addition to the above, also the existence of a "trusted dealer" at a pre-computation stage. <p> Authentication (Auth): 1. I sends s and the rest of the y's to R. 2. If k=2 out of the unrevealed indices d i satisfy s b d i + y d i = c d i then R sets Auth= s, otherwise Auth=null. Rabin and Ben-Or <ref> [TRa, RB] </ref> We first state the properties of this protocol. Next we sketch the [TRa, RB] construction. The protocol is executed by three parties: a dealer D, an intermediary I, and a receiver R. The dealer hands a secret value s over to I. <p> If k=2 out of the unrevealed indices d i satisfy s b d i + y d i = c d i then R sets Auth= s, otherwise Auth=null. Rabin and Ben-Or <ref> [TRa, RB] </ref> We first state the properties of this protocol. Next we sketch the [TRa, RB] construction. The protocol is executed by three parties: a dealer D, an intermediary I, and a receiver R. The dealer hands a secret value s over to I. <p> Secrecy: 4. If D and I are honest, then as long as I has not joined in the Authentication phase, R has no information about the secret s. For self containment we sketch the <ref> [TRa, RB] </ref> construction in Figure 5-1. 1 5.3.2 Broadcast We use the same definition of Broeadcast as in Chapter 4 (see Section 4.2.2). <p> well as in all subsequent secret sharing schemes, we use the convention that the dealer, in addition to executing his specific code, also participates as one of the parties (and will eventually have a share of the secret). 1 In fact, the version presented here differs from the one in <ref> [TRa, RB] </ref> in the decision rule for R in the Authentication stage (in the original construction R accepted the secret if there existed an index d i that satisfied the requirement. <p> There, in case that the dealer is faulty, the adversary has the power to decide, at the reconstruction stage, which value each honest party reconstructs (out of the predefined set of size 2t + 1). Our construction. Our construction follows the synchronous WSS version of <ref> [TRa, RB] </ref>. <p> The construction is quite involved, using many layers and techniques. The main technical contributions are, in our opinion, two: First, we adapt techniques from <ref> [RB, TRa] </ref> to construct the first Asynchronous Verifiable Secret Sharing (AVSS) scheme with optimal resilience. Next, we slightly modify the [F] scheme (which was never published and unaccessible) for reaching BA given an AVSS scheme, and present it in a (hopefully) readable way.
Reference: [TRa] <author> T. </author> <title> Rabin , "Robust Sharing of Secrets When The Dealer is Honest or Faulty", </title> <journal> Journal of the ACM, </journal> <volume> No. 6, Vol. 41, </volume> <year> 1994, </year> <pages> pp. 1089-1109. </pages>
Reference-contexts: We overcome these difficulties by devising a tool, called Asynchronous Recoverable Sharing (A-RS), assuring that, with overwhelming probability, the shares of all the parties in the set C 1 (defined above) will be available in the reconstruction phase. The A-RS protocol uses a tool presented in <ref> [TRa, RB] </ref>, called Information Checking Protocol. Using A-RS as a primitive, we construct a secret sharing scheme, called Asynchronous Weak Secret Sharing (AWSS). Using AWSS, we construct our AVSS scheme. (Both the AWSS and the AVSS schemes generalize synchronous constructs introduced in [TRa, RB].) 1.6 Proactive security: Maintaining security in the <p> The A-RS protocol uses a tool presented in <ref> [TRa, RB] </ref>, called Information Checking Protocol. Using A-RS as a primitive, we construct a secret sharing scheme, called Asynchronous Weak Secret Sharing (AWSS). Using AWSS, we construct our AVSS scheme. (Both the AWSS and the AVSS schemes generalize synchronous constructs introduced in [TRa, RB].) 1.6 Proactive security: Maintaining security in the presence of transient faults Traditionally, cryptography is focused on protecting interacting parties (i.e., computers) against external malicious entities. Such cryptographic tasks include private communication over insecure channels, authentication of parties, unforgeable signatures, and general multiparty secure computation. <p> Authentication (Auth): 1. I sends s and the rest of the y's to R. 2. If k=2 out of the unrevealed indices d i satisfy s b d i + y d i = c d i then R sets Auth= s, otherwise Auth=null. Rabin and Ben-Or <ref> [TRa, RB] </ref> We first state the properties of this protocol. Next we sketch the [TRa, RB] construction. The protocol is executed by three parties: a dealer D, an intermediary I, and a receiver R. The dealer hands a secret value s over to I. <p> If k=2 out of the unrevealed indices d i satisfy s b d i + y d i = c d i then R sets Auth= s, otherwise Auth=null. Rabin and Ben-Or <ref> [TRa, RB] </ref> We first state the properties of this protocol. Next we sketch the [TRa, RB] construction. The protocol is executed by three parties: a dealer D, an intermediary I, and a receiver R. The dealer hands a secret value s over to I. <p> Secrecy: 4. If D and I are honest, then as long as I has not joined in the Authentication phase, R has no information about the secret s. For self containment we sketch the <ref> [TRa, RB] </ref> construction in Figure 5-1. 1 5.3.2 Broadcast We use the same definition of Broeadcast as in Chapter 4 (see Section 4.2.2). <p> well as in all subsequent secret sharing schemes, we use the convention that the dealer, in addition to executing his specific code, also participates as one of the parties (and will eventually have a share of the secret). 1 In fact, the version presented here differs from the one in <ref> [TRa, RB] </ref> in the decision rule for R in the Authentication stage (in the original construction R accepted the secret if there existed an index d i that satisfied the requirement. <p> There, in case that the dealer is faulty, the adversary has the power to decide, at the reconstruction stage, which value each honest party reconstructs (out of the predefined set of size 2t + 1). Our construction. Our construction follows the synchronous WSS version of <ref> [TRa, RB] </ref>. <p> Our construction of Two&Sum-AWSS, presented in Figure 5-6, is a straightforward generalization of our AWSS scheme. (The scheme is based on the synchronous Two&Sum-WSS presented in <ref> [TRa] </ref>.) The reconstruction protocol is identical to AWSS-Rec, with the addition of parameters specifying which value should be reconstructed. <p> The correctness of Two&Sum AWSS is proven in a way similar to the proof of correctness of the AWSS scheme. (Similar proofs appear in <ref> [TRa] </ref>.) 5.5 Asynchronous Weak Secret Sharing | AWSS 116 Protocol Two&Sum AWSS-Share [*; k] Code for the dealer: (on input s; a 1 ; : : : ; a k and *) 1. Choose random polynomials f () for s and g l () for each a l . <p> The construction is quite involved, using many layers and techniques. The main technical contributions are, in our opinion, two: First, we adapt techniques from <ref> [RB, TRa] </ref> to construct the first Asynchronous Verifiable Secret Sharing (AVSS) scheme with optimal resilience. Next, we slightly modify the [F] scheme (which was never published and unaccessible) for reaching BA given an AVSS scheme, and present it in a (hopefully) readable way.
Reference: [Re] <author> R. Reischuk, </author> <title> "A new solution to the byzantine generals problem", </title> <journal> Information and Control, </journal> <year> 1985, </year> <pages> pp. 23-42. </pages>
Reference: [SK] <author> K. Sako and J. Kilian, </author> <title> "Receipt-Free Mix-Type Voting Scheme", </title> <booktitle> Eurocrypt 1995, </booktitle> <pages> pp. 393-403. </pages>
Reference: [Sh] <author> A. Shamir, </author> <title> "How to share a secret", </title> <journal> CACM, </journal> <volume> Vol. 22, No. 11, </volume> <year> 1979, </year> <pages> pp. 612-613. </pages>
Reference-contexts: All the computations in the sequel are done in F . An outline of the protocol follows. Let x i be the input of P i . As a first step, each party shares its input among the parties, using a technique similar to Shamir's secret sharing scheme <ref> [Sh] </ref>. (Namely, for each party P i that successfully shared its input, a random polynomial p i () of degree t is generated, so that each party P j has p i (j) and p i (0) is P i 's input value. <p> We use this property in the construction of AWSS in the next section. We describe our construction. Basically, we use Shamir's classic secret sharing scheme <ref> [Sh] </ref> while using ICP to verify the shares.
Reference: [St] <author> C. Stoll, </author> <title> "How secure are computers in the u.s.a.?", </title> <journal> Computers and Security, </journal> <volume> 7(6), </volume> <year> 1988, </year> <pages> pp. 543-547. </pages>
Reference-contexts: An inherent property of all these scenarios is that once a party is corrupted it remains this way. As computer systems become more complex, internal attacks on systems (i.e., attacks that corrupt components within a system) become an even more important security threat (e.g., <ref> [LE, St] </ref>). Such attacks may be performed, for instance, by internal (human) fraud, operating system weaknesses, or Trojan horse software (e.g. viruses). We use the generic term break-ins for all these attacks. Security administrators often find break-ins more alarming than external attacks, such as line tappings.
Reference: [Y1] <author> A. Yao, </author> <title> "Protocols for Secure Computation", </title> <booktitle> 23th FOCS, </booktitle> <year> 1982, </year> <pages> pp. 160-164. </pages>
Reference-contexts: We also mention some other prominent works in secure multiparty computation. (We present other relevant works in the sequel.) The problem of secure computation was first formulated by Yao for the two-party case in 1982 <ref> [Y1] </ref>. Five years later, Goldreich, Micali and Wigderson showed how to securely compute any function whose inputs are divided among the parties, in a computational setting [GMW].
Reference: [Y2] <author> A. Yao, </author> <title> "Theory and applications of trapdoor functions", </title> <booktitle> 23rd FOCS, </booktitle> <year> 1982, </year> <pages> pp. 80-91. </pages>
Reference-contexts: Such an initial set-up is not desirable in practice and does not resolve the theoretically important problem of dealing with a setting in which no secret information is shared a-priori. Our scheme uses a collection of trapdoor permutations together with a corresponding hard-core predicate <ref> [BM, Y2, GrL] </ref>. <p> This yields a collection of "common-domain" permutations, fg fi : f0; 1g jfij 1-1 7! f0; 1g jfij g, which are weakly one-way. Employing amplification techniques (e.g., <ref> [Y2, GILVZ] </ref>) we obtain a proper common-domain system. 3.3 A solution for non-erasing parties 36 In the sequel we refer to common-domain trapdoor systems in a less formal way. <p> With non-negligible probability N is a product of two large primes. Thus, this construction yields a collection of common-domain permutations which are weakly one-way. Employing an amplification procedure (e.g., <ref> [Y2, GILVZ] </ref>) we obtain a proper common-domain system. This common-domain trapdoor system can be used as described in Section 3.3.2. However, here the key-generation stage can be simplified considerably. Observe that it is possible to choose a permutation from the above distribution without knowing its trapdoor.
References-found: 72

