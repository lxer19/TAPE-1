URL: http://www.neci.nj.nec.com/homepages/oliensis/latejournallinalg.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/oliensis/
Root-URL: 
Email: (oliensis@research.nj.nec.com)  
Title: Recovering Heading and Structure for Constant-Direction Motion motion, structure from motion, heading, shape from X,
Author: John Oliensis 
Keyword: Multi-frame structure  
Note: from  
Address: 4 Independence Way Princeton, N.J. 08540  
Affiliation: NEC Research Institute  
Abstract: We describe a new algorithm for computing the camera heading for a multi-frame sequence of tracked points where the camera translates in a constant direction. We also adapt our previous general-motion algorithm to recover the complete structure and motion. We experimentally compare our approach to a standard two-frame algorithm and to the maximum likelihood estimate. We discuss the flipping ambiguity, a new ambiguity of structure from motion described in detail elsewhere, and demonstrate that allowing for it improves the robustness of two-frame reconstruction as well as that of our approach. Our experiments on heading recovery for planar scenes show that the error landscape has few significant local minima for such scenes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Adiv, </author> <title> "Inherent ambiguities in recovering 3-D motion and structure from a noisy flow field," </title> <type> PAMI 11 </type> <pages> 477-489, </pages> <year> 1989. </year>
Reference: [2] <author> R. Dutta, R. Manmatha, </author> <title> L.R. Williams, and E.M. Riseman, "A data set for quantitative motion analysis," </title> <booktitle> CVPR, </booktitle> <pages> 159-164, </pages> <year> 1989. </year>
Reference-contexts: Our algorithm performs comparably to two-frame 23 translation size 0:2 with 10 percent added random translations, 20 Slant 70, F = 60. Right: One frame of rocket sequence <ref> [2] </ref>. reconstruction on these planar sequences with approximately linear motion. We repeated the experiment with exactly linear motion and found average errors of 4:7 and 5:1 for min fi ^ T; ^ T G ; fi ^ T; ^ T A (our algorithm) and min . <p> Thus the major problem our algorithm faces for planar scenes is the poor initial rotation compensation, and this can be corrected by recompensating. Real Image Sequences. The Martin|Marietta Rocket sequence <ref> [2] </ref> (Figure 8 (right)) consists of 9 images of 22 tracked points. The scene is approximately a plane slanted at 84 ffi , where the 3D points deviate from the plane on average by 0:9. <p> as well as the base image, which gives p inew = N 1 f @ h=0 i h=1 i A : Lastly, we compute (X e ; Y e ) i = Z ie p inew . 3.6 Experiments: structure reconstruction We tested our algorithm on the Martin-Marietta Rocket sequence <ref> [2] </ref> (Figure 8 (right)), comparing it to two brute-force optimization algorithms as well as our two-frame approach. For the first brute-force algorithm (BFCT), the translation was constrained to have a constant direction as before, while the second algorithm (MLE) computed the standard least-squares MLE with no constraints.
Reference: [3] <author> R. I. </author> <title> Hartley, "In Defense of the Eight-Point Algorithm," </title> <type> PAMI 19 </type> <pages> 580-593, </pages> <year> 1995. </year>
Reference-contexts: This algorithm first reconstructed the motion 17 using the "8-point" algorithm [11] modified following Hartley <ref> [3] </ref> and then used this as the starting estimate for an iterative algorithm minimizing a weighted coplanarity error [16]. (The "8-point" algorithm has a 2-fold ambiguity in recovering the translation and rotation; we selected the correct solution by comparing to the ground truth.) Previous work [16] has shown that this two-frame <p> We ran an additional 800 trials for approximately planar scenes. We generated these as before, except that we added a random deviation ffiP i away from the plane to each 3D point, with ffiP i 2 <ref> [3; 3] </ref>. Figure 8 (left) shows the results. Again, the lower-right plot in this Figure shows the results of a two-frame algorithm started from the ground truth.
Reference: [4] <author> D.J. Heeger and A.D. Jepson, </author> <title> "Subspace methods for recovering rigid motion I: Algorithm and implementation," </title> <booktitle> IJCV 7 </booktitle> <pages> 95-117, </pages> <year> 1992. </year>
Reference: [5] <author> D. Jacobs, </author> <title> "Linear Fitting with Missing Data: Applications to Structure-from-Motion and to Characterizing Intensity Images," </title> <address> CVPR 206-212, </address> <year> 1997. </year>
Reference-contexts: When there is occlusion, one can derive a good initial estimate for this row vector as in <ref> [5] </ref>|or by determining rows that are at relatively small angles with respect to each other and averaging them [18]|and then improve this estimate iteratively [24] [5]. For simplicity, we assume no occlusion.
Reference: [6] <author> A.D. </author> <title> Jepson and D.J. Heeger, "Linear subspace methods for recovering translational direction," in Spatial Vision in Humans and Robots, </title> <publisher> Cambridge, </publisher> <pages> 39-62, </pages> <year> 1993. </year>
Reference-contexts: In this paper, we assume the camera has been calibrated. [16] describes a modification of our approach that can deal with poor calibration of the camera center and with unknown focal lengths varying over the image sequence. For simplicity, we also assume no occlusion. However, as in <ref> [6] </ref>, occlusion causes no difficulties for recovering the heading. In addition to presenting our algorithm, we demonstrate in this paper that structure from motion is relatively easy for planar scenes and that allowing for the flipping ambiguity improves the robustness of two-frame reconstruction as well as that of our approach. <p> The algorithm consists of two stages: an initial linear estimate followed by iterative improvement via optimization. Section 2.2 discusses the initial estimate and compares it experimentally to the previous technique of <ref> [6] </ref>. Section 2.3 presents and analyzes the iterative-refinement stage. We show that the error minimized in this stage equals the true coplanarity/epipolar error to a good approximation and that the resulting heading estimate is nearly unbiased. <p> Explicitly, [C 1=2 ] hh 0 = ffi hh 0 N 1 The technique of solving (4) for ^ T is essentially due to <ref> [6] </ref>, which derived it in the context of optical flow. <p> We previously derived (4) in [18]. Improved Linear Algorithm For moderate FOV ( F 90 ffi ), <ref> [6] </ref> has shown that solving (4) for ^ T causes a strong bias toward recovering ^ T ^z. This happens since Q ^z ~ o (x; y) while Q ^x; Q ^y ~ o (1), so that one can approximately satisfy (4) simply by taking ^ T ^z. <p> Dithering. <ref> [6] </ref> proposed a different linear method based on dithering to correct the bias of (4). We briefly discuss their method as modified for our situation and compare it to our linear reweighting method (8). [6] adds carefully chosen random noise to the data itself, a process known as dithering, so that <p> Dithering. <ref> [6] </ref> proposed a different linear method based on dithering to correct the bias of (4). We briefly discuss their method as modified for our situation and compare it to our linear reweighting method (8). [6] adds carefully chosen random noise to the data itself, a process known as dithering, so that the covariance matrix for the modified data approximates the identity matrix. The modified data determines ^ T approximately without bias. <p> In contrast, our reweighting method does not require 8 knowing the size of the noise. Second, because dithering adds noise, it gives results that are noisier than is warranted by the original data. Third, dithering requires computing the added random noise h Di . Jepson and Heeger <ref> [6] </ref> actually use a modified form of the technique described above, taking ~ Q Q h Di + 0 Di , where h D has covariance ffi ii 0 ffi hh 0 2 a i a T instead of (9). <p> Solving (10) still gives an approximately unbiased estimate of ^ T up to o ( F ) corrections, which should be adequate at moderate-to-small FOV. Experimental Comparison of Linear Algorithms We experimentally compared our approach to the full and modified dithering methods <ref> [6] </ref>. We tested the dithering methods assuming the noise was known and, more realistically, using a simple estimate of derived by: estimating ^ T from (4), computing the residual R trace Q , and then using R 2 (N f 1) trace for the ground truth ^ T G . <p> Our algorithm performs reasonably well given that it is inappropriate for this sequence. Summary of Experiments Our initial linear estimate performs significantly better than that of <ref> [6] </ref>. The iterative second stage of our algorithm gives good results for the moderate-translation, constant-heading domain for which it was designed, but it also does well for large translations and non-constant heading. It produces significantly fewer outliers than two-frame reconstruction. <p> T z =T x , for the current algorithm (crosses), MLE (circles), and two-frame algorithm (triangles). 33 the inverse-depth components in essentially all cases. 4 Conclusions We have shown that our linear estimate of ^ T improves significantly on that of <ref> [6] </ref>. However, Section 2.3 also points out the disadvantages of the linear estimates. For non-planar scenes, our heading-recovery algorithm does nearly as well as the full least-squares MLE for ^ T bounded away from ^z and from directions parallel to the image plane.
Reference: [7] <author> A.D. </author> <title> Jepson and D.J. Heeger, "A fast subspace algorithm for recovering rigid motion," </title> <booktitle> Motion Workshop , Princeton, N.J., </booktitle> <pages> 124-131, </pages> <year> 1991. </year>
Reference-contexts: Note that H exactly annihilates the rotational flows; in contrast with the linear stage of heading recovery and <ref> [7] </ref>, we lose no useful information through the H multiplication. Assuming the translations are along a line, D H DH T is rank 1 to first approximation and involves only the translation and structure. We can use this condition to verify that camera does move approximately along a line.
Reference: [8] <author> A.D. </author> <title> Jepson and D.J. Heeger, "Subspace methods for recovering rigid motion II: Theory," </title> <type> U. </type> <institution> of Toronto TR RBCV-TR-90-36, </institution> <year> 1990. </year>
Reference-contexts: Near ^ T ~ ^x, the tendency to confound translations with rotations due to the bas-relief ambiguity worsens the initial rotation compensation. It also causes the position of ^ T within the ^ T-^z plane to be relatively sensitive to noise [14] <ref> [8] </ref>. For both these reasons, one again expects relatively better results from the brute-force approach. As we show below, one can easily correct the first, bas-relief-induced problem by using the initially recovered ^ T to recalculate and recompensate for the rotations and then recalculating ^ T. <p> The residual rotations between the base and h-th image are not large, so to compute them for known ^ T one can use the linear technique of <ref> [8] </ref>. 20 random translations, 30 Z 90, F = 40. Right Figure, upper plot: current algorithm following recompensation of the rotations based on the initially recovered translation direction. For convenience, we instead applied our two-frame algorithm assuming known ^ T, since optimizing over the rotations alone is straightforward. <p> This takes o (N p ) steps since w is length-3. Given w, it is easy to solve (20) pointwise for also in o (N p ) steps. 3.3 Error analysis The analysis in <ref> [8, 12] </ref> of the errors in recovering ^ T from optical flow applies also to multi-frame sequences with variable motion. The most important effect is the approximate bas-relief ambiguity, which for moderate-to-small FOV makes the recovery of ^ T z much more noise-sensitive that that of the other translation components. <p> Presuming that the true ^ T is known, we can analyze the errors in determining the depths and translation magnitudes by a perturbation analysis of the SVD [17]. Again, the results are similar to those of <ref> [8] </ref> for optical flow. Essentially, we obtain the extended bas-relief effect: the three inverse-depth components linear in the image coordinates are relatively more noise-sensitive than the rest, and of these the constant component of the inverse depths tends to have the largest errors.
Reference: [9] <author> K. Kanatani, </author> <title> "Analysis of 3-D Rotation Fitting," </title> <type> PAMI 16 </type> <pages> 543-549, </pages> <year> 1995. </year>
Reference: [10] <author> R. Kumar and A.R. Hanson, </author> <title> "Sensitivity of the Pose Refinement Problem to Accurate Estimation of Camera Parameters," </title> <booktitle> ICCV, </booktitle> <pages> 365-369, </pages> <year> 1990. </year>
Reference-contexts: The two-frame algorithm's error was 3:0 ffi , regardless of whether the rotations were compensated. The brute-force LM algorithm assuming constant translation direction gave an error of 1:7 ffi . We also tested our algorithm on the PUMA sequence <ref> [10] </ref>. 32 points were automatically tracked 24 sequence, shown in the plane of motion. over 16 image frames. The maximum displacement of the camera was 1.5, and the 3D depths varied from 13.5 to 31.8. The FOV spanned by the image points was 22 ffi .
Reference: [11] <author> H. C. Longuet-Higgins, </author> <title> "A computer algorithm for reconstructing a scene from two projections," </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: Experimentally, our approach gives good results even when the camera's motion is far from linear. Previous approaches to SFM cope well with large translations or small perspective effects <ref> [27, 11] </ref>. Our algorithm is designed for the complementary case of small translations and large perspective 1 effects. We have argued previously [15] [19, 21] that it is best to deal with the variety of SFM problems by using a variety of specialized algorithms rather than a single general-purpose approach. <p> This algorithm first reconstructed the motion 17 using the "8-point" algorithm <ref> [11] </ref> modified following Hartley [3] and then used this as the starting estimate for an iterative algorithm minimizing a weighted coplanarity error [16]. (The "8-point" algorithm has a 2-fold ambiguity in recovering the translation and rotation; we selected the correct solution by comparing to the ground truth.) Previous work [16] has
Reference: [12] <author> S. Maybank, </author> <title> Theory of Reconstruction from Image Motion, </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: This takes o (N p ) steps since w is length-3. Given w, it is easy to solve (20) pointwise for also in o (N p ) steps. 3.3 Error analysis The analysis in <ref> [8, 12] </ref> of the errors in recovering ^ T from optical flow applies also to multi-frame sequences with variable motion. The most important effect is the approximate bas-relief ambiguity, which for moderate-to-small FOV makes the recovery of ^ T z much more noise-sensitive that that of the other translation components.
Reference: [13] <author> S. Maybank, </author> <title> "A theoretical study of optical flow," </title> <type> PhD thesis, </type> <institution> University of London, </institution> <year> 1987. </year>
Reference: [14] <author> J. Oliensis, </author> <title> "A New Structure from Motion Ambiguity," </title> <journal> NECI TR 1997. </journal> <volume> 36 </volume>
Reference-contexts: The flipping ambiguity is a new, intrinsic SFM ambiguity described in detail in <ref> [14] </ref>. 1.1 Outline of the Paper Section 2 describes and tests our algorithm for heading recovery. The algorithm consists of two stages: an initial linear estimate followed by iterative improvement via optimization. Section 2.2 discusses the initial estimate and compares it experimentally to the previous technique of [6]. <p> Section 2.3 presents and analyzes the iterative-refinement stage. We show that the error minimized in this stage equals the true coplanarity/epipolar error to a good approximation and that the resulting heading estimate is nearly unbiased. This section also describes how our optimization copes with 2 the SFM flipping ambiguity <ref> [14] </ref> and how to expedite the optimization by minimizing initially in a single variable. Also, we point out that only the second stage of our algorithm can deal with planar scenes. <p> We report experimental results on planar and approximately planar scenes below. Our second-stage algorithm iteratively minimizes the error defined below 1 . Let ^u T i fi fi fi 1 This definition also appears in <ref> [14] </ref> and is included here for completeness. 11 and i d y d x i is analogous to d, but ^u T i unlike is normalized by the ^ T-dependent denominator. We can afford to introduce this nonlinear dependence since the second-stage algorithm is nonlinear. <p> Using C 1=2 E R is equivalent to minimizing the squared discrepancy from coplanarity over all rotational flows, whereas for the true coplanarity error one must minimize over finite rotations. But one can show that the infinitesimal assumption gives a good approximation when the translations are moderate <ref> [14] </ref>. Thus, since the corrections in (14) are small, R accurately approximates the true coplanarity error. Also, minimizing trace R gives an approximately unbiased estimate of ^ T. <p> Right Figure: Error (12) versus translation direction (T x ; T y ; 1) for a 15-image sequence. side). We refer to this as the flipped local minimum since it occurs on the wrong side of the ^z axis. In a companion paper <ref> [14] </ref>, we demonstrate that this local minimum occurs generically and represents a new and important ambiguity in SFM that differs from the bas-relief ambiguity (for instance, it occurs more strongly for scenes with larger depth variation). <p> Specifically, in our experiments the projection of onto the constant component f1g typically accounts for more than 90% of its magnitude 3 . As discussed in <ref> [14] </ref>, when the true translation direction ^ T G differs from ^x, the hypothesis of a ^ T near ^x is unlikely because ^ T ~ ^x predicts a translational flow parallel to ^x whereas the true flow projects significantly onto ^y. <p> Figure 2 (left side) demonstrates this: as ^ T ! ^x the true reprojection error and (12) grow large while the errors (6) and (7) remain small <ref> [14] </ref>. As a result, for (6) and (7) the noise is relatively more important and shifts the position of the global minimum to the wrong side of ^z. 2.4 Recovering Heading: Experiments. We tested the performance of our algorithm on a number of difficult sequences. <p> A more sophisticated search for the global minima in the T-z plane would probably have avoided large errors in these cases, since most of the incorrect local minima occur at high error values near T ~ ^ z <ref> [14] </ref> (also see the Appendix). Also, a more thorough one-variable search should not be computationally prohibitive, since the error typically has few important stationary points [14]. For our algorithm, the linear and final reconstructions had different signs for T x in 280 of the trials. <p> probably have avoided large errors in these cases, since most of the incorrect local minima occur at high error values near T ~ ^ z <ref> [14] </ref> (also see the Appendix). Also, a more thorough one-variable search should not be computationally prohibitive, since the error typically has few important stationary points [14]. For our algorithm, the linear and final reconstructions had different signs for T x in 280 of the trials. For the two-frame algorithm, the reconstruction generated from the alternative to the "8-point" solution had lower energy in 77 trials. <p> These problems make any coplanarity-based approach such as ours intrinsically less accurate at ^ T ^z than brute-force optimization based on the reprojection error. In addition, as discussed in <ref> [14] </ref> and the Appendix, our algorithm has problems with local minima at ^ T ^z which are easily fixable, since the local minima only occur at high errors and very close to ^ T = ^z. <p> Near ^ T ~ ^x, the tendency to confound translations with rotations due to the bas-relief ambiguity worsens the initial rotation compensation. It also causes the position of ^ T within the ^ T-^z plane to be relatively sensitive to noise <ref> [14] </ref> [8]. For both these reasons, one again expects relatively better results from the brute-force approach. As we show below, one can easily correct the first, bas-relief-induced problem by using the initially recovered ^ T to recalculate and recompensate for the rotations and then recalculating ^ T. <p> On the other hand, when ^ T G ~ ^x, the error is small and almost flat except for the large central peak around T max <ref> [14] </ref>. Partly this is because the initial linear estimate tends to recover the ^ T-^z plane accurately for ^ T G ~ ^x [14]. Thus a bracketing failure causes no harm, since at worst fmin returns T min on the boundary at 0 or , close to the true solution. <p> On the other hand, when ^ T G ~ ^x, the error is small and almost flat except for the large central peak around T max <ref> [14] </ref>. Partly this is because the initial linear estimate tends to recover the ^ T-^z plane accurately for ^ T G ~ ^x [14]. Thus a bracketing failure causes no harm, since at worst fmin returns T min on the boundary at 0 or , close to the true solution. <p> cases, the initial estimate does not always find the ^ T-^z plane accurately, and the error can also vary significantly near ^ T ~ ^z due to the closeness of the FOE to some image points and the nearness of the global minimum to the ^ T x 0 peak <ref> [14] </ref>. As a result, fmin sometimes returns incorrect local minima at high errors. This could be cured by a more thorough search, or by a more sophisticated search that discounts the misleading structure at high errors near ^ T ^z.
Reference: [15] <author> J. Oliensis, </author> <title> "A Critique of Structure from Motion Algorithms," </title> <note> NECI TR 1997. </note>
Reference-contexts: Previous approaches to SFM cope well with large translations or small perspective effects [27, 11]. Our algorithm is designed for the complementary case of small translations and large perspective 1 effects. We have argued previously <ref> [15] </ref> [19, 21] that it is best to deal with the variety of SFM problems by using a variety of specialized algorithms rather than a single general-purpose approach. Take e.g. the maximum-likelihood least-squares estimate (MLE) as the "optimal" reconstruction. Its dependence on the observed image points is highly nonlinear.
Reference: [16] <author> J. Oliensis, </author> <title> "A Multi-frame Structure from Motion Algorithm under Perspective Projection," </title> <note> NECI TR 1996. </note>
Reference-contexts: Because our algorithms exploit the properties of their intended domains, they are fast and robust. They currently take a few seconds on an SGI 10000 for 15 images of 22 points in non-optimized MATLAB code, with a computational cost linear in the number of points [19] <ref> [16] </ref>. They are guaranteed to work under the appropriate conditions, and when applied to inappropriate motion sequences they clearly signal that their assumptions are violated. The main difference between our current and previous ([19][16]) algorithms is that here we first compute the camera heading, exploiting the fact that it remains approximately <p> Also, we show how to adapt our previous general-motion algorithm [19]<ref> [16] </ref> to recover the complete structure and motion given the heading. The adaptations give improved structure recovery by exploiting the constancy of the heading. In this paper, we assume the camera has been calibrated. [16] describes a modification of our approach that can deal with poor calibration of the camera center and with unknown focal lengths varying over the image sequence. For simplicity, we also assume no occlusion. However, as in [6], occlusion causes no difficulties for recovering the heading. <p> This algorithm first reconstructed the motion 17 using the "8-point" algorithm [11] modified following Hartley [3] and then used this as the starting estimate for an iterative algorithm minimizing a weighted coplanarity error <ref> [16] </ref>. (The "8-point" algorithm has a 2-fold ambiguity in recovering the translation and rotation; we selected the correct solution by comparing to the ground truth.) Previous work [16] has shown that this two-frame algorithm reconstructs the two-frame MLE of ^ T typically to within better than :01 ffi when it locates <p> algorithm [11] modified following Hartley [3] and then used this as the starting estimate for an iterative algorithm minimizing a weighted coplanarity error <ref> [16] </ref>. (The "8-point" algorithm has a 2-fold ambiguity in recovering the translation and rotation; we selected the correct solution by comparing to the ground truth.) Previous work [16] has shown that this two-frame algorithm reconstructs the two-frame MLE of ^ T typically to within better than :01 ffi when it locates the correct global minimum, which it does in most cases. <p> Note that solving (20) gives an essentially unbiased estimate of the Z 1 i ; in contrast with the analogous phase of our general-motion algorithm <ref> [16] </ref>. In [16] we used additional techniques to correct the bias which are not needed here. 3.4 Correcting the initial reconstruction. The next phase of the algorithm iteratively improves the , fg and rotation estimates. <p> Note that solving (20) gives an essentially unbiased estimate of the Z 1 i ; in contrast with the analogous phase of our general-motion algorithm <ref> [16] </ref>. In [16] we used additional techniques to correct the bias which are not needed here. 3.4 Correcting the initial reconstruction. The next phase of the algorithm iteratively improves the , fg and rotation estimates. <p> We made two approximations in our initial estimates of , fg: we neglected the second-order terms from the rotation error and from the denominator in (1). As for our general-motion algorithm, we correct these in turn <ref> [16] </ref>. In each iteration, we first recompensate for the rotations correcting for the translational image displacements recovered so far and then correct for the denominator error by multiplying the displacements by the current denominator estimate. <p> To correct the rotational estimates, we warp the base image by the calculated translational image displacements. The displacement between the warped image and the subsequent images are then due primarily to the residual rotations, which we recover as before. The details are given in <ref> [16] </ref>. This improves the rotation estimate by a factor o with each iteration. <p> To reestimate Z 1 i , h , we simply reapply our previous algorithm to the ~ d h i instead of to the d h i . Again, with each iteration the estimates improve by o Z 1 . See <ref> [16] </ref> for the details. As discussed there, multiplying by the denominator does introduce some bias into our estimate. It is possible to define an iteration that avoids this bias by correcting d h i additively rather than multiplicatively, but it has a smaller domain of convergence. <p> each iteration, convergence is rapid. 29 In our experiments we find that convergence to within one part in 10 3 typically takes just 5 or 6 cycles. 3.5 Reconstructing the X, Y Coordinates Following convergence, we reconstruct the X, Y structure coordinates using the information from all images as in <ref> [16] </ref>. We do this by reestimating the image displacements d h i , essentially from the requirement that the corresponding matrix D must be rank 3. Note that we are relaxing the constraint that the camera translates along a line, which would correspond to requiring that D be rank 1. <p> Note that we are relaxing the constraint that the camera translates along a line, which would correspond to requiring that D be rank 1. Relaxing the constraint at this stage costs relatively little and enables the algorithm to deal with small deviations from linear motion. As discussed in <ref> [16] </ref> and Section 2.2, introducing the matrix C in D CH eliminates all bias in recovering the translational image displacements. Let D (3) CH denote the best rank 3 approximation to D CH . <p> Note that using the estimated h ie in (23) or using and H computed from the measured base coordinates causes no bias in solving (22) <ref> [16] </ref>. Given T , we estimate ~ D G via ~ D G C 1=2 (3) and divide by the denominator factor e ie to get improved estimates d 0 of the true image displacements. <p> These do not necessarily represent significant failures of the algorithms. At ^ T ~ ^ x, any large error is typically confined to the constant component of the inverse depths, due to the bas-relief effect. The other depth components are typically recovered accurately <ref> [16] </ref>. For ^ T ~ ^ z, a few image points close to the FOE can give large depth errors without affecting the accurate depth recovery of the remaining points. <p> We created another set of 800 sequences under the same conditions as before and evaluated the two-frame algorithm and ours taking these factors into account. As in <ref> [16] </ref>, we defined one measure of depth-recovery accuracy by eliminating the potentially noise-sensitive constant component from the inverse depths and measuring the angular error for the remaining inverse-depth vector. We also defined a second measure given by the standard deviation of the depth error excluding outliers points. <p> For ^ T nearly parallel to the image plane, the bas-relief ambiguity causes the constant component of the inverse depths to be especially sensitive to noise, but the remaining inverse-depth components can still be recovered accurately <ref> [16] </ref>. This problem is inherent and not peculiar to our algorithm. For ^ T ~ ^z, our algorithm has problems recovering the depths for image points near the FOE. The problem is partly inherent, since the image data provides little depth information for these points.
Reference: [17] <author> J. Oliensis, </author> <note> in preparation. </note>
Reference-contexts: Presuming that the true ^ T is known, we can analyze the errors in determining the depths and translation magnitudes by a perturbation analysis of the SVD <ref> [17] </ref>. Again, the results are similar to those of [8] for optical flow.
Reference: [18] <author> J. Oliensis, </author> <title> "Structure from Linear and Planar Motions," </title> <address> CVPR 335-342, </address> <year> 1996. </year>
Reference-contexts: We previously derived (4) in <ref> [18] </ref>. Improved Linear Algorithm For moderate FOV ( F 90 ffi ), [6] has shown that solving (4) for ^ T causes a strong bias toward recovering ^ T ^z.
Reference: [19] <author> J. Oliensis, </author> <title> "Multiframe Structure from Motion in Perspective," </title> <booktitle> Workshop on the Representations of Visual Scenes, </booktitle> <pages> 77-84, </pages> <year> 1995. </year> <note> [20] http://www.neci.nj.nec.com/homepages/oliensis.html. </note>
Reference-contexts: Previous approaches to SFM cope well with large translations or small perspective effects [27, 11]. Our algorithm is designed for the complementary case of small translations and large perspective 1 effects. We have argued previously [15] <ref> [19, 21] </ref> that it is best to deal with the variety of SFM problems by using a variety of specialized algorithms rather than a single general-purpose approach. Take e.g. the maximum-likelihood least-squares estimate (MLE) as the "optimal" reconstruction. Its dependence on the observed image points is highly nonlinear. <p> Because our algorithms exploit the properties of their intended domains, they are fast and robust. They currently take a few seconds on an SGI 10000 for 15 images of 22 points in non-optimized MATLAB code, with a computational cost linear in the number of points <ref> [19] </ref> [16]. They are guaranteed to work under the appropriate conditions, and when applied to inappropriate motion sequences they clearly signal that their assumptions are violated. The main difference between our current and previous ([19][16]) algorithms is that here we first compute the camera heading, exploiting the fact that it remains <p> The error is unbiased since ^u is a unit vector and P 3 is a projection. (Since the matrix C 1 compensates for the noise in the base image <ref> [19] </ref>, it does not appear for optical flow since there all noise is in the flow.) [4][1] derived the optical flow error in a form similar to (12), but the advantage of (12) is that it is easily computable in o (N p N f ) steps.
Reference: [21] <author> J. Oliensis, </author> <title> "A Linear Solution for Multiframe Structure from Motion," </title> <booktitle> IUW, </booktitle> <pages> 1225-1231. </pages> <year> 1994. </year>
Reference-contexts: Previous approaches to SFM cope well with large translations or small perspective effects [27, 11]. Our algorithm is designed for the complementary case of small translations and large perspective 1 effects. We have argued previously [15] <ref> [19, 21] </ref> that it is best to deal with the variety of SFM problems by using a variety of specialized algorithms rather than a single general-purpose approach. Take e.g. the maximum-likelihood least-squares estimate (MLE) as the "optimal" reconstruction. Its dependence on the observed image points is highly nonlinear.
Reference: [22] <author> J. Oliensis, </author> <title> "Rigorous Bounds for Two-Frame Structure from Motion," </title> <note> ECCV 1996 and NECI TR 1995 (expanded version). </note>
Reference-contexts: We recover the rotations separately between the base frame and each subsequent frame assuming that the translations are zero. This assumption may seem strong, but we have proven that the resulting rotation errors are small when the translations are moderate <ref> [22] </ref>. The rotation recovery can be done exactly and quickly, e.g., via the singular value decomposition (SVD) [9][28]. The small-translation assumption is actually not crucial at this stage, since one can also recover the rotations accurately for large translations assuming the depth variation is significant [22]. 3 2.2 Initial Linear Algorithm <p> when the translations are moderate <ref> [22] </ref>. The rotation recovery can be done exactly and quickly, e.g., via the singular value decomposition (SVD) [9][28]. The small-translation assumption is actually not crucial at this stage, since one can also recover the rotations accurately for large translations assuming the depth variation is significant [22]. 3 2.2 Initial Linear Algorithm For Heading Recovery After compensation, the residual rotations are small, and one can approximate the rotational displacements in (1) to first order as f (R h ; p h y ; ! h z p i (! h y x i ) + o ! <p> Thus we get ffi ^ T ~o @ 1=2 1=2 1 0 N f N p A ; where we have introduced a factor 1= 1=2 1=2 to roughly represent the effect of the data re dundancy and also used o (!) ~ <ref> [22] </ref>. The first term on the right is the minimal error 14 one expects in solving for ^ T using the exact coplanarity/epipolar constraint. The second term represents the additional error due to our algorithm's approximations, which is typically smaller than the first. <p> The two-frame algorithm gives smaller errors partly because it starts from the ground truth and partly because the alternative translation is exact for two frames. Also, our algorithm's initial rotation compensation is worse for planar scenes due to the linear correlation between the depths and image points <ref> [22] </ref>, particularly at ^ T ~ ^x where it averaged about 3-4 ffi . Again, this is not a significant problem, since one can recompensate for the rotations following the initial recovery of ^ T to correct for this, as done in the next experiment.
Reference: [23] <author> H. S. Sawhney and R. Kumar, </author> <title> "True Multi-Image Alignment and its Application to Mosaicing and Lens Distortion Correction," </title> <booktitle> CVPR, </booktitle> <pages> 450-456, </pages> <year> 1997. </year>
Reference-contexts: When this occurs, rather than blindly applying our linear algorithm, it may well make more sense to compute the initial estimate of ^ T by modelling the scene as exactly planar (e.g. <ref> [23] </ref>). We report experimental results on planar and approximately planar scenes below. Our second-stage algorithm iteratively minimizes the error defined below 1 .
Reference: [24] <author> H-Y Shum et al., </author> <title> "Principal Component Analysis with Missing Data and Its Application to Object Modeling," </title> <booktitle> CVPR 1994, </booktitle> <pages> 560-565. </pages>
Reference-contexts: When there is occlusion, one can derive a good initial estimate for this row vector as in [5]|or by determining rows that are at relatively small angles with respect to each other and averaging them [18]|and then improve this estimate iteratively <ref> [24] </ref> [5]. For simplicity, we assume no occlusion.
Reference: [25] <author> J. Inigo Thomas, A. Hanson, and J. Oliensis, </author> <title> "Refining 3D reconstructions: A theoretical and experimental study of the effect of cross-correlations", </title> <journal> CVGIP:IU, </journal> <volume> 60 </volume> <pages> 359-370, </pages> <year> 1994. </year>
Reference-contexts: Most of this error comes from two points (the 7-th and 10-th), which are both distant and near the FOE. Our algorithm still does better than two-frame reconstruction, which had average errors of 6:6 and 18%. Our results also improve on those of a Kalman filtering approach <ref> [25, 26] </ref>. After translating, rotating, and scaling the complete (X; Y; Z) reconstructions to the ground truth, the standard deviation of the error per 3D point was 3:2 (4:2) for our algorithm without (with) compensation and 8:1 for the two-frame reconstruction. For MLE it was 3:8.
Reference: [26] <author> J. Inigo Thomas and J. Oliensis, </author> <title> "Isolation and Correction of Noise in Multi-Frame Structure from Motion," </title> <type> U. </type> <institution> of Massachusetts TR, </institution> <year> 1994. </year>
Reference-contexts: Most of this error comes from two points (the 7-th and 10-th), which are both distant and near the FOE. Our algorithm still does better than two-frame reconstruction, which had average errors of 6:6 and 18%. Our results also improve on those of a Kalman filtering approach <ref> [25, 26] </ref>. After translating, rotating, and scaling the complete (X; Y; Z) reconstructions to the ground truth, the standard deviation of the error per 3D point was 3:2 (4:2) for our algorithm without (with) compensation and 8:1 for the two-frame reconstruction. For MLE it was 3:8.
Reference: [27] <author> C. Tomasi and T. Kanade, </author> <title> "Shape and motion from image streams under orthography: A factorization method," </title> <booktitle> IJCV 9 </booktitle> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: Experimentally, our approach gives good results even when the camera's motion is far from linear. Previous approaches to SFM cope well with large translations or small perspective effects <ref> [27, 11] </ref>. Our algorithm is designed for the complementary case of small translations and large perspective 1 effects. We have argued previously [15] [19, 21] that it is best to deal with the variety of SFM problems by using a variety of specialized algorithms rather than a single general-purpose approach. <p> With no occlusion, one can do this using the SVD as in <ref> [27] </ref>. When there is occlusion, one can derive a good initial estimate for this row vector as in [5]|or by determining rows that are at relatively small angles with respect to each other and averaging them [18]|and then improve this estimate iteratively [24] [5]. For simplicity, we assume no occlusion.
Reference: [28] <author> S. Umeyama, </author> <title> "Least-squares estimation of transformation parameters between two point patterns," </title> <type> PAMI 13 </type> <pages> 376-380, </pages> <year> 1991. </year> <month> 37 </month>
References-found: 27

