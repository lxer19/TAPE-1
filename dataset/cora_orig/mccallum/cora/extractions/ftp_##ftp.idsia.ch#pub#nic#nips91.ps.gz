URL: ftp://ftp.idsia.ch/pub/nic/nips91.ps.gz
Refering-URL: http://www.cnl.salk.edu/~schraudo/pubs.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: nici@cs.ucsd.edu  tsejnowski@ucsd.edu  
Title: Competitive Anti-Hebbian Learning of Invariants  
Author: Nicol N. Schraudolph Terrence J. Sejnowski 
Address: La Jolla, CA 92093-0114  La Jolla, CA 92186-5800  
Affiliation: Computer Science Engr. Dept. University of California, San Diego  Computational Neurobiology Laboratory The Salk Institute for Biological Studies  
Abstract: Although the detection of invariant structure in a given set of input patterns is vital to many recognition tasks, connectionist learning rules tend to focus on directions of high variance (principal components). The prediction paradigm is often used to reconcile this dichotomy; here we suggest a more direct approach to invariant learning based on an anti-Hebbian learning rule. An unsupervised two-layer network implementing this method in a competitive setting learns to extract coherent depth information from random-dot stereograms.
Abstract-found: 1
Intro-found: 1
Reference: <author> Baldi, P. and Hornik, K. </author> <year> (1989). </year> <title> Neural networks and principal component analysis: Learning from examples without local minima. </title> <booktitle> Neural Networks, </booktitle> <volume> 2 </volume> <pages> 53-58. </pages>
Reference-contexts: The same type of representation also develops in the hidden layer of backpropagation autoassociator networks <ref> (Baldi and Hornik, 1989) </ref>. However, the directions of highest variance need not always be those that yield the most information, or | as the case may be | the information we are interested in (Intrator, 1991).
Reference: <author> Barlow, H. B. and Foldiak, P. </author> <year> (1989). </year> <title> Adaptation and decorrelation in the cortex. </title> <editor> In Durbin, R. M., Miall, C., and Mitchison, G. J., editors, </editor> <booktitle> The Computing Neuron, chapter 4, </booktitle> <pages> pages 54-72. </pages> <publisher> Addison-Wesley, Wokingham. </publisher>
Reference: <author> Becker, S. and Hinton, G. E. </author> <year> (1992). </year> <title> A self-organizing neural network that discovers surfaces in random-dot stereograms. </title> <note> Nature, to appear. </note>
Reference-contexts: It is also possible to explicitly derive an error signal from the mutual information between two patches of structured input <ref> (Becker and Hinton, 1992) </ref>, a technique which has been applied to viewpoint-invariant object recognition (Zemel and Hinton, 1991). 2 METHODS 2.1 ANTI-HEBBIAN FEEDFORWARD LEARNING In most formulations of the covariance learning rule it is quietly assumed that the learning rate be positive.
Reference: <author> Elman, J. </author> <year> (1990). </year> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14 </volume> <pages> 179-211. </pages>
Reference-contexts: A more general approach is to make information about invariant structure available in the error signal of a supervised network. The most popular way of doing this is to require the network to predict the next patch of some structured input from the preceding context, as in <ref> (Elman, 1990) </ref>; the same prediction technique can be used across space as well as time.
Reference: <author> Foldiak, P. </author> <year> (1991). </year> <title> Learning invariance from transformation sequences. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 194-200. </pages>
Reference-contexts: The problem, then, is how to achieve this within a connectionist framework that is so closely tied to the maximization of variance. fl Reprinted from J.E. Moody, S.J. Hanson, and R.P. Lippmann, editors (1992), Advances in Neural Information Processing Systems, volume 4, pages 1017-1024. Morgan Kaufmann, San Mateo. In <ref> (Foldiak, 1991) </ref>, spatial invariance is turned into a temporal feature by presenting trans-formation sequences within invariance classes as a stimulus. A built-in temporal smoothness constraint enables Hebbian neurons to learn these transformations, and hence the invariance classes.
Reference: <author> Intrator, N. </author> <year> (1991). </year> <title> Exploratory feature extraction in speech signals. </title> <editor> In (Lippmann et al., </editor> <year> 1991), </year> <pages> pages 241-247. </pages>
Reference-contexts: The same type of representation also develops in the hidden layer of backpropagation autoassociator networks (Baldi and Hornik, 1989). However, the directions of highest variance need not always be those that yield the most information, or | as the case may be | the information we are interested in <ref> (Intrator, 1991) </ref>. In fact, it is sometimes desirable to extract the invariant structure of a stimulus instead, learning to encode those aspects that vary the least.
Reference: <author> Jolliffe, I. </author> <year> (1986). </year> <title> Principal Component Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: 1 INTRODUCTION: LEARNING INVARIANT STRUCTURE Many connectionist learning algorithms share with principal component analysis <ref> (Jolliffe, 1986) </ref> the strategy of extracting the directions of highest variance from the input.
Reference: <author> Kohonen, T. </author> <year> (1989). </year> <title> Self-Organization and Associative Memory. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, 3 edition. </address>
Reference-contexts: By reversing the sign of this constant in a recurrent autoassociator, Kohonen constructed a "novelty filter" that learned to be insensitive to familiar features in its input <ref> (Kohonen, 1989) </ref>. More recently, such anti-Hebbian synapses have been used for lateral decorrelation of feature detectors (Barlow and Foldiak, 1989; Leen, 1991) as well as | in differential form | removal of temporal variations from the input (Mitchison, 1991).
Reference: <author> Kung, S. Y. </author> <year> (1990). </year> <title> Neural networks for extracting constrained principal components. </title> <journal> submitted to IEEE Trans. Neural Networks. </journal>
Reference: <author> Leen, T. K. </author> <year> (1991). </year> <title> Dynamics of learning in linear feature-discovery networks. </title> <journal> Network, </journal> <volume> 2 </volume> <pages> 85-105. </pages>
Reference: <editor> Lippmann, R. P., Moody, J. E., and Touretzky, D. S., editors (1991). </editor> <booktitle> Advances in Neural Information Processing Systems, volume 3, </booktitle> <address> Denver 1990. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo. </address>
Reference: <author> Mitchison, G. </author> <year> (1991). </year> <title> Removing time variation with the anti-hebbian differential synapse. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 312-320. </pages>
Reference-contexts: More recently, such anti-Hebbian synapses have been used for lateral decorrelation of feature detectors (Barlow and Foldiak, 1989; Leen, 1991) as well as | in differential form | removal of temporal variations from the input <ref> (Mitchison, 1991) </ref>. We suggest that in certain cases the use of anti-Hebbian feedforward connections to learn invariant structure may eliminate the need to bring in the heavy machinery of supervised learning algorithms required by the prediction paradigm, with its associated lack of neuro-biological plausibility.
Reference: <author> Nowlan, S. J. </author> <year> (1990). </year> <title> Maximum likelihood competitive learning. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 574-582, </pages> <address> Denver 1989. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo. </address>
Reference-contexts: Soft competition between nodes in a layer can then be implemented simply by normalizing these probabilities (i.e. dividing each output by the sum of outputs in a layer), then using them to scale weight changes <ref> (Nowlan, 1990) </ref>. 2.2 AN ANTI-HEBBIAN OBJECTIVE FUNCTION The magnitude of weight change in a Hebbian neuron is proportional to the cosine of the angle between input and weight vectors.
Reference: <author> Oja, E. </author> <year> (1982). </year> <title> A simplified neuron model as a principal component analyzer. </title> <journal> Journal of Mathematical Biology, </journal> <volume> 15 </volume> <pages> 267-273. </pages>
Reference-contexts: In what follows we address some of the problems thus introduced. Like the Hebb rule, anti-Hebbian learning requires weight normalization, in this case to prevent weight vectors from collapsing to zero. Oja's active decay rule <ref> (Oja, 1982) </ref> is a popular local approximation to explicit weight normalization: ~w = (~xy ~wy 2 ), where y = ~w T ~x (1) Here the first term in parentheses represents the standard Hebb rule, while the second is the active decay.
Reference: <author> Oja, E. and Karhunen, J. </author> <year> (1985). </year> <title> On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix. </title> <journal> Journal of Mathematical Analysis and Applications, </journal> <volume> 106 </volume> <pages> 69-84. </pages>
Reference-contexts: 1 INTRODUCTION: LEARNING INVARIANT STRUCTURE Many connectionist learning algorithms share with principal component analysis (Jolliffe, 1986) the strategy of extracting the directions of highest variance from the input. A single Hebbian neuron, for instance, will come to encode the input's first principal component <ref> (Oja and Karhunen, 1985) </ref>; various forms of lateral interaction can be used to force a layer of such nodes to differentiate and span the principal component subspace | cf. (Sanger, 1989; Kung, 1990; Leen, 1991), and others. <p> In our experiments, this is done by the soft competition mechanism; here we present a more general framework towards this end. A simple Hebbian neuron maximizes the variance of its output y through stochastic approximation by performing gradient ascent in 1 2 y 2 <ref> (Oja and Karhunen, 1985) </ref>: w i / @w i 2 @ y = x i y (2) As seen above, it is not sufficient for an anti-Hebbian neuron to simply perform gradient descent in the same function.
Reference: <author> Sanger, T. D. </author> <year> (1989). </year> <title> Optimal unsupervised learning in a single-layer linear feedforward neural network. </title> <booktitle> Neural Networks, </booktitle> <volume> 2 </volume> <pages> 459-473. </pages>
Reference: <author> Zemel, R. S. and Hinton, G. E. </author> <year> (1991). </year> <title> Discovering viewpoint-invariant relationships that characterize objects. </title> <editor> In (Lippmann et al., </editor> <year> 1991), </year> <pages> pages 299-305. </pages>
Reference-contexts: It is also possible to explicitly derive an error signal from the mutual information between two patches of structured input (Becker and Hinton, 1992), a technique which has been applied to viewpoint-invariant object recognition <ref> (Zemel and Hinton, 1991) </ref>. 2 METHODS 2.1 ANTI-HEBBIAN FEEDFORWARD LEARNING In most formulations of the covariance learning rule it is quietly assumed that the learning rate be positive.
References-found: 17

