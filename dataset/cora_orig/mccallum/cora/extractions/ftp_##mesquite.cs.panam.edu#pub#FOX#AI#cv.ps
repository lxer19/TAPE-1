URL: ftp://mesquite.cs.panam.edu/pub/FOX/AI/cv.ps
Refering-URL: http://www.cs.panam.edu/fox/sr.html
Root-URL: http://www.cs.panam.edu
Author: Richard Fox and John Josephson 
Date: August 12, 1990  
Abstract: CV Experiment and Results 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L.D. Erman. </author> <title> The hearsay-ii speech understanding system: A tutorial. </title> <editor> In Wayne A. Lea, editor, </editor> <booktitle> Trends In Speech Recognition. Prentice-Hall Signal Processing Series, </booktitle> <year> 1980. </year>
Reference-contexts: Speech Recognition and Layered Abduction Past attempts at speech recognition have taken on a range of solutions. Hearsay-II <ref> [1, 7] </ref> used a deliberative problem solving strategy where communication between levels was accomplished via a blackboard. Hearsay-II also used an explicit control strategy to determine what area of the problem to focus on.
Reference: [2] <author> Richard Fox, John Josephson, and Sunil Thadani. </author> <title> A three level abduction machine for word recognition from articulation. </title> <type> Technical report, </type> <institution> The Ohio State University, </institution> <year> 1991. </year>
Reference-contexts: We are not ready to address these problems. Out initial interest in CV was to build a multi-layered abduction speech recognizer. CV falls short of this as it is only a single-layered abduction. Since the CV project, we have constructed a multi-layered articulatory recognition system <ref> [2] </ref>. 9
Reference: [3] <author> J. Josephson and D. Smetters and R. Fox and D. Oblinger and A. Welch and G. Northrup. </author> <title> The Integrated Generic Task Toolset, Fafner Release 1.0. </title> <type> Technical report, </type> <institution> The Ohio State University, </institution> <year> 1989. </year>
Reference-contexts: These phonemes are the six stop consonants (/b/, /d/, /g/, /k/, /p/, and /t/) and five vowels (/a/, /ae/, /er/, /i/, /u/). The CV system was created out of the Integrated Generic Task Toolset <ref> [3] </ref> and common lisp. It was built over a few months period, tested on 60 files of CVs and then run on 90 files. Results are discussed later. CV uses multiple features to determine both the consonant and vowel.
Reference: [4] <author> H.W. Hon Kai-Fe Lee. </author> <title> Speaker-independent phoneme recognition using hidden markov models. </title> <type> Technical report, </type> <institution> Carnegie Mellon University, Computer Science Department, </institution> <month> April, </month> <year> 1988. </year>
Reference-contexts: However, neither of these systems used an explicit abduction algorithm. If there is any purchase for using the explanatory nature of abduction, it was lossed on these systems. More recently, Sphinx <ref> [6, 4, 5] </ref> among other systems has used Hidden Markov Modeling approaches by creating mathematical models of phonemes or other linguistic units. Then, a dynamic programming algorithm is used to traverse the space of possible utterances. Where available, simple grammars are used to prune the utterance space.
Reference: [5] <author> Kai-Fe Lee. </author> <title> Towards speaker-independent continuous speech recognition. </title> <booktitle> In 1987 NATO ASI on Speech Recognition and Dialog Understanding, </booktitle> <year> 1987. </year>
Reference-contexts: However, neither of these systems used an explicit abduction algorithm. If there is any purchase for using the explanatory nature of abduction, it was lossed on these systems. More recently, Sphinx <ref> [6, 4, 5] </ref> among other systems has used Hidden Markov Modeling approaches by creating mathematical models of phonemes or other linguistic units. Then, a dynamic programming algorithm is used to traverse the space of possible utterances. Where available, simple grammars are used to prune the utterance space.
Reference: [6] <author> Kai-Fe Lee. </author> <title> Large-Vocabulary Speaker-Independent Continuous Speech Recognition: The SPHINX System. </title> <address> CMU, </address> <year> 1988. </year>
Reference-contexts: However, neither of these systems used an explicit abduction algorithm. If there is any purchase for using the explanatory nature of abduction, it was lossed on these systems. More recently, Sphinx <ref> [6, 4, 5] </ref> among other systems has used Hidden Markov Modeling approaches by creating mathematical models of phonemes or other linguistic units. Then, a dynamic programming algorithm is used to traverse the space of possible utterances. Where available, simple grammars are used to prune the utterance space.
Reference: [7] <author> Lee Erman Frederick Hayes-Roth Victor Lesser and Raj Reddy. </author> <title> The hearsay-ii speech understanding system: Integrating knowledge to resolve uncertainty. </title> <journal> Computing Surveys, </journal> <volume> Vol. 12, No. 2 </volume> <pages> 213-253, </pages> <month> June, </month> <year> 1980. </year>
Reference-contexts: Speech Recognition and Layered Abduction Past attempts at speech recognition have taken on a range of solutions. Hearsay-II <ref> [1, 7] </ref> used a deliberative problem solving strategy where communication between levels was accomplished via a blackboard. Hearsay-II also used an explicit control strategy to determine what area of the problem to focus on.
Reference: [8] <author> B. Lowerre and R. Reddy. </author> <title> The harpy speech understanding system. Trends In Speech Recognition, </title> <year> 1980. </year>
Reference-contexts: Hearsay-II [1, 7] used a deliberative problem solving strategy where communication between levels was accomplished via a blackboard. Hearsay-II also used an explicit control strategy to determine what area of the problem to focus on. Harpy <ref> [8] </ref> took an entirely different approach by modeling all possible utterances as one large lattice expanded from the grammar and lexicon. Then, Harpy used matching templates of phonemes against the input to find the most probable path through the lattice.
Reference: [9] <author> Ron Rassner. </author> <title> Data analysis manual. </title> <type> Technical report, </type> <institution> University of Wisconsin Speech Motor Control Laboratories X-Ray Microbeam Facility, </institution> <month> Oct. </month> <year> 1987. </year> <month> 10 </month>
Reference-contexts: CV System Our research on speech recognition has led to the construction of an acoustic CV pair 1 recognition system. CV attempts to recognize an isolated consonant-vowel pair amid silence. CV takes as input a file of acoustic features created by the ESPS sound analysis software <ref> [9] </ref>. CV then takes an abductive approach at solving the speech recognition problem. The steps that CV takes will be described later. CV was to be an initial attempt at acoustic speech recognition. To begin, we chose to solve a simple problem of isolated CV recognition using 11 phonemes.
References-found: 9

