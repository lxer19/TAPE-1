URL: ftp://ftp.speech.sri.com/pub/people/francois/icassp97-2.ps.gz
Refering-URL: http://www.speech.sri.com/people/francois/publications.html
Root-URL: 
Email: e-mail: francois,mw@speech.sri.com  
Title: MODEL TRANSFORMATION FOR ROBUST SPEAKER RECOGNITION FROM TELEPHONE DATA technique is illustrated with experiments conducted
Author: Fran~coise Beaufays and Mitch Weintraub 
Note: The  
Address: Menlo Park, CA.  
Affiliation: Speech Technology and Research Laboratory SRI International,  
Abstract: In the context of automatic speaker recognition, we propose a model transformation technique that renders speaker models more robust to acoustic mismatches and to data scarcity by appropriately increasing their variances. We use a stereo database containing speech recorded simultaneously under different acoustic conditions to derive a synthetic variance distribution. This distribution is then used to modify the variances of other speaker models from other telephone databases. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.A. Reynolds, </author> <title> "Large population speaker identification using clean and telephone speech," </title> <journal> IEEE Signal Proc. Letters, </journal> <volume> vol. 2, no. 3, </volume> <pages> pp. 46-48, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Such mismatches are known to severely affect the performance of the speaker-ID system <ref> [1] </ref>. In addition, the typically limited amount of training data further accentuates the problem.
Reference: [2] <author> C.R. Janowski Jr., T.F. Quatieri, D.A. Reynolds, </author> <title> "Measuring fine structure in speech: Application to Speaker Identification," </title> <booktitle> in Proc. ICASSP-95, </booktitle> <pages> pp. 325-328. </pages>
Reference-contexts: In addition, the typically limited amount of training data further accentuates the problem. The issue of acoustic mismatches can be tackeled at different levels: speech features can be extracted that are less sensitive to channel effects than the traditional cep-strum (see e.g., <ref> [2, 13] </ref>) the effect of mismatches can be reduced via cepstral mean/bias removal (see e.g., [3-6]), the speaker models can be transformed to compensate for the mismatches, rescoring techniques can be used to normalize the speaker scores and reduce the channel effects (see e.g., [7]), etc.
Reference: [3] <author> S. Furui, </author> <title> "Cepstral Analysis Technique for Automatic Speaker Verification", </title> <journal> IEEE Trans. ASSP, </journal> <volume> vol. ASSP-29, </volume> <pages> pp. 254-272, </pages> <month> April </month> <year> 1981. </year>
Reference: [4] <author> R.M. Stern, F.-H. Liu, P.J. Moreno, A. Acero, </author> <title> "Signal processing for robust speech recognition", </title> <journal> Proc. ICSLP-94, </journal> <volume> vol. 3, </volume> <pages> pp. 1027-1030, </pages> <address> Sept. 1994, Yokohama, Japan. </address>
Reference: [5] <author> F.-H. Liu, R.M. Stern, A. Acero, P.J. Moreno, </author> <title> "Environment normalization for robust speech recognition using direct cepstral comparison," </title> <journal> Proc. ICASSP-94, </journal> <volume> vol. 2, </volume> <pages> pp. </pages> <address> II/61-64, Adelaide, Australia. </address>
Reference: [6] <author> A.E. Rosenberg, C.-H. Lee, F.K. Soong, </author> <title> "Cepstral channel normalization techniques for HMM-based speaker verification", </title> <booktitle> 1994 Intl. Conf. on Spoken Language Proc., </booktitle> <address> Yoko-hama, Japan. </address>
Reference: [7] <author> L.P. Heck, H. Murthy, F. Beaufays, M. Weintraub, </author> <title> "Speaker Recognition at SRI International", NIST Speaker Recognition Workshop, </title> <institution> Maritime Institute of Technology, Baltimore, Md. </institution> <month> March </month> <year> 1996 </year>
Reference-contexts: than the traditional cep-strum (see e.g., [2, 13]) the effect of mismatches can be reduced via cepstral mean/bias removal (see e.g., [3-6]), the speaker models can be transformed to compensate for the mismatches, rescoring techniques can be used to normalize the speaker scores and reduce the channel effects (see e.g., <ref> [7] </ref>), etc. This paper concentrates on the model transformation approach. The method we propose is a channel compensation method, as opposed to a channel adaptation one. It aims at making the speaker models more robust to channel mismatches rather than adapting them to the test environment. <p> Roughly 50% of the handsets used for testing were identical to those used for training. This was an open-set speaker recognition task, with 21 male target speakers, and 400 imposter speakers. The figure of interest was the probability of false alarm at 10% miss (see <ref> [7] </ref> for more details about the open-set baseline system).
Reference: [8] <author> J.L. Gauvain, C.-H. Lee, </author> <title> "Maximum a Posteriori Estimation for Multivariate Gaussian Mixture Observations of Markov Chains", </title> <journal> IEEE Trans. Speech and Audio Proc., </journal> <volume> vol. 2, no. 2, </volume> <pages> pp 291-298, </pages> <month> April </month> <year> 1994. </year>
Reference: [9] <author> C.J. Legetter, </author> <title> P.C. Woodland, "Flexible Speaker Adaptation using Maximum Likelihood Linear Regression", </title> <booktitle> Proc. of the Spoken Language Systems Techn. Workshop, </booktitle> <pages> pp. 110-115, </pages> <year> 1995. </year>
Reference: [10] <author> V. Digalakis, D. Rtischev, L. Neumeyer, </author> <title> "Speaker Adaptation Using Constrained Reestimation of Gaussian Mixtures", </title> <journal> IEEE Trans. Speech and Audio Proc., </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 357-366, </pages> <year> 1995. </year>
Reference: [11] <author> A. Sankar, C.-H. Lee, </author> <title> "A Maximum-Likelihood Approach to Stochastic Matching for Robust Speech Recognition", </title> <journal> IEEE Trans. Speech and Audio Proc., </journal> <pages> pp. 190-202, </pages> <month> May </month> <year> 1996. </year>
Reference: [12] <author> L.Neumeyer and M.Weintraub, </author> <title> "Probabilistic optimum filtering for robust speech recognition," </title> <journal> Proc. ICASSP-94, </journal> <volume> vol. 1, </volume> <pages> pp. 417-420, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: If such knowledge is available (for example if we know that the handset has an electret or a carbon-button), it can be used to map the speaker models from one environment to another (e.g., using POF filters <ref> [12] </ref>) or to refine the variance transformation described here by making it telephone-dependent; but we show that even without such information a significant performance gain can be achieved.
Reference: [13] <author> H.A. Murthy, F. Beaufays, L.P. Heck, M. Weintraub, </author> <title> "Robust Text-Independent Speaker Identification over Telephone Channels", </title> <note> in preparation to be submitted to IEEE Trans. Speech and Audio Proc.. 4 </note>
Reference-contexts: In addition, the typically limited amount of training data further accentuates the problem. The issue of acoustic mismatches can be tackeled at different levels: speech features can be extracted that are less sensitive to channel effects than the traditional cep-strum (see e.g., <ref> [2, 13] </ref>) the effect of mismatches can be reduced via cepstral mean/bias removal (see e.g., [3-6]), the speaker models can be transformed to compensate for the mismatches, rescoring techniques can be used to normalize the speaker scores and reduce the channel effects (see e.g., [7]), etc. <p> Assuming that the acoustic coverage of Sennheiser data is similar to that of data collected from a telephone unit under similar conditions (same amount of data), we could apply this transformation to speaker models trained for other telephone databases. This approach is further described in <ref> [13] </ref>. It gave good results but was outperformed by the variance transformation described in the next section. 7. SPEAKER MODEL TRANSFORMATION This transformation can be seen as an extension of the affine transformation mentioned previously. <p> Speaker-ID error-rate on SRI-digits, 2-line 2-minute training, 4-second testing. 8.2. Experiments on the Switchboard Corpus So far, we considered only cepstrum-based systems. In <ref> [13] </ref>, we propose a new speaker-ID feature that measures the slope of the filterbank used to derive the cepstrum. Cepstrum-based and filterbank slope-based GMMs can be combined by averaging the log-likelihoods of the test utterances wrt. the two GMMs (see [13] for more details). <p> In <ref> [13] </ref>, we propose a new speaker-ID feature that measures the slope of the filterbank used to derive the cepstrum. Cepstrum-based and filterbank slope-based GMMs can be combined by averaging the log-likelihoods of the test utterances wrt. the two GMMs (see [13] for more details). Two sets of 64-Gaussian GMMs were built for the 30-second training, 5-second testing close-set task of the NIST'95 Evaluation (26-speaker subset of Switchboard). 3 One GMM was based on a 17-dimensional cepstrum, the other used a 28-dimensional filterbank slope feature [13]. <p> utterances wrt. the two GMMs (see <ref> [13] </ref> for more details). Two sets of 64-Gaussian GMMs were built for the 30-second training, 5-second testing close-set task of the NIST'95 Evaluation (26-speaker subset of Switchboard). 3 One GMM was based on a 17-dimensional cepstrum, the other used a 28-dimensional filterbank slope feature [13]. Synthetic variance distributions were computed for each front-end, and fixed-target translations were applied to the corresponding GMMs. Table 3 summarizes the error-rates of the different systems.
References-found: 13

