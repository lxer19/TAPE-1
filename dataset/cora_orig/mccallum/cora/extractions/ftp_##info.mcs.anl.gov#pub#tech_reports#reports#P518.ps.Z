URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P518.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts95.htm
Root-URL: http://www.mcs.anl.gov
Email: E-mail: kwong@mcs.anl.gov  
Title: Random Wavelet Transforms, Algebraic Geometric Coding, and Their Applications in Signal Compression and De-Noising  
Author: Tomasz Bieleck Li M. Song Stephen S. T. Yau Man Kam Kwong 
Address: Chicago, IL 60607-7045  Argonne, IL 60439-4844  
Affiliation: Department of Mathematics, Statistics and Computer Science The University of Illinois at Chicago  Mathematics and Computer Science Division Argonne National Laboratory  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bielecki, T., </author> <title> On integration with respect to fractional Brownian motions, </title> <journal> Statistics and Probability Letters, </journal> <note> to appear 1995 </note>
Reference-contexts: The scaling and wavelet coefficients of B H are random sequences given by a H Z B H (x)OE j;k (x)dx; (3:26) b H Z B H (x) j;k (x)dx (3:27) respectively, for j; k 2 Z. Using the results of <ref> [1] </ref>, we can also define what we call random scaling and random wavelet coefficients of B H . We have used stochastic integrals of scaling and wavelet functions with respect to B M .
Reference: [2] <author> Bielecki, T., </author> <title> On integration with respect to fractional Wiener sheet, </title> <type> preprint, </type> <year> 1995 </year>
Reference-contexts: Remark 1.1 A fractional Wiener sheet on R d was first constructed and studied in <ref> [2] </ref>. Remark 1.2 In the case d = 1, a fractional Wiener sheet coincides with fractional Brownian motion (fBm) and is denoted by B H j (B H (t)) t2R . For the classical definition of fBm, see, for example, [18]. <p> In the remaining part of this section, we shall briefly describe transforms of the fractional Brownian motion B H . The results given below can be extended to the case of Wiener sheet by using the result of <ref> [2] </ref>. The scaling and wavelet coefficients of B H are random sequences given by a H Z B H (x)OE j;k (x)dx; (3:26) b H Z B H (x) j;k (x)dx (3:27) respectively, for j; k 2 Z.
Reference: [3] <author> Bielecki, T., Chen, J. and Yau, Stephen S. T., </author> <title> Random wavelet transformation and its properties, in Wavelet Applications in Signal and Image Processing II, </title> <editor> eds. A. F. Laine and M. A. Unser, </editor> <booktitle> SPIE Proc. </booktitle> <volume> vol. </volume> <month> 2303 </month> <year> (1994) </year>
Reference-contexts: That is, we define a H Z OE j;k (x)dB H (x) (3:28) b H Z j;k (x)dB H (x) (3:29) for j; k 2 Z. Several properties of the random wavelet coefficients of B M are demonstrated in <ref> [3] </ref>. The transform in (3.29) is called the random wavelet transform.
Reference: [4] <author> Chui, C., </author> <title> An Introduction to Wavelets, </title> <publisher> Academic Press, </publisher> <year> 1992 </year>
Reference-contexts: The fol lowing notation will be useful. V j := closure L 2 (R) fOE j;k ; k 2 Zg; V 1 := OE; (3:10) W j := closure L 2 (R) f j;k ; k 2 Zg: Then we have (see [5] or <ref> [4] </ref>) V j+1 = V j W j : (3:11) Therefore, if we denote by f j the projection of f on V j , and by g j the projection of f on W j , we see that for each f 2 L 2 (R) and all M N
Reference: [5] <author> Daubechies, I., </author> <title> Orthonormal basis of compactly supported wavelets, </title> <journal> Commun. Pure Appl. Math., </journal> <volume> vol. 41, </volume> <pages> pp. </pages> <month> 909-996 </month> <year> (1988) </year>
Reference-contexts: Wavelet Transform and Random Wavelet Transform We will discuss, for simplicity, only one-dimensional wavelets. Higher-dimensional wavelets can be treated in a similar way. In her seminal paper <ref> [5] </ref>, Ingrid Daubechies presented the construction of two sequences (p k ) and (q k ) of real numbers that solve the two-scale equations, OE (x) = k (x) = k for all x 2 R d . She proved the existence of compactly supported solutions in L 2 (R). <p> version of the basic functions OE () and (), j;k (x) := 2 j=2 (2 j x k) (3:5) Let us denote, for J 2 Z, J = fOE J ;k (); k 2 Zg; J = f j;k (); j J ; k 2 Zg: Then, as shown in <ref> [5] </ref>, ( J ; J ) is an orthonormal basis for L 2 (R) for each J 2 Z, under appropriate choice of the coefficients (p k ) and (q k ). Such a choice of (p k ) and (q k ) will be assumed from now on. <p> The fol lowing notation will be useful. V j := closure L 2 (R) fOE j;k ; k 2 Zg; V 1 := OE; (3:10) W j := closure L 2 (R) f j;k ; k 2 Zg: Then we have (see <ref> [5] </ref> or [4]) V j+1 = V j W j : (3:11) Therefore, if we denote by f j the projection of f on V j , and by g j the projection of f on W j , we see that for each f 2 L 2 (R) and all
Reference: [6] <author> Ehrhard, D., </author> <title> Achieving the designed error capacity in decoding algebraic-geometric codes, </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 39, no. </volume> <month> 3 </month> <year> (1993) </year>
Reference-contexts: They have close error-correcting capacity (by which we mean the number of errors the code is capable of correcting) and similar complexity, as illustrated below, and are given respectively in Justesen et. al. [11], Feng and Rao [7], and Ehrhard <ref> [6] </ref>. Ref. Curve Capacity Complexity [11] planar d fl i 8 m 8 7 [7] any (d fl 1)=2 O (n 3 ) In the above, m is the degree of the plane curve; d fl should be considered as proportional to n. <p> They each were able to make use of an algorithm generalizing some standard ones to the cyclic codes (cases of [11] and [7]), thanks to the underlying algebraic structure. An equivalent description using differentials was the presentation in [7] and <ref> [6] </ref>. They all have the appeal of implementabil-ity. 5. Perspective. AG codes are easy to construct, have rates and error-correcting capacity, and algorithms for decoding are fast.
Reference: [7] <author> Feng, G.-L. and Rao, T. R. N., </author> <title> Decoding algebraic-geometric codes up to the designed minimal distance, </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 39, no. </volume> <month> 1 </month> <year> (1993) </year>
Reference-contexts: They have close error-correcting capacity (by which we mean the number of errors the code is capable of correcting) and similar complexity, as illustrated below, and are given respectively in Justesen et. al. [11], Feng and Rao <ref> [7] </ref>, and Ehrhard [6]. Ref. Curve Capacity Complexity [11] planar d fl i 8 m 8 7 [7] any (d fl 1)=2 O (n 3 ) In the above, m is the degree of the plane curve; d fl should be considered as proportional to n. <p> capacity (by which we mean the number of errors the code is capable of correcting) and similar complexity, as illustrated below, and are given respectively in Justesen et. al. [11], Feng and Rao <ref> [7] </ref>, and Ehrhard [6]. Ref. Curve Capacity Complexity [11] planar d fl i 8 m 8 7 [7] any (d fl 1)=2 O (n 3 ) In the above, m is the degree of the plane curve; d fl should be considered as proportional to n. <p> They each were able to make use of an algorithm generalizing some standard ones to the cyclic codes (cases of [11] and <ref> [7] </ref>), thanks to the underlying algebraic structure. An equivalent description using differentials was the presentation in [7] and [6]. They all have the appeal of implementabil-ity. 5. Perspective. AG codes are easy to construct, have rates and error-correcting capacity, and algorithms for decoding are fast. <p> They each were able to make use of an algorithm generalizing some standard ones to the cyclic codes (cases of [11] and <ref> [7] </ref>), thanks to the underlying algebraic structure. An equivalent description using differentials was the presentation in [7] and [6]. They all have the appeal of implementabil-ity. 5. Perspective. AG codes are easy to construct, have rates and error-correcting capacity, and algorithms for decoding are fast.
Reference: [8] <author> Gray, R. M., </author> <title> Source coding theory, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1990 </year>
Reference: [9] <author> Hartshorne, R. </author> <title> Algebraic Geometry, </title> <publisher> Springer-Verlag, </publisher> <year> 1990 </year>
Reference: [10] <author> Haykin, S. </author> <title> Digital Communications, </title> <publisher> John Wi-ley & Sons, </publisher> <year> 1988 </year>
Reference-contexts: Such average length is bounded below by the entropy, the information that the source carries (known as the source coding theorem; see <ref> [10] </ref>). Low average length can generally be made close to the entropy for the price of decoding complexity. In the approach presented in this paper, random wavelet representation is the main tool we use in signal compression/de-noising. This compression procedure, accomplished with various thresholding techniques, is an entropy-reduction transformation.
Reference: [11] <author> Justesen, J., Larson, K. J., Jensen, H. E., and HOEholdt, T. </author> , <title> Fast decoding of codes from algebraic plane curves, </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 38, no. </volume> <month> 1 </month> <year> (1992) </year>
Reference-contexts: Three recent results in the area of decoding AG codes are worth attention. They have close error-correcting capacity (by which we mean the number of errors the code is capable of correcting) and similar complexity, as illustrated below, and are given respectively in Justesen et. al. <ref> [11] </ref>, Feng and Rao [7], and Ehrhard [6]. Ref. Curve Capacity Complexity [11] planar d fl i 8 m 8 7 [7] any (d fl 1)=2 O (n 3 ) In the above, m is the degree of the plane curve; d fl should be considered as proportional to n. <p> They have close error-correcting capacity (by which we mean the number of errors the code is capable of correcting) and similar complexity, as illustrated below, and are given respectively in Justesen et. al. <ref> [11] </ref>, Feng and Rao [7], and Ehrhard [6]. Ref. Curve Capacity Complexity [11] planar d fl i 8 m 8 7 [7] any (d fl 1)=2 O (n 3 ) In the above, m is the degree of the plane curve; d fl should be considered as proportional to n. <p> They each were able to make use of an algorithm generalizing some standard ones to the cyclic codes (cases of <ref> [11] </ref> and [7]), thanks to the underlying algebraic structure. An equivalent description using differentials was the presentation in [7] and [6]. They all have the appeal of implementabil-ity. 5. Perspective. AG codes are easy to construct, have rates and error-correcting capacity, and algorithms for decoding are fast.
Reference: [12] <author> Keshner, M. S., </author> <title> 1 f Noise, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 70, no. 3, </volume> <pages> pp. </pages> <month> 212-218 </month> <year> (1982) </year>
Reference-contexts: For the classical definition of fBm, see, for example, [18]. A discussion of various real-life phenomena giving rise to fBm can be found in <ref> [12] </ref>. The fWs extends the concept of fBm to the multiparameter case and is very useful in modeling multiparameter disturbances whose intensities depend on the size of the perturbed object.
Reference: [13] <author> Kwong, M. K. and P. T. Peter Tang, </author> <title> W -matrices, nonorthogonal multiresolution analysis, and finite signals of arbitrary length, </title> <institution> Argonne National Lab oratory Preprint MCS-P449-0794. </institution>
Reference: [14] <author> Kwong, M. K., </author> <title> MATLAB implementation of W - matrix multiresolution analyses, Argonne National Laboratory Preprint MCS-P462-0894. [15] van Lint, Introduction to Coding Theory, Springer-Verlag, 1991 [16] van Lint and van der Geer, Introduction to Coding and Algebraic Geometry, </title> <publisher> Birkhauser, </publisher> <year> 1988 </year>
Reference: [17] <author> Mallat, S., </author> <title> A theory for multiresolution signal decomposition: the wavelet representation, </title> <journal> IEEE Transaction on Pattern Analysis and Machine In telligence, </journal> <volume> vol. </volume> <pages> 11 pp. </pages> <month> 674-693 </month> <year> (1989) </year>
Reference: [18] <author> Mandelbrot, B. B. and van Ness, T., </author> <title> Fractional Brownian motions, fractional noises and applica tions, </title> <journal> SIAM Review, </journal> <volume> vol. 10, no. </volume> <month> 4 </month> <year> (1968) </year>
Reference-contexts: Remark 1.2 In the case d = 1, a fractional Wiener sheet coincides with fractional Brownian motion (fBm) and is denoted by B H j (B H (t)) t2R . For the classical definition of fBm, see, for example, <ref> [18] </ref>. A discussion of various real-life phenomena giving rise to fBm can be found in [12]. The fWs extends the concept of fBm to the multiparameter case and is very useful in modeling multiparameter disturbances whose intensities depend on the size of the perturbed object.
Reference: [19] <author> Morgera, S. D. and Krishma, H., </author> <title> Digital Signal Processing, </title> <publisher> Academic Press, </publisher> <year> 1989 </year>
Reference: [20] <author> Oppenheim, A. V. and Schafer, R. W., </author> <title> Discrete Time Signal Processing, </title> <publisher> Prentice Hall, </publisher> <year> 1989 </year>
Reference: [21] <editor> SIAM News, </editor> <volume> vol. 27, number 2, </volume> <month> Feb </month> <year> 1994. </year>
Reference-contexts: Two constructions were given. One was a triple-layered concatenated code; the other used algebraic geometric codes that were equipped with extraordinary bounds. It is also known <ref> [21] </ref> that algebraic geometric codes could be used to rewrite a nonlinear code into a linear code. We conclude that AG codes can be used to provide optimal performance. We have performed some computer simulations of the decoding algorithms we mentioned above and compared their performance to other existing ones.
Reference: [22] <author> Song, L., </author> <title> Lectures on error correcting codes, algebraic geometric codes and the decoding algorithms, </title> <booktitle> Lecture Notes, </booktitle> <institution> the University of Illinois at Chicago, </institution> <note> fall 1993 and spring 1994 </note>
Reference: [23] <author> Tsfaman, M. G. and Vladut, S. G., </author> <title> Algebraic Geometric Codes, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991 </year>
Reference-contexts: Decoding Algorithms. Decoding algorithms are one of the most important factors in channel coding. The study in this area began late last decade; the efforts are summarized in <ref> [23] </ref>. The basic algorithm is similar to the idea of decoding cyclic codes: (1) write down a parity check matrix; (2) determine an error locator; (3) solve a system of linear equations to determine the error location; and (4) finally evaluate the correct value.
Reference: [24] <author> Verdo, S., and Wei, V. K., </author> <title> Explicit construction of optimal constant-weight codes for identification via channels, </title> <journal> IEEE Transactions on Information The ory, </journal> <volume> vol. 39, no. </volume> <month> 1 </month> <year> (1993) </year> <month> 7 </month>
Reference-contexts: An equivalent description using differentials was the presentation in [7] and [6]. They all have the appeal of implementabil-ity. 5. Perspective. AG codes are easy to construct, have rates and error-correcting capacity, and algorithms for decoding are fast. In <ref> [24] </ref> the authors constructed a code, for channels with or without memory, with a rate arbitrarily close to the channel capacity, and with the remarkable property (an example of the identification coding theorem of 6 Ahlswede and Dueck) that the transmission can achieve double exponential rate. Two constructions were given.
References-found: 22

