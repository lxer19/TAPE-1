URL: http://www-cad.eecs.berkeley.edu/~dealfaro/crg-techrep.ps
Refering-URL: http://www-cad.eecs.berkeley.edu/~dealfaro/pabs.html
Root-URL: 
Email: Email:fdealfaro,tah,ornag@eecs.berkeley.edu  
Author: Luca de Alfaro Thomas A. Henzinger Orna Kupferman 
Note: The work was partially supported by the SRC contract 97-DC-324.041, by ARO under the MURI grant DAAH04-96-1-0341, by the ONR YIP award N00014-95-1-0520, by the NSF CAREER award CCR-9501708, by the DARPA/NASA grant NAG-2-1214, and by the NSF grant CCR-9504469.  
Address: Berkeley, CA 94720-1770, USA  
Affiliation: Department of EECS, University of California at Berkeley,  
Abstract: Concurrent Reachability Games fl Technical Report UCB/ERL M98/33, University of California at Berkeley, 1998. Abstract An open system can be modeled as a two-player game between the system and its environment. At each round of the game, player 1 (the system) and player 2 (the environment) independently and simultaneously choose moves, and the two choices determine the next state of the game. Properties of open systems can be modeled as objectives of these two-player games. For the basic objective of reachability |can player 1 reach a given set of target states?| there are three types of winning states, according to the degree of certainty with which player 1 can reach the target. From type-1 states, player 1 has a deterministic strategy to always reach the target. From type-2 states, player 1 has a randomized strategy to reach the target with probability 1. From type-3 states, player 1 has for every real " &gt; 0 a randomized strategy to reach the target with probability greater than 1 ". We show that for finite state spaces, all three sets of winning states can be computed in polynomial time: type-1 states in linear time, and type-2 and type-3 states in quadratic time. The algorithms to compute the three sets of winning states also enable the construction of the winning and spoiling strategies. Finally, we apply our results by introducing a temporal logic in which all three kinds of winning conditions can be specified, and which can be model checked in polynomial time. This logic, called randomized ATL, is suitable for reasoning about randomized behavior in open (two-agent) as well as multi-agent systems. 
Abstract-found: 1
Intro-found: 1
Reference: [AHK97] <author> R. Alur, T.A. Henzinger, and O. Kupferman. </author> <title> Alternating-time temporal logic. </title> <booktitle> In Proc. 38th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 100-109, </pages> <year> 1997. </year>
Reference-contexts: The set from which the answer is Sure can be determined in linear time using the methods of <ref> [AHK97] </ref>. By contrast, the sets corresponding to answers Almost-Sure and Limit-Sure require quadratic time. All three algorithms are formulated as nested fixed-point computations, and can be implemented using symbolic state-space traversal methods [BCM+92]. <p> Third, we introduce a temporal logic for the specification of open systems, which can be used both for two-agent systems (system vs. environment) and for more general, multi-agent systems. The logic, called randomized ATL (RATL), is an extension of the logic ATL of <ref> [AHK97] </ref>. Both logics let us specify that a set of agents has strategies to ensure that the paths of the global system satisfy given temporal properties. <p> states, we generalize these definitions to U : the time (or the expected time) to R is bounded from U iff it is bounded from all s 2 U . 2.4 Previous Results on Reachability Games Since Sure reachability can be studied by considering deterministic strategies only, the algorithms of <ref> [AHK97] </ref> enable the computation of the set Sure (R) in linear time in the size of the game. Algorithms to compute the sets Almost (R) and Limit (R) are known 8 for one-player games (or Markov decision processes) and turn-based games. <p> Repeat For k 0, let U k+1 = U k [ Pre 1 (U; 1 ; 2 ). Until U k+1 = U k . Return: U k . The algorithm can be implemented to run in time linear in the size of the game <ref> [AHK97] </ref>. The algorithm can also be implemented symbolically as a fixed-point computation. The theorem below summarizes some basic facts about the set Sure (R). Theorem 2 For every reachability game with target set R: 1. Algorithm 2 computes set Sure (R). <p> For every state s 2 Sure (R), the time from s to R is bounded by the size of the state space. Theorem 2 (2) indicates that the consideration of deterministic strategies only is appropriate for the logic ATL, whose semantics is based on sure reachability <ref> [AHK97] </ref>. For deterministic games, the existence of a memoryless deterministic winning strategy for almost-sure or limit-sure reachability indicates that these two notions of reachability coincide with sure reachability. <p> These methods are presented in Theorems 15 and 16 of Section 5.3. 4 Randomized ATL For the specification and verification of open systems, <ref> [AHK97] </ref> introduced the temporal logic ATL. The logic ATL is interpreted over multi-player game structures, and includes formulas of the form hhAii , which asserts that a team A of players (called agents) have a strategy to ensure that all paths of the game satisfy the temporal property . <p> A model-checking algorithm for randomized ATL can proceed bottom-up on the state subformulas of ', as in CTL and ATL model checking <ref> [CE81, QS81, AHK97] </ref>. There are two cases of state subformulas that have no equivalent expression in ATL: hhAii almost ' 1 U ' 2 and hhAii limit ' 1 U ' 2 . <p> The following theorem and corollary summarize the relevant results on the model checking of randomized ATL specifications. Theorem 13 The model-checking problem for randomized ATL specifications can be solved by combining the algorithms of <ref> [AHK97] </ref> for hh ii sure with the modification (17) of Algorithms 3 and 6 for hh ii almost and hh ii limit . <p> In fact, for each k 0 the set U k+1 = Safe 1 (U k n C k ; 1 ; 2 ) can also be computed in linear time <ref> [AHK97] </ref>, and the algorithm terminates after a number of iterations bounded by the size of the state space. From the remarks of Section 3.4.3, with small modifications, the argument also shows that the sets C k of Algorithm 3 can be computed in linear time, for k 0.
Reference: [BCM+92] <author> J.R. Burch, E.M. Clarke, K.L. McMillan, D.L. Dill, and L.J. Hwang. </author> <title> Symbolic model checking: 10 20 states and beyond. </title> <booktitle> In Information and Computation, </booktitle> <volume> 95(2) </volume> <pages> 142-170, </pages> <year> 1992. </year>
Reference-contexts: By contrast, the sets corresponding to answers Almost-Sure and Limit-Sure require quadratic time. All three algorithms are formulated as nested fixed-point computations, and can be implemented using symbolic state-space traversal methods <ref> [BCM+92] </ref>. Our algorithms can also be used to compute the set of states of a finite 3 state discrete-time pursuit-evasion game from which the pursuer can catch the evader with Sure, Almost-Sure, and Limit-Sure confidence [Isa65].
Reference: [Bee80] <author> C. Beeri. </author> <title> On the membership problem for functional and multivalued dependencies in relational databases. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 5 </volume> <pages> 241-259, </pages> <year> 1980. </year>
Reference-contexts: Until V k+1 = V k . Return: V k . 12 A nave application of this algorithm runs in time quadratic in the size of the game. However, using an appropriate data structure, as suggested in <ref> [Bee80, CS91] </ref>, it can be implemented to run in linear time. The algorithm can also be implemented symbolically as a nested fixed-point iteration. 3.2 Sure-Reachability States The set Sure (R) satisfies the fixed-point characterization given by the following theorem.
Reference: [Ber95] <author> D.P. Bertsekas. </author> <title> Dynamic Programming and Optimal Control. </title> <publisher> Athena Scientific, </publisher> <year> 1995. </year>
Reference-contexts: This latter problem can be solved in polynomial time by a reduction to linear programming, providing an algorithm 2 for the computation of set Limit (R) <ref> [Der70, Ber95] </ref>. <p> The existence of optimal 2 It is possible to obtain a polynomial-time algorithm for the computation of set Limit (R) also by considering the reward structure (2) and the problem of computing the total reward of the Markov decision process <ref> [Ber95] </ref>. 9 strategies for the single player then implies Almost (R) = Limit (R). Additionally, it is known that there are deterministic optimal strategies [Der70, Ber95]. We can obtain more efficient algorithms for our reachability questions on one-player games as follows. <p> Additionally, it is known that there are deterministic optimal strategies <ref> [Der70, Ber95] </ref>. We can obtain more efficient algorithms for our reachability questions on one-player games as follows. <p> Once 1 ["] is fixed, results on Markov decision processes ensure that the optimal strategy for player 2 to avoid reaching R is memoryless (and also deterministic) <ref> [Der70, Ber95] </ref>. <p> Hence, if player 2 uses strategy * 2 , there is a (memoryless) strategy ffi 1 for player 1 that maximizes the probability of reaching R from every state <ref> [Der70, Ber95] </ref>.
Reference: [BO82] <author> T. Ba~sar and G.J. Olsder. </author> <title> Dynamic Noncooperative Game Theory. </title> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference-contexts: There are games for which both inclusions are strict. The strictness of the inclusion Sure (R) Almost (R) follows from the well-known fact that randomized strategies are more powerful than deterministic strategies <ref> [vN28, BO82] </ref>, and is witnessed by the state t throw of the game left-or-right. The strictness of the inclusion Almost (R) Limit (R) is witnessed by the state s hide of the game hide-or-run [KS81]. Winning and spoiling strategies.
Reference: [BT91] <author> D.P. Bertsekas and J.N. Tsitsiklis. </author> <title> An analysis of stochastic shortest path problems. </title> <journal> Math. of Op. Res., </journal> <volume> 16(3) </volume> <pages> 580-595, </pages> <year> 1991. </year>
Reference-contexts: Note that the second gap does not appear in reachability problems over Markov chains, 2 s wet s hide hide, wait hide, throw run , throw run, wait s home s safe or Markov decision processes <ref> [KSK66, BT91] </ref>. While the game left-or-right witnesses the first gap, the second gap is witnessed by the game hide-or-run, adapted from [KS81] and depicted in Figure 2. The target state is s home , and the interesting part of the game happens at state s hide . <p> If the answer is Limit-Sure but not Almost-Sure, neither the time to target nor the expected time to target are bounded. We also prove prove that the spoiling strategies for Almost-Sure reachability must in general have infinite memory, in contrast with the common situation for Markov decision processes <ref> [Der70, HSP83, Var85, BT91] </ref> and for limit-sure reachability [KS81, Sec97]. Third, we introduce a temporal logic for the specification of open systems, which can be used both for two-agent systems (system vs. environment) and for more general, multi-agent systems. <p> Result 3b is proved by an analysis of the game hide-or-run, considering the strategies available to the players at the state s hide 62 Almost (R). Result 4 then follows from result 2a, and from results about the stochastic shortest-path problem <ref> [BT91] </ref>. Note also that * For every state s 62 Sure (R), the time to R is unbounded, since not all paths reach R. * For every state s 62 Almost (R), the expected time to R is unbounded, since R is reached with probability always smaller than 1.
Reference: [CE81] <author> E.M. Clarke and E.A. Emerson. </author> <title> Design and synthesis of synchronization skeletons using branching time temporal logic. </title> <booktitle> In Proc. Workshop on Logic of Programs, volume 131 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 52-71. </pages> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: A model-checking algorithm for randomized ATL can proceed bottom-up on the state subformulas of ', as in CTL and ATL model checking <ref> [CE81, QS81, AHK97] </ref>. There are two cases of state subformulas that have no equivalent expression in ATL: hhAii almost ' 1 U ' 2 and hhAii limit ' 1 U ' 2 .
Reference: [CS91] <author> R. Cleaveland and B. Steffen. </author> <title> A linear-time model-checking algorithm for the alternation-free modal -calculus. </title> <booktitle> In Computer Aided Verification, volume 575 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 48-58. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Until V k+1 = V k . Return: V k . 12 A nave application of this algorithm runs in time quadratic in the size of the game. However, using an appropriate data structure, as suggested in <ref> [Bee80, CS91] </ref>, it can be implemented to run in linear time. The algorithm can also be implemented symbolically as a nested fixed-point iteration. 3.2 Sure-Reachability States The set Sure (R) satisfies the fixed-point characterization given by the following theorem.
Reference: [Con92] <author> A. Condon. </author> <title> The complexity of stochastic games. </title> <journal> Information and Computation, </journal> <volume> 96 </volume> <pages> 203-224, </pages> <year> 1992. </year>
Reference-contexts: In the case of probabilistic turn-based games, our results indicate that Almost (R) = Limit (R). The set Almost (R) = Limit (R) can be computed in polynomial time [Yan98], and the problem of deciding which player has the greatest probability of winning is in NP " co-NP <ref> [Con92] </ref>. Under the reward structure (1), probabilistic turn-based reachability games are a special case of switching-controller undiscounted games. The algorithm of [VTRF83a] enables the computation of v avg (s) = p + (s) at all s 2 S, and hence the determination of Almost (R) = Limit (R).
Reference: [CY88] <author> C. Courcoubetis and M. Yannakakis. </author> <title> Verifying temporal properties of finite-state probabilistic programs. </title> <booktitle> In Proc. 29th IEEE Symp. Found. of Comp. Sci., </booktitle> <pages> pages 338-354, </pages> <year> 1988. </year>
Reference-contexts: Our algorithms also enable the effective construction of winning strategies for player 1, and spoiling strategies for player 2, for the three types of answers. Polynomial-time algorithms for the reachability problem are known for turn-based games [Yan98], as well as for one-player games such as Markov decision processes <ref> [HSP83, Var85, CY88, dA97] </ref>. Moreover, by associating rewards to the transitions that lead to the target set, or to the states in the target set, our reachability questions can be phrased as questions about the total reward or the average reward of stochastic games. <p> This problem can be solved using the algorithms of <ref> [HSP83, Var85, CY88] </ref>. 2.4.2 Turn-based Games Due to their simpler structure and their ability to model interleaving, turn-based games are commonly considered in computer science and game theory (see for example [Fil81]). Deterministic turn-based games.
Reference: [dA97] <author> L. de Alfaro. </author> <title> Formal verification of probabilistic systems. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1997. </year> <note> Technical Report STAN-CS-TR-98-1601. </note>
Reference-contexts: Our algorithms also enable the effective construction of winning strategies for player 1, and spoiling strategies for player 2, for the three types of answers. Polynomial-time algorithms for the reachability problem are known for turn-based games [Yan98], as well as for one-player games such as Markov decision processes <ref> [HSP83, Var85, CY88, dA97] </ref>. Moreover, by associating rewards to the transitions that lead to the target set, or to the states in the target set, our reachability questions can be phrased as questions about the total reward or the average reward of stochastic games. <p> This problem can be solved using the algorithms described in <ref> [dA97] </ref>. If player 2 is the only player having non-singleton move sets, the problem of computing Almost (R) is equivalent to the problem of computing the set of states of a Markov decision process from which R is reached with probability 1 under any strategy.
Reference: [Der70] <author> C. Derman. </author> <title> Finite State Markovian Decision Processes. </title> <publisher> Acedemic Press, </publisher> <year> 1970. </year>
Reference-contexts: Another way of thinking about randomized strategies is through the concept of initial randomization. The choice of a randomized strategy is equivalent to the choice of a probability distribution over the set of deterministic strategies <ref> [Der70] </ref>. By choosing such a distribution, rather than a single strategy, player 1 prevents player 2 from tailoring her strategy to counteract the strategy chosen by player 1. <p> If the answer is Limit-Sure but not Almost-Sure, neither the time to target nor the expected time to target are bounded. We also prove prove that the spoiling strategies for Almost-Sure reachability must in general have infinite memory, in contrast with the common situation for Markov decision processes <ref> [Der70, HSP83, Var85, BT91] </ref> and for limit-sure reachability [KS81, Sec97]. Third, we introduce a temporal logic for the specification of open systems, which can be used both for two-agent systems (system vs. environment) and for more general, multi-agent systems. <p> then on S n R the total value of the stochastic game is equal to the maximal probability of reaching the target, or v tot (s) = p + (s) for all s 2 S n R. 2.4.1 One-Player Games A one-player game is equivalent to a Markov decision process <ref> [Der70] </ref>, in which the controller has as objective to maximize or minimize the probability of reaching the target set R. <p> This latter problem can be solved in polynomial time by a reduction to linear programming, providing an algorithm 2 for the computation of set Limit (R) <ref> [Der70, Ber95] </ref>. <p> Additionally, it is known that there are deterministic optimal strategies <ref> [Der70, Ber95] </ref>. We can obtain more efficient algorithms for our reachability questions on one-player games as follows. <p> Once 1 ["] is fixed, results on Markov decision processes ensure that the optimal strategy for player 2 to avoid reaching R is memoryless (and also deterministic) <ref> [Der70, Ber95] </ref>. <p> Similar statements hold if the roles of player 1 and player 2 are exchanged. Proof. Under strategy 2 , the game from the point of view of player 1 is a Markov decision process <ref> [Der70] </ref>. The first statement can be proved by induction on the number of the iteration at which s has been removed from U during the execution of Algorithm 1. <p> Hence, if player 2 uses strategy * 2 , there is a (memoryless) strategy ffi 1 for player 1 that maximizes the probability of reaching R from every state <ref> [Der70, Ber95] </ref>.
Reference: [Eme90] <author> E.A. Emerson. </author> <title> Temporal and modal logic. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B, chapter 16, </booktitle> <pages> pages 995-1072. </pages> <publisher> Elsevier Science Publishers (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference-contexts: The operators hh ii win are path quantifiers, and ("next"), 2 ("always"), and U ("until") are the usual temporal operators <ref> [Eme90, MP91] </ref>. Semantics. We interpret randomized ATL formulas over the states of a system S that has the same sets of agents and propositions used to define the formulas.
Reference: [Eve57] <author> H. Everett. </author> <title> Recursive games. In Contributions to the Theory of Games III, </title> <journal> volume 39 of Annals of Mathematical Studies, </journal> <pages> pages 47-78, </pages> <year> 1957. </year>
Reference-contexts: Thus, a reachability game is a special case of a recursive game, in which all absorbing states are equivalent from the point of view of the reward <ref> [Eve57, Sec97] </ref>. In the following, we consider a game G = hhS; Moves; 1 ; 2 ; pi; Ri, unless otherwise noted. <p> The optimized version is given as Algorithm 8 of Section 5.3. Results 2 and 3 are from [KS81]. However, while previous results were concerned only with the existence of particular types of winning and spoiling strategies <ref> [Eve57, KS81, Sec97] </ref>, our algorithms provide methods for the effective computation of such strategies. These methods are presented in Theorems 15 and 16 of Section 5.3. 4 Randomized ATL For the specification and verification of open systems, [AHK97] introduced the temporal logic ATL.
Reference: [Fil81] <author> J.A. Filar. </author> <title> Ordered field property for stochastic games when the player who controls transitions changes from state to state. </title> <journal> J. Optimization Theory and Applications, </journal> <volume> 34(4) </volume> <pages> 503-515, </pages> <year> 1981. </year>
Reference-contexts: This problem can be solved using the algorithms of [HSP83, Var85, CY88]. 2.4.2 Turn-based Games Due to their simpler structure and their ability to model interleaving, turn-based games are commonly considered in computer science and game theory (see for example <ref> [Fil81] </ref>). Deterministic turn-based games. As we prove later, for deterministic turn-based games the three types of winning states coincide: that is, Sure (R) = Almost (R) = Limit (R).
Reference: [FV97] <author> J. Filar and K. Vrieze. </author> <title> Competitive Markov Decision Processes. </title> <publisher> Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: This observation yields successive approximation methods for the computation of the maximal probability of reaching the target <ref> [TV87, FV97] </ref>. A review of the classes of games for which polynomial-time algorithms are known is presented in Section 2.4. <p> Algorithms to compute the sets Almost (R) and Limit (R) are known 8 for one-player games (or Markov decision processes) and turn-based games. Moreover, the maximal probability of winning a general reachability game can be computed using successive approximation methods <ref> [FV97] </ref>. For every state s 2 S, denote the maximal probability of reaching the target by p + (s) = sup inf Pr 1 ; 2 Clearly, s 2 Limit (R) iff p + (s) = 1. <p> The proofs of existence of these strategies do not provide methods for the effective construction of winning and spoiling strategies. The total reward v tot (s) of a stochastic game with non-negative rewards can be computed using a successive approximation method <ref> [TV87, FV97] </ref>. Under the reward structure (2), this method enables the computation of successive approximations for p + (s) at all s 2 S.
Reference: [Gil57] <author> D. Gillette. </author> <title> Stochastic games with zero stop probabilities. In Contributions to the Theory of Games III, </title> <journal> volume 39 of Annals of Mathematical Studies, </journal> <year> 1957. </year>
Reference: [HSP83] <author> S. Hart, M. Sharir, and A. Pnueli. </author> <title> Termination of probabilistic concurrent programs. </title> <journal> ACM Trans. Prog. Lang. Sys., </journal> <volume> 5(3) </volume> <pages> 356-380, </pages> <month> July </month> <year> 1983. </year> <month> 42 </month>
Reference-contexts: Our algorithms also enable the effective construction of winning strategies for player 1, and spoiling strategies for player 2, for the three types of answers. Polynomial-time algorithms for the reachability problem are known for turn-based games [Yan98], as well as for one-player games such as Markov decision processes <ref> [HSP83, Var85, CY88, dA97] </ref>. Moreover, by associating rewards to the transitions that lead to the target set, or to the states in the target set, our reachability questions can be phrased as questions about the total reward or the average reward of stochastic games. <p> If the answer is Limit-Sure but not Almost-Sure, neither the time to target nor the expected time to target are bounded. We also prove prove that the spoiling strategies for Almost-Sure reachability must in general have infinite memory, in contrast with the common situation for Markov decision processes <ref> [Der70, HSP83, Var85, BT91] </ref> and for limit-sure reachability [KS81, Sec97]. Third, we introduce a temporal logic for the specification of open systems, which can be used both for two-agent systems (system vs. environment) and for more general, multi-agent systems. <p> This problem can be solved using the algorithms of <ref> [HSP83, Var85, CY88] </ref>. 2.4.2 Turn-based Games Due to their simpler structure and their ability to model interleaving, turn-based games are commonly considered in computer science and game theory (see for example [Fil81]). Deterministic turn-based games.
Reference: [Imm81] <author> N. Immerman. </author> <title> Number of quantifiers is better than number of tape cells. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 22(3) </volume> <pages> 384-406, </pages> <year> 1981. </year>
Reference-contexts: This problem can again be solved in linear time and is complete for Ptime <ref> [Imm81] </ref>. With respect to And-Or graph reachability, randomized strategies are no more powerful than deterministic strategies. A randomized strategy for the And player maps every path that ends in an And state to a probability distribution on the successor states, and similarly for the Or player. <p> As mentioned earlier, the problem of computing Sure (R) is equivalent to the And-Or reach-ability problem, which can be solved in linear time and is complete for Ptime <ref> [Imm81] </ref>. The existence of memoryless deterministic winning and spoiling strategies follows from an analysis of the algorithms.
Reference: [Isa65] <author> R. Isaacs. </author> <title> Differential Games. </title> <publisher> John Wiley, </publisher> <year> 1965. </year>
Reference-contexts: Our algorithms can also be used to compute the set of states of a finite 3 state discrete-time pursuit-evasion game from which the pursuer can catch the evader with Sure, Almost-Sure, and Limit-Sure confidence <ref> [Isa65] </ref>. Our algorithms also enable the effective construction of winning strategies for player 1, and spoiling strategies for player 2, for the three types of answers.
Reference: [Jon75] <author> N.D. Jones. </author> <title> Space-bounded reducibility among combinatorial problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 11 </volume> <pages> 68-75, </pages> <year> 1975. </year>
Reference-contexts: state t, can the system get from s to t? The dynamics of a closed system, which does not interact with its environment, can be modeled by a state-transition graph, and the reachability question reduces to graph reachability, which can be solved in linear time and is complete for Nlogspace <ref> [Jon75] </ref>. By contrast, the dynamics of an open system, which does interact with its environment, is best modeled as a game between the system and the environment. In some situations, it may suffice to have the system and the environment take turns to make moves, yielding a turn-based model.
Reference: [KS81] <author> P.R. Kumar and T.H. Shiau. </author> <title> Existence of value and randomized strategies in zero-sum discrete-time stochastic dynamic games. </title> <journal> SIAM J. Control and Optimization, </journal> <volume> 19(5) </volume> <pages> 617-634, </pages> <year> 1981. </year>
Reference-contexts: While the game left-or-right witnesses the first gap, the second gap is witnessed by the game hide-or-run, adapted from <ref> [KS81] </ref> and depicted in Figure 2. The target state is s home , and the interesting part of the game happens at state s hide . At this state, player 1 is hiding behind a small hill, while player 2 is trying to hit him with a snowball. <p> On the other hand, by choosing an appropriate strategy, player 1 can be sure of reaching s home with probability arbitrarily close to 1 <ref> [KS81] </ref>. In fact, if player 1 runs with very small probability at each round, it becomes very difficult for player 2 to time her snowball to coincide with the running of player 1 |and a badly timed snowball enables player 1 to reach s home . <p> We also prove prove that the spoiling strategies for Almost-Sure reachability must in general have infinite memory, in contrast with the common situation for Markov decision processes [Der70, HSP83, Var85, BT91] and for limit-sure reachability <ref> [KS81, Sec97] </ref>. Third, we introduce a temporal logic for the specification of open systems, which can be used both for two-agent systems (system vs. environment) and for more general, multi-agent systems. The logic, called randomized ATL (RATL), is an extension of the logic ATL of [AHK97]. <p> The strictness of the inclusion Almost (R) Limit (R) is witnessed by the state s hide of the game hide-or-run <ref> [KS81] </ref>. Winning and spoiling strategies. The winning strategies of a reachability game are the strategies that enable player 1 to win the game whenever possible. <p> and memoryless memoryless memoryless Spoiling strategies memoryless counting memoryless Time to target bounded unbounded unbounded Expected time to target bounded bounded unbounded Table 1: Overview of results about sure, almost-sure, and limit-sure reachability. 2.4.3 General Reachability Games For general reachability games, the existence of memoryless "-optimal strategies was shown by <ref> [KS81, Sec97] </ref>. These results imply the existence of memoryless winning and spoiling strategies for limit-sure reachability. The proofs of existence of these strategies do not provide methods for the effective construction of winning and spoiling strategies. <p> We call this type of escape limit escape. Before discussing limit escape in general, let us consider the situation of state s hide of game hide-or-run. As we mentioned in the introduction, s hide 2 Limit (R) n Almost (R), where R = fs home g <ref> [KS81] </ref>. If we consider the execution of Algorithm 3 on game hide-or-run, we see that C 0 = fs wet g, C 1 = fs hide g, and U 1 = fs hide ; s safe ; s home g. <p> Once 1 ["] is fixed, results on Markov decision processes ensure that the optimal strategy for player 2 to avoid reaching R is memoryless (and also deterministic) [Der70, Ber95]. Hence, simple calculations show that <ref> [KS81] </ref>: inf Pr 1 ["]; 2 s hide ( 3 fs home g) = 1 " ; so that sup inf Pr 1 ["]; 2 s hide ( 3 fs home g) = lim "!0 In the general case, limit escape is defined as follows. <p> In particular, to obtain a version of the algorithm that runs in quadratic time it is necessary to optimize the implementation of Algorithm 5. The optimized version is given as Algorithm 8 of Section 5.3. Results 2 and 3 are from <ref> [KS81] </ref>. However, while previous results were concerned only with the existence of particular types of winning and spoiling strategies [Eve57, KS81, Sec97], our algorithms provide methods for the effective computation of such strategies. <p> The optimized version is given as Algorithm 8 of Section 5.3. Results 2 and 3 are from [KS81]. However, while previous results were concerned only with the existence of particular types of winning and spoiling strategies <ref> [Eve57, KS81, Sec97] </ref>, our algorithms provide methods for the effective computation of such strategies. These methods are presented in Theorems 15 and 16 of Section 5.3. 4 Randomized ATL For the specification and verification of open systems, [AHK97] introduced the temporal logic ATL.
Reference: [KSK66] <author> J.G. Kemeny, J.L. Snell, and A.W. Knapp. </author> <title> Denumerable Markov Chains. </title> <address> D. </address> <publisher> Van Nostrand Company, </publisher> <year> 1966. </year>
Reference-contexts: Note that the second gap does not appear in reachability problems over Markov chains, 2 s wet s hide hide, wait hide, throw run , throw run, wait s home s safe or Markov decision processes <ref> [KSK66, BT91] </ref>. While the game left-or-right witnesses the first gap, the second gap is witnessed by the game hide-or-run, adapted from [KS81] and depicted in Figure 2. The target state is s home , and the interesting part of the game happens at state s hide . <p> of first passage in U by T 3 U = minfk j X k 2 U g. 1 To be precise, we should define events as measurable sets of paths sharing the same initial state, and we should replace our events with families of events, indexed by their initial state <ref> [KSK66] </ref>. However, our (slightly) improper definition leads to more concise notation. 6 Types of strategies. We distinguish the following types of strategies: * A strategy is deterministic if for all 2 S + there exists a 2 Moves such that ()(a) = 1.
Reference: [MP91] <author> Z. Manna and A. Pnueli. </author> <title> The Temporal Logic of Reactive and Concurrent Systems: Specification. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: The operators hh ii win are path quantifiers, and ("next"), 2 ("always"), and U ("until") are the usual temporal operators <ref> [Eme90, MP91] </ref>. Semantics. We interpret randomized ATL formulas over the states of a system S that has the same sets of agents and propositions used to define the formulas.
Reference: [vN28] <author> J. von Neumann. </author> <title> Zur Theorie der Gesellschaftsspiele. </title> <journal> Math. Annal, </journal> <volume> 100 </volume> <pages> 295-320, </pages> <year> 1928. </year>
Reference-contexts: The greater power of randomized strategies is a well-known fact in game theory, and it has its roots in von Neumann's minimax theorem <ref> [vN28] </ref>. Once we consider randomized strategies, we can answer the reachability question with three kinds of affirmative answers. The first kind of answer is the answer Sure: Player 1 has a strategy so that for all strategies of player 2, the game, if started in s, always reaches t. <p> There are games for which both inclusions are strict. The strictness of the inclusion Sure (R) Almost (R) follows from the well-known fact that randomized strategies are more powerful than deterministic strategies <ref> [vN28, BO82] </ref>, and is witnessed by the state t throw of the game left-or-right. The strictness of the inclusion Almost (R) Limit (R) is witnessed by the state s hide of the game hide-or-run [KS81]. Winning and spoiling strategies.
Reference: [QS81] <author> J.P. Queille and J. Sifakis. </author> <title> Specification and verification of concurrent systems in Cesar. </title> <booktitle> In Proc. 5th International Symp. on Programming, Lecture Notes in Computer Science, </booktitle> <volume> volume 137, </volume> <pages> pages 337-351. </pages> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: A model-checking algorithm for randomized ATL can proceed bottom-up on the state subformulas of ', as in CTL and ATL model checking <ref> [CE81, QS81, AHK97] </ref>. There are two cases of state subformulas that have no equivalent expression in ATL: hhAii almost ' 1 U ' 2 and hhAii limit ' 1 U ' 2 .
Reference: [RF91] <author> T.E.S. Raghavan and J.A. Filar. </author> <title> Algorithms for stochastic games | a survey. ZOR | Methods and Models of Op. </title> <journal> Res., </journal> <volume> 35 </volume> <pages> 437-472, </pages> <year> 1991. </year>
Reference: [Sec97] <author> P. Secchi. </author> <title> Stationary strategies for recursive games. </title> <journal> Math. of Op. Res., </journal> <volume> 22(2) </volume> <pages> 494-512, </pages> <year> 1997. </year>
Reference-contexts: We also prove prove that the spoiling strategies for Almost-Sure reachability must in general have infinite memory, in contrast with the common situation for Markov decision processes [Der70, HSP83, Var85, BT91] and for limit-sure reachability <ref> [KS81, Sec97] </ref>. Third, we introduce a temporal logic for the specification of open systems, which can be used both for two-agent systems (system vs. environment) and for more general, multi-agent systems. The logic, called randomized ATL (RATL), is an extension of the logic ATL of [AHK97]. <p> Thus, a reachability game is a special case of a recursive game, in which all absorbing states are equivalent from the point of view of the reward <ref> [Eve57, Sec97] </ref>. In the following, we consider a game G = hhS; Moves; 1 ; 2 ; pi; Ri, unless otherwise noted. <p> and memoryless memoryless memoryless Spoiling strategies memoryless counting memoryless Time to target bounded unbounded unbounded Expected time to target bounded bounded unbounded Table 1: Overview of results about sure, almost-sure, and limit-sure reachability. 2.4.3 General Reachability Games For general reachability games, the existence of memoryless "-optimal strategies was shown by <ref> [KS81, Sec97] </ref>. These results imply the existence of memoryless winning and spoiling strategies for limit-sure reachability. The proofs of existence of these strategies do not provide methods for the effective construction of winning and spoiling strategies. <p> The optimized version is given as Algorithm 8 of Section 5.3. Results 2 and 3 are from [KS81]. However, while previous results were concerned only with the existence of particular types of winning and spoiling strategies <ref> [Eve57, KS81, Sec97] </ref>, our algorithms provide methods for the effective computation of such strategies. These methods are presented in Theorems 15 and 16 of Section 5.3. 4 Randomized ATL For the specification and verification of open systems, [AHK97] introduced the temporal logic ATL.
Reference: [TV87] <author> F. Thuijsman and O.J. Vrieze. </author> <title> The bad match, a total reward stochastic game. </title> <journal> Operations Research Spektrum, </journal> <volume> 9 </volume> <pages> 93-99, </pages> <year> 1987. </year>
Reference-contexts: This observation yields successive approximation methods for the computation of the maximal probability of reaching the target <ref> [TV87, FV97] </ref>. A review of the classes of games for which polynomial-time algorithms are known is presented in Section 2.4. <p> The proofs of existence of these strategies do not provide methods for the effective construction of winning and spoiling strategies. The total reward v tot (s) of a stochastic game with non-negative rewards can be computed using a successive approximation method <ref> [TV87, FV97] </ref>. Under the reward structure (2), this method enables the computation of successive approximations for p + (s) at all s 2 S.
Reference: [Var85] <author> M.Y. Vardi. </author> <title> Automatic verification of probabilistic concurrent finite-state programs. </title> <booktitle> Proc. 26th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 327-338, </pages> <year> 1985. </year>
Reference-contexts: Our algorithms also enable the effective construction of winning strategies for player 1, and spoiling strategies for player 2, for the three types of answers. Polynomial-time algorithms for the reachability problem are known for turn-based games [Yan98], as well as for one-player games such as Markov decision processes <ref> [HSP83, Var85, CY88, dA97] </ref>. Moreover, by associating rewards to the transitions that lead to the target set, or to the states in the target set, our reachability questions can be phrased as questions about the total reward or the average reward of stochastic games. <p> If the answer is Limit-Sure but not Almost-Sure, neither the time to target nor the expected time to target are bounded. We also prove prove that the spoiling strategies for Almost-Sure reachability must in general have infinite memory, in contrast with the common situation for Markov decision processes <ref> [Der70, HSP83, Var85, BT91] </ref> and for limit-sure reachability [KS81, Sec97]. Third, we introduce a temporal logic for the specification of open systems, which can be used both for two-agent systems (system vs. environment) and for more general, multi-agent systems. <p> This problem can be solved using the algorithms of <ref> [HSP83, Var85, CY88] </ref>. 2.4.2 Turn-based Games Due to their simpler structure and their ability to model interleaving, turn-based games are commonly considered in computer science and game theory (see for example [Fil81]). Deterministic turn-based games. <p> It is not difficult to show that [[ ]] is measurable for any path subformula , under any strategies <ref> [Var85] </ref>. Subformulas of randomized ATL that have the form p, :', ' 1 _ ' 2 , or hhAii win are called state subformulas, and they are interpreted over the states of S.
Reference: [VTRF83a] <author> O.J. Vrieze, S.H. Tijs, T.E.S. Raghavan, and J.A. Filar. </author> <title> A finite algorithm for the switching controller stochastic game. </title> <journal> OR Spectrum, </journal> <volume> 5 </volume> <pages> 15-24, </pages> <year> 1983. </year>
Reference-contexts: Under the reward structure (1), probabilistic turn-based reachability games are a special case of switching-controller undiscounted games. The algorithm of <ref> [VTRF83a] </ref> enables the computation of v avg (s) = p + (s) at all s 2 S, and hence the determination of Almost (R) = Limit (R).
Reference: [Yan98] <author> M. Yannakakis. </author> <type> Personal communication, </type> <year> 1998. </year>
Reference-contexts: Our algorithms also enable the effective construction of winning strategies for player 1, and spoiling strategies for player 2, for the three types of answers. Polynomial-time algorithms for the reachability problem are known for turn-based games <ref> [Yan98] </ref>, as well as for one-player games such as Markov decision processes [HSP83, Var85, CY88, dA97]. <p> Probabilistic turn-based games. In the case of probabilistic turn-based games, our results indicate that Almost (R) = Limit (R). The set Almost (R) = Limit (R) can be computed in polynomial time <ref> [Yan98] </ref>, and the problem of deciding which player has the greatest probability of winning is in NP " co-NP [Con92]. Under the reward structure (1), probabilistic turn-based reachability games are a special case of switching-controller undiscounted games.
Reference: [ZP96] <author> U. Zwick and M. Paterson. </author> <title> The complexity of mean payoff games on graphs. </title> <journal> Theor. Comp. Sci., </journal> <volume> 158 </volume> <pages> 343-359, </pages> <year> 1996. </year> <month> 43 </month>
Reference-contexts: After the only round, the game moves from the state t throw either to the state t hit or to the state t missed . Then, sup inf Pr t throw ( 3 ft hit g) = 2 In the case of general reward structures, <ref> [ZP96] </ref> showed that the average value of a deterministic turn-based game can be computed in pseudo-polynomial time. Probabilistic turn-based games. In the case of probabilistic turn-based games, our results indicate that Almost (R) = Limit (R).
References-found: 33

