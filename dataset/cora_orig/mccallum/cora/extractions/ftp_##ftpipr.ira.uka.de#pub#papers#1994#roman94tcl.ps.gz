URL: ftp://ftpipr.ira.uka.de/pub/papers/1994/roman94tcl.ps.gz
Refering-URL: ftp://ftpipr.ira.uka.de/.public_html/papersna.html
Root-URL: 
Email: email: t.lueth@ieee.org  email: herzog@cs.uni-sb.de  
Title: KANTRA Human-Machine Interaction for Intelligent Robots using Natural Language  
Author: T.C. Lueth, Th. Laengle, G. Herzog, E. Stopp, U. Rembold 
Address: D-76128 Karlsruhe F.R. Germany,  D-66041 Saarbruecken F.R. Germany,  
Affiliation: Institute for Real-Time Computer Systems and Robotics University of Karlsruhe,  Project VITRA FB 14 Informatik University of the Saarland,  
Abstract: In this paper, a new natural language interface is presented that can be applied to make the use of intelligent robots more flexible. This interface was developed for the autonomous mobile two-arm robot KAMRO, which uses s e v e r a l c a m e r a s y st e m s t o g e n e r a t e a n environment model and to perform assembly tasks. A fundamental requirement in human-machine interaction for intelligent robots is the ability to refer to objects in the robot's environment. Hence, the interface and the intelligent system need similar environment models and it is necessary to provide current sensor information. Additional flexibility can be achieve d by int egr ating t he man-mac hine interface into the control architecture of the robot and to give it access to all internal information and to the models that the robot uses for an autonomous behaviour. In order to fully exploit the capabilities of a natural language access, we favour a dialogue-based approach, i.e., for the interface, KANTRA, presented here, the human-machine interaction is not restricted to unidirectional communication. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Rembold, U.; Lueth, T.; Hoermann, A.: </author> <title> Advancement of Intelligent Machines. </title> <booktitle> ICAM JSME Int. Conf. on Advanced Mechatronics, </booktitle> <address> Tokyo, Japan, </address> <month> August, </month> <pages> 2-4, </pages> <year> 1993, </year> <pages> pp. 1-7. </pages>
Reference-contexts: 1. INTRODUCTION The future use of intelligent robots <ref> [1] </ref> in manufacturing or as service robots for different applications will lead to high demands for man-machine interaction and communication. The more robots work autonomously the more cooperation of man-machine and machine-machine [2] will be necessary.
Reference: [2] <author> Fukuda, T.; Sekiyama, K.; Ueyama, T.; Arai, F.: </author> <title> Efficient Communication Method in the Cellular Robotic System. </title> <booktitle> IROS IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, </booktitle> <address> Yokohama, Japan, </address> <month> July, </month> <pages> 26-30, </pages> <year> 1993, </year> <pages> pp. 1091-1096. </pages>
Reference-contexts: 1. INTRODUCTION The future use of intelligent robots [1] in manufacturing or as service robots for different applications will lead to high demands for man-machine interaction and communication. The more robots work autonomously the more cooperation of man-machine and machine-machine <ref> [2] </ref> will be necessary. Distributed multi-robot systems show the way future intelligent manufacturing systems can operate independently [3, 4]. In such an environment, all machines can't always be programmed or controlled in the same way.
Reference: [3] <author> Asama, H.: </author> <title> Distributed Autonomous Robotic System Configurated with Multiple Agents and Its Cooperative Behaviour. </title> <journal> Journal of Robotics and Mechatronics, </journal> <volume> 4, 3 (1992), </volume> <pages> pp. 199-204. </pages>
Reference-contexts: The more robots work autonomously the more cooperation of man-machine and machine-machine [2] will be necessary. Distributed multi-robot systems show the way future intelligent manufacturing systems can operate independently <ref> [3, 4] </ref>. In such an environment, all machines can't always be programmed or controlled in the same way. On that account, natural language as a communication medium for humans is an efficient means to make a technical system easier accessible to its users [5].
Reference: [4] <author> Tsukune, H.; Tsukamoto, M.; Matshisita, T.; Tomita, F.; Okada, K.; Ogasawara, T.; Takase, K.; Yuba, T.: </author> <title> Modular Manufacturing. </title> <journal> Journal of Intelligent Manufacturing, </journal> <volume> 4 (1993), </volume> <pages> pp. 163-181. </pages>
Reference-contexts: The more robots work autonomously the more cooperation of man-machine and machine-machine [2] will be necessary. Distributed multi-robot systems show the way future intelligent manufacturing systems can operate independently <ref> [3, 4] </ref>. In such an environment, all machines can't always be programmed or controlled in the same way. On that account, natural language as a communication medium for humans is an efficient means to make a technical system easier accessible to its users [5].
Reference: [5] <author> Wahlster, </author> <title> W: Natural Language Systems: Some Research Trends. In: Schnelle, </title> <editor> H.; Bernsen, </editor> <volume> N.O. </volume> <editor> (eds.): </editor> <booktitle> Logic and Linguistics: Research Directions in Cognitive Science - European Perspectives, </booktitle> <volume> Vol. </volume> <pages> 2. </pages> <address> Hillsdale: </address> <publisher> Erlbaum, </publisher> <year> 1989, </year> <pages> pp. 171-183. </pages>
Reference-contexts: In such an environment, all machines can't always be programmed or controlled in the same way. On that account, natural language as a communication medium for humans is an efficient means to make a technical system easier accessible to its users <ref> [5] </ref>. A practical advantage of a natural language access is the possibility to convey information in a varying degree of condensation and to communicate on different levels of abstraction in an applicationspecific way.
Reference: [6] <author> Sondheimer, </author> <title> N.K.: Spatial Reference and Natural Language Machine Control. </title> <journal> Int. Journal of Man-Machine Studies, </journal> <volume> 8 (1976), </volume> <pages> pp. 329-336. </pages>
Reference-contexts: STATE OF THE ART Although natural language processing and robotics constitute two major areas of AI, they have been studied rather independently. Only a few works are concerned with natural language access for human-machine-interaction and communication. Sondheimer <ref> [6] </ref> focuses on the problem of spatial reference in natural language machine control. The well known SHAKEY system [7], a mobile robot without manipulators, is able to understand simple commands given in natural language. The work described in [8] concentrates on language-aided instruction for teleoperational control.
Reference: [7] <author> Nilsson, N.J.: </author> <title> Shakey the Robot. </title> <type> Technical Note 323, </type> <institution> Artificial Intelligence Center, SRI International, </institution> <address> Menlo Park, CA, </address> <year> 1984. </year>
Reference-contexts: Only a few works are concerned with natural language access for human-machine-interaction and communication. Sondheimer [6] focuses on the problem of spatial reference in natural language machine control. The well known SHAKEY system <ref> [7] </ref>, a mobile robot without manipulators, is able to understand simple commands given in natural language. The work described in [8] concentrates on language-aided instruction for teleoperational control. Specific words can be utilized to simplify the specification of teleoperational functions for the instruction of a remote robot system.
Reference: [8] <author> Sato, T.; Hirai, S.: </author> <title> Language-Aided Robotic Teleoperation System (LARTS) for Advanced Teleoperation. </title> <journal> IEEE Journal on Robotics and Automation (RA), </journal> <volume> 3, 5 (1987), </volume> <pages> pp. 476-480. </pages>
Reference-contexts: Sondheimer [6] focuses on the problem of spatial reference in natural language machine control. The well known SHAKEY system [7], a mobile robot without manipulators, is able to understand simple commands given in natural language. The work described in <ref> [8] </ref> concentrates on language-aided instruction for teleoperational control. Specific words can be utilized to simplify the specification of teleoperational functions for the instruction of a remote robot system. Torrance [9] presents a natural language interface for a navigating indoor office-based mobile robot.
Reference: [9] <author> Torrance, M. C.: </author> <title> Natural Communication with Robots. </title> <type> Master's thesis, </type> <institution> MIT, Department of Electrical Engineering and Computer Science, </institution> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: The work described in [8] concentrates on language-aided instruction for teleoperational control. Specific words can be utilized to simplify the specification of teleoperational functions for the instruction of a remote robot system. Torrance <ref> [9] </ref> presents a natural language interface for a navigating indoor office-based mobile robot. In addition to giving commands and asking questions about the robot's plans the user can associate arbitrary names with specific locations in the environment.
Reference: [10] <author> Lobin, H.: </author> <title> Situierte Agenten als nat""urlichsprachliche Schnittstellen. </title> <type> Arbeitsberichte Computerlinguistik 3-92, </type> <institution> Univ. Bielefeld, W. Germany, </institution> <year> 1992. </year>
Reference-contexts: In addition to giving commands and asking questions about the robot's plans the user can associate arbitrary names with specific locations in the environment. Some theoretical aspects of natural language communication with robot systems from the perspective of computer linguistics are discussed in <ref> [10] </ref>. Other approaches have been concerned with natural language control of autonomous agents within simulated 2D or 3D environments [11-13].One salient aspect for natural language access to robot systems is the relationship between sensory information and verbal descriptions.
Reference: [11] <author> Badler, N.I.; Webber, B.L.; Kalita, J.; Esakov, J.: </author> <title> Animation from Instructions. In: N.I. </title> <editor> Badler, B.A. Barsky, and D. Zeltzer (eds.): </editor> <title> Making Them Move: Mechanics, Control, and Animation of Articulaited Figures. </title> <publisher> Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991, </year> <pages> pp. 51-93. </pages>
Reference: [12] <author> Chapman, D.: </author> <title> Vision, Instruction, and Action. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year> <month> 6 </month>
Reference: [13] <author> Vere, S.; Bickmore, T.: </author> <title> A Basic Agent. </title> <journal> Computational Intelligence, </journal> <volume> 6, 1 (1990), </volume> <pages> pp. 41-60. </pages>
Reference: [14] <author> Bajcsy, R.; Joshi, A.; Krotkov, E.; Zwarico, </author> <title> A: Landscan: A Natural Language and Computer Vision System for Analyzing Aerial Images. </title> <booktitle> Proc. of the 9th IJCAI, </booktitle> <address> Los Angeles, CA, </address> <year> 1985, </year> <pages> pp. 919-921. </pages>
Reference: [15] <author> Herzog, G.; Wazinski, P.: </author> <title> VIsual TRAnslator: Linking Perceptions and Natural Language Descriptions. </title> <journal> Artificial Intelligence Review Journal, </journal> <volume> 8, </volume> <year> 1994, </year> <note> to appear </note>
Reference-contexts: An incremental generator, which is based on Tree Adjoining Grammars, generates the surface structures [24]. KANTRA is an extension of the VITRA (Visual Translator) system, which allows for natural language access to visual data <ref> [15] </ref>. A referential semantics has been defined which connects verbal descriptions to visual and geometric information. This approach provides powerful methods to treat the problem of spatial reference.
Reference: [16] <author> Neumann, B.: </author> <title> Natural Language Description of Time-Varying Scenes. </title> <editor> In: D.L. Waltz (ed.): </editor> <title> Semantic Structures. </title> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1989, </year> <pages> pp. 167-207. </pages>
Reference: [17] <author> Wahlster, W.; Marburger, H.; Jameson, A.; Busemann, S.: </author> <title> Over-Answering Yes-No Questions: Extended Responses in a NL Interface to a Vision System. </title> <booktitle> Proc. of the 8th IJCAI, </booktitle> <address> Karlsruhe, </address> <publisher> W. </publisher> <address> Germany, </address> <year> 1983, </year> <pages> pp. 643-646. </pages>
Reference: [18] <author> Lueth, T.C.; Rembold, U.: </author> <title> Extensive Manipulation Capabilities and Reliable Behavior at Autonomous Robot Assembly. </title> <booktitle> accepted at IEEE Int. Conf. on Robotics and Automation, </booktitle> <address> San Diego, CA, </address> <month> May 8-13, </month> <year> 1994. </year>
Reference-contexts: In the KAMRO (Karlsruhe Autonomous Mobile Robot) project, for example, an autonomous mobile robot (Fig.1) for assembly tasks is being developed which also has the capability of recovering from error situations <ref> [18] </ref>. The autonomous mobile robot KAMRO is a two-arm robot-system that consists of a mobile platform with an omnidirectional drive system, two Puma 260 manipulators, and different sensors for navigation, docking and manipulation. Fig. 1: The mobile robot KAMRO KAMRO is capable of performing assembly tasks (Fig.2) autonomously.
Reference: [19] <author> Webber, B.; Grosz, B.; Hirai, S.; Rist, T.; Scott, D.:Instructions: </author> <title> Language and Behaviour (panel). </title> <booktitle> Proc. of the 13thIJCAI, </booktitle> <address> Chambery, France, </address> <year> 1993, </year> <pages> pp. 1684-1689. </pages>
Reference-contexts: DIALOG-ORIENTED USE OF NATURAL LANGUAGE As mentioned above, simple instructions in a natural language syntax are not sufficient for interacting with an autonomous mobile robot. In any command-based approach the limitations of unidirectional communication will soon become obvious <ref> [19] </ref>. Flexible human-machine interaction is only possible if intelligent robots are made more responsive. A robot needs the capability to report task specific information, to explain its behaviour, and to provide information about the environment.
Reference: [20] <author> Allgayer, J.; Harbusch, K.; Kobsa, A.; Reddig, C.; Reithinger, N.; Schmauks, D.: </author> <title> XTRA: A Natural-Language Access System to Expert Systems. In: </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 31, </volume> <year> 1989, </year> <pages> pp. 161-195. </pages>
Reference: [21] <author> Carbonell, J.G.; Boggs, W.M.; Mauldin, </author> <title> M.L.; Anick, P.G.: The XCALIBUR project: A Natural Natural Language Interface to Expert Systems and Data Bases. </title> <editor> In: S. Andriole (ed.): </editor> <booktitle> Applications in Artificial Intelligence. </booktitle> <publisher> Petrocelli, </publisher> <year> 1985. </year>
Reference: [22] <author> Trost, H.; Buchberger, E.; Heinz, W.; Hoertnagl, C.; Matiasek, J.: DATENBANK-DIALOG: </author> <title> A German Language Interface for Relational Databases. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 1 (1987), </volume> <pages> pp. 181-203. </pages>
Reference: [23] <author> Harbusch, K.: </author> <title> A First Snapshot of XTRAGRAM, A Unification Grammar for German Based on PATR. </title> <type> Memo 14, </type> <institution> Universitaet des Saarlandes, </institution> <type> SFB 314 (XTRA), </type> <year> 1986. </year>
Reference-contexts: The architecture of our integrated system is shown in Fig. 4. Natural language commands and queries from the user form the input for the natural language access system. The linguistic analysis translates the natural language expressions into propositions. The syntactic-semantic parser we use is a modified version of SB-PATR <ref> [23] </ref> which is based on a unification grammar with semantic information. The propositions are further interpreted in the evaluation component, which is also responsible for the reference semantic interpretation.
Reference: [24] <author> Harbusch, K.; Finkler, W.; Schauder, A.: </author> <title> Incremental Syntax Generation with Tree Adjoining Grammars. </title> <editor> In: W. Brauer and D. Hernandez (eds.): </editor> <booktitle> Verteilte Kueunstliche Intelligenz und kooperatives Arbeiten: 4. Int. GI-Kongress Wissensbasierte Systeme, </booktitle> <address> Heidelberg: </address> <publisher> Springer, </publisher> <year> 1991, </year> <pages> pp. 363-374. </pages>
Reference-contexts: Fig. 5: Different localisation expressions for robot and operator The generation component translates selected propositions into natural language descriptions, explanations, and queries. An incremental generator, which is based on Tree Adjoining Grammars, generates the surface structures <ref> [24] </ref>. KANTRA is an extension of the VITRA (Visual Translator) system, which allows for natural language access to visual data [15]. A referential semantics has been defined which connects verbal descriptions to visual and geometric information. This approach provides powerful methods to treat the problem of spatial reference.
Reference: [25] <author> Stopp, E.; Gapp, K.-P.; Herzog, G.; Laengle, Th.; Lueth, </author> <title> T.C.: Utilizing Spatial Relations for Natural Language Access to an Autonomous Mobile Robot. </title> <note> Accepted at 18. </note> <institution> Deutsche Jahrestagung fuer Kuenstliche Intelligenz, Saarbruecken, Germany, </institution> <month> September 18.-23., </month> <year> 1994. </year>
Reference-contexts: In order to use and understand localization expressions, the interface has to take into account how the user perceives the assembly parts and 5 the robot (cf. Fig. 5). A more detailed description of the utilization of spatial relations in KANTRA can be found in <ref> [25] </ref>. 7.
References-found: 25

