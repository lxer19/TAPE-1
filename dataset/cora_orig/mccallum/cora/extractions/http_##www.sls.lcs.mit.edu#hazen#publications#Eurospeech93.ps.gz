URL: http://www.sls.lcs.mit.edu/hazen/publications/Eurospeech93.ps.gz
Refering-URL: http://www.sls.lcs.mit.edu/hazen/publications.html
Root-URL: 
Title: AUTOMATIC LANGUAGE IDENTIFICATION USING A SEGMENT-BASED APPROACH  
Author: Timothy J. Hazen and Victor W. Zue 
Address: Cambridge, Massachusetts 02139 USA  
Affiliation: Spoken Language Systems Group Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: A segment-based Automatic Language Identification (ALI) system has been developed. The system was designed around a formal probabilistic framework. This framework forms the basis for investigating the ALI approach proposed by House and Neuburg which utilizes phonotactic constraints of languages. The system incorporates different components which model the phonotactic, prosodic, and acoustic properties of the different languages used in the system. The system was trained and tested using the OGI Multi-Language Telephone Speech Corpus. An overall system performance of 47.7% was achieved in identifying the language of test utterances. Keywords: Automatic language identification. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Cimarusti and R. B. Ives, </author> <title> "Development of an automatic identification system of spoken languages: Phase I," </title> <booktitle> In Proc. ICASSP-82, </booktitle> <pages> pp. 1661-1663, </pages> <year> 1982. </year>
Reference-contexts: The goal of an ALI system is to accurately and efficiently determine the language of a spoken utterance. To date a majority of the research in ALI has focused on frame-based statistical approaches which are trained in an unsupervised manner <ref> [1, 2, 3, 4, 5] </ref>. While some of these approaches have performed quite well, the work of House and Neuburg suggests that an approach which models the phonotac-tic constraints of languages could prove extremely effective [6].
Reference: [2] <author> R. B. Ives, </author> <title> "A minimal rule AI expert system for real-time classification of natural spoken languages," </title> <booktitle> In Proc. of the 2nd Annual Artificial Intelligence and Advanced Computer Technology Conf., </booktitle> <pages> pp. 337-340, </pages> <year> 1986. </year>
Reference-contexts: The goal of an ALI system is to accurately and efficiently determine the language of a spoken utterance. To date a majority of the research in ALI has focused on frame-based statistical approaches which are trained in an unsupervised manner <ref> [1, 2, 3, 4, 5] </ref>. While some of these approaches have performed quite well, the work of House and Neuburg suggests that an approach which models the phonotac-tic constraints of languages could prove extremely effective [6].
Reference: [3] <author> J. T. </author> <title> Foil, "Language identification using noisy speech," </title> <booktitle> In Proc. ICASSP-86, </booktitle> <pages> pp. 861-864, </pages> <year> 1986. </year>
Reference-contexts: The goal of an ALI system is to accurately and efficiently determine the language of a spoken utterance. To date a majority of the research in ALI has focused on frame-based statistical approaches which are trained in an unsupervised manner <ref> [1, 2, 3, 4, 5] </ref>. While some of these approaches have performed quite well, the work of House and Neuburg suggests that an approach which models the phonotac-tic constraints of languages could prove extremely effective [6].
Reference: [4] <author> F. J. Goodman, A. F. Martin, and R. E. Wohlford, </author> <title> "Improved automatic language identification in noisy speech," </title> <booktitle> In Proc. ICASSP-89, </booktitle> <pages> pp. 528-531, </pages> <year> 1989. </year>
Reference-contexts: The goal of an ALI system is to accurately and efficiently determine the language of a spoken utterance. To date a majority of the research in ALI has focused on frame-based statistical approaches which are trained in an unsupervised manner <ref> [1, 2, 3, 4, 5] </ref>. While some of these approaches have performed quite well, the work of House and Neuburg suggests that an approach which models the phonotac-tic constraints of languages could prove extremely effective [6].
Reference: [5] <author> M. A. Zissman, </author> <title> "Automatic language identification using Gaussian mixture and hidden Markov models," </title> <booktitle> In Proc. ICASSP-93, </booktitle> <pages> pp. 399-402, </pages> <year> 1993. </year>
Reference-contexts: The goal of an ALI system is to accurately and efficiently determine the language of a spoken utterance. To date a majority of the research in ALI has focused on frame-based statistical approaches which are trained in an unsupervised manner <ref> [1, 2, 3, 4, 5] </ref>. While some of these approaches have performed quite well, the work of House and Neuburg suggests that an approach which models the phonotac-tic constraints of languages could prove extremely effective [6]. <p> Despite the fact that certain simplifying assumptions were made, the performance of the system that we developed indicates that the phonotactically motivated approach proposed by House and Neuburg can be effective. While our results are very preliminary, they are nevertheless competitive to systems developed by others <ref> [5, 9] </ref>. speakers, suggesting that there is plenty of room for performance improvement. We believe that the system will benefit most from improvements to the phonetic recognition and language modeling components of the system.
Reference: [6] <author> A. S. House and E. P. Neuburg, </author> <title> "Toward automatic identification of the language of an utterance. I. Preliminary methodological considerations," </title> <journal> JASA, </journal> <volume> Vol. 62, No. 3, </volume> <pages> pp. 708-713, </pages> <month> Sep. </month> <year> 1977. </year>
Reference-contexts: While some of these approaches have performed quite well, the work of House and Neuburg suggests that an approach which models the phonotac-tic constraints of languages could prove extremely effective <ref> [6] </ref>. Specifically, they proposed that languages can be differentiated strictly based on sequential constraints on phonemes. In fact, the constraints are so strong that they can be captured even if phonemes are described in terms of broad phonetic classes.
Reference: [7] <author> K. P. Li and T. J. Edwards, </author> <title> "Statistical models for automatic language identification" In Proc. </title> <booktitle> ICASSP-80, </booktitle> <pages> pp. 884-887, </pages> <year> 1980. </year>
Reference-contexts: House and Neuburg's work provides a strong base upon which a segment-based approach to ALI can be built. Despite their compelling demonstration, albeit on hand-labeled data without error, only a few studies have utilized the ideas they introduced <ref> [7, 8, 9] </ref>. In this paper a segment-based approach to ALI is presented. To provide a solid theoretical foundation for the approach, a probabilistic framework which builds upon House and Neuburg's ideas is first formulated.
Reference: [8] <author> Y. K. Muthusamy, R. A. Cole, and M. Gopalakrishnan, </author> <title> "A segment-based approach to automatic language identification," </title> <booktitle> In Proc. ICASSP-91, </booktitle> <pages> pp. 353-356, </pages> <year> 1991. </year>
Reference-contexts: House and Neuburg's work provides a strong base upon which a segment-based approach to ALI can be built. Despite their compelling demonstration, albeit on hand-labeled data without error, only a few studies have utilized the ideas they introduced <ref> [7, 8, 9] </ref>. In this paper a segment-based approach to ALI is presented. To provide a solid theoretical foundation for the approach, a probabilistic framework which builds upon House and Neuburg's ideas is first formulated.
Reference: [9] <author> Y. K. Muthusamy and R. A. Cole, </author> <title> "Automatic segmentation and identification of ten languages using telephone speech," </title> <booktitle> In Proc. ICSLP 92, </booktitle> <pages> pp. 1007-1010, </pages> <year> 1992. </year>
Reference-contexts: House and Neuburg's work provides a strong base upon which a segment-based approach to ALI can be built. Despite their compelling demonstration, albeit on hand-labeled data without error, only a few studies have utilized the ideas they introduced <ref> [7, 8, 9] </ref>. In this paper a segment-based approach to ALI is presented. To provide a solid theoretical foundation for the approach, a probabilistic framework which builds upon House and Neuburg's ideas is first formulated. <p> Despite the fact that certain simplifying assumptions were made, the performance of the system that we developed indicates that the phonotactically motivated approach proposed by House and Neuburg can be effective. While our results are very preliminary, they are nevertheless competitive to systems developed by others <ref> [5, 9] </ref>. speakers, suggesting that there is plenty of room for performance improvement. We believe that the system will benefit most from improvements to the phonetic recognition and language modeling components of the system.
Reference: [10] <author> T. J. Hazen, </author> <title> Automatic Language Identification Using a Segment-Based Approach, </title> <type> SM thesis, </type> <institution> MIT, </institution> <year> 1993. </year>
Reference-contexts: Interested readers are referred to a more detailed description of this work in <ref> [10] </ref>. PROBABILISTIC FRAMEWORK Before designing the segment-based ALI system, a probabilistic framework describing the ALI problem was derived. To begin, let L = fL 1 ; L 2 ; : : : ; L n g represent the language set of n different languages.
Reference: [11] <author> Y. K. Muthusamy, R. A. Cole, and B. T. Oshika, </author> <title> "The OGI Multi-Language Speech Corpus," </title> <booktitle> In Proc. of ICSLP 92, </booktitle> <pages> pp. 895-898, </pages> <year> 1992. </year>
Reference-contexts: SYSTEM DESCRIPTION Corpus The ALI system described below was trained and tested using the OGI Multi-Language Telephone Speech Corpus <ref> [11] </ref>. The OGI database consists of utterances spoken in 10 different languages that were collected over the telephone lines. The ten languages are English, Farsi, French, German, Japanese, Korean, Mandarin, Spanish, Tamil, and Vietnamese. Each language contains utterances from 90 different speakers.
Reference: [12] <author> J. R. Glass and V. W. Zue, </author> <title> "Multi-level acoustic segmentation of continuous speech," </title> <booktitle> In Proc. of ICASSP-88, </booktitle> <pages> pp. 429-432, </pages> <year> 1988. </year>
Reference-contexts: To circumvent this problem, two alternatives were investigated. The first option was to train the recognizer in an unsupervised manner. For this option, all of the utterances were automatically segmented using an adaptation of Glass's multi-level acoustic segmentation algorithm <ref> [12] </ref>. A threshold was used to obtain a single segmentation from a dendrogram of possible segmentations. For each segment a feature vector of 14 MFCC coefficients averaged over the length of the segment was created.
Reference: [13] <author> V. Zue, J. Glass, M. Phillips, and S. Seneff, </author> <title> "The MIT SUMMIT Speech Recognition System: A progress report," </title> <booktitle> In Proc. of the DARPA Speech and Natural Language Workshop, </booktitle> <month> February, </month> <year> 1989. </year>
Reference-contexts: Therefore, we may be able to determine the segments and phonetic classes using a recognizer trained on data from one language. In our case, we used the summit phonetic recognizer <ref> [13, 14] </ref> trained on the NTIMIT corpus. The recognizer was then applied to all of the utterances in the OGI corpus to provide the best transcription of English phones for each utterance. The detailed phonetic labels produced by summit were then collapsed into broad phonetic classes.
Reference: [14] <author> V. Zue, J. Glass, D. Goodine, H. Leung, M. Phillips, J. Polifroni, and S. Seneff, </author> <title> "Recent Progress on the SUMMIT System," </title> <booktitle> In Proc. of the Third DARPA Speech and Natural Language Workshop, </booktitle> <month> June, </month> <year> 1990. </year>
Reference-contexts: Therefore, we may be able to determine the segments and phonetic classes using a recognizer trained on data from one language. In our case, we used the summit phonetic recognizer <ref> [13, 14] </ref> trained on the NTIMIT corpus. The recognizer was then applied to all of the utterances in the OGI corpus to provide the best transcription of English phones for each utterance. The detailed phonetic labels produced by summit were then collapsed into broad phonetic classes.
References-found: 14

