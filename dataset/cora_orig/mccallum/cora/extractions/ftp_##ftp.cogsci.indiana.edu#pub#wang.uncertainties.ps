URL: ftp://ftp.cogsci.indiana.edu/pub/wang.uncertainties.ps
Refering-URL: http://www.cogsci.indiana.edu/farg/peiwang/papers.html
Root-URL: 
Email: pwang@cogsci.indiana.edu  
Title: A Unified Treatment of Uncertainties  
Author: Pei Wang 
Date: September 29, 1993  
Affiliation: Indiana University  
Note: Center for Research on Concepts and Cognition  
Abstract: Uncertainty in artificial intelligence" is an active research field, where several approaches have been suggested and studied for dealing with various types of uncertainty. However, it's hard to rank the approaches in general, because each of them is usually aimed at a special application environment. This paper begins by defining such an environment, then show why some existing approaches cannot be used in such a situation. Then a new approach, Non-Axiomatic Reasoning System, is introduced to work in the environment. The system is designed under the assumption that the system's knowledge and resources are usually insufficient to handle the tasks imposed by its environment. The system can consistently represent several types of uncertainty, and can carry out multiple operations on these uncertainties. Finally, the new approach is compared with the previous approaches in terms of uncertainty representation and interpretation.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Bhatnagar and L. Kanal. </author> <title> Handling uncertain information. </title> <editor> In L. Kanal and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 3-26. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference-contexts: Therefore, here we'll focus our attention on the latter approach: representing the uncertainty of a proposition by a real number in <ref> [0, 1] </ref>. To simplify our discussion, let's assume the proposition have the form "b is A", so the number is the grade of membership of b in A ([35]). <p> In this way, ignorance can be represented by the width of the interval. When the system know nothing about a proposition, the interval is <ref> [0, 1] </ref>, that is, the objective probability can be anywhere; when the objective probability is known, the interval degenerates into a point. The operations on the interval can be got directly from probability theory, so the approach has a solid foundation. <p> Of course we don't know the probability of head (defined as the limit of the frequency), but do we know the interval within which the probability stays? Since future evidence is infinite compared with known evidence, no such interval can be guaranteed, except the trivial <ref> [0, 1] </ref>. Of course we can guess such an interval, but then the reliability of the guess need to be indicated somehow | once again, we are facing an infinite regression. <p> Therefore, the cardinal of such a "fuzzy set" is not necessarily to be an integer. 3.2 The ratio form Though the cardinal form of uncertainty is logically more basic, it is unnatural and inconvenient in many situations. We often prefer a "relative measurements", such as a real number in <ref> [0; 1] </ref>. It's easy to see that f = w will give us the "success frequency" of the inheritance relation between the two terms, according to the system's experience. <p> Such an interval have some interesting properties: 1. The width of the interval is exactly the ignorance as defined above, that is, z a = i = 1 c. 2. The frequency f divide the [a; z] interval into the same proportion as it divide the <ref> [0; 1] </ref> interval, which is the proportion between the weights of the positive and the negative evidence, that is, f a : z f = f : 1 f = w + : w . 3.4 Summary Now we have three functionally identical ways to represent the uncertainty in a proposition <p> uncertainty in a proposition in NARS ([30]): 1. as a pair of cardinals fw + , wg, where w + is a non-negative real number, w is a positive real number, and w w + ; 11 2. as a pair of ratios &lt; f; c &gt;, where f 2 <ref> [0; 1] </ref>, and c 2 (0; 1); or 3. as an interval [a; z], where 0 a &lt; z 1, and 1 &gt; z a. <p> For example, the label set ffalse, more or less false, borderline, more or less true, trueg can be translated into [0, 0.2], [0.2, 0.4], [0.4, 0.6], [0.6, 0.8], and <ref> [0.8, 1] </ref>, respectively (similar methods are discussed in [27]). 2 It is also possible to determine the meanings of everyday verbal uncertainty expressions by psychological experiments ([17, 27]). <p> approaches, are applicable only in situations where the system's knowledge is sufficient on the relations between evidence from different sources, and the system's resources are sufficient for globe updating when new evidence comes ([28]). 4.4 The higher-order approaches As discussed previously, though the confidence c of a proposition is in <ref> [0; 1] </ref>, can be measured as a ratio, and is at a higher level than the frequency of positive evidence f , in the sense that c indicates f 's stability, c cannot be interpreted as a second-order probability h in the sense that it is the probability of the judgment
Reference: [2] <author> P. Bonissone. </author> <title> Summarizing and propagating uncertain information with triangular norms. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 1 </volume> <pages> 71-101, </pages> <year> 1987. </year>
Reference: [3] <author> P. Bonissone and K. Decker. </author> <title> Selecting uncertain calculi and granularity. </title> <editor> In L. Kanal and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 217-247. </pages> <publisher> North-Holland, </publisher> <address> Am-sterdam, </address> <year> 1986. </year>
Reference-contexts: Here I only discuss how two simple 2 For a comparison, in fuzzy logic the set may be translated into f0, 0.25, 0.5, 0.75, 1g as in [4], or into five 4-tuples as in <ref> [3] </ref>. types of fuzziness are interpreted and represented in NARS.
Reference: [4] <author> D. Dubois and H. Prade. </author> <title> Fuzzy Sets and Systems. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year> <month> 17 </month>
Reference-contexts: Here I only discuss how two simple 2 For a comparison, in fuzzy logic the set may be translated into f0, 0.25, 0.5, 0.75, 1g as in <ref> [4] </ref>, or into five 4-tuples as in [3]. types of fuzziness are interpreted and represented in NARS.
Reference: [5] <author> R. Fung and C. Chong. </author> <title> Metaprobability and Dempster-Shafer in evidential reasoning. </title> <editor> In L. Kanal and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 295-302. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference: [6] <author> H. Gaifman. </author> <title> A theory of higher order probabilities. </title> <editor> In J. Halpern, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 275-292. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California, </address> <year> 1986. </year>
Reference: [7] <author> I. </author> <title> Good. The Estimation of Probabilities. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1965. </year>
Reference: [8] <author> B. Grosof. </author> <title> An inequality paradigm for probabilistic knowledge. </title> <editor> In L. Kanal and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 259-275. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference: [9] <author> G. Harman. </author> <title> Change in View. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1986. </year>
Reference: [10] <author> H. Kyburg. </author> <title> The Logical Foundations of Statistical Inference. </title> <address> D. </address> <publisher> Reidel Publishing Company, </publisher> <address> Boston, </address> <year> 1974. </year>
Reference: [11] <author> H. Kyburg. </author> <title> Bayesian and non-Bayesian evidential updating. </title> <journal> Artificial Intelligence, </journal> <volume> 31 </volume> <pages> 271-293, </pages> <year> 1987. </year>
Reference: [12] <author> H. Kyburg. </author> <title> Higher order probabilities. </title> <editor> In L. Kanal, T. Levitt, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 15-22. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1989. </year>
Reference: [13] <author> R. Loui. </author> <title> Interval-based decisions for reasoning systems. </title> <editor> In L. Kanal and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 459-472. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference: [14] <author> J. McCarthy and P. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence 4, </booktitle> <pages> pages 463-502. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1969. </year>
Reference: [15] <author> G. Paa. </author> <title> Second order probabilities for uncertain and conflicting evidence. </title> <editor> In P. Bonissone, M. Henrion, L. Kanal, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pages 447-456. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference: [16] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference: [17] <author> R. Reagan, F. Mosteller, and C. Youtz. </author> <title> Quantitative meanings of verbal probability expressions. </title> <journal> Journal of Applied Psychology, </journal> <volume> 74 </volume> <pages> 433-442, </pages> <year> 1989. </year>
Reference: [18] <author> R. Reiter. </author> <title> Nonmonotonic reasoning. </title> <booktitle> Annual Review of Computer Science, </booktitle> <volume> 2 </volume> <pages> 147-186, </pages> <year> 1987. </year>
Reference-contexts: When there are competing guesses generated by different default rules, there is no universal way to make the choice. This is the so-called 'Multiple extensions problem". 3 Reiter wrote in <ref> [18] </ref>: "Nonmonotonic reasoning is necessary precisely because the information associated with such settings requires that certain conventions be respected." Since IRS is defined as a system that open to all representable new knowledge, no such convention can be assumed here.
Reference: [19] <author> E. Rosch. </author> <title> On the internal structure of perceptual and semantic categories. </title> <editor> In T. Moore, editor, </editor> <booktitle> Cognitive Development and the Acquisition of Language, </booktitle> <pages> pages 111-144. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1973. </year>
Reference: [20] <author> E. Rosch and C. Mervis. </author> <title> Family resemblances: Studies in the internal structure of categories. </title> <journal> Cognitive Psychology, </journal> <volume> 7 </volume> <pages> 573-605, </pages> <year> 1975. </year>
Reference: [21] <author> G. Shafer. </author> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, New Jersey, </address> <year> 1976. </year> <month> 18 </month>
Reference-contexts: weight of evidence that support H, and w is the weight of evidence that support H, then it follows from Dempster's rule that Bel (fHg) = m (fHg) = 1 + e w P l (fHg) = 1 m (f Hg) = e w + 1 which are derived in <ref> [21] </ref>. The above equations lead to two results when the [Bel; P l] interval degenerated into a point, that is, when the weight of total evidence w + + w go to infinite: 7 1.
Reference: [22] <author> G. Shafer and R. Srivastava. </author> <title> The Bayesian and belief-function formalisms: A general perspec-tive for auditing. Auditing: </title> <journal> A Journal of practice and Theory, </journal> <volume> 9, </volume> <year> 1990. </year>
Reference: [23] <author> P. Smets. </author> <title> Varieties of ignorance and the need for well-founded theories. </title> <journal> Information Sciences, </journal> <volume> 57-58:135-144, </volume> <year> 1991. </year>
Reference-contexts: NARS process multiple types of uncertainty in a unified way, not because they are not different (on the contrary, they are different, see <ref> [23] </ref>), but because the system have to find a common measurement at a more abstract level, otherwise the system would fail to satisfy the requirements of the environment. I hope this paper can show that such a common measurement is possible.
Reference: [24] <author> M. Sullivan and P. Cohen. </author> <title> An endorsement-based plan recognition program. </title> <booktitle> In Proceedings of the National Conference of Artificial Intelligence, </booktitle> <pages> pages 475-479. </pages> <year> 1985. </year>
Reference: [25] <author> A. Tversky and D. Kahneman. </author> <title> Judgment under uncertainty: Heuristics and biases. </title> <journal> Science, </journal> <volume> 185 </volume> <pages> 1124-1131, </pages> <year> 1974. </year>
Reference-contexts: system may make mistakes, but these mistakes are caused by the insufficiency of knowledge and resources, so they are "reasonable errors" in the sense that they are similar to human mistakes under the same situation (for example, some phenomena happened in NARS are like what Tversky and Kahneman discussed in <ref> [25] </ref> as "heuristics and biases"). Therefore, NARS is not only proposed as an engineering model for solving certain practical problems under certain situations, but also as a cognitive model to explain intelligence. Acknowledgement This work is supported by a research assistantship from Center for Research on Concepts and Cognition, Indiana University.
Reference: [26] <author> F. Voorbraak. </author> <title> On the justification of Dempster's rule of combination. </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 171-197, </pages> <year> 1991. </year>
Reference: [27] <author> T. Wallsten, D. Budescu, and R. Zwick. </author> <title> Comparing the calibration and coherence of numerical and verbal probability judgments. </title> <journal> Management Science, </journal> <volume> 39 </volume> <pages> 176-190, </pages> <year> 1993. </year>
Reference-contexts: For example, the label set ffalse, more or less false, borderline, more or less true, trueg can be translated into [0, 0.2], [0.2, 0.4], [0.4, 0.6], [0.6, 0.8], and [0.8, 1], respectively (similar methods are discussed in <ref> [27] </ref>). 2 It is also possible to determine the meanings of everyday verbal uncertainty expressions by psychological experiments ([17, 27]).
Reference: [28] <author> P. Wang. </author> <title> Belief revision in probability theory. </title> <booktitle> In Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 519-526, </pages> <address> Washington, DC, 1993. </address> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California. </address>
Reference-contexts: reasons: * As in the case of fuzziness, how the degree of belief is related to weight of evidence is unclear ([21]). * Due to insufficient knowledge and resources, it is usually impossible for IRS to maintain a consistent probability assignment on its knowledge base ([9]). * As discussed in <ref> [28] </ref>, conditionalization cannot be referred as a general way to symmetrically combine evidence from different sources. * With all the efforts to improve its efficiency, the resources expense of Bayesian approach is still pretty high for large knowledge bases. 5 The origin of the problems is: all the probability assignments in <p> However, these approaches still lack clear interpretations and well-defined operations. 1 The claim that ignorance can be derived from a probability distribution ([16]) is incorrect due to the confusion of the "explicit condition" and the "implicit condition" of a probability assignment, as discussed in <ref> [28] </ref>. 6 2.5 The interval approach Another intuitively appealing approach to measure ignorance is to use an interval, rather than a point, to represent the probability of a proposition, and interpret the interval as the lower bound and upper bound of the "objective probability" ([2, 8, 11, 13, 33]).
Reference: [29] <author> P. Wang. </author> <title> A defect in Dempster-Shafer theory. </title> <type> Technical Report 85, </type> <institution> Center for Research on Concepts and Cognition, Indiana University, Bloomington, Indiana, </institution> <year> 1993. </year>
Reference-contexts: Shafer claimed that probability is a special case of degree of belief, when the [Bel; P l] interval degenerated into a point ([21, 22]). In <ref> [29] </ref>, I argued that such a claim is misleading. I'll briefly summarize my argument here: Consider a simple frame of discernment fi = fH; Hg. <p> For a detailed discussion of the problem, see <ref> [29] </ref>. Beside the above problem, there are some other factors that make Dempster-Shafer theory unsuitable for IRS, such as * Dempster-Shafer theory only works on exclusive and exhaustive sets of hypotheses.
Reference: [30] <author> P. Wang. </author> <title> From inheritance relation to non-axiomatic logic. </title> <type> Technical Report 84, </type> <institution> Center for Research on Concepts and Cognition, Indiana University, Bloomington, Indiana, </institution> <year> 1993. </year>
Reference-contexts: To solve such problems, some other method can be used as a supplement, rather than a replacement, of the numerical approach. For example, such a mechanism is described in <ref> [30] </ref> for detecting correlated evidence in revision. Though non-numerical approach is unsuitable in IRS, their motivations need to be respected, that is, the numerical measurement should have a natural interpretation, so that the numbers can make sense to human beings. <p> Here, I'll concentrate on its representation and interpretation of uncertainty, and leave the other components (such as inference rules, memory structure, and control mechanism) to other papers. For more detailed and complete descriptions for NARS, see [32] and <ref> [30] </ref>. 3.1 The cardinal form As mentioned previously, NARS need to measure the weights of (positive and negative) evidence of a proposition. <p> Intuitively speaking, the extension of a term is its specializations, or subsets; the intension of a term is its generalizations, or supersets. (See <ref> [30] </ref> for a detailed description of the representation language.) "S P " is called a "inheritance relation" from S to P , since in its idealized case (represented by "S &lt; P ") S inherits P 's intension, and P inherits S's extension. <p> constant, the more the system knows about the inheritance relation (represented by a bigger w), the more confident the system is about the frequency, since the effect of evidence that comes in the near future will be relatively smaller (we'll see how c actually works in the revision operation in <ref> [30] </ref>). We can also naturally define ignorance as the complement of confidence by i = 1 c: Confidence and ignorance, when defined like these, are measurement about the stability or sensitivity of the frequence, by consider its variability in the near future. <p> For each rule, there are functions calculating the truth value of the conclusion (s) from the truth values of the premises, and different functions correspond to different rules. As shown in <ref> [30] </ref>, for some rules it is easier to choose a function if we treat the truth values as cardinals, while for other rules, we may prefer to treat truth values as ratios or intervals. <p> As a result, there are usually conflicting beliefs in the system's knowledge base, and the system may make mistakes due to the incomplete record of each belief's sources of evidence (see <ref> [30] </ref> for a detailed discussion). However, these problems is caused by the insufficiency of knowledge and resources, so are inevitable for IRS (as well as for human beings).
Reference: [31] <author> P. Wang. </author> <title> The interpretation of fuzziness. </title> <type> Technical Report 86, </type> <institution> Center for Research on Concepts and Cognition, Indiana University, Bloomington, Indiana, </institution> <year> 1993. </year>
Reference-contexts: To simplify our discussion, let's assume the proposition have the form "b is A", so the number is the grade of membership of b in A ([35]). The problem of using such an approach in IRS is: fuzziness is not properly analyzed and interpreted in fuzzy logic (see <ref> [31] </ref> for a detailed discussion). According to Zadeh, membership functions are subjective and context-dependent, therefore, there is no general method to determine them by experiment or analysis ([36]). <p> of operations on uncertainty than non-monotonic logics, for example, NARS can generate hypotheses from evidences by induction and abduction, and all of its knowledge is revisible. 4.2 The fuzzy approaches By the way the uncertainty of a proposition is represented and interpreted, NARS suggest a new interpretation of fuzziness (see <ref> [31] </ref> for a detailed discussion). Here I only discuss how two simple 2 For a comparison, in fuzzy logic the set may be translated into f0, 0.25, 0.5, 0.75, 1g as in [4], or into five 4-tuples as in [3]. types of fuzziness are interpreted and represented in NARS.
Reference: [32] <author> P. Wang. </author> <title> Non-axiomatic reasoning system (version 2.2). </title> <type> Technical Report 75, </type> <institution> Center for Research on Concepts and Cognition, Indiana University, Bloomington, Indiana, </institution> <year> 1993. </year>
Reference-contexts: Though it is too early to establish a universally accepted definition for intelligent reasoning system, I want to give a definition to make it clear that what type of system I'm talking about. Why such a definition is chosen is explained in <ref> [32] </ref>. <p> In these inferences, uncertainty emerge even if all the premises are certain, and the amount of evidence is a dominant factor for the uncertainty (see <ref> [32] </ref> for an example). For this reason, even if verbal labels of uncertainty is used in the communication language for the sake of naturalness, it is still desired to represent uncertainty numerically in the internal representation. <p> Here, I'll concentrate on its representation and interpretation of uncertainty, and leave the other components (such as inference rules, memory structure, and control mechanism) to other papers. For more detailed and complete descriptions for NARS, see <ref> [32] </ref> and [30]. 3.1 The cardinal form As mentioned previously, NARS need to measure the weights of (positive and negative) evidence of a proposition. <p> For why such an environment is important and interesting from the point of view of artificial intelligence and cognitive science, see <ref> [32] </ref>. This approach have many interesting properties, for example, it satisfies most requirements in Bonissone's list of desiderata ([2]).
Reference: [33] <author> K. Weichselberger and S. Pohlmann. </author> <title> A Methodology for Uncertainty in Knowledge-Based Systems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference: [34] <author> R. Yager. </author> <title> Credibility discounting in the theory of approximate reasoning. </title> <editor> In P. Bonissone, M. Henrion, L. Kanal, and J. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pages 299-310. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference: [35] <author> L. Zadeh. </author> <title> Fuzzy sets. </title> <journal> Information and Control, </journal> <volume> 8 </volume> <pages> 338-353, </pages> <year> 1965. </year>
Reference: [36] <author> L. Zadeh. </author> <title> A fussy-set-theoretic interpretation of linguistic hedges. </title> <journal> Journal of Cybernetics, </journal> <volume> 2 </volume> <pages> 4-34, </pages> <year> 1972. </year>
Reference: [37] <author> L. Zadeh. </author> <title> Fuzzy sets as a basis for a theory of possibility. </title> <journal> Fuzzy Sets and System, </journal> <volume> 1 </volume> <pages> 3-28, </pages> <year> 1978. </year>
Reference-contexts: possible to absorb these ideas into a numerical representation of uncertainty. 2.2 The fuzzy approaches There are two types of approaches that can be called "fuzzy": one is using linguistic variables to represent uncertainty, and the other is using grade of membership (or its variations, such as possibility, as in <ref> [37] </ref>) to do it. The former falls into the category of non-numerical approaches, so the 4 previous discussion applies, that is, though such an approach may work well for the communication language, it is not good enough as an internal representation.
References-found: 37

