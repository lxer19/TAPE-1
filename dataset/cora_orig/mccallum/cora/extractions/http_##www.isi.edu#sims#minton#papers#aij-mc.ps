URL: http://www.isi.edu/sims/minton/papers/aij-mc.ps
Refering-URL: http://www.isi.edu/sims/minton/homepage.html
Root-URL: 
Title: Minimizing Conflicts: A Heuristic Repair Method for Constraint-Satisfaction and Scheduling Problems  
Author: Steven Minton Mark D. Johnston Andrew B. Philips Philip Laird 
Keyword: Abbreviated Title: "Minimizing Conflicts: A Heuristic Repair Method"  
Address: Baltimore, MD 21218 USA Mail Stop: 269-2 Mail Stop: 269-2 Moffett Field, CA 94035 USA Moffett Field, CA 94035 USA  
Affiliation: 1 Sterling Federal Systems 2 Space Telescope Science Institute 3 NASA Ames Research Center NASA Ames Research Center 3700 San Martin Drive, AI Research Branch AI Research Branch  
Abstract: This paper describes a simple heuristic approach to solving large-scale constraint satisfaction and scheduling problems. In this approach one starts with an inconsistent assignment for a set of variables and searches through the space of possible repairs. The search can be guided by a value-ordering heuristic, the min-conflicts heuristic, that attempts to minimize the number of constraint violations after each step. The heuristic can be used with a variety of different search strategies. We demonstrate empirically that on the n-queens problem, a technique based on this approach performs orders of magnitude better than traditional backtracking techniques. We also describe a scheduling application where the approach has been used successfully. A theoretical analysis is presented both to explain why this method works well on certain types of problems and to predict when it is likely to be most effective. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Abramson and M. Yung. </author> <title> Divide and conquer under global constraints: A solution to the n-queens problem. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 61 </volume> <pages> 649-662, </pages> <year> 1989. </year>
Reference-contexts: In a sense, the problem of finding a single solution has been solved, since there are a 5 number of analytic methods which yield a solution in linear time <ref> [1] </ref>. For example, there are certain well--known patterns that can be instantiated to produce a solution. Nevertheless, the problem has been perceived as relatively "hard" for heuristic search methods.
Reference: [2] <author> H.M. Adorf and M.D. Johnston. </author> <title> A discrete stochastic neural network algorithm for constraint satisfaction problems. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <address> San Diego, CA, </address> <year> 1990. </year>
Reference-contexts: The work described in this paper was inspired by a surprisingly effective neural network developed by Adorf and Johnston <ref> [2, 22] </ref> for scheduling astronomical observations on the Hubble Space Telescope. Our heuristic CSP method was distilled from an analysis of the network. In the process of carrying out the analysis, we discovered that the effectiveness of the network has little to do with its connectionist implementation. <p> As described in section 4.2, this problem was remedied by the development of a successful constraint-based system to augment the initial system. At the heart of the constraint-based system is a neural network developed by Adorf and Johnston, the Guarded Discrete Stochastic (GDS) network, which searches for a schedule <ref> [2, 22] </ref>. From a computational point of view the network is interesting because Adorf and Johnston found that it performs well on a variety of tasks, in addition to the space telescope scheduling problem. <p> To the best of our knowledge, the GDS network was the first search method which could consistently solve problems involving hundreds of queens in several minutes. On the n-queens problem, Adorf and Johnston <ref> [2] </ref> reported that the probability of the GDS network converging increases with the size of the problem. For large problems, e.g., n &gt; 100 (where n is the number of queens), they observed that the network almost always converges.
Reference: [3] <author> E. Biefeld and L. Cooper. </author> <title> Bottleneck identification using process chronologies. </title> <booktitle> In Proceedings IJCAI-91, </booktitle> <address> Sydney, Australia, </address> <year> 1991. </year>
Reference-contexts: In general, scheduling appears to be an excellent application area for repair-based methods. Supporting evidence comes from previous work on other real-world scheduling applications by Zweben et al.[44], Biefeld and Cooper <ref> [3] </ref> and Kurtzmann [27]. Each of these projects use iterative improvement methods which can be characterized as repair-based. There are several reasons why repair-based methods are well-suited to scheduling applications. <p> The telescope is expected to remain highly over-subscribed, in that many more proposals will be submitted than can be accommodated by any schedule. On such problems, repair-based methods offer an alternative to traditional branch-and-bound techniques. Finally, as Biefeld and Cooper <ref> [3] </ref> have pointed out, there are real-world scheduling problems where humans find repair-based methods very natural. For example, human schedulers at JPL employ repair-based methods when constructing mission schedules for robotic spacecraft.
Reference: [4] <author> J. Bitner and E.M. Reingold. </author> <title> Backtrack programming techniques. </title> <journal> Communications of the ACM, </journal> <volume> 18 </volume> <pages> 651-655, </pages> <year> 1975. </year>
Reference-contexts: In an empirical study of the n-queens problem, Stone and Stone [39] found that this was by far the most powerful heuristic for the n-queens problem out of several described earlier by Bitner and Reingold <ref> [4] </ref>. The program exhibited highly variable behavior. At n = 1000, the program found a solution on only 81% of the runs, but three-quarters of these successful runs required fewer than 100 backtracks.
Reference: [5] <author> G. Brassard and P. Bratley. </author> <title> Algorithmics Theory and Practice. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: In comparison, a search strategy which examines the leaves of the tree in random order is unaffected by solution clustering. We investigated whether this phenomenon explained the relatively poor performance of depth-first search on n-queens by experimenting with a randomized search algorithm, called a Las Vegas algorithm <ref> [5] </ref>. The algorithm begins by selecting a path from the root to a leaf. To select a path, the algorithm starts at the root node and chooses one of its children with equal probability. This process continues recursively until a leaf is encountered. <p> For larger problems, memory becomes a limiting factor because the network requires approximately O (n 2 ) space. (Although the number of connections is actually O (n 3 ), some connections are computed dynamically rather than stored). 3 fact, this result was already known <ref> [5] </ref>.
Reference: [6] <author> D. Brelaz. </author> <title> New methods to color the vertices of a graph. </title> <journal> Communications of the ACM, </journal> <volume> 22 </volume> <pages> 251-256, </pages> <year> 1979. </year>
Reference-contexts: The hill-climbing algorithm behaves in a similar manner. To determine whether the min-conflicts approach would be practical for graph-coloring applications, we compared our two min-conflicts algorithms to a simple constructive backtracking algorithm that is known to perform well on graph-coloring problems. The algorithm, originally proposed by Brelaz <ref> [6, 41] </ref>, can be described as the repeated application of the following rule for choosing a node to color: colorings with maximum degree in the uncolored subgraph. Break ties randomly. Find the uncolored node that has the fewest consistent colorings with its neighbors.
Reference: [7] <author> P. Cheeseman, B. Kanefsky, and W.M. Taylor. </author> <title> Where the really hard problems are. </title> <booktitle> In Proceedings IJCAI-91, </booktitle> <address> Sydney, Australia, </address> <year> 1991. </year>
Reference-contexts: For the Brelaz backtracking method, a mistake is easily corrected since the subsequent choices will be pruned quickly due to the overconstrained nature of the problem. In a study motivated in part by these experiments, Cheeseman et al. <ref> [7] </ref> have shown that as the average connectivity of a (connected) graph increases, a "phase transition" occurs, and it is at this point that most of the hard graph colorability problems are found.
Reference: [8] <author> R. Dechter and J. Pearl. </author> <title> Network-based heuristics for constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 1-38, </pages> <year> 1988. </year>
Reference-contexts: For comparison, the table also shows the corresponding values for the random problem described by Dechter and Pearl <ref> [8] </ref>. 5.3.2 Highly-Structured CSPs The conflict distribution functions for random CSPs derived above predict significant variance in conflict counts in the solution state.
Reference: [9] <author> M. Eskey and M. </author> <title> Zweben. Learning search control for constraint-based scheduling. </title> <booktitle> In Proceedings AAAI-90, </booktitle> <address> Boston, Mass, </address> <year> 1990. </year>
Reference-contexts: This improves performance because the min-conflicts heuristic is less likely to violate a set of constraints than a single constraint. In some cases, we expect that more sophisticated techniques will be necessary to identify critical constraints [11]. To this end, we are currently evaluating explanation-based learning techniques <ref> [9] </ref> as a method for identifying critical constraints. The algorithms described in this paper also have an important relation to previous work in AI.
Reference: [10] <author> M.S. Fox. </author> <title> Constraint-Directed Search: A Case Study of Job-Shop Scheduling. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1987. </year>
Reference-contexts: A scheduling problem involves placing a set of tasks on a time line, subject to temporal constraints, resource constraints, preferences, etc. The Hubble Space Telescope scheduling problem can be considered a constrained optimization problem <ref> [12, 10] </ref> where we must maximize both the number and the importance of the constraints that are satisfied. As noted earlier, the initial scheduling system developed for this application had difficulty producing schedules efficiently.
Reference: [11] <author> M.S. Fox, N. Sadeh, and C. Baykan. </author> <title> Constrained heuristic search. </title> <booktitle> In Proceedings IJCAI-89, </booktitle> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: This improves performance because the min-conflicts heuristic is less likely to violate a set of constraints than a single constraint. In some cases, we expect that more sophisticated techniques will be necessary to identify critical constraints <ref> [11] </ref>. To this end, we are currently evaluating explanation-based learning techniques [9] as a method for identifying critical constraints. The algorithms described in this paper also have an important relation to previous work in AI.
Reference: [12] <author> E.C. Freuder. </author> <title> Partial constraint satisfaction. </title> <booktitle> In Proceedings IJCAI-89, </booktitle> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: A scheduling problem involves placing a set of tasks on a time line, subject to temporal constraints, resource constraints, preferences, etc. The Hubble Space Telescope scheduling problem can be considered a constrained optimization problem <ref> [12, 10] </ref> where we must maximize both the number and the importance of the constraints that are satisfied. As noted earlier, the initial scheduling system developed for this application had difficulty producing schedules efficiently.
Reference: [13] <author> M.L. Ginsberg and W.D. Harvey. </author> <title> Iterative broadening. </title> <booktitle> In AAAI Proceedings, </booktitle> <year> 1990. </year>
Reference-contexts: In a depth-first search, the average time to find the first solution increases with the average distance between solutions. Consequently depth-first search performs relatively poorly in a tree where the solutions are clustered, such as that on the left <ref> [13, 29] </ref>. In comparison, a search strategy which examines the leaves of the tree in random order is unaffected by solution clustering. We investigated whether this phenomenon explained the relatively poor performance of depth-first search on n-queens by experimenting with a randomized search algorithm, called a Las Vegas algorithm [5].
Reference: [14] <author> K.J. Hammond. </author> <title> Case-based Planning: An Integrated Theory of Planning, Learning and Memory. </title> <type> PhD thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <year> 1986. </year>
Reference-contexts: In particular, there is a long history of AI programs that use repair or debugging strategies to solve problems, primarily in the areas of planning and design [37, 40]. This approach has recently had a renaissance with the emergence of case-based <ref> [14, 26] </ref> and analogical [17, 24, 42] problem solving. To solve a problem, a case-based system will retreive the solution from a previous, similar problem and repair the old solution so that it solves the new problem.
Reference: [15] <author> R.M. Haralick and G.L. Elliot. </author> <title> Increasing tree search efficiency for constraint satisfaction problems. </title> <journal> Artificial Intelligence, </journal> <volume> 14 </volume> <pages> 263-313, </pages> <year> 1980. </year>
Reference-contexts: For example, there are certain well--known patterns that can be instantiated to produce a solution. Nevertheless, the problem has been perceived as relatively "hard" for heuristic search methods. Several studies of the n-queens problem <ref> [39, 15, 25] </ref> have compared heuristic backtracking methods such as search rearrangement backtracking (e.g., most-constrained first), forward checking, dependency-directed backtracking, etc. To the best of our knowledge, the GDS network was the first search method which could consistently solve problems involving hundreds of queens in several minutes.
Reference: [16] <author> A. Hertz and D. de Werra. </author> <title> Using tabu search techniques for graph coloring. </title> <journal> Computing, </journal> <volume> 39 </volume> <pages> 345-351, </pages> <year> 1987. </year>
Reference-contexts: In this paper, we only considered two very basic methods, hill climbing and backtracking. However, more sophisticated techniques such as best-first search are obvious candidates for investigation, since the number of conflicts in an assignment can serve as a heuristic evaluation function. Another possibility is Tabu search <ref> [16] </ref>, a hill-climbing technique that maintains a list of forbidden moves in order to avoid cycles. Morris [31, 32] has also proposed a hill-climbing method which can break out of local maxima by systematically altering the cost function.
Reference: [17] <author> A.K. Hickman and M.C. Lovett. </author> <title> Partial match and search control via internal analogy. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <address> Chicago, Ill., </address> <year> 1991. </year>
Reference-contexts: In particular, there is a long history of AI programs that use repair or debugging strategies to solve problems, primarily in the areas of planning and design [37, 40]. This approach has recently had a renaissance with the emergence of case-based [14, 26] and analogical <ref> [17, 24, 42] </ref> problem solving. To solve a problem, a case-based system will retreive the solution from a previous, similar problem and repair the old solution so that it solves the new problem.
Reference: [18] <author> J.J. </author> <title> Hopfield. Neural networks and physical systems with emergent collective computational abilities. </title> <booktitle> In Proceedings of the National Academy of Sciences, </booktitle> <volume> volume 79, </volume> <year> 1982. </year>
Reference-contexts: The network has been used to solve problems of up to 1024 queens, whereas most heuristic backtracking methods encounter difficulties with problems one-tenth that size [39]. The GDS network is a modified Hopfield network <ref> [18] </ref>. In a standard Hopfield network, all connections between neurons are symmetric. In the GDS network, the main network is coupled asymmetrically to an auxiliary network of guard neurons which restricts the configurations that the network can assume.
Reference: [19] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation, Part II. </title> <journal> Journal of Operations Research, </journal> <year> 1990. </year>
Reference-contexts: 1 Introduction One of the most promising general approaches for solving combinatorial search problems is to generate an initial, suboptimal solution and then to apply local repair heuristics <ref> [36, 28, 32, 30, 44, 38, 19] </ref>. Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems [20]. <p> For example, the Kernighan-Lin method, perhaps the most successful algorithm for solving graph-partitioning problems, repeatedly 27 improves a partitioning by swapping the two vertices that yield the greatest cost differential. The much--publicized simulated annealing method can also be characterized as a form of local search <ref> [19] </ref>. However, it is well-known that the effectiveness of local search methods depends greatly on the particular task. In fact, it is easy to imagine problems on which the min-conflicts heuristic will fail.
Reference: [20] <author> D.S. Johnson, C.H. Papadimitrou, and M. Yannakakis. </author> <title> How easy is local search? Journal of Computer and System Sciences, </title> <booktitle> 37 </booktitle> <pages> 79-100, </pages> <year> 1988. </year>
Reference-contexts: Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems <ref> [20] </ref>. Such techniques also have a long tradition in AI, most notably in problem-solving systems that operate by debugging initial solutions [37, 40]. In this paper, we describe how this idea can be extended to constraint satisfaction problems (CSPs) in a natural manner. <p> For example, in a recent paper, Morris [33] examines the structure of the n-queens problem, and shows analytically that, for min-conflicts hill-climbing, almost all local minima are solutions. 6 Discussion The heuristic hill-climbing method described in this paper can be characterized as a local search method <ref> [20] </ref>, in that each repair minimizes the number of conflicts for an individual variable. Local search methods have been applied to a variety of important problems, often with impressive results.
Reference: [21] <author> M.D. Johnston. </author> <title> Automated telescope scheduling. </title> <booktitle> In Proceedings of the Symposium on Coordination of Observational Projects. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1987. </year>
Reference-contexts: Finally, we consider a theoretical model identifying general problem characteristics that influence the performance of the method. 2 Previous Work: The GDS Network By almost any measure, the Hubble Space Telescope scheduling problem is a complex task <ref> [21, 34, 43] </ref>. Between ten thousand and thirty thousand astronomical observations per year must be scheduled, subject to a great variety of constraints including power restrictions, observation priorities, time-dependent orbital characteristics, movement of astronomical bodies, stray light sources, etc. <p> The constraints relevant to the long term problem are primarily temporal constraints. As outlined in <ref> [21] </ref>, some exposures are designed as calibrations or target acquisitions for others, and so must proceed them. Some must be executed at specific times, or at specific phases in the case of periodic phenomena. Some observations must be made at regular intervals, or grouped within a specified time span.
Reference: [22] <author> M.D. Johnston and H.M. Adorf. </author> <title> Learning in stochastic neural networks for constraint satisfaction problems. </title> <booktitle> In Proceedings of NASA Conference on Space Telerobotics, </booktitle> <address> Pasadena, CA, </address> <month> January </month> <year> 1989. </year>
Reference-contexts: The work described in this paper was inspired by a surprisingly effective neural network developed by Adorf and Johnston <ref> [2, 22] </ref> for scheduling astronomical observations on the Hubble Space Telescope. Our heuristic CSP method was distilled from an analysis of the network. In the process of carrying out the analysis, we discovered that the effectiveness of the network has little to do with its connectionist implementation. <p> As described in section 4.2, this problem was remedied by the development of a successful constraint-based system to augment the initial system. At the heart of the constraint-based system is a neural network developed by Adorf and Johnston, the Guarded Discrete Stochastic (GDS) network, which searches for a schedule <ref> [2, 22] </ref>. From a computational point of view the network is interesting because Adorf and Johnston found that it performs well on a variety of tasks, in addition to the space telescope scheduling problem.
Reference: [23] <author> L.V. Kale. </author> <title> An almost perfect heuristic for the n nonattacking queens problem. </title> <journal> Information Processing Letters, </journal> <volume> 34 </volume> <pages> 173-178, </pages> <year> 1990. </year>
Reference-contexts: problems have also recently been invented. (By coincidence, these two other methods and our method were all developed and published independently.) While both methods are specific to n-queens, one method is a repair-based method that is similar to ours in spirit [38], whereas the other employs a constructive backtracking approach <ref> [23] </ref>. This latter method uses a combination of variable and value-ordering heuristics which take advantage of the particular structure inherent in n-queens. This shows that one can solve n-queens problems quickly with a traditional, constructive backtracking method.
Reference: [24] <author> S. Kambhampati. </author> <title> Supporting flexible plan reuse. </title> <editor> In Minton S., editor, </editor> <title> Machine Learning Methods for Planning and Scheduling. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: In particular, there is a long history of AI programs that use repair or debugging strategies to solve problems, primarily in the areas of planning and design [37, 40]. This approach has recently had a renaissance with the emergence of case-based [14, 26] and analogical <ref> [17, 24, 42] </ref> problem solving. To solve a problem, a case-based system will retreive the solution from a previous, similar problem and repair the old solution so that it solves the new problem.
Reference: [25] <author> N. Keng and D.Y.Y. Yun. </author> <title> A planning/scheduling methodology for the constrained resource problem. </title> <booktitle> In Proceedings IJCAI-89, </booktitle> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: For example, there are certain well--known patterns that can be instantiated to produce a solution. Nevertheless, the problem has been perceived as relatively "hard" for heuristic search methods. Several studies of the n-queens problem <ref> [39, 15, 25] </ref> have compared heuristic backtracking methods such as search rearrangement backtracking (e.g., most-constrained first), forward checking, dependency-directed backtracking, etc. To the best of our knowledge, the GDS network was the first search method which could consistently solve problems involving hundreds of queens in several minutes.
Reference: [26] <author> J.L. Kolodner, R.L.Jr. Simpson, and K. Sycara-Cyranski. </author> <title> A process model of case-based reasoning in problem solving. </title> <booktitle> In Proceedings IJCAI-85, </booktitle> <address> Los Angeles, CA, </address> <year> 1985. </year> <month> 30 </month>
Reference-contexts: In particular, there is a long history of AI programs that use repair or debugging strategies to solve problems, primarily in the areas of planning and design [37, 40]. This approach has recently had a renaissance with the emergence of case-based <ref> [14, 26] </ref> and analogical [17, 24, 42] problem solving. To solve a problem, a case-based system will retreive the solution from a previous, similar problem and repair the old solution so that it solves the new problem.
Reference: [27] <author> C.R. Kurtzman. </author> <title> Time and Resource Constrained Scheduling, with Applications to Space Station Plan--ning. </title> <type> PhD thesis, </type> <institution> Dept. of Aeronautics and Astronautics, MIT, </institution> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: In general, scheduling appears to be an excellent application area for repair-based methods. Supporting evidence comes from previous work on other real-world scheduling applications by Zweben et al.[44], Biefeld and Cooper [3] and Kurtzmann <ref> [27] </ref>. Each of these projects use iterative improvement methods which can be characterized as repair-based. There are several reasons why repair-based methods are well-suited to scheduling applications.
Reference: [28] <author> C.R. Kurtzman and D.L. Aiken. </author> <title> The Mfive space station crew activity scheduler and stowage logistics clerk. </title> <booktitle> In Proceedings the AIAA Computers in Aerospace VII Conference, </booktitle> <address> Monterey, CA, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction One of the most promising general approaches for solving combinatorial search problems is to generate an initial, suboptimal solution and then to apply local repair heuristics <ref> [36, 28, 32, 30, 44, 38, 19] </ref>. Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems [20].
Reference: [29] <author> P. Langley. </author> <title> Systematic and nonsystematic search strategies. </title> <booktitle> In Proceedings AAAI-92, </booktitle> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: In a depth-first search, the average time to find the first solution increases with the average distance between solutions. Consequently depth-first search performs relatively poorly in a tree where the solutions are clustered, such as that on the left <ref> [13, 29] </ref>. In comparison, a search strategy which examines the leaves of the tree in random order is unaffected by solution clustering. We investigated whether this phenomenon explained the relatively poor performance of depth-first search on n-queens by experimenting with a randomized search algorithm, called a Las Vegas algorithm [5].
Reference: [30] <author> S. Minton, M. Johnston, A.B. Philips, and P. Laird. </author> <title> Solving large scale constraint satisfaction and scheduling problems using a heuristic repair method. </title> <booktitle> In Proceedings AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: 1 Introduction One of the most promising general approaches for solving combinatorial search problems is to generate an initial, suboptimal solution and then to apply local repair heuristics <ref> [36, 28, 32, 30, 44, 38, 19] </ref>. Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems [20]. <p> We present empirical evidence showing that on some standard problems our approach is considerably more efficient than traditional constructive backtracking methods. For example, on the n-queens problem, our method quickly finds solutions to the one million queens problem <ref> [30] </ref>. We argue that the reason that repair-based methods can outperform constructive methods is because a complete assignment can be more informative in guiding search than a partial assignment. However, the utility of the extra information is domain dependent.
Reference: [31] <author> P. Morris. </author> <title> Solutions without exhaustive search: An iterative descent method for binary constraint satisfaction problems. </title> <booktitle> In Proceedings the AAAI-90 Workshop on Constraint-Directed Reasoning, </booktitle> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: Another possibility is Tabu search [16], a hill-climbing technique that maintains a list of forbidden moves in order to avoid cycles. Morris <ref> [31, 32] </ref> has also proposed a hill-climbing method which can break out of local maxima by systematically altering the cost function.
Reference: [32] <author> P. Morris. </author> <title> An iterative improvement algorithm with guaranteed convergence. </title> <type> Technical Report TR-M-91-1, </type> <note> Intellicorp Technical Note, </note> <year> 1991. </year>
Reference-contexts: 1 Introduction One of the most promising general approaches for solving combinatorial search problems is to generate an initial, suboptimal solution and then to apply local repair heuristics <ref> [36, 28, 32, 30, 44, 38, 19] </ref>. Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems [20]. <p> Another possibility is Tabu search [16], a hill-climbing technique that maintains a list of forbidden moves in order to avoid cycles. Morris <ref> [31, 32] </ref> has also proposed a hill-climbing method which can break out of local maxima by systematically altering the cost function.
Reference: [33] <author> P. Morris. </author> <title> On the density of solutions in equilibrium points for the queens problem. </title> <booktitle> In Proceedings AAAI-92, </booktitle> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: To model the performance of the min-conflicts heuristic in conjunction with a particular search strategy, such as hill-climbing, a more detailed analysis is required. For example, in a recent paper, Morris <ref> [33] </ref> examines the structure of the n-queens problem, and shows analytically that, for min-conflicts hill-climbing, almost all local minima are solutions. 6 Discussion The heuristic hill-climbing method described in this paper can be characterized as a local search method [20], in that each repair minimizes the number of conflicts for an
Reference: [34] <author> N. Muscettola, S.F. Smith, G. Amiri, and D. Pathak. </author> <title> Generating space telescope observation schedules. </title> <type> Technical Report CMU-RI-TR-89-28, </type> <institution> Carnegie Mellon University, Robotics Institute, </institution> <year> 1989. </year>
Reference-contexts: Finally, we consider a theoretical model identifying general problem characteristics that influence the performance of the method. 2 Previous Work: The GDS Network By almost any measure, the Hubble Space Telescope scheduling problem is a complex task <ref> [21, 34, 43] </ref>. Between ten thousand and thirty thousand astronomical observations per year must be scheduled, subject to a great variety of constraints including power restrictions, observation priorities, time-dependent orbital characteristics, movement of astronomical bodies, stray light sources, etc. <p> Currently SPIKE handles only the long-term problem. The long-term problem involves assigning approximately one year's worth of exposures to a set of "bins" or time segments of several days length. (The short-term problem involves deriving a detailed series of commands for the telescope and is addressed using different techniques <ref> [34] </ref>.) The input to SPIKE is a set of detailed specifications for exposures that are to be scheduled on the telescope. The constraints relevant to the long term problem are primarily temporal constraints.
Reference: [35] <author> R. Musick and S. Russell. </author> <title> How long will it take? In Proceedings AAAI-92, </title> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: small, a mistake is also less likely, explaining our empirical observation that having a "good" initial assignment can be important. (Of course, an assignment with few conflicts does not necessarily imply small d, as was illustrated by the 3-colorability problem in figure 6.) In a recent paper, Musick and Russell <ref> [35] </ref> present an analysis which supports this result. They model heuristic repair algorithms as Markov processes, and show that under this model the choice of initial state has a significant impact on the expected solution time.
Reference: [36] <author> B. Selman, H. Levesque, and D. Mitchell. </author> <title> A new method for solving hard satisfiability problems. </title> <booktitle> In Proceedings AAAI-92, </booktitle> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction One of the most promising general approaches for solving combinatorial search problems is to generate an initial, suboptimal solution and then to apply local repair heuristics <ref> [36, 28, 32, 30, 44, 38, 19] </ref>. Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems [20]. <p> The fact that the min-conflicts approach performs well on n-queens, a well-studied, "standard" constraint-satisfaction problem, suggests that AI repair-based approaches may be more generally useful than previously thought. Additional evidence also comes from a very recent study by Selman, Levesque and Mitchell <ref> [36] </ref>, in which they showed that a repair-based algorithm (very similar to the hill-climbing algorithms investigated here) performs well on hard satisfiability problems. However, as we have pointed out, in some cases it can be more time-consuming to repair a solution than to construct a new one from scratch.
Reference: [37] <author> R.G. Simmons. </author> <title> A theory of debugging plans and interpretations. </title> <booktitle> In Proceedings AAAI-88, </booktitle> <address> Minneapolis, MN, </address> <year> 1988. </year>
Reference-contexts: Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems [20]. Such techniques also have a long tradition in AI, most notably in problem-solving systems that operate by debugging initial solutions <ref> [37, 40] </ref>. In this paper, we describe how this idea can be extended to constraint satisfaction problems (CSPs) in a natural manner. Most of the previous work on CSP algorithms has assumed a "constructive" backtracking approach in which a partial assignment to the variables is incrementally extended. <p> The algorithms described in this paper also have an important relation to previous work in AI. In particular, there is a long history of AI programs that use repair or debugging strategies to solve problems, primarily in the areas of planning and design <ref> [37, 40] </ref>. This approach has recently had a renaissance with the emergence of case-based [14, 26] and analogical [17, 24, 42] problem solving.
Reference: [38] <author> R. Sosic and J. Gu. </author> <title> A polynomial time algorithm for the n-queens problem. </title> <journal> SIGART, </journal> <volume> 1(3), </volume> <year> 1990. </year>
Reference-contexts: 1 Introduction One of the most promising general approaches for solving combinatorial search problems is to generate an initial, suboptimal solution and then to apply local repair heuristics <ref> [36, 28, 32, 30, 44, 38, 19] </ref>. Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems [20]. <p> two other heuristic methods that can quickly solve n-queens problems have also recently been invented. (By coincidence, these two other methods and our method were all developed and published independently.) While both methods are specific to n-queens, one method is a repair-based method that is similar to ours in spirit <ref> [38] </ref>, whereas the other employs a constructive backtracking approach [23]. This latter method uses a combination of variable and value-ordering heuristics which take advantage of the particular structure inherent in n-queens. This shows that one can solve n-queens problems quickly with a traditional, constructive backtracking method.
Reference: [39] <author> H.S. Stone and J.M. Stone. </author> <title> Efficient search techniques an empirical study of the n-queens problem. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 31 </volume> <pages> 464-474, </pages> <year> 1987. </year>
Reference-contexts: The n-queens problem requires placing n queens on an n fi n chessboard so that no two queens share a row, column or diagonal. The network has been used to solve problems of up to 1024 queens, whereas most heuristic backtracking methods encounter difficulties with problems one-tenth that size <ref> [39] </ref>. The GDS network is a modified Hopfield network [18]. In a standard Hopfield network, all connections between neurons are symmetric. In the GDS network, the main network is coupled asymmetrically to an auxiliary network of guard neurons which restricts the configurations that the network can assume. <p> n-queens problem, depth-first search tends to find a solution more quickly when the first queen is placed in the center of the first row rather than in the corner; apparently this occurs because there are more solutions with the queen in the center than with the queen in the corner <ref> [39] </ref>. Nevertheless, most naive algorithms tend to start in the corner simply because humans find it more natural to program that way. However, this fact by itself does not explain why nonsystematic search would work so well for n-queens. <p> For example, there are certain well--known patterns that can be instantiated to produce a solution. Nevertheless, the problem has been perceived as relatively "hard" for heuristic search methods. Several studies of the n-queens problem <ref> [39, 15, 25] </ref> have compared heuristic backtracking methods such as search rearrangement backtracking (e.g., most-constrained first), forward checking, dependency-directed backtracking, etc. To the best of our knowledge, the GDS network was the first search method which could consistently solve problems involving hundreds of queens in several minutes. <p> This program is a constructive backtracking program that selects the row that is most constrained when choosing the next row on which to place a queen. In an empirical study of the n-queens problem, Stone and Stone <ref> [39] </ref> found that this was by far the most powerful heuristic for the n-queens problem out of several described earlier by Bitner and Reingold [4]. The program exhibited highly variable behavior.
Reference: [40] <author> G. J. Sussman. </author> <title> A Computer Model of Skill Acquisition. </title> <publisher> American Elsevier, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems [20]. Such techniques also have a long tradition in AI, most notably in problem-solving systems that operate by debugging initial solutions <ref> [37, 40] </ref>. In this paper, we describe how this idea can be extended to constraint satisfaction problems (CSPs) in a natural manner. Most of the previous work on CSP algorithms has assumed a "constructive" backtracking approach in which a partial assignment to the variables is incrementally extended. <p> The algorithms described in this paper also have an important relation to previous work in AI. In particular, there is a long history of AI programs that use repair or debugging strategies to solve problems, primarily in the areas of planning and design <ref> [37, 40] </ref>. This approach has recently had a renaissance with the emergence of case-based [14, 26] and analogical [17, 24, 42] problem solving.
Reference: [41] <author> J.S. Turner. </author> <title> Almost all k-colorable graphs are easy to color. </title> <journal> Journal of Algorithms, </journal> <volume> 9 </volume> <pages> 63-82, </pages> <year> 1988. </year>
Reference-contexts: The hill-climbing algorithm behaves in a similar manner. To determine whether the min-conflicts approach would be practical for graph-coloring applications, we compared our two min-conflicts algorithms to a simple constructive backtracking algorithm that is known to perform well on graph-coloring problems. The algorithm, originally proposed by Brelaz <ref> [6, 41] </ref>, can be described as the repeated application of the following rule for choosing a node to color: colorings with maximum degree in the uncolored subgraph. Break ties randomly. Find the uncolored node that has the fewest consistent colorings with its neighbors. <p> The tie-breaking criterion is a preference for the "most-constraining" variable. Thus, this rule is composed of two generic variable-ordering heuristics. No value-ordering heuristic is required. The rule can be incorporated in a standard backtracking algorithm in the obvious manner. Turner <ref> [41] </ref> has shown that this algorithm will optimally color "almost all" random k-colorable graphs without backtracking. This result actually says more about the distribution of random k-colorable graphs than about the effectiveness of the algorithm, but nonetheless, the Brelaz algorithm outperforms other algorithms we have tried.
Reference: [42] <editor> M.M. Veloso and J.G. Carbonell. </editor> <title> Towards scaling up machine learning: A case study with derivation analogy in prodigy. </title> <editor> In Minton S., editor, </editor> <title> Machine Learning Methods for Planning and Scheduling. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: In particular, there is a long history of AI programs that use repair or debugging strategies to solve problems, primarily in the areas of planning and design [37, 40]. This approach has recently had a renaissance with the emergence of case-based [14, 26] and analogical <ref> [17, 24, 42] </ref> problem solving. To solve a problem, a case-based system will retreive the solution from a previous, similar problem and repair the old solution so that it solves the new problem.
Reference: [43] <author> M. Waldrop. </author> <title> Will the Hubble space telescope compute? Science, </title> <booktitle> 243 </booktitle> <pages> 1437-1439, </pages> <year> 1989. </year>
Reference-contexts: Finally, we consider a theoretical model identifying general problem characteristics that influence the performance of the method. 2 Previous Work: The GDS Network By almost any measure, the Hubble Space Telescope scheduling problem is a complex task <ref> [21, 34, 43] </ref>. Between ten thousand and thirty thousand astronomical observations per year must be scheduled, subject to a great variety of constraints including power restrictions, observation priorities, time-dependent orbital characteristics, movement of astronomical bodies, stray light sources, etc.
Reference: [44] <author> M. </author> <title> Zweben. A framework for iterative improvement search algorithms suited for constraint satisfaction problems. </title> <type> Technical Report RIA-90-05-03-1, </type> <institution> NASA Ames Research Center, AI Research Branch, </institution> <year> 1990. </year>
Reference-contexts: 1 Introduction One of the most promising general approaches for solving combinatorial search problems is to generate an initial, suboptimal solution and then to apply local repair heuristics <ref> [36, 28, 32, 30, 44, 38, 19] </ref>. Techniques based on this approach have met with empirical success on many combinatorial problems, including the traveling salesman and graph partitioning problems [20].
Reference: [45] <author> M. Zweben, M. Deale, and R. Gargan. Anytime rescheduling. </author> <title> In Proceeedings of the Workshop on Innovative Approaches to Planning, Scheduling and Control. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year> <month> 31 </month>
Reference-contexts: Each of these projects use iterative improvement methods which can be characterized as repair-based. There are several reasons why repair-based methods are well-suited to scheduling applications. First, as Zweben and Gargan <ref> [45] </ref> have pointed out, unexpected events may require schedule revision, in which case dynamic rescheduling is an important issue. Repair-based methods can be used for rescheduling in a natural manner.
References-found: 45

