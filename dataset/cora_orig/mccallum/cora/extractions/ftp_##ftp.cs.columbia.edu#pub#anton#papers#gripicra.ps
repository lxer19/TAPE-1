URL: ftp://ftp.cs.columbia.edu/pub/anton/papers/gripicra.ps
Refering-URL: http://www.cs.columbia.edu/~anton/
Root-URL: http://www.cs.columbia.edu
Title: Transparent Grippers for Robot Vision  
Author: Anton Nikolaev and Shree K. Nayar 
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University,  
Abstract: While existing grippers execute manipulation tasks, they occlude parts of the objects they grasp as well as parts of the workspace from vision sensors. We present the concept of a transparent gripper that enables vision sensors to image an object without occlusion while it is being manipulated. The physics of refraction, total internal reflection, lens effects, dispersion and transmittance are analyzed to determine the geometry and material properties of a practical transparent gripper. Algorithms are presented that compensate for image shifts caused by refraction. The experiments demonstrate the proposed gripper to be an effective solution to a variety of problems, including 3D object model generation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ash and I.Ash, </author> <title> Encyclopedia of plastics, polymers, and resins, </title> <publisher> Chemical Publishing Co., </publisher> <pages> 1982-1983. </pages>
Reference: [2] <author> M.Born and E.Wolf, </author> <title> Principles of Optics, </title> <publisher> Pergamon, </publisher> <year> 1965. </year>
Reference-contexts: Here, we review the pertinent physical effects and discuss the considerations they raise in the development of a practical gripper. The optical effect of primary interest to us is the refraction of light rays as they travel from one medium to another <ref> [2] </ref>. <p> This implies that clearer images of the object would be seen for smaller angles of incidence. well as the polarization of the incoming light. For linearly polarized light, the fraction of the incident energy that is reflected and refracted (transmitted), is given by Fresnel's equations <ref> [2] </ref>: r ? = sin (ff 1 ff 2 ) 2 r k = tan (ff 1 ff 2 ) 2 Here, r ? and t ? are the reflected and refracted energies for incident light that is polarized perpendicular to the plane of incidence, and r k and t k
Reference: [3] <editor> J.A.Brydson Plastic materials, 6th ed., Butterworth Heinemann, </editor> <year> 1995. </year>
Reference-contexts: Generally, dispersion is not a severe problem, since it is always possible to use color filters and treat each wavelength component in isolation. Nevertheless, materials that exhibit less light dispersion are obviously preferred. Many plastics have almost constant refractive indices within the visible spectrum <ref> [3] </ref>. Glass, on the other hand, is known to produce strong dispersion. 2.4 Energy Transport At a smooth interface between two media, an incident light ray generally splits into two rays: the refracted ray discussed above and a reflected ray.
Reference: [4] <editor> W.H.J.Childs Physical constants, </editor> <title> selected for students, 6th ed. rev., </title> <publisher> Methuen, </publisher> <year> 1951. </year>
Reference-contexts: Since light propagates slower in denser media, refractive indices of solids and liquids have values greater than 1. The table below gives indices of some common materials for the wavelength of 5893 A at 20 ffi C <ref> [4] </ref>: Material Refractive Index Water 1.33-1.34 Ice 1.31 Glass 1.51-1.67 Celluloid 1.49-1.50 Benzine 1.50 Glycerine 1.47 If it were possible to build a completely invisible gripper, we would only need to concern ourselves with its grasping abilities.
Reference: [5] <author> B. Curless and M. Levoy, </author> <title> "Better Optical Triangulation through Spacetime Analysis," </title> <booktitle> Proc. of Intl. Conf. on Computer Vision, </booktitle> <pages> pp. 987-994, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: In both machine vision as well as in computer graphics, there is a tangible need for efficient and robust way of recovering the 3D geometry of an object from a sample. Current approaches typically involve special purpose scanning devices <ref> [5] </ref>. Given that the shape of an object can be fairly complex, scanning it in a finite number of poses does not always suffice. In order to ensure complete shape recovery, the object has to be repositioned or re-grasped during the process.
Reference: [6] <author> M. Cutkosky, </author> <title> "On grasp choice, grasp models, and the design of hands for manufacturing tasks," </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> Vol 5, No. 3, </volume> <month> June </month> <year> 1989. </year>
Reference: [7] <editor> W.G. Driscoll, editor, </editor> <booktitle> Handbook of Optics, </booktitle> <publisher> McGraw Hill Inc., </publisher> <year> 1978. </year>
Reference: [8] <author> S. Mersch, </author> <title> "Polarized Lighting for Machine Vision Ap plications," </title> <booktitle> Proc. of RI/SME Third Annual Applied Machine Vision Conf., </booktitle> <pages> pp. 40-54, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: Since specularly reflected light tends to preserve the incident polarization, a cross-polarized 1:5). filter at the sensor end would help block out a large fraction of the reflected light <ref> [8] </ref>. 3 An Example Gripper The optimal gripper would be one whose shape and material properties minimize the undesirable effects described above, namely, total internal reflections, invisible volumes, lens distortion, dispersion, low transmittance, and specular reflections.
Reference: [9] <author> I. Kato, </author> <title> Mechanical Hands Illustrated, </title> <publisher> Hemisphere Publishing Corporation, </publisher> <year> 1982. </year>
Reference: [10] <author> G. Lundstrom, B. Glemme, and B. W. Rooks, </author> <title> Indus trial Robots Gripper Review, </title> <publisher> International Fluidics Services Ltd., </publisher> <year> 1977. </year>
Reference: [11] <editor> R.Y.Tsai "An Efficient and Accurate Camera Calibra tion Technique for 3D Machine Vision," </editor> <booktitle> IEEE Trans actions on Robotics and Automation, p. </booktitle> <volume> 364-374, No. 5, </volume> <year> 1986. </year>
Reference-contexts: + m 42 y + m 43 z + 1 ey = m 41 x + m 42 y + m 43 z + 1 where ex and ey are measured image plane coordinates, x, y, and z are world coordinates, and m ij is the 4x4 projective transformation matrix <ref> [11] </ref> to be determined. m 44 is set to 1 in order to get rid of the arbitrary scale factor. Using 64 calibration points and solving the resulting overdetermined linear system (6)-(7), we were able to calibrate the camera to within 1 pixel accuracy.
References-found: 11

