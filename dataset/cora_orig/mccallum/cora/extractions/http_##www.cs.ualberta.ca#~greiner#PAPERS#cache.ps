URL: http://www.cs.ualberta.ca/~greiner/PAPERS/cache.ps
Refering-URL: http://www.cs.ualberta.ca/~greiner/PAPERS/
Root-URL: 
Email: vinay@ai.toronto.edu  greiner@learning.siemens.com  
Title: A Formal Analysis of Solution Caching  
Author: Vinay K. Chaudhri Russell Greiner 
Address: Toronto, Ontario M5S 1A4  Princeton, NJ 08540  
Affiliation: Department of Computer Science University of Toronto  Siemens Corporate Research  
Abstract: Many inference management systems store and maintain the conclusions found during a derivation process in a form that allows these conclusions to be used during subsequent derivations. As this approach, called "solution caching", allows the system to avoid repeating these derivations, it can reduce the system's overall cost for answering queries. Unfortunately, as there is a cost for storing these conclusions, it is not always desirable to cache every solution found | this depends on whether the savings achieved by performing fewer inference steps for these future queries exceeds the storage overhead incurred. This paper formally characterizes this tradeoff and presents an efficient algorithm, FOCL, that produces an optimal caching strategy: i.e., given an inference graph of a knowledge base, anticipated frequencies of queries and updates of each node in this graph, and various implementation-dependent cost parameters, FOCL determines which of these nodes should cache their solutions to produce a system whose overall cost is minimal. The paper also presents empirical results that indicate that a system based on FOCL can significantly outperform one based on any of the standard approaches to solution caching. 
Abstract-found: 1
Intro-found: 1
Reference: [AHU87] <author> Alfred V. Aho, John E. Hopcroft, and Jef-frey D. Ullman. </author> <title> Data Structure and Algorithms. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1987. </year>
Reference-contexts: Thus the expressions for the basic terms remain similar to the previous subsection. The cost for sorting a list of length m is O (m log m) <ref> [AHU87] </ref>, and of a simple traversal, is O (m).
Reference: [CG92] <author> Vinay K. Chaudhri and Russell Greiner. </author> <title> A formal analyis of caching in backward chaining systems. </title> <type> Technical Report forthcoming, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: Due to space restrictions, this short article cannot provide a comprehensive survey of the related research; instead, we refer the interested reader to our extended paper <ref> [CG92] </ref>. <p> 2 LL (G) whose cost is minimal over all labellings | i.e., such that 8 L 2 LL (G) E [L fl ] E [L]: 2 The rest of this subsection sketchs a particular concrete cost model (i.e., a specific E [] function) for a particular class of inference graphs; <ref> [CG92] </ref> provides a more exact specification. 5 5 This paper uses a very simple model for purely pedagogical reasons; we are aware that sophisticated Prolog systems require a much more elaborate model [Debray, personal communication]. The analysis in this paper does apply to those models as well; see [CG92]. <p> inference graphs; <ref> [CG92] </ref> provides a more exact specification. 5 5 This paper uses a very simple model for purely pedagogical reasons; we are aware that sophisticated Prolog systems require a much more elaborate model [Debray, personal communication]. The analysis in this paper does apply to those models as well; see [CG92]. We assume that the total cost of a database retrieval varies linearly with the number of solutions obtained | e.g., the cost of retrieving the 2 facts matching man (Y) is twice the cost of retrieving the 1 fact matching vegetable (Z) (viz., vegetable (bean7)).
Reference: [CM81] <author> William F. Clocksin and Christopher S. Mel-lish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: Our goal is to use solution caching as a way of producing an efficient IMS | one that requires a minimal amount of time to deal with the anticipated distribution of queries and updates. There are two standard ways of dealing with solution caching. Many systems, including Prolog <ref> [CM81] </ref>, never cache any solutions. Others (e.g., [Mos83]) will cache every solution found | e.g., at every node in the graph shown in Figure 1.
Reference: [Deb90] <author> S. K. Debray. </author> <type> Personal Communication, </type> <year> 1990. </year>
Reference-contexts: Each context is defined in terms of a particular knowledge base and specific distribution of queries, specified below. All simulations use the same cost parameters R = 2, L = 1 and S = 10, obtained from experimental data <ref> [Deb90] </ref>. The depth of each knowledge base is set at 6, which is considered typical for real applications. Furthermore, the only atomic database facts that match a node are at the leaves; i.e., s (n i ) = 0 for all internal nodes n i .
Reference: [Gre91] <author> Russell Greiner. </author> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <journal> Artificial Intelligence, </journal> <volume> 50(1) </volume> <pages> 95-116, </pages> <year> 1991. </year>
Reference-contexts: Of course, neither of these can be better than IMS opt , which is guaranteed to have the best performance in all cases. 5 Conclusions This work can be extended in a few directions: To deal with inference graphs that are not tree-shaped (e.g., redundant <ref> [Gre91] </ref>, recursive [SGG86], etc.); to estimate the number of solutions that can be cached at each node without actually running the inference process; to use sampling to approximate the distribution of queries and updates [LN90, Gre92]; and to deal with different cost models | e.g., to include the storage cost of
Reference: [Gre92] <author> Russell Greiner. </author> <title> Learning efficient query processing strategies. </title> <booktitle> In Proceedings of Eleventh ACM SIGACT/SIGMOD Symposium on Principles of Database Systems, </booktitle> <year> 1992. </year>
Reference-contexts: We can also use statistical measures to bound our confidence in these estimates; see <ref> [Gre92] </ref>. <p> extended in a few directions: To deal with inference graphs that are not tree-shaped (e.g., redundant [Gre91], recursive [SGG86], etc.); to estimate the number of solutions that can be cached at each node without actually running the inference process; to use sampling to approximate the distribution of queries and updates <ref> [LN90, Gre92] </ref>; and to deal with different cost models | e.g., to include the storage cost of maintaining cached values, or to allow the values of the various parameters (e.g., R, L, S) to vary with the size of knowledge base, or the number of variables involved, etc.
Reference: [LN90] <author> R.J. Lipton and J.F. Naughton. </author> <title> Query size estimation by adaptive sampling. </title> <booktitle> In Proceedings of Ninth ACM SIGACT/SIGMOD Symposium on Principles of Database Systems, </booktitle> <pages> pages 40-46, </pages> <year> 1990. </year>
Reference-contexts: extended in a few directions: To deal with inference graphs that are not tree-shaped (e.g., redundant [Gre91], recursive [SGG86], etc.); to estimate the number of solutions that can be cached at each node without actually running the inference process; to use sampling to approximate the distribution of queries and updates <ref> [LN90, Gre92] </ref>; and to deal with different cost models | e.g., to include the storage cost of maintaining cached values, or to allow the values of the various parameters (e.g., R, L, S) to vary with the size of knowledge base, or the number of variables involved, etc.
Reference: [MCPT91] <author> John Mylopoulos, Vinay K. Chaudhri, Dim-itris Plexousakis, and Thodoros Topaloglou. </author> <title> Four Obvious Steps Towards Knowledge Base Management. </title> <booktitle> In Proceedings of the Second International Workshop on Intelligent and Cooperative Information Systems: Core Technology for Next Generation Information Systems, </booktitle> <pages> pages 28-30, </pages> <address> Como, Italy, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Note that these are precisely the kind of knowledge bases envisaged to be required in the future applications <ref> [MCPT91] </ref>. IMS 8 IMS 8 IMS 8 almost optimal here; in most cases within 10%. IMS 8 does worse in general, especially with larger branching factors.
Reference: [Mos83] <author> M. G. Moser. </author> <title> An Overview of NIKL, the new implementation of KL-ONE. </title> <editor> In C. L. Sidner, editor, </editor> <booktitle> Research in Knowledge Representation and Natural Language Understanding - Annual Report, </booktitle> <month> 1 September </month> <year> 1982 </year> <month> - 31 August </month> <year> 1983, </year> <pages> pages 7-26. </pages> <institution> Bolt Beranek and Newman, </institution> <year> 1983. </year>
Reference-contexts: There are two standard ways of dealing with solution caching. Many systems, including Prolog [CM81], never cache any solutions. Others (e.g., <ref> [Mos83] </ref>) will cache every solution found | e.g., at every node in the graph shown in Figure 1. This paper shows that neither of these two simple approaches leads to an optimally efficient system, and so proposes a third approach: of selectively caching only at certain nodes.
Reference: [Nem66] <author> George L. Nemhauser. </author> <title> Introduction to Dynamic Programming. </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: This rules out a single traversal in either direction, as either requires quantities that would not be available. Fortunately, however, we can capture this interdependence using a dynamic programming technique to obtain a solution that is provably optimal <ref> [Nem66] </ref>. The basic idea involves two traversals of the inference graph; see Figure 4. Equation 3 shows that the value of E [L ` ; n k ] depends on E [L ` ; n k+1 ], I L ` (n k ) and various input parameters.
Reference: [SAC + 79] <editor> P.G. Selinger, M.M. Astrahan, D.D. Cham-berlin, R.A. Lorie, and T.G. Price. </editor> <title> Access Path Selection in a Relational DBMS. </title> <booktitle> In Proceedings of the 1979 SIGMOD Conference, </booktitle> <year> 1979. </year>
Reference-contexts: Fortunately, we can estimate these values based on the statistics that are maintained by several commercial database systems <ref> [SAC + 79] </ref>. We can periodically collect these statistics (e.g., each time the system is "re-compiled"), and use these values as (estimates of) s (n k ), u (n k ) and d (n k ) when computing the appropriate caching label.
Reference: [Sel89] <author> Timos K. Sellis. </author> <title> Efficiently supporting procedures in a relational database system. </title> <booktitle> In Proceedings of the 1987 SIGMOD Conference, </booktitle> <address> Detroit, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: The precise characterization of the cost, shown in Equation 3, is one of the important contributions of our work. Notice it extends previous work (e.g., <ref> [Sel89, SJGP90] </ref>) which assumes that this cost is given and is independent of the structure of the knowledge base. 3 Optimal Labelling Algorithm For pedagogical reasons, Subsection 3.1 first describes the FOCL algorithm for a simple class of inference graphs; Subsections 3.2 and 3.3 then discuss how FOCL generalizes to cover
Reference: [SGG86] <author> D. E. Smith, M. R. Genesereth, and M. L. Ginsberg. </author> <title> Controlling recursive inference. </title> <journal> Artificial Intelligence, </journal> <volume> 30(3) </volume> <pages> 343-89, </pages> <year> 1986. </year>
Reference-contexts: Of course, neither of these can be better than IMS opt , which is guaranteed to have the best performance in all cases. 5 Conclusions This work can be extended in a few directions: To deal with inference graphs that are not tree-shaped (e.g., redundant [Gre91], recursive <ref> [SGG86] </ref>, etc.); to estimate the number of solutions that can be cached at each node without actually running the inference process; to use sampling to approximate the distribution of queries and updates [LN90, Gre92]; and to deal with different cost models | e.g., to include the storage cost of maintaining cached
Reference: [SJGP90] <author> Michael Stonebraker, Anant Jhingaran, Jef-frey Goh, and Spyros Potamianos. </author> <title> On rules, procedures, caching and views in databases. </title> <type> Technical Report UCB/ERL M90/36, </type> <institution> University of California, Berkeley, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: The precise characterization of the cost, shown in Equation 3, is one of the important contributions of our work. Notice it extends previous work (e.g., <ref> [Sel89, SJGP90] </ref>) which assumes that this cost is given and is independent of the structure of the knowledge base. 3 Optimal Labelling Algorithm For pedagogical reasons, Subsection 3.1 first describes the FOCL algorithm for a simple class of inference graphs; Subsections 3.2 and 3.3 then discuss how FOCL generalizes to cover
Reference: [SM91] <author> G. Schmolze and William S. Mark. </author> <title> The NIKL Experience. </title> <journal> Cognitive Science, </journal> <volume> 6(2) </volume> <pages> 48-69, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: this caching strategy is "in effect", which can be the interval of time between a pair of re-compilations. 4 Empirical Results This section compares the performance of three IMS systems: IMS opt that uses the optimal caching scheme obtained by FOCL, IMS 8 that uses the cache everywhere scheme of <ref> [SM91] </ref>, and IMS : that uses the no cache scheme. Experimental Setup: We determined the values of E [IMS opt ], E [IMS 8 ] and E [IMS : ] in 54 different contexts. <p> IMS 8 IMS 8 IMS 8 almost optimal here; in most cases within 10%. IMS 8 does worse in general, especially with larger branching factors. Summary of Experiments: These experiments suggest that IMS 8 is appropriate only for small number of ground instances; this explains the results obtained by <ref> [SM91] </ref>. However, this approach does not hold for larger knowledge bases. Given a large number of ground instances, it may be better to use IMS : rather than IMS 8 .
Reference: [Ull88] <author> Jeffrey Ullman. </author> <title> Principles of Data Base and Knowledge Base Systems, volume 1. </title> <publisher> Addison Wesley, </publisher> <year> 1988. </year>
Reference-contexts: While computing the cost function for such nodes, we must deal with the extra overhead of finding solutions that satisfy all literals. This process is equivalent to evaluating a join in the relational database <ref> [Ull88] </ref>. There are various methods of evaluating joins, including selection on an attribute, sort join, multiway merge-sort, join using index, etc. [Ull89]. As sort join seems to work well in general, we will base our discussion on this approach.
Reference: [Ull89] <author> Jeffrey Ullman. </author> <title> Principles of Data Base and Knowledge Base Systems, volume 2. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: This process is equivalent to evaluating a join in the relational database [Ull88]. There are various methods of evaluating joins, including selection on an attribute, sort join, multiway merge-sort, join using index, etc. <ref> [Ull89] </ref>. As sort join seems to work well in general, we will base our discussion on this approach. To explain the working of the sort join, consider the inference graph shown in Figure 6 (taken from the far right side of Figure 1). <p> This value needs to be added to the cost expression Equation 3. When there are more than two subgoals in a conjunction, we need to use multi-way joins <ref> [Ull89] </ref>. The basic process, however, remains the same. 3.4 Computing the Parameters In any given environment, these values of the three implementation dependent parameters, L, R and S, are standard and should be known from the supplier's data.
References-found: 17

