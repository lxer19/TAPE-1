URL: http://www.cs.washington.edu/homes/anhai/papers/haddawy-efficient.ps.Z
Refering-URL: http://www.cs.washington.edu/homes/anhai/anhai-cv.html
Root-URL: 
Email: fanhai, haddawyg@cs.uwm.edu  rich@cs.cmu.edu  
Title: Efficient Decision-Theoretic Planning: Techniques and Empirical Analysis  
Author: Peter Haddawy AnHai Doan Richard Goodwin 
Address: Milwaukee, WI 53201  5000 Forbes Ave. Pittsburgh, PA 15213  
Affiliation: Department of EE&CS University of Wisconsin-Milwaukee  School of Computer Science Carnegie Mellon University  
Date: August 1995.  
Note: In: Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence,  
Abstract: This paper discusses techniques for performing efficient decision-theoretic planning. We give an overview of the drips decision-theoretic refinement planning system, which uses abstraction to efficiently identify optimal plans. We present techniques for automatically generating search control information, which can significantly improve the planner's performance. We evaluate the efficiency of drips both with and without the search control rules on a complex medical planning problem and compare its performance to that of a branch-and-bound deci sion tree algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Boutilier and R. Dearden. </author> <title> Using abstractions for decision-theoretic planning with time constraints. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1016-1022, </pages> <address> Seattle, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: A second popular approach has been to work with a constrained and highly structured problem representa tion, exemplified by the discrete Markov process-based planners <ref> [ 2, 1 ] </ref> . The model assumes a finite state space and a limited class of utility functions. <p> This representation form is used in [ 10 ] and utilized by work in Markov Decision Process <ref> [ 2, 1 ] </ref> . In that work an action condition or effect is specified by a set of propositional assignments, such as painted ^ : hold-block. <p> The applicability and the performance of the planner would be improved if methods could be devised to perform tight abstraction, and loss due to abstraction could be quantified. Devising such procedures and loss estimates has been shown to be possible for a limited class of domains <ref> [ 1 ] </ref> . In more complex domains with more expressive utility functions it is much harder to work out efficient abstraction procedures, although relatively good abstraction hierarchy can still be built by exploiting simple regularities in the domain and heuristics given by domain experts.
Reference: [2] <author> T. Dean, L. Pack Kaelbling, J. Kirman, and A. Nichol-son. </author> <title> Planning with deadlines in stochastic domains. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 574-579, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: A second popular approach has been to work with a constrained and highly structured problem representa tion, exemplified by the discrete Markov process-based planners <ref> [ 2, 1 ] </ref> . The model assumes a finite state space and a limited class of utility functions. <p> This representation form is used in [ 10 ] and utilized by work in Markov Decision Process <ref> [ 2, 1 ] </ref> . In that work an action condition or effect is specified by a set of propositional assignments, such as painted ^ : hold-block.
Reference: [3] <author> A. Doan and P. Haddawy. </author> <title> Generating macro operators for decision-theoretic planning. </title> <booktitle> In Working Notes of the AAAI Spring Symposium on Extending Theories of Action, </booktitle> <address> Stanford, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: We have implemented tools that automatically create inter-action abstractions [ 5 ] and sequential abstractions <ref> [ 3 ] </ref> . For a general theory of action abstraction which includes intra-action and sequential abstraction see [ 4 ] . 3.2 The drips Planner A planning problem is described in terms of an initial state distribution, a set of action descriptions, and a utility function.
Reference: [4] <author> A.H. Doan and P. Haddawy. </author> <title> Decision-theoretic refinement planning: Principles and application. </title> <type> Technical Report TR-95-01-01, </type> <institution> Dept. of Elect. Eng. & Computer Science, University of Wisconsin-Milwaukee, </institution> <month> January </month> <year> 1995. </year> <note> Available via anonymous FTP from pub/tech_reports at ftp.cs.uwm.edu. </note>
Reference-contexts: We have implemented tools that automatically create inter-action abstractions [ 5 ] and sequential abstractions [ 3 ] . For a general theory of action abstraction which includes intra-action and sequential abstraction see <ref> [ 4 ] </ref> . 3.2 The drips Planner A planning problem is described in terms of an initial state distribution, a set of action descriptions, and a utility function. The space of possible plans is described by an abstraction/decomposition network, supplied by the user.
Reference: [5] <author> M.G. Finigan. </author> <title> Knowledge acquisition for decision-theoretic planning. </title> <booktitle> In Proceedings MAICSS'95, </booktitle> <pages> pages 98-102, </pages> <address> Carbondale, IL, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: The condition on the abstract branch is the conjunction of the conditions on the paired branches; the probability is the product of the probabilities on the paired branches; and the effect is the composition of the effects. We have implemented tools that automatically create inter-action abstractions <ref> [ 5 ] </ref> and sequential abstractions [ 3 ] .
Reference: [6] <author> R.P. Goldman and M.S. Boddy. </author> <title> Epsilon-safe planning. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 253-261, </pages> <address> Seattle, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Researchers have taken various approaches to dealing with this complexity. One approach has been to focus on solving part of the problem by working with probabilities and categorical goals <ref> [ 10, 6 ] </ref> or by planning with goal-directed utility functions but under complete certainty [ 13 ] .
Reference: [7] <author> P. Haddawy and S. Hanks. </author> <title> Utility models for goal-directed decision-theoretic planners. </title> <type> Technical Report 93-06-04, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> June </month> <year> 1993. </year> <note> Available via anonymous FTP from ~ftp/pub/ai/ at cs.washington.edu. </note>
Reference-contexts: This should lead to increased search efficiency. In the rest of this section, we present sensitivity analysis for a general utility model proposed <ref> [ 7 ] </ref> . The expected utility of a plan p is the sum of the utilities of the possible chronicles weighted by the probability of each chronicle EU (p) = P c2fchroniclesg U (c) P (c).
Reference: [8] <editor> Hillner BE, Philbrick JT, Becker DM. </editor> <title> Optimal management of suspected lower-extremity deep vein thrombosis: an evaluation with cost assessment of 24 management strategies. </title> <journal> Arch Intern Med, </journal> <volume> 152 </volume> <pages> 165-175, </pages> <year> 1992. </year>
Reference-contexts: To evaluate the effectiveness of drips, we con structed a model for diagnosis and treatment of DVT 1 , based on data from an article that compared various different management strategies <ref> [ 8 ] </ref> . To encompass all of the strategies described in the original model, our model incorporated up to four tests, with a maximum of three 7-day waiting periods between tests. <p> This was verified by comparison with a decision-tree evaluation algorithm. The results produced by drips differed from those reported in the reference manuscript <ref> [ 8 ] </ref> . In reviewing these results, we discovered that drips had uncovered an error in the original study [ 9 ] .
Reference: [9] <author> CE Kahn, Jr and P Haddawy. </author> <title> Management of suspected lower-extremity deep venous thrombosis (letter). Archives of Internal Medicine, </title> <address> 155:426, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: This was verified by comparison with a decision-tree evaluation algorithm. The results produced by drips differed from those reported in the reference manuscript [ 8 ] . In reviewing these results, we discovered that drips had uncovered an error in the original study <ref> [ 9 ] </ref> .
Reference: [10] <author> N. Kushmerick, S. Hanks, and D. Weld. </author> <title> An algorithm for probabilistic least-commitment planning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1073-1078, </pages> <address> Seattle, </address> <year> 1994. </year>
Reference-contexts: Researchers have taken various approaches to dealing with this complexity. One approach has been to focus on solving part of the problem by working with probabilities and categorical goals <ref> [ 10, 6 ] </ref> or by planning with goal-directed utility functions but under complete certainty [ 13 ] . <p> The intended meaning of an action is that if the condition c i is satisfied at the beginning of the action then with probability p i the effect e i will be realized immediately following the action. This representation form is used in <ref> [ 10 ] </ref> and utilized by work in Markov Decision Process [ 2, 1 ] . In that work an action condition or effect is specified by a set of propositional assignments, such as painted ^ : hold-block.
Reference: [11] <author> M.P. Wellman. </author> <title> Formulation of Tradeoffs in Planning Under Uncertainty. </title> <publisher> Pitman, </publisher> <address> London,UK, </address> <year> 1990. </year>
Reference-contexts: A third approach uses qualitative techniques to filter out classes of obviously bad plans, thus avoiding costly plan evaluation <ref> [ 11 ] </ref> . While such qualitative dominance proving can be highly efficient, it requires much structure and is typically not powerful enough to identify the optimal plan. At some point one must resort to quantitative reasoning about expected utility in order to evaluate tradeoffs.
Reference: [12] <author> G. A. Whitmore and M. C. Findlay. </author> <title> Stochastic Dominance: An Approach to Decision Making Under Risk. </title> <address> D. C. </address> <publisher> Health and Company, </publisher> <address> Lexington, MA, </address> <year> 1978. </year>
Reference-contexts: A relation called stochastic dominance can be established between the probability distributions of two random variables if the two distributions satisfy certain constraints <ref> [ 12 ] </ref> . Random variables representing domain attributes at different time points are typically related to one another by formulas via action effect assignments, and transformations caused by actions often create dominance situations, which can be verified fairly easily without knowing the exact probability distributions of the random variables. <p> The dominance of P over Q can be used to to prove that p 1 has a higher expected utility than p 2 (or vice versa) <ref> [ 12 ] </ref> ; p 2 can then be eliminated from further consideration. DVT domain (b) for a DVT domain of 6,206 plans. We have successfully applied this technique to a variety of domains to reduce the number of plans before applying the drips algorithm.
Reference: [13] <author> M. Williamson and S. Hanks. </author> <title> Optimal planning with a goal-directed utility model. </title> <booktitle> In Proceedings of the Second International Conference on Artificial Intelligence Planning Systems, </booktitle> <pages> pages 176-181, </pages> <address> Chicago, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Researchers have taken various approaches to dealing with this complexity. One approach has been to focus on solving part of the problem by working with probabilities and categorical goals [ 10, 6 ] or by planning with goal-directed utility functions but under complete certainty <ref> [ 13 ] </ref> . These approaches are able to gain some efficiency by exploiting the structure that arises due to the use of categorical goals, deterministic actions, or restrictions on the form of the utility function.
References-found: 13

