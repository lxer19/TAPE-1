URL: ftp://www.cs.rutgers.edu/pub/technical-reports/lcsr-tr-196.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: 
Title: The CAM2000 Chip Architecture  
Author: D. Smith J. Hall K. Miyake 
Note: 1 This works was supported by the Defense Advanced Projects Agency and the National Aero nautics and Space Administration under NASA-Ames Research Center grant NAG 2-668  
Date: January 28, 1994  
Affiliation: Laboratory for Computer Science Research Department of Computer Science Rutgers University  
Abstract-found: 0
Intro-found: 1
Reference: [Blelloch, 1987] <author> Blelloch, G. </author> <year> (1987). </year> <title> Scans as primitive parallel operations. </title> <booktitle> In Proceedings of the 15th International Conference on Parallel Processing, </booktitle> <pages> pages 355-362, </pages> <address> University Park, PA. </address> <publisher> Pennsylvania State University Press. </publisher>
Reference-contexts: The parallel prefix/suffix operations are similar to those reported by Blelloch's <ref> [Blelloch, 1987, Blelloch, 1990] </ref>, but the CAM2000 architecture differs from Blelloch's in the fundamental regard that the CAM2000 architecture is a memory architecture and not a model for parallel computation. As such, the CAM2000 focuses on implementing memory-based prefix and suffix operations with simple, dedicated, efficient hardware.
Reference: [Blelloch, 1990] <author> Blelloch, G. </author> <year> (1990). </year> <title> Vector Models for Data-Parallel Computing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The parallel prefix/suffix operations are similar to those reported by Blelloch's <ref> [Blelloch, 1987, Blelloch, 1990] </ref>, but the CAM2000 architecture differs from Blelloch's in the fundamental regard that the CAM2000 architecture is a memory architecture and not a model for parallel computation. As such, the CAM2000 focuses on implementing memory-based prefix and suffix operations with simple, dedicated, efficient hardware.
Reference: [Hennessy and Patterson, 1990] <author> Hennessy, J. L. and Patterson, D. A. </author> <year> (1990). </year> <title> Computer Architecture A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address> <month> 32 </month>
Reference-contexts: The need for large, fast memories has been circumvented by cleverly designed memory systems and hierarchies that employ interleaved memories, static column DRAM <ref> [Hennessy and Patterson, 1990] </ref>, and multiple level caches [Hennessy and Patterson, 1990]. These systems rely on the local nature of information usage particular to the VonNeumann architecture to provide a memory system that performs as though it were a single large, fast memory. <p> The need for large, fast memories has been circumvented by cleverly designed memory systems and hierarchies that employ interleaved memories, static column DRAM <ref> [Hennessy and Patterson, 1990] </ref>, and multiple level caches [Hennessy and Patterson, 1990]. These systems rely on the local nature of information usage particular to the VonNeumann architecture to provide a memory system that performs as though it were a single large, fast memory. <p> They are implemented hierarchically using smaller and faster caches near the processor and larger slower memories near the main memory. The performance of such memory systems has been studied in detail over the last 10 years <ref> [Hennessy and Patterson, 1990] </ref> with the results indicating that typical programs produce memory access patterns with a high degree of clustering.
References-found: 3

