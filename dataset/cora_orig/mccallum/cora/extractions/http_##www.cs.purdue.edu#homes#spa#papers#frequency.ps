URL: http://www.cs.purdue.edu/homes/spa/papers/frequency.ps
Refering-URL: http://www.cs.purdue.edu/homes/spa/publications.html
Root-URL: http://www.cs.purdue.edu
Email: Mireille.Regnier@inria.fr spa@cs.purdue.edu  
Title: ON PATTERN FREQUENCY OCCURRENCES IN A MARKOVIAN  "Motifs dans les Sequences".  
Author: SEQUENCE? Mireille Regnier Wojciech Szpankowski 
Keyword: Key Words: Frequency of pattern occurrences, Markov source, empirical distribution, autocorrelation polynomials, languages, generating functions, asymptotic analysis, large deviations.  
Note: This research was supported by NATO Collaborative Grant CRG.950060. Part of this work was done during authors visits  This work was additionally supported by ESPRIT LTR Project No. 20244 (ALCOM-IT) and GREG  This research was additionally supported by NSF Grants CCR-9201078, NCR-9206315 and NCR 9415491.  
Address: 78153 Le Chesnay Cedex W. Lafayette, IN 47907 France U.S.A.  Rocquencourt.  
Affiliation: INRIA Department of Computer Science Rocquencourt Purdue University  at Purdue University and at INRIA,  
Date: May 20, 1997  
Abstract: Consider a given pattern H and a random text T generated by a Markovian source. We study the frequency of pattern occurrences in a random text when overlapping copies of the pattern are counted separately. We present exact and asymptotic formul for all moments (including the variance), and probability of r pattern occurrences for three different regions of r, namely: (i) r = O(1), (ii) central limit regime, and (iii) large deviations regime. In order to derive these results, we first construct some language expressions that characterize pattern occurrences which are later translated into generating functions. Finally, we use analytical methods to extract asymptotic behaviors of the pattern frequency. Applications of these results include molecular biology, source coding, synchronization, wireless communications, approximate pattern matching, games, and stock market analysis. These findings are of particular interest to information theory (e.g., second-order properties of the relative frequency), and molecular biology problems (e.g., finding patterns with unexpected high or low frequencies, and gene recognition). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.Barbara, and T.Imielinski, </author> <title> Sleepers and Workoholics Caching in Mobile Wireless Environments, </title> <booktitle> Proc. ACM SIGMOD, </booktitle> <pages> 1-15, </pages> <address> Minneapolis 1994 </address>
Reference-contexts: One of the most fundamental questions arising in such studies is the frequency of pattern occurrences in another string known as text. Applications of these results include wireless communications (cf. <ref> [1] </ref>), approximate pattern matching (cf. [22]), molecular biology (cf. [31]), games, code synchronization, (cf. [17, 18, 19]), source coding (cf. [7], stock market analysis, and so forth. <p> In fact, this work and the one by Fudos et al. [13] were motivated by problems arising in approximate pattern matching by q-grams (cf. [22]), developing performance models for database systems in wireless communications (cf. <ref> [1] </ref>), and gene recognition in a DNA sequence (cf. [31]), respectively. Actually, one of the earliest application appears to be in code synchronization (cf. [17]).
Reference: [2] <author> E. Bender, </author> <title> Central and Local Limit Theorems Applied to Asymptotic Enumeration, </title> <journal> J. Combin. Theory, Ser. A, </journal> <volume> 15, </volume> <pages> 91-111, </pages> <year> 1973. </year>
Reference: [3] <author> S. Breen, M. Waterman and N. Zhang, </author> <title> Renewal Theory for Several Patterns, </title> <journal> J. Appl. Prob., </journal> <volume> 22, </volume> <pages> 228-234, </pages> <year> 1985. </year>
Reference-contexts: In the Markovian model, the next symbol depends on a finite number of previous symbols. Pattern occurrences in a random string is a classical problem. Feller [10] already in 1968 suggested a solution in his book. Several other authors also contributed to this problem: e.g., see <ref> [3, 5, 21, 26] </ref> and references there. However, the most important recent contributions belong to Guibas and Odlyzko, who in a series of papers (cf. [17, 18, 19]) laid the foundations of the analysis for the symmetric Bernoulli model. <p> Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. Some other contributions are <ref> [3, 15, 23, 24, 29, 31, 38] </ref>. In this paper, we provide a complete description of the frequency of pattern occurrences in a random text generated according either to the Bernoulli model or the Markovian model using a methodology that might be of interest to other problems on words. <p> Our goal is to estimate the frequency of multiple pattern occurrences in the text assuming either Bernoulli or Markovian model. To present our main findings we adopt some notation (cf. also <ref> [3, 17, 18, 21] </ref>).
Reference: [4] <author> J. Bucklew, and J. Sadowsky, </author> <title> A Contribution to the Theory of Chernoff Bounds, </title> <journal> IEEE Trans. Information Theory, </journal> <volume> 39, </volume> <pages> 249-254, </pages> <year> 1993. </year>
Reference-contexts: D. Case r = (1 + ffi)EO n Large deviations Finally, we consider the large deviations result. From (47) we conclude that lim log T n (e t ) = (t) : Thus, directly from Gartner-Ellis theorem <ref> [4, 8] </ref> we prove that lim log PrfO n &gt; nag n where, after defining ! a as a solution of 0 (t) = a, we obtain I (a) = a! a + (! a ) : A stronger version of the above, follows directly from Theorem 3.1 of [4]. <p> theorem [4, 8] we prove that lim log PrfO n &gt; nag n where, after defining ! a as a solution of 0 (t) = a, we obtain I (a) = a! a + (! a ) : A stronger version of the above, follows directly from Theorem 3.1 of <ref> [4] </ref>. To derive our result expressed in Theorem 2.2, we shall use (48) and the "shift of mean" technique as discussed below (cf. [4, 16, 20]). <p> To derive our result expressed in Theorem 2.2, we shall use (48) and the "shift of mean" technique as discussed below (cf. <ref> [4, 16, 20] </ref>). As in the central limit regime, we could use Cauchy's formula to compute the probability PrfO n = rg for r = EO n + xO ( p n). But, formula (48) is only good for x = O (1).
Reference: [5] <author> C. Chrysaphinou, and S. Papastavridis, </author> <title> The Occurrence of Sequence of Patterns in Repeated Dependent Experiments, </title> <booktitle> Theory of Probability and Applications, </booktitle> <pages> 167-173, </pages> <year> 1990. </year>
Reference-contexts: In the Markovian model, the next symbol depends on a finite number of previous symbols. Pattern occurrences in a random string is a classical problem. Feller [10] already in 1968 suggested a solution in his book. Several other authors also contributed to this problem: e.g., see <ref> [3, 5, 21, 26] </ref> and references there. However, the most important recent contributions belong to Guibas and Odlyzko, who in a series of papers (cf. [17, 18, 19]) laid the foundations of the analysis for the symmetric Bernoulli model. <p> Recently, Fudos et al. [13] computed the probability of exactly r occurrences of a pattern in a random text in the asymmetric Bernoulli model, just directly extending the results of Guibas and Odlyzko. The Markovian model was tackled by Li [26], Chrysaphinou and Papastavridis <ref> [5] </ref> who extended the Guibas and Odlyzko results 2 of no pattern occurrence to Markovian texts. Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. <p> This completes the proof of the theorem. Remark. The generating function of language T j 0 (no H occurrence with the last symbol of a word from T j 0 being j) in the Markov case were previously derived by Chrysaphinou and Papastavridis in <ref> [5] </ref>.
Reference: [6] <author> M. Crochemore and W. Rytter, </author> <title> Text Algorithms, </title> <publisher> Oxford University Press, </publisher> <address> New York 1995. </address>
Reference: [7] <author> I. Csiszar and J. Korner, </author> <title> Information Theory: Coding Theorems for Discrete Memo-ryless Systems, </title> <publisher> Academic Press, </publisher> <address> New York 1981. </address>
Reference-contexts: Applications of these results include wireless communications (cf. [1]), approximate pattern matching (cf. [22]), molecular biology (cf. [31]), games, code synchronization, (cf. [17, 18, 19]), source coding (cf. <ref> [7] </ref>, stock market analysis, and so forth. <p> In information theory, relative frequency defined as n = O n =(n m + 1), where m is the length of the pattern, is often used to assess statistics of information sources. It is well known <ref> [7, 28] </ref> that n converges almost surely to the probability P (H) of the pattern H, but much less is known about second-order properties of n such as limiting distribution, large deviations, and rate of convergence. <p> Our results characterize precisely such a convergence in the central limit regime and the large deviations regime. Finally, results of this paper should shed more light on second-order properties of the powerful method of typical types <ref> [7] </ref>. This paper is organized as follows. In the next section, we present our main results and their consequences. The proofs are delayed until the last section. Our derivation in Section 3.1 use a language approach, thus is also valid for Markovian models since no probabilistic assumption is made. <p> For example, the relative frequency is an important concept in information theory, and it is defined as n (H) = n m + 1 Relative frequency appears in the definition of types and typical types (cf. <ref> [7] </ref>), and is often used to estimate information source statistics. <p> These results should be compared with first-order properties of n (H) discussed in <ref> [7, 28] </ref>.
Reference: [8] <author> R. Ellis, </author> <title> Large Deviations for a General Class of Random Vectors, </title> <journal> Ann. Probab., </journal> <pages> 1-12, </pages> <year> 1984. </year>
Reference-contexts: D. Case r = (1 + ffi)EO n Large deviations Finally, we consider the large deviations result. From (47) we conclude that lim log T n (e t ) = (t) : Thus, directly from Gartner-Ellis theorem <ref> [4, 8] </ref> we prove that lim log PrfO n &gt; nag n where, after defining ! a as a solution of 0 (t) = a, we obtain I (a) = a! a + (! a ) : A stronger version of the above, follows directly from Theorem 3.1 of [4].
Reference: [9] <author> J. Fickett, </author> <title> Recognition of Protein Coding Regions in DNA Sequences, </title> <journal> Nucleic Acids Res., </journal> <volume> 10, </volume> <pages> 5303-5318, </pages> <year> 1982. </year>
Reference-contexts: Two problems of molecular biology can benefit from these results, namely: finding patterns with unexpected (high or low) frequencies (the so called contrast words) [14], and recognizing genes by statistical properties <ref> [9] </ref>. Statistical methods have been successfully used from the early 80's to extract information from sequences of DNA. In particular, identifying deviant short motifs, the frequency of which is either too high or too low, might point out unknown biological information (cf. [9] and others for the analysis of functions of <p> words) [14], and recognizing genes by statistical properties <ref> [9] </ref>. Statistical methods have been successfully used from the early 80's to extract information from sequences of DNA. In particular, identifying deviant short motifs, the frequency of which is either too high or too low, might point out unknown biological information (cf. [9] and others for the analysis of functions of contrast words in DNA texts). From this perspective, our results give estimates for the statistical significance of deviations of word occurrences from the expected values and allow a biologist to build a dictionary of contrast words in genetic texts.
Reference: [10] <author> W. Feller, </author> <title> An Introduction to Probability and its Applications, </title> <journal> Vol. </journal> <volume> 1, </volume> <publisher> John Wiley & Sons, </publisher> <address> New York 1968. </address>
Reference-contexts: In the Markovian model, the next symbol depends on a finite number of previous symbols. Pattern occurrences in a random string is a classical problem. Feller <ref> [10] </ref> already in 1968 suggested a solution in his book. Several other authors also contributed to this problem: e.g., see [3, 5, 21, 26] and references there.
Reference: [11] <author> P. Flajolet and M. Soria, </author> <title> General Combinatorial Schemas: Gaussian Limit Distributions and Exponential Tails, </title> <journal> Discrete Mathematics, </journal> <volume> 114, </volume> <pages> 159-180, </pages> <year> 1993. </year>
Reference: [12] <author> P. Flajolet, X. Gourdon, C. Martinez, </author> <title> Patterns in Random Binary Search Trees, Random Structures and Algorithms, </title> <note> to appear. </note>
Reference-contexts: Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. <ref> [12] </ref> considered pattern occurrences in a random tree. Some other contributions are [3, 15, 23, 24, 29, 31, 38].
Reference: [13] <author> I. Fudos, E. Pitoura and W. Szpankowski, </author> <title> On Pattern Occurrences in a Random Text, </title> <journal> Information Processing Letters, </journal> <volume> 57, </volume> <pages> 307-312, </pages> <year> 1996. </year>
Reference-contexts: Applications of these results include wireless communications (cf. [1]), approximate pattern matching (cf. [22]), molecular biology (cf. [31]), games, code synchronization, (cf. [17, 18, 19]), source coding (cf. [7], stock market analysis, and so forth. In fact, this work and the one by Fudos et al. <ref> [13] </ref> were motivated by problems arising in approximate pattern matching by q-grams (cf. [22]), developing performance models for database systems in wireless communications (cf. [1]), and gene recognition in a DNA sequence (cf. [31]), respectively. Actually, one of the earliest application appears to be in code synchronization (cf. [17]). <p> Furthermore, Guibas and Odlyzko [19] in a passing remark also presented some basic results for several pattern occurrences in a random text for the symmetric Bernoulli model, and for the probability of no occurrence of a given pattern in the asymmetric Bernoulli model. Recently, Fudos et al. <ref> [13] </ref> computed the probability of exactly r occurrences of a pattern in a random text in the asymmetric Bernoulli model, just directly extending the results of Guibas and Odlyzko.
Reference: [14] <author> M.S. Gelfand, </author> <title> Prediction of Function in DNA Sequence Analysis, </title> <journal> J. Comput. Biol., </journal> <volume> 2, </volume> <pages> 87-117, </pages> <year> 1995. </year>
Reference-contexts: Our results should be of particular interest to information theory (e.g., relative frequency, code synchronization, source coding, etc.) and molecular biology. Two problems of molecular biology can benefit from these results, namely: finding patterns with unexpected (high or low) frequencies (the so called contrast words) <ref> [14] </ref>, and recognizing genes by statistical properties [9]. Statistical methods have been successfully used from the early 80's to extract information from sequences of DNA.
Reference: [15] <author> M. Geske, A. Godbole, A. Schafner, A. Skolnick, G. Wallstrom, </author> <title> Compound Poisson Approximations for World Patterns Under Markovian Hypotheses, </title> <journal> J. Appl. Prob., </journal> <volume> 32, </volume> <pages> 877-892, </pages> <year> 1995. </year>
Reference-contexts: Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. Some other contributions are <ref> [3, 15, 23, 24, 29, 31, 38] </ref>. In this paper, we provide a complete description of the frequency of pattern occurrences in a random text generated according either to the Bernoulli model or the Markovian model using a methodology that might be of interest to other problems on words. <p> Namely, (i) r = O (1), (ii) r = EO n + x p for x = O (1) (i.e., central limit regime), and (iii) r = (1 + ffi)EO n (i.e., large deviations regime). For our results to hold we assume that nP (H) ! 1 (see <ref> [15] </ref> for other regimes of nP (H)). However, for a given pattern H it is natural to assume that the length of the pattern is constant with respect to n (and we adopt throughout this assumption).
Reference: [16] <author> D. Greene and D. E. Knuth, </author> <title> Mathematics for the Analysis of Algorithms, </title> <publisher> Birkhauser, </publisher> <address> Boston 1990. </address> <month> 21 </month>
Reference-contexts: Actually, we can proceed as in Greene and Knuth <ref> [16] </ref> or Hwang [20] to obtain much more refined local limit result. For example, a direct application of results from [16] (cf. <p> Actually, we can proceed as in Greene and Knuth <ref> [16] </ref> or Hwang [20] to obtain much more refined local limit result. For example, a direct application of results from [16] (cf. Chap. 4.3.3) leads to the following for x = o (n 1=6 ) PrfO n = EO n + x p 1 2nc 1 2 x 2 1 2c 1 n x 3 + O (n 3=2 ) ; (48) where 3 a constant (i.e., the third cumulant). <p> To derive our result expressed in Theorem 2.2, we shall use (48) and the "shift of mean" technique as discussed below (cf. <ref> [4, 16, 20] </ref>). As in the central limit regime, we could use Cauchy's formula to compute the probability PrfO n = rg for r = EO n + xO ( p n). But, formula (48) is only good for x = O (1).
Reference: [17] <author> L. Guibas and A. Odlyzko, </author> <title> Maximal Prefix-Synchronized Codes, </title> <journal> SIAM J. Appl. Math, </journal> <volume> 35, </volume> <pages> 401-418, </pages> <year> 1978. </year>
Reference-contexts: One of the most fundamental questions arising in such studies is the frequency of pattern occurrences in another string known as text. Applications of these results include wireless communications (cf. [1]), approximate pattern matching (cf. [22]), molecular biology (cf. [31]), games, code synchronization, (cf. <ref> [17, 18, 19] </ref>), source coding (cf. [7], stock market analysis, and so forth. <p> Actually, one of the earliest application appears to be in code synchronization (cf. <ref> [17] </ref>). We study the problem in a probabilistic framework in which the text is generated randomly either by a memoryless source (the so called Bernoulli model) or by a Markovian source (the so called Markovian model). <p> Feller [10] already in 1968 suggested a solution in his book. Several other authors also contributed to this problem: e.g., see [3, 5, 21, 26] and references there. However, the most important recent contributions belong to Guibas and Odlyzko, who in a series of papers (cf. <ref> [17, 18, 19] </ref>) laid the foundations of the analysis for the symmetric Bernoulli model. In particular, the authors of [19] computed the moment generating function for the number of strings of length n that do not contain any one of a given set of patterns. <p> Our goal is to estimate the frequency of multiple pattern occurrences in the text assuming either Bernoulli or Markovian model. To present our main findings we adopt some notation (cf. also <ref> [3, 17, 18, 21] </ref>).
Reference: [18] <author> L. Guibas and A. Odlyzko, </author> <title> Periods in Strings, </title> <journal> J. Combin.Theory Ser. A, </journal> <volume> 30, </volume> <pages> 19-43, </pages> <year> 1981. </year>
Reference-contexts: One of the most fundamental questions arising in such studies is the frequency of pattern occurrences in another string known as text. Applications of these results include wireless communications (cf. [1]), approximate pattern matching (cf. [22]), molecular biology (cf. [31]), games, code synchronization, (cf. <ref> [17, 18, 19] </ref>), source coding (cf. [7], stock market analysis, and so forth. <p> Feller [10] already in 1968 suggested a solution in his book. Several other authors also contributed to this problem: e.g., see [3, 5, 21, 26] and references there. However, the most important recent contributions belong to Guibas and Odlyzko, who in a series of papers (cf. <ref> [17, 18, 19] </ref>) laid the foundations of the analysis for the symmetric Bernoulli model. In particular, the authors of [19] computed the moment generating function for the number of strings of length n that do not contain any one of a given set of patterns. <p> Our goal is to estimate the frequency of multiple pattern occurrences in the text assuming either Bernoulli or Markovian model. To present our main findings we adopt some notation (cf. also <ref> [3, 17, 18, 21] </ref>).
Reference: [19] <author> L. Guibas and A. W. Odlyzko, </author> <title> String Overlaps, Pattern Matching, and Nontransitive Games, </title> <journal> J. Combin.Theory Ser. A, </journal> <volume> 30, </volume> <pages> 183-208, </pages> <year> 1981. </year>
Reference-contexts: One of the most fundamental questions arising in such studies is the frequency of pattern occurrences in another string known as text. Applications of these results include wireless communications (cf. [1]), approximate pattern matching (cf. [22]), molecular biology (cf. [31]), games, code synchronization, (cf. <ref> [17, 18, 19] </ref>), source coding (cf. [7], stock market analysis, and so forth. <p> Feller [10] already in 1968 suggested a solution in his book. Several other authors also contributed to this problem: e.g., see [3, 5, 21, 26] and references there. However, the most important recent contributions belong to Guibas and Odlyzko, who in a series of papers (cf. <ref> [17, 18, 19] </ref>) laid the foundations of the analysis for the symmetric Bernoulli model. In particular, the authors of [19] computed the moment generating function for the number of strings of length n that do not contain any one of a given set of patterns. <p> However, the most important recent contributions belong to Guibas and Odlyzko, who in a series of papers (cf. [17, 18, 19]) laid the foundations of the analysis for the symmetric Bernoulli model. In particular, the authors of <ref> [19] </ref> computed the moment generating function for the number of strings of length n that do not contain any one of a given set of patterns. Certainly, this suffices to estimate the probability of at least one pattern occurrence in a random string generated by the symmetric Bernoulli model. <p> Certainly, this suffices to estimate the probability of at least one pattern occurrence in a random string generated by the symmetric Bernoulli model. Furthermore, Guibas and Odlyzko <ref> [19] </ref> in a passing remark also presented some basic results for several pattern occurrences in a random text for the symmetric Bernoulli model, and for the probability of no occurrence of a given pattern in the asymmetric Bernoulli model.
Reference: [20] <author> H-K. Hwang, </author> <title> Theoremes Limites Pour les Structures Combinatoires et les Fonctions Arithmetiques, </title> <institution> These de Doctorat de l'Ecole Polytechnique, </institution> <year> 1994. </year>
Reference-contexts: Actually, we can proceed as in Greene and Knuth [16] or Hwang <ref> [20] </ref> to obtain much more refined local limit result. For example, a direct application of results from [16] (cf. <p> To derive our result expressed in Theorem 2.2, we shall use (48) and the "shift of mean" technique as discussed below (cf. <ref> [4, 16, 20] </ref>). As in the central limit regime, we could use Cauchy's formula to compute the probability PrfO n = rg for r = EO n + xO ( p n). But, formula (48) is only good for x = O (1).
Reference: [21] <author> P. Jacquet and W. Szpankowski, </author> <title> Autocorrelation on Words and Its Applications. Analysis of Suffix Trees by String-Ruler Approach, </title> <journal> J. Combin.Theory Ser. A, </journal> <volume> 66, </volume> <pages> 237-269, </pages> <year> 1994. </year>
Reference-contexts: In the Markovian model, the next symbol depends on a finite number of previous symbols. Pattern occurrences in a random string is a classical problem. Feller [10] already in 1968 suggested a solution in his book. Several other authors also contributed to this problem: e.g., see <ref> [3, 5, 21, 26] </ref> and references there. However, the most important recent contributions belong to Guibas and Odlyzko, who in a series of papers (cf. [17, 18, 19]) laid the foundations of the analysis for the symmetric Bernoulli model. <p> Our goal is to estimate the frequency of multiple pattern occurrences in the text assuming either Bernoulli or Markovian model. To present our main findings we adopt some notation (cf. also <ref> [3, 17, 18, 21] </ref>).
Reference: [22] <author> P. Jokinen and E. Ukkonen, </author> <title> Two Algorithms for Approximate String Matching in Static Texts, </title> <booktitle> Proc. MFCS 91, Lecture Notes in Computer Science 520, </booktitle> <pages> 240-248, </pages> <publisher> Springer Verlag 1991. </publisher>
Reference-contexts: One of the most fundamental questions arising in such studies is the frequency of pattern occurrences in another string known as text. Applications of these results include wireless communications (cf. [1]), approximate pattern matching (cf. <ref> [22] </ref>), molecular biology (cf. [31]), games, code synchronization, (cf. [17, 18, 19]), source coding (cf. [7], stock market analysis, and so forth. In fact, this work and the one by Fudos et al. [13] were motivated by problems arising in approximate pattern matching by q-grams (cf. [22]), developing performance models for <p> approximate pattern matching (cf. <ref> [22] </ref>), molecular biology (cf. [31]), games, code synchronization, (cf. [17, 18, 19]), source coding (cf. [7], stock market analysis, and so forth. In fact, this work and the one by Fudos et al. [13] were motivated by problems arising in approximate pattern matching by q-grams (cf. [22]), developing performance models for database systems in wireless communications (cf. [1]), and gene recognition in a DNA sequence (cf. [31]), respectively. Actually, one of the earliest application appears to be in code synchronization (cf. [17]).
Reference: [23] <author> S. Karlin, C. Bruge and A. Campbell, </author> <title> Statistical Analysis of Counts and Distributions of Restriction Sites in DNA Sequences, Nucl. </title> <journal> Acids Res., </journal> <volume> 20, </volume> <pages> 1363-1370, </pages> <year> 1992. </year>
Reference-contexts: Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. Some other contributions are <ref> [3, 15, 23, 24, 29, 31, 38] </ref>. In this paper, we provide a complete description of the frequency of pattern occurrences in a random text generated according either to the Bernoulli model or the Markovian model using a methodology that might be of interest to other problems on words.
Reference: [24] <author> S. Karlin and F. </author> <title> Ost, Counts of Long Aligned Word Matches Among Random Letter Sequences, </title> <journal> Ann. Prob., </journal> <volume> 19, </volume> <pages> 293-351, </pages> <year> 1987. </year>
Reference-contexts: Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. Some other contributions are <ref> [3, 15, 23, 24, 29, 31, 38] </ref>. In this paper, we provide a complete description of the frequency of pattern occurrences in a random text generated according either to the Bernoulli model or the Markovian model using a methodology that might be of interest to other problems on words.
Reference: [25] <author> D.E. Knuth, </author> <booktitle> The Art of Computer Programming: Fundamental Algorithms, </booktitle> <volume> vol. 1., </volume> <publisher> Addison-Wesley, </publisher> <address> Reading 1973 </address> . 
Reference: [26] <author> S. R. Li, </author> <title> A Martingale Approach to the Study of Occurrences of Sequence Patterns in Repeated Experiments, </title> <journal> Ann. Probab., </journal> <volume> 8, </volume> <pages> 1171-1176, </pages> <year> 1980. </year>
Reference-contexts: In the Markovian model, the next symbol depends on a finite number of previous symbols. Pattern occurrences in a random string is a classical problem. Feller [10] already in 1968 suggested a solution in his book. Several other authors also contributed to this problem: e.g., see <ref> [3, 5, 21, 26] </ref> and references there. However, the most important recent contributions belong to Guibas and Odlyzko, who in a series of papers (cf. [17, 18, 19]) laid the foundations of the analysis for the symmetric Bernoulli model. <p> Recently, Fudos et al. [13] computed the probability of exactly r occurrences of a pattern in a random text in the asymmetric Bernoulli model, just directly extending the results of Guibas and Odlyzko. The Markovian model was tackled by Li <ref> [26] </ref>, Chrysaphinou and Papastavridis [5] who extended the Guibas and Odlyzko results 2 of no pattern occurrence to Markovian texts. Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model.
Reference: [27] <author> T. Luczak and W. Szpankowski, </author> <title> A Suboptimal Lossy Data Compression Based on Approximate Pattern Matching, </title> <journal> IEEE Trans. Information Theory, </journal> <volume> 43, 5, </volume> <year> 1997. </year>
Reference-contexts: The rate of convergence to the source entropy which is related to the rate of convergence of the relative frequency [28] have recently appeared in the formulation of some results on data compression (cf. <ref> [27, 36, 37, 40] </ref>). Marton and Shields [28] proved that n converges exponentially fast to P (H) for sources satisfying the so called blow-up property (e.g., Markov sources, hidden Markov, etc). Our results characterize precisely such a convergence in the central limit regime and the large deviations regime.
Reference: [28] <author> K. Marton and P. Shields, </author> <title> The Positive-Divergence and Blowing-up Properties, </title> <journal> Israel J. Math, </journal> <volume> 80, </volume> <month> 331-348 </month> <year> (1994). </year>
Reference-contexts: In information theory, relative frequency defined as n = O n =(n m + 1), where m is the length of the pattern, is often used to assess statistics of information sources. It is well known <ref> [7, 28] </ref> that n converges almost surely to the probability P (H) of the pattern H, but much less is known about second-order properties of n such as limiting distribution, large deviations, and rate of convergence. <p> The rate of convergence to the source entropy which is related to the rate of convergence of the relative frequency <ref> [28] </ref> have recently appeared in the formulation of some results on data compression (cf. [27, 36, 37, 40]). Marton and Shields [28] proved that n converges exponentially fast to P (H) for sources satisfying the so called blow-up property (e.g., Markov sources, hidden Markov, etc). <p> The rate of convergence to the source entropy which is related to the rate of convergence of the relative frequency <ref> [28] </ref> have recently appeared in the formulation of some results on data compression (cf. [27, 36, 37, 40]). Marton and Shields [28] proved that n converges exponentially fast to P (H) for sources satisfying the so called blow-up property (e.g., Markov sources, hidden Markov, etc). Our results characterize precisely such a convergence in the central limit regime and the large deviations regime. <p> These results should be compared with first-order properties of n (H) discussed in <ref> [7, 28] </ref>.
Reference: [29] <author> P. T. Nielsen, </author> <title> On the Expected Duration of a Search for Fixed Pattern in Random Data, </title> <journal> IEEE Trans. Information Theory, </journal> <pages> 702-704, </pages> <year> 1973. </year>
Reference-contexts: Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. Some other contributions are <ref> [3, 15, 23, 24, 29, 31, 38] </ref>. In this paper, we provide a complete description of the frequency of pattern occurrences in a random text generated according either to the Bernoulli model or the Markovian model using a methodology that might be of interest to other problems on words.
Reference: [30] <author> A. Odlyzko, </author> <title> Asymptotic Enumeration, </title> <booktitle> in Handbook of Combinatorics, </booktitle> <volume> Vol. II, </volume> <editor> (Eds. R. Graham, M. Gotschel and L. Lovasz), </editor> <publisher> Elsevier Science, </publisher> <year> 1995. </year>
Reference: [31] <author> P. Pevzner, M. Borodovsky, and A. Mironov, </author> <title> Linguistic of Nucleotide Sequences: The Significance of Deviations from Mean: Statistical Characteristics and Prediction of the Frequency of Occurrence of Words, </title> <journal> J. Biomol. Struct. Dynam., </journal> <volume> 6, </volume> <pages> 1013-1026, </pages> <year> 1991. </year>
Reference-contexts: One of the most fundamental questions arising in such studies is the frequency of pattern occurrences in another string known as text. Applications of these results include wireless communications (cf. [1]), approximate pattern matching (cf. [22]), molecular biology (cf. <ref> [31] </ref>), games, code synchronization, (cf. [17, 18, 19]), source coding (cf. [7], stock market analysis, and so forth. <p> In fact, this work and the one by Fudos et al. [13] were motivated by problems arising in approximate pattern matching by q-grams (cf. [22]), developing performance models for database systems in wireless communications (cf. [1]), and gene recognition in a DNA sequence (cf. <ref> [31] </ref>), respectively. Actually, one of the earliest application appears to be in code synchronization (cf. [17]). <p> Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. Some other contributions are <ref> [3, 15, 23, 24, 29, 31, 38] </ref>. In this paper, we provide a complete description of the frequency of pattern occurrences in a random text generated according either to the Bernoulli model or the Markovian model using a methodology that might be of interest to other problems on words. <p> Our results allow an easy computation of all moments, using for instance a symbolic computation system. We observe that the evaluation of the variance was quite challenging in the past as pointed out in <ref> [31] </ref> and [32]. It turns out that the variance depends on the internal structure of the pattern through the so called autocorrelation polynomial. Actually, Prum et al. [32] suggested two statistical methods to estimate the variance which should be compared with our computations (cf. Theorem 2.2, and Section 3).
Reference: [32] <author> B. Prum, F. Rodolphe, and E. Turckheim, </author> <title> Finding Words with Unexpected Frequencies in Deoxyribonucleic Acid Sequence, J.R. </title> <journal> Stat. Soc. B, </journal> <volume> 57, </volume> <pages> 205-220, </pages> <year> 1995. </year> <month> 22 </month>
Reference-contexts: The Markovian model was tackled by Li [26], Chrysaphinou and Papastavridis [5] who extended the Guibas and Odlyzko results 2 of no pattern occurrence to Markovian texts. Recently, Prum et al. <ref> [32] </ref> (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. Some other contributions are [3, 15, 23, 24, 29, 31, 38]. <p> Our results allow an easy computation of all moments, using for instance a symbolic computation system. We observe that the evaluation of the variance was quite challenging in the past as pointed out in [31] and <ref> [32] </ref>. It turns out that the variance depends on the internal structure of the pattern through the so called autocorrelation polynomial. Actually, Prum et al. [32] suggested two statistical methods to estimate the variance which should be compared with our computations (cf. Theorem 2.2, and Section 3). <p> We observe that the evaluation of the variance was quite challenging in the past as pointed out in [31] and <ref> [32] </ref>. It turns out that the variance depends on the internal structure of the pattern through the so called autocorrelation polynomial. Actually, Prum et al. [32] suggested two statistical methods to estimate the variance which should be compared with our computations (cf. Theorem 2.2, and Section 3). We also estimate asymptotically the probability of exact r occurrences of the pattern for three different ranges of r (cf. Theorem 2.2).
Reference: [33] <author> R. Remmert, </author> <title> Theory of Complex Functions, </title> <publisher> Springer Verlag, </publisher> <address> New York 1991. </address>
Reference-contexts: We first re-write the formula on T (r) (z) as follows: T (r) (z) = D r+1 : (43) PrfO n = rg is the coefficient at z n of T (r) (z). By Hadamard's theorem (cf. <ref> [33] </ref>), the asymptotics of the coefficients of T (r) (z) depend on the singularities of T (r) (z). In our case, the generating function is a rational function, thus we can only expect poles (which cause the denominator D H (z) to vanish). <p> The existence of a root is guaranteed when D H (z) is a polynomial. The property extends to the Markov case by the Rouche theorem. In view of the above, the generating function T (r) (z) can be expanded around z = H in the following Laurent's series (cf. <ref> [33, 39] </ref>): T (r) (z) = j=1 (z H ) j + e T (r) (z) (44) where e T (r) (z) is analytical in jzj &lt; 0 and 0 is defined as 0 = inffjj; &gt; H and D H () = 0g.
Reference: [34] <author> M. Regnier and W. Szpankowski, </author> <title> On the Approximate Pattern Occurrence in a Text, </title> <booktitle> Proc. </booktitle> <address> SEQUENCE'97, </address> <month> Positano </month> <year> 1997. </year>
Reference: [35] <author> S. Schbath, </author> <title> Etude Asymptotique du Nombre d'Occurrences d'un mot dans une Cha ^ ine de Markov et Application a la Recherche de Mots de Frequence Exceptionnelle dans les Sequences d'ADN, </title> <institution> These Universite Rene Descartes Paris V, </institution> <year> 1995. </year>
Reference-contexts: The Markovian model was tackled by Li [26], Chrysaphinou and Papastavridis [5] who extended the Guibas and Odlyzko results 2 of no pattern occurrence to Markovian texts. Recently, Prum et al. [32] (see also <ref> [35] </ref>) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. Some other contributions are [3, 15, 23, 24, 29, 31, 38].
Reference: [36] <author> W. Szpankowski, </author> <title> Asymptotic Properties of Data Compression and Suffix Trees, </title> <journal> IEEE Trans. Information Theory, </journal> <volume> 39, </volume> <pages> 1647-1659, </pages> <year> 1993. </year>
Reference-contexts: The rate of convergence to the source entropy which is related to the rate of convergence of the relative frequency [28] have recently appeared in the formulation of some results on data compression (cf. <ref> [27, 36, 37, 40] </ref>). Marton and Shields [28] proved that n converges exponentially fast to P (H) for sources satisfying the so called blow-up property (e.g., Markov sources, hidden Markov, etc). Our results characterize precisely such a convergence in the central limit regime and the large deviations regime.
Reference: [37] <author> W. Szpankowski, </author> <title> A Generalized Suffix Tree and Its (Un)Expected Asymptotic Behaviors, </title> <journal> SIAM J. Computing, </journal> <volume> 22, </volume> <month> 1176-1198 </month> <year> (1993). </year>
Reference-contexts: The rate of convergence to the source entropy which is related to the rate of convergence of the relative frequency [28] have recently appeared in the formulation of some results on data compression (cf. <ref> [27, 36, 37, 40] </ref>). Marton and Shields [28] proved that n converges exponentially fast to P (H) for sources satisfying the so called blow-up property (e.g., Markov sources, hidden Markov, etc). Our results characterize precisely such a convergence in the central limit regime and the large deviations regime.
Reference: [38] <author> M. Waterman, </author> <title> Introduction to Computational Biology, </title> <publisher> Chapman & Hall, </publisher> <address> New York 1995. </address>
Reference-contexts: Recently, Prum et al. [32] (see also [35]) obtained the limiting distribution for the number of pattern occurrences in the Markovian model. Finally, Flajolet et al. [12] considered pattern occurrences in a random tree. Some other contributions are <ref> [3, 15, 23, 24, 29, 31, 38] </ref>. In this paper, we provide a complete description of the frequency of pattern occurrences in a random text generated according either to the Bernoulli model or the Markovian model using a methodology that might be of interest to other problems on words.
Reference: [39] <editor> H. Wilf, generatingfunctionology, </editor> <publisher> Academic Press, </publisher> <address> Boston 1990. </address>
Reference-contexts: The existence of a root is guaranteed when D H (z) is a polynomial. The property extends to the Markov case by the Rouche theorem. In view of the above, the generating function T (r) (z) can be expanded around z = H in the following Laurent's series (cf. <ref> [33, 39] </ref>): T (r) (z) = j=1 (z H ) j + e T (r) (z) (44) where e T (r) (z) is analytical in jzj &lt; 0 and 0 is defined as 0 = inffjj; &gt; H and D H () = 0g. <p> The constants a j satisfy the formulae (22). This formula simplifies into (21) for the leading constant a r1 . As a consequence of analyticity <ref> [39] </ref> we have for 1 &lt; H &lt; &lt; 0 : [z n ] e T (r) (z) = O ( n ). Hence, the term e T (r) (z) contributes only to the lower terms in the asymptotic expansion of T (r) (z). <p> Hence, the term e T (r) (z) contributes only to the lower terms in the asymptotic expansion of T (r) (z). We need an asymptotic expansion for the first terms in (43). This is rather a standard computation (cf. <ref> [39] </ref>), but for the completeness we provide a short proof.
Reference: [40] <author> Z. Zhang and E. Yang, </author> <title> An On-Line Universal Lossy Data Compression Algorithm via Continuous Codebook Refinement Part II: Optimality for Phi-Mixing Source Models, </title> <journal> IEEE Trans. Information Theory, </journal> <volume> 42, </volume> <pages> 822-836, </pages> <year> 1996. </year> <month> 23 </month>
Reference-contexts: The rate of convergence to the source entropy which is related to the rate of convergence of the relative frequency [28] have recently appeared in the formulation of some results on data compression (cf. <ref> [27, 36, 37, 40] </ref>). Marton and Shields [28] proved that n converges exponentially fast to P (H) for sources satisfying the so called blow-up property (e.g., Markov sources, hidden Markov, etc). Our results characterize precisely such a convergence in the central limit regime and the large deviations regime.
References-found: 40

