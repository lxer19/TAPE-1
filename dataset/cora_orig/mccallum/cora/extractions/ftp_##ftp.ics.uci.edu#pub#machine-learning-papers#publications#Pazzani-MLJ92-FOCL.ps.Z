URL: ftp://ftp.ics.uci.edu/pub/machine-learning-papers/publications/Pazzani-MLJ92-FOCL.ps.Z
Refering-URL: http://www.ics.uci.edu/AI/ML/MLAbstracts.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: pazzani@ics.uci.edu kibler@ics.uci.edu  
Phone: (714) 856-5951  
Title: The Utility of Knowledge in Inductive Learning  Running Head: Knowledge in Inductive Learning  
Author: Michael Pazzani Dennis Kibler 
Address: Irvine, CA 92717 U.S.A.  
Affiliation: Department of Information Computer Science University of California, Irvine  
Abstract-found: 0
Intro-found: 1
Reference: <author> Bergadano, F., & Giordana, A. </author> <year> (1988). </year> <title> A knowledge intensive approach to concept induction. </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning (pp. </booktitle> <pages> 305-317). </pages> <address> Ann Arbor, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Due to its induction component and the algorithm EITHER uses to assign blame for proving a negative example or failing to prove a positive example, EITHER is restricted to using propositional domain theories and training examples represented as attribute-value pairs. 6.4 ML-SMART In many respects, FOCL is similar to ML-SMART <ref> (Bergadano & Giordana, 1988) </ref>. ML-SMART also is designed to deal with both overly general and overly specific domain theories. The major differences between ML-SMART and FOCL are involved with the search control strategy. FOCL uses hill climbing while ML-SMART uses best-first search.
Reference: <author> Bergadano, F., Giordana, A., & Ponsero, S. </author> <year> (1989). </year> <title> Deduction in top-down inductive learning. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 23-25). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The few systems that allow relational concept definitions (e.g., OCCAM (Pazzani, 1990), IOE (Flann & Dietterich, 1989), ML-SMART <ref> (Bergadano, Giordana, & Ponsero, 1989) </ref>) place strong restrictions on the form of induction and the initial knowledge that is provided to the system. The restricted concept definitions languages that are usually required by the empirical learning component, reduce the applicability of the integrated learning system.
Reference: <author> Cohen, W. </author> <year> (1990). </year> <title> Abductive explanation-based learning: A solution to the multiple explanation-problem (ML-TR-29). </title> <address> New Brunswick, NJ: </address> <institution> Rutgers University. </institution>
Reference-contexts: As already mentioned, FOCL allows Horn clause descriptions of the background knowledge. In addition, the provided target concept need not be correct or overly general. 6.2 A-EBL The A-EBL system <ref> (Cohen, 1990) </ref> is also designed to handle overly general domain theories. It operates by finding all proofs of all positive examples, and uses a greedy set covering algorithm to find a set of operational definitions that cover all positive examples and no negative examples.
Reference: <author> Danyluk, A. </author> <year> (1989). </year> <title> Finding new rules for incomplete theories: Explicit biases for induction with contextual information. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 34-36). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fisher, D. </author> <year> (1987). </year> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 139-172. </pages>
Reference-contexts: of prior knowledge that includes typing information, both extensionally and intensionally defined predicates, and an initial, approximate definition of the concept to be learned. 2 This taxonomy can be used to illuminate the similarities and differences be-tween the types of background knowledge used in a variety of systems including COBWEB <ref> (Fisher, 1987) </ref>, CIGOL (Muggleton & Buntine, 1988), and OCCAM (Pazzani, 1990). We demonstrate the effects of each form of knowledge with a complexity analysis of FOIL and with a series of experiments on learning concepts from the domains of list relations and chess end game relations.
Reference: <author> Flann, N., & Dietterich, T. </author> <year> (1989). </year> <title> A study of explanation-based methods for inductive learning. </title> <journal> Machine Learning, </journal> <volume> 4, </volume> <pages> 187-226. </pages>
Reference-contexts: Others effectively restrict the concept definition language to that of propositional calculus, by only allowing unary predicates (Hirsh, 1989; Mooney & Ourston, 1989; Katz, 1989; Shavlik & Towell, 1989; Pazzani, 1989; Sarrett & Pazzani, 1989). The few systems that allow relational concept definitions (e.g., OCCAM (Pazzani, 1990), IOE <ref> (Flann & Dietterich, 1989) </ref>, ML-SMART (Bergadano, Giordana, & Ponsero, 1989)) place strong restrictions on the form of induction and the initial knowledge that is provided to the system. The restricted concept definitions languages that are usually required by the empirical learning component, reduce the applicability of the integrated learning system. <p> Given a set of a examples and a correct domain theory, the output of FOCL is similar to that produced by m-EBG <ref> (Flann & Dietterich, 1989) </ref>. Without any background knowledge, FOCL operates like FOIL. The interesting issues arise when FOCL is given an incomplete or incorrect domain theory. <p> IOU operates by first forming a definition via a process similar to m-EBG <ref> (Flann & Dietterich, 1989) </ref> for the positive examples. Next, IOU removes any negative examples from the training set that are correctly classified by the results of m-EBG.
Reference: <author> Ginsberg, M., & Harvey, W. </author> <year> (1990). </year> <title> Iterative broadening. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 216-220). </pages> <address> Boston, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We also evaluate the benefit that these extensions have. After we have considered each of these extensions separately, we present the complete FOCL algorithm. 4 It is also similar to the iterative broadening technique <ref> (Ginsberg & Harvey, 1990) </ref> where heuristics are used to order the nodes expanded. In our case the heuristic is to favor nodes with few new variables. Their analysis was for constant branching factor and the success of the method relied on having enough goal nodes.
Reference: <author> Hirsh, H. </author> <year> (1989). </year> <title> Combining empirical and analytical learning with version spaces. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 29-33). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Katz, B. </author> <year> (1989). </year> <title> Integrating learning in a neural network. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 69-71). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Korf, R. E. </author> <year> (1985). </year> <title> Depth-first iterative-deepening: An optimal admissible tree search. </title> <journal> Artificial Intelligence, </journal> <volume> 1, </volume> <pages> 11-46. </pages>
Reference-contexts: As noted in Section 3, the theory-cost and the evaluation-cost grows exponentially in the number of distinct variables. Consequently, to lessen this cost, in FOCL, we have introduced an iterative widening search strategy 4 that is analogous to iterative depth-first search <ref> (Korf, 1985) </ref>. FOCL first attempts to learn a clause by introducing no free variables. If that fails (because a situation is encountered where no variablization of any predicate has positive gain), an attempt is made to learn the clause by allowing an additional free variable.
Reference: <author> Lebowitz, M. </author> <year> (1986). </year> <title> Integrated learning: Controlling explanation. </title> <journal> Cognitive Science, </journal> <volume> 10. </volume>
Reference: <author> Michalski, R. </author> <year> (1980). </year> <title> Pattern recognition as rule-guided inductive inference. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 2, </volume> <pages> 349-361. </pages> <note> 36 Mitchell, </note> <author> T., Keller, R., & Kedar-Cabelli, S. </author> <year> (1986). </year> <title> Explanation-based learning: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 47-80. </pages>
Reference-contexts: Like ID3 (Quinlan, 1986), FOIL is a non-incremental learner that hill climbs using a metric based on information theory to construct a rule that covers the data. Pagallo and Haussler (1990) introduced the idea of separate-and-conquer to define their GROVE and GREEDY3 algorithms. Unlike ID3 and like AQ <ref> (Michalski, 1980) </ref>, FOIL uses this separate-and-conquer approach rather than a divide-and-conquer approach. The separate stage of the algorithm begins a new clause while the conquer stage constructs a conjunction of literals to serve as the body of the clause.
Reference: <author> Mooney, R., & Ourston, D. </author> <year> (1989). </year> <title> Induction over the unexplained: Integrated learning of concepts with both explainable and conventional aspects. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 5-7). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Comparison to Related Work In this section, we compare FOCL to a variety of related work on either learning relational concepts or combining empirical and inductive learning methods, focusing on the types of knowledge exploited by the systems to constrain learning and how this knowledge is used. 6.1 IOU IOU <ref> (Mooney & Ourston, 1989) </ref> is a system that is designed to learn from overly general domain theories. IOU operates by first forming a definition via a process similar to m-EBG (Flann & Dietterich, 1989) for the positive examples.
Reference: <author> Muggleton, S., Bain, M., Hayes-Michie, J., & Michie, D. </author> <year> (1989). </year> <title> An experimental comparison of human and machine learning formalisms. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 115-118). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Muggleton, S., & Buntine, W. </author> <year> (1988). </year> <title> Machine invention of first-order predicates by inverting resolution. </title> <booktitle> Proceedings of the Fifth International Workshop on Machine Learning (pp. </booktitle> <pages> 339-352). </pages> <address> Ann Arbor, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: that includes typing information, both extensionally and intensionally defined predicates, and an initial, approximate definition of the concept to be learned. 2 This taxonomy can be used to illuminate the similarities and differences be-tween the types of background knowledge used in a variety of systems including COBWEB (Fisher, 1987), CIGOL <ref> (Muggleton & Buntine, 1988) </ref>, and OCCAM (Pazzani, 1990). We demonstrate the effects of each form of knowledge with a complexity analysis of FOIL and with a series of experiments on learning concepts from the domains of list relations and chess end game relations. <p> Systems such as CIGOL <ref> (Muggleton & Buntine, 1988) </ref> make use of (or invent) background knowledge of this form.
Reference: <author> Ourston, D., & Mooney, R. </author> <year> (1990). </year> <title> Chaining the rules: A comprehensive approach to theory refinement. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 815-820). </pages> <address> Boston, MA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Furthermore, due to its induction component, FOCL can learn from overly specific domain theories as well as overly general theories caused by a clause lacking a precondition (i.e., a missing literal), in addition to overly general domain theories caused by extra clauses. 6.3 EITHER Like FOCL, the EITHER system <ref> (Ourston & Mooney, 1990) </ref> is one of the few systems designed to work with either overly general or overly specific domain theories. Furthermore, unlike FOCL, EITHER revises incorrect domain theories, rather than just learning in spite of incorrect domain theories.
Reference: <author> Pagallo, G., & Haussler, D. </author> <year> (1990). </year> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 71-100. </pages>
Reference: <author> Pazzani, M. </author> <year> (1989). </year> <title> Explanation-based learning with weak domain theories. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 72-74). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Pazzani, M. J. </author> <year> (1990). </year> <title> Creating a memory of causal relationships: An integration of empirical and explanation-based learning methods. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Others effectively restrict the concept definition language to that of propositional calculus, by only allowing unary predicates (Hirsh, 1989; Mooney & Ourston, 1989; Katz, 1989; Shavlik & Towell, 1989; Pazzani, 1989; Sarrett & Pazzani, 1989). The few systems that allow relational concept definitions (e.g., OCCAM <ref> (Pazzani, 1990) </ref>, IOE (Flann & Dietterich, 1989), ML-SMART (Bergadano, Giordana, & Ponsero, 1989)) place strong restrictions on the form of induction and the initial knowledge that is provided to the system. <p> and intensionally defined predicates, and an initial, approximate definition of the concept to be learned. 2 This taxonomy can be used to illuminate the similarities and differences be-tween the types of background knowledge used in a variety of systems including COBWEB (Fisher, 1987), CIGOL (Muggleton & Buntine, 1988), and OCCAM <ref> (Pazzani, 1990) </ref>. We demonstrate the effects of each form of knowledge with a complexity analysis of FOIL and with a series of experiments on learning concepts from the domains of list relations and chess end game relations. We selected list relations primarily to illustrate the mechanism. <p> In fact, FOCL has been tested on a variety of problems, including a number of standard EBL problems, and a larger problem that includes a domain theory describing when a student loan is required to be repaid <ref> (Pazzani & Brunk, 1990) </ref>. 2 Background: FOIL In this section, we present a brief discussion of FOIL that will allow us to analyze its complexity and that of FOCL. We begin by introducing some definitions. A predicate is a Boolean function. <p> In the inductive portion of FOCL, facts are stored in hash tables that allow constant time retrieval. 4.7 Learning Non-Operational Concept Definitions A relatively minor modification to FOCL also allows it to learn non-operational concept definitions that can be used as target concepts for EBL <ref> (Pazzani & Brunk, 1990) </ref>. Presented with a domain theory, but no target concept, FOCL searches for all variablizations of all operational and non-operational predicates. As discussed in Section 4.4, FOCL then operationalizes any non-operational predicate variabliza-tion. By simply eliminating this operationalization process, FOCL can induce a non-operational concept definition.
Reference: <author> Pazzani, M., & Brunk, C. </author> <title> (1990) Detecting and correcting errors in rule-based expert systems: An integration of empirical and explanation-based learning. </title> <booktitle> Proceedings of the Workshop on Knowledge Acquisition for Knowledge-Based System. </booktitle> <address> Banff, Canada. </address>
Reference-contexts: Others effectively restrict the concept definition language to that of propositional calculus, by only allowing unary predicates (Hirsh, 1989; Mooney & Ourston, 1989; Katz, 1989; Shavlik & Towell, 1989; Pazzani, 1989; Sarrett & Pazzani, 1989). The few systems that allow relational concept definitions (e.g., OCCAM <ref> (Pazzani, 1990) </ref>, IOE (Flann & Dietterich, 1989), ML-SMART (Bergadano, Giordana, & Ponsero, 1989)) place strong restrictions on the form of induction and the initial knowledge that is provided to the system. <p> and intensionally defined predicates, and an initial, approximate definition of the concept to be learned. 2 This taxonomy can be used to illuminate the similarities and differences be-tween the types of background knowledge used in a variety of systems including COBWEB (Fisher, 1987), CIGOL (Muggleton & Buntine, 1988), and OCCAM <ref> (Pazzani, 1990) </ref>. We demonstrate the effects of each form of knowledge with a complexity analysis of FOIL and with a series of experiments on learning concepts from the domains of list relations and chess end game relations. We selected list relations primarily to illustrate the mechanism. <p> In fact, FOCL has been tested on a variety of problems, including a number of standard EBL problems, and a larger problem that includes a domain theory describing when a student loan is required to be repaid <ref> (Pazzani & Brunk, 1990) </ref>. 2 Background: FOIL In this section, we present a brief discussion of FOIL that will allow us to analyze its complexity and that of FOCL. We begin by introducing some definitions. A predicate is a Boolean function. <p> In the inductive portion of FOCL, facts are stored in hash tables that allow constant time retrieval. 4.7 Learning Non-Operational Concept Definitions A relatively minor modification to FOCL also allows it to learn non-operational concept definitions that can be used as target concepts for EBL <ref> (Pazzani & Brunk, 1990) </ref>. Presented with a domain theory, but no target concept, FOCL searches for all variablizations of all operational and non-operational predicates. As discussed in Section 4.4, FOCL then operationalizes any non-operational predicate variabliza-tion. By simply eliminating this operationalization process, FOCL can induce a non-operational concept definition.
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference-contexts: Conjoin L to NewClauseBody. Remove from NEG examples that do not satisfy L. predicates. In a restricted way, FOIL also allows the use of the predicate to be learned. In this way, FOIL can learn some recursive concepts. Like ID3 <ref> (Quinlan, 1986) </ref>, FOIL is a non-incremental learner that hill climbs using a metric based on information theory to construct a rule that covers the data. Pagallo and Haussler (1990) introduced the idea of separate-and-conquer to define their GROVE and GREEDY3 algorithms.
Reference: <author> Quinlan, J. R. </author> <year> (1989). </year> <title> Learning relations: Comparison of a symbolic and a connectionist approach (Technical Report). </title> <address> Sydney, Australia: </address> <institution> University of Sidney. </institution>
Reference: <author> Quinlan, J. R. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 239-266. </pages> <note> 37 Sarrett, </note> <author> W., & Pazzani, M. </author> <year> (1989). </year> <title> One-sided algorithms for integrating empirical and explanation-based learning. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 26-28). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: the clause, P 1 and N 1 are the number of positive and negative tuples after adding the literal to the clause, and T ++ is the number of positive tuples before adding the literal that have at least one corresponding extension in the positive tuples after adding the literal <ref> (Quinlan, 1990) </ref>. 5 Table 2: FOIL Design II Let POS be the positive tuples. Let NEG be the negative tuples. Set NewClauseBody to empty. Until POS is empty do: Separate: (begins new clauses) Remove from POS all tuples that satisfy the NewClauseBody. <p> This does not affect the accuracy of the resulting concept, but merely results in the induced theory having redundant clauses. A simple postprocessor could be added to detect and simplify the definition <ref> (Quinlan, 1990) </ref>. * Clause Addition: FOCL operationalizes clauses with maximum gain and it 27 is unlikely that randomly added clauses will have more gain. In effect, FOCL uses information gain as a method to find a subset of the domain theory that is accurate.
Reference: <author> Shavlik, J., & Towell, G. </author> <year> (1989). </year> <title> Combining explanation-based learning and artificial neural networks. </title> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 90-93). </pages> <address> Ithaca, NY: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Widmer, G. </author> <year> (1990). </year> <title> Incremental knowledge-intensive learning: A case study based on an extension to Bergadano & Giordana's integrated learning strategy (Technical Report). </title> <booktitle> Austrian Research Institute for Artificial Intelligence. </booktitle> <pages> 38 </pages>
Reference-contexts: For the subsequent discussion we regard an operational predicate as one that is given extensionally. If a predicate is defined by other predicates, we say the definition is non-operational. Such an initial rule might be provided by a teacher, or, in an incremental learning system <ref> (e.g., Widmer, 1990) </ref>, learned from an initial subset of the examples. The extension to FOCL to use a partial, operational Horn clause rule is straightforward.
References-found: 25

