URL: http://www.cs.tamu.edu/people/miket/lpr.ps.gz
Refering-URL: http://www.cs.tamu.edu/people/miket/
Root-URL: http://www.cs.tamu.edu
Email: miket@cs.tamu.edu  
Title: Implementation and Evaluation of Primal and Dual Simplex Methods with Different Pivot-Selection Techniques in the
Author: Michael E. Thomadakis 
Date: May 7, 1994  
Address: College Station, TX 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Bartels, R. H. and G. H. Golub, </author> <title> "The Simplex Method of Linear Programming using LU Decomposition," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 12, </volume> <pages> pp. 266-268, </pages> <year> 1969. </year>
Reference-contexts: Definition 29 The determinant of a n fi n matrix A = (a ij ) is defined to be the number j A j given by X fga 1i 1 a 2i 2 : : : a ni n ; (4.1) where the sum is taken over all possible permutations <ref> [1; 2; : : :; n] </ref> of the second subscript of (4.1). <p> There are n! terms in (4.1) and a term is assigned a plus sign if (i 1 ; i 2 ; : : :; i n ) T 2 <ref> [1; 2; : : : ; n] </ref> is an even permutation, and a minus sign is it is an odd permutation. Definition 30 1. For any m fi n matrix A consider the submatrix R obtained by deleting all but k rows and k columns of A. <p> chapter is based on material in [2], [16], and [19]. 5.1 Convex Sets Definition 35 A set X in E n is called a convex set if given any two points x 1 and x 2 in X, then x 1 + (1 )x 2 2 X for each 2 <ref> [0; 1] </ref>. 39 CHAPTER 5. CONVEX ANALYSIS 40 Note that x 1 + (1 )x 2 for in the interval [0; 1] represents a point on the line segment joining x 1 and x 2 . <p> n is called a convex set if given any two points x 1 and x 2 in X, then x 1 + (1 )x 2 2 X for each 2 <ref> [0; 1] </ref>. 39 CHAPTER 5. CONVEX ANALYSIS 40 Note that x 1 + (1 )x 2 for in the interval [0; 1] represents a point on the line segment joining x 1 and x 2 . Any point of the form y = x 1 + (1 )x 2 where 0 1 is called a convex combination (or weighted average) of x 1 and x 2 . <p> The elimination form of the inverse is a LU factorization which preserves sparsity during re-inversion, i.e., re-factorization B = LU . This form of the inverse was initially proposed by Markowitz [15] in 1957. Bartels and Golub <ref> [1] </ref> proposed numerically stable ways to update the L and U matrices. Chapter 9 Implementation Issues in LP Systems In Chapter 6 we gave the algebraic derivation and the geometric interpretation of the Simplex method.
Reference: [2] <author> Bazaraa, M. S., J. J. Jarvis and H. D. Sherali, </author> <title> Linear Programming and Network Flows, </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1990. </year>
Reference-contexts: Chapter 2 Analytic Geometry in n-Dimensions This Chapter presents a discussion of topics from analytic geometry in 3 and higher dimensions which are fundamental in the development of the Simplex method from the geometric point of view. This part of the report is based on material in <ref> [2, 20] </ref>. 2.1 The Number Space R n , Coordinates and Distances The set of all possible ntuples of real numbers form the n-dimensional number space, denoted by R n . For n = 2 and n = 3 we get the familiar 2 and 3-dimensional spaces, respectively. <p> Chapter 3 Linear Algebra for Mathematical Programming In this Chapter we overview some fundamental parts of Linear Algebra which are necessary for the development of the Simplex algorithm from a theoretical stand-point. The discussion of this Chapter is based on material in <ref> [2, 9, 11, 13, 20, 22] </ref>. 3.1 Vector Spaces In Chapter 2 we overviewed some important properties of lines and planes in E n and then we studied linear equations which determine them. <p> Definition 29 The determinant of a n fi n matrix A = (a ij ) is defined to be the number j A j given by X fga 1i 1 a 2i 2 : : : a ni n ; (4.1) where the sum is taken over all possible permutations <ref> [1; 2; : : :; n] </ref> of the second subscript of (4.1). <p> There are n! terms in (4.1) and a term is assigned a plus sign if (i 1 ; i 2 ; : : :; i n ) T 2 <ref> [1; 2; : : : ; n] </ref> is an even permutation, and a minus sign is it is an odd permutation. Definition 30 1. For any m fi n matrix A consider the submatrix R obtained by deleting all but k rows and k columns of A. <p> The above ideas will be used in the formation of the Tableau Simplex method. Chapter 5 Convex Analysis In this Chapter the basic concepts in convex analysis and some of the fundamental results related with linear programming are introduced. The discussion of this chapter is based on material in <ref> [2] </ref>, [16], and [19]. 5.1 Convex Sets Definition 35 A set X in E n is called a convex set if given any two points x 1 and x 2 in X, then x 1 + (1 )x 2 2 X for each 2 [0; 1]. 39 CHAPTER 5. <p> We proceed now to present some popular pivot selection methods. 7.2 The Non-Basic Gradient Method This method, also known as the "Dantzig's rule", is the oldest one and has been widely used in Simplex implementations <ref> [2, 9, 17, 19] </ref>. In this method Simplex selects the column A j with the most negative c j . <p> This method is intuitively appealing and claimed as simple but powerful enough to guide Simplex into short paths of bfs traversals, on the average [17, 19]. We have implemented this method as one of the pivot selection methods of our project. 7.3 Bland's Rule This method <ref> [2, 19, 18] </ref> is a generalization of a very simple pivot selection rule called the leftmost of the eligible variable rule. It requires that the variables are arranged in a specific order before the algorithm is initiated. <p> If j = n then we start searching from column A 1 again. This rule is very simple to implement and has a most desirable property. It prevents stalling and in practice it has been observed that it performs fairly well <ref> [2, 17] </ref>. CHAPTER 7. PIVOT SELECTION TECHNIQUES 82 This rule has also been implemented in our project. 7.5 The Greatest-Increment Method This method attempts to utilize as much information as possible to decide which column to introduce into the basis. <p> Then with probability 1 we do not cycle [9]. 2. Perturbation of the right-hand side b. b is slightly perturbed by * = (* 0 ; * 1 ; : : :; * m ) 2 R m to make the polyhedron non-degenerate, and, thus, avoid cycling <ref> [2, 17] </ref>. 3. The lexicographic rule for selecting the exiting variables. The lexicographic rule allows any variable to be introduced into the basis but it imposes an order in the way that columns are selected to exit the bases when there ties in the minimum-ratio test [2, 18, 19]. <p> The lexicographic rule for selecting the exiting variables. The lexicographic rule allows any variable to be introduced into the basis but it imposes an order in the way that columns are selected to exit the bases when there ties in the minimum-ratio test <ref> [2, 18, 19] </ref>. The relative cost row of the tableau storing the c B coefficients, is allowed to increase lexicographically only. CHAPTER 9. <p> Some problem are highly degenerate or highly sparse so cycling is a concern [19]. However, some authors claim that cycling is a very unlikely event, and it is practically ignored in commercial codes <ref> [2, 18] </ref>. The reason which is stated to support the un-likelyhood of cycling is that computer round-off errors have the same effect as a perturbation of the polytope. <p> Dual Formulation of an LP Problem Primal LP Dual LP min z = c 0 x (9.6) i x = b i ; i 2 M i x b i ; i 2 M x j &lt; 0; j 2 N i &lt; 0 0 0 It is well known <ref> [19, 2] </ref> that the Primal and the Dual formulations of an LP problem are related in the following manner and that, if a Primal LP has an optimal solution so does its dual, and at optimality their costs are equal.
Reference: [3] <author> Beale, E. M. L. </author> <title> "The Current Algorithmic Scope of Mathematical Programming," </title> <journal> Mathematical Programming Study, </journal> <volume> Vol. 4, </volume> <pages> pp. 1-11, </pages> <publisher> North-Holland Publ. Company, </publisher> <year> 1975. </year>
Reference-contexts: These methods have not been implemented in our project, so we are not going to discuss more about them. Chapter 8 Sparse Matrix Techniques A common feature of most practical large-scale mathematical programming problems is sparseness <ref> [3, 16, 23] </ref>. This applies whether the constraints are linear or non-linear and whether the variables are continuous or discrete. In this Chapter we overview techniques which utilize the sparseness of the LP problem. The inverse of the current basis is maintained explicitly and re-computations are performed only if necessary. <p> it updates the cost coefficients of the initial objective function computing the relative cost row c B for Phase II, and stores them in the zeroth row of the tableau X I which, immediately before simplex Phase II is in the following configuration [X I ] = 7 0 0 <ref> [3] </ref> 1 0 6 0 2 0 0 0 Note that the value of the objective function before Phase II is equal to c I = x 00 = 2, and, the inverse of the Phase I basis B 1 I is computed by the system to be [B 1 1
Reference: [4] <author> Bradley, A., A. Hax, and T. Magnati, </author> <title> Applied Mathematical Programming, </title> <publisher> Addison-Wesley, </publisher> <address> Reading Massachusetts, </address> <year> 1977. </year>
Reference: [5] <author> Crowder, H. and J. M. Hatting, </author> <title> "Partially Normalized Pivot Selection in Linear Programming," </title> <journal> Mathematical Programming Study, </journal> <volume> Vol. 4, </volume> <pages> pp. 12-25, </pages> <publisher> North-Holland Publ. Company, </publisher> <year> 1975. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 4 1.3 The Linear Programming Problem In the period since George Dantzig introduced the Simplex method [7] many innovations, changes and extensions have been introduced by researchers and practitioners. Most effort has focused on the improvement of its computational efficiency <ref> [5, 10, 12, 15] </ref>, while relatively few attempts have been made to evaluate its performance [6, 14]. <p> Harris has reported results which indicate in some cases halving in the total number of iterations on large problems. Another method called the partially normalized pivot selection by Crowder, H. and J. M. Hattingh <ref> [5] </ref>, uses the partial norm of the columns x j to scale dynamically its relative cost c j . <p> This method is proposed as an alternative to the Devex method, and they present results on sample LP problems with a number of pivot operations comparable to that for the Devex method <ref> [5] </ref>. The all-variable gradient method is considered to be an exact way to compute the c j normalizations and it is an improvement over both the Devex and the Partially Normalized methods.
Reference: [6] <author> Cutler, L. and P. Wolfe, </author> <title> "Experiments in linear Programming," </title> <editor> in: R. L. Graves and P. Wolfe, eds, </editor> <booktitle> Recent Advances in Mathematical Programming, </booktitle> <address> McGraw Hill, New York, </address> <year> 1963. </year>
Reference-contexts: Most effort has focused on the improvement of its computational efficiency [5, 10, 12, 15], while relatively few attempts have been made to evaluate its performance <ref> [6, 14] </ref>. Efforts to improve the efficiency of the Simplex algorithm have concentrated in three basic areas, namely 1. in pivot selection methods, 2. in basis inverse organization, and 3. in sparse-matrix techniques for the matrix manipulations involved.
Reference: [7] <author> Dantzig, G. B., </author> <title> "Programming of Interdependent Activities, II, </title> <booktitle> Mathematical Model," </booktitle> <pages> pp. </pages> <month> 19-32, </month> <title> in Activity Analysis of Production and Allocation, </title> <editor> ed. T. C. Coopmans, </editor> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York, </address> <year> 1951. </year>
Reference-contexts: The algorithm itself provides considerable insight into the theory of linear programming and for this reason it has been studied intensely by researchers and practitioners. Since the development of the Simplex algorithm by George B. Dantzig in 1947 <ref> [7] </ref>, linear programming has been extensively used in the military, the industry, and the government on a wide base of linear optimization problems. It has also been used as aiding tool for solving more complex problems, such as nonlinear programs, combinatorial problems, and problems of optimal control, among others. <p> The source program listings of the LP Solving System are given in the appendices. CHAPTER 1. INTRODUCTION 4 1.3 The Linear Programming Problem In the period since George Dantzig introduced the Simplex method <ref> [7] </ref> many innovations, changes and extensions have been introduced by researchers and practitioners. Most effort has focused on the improvement of its computational efficiency [5, 10, 12, 15], while relatively few attempts have been made to evaluate its performance [6, 14].
Reference: [8] <author> Dantzig, G. B., and W. Orchard Hays, </author> <title> "The Product Form of the Inverse in the Simplex Method," </title> <journal> Mathematics of Computation, </journal> <volume> Vol. 8, </volume> <pages> pp. 64-67, </pages> <year> 1954. </year>
Reference-contexts: We expect both A q and q 0 to be sparse. The product form of the inverse was initially published by Dantzig and Hays <ref> [8] </ref> in 1954. 8.2 LU Factorization of Basis The LU factorization transforms the matrix of the basis into the product of two triangular matrices B = LU ; (8.9) where, L is a lower triangular and U is an upper matrix.
Reference: [9] <author> Dantzig, G. B., </author> <title> Linear Programming and Extensions, </title> <publisher> Princeton University Press, </publisher> <address> Princeton, New Jersey, </address> <year> 1963. </year> <note> 111 BIBLIOGRAPHY 112 </note>
Reference-contexts: Chapter 3 Linear Algebra for Mathematical Programming In this Chapter we overview some fundamental parts of Linear Algebra which are necessary for the development of the Simplex algorithm from a theoretical stand-point. The discussion of this Chapter is based on material in <ref> [2, 9, 11, 13, 20, 22] </ref>. 3.1 Vector Spaces In Chapter 2 we overviewed some important properties of lines and planes in E n and then we studied linear equations which determine them. <p> We proceed now to present some popular pivot selection methods. 7.2 The Non-Basic Gradient Method This method, also known as the "Dantzig's rule", is the oldest one and has been widely used in Simplex implementations <ref> [2, 9, 17, 19] </ref>. In this method Simplex selects the column A j with the most negative c j . <p> A few anti-cycling methods have been proposed, including among others 1. Random resolution of ties in the minimum ratio test. In this rule when there is a tie in the exiting column determination we simply select one at random. Then with probability 1 we do not cycle <ref> [9] </ref>. 2. Perturbation of the right-hand side b. b is slightly perturbed by * = (* 0 ; * 1 ; : : :; * m ) 2 R m to make the polyhedron non-degenerate, and, thus, avoid cycling [2, 17]. 3. The lexicographic rule for selecting the exiting variables.
Reference: [10] <author> Goldfarb, D. and J. K. Reid, </author> <title> "A Practicable Steepest-Edge Simplex Algorithm," </title> <journal> Mathematical Programming, </journal> <volume> Vol. 12, no. 3, </volume> <pages> pp. 361-371, </pages> <publisher> North-Holland Publ. Company, </publisher> <month> June </month> <year> 1977. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 4 1.3 The Linear Programming Problem In the period since George Dantzig introduced the Simplex method [7] many innovations, changes and extensions have been introduced by researchers and practitioners. Most effort has focused on the improvement of its computational efficiency <ref> [5, 10, 12, 15] </ref>, while relatively few attempts have been made to evaluate its performance [6, 14]. <p> However, this advantage is debatable due to the additional computational overhead involved in computing the minimum-ratio tests of all eligible columns. This method has been implemented in our project. 7.6 The All-Variable Gradient Method This method <ref> [10] </ref> selects the column A j with the most cost value reduction per unit distance traversed on the chosen edge of the polytope. <p> PIVOT SELECTION TECHNIQUES 83 which corresponds to the fraction of the projection of direction d of the edge of the polytope divided by the length of the edge itself. This method carries additional computational overhead, but Goldfarb and Reid <ref> [10] </ref> have devised appropriate recurrence equations to recompute ^c j ; j = 1; 2; : : : ; n efficiently, from iteration to iteration.
Reference: [11] <author> Hadley, G., </author> <title> Linear Programming, </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1962. </year>
Reference-contexts: Chapter 3 Linear Algebra for Mathematical Programming In this Chapter we overview some fundamental parts of Linear Algebra which are necessary for the development of the Simplex algorithm from a theoretical stand-point. The discussion of this Chapter is based on material in <ref> [2, 9, 11, 13, 20, 22] </ref>. 3.1 Vector Spaces In Chapter 2 we overviewed some important properties of lines and planes in E n and then we studied linear equations which determine them.
Reference: [12] <author> Harris, P. M. J., </author> <title> "Pivot Selection Methods of the Devex LP Code," Mathematical Programming Study Vol. 4, </title> <publisher> North-Holland Publ. Company, </publisher> <address> Amsterdam, </address> <month> December </month> <year> 1975. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 4 1.3 The Linear Programming Problem In the period since George Dantzig introduced the Simplex method [7] many innovations, changes and extensions have been introduced by researchers and practitioners. Most effort has focused on the improvement of its computational efficiency <ref> [5, 10, 12, 15] </ref>, while relatively few attempts have been made to evaluate its performance [6, 14]. <p> In our project we have implemented this method as well. 7.7 The Devex and the Partially Normalized Pivot Selection Meth ods The Devex method, developed by P. Harris <ref> [12] </ref>, attempts to select a column A j with the smallest gradient in the space of the initial non-basic variables. In this method, as in the all-variable gradient, the relative cost c j ; j = 1; 2; : : :; n is weighted by appropriate constants.
Reference: [13] <author> Kreyszig, E., </author> <title> Advanced Engineering Mathematics, Seventh Edition, </title> <publisher> John Wiley&Sons, Inc., </publisher> <year> 1993. </year>
Reference-contexts: Chapter 3 Linear Algebra for Mathematical Programming In this Chapter we overview some fundamental parts of Linear Algebra which are necessary for the development of the Simplex algorithm from a theoretical stand-point. The discussion of this Chapter is based on material in <ref> [2, 9, 11, 13, 20, 22] </ref>. 3.1 Vector Spaces In Chapter 2 we overviewed some important properties of lines and planes in E n and then we studied linear equations which determine them.
Reference: [14] <author> Kuhn, H. W. and R. E. Quandt, </author> <title> "An Experimental Study of the Simplex Method," </title> <journal> pp. </journal> <pages> 107-124, </pages> <booktitle> in Proceedings in Symposia on Applied Mathematics, </booktitle> <volume> vol. XV, </volume> <editor> ed. N. Metropolis, et al., </editor> <publisher> American Mathematical Society, </publisher> <address> Providence, R.I., </address> <year> 1963. </year>
Reference-contexts: Most effort has focused on the improvement of its computational efficiency [5, 10, 12, 15], while relatively few attempts have been made to evaluate its performance <ref> [6, 14] </ref>. Efforts to improve the efficiency of the Simplex algorithm have concentrated in three basic areas, namely 1. in pivot selection methods, 2. in basis inverse organization, and 3. in sparse-matrix techniques for the matrix manipulations involved.
Reference: [15] <author> Markowitz, . M., </author> <title> "The Elimination Form of the Inverse and its Application to Linear Programming," </title> <journal> Management Science, </journal> <volume> Vol. 3, </volume> <pages> pp. 255-269, </pages> <year> 1957. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 4 1.3 The Linear Programming Problem In the period since George Dantzig introduced the Simplex method [7] many innovations, changes and extensions have been introduced by researchers and practitioners. Most effort has focused on the improvement of its computational efficiency <ref> [5, 10, 12, 15] </ref>, while relatively few attempts have been made to evaluate its performance [6, 14]. <p> The elimination form of the inverse is a LU factorization which preserves sparsity during re-inversion, i.e., re-factorization B = LU . This form of the inverse was initially proposed by Markowitz <ref> [15] </ref> in 1957. Bartels and Golub [1] proposed numerically stable ways to update the L and U matrices. Chapter 9 Implementation Issues in LP Systems In Chapter 6 we gave the algebraic derivation and the geometric interpretation of the Simplex method.
Reference: [16] <author> Murtagh, B. A., </author> <title> Advanced Linear Programming: Computation and Practice, </title> <publisher> McGraw-Hill Inc., </publisher> <year> 1981. </year>
Reference-contexts: Chapter 5 Convex Analysis In this Chapter the basic concepts in convex analysis and some of the fundamental results related with linear programming are introduced. The discussion of this chapter is based on material in [2], <ref> [16] </ref>, and [19]. 5.1 Convex Sets Definition 35 A set X in E n is called a convex set if given any two points x 1 and x 2 in X, then x 1 + (1 )x 2 2 X for each 2 [0; 1]. 39 CHAPTER 5. <p> These methods have not been implemented in our project, so we are not going to discuss more about them. Chapter 8 Sparse Matrix Techniques A common feature of most practical large-scale mathematical programming problems is sparseness <ref> [3, 16, 23] </ref>. This applies whether the constraints are linear or non-linear and whether the variables are continuous or discrete. In this Chapter we overview techniques which utilize the sparseness of the LP problem. The inverse of the current basis is maintained explicitly and re-computations are performed only if necessary. <p> These are the big M method and the crash methods. The big-M method introduces numerical inaccuracies in the matrix computations, since it requires relatively large values for M <ref> [16] </ref>. The crash methods are ad-hoc ways to force Simplex to use some columns which are expected to form a basis [23]. This method may lead to an impasse when the selected columns do not really constitute a basis.
Reference: [17] <author> Murty, K. G., </author> <title> Linear Programming, </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1983. </year>
Reference-contexts: We proceed now to present some popular pivot selection methods. 7.2 The Non-Basic Gradient Method This method, also known as the "Dantzig's rule", is the oldest one and has been widely used in Simplex implementations <ref> [2, 9, 17, 19] </ref>. In this method Simplex selects the column A j with the most negative c j . <p> This method is intuitively appealing and claimed as simple but powerful enough to guide Simplex into short paths of bfs traversals, on the average <ref> [17, 19] </ref>. We have implemented this method as one of the pivot selection methods of our project. 7.3 Bland's Rule This method [2, 19, 18] is a generalization of a very simple pivot selection rule called the leftmost of the eligible variable rule. <p> If j = n then we start searching from column A 1 again. This rule is very simple to implement and has a most desirable property. It prevents stalling and in practice it has been observed that it performs fairly well <ref> [2, 17] </ref>. CHAPTER 7. PIVOT SELECTION TECHNIQUES 82 This rule has also been implemented in our project. 7.5 The Greatest-Increment Method This method attempts to utilize as much information as possible to decide which column to introduce into the basis. <p> Then with probability 1 we do not cycle [9]. 2. Perturbation of the right-hand side b. b is slightly perturbed by * = (* 0 ; * 1 ; : : :; * m ) 2 R m to make the polyhedron non-degenerate, and, thus, avoid cycling <ref> [2, 17] </ref>. 3. The lexicographic rule for selecting the exiting variables. The lexicographic rule allows any variable to be introduced into the basis but it imposes an order in the way that columns are selected to exit the bases when there ties in the minimum-ratio test [2, 18, 19].
Reference: [18] <author> Murty, K. G., </author> <title> Linear and Combinatorial Programming, Reprint Edition, </title> <editor> Robert E. </editor> <publisher> Krieger Publ. Company, </publisher> <address> Malabar, Florida, </address> <year> 1985. </year>
Reference-contexts: This method is intuitively appealing and claimed as simple but powerful enough to guide Simplex into short paths of bfs traversals, on the average [17, 19]. We have implemented this method as one of the pivot selection methods of our project. 7.3 Bland's Rule This method <ref> [2, 19, 18] </ref> is a generalization of a very simple pivot selection rule called the leftmost of the eligible variable rule. It requires that the variables are arranged in a specific order before the algorithm is initiated. <p> The lexicographic rule for selecting the exiting variables. The lexicographic rule allows any variable to be introduced into the basis but it imposes an order in the way that columns are selected to exit the bases when there ties in the minimum-ratio test <ref> [2, 18, 19] </ref>. The relative cost row of the tableau storing the c B coefficients, is allowed to increase lexicographically only. CHAPTER 9. <p> Some problem are highly degenerate or highly sparse so cycling is a concern [19]. However, some authors claim that cycling is a very unlikely event, and it is practically ignored in commercial codes <ref> [2, 18] </ref>. The reason which is stated to support the un-likelyhood of cycling is that computer round-off errors have the same effect as a perturbation of the polytope.
Reference: [19] <author> Papadimitriou C. H. and K. Steiglitz, </author> <title> Combinatorial Optimization: Algorithms and Complexity, </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1982. </year>
Reference-contexts: Chapter 5 Convex Analysis In this Chapter the basic concepts in convex analysis and some of the fundamental results related with linear programming are introduced. The discussion of this chapter is based on material in [2], [16], and <ref> [19] </ref>. 5.1 Convex Sets Definition 35 A set X in E n is called a convex set if given any two points x 1 and x 2 in X, then x 1 + (1 )x 2 2 X for each 2 [0; 1]. 39 CHAPTER 5. <p> We proceed now to present some popular pivot selection methods. 7.2 The Non-Basic Gradient Method This method, also known as the "Dantzig's rule", is the oldest one and has been widely used in Simplex implementations <ref> [2, 9, 17, 19] </ref>. In this method Simplex selects the column A j with the most negative c j . <p> This method is intuitively appealing and claimed as simple but powerful enough to guide Simplex into short paths of bfs traversals, on the average <ref> [17, 19] </ref>. We have implemented this method as one of the pivot selection methods of our project. 7.3 Bland's Rule This method [2, 19, 18] is a generalization of a very simple pivot selection rule called the leftmost of the eligible variable rule. <p> This method is intuitively appealing and claimed as simple but powerful enough to guide Simplex into short paths of bfs traversals, on the average [17, 19]. We have implemented this method as one of the pivot selection methods of our project. 7.3 Bland's Rule This method <ref> [2, 19, 18] </ref> is a generalization of a very simple pivot selection rule called the leftmost of the eligible variable rule. It requires that the variables are arranged in a specific order before the algorithm is initiated. <p> The lexicographic rule for selecting the exiting variables. The lexicographic rule allows any variable to be introduced into the basis but it imposes an order in the way that columns are selected to exit the bases when there ties in the minimum-ratio test <ref> [2, 18, 19] </ref>. The relative cost row of the tableau storing the c B coefficients, is allowed to increase lexicographically only. CHAPTER 9. <p> CHAPTER 9. IMPLEMENTATION ISSUES IN LP SYSTEMS 96 4. Bland's rule, where we simply select the "left-most" eligible variable to enter the basis and again the leftmost variable to exit it. Some problem are highly degenerate or highly sparse so cycling is a concern <ref> [19] </ref>. However, some authors claim that cycling is a very unlikely event, and it is practically ignored in commercial codes [2, 18]. The reason which is stated to support the un-likelyhood of cycling is that computer round-off errors have the same effect as a perturbation of the polytope. <p> Dual Formulation of an LP Problem Primal LP Dual LP min z = c 0 x (9.6) i x = b i ; i 2 M i x b i ; i 2 M x j &lt; 0; j 2 N i &lt; 0 0 0 It is well known <ref> [19, 2] </ref> that the Primal and the Dual formulations of an LP problem are related in the following manner and that, if a Primal LP has an optimal solution so does its dual, and at optimality their costs are equal.
Reference: [20] <author> Protter, M. H. and C. B. Morrey, Jr., </author> <title> Intermediate Calculus, 2nd Edition, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <publisher> Inc., </publisher> <year> 1985. </year>
Reference-contexts: Chapter 2 Analytic Geometry in n-Dimensions This Chapter presents a discussion of topics from analytic geometry in 3 and higher dimensions which are fundamental in the development of the Simplex method from the geometric point of view. This part of the report is based on material in <ref> [2, 20] </ref>. 2.1 The Number Space R n , Coordinates and Distances The set of all possible ntuples of real numbers form the n-dimensional number space, denoted by R n . For n = 2 and n = 3 we get the familiar 2 and 3-dimensional spaces, respectively. <p> Chapter 3 Linear Algebra for Mathematical Programming In this Chapter we overview some fundamental parts of Linear Algebra which are necessary for the development of the Simplex algorithm from a theoretical stand-point. The discussion of this Chapter is based on material in <ref> [2, 9, 11, 13, 20, 22] </ref>. 3.1 Vector Spaces In Chapter 2 we overviewed some important properties of lines and planes in E n and then we studied linear equations which determine them.
Reference: [21] <author> Quandt, R. E. and H. W. Kuhn, </author> <title> "On Upper Bounds for the Number of Iterations in Solving Linear Programs," </title> <journal> Operations Research, </journal> <volume> Vol. 11, pp.161-165, </volume> <year> 1963. </year>
Reference: [22] <author> Smith, L., </author> <title> Linear Algebra, 2nd Edition, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <publisher> Inc., </publisher> <year> 1984. </year>
Reference-contexts: Chapter 3 Linear Algebra for Mathematical Programming In this Chapter we overview some fundamental parts of Linear Algebra which are necessary for the development of the Simplex algorithm from a theoretical stand-point. The discussion of this Chapter is based on material in <ref> [2, 9, 11, 13, 20, 22] </ref>. 3.1 Vector Spaces In Chapter 2 we overviewed some important properties of lines and planes in E n and then we studied linear equations which determine them.
Reference: [23] <author> White, W. W., </author> <title> "Status Report on Computing Algorithms for Mathematical Programming," </title> <journal> Computing Surveys, </journal> <volume> Vol. 5, no. 3, </volume> <pages> pp. 135-166, </pages> <year> 1973. </year>
Reference-contexts: These methods have not been implemented in our project, so we are not going to discuss more about them. Chapter 8 Sparse Matrix Techniques A common feature of most practical large-scale mathematical programming problems is sparseness <ref> [3, 16, 23] </ref>. This applies whether the constraints are linear or non-linear and whether the variables are continuous or discrete. In this Chapter we overview techniques which utilize the sparseness of the LP problem. The inverse of the current basis is maintained explicitly and re-computations are performed only if necessary. <p> These are the big M method and the crash methods. The big-M method introduces numerical inaccuracies in the matrix computations, since it requires relatively large values for M [16]. The crash methods are ad-hoc ways to force Simplex to use some columns which are expected to form a basis <ref> [23] </ref>. This method may lead to an impasse when the selected columns do not really constitute a basis. Thus, both methods were not considered as appropriate for implementation in our LP system. CHAPTER 9.
References-found: 23

