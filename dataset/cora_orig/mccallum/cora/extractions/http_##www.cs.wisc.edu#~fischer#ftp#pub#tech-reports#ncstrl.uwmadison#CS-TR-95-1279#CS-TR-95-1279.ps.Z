URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-95-1279/CS-TR-95-1279.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-95-1279/
Root-URL: http://www.cs.wisc.edu
Title: ALGORITHMS FOR SCHEDULING MALLEABLE AND NONMALLEABLE PARALLEL TASKS  
Author: By Walter T. Ludwig 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Sciences) at the  
Date: 1995  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Aho, J. Hopcroft, and J. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1974. </year>
Reference-contexts: Theorem 2.1.1 leads to the following family of lower bounds. Corollary 2.1.1 For any nonmalleable task set T (p) and any 2 <ref> [0; 1] </ref>, the total weighted completion time R X of any schedule X for T (p) is at least R X A T (p) + (1 2 1 U T (p): (23) Proof: R X = R X + (1 )R X 1 H T (p) 2 = A T (p) <p> (p) + (1 2 1 U T (p): (23) Proof: R X = R X + (1 )R X 1 H T (p) 2 = A T (p) + (1 2 1 U T (p): (24) L 1 )H T (p) 2 21 Then by Corollary 2.1.1, for any 2 <ref> [0; 1] </ref>, we have L So L T (p) is a lower bound on total weighted completion time for T (p). <p> Corollary 2.1.3 For any malleable task set T and any 2 <ref> [0; 1] </ref>, the total weighted completion time R X of any schedule X for T is at least R X min fA T (p) + (1 2 1 U T (p)g: (35) 2.2 A List Scheduling Algorithm for NMWACT We can use the results of the previous section to prove an <p> Observe that Corollary 2.1.3 defines an allotment selection problem. That is, for a given 2 <ref> [0; 1] </ref>, let L p T (p)g = min fA T (p) + (1 2 1 U T (p)g: (44) Then the allotment selection problem is to find for a given an allotment p such that L T . <p> Let R fl (T ) denote the optimal value of R X over all possible schedules X for the malleable task set T . Then for all 2 <ref> [0; 1] </ref>, we have L T R fl (T ). The results of the previous two sections suggest the following method of scheduling a set of malleable tasks T . First, find a solution p to the allotment selection problem. <p> In this chapter, we present algorithms that select for any 2 <ref> [0; 1] </ref> an allotment of processors p to a set T of malleable tasks such that L T (p) L T , where is some constant. For the case of equal task weights, we present a polynomial-time algorithm in Section 3.2 that solves the problem exactly ( = 1). <p> We refer to this as the exact algorithm, since it gives an exact solution to the allotment selection problem. Theorem 3.2.1 For any set T of malleable tasks with w i = 1 for all i, and any 2 <ref> [0; 1] </ref>, the exact algorithm finds an allotment p that satisfies L T (p) = L running time is O (n 3 + mn). <p> Repeat this process until 40 every task has been assigned to a position. Finally, construct an allotment p by taking p i = i (( w) Theorem 3.3.1 For any set T of malleable tasks and any 2 <ref> [0; 1] </ref>, the greedy algorithm finds an allotment p that satisfies L T (p) 2L T . Its running time is O (n 2 + mn). <p> Theorem 3.4.1 For any set T of malleable tasks satisfying the nondecreasing work and nonincreasing execution time conditions, with M i = [m] and w i = 1 for all tasks i, and any 2 <ref> [0; 1] </ref>, the semi-oblivious algorithm finds an allotment p that satisfies L T . Its running time is O (minfn + m log m; n 2 g). <p> In order to apply Theorem 2.3.1, we wish to select fi as small as possible subject to dfime kpk and dfime dffme. Observe that kpk = (1 1 2 1 ' ~ 2 ; (121) since (1 1 2 )=(2 1 2 for all 2 <ref> [0; 1] </ref>. Now applying Theorem 2.3.1 with fi = maxf 1 2 ; ffg and = 4 yields the desired approximation factor. <p> In each iteration, we will use a linear time selection algorithm as in <ref> [1] </ref> to choose the s s 0 tasks with the smallest values of t i (p (s)). Observe that there are O (m=j) positions s for which p (s) &gt; j. <p> is, write j i k if j &lt; k and t i (j) t i (k), or j &gt; k and jt i (j) kt i (k), and let M 0 i = fk 2 M i :6 9j 2 M i such that j i kg: (196) Let v <ref> [i; 1] </ref> &lt; v [i; 2] &lt; &lt; v [i; z [i]] be all the elements of M 0 i , and let t [i; j] denote the execution time of task i when v [i; j] processors are allotted to it. <p> Therefore, maxft k ; W (t k )g minfmaxft s ; W (t s )g; maxft u ; W (t u )gg = minfsuccessful; unsuccessfulg: (207) We conclude that ! T = minfsuccessful; unsuccessfulg, and that the allotment computed by the algorithm, p = (v <ref> [1; allot [1] </ref>]; v [2; allot [2]]; : : : ; v [n; allot [n]]), satisfies ! T = ! T (p). <p> Therefore, maxft k ; W (t k )g minfmaxft s ; W (t s )g; maxft u ; W (t u )gg = minfsuccessful; unsuccessfulg: (207) We conclude that ! T = minfsuccessful; unsuccessfulg, and that the allotment computed by the algorithm, p = (v [1; allot <ref> [1] </ref>]; v [2; allot [2]]; : : : ; v [n; allot [n]]), satisfies ! T = ! T (p). <p> These all require binary search for each of the active tasks and can be completed in O (log m) per task. Note that in Step 5b, the median of the set can be found in time proportional to the number of active tasks using a selection algorithm as in <ref> [1] </ref>. So the running time of the algorithm is O (log m) per active task per iteration. Now our goal is to bound the sum of the number of active tasks over all the iterations of the algorithm's main loop. <p> The algorithm in Figure 8 computes a list of the nonempty intervals for task i 0 . Upon termination, the values of j for which the corresponding intervals (v i 0 ;j+1 ; v i 0 j ] are nonempty are given by d <ref> [1] </ref> &lt; d [2] &lt; &lt; d [r]. The interval corresponding to d [k] is given by (v [k + 1]; v [k]]. That is, C i 0 () = C i 0 (; d [k]) for all 2 (v [k + 1]; v [k]]. <p> i ; v [r + 1] := 0; (c) else if x (j; d [r]) &gt; 0 then i. r := r + 1; iii. v [r] := x (j; d [r 1]); v [r + 1] := 0; 1. v j [r j + 1] = 0, v j <ref> [1] </ref> = i=1 w i , and v j [k + 1] &lt; v j [k] for all k 2 [r j ]. P n i=1 w i ], let k be such that 2 (v j [k + 1]; v j [k]]. <p> Proof of Lemma A.0.18: We proceed by induction on j. After the first iteration, we have r 1 = 1, d 1 <ref> [1] </ref> = 1, v 1 [1] = P n i=1 w i , and v 1 [2] = 0. Thus the lemma holds for j = 1. Now we will show that the lemma holds for iteration j &gt; 1, supposing that it holds for the previous iteration. <p> Proof of Lemma A.0.18: We proceed by induction on j. After the first iteration, we have r 1 = 1, d 1 <ref> [1] </ref> = 1, v 1 [1] = P n i=1 w i , and v 1 [2] = 0. Thus the lemma holds for j = 1. Now we will show that the lemma holds for iteration j &gt; 1, supposing that it holds for the previous iteration. <p> Therefore, to prove the first part of the lemma, we need only consider the possible cases in which v is altered. Suppose that v is updated in Step 2 (b)iii. Then r j = 1, and so 0 = v j [2] &lt; v j <ref> [1] </ref> = i=1 w i , as required. Suppose instead that v is updated in Step 2 (c)iii. <p> Note that v j [r j + 1] = 0, and so it follows that &gt; v j [r j ]. Now by the first part of Lemma A.0.18, v j <ref> [1] </ref> = P n i=1 w i , and therefore r j &gt; 1. Then r j 1, and so by Lemma A.0.20 it follows that (j) &gt; (d j1 [r j ]). <p> If r j = 0, then the test in Step 2b is true, and so v j [r j ] = P n i=1 w i . Furthermore, r j = 1, and so by the induction hypothesis, v j1 [r j ] = v j1 <ref> [1] </ref> = P n i=1 w i . We conclude that v j [r j ] = v j1 [r j ]. Suppose instead that r j &gt; 0. Note that r j &lt; k r j1 .
Reference: [2] <author> B. Baker, D. Brown, and H. Katseff. </author> <title> A 5/4 algorithm for two-dimensional packing. </title> <journal> Journal of Algorithms, </journal> <volume> 2(4) </volume> <pages> 348-368, </pages> <month> December </month> <year> 1981. </year>
Reference-contexts: Garey and Graham show that this algorithm has an approximation factor of 2 for NMM. Another closely related problem is the oriented orthogonal rectangle packing problem, first posed by Baker, Coffman, and Rivest [3], and also studied by many others <ref> [14, 51, 2, 4, 53] </ref>. This problem is in fact identical to NMM on a line of processors: one of the dimensions in the rectangle-packing problem corresponds to time in NMM, and the other corresponds to processors. <p> k if j &lt; k and t i (j) t i (k), or j &gt; k and jt i (j) kt i (k), and let M 0 i = fk 2 M i :6 9j 2 M i such that j i kg: (196) Let v [i; 1] &lt; v <ref> [i; 2] </ref> &lt; &lt; v [i; z [i]] be all the elements of M 0 i , and let t [i; j] denote the execution time of task i when v [i; j] processors are allotted to it. That is, t [i; j] = t i (v [i; j]). <p> Therefore, maxft k ; W (t k )g minfmaxft s ; W (t s )g; maxft u ; W (t u )gg = minfsuccessful; unsuccessfulg: (207) We conclude that ! T = minfsuccessful; unsuccessfulg, and that the allotment computed by the algorithm, p = (v [1; allot [1]]; v <ref> [2; allot [2] </ref>]; : : : ; v [n; allot [n]]), satisfies ! T = ! T (p). <p> maxft k ; W (t k )g minfmaxft s ; W (t s )g; maxft u ; W (t u )gg = minfsuccessful; unsuccessfulg: (207) We conclude that ! T = minfsuccessful; unsuccessfulg, and that the allotment computed by the algorithm, p = (v [1; allot [1]]; v [2; allot <ref> [2] </ref>]; : : : ; v [n; allot [n]]), satisfies ! T = ! T (p). <p> The algorithm in Figure 8 computes a list of the nonempty intervals for task i 0 . Upon termination, the values of j for which the corresponding intervals (v i 0 ;j+1 ; v i 0 j ] are nonempty are given by d [1] &lt; d <ref> [2] </ref> &lt; &lt; d [r]. The interval corresponding to d [k] is given by (v [k + 1]; v [k]]. That is, C i 0 () = C i 0 (; d [k]) for all 2 (v [k + 1]; v [k]]. <p> Proof of Lemma A.0.18: We proceed by induction on j. After the first iteration, we have r 1 = 1, d 1 [1] = 1, v 1 [1] = P n i=1 w i , and v 1 <ref> [2] </ref> = 0. Thus the lemma holds for j = 1. Now we will show that the lemma holds for iteration j &gt; 1, supposing that it holds for the previous iteration. <p> Therefore, to prove the first part of the lemma, we need only consider the possible cases in which v is altered. Suppose that v is updated in Step 2 (b)iii. Then r j = 1, and so 0 = v j <ref> [2] </ref> &lt; v j [1] = i=1 w i , as required. Suppose instead that v is updated in Step 2 (c)iii.
Reference: [3] <author> B. Baker, E. Coffman, and R. Rivest. </author> <title> Orthogonal packings in two dimensions. </title> <journal> SIAM Journal on Computing, </journal> <volume> 9(4) </volume> <pages> 846-855, </pages> <month> November </month> <year> 1980. </year>
Reference-contexts: Garey and Graham show that this algorithm has an approximation factor of 2 for NMM. Another closely related problem is the oriented orthogonal rectangle packing problem, first posed by Baker, Coffman, and Rivest <ref> [3] </ref>, and also studied by many others [14, 51, 2, 4, 53]. This problem is in fact identical to NMM on a line of processors: one of the dimensions in the rectangle-packing problem corresponds to time in NMM, and the other corresponds to processors. <p> We will do this by showing S i 0 for each i 2 <ref> [3] </ref>. To see that S 1 0, consider any k 2 K 1 .
Reference: [4] <author> B. Baker and J. Schwarz. </author> <title> Shelf algorithms for two-dimensional packing problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 12(3) </volume> <pages> 508-525, </pages> <month> August </month> <year> 1983. </year>
Reference-contexts: Garey and Graham show that this algorithm has an approximation factor of 2 for NMM. Another closely related problem is the oriented orthogonal rectangle packing problem, first posed by Baker, Coffman, and Rivest [3], and also studied by many others <ref> [14, 51, 2, 4, 53] </ref>. This problem is in fact identical to NMM on a line of processors: one of the dimensions in the rectangle-packing problem corresponds to time in NMM, and the other corresponds to processors.
Reference: [5] <author> K. Belkhale and P. Banerjee. </author> <title> Approximate algorithms for the partitionable independent task scheduling problem. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <volume> vol. I, </volume> <pages> pages 72-75, </pages> <year> 1990. </year>
Reference-contexts: Belkhale and Banerjee <ref> [5] </ref> consider a restriction of MMM in which M i = [m] for all tasks i.
Reference: [6] <author> J. Blazewicz, W. Cellary, R. Slowinski, and J. Weglarz. </author> <title> Scheduling under resource constraints | deterministic models. </title> <journal> Annals of Operations Research, </journal> <volume> 7, </volume> <year> 1986. </year>
Reference-contexts: We also present methods for both GMM and MMM for computing an optimal allotment efficiently in parallel. 1.3 Related Work 1.3.1 Minimizing Makespan The predecessor of parallel task scheduling problems is the resource-constrained scheduling problem <ref> [6] </ref>, as posed by Garey and Graham [22]. In the resource-constrained scheduling problem, there are one or more resources, and each task requires a certain amount of each resource for the duration of its execution time. <p> The same approach can also be applied to NMM [7, 10, 23]. Note that MM can be viewed as resource-constrained scheduling with one discrete malleable resource. For the variation in which the resource is continuous rather than discrete, see <ref> [8, 6] </ref>. <p> Results for resource-constrained scheduling with this objective are directed toward identifying special cases that can be solved in polynomial time <ref> [6, 9] </ref>, rather than providing approximation algorithms for the general case with a single resource.
Reference: [7] <author> J. Blazewicz, M. Drabowski, and J. Weglarz. </author> <title> Scheduling multiprocessor tasks to minimize schedule length. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(5):389-393, </volume> <year> 1986. </year>
Reference-contexts: This is the approach to MM that is taken by Du and Leung [18]. The same approach can also be applied to NMM <ref> [7, 10, 23] </ref>. Note that MM can be viewed as resource-constrained scheduling with one discrete malleable resource. For the variation in which the resource is continuous rather than discrete, see [8, 6].
Reference: [8] <author> J. Blazewicz, K. Ecker, G. Schmidt, and J. Weglarz. </author> <title> Scheduling in Computer and Manufacturing Systems. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: The same approach can also be applied to NMM [7, 10, 23]. Note that MM can be viewed as resource-constrained scheduling with one discrete malleable resource. For the variation in which the resource is continuous rather than discrete, see <ref> [8, 6] </ref>.
Reference: [9] <author> J. Blazewicz, W. Kubiak, H. Rock, and J. Szwarcfiter. </author> <title> Minimizing mean flow-time with parallel processors and resource constraints. </title> <journal> Acta Informatica, </journal> <volume> 24 </volume> <pages> 513-524, </pages> <year> 1987. </year>
Reference-contexts: Results for resource-constrained scheduling with this objective are directed toward identifying special cases that can be solved in polynomial time <ref> [6, 9] </ref>, rather than providing approximation algorithms for the general case with a single resource.
Reference: [10] <author> J. Blazewicz, J. K. Lenstra, and A. H. G. Rinnooy Kan. </author> <title> Scheduling subject to resource constraints: Classification and complexity. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 5 </volume> <pages> 11-24, </pages> <year> 1983. </year>
Reference-contexts: Furthermore, NMACT is NP-hard in the strong sense even when the tasks have unit execution times <ref> [10] </ref>. Therefore NMWACT, MACT, and MWACT are also NP-hard in the strong sense. For malleable scheduling problems, it is often helpful to assume that the task execution time functions satisfy certain reasonable conditions. <p> This is the approach to MM that is taken by Du and Leung [18]. The same approach can also be applied to NMM <ref> [7, 10, 23] </ref>. Note that MM can be viewed as resource-constrained scheduling with one discrete malleable resource. For the variation in which the resource is continuous rather than discrete, see [8, 6].
Reference: [11] <author> J. Bruno, E. Coffman, Jr., and R. Sethi. </author> <title> Scheduling independent tasks to reduce mean finishing time. </title> <journal> Communications of the ACM, </journal> <volume> 17 </volume> <pages> 382-387, </pages> <year> 1974. </year> <month> 125 </month>
Reference: [12] <author> S. H. Chiang, R. Mansharamani, and M. Vernon. </author> <title> Use of application characteristics and limited preemption for run-to-completion parallel processor scheduling policies. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <volume> volume 22, </volume> <year> 1994. </year>
Reference-contexts: Such an environment may reflect more accurately the conditions that are encountered in practice. Thus it is not surprising that many processor allocation policies for this environment have been studied, typically using simulations or analytical modeling to evaluate their relative performance. (For example, see <ref> [12, 41, 40, 48, 25, 35, 60, 54] </ref>.) We introduce a new processor allocation policy based on our fastest allotment selection algorithm, and present simulation results suggesting that its performance is comparable to that of the best known policies. 1.4 Organization of This Thesis Chapter 2 contains all the elements of <p> The resulting policy, which we call SO, belongs to the class of run-to-completion (RTC) policies | nonpreemptive policies that do not change the allocation of processors to a task during that task's execution. Chiang, Mansharamani, and Vernon <ref> [12] </ref> have recently compared RTC policies that have been proposed in the literature, and concluded that the policies they call ASP-max and ASP-max+ appear to have the best performance. <p> computed using a 57 formula analogous to the processor allocation formula given by Sevcik [49]: i= &gt; &gt; &lt; N i if &lt; 1 max + 1 1 (132) where = :25. 3.5.2 The Model For our simulations, we adopt the system and workload model used by Chiang et al. <ref> [12] </ref>, which is due to Mansharamani and Vernon [39]. Tasks arrive according to a Poisson process with rate . We have m identical processors on which to schedule the tasks, and there is no scheduling overhead. <p> Furthermore, SO (a 1 ,a 2 ) policies and ASP-max policies have three important characteristics in common. First, both are sensitive to system load, allocating fewer processors to each task as system load increases. Various studies show that this is a desirable property <ref> [49, 25, 41, 40, 48, 12] </ref>. Second, both place an upper limit on the allocation of processors to a task, which has also been shown to be desirable [12]. Third, neither requires any information about task demand or execution rate | information that may not be available. <p> Various studies show that this is a desirable property [49, 25, 41, 40, 48, 12]. Second, both place an upper limit on the allocation of processors to a task, which has also been shown to be desirable <ref> [12] </ref>. Third, neither requires any information about task demand or execution rate | information that may not be available.
Reference: [13] <author> V. Chvatal. </author> <title> Linear Programming. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1983. </year>
Reference-contexts: &gt; : 0 if i 2 fk + 1; k + 2; : : : ; ng P k1 a k if i = k: To verify that this is optimal, we can construct the dual problem and check that its optimal solution has the same objective function value. (See <ref> [13] </ref> for a discussion of linear programming and duality.) The dual of (18) is minimize mtz + P n subject to a i z + y i w i for all i 2 [n] y i 0 for all i 2 [n] (20) It has an optimal solution at z fl
Reference: [14] <author> E. Coffman, M. Garey, D. Johnson, and R. Tarjan. </author> <title> Performance bounds for level-oriented two-dimensional packing problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 9(4) </volume> <pages> 808-826, </pages> <month> November </month> <year> 1980. </year>
Reference-contexts: Garey and Graham show that this algorithm has an approximation factor of 2 for NMM. Another closely related problem is the oriented orthogonal rectangle packing problem, first posed by Baker, Coffman, and Rivest [3], and also studied by many others <ref> [14, 51, 2, 4, 53] </ref>. This problem is in fact identical to NMM on a line of processors: one of the dimensions in the rectangle-packing problem corresponds to time in NMM, and the other corresponds to processors.
Reference: [15] <author> R. Cole. </author> <title> Parallel merge sort. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17 </volume> <pages> 770-785, </pages> <year> 1988. </year>
Reference-contexts: One way of computing the weighted median of n items is to first sort the items, and then compute the prefix sums of the weights. Each of these operations can be completed in O (log n) time on an n-processor EREW PRAM, using algorithms due 108 to Cole <ref> [15] </ref> and Ladner and Fischer [33]. (See Karp and Ramachandran's survey [29] for a discussion of parallel selection and sorting.) So after making this change to Step 5b, the running time per iteration remains O (log (mn)). <p> j]g satisfying t max k2 [n] ft [k; z [k]]g, the associated prefix sum is the minimum total work required if every task has execution time not exceeding t : X u [i; k] = i=1 k=j i (t) = i=1 = mW (t ): (209) As noted above, sorting <ref> [15] </ref> and computing prefix sums [33] of mn items can both be done in O (log (mn)) steps on an mn-processor EREW PRAM.
Reference: [16] <author> R. Conway, W. Maxwell, and L. Miller. </author> <title> Theory of Scheduling. </title> <publisher> Addison-Wesley, </publisher> <year> 1967. </year>
Reference-contexts: When the objective is minimizing average completion time, while unweighted sequential tasks can be scheduled optimally in O (n log n) steps <ref> [16] </ref>, scheduling weighted sequential tasks is NP-hard in the strong sense [24]. Furthermore, NMACT is NP-hard in the strong sense even when the tasks have unit execution times [10]. Therefore NMWACT, MACT, and MWACT are also NP-hard in the strong sense.
Reference: [17] <author> L. Dowdy. </author> <title> On the partitioning of multiprocessor systems. </title> <type> Technical report, </type> <institution> Van-derbilt University, </institution> <month> July </month> <year> 1988. </year>
Reference-contexts: We choose a distribution with mean D = m, so that the system load will be given by = D=m = . We use an execution rate function derived from that of Dowdy <ref> [17] </ref>. It is the same for every task, and is given by E i (j) = E (j) = B + j We refer to B as the sublinearity parameter. Note that the function E (j) more nearly reflects linear speedup as B increases.
Reference: [18] <author> J. Du and J. Leung. </author> <title> Complexity of scheduling parallel task systems. </title> <journal> SIAM Journal on Discrete Mathematics, </journal> <volume> 2(4) </volume> <pages> 473-487, </pages> <year> 1989. </year>
Reference-contexts: This is the approach to MM that is taken by Du and Leung <ref> [18] </ref>. The same approach can also be applied to NMM [7, 10, 23]. Note that MM can be viewed as resource-constrained scheduling with one discrete malleable resource. For the variation in which the resource is continuous rather than discrete, see [8, 6].
Reference: [19] <author> W. L. Eastman, S. Even, and I. M. Isaacs. </author> <title> Bounds for the optimal scheduling of n jobs on m processors. </title> <journal> Management Science, </journal> <volume> 11(2) </volume> <pages> 268-279, </pages> <month> November </month> <year> 1964. </year>
Reference-contexts: In the case of average completion time, we present three algorithms for scheduling nonmalleable tasks, and prove approximation factors for all three using a new lower bound. This lower bound is a generalization of the bound for sequential tasks given by Eastman, Even, and Isaacs <ref> [19] </ref>. We also present three algorithms for choosing an allotment to minimize the lower bound.
Reference: [20] <author> A. Feldmann, M.-Y. Kao, J. Sgall, and S.-H. Teng. </author> <title> Optimal online scheduling of parallel jobs with dependencies. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 642-651, </pages> <year> 1993. </year>
Reference-contexts: The same approach can also be applied to NMM [7, 10, 23]. Note that MM can be viewed as resource-constrained scheduling with one discrete malleable resource. For the variation in which the resource is continuous rather than discrete, see [8, 6]. In another variation, Feldmann, Kao, Sgall, and Teng <ref> [20] </ref> consider on-line MM with precedence constraints and linear speedup. 1.3.2 Minimizing Weighted Average Completion Time Scheduling to minimize average completion time is well-studied in the case of tasks that each require a single processor, and many variations have been considered. (See [34] for a survey.) However, approximation algorithms for the <p> Extension to specific parallel architectures. The problem of scheduling malleable tasks can be extended so that some network topology is specified for the m processors, and each task is scheduled on a subset 111 of processors with a particular interconnection network, rather than on an arbitrary subset <ref> [21, 20] </ref>. (Scheduling on a line of processors is one example of this.) With the exception of the semi-oblivious algorithm, our allotment selection algorithms for both average completion time and makespan apply to this extended problem.
Reference: [21] <author> A. Feldmann, J. Sgall, and S.-H. Teng. </author> <title> Dynamic scheduling on parallel machines. </title> <booktitle> In 32nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 111-120, </pages> <year> 1991. </year>
Reference-contexts: Extension to specific parallel architectures. The problem of scheduling malleable tasks can be extended so that some network topology is specified for the m processors, and each task is scheduled on a subset 111 of processors with a particular interconnection network, rather than on an arbitrary subset <ref> [21, 20] </ref>. (Scheduling on a line of processors is one example of this.) With the exception of the semi-oblivious algorithm, our allotment selection algorithms for both average completion time and makespan apply to this extended problem.
Reference: [22] <author> M. Garey and R. Graham. </author> <title> Bounds for multiprocessor scheduling with resource constraints. </title> <journal> SIAM Journal on Computing, </journal> <volume> 4(2) </volume> <pages> 187-200, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: This algorithm can be extended to GMM at a cost of increasing the running time to O (mn). Combining these algorithms with existing NMM algorithms yields 9 running time approx. line? GMM NMM factor or MMM? reference O (mn) 2 no GMM <ref> [22] </ref> O (mn + n log 2 n= log log n) 2 yes GMM [53] O (mn + n log n) 2.5 yes GMM [51] Table 2: MM algorithms the results shown in Table 2. <p> We also present methods for both GMM and MMM for computing an optimal allotment efficiently in parallel. 1.3 Related Work 1.3.1 Minimizing Makespan The predecessor of parallel task scheduling problems is the resource-constrained scheduling problem [6], as posed by Garey and Graham <ref> [22] </ref>. In the resource-constrained scheduling problem, there are one or more resources, and each task requires a certain amount of each resource for the duration of its execution time. NMM can be formulated as a resource-constrained scheduling problem, with available processors as the single 10 resource. Garey and Graham [22] proposed <p> Graham <ref> [22] </ref>. In the resource-constrained scheduling problem, there are one or more resources, and each task requires a certain amount of each resource for the duration of its execution time. NMM can be formulated as a resource-constrained scheduling problem, with available processors as the single 10 resource. Garey and Graham [22] proposed a simple list scheduling approach to this problem. In particular, let the tasks be arranged in some arbitrary order. Whenever processors are free, schedule the first task in the list whose processor requirement does not exceed the number of available processors. <p> The running time follows from the fact that the set of allotments generated in the first step contains no more than mn elements. Applying the NMM results of Garey and Graham <ref> [22] </ref>, this technique yields a 2-approximate algorithm for GMM with running time O (n 2 m log m). <p> The immediate consequences of Corollary 5.2.1 are summarized in Table 2. The MM algorithms in this table are obtained using the NMM algorithms due to Garey and Graham <ref> [22] </ref>, Steinberg [53], and Sleator [51]. The extension of an NMM algorithm to a GMM algorithm given by Corollary 5.2.1 is nearly optimal in the following sense. <p> Therefore, an algorithm for scheduling nonmalleable tasks on a particular architecture can be extended to an algorithm for scheduling malleable tasks on the same architecture. Garey and Graham's <ref> [22] </ref> list scheduling algorithm can be adjusted to apply to hypercubes by arranging the tasks in nonincreasing order of processor requirement, rather than taking them in an arbitrary order. This yields a 2-approximate algorithm for MM on a hypercube. <p> This results in improved approximation factors for several of our MACT and MWACT algorithms. 5. Improved approximation factor for NMM. While Garey and Graham <ref> [22] </ref> have shown that the approximation factor of 2 for list scheduling is tight when the tasks are taken in an arbitrary order, it may be possible to obtain a better approximation factor by arranging the tasks in a particular way.
Reference: [23] <author> M. Garey and D. Johnson. </author> <title> Complexity results for multiprocessor scheduling under resource constraints. </title> <journal> SIAM Journal on Computing, </journal> <volume> 4 </volume> <pages> 397-411, </pages> <year> 1975. </year>
Reference-contexts: This is the approach to MM that is taken by Du and Leung [18]. The same approach can also be applied to NMM <ref> [7, 10, 23] </ref>. Note that MM can be viewed as resource-constrained scheduling with one discrete malleable resource. For the variation in which the resource is continuous rather than discrete, see [8, 6].
Reference: [24] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference-contexts: Regardless of objective, scheduling malleable tasks is a generalization of scheduling nonmalleable tasks, which in turn is a generalization of scheduling sequential tasks (i.e., tasks that require one processor). When the objective is minimizing makespan, even scheduling sequential tasks is NP-hard in the strong sense <ref> [24] </ref>, and therefore NMM and MM are also NP-hard in the strong sense. When the objective is minimizing average completion time, while unweighted sequential tasks can be scheduled optimally in O (n log n) steps [16], scheduling weighted sequential tasks is NP-hard in the strong sense [24]. <p> in the strong sense <ref> [24] </ref>, and therefore NMM and MM are also NP-hard in the strong sense. When the objective is minimizing average completion time, while unweighted sequential tasks can be scheduled optimally in O (n log n) steps [16], scheduling weighted sequential tasks is NP-hard in the strong sense [24]. Furthermore, NMACT is NP-hard in the strong sense even when the tasks have unit execution times [10]. Therefore NMWACT, MACT, and MWACT are also NP-hard in the strong sense. For malleable scheduling problems, it is often helpful to assume that the task execution time functions satisfy certain reasonable conditions.
Reference: [25] <author> D. Ghosal, G. Serazzi, and S. Tripathi. </author> <title> The processor working set and its use in scheduling multiprocessor systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(5) </volume> <pages> 443-453, </pages> <month> May </month> <year> 1991. </year> <month> 126 </month>
Reference-contexts: Such an environment may reflect more accurately the conditions that are encountered in practice. Thus it is not surprising that many processor allocation policies for this environment have been studied, typically using simulations or analytical modeling to evaluate their relative performance. (For example, see <ref> [12, 41, 40, 48, 25, 35, 60, 54] </ref>.) We introduce a new processor allocation policy based on our fastest allotment selection algorithm, and present simulation results suggesting that its performance is comparable to that of the best known policies. 1.4 Organization of This Thesis Chapter 2 contains all the elements of <p> Furthermore, SO (a 1 ,a 2 ) policies and ASP-max policies have three important characteristics in common. First, both are sensitive to system load, allocating fewer processors to each task as system load increases. Various studies show that this is a desirable property <ref> [49, 25, 41, 40, 48, 12] </ref>. Second, both place an upper limit on the allocation of processors to a task, which has also been shown to be desirable [12]. Third, neither requires any information about task demand or execution rate | information that may not be available.
Reference: [26] <author> W. Horn. </author> <title> Minimizing average flow time with parallel machines. </title> <journal> Operations Research, </journal> <volume> 21(3) </volume> <pages> 846-847, </pages> <year> 1973. </year>
Reference: [27] <author> D. Johnson. </author> <title> Near-optimal bin-packing algorithms. </title> <type> Technical Report TR-109, </type> <institution> MIT, </institution> <month> June </month> <year> 1973. </year>
Reference-contexts: As for the running time, note that the FFIA packing of the tasks onto shelves can be computed in O (n log n) steps using the method described by Johnson <ref> [27, 28] </ref>. We will conclude this section with a proof Lemma 4.3.1. The proof will make use of the following alternate definition of A T . Lemma 4.3.3 Let T be a set of unweighted nonmalleable tasks, indexed arbitrarily.
Reference: [28] <author> D. Johnson. </author> <title> Fast algorithms for bin packing. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 8(3) </volume> <pages> 272-314, </pages> <month> June </month> <year> 1974. </year>
Reference-contexts: As for the running time, note that the FFIA packing of the tasks onto shelves can be computed in O (n log n) steps using the method described by Johnson <ref> [27, 28] </ref>. We will conclude this section with a proof Lemma 4.3.1. The proof will make use of the following alternate definition of A T . Lemma 4.3.3 Let T be a set of unweighted nonmalleable tasks, indexed arbitrarily.
Reference: [29] <author> R. Karp and V. Ramachandran. </author> <title> Parallel algorithms for shared-memory machines. </title> <booktitle> In Handbook of Theoretical Computer Science, Volume A: Algorithms and Complexity. </booktitle> <publisher> The MIT Press/Elsevier, </publisher> <year> 1990. </year>
Reference-contexts: Each of these operations can be completed in O (log n) time on an n-processor EREW PRAM, using algorithms due 108 to Cole [15] and Ladner and Fischer [33]. (See Karp and Ramachandran's survey <ref> [29] </ref> for a discussion of parallel selection and sorting.) So after making this change to Step 5b, the running time per iteration remains O (log (mn)). Therefore, we have a makespan allotment selection algorithm for MMM with running time O (log 2 (mn)) on an n-processor EREW PRAM.
Reference: [30] <author> R. Krishnamurti and E. Ma. </author> <title> The processor partitioning problem in special-purpose partitionable systems. </title> <booktitle> In Proceedings of the 1988 International Conference on Parallel Processing, </booktitle> <volume> vol. I, </volume> <pages> pages 434-443, </pages> <year> 1988. </year>
Reference-contexts: The extension of the rectangle-packing problem to packing in three dimensions amounts to NMM on a two-dimensional mesh of processors. Li and Cheng [36] give a 46/7-approximate algorithm for this problem with running time O (n log n). Krishnamurti and Ma <ref> [30] </ref> first posed MM (the MMM variant), but in a restricted form.
Reference: [31] <author> R. Krishnamurti and B. Narahari. </author> <title> Preemptive scheduling of independent jobs on partitionable parallel architectures. </title> <booktitle> In Proceedings of the 1992 International Conference on Parallel Processing, </booktitle> <volume> vol. I, </volume> <pages> pages 268-275, </pages> <year> 1992. </year>
Reference-contexts: Belkhale and Banerjee [5] consider a restriction of MMM in which M i = [m] for all tasks i. For this special case, they give a 2-approximate algorithm with running time O (n log m + m log m) that applies to lines. 11 Krishnamurti and Narahari <ref> [31] </ref> consider a less restricted version of MMM in which M i f1; 2; 4; : : : ; 2 r i g for all tasks i. They obtain a 2-approximate algorithm with running time O (n + m log m), but it requires the use of preemption.
Reference: [32] <author> H. W. Kuhn. </author> <title> The Hungarian method for the assignment problem. </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 2 </volume> <pages> 83-97, </pages> <year> 1955. </year>
Reference-contexts: We have not yet specified how the edge weights C i (s) will be computed, and how a minimum weight matching will be found. The latter can be done in O (n 3 ) steps using the Hungarian method, which is due to Kuhn <ref> [32, 43] </ref>. As for computing the edge weights, one simple method is to compute C i (s; j) for all i; s 2 [n] and all j 2 M i . This requires O (mn 2 ) steps.
Reference: [33] <author> R. Ladner and M. Fischer. </author> <title> Parallel prefix computation. </title> <journal> Journal of the ACM, </journal> <volume> 27 </volume> <pages> 831-838, </pages> <year> 1980. </year>
Reference-contexts: Each of these operations can be completed in O (log n) time on an n-processor EREW PRAM, using algorithms due 108 to Cole [15] and Ladner and Fischer <ref> [33] </ref>. (See Karp and Ramachandran's survey [29] for a discussion of parallel selection and sorting.) So after making this change to Step 5b, the running time per iteration remains O (log (mn)). <p> [n] ft [k; z [k]]g, the associated prefix sum is the minimum total work required if every task has execution time not exceeding t : X u [i; k] = i=1 k=j i (t) = i=1 = mW (t ): (209) As noted above, sorting [15] and computing prefix sums <ref> [33] </ref> of mn items can both be done in O (log (mn)) steps on an mn-processor EREW PRAM.
Reference: [34] <author> E. Lawler, J. Lenstra, A. Rinnooy Kan, and D. Shmoys. </author> <title> Sequencing and scheduling: Algorithms and complexity. </title> <booktitle> In Handbook of Operations Research and Management Science, Volume IV: Logistics of Production and Inventory. </booktitle> <publisher> North-Holland, </publisher> <year> 1993. </year>
Reference-contexts: In another variation, Feldmann, Kao, Sgall, and Teng [20] consider on-line MM with precedence constraints and linear speedup. 1.3.2 Minimizing Weighted Average Completion Time Scheduling to minimize average completion time is well-studied in the case of tasks that each require a single processor, and many variations have been considered. (See <ref> [34] </ref> for a survey.) However, approximation algorithms for the natural extension from sequential tasks to parallel tasks are scarce.
Reference: [35] <author> S. Leutenegger and M. Vernon. </author> <title> The performance of multiprogrammed multiprocessor scheduling policies. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <volume> volume 18, </volume> <pages> pages 226-236, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Such an environment may reflect more accurately the conditions that are encountered in practice. Thus it is not surprising that many processor allocation policies for this environment have been studied, typically using simulations or analytical modeling to evaluate their relative performance. (For example, see <ref> [12, 41, 40, 48, 25, 35, 60, 54] </ref>.) We introduce a new processor allocation policy based on our fastest allotment selection algorithm, and present simulation results suggesting that its performance is comparable to that of the best known policies. 1.4 Organization of This Thesis Chapter 2 contains all the elements of
Reference: [36] <author> K. Li and K. H. Cheng. </author> <title> On 3-dimensional packing. </title> <journal> SIAM Journal on Computing, </journal> <volume> 19(5) </volume> <pages> 847-867, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: The extension of the rectangle-packing problem to packing in three dimensions amounts to NMM on a two-dimensional mesh of processors. Li and Cheng <ref> [36] </ref> give a 46/7-approximate algorithm for this problem with running time O (n log n). Krishnamurti and Ma [30] first posed MM (the MMM variant), but in a restricted form. <p> Garey and Graham's [22] list scheduling algorithm can be adjusted to apply to hypercubes by arranging the tasks in nonincreasing order of processor requirement, rather than taking them in an arbitrary order. This yields a 2-approximate algorithm for MM on a hypercube. Li and Cheng <ref> [36] </ref> give a 46/7-approximate algorithm for packing in three dimensions, which is identical to NMM on a 2-d mesh. The lower bound ! T is used to prove the approximation factor, and therefore we have a 46/7-approximate algorithm for MM on a 2-d mesh.
Reference: [37] <author> W. Ludwig and P. Tiwari. </author> <title> Scheduling malleable and nonmalleable parallel tasks. </title> <booktitle> In Proceedings of the 5th SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: When all the tasks on the current shelf have been scheduled, go on to the next shelf. 89 Chapter 5 Scheduling to Minimize Makespan Note: The results reported in this chapter were obtained jointly with Tiwari and are reported in <ref> [37] </ref>, as well as in a paper that has been submitted to SIAM Journal on Computing. Many algorithms for scheduling nonmalleable tasks to minimize makespan (NMM) already exist, including algorithms for NMM on a line of processors.
Reference: [38] <author> S. Majumdar, D. Eager, and R. Bunt. </author> <title> Scheduling in multiprogrammed parallel systems. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <volume> volume 16, </volume> <pages> pages 104-113, </pages> <month> May </month> <year> 1988. </year> <month> 127 </month>
Reference-contexts: The experiments we present here all use N i = m, but letting N i be a random variable yields similar results. For task demand, we use a two-stage hyperexponential distribution with coefficient of variation C D = 5, following Majumdar, Eager, and Bunt <ref> [38] </ref>. We choose a distribution with mean D = m, so that the system load will be given by = D=m = . We use an execution rate function derived from that of Dowdy [17].
Reference: [39] <author> R. K. Mansharamani and M. K. Vernon. </author> <title> Approximate analysis of parallel processor allocation policies. </title> <type> Technical Report 1187, </type> <institution> University of Wisconsin-Madison, Computer Sciences Department, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: processor allocation formula given by Sevcik [49]: i= &gt; &gt; &lt; N i if &lt; 1 max + 1 1 (132) where = :25. 3.5.2 The Model For our simulations, we adopt the system and workload model used by Chiang et al. [12], which is due to Mansharamani and Vernon <ref> [39] </ref>. Tasks arrive according to a Poisson process with rate . We have m identical processors on which to schedule the tasks, and there is no scheduling overhead.
Reference: [40] <author> V. Naik, S. Setia, and M. Squillante. </author> <title> Performance analysis of job scheduling policies in parallel supercomputing environments. </title> <booktitle> In Supercomputing '93, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: Such an environment may reflect more accurately the conditions that are encountered in practice. Thus it is not surprising that many processor allocation policies for this environment have been studied, typically using simulations or analytical modeling to evaluate their relative performance. (For example, see <ref> [12, 41, 40, 48, 25, 35, 60, 54] </ref>.) We introduce a new processor allocation policy based on our fastest allotment selection algorithm, and present simulation results suggesting that its performance is comparable to that of the best known policies. 1.4 Organization of This Thesis Chapter 2 contains all the elements of <p> Furthermore, SO (a 1 ,a 2 ) policies and ASP-max policies have three important characteristics in common. First, both are sensitive to system load, allocating fewer processors to each task as system load increases. Various studies show that this is a desirable property <ref> [49, 25, 41, 40, 48, 12] </ref>. Second, both place an upper limit on the allocation of processors to a task, which has also been shown to be desirable [12]. Third, neither requires any information about task demand or execution rate | information that may not be available.
Reference: [41] <author> V. Naik, S. Setia, and M. Squillante. </author> <title> Scheduling of large scientific applications on distributed memory multiprocessor systems. </title> <booktitle> In Proceedings of the 6th SIAM Conference on Parallel Processing for Scientific Computation, </booktitle> <year> 1993. </year>
Reference-contexts: Such an environment may reflect more accurately the conditions that are encountered in practice. Thus it is not surprising that many processor allocation policies for this environment have been studied, typically using simulations or analytical modeling to evaluate their relative performance. (For example, see <ref> [12, 41, 40, 48, 25, 35, 60, 54] </ref>.) We introduce a new processor allocation policy based on our fastest allotment selection algorithm, and present simulation results suggesting that its performance is comparable to that of the best known policies. 1.4 Organization of This Thesis Chapter 2 contains all the elements of <p> Furthermore, SO (a 1 ,a 2 ) policies and ASP-max policies have three important characteristics in common. First, both are sensitive to system load, allocating fewer processors to each task as system load increases. Various studies show that this is a desirable property <ref> [49, 25, 41, 40, 48, 12] </ref>. Second, both place an upper limit on the allocation of processors to a task, which has also been shown to be desirable [12]. Third, neither requires any information about task demand or execution rate | information that may not be available.
Reference: [42] <author> B. Narahari and R. Krishnamurti. </author> <title> Scheduling independent tasks on partitionable hypercube multiprocessors. </title> <booktitle> In 7th International Parallel Processing Symposium, </booktitle> <pages> pages 118-122, </pages> <year> 1993. </year>
Reference-contexts: They obtain a 2-approximate algorithm with running time O (n + m log m), but it requires the use of preemption. In a later improvement <ref> [42] </ref>, they give a nonpreemptive algorithm for the same problem with the same approximation factor and running time O (n log n + m log m). Both algorithms apply to lines.
Reference: [43] <author> C. Papadimitriou and K. Steiglitz. </author> <title> Combinatorial Optimization. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: We have not yet specified how the edge weights C i (s) will be computed, and how a minimum weight matching will be found. The latter can be done in O (n 3 ) steps using the Hungarian method, which is due to Kuhn <ref> [32, 43] </ref>. As for computing the edge weights, one simple method is to compute C i (s; j) for all i; s 2 [n] and all j 2 M i . This requires O (mn 2 ) steps.
Reference: [44] <author> V. Peris, M. Squillante, and V. Naik. </author> <title> Analysis of the impact of memory in distributed parallel processing systems. </title> <type> Technical Report RC 19336, </type> <institution> IBM Research Division, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: In this case, we may see work decreasing as we increase the allocation from three to four processors. Another situation in which the condition may be violated arises from the impact of memory in distributed parallel processing systems <ref> [44] </ref>. In such systems, the amount of local memory allocated to a task is limited by the number 5 of processors allocated to it, and allocating insufficient local memory may result in excessive paging overhead.
Reference: [45] <author> E. Rosti, E. Smirni, L. Dowdy, G. Serazzi, and B. Carlson. </author> <title> Robust partitioning policies of multiprocessor systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 141-165, </pages> <year> 1994. </year>
Reference-contexts: ASP-max is the same as ASP, except that there is an additional parameter max, and no task can be assigned more than max processors. ASP-max is essentially identical to EPM, which was introduced by Rosti, Smirni, Dowdy, Serazzi, and Carlson <ref> [45] </ref>.
Reference: [46] <author> U. Schwiegelshohn, W. Ludwig, J. Wolf, J. Turek, and P. Yu. </author> <title> Smart SMART bounds for weighted response time scheduling. </title> <type> Technical report, </type> <institution> IBM T. J. Watson Research Center, </institution> <year> 1994. </year>
Reference-contexts: We conclude that SO (a 1 ,a 2 ) appears to be a promising family of RTC policies. 64 Chapter 4 Algorithms for NMACT and NMWACT Note: The results reported in this chapter were obtained jointly with Schwiegelshohn, Wolf, Turek, and Yu, and are reported in <ref> [46] </ref>. We have seen that the approximation factor of the LRF algorithm for NMWACT depends on the number of processors required by the tasks.
Reference: [47] <author> S. Setia and S. Tripathi. </author> <title> An analysis of several processor partitioning policies for parallel computers. </title> <type> Technical Report CS-TR-2684, </type> <institution> University of Maryland, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: Therefore, we will follow the experimental methods of Chiang et al. and compare the performance of SO with that of ASP-max and ASP-max+. ASP-max is based on ASP (adaptive static partitioning), a policy introduced by Setia and Tripathi <ref> [47] </ref>. ASP works in the following way. Whenever processors are free and there are tasks ready to be executed, divide the processors as equally as possible among the tasks, subject to the constraint that no task is assigned more processors than its available parallelism.
Reference: [48] <author> S. Setia and S. Tripathi. </author> <title> A comparative analysis of static processor partitioning policies for parallel computers. </title> <booktitle> In Proceedings of the International Workshop on Modeling and Simulation of Computer and Telecommunication Systems, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: Such an environment may reflect more accurately the conditions that are encountered in practice. Thus it is not surprising that many processor allocation policies for this environment have been studied, typically using simulations or analytical modeling to evaluate their relative performance. (For example, see <ref> [12, 41, 40, 48, 25, 35, 60, 54] </ref>.) We introduce a new processor allocation policy based on our fastest allotment selection algorithm, and present simulation results suggesting that its performance is comparable to that of the best known policies. 1.4 Organization of This Thesis Chapter 2 contains all the elements of <p> Furthermore, SO (a 1 ,a 2 ) policies and ASP-max policies have three important characteristics in common. First, both are sensitive to system load, allocating fewer processors to each task as system load increases. Various studies show that this is a desirable property <ref> [49, 25, 41, 40, 48, 12] </ref>. Second, both place an upper limit on the allocation of processors to a task, which has also been shown to be desirable [12]. Third, neither requires any information about task demand or execution rate | information that may not be available.
Reference: [49] <author> K. Sevcik. </author> <title> Characterization of parallelism in applications and their use in scheduling. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <volume> volume 17, </volume> <pages> pages 171-180, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: same as ASP-max , except that instead of using max as an upper bound on the number of processors allocated to each task, it uses a function i of max and the system load that is computed using a 57 formula analogous to the processor allocation formula given by Sevcik <ref> [49] </ref>: i= &gt; &gt; &lt; N i if &lt; 1 max + 1 1 (132) where = :25. 3.5.2 The Model For our simulations, we adopt the system and workload model used by Chiang et al. [12], which is due to Mansharamani and Vernon [39]. <p> Furthermore, SO (a 1 ,a 2 ) policies and ASP-max policies have three important characteristics in common. First, both are sensitive to system load, allocating fewer processors to each task as system load increases. Various studies show that this is a desirable property <ref> [49, 25, 41, 40, 48, 12] </ref>. Second, both place an upper limit on the allocation of processors to a task, which has also been shown to be desirable [12]. Third, neither requires any information about task demand or execution rate | information that may not be available.
Reference: [50] <author> H. Shachnai and J. Glasgow. </author> <title> Minimizing the flow time for parallelizable task systems. </title> <type> Technical Report TR790, </type> <institution> Technion, </institution> <month> November </month> <year> 1993. </year> <month> 128 </month>
Reference-contexts: However, they are still a generalization of sequential tasks, and therefore the NP-hardness results for MM and MWACT apply even under these conditions. As for MACT, Shachnai and Glasgow <ref> [50] </ref> have shown that a restricted version of MACT that satisfies these conditions is NP-hard in the strong sense. Therefore, since the problems that we are studying are all NP-hard, we will consider approximation algorithms, and evaluate these algorithms in terms of approximation factor and running time.
Reference: [51] <author> D. Sleator. </author> <title> A 2.5 times optimal algorithm for packing in two dimensions. </title> <journal> Information Processing Letters, </journal> <volume> 10(1) </volume> <pages> 37-40, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: Combining these algorithms with existing NMM algorithms yields 9 running time approx. line? GMM NMM factor or MMM? reference O (mn) 2 no GMM [22] O (mn + n log 2 n= log log n) 2 yes GMM [53] O (mn + n log n) 2.5 yes GMM <ref> [51] </ref> Table 2: MM algorithms the results shown in Table 2. To our knowledge, 2 is the best known approximation factor of a polynomial-time algorithm for GMM, and these are the fastest known running times in which that factor can be achieved. <p> Garey and Graham show that this algorithm has an approximation factor of 2 for NMM. Another closely related problem is the oriented orthogonal rectangle packing problem, first posed by Baker, Coffman, and Rivest [3], and also studied by many others <ref> [14, 51, 2, 4, 53] </ref>. This problem is in fact identical to NMM on a line of processors: one of the dimensions in the rectangle-packing problem corresponds to time in NMM, and the other corresponds to processors. <p> This problem is in fact identical to NMM on a line of processors: one of the dimensions in the rectangle-packing problem corresponds to time in NMM, and the other corresponds to processors. Sleator <ref> [51] </ref> gives a 2.5-approximate rectangle-packing algorithm with running time O (n log n). This was the best known approximation factor for this problem until recently, when Steinberg [53] gave a 2-approximate algorithm with only a slightly greater running time of O (n log 2 n= log log n). <p> Applying the NMM results of Garey and Graham [22], this technique yields a 2-approximate algorithm for GMM with running time O (n 2 m log m). For NMM on a line, the rectangle-packing results of Steinberg [53] and Sleator <ref> [51] </ref> yield a 2-approximate algorithm with running time O (mn 2 log 2 n= log log n), and a 2.5-approximate algorithm with running time O (mn 2 log n), respectively. <p> The immediate consequences of Corollary 5.2.1 are summarized in Table 2. The MM algorithms in this table are obtained using the NMM algorithms due to Garey and Graham [22], Steinberg [53], and Sleator <ref> [51] </ref>. The extension of an NMM algorithm to a GMM algorithm given by Corollary 5.2.1 is nearly optimal in the following sense. Any NMM instance can also be formulated as an MMM instance, and therefore any algorithm for MMM or GMM can also be applied to NMM.
Reference: [52] <author> W. Smith. </author> <title> Various optimizers for single-stage production. </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 3 </volume> <pages> 59-66, </pages> <year> 1956. </year>
Reference-contexts: Each task has a squashed counterpart with the same work requirement and the same weight, but that requires all m processors. (So its execution time is p i t i (p i )=m.) An optimal schedule of the squashed tasks is obtained using Smith's rule <ref> [52] </ref>: schedule the tasks in order of nondecreasing ratio of work to weight. This gives a lower bound on total weighted completion time for the original task set. In order to give an expression for this lower bound, we introduce the following notation. <p> This method of ordering the shelves amounts to Smith's ratio rule for scheduling tasks of width 1 on a single processor <ref> [52] </ref>, and has the same proof of optimality. Proof of Lemma 4.1.1: Suppose that the shelves are not in order of nondecreasing H k =W k . Then there is a shelf k such that H k =W k &gt; H k+1 =W k+1 .
Reference: [53] <author> A. Steinberg. </author> <title> A strip packing algorithm with absolute performance bound 2. </title> <note> To appear in SIAM Journal on Computing. </note>
Reference-contexts: Combining these algorithms with existing NMM algorithms yields 9 running time approx. line? GMM NMM factor or MMM? reference O (mn) 2 no GMM [22] O (mn + n log 2 n= log log n) 2 yes GMM <ref> [53] </ref> O (mn + n log n) 2.5 yes GMM [51] Table 2: MM algorithms the results shown in Table 2. <p> Garey and Graham show that this algorithm has an approximation factor of 2 for NMM. Another closely related problem is the oriented orthogonal rectangle packing problem, first posed by Baker, Coffman, and Rivest [3], and also studied by many others <ref> [14, 51, 2, 4, 53] </ref>. This problem is in fact identical to NMM on a line of processors: one of the dimensions in the rectangle-packing problem corresponds to time in NMM, and the other corresponds to processors. <p> Sleator [51] gives a 2.5-approximate rectangle-packing algorithm with running time O (n log n). This was the best known approximation factor for this problem until recently, when Steinberg <ref> [53] </ref> gave a 2-approximate algorithm with only a slightly greater running time of O (n log 2 n= log log n). The extension of the rectangle-packing problem to packing in three dimensions amounts to NMM on a two-dimensional mesh of processors. <p> Applying the NMM results of Garey and Graham [22], this technique yields a 2-approximate algorithm for GMM with running time O (n 2 m log m). For NMM on a line, the rectangle-packing results of Steinberg <ref> [53] </ref> and Sleator [51] yield a 2-approximate algorithm with running time O (mn 2 log 2 n= log log n), and a 2.5-approximate algorithm with running time O (mn 2 log n), respectively. <p> The immediate consequences of Corollary 5.2.1 are summarized in Table 2. The MM algorithms in this table are obtained using the NMM algorithms due to Garey and Graham [22], Steinberg <ref> [53] </ref>, and Sleator [51]. The extension of an NMM algorithm to a GMM algorithm given by Corollary 5.2.1 is nearly optimal in the following sense. Any NMM instance can also be formulated as an MMM instance, and therefore any algorithm for MMM or GMM can also be applied to NMM.
Reference: [54] <author> A. Tucker and A. Gupta. </author> <title> Process control and scheduling issues for multipro-grammed shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 159-166, </pages> <year> 1989. </year>
Reference-contexts: Such an environment may reflect more accurately the conditions that are encountered in practice. Thus it is not surprising that many processor allocation policies for this environment have been studied, typically using simulations or analytical modeling to evaluate their relative performance. (For example, see <ref> [12, 41, 40, 48, 25, 35, 60, 54] </ref>.) We introduce a new processor allocation policy based on our fastest allotment selection algorithm, and present simulation results suggesting that its performance is comparable to that of the best known policies. 1.4 Organization of This Thesis Chapter 2 contains all the elements of
Reference: [55] <author> J. Turek, W. Ludwig, J. L. Wolf, L. Fleischer, P. Tiwari, J. Glasgow, U. Schwiegelshohn, and P. S. Yu. </author> <title> Scheduling parallelizable tasks to minimize average response time. </title> <booktitle> In 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1994. </year>
Reference-contexts: and directions for future work. 14 Chapter 2 MWACT Algorithm Foundations Note: The results reported in this chapter and in Sections 3.1 and 3.2 of the subsequent chapter were obtained jointly with Tiwari, and similar results were obtained independently by Turek, Wolf, Fleischer, Glasgow, Schwiegelshohn, and Yu, and appear in <ref> [55] </ref>. 2.1 NMWACT Lower Bounds A lower bound on weighted average completion time for nonmalleable task sets provides the link between the two steps of our approach to MWACT.
Reference: [56] <author> J. Turek, U. Schwiegelshohn, J. L. Wolf, and P. S. Yu. </author> <title> Scheduling parallel tasks to minimize average response time. </title> <booktitle> In Proceedings of the 5th SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: Results for resource-constrained scheduling with this objective are directed toward identifying special cases that can be solved in polynomial time [6, 9], rather than providing approximation algorithms for the general case with a single resource. It was only recently that Turek, Schwiegelshohn, Wolf, and Yu <ref> [56] </ref> demonstrated an NMACT algorithm with running time O (n log n) and approximation factor 32, the first proof of a constant approximation factor for a polynomial-time NMACT algorithm. Our 8-approximate NMACT algorithm and 10.43-approximate NMWACT algorithm improve this result. <p> 1 (s) ): (5) Now if we let k = 1 (s) and r = (i) and change the order of summation, then we get A T (p) = m k=1 (k) X w 1 (r) (6) 1 n X ( w) This is the "squashed area" lower bound of <ref> [56] </ref>, extended to weighted tasks. Let 1 n X w i p i t i (p i ) (8) be the ratio of the weighted sum of the task work requirements to the total number of processors.
Reference: [57] <author> J. Turek, J. Wolf, and P. Yu. </author> <title> Approximate algorithms for scheduling parallelizable tasks. </title> <booktitle> In 4th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 323-332, </pages> <year> 1992. </year>
Reference-contexts: In a later improvement [42], they give a nonpreemptive algorithm for the same problem with the same approximation factor and running time O (n log n + m log m). Both algorithms apply to lines. The precursor to our two-step method was introduced by Turek, Wolf, and Yu <ref> [57] </ref>, who showed that an algorithm for NMM with approximation factor and running time Q (m; n) can be extended to an algorithm for GMM with the same approximation factor and running time O (mn Q (m; n)).
Reference: [58] <author> R. Uzsoy. </author> <title> Scheduling a single batch processing machine with non-identical job sizes. </title> <journal> International Journal of Production Research, </journal> <volume> 32(7) </volume> <pages> 1615-1635, </pages> <year> 1994. </year>
Reference-contexts: This is the case with parallel systems where the user specifies for each job the number of processors on which it is to be executed. Another example of nonmalleable tasks is found in scheduling burn-in operations in semiconductor manufacturing <ref> [58] </ref>. In this problem, each task consists of some number of circuit boards that are to be heated in an oven for some length of time.
Reference: [59] <author> J. Weglarz. </author> <title> Multiprocessor scheduling with memory allocation | a deterministic approach. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-29(8):703-709, </volume> <month> August </month> <year> 1980. </year>
Reference-contexts: Although we frame the discussion of resource allocation in terms of allocating processors to parallel tasks, the model that we are using applies whenever there is a single resource that can 2 be allocated to independent tasks in arbitrary amounts. Another example of such a resource is memory <ref> [59] </ref>. Suppose we have a parallel system with virtual memory and a common primary memory in which each task is executed on a single processor. Then we can treat the execution time of a task as a function of the number of pages of main memory it is allocated.
Reference: [60] <author> J. Zahorjan and C. McCann. </author> <title> Processor scheduling in shared memory multiprocessors. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 214-225, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Such an environment may reflect more accurately the conditions that are encountered in practice. Thus it is not surprising that many processor allocation policies for this environment have been studied, typically using simulations or analytical modeling to evaluate their relative performance. (For example, see <ref> [12, 41, 40, 48, 25, 35, 60, 54] </ref>.) We introduce a new processor allocation policy based on our fastest allotment selection algorithm, and present simulation results suggesting that its performance is comparable to that of the best known policies. 1.4 Organization of This Thesis Chapter 2 contains all the elements of
References-found: 60

