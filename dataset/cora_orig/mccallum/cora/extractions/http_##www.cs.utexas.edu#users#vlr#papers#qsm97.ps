URL: http://www.cs.utexas.edu/users/vlr/papers/qsm97.ps
Refering-URL: http://www.cs.utexas.edu/users/vlr/pub.html
Root-URL: 
Title: Can a Shared-Memory Model Serve as a Bridging Model for Parallel Computation?  
Author: Phillip B. Gibbons Yossi Matias Vijaya Ramachandran 
Date: November 11, 1997  
Abstract: There has been a great deal of interest recently in the development of general-purpose bridging models for parallel computation. Models such as the bsp and logp have been proposed as more realistic alternatives to the widely-used pram model. The bsp and logp models imply a rather different style for designing algorithms when compared to the pram model. Indeed, while many consider data parallelism as a convenient style, and the shared-memory abstraction as an easy-to-use platform, the bandwidth limitations of current machines have diverted much attention to message-passing and distributed-memory models (such as the bsp and logp) that account more properly for these limitations. In this paper we consider the question of whether a shared-memory model can serve as an effective bridging model for parallel computation. In particular, can a shared-memory model be as effective as, say, the bsp? As a candidate for a bridging model, we introduce the Queuing Shared Memory (qsm) model, which accounts for limited communication bandwidth while still providing a simple shared-memory abstraction. We substantiate the ability of the qsm to serve as a bridging model by providing a simple work-preserving emulation of the qsm on both the bsp, and on a related model, the (d; x)-bsp. We present evidence that the features of the qsm are essential to its effectiveness as a bridging model. In addition, we describe scenarios in which the high-level qsm more accurately models certain machines than the more detailed bsp and logp models. Finally, we present algorithmic results for the qsm, as well as general strategies for mapping algorithms designed for the bsp or pram models onto the qsm model. Our main conclusion is that shared-memory models can potentially serve as viable alternatives to existing message-passing, distributed-memory bridging models. fl A preliminary version of this paper appeared in Proc. 9th ACM Symp. on Parallel Algorithms and Architectures, pages 72-83, June 1997. y Information Sciences Research Center, Bell Laboratories (Lucent Technologies), 600 Mountain Avenue, Murray Hill NJ 07974. email: gibbons@research.bell-labs.com z Information Sciences Research Center, Bell Laboratories (Lucent Technologies), 600 Mountain Avenue, Murray Hill NJ 07974. Current address is Tel-Aviv University, Ramat Aviv, Tel-Aviv 69978 Israel. Email: matias@math.tau.ac.il. x Dept. of Computer Sciences, University of Texas at Austin, Austin TX 78712. email: vlr@cs.utexas.edu. This work was supported in part by NSF grant CCR/GER-90-23059. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Adler, P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Modeling parallel bandwidth: Local vs. global restrictions. </title> <booktitle> In Proc. 9th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 94-105, </pages> <month> June </month> <year> 1997. </year> <month> 27 </month>
Reference-contexts: The following lower bounds for the qsm are given in <ref> [1] </ref>. <p> A lower bound of (g lg n= lg g) for broadcasting to n processors is given in <ref> [1] </ref>; in contrast to an earlier lower bound for this problem on the bsp given in [43] this lower bound holds even if processors can acquire knowledge through non-receipt of messages (i.e., by reading memory locations that were not updated by a recent write operation). <p> Such validation may reveal the primary importance of features not present in either the qsm, bsp or logp. For example, each of these models defines a single bandwidth parameter that reflects a per-processor bandwidth limitation; other recent work has considered variants of these models with an aggregate bandwidth limitation <ref> [1] </ref> or a hierarchical bandwidth limitation that accounts for network proximity [50, 24, 25, 44, 69].
Reference: [2] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> On communication latency in PRAM computations. </title> <booktitle> In Proc. 1st ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 11-21, </pages> <month> June </month> <year> 1989. </year>
Reference: [3] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> Communication complexity of PRAMs. </title> <journal> Theoretical Computer Science, </journal> <volume> 71(1) </volume> <pages> 3-28, </pages> <year> 1990. </year>
Reference-contexts: least for certain machines, taking the maximum is more accurate than taking their sum. 2 This issue is explored further in Section 7. 5 Comparison of Models of Parallel Computation model synchrony communication parameters PRAM [27] lock-step shared memory p Module Parallel Computer (mpc) [56] lock-step distributed memory p LPRAM <ref> [3] </ref> lock-step shared memory p; ` Phase LPRAM [30] bulk-synchrony shared memory p; `; s XPRAM [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33]
Reference: [4] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> Sorting in c lg n parallel steps. </title> <journal> Combinatorica, </journal> <volume> 3(1) </volume> <pages> 1-19, </pages> <year> 1983. </year>
Reference-contexts: The problem of designing highly parallel algorithms for sorting n keys from a totally ordered set is a well-studied one. On the erew pram, there are two known O (lg n) time, O (n lg n) work algorithms for general sorting <ref> [4, 18] </ref>; these deterministic algorithms match the asymptotic lower bounds for general sorting on the erew and crew pram models. Both of these algorithms map onto the qsm to run in O (g lg n) time and O (gn lg n) work using Observation 6.2.
Reference: [5] <author> A. Alexandrov, M. F. Ionescu, K. E. Schauser, and C. Sheiman. LogGP: </author> <title> Incorporating long messages into the LogP model | one step closer towards a realistic model for parallel computation. </title> <booktitle> In Proc. 7th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 95-105, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: It is well known that hashing destroys spatial locality, but not temporal locality. Spatial locality enables long messages to be sent between components, thereby minimizing overheads on many machines. Some models, such as bdm [42], loggp <ref> [5] </ref>, and bsp fl [12, 11], account for advantages in long messages; most others, e.g., qsm, bsp, (d; x)-bsp and logp, do not. Thus the qsm shares with the bsp, (d; x)-bsp and logp models a disregard for spatial locality. Spatial locality can also arise in initial data placement. <p> Third, as discussed in Section 4, each of these models disregards spatial locality. Variants of the bsp and logp that account for spatial locality include <ref> [42, 5, 44, 11] </ref>. In machines supporting a single address space, the unit of data transfer between components is typically either a cache line or a page, and hence opportunities to exploit spatial locality are restricted to that level of granularity.
Reference: [6] <author> B. Alpern, L. Carter, and E. Feig. </author> <title> Uniform memory hierarchies. </title> <booktitle> In Proc. 31st IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 600-608, </pages> <month> October </month> <year> 1990. </year>
Reference: [7] <author> R. J. Anderson and G. L. Miller. </author> <title> Optical communication for pointer based algorithms. </title> <type> Technical Report CRI 88-14, </type> <institution> Computer Science Department, University of Southern California, </institution> <address> Los Angeles, CA, </address> <year> 1988. </year>
Reference: [8] <author> Y. Aumann and M. O. Rabin. </author> <title> Clock construction in fully asynchronous parallel systems and PRAM simulation. </title> <booktitle> In Proc. 33rd IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 147-156, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Thus, a number of alternative, intermediate models have been proposed and studied in the last eight years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g. <ref> [8, 19, 20, 26, 30, 33, 47, 54, 57] </ref>). Others focus on accounting for the overheads in accessing the shared memory ([2, 3, 24, 30, 39, 42, 50, 53]) or in sending messages ([5, 9, 10, 21, 22, 37, 51, 52, 65]).
Reference: [9] <author> A. Bar-Noy, J. Bruck, C. T. Ho, S. Kipnis, and B. Schieber. </author> <title> Computing global combine operations in the multi-port postal model. </title> <booktitle> In Proc. 5th IEEE Symp. on Parallel and Distributed Processing, </booktitle> <pages> pages 336-343, </pages> <month> December </month> <year> 1993. </year>
Reference: [10] <author> A. Bar-Noy and S. Kipnis. </author> <title> Designing broadcasting algorithms in the postal model for message-passing systems. </title> <booktitle> In Proc. 4th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 13-22, </pages> <month> June-July </month> <year> 1992. </year>
Reference-contexts: parameters PRAM [27] lock-step shared memory p Module Parallel Computer (mpc) [56] lock-step distributed memory p LPRAM [3] lock-step shared memory p; ` Phase LPRAM [30] bulk-synchrony shared memory p; `; s XPRAM [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model <ref> [10] </ref> asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33] asynchronous shared memory p QRQW PRAM [34] bulk-synchrony shared memory p Block Distributed Memory (bdm) [42] bulk-synchrony distributed memory p; g; L; B PRAM (m) model [53] lock-step shared memory p; m Interval
Reference: [11] <author> A. Baumker and W. Dittrich. </author> <title> Fully dynamic search trees for an extension of the BSP model. </title> <booktitle> In Proc. 8th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 233-242, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: It is well known that hashing destroys spatial locality, but not temporal locality. Spatial locality enables long messages to be sent between components, thereby minimizing overheads on many machines. Some models, such as bdm [42], loggp [5], and bsp fl <ref> [12, 11] </ref>, account for advantages in long messages; most others, e.g., qsm, bsp, (d; x)-bsp and logp, do not. Thus the qsm shares with the bsp, (d; x)-bsp and logp models a disregard for spatial locality. Spatial locality can also arise in initial data placement. <p> Third, as discussed in Section 4, each of these models disregards spatial locality. Variants of the bsp and logp that account for spatial locality include <ref> [42, 5, 44, 11] </ref>. In machines supporting a single address space, the unit of data transfer between components is typically either a cache line or a page, and hence opportunities to exploit spatial locality are restricted to that level of granularity.
Reference: [12] <editor> A. Baumker, W. Dittrich, and F. Meyer auf der Heide. </editor> <title> Truly efficient parallel algorithms: 1-optimal multisearch for an extension of the BSP model. </title> <type> Technical report, </type> <institution> University of Paderborn, </institution> <year> 1996. </year>
Reference-contexts: It is well known that hashing destroys spatial locality, but not temporal locality. Spatial locality enables long messages to be sent between components, thereby minimizing overheads on many machines. Some models, such as bdm [42], loggp [5], and bsp fl <ref> [12, 11] </ref>, account for advantages in long messages; most others, e.g., qsm, bsp, (d; x)-bsp and logp, do not. Thus the qsm shares with the bsp, (d; x)-bsp and logp models a disregard for spatial locality. Spatial locality can also arise in initial data placement.
Reference: [13] <author> P. Beame and J. H-astad. </author> <title> Optimal bounds for decision problems on the CRCW PRAM. </title> <journal> Journal of the ACM, </journal> <volume> 36(3) </volume> <pages> 643-670, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: The following lower bounds for the qsm are given in [1]. The crcw pram lower bound result of Beame and Hastad <ref> [13] </ref> gives a lower bound for the n-element parity, summation, list ranking and sorting problems of (glg n= lg lg n) time on the qsm for either deterministic or randomized algorithms when the number of processors is polynomial in n, the size of the input.
Reference: [14] <author> G. E. Blelloch. </author> <title> Vector Models for Data-Parallel Computing. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference: [15] <author> G. E. Blelloch. </author> <title> Programming parallel algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 39(3) </volume> <pages> 85-97, </pages> <year> 1996. </year>
Reference-contexts: Finally, a few models incorporate powerful aggregate communication primitives ([14, 17]). Given this plethora of models, it is natural to seek to distinguish a few models with the most promise, and concentrate on these models. Advocates such as Vishkin [67], Kennedy [48], Smith [63], and Blelloch <ref> [15] </ref> have long presented arguments in support of the shared-memory abstraction. On the other hand, shared-memory models have been criticized for years for failing to model essential realities of parallel machines. In particular, the pram model has been faulted for completely failing to model bandwidth limitations of parallel machines.
Reference: [16] <author> G. E. Blelloch, P. B. Gibbons, Y. Matias, and M. Zagha. </author> <title> Accounting for memory bank contention and delay in high-bandwidth multiprocessors. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 8(9) </volume> <pages> 943-958, </pages> <year> 1997. </year> <title> Preliminary version appears in Proc. </title> <booktitle> 7th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 84-94, </pages> <month> July </month> <year> 1995. </year> <month> 28 </month>
Reference-contexts: We substantiate the ability of the qsm to serve as a bridging model by providing a simple work-preserving emulation of the qsm on both the bsp, and on a related model, the (d; x)-bsp <ref> [16] </ref>, and arguing for the practicality of this emulation. Thus the qsm can be effectively realized on machines that can effectively realize the bsp, as well as on machines that are better modeled by the (d; x)- bsp. <p> The discussion in Section 4 provides some intuition for this rather surprising result. The particular instance of the Queuing Shared Memory model in which the gap parameter, g, equals 1 is essentially the Queue-Read Queue-Write (qrqw) pram model defined by the authors [34]. Previous work on the qrqw pram <ref> [34, 32, 16] </ref> has been focused primarily on contention issues, unlike this paper, which is primarily concerned with bridging models and bandwidth issues. 3.1 Model comparison Table 1 compares the qsm model to a number of other models in the literature. <p> the synchrony assumption of the model: Lock-step indicates that the processors are fully synchronized at each step, with no cost 1 Alternatively, the time cost could be m op + g m rw + ; this affects the bounds by at most a factor of 3, and the results in <ref> [16] </ref> show that at least for certain machines, taking the maximum is more accurate than taking their sum. 2 This issue is explored further in Section 7. 5 Comparison of Models of Parallel Computation model synchrony communication parameters PRAM [27] lock-step shared memory p Module Parallel Computer (mpc) [56] lock-step distributed <p> Since the qsm has fewer parameters than the bsp, and does not deal with memory partitioning details, for most problems it should be easier 3 Alternatively, the time is w + g h + L; this affects the bounds by at most a factor of 3, and the results in <ref> [16] </ref> show that at least for certain machines, taking the maximum of the three terms is more accurate than taking their sum. 9 to design algorithms on the qsm than on the bsp. <p> Thus, overall, the qsm is effective in modeling the essential features of the bsp while remaining at a higher level of abstraction. 4 Emulations of qsm on bsp models The (d; x)-bsp <ref> [16] </ref> is a model similar to the (distributed-memory view of the) bsp, but it provides a more detailed modeling of memory bank contention and delay. In [16], it is argued that the (d; x)-bsp 10 more accurately models shared-memory machines with a high-bandwidth communication network and more memory banks than processors <p> the essential features of the bsp while remaining at a higher level of abstraction. 4 Emulations of qsm on bsp models The (d; x)-bsp <ref> [16] </ref> is a model similar to the (distributed-memory view of the) bsp, but it provides a more detailed modeling of memory bank contention and delay. In [16], it is argued that the (d; x)-bsp 10 more accurately models shared-memory machines with a high-bandwidth communication network and more memory banks than processors than the bsp does. <p> For other machines, computing a pseudo-random hash in software is feasible. For example, it is shown in <ref> [16] </ref> that the overhead to compute a certain provably-good (i.e., 2-universal) pseudo-random hash function on the Cray C90 averages 1.8 clock cycles. Also as noted in [16], for some algorithms it is possible to get the same effect without memory hashing, by randomly permuting the input and some of the intermediate <p> For other machines, computing a pseudo-random hash in software is feasible. For example, it is shown in <ref> [16] </ref> that the overhead to compute a certain provably-good (i.e., 2-universal) pseudo-random hash function on the Cray C90 averages 1.8 clock cycles. Also as noted in [16], for some algorithms it is possible to get the same effect without memory hashing, by randomly permuting the input and some of the intermediate results. In others, the nature of the algorithm results in random mapping without any additional steps. <p> This result is not implied by previous simulation results for the qrqw pram <ref> [34, 16] </ref>, since these previous results considered standard pram models with no gap parameter and bsp or (d; x)-bsp models with a small constant gap parameter (that was hence ignored as part of the big-O notation). <p> Proof of Theorem 4.1 We now prove the theorem. The proof is similar to that in <ref> [16] </ref>, extended and adjusted to properly account for the gap parameter in the qsm and to improve upon the results for large values of x, even for the case studied previously of g = 1. <p> Therefore, the time on the (d; x)-bsp is at least T . 5 Improved accuracy through the qsm abstraction In this section, we draw attention to cases where the extra abstraction provided by the qsm may actually result with more accurate modeling. Blelloch et al. <ref> [16] </ref> demonstrated pitfalls in applying 16 existing message-passing or distributed-memory models to machines such as the Cray C90, Cray J90, SGI Power Challenge and Tera MTA. <p> The abstraction of memory components to shared memory, as assumed in the qsm, make it more robust to changes in the number of memory components. We elaborate below on how the work-preserving emulation of Section 4, together with the experimental results of <ref> [16] </ref>, indicate general cases for Cray-like machines where the qsm is a more accurate model than the bsp and logp. <p> For example, the 16-processor Cray C90 has 1024 memory banks, the 16-processor Cray J90 has 512 memory banks, the 18-processor SGI Power Challenge has 64 memory banks, and the 256-processor Tera MTA will have 32K memory banks. In order to more accurately model such machines, Blelloch et al. <ref> [16] </ref> introduced the (d; x)-bsp model and showed experimentally that it models the Cray C90 and Cray J90 quite accurately, even though the model ignores many details about these machines. <p> As discussed in <ref> [16] </ref>, the Cray C90 and Cray J90 machines are well suited to the bulk-synchronization provided by bsp-like models, since each of the processors can pipeline hundreds of shared-memory requests, thereby amortizing against the latency, the bank delay (in the absence of high contention), and the cost of synchronizing the processors. <p> It is shown in <ref> [16] </ref> that accounting for the memory bank delay is critical in predicting running times of algorithms with high memory contention. Therefore, in some situations the bsp and logp models may provide poor prediction for an algorithm performance, while the (d; x)-bsp may provide a good one. <p> In particular our emulation result of the previous section shows that any 17 layout and underestimating the cost of memory bank contention. This figure is from <ref> [16] </ref>. algorithm designed for the qsm will map in a work-preserving manner onto the (d; x)-bsp given a reasonable amount of parallel slackness, and thus onto these machines.
Reference: [17] <author> G. E. Blelloch, C. E. Leiserson, B. M. Maggs, C. G. Plaxton, S. J. Smith, and M. Zagha. </author> <title> A comparison of sorting algorithms for the Connection Machine CM-2. </title> <booktitle> In Proc. 3rd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 3-16, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting <ref> [17, 28, 42, 35] </ref>, connected components [36, 40], computational geometry [62], FFT [21], and string matching [23].
Reference: [18] <author> R. Cole. </author> <title> Parallel merge sort. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17(4) </volume> <pages> 770-785, </pages> <year> 1988. </year>
Reference-contexts: The problem of designing highly parallel algorithms for sorting n keys from a totally ordered set is a well-studied one. On the erew pram, there are two known O (lg n) time, O (n lg n) work algorithms for general sorting <ref> [4, 18] </ref>; these deterministic algorithms match the asymptotic lower bounds for general sorting on the erew and crew pram models. Both of these algorithms map onto the qsm to run in O (g lg n) time and O (gn lg n) work using Observation 6.2. <p> Both of these algorithms map onto the qsm to run in O (g lg n) time and O (gn lg n) work using Observation 6.2. Unfortunately, these two algorithms are not as simple and practical as one would like. Goodrich [35] gives an algorithm for the bsp based on <ref> [18] </ref> that performs work O ((L + gn) lg n= lg (n=p) + n lg n) with p processors. Since this algorithm is an adaptation of [18] it is again a fairly complicated algorithm. <p> Goodrich [35] gives an algorithm for the bsp based on <ref> [18] </ref> that performs work O ((L + gn) lg n= lg (n=p) + n lg n) with p processors. Since this algorithm is an adaptation of [18] it is again a fairly complicated algorithm.
Reference: [19] <author> R. Cole and O. Zajicek. </author> <title> The APRAM: Incorporating asynchrony into the PRAM model. </title> <booktitle> In Proc. 1st ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 169-178, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Thus, a number of alternative, intermediate models have been proposed and studied in the last eight years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g. <ref> [8, 19, 20, 26, 30, 33, 47, 54, 57] </ref>). Others focus on accounting for the overheads in accessing the shared memory ([2, 3, 24, 30, 39, 42, 50, 53]) or in sending messages ([5, 9, 10, 21, 22, 37, 51, 52, 65]).
Reference: [20] <author> R. Cole and O. Zajicek. </author> <title> The expected advantage of asynchrony. </title> <booktitle> In Proc. 2nd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 85-94, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Thus, a number of alternative, intermediate models have been proposed and studied in the last eight years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g. <ref> [8, 19, 20, 26, 30, 33, 47, 54, 57] </ref>). Others focus on accounting for the overheads in accessing the shared memory ([2, 3, 24, 30, 39, 42, 50, 53]) or in sending messages ([5, 9, 10, 21, 22, 37, 51, 52, 65]).
Reference: [21] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proc. 4th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, </booktitle> <pages> pages 1-12, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Until recently, there were few attractive alternatives, so shared-memory models such as the pram remained the most widely used models for the design and analysis of parallel algorithms (see, e.g. [41, 46, 61]). However, in the last few years, new alternatives such as the bsp [65] and logp <ref> [21] </ref> models have gained considerable popularity. These abstract network models support point-to-point message-passing, can directly support a distributed-memory abstraction, and account for bandwidth limitations using a `gap' parameter. <p> Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting [17, 28, 42, 35], connected components [36, 40], computational geometry [62], FFT <ref> [21] </ref>, and string matching [23]. Designing an algorithm directly for the more complex model is typically a more daunting task than first developing the algorithmic insights on a simple shared-memory model and only then adapting them to the more complex model. <p> Module Parallel Computer (mpc) [56] lock-step distributed memory p LPRAM [3] lock-step shared memory p; ` Phase LPRAM [30] bulk-synchrony shared memory p; `; s XPRAM [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model <ref> [21] </ref> asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33] asynchronous shared memory p QRQW PRAM [34] bulk-synchrony shared memory p Block Distributed Memory (bdm) [42] bulk-synchrony distributed memory p; g; L; B PRAM (m) model [53] lock-step shared memory p; m Interval model [52] bulk-synchrony message-passing p; I Queuing <p> Permitting general asynchrony can lead to algorithms that run faster on mimd machines. However, any asynchronous model that reasonably reflects real machines is considerably more difficult to use. 3. Few parameters. For simplicity, it is desirable for bridging models to have only a few parameters. As evidenced by <ref> [21, 28, 45] </ref> and elsewhere, having additional parameters in a model can make it quite difficult to obtain a concise analysis of an algorithm. On the other hand, it is desirable to have whatever parameters are essential for a desired level of accuracy in modeling machines realizing the bridging model. <p> The emulation of the qsm on the bsp requires only max (g lg p; L=g) slackness; on the (d; x)-bsp, as little as max (d; L=g) slackness may be required. Note that the L=g term matches the limit on multithreading imposed by the logp model <ref> [21] </ref>.
Reference: [22] <author> R. Cypher and S. Konstantinidou. </author> <title> Bounds on the efficiency of message-passing protocols for parallel computers. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 173-181, </pages> <month> June-July </month> <year> 1993. </year>
Reference: [23] <author> A. Czumaj, Z. Galil, L. G~asieniec, K. Park, and W. Plandowski. </author> <title> Work-time-optimal parallel algorithms for string problems. </title> <booktitle> In Proc. 27th ACM Symp. on the Theory of Computing, </booktitle> <pages> pages 713-722, </pages> <month> May-June </month> <year> 1995. </year>
Reference-contexts: Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting [17, 28, 42, 35], connected components [36, 40], computational geometry [62], FFT [21], and string matching <ref> [23] </ref>. Designing an algorithm directly for the more complex model is typically a more daunting task than first developing the algorithmic insights on a simple shared-memory model and only then adapting them to the more complex model.
Reference: [24] <author> P. de la Torre and C. P. Kruskal. </author> <title> Towards a single model of efficient computation in real parallel machines. </title> <journal> Future Generation Computer Systems, </journal> <volume> 8 </volume> <pages> 395-408, </pages> <year> 1992. </year>
Reference-contexts: For example, each of these models defines a single bandwidth parameter that reflects a per-processor bandwidth limitation; other recent work has considered variants of these models with an aggregate bandwidth limitation [1] or a hierarchical bandwidth limitation that accounts for network proximity <ref> [50, 24, 25, 44, 69] </ref>. Per-processor bandwidth limitations better model machines in which each processor has access to its "share" of the network bandwidth and no more, as well as machines for which the primary network bottleneck, in the absence of hot-spots, is in the processor-network interface.
Reference: [25] <author> P. de la Torre and C. P. Kruskal. </author> <title> Submachine locality in the bulk synchronous setting. </title> <booktitle> In Proc. Euro-Par'96, </booktitle> <pages> pages 352-358, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: For example, each of these models defines a single bandwidth parameter that reflects a per-processor bandwidth limitation; other recent work has considered variants of these models with an aggregate bandwidth limitation [1] or a hierarchical bandwidth limitation that accounts for network proximity <ref> [50, 24, 25, 44, 69] </ref>. Per-processor bandwidth limitations better model machines in which each processor has access to its "share" of the network bandwidth and no more, as well as machines for which the primary network bottleneck, in the absence of hot-spots, is in the processor-network interface.
Reference: [26] <author> C. Dwork, M. Herlihy, and O. Waarts. </author> <title> Contention in shared memory algorithms. </title> <booktitle> In Proc. 25th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 174-183, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Thus, a number of alternative, intermediate models have been proposed and studied in the last eight years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g. <ref> [8, 19, 20, 26, 30, 33, 47, 54, 57] </ref>). Others focus on accounting for the overheads in accessing the shared memory ([2, 3, 24, 30, 39, 42, 50, 53]) or in sending messages ([5, 9, 10, 21, 22, 37, 51, 52, 65]).
Reference: [27] <author> S. Fortune and J. Wyllie. </author> <title> Parallelism in random access machines. </title> <booktitle> In Proc. 10th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 114-118, </pages> <month> May </month> <year> 1978. </year>
Reference-contexts: A number of models for parallel computation have been proposed and studied in the last twenty years. Primary among them are the parallel random access machine (pram) model <ref> [27, 46, 41, 61] </ref>, in which processors execute in lock-step and communicate by reading and writing locations in a shared memory, and network-based models (hypercube, butterfly, arrays, etc. [49]), in which processors communicate by sending messages to their neighbors in the given network. <p> by at most a factor of 3, and the results in [16] show that at least for certain machines, taking the maximum is more accurate than taking their sum. 2 This issue is explored further in Section 7. 5 Comparison of Models of Parallel Computation model synchrony communication parameters PRAM <ref> [27] </ref> lock-step shared memory p Module Parallel Computer (mpc) [56] lock-step distributed memory p LPRAM [3] lock-step shared memory p; ` Phase LPRAM [30] bulk-synchrony shared memory p; `; s XPRAM [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing
Reference: [28] <author> A. V. Gerbessiotis and L. Valiant. </author> <title> Direct bulk-synchronous parallel algorithms. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 22 </volume> <pages> 251-267, </pages> <year> 1994. </year>
Reference-contexts: Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting <ref> [17, 28, 42, 35] </ref>, connected components [36, 40], computational geometry [62], FFT [21], and string matching [23]. <p> Permitting general asynchrony can lead to algorithms that run faster on mimd machines. However, any asynchronous model that reasonably reflects real machines is considerably more difficult to use. 3. Few parameters. For simplicity, it is desirable for bridging models to have only a few parameters. As evidenced by <ref> [21, 28, 45] </ref> and elsewhere, having additional parameters in a model can make it quite difficult to obtain a concise analysis of an algorithm. On the other hand, it is desirable to have whatever parameters are essential for a desired level of accuracy in modeling machines realizing the bridging model. <p> be mapped onto the qsm to perform O (n lg n) work provided the computation is very coarse-grained, i.e., the number of processors p is polynomially small in n and g = o (lg n); this qsm algorithm is essentially the same as the bsp algorithm based on sample sort <ref> [28] </ref>. If we look for a highly parallel sorting algorithm that is fairly simple, an adaptation of the qrqw pram sample sort algorithm appears to be the fastest. <p> Similarly the bsp sorting algorithm of <ref> [28] </ref> and the matrix multiplication algorithms of [65, 55] map onto the qsm step by step with a performance corresponding to the case when L = 1 in the bsp algorithms.
Reference: [29] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proc. 17th International Symp. on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: For example, the target machine may choose to dynamically map memory locations to processors as the computation proceeds, as in a cache-only memory architecture (coma) [64]. In general, the target machine is free to implement a variety of cache and memory consistency protocols (e.g. <ref> [29] </ref>), since the model does not presuppose a particular memory layout.
Reference: [30] <author> P. B. Gibbons. </author> <title> A more practical PRAM model. </title> <booktitle> In Proc. 1st ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 158-168, </pages> <month> June </month> <year> 1989. </year> <title> Full version in The Asynchronous PRAM: A semi-synchronous model for shared memory MIMD machines, </title> <type> PhD thesis, </type> <institution> U.C. Berkeley 1989. </institution>
Reference-contexts: Thus, a number of alternative, intermediate models have been proposed and studied in the last eight years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g. <ref> [8, 19, 20, 26, 30, 33, 47, 54, 57] </ref>). Others focus on accounting for the overheads in accessing the shared memory ([2, 3, 24, 30, 39, 42, 50, 53]) or in sending messages ([5, 9, 10, 21, 22, 37, 51, 52, 65]). <p> more accurate than taking their sum. 2 This issue is explored further in Section 7. 5 Comparison of Models of Parallel Computation model synchrony communication parameters PRAM [27] lock-step shared memory p Module Parallel Computer (mpc) [56] lock-step distributed memory p LPRAM [3] lock-step shared memory p; ` Phase LPRAM <ref> [30] </ref> bulk-synchrony shared memory p; `; s XPRAM [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33] asynchronous shared memory p QRQW PRAM [34] bulk-synchrony <p> The advantages of a shared-memory abstraction were discussed in Section 2. 2. Bulk-synchrony. The qsm supports bulk-synchronous operation, in which processors operate asynchronously between barrier synchronizations. As in models such as the phase lpram <ref> [30] </ref>, the algorithm dictates the points at which barriers occur. This allows a qsm algorithm to synchronize less frequently than algorithms designed for a lock-step model, which makes for a more efficient mapping of the algorithm to mimd machines. The model does not allow for general asynchronous algorithms.
Reference: [31] <author> P. B. Gibbons. </author> <title> What good are shared-memory models? In Proc. </title> <booktitle> 1996 ICPP Workshop on Challenges for Parallel Processing, </booktitle> <pages> pages 103-114, </pages> <month> August </month> <year> 1996. </year> <note> Invited position paper. </note>
Reference-contexts: Section 6 presents algorithmic results and issues related to algorithm design on the qsm. Section 7 explores the merits of incorporating into the qsm model distinct bandwidth gaps at the processors and the memories. Finally, we refer the reader to the position paper <ref> [31] </ref>, which provides a non-technical overview of much of this work in arguing the importance of shared-memory models in general and the qsm model in particular. 2 2 Advantages of shared-memory models as bridging models A bridging model should provide an abstraction that is on the one hand easy to use
Reference: [32] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> Efficient low-contention parallel algorithms. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 53(3) </volume> <pages> 417-442, </pages> <year> 1996. </year> <note> Special issue devoted to selected papers from the 1994 ACM Symp. on Parallel Algorithms and Architectures. 29 </note>
Reference-contexts: The discussion in Section 4 provides some intuition for this rather surprising result. The particular instance of the Queuing Shared Memory model in which the gap parameter, g, equals 1 is essentially the Queue-Read Queue-Write (qrqw) pram model defined by the authors [34]. Previous work on the qrqw pram <ref> [34, 32, 16] </ref> has been focused primarily on contention issues, unlike this paper, which is primarily concerned with bridging models and bandwidth issues. 3.1 Model comparison Table 1 compares the qsm model to a number of other models in the literature. <p> A qrqw pram algorithm in the work-time framework that runs in time t while performing work w immediately implies a qsm algorithm that runs in time at most t g with w=t processors. Thus the linear-work qrqw pram algorithms given in <ref> [34, 32] </ref> for leader election, linear compaction, multiple compaction, load balancing, and hashing, as well as the extensive collection of linear-work logarithmic-time erew pram algorithms reported in the literature, all translate into qsm algorithms with work O (n g) on inputs of length n with a slowdown by a factor of <p> work algorithm on the erew pram is an O (lg 2 n) time randomized quicksort algorithm (see, e.g. [41]), and on the qrqw pram, a randomized p n-sample sort algorithm that runs in O (lg 2 n= lg lg n) time, O (n lg n) work, and O (n) space <ref> [32] </ref>. <p> The algorithm is reminiscent of a randomized crqw pram algorithm for integer sorting given in <ref> [32] </ref>. It proceeds by using the shared memory to sort the messages being sent in the current step according to their destination. <p> Use an algorithm for multiple compaction to get the messages in each group into a linear-sized array for that group; this takes O (g lg M ) time and O (g M ) work by the adaptation of the 24 randomized qrqw pram algorithm for multiple compaction given in <ref> [32] </ref> to the qsm using Observation 6.2. 8. Perform a stable sort within each group according to the individual destination; this can be performed in O (g lg M ) time and O (gM ) work deterministically using an erew pram radix-sort algorithm within each group. 9. <p> We then perform step 9 above. Since M n h, the above qsm algorithm runs in O (g (h + lg n)) time while performing O (ghn) work. High-probability bounds for the randomized steps in the above algorithm are shown in <ref> [32] </ref>. Since a bsp routes an h-relation in O (gh + L) time while performing O (n (gh + L)) work, this is a work-preserving emulation of a bsp h-relation, with a slowdown of O (1 + lg n=(h + L=g)). In summary we have the following result.
Reference: [33] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The Queue-Read Queue-Write Asynchronous PRAM model. </title> <editor> In L. Bouge, P. Fraigniaud, A. Mignotte, and Y. Robert, editors, </editor> <booktitle> Euro-Par'96 Parallel Processing, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 1124, </volume> <pages> pages 279-292. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <month> August </month> <year> 1996. </year> <booktitle> Proc. 2nd International Euro-Par Conference, Lyon, France, Volume II. </booktitle>
Reference-contexts: Thus, a number of alternative, intermediate models have been proposed and studied in the last eight years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g. <ref> [8, 19, 20, 26, 30, 33, 47, 54, 57] </ref>). Others focus on accounting for the overheads in accessing the shared memory ([2, 3, 24, 30, 39, 42, 50, 53]) or in sending messages ([5, 9, 10, 21, 22, 37, 51, 52, 65]). <p> [3] lock-step shared memory p; ` Phase LPRAM [30] bulk-synchrony shared memory p; `; s XPRAM [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM <ref> [33] </ref> asynchronous shared memory p QRQW PRAM [34] bulk-synchrony shared memory p Block Distributed Memory (bdm) [42] bulk-synchrony distributed memory p; g; L; B PRAM (m) model [53] lock-step shared memory p; m Interval model [52] bulk-synchrony message-passing p; I Queuing Shared Memory (qsm) bulk-synchrony shared memory p; g Table 1:
Reference: [34] <author> P. B. Gibbons, Y. Matias, and V. Ramachandran. </author> <title> The Queue-Read Queue-Write PRAM model: Accounting for contention in parallel algorithms. </title> <journal> SIAM Journal on Computing, </journal> <note> 1997. To appear. Preliminary version appears in Proc. </note> <editor> 5th ACM-SIAM Symp. </editor> <booktitle> on Discrete Algorithms, </booktitle> <pages> pages 638-648, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Thus, the qsm is envisioned as a "minimal" shared-memory model that can be competitive with the bsp. Similarly, the memory contention rule of the qsm is the queuing contention rule, as in the qrqw pram <ref> [34] </ref>. This rule is strong enough to provide the qsm with an expressive power comparable to that of the bsp, but it is not too strong to prevent a fast and efficient emulation of the qsm on the bsp with the techniques we use. <p> The discussion in Section 4 provides some intuition for this rather surprising result. The particular instance of the Queuing Shared Memory model in which the gap parameter, g, equals 1 is essentially the Queue-Read Queue-Write (qrqw) pram model defined by the authors <ref> [34] </ref>. Previous work on the qrqw pram [34, 32, 16] has been focused primarily on contention issues, unlike this paper, which is primarily concerned with bridging models and bandwidth issues. 3.1 Model comparison Table 1 compares the qsm model to a number of other models in the literature. <p> The discussion in Section 4 provides some intuition for this rather surprising result. The particular instance of the Queuing Shared Memory model in which the gap parameter, g, equals 1 is essentially the Queue-Read Queue-Write (qrqw) pram model defined by the authors [34]. Previous work on the qrqw pram <ref> [34, 32, 16] </ref> has been focused primarily on contention issues, unlike this paper, which is primarily concerned with bridging models and bandwidth issues. 3.1 Model comparison Table 1 compares the qsm model to a number of other models in the literature. <p> LPRAM [30] bulk-synchrony shared memory p; `; s XPRAM [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33] asynchronous shared memory p QRQW PRAM <ref> [34] </ref> bulk-synchrony shared memory p Block Distributed Memory (bdm) [42] bulk-synchrony distributed memory p; g; L; B PRAM (m) model [53] lock-step shared memory p; m Interval model [52] bulk-synchrony message-passing p; I Queuing Shared Memory (qsm) bulk-synchrony shared memory p; g Table 1: A comparison of several models of parallel <p> Queue contention metric. The "queue-read queue-write" (qrqw) contention rule of the qsm model more accurately reflects the contention properties of parallel machines with simple, non-combining interconnection networks than either the well-studied exclusive-read exclusive-write (erew) or concurrent-read concurrent-write (crcw) rules. As argued in <ref> [34] </ref>, the erew rule is too strict, and the crcw rule ignores the large performance penalty of high contention steps. <p> This result is not implied by previous simulation results for the qrqw pram <ref> [34, 16] </ref>, since these previous results considered standard pram models with no gap parameter and bsp or (d; x)-bsp models with a small constant gap parameter (that was hence ignored as part of the big-O notation). <p> A qrqw pram algorithm in the work-time framework that runs in time t while performing work w immediately implies a qsm algorithm that runs in time at most t g with w=t processors. Thus the linear-work qrqw pram algorithms given in <ref> [34, 32] </ref> for leader election, linear compaction, multiple compaction, load balancing, and hashing, as well as the extensive collection of linear-work logarithmic-time erew pram algorithms reported in the literature, all translate into qsm algorithms with work O (n g) on inputs of length n with a slowdown by a factor of
Reference: [35] <author> M. Goodrich. </author> <title> Communication-efficient parallel sorting. </title> <booktitle> In Proc. 28th ACM Symp. on the Theory of Computing, </booktitle> <pages> pages 247-256, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting <ref> [17, 28, 42, 35] </ref>, connected components [36, 40], computational geometry [62], FFT [21], and string matching [23]. <p> Moreover, the emulation result implies that any machine that can realize the bsp model can also realize the qsm model, given the additional system software needed for the (simple) emulation algorithm. Many algorithms designed for the bsp have as their goal to minimize the number of supersteps (e.g., <ref> [35] </ref>). In contrast, the qsm does not account for the number of supersteps (e.g., there is no L parameter in the qsm model). <p> Both of these algorithms map onto the qsm to run in O (g lg n) time and O (gn lg n) work using Observation 6.2. Unfortunately, these two algorithms are not as simple and practical as one would like. Goodrich <ref> [35] </ref> gives an algorithm for the bsp based on [18] that performs work O ((L + gn) lg n= lg (n=p) + n lg n) with p processors. Since this algorithm is an adaptation of [18] it is again a fairly complicated algorithm.
Reference: [36] <author> J. Greiner. </author> <title> A comparison of data-parallel algorithms for connected components. </title> <booktitle> In Proc. 6th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 16-25, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting [17, 28, 42, 35], connected components <ref> [36, 40] </ref>, computational geometry [62], FFT [21], and string matching [23]. Designing an algorithm directly for the more complex model is typically a more daunting task than first developing the algorithmic insights on a simple shared-memory model and only then adapting them to the more complex model. <p> An example is shown in Figure 1 for the Cray J90. In this figure, predicted and measured performance are shown on a set of memory access patterns extracted from a trace of Greiner's algorithm for finding the connected components of a graph <ref> [36] </ref>. Measured times on an 8 processor Cray J90 for several patterns are shown with squares. Predicted times are given for the (d; x)-bsp, which models the Cray J90 quite accurately, and the bsp and the logp, which do not.
Reference: [37] <author> S. Hambrusch and A. Khokhar. </author> <title> C 3 : An architecture-independent model for coarse-grained parallel machines. </title> <booktitle> In Proc. 6th IEEE Symp. on Parallel and Distributed Processing, </booktitle> <pages> pages 544-551, </pages> <year> 1994. </year>
Reference: [38] <author> J. Hennessy and D. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kauf-mann, </publisher> <address> San Francisco, CA, </address> <year> 1996. </year> <note> Second edition. </note>
Reference-contexts: We then illustrate this observation by a concrete simple instance. 5.1 Suitability of qsm to Cray-like machines Processor speeds have been increasing at over 50% a year while memory speeds have been increasing at less than 10% a year <ref> [38] </ref>. This divergence has motivated several computer manufacturers to design parallel machines with many more memory banks than processors. <p> Finally, each of these models ignores the effects of the cache coherence protocol used in most shared-memory multiprocessors to maintain consistency among the various cached copies of shared-memory data. It would be interesting to study a qsm model that incorporates and accounts for a standard invalidation-based cache coherence protocol <ref> [38] </ref>. Should it become necessary to include additional features as part of a bridging model, the qsm may be more suited for augmentation than the bsp or logp, since it is simpler, with fewer parameters.
Reference: [39] <author> T. Heywood and S. Ranka. </author> <title> A practical hierarchical model of parallel computation: I. The model. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16 </volume> <pages> 212-232, </pages> <year> 1992. </year>
Reference: [40] <author> T.-s. Hsu, V. Ramachandran, and N. Dean. </author> <title> Parallel implementation of algorithms for finding connected components in graphs. </title> <booktitle> In Proc. AMS/DIMACS Parallel Implementation Challenge Workshop III, </booktitle> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting [17, 28, 42, 35], connected components <ref> [36, 40] </ref>, computational geometry [62], FFT [21], and string matching [23]. Designing an algorithm directly for the more complex model is typically a more daunting task than first developing the algorithmic insights on a simple shared-memory model and only then adapting them to the more complex model.
Reference: [41] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference-contexts: A number of models for parallel computation have been proposed and studied in the last twenty years. Primary among them are the parallel random access machine (pram) model <ref> [27, 46, 41, 61] </ref>, in which processors execute in lock-step and communicate by reading and writing locations in a shared memory, and network-based models (hypercube, butterfly, arrays, etc. [49]), in which processors communicate by sending messages to their neighbors in the given network. <p> In particular, the pram model has been faulted for completely failing to model bandwidth limitations of parallel machines. Until recently, there were few attractive alternatives, so shared-memory models such as the pram remained the most widely used models for the design and analysis of parallel algorithms (see, e.g. <ref> [41, 46, 61] </ref>). However, in the last few years, new alternatives such as the bsp [65] and logp [21] models have gained considerable popularity. These abstract network models support point-to-point message-passing, can directly support a distributed-memory abstraction, and account for bandwidth limitations using a `gap' parameter. <p> Since this algorithm is an adaptation of [18] it is again a fairly complicated algorithm. Among sorting algorithms that are fairly simple, the fastest O (n lg n) work algorithm on the erew pram is an O (lg 2 n) time randomized quicksort algorithm (see, e.g. <ref> [41] </ref>), and on the qrqw pram, a randomized p n-sample sort algorithm that runs in O (lg 2 n= lg lg n) time, O (n lg n) work, and O (n) space [32].
Reference: [42] <author> J. JaJa and K. W. Ryu. </author> <title> The Block Distributed Memory model. </title> <type> Technical Report UMIACS-TR-94-5, </type> <institution> University of Maryland Institute for Advanced Computer Studies, College Park, MD, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting <ref> [17, 28, 42, 35] </ref>, connected components [36, 40], computational geometry [62], FFT [21], and string matching [23]. <p> [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33] asynchronous shared memory p QRQW PRAM [34] bulk-synchrony shared memory p Block Distributed Memory (bdm) <ref> [42] </ref> bulk-synchrony distributed memory p; g; L; B PRAM (m) model [53] lock-step shared memory p; m Interval model [52] bulk-synchrony message-passing p; I Queuing Shared Memory (qsm) bulk-synchrony shared memory p; g Table 1: A comparison of several models of parallel computation. <p> If the processors communicate by reading and writing locations in a memory that is partitioned, the model is considered to be a distributed memory model. For example, the bdm model <ref> [42] </ref> is distributed memory since the contention encountered by a read request depends on the number of other requests to the same memory module. <p> In others, the nature of the algorithm results in random mapping without any additional steps. It is well known that hashing destroys spatial locality, but not temporal locality. Spatial locality enables long messages to be sent between components, thereby minimizing overheads on many machines. Some models, such as bdm <ref> [42] </ref>, loggp [5], and bsp fl [12, 11], account for advantages in long messages; most others, e.g., qsm, bsp, (d; x)-bsp and logp, do not. Thus the qsm shares with the bsp, (d; x)-bsp and logp models a disregard for spatial locality. <p> Third, as discussed in Section 4, each of these models disregards spatial locality. Variants of the bsp and logp that account for spatial locality include <ref> [42, 5, 44, 11] </ref>. In machines supporting a single address space, the unit of data transfer between components is typically either a cache line or a page, and hence opportunities to exploit spatial locality are restricted to that level of granularity.
Reference: [43] <author> B H. H. Juurlink. </author> <type> Ph.D. Thesis, </type> <institution> Leiden University, </institution> <year> 1996. </year>
Reference-contexts: A lower bound of (g lg n= lg g) for broadcasting to n processors is given in [1]; in contrast to an earlier lower bound for this problem on the bsp given in <ref> [43] </ref> this lower bound holds even if processors can acquire knowledge through non-receipt of messages (i.e., by reading memory locations that were not updated by a recent write operation).
Reference: [44] <author> B. H. H. Juurlink and H. A. G. Wijshoff. </author> <title> The E-BSP Model: Incorporating general locality and unbalanced communication into the BSP Model. </title> <booktitle> In Proc. Euro-Par'96, </booktitle> <pages> pages 339-347, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: For example, each of these models defines a single bandwidth parameter that reflects a per-processor bandwidth limitation; other recent work has considered variants of these models with an aggregate bandwidth limitation [1] or a hierarchical bandwidth limitation that accounts for network proximity <ref> [50, 24, 25, 44, 69] </ref>. Per-processor bandwidth limitations better model machines in which each processor has access to its "share" of the network bandwidth and no more, as well as machines for which the primary network bottleneck, in the absence of hot-spots, is in the processor-network interface. <p> Third, as discussed in Section 4, each of these models disregards spatial locality. Variants of the bsp and logp that account for spatial locality include <ref> [42, 5, 44, 11] </ref>. In machines supporting a single address space, the unit of data transfer between components is typically either a cache line or a page, and hence opportunities to exploit spatial locality are restricted to that level of granularity.
Reference: [45] <author> R. Karp, A. Sahay, E. Santos, and K.E. Schauser. </author> <title> Optimal broadcast and summation in the LogP model. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 142-153, </pages> <month> June-July </month> <year> 1993. </year>
Reference-contexts: Permitting general asynchrony can lead to algorithms that run faster on mimd machines. However, any asynchronous model that reasonably reflects real machines is considerably more difficult to use. 3. Few parameters. For simplicity, it is desirable for bridging models to have only a few parameters. As evidenced by <ref> [21, 28, 45] </ref> and elsewhere, having additional parameters in a model can make it quite difficult to obtain a concise analysis of an algorithm. On the other hand, it is desirable to have whatever parameters are essential for a desired level of accuracy in modeling machines realizing the bridging model.
Reference: [46] <author> R. M. Karp and V. Ramachandran. </author> <title> Parallel algorithms for shared-memory machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Volume A, </booktitle> <pages> pages 869-941. </pages> <publisher> Elsevier Science Publishers B.V., </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: A number of models for parallel computation have been proposed and studied in the last twenty years. Primary among them are the parallel random access machine (pram) model <ref> [27, 46, 41, 61] </ref>, in which processors execute in lock-step and communicate by reading and writing locations in a shared memory, and network-based models (hypercube, butterfly, arrays, etc. [49]), in which processors communicate by sending messages to their neighbors in the given network. <p> In particular, the pram model has been faulted for completely failing to model bandwidth limitations of parallel machines. Until recently, there were few attractive alternatives, so shared-memory models such as the pram remained the most widely used models for the design and analysis of parallel algorithms (see, e.g. <ref> [41, 46, 61] </ref>). However, in the last few years, new alternatives such as the bsp [65] and logp [21] models have gained considerable popularity. These abstract network models support point-to-point message-passing, can directly support a distributed-memory abstraction, and account for bandwidth limitations using a `gap' parameter.
Reference: [47] <author> Z. M. Kedem, K. V. Palem, M. O. Rabin, and A. Raghunathan. </author> <title> Efficient program transformations for resilient parallel computation via randomization. </title> <booktitle> In Proc. 24th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 306-317, </pages> <month> May </month> <year> 1992. </year> <month> 30 </month>
Reference-contexts: Thus, a number of alternative, intermediate models have been proposed and studied in the last eight years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g. <ref> [8, 19, 20, 26, 30, 33, 47, 54, 57] </ref>). Others focus on accounting for the overheads in accessing the shared memory ([2, 3, 24, 30, 39, 42, 50, 53]) or in sending messages ([5, 9, 10, 21, 22, 37, 51, 52, 65]).
Reference: [48] <author> K. Kennedy. </author> <title> A research agenda for high performance computing software. </title> <booktitle> In Developing a Computer Science Agenda for High-Performance Computing, </booktitle> <pages> pages 106-109. </pages> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference-contexts: Finally, a few models incorporate powerful aggregate communication primitives ([14, 17]). Given this plethora of models, it is natural to seek to distinguish a few models with the most promise, and concentrate on these models. Advocates such as Vishkin [67], Kennedy <ref> [48] </ref>, Smith [63], and Blelloch [15] have long presented arguments in support of the shared-memory abstraction. On the other hand, shared-memory models have been criticized for years for failing to model essential realities of parallel machines.
Reference: [49] <author> F. T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays Trees Hypercubes. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: Primary among them are the parallel random access machine (pram) model [27, 46, 41, 61], in which processors execute in lock-step and communicate by reading and writing locations in a shared memory, and network-based models (hypercube, butterfly, arrays, etc. <ref> [49] </ref>), in which processors communicate by sending messages to their neighbors in the given network. The pram model, although simple and well-suited for developing parallel algorithms, is considered by many to be too high level, failing to accurately model parallel machines.
Reference: [50] <author> C. E. Leiserson and B. M. Maggs. </author> <title> Communication-efficient parallel algorithms for distributed random-access machines. </title> <journal> Algorithmica, </journal> <volume> 3(1) </volume> <pages> 53-77, </pages> <year> 1988. </year>
Reference-contexts: For example, each of these models defines a single bandwidth parameter that reflects a per-processor bandwidth limitation; other recent work has considered variants of these models with an aggregate bandwidth limitation [1] or a hierarchical bandwidth limitation that accounts for network proximity <ref> [50, 24, 25, 44, 69] </ref>. Per-processor bandwidth limitations better model machines in which each processor has access to its "share" of the network bandwidth and no more, as well as machines for which the primary network bottleneck, in the absence of hot-spots, is in the processor-network interface.
Reference: [51] <author> P. Liu, W. Aiello, and S. Bhatt. </author> <title> An atomic model for message-passing. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 154-163, </pages> <month> June-July </month> <year> 1993. </year>
Reference: [52] <author> B. M. Maggs, L. R. Matheson, and R. E. Tarjan. </author> <title> Models of parallel computation: A survey and synthesis. </title> <booktitle> In Proc. 28th Hawaii International Conf. on System Sciences, pages II: </booktitle> <pages> 61-70, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33] asynchronous shared memory p QRQW PRAM [34] bulk-synchrony shared memory p Block Distributed Memory (bdm) [42] bulk-synchrony distributed memory p; g; L; B PRAM (m) model [53] lock-step shared memory p; m Interval model <ref> [52] </ref> bulk-synchrony message-passing p; I Queuing Shared Memory (qsm) bulk-synchrony shared memory p; g Table 1: A comparison of several models of parallel computation.
Reference: [53] <author> Y. Mansour, N. Nisan, and U. Vishkin. </author> <title> Trade-offs between communication throughput and parallel time. </title> <booktitle> In Proc. 26th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 372-381, </pages> <year> 1994. </year>
Reference-contexts: message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33] asynchronous shared memory p QRQW PRAM [34] bulk-synchrony shared memory p Block Distributed Memory (bdm) [42] bulk-synchrony distributed memory p; g; L; B PRAM (m) model <ref> [53] </ref> lock-step shared memory p; m Interval model [52] bulk-synchrony message-passing p; I Queuing Shared Memory (qsm) bulk-synchrony shared memory p; g Table 1: A comparison of several models of parallel computation.
Reference: [54] <author> C. Martel, A. Park, and R. Subramonian. </author> <title> Work-optimal asynchronous algorithms for shared memory parallel computers. </title> <journal> SIAM Journal on Computing, </journal> <volume> 21(6) </volume> <pages> 1070-1099, </pages> <year> 1992. </year>
Reference-contexts: Thus, a number of alternative, intermediate models have been proposed and studied in the last eight years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g. <ref> [8, 19, 20, 26, 30, 33, 47, 54, 57] </ref>). Others focus on accounting for the overheads in accessing the shared memory ([2, 3, 24, 30, 39, 42, 50, 53]) or in sending messages ([5, 9, 10, 21, 22, 37, 51, 52, 65]).
Reference: [55] <author> W. F. McColl. </author> <title> A BSP realization of Strassen's algorithm. </title> <type> Technical report, </type> <institution> Oxford University Computing Laboratory, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Similarly the bsp sorting algorithm of [28] and the matrix multiplication algorithms of <ref> [65, 55] </ref> map onto the qsm step by step with a performance corresponding to the case when L = 1 in the bsp algorithms.
Reference: [56] <author> K. Mehlhorn and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 21 </volume> <pages> 339-374, </pages> <year> 1984. </year>
Reference-contexts: results in [16] show that at least for certain machines, taking the maximum is more accurate than taking their sum. 2 This issue is explored further in Section 7. 5 Comparison of Models of Parallel Computation model synchrony communication parameters PRAM [27] lock-step shared memory p Module Parallel Computer (mpc) <ref> [56] </ref> lock-step distributed memory p LPRAM [3] lock-step shared memory p; ` Phase LPRAM [30] bulk-synchrony shared memory p; `; s XPRAM [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g;
Reference: [57] <author> N. Nishimura. </author> <title> Asynchronous shared memory parallel computation. </title> <booktitle> In Proc. 2nd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 76-84, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Thus, a number of alternative, intermediate models have been proposed and studied in the last eight years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g. <ref> [8, 19, 20, 26, 30, 33, 47, 54, 57] </ref>). Others focus on accounting for the overheads in accessing the shared memory ([2, 3, 24, 30, 39, 42, 50, 53]) or in sending messages ([5, 9, 10, 21, 22, 37, 51, 52, 65]).
Reference: [58] <author> M. H. Nodine and J. S. Vitter. </author> <title> Large-scale sorting in parallel memories. </title> <booktitle> In Proc. 3rd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 29-39, </pages> <month> July </month> <year> 1991. </year>
Reference: [59] <author> P. Raghavan. </author> <title> Probabilistic construction of deterministic algorithms: approximating packing integer programs. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 37 </volume> <pages> 130-143, </pages> <year> 1988. </year>
Reference: [60] <author> V. Ramachandran. </author> <title> A general purpose shared memory model for parallel computation. </title> <booktitle> In Proc. IMA Workshop on Parallel Algorithms, </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: We refer to this model as qsm (g; d). The following result is shown in <ref> [60] </ref>. Observation 7.1 [60] There is a deterministic work-preserving emulation of qsm (g; d 0 ) on qsm (g; d) with slowdown O (d d d 0 e). <p> We refer to this model as qsm (g; d). The following result is shown in <ref> [60] </ref>. Observation 7.1 [60] There is a deterministic work-preserving emulation of qsm (g; d 0 ) on qsm (g; d) with slowdown O (d d d 0 e).
Reference: [61] <author> J. H. Reif, </author> <title> editor. A Synthesis of Parallel Algorithms. </title> <publisher> Morgan-Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: A number of models for parallel computation have been proposed and studied in the last twenty years. Primary among them are the parallel random access machine (pram) model <ref> [27, 46, 41, 61] </ref>, in which processors execute in lock-step and communicate by reading and writing locations in a shared memory, and network-based models (hypercube, butterfly, arrays, etc. [49]), in which processors communicate by sending messages to their neighbors in the given network. <p> In particular, the pram model has been faulted for completely failing to model bandwidth limitations of parallel machines. Until recently, there were few attractive alternatives, so shared-memory models such as the pram remained the most widely used models for the design and analysis of parallel algorithms (see, e.g. <ref> [41, 46, 61] </ref>). However, in the last few years, new alternatives such as the bsp [65] and logp [21] models have gained considerable popularity. These abstract network models support point-to-point message-passing, can directly support a distributed-memory abstraction, and account for bandwidth limitations using a `gap' parameter.
Reference: [62] <author> J. H. Reif and S. Sen. </author> <title> Randomized algorithms for binary search and load balancing on fixed connection networks with geometric applications. </title> <booktitle> In Proc. 2nd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 327-337, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting [17, 28, 42, 35], connected components [36, 40], computational geometry <ref> [62] </ref>, FFT [21], and string matching [23]. Designing an algorithm directly for the more complex model is typically a more daunting task than first developing the algorithmic insights on a simple shared-memory model and only then adapting them to the more complex model.
Reference: [63] <author> B. Smith. </author> <booktitle> Invited lecture, 7th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Finally, a few models incorporate powerful aggregate communication primitives ([14, 17]). Given this plethora of models, it is natural to seek to distinguish a few models with the most promise, and concentrate on these models. Advocates such as Vishkin [67], Kennedy [48], Smith <ref> [63] </ref>, and Blelloch [15] have long presented arguments in support of the shared-memory abstraction. On the other hand, shared-memory models have been criticized for years for failing to model essential realities of parallel machines.
Reference: [64] <author> P. Stenstrom, T. Joe, and A. Gupta. </author> <title> Comparative performance evaluation of cache-coherent NUMA and COMA architectures. </title> <booktitle> In Proc. 19th International Symp. on Computer Architecture, </booktitle> <pages> pages 80-91, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: For example, the target machine may choose to dynamically map memory locations to processors as the computation proceeds, as in a cache-only memory architecture (coma) <ref> [64] </ref>. In general, the target machine is free to implement a variety of cache and memory consistency protocols (e.g. [29]), since the model does not presuppose a particular memory layout.
Reference: [65] <author> L. G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <year> 1990. </year>
Reference-contexts: Until recently, there were few attractive alternatives, so shared-memory models such as the pram remained the most widely used models for the design and analysis of parallel algorithms (see, e.g. [41, 46, 61]). However, in the last few years, new alternatives such as the bsp <ref> [65] </ref> and logp [21] models have gained considerable popularity. These abstract network models support point-to-point message-passing, can directly support a distributed-memory abstraction, and account for bandwidth limitations using a `gap' parameter. <p> This rule is strong enough to provide the qsm with an expressive power comparable to that of the bsp, but it is not too strong to prevent a fast and efficient emulation of the qsm on the bsp with the techniques we use. As advocated in <ref> [65, 67] </ref> and elsewhere, one reasonable goal for a high-level, shared-memory model is that it allow for efficient emulation on lower-level, seemingly more realistic, models. If the overheads in the emulation are small, then the high-level model becomes an attractive general-purpose bridging model. <p> of Models of Parallel Computation model synchrony communication parameters PRAM [27] lock-step shared memory p Module Parallel Computer (mpc) [56] lock-step distributed memory p LPRAM [3] lock-step shared memory p; ` Phase LPRAM [30] bulk-synchrony shared memory p; `; s XPRAM [66] bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) <ref> [65] </ref> bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33] asynchronous shared memory p QRQW PRAM [34] bulk-synchrony shared memory p Block Distributed Memory (bdm) [42] bulk-synchrony distributed memory p; g; L; B PRAM (m) <p> We choose to compare the qsm with the bsp rather than the logp model since the qsm is a bulk-synchronous model like the bsp (and unlike the logp) model. The Bulk-Synchronous Parallel (bsp) model <ref> [65, 66] </ref> consists of p processor/memory components communicating by sending point-to-point messages. <p> Similarly the bsp sorting algorithm of [28] and the matrix multiplication algorithms of <ref> [65, 55] </ref> map onto the qsm step by step with a performance corresponding to the case when L = 1 in the bsp algorithms.
Reference: [66] <author> L. G. Valiant. </author> <title> General purpose parallel architectures. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Volume A, </booktitle> <pages> pages 943-972. </pages> <publisher> Elsevier Science Publishers B.V., </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: issue is explored further in Section 7. 5 Comparison of Models of Parallel Computation model synchrony communication parameters PRAM [27] lock-step shared memory p Module Parallel Computer (mpc) [56] lock-step distributed memory p LPRAM [3] lock-step shared memory p; ` Phase LPRAM [30] bulk-synchrony shared memory p; `; s XPRAM <ref> [66] </ref> bulk-synchrony message-passing p; g; L Bulk-Synchronous Parallel (bsp) [65] bulk-synchrony message-passing p; g; L Postal model [10] asynchronous message-passing p; ` LogP model [21] asynchronous message-passing p; g; `; o QRQW Asynchronous PRAM [33] asynchronous shared memory p QRQW PRAM [34] bulk-synchrony shared memory p Block Distributed Memory (bdm) [42] <p> We choose to compare the qsm with the bsp rather than the logp model since the qsm is a bulk-synchronous model like the bsp (and unlike the logp) model. The Bulk-Synchronous Parallel (bsp) model <ref> [65, 66] </ref> consists of p processor/memory components communicating by sending point-to-point messages.
Reference: [67] <author> U. Vishkin. </author> <title> A parallel-design distributed-implementation (PDDI) general purpose computer. </title> <journal> Theoretical Computer Science, </journal> <volume> 32 </volume> <pages> 157-172, </pages> <year> 1984. </year>
Reference-contexts: Finally, a few models incorporate powerful aggregate communication primitives ([14, 17]). Given this plethora of models, it is natural to seek to distinguish a few models with the most promise, and concentrate on these models. Advocates such as Vishkin <ref> [67] </ref>, Kennedy [48], Smith [63], and Blelloch [15] have long presented arguments in support of the shared-memory abstraction. On the other hand, shared-memory models have been criticized for years for failing to model essential realities of parallel machines. <p> This rule is strong enough to provide the qsm with an expressive power comparable to that of the bsp, but it is not too strong to prevent a fast and efficient emulation of the qsm on the bsp with the techniques we use. As advocated in <ref> [65, 67] </ref> and elsewhere, one reasonable goal for a high-level, shared-memory model is that it allow for efficient emulation on lower-level, seemingly more realistic, models. If the overheads in the emulation are small, then the high-level model becomes an attractive general-purpose bridging model.
Reference: [68] <author> J. S. Vitter and E. A. M. Shriver. </author> <title> Optimal disk I/O with parallel block transfer. </title> <booktitle> In Proc. 22nd ACM Symp. on Theory of Computing, </booktitle> <pages> pages 159-169, </pages> <month> May </month> <year> 1990. </year>
Reference: [69] <author> H. A. G. Wijshoff and B. H. H. Juurlink. </author> <title> A quantitative comparison of parallel computation models. </title> <booktitle> In Proc. 8th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 13-24, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: For example, each of these models defines a single bandwidth parameter that reflects a per-processor bandwidth limitation; other recent work has considered variants of these models with an aggregate bandwidth limitation [1] or a hierarchical bandwidth limitation that accounts for network proximity <ref> [50, 24, 25, 44, 69] </ref>. Per-processor bandwidth limitations better model machines in which each processor has access to its "share" of the network bandwidth and no more, as well as machines for which the primary network bottleneck, in the absence of hot-spots, is in the processor-network interface.
References-found: 69

