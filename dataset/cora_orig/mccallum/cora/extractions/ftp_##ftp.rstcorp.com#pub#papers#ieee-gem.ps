URL: ftp://ftp.rstcorp.com/pub/papers/ieee-gem.ps
Refering-URL: http://www.rstcorp.com/fault-injection.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Predicting How Badly "Good" Software can Behave  
Author: Jeffrey Voas Frank Charron, Gary McGraw Keith Miller Michael Friedman 
Keyword: fault-injection, software failure tolerance, fault tolerance, input distribution, software testing, software quality  
Address: Springfield  
Affiliation: Reliable Software Technologies Corporation  University of Illinois at  Hughes Electronics Corporation  
Abstract: This paper presents a fault-injection methodology that predicts how software will behave when: (1) components of the software fail, (2) hardware components external to the software fail, (3) human factor errors occur and bad input is provided to the software, and (4) the software is executing in unlikely operational modes. Because of the enterprise-critical nature of many of today's software systems, it is vital that these system are robust enough to handle problems that originate externally as well as the expected problems that will arise from internal defects. Also, this paper presents four cases studies that highlight the benefit of this analysis for both safety-critical systems and non-safety critical systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. A. FRIEDMAN. </author> <title> BART Advanced Automated Train Control System Safety Concepts. </title> <booktitle> In Proceedings of American Public Transit Association Convention, </booktitle> <address> New York, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: This information could be of use in the development of a more thorough set of tests. 3.4 Case Study 4: Bay Area Rapid Transit Our fourth example involves another real-world control problem, the Advanced Automated Train Control (AATC) system <ref> [1] </ref>. Hughes Aircraft Company, El Segundo, CA, in partnership with the San Francisco Bay Area Rapid Transit (BART) district and Morrison Knudsen Corporation, is producing this new train control technology with partial funding from the US government's Advanced Research Projects Agency (ARPA).
Reference: [2] <author> J. J. MARCINIAK. </author> <title> Encyclopedia of Software Engineering. </title> <publisher> Wiley, </publisher> <year> 1994. </year>
Reference-contexts: studies suggest that EPA is a valuable technique for anyone concerned with the quality of the outputs that software produces. 1.1 Extended Propagation Analysis Differs from Traditional Measures of Fault-Tolerance Traditionally, fault tolerance refers to building subsystems from redundant components that are placed in parallel to ensure higher quality systems <ref> [2] </ref>. Unlike traditional fault tolerance, EPA not only seeks to aid developers in increasing quality, but it also measures the quality of software outputs.
Reference: [3] <author> M. ELDER AND J. KNIGHT. </author> <title> Specifying user interfaces for safety-critical medical systems. </title> <booktitle> In Proc. of the 2nd Annual International Symposium on Medical Robotics and Computer Assisted Surgery, </booktitle> <pages> pages 148-155, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: Further information concerning the operation of the MSS is provided in <ref> [3] </ref>. EPA was applied to a portion of the MSS responsible for controlling the current level in the coils. In the MSS, the coil current is adjusted by the controller subsystem in order to create a magnetic field that will move the seed to a specified location in the brain.
Reference: [4] <author> D. J. LAWSON. </author> <title> Failure Mode, Effect, and Criticality Analysis. </title> <editor> In J. K. Skwirzynski, editor, </editor> <booktitle> Electronic Systems Effectiveness and Life Cycle Costing, </booktitle> <pages> pages 55-74, </pages> <publisher> NATO ASI Series, F3, Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1983. </year>
Reference-contexts: As we will further explain below, EPA is a natural extension of the basic hypotheses on which fault-tree analysis is based. By contrast to the usual approach, however, EPA employs fault-injection to play "what-if" scenarios, much like a Failure Mode Effect and Criticality Analysis <ref> [4] </ref>. EPA's dynamic approach is computationally expensive in terms of cpu time. Fortunately EPA can be almost fully automated, leading to a software safety analysis technique that exploits readily-available computational power instead of relying on human intuition.
Reference: [5] <author> J. VOAS, C. C. MICHAEL AND K. MILLER. </author> <title> Using Fault-Injection to Assess Software Engineering Standards. </title> <booktitle> In Proc. of Pacific Northwest Software Quality Conference, </booktitle> <pages> pages 318-336, </pages> <address> Portland, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: A data state that has been changed is said to have been perturbed. Users of this technique have complete control over the perturbation functions and can define their own perturbation functions or use some default perturbation functions that we have published elsewhere <ref> [5] </ref>. EPA detects when particular types of output events or program data-state events occur by making use of a user-defined logical predicate called P RED.
Reference: [6] <author> J. VOAS, G. MCGRAW, A. GHOSH, F. CHARRON, AND K. MILLER. </author> <title> Defining an adaptive software security metric from a dynamic software failure tolerance measure. </title> <booktitle> In Proc. of Ninth Annual Conference on Computer Assurance, </booktitle> <institution> National Institute of Standards and Technology, Gaithersburg, MD, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: EPA only detects locations in the code where, if anomalies hypothetically existed and were triggered during execution, undesirable outputs could occur. 3.5 Other Applications EPA, together with its derivative techniques of Sensitivity Analysis [8] and Adaptive Vulnerability Analysis <ref> [6] </ref>, has demonstrated the potential for addressing a wealth of different software quality concerns. In this article, we have demonstrated EPA's application to four projects, two of which are real-world control applications. We now highlight other applications that are amenable to the EPA methodology.
Reference: [7] <author> J. VOAS AND K. MILLER. </author> <title> Dynamic testability analysis for assessing fault tolerance. </title> <journal> High Integrity Systems Journal, </journal> <volume> 1(2) </volume> <pages> 171-178, </pages> <year> 1994. </year>
Reference-contexts: The automated software analysis environment is called the PiSCES Safety Net (PSN). 1 The PiSCES Safety Net is an implementation of a software analysis technique called "extended propagation analysis", or EPA <ref> [7, 15] </ref>. EPA uses the injection of artificial faults (of both software and hardware varieties) to test software's tolerance to unusual events. Artificial faults simulate problems occurring both internally and externally to the software.
Reference: [8] <author> J. VOAS AND K. MILLER. </author> <title> Software Testability: The New Verification. </title> <journal> IEEE Software, </journal> <volume> 12(3) </volume> <pages> 17-28, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Note again that these cases do not represent actual faults in the code. EPA only detects locations in the code where, if anomalies hypothetically existed and were triggered during execution, undesirable outputs could occur. 3.5 Other Applications EPA, together with its derivative techniques of Sensitivity Analysis <ref> [8] </ref> and Adaptive Vulnerability Analysis [6], has demonstrated the potential for addressing a wealth of different software quality concerns. In this article, we have demonstrated EPA's application to four projects, two of which are real-world control applications. We now highlight other applications that are amenable to the EPA methodology.
Reference: [9] <author> H. D. MILLS. </author> <title> On the Statistical Validation of Computer Programs. </title> <institution> IBM Federal Systems Division, Report FSC-72-6015, Gaithersburg, MD. </institution>
Reference-contexts: Thus acceptable results can be made to exhibit characteristics such as correctness, timeliness, and/or safety. 2 Extended Propagation Analysis: Theory and Implementation EPA works by instrumenting source code with functions that cause corrupted internal states. In principle, this is similar to a predecessor technique known as error seeding <ref> [9] </ref>. As such, EPA is meant to be applied late in the software life-cycle, near the time when code certification occurs.
Reference: [10] <author> J. D. MUSA. </author> <title> Operational Profiles in Software Reliability Engineering. </title> <journal> IEEE Software, </journal> <volume> 10(2), </volume> <month> March </month> <year> 1993. </year>
Reference-contexts: Clearly the most interesting result from this case study is that divergent operational profiles can produce quite divergent results, and hence the benefit of having an accurate operational distribution is again demonstrated <ref> [10] </ref>. 3.3 Case Study 3: Magnetic Stereotaxis System Our third case study involves a real-world control problem in a medical domain | the Magnetic Stereotaxis System (MSS).
Reference: [11] <author> NASA. </author> <title> NASA Software Safety Standard. Office of Safety and Mission Assurance, </title> <month> June </month> <year> 1994. </year> <note> Interim Report 1740.13. </note>
Reference-contexts: The report states that the Code Safety Analysis phase of development must: Identify potentially unsafe states caused by input/output timing, multiple events, out-of-sequence events, failure of events, adverse environments, deadlocking, wrong events, inappropriate magni 13 tude, improper polarity, and hardware failure sensitivities, etc. <ref> [11] </ref> Underwriter's Laboratory also has a software safety standard (UL1998) in place.
Reference: [12] <author> K. N. KING AND A. J. OFFUTT. </author> <title> A Fortran Language System for Mutation-based Software Testing. </title> <journal> Software-Practice and Experience, </journal> <volume> 27(7), </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: EPA uses the injection of artificial faults (of both software and hardware varieties) to test software's tolerance to unusual events. Artificial faults simulate problems occurring both internally and externally to the software. Although there is extensive literature on the use of artificial faults in software testing <ref> [13, 12] </ref>, the commercial adoption of such techniques has been slow, due to both practical and theoretical limitations. Though EPA is certainly related to previous work in artificial fault injection, it is distinct in two important ways: 1. EPA does not worry about correctness.
Reference: [13] <author> R. A. DEMILLO, R. J. LIPTON, AND F. G. SAYWARD. </author> <title> Hints on test data selection: Help for the practicing programmer. </title> <journal> IEEE Computer, </journal> <volume> 11(4) </volume> <pages> 34-41, </pages> <month> April </month> <year> 1978. </year> <month> 16 </month>
Reference-contexts: EPA uses the injection of artificial faults (of both software and hardware varieties) to test software's tolerance to unusual events. Artificial faults simulate problems occurring both internally and externally to the software. Although there is extensive literature on the use of artificial faults in software testing <ref> [13, 12] </ref>, the commercial adoption of such techniques has been slow, due to both practical and theoretical limitations. Though EPA is certainly related to previous work in artificial fault injection, it is distinct in two important ways: 1. EPA does not worry about correctness.
Reference: [14] <institution> UNDERWRITERS LABORATORY INC. Safety Related Software, </institution> <month> January </month> <year> 1994. </year> <title> Standard for Safety UL1998, First Edition. </title>
Reference-contexts: . . b) Coding errors, including syntax, incorrect signs, endless loops, and the like; c) Timing errors that can cause program execution to occur prematurely or late; d) Induced errors caused by hardware failure; e) Latent errors that are not detectable until a given set of conditions occur;. . . <ref> [14] </ref> These standards explicitly spell out hazardous output events and internal events that are undesirable. Along with an appropriate set of simulated infections, data state assertions, and output events, EPA is able to provide an important relative measure of code robustness.
Reference: [15] <author> M. FRIEDMAN AND J. VOAS. </author> <title> Software Assessment: Reliability, Safety, Testability. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1995. </year> <note> ISBN 0471-01009-X. </note>
Reference-contexts: The automated software analysis environment is called the PiSCES Safety Net (PSN). 1 The PiSCES Safety Net is an implementation of a software analysis technique called "extended propagation analysis", or EPA <ref> [7, 15] </ref>. EPA uses the injection of artificial faults (of both software and hardware varieties) to test software's tolerance to unusual events. Artificial faults simulate problems occurring both internally and externally to the software.
Reference: [16] <author> P. YAM. </author> <title> Magnet on the Brain. </title> <journal> Scientific American, August 1996, </journal> <volume> Vol. 275, No. 2, pg. 32. </volume> <pages> 17 </pages>
Reference-contexts: Dr. John Knight of UVA provided us with access to the source code for an early version of the control software for the MSS; what relationship if any our code has with the code to the real system that is slated to undergo FDA approval is unknown <ref> [16] </ref>. Further information concerning the operation of the MSS is provided in [3]. EPA was applied to a portion of the MSS responsible for controlling the current level in the coils.
References-found: 16

