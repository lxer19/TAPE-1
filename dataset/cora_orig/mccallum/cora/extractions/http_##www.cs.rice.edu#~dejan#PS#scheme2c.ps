URL: http://www.cs.rice.edu/~dejan/PS/scheme2c.ps
Refering-URL: http://www.cs.rice.edu:80/~dejan/
Root-URL: 
Title: The Architecture of Function Calls  
Author: Dejan Mircevski Bruce F. Duba 
Address: Houston, Texas  
Affiliation: Department of Computer Science, Rice University,  
Abstract: This paper shows that the principal difference between portable tail-recursive code generators is in the way they generate a function call. It also measures the cost of a portable function call on two popular architectures: MIPS and SPARC.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Henry G. Baker. </author> <title> Cons should not cons its arguments, part ii: Cheney on the m.t.a. </title> <type> Draft Memorandum, </type> <month> January </month> <year> 1994. </year>
Reference-contexts: n, ...) - if (ZERO (n)) - ARGUMENTS (symbol_done); return CURRENT_CONTINUATION; - else - object g1 = NEW_OBJECT (number_object); set_number_field (g1, MINUS (n, const_1)); ARGUMENTS (g1); return loop; - Here CURRENT CONTINUATION is a macro referencing the current continuation. 2.3 Baker The Baker method was proposed by Henry Baker in <ref> [1] </ref>. It improves over the trampoline's call sequence by invoking the callee immediately, without returning to the trampoline. <p> Compilers with code generators similar to the ones we are considering have traditionally used continuation-passing style, or CPS, as their intermediate form. In fact, both Baker and trampoline methods were originally developed within CPS frameworks <ref> [1, 9] </ref>.
Reference: [2] <author> Joel F. Bartlett. Scheme|&gt;c: </author> <title> a portable scheme-to-c compiler. </title> <type> Research Report 89 1, </type> <institution> DEC Western Research Laboratory, Palo Alto, California, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: Since function returns are transformed into jumps, the caller's context may be safely discarded by doing the goto. 2.4.1 Bartlett There is yet another method which bears mentioning, since it has been in use for a while in Bartlett's Scheme!C compiler <ref> [2] </ref>. The method optimizes only tail calls to known functions. A function is known [8] if it only appears in the call position of any expression using it.
Reference: [3] <author> Cormac Flanagan, Amr Sabry, Bruce F. Duba, and Matthias Felleisen. </author> <title> The essence of compiling with continuations. </title> <booktitle> In Proc. SIGPLAN '93 Conference on Programming Languages Design and Implementation, </booktitle> <pages> pages 237-247, </pages> <year> 1993. </year>
Reference-contexts: Little Lisp has minimal support for basic data types and primitive operations, but it provides powerful control constructs through first-order functions and first-order continuations. The semantics of Little Lisp is similar to the semantics of Core Scheme from <ref> [3] </ref>. All the constructs have their usual meanings, with if0 evaluating the "then" part if the condition evaluates to zero, and the "else" part otherwise. 4 The Compilation System The compilation system consists of several parts, as depicted in figure 2. <p> The input program is first converted into the A-normal form <ref> [3] </ref>, or ANF. A-normal form, given in figure 3, explicitly names the intermediate results, but doesn't translate the function calls into jumps. Compilers with code generators similar to the ones we are considering have traditionally used continuation-passing style, or CPS, as their intermediate form. <p> M n ) V ! n j i O ! + j j fl j = j &lt; j cons j car j cdr j pair? n 2 Numbers i 2 Variables V 2 Values O 2 Primitive Operations * ANF is a more direct transformation than a non-nave CPS <ref> [3] </ref>. * Passing continuations is not really necessary for the code generators to work. All that is needed is translating the function calls into jumps. * First-class continuations are cheaper to build in ANF than in CPS.
Reference: [4] <author> Richard P. Gabriel. </author> <title> Performance and Evaluation of Lisp systems. </title> <publisher> MIT Press, </publisher> <year> 1985. </year> <month> 12 </month>
Reference-contexts: This does not, however, devaluate our experiments | we want to compare the cost of function calls, and our benchmarks do contain a lot of function calls (even more so because they are purely functional). The benchmark set includes six programs from the Gabriel suite <ref> [4] </ref>: cpstak, ctak, deriv, div, tak, and takl. The rest of the programs in the suite were not purely functional, and we decided not to rewrite them in Little Lisp. A similar issue arose with the hal benchmark, which uses imperative style to implement lazy sequences.
Reference: [5] <author> Richard A. Kelsey. </author> <title> Tail-recursive stack disciplines for an interpreter. </title> <type> Technical Report NU--CCS-93-03, </type> <institution> College of Computer Science, Northeastern University, (enhanced), </institution> <year> 1993. </year>
Reference-contexts: We are not aware of any previous work comparing the performance of portable tail-recursive code generators. Tarditi, et al., compare the performance of a portable trampoline code generator to a native code generator in [9]. Kelsey investigates stack disciplines for implementing tail-recursive function call in interpreters <ref> [5] </ref>.
Reference: [6] <author> Lawrence C. Paulson. </author> <title> ML for the Working Programmer. </title> <publisher> Cambridge University Press, </publisher> <year> 1993. </year>
Reference-contexts: Thus the performance of Little Lisp programs is a good indicator of the function call performance. Little Lisp is, on the other hand, still capable of expressing interesting programs, like the Hal automatic theorem prover <ref> [6, chapter 10] </ref>. 2 Portable Code Generators This section describes the details of the code generators, starting with the general points applicable to all of them, in 2.1, followed by the particulars of each, in 2.2 to 2.4, and finishing with a brief consideration of yet another code generator, which is <p> For the measurements, we used a SPARCStation 5 and a DECStation 5000/200. The C compiler was, on both machines, gcc-2.6.3, with "-O" switch. The sizes of input for the benchmarks were 10 hal A tactical theorem prover <ref> [6, chapter 10] </ref>; 850 lines primes Prime numbers using the sieve method; 25 lines church Primality tester for Church numerals; 110 lines deriv Symbolic derivative finder for simple func tions; 129 lines div Division by 2 using lists for numbers; 29 lines fibo Recursive Fibonacci; 9 lines tak Takeuchi function; 11
Reference: [7] <author> Amr Sabry and Matthias Felleisen. </author> <title> Reasoning about programs in continuation-passing style. </title> <booktitle> In Proc. 1992 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 288-298, </pages> <year> 1993. </year>
Reference-contexts: In fact, both Baker and trampoline methods were originally developed within CPS frameworks [1, 9]. The reasons we prefer ANF over CPS are: * ANF has the same potential for optimizations as CPS <ref> [7] </ref>. 7 M ! V j (if0 M M 1 M 2 ) j (letrec (i ( (i 1 i 2 : : : i n ) M 1 )) M 2 ) j (letcc i M) j (M M 1 : : : M n ) V ! n j
Reference: [8] <author> Guy L. Steele, Jr. RABBIT: </author> <title> A compiler for SCHEME. </title> <type> Memo 474, </type> <institution> MIT AI Lab, </institution> <year> 1978. </year>
Reference-contexts: The method optimizes only tail calls to known functions. A function is known <ref> [8] </ref> if it only appears in the call position of any expression using it. If, on the other hand, there is an expression which uses the function in a way other than calling it, that function is an escaping function. <p> All that is needed is translating the function calls into jumps. * First-class continuations are cheaper to build in ANF than in CPS. The next stage in the compiler, the known-funciton analysis, is an optional optimization of the ANF program. Closures need not be created for known functions <ref> [8] </ref>. The known-function analysis identifies all calls to known functions and extends the argument lists of these functions to include their free variables. The tail-conversion stage finally translates the function calls into jumps. The stage's output is the true intermediate form of our compiler.
Reference: [9] <author> David Tarditi, Peter Lee, and Anurag Acharya. </author> <title> No assembly required: Compiling standard ML to C. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1-2:161-177, </volume> <year> 1986. </year> <editor> 13 church cpstak ctak deriv div fibo tak takl hal primes Baker 4.80 8.73 5.47 5.77 4.03 5.57 3.50 5.20 5.89 6.57 Trampoline 8.00 17.13 10.50 7.97 6.27 11.50 6.80 10.53 8.03 7.70 Gnu C 4.57 10.00 5.60 4.97 3.90 8.00 3.90 4.60 5.50 6.33 Table 5: </editor> <title> Execution times on MIPS 14 </title>
Reference-contexts: Compilers with code generators similar to the ones we are considering have traditionally used continuation-passing style, or CPS, as their intermediate form. In fact, both Baker and trampoline methods were originally developed within CPS frameworks <ref> [1, 9] </ref>. <p> In particular, the SPARC architecture makes the portable function calls a la Baker extremely expensive. We are not aware of any previous work comparing the performance of portable tail-recursive code generators. Tarditi, et al., compare the performance of a portable trampoline code generator to a native code generator in <ref> [9] </ref>. Kelsey investigates stack disciplines for implementing tail-recursive function call in interpreters [5].
References-found: 9

