URL: http://www.cs.utexas.edu/users/yau/papers/sigcomm97.ps
Refering-URL: http://www.cs.utexas.edu/users/yau/research.html
Root-URL: 
Email: fyau,lamg@cs.utexas.edu  
Title: Migrating Sockets for Networking with Quality of Service Guarantees  
Author: David K.Y. Yau and Simon S. Lam 
Date: February 5, 1997  
Address: Austin, Texas 78712-1188  
Affiliation: Department of Computer Sciences The University of Texas at Austin  
Pubnum: TR-97-05  
Abstract: With network infrastructure and application requirements quickly evolving, flexible and customizable implementation of network protocols will become highly desirable. Towards this goal, we present Migrating Sockets as a framework for implementing protocols at user level. Migrating Sockets runs as the protocol processing component of an end system architecture designed for networking with quality of service (QoS) guarantees. The architecture provides (1) adaptive rate-controlled (ARC) scheduling of protocol threads used in Migrating Sockets, (2) rate-based flow control for reserved rate connections in future integrated services networks, and (3) a constant overhead packet demultiplexing mechanism (active demulti-plexing) based on exclusive packet receiver information exported by Migrating Sockets. Migrating Sockets achieves its efficiency by allowing user applications to manage a network endpoint with minimal system intervention, providing user level protocols read-only access to routing information in a well-known shared memory region, and integrating efficient kernel level support we previously built. The framework is backward compatible with Unix semantics and Berkeley sockets, and has been used to implement Internet protocols such as TCP, UDP and IP (including IP multicast). We also show that active demultiplexing supported by the framework can be transparently enabled in wide-area TCP/IP internetworking (although it is not restricted to TCP/IP). We have an implementation of the framework in Solaris 2.5. We discuss our implementation experience, and present performance figures of our system running on the Ultra-1, SPARC 10 and SPARC 20 architectures. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M.L. Bailey, B. Gopal, M.A. Pagels, L.L. Peterson, and P. Sarkar. PATHFINDER: </author> <title> A pattern-based packet classifier. </title> <booktitle> In Proc. First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 115123, </pages> <address> Monterey, CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: On the receive side, packet arrivals to a network interface are processed by the interrupt handler of the interface. Kernel level code must then demultiplex the packets to their destination processes. Traditionally, such demultiplexing is performed by packet filters [5, 11] (also known as packet classifiers in <ref> [1] </ref>). Our system makes use of packet filters, but, in addition, can exploit exclusive packet receiver information exported by Migrating Sockets to perform active packet demultiplexing.
Reference: 2. <author> Torsten Braun and Christophe Diot. </author> <title> Protocol implementation using integrated layer processing. </title> <booktitle> In Proc. ACM SIGCOMM '95, </booktitle> <address> Boston, MA, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: These works target high performance on the send/receive path, without paying much attention to the issues of connection management, routing management, and the semantics of sharing network endpoints. Performance benefits of Integrated Layer Processing in user level protocols are evaluated in <ref> [2] </ref>. Migrating Sockets similarly enables the integration of protocol functions at the presentation, session, transport and network layers. Real-time upcalls were proposed in [6] to achieve QoS guarantees in protocol processing.
Reference: 3. <author> Chris Dalton, Greg Watson, David Banks, Costas Calamvokis, Aled Edwards, and John Lumley. </author> <title> Afterburner. </title> <journal> IEEE Network, </journal> <volume> 7(4):3643, </volume> <month> July </month> <year> 1993. </year> <title> subsystem (Ultra-1 and SPARC 10). size (in bytes) for Ultra-1. </title>
Reference-contexts: Additional goals such as compatibility with Berke-ley sockets and Unix semantics are addressed in [10]. A user level TCP implementation on top of the Jetstream high-speed network interface is described in <ref> [3] </ref>. U-Net [19] integrates interface firmware with host software in a design that provides user level access to a network without kernel intervention.
Reference: 4. <author> Peter Druschel and Larry L. Peterson. Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility. </title> <booktitle> In Proc. 14th SOSP, </booktitle> <pages> pages 189202, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Send/receive buffers shown in Figure 6 are allocated using the IOBuffer::IOBuffer () method in Table 1. The method creates a network buffer region for direct send/receive to/from the network (i.e. no intermediate data copies are required <ref> [4] </ref>). If the network interface for send/receive uses DMA, the allocated network buffers will be automatically backed by required DMA resources. Moreover, buffers can be pinned in physical memory for predictable performance.
Reference: 5. <author> D.R. Engler and M.F. Kaashoek. DPF: </author> <title> fast, flexible message demultiplexing using dynamic code generation. </title> <booktitle> In Proc. ACM SIGCOMM '96, </booktitle> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: On the receive side, packet arrivals to a network interface are processed by the interrupt handler of the interface. Kernel level code must then demultiplex the packets to their destination processes. Traditionally, such demultiplexing is performed by packet filters <ref> [5, 11] </ref> (also known as packet classifiers in [1]). Our system makes use of packet filters, but, in addition, can exploit exclusive packet receiver information exported by Migrating Sockets to perform active packet demultiplexing.
Reference: 6. <author> R. Gopalakrishnan and G.M. Parulkar. </author> <title> Real-time upcalls: A mechanism to provide real-time processing guarantees. </title> <type> Technical report, </type> <institution> Washington University, </institution> <year> 1995. </year>
Reference-contexts: Performance benefits of Integrated Layer Processing in user level protocols are evaluated in [2]. Migrating Sockets similarly enables the integration of protocol functions at the presentation, session, transport and network layers. Real-time upcalls were proposed in <ref> [6] </ref> to achieve QoS guarantees in protocol processing. While the approach is an interesting alternative to real-time threads, it is specifically designed for periodic protocol processing and appears to be less general than our approach. Moreover, [6] addresses only performance on the send/receive path. <p> Real-time upcalls were proposed in <ref> [6] </ref> to achieve QoS guarantees in protocol processing. While the approach is an interesting alternative to real-time threads, it is specifically designed for periodic protocol processing and appears to be less general than our approach. Moreover, [6] addresses only performance on the send/receive path.
Reference: 7. <author> N.C. Hutchinson, S. Mishra, L.L. Peterson, and V.T. Thomas. </author> <title> Tools for implementing network protocols. </title> <journal> Software Practice and Experience, </journal> <year> 1989. </year>
Reference-contexts: However, parts of the runtime support system have been rewritten. First, we replaced BSD mbuf buffer management by message blocks similar to those used in SVR4 streams. This is because mbuf has been found to treat small and large messages non-uniformly and hence exhibit undesirable performance idiosyncrasies <ref> [7] </ref>. Moreover, message blocks can very naturally handle both normal data buffers and network buffers (see section 4.4) supported in our system (using the esballoc () library call). Second, we implemented a timer management interface for timer activities.
Reference: 8. <author> Van Jacobson. </author> <note> LBL whiteboard. </note> <institution> Lawrence Berkeley Lab, </institution> <note> software on-line at ftp://ftp.ee.lbl.gov/conferencing/wb. </note>
Reference-contexts: We believe that such flexibility and customizability will become highly desirable, given recent proliferation of heterogeneous networking technologies and user application requirements <ref> [8, 9, 12, 22] </ref>. Apart from flexibility and customizability, it is increasingly impor fl Research supported in part by National Science Foundation under grant no.
Reference: 9. <author> Van Jacobson. </author> <title> Visual audio tool. </title> <institution> Lawrence Berkeley Lab, </institution> <note> software on-line at ftp://ftp.ee.lbl.gov/conferencing/vat. </note>
Reference-contexts: We believe that such flexibility and customizability will become highly desirable, given recent proliferation of heterogeneous networking technologies and user application requirements <ref> [8, 9, 12, 22] </ref>. Apart from flexibility and customizability, it is increasingly impor fl Research supported in part by National Science Foundation under grant no.
Reference: 10. <author> Chris Maeda and Brian N. Bershad. </author> <title> Protocol service decomposition for high-performance networking. </title> <booktitle> In Proc. 14th SOSP, </booktitle> <pages> pages 244255, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: We present experimental results on the performance of our current system in section 7, and conclude in section 8. 1.3 Related work There has been growing interest in user level protocol implementation in recent years. In <ref> [10, 18] </ref>, an application process performs protocol operations of connection management through an intermediate server process, while operations on the performance critical path, such as send and receive, are performed directly by the application process. Additional goals such as compatibility with Berke-ley sockets and Unix semantics are addressed in [10]. <p> Additional goals such as compatibility with Berke-ley sockets and Unix semantics are addressed in <ref> [10] </ref>. A user level TCP implementation on top of the Jetstream high-speed network interface is described in [3]. U-Net [19] integrates interface firmware with host software in a design that provides user level access to a network without kernel intervention. <p> We there QoS guarantees. fore decided to maintain backward compatibility with the widely used Berkeley socket interface. In concept, our migrating sockets framework draws upon previous experience in user level protocol implementation <ref> [10, 18] </ref>. In what follows, we give an overview of Migrating Sockets. Several novel ideas implemented in the framework are presented in section 4. 3.1 Berkeley sockets Sockets are used by applications to access local endpoints of network connections. <p> Hence, it was higher for a larger packet size. We note that although high performance is not the main concern in our work, our TCP/UDP latency numbers do seem to compare very well with those reported in the literature (e.g. <ref> [10] </ref>). 3 7.4 Protocol runtime support Migrating Sockets implements a buffer management subsystem and timer subsystem different from those in 4.4 BSD. We measured the performance of the buffer management subsystem in our current implementation. Figure 11 shows the overhead for copying a message block.
Reference: 11. <author> S. McCanne and Van Jacobson. </author> <title> The BSD packet filter: A new architecture for user-level packet capture. </title> <booktitle> In USENIX Technical Conference Proceedings, </booktitle> <pages> pages 259269, </pages> <address> San Diego, CA, </address> <month> Winter </month> <year> 1993. </year>
Reference-contexts: On the receive side, packet arrivals to a network interface are processed by the interrupt handler of the interface. Kernel level code must then demultiplex the packets to their destination processes. Traditionally, such demultiplexing is performed by packet filters <ref> [5, 11] </ref> (also known as packet classifiers in [1]). Our system makes use of packet filters, but, in addition, can exploit exclusive packet receiver information exported by Migrating Sockets to perform active packet demultiplexing.
Reference: 12. <author> S. McCanne and Van Jacobson. </author> <title> vic: A flexible framework for packet video. </title> <booktitle> In Proc. ACM Multimedia '95, </booktitle> <year> 1995. </year>
Reference-contexts: We believe that such flexibility and customizability will become highly desirable, given recent proliferation of heterogeneous networking technologies and user application requirements <ref> [8, 9, 12, 22] </ref>. Apart from flexibility and customizability, it is increasingly impor fl Research supported in part by National Science Foundation under grant no.
Reference: 13. <author> Clifford W. Mercer, Jim Zelenka, and Ragunathan Rajkumar. </author> <title> On predictable operating system protocol processing. </title> <type> Technical Report CMU-CS-94-165, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> May </month> <year> 1994. </year> <title> versus data size (in bytes) for small memory footprint (Ultra-1). versus data size (in bytes) for large memory footprint (Ultra-1). </title>
Reference-contexts: Moreover, [6] addresses only performance on the send/receive path. Lastly, protocol processing with predictable performance has been investigated in the context of Real-Time Mach <ref> [13] </ref>, based upon design principles for CPU scheduling different from ours. 2 Architectural Overview Our end system architecture for networking with QoS guarantees has the following major components: (1) adaptive rate-controlled (ARC) scheduling for time-shared resources in an end system, such as CPU and network interface, (2) a migrating sockets framework
Reference: 14. <author> C. Partridge and S. Pink. </author> <title> A faster UDP. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 1(4):429440, </volume> <month> August </month> <year> 1993. </year>
Reference-contexts: Deliver packet directly to process identified in handle; 5. return; fallback: 6. Match packet against installed packet filters in system; end ; rithm. 4.4 BSD to Migrating Sockets. For UDP, we have incorporated the following optimization techniques proposed in <ref> [14] </ref>: (1) Integrated checksumming and copying of data from application buffers to network buffers, (2) replacement of general purpose socket send code with more efficient UDP specific code, and (3) delete of pseudo-connect in UDP send.
Reference: 15. <author> K.K. Ramakrishnan, L. Vaitzblit, C. Gray, U. Vahalia, D. Ting, P. Tzelnic, S. Glaser, and W. Duso. </author> <title> Operating system support for a video-on-demand service. Multimedia Systems, </title> <address> 1995(3):5365, </address> <year> 1995. </year>
Reference-contexts: Aside from the use of background system services, traditional kernel level protocols perform entire receive side protocol processing in the context of interrupt handling. From a QoS perspective, it is similarly difficult to control the rate of progress of interrupt handling code (some researchers, such as <ref> [15] </ref>, have considered disabling device interrupt for more predictable performance). Migrating Sockets reduces the use of such hidden scheduling for cached sockets. First, each user process has a dedicated timer thread that handles timer events only for network endpoints local to the process.
Reference: 16. <author> D.M. Ritchie. </author> <title> A stream input-output system. </title> <journal> AT&T Bell Laboratories Technical Journal, </journal> <volume> 63(8):18971910, </volume> <month> October </month> <year> 1984. </year>
Reference-contexts: In streams <ref> [16] </ref>, for example, network send and receive can take place in service routines run by background system threads of control. In BSD Unix, a single system timeout invocation has to handle outstanding timer activities of all the network endpoints in the system.
Reference: 17. <author> Richard Stevens. </author> <title> UNIX Network Programming. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: Section 5 discusses ARC scheduling for protocol threads in Migrating Sockets. 4.2 Optimization for concurrent server model In client/server programming, there are two principal programming models. They are the iterative server model and the concurrent server model (see, for example, <ref> [17] </ref>). In the latter model, the server's role is only to listen for service requests from remote hosts. Once a request has been received, the server forks a child process to handle it, and itself goes back to listening for more requests.
Reference: 18. <author> C.A. Thekkath, T.D. Nguyen, E. Moy, and E.D. Lazowska. </author> <title> Implementing network protocols at user level. </title> <journal> IEEE/ACM Trans. Networking, </journal> <volume> 1(5):554565, </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: With fault containment in user processes and the availability of sophisticated tools for developing user level code, the cost of protocol development and experimentation will go down, and the lead time to deployment of protocols in a production environment will be reduced <ref> [18] </ref>. Moreover, without the need to configure and load protocols into kernel space, user applications can be given access to a wider choice of protocol stacks and choose the one that is most suitable for their particular needs. <p> We present experimental results on the performance of our current system in section 7, and conclude in section 8. 1.3 Related work There has been growing interest in user level protocol implementation in recent years. In <ref> [10, 18] </ref>, an application process performs protocol operations of connection management through an intermediate server process, while operations on the performance critical path, such as send and receive, are performed directly by the application process. Additional goals such as compatibility with Berke-ley sockets and Unix semantics are addressed in [10]. <p> We there QoS guarantees. fore decided to maintain backward compatibility with the widely used Berkeley socket interface. In concept, our migrating sockets framework draws upon previous experience in user level protocol implementation <ref> [10, 18] </ref>. In what follows, we give an overview of Migrating Sockets. Several novel ideas implemented in the framework are presented in section 4. 3.1 Berkeley sockets Sockets are used by applications to access local endpoints of network connections.
Reference: 19. <author> Thorsten von Eicken, Anindya Basu, Vineet Buch, and Werner Vogels. U-Net: </author> <title> A user-level network interface for parallel and distributed computing. </title> <booktitle> In Proc. 15th SOSP, </booktitle> <month> November </month> <year> 1995. </year>
Reference-contexts: Additional goals such as compatibility with Berke-ley sockets and Unix semantics are addressed in [10]. A user level TCP implementation on top of the Jetstream high-speed network interface is described in [3]. U-Net <ref> [19] </ref> integrates interface firmware with host software in a design that provides user level access to a network without kernel intervention. These works target high performance on the send/receive path, without paying much attention to the issues of connection management, routing management, and the semantics of sharing network endpoints.
Reference: 20. <author> David K.Y. Yau and Simon S. Lam. </author> <title> Adaptive rate-controlled scheduling for multimedia applications. </title> <booktitle> In Proc. ACM Multimedia, </booktitle> <address> Cambridge, MA, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: Based on the progress requirements of all processes in the system, an ARC CPU scheduler can perform admission control and provide conditional progress guarantees to processes. The ARC scheduler in <ref> [20] </ref> provides the following progress guarantee: a punctual process with rate r and period p is guaranteed at least krp CPU time over time interval kp, for k = 1; 2; : : :. <p> concurrent server programming model, (3) sharing of routing information between network and higher level protocols using a well-known shared memory region, and (4) a kernel/user interface that provides user level protocol code with access to efficient kernel level support [21] through Unix file descriptors. 4.1 Minimizing hidden scheduling Our experience <ref> [20] </ref> has been that it is difficult to provide QoS guarantees in certain protocol implementation frameworks. In streams [16], for example, network send and receive can take place in service routines run by background system threads of control. <p> The IOBuffer::IOBuffer () method creates device dependent DMA resources backing allocated network buffers. 5 ARC Scheduling of Protocol Threads Application and protocol threads in Migrating Sockets can specify their CPU requirements using the rate-based reservation model of ARC scheduling <ref> [20] </ref>. The rate-based model has two parameters: (1) rate, r, (0 &lt; r 1), and (2) period, p, in s. Informally, the rate specifies a guaranteed fraction of CPU time that a thread with the reservation will be allocated over time intervals determined by p. <p> ARC schedulers have the following properties: (1) reserved rate can be negotiated, (2) QoS guarantees are conditional upon thread behavior, and (3) firewall protection between threads is provided. The first property is provided by a monitoring module and a rate-adaptation interface as discussed in <ref> [20] </ref>. The second and third properties are provided by using an on-line CPU scheduling algorithm with the firewall property, such as the RC scheduler in [20]. <p> The first property is provided by a monitoring module and a rate-adaptation interface as discussed in <ref> [20] </ref>. The second and third properties are provided by using an on-line CPU scheduling algorithm with the firewall property, such as the RC scheduler in [20].
Reference: 21. <author> David K.Y. Yau and Simon S. Lam. </author> <title> An architecture towards efficient OS support for distributed multimedia. </title> <booktitle> In Proc. IS&T/SPIE Multimedia Computing and Networking, </booktitle> <pages> pages 424435, </pages> <address> San Jose, CA, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: Fourth, Migrating Sockets has been integrated with operating system techniques that minimize data copying and system call overhead for network communication <ref> [21] </ref>. Lastly, exclusive packet receiver information exported by Migrating Sockets enables a constant overhead packet demultiplex-ing mechanism called active demultiplexing. By eliminating table search, active demultiplexing is highly efficient and is suitable for networking with QoS guarantees. 1.2 Organization of this paper The balance of this paper is as follows. <p> If the network connection is shared by multiple processes, it is possible for a sudden burst of packets by one process to block out access to the network connection for an extended period of time <ref> [21] </ref>, thereby jeopardizing the bandwidth requirements of other processes. This problem is especially pronounced if the connection has a moderate or low reserved rate. To solve the problem, an end system should provide rate-based flow control to reserved-rate network connections. In our proposal [21], flow control is enforced by a lightweight <p> connection for an extended period of time <ref> [21] </ref>, thereby jeopardizing the bandwidth requirements of other processes. This problem is especially pronounced if the connection has a moderate or low reserved rate. To solve the problem, an end system should provide rate-based flow control to reserved-rate network connections. In our proposal [21], flow control is enforced by a lightweight kernel thread. The approach is quite flexible in that different flow control policies can be provided by different loadable kernel modules. On the receive side, packet arrivals to a network interface are processed by the interrupt handler of the interface. <p> minimizing hidden scheduling in protocol processing, (2) caching optimization for the concurrent server programming model, (3) sharing of routing information between network and higher level protocols using a well-known shared memory region, and (4) a kernel/user interface that provides user level protocol code with access to efficient kernel level support <ref> [21] </ref> through Unix file descriptors. 4.1 Minimizing hidden scheduling Our experience [20] has been that it is difficult to provide QoS guarantees in certain protocol implementation frameworks. In streams [16], for example, network send and receive can take place in service routines run by background system threads of control. <p> For example, users on a Unix system are often permitted to use the netstat (1) command to return the same kind of information. 4.4 Protocol/kernel interface For efficiency, Migrating Sockets runs on top of an OS architecture (Figure 6) we have previously prototyped for supporting continuous media (CM) applications <ref> [21] </ref>. 2 This region is mapped read-only by application processes. Send/receive buffers shown in Figure 6 are allocated using the IOBuffer::IOBuffer () method in Table 1. The method creates a network buffer region for direct send/receive to/from the network (i.e. no intermediate data copies are required [4]). <p> The method causes a multiplex group, a data structure used by the kernel thread for rate-based packet scheduling, to be created within the kernel. The alg parameter specifies the packet scheduling algorithm to use for the multiplex group. Currently, the KT RC algorithm in <ref> [21] </ref> is supported. Parameters of the scheduling algorithm can be passed with the params pointer. For example, the KT RC algorithm takes the scheduling period (in s) of the kernel thread as a parameter.
Reference: 22. <author> Lixia Zhang, Stephen Deering, Deborah Estrin, Scott Shenker, and Daniel Zappala. RSVP: </author> <title> A new resource ReSerVation Protocol. </title> <journal> IEEE Network, </journal> <pages> pages 818, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: We believe that such flexibility and customizability will become highly desirable, given recent proliferation of heterogeneous networking technologies and user application requirements <ref> [8, 9, 12, 22] </ref>. Apart from flexibility and customizability, it is increasingly impor fl Research supported in part by National Science Foundation under grant no.
References-found: 22

