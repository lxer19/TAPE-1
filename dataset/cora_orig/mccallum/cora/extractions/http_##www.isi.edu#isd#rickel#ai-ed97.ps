URL: http://www.isi.edu/isd/rickel/ai-ed97.ps
Refering-URL: http://www.isi.edu/isd/rickel/index.html
Root-URL: http://www.isi.edu
Email: rickel, johnson@isi.edu  
Title: Intelligent Tutoring in Virtual Reality: A Preliminary Report  
Author: Jeff Rickel and W. Lewis Johnson 
Web: http://www.isi.edu/isd/VET/vet.html  
Address: 4676 Admiralty Way, Marina del Rey, CA 90292-6695  
Affiliation: Information Sciences Institute Computer Science Department University of Southern California  
Date: August 1997.  
Note: To appear in Proc. of Eighth World Conference on AI in Education,  
Abstract: Virtual reality simulation environments offer exciting opportunities and challenges for intelligent tutoring systems. Students, immersed in a 3D computer simulation of their work environment, improve their skills through practice on realistic tasks. Computer tutors can inhabit the virtual world along with students, allowing them to physically collaborate with students on tasks, and they can interact and communicate in nonverbal ways that would be impossible with a traditional disembodied computer tutor. This paper discusses these opportunities and challenges, as well as our progress in addressing them in our pedagogical agent Steve. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.R. Anderson, A.T. Corbett, K.R. Koedinger, and R. Pelletier. </author> <title> Cognitive tutors: Lessons learned. </title> <journal> Journal of the Learning Sciences, </journal> <volume> 4(2) </volume> <pages> 167-207, </pages> <year> 1995. </year>
Reference-contexts: We turn to this issue next. 3 Representing and Reasoning about Domain Tasks Intelligent tutoring systems typically represent procedural knowledge in one of two ways. Some, notably those of Anderson and his colleagues <ref> [1] </ref>, use detailed cognitive models built from production rules. Such systems perform domain tasks by directly executing the rules. Other systems use a declarative representation of the knowledge, usually some variant of a procedural network representation [20] specifying the steps in the procedure and their ordering.
Reference: [2] <author> N.I. Badler, C.B. Phillips, and B.L. Webber. </author> <title> Simulating Humans. </title> <publisher> Oxford University Press, </publisher> <year> 1993. </year>
Reference-contexts: Currently, we are experimenting with three graphical representations for Steve: a head and hand, as described in Section 2, a hand alone, and a full human figure. To implement the full human figure, we use the Jack software <ref> [2] </ref> developed at the University of Pennsylvania. Jack can be used two different ways. The Jack software would allow course authors to create a variety of animation sequences, and these could be dynamically strung together by Steve during task execution.
Reference: [3] <author> M. Billinghurst and J. Savage. </author> <title> Adding intelligence to the interface. </title> <booktitle> In Proc. of IEEE Virtual Reality Annual International Symposium (VRAIS '96), </booktitle> <pages> pages 168-175, </pages> <address> 1996. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: A virtual reality interface makes plan recognition more difficult than action menus, but it also opens up new possibilities. Data gloves with position sensors allow students to use gestures and to reference objects in the virtual world by pointing at them. Billinghurst and Savage <ref> [3] </ref> developed a virtual reality interface between humans and agents that allows the human to combine speech and gestures, and they report two key advantages of the combination: (1) different types of communication are simpler in one or the other mode, and (2) in cases where either mode alone would be
Reference: [4] <author> R.R. Burton. </author> <title> Diagnosing bugs in a simple procedural skill. </title> <editor> In D. Sleeman and J.S. Brown, editors, </editor> <booktitle> Intelligent Tutoring Systems, </booktitle> <pages> pages 157-183. </pages> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference-contexts: Causal links allow Steve to determine which parts of the task are still relevant to achieving the task's end goals, as just described. Previous tutoring systems based on procedural net representations (e.g., <ref> [4] </ref>, [15], and [17]), on the other hand, only represent steps and ordering constraints. Without causal links, which represent the role of steps in the task, these systems are incapable of adapting procedures to unexpected circumstances.
Reference: [5] <author> J. Cassell, C. Pelachaud, N. Badler, M. Steedman, B. Achorn, T. Becket, B. Douville, S. Prevost, and M. Stone. </author> <title> Animated conversation: Rule-based generation of facial expression, gesture and spoken intonation for multiple conversational agents. </title> <booktitle> In Proc. of ACM SIGGRAPH '94, </booktitle> <year> 1994. </year> <month> 7 </month>
Reference-contexts: He could use a nod of approval to show agreement with the student's actions, and a nod of disapproval or look of puzzlement to make the student think twice. Nonverbal feedback is also important in carrying on dialogues; for example, Cassell et al. <ref> [5] </ref> have created Jack agents that coordinate speech, intonation, facial expressions and hand gestures in conversations, albeit only with one another.
Reference: [6] <author> A. Collins, J.S. Brown, and S.E. Newman. </author> <title> Cognitive apprenticeship: Teaching the crafts of reading, writing, and mathematics. In L.B. Resnick, editor, Knowing, Learning, and Instruction: </title> <booktitle> Essays in Honor of Robert Glaser. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1989. </year>
Reference-contexts: Figure 1a shows a snapshot of the virtual HPAC and its surrounding room. Steve teaches students how to perform procedural tasks, like operating the HPAC. Our goal is to support the apprenticeship model of learning <ref> [6] </ref>. This requires two capabilities: Steve must be able to demonstrate and explain tasks, and he must be able to monitor students performing tasks, providing assistance when it is needed. All of Steve's instruction and assistance is situated in the performance of domain tasks.
Reference: [7] <author> N.I. Durlach and A.S. Mavor, </author> <title> editors. Virtual Reality: Scientific and Technological Challenges. </title> <publisher> National Academy Press, </publisher> <address> Washington, D.C., </address> <year> 1995. </year>
Reference-contexts: However, virtual reality can provide more realistic perceptual stimuli (e.g., visual, auditory, and haptic) than earlier technologies, thereby providing an adequate simulation for a wider range of situations <ref> [7] </ref>. In addition, using networked virtual reality systems, multiple students (possibly at different work sites) can learn to perform collaborative or competitive tasks together. Virtual reality also offers exciting opportunities and challenges for intelligent tutoring systems.
Reference: [8] <author> C. Geib, L. Levison, and M.B. Moore. Sodajack: </author> <title> An architecture for agents that search and manipulate objects. </title> <type> Technical Report MS-CIS-94-16/LINC LAB 265, </type> <institution> Department of Computer and Information Science, University of Pennsylvania, </institution> <year> 1994. </year>
Reference-contexts: makes it awkward to use another program to control him. (Jack was primarily designed for interactive control by a person via a graphical user interface.) However, work at 5 the University of Pennsylvania has shown the potential for using Jack to autonomously move around a virtual world and manipulate objects <ref> [8, 12] </ref>, and we believe this approach holds more promise than handcrafted animation sequences. There are many useful types of nonverbal feedback that a pedagogical agent could give to a student beyond those currently used by Steve.
Reference: [9] <author> R.W. Hill, Jr. and W.L. Johnson. </author> <title> Situated plan attribution. </title> <journal> Journal of Artificial Intelligence in Education, </journal> <volume> 6(1) </volume> <pages> 35-66, </pages> <year> 1995. </year>
Reference-contexts: Although the apprenticeship model calls for a gradual elimination of assistance as the student gains mastery, Steve currently has no such "fading." Steve does not yet maintain a student model, nor does he intervene except when asked for help. (We are currently adapting the method of impasse-driven tutoring <ref> [9] </ref> to tracking students' actions and guiding Steve's interventions.) Rather, our efforts so far have focused on Steve's ability to apply his knowledge of domain procedures to any given situation and explain his reasoning.
Reference: [10] <author> W. L. Johnson. </author> <title> Agents that learn to explain themselves. </title> <booktitle> In Proc. of Twelfth National Conf. on Artificial Intelligence (AAAI-94), </booktitle> <pages> pages 1257-1263, </pages> <address> 1994. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Steve's demonstrations are not canned; he continuously monitors the state of the virtual world and adapts his task execution accordingly, as will be discussed in the next section. When demonstrating a task, Steve maintains an episodic memory of situations in which he performs actions, using Johnson's Debrief software <ref> [10] </ref>. After the demonstration, the student can ask Steve to rationalize any of his actions. Steve recalls the situation and explains his action in terms of its relevant effect.
Reference: [11] <author> J.E. Laird, A. Newell, </author> <title> and P.S. Rosenbloom. Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1) </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: Therefore, we wanted an architecture for Steve that would allow us to evaluate the tradeoffs between different representations. To experiment with different graphical representations for Steve, we designed him as two cooperating modules. The cognitive module, implemented in Soar <ref> [11, 16] </ref> handles the normal duties of an intelligent tutoring system, and it outputs motor commands (e.g., press a button or look at an object) to a sensorimotor module [18].
Reference: [12] <author> L. Levison and N.I. Badler. </author> <title> How animated agents perform tasks: Connecting planning and manipulation through object-specific reasoning. In Toward Physical Interaction and Manipulation, </title> <booktitle> AAAI Spring Symposium Series, </booktitle> <year> 1994. </year>
Reference-contexts: makes it awkward to use another program to control him. (Jack was primarily designed for interactive control by a person via a graphical user interface.) However, work at 5 the University of Pennsylvania has shown the potential for using Jack to autonomously move around a virtual world and manipulate objects <ref> [8, 12] </ref>, and we believe this approach holds more promise than handcrafted animation sequences. There are many useful types of nonverbal feedback that a pedagogical agent could give to a student beyond those currently used by Steve.
Reference: [13] <editor> M.T. Maybury, editor. </editor> <title> Intelligent Multimedia Interfaces. </title> <publisher> AAAI Press, </publisher> <year> 1993. </year>
Reference-contexts: By controlling their own field of view, students learn to navigate around their work environment, and they can view objects from different angles. In contrast, most tutoring systems, and even multimedia presentation systems <ref> [13] </ref>, assume they can design and control the student's view. The Vista software allows Steve to control the student's field of view when necessary. However, to avoid losing the benefits of having students control their own view, we have ignored that option.
Reference: [14] <author> D. McAllester and D. Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. of Ninth National Conf. on Artificial Intelligence (AAAI-91), </booktitle> <pages> pages 634-639, </pages> <address> 1991. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Composite actions give plans a hierarchical structure. Second, there may be ordering constraints among the steps; these constraints define a partial order over the steps. Finally, the role of the steps in the plan is represented by a set of causal links <ref> [14] </ref>; each causal link specifies that one step in the plan achieves a goal that is a precondition for another step in the plan (or for termination of the task).
Reference: [15] <author> A. Munro, M.C. Johnson, D.S. Surmon, and J.L. Wogulis. </author> <title> Attribute-centered simulation authoring for instruction. </title> <booktitle> In Proc. of World Conf. on Artificial Intelligence in Education (AI-ED '93), </booktitle> <pages> pages 82-89. </pages> <booktitle> Assoc. for the Advancement of Computing in Education, </booktitle> <year> 1993. </year>
Reference-contexts: Students interact with the virtual world using a 3D mouse or data gloves. Sensors on the mouse and gloves keep track of the student's hands, and the Vista software sends out messages when the student touches virtual objects. These messages are received and handled by the RIDES software <ref> [15] </ref>, which controls the behavior of the virtual world. (The RIDES software makes it easy for course authors to create simulation behaviors.) Currently, we are applying the VET system to training Navy personnel to operate a high-pressure air compressor (HPAC) on board a ship. <p> Causal links allow Steve to determine which parts of the task are still relevant to achieving the task's end goals, as just described. Previous tutoring systems based on procedural net representations (e.g., [4], <ref> [15] </ref>, and [17]), on the other hand, only represent steps and ordering constraints. Without causal links, which represent the role of steps in the task, these systems are incapable of adapting procedures to unexpected circumstances.
Reference: [16] <author> A. Newell. </author> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press, </publisher> <year> 1990. </year>
Reference-contexts: Therefore, we wanted an architecture for Steve that would allow us to evaluate the tradeoffs between different representations. To experiment with different graphical representations for Steve, we designed him as two cooperating modules. The cognitive module, implemented in Soar <ref> [11, 16] </ref> handles the normal duties of an intelligent tutoring system, and it outputs motor commands (e.g., press a button or look at an object) to a sensorimotor module [18].
Reference: [17] <author> J. Rickel. </author> <title> An intelligent tutoring framework for task-oriented domains. </title> <booktitle> In Proc. of International Conf. on Intelligent Tutoring Systems, </booktitle> <address> Montreal, Canada, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Causal links allow Steve to determine which parts of the task are still relevant to achieving the task's end goals, as just described. Previous tutoring systems based on procedural net representations (e.g., [4], [15], and <ref> [17] </ref>), on the other hand, only represent steps and ordering constraints. Without causal links, which represent the role of steps in the task, these systems are incapable of adapting procedures to unexpected circumstances.
Reference: [18] <author> J. Rickel and W. L. Johnson. </author> <title> Integrating pedagogical capabilities in a virtual environment agent. </title> <booktitle> In Proc. of First International Conf. on Autonomous Agents, 1997. </booktitle> <publisher> ACM Press. </publisher>
Reference-contexts: The paper concludes with a brief summary of our main points and our current efforts (Section 6). For more information on Steve's architecture and his interface to the virtual world, see <ref> [18] </ref>. 2 The Learning Environment The VET system allows multiple students and agents to cohabit a virtual world. Each student's interface to the virtual world is provided by special-purpose hardware and Lockheed Martin's Vista Viewer software [21]. <p> The cognitive module, implemented in Soar [11, 16] handles the normal duties of an intelligent tutoring system, and it outputs motor commands (e.g., press a button or look at an object) to a sensorimotor module <ref> [18] </ref>. The sensorimotor module translates these motor commands into lower-level graphical commands to move Steve's body and, if necessary, commands to the simulator to affect the virtual world (e.g., simulate the button and its effects).
Reference: [19] <author> S. Russell and P. Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: For these reasons, Steve uses a procedural network (plan) representation of domain tasks. Steve's representation is not uncommon in the AI planning community <ref> [19] </ref>, although, as we will discuss, it differs in important ways from representations in other tutoring systems. First, each plan consists of a set of steps, each of which is either a primitive action (e.g., press a button) or a composite action (i.e., itself a plan).
Reference: [20] <author> E. Sacerdoti. </author> <title> A Structure for Plans and Behavior. </title> <publisher> Elsevier, </publisher> <year> 1977. </year>
Reference-contexts: Some, notably those of Anderson and his colleagues [1], use detailed cognitive models built from production rules. Such systems perform domain tasks by directly executing the rules. Other systems use a declarative representation of the knowledge, usually some variant of a procedural network representation <ref> [20] </ref> specifying the steps in the procedure and their ordering. Such systems perform tasks by using a domain-independent interpreter to "execute" the procedural network (i.e., walk through the steps). Production rule models provide a more flexible ontology at a price: they are laborious to build. <p> Moreover, he must do so quickly, since he and the student are collaborating on the task in real time. To satisfy these criteria, Steve uses a novel combination of task decomposition planning <ref> [20] </ref> and partial-order planning [23]. Given a task to demonstrate or monitor, Steve first constructs a plan for performing it, using top-down task decomposition.
Reference: [21] <author> R. Stiles, L. McCarthy, and M. Pontecorvo. </author> <title> Training studio: A virtual environment for training. In Workshop on Simulation and Interaction in Virtual Environments (SIVE-95), July 1995. </title> <publisher> ACM Press. </publisher>
Reference-contexts: Each student's interface to the virtual world is provided by special-purpose hardware and Lockheed Martin's Vista Viewer software <ref> [21] </ref>. Students get a 3D, immersive view of the world through a head-mounted display (HMD). Vista uses data from a position and orientation sensor on the HMD to update the student's view as they move around. Students interact with the virtual world using a 3D mouse or data gloves. <p> In the VET system, students wear position and orientation sensors on their head and hands. The Vista software <ref> [21] </ref> uses the sensor data to continuously update each student's field of view and the location of their virtual hands, and it makes this information available to Steve.
Reference: [22] <author> B.A. Stone and J.C. Lester. </author> <title> Dynamically sequencing an animated pedagogical agent. </title> <booktitle> In Proc. of Thirteenth National Conf. on Artificial Intelligence (AAAI-96), </booktitle> <pages> pages 424-431, </pages> <address> 1996. </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: Jack can be used two different ways. The Jack software would allow course authors to create a variety of animation sequences, and these could be dynamically strung together by Steve during task execution. This approach is used for Stone and Lester's <ref> [22] </ref> animated pedagogical agent, although they use their own character, Herman the Bug, rather than Jack. We have focused on the alternative approach: Jack can be commanded to look at, walk to, and reach out and grasp arbitrary objects.
Reference: [23] <author> D.S. Weld. </author> <title> An introduction to least commitment planning. </title> <journal> AI Mag., </journal> <volume> 15(4) </volume> <pages> 27-61, </pages> <year> 1994. </year> <month> 8 </month>
Reference-contexts: Moreover, he must do so quickly, since he and the student are collaborating on the task in real time. To satisfy these criteria, Steve uses a novel combination of task decomposition planning [20] and partial-order planning <ref> [23] </ref>. Given a task to demonstrate or monitor, Steve first constructs a plan for performing it, using top-down task decomposition.
References-found: 23

