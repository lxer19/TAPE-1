URL: ftp://cindy.di.unito.it/articles/aiia95.ps
Refering-URL: http://www.di.unito.it/pub/WWW/MLgroup/bottabib.html
Root-URL: 
Email: email: -baroglio,botta-@di.unito.it  
Title: Multiple Predicate Learning with RTL  
Author: Cristina Baroglio and Marco Botta 
Address: Corso Svizzera 185 10149 Torino ITALY  
Affiliation: Dipartimento di Informatica Universita` di Torino  
Abstract: RTL is an algorithm designed to learn any number of simple, mutually dependent relations, producing recursive programs that are stratified in the sense given by Apt. In this paper, we present a revised algorithm and its implementation based on previous theoretical works that establish properties and limits of the learning framework. The algorithm is described both in abstract form and through an example. Emphasis is put on the way RTL uses induction and domain knowledge to guide the search towards specific kinds of hypothesis. The algorithm has been tested on three different domains obtaining encouraging results, as reported in the discussion. Finally, it is shown experimentally that the control strategy realized is somewhat independent of the order in which concepts are learned.
Abstract-found: 1
Intro-found: 1
Reference: <author> K.R. Apt, H.A. Blair, and A. Walker: </author> <title> "Towards a Theory of Declarative Knowledge", in Foundations of Deductive Databases and Logic Programming, </title> <editor> J. Minker (Ed), </editor> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, 89-148, </address> <year> 1988. </year> <note> 54 C. </note> <author> Baroglio, A. Giordana, and L. Saitta: </author> <title> "Learning Mutually Dependent Relations", </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 1, </volume> <publisher> Kluwer Academic Publishers, </publisher> <pages> 159-176, </pages> <year> 1992. </year>
Reference-contexts: As a side effect, this strategy makes RTL almost independent of the initial concept ordering. RTL starts from a set F of learning instances and, taking into account that a logic program terminates only if it has an acyclic ground graph <ref> (Apt et al., 1988) </ref>, it first builds a non recursive program G, that has an isomorphic ground graph covering the whole F. Then, it transforms G into a recursive program T, that has the same ground graph on F. The construction of G is fundamentally a monotonic process without backtracking. <p> Such chains will then be generalized into recursive clauses in T. It should be noticed that recursive generalizations that need extensional checks (such as those leading to recursion through negated literals) are prevented by creating strata <ref> (Apt et al., 1988) </ref>. 3. Basic Notions and Definitions In the following we will adopt standard ILP terminology and introduce some basic definitions to allow a better understanding of RTL. Concepts are represented by a set of program clauses (a theory) expressed in a function-free FOPL augmented with negation. <p> Concepts are represented by a set of program clauses (a theory) expressed in a function-free FOPL augmented with negation. A theory, in order to be tractable by the system, must be stratified <ref> (Apt et al., 1988) </ref>. Stratification determines priority levels (strata) of a set of predicates and guarantees that a predicate is not dependent on its negation, thus generating an acyclic ground graph over the learning set. <p> The Actual Algorithm RTL repeats three main phases: (1) inducing a simply recurrent theory, (2) generalizing to a simply recursive theory, (3) generalizing a set of complete simply recursive networks to close a stratum. In doing so, RTL generates programs which are stratified in the sense given by Apt <ref> (Apt et al., 1988) </ref> avoiding the combinatorial explosion of extensional checks.
Reference: <author> M. Botta: </author> <title> "Learning First Order Theories", </title> <booktitle> Proc of the ISMIS-94, LNAI 869, Charlotte, NC, </booktitle> <pages> 356-365, </pages> <year> 1994. </year>
Reference-contexts: However, in the current version of the algorithm, powerful heuristics to guide the selection of golden points and recurrents take precedence over refinements of the theory. The induction procedure RTL uses is that of KBI <ref> (Botta, 1994) </ref>, a system that is able to learn first order clauses from theory and data.
Reference: <author> M. Botta, and A. Giordana: </author> <title> "SMART+: A Multi-Strategy Learning Tool", </title> <booktitle> Proc. of the 13th International Joint Conference on Artificial Intelligence, IJCAI-93, </booktitle> <address> Chambery, France, 937-943, </address> <year> 1993. </year>
Reference: <author> L. De Raedt: </author> <title> Interactive Theory Revision, </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: Thus, under the strong setting, the order of learning clauses may affect the results of the learning task, and sometimes even the existence of a solution (De Raedt 44 et al., 1993a). Also incremental systems, such as CIGOL (Muggleton & Buntine, 1988), CLINT <ref> (De Raedt, 1992) </ref>, MIS (Shapiro, 1983) and MOBAL (Kietz & Wrobel, 1992), present the same problem. On the other hand, some theory revision systems (e.g.
Reference: <author> L. De Raedt, and N. </author> <title> Lavrac ~ : "The Many Faces of Inductive Logic Programming", </title> <booktitle> Proc. of the 7th International Symposium on Methodologies for Intelligent Systems, </booktitle> <address> ISMIS-93, Trondheim, Norway, 435-449, </address> <year> 1993a. </year>
Reference-contexts: Thus, under the strong setting, the order of learning clauses may affect the results of the learning task, and sometimes even the existence of a solution <ref> (De Raedt 44 et al., 1993a) </ref>. Also incremental systems, such as CIGOL (Muggleton & Buntine, 1988), CLINT (De Raedt, 1992), MIS (Shapiro, 1983) and MOBAL (Kietz & Wrobel, 1992), present the same problem. On the other hand, some theory revision systems (e.g.
Reference: <author> L. De Raedt, N. Lavrac ~ , and S. Dz ~ eroski: </author> <title> "Multiple Predicate Learning", </title> <booktitle> Proc. of the 13th International Joint Conference on Artificial Intelligence, IJCAI-93, </booktitle> <address> Chambery, France, 1037-1042, </address> <year> 1993b. </year>
Reference-contexts: A different solution is that of designing specific algorithms to address a multiple predicate learning task, such as MPL <ref> (De Raedt et al., 1993b) </ref> and RTL (Baroglio et al., 1992; Giordana et al., 1993). MPL proposes a method to avoid the ordering dependence of the learning process that dynamically associates head and body of a learning clause, but, as a side effect, complexity is dramatically increased. <p> The first step builds a simply recurrent theory: this is the most critical point in RTL, since the structure of the learned theory depends on the selection of good golden points and recurrent clauses, a problem inherent to the task and not related to the method itself. MPL <ref> (De Raedt et al., 1993b) </ref> tries to solve the problem by adopting a strategy that dynamically allows to add and retract clauses until the program reaches a maximum of an assigned evaluation function.
Reference: <author> F. Esposito, D. Malerba, G. Semeraro, and M. Pazzani: </author> <title> "A Machine Learning Approach to Document Understanding", </title> <booktitle> Proc. of the 2nd Intenational Workshop on Multistrategy Learning, </booktitle> <address> Harpers Ferry, WV, 276-292, </address> <year> 1993. </year>
Reference-contexts: A solution to overcome these drawbacks is that of explicitly representing dependency information, by using dependency hierarchies and exploiting it to guide the learning process (see for instance <ref> (Esposito et al., 1993) </ref>). A different solution is that of designing specific algorithms to address a multiple predicate learning task, such as MPL (De Raedt et al., 1993b) and RTL (Baroglio et al., 1992; Giordana et al., 1993). <p> We considered a document understanding problem, in which concepts are dependent according to a predefined hierarchy (see <ref> (Esposito et al., 1993) </ref> for a complete description of the application). There are five concepts to be learned, namely sender of the letter, receiver, logotype, reference number and date, in terms of operational predicates such as height, width, position, type, relative position and relative alignment of objects in a document. <p> The test set consists of 10 documents composed of 133 objects, 12 of which are instances of concept sender, 10 are instances of receiver, 10 of logotype, 19 of reference number and 11 of date. The concept dependencies hierarchy as defined in <ref> (Esposito et al., 1993) </ref> is shown in Fig. 2. logotype sender receiver reference No. date Fig. 2 - The hierarchy of concept dependencies.
Reference: <author> A. Giordana, L. Saitta, and C. Baroglio: </author> <title> "Learning Simple Recursive Theories", </title> <booktitle> Proc. of the 7th International Symposium on Methodologies for Intelligent Systems, </booktitle> <address> ISMIS-93, Trondheim, Norway, 425-434, </address> <year> 1993. </year>
Reference-contexts: Nevertheless, in many cases, such an expensive step can be avoided if program changes are appropriately restricted and if a proper policy is followed during the induction process (see <ref> (Giordana et al., 1993) </ref> for a formal dissertation). This paper pursues three main goals: a new algorithm that solves some technical flaws and extends to a larger class of programs the abstract RTL algorithm reported in (Giordana et al., 1993) is presented; a full and sound implementation of the new algorithm <p> appropriately restricted and if a proper policy is followed during the induction process (see <ref> (Giordana et al., 1993) </ref> for a formal dissertation). This paper pursues three main goals: a new algorithm that solves some technical flaws and extends to a larger class of programs the abstract RTL algorithm reported in (Giordana et al., 1993) is presented; a full and sound implementation of the new algorithm is described; a set of experiments aimed at testing the current potentialities of the algorithm is finally discussed. 2. <p> Then, it transforms G into a recursive program T, that has the same ground graph on F. The construction of G is fundamentally a monotonic process without backtracking. Moreover, the recursive program T can be built without any extensional checks, provided that specific properties hold for G <ref> (Giordana et al., 1993) </ref>. RTL control strategy interleaves inductive steps and theory driven steps in order to facilitate the discovery of recursive structures. G is induced starting from the golden points, i.e. the base clauses of the recursive program T. <p> The recursive generalization process is sound under specific conditions as formally stated in <ref> (Giordana et al., 1993) </ref>. Definition 3.5 A simply recursive network is a set of simply recursive theories with no dependency loops 1 . <p> The simply recursive theories that belong to a complete simply recursive network are partial definitions of the concepts to be learned that can be further generalized by applying a stratification process without the need of extensional checks, as proved in <ref> (Giordana et al., 1993) </ref>. 4. The Actual Algorithm RTL repeats three main phases: (1) inducing a simply recurrent theory, (2) generalizing to a simply recursive theory, (3) generalizing a set of complete simply recursive networks to close a stratum.
Reference: <author> J.U. Kietz, and S. Wrobel: </author> <title> "Controlling the Complexity of Learning in Logic though Syntactic and Task-Oriented Models", in Inductive Logic Programming, </title> <publisher> S. </publisher>
Reference: <author> Muggleton (Ed)., Academinc Pres, </author> <year> 1992. </year>
Reference: <author> N. Lavrac ~ ~ eroski, and M. Grobelnik: </author> <title> "Learning Non Recursive Definitions of Relations with LINUS", </title> <booktitle> Proc. of the 5th European Working Session on Learning, </booktitle> <publisher> LNAI 482, Springer-Verlag, </publisher> <year> 1991. </year>
Reference: <author> R.S. Michalski: </author> <title> "A Theory and Methodology of Inductive Learning", </title> <journal> Artificial Intelligence, </journal> <volume> 20, </volume> <pages> 111-161, </pages> <year> 1983. </year>
Reference-contexts: Moreover, this criterion has been extended to account also for simplicity. A simplicity criterion has been used more or less explicitly in many inductive systems starting from INDUCE <ref> (Michalski, 1983) </ref>. Here, it is particularly relevant to privilege the discovery of recursive structures. In fact, being every model in F finite, it is always possible to find a non recursive theory covering all the training events if no limit is put on the complexity of the clauses.
Reference: <author> S. Muggleton, and W. Buntine: </author> <title> "Machine Invention of First-order Predicates by Inverting Resolution", </title> <booktitle> Proc. of the 5th International Conference on Machine Learning, </booktitle> <address> Ann Arbor, MI, 339-352, </address> <year> 1988. </year>
Reference-contexts: Thus, under the strong setting, the order of learning clauses may affect the results of the learning task, and sometimes even the existence of a solution (De Raedt 44 et al., 1993a). Also incremental systems, such as CIGOL <ref> (Muggleton & Buntine, 1988) </ref>, CLINT (De Raedt, 1992), MIS (Shapiro, 1983) and MOBAL (Kietz & Wrobel, 1992), present the same problem. On the other hand, some theory revision systems (e.g.
Reference: <author> S. Muggleton, and C. Feng: </author> <title> "Efficient Induction of Logic Programs", </title> <booktitle> Proc. of the 1st Conference on Algorithmic Learning Theory, </booktitle> <publisher> Ohmsha, </publisher> <address> Tokio, Japn, </address> <year> 1990. </year>
Reference-contexts: Complexity grows combinatorially when more than one concept has to be learned. Furthermore, the classical ILP approaches (strong and weak setting, as classified by De Raedt et al. (1993a)), have other limitations. For instance, many classical ILP systems (such as FOIL (Quinlan, 1990), GOLEM <ref> (Muggleton & Feng, 1990) </ref> and LINUS (Lavrac ~ et al., 1991)) are not designed to learn more than one concept at a time.
Reference: <author> R. Quinlan: </author> <title> "Learning Logical Definitions from Relations", </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: Complexity grows combinatorially when more than one concept has to be learned. Furthermore, the classical ILP approaches (strong and weak setting, as classified by De Raedt et al. (1993a)), have other limitations. For instance, many classical ILP systems (such as FOIL <ref> (Quinlan, 1990) </ref>, GOLEM (Muggleton & Feng, 1990) and LINUS (Lavrac ~ et al., 1991)) are not designed to learn more than one concept at a time.
Reference: <author> B.L. Richards, and R.J. Mooney: </author> <title> "First Order Theory Revision", </title> <booktitle> Proc. of the 8th International Workshop on Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <pages> 447-451, </pages> <year> 1991. </year>
Reference-contexts: Also incremental systems, such as CIGOL (Muggleton & Buntine, 1988), CLINT (De Raedt, 1992), MIS (Shapiro, 1983) and MOBAL (Kietz & Wrobel, 1992), present the same problem. On the other hand, some theory revision systems (e.g. FORTE <ref> (Richards & Mooney, 1991) </ref> and AUDREY (Wogulis, 1991)) can learn multiple concepts, though different orderings of the learning examples lead to different results, and some of them (e.g., AUDREY) cannot handle recursion.
Reference: <author> H. Shapiro: </author> <title> Algorithmic Program Debugging, </title> <publisher> MIT Press, </publisher> <year> 1983. </year>
Reference-contexts: Thus, under the strong setting, the order of learning clauses may affect the results of the learning task, and sometimes even the existence of a solution (De Raedt 44 et al., 1993a). Also incremental systems, such as CIGOL (Muggleton & Buntine, 1988), CLINT (De Raedt, 1992), MIS <ref> (Shapiro, 1983) </ref> and MOBAL (Kietz & Wrobel, 1992), present the same problem. On the other hand, some theory revision systems (e.g.
Reference: <author> J. Wogulis: </author> <title> "Revising Relational Theories", </title> <booktitle> Proc. of the 8th International Workshop on Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <pages> 462-466, </pages> <year> 1991. </year> <month> 55 </month>
Reference-contexts: Also incremental systems, such as CIGOL (Muggleton & Buntine, 1988), CLINT (De Raedt, 1992), MIS (Shapiro, 1983) and MOBAL (Kietz & Wrobel, 1992), present the same problem. On the other hand, some theory revision systems (e.g. FORTE (Richards & Mooney, 1991) and AUDREY <ref> (Wogulis, 1991) </ref>) can learn multiple concepts, though different orderings of the learning examples lead to different results, and some of them (e.g., AUDREY) cannot handle recursion.
References-found: 18

