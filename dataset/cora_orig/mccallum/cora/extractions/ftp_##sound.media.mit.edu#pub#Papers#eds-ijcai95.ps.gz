URL: ftp://sound.media.mit.edu/pub/Papers/eds-ijcai95.ps.gz
Refering-URL: http://sound.media.mit.edu/papers.html
Root-URL: http://www.media.mit.edu
Email: email: eds@media.mit.edu  
Title: Using Musical Knowledge to Extract Expressive Performance Information from Audio Recordings  
Author: Eric D. Scheirer 
Date: December 14, 1995  
Address: E15-401C Cambridge, MA 02140  
Affiliation: MIT Media Laboratory  
Abstract: A computer system is described which performs polyphonic transcription of known solo piano music by using high-level musical information to guide a signal-processing system. This process, which we term expressive performance extraction, maps a digital audio representation of a musical performance to a MIDI representation of the same performance using the score of the music as a guide. Analysis of the accuracy of the system is presented, and its usefulness both as a tool for music-psychology researchers and as an example of a musical-knowledge-based signal-processing system is discussed.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jeff Bilmes. </author> <title> Timing is of the essence: Perceptual and computational techniques for representing, learning, and reproducing expressive timing in percussive rhythm. </title> <type> Master's thesis, </type> <institution> MIT Media Laboratory, </institution> <year> 1993. </year>
Reference-contexts: We can similarly recreate other sorts of analyses such as those found in [8] or <ref> [1] </ref> by treating 10 the timing variables as random Gaussian variables rather than known values. 2 Depending on which question we want to answer, though, the answers may be less satisfactory for small timing details.
Reference: [2] <author> Stephen Handel. </author> <title> Listening. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference: [3] <author> Carol Krumhansl. </author> <title> Cognitive Foundations of Musical Pitch. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1991. </year>
Reference: [4] <author> Fred Lerdahl and Ray Jackendoff. </author> <title> A Generative Theory of Tonal Music. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference: [5] <author> Eugene Narmour. </author> <title> The Analysis and Cognition of Basic Melodic Structures. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1990. </year> <month> 16 </month>
Reference: [6] <author> Eugene Narmour. </author> <title> The Analysis and Cognition of Melodic Complexity. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1993. </year>
Reference-contexts: It is clear that the human music-cognition system is working with representations of music on many different levels which guide and shape the perception of a particular musical performance. Work such as Krumhansl's tonal hierarchy ([3]) and Narmour's multi-layered grouping rules ([5], <ref> [6] </ref>) show evidence for certain low- and mid-level cognitive representations for musical structure; and syntactic work such as Lerdahl and Jackendoffs' ([4]), while not as well-grounded experimentally, suggests a possible structure for higher levels of music cognition.
Reference: [7] <author> Alan Oppenheim and S. Hamid Nawab. </author> <title> Symbolic and Knowledge-Based Signal Processing. </title> <publisher> Prentice-Hall, Inc, </publisher> <year> 1992. </year>
Reference-contexts: Certainly, the artificial intelligence component, for understanding and making predictions about the musical signal, would be enormously complex in such a system. Work is currently in progress on a blackboard system architecture (see, eg, <ref> [7] </ref>) for investigation of these issues.
Reference: [8] <author> Caroline Palmer. </author> <title> Timing in Skilled Music Performance. </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <year> 1989. </year>
Reference-contexts: However, the system also stands as a example of a new general approach to the polyphonic transcription problem. The parameters extracted are those which are controllable by the pianist: velocity (the force of the stroke), and attack and release timing. <ref> [8] </ref> suggests certain levels of timing accuracy in performance which can be understood as benchmarks for a system which is to extract note information accurately enough to allow the study of musical interpretation. <p> We can similarly recreate other sorts of analyses such as those found in <ref> [8] </ref> or [1] by treating 10 the timing variables as random Gaussian variables rather than known values. 2 Depending on which question we want to answer, though, the answers may be less satisfactory for small timing details.
Reference: [9] <author> Athanasios Papoulis. </author> <title> Probability, Random Variables, and Stochastic Processes. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, third edition, </address> <year> 1991. </year>
Reference-contexts: these in turn, and then discuss ways in which the current system could be improved. 4.1 Stochastic Analysis of Music Performance Part of the value of the sort of variance-of-error study conducted in the Results section is that we can treat extracted data as a stochastic estimator (cf, for example, <ref> [9] </ref>) for the actual performance, and make firm enough assumptions about the distribution of the estimation that we can obtain usable results. It is clear that some aspects of expressive music performance can be readily analyzed within the constraints of the variance in extraction discussed above.
Reference: [10] <author> Barry Vercoe. </author> <title> The synthetic performer in the context of live performance. </title> <booktitle> In Proc. Int. Computer Music Conf., </booktitle> <year> 1984. </year> <month> 17 </month>
Reference-contexts: This method is adequate for following the performance of the pieces used in the validation experiment. There are, of course, many other techniques for robust performance-following in the literature - <ref> [10] </ref>, for example. 4 3 Validation Experiment To analyze the accuracy of the timing and velocity information extracted by the system, a validation experiment was conducted using a Yamaha Disclavier MIDI-recording piano. <p> It is anticipated that any of these situations could be dealt with in the current architecture, although the tempo-follower would have to be made more robust in order to handle performance which are not well-modeled by linear tempo segments. This is generally a solvable problem, though see <ref> [10] </ref> for an example. 12 A larger issue regarding the problem of general polyphonic transcription is the goal and motivations underlying them. Why is there so much interest in building transcription systems? We submit that it is for several reasons.
References-found: 10

