URL: ftp://ftp.cs.wisc.edu/sohi/papers/1998/hpca.svc.ps.gz
Refering-URL: http://www.cs.wisc.edu/~sohi/sohi.html
Root-URL: 
Email: gsri@cs.wisc.edu vijay@ecn.purdue.edu jes@ece.wisc.edu sohi@cs.wisc.edu  
Title: Speculative Versioning Cache  
Author: Sridhar Gopal T.N.Vijaykumar James E. Smith Gurindar S. Sohi 
Affiliation: Computer Sciences School of Electrical and Department of Electrical Department Computer Engineering and Computer Engineering University of Wisconsin Purdue University University of Wisconsin  
Abstract: Dependences among loads and stores whose addresses are unknown hinder the extraction of instruction level parallelism during the execution of a sequential program. Such ambiguous memory dependences can be overcome by memory dependence speculation which enables a load or store to be speculatively executed before the addresses of all preceding loads and stores are known. Furthermore, multiple speculative stores to a memory location create multiple speculative versions of the location. Program order among the speculative versions must be tracked to maintain sequential semantics. A previously proposed approach, the Address Resolution Buffer(ARB) uses a centralized buffer to support speculative versions. Our proposal, called the Speculative Versioning Cache(SVC), uses distributed caches to eliminate the latency and bandwidth problems of the ARB. The SVC conceptually unifies cache coherence and speculative versioning by using an organization similar to snooping bus-based coherent caches. A preliminary evaluation for the Multiscalar architecture shows that hit latency is an important factor affecting performance, and private cache solutions trade-off hit rate for hit latency. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> IEEE Standard for Scalable Coherent Interface (SCI) 1596-1992. </institution> <note> IEEE 1993. </note>
Reference-contexts: This ordered set or list, called the Version Ordering List (VOL), can be implemented in several different ways the SVC, proposed in this paper, uses explicit pointers in each line to implement it as a linked list (like in SCI <ref> [1] </ref>). The following sections elaborate on a design that uses pointers in each cache line to maintain the VOL.
Reference: [2] <author> S. E. Breach, T. Vijaykumar, S. Gopal, J. E. Smith, and G. S. Sohi. </author> <title> Data memory alternatives for multiscalar processors. </title> <type> Technical Report CS TR-1344, </type> <institution> University of Wis-consin, Madison, </institution> <month> Nov. </month> <year> 1996. </year>
Reference-contexts: Such write backs generate bursty traffic and can increase the time to commit a task, which delays the issue of new task to that processor and lowers the overall performance. We propose a new solution for speculative versioning called the Speculative Versioning Cache <ref> [2, 5] </ref> (SVC), for hierarchical execution models. The SVC comprises a private cache for each processor, and the system is organized similar to a snooping bus-based cache coherent Symmetric Multiprocessor (SMP). Memory references that hit in the private cache do not use the bus as in an SMP.
Reference: [3] <author> M. Franklin and G. S. Sohi. ARB: </author> <title> A hardware mechanism for dynamic reordering of memory references. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 45(5):552571, </volume> <month> May </month> <year> 1996. </year>
Reference-contexts: It is more challenging to support speculative versioning for this execution model than a superscalar execution model because a processor executes loads and stores without knowing those executed by other processors. The Address Resolution Buffer <ref> [3] </ref> (ARB) provides speculative versioning support for such hierarchical execution models. Each entry in the ARB buffers all versions of the same memory location. However, there are two significant performance limitations of the ARB: 1. <p> A block diagram of the Version Control Logic is shown in Figure 5. For the base design, the VCL responses are similar to that of the dis 5 To appear in the Fourth International Symposium on High-Performance Computer Architecture. ambiguation logic in the ARB <ref> [3] </ref>. The disambiguation logic searches for previous or succeeding stages in a line to execute a load or store, respectively. 3.2.1. Loads Loads are handled in the same way as in an SMP except that the L bit is set if the line was initially invalid.
Reference: [4] <author> J. R. Goodman. </author> <title> Using cache memory to reduce processor-memory traffic. </title> <booktitle> In Proceedings of the 10th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 124 131, </pages> <year> 1983. </year>
Reference-contexts: Store Communicate store to later tasks; later tasks look for memory dependence violations. Commit Write back buffered versions created by the task to main memory. Squash Invalidate buffered versions created by the task. Table 1: Versioning: events and actions. SMPs typically use snooping <ref> [4] </ref> to implement a Multiple Reader/Single Writer protocol, which uses a coherence directory that is a collection of sets, each of which tracks the sharers of a line.
Reference: [5] <author> S. Gopal, T.N.Vijaykumar, J. E. Smith, and G. S. Sohi. </author> <title> Speculative Versioning Cache. </title> <type> Technical Report CS TR-1334, </type> <institution> University of Wisconsin, Madison, </institution> <month> July </month> <year> 1997. </year>
Reference-contexts: Such write backs generate bursty traffic and can increase the time to commit a task, which delays the issue of new task to that processor and lowers the overall performance. We propose a new solution for speculative versioning called the Speculative Versioning Cache <ref> [2, 5] </ref> (SVC), for hierarchical execution models. The SVC comprises a private cache for each processor, and the system is organized similar to a snooping bus-based cache coherent Symmetric Multiprocessor (SMP). Memory references that hit in the private cache do not use the bus as in an SMP.
Reference: [6] <author> D. Lilja, D. Marcovitz, and P.-C. Yew. </author> <title> Memory reference behavior and cache performance in a shared memory multiprocessor. </title> <type> Technical Report 836, </type> <institution> CSRD, University of Illi-nois, Urbana-Champaign, </institution> <month> Dec. </month> <year> 1988. </year>
Reference-contexts: Task squashes are as simple as in the base design, but are more efficient as they retain non-speculative data in the caches across task squashes. 2. The second advanced design (section 3.6) boosts the hit-rate of the ECS design by allowing requests to snarf <ref> [6] </ref> the bus to account for reference spreading. Snarfing involves copying the data supplied on a bus request issued by another processor in an attempt to combine bus re quests indirectly. 3. <p> This phenomenon is also observed for parallel programs where the miss rate for read-only shared data with private caches is higher than that with a shared cache. We use snarfing <ref> [6] </ref> to mitigate this problem. Our SVC implementation snarfs data on the bus if the corresponding cache set has a free line available. However, an active task's cache can only snarf the version that the task can use unlike an SMP coherent cache. <p> The distribution of storage for the SVC produces higher miss rates than for the ARB. We attribute the increase in miss rates for the SVC to two factors. First, distributing the available storage results in reference spreading <ref> [6] </ref> and replication of data reduces available storage. Second, a latest version of a line that caches fine-grain shared data between Multiscalar tasks constantly moves from one L1 cache to another (migratory data). Such fine-grain communication may increase the number of total misses as well. 5.
Reference: [7] <author> J. S. Liptay. </author> <title> Structural aspects of the system/360 model 85 part II: The cache. </title> <journal> IBM Systems Journal, </journal> <volume> 7(1):1521, </volume> <year> 1968. </year>
Reference-contexts: We mitigate the effects of false sharing by using a technique similar to the sector cache <ref> [7] </ref>. Each line is divided into sub-blocks and the L and S bits are maintained for each sub-block.
Reference: [8] <author> A. Moshovos, S. E. Breach, T. N. Vijaykumar, and G. S. Sohi. </author> <title> Dynamic speculation and synchronization of data dependences. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <month> June 24, </month> <year> 1997. </year>
Reference-contexts: More aggressive uniprocessor implementations issue load instructions as soon as their addresses are known, even if the addresses of all previous stores may not be known. These implementations employ memory dependence speculation <ref> [8] </ref> and predict that a load does not depend on previous stores. Furthermore, one can also envision issuing and computing store addresses out of order. Such memory dependence speculation enables higher levels of ILP, but more advanced mechanisms are needed to support this speculation.
Reference: [9] <author> K. Olukotun, B. A. Nayfeh, L. Hammond, K. Wilson, and K.-Y. Chang. </author> <title> The case for a single-chip multiprocessor. </title> <booktitle> In Proceedings of the 7th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 211, </pages> <month> October 15, </month> <year> 1996. </year>
Reference-contexts: Higher level instruction 1 To appear in the Fourth International Symposium on High-Performance Computer Architecture. control units distribute the tasks to the processors for execution and, the processors execute the instructions within each task leading to a hierarchical execution model. Proposed next generation multiprocessors <ref> [9, 12] </ref> that provide hardware support for dependence speculation also use such execution models. A hierarchical execution model naturally leads to memory address streams with a similar hierarchical structure. <p> The following sections elaborate on a design that uses pointers in each cache line to maintain the VOL. The private cache organization of the SVC makes it a feasible memory system for proposed next generation single chip multiprocessors that execute sequential programs on tightly coupled processors using automatic par-allelization <ref> [9, 12] </ref>. Previously, ambiguous memory dependences limited the range of programs chosen for automatic parallelization. The SVC provides hardware support to overcome ambiguous memory dependences and enables more aggressive automatic parallelization of sequential programs. 3.
Reference: [10] <author> J. E. Smith and S. Vajapeyam. </author> <title> Trace processors: Moving to fourth-generation microarchitectures. </title> <journal> Computer, </journal> <volume> 30(9):68 74, </volume> <month> Sept. </month> <year> 1997. </year>
Reference-contexts: The presence of such queues provides support for a simple form of speculative versioning. However, proposed next generation processor designs use replicated processing units that dispatch and/or issue instructions in a distributed manner. These future approaches partition the instruction stream into sub streams called tasks [11] or traces <ref> [10] </ref>. Higher level instruction 1 To appear in the Fourth International Symposium on High-Performance Computer Architecture. control units distribute the tasks to the processors for execution and, the processors execute the instructions within each task leading to a hierarchical execution model.
Reference: [11] <author> G. S. Sohi, S. E. Breach, and T. N. Vijaykumar. </author> <title> Multiscalar processors. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 414425, </pages> <month> June 2224, </month> <year> 1995. </year>
Reference-contexts: The presence of such queues provides support for a simple form of speculative versioning. However, proposed next generation processor designs use replicated processing units that dispatch and/or issue instructions in a distributed manner. These future approaches partition the instruction stream into sub streams called tasks <ref> [11] </ref> or traces [10]. Higher level instruction 1 To appear in the Fourth International Symposium on High-Performance Computer Architecture. control units distribute the tasks to the processors for execution and, the processors execute the instructions within each task leading to a hierarchical execution model. <p> A higher level control unit predicts the next task in the sequence and assigns it for execution to a free processor. Each processor executes the instructions in the task assigned to it and buffers the speculative state created by the task. The Wisconsin Mul-tiscalar <ref> [11] </ref> is an example architecture that uses the hierarchical execution model. When a task misprediction is detected, the speculative state of all the tasks in the sequence including and after the incorrectly predicted task are invalidated 1 and the corresponding processors are freed. This is called a task squash.
Reference: [12] <author> J. G. Steffan and T. C. Mowry. </author> <title> The potential for thread-level data speculation in tightly-coupled multiprocessors. </title> <type> Technical Report CSRI-TR-350, </type> <institution> Computer Systems Research Institute, University of Toronto, </institution> <month> Feb. </month> <year> 1997. </year> <month> 11 </month>
Reference-contexts: Higher level instruction 1 To appear in the Fourth International Symposium on High-Performance Computer Architecture. control units distribute the tasks to the processors for execution and, the processors execute the instructions within each task leading to a hierarchical execution model. Proposed next generation multiprocessors <ref> [9, 12] </ref> that provide hardware support for dependence speculation also use such execution models. A hierarchical execution model naturally leads to memory address streams with a similar hierarchical structure. <p> The following sections elaborate on a design that uses pointers in each cache line to maintain the VOL. The private cache organization of the SVC makes it a feasible memory system for proposed next generation single chip multiprocessors that execute sequential programs on tightly coupled processors using automatic par-allelization <ref> [9, 12] </ref>. Previously, ambiguous memory dependences limited the range of programs chosen for automatic parallelization. The SVC provides hardware support to overcome ambiguous memory dependences and enables more aggressive automatic parallelization of sequential programs. 3.
References-found: 12

