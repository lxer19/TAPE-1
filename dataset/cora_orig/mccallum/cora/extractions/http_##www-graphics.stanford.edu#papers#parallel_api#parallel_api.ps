URL: http://www-graphics.stanford.edu/papers/parallel_api/parallel_api.ps
Refering-URL: http://www-graphics.stanford.edu/papers/parallel_api/
Root-URL: http://www.cs.stanford.edu
Title: The Design of a Parallel Graphics Interface  
Author: Homan Igehy Gordon Stoll Pat Hanrahan 
Keyword: CR Categories and Subject Descriptors: C.0 [Computer Systems Organization]: Hardware/Software Interfaces; D.1.3 [Programming Techniques]: Concurrent Programming; I.3.1 [Computer Graphics]: Hardware Architecture.  
Affiliation: Computer Science Department Stanford University  
Abstract: It has become increasingly difficult to drive a modern high-performance graphics accelerator at full speed with a serial immediate-mode graphics interface. To resolve this problem, retained-mode constructs have been integrated into graphics interfaces. While retained-mode constructs provide a good solution in many cases, at times they provide an undesirable interface model for the application programmer, and in some cases they do not solve the performance problem. In order to resolve some of these cases, we present a parallel graphics interface that may be used in conjunction with the existing API as a new paradigm for high-performance graphics applications. The parallel API extends existing ideas found in OpenGL and X11 that allow multiple graphics contexts to simultaneously draw into the same image. Through the introduction of synchronization primitives, the parallel API allows parallel traversal of an explicitly ordered scene. We give code examples which demonstrate how the API can be used to expose parallelism while retaining many of the desirable features of serial immediate-mode programming. The viability of the API is demonstrated by the performance of our implementation which achieves scalable performance on a 24 processor system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Amarasinghe, J. Anderson, C. Wilson, S. Liao, B. Murphy, R. French, M. Lam, and M. Hall. </author> <title> Multiprocessors from a Software Perspective. </title> <journal> IEEE Micro, </journal> <volume> 16:3, </volume> <pages> pages 52-61, </pages> <year> 1996. </year>
Reference-contexts: A second novel use of the parallel API is to write a compiler that can automatically parallelize the graphics calls of a serial graphics application. Recent advances in compiler tec hnology allow automatic parallelization of regular serial applications <ref> [1] </ref>, and extending this work to encompass graphics applications would be an interesting research direction. Another significant step in validating the parallel API is implementing an architecture with hardware acceleration.
Reference: [2] <author> A. Beers, M. Agrawala, and N. Chaddha. </author> <title> Rendering from Compressed Textures. </title> <booktitle> Computer Graphics (SIGGRAPH 96 Proceedings), </booktitle> <volume> volume 30, </volume> <pages> pages 373-378, </pages> <year> 1996. </year>
Reference-contexts: One system compresses the geometric data sent through the API [6]; other systems compress the texture data <ref> [2, 25] </ref>. All compression schemes increase the decoding costs, and systems which compress the data interactively increase the encoding costs.
Reference: [3] <author> J. </author> <title> Blinn. Me and My (Fake) Shadow. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 8:1, </volume> <pages> pages 82-86, </pages> <year> 1988. </year>
Reference-contexts: In a strictly ordered interface, primitives must be drawn in the order in which they are specified. This behavior is essential for many algorithms such as the placement of gr ound-plane shadows <ref> [3] </ref> and transparency through alpha-compositing [21]. Sometimes, however, a programmer may not care whether or not primitives are drawn in the order specified. For example, depth buffering alleviates the need for drawing a scene of opaque 3D primitives in any particular order.
Reference: [4] <author> M. Cox, N. Bhandari, and M. Shantz. </author> <title> MultiLevel Texture Caching for 3D Graphics Hardware. </title> <booktitle> Proceedings of the 25 th International Symposium on Computer Architecture, </booktitle> <year> 1998. </year>
Reference-contexts: Since hardware systems have a limited amount of local texture memory, applications issue primitives in an order which exploits texture locality. The parallel API can reduce this locality since the rasterizers can interleave the rendering of several command streams. In architectures which use implicit caching <ref> [4, 10] </ref>, the effectiveness of the cache can possibly be reduced. In architectures which utilize local texture memory as an explicit cache, texture management is complicated.
Reference: [5] <author> T. Crockett. </author> <title> Design Considerations for Parallel Graphics Libraries. </title> <booktitle> Proceedings of the Intel Supercomputer Users Group 1994 , 1994. </booktitle>
Reference-contexts: And finally, the new API should extend the current framework of graphics architectures to provide a rich set of implementation choices. 3 RELATED WORK In the field of parallel graphics interfaces, Crockett intr oduced the Parallel Graphics Library (PGL) for use in visualizing 3D graphics data produced by message-passing supercomputers <ref> [5] </ref>. Due to the characteristics of its target architecture and target applications, PGL was designed as a retained-mode interface. In parallel, each processor adds objects to a scene by passing pointers to graphics data residing in system memory.
Reference: [6] <author> M. Deering. </author> <title> Geometry Compression. </title> <booktitle> Computer Graphics (SIGGRAPH 95 Proceedings), </booktitle> <volume> volume 29, </volume> <pages> pages 13-20, </pages> <year> 1995. </year>
Reference-contexts: One system compresses the geometric data sent through the API <ref> [6] </ref>; other systems compress the texture data [2, 25]. All compression schemes increase the decoding costs, and systems which compress the data interactively increase the encoding costs.
Reference: [7] <author> E. Dijkstra. </author> <title> Cooperating Sequential Processes. </title> <booktitle> Programming Languages, </booktitle> <pages> pages 43-112, </pages> <year> 1968. </year>
Reference-contexts: Borrowing from the field of concurrent programming, we find that semaphores provide an elegant solution for many problems <ref> [7] </ref>. Among them is a mechanism for signal-and-wait semantics between multiple streams. The specification of the barrier and semaphore commands can be found in Figure 1. As with texture data and display lists, the data associated with barriers and semaphores should be sharable between contexts.
Reference: [8] <author> J. Eyles, S. Molnar, J. Poulton, T. Greer, A. Lastra, N. England, and L. Westover. PixelFlow: </author> <title> The Realization. </title> <booktitle> Proceedings of the 1997 SIGGRAPH/Eurographics Workshop on Graphics Hardware, </booktitle> <pages> pages 57-68, </pages> <year> 1997. </year>
Reference-contexts: In parallel, each processor adds objects to a scene by passing pointers to graphics data residing in system memory. A separate command is used to render the objects into a framebuffer, and no ordering constraints are imposed by the interface. PixelFlow <ref> [8, 18] </ref> is another system designed to support multiple simultaneous inputs from a parallel host machine, and PixelFlow OpenGL includes extensions for this purpose. However, due to the underlying image composition architecture, PixelFlow OpenGL also imposes frame semantics and does not support ordering. <p> Though this task is by no means easy, we believe that such a system is feasible with the techniques described in Section 7.2. The parallel API can also be implemented by a variety of other, more exotic architectures. Image composition architectures such as PixelFlow <ref> [8, 18] </ref> are one class of rendering architectures that have not been addressed by the parallel API.
Reference: [9] <author> J. Gettys and P. Karlton. </author> <title> The X Window System, Version 11. </title> <journal> SoftwarePractice and Experience, </journal> <volume> 20:S2, </volume> <pages> pages 35-67, </pages> <year> 1990. </year>
Reference-contexts: However, due to the underlying image composition architecture, PixelFlow OpenGL also imposes frame semantics and does not support ordering. B ecause of these constraints, PGL and PixelFlow OpenGL do not meet the requirements of many graphics applications. The X11 window system provides a parallel 2D graphics interface <ref> [9, 23] </ref>. A client with the proper permissions may open a connection to an X server and ask for X resources to be allocated. Among these resources are drawables (which are on or off-screen framebuffers) and X contexts (which hold graphics state).
Reference: [10] <author> Z. Hakura and A. Gupta. </author> <title> The Design and Analysis of a Cache Architecture for Texture Mapping. </title> <booktitle> Proceedings of the 24 th International Symposium on Computer Architecture, </booktitle> <year> 1997. </year>
Reference-contexts: Since hardware systems have a limited amount of local texture memory, applications issue primitives in an order which exploits texture locality. The parallel API can reduce this locality since the rasterizers can interleave the rendering of several command streams. In architectures which use implicit caching <ref> [4, 10] </ref>, the effectiveness of the cache can possibly be reduced. In architectures which utilize local texture memory as an explicit cache, texture management is complicated.
Reference: [11] <author> H. Hoppe. </author> <title> View-Dependent Refinement of Progressive Meshes. </title> <booktitle> Computer Graphics (SIGGRAPH 97 Proceedings), </booktitle> <volume> volume 31, </volume> <pages> pages 189-198, </pages> <year> 1997. </year>
Reference-contexts: Display lists provide an excellent solution for performance bottlenecks if the same objects are drawn from frame to frame. But on applications that recompute the graphics data on every frame (e.g., <ref> [11, 24] </ref>), display lists are not useful. <p> Many graphics algorithms exist that need an immediate-mode interface but are limited by application computation speed (e.g., <ref> [11, 24] </ref>), and parallelizing them can help greatly. There are two other uses of the parallel API which are of special interest. Scene graph libraries such as Performer [22] are parallel applications which traverse, cull, and issue scenes on multiple processors.
Reference: [12] <author> M. Kilgard. </author> <title> OpenGL Programming for the X Window System, </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: In the interest of efficiency, both display lists and packed primitive arrays are supported. Furthermore, both texture data and display lists may be shared between contexts in order to allow the efficient sharing of hardware resources amongst related contexts <ref> [12] </ref>. Strict ordering semantics are enforced in X and OpenGL: from the point of view of the API, every command appears to be executed once the API call returns. However, in the interest of efficiency, both interfaces allow implementations to indefinitely buffer commands.
Reference: [13] <author> D. Kirkland. </author> <type> Personal Communication. </type> <institution> Intergraph Corp., </institution> <year> 1998. </year>
Reference-contexts: Though context switches are typically inexpensive enough to allow multiple windows, they are expensive enough to discourage fine-grained sharing of the graphics hardware between application threads. A few architectures actually provide hardware support for multiple simultaneous contexts drawing into the same framebuffer <ref> [13, 26] </ref>, but all commands must go through a single graphics port. <p> the example scene may be drawn using the wait command: Thread1 Thread2 DrawPrimitives (opaq [1..256]) DrawPrimitives (opaq [257..512]) appBarrier (appBarrierVar) appBarrier (appBarrierVar) glpWaitContext (Thread2Ctx) DrawPrimitives (tran [1..256]) appBarrier (appBarrierVar) appBarrier (appBarrierVar) glpWaitContext (Thread1Ctx) DrawPrimitives (tran [257..512]) Intergraph uses a different mechanism to provide the same effect as the wait call <ref> [13] </ref>. Due to the underlying implementation of the single graphics port, returning from a flush call guarantees that all of a contexts primitives will be drawn before any subsequent primitives from any other context. <p> Hardware implementations which allow for multiple simultaneous contexts have already been demonstrated <ref> [13, 26] </ref>. In Argus, multiple simultaneous contexts are handled efficiently by taking advantage of state coherence in the state management algorithm through the use of shared memory and processor caching. One type of state which requires special attention is texture.
Reference: [14] <author> L. Lamport. </author> <title> How to Make a Multiprocessor Computer that Correctly Executes Multiprocess Programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 28:9, </volume> <pages> pages 241-248, </pages> <year> 1979. </year>
Reference-contexts: Supporting multiple contexts that share a framebuffer means that the system must provide a consistency model. We borrow the notion of sequential consistency from the field of computer architecture <ref> [14] </ref>. Imagine a system consisting of multiple processes simultaneously performing atomic operations. A sequentially consistent system computes a result that is realizable by some serial interleaving of these atomic operations.
Reference: [15] <author> J. Laudon and D. Lenoski. </author> <title> The SGI Origin: A ccNUMA Highly Scalable Server. </title> <booktitle> Proceedings of the 24 th Annual Symposium on Computer Architecture, </booktitle> <year> 1997. </year>
Reference-contexts: Although Argus can run on many architectures, particular care was taken to optimize the library for the Silicon Graphics Origin system <ref> [15] </ref>. The Origin is composed of 195 MHz R10000 processors interconnected in a scalable NUMA architecture. Depending on the rendering parameters, the single processor version of Argus is able to render up to 200K triangles per second; this rendering rate scales up to 24 processors.
Reference: [16] <author> W. Lorensen and H. Cline. </author> <title> Marching Cubes: A High-Resolution 3D Surface Reconstruction Algorithm. </title> <booktitle> Computer Graphics (SIGGRAPH 87 Proceedings), </booktitle> <volume> volume 21, </volume> <pages> pages 163-169, </pages> <year> 1987. </year>
Reference-contexts: However, in conjunction with the graphics barrier, the finish guarantees that the commands of the slaves are also completed. 5.2 Marching Cubes As a more demanding example, we consider the marching cubes algorithm <ref> [16] </ref>. Marching cubes is used to extract the polygonal approximation of an isosurface of a function which is sampled on a 3D grid. The grid is divided into a set of cells, and each cell is composed of one or more voxels. <p> Our second application, March, is a parallel implementation of the marching cubes algorithm <ref> [16] </ref>. By extracting the isosurface on every frame, the application may choose the desired isosurf aces interactively. Rendering is performed in back-to-front order to allow transparency effects by issuing graphics semaphores which enforce the dependencies described in Section 5.2.
Reference: [17] <author> S. Molnar, M. Cox, D. Ellsworth, and H. Fuchs. </author> <title> A Sorting Classification of Parallel Rendering. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 14:4, </volume> <pages> pages 23-32, </pages> <year> 1994. </year>
Reference-contexts: A geometry thread transforms and shades the primitives encoded in the graphics instruction stream. A rasterization thread is responsible for drawing these transformed primitives into the framebuffer. The version of Argus that implements the serial API is a sort-middle tiled parallel graphics system <ref> [17] </ref>. Graphics commands from a single application thread fill a global command queue which is drained by many geometry threads. The number of geometry threads is scalable since the data in this global command queue can be read in parallel. <p> One possible architecture consists of implementing the parallel API on a cluster of interconnected PCs with rasterization hardware. Another possibility is to extend the basic sort-middle interleaved architecture <ref> [17] </ref> of a high-end system such as the SGI InfiniteRe-ality [19]. Though this task is by no means easy, we believe that such a system is feasible with the techniques described in Section 7.2. The parallel API can also be implemented by a variety of other, more exotic architectures.
Reference: [18] <author> S. Molnar, J. Eyles, and J. Poulton. PixelFlow: </author> <title> HighSpeed Rendering Using Image Composition. </title> <booktitle> Computer Graphics (SIGGRAPH 92 Proceedings), </booktitle> <volume> volume 26, </volume> <pages> pages 231-240, </pages> <year> 1992. </year>
Reference-contexts: In parallel, each processor adds objects to a scene by passing pointers to graphics data residing in system memory. A separate command is used to render the objects into a framebuffer, and no ordering constraints are imposed by the interface. PixelFlow <ref> [8, 18] </ref> is another system designed to support multiple simultaneous inputs from a parallel host machine, and PixelFlow OpenGL includes extensions for this purpose. However, due to the underlying image composition architecture, PixelFlow OpenGL also imposes frame semantics and does not support ordering. <p> Though this task is by no means easy, we believe that such a system is feasible with the techniques described in Section 7.2. The parallel API can also be implemented by a variety of other, more exotic architectures. Image composition architectures such as PixelFlow <ref> [8, 18] </ref> are one class of rendering architectures that have not been addressed by the parallel API.
Reference: [19] <author> J. Montrym, D. Baum, D. Dignam, and C. Migdal. </author> <month> InfiniteReality: </month>
Reference-contexts: The parallel API imposes special requirements on the handling of state. In past architectures, state changes have been expensive due to pipeline flushing. Recent graphics architectures, however, have taken measures to allow large numbers of state changes <ref> [19] </ref>. <p> Efficient implementations of synchronized texture download can be realized by extending the idea of the texture download barrier found in the SGI InfiniteReality <ref> [19] </ref>. The access of texture memory may also require special care. Since hardware systems have a limited amount of local texture memory, applications issue primitives in an order which exploits texture locality. The parallel API can reduce this locality since the rasterizers can interleave the rendering of several command streams. <p> One possible architecture consists of implementing the parallel API on a cluster of interconnected PCs with rasterization hardware. Another possibility is to extend the basic sort-middle interleaved architecture [17] of a high-end system such as the SGI InfiniteRe-ality <ref> [19] </ref>. Though this task is by no means easy, we believe that such a system is feasible with the techniques described in Section 7.2. The parallel API can also be implemented by a variety of other, more exotic architectures.
References-found: 19

