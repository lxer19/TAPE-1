URL: http://www.cs.washington.edu/research/projects/lis/www/rapid/pubs/fccm98.ps.gz
Refering-URL: http://www.cs.washington.edu/research/projects/lis/www/rapid/index.html
Root-URL: http://www.cs.washington.edu
Title: Specifying and Compiling Applications for RaPiD  
Author: Darren C. Cronquist, Paul Franklin, Stefan G. Berg, and Carl Ebeling 
Address: Box 352350 Seattle, WA 98195-2350  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Efficient, deeply pipelined implementations exist for a wide variety of important computation-intensive applications, and many special-purpose hardware machines have been built that take advantage of these pipelined computation structures. While these implementations achieve high performance, this comes at the expense of flexibility. On the other hand, flexible architectures proposed thus far have not been very efficient. RaPiD is a reconfigurable pipelined data-path architecture designed to provide a combination of performance and flexibility for a variety of applications. It uses a combination of static and dynamic control to efficiently implement pipelined computations. This control, however, is very complicated; specifying a computation's control circuitry directly would be prohibitively difficult. This paper describes how specifications of a pipelined computation in a suitably high-level language are compiled into the control required to implement that computation in the RaPiD architecture. The compiler extracts a statically configured datapath from this description, identifies the dynamic control signals required to execute the computation, and then produces the control program and decoding structure that generates these dynamic control signals. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Ebeling, D. C. Cronquist, and P. Franklin. </author> <title> RaPiD|reconfigurable pipelined datapath. </title> <editor> In R. Hartenstein and M. Glesner, editors, </editor> <booktitle> 6th International Workshop on Field-Programmable Logic and Compilers, Lecture Notes in Computer Science, </booktitle> <pages> pages 126-135. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1996. </year>
Reference-contexts: Finally, we describe the compilation process used to generate and optimize datapath and its control. 2 The RaPiD Architecture This section provides a brief overview of the architectural details of RaPiD which directly affect the compilation process. For a more thorough description of the architecture, see <ref> [1] </ref> and [2]. RaPiD is a coarse-grained field-programmable architecture for compute intensive applications. The architecture consists of an abundance of functional units such as ALUs and multipliers as well as general purpose registers (GP-REGs) and RAMs.
Reference: [2] <author> C. Ebeling, D. C. Cronquist, P. Franklin, and S. Berg. </author> <title> Mapping applications to the rapid configurable architecture. </title> <booktitle> In Field-Programmable Custom Computing Machines (FCCM-97), </booktitle> <year> 1997. </year>
Reference-contexts: Finally, we describe the compilation process used to generate and optimize datapath and its control. 2 The RaPiD Architecture This section provides a brief overview of the architectural details of RaPiD which directly affect the compilation process. For a more thorough description of the architecture, see [1] and <ref> [2] </ref>. RaPiD is a coarse-grained field-programmable architecture for compute intensive applications. The architecture consists of an abundance of functional units such as ALUs and multipliers as well as general purpose registers (GP-REGs) and RAMs. <p> Instead, this can be constructed using a FSM; a stage can remember whether or not its RAM is active, and one instruction bit can be used to deactivate one stage and activate the next, requiring only two control lines. This is used in implementing a 2-D DCT on RaPiD <ref> [2] </ref>. The number of busses required in the control path varies by application, but is not large because control signals tend to be reused extensively. The benchmark version of the RaPiD architecture provides 31 busses, which can be pipelined and otherwise manipulated individually.
Reference: [3] <author> P. Lee and Z. M. Kedem. </author> <title> On high-speed computing with a programmable linear array. </title> <booktitle> In Proceedings. Supercomputing '88, </booktitle> <pages> pages 425-32. </pages> <publisher> IEEE Comput. Soc. Press, </publisher> <year> 1988. </year>
Reference-contexts: Instead, we propose a language that is C-like and requires the programmer to specify the parallelism, data movement, and partitioning. To this end, the programmer uses well known techniques of loop transformation [5] and space/time mapping <ref> [4, 3] </ref>. The resulting specification is a nested loop where outer loops specify time and the innermost loop space. 1 In the context of RaPiD-C, the space loop refers to a loop over the stages of an algorithm, where a stage is one iteration of the innermost loop.
Reference: [4] <author> D. Moldovan and J. A. B. Fortes. </author> <title> Partitioning and mapping algorithms into fixed size systolic arrays. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(1):1-12, </volume> <year> 1986. </year>
Reference-contexts: Instead, we propose a language that is C-like and requires the programmer to specify the parallelism, data movement, and partitioning. To this end, the programmer uses well known techniques of loop transformation [5] and space/time mapping <ref> [4, 3] </ref>. The resulting specification is a nested loop where outer loops specify time and the innermost loop space. 1 In the context of RaPiD-C, the space loop refers to a loop over the stages of an algorithm, where a stage is one iteration of the innermost loop.
Reference: [5] <author> M. E. Wolf and M. S. Lam. </author> <title> A loop transformation theory and an algorithm to maximize parallelism. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 452-471, </pages> <year> 1991. </year>
Reference-contexts: Instead, we propose a language that is C-like and requires the programmer to specify the parallelism, data movement, and partitioning. To this end, the programmer uses well known techniques of loop transformation <ref> [5] </ref> and space/time mapping [4, 3].
References-found: 5

