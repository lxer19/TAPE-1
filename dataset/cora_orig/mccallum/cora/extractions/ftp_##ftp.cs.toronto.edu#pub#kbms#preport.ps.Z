URL: ftp://ftp.cs.toronto.edu/pub/kbms/preport.ps.Z
Refering-URL: ftp://ftp.cs.toronto.edu/pub/kbms/readme.html
Root-URL: 
Title: Building Knowledge Base Management Systems: A Progress Report  
Author: John Mylopoulos, Vinay Chaudhri, Dimitris Plexousakis Adel Shrufi and Thodoros Topaloglou 
Keyword: Knowledge bases, knowledge base management systems, knowledge representation, storage management, query processing, concurrency control, constraint enforcement, rule management  
Date: May 6, 1994  
Address: Toronto, Toronto, Canada, M5S 1A4.  
Affiliation: Department of Computer Science University of  
Abstract: Advanced applications in fields such as CAD, Software Engineering, Real-Time Process Control, Corporate Repositories and Digital Libraries require the construction, efficient access and management of large, shared knowledge bases. Such knowledge bases cannot be built using existing tools such as expert system shells, because these do not scale up; nor can they be built in terms of existing database technology because such technology does not support the rich representational structure and inference mechanisms required for knowledge based systems. This paper proposes a generic architecture for a knowledge base management system intended for such applications. The architecture assumes an object-oriented knowledge representation language with an as-sertional sublanguage used to express constraints and rules. It also provides for general-purpose deductive inference and special-purpose temporal reasoning. Results reported in the paper address several knowledge base management issues. For storage management, a new method is proposed for generating a logical schema for a given knowledge base. Query processing algorithms are offered for semantic and physical query optimization, along with an enhanced cost model for query cost estimation. On concurrency control, the paper describes a novel concurrency control policy which takes advantage of knowledge base structure and is shown to outperform two-phase locking for highly structured knowledge bases and update-intensive transactions. Finally, algorithms for compilation and efficient processing of constraints and rules during knowledge base operations are described. The paper describes original results, including novel data structures and algorithms, as well as preliminary performance evaluation data. Based on these results, we conclude that knowledge base management systems which can accommodate large knowledge bases are feasible. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agrawal, R., Carey, M. J., and Livny, M. </author> <year> (1987). </year> <title> Concurrency Control Performance Modeling: Alternatives and Implications. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(4) </volume> <pages> 609-654. </pages>
Reference-contexts: Further details about the design of the DDG implementation are provided elsewhere (Chaudhri, 1994). 6.3 Performance Results The DDG policy has been implemented in the DeNet (Livny, 1986) simulation environment. Our performance model is similar to that presented in <ref> (Agrawal, Carey and Livny, 1987) </ref> and has four components: a source, which generates transactions, a transaction manager, which models the execution behavior of transactions, a concurrency control manager, which implements the details of a particular algorithm; and a resource manager, which models the CPU and I/O resources of the database.
Reference: <author> Aho, A. V., Hopcroft, J. E., and Ullman, J. D. </author> <year> (1987). </year> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley Publishing Company. </publisher>
Reference-contexts: The dominator information is maintained incrementally using the algorithm of (Carroll, 1988). The information on strongly connected components is computed at compile time in time O (m log (m)) <ref> (Aho, Hopcroft and Ullman, 1987) </ref>. We developed a new algorithm for incrementally maintaining information on strongly connected components as the knowledge base evolves (Chaudhri, 1994). Let us now describe the order in which a transaction acquires and releases locks.
Reference: <author> Allen, J. </author> <year> (1983). </year> <title> Maintaining Knowledge about Temporal Intervals. </title> <journal> Communications of the ACM, </journal> <volume> 26(11) </volume> <pages> 832-843. </pages>
Reference-contexts: Both history and belief time are represented by means of time intervals. The model of time adopted is a modification of Allen's framework <ref> (Allen, 1983) </ref>. Seven exclusive temporal relations (e.g, equal, meet, before, after, during, start, end) together with their inverses are used to characterize the possible positions of two intervals on a linear time line. Temporal relationships participate in the expression of deductive rules and integrity constraints in the assertion language. <p> Temporal Simplification The objective of temporal simplification rules is to simplify a conjunction of temporal relationships into a single temporal relationship. In its full generality this task is intractable <ref> (Allen, 1983) </ref>. In our method, however, we require that at least one of the temporal variables in each temporal relation should be instantiated, and with this condition the simplification can be performed efficiently. In fact only a table lookup is required.
Reference: <author> Attardi, G. and Simi, M. </author> <year> (1981). </year> <title> Semantics of Inheritance and Attributions in the Description System OMEGA. </title> <type> Technical Report S-81-16, </type> <institution> Universita Di Pisa. </institution> <note> Also MIT AI memo 642, </note> <year> 1981. </year>
Reference-contexts: A proposition can be represented by a 3-tuple 2 (e.g. [Martin,age,35]). Propositions (individuals and attributes) are organized along three dimensions, referred to in the literature as attribution <ref> (Attardi and Simi, 1981) </ref>, classification and generalization (Brodie, Mylopoulos and Schmidt, 1984). Structured objects consist of collections of (possibly multi-valued) attributes that have a common proposition as a source, thus adding a simple form of aggregation.
Reference: <author> Bernstein, P. A., Hadzilacos, V., and Goodman, N. </author> <year> (1987). </year> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Welssley Publishing Company. </publisher>
Reference-contexts: The rest of the discussion in this section focuses on locking rules. A detailed description of the DDG algorithm appears elsewhere (Chaudhri, Hadzilacos and Mylopoulos, 1992). A transaction may lock a node in shared or exclusive mode, denoted by S and X respectively <ref> (Bernstein, Hadzilacos and Goodman, 1987) </ref>. The locking rules for DDG are as follows: L1. The first lock obtained by a transaction can be on any node. L2.
Reference: <author> Bertino, E. and Kim, W. </author> <year> (1989). </year> <title> Indexing Techniques for Queries on Nested Objects. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 1(2) </volume> <pages> 196-214. </pages>
Reference-contexts: To make the two-way access efficient we assume that that two copies of a TJI are stored. Each copy is clustered on one of the object identifiers of the two classes. A series of TJIs can be used to form the temporal equivalent of the multi-join index <ref> (Bertino and Kim, 1989) </ref>. 5 Query Processing For the Telos KBMS, queries are specified through an ASK operation (Mylopoulos et al., 1990), that has the following structure: ASK x 1 =S 1 ; :::; x n =S n : W AS OF t 2 x 1 ; :::; x n are
Reference: <author> Biliris, A. </author> <year> (1992). </year> <title> The Performance of Three Database Storage Structures for Managing Large Objects. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data. </booktitle>
Reference: <author> Bocca, J. </author> <year> (1986). </year> <title> On Evaluation Strategy of EDUCE. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 368-378. </pages>
Reference-contexts: Specifically, this section compares the join index strategy to the sort-merge and nested-loop strategies. The sort-merge strategy represents the traditional database approach in computing large joins. The nested-loop strategy represents the traditional AI approach in query processing where processing is done in a tuple-oriented fashion <ref> (Bocca, 1986) </ref>. Our key conclusion is that our choice of using the join index for evaluating joins performs better than the sort-merge and nested-loop methods. In our test knowledge base, the total number of classes is 40.
Reference: <editor> Brodie, M., Mylopoulos, J., and Schmidt, J., editors (1984). </editor> <booktitle> On Conceptual Modeling: Perspectives from Artificial Intelligence, Databases and Programming Languages. </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: A proposition can be represented by a 3-tuple 2 (e.g. [Martin,age,35]). Propositions (individuals and attributes) are organized along three dimensions, referred to in the literature as attribution (Attardi and Simi, 1981), classification and generalization <ref> (Brodie, Mylopoulos and Schmidt, 1984) </ref>. Structured objects consist of collections of (possibly multi-valued) attributes that have a common proposition as a source, thus adding a simple form of aggregation.
Reference: <author> Bry, F., Decker, H., and Manthey, R. </author> <year> (1988). </year> <title> A Uniform Approach to Constraint Satisfaction and Constraint Satisfiability in Deductive Databases. </title> <booktitle> In 1st Int. Conference on Extending Data Base Technology, </booktitle> <pages> pages 488-505, </pages> <address> Venice, Italy. </address>
Reference-contexts: A transaction is not committed until all constraints are found to be satisfied. 10 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982)), deductive (e.g. (Decker, 1986), <ref> (Bry, Decker and Manthey, 1988) </ref>, (Kuchenhoff, 1991)) and, most recently, object-oriented databases (Jeusfeld and Jarke, 1991) have appeared in the recent literature. A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). <p> Transaction modification is less flexible than constraint simplification since each transaction has to be modified for each relevant constraint. Most promising, as a basis for enforcing more expressive constraints such as the ones expressible in the assertion language of Telos, are the compilation method of <ref> (Bry, Decker and Manthey, 1988) </ref> and the historical knowledge minimization techniques of (Hulsmann and Saake, 1990) and (Chomicki, 1992). <p> A dependence graph is a structure representing such a dependence relation for a set of deductive rules and integrity constraints. 11 A formula is rectified if no two quantifiers introduce the same variable <ref> (Bry, Decker and Manthey, 1988) </ref>. 12 This class of constraints is equivalent to both the restricted quantification form of (Bry, Decker and Manthey, 1988) and the range form of (Jeusfeld and Jarke, 1991). 25 Definition 7.4 (Direct Dependence) A literal L directly depends on literal K if and only if there <p> graph is a structure representing such a dependence relation for a set of deductive rules and integrity constraints. 11 A formula is rectified if no two quantifiers introduce the same variable <ref> (Bry, Decker and Manthey, 1988) </ref>. 12 This class of constraints is equivalent to both the restricted quantification form of (Bry, Decker and Manthey, 1988) and the range form of (Jeusfeld and Jarke, 1991). 25 Definition 7.4 (Direct Dependence) A literal L directly depends on literal K if and only if there exists a rule of the form 8x 1 =C 1 : : : 8x n =C n (F ) <p> A dual approach to constraint enforcement, based on compiling constraints into transaction specifications, is a topic of current research 31 (Plexousakis, 1994b). Finally, a more fine grained approach to integrity violation needs to be devised, possibly adopting ideas of finite constraint satisfiability <ref> (Bry, Decker and Manthey, 1988) </ref>. In addition, we are working towards benchmarks for knowledge based systems, so that we can have a standard method to evaluate the algorithms developed for such systems.
Reference: <author> Buchanan, B. G. and Wilkins, D. C., </author> <title> editors (1993). Readings in Knowledge Acquisition and Learning. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA. </address>
Reference: <author> Carey, M., DeWitt, D., Richardson, J., and Shekita, E. </author> <year> (1986). </year> <title> Object and File Management in the EXODUS Extensible Database System. </title> <booktitle> In Proceedings of the 12th International Conference on Very Large Data Bases, </booktitle> <pages> pages 91-100. </pages>
Reference: <author> Carroll, M. D. </author> <year> (1988). </year> <title> Data Flow Analysis via Dominator and Attribute Updates. </title> <type> Technical Report LCSR-TR-111, </type> <institution> Rutgers University. </institution>
Reference-contexts: Using this information, the dominator of the set of nodes in the transaction can be computed in time linear in the length of a transaction using the nearest common ancestor algorithm of (Schieber and Vishkin, 1988). The dominator information is maintained incrementally using the algorithm of <ref> (Carroll, 1988) </ref>. The information on strongly connected components is computed at compile time in time O (m log (m)) (Aho, Hopcroft and Ullman, 1987). We developed a new algorithm for incrementally maintaining information on strongly connected components as the knowledge base evolves (Chaudhri, 1994).
Reference: <author> Chakravarthy, V., Grant, J., and Minker, J. </author> <year> (1988). </year> <title> Foundations of Semantic Query Optimization for Deductive Databases. </title> <editor> In Minker, J., editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, </booktitle> <pages> pages 243-273. </pages> <publisher> Morgan-Kaufmann. </publisher>
Reference: <author> Chaudhri, V. K. </author> <year> (1994). </year> <title> Transaction Synchronization in Knowledge Bases: Concepts, Realization and Quantitative Evaluation. </title> <type> PhD thesis, </type> <institution> University of Toronto, Toronto. </institution>
Reference-contexts: L5. Each node can be locked by a transaction at most once. Theorem 6.1 The DDG policy produces only serializable schedules <ref> (Chaudhri, 1994) </ref>. In general, the DDG policy does not permit concurrency within cycles (see rule L4 above). This suggests that if a knowledge base contains very large cycles which need to be locked as one node, concurrency will be reduced. <p> The information on strongly connected components is computed at compile time in time O (m log (m)) (Aho, Hopcroft and Ullman, 1987). We developed a new algorithm for incrementally maintaining information on strongly connected components as the knowledge base evolves <ref> (Chaudhri, 1994) </ref>. Let us now describe the order in which a transaction acquires and releases locks. A transaction always begins by locking the dominator of all the nodes that it might access. <p> To implement the third condition, we check all the undirected paths to a node to ensure that this condition is satisfied. A description of an efficient method to accomplish this is available elsewhere <ref> (Chaudhri, 1994) </ref>. These data structures are integrated into the lock manager by maintaining an unlock table. This table is indexed on the node identifier and transaction identifier. An unlock record has three fields that were described above: neededByTransaction, onePredecessor and count. <p> These entries are created when the transaction begins execution and are incrementally updated as the transaction progresses and as changes in the underlying structure of the graph occur. Further details about the design of the DDG implementation are provided elsewhere <ref> (Chaudhri, 1994) </ref>. 6.3 Performance Results The DDG policy has been implemented in the DeNet (Livny, 1986) simulation environment. <p> Performance of the DDG policy was studied on a knowledge base under development for industrial process control <ref> (Chaudhri, 1994) </ref>. The objects represented in the knowledge base (boilers, valves, preheaters, alarms, etc.) are organized into a collection of classes, each with its own subclasses, instances and semantic relationships to other classes. There are five kinds of relationships in this knowledge base. <p> All simulation measurements were done on a DECStation 5000 (model 132). Our detailed measurement results can be found elsewhere <ref> (Chaudhri, 1994) </ref>. The values of overheads are subject to fluctuations. To maintain the consistency of results across different simulation runs, the values of overheads measured from the implementation were given as parameters to the simulation. <p> On the other hand, if the transactions are update intensive, the extra overhead is more than offset by the increased concurrency obtained due to lock pre-release. A more comprehensive description of experiments may be found elsewhere <ref> (Chaudhri, 1994) </ref>. 22 7 Integrity Constraint and Rule Management Integrity constraints specify the valid states of a knowledge base (static constraints) as well as the allowable knowledge base state transitions (dynamic constraints).
Reference: <author> Chaudhri, V. K., Hadzilacos, V., and Mylopoulos, J. </author> <year> (1992). </year> <title> Concurrency Control for Knowledge Bases. </title> <booktitle> In Proceedings of the Third International Conference on Knowledge Representation and Reasoning, </booktitle> <pages> pages 762-773. </pages>
Reference-contexts: Locking rules specify how each transaction should acquire locks. Maintenance rules specify additional operations that must be executed by transactions to keep the structure rooted and connected. The rest of the discussion in this section focuses on locking rules. A detailed description of the DDG algorithm appears elsewhere <ref> (Chaudhri, Hadzilacos and Mylopoulos, 1992) </ref>. A transaction may lock a node in shared or exclusive mode, denoted by S and X respectively (Bernstein, Hadzilacos and Goodman, 1987). The locking rules for DDG are as follows: L1. The first lock obtained by a transaction can be on any node. L2. <p> This suggests that if a knowledge base contains very large cycles which need to be locked as one node, concurrency will be reduced. We have a version of the DDG policy that does permit concurrency within cycles <ref> (Chaudhri, Hadzilacos and Mylopoulos, 1992) </ref>. We adopted the above version, because the transactions in knowledge bases tend to access all the nodes on a cycle together, and therefore, the cycles are a natural unit of locking.
Reference: <author> Chomicki, J. </author> <year> (1992). </year> <title> History-less Checking of Dynamic Integrity Constraints. </title> <booktitle> In 8th Int. Conference on Data Engineering, </booktitle> <pages> pages 557-564, </pages> <month> Phoenix,AZ. </month>
Reference-contexts: Most promising, as a basis for enforcing more expressive constraints such as the ones expressible in the assertion language of Telos, are the compilation method of (Bry, Decker and Manthey, 1988) and the historical knowledge minimization techniques of (Hulsmann and Saake, 1990) and <ref> (Chomicki, 1992) </ref>. The former method, extended with the ability to deal with object identity, aggregation and classification, has been used in the integrity subsystem of the deductive object base ConceptBase (Jeusfeld and Jarke, 1991) (also based on a version of Telos).
Reference: <author> Copeland, G. and Khoshafian, S. </author> <year> (1985). </year> <title> A Decomposition Storage Model. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 268-279. </pages>
Reference-contexts: Each tuple has three fields. Therefore, the required disk storage can be estimated as follows: rds (DSM) = k=0 h X b j )I C (2) Note that equations 1 and 2 modify <ref> (Copeland and Khoshafian, 1985) </ref> formulas for NSM and DSM storage, taking into account attributes defined over isA hierarchies. In the CDM, the degree of decomposition depends on the average number of attributes with complex domains and the access frequency of the attributes. <p> With this change, the expression for the storage cost of CDM is as follows: rds (CDM) = (1 d) fl (rds (N SM ) + cor (N SM )) + d fl rds (DSM ) (3) The estimates of space costs suggested by the above formulae confirm the claim of <ref> (Copeland and Khoshafian, 1985) </ref> that DSM requires 2 to 4 times more data storage than NSM. As expected, CDM's storage costs fall between those of the other two schemes. The first graph in Figure 5 shows relative storage costs for a balanced-tree isA hierarchy.
Reference: <author> Dechter, R., Meiri, I., and Pearl, J. </author> <year> (1989). </year> <title> Temporal Constraint Networks. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Representation and Reasoning, </booktitle> <pages> pages 83-93. </pages>
Reference-contexts: The testing of the temporal condition in the schema query is formulated as a CSP with integer order constraints which is solved in polynomial time <ref> (Dechter, Meiri and Pearl, 1989) </ref>. For the last step, we need to index the rules and the constraints on their history and belief time.
Reference: <author> Decker, H. </author> <year> (1986). </year> <title> Integrity Enforcement in Deductive Databases. </title> <booktitle> In Expert Database Systems, 1st Int. </booktitle> <pages> Conference , pages 271-285. </pages> <note> 35 Eswaran, </note> <author> K., Gray, J. N., Lorie, R. A., and Traiger, I. L. </author> <year> (1976). </year> <title> The Notions of Consistency and Predicate Locks in Database Systems. </title> <journal> Communications of the ACM, </journal> <volume> 19(9) </volume> <pages> 624-633. </pages>
Reference-contexts: A transaction is not committed until all constraints are found to be satisfied. 10 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982)), deductive (e.g. <ref> (Decker, 1986) </ref>, (Bry, Decker and Manthey, 1988), (Kuchenhoff, 1991)) and, most recently, object-oriented databases (Jeusfeld and Jarke, 1991) have appeared in the recent literature. A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). <p> Each C i is a Telos class and the meaning of each restricted quantification is that the variable bound by the quantifier ranges over the extension of the class instead of the entire domain. Any constraint in this form is range-restricted <ref> (Decker, 1986) </ref>. 12 The typed quantifications 8x=C F and 9x=C F are short forms for the formulae: 8x 8t instanceOf (x; C; t) ^ instanceOf (t; TimeInterval; Alltime) ) F , 9x 9t instanceOf (x; C; t) ^ instanceOf (t; TimeInterval; Alltime) ^ F The introduction of temporal variables and their
Reference: <author> Findler, N., </author> <title> editor (1979). Associative Networks. </title> <publisher> Academic Press. </publisher>
Reference-contexts: Section 8 summarizes the results of this work and outlines open problems for further research. 2 Overview of Telos The representational framework of Telos (Mylopoulos et al., 1990) constitutes a generalization of graph-theoretic data structures used in semantic networks <ref> (Findler, 1979) </ref>, semantic data models (Hull and King, 1987) and object-oriented representations (Zdonik and Maier, 1989). Telos treats attributes as first-class citizens, supports a powerful classification (or instantiation) mechanism which enhances extensibility and offers special representational and inferential mechanisms for temporal knowledge.
Reference: <author> Finkelstein, S., Schkolnick, M., and Tiberio, P. </author> <year> (1988). </year> <title> Physical Databases Design for Relational Databases. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 13(1) </volume> <pages> 91-128. </pages>
Reference: <author> Frank, M., Omiecinski, E., and Navathe, S. </author> <year> (1992). </year> <title> Adaptive and Automated Index Selection in RDBMS. </title> <booktitle> In Proceedings of International Conference on Extending Database Technology, </booktitle> <pages> pages 277-292. </pages>
Reference: <author> Frenkel, K. A. </author> <year> (1991). </year> <title> The Human Genome Project and Informatics. </title> <journal> Communications of the ACM, </journal> <volume> 34(11) </volume> <pages> 41-51. </pages>
Reference-contexts: alarms (what does it mean when alarm 692 goes off) and diagnostic knowledge used by plant operators to determine the nature of an emergency (Mylopoulos et al., 1992); * "grand challenges", such as information system support for environmental global change research (Stonebraker and Dozier, 1991) and the human GENOME project <ref> (Frenkel, 1991) </ref>; * knowledge sharing applications that involve construction of generic knowledge bases that include thousands of concept descriptions and are used as references in the construction of knowledge based systems (Neches et al., 1991).
Reference: <author> Guttman, A. </author> <year> (1984). </year> <title> R-Trees: A Dynamic Index Structure For Spatial Searching. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 47-57. </pages>
Reference-contexts: With these indices it is possible to perform selection using keys and time simultaneously. Since the index entries are no longer points, it is assumed that they are implemented as spatial access methods <ref> (Guttman, 1984) </ref>. Moreover, the indices are hierarchical in the sense that one index stores information for all the instances of a class (including inherited ones). This choice is consistent with a previous study (Kim, Kim and Dale, 1989) which shows that a hierarchical index always outperforms the simple class index. <p> For the last step, we need to index the rules and the constraints on their history and belief time. In the two dimensional space that history and belief time define, each rule or constraint is viewed as a rectangular area; We use an R-tree based spatial access method <ref> (Guttman, 1984) </ref> to assist the temporal selection with logarithmic complexity. 5.1.2 Syntactic Simplification Syntactic simplification exploits the properties of the structural features of Telos (i.e., isA, instanceOf and proposition relationships). Also, subexpressions within the query expression that are always true, always false, or inconsistent are detected.
Reference: <author> Hull, R. and King, R. </author> <year> (1987). </year> <title> Semantic Database Modeling: Survey, Applications and Research Issues. </title> <journal> ACM Computing Surveys, </journal> <volume> 19(3). </volume>
Reference-contexts: Section 8 summarizes the results of this work and outlines open problems for further research. 2 Overview of Telos The representational framework of Telos (Mylopoulos et al., 1990) constitutes a generalization of graph-theoretic data structures used in semantic networks (Findler, 1979), semantic data models <ref> (Hull and King, 1987) </ref> and object-oriented representations (Zdonik and Maier, 1989). Telos treats attributes as first-class citizens, supports a powerful classification (or instantiation) mechanism which enhances extensibility and offers special representational and inferential mechanisms for temporal knowledge.
Reference: <author> Hulsmann, K. and Saake, G. </author> <year> (1990). </year> <title> Representation of the Historical Information Necessary for Temporal Integrity Monitoring. </title> <booktitle> In 2nd Int. Conference on Extending Data Base Technology, </booktitle> <pages> pages 378-392, </pages> <address> Venice, Italy. </address>
Reference-contexts: Most promising, as a basis for enforcing more expressive constraints such as the ones expressible in the assertion language of Telos, are the compilation method of (Bry, Decker and Manthey, 1988) and the historical knowledge minimization techniques of <ref> (Hulsmann and Saake, 1990) </ref> and (Chomicki, 1992). The former method, extended with the ability to deal with object identity, aggregation and classification, has been used in the integrity subsystem of the deductive object base ConceptBase (Jeusfeld and Jarke, 1991) (also based on a version of Telos).
Reference: <author> Ibaraki, T. and Katoh, N. </author> <year> (1983). </year> <title> On-Line Computation of Transitive Closures of Graphs. </title> <journal> Information Processing Letters, </journal> <volume> 16(3) </volume> <pages> 95-97. </pages>
Reference: <author> Ioannidis, Y. E. and Kang, Y. C. </author> <year> (1991). </year> <title> Left-Deep vs. Bushy Trees: An Analysis of Strategy Spaces and its Implications for Query Optimization. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 168-177. </pages>
Reference-contexts: For our KBMS, we have adopted a heuristic search method based upon the enumeration of the most promising execution plan based on the selectivity of classes (Shrufi and Topaloglou, 1994). Exploring randomized algorithms <ref> (Ioannidis and Kang, 1991) </ref> is left for future work. 5.2.5 Performance Analysis In this section, our goal is to quantitatively evaluate the proposed join-index-based query processing methods. Specifically, this section compares the join index strategy to the sort-merge and nested-loop strategies.
Reference: <author> Ishikawa, H., Suzuki, F., Kozakura, F., Makinouchi, A., Miyagishima, M., Izumida, Y., Aoshima, M., and Yamane, Y. </author> <year> (1993). </year> <title> The Model, Language, and Implementation of an Object-Oriented Multimedia Knowledge Base Management System . ACM Transactions on Database Systems, </title> <booktitle> 18(1) </booktitle> <pages> 1-50. </pages>
Reference: <author> Italiano, G. </author> <year> (1988). </year> <title> Finding Paths and Deleting Edges in Directed Acyclic Graphs. </title> <journal> Information Processing Letters, </journal> <volume> 28(1) </volume> <pages> 5-11. </pages>
Reference: <author> Jarke, M. and Koch, J. </author> <year> (1984). </year> <title> Query Optimization in Database Systems. </title> <journal> Computing Surveys, </journal> <volume> 16(2) </volume> <pages> 111-143. </pages>
Reference: <author> Jarke, M. and Koubarakis, M. </author> <year> (1989). </year> <title> Query Optimization in KBMS: Overview, Research Issues, and Concepts for a Telos Implementation. </title> <type> Technical Report KRR-TR-89-6, </type> <institution> Dept. of Computer Science, University of Toronto. </institution>
Reference-contexts: In the following, we summarize the 12 three steps in semantic optimization. More details can be found elsewhere (Topaloglou, Illarramendi and Sbattella, 1992). 5.1.1 Temporal Simplification Temporal simplification attempts to identify those parts of a knowledge base that are relevant to a query from a temporal viewpoint <ref> (Jarke and Koubarakis, 1989) </ref>. Temporal simplification involves the following three steps: 1. Check for inconsistent or redundant temporal constraints in the query expression; 2.
Reference: <author> Jeusfeld, M. and Jarke, M. </author> <year> (1991). </year> <title> From Relational to Object-Oriented Integrity Simplification. </title> <booktitle> In 2nd Int. Conference on Deductive and Object-Oriented Databases, </booktitle> <pages> pages 460-477, </pages> <address> Munich, Germany. </address>
Reference-contexts: A transaction is not committed until all constraints are found to be satisfied. 10 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982)), deductive (e.g. (Decker, 1986), (Bry, Decker and Manthey, 1988), (Kuchenhoff, 1991)) and, most recently, object-oriented databases <ref> (Jeusfeld and Jarke, 1991) </ref> have appeared in the recent literature. A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). <p> The former method, extended with the ability to deal with object identity, aggregation and classification, has been used in the integrity subsystem of the deductive object base ConceptBase <ref> (Jeusfeld and Jarke, 1991) </ref> (also based on a version of Telos). However, this method does not deal with temporal or dynamic constraints. Historical knowledge minimization techniques assume a formulation of constraints in temporal logic and attempt to minimize the historical information required in order to verify the constraints. <p> The definition of relevance found in <ref> (Jeusfeld and Jarke, 1991) </ref> is not sufficient in the presence of time. The following definition provides sufficient conditions for "relevance" of a constraint to an update, by considering the relationships of the time intervals participating in the literals of the constraint and the update. <p> a set of deductive rules and integrity constraints. 11 A formula is rectified if no two quantifiers introduce the same variable (Bry, Decker and Manthey, 1988). 12 This class of constraints is equivalent to both the restricted quantification form of (Bry, Decker and Manthey, 1988) and the range form of <ref> (Jeusfeld and Jarke, 1991) </ref>. 25 Definition 7.4 (Direct Dependence) A literal L directly depends on literal K if and only if there exists a rule of the form 8x 1 =C 1 : : : 8x n =C n (F ) A) such that, there exists a literal in the body
Reference: <author> Khoshafian, S. and Copeland, G. </author> <year> (1986). </year> <title> Object identity. </title> <booktitle> In Proceedings of OOPSLA-86, </booktitle> <pages> pages 406-416, </pages> <address> Portland, Oregon. </address>
Reference-contexts: Updating the value of an attribute: First, the relevant storage record is located by accessing an index. Then, the block which contains that record is written and the attribute's index is updated. For the DSM, as with the CDM, this requires on average three writes <ref> (Khoshafian and Copeland, 1986) </ref>. Appropriate buffering policy may further minimize that cost. The graph of Figure 5 (b) shows the cost for the token insertion case.
Reference: <author> Kim, W., Kim, K.-C., and Dale, A. </author> <year> (1989). </year> <title> Indexing Techniques for Object-Oriented Databases. In Object-Oriented Concepts, Databases and Applications. </title> <publisher> ACM Press. </publisher>
Reference-contexts: Moreover, the indices are hierarchical in the sense that one index stores information for all the instances of a class (including inherited ones). This choice is consistent with a previous study <ref> (Kim, Kim and Dale, 1989) </ref> which shows that a hierarchical index always outperforms the simple class index. The simple temporal index (STI) is used on attributes with primitive domains. <p> To make the two-way access efficient we assume that that two copies of a TJI are stored. Each copy is clustered on one of the object identifiers of the two classes. A series of TJIs can be used to form the temporal equivalent of the multi-join index <ref> (Bertino and Kim, 1989) </ref>. 5 Query Processing For the Telos KBMS, queries are specified through an ASK operation (Mylopoulos et al., 1990), that has the following structure: ASK x 1 =S 1 ; :::; x n =S n : W AS OF t 2 x 1 ; :::; x n are
Reference: <author> Kuchenhoff, V. </author> <year> (1991). </year> <title> On the Efficient Computation of the Difference Between Consecutive Database States. </title> <booktitle> In 2nd International Conference on Deductive and Object-Oriented Databases, </booktitle> <pages> pages 478-502, </pages> <address> Munich, Germany. </address>
Reference-contexts: A transaction is not committed until all constraints are found to be satisfied. 10 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. (Nicolas, 1982)), deductive (e.g. (Decker, 1986), (Bry, Decker and Manthey, 1988), <ref> (Kuchenhoff, 1991) </ref>) and, most recently, object-oriented databases (Jeusfeld and Jarke, 1991) have appeared in the recent literature. A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). <p> Moreover, issues such as the efficient storage and access of the dependence graph and storage and indexing of rules and constraints are currently under investigation. The performance of the compilation method needs to be assessed and compared to methods that interleave compilation and evaluation, e.g. <ref> (Kuchenhoff, 1991) </ref>. A dual approach to constraint enforcement, based on compiling constraints into transaction specifications, is a topic of current research 31 (Plexousakis, 1994b). Finally, a more fine grained approach to integrity violation needs to be devised, possibly adopting ideas of finite constraint satisfiability (Bry, Decker and Manthey, 1988).
Reference: <author> Law, A. M. and Kelton, W. D. </author> <year> (1991). </year> <title> Simulation Modeling and Analysis. </title> <address> McGraw-Hill New York, NY. </address>
Reference-contexts: We employ a batch means method for the statistical data analysis of our results, and run each simulation long enough to obtain sufficiently tight confidence intervals (in most cases, 90% confidence level, within 5% of the mean) <ref> (Law and Kelton, 1991) </ref>. Performance of the DDG policy was studied on a knowledge base under development for industrial process control (Chaudhri, 1994).
Reference: <author> Lengauer, T. and Tarjan, R. E. </author> <year> (1979). </year> <title> A Fast Dominator Algorithm for Finding Dominators in a Flow Graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 1(1) </volume> <pages> 121-141. </pages>
Reference-contexts: To enforce the locking rules, we need information on the dominator relationships and the strongly connected components within the knowledge base graph. In our implementation, the dominator tree of the knowledge base is computed at compile time using a bit vector algorithm <ref> (Lengauer and Tarjan, 1979) </ref>. Using this information, the dominator of the set of nodes in the transaction can be computed in time linear in the length of a transaction using the nearest common ancestor algorithm of (Schieber and Vishkin, 1988).
Reference: <author> Lipeck, U. </author> <year> (1990). </year> <title> Transformation of Dynamic Integrity Constraints into Transaction Specifications. </title> <journal> Theoretical Computer Science, </journal> <volume> 76 </volume> <pages> 115-142. </pages> <note> 36 Livny, </note> <author> M. </author> <year> (1986). </year> <title> DeNeT User's Guide (Version 1.5). </title> <type> Technical report, </type> <institution> University of Wisconsin. </institution>
Reference-contexts: A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and (Wallace, 1991). Along the same lines, a transaction modification technique for temporal constraints has been proposed in <ref> (Lipeck, 1990) </ref>, but does not account for implicit updates. A transaction modification method for temporal constraints and implicit updates appears in (Plexousakis, 1994b). Transaction modification is less flexible than constraint simplification since each transaction has to be modified for each relevant constraint.
Reference: <author> Lloyd, J. and Topor, R. </author> <year> (1985). </year> <title> A Basis for Deductive Database Systems. </title> <journal> Journal of Logic Programming, </journal> <volume> 2 </volume> <pages> 93-109. </pages>
Reference-contexts: Their general form is: DR 8x 1 =C 1 : : : 8x n =C n (F ) A) where F is subject to the same restrictions as above and A is an atom of the assertion language. In addition deductive rules are assumed to be stratified <ref> (Lloyd and Topor, 1985) </ref>. Let us now introduce some terminology that we will use in the rest of the section. Definition 7.1 An update is an instantiated literal whose sign determines whether it is an insertion or a deletion.
Reference: <author> Lockemann, P. C., Nagel, H.-H., and Walter, I. M. </author> <year> (1991). </year> <title> Databases for Knowledge Bases: empirical study of a knowledge base management system for a semantic network. </title> <journal> Data & Knowledge Engineering, </journal> <volume> 7 </volume> <pages> 115-154. </pages>
Reference: <author> Mylopoulos, J., Borgida, A., Jarke, M., and Koubarakis, M. </author> <year> (1990). </year> <title> Telos: A Language for Representing Knowledge About Information Systems. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 8(4) </volume> <pages> 325-362. </pages>
Reference-contexts: Moreover, the system supports reasoning mechanisms including deductive inference, constraint enforcement and temporal reasoning. The representation language adopted for the KBMS design is Telos <ref> (Mylopoulos et al., 1990) </ref>. The term "knowledge base" is used throughout the paper, instead of "database", mostly for historical reasons. <p> The methodology used to evaluate the proposed research results varies with the results being evaluated. Section 8 summarizes the results of this work and outlines open problems for further research. 2 Overview of Telos The representational framework of Telos <ref> (Mylopoulos et al., 1990) </ref> constitutes a generalization of graph-theoretic data structures used in semantic networks (Findler, 1979), semantic data models (Hull and King, 1987) and object-oriented representations (Zdonik and Maier, 1989). <p> This section introduces the core features of Telos which are divided into structural, temporal and assertional features. A more comprehensive description of the language can be found elsewhere <ref> (Mylopoulos et al., 1990) </ref>. 2.1 Structural Component A Telos knowledge base consists of structured objects built out of two kinds of primitive units, individuals and attributes. <p> The definitions of other functions can be found elsewhere <ref> (Mylopoulos et al., 1990) </ref>. The terms of the language include variables, constants (including conventional dates) and the result of applying functions to terms. <p> These services are interfaced with the logical layer through the knowledge representation language interpreter or compiler and a session manager. The logical layer maintains information on class definitions, including rules and constraints, and supports primitive knowledge base operations such as TELL and ASK <ref> (Mylopoulos et al., 1990) </ref>. <p> Each copy is clustered on one of the object identifiers of the two classes. A series of TJIs can be used to form the temporal equivalent of the multi-join index (Bertino and Kim, 1989). 5 Query Processing For the Telos KBMS, queries are specified through an ASK operation <ref> (Mylopoulos et al., 1990) </ref>, that has the following structure: ASK x 1 =S 1 ; :::; x n =S n : W AS OF t 2 x 1 ; :::; x n are assumed to be target variables for which the query processor needs to determine values; S 1 ; :::;
Reference: <author> Mylopoulos, J., Kramer, B., Wang, H., Benjamin, M., Chou, Q. B., and Mensah, S. </author> <year> (1992). </year> <title> Expert System Applications in Process Control. </title> <booktitle> In Proceedings of the International Symposium on Artificial Intelligence in Materials Processing Applications, </booktitle> <address> Edmonton. </address>
Reference-contexts: them; for an industrial process, such knowledge includes a plant schematic, knowledge about plant components (pipes, valves, boilers, etc.) and their operational characteristics, knowledge about hardwired alarms (what does it mean when alarm 692 goes off) and diagnostic knowledge used by plant operators to determine the nature of an emergency <ref> (Mylopoulos et al., 1992) </ref>; * "grand challenges", such as information system support for environmental global change research (Stonebraker and Dozier, 1991) and the human GENOME project (Frenkel, 1991); * knowledge sharing applications that involve construction of generic knowledge bases that include thousands of concept descriptions and are used as references in <p> Locking rules specify how each transaction should acquire locks. Maintenance rules specify additional operations that must be executed by transactions to keep the structure rooted and connected. The rest of the discussion in this section focuses on locking rules. A detailed description of the DDG algorithm appears elsewhere <ref> (Chaudhri, Hadzilacos and Mylopoulos, 1992) </ref>. A transaction may lock a node in shared or exclusive mode, denoted by S and X respectively (Bernstein, Hadzilacos and Goodman, 1987). The locking rules for DDG are as follows: L1. The first lock obtained by a transaction can be on any node. L2. <p> This suggests that if a knowledge base contains very large cycles which need to be locked as one node, concurrency will be reduced. We have a version of the DDG policy that does permit concurrency within cycles <ref> (Chaudhri, Hadzilacos and Mylopoulos, 1992) </ref>. We adopted the above version, because the transactions in knowledge bases tend to access all the nodes on a cycle together, and therefore, the cycles are a natural unit of locking.
Reference: <author> Neches, R., Fikes, R., Finin, T., Gruber, T., Patil, R., Senator, T., and Swartout, W. </author> <year> (1991). </year> <title> Enabling Technology for Knowledge Sharing. </title> <journal> AI Magazine, </journal> <volume> 12(3) </volume> <pages> 36-56. </pages>
Reference-contexts: such as information system support for environmental global change research (Stonebraker and Dozier, 1991) and the human GENOME project (Frenkel, 1991); * knowledge sharing applications that involve construction of generic knowledge bases that include thousands of concept descriptions and are used as references in the construction of knowledge based systems <ref> (Neches et al., 1991) </ref>. Such knowledge bases may be built in terms of existing knowledge representation systems (expert system shells, for instance) or AI languages such as Lisp or Prolog.
Reference: <author> Nicolas, J.-M. </author> <year> (1982). </year> <title> Logic for Improving Integrity Checking in Relational Databases. </title> <journal> Acta Informatica, </journal> <volume> 18 </volume> <pages> 227-253. </pages>
Reference-contexts: At present, we adopt a rather coarse-grained approach to integrity recovery, namely the rejection of any integrity violating transaction. A transaction is not committed until all constraints are found to be satisfied. 10 7.1 Inadequacies of Existing Methods A number of incremental constraint checking techniques for relational (e.g. <ref> (Nicolas, 1982) </ref>), deductive (e.g. (Decker, 1986), (Bry, Decker and Manthey, 1988), (Kuchenhoff, 1991)) and, most recently, object-oriented databases (Jeusfeld and Jarke, 1991) have appeared in the recent literature.
Reference: <author> Paul, H.-B., Schek, H.-J., Scholl, M., Weikum, G., and Deppish, U. </author> <year> (1987). </year> <title> Architecture and Implementation of a Darmstadt Database Kernel System. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 196-207, </pages> <address> San Francisco, CA. </address>
Reference: <author> Plexousakis, D. </author> <year> (1993a). </year> <title> Integrity Constraint and Rule Maintenance in Temporal Deductive Knowledge Bases. </title> <booktitle> In Proceedings of the 19th International Conference on Very Large Data Bases, </booktitle> <pages> pages 146-157, </pages> <address> Dublin, IR. </address>
Reference-contexts: Integrity constraints are used to express complex semantic relationships including, among others, existence, disjunction or properties referring to state transitions or histories <ref> (Plexousakis, 1993a) </ref>. <p> The compilation scheme allows for dynamic insertion or removal of integrity constraints and deductive rules without having to recompile the entire knowledge base. We describe the method in more detail in <ref> (Plexousakis, 1993a) </ref> . 7.2 A Constraint Enforcement Algorithm Our constraint enforcement method operates in two phases: compilation and evaluation.
Reference: <author> Plexousakis, D. </author> <year> (1993b). </year> <title> Semantical and Ontological Consideration in Telos: a Language for Knowledge Representation. </title> <journal> Computational Intelligence, </journal> <volume> 9(1) </volume> <pages> 41-72. </pages>
Reference-contexts: In addition, there have been formal accounts of the semantics of the language based on an axiomatic approach (Stanley, 1986) or a possible-worlds model <ref> (Plexousakis, 1993b) </ref>. This section introduces the core features of Telos which are divided into structural, temporal and assertional features.
Reference: <author> Plexousakis, D. </author> <year> (1994a). </year> <title> Integrity Maintenance in a Telos-based KBMS. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Toronto. Forthcoming. </institution>
Reference-contexts: There can be cycles among deductive rule nodes in the graph. This happens when R contains mutually recursive rules. There are no trivial cycles in the graph and it has the following property <ref> (Plexousakis, 1994a) </ref>: Theorem 7.2 For any Telos knowledge base, dependence graph construction yields a graph that may contain cycles of length at most equal to the number of deductive rules participating in the same recursive scheme. 29 Furthermore, the graph is sparse for an average number ff of literals per rule <p> The time complexity for computing implicit updates caused by an explicit update matching some node in the graph is O (jEj), and O (jV R j fl jEj) for computing the transitive closure of the entire graph by solving jV R j single-source problems <ref> (Plexousakis, 1994a) </ref>. Experiments with randomly generated dependence graphs have shown that, on the average, the execution time of computing single-source implicit updates is sub-linear in jEj (Plexousakis, 1994a). 7.2.3 Evaluation Phase In this section we describe the evaluation phase of our algorithm. <p> (jEj), and O (jV R j fl jEj) for computing the transitive closure of the entire graph by solving jV R j single-source problems <ref> (Plexousakis, 1994a) </ref>. Experiments with randomly generated dependence graphs have shown that, on the average, the execution time of computing single-source implicit updates is sub-linear in jEj (Plexousakis, 1994a). 7.2.3 Evaluation Phase In this section we describe the evaluation phase of our algorithm. We first discuss how the dependence graph generated in the compilation phase is used to check the integrity constraints at the time of update. <p> Rule deletion requires worst-case time of O (jV R j fl jEj). An analytical model giving more precise characterizations of the cost of updates of rules and constraints can be found elsewhere <ref> (Plexousakis, 1994a) </ref>. In addition to updating the dependence graph, we also need to incrementally compute its transitive closure. Incremental transitive closure algorithms available in literature can deal only with directed acyclic graphs (Ibaraki and Katoh, 1983; Italiano, 1988). <p> Incremental transitive closure algorithms available in literature can deal only with directed acyclic graphs (Ibaraki and Katoh, 1983; Italiano, 1988). In our research we have developed an algorithm that incrementally computes transitive closure for general graphs <ref> (Plexousakis, 1994a) </ref>. Our preliminary experiments have shown that this algorithm can efficiently update the transitive closure of a dependence graph.
Reference: <author> Plexousakis, D. </author> <year> (1994b). </year> <title> The Role of Ramifications in Transaction Specifications and Integrity Checking. </title> <note> Submitted for Publication. </note>
Reference-contexts: Along the same lines, a transaction modification technique for temporal constraints has been proposed in (Lipeck, 1990), but does not account for implicit updates. A transaction modification method for temporal constraints and implicit updates appears in <ref> (Plexousakis, 1994b) </ref>. Transaction modification is less flexible than constraint simplification since each transaction has to be modified for each relevant constraint. <p> The performance of the compilation method needs to be assessed and compared to methods that interleave compilation and evaluation, e.g. (Kuchenhoff, 1991). A dual approach to constraint enforcement, based on compiling constraints into transaction specifications, is a topic of current research 31 <ref> (Plexousakis, 1994b) </ref>. Finally, a more fine grained approach to integrity violation needs to be devised, possibly adopting ideas of finite constraint satisfiability (Bry, Decker and Manthey, 1988).
Reference: <author> Qaddah, G., Henschen, L., and Kim, J. </author> <year> (1991). </year> <title> Efficient Algorithms for the Instantiated Transitive Closure Queries. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(3) </volume> <pages> 296-309. </pages>
Reference-contexts: The dependence graph is constructed once when the knowledge base is compiled and is updated incrementally when new rules or constraints are inserted or deleted. The transitive closure of the graph is computed by a modification of the ffi-wavefront algorithm <ref> (Qaddah, Henschen and Kim, 1991) </ref>. The algorithm has been modified to apply to cyclic graphs and take advantage of the dependence graph properties. Evaluating the dependence graph's transitive closure amounts to computing the potential implicit updates caused by explicit updates on literals occurring in the bodies of deductive rules.
Reference: <author> Schieber, B. and Vishkin, U. </author> <year> (1988). </year> <title> On Finding Lowest Common Ancestors: Simplification and Paralleliza-tion. </title> <journal> SIAM Journal of Computing, </journal> <volume> 17(6) </volume> <pages> 1253-1262. </pages>
Reference-contexts: Using this information, the dominator of the set of nodes in the transaction can be computed in time linear in the length of a transaction using the nearest common ancestor algorithm of <ref> (Schieber and Vishkin, 1988) </ref>. The dominator information is maintained incrementally using the algorithm of (Carroll, 1988). The information on strongly connected components is computed at compile time in time O (m log (m)) (Aho, Hopcroft and Ullman, 1987).
Reference: <author> Selinger, G., Astrahan, M., Chamberlin, D., Lorie, R., and Price, T. </author> <year> (1979). </year> <title> Access Path Selection in a Relational Database Management System. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 23-34. </pages>
Reference-contexts: Inconsistency Inconsistency Inconsistency Temporal Simplification Semantic Transformation KB structure KB temporal Set of Rules Query Q' Syntactic Simplification Physical Query Optimization Access Plan Transformed Query PO Tree Execution Tree Access Plan Optimizer Statistics Cost Model a query is subjected to four phases of processing: parsing, optimization, code generation and execution <ref> (Selinger et al., 1979) </ref>. The focus of this section is on the optimization phase. Query optimization for knowledge bases is hard for several reasons. First, the representation formalism adopted for the knowledge bases is more expressive giving a query language with temporal, spatial, class- and meta-class-related expressions. <p> For a query with n classes, there are n (n 1) parameterized trees generated, in the worst case. Unfortunately, the substitution of the primitive operations on the parameterized tree implies a O (2 n1 ) size of the execution space that obviates the enumeration of all possible executions <ref> (Selinger et al., 1979) </ref>. In order to pick an execution tree with an optimal cost, we need a cost function that is used to compute the cost of access plan corresponding to each execution tree. Furthermore, we need a heuristic search algorithm to walk selectively the space of possible executions.
Reference: <author> Shrufi, A. </author> <year> (1994). </year> <title> Performance of Static Clustering Algorithm for Knowledge Bases. </title> <type> Technical Report Forthcoming, </type> <institution> University of Toronto. </institution>
Reference-contexts: The costs of the primitive operations that were shown in the previous section are given in Table 2. For our KBMS, we have adopted a heuristic search method based upon the enumeration of the most promising execution plan based on the selectivity of classes <ref> (Shrufi and Topaloglou, 1994) </ref>. Exploring randomized algorithms (Ioannidis and Kang, 1991) is left for future work. 5.2.5 Performance Analysis In this section, our goal is to quantitatively evaluate the proposed join-index-based query processing methods. Specifically, this section compares the join index strategy to the sort-merge and nested-loop strategies. <p> Soundness and completeness of the simplification method have been proven and preliminary performance results have been established. Clearly, the design and performance analysis of the proposed architecture is not complete. In particular, work is in progress on the physical design of the KBMS <ref> (Shrufi, 1994) </ref>, exploring the use of existing database storage kernels. A thorough experimental performance analysis is planned to validate the cost function of our storage and query model. The study of semantic criteria for reducing the search space when an access is planned is an issue that requires further research.
Reference: <author> Shrufi, A. and Topaloglou, T. </author> <year> (1994). </year> <title> Query Processing Techniques for Temporal Knowledge Bases. </title> <type> Technical Report Forthcoming, </type> <institution> University of Toronto. </institution>
Reference-contexts: The costs of the primitive operations that were shown in the previous section are given in Table 2. For our KBMS, we have adopted a heuristic search method based upon the enumeration of the most promising execution plan based on the selectivity of classes <ref> (Shrufi and Topaloglou, 1994) </ref>. Exploring randomized algorithms (Ioannidis and Kang, 1991) is left for future work. 5.2.5 Performance Analysis In this section, our goal is to quantitatively evaluate the proposed join-index-based query processing methods. Specifically, this section compares the join index strategy to the sort-merge and nested-loop strategies. <p> Soundness and completeness of the simplification method have been proven and preliminary performance results have been established. Clearly, the design and performance analysis of the proposed architecture is not complete. In particular, work is in progress on the physical design of the KBMS <ref> (Shrufi, 1994) </ref>, exploring the use of existing database storage kernels. A thorough experimental performance analysis is planned to validate the cost function of our storage and query model. The study of semantic criteria for reducing the search space when an access is planned is an issue that requires further research.
Reference: <author> Silberschatz, A. and Kedem, Z. M. </author> <year> (1980). </year> <title> Consistency in Hierarchical Database Systems. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 27(1) </volume> <pages> 72-80. </pages>
Reference: <author> Snodgrass, R. </author> <year> (1987). </year> <title> The Temporal Query Language TQuel. </title> <journal> ACM Transcactions on Database Systems, </journal> <volume> 12(2) </volume> <pages> 247-298. </pages>
Reference-contexts: The second query retrieves all employees who worked for the database group of IBM in 1990 according to what the system currently believes. The first query is a temporal query and the second is a historical query <ref> (Snodgrass, 1987) </ref>. Q1. ASK e=Employee : Exist t 1 ; t 2 =TimeInterval (e [t 1 ]:salary e [t 2 ]:salary 5000) and (t 1 before t 2 ) ON (1988::fl) Q2.
Reference: <author> Stanley, M. </author> <year> (1986). </year> <title> CML: A Knowledge Representation Language with Application to Requirements Modeling. </title> <type> Technical report, </type> <institution> University of Toronto, Toronto. </institution>
Reference-contexts: Telos treats attributes as first-class citizens, supports a powerful classification (or instantiation) mechanism which enhances extensibility and offers special representational and inferential mechanisms for temporal knowledge. In addition, there have been formal accounts of the semantics of the language based on an axiomatic approach <ref> (Stanley, 1986) </ref> or a possible-worlds model (Plexousakis, 1993b). This section introduces the core features of Telos which are divided into structural, temporal and assertional features.
Reference: <author> Steinbrunn, M., Moerkotte, G., and Kemper, A. </author> <year> (1993). </year> <title> Optimizing Join Orders. </title> <type> Technical Report MIP-9307, </type> <institution> Universitat Passsu, Fakulat fur Mathematik and Informatik. </institution> <note> 37 Stickel, </note> <author> M. </author> <year> (1985). </year> <title> Automated Deduction by Theory Resolution. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 455-458, </pages> <address> Los Angeles, CA. </address>
Reference-contexts: First, the search space (that is, all possible access plans) in case of the generalized bushy trees becomes unmanageably large. Second, it has been argued that the space of left-deep trees contains the most feasible execution strategies <ref> (Steinbrunn, Moerkotte and Kemper, 1993) </ref>. Third, in the controlled decomposition model adopted here, the left-deep trees better utilize the join index relations that are available. The number of all possible P O trees for a query graph with n nodes is at most n (n 1).
Reference: <author> Stonebraker, M. </author> <year> (1975). </year> <title> Implementation of Integrity Constraints and Views by Query Modification. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 65-78. </pages>
Reference-contexts: A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in <ref> (Stonebraker, 1975) </ref> and (Wallace, 1991). Along the same lines, a transaction modification technique for temporal constraints has been proposed in (Lipeck, 1990), but does not account for implicit updates. A transaction modification method for temporal constraints and implicit updates appears in (Plexousakis, 1994b).
Reference: <author> Stonebraker, M. and Dozier, J. </author> <year> (1991). </year> <title> An Overview of the SEQUOIA 2000 Project. </title> <type> Technical Report SEQUOIA-TR-91/5, </type> <institution> University of California, Berkeley. </institution>
Reference-contexts: boilers, etc.) and their operational characteristics, knowledge about hardwired alarms (what does it mean when alarm 692 goes off) and diagnostic knowledge used by plant operators to determine the nature of an emergency (Mylopoulos et al., 1992); * "grand challenges", such as information system support for environmental global change research <ref> (Stonebraker and Dozier, 1991) </ref> and the human GENOME project (Frenkel, 1991); * knowledge sharing applications that involve construction of generic knowledge bases that include thousands of concept descriptions and are used as references in the construction of knowledge based systems (Neches et al., 1991).
Reference: <author> Topaloglou, T. </author> <year> (1993). </year> <title> Storage Management for Knowledge Bases. </title> <booktitle> In Proceedings of Second International Conference on Information and Knowledge Management (CIKM'93). </booktitle>
Reference-contexts: A token is stored as a tuple in the relation corresponding to the most general class of which the token is an instance. Object identifiers are assigned to each tuple using a hierarchical scheme (see <ref> (Topaloglou, 1993) </ref>). C4. A relation corresponding to a class will have all the local attributes of that class except in the following cases: C4a. <p> Therefore, in Equation 1, the term kl is dropped when computing the storage cost, and a correction cor (N SM ) is applied to take into account the cost of storage of the instances (A more detailed analysis appears elsewhere <ref> (Topaloglou, 1993) </ref>.) With this change, the expression for the storage cost of CDM is as follows: rds (CDM) = (1 d) fl (rds (N SM ) + cor (N SM )) + d fl rds (DSM ) (3) The estimates of space costs suggested by the above formulae confirm the claim <p> These results suggest that CDM requires on average 65% of the required space of DSM. 5 For simplicity, we assume that these sizes are equal. A more general model that does not make this assumption is available elsewhere <ref> (Topaloglou, 1993) </ref>. 9 Table 1: SUMMARY OF UPDATE COSTS update operation NSM DSM CDM insert attribute not supported new binary relation rule C4 insert sub (super)class not supported l + 1 new relations rules C2, C4 insert token (in disk writes) 1 1 + 2n (1 d) + d (1 + <p> The cost in CDM is the weighted sum of the costs of the NSM and DSM models. Experimental results have shown that CDM's cost can be as low as 1/4 of DSM costs <ref> (Topaloglou, 1993) </ref>. 4. Updating the value of an attribute: First, the relevant storage record is located by accessing an index. Then, the block which contains that record is written and the attribute's index is updated. <p> Given an object identifier, RAI determines the location of its components on disk. Due to space limitations, only a brief discussion of STI and TJI is presented here. The interested reader can find more details about the functionality and the performance of the above indices elsewhere <ref> (Topaloglou, 1993) </ref>. 10 The STI and TJI are generalizations of non-temporal indices where, in contrast to the traditional hkey; valuei pair, each entry is a triplet hkey; value; timei, where time is the history time during which the entry is true.
Reference: <author> Topaloglou, T., Illarramendi, A., and Sbattella, L. </author> <year> (1992). </year> <title> Query Optimization for KBMSs: Temporal, Syntactic and Semantic Transformation. </title> <booktitle> In Proceedings of the International Conference on Data Engineering, </booktitle> <pages> pages 310-319. </pages>
Reference-contexts: Finally, we have advanced the semantic transformation techniques by using theory resolution (Stickel, 1985) and specialized reasoners. In the following, we summarize the 12 three steps in semantic optimization. More details can be found elsewhere <ref> (Topaloglou, Illarramendi and Sbattella, 1992) </ref>. 5.1.1 Temporal Simplification Temporal simplification attempts to identify those parts of a knowledge base that are relevant to a query from a temporal viewpoint (Jarke and Koubarakis, 1989). Temporal simplification involves the following three steps: 1. <p> Theory resolution is, in general, more efficient than classical resolution because it decreases the length of refutations and the size of the search space. Finally, our semantic transformation algorithm has been shown to be sound <ref> (Topaloglou, Illarramendi and Sbattella, 1992) </ref>. 5.2 Physical Query Optimization The task of physical query optimizer is to take the simplified query as generated by the semantic optimization phase and generate an optimal execution strategy.
Reference: <author> Valduriez, P. </author> <year> (1987). </year> <title> Join Indices. </title> <journal> ACM Transaction on Database Systems, </journal> <volume> 12(2) </volume> <pages> 218-246. </pages>
Reference-contexts: In this section we propose an algorithm called, Controlled Decomposition Method (CDM), that combines the advantages of both the NSM and DSM and also takes into account temporal knowledge. As far as access methods are concerned, the most promising solution for knowledge bases is the join index <ref> (Valduriez, 1987) </ref>. The join index is used, as part of the data storage, by the DSM. Once again, however, this index cannot be adopted as is because it offers no provisions for dealing with temporal attributes.
Reference: <author> Valduriez, P., Khoshafian, S., and Copeland, G. </author> <year> (1986). </year> <title> Implementation Techniques of Complex Objects. </title> <booktitle> In Proceedings of the 12th International Conference on Very Large Data Bases, </booktitle> <pages> pages 101-109, </pages> <address> Kyoto, Japan. </address>
Reference: <author> Vilain, M., Kautz, H., and van Beek, P. </author> <year> (1989). </year> <title> Constraint Propagation Algorithms for Temporal Reasoning: </title> <note> a Revised Report. In Weld, </note> <editor> D. and de Kleer, J., editors, </editor> <booktitle> Readings in Qualitative Reasoning about Physical Systems, </booktitle> <pages> pages 373-381. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The first step is formulated as a constraint satisfaction problem (CSP) on the temporal relations of the query formula. These relations are interval constraints which belong in the pointsable class and therefore the CSP is solved in polynomial time <ref> (Vilain, Kautz and van Beek, 1989) </ref>.
Reference: <author> Wallace, M. </author> <year> (1991). </year> <title> Compiling Integrity Checking into Update Procedures. </title> <booktitle> In Proceedings of the 12th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 903-908. </pages>
Reference-contexts: A complementary approach, which modifies transactions prior to their execution to ensure knowledge base integrity, is studied in (Stonebraker, 1975) and <ref> (Wallace, 1991) </ref>. Along the same lines, a transaction modification technique for temporal constraints has been proposed in (Lipeck, 1990), but does not account for implicit updates. A transaction modification method for temporal constraints and implicit updates appears in (Plexousakis, 1994b).
Reference: <author> Yannakakis, M. </author> <year> (1982). </year> <title> A Theory of Safe Locking Policies in Database Systems. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 29(3) </volume> <pages> 718-740. </pages>
Reference: <author> Yao, S. </author> <year> (1977). </year> <title> Approximating Block Accesses in Database Organizations. </title> <journal> Communications of ACM, </journal> <volume> 20(4) </volume> <pages> 260-261. </pages>
Reference-contexts: ; j C j) Legend: R C storage relation for class C P qualification predicate selectivity of a predicate I C a index relation for class C, attr. a B storage capacity of a page L C list of OIDs of class C Yao (K; M; N ) Yao's formula <ref> (Yao, 1977) </ref> LP Index pages at leaf level V C;i unique instances of C in the r a avg. number of historical values domain of ith attribute associated with each occurrence of attr. a h tree height of an index tree M R C number of pages for storage relation R
Reference: <author> Zdonik, S. B. and Maier, D., </author> <title> editors (1989). Readings in Object-Oriented Databases. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA. </address> <month> 38 </month>
Reference-contexts: 8 summarizes the results of this work and outlines open problems for further research. 2 Overview of Telos The representational framework of Telos (Mylopoulos et al., 1990) constitutes a generalization of graph-theoretic data structures used in semantic networks (Findler, 1979), semantic data models (Hull and King, 1987) and object-oriented representations <ref> (Zdonik and Maier, 1989) </ref>. Telos treats attributes as first-class citizens, supports a powerful classification (or instantiation) mechanism which enhances extensibility and offers special representational and inferential mechanisms for temporal knowledge.
References-found: 71

