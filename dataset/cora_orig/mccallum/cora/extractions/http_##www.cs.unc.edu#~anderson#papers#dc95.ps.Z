URL: http://www.cs.unc.edu/~anderson/papers/dc95.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Title: A Fast, Scalable Mutual Exclusion Algorithm  
Author: Jae-Heon Yang James H. Anderson 
Keyword: Fast mutual exclusion, local spinning, mutual exclusion, read/write atomicity, scalability, synchronization primitives, time complexity. CR Categories: D.4.1, D.4.2, F.3.1  
Note: Preliminary version was presented at the Twelfth Annual ACM Symposium on Principles of Distributed Computing, Ithaca, New York, August 1993. Work supported, in part, by NSF Contracts CCR-9109497 and CCR-9216421 and by the Center for Excellence in Space Data and Information Sciences (CESDIS).  
Date: October 1993 Revised November 1994  
Address: Mills College Oakland, California 94613  Chapel Hill, North Carolina 27599-3175  
Affiliation: Department of Mathematics and Computer Science  Department of Computer Science The University of North Carolina at Chapel Hill  
Abstract: This paper is concerned with synchronization under read/write atomicity in shared memory multiprocessors. We present a new algorithm for N-process mutual exclusion that requires only read and write operations and that has O(log N) time complexity, where "time" is measured by counting remote memory references. The time complexity of this algorithm is better than that of all prior solutions to the mutual exclusion problem that are based upon atomic read and write instructions; in fact, the time complexity of most prior solutions is unbounded. Performance studies are presented that show that our mutual exclusion algorithm exhibits scalable performance under heavy contention. In fact, its performance rivals that of the fastest queue-based spin locks based on strong primitives such as compare-and-swap and fetch-and-add. We also present a modified version of our algorithm that generates only O(1) memory references in the absence of contention. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal and M. Cherian, </author> <title> "Adaptive Backoff Synchronization Techniques", </title> <booktitle> Proceedings of the 16th International Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1989, </year> <pages> pp. 396-406. </pages>
Reference-contexts: Informally, side (i) = 0 iff process i is a process from the left subtree, and side (i) = 1 iff process i is a process from the right subtree. 4 shared var C : array <ref> [0; 1] </ref> of 1::N 1; P : array [0::N 1] of 0::2; T : 0::N 1 initially C [0] = 1 ^ C [1] = 1 ^ (8i :: P [i] = 0) always (8i : i &lt; bN=2c :: side (i) = 0) ^ (8i : i bN=2c :: side <p> a process from the left subtree, and side (i) = 1 iff process i is a process from the right subtree. 4 shared var C : array [0; 1] of 1::N 1; P : array [0::N 1] of 0::2; T : 0::N 1 initially C [0] = 1 ^ C <ref> [1] </ref> = 1 ^ (8i :: P [i] = 0) always (8i : i &lt; bN=2c :: side (i) = 0) ^ (8i : i bN=2c :: side (i) = 1) process i private var rival : 1::N 1; while true do 0: Noncritical Section; 1: if i &lt; bN=2c then <p> We assume that process identifiers range over f0::N 1g. The algorithm employs shared variables, C [0], C <ref> [1] </ref>, and T , in addition to a spin location P [i] for each process i. Variable C [0] is used by a process from the left subtree to inform processes in the right subtree of its intent to enter its critical section. <p> Observe that C [0] = i 6= 1 holds while a process from the left subtree i executes its statements 5 through 16, and C [0] = 1 holds when no process from the left subtree executes these statements. Variable C <ref> [1] </ref> is used similarly. Variable T is used as a tie-breaker in the event that a process from the left subtree and a process from the right subtree attempt to enter their critical sections at the same time. <p> Then, process i assigns its identifier i to the tie-breaker variable T , and initializes its spin location P [i]. If no process in the right subtree has shown interest in entering its critical section, in other words, if C <ref> [1] </ref> = 1 holds when i executes statement 7, then process i proceeds directly to its critical section. Otherwise, i reads the tie-breaker variable T . <p> The average execution time for the 64 processor case, which is not depicted in Figure 5, is about 330 microseconds. Where there is a possibility of contention among a large number of processors, it should be avoided, or used with good backoff scheme <ref> [1] </ref>. Three algorithms based on atomic reads and writes | Lamport's, Peterson and Fischer's, and Styer's | also showed poor scalability. In particular, the performance of Lamport's algorithm degrades dramatically as the number of contenders increases.
Reference: [2] <author> J. Anderson, </author> <title> "A Fine-Grained Solution to the Mutual Exclusion Problem", </title> <journal> Acta Informatica, </journal> <volume> Vol. 30, No. 3, </volume> <year> 1993, </year> <pages> pp. 249-265. </pages>
Reference-contexts: Alternative definitions of local and remote memory accesses based on cache-coherence are briefly considered in Section 6. In a recent paper <ref> [2] </ref>, Anderson presented a mutual exclusion algorithm that uses only local spins and that 1 requires only atomic read and write operations. In his algorithm, each of N processes executes O (N ) remote operations to enter its critical section whether there is contention or not. <p> Our algorithm induces O (log N ) remote operations under any amount of contention, and thus is an improvement over the algorithm given by Anderson in <ref> [2] </ref>. We also present a modified version of this algorithm, called the "fast-path" algorithm, that requires only O (1) remote operations in the absence of contention. Unfortunately, in the fast-path algorithm, worst-case complexity rises to O (N ).
Reference: [3] <author> T. Anderson, </author> <title> "The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors", </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 1, No. 1, </volume> <month> January, </month> <year> 1990, </year> <pages> pp. 6-16. </pages>
Reference-contexts: Recently, several queue-based mutual exclusion algorithms based on primitives that are stronger than reads and writes have been proposed in which this type of busy-waiting is avoided <ref> [3, 7, 11] </ref>. These algorithms are based on the idea of "local spinning". In particular, processes busy-wait only on locally accessible shared variables that do not require a traversal of the global interconnect when accessed. Performance studies presented in [3, 7, 11] have established the importance of local spinning in ensuring <p> have been proposed in which this type of busy-waiting is avoided <ref> [3, 7, 11] </ref>. These algorithms are based on the idea of "local spinning". In particular, processes busy-wait only on locally accessible shared variables that do not require a traversal of the global interconnect when accessed. Performance studies presented in [3, 7, 11] have established the importance of local spinning in ensuring good performance under heavy contention. Although the notion of a locally accessible shared variable may at first seem counterintuitive, there are two architectural paradigms that support it. <p> It is worth noting that our algorithm and its variation are starvation-free, whereas some of the aforementioned algorithms are not. The results of this paper suggest some interesting questions regarding the inherent complexity of synchronization. The queue-based algorithms in <ref> [3, 7, 11] </ref> require O (1) remote operations, whether there is contention or not (actually the algorithms in [3, 7] have O (1) complexity only if coherent caches are provided), whereas our algorithm requires O (log N ) remote operations. <p> The results of this paper suggest some interesting questions regarding the inherent complexity of synchronization. The queue-based algorithms in [3, 7, 11] require O (1) remote operations, whether there is contention or not (actually the algorithms in <ref> [3, 7] </ref> have O (1) complexity only if coherent caches are provided), whereas our algorithm requires O (log N ) remote operations. <p> The TC2000 has cache memory, but does not provide a cache coherence mechanism. We tested seven mutual exclusion algorithms on the TC2000: a simple test-and-set algorithm; the queue-based algorithm using compare-and-swap given by Mellor-Crummey and Scott in [11]; the queue-based algorithm using fetch-and-add given by T. Anderson in <ref> [3] </ref>; the fast mutual exclusion algorithm given by Lamport in [9]; the tree-based algorithm given by Styer in [14]; the tree-based algorithm given by Peterson and Fischer in [13]; and the mutual exclusion algorithm described in Section 3. <p> Because other strong primitives are not provided, we used a version of Mellor-Crummey and Scott's algorithm that is implemented with fetch-and-store and that does not ensure starvation-freedom [11]. Fetch-and-add, which is used in T. Anderson's algorithm, was simulated by a test-and-set algorithm with randomized backoff, as Anderson did in <ref> [3] </ref>. The experiments on the Symmetry show similar results to that for the TC2000. However, on the Symmetry, T. Anderson's algorithm has the best overall performance, mainly because the availability of coherent 11 12 caches makes all spins in his algorithm local. <p> In one of our tests for the two-process case, one process executed 50,000 critical sections during a period of time in which the other process executed only 120 critical sections. Dependence on coherent caching for efficient synchronization <ref> [3, 7] </ref> is questionable, as many caching schemes do not cache shared writable data. Our solution neither requires a coherent cache for efficient implementation nor any strong primitives.
Reference: [4] <institution> BBN Advanced Computers, Inside the TC2000 Computer, </institution> <month> February, </month> <year> 1990. </year>
Reference-contexts: Each node's processor, a Motorola 88100, provides an atomic fetch-and-store instruction called xmem. Other strong primitives such as compare-and-swap and fetch-and-add are provided using the TC2000 hardware locking protocol <ref> [4] </ref>. The TC2000 has cache memory, but does not provide a cache coherence mechanism. We tested seven mutual exclusion algorithms on the TC2000: a simple test-and-set algorithm; the queue-based algorithm using compare-and-swap given by Mellor-Crummey and Scott in [11]; the queue-based algorithm using fetch-and-add given by T.
Reference: [5] <author> K. Chandy and J. Misra, </author> <title> Parallel Program Design: A Foundation, </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: This assumption is reflective of a distributed shared memory model. We refer to a statement execution as an operation. An operation is remote if it accesses remote variables, and is local otherwise. Following <ref> [5] </ref>, we define safety properties using unless assertions and progress properties using leads-to assertions. Consider two predicates P and Q over the variables of a program. <p> Similarly, ENTRY RIGHT and EXIT RIGHT are used in the right subtree. We depict the algorithm in this way in order to hide the details relating to how variables are named in the arbitration tree. The always section <ref> [5] </ref> in Figure 1 is used to define the expression side (i).
Reference: [6] <author> E. Dijkstra, </author> <title> "Solution of a Problem in Concurrent Programming Control", </title> <journal> Communications of the ACM , Vol. </journal> <volume> 8, No. 9, </volume> <year> 1965, </year> <pages> pp. 569. </pages>
Reference-contexts: 1 Introduction The mutual exclusion problem is a paradigm for resolving conflicting accesses to shared resources and has been studied for many years, dating back to the seminal paper of Dijkstra <ref> [6] </ref>. In this problem, each of a set of processes repeatedly executes a program fragment known as its "critical section". Before and after executing its critical section, a process executes two other program fragments, its "entry section" and "exit section", respectively.
Reference: [7] <author> G. Graunke and S. Thakkar, </author> <title> "Synchronization algorithms for shared-memory multiprocessors", </title> <journal> IEEE Computer, </journal> <volume> Vol. 23, </volume> <month> June, </month> <year> 1990, </year> <pages> pp. 60-69. </pages>
Reference-contexts: Recently, several queue-based mutual exclusion algorithms based on primitives that are stronger than reads and writes have been proposed in which this type of busy-waiting is avoided <ref> [3, 7, 11] </ref>. These algorithms are based on the idea of "local spinning". In particular, processes busy-wait only on locally accessible shared variables that do not require a traversal of the global interconnect when accessed. Performance studies presented in [3, 7, 11] have established the importance of local spinning in ensuring <p> have been proposed in which this type of busy-waiting is avoided <ref> [3, 7, 11] </ref>. These algorithms are based on the idea of "local spinning". In particular, processes busy-wait only on locally accessible shared variables that do not require a traversal of the global interconnect when accessed. Performance studies presented in [3, 7, 11] have established the importance of local spinning in ensuring good performance under heavy contention. Although the notion of a locally accessible shared variable may at first seem counterintuitive, there are two architectural paradigms that support it. <p> It is worth noting that our algorithm and its variation are starvation-free, whereas some of the aforementioned algorithms are not. The results of this paper suggest some interesting questions regarding the inherent complexity of synchronization. The queue-based algorithms in <ref> [3, 7, 11] </ref> require O (1) remote operations, whether there is contention or not (actually the algorithms in [3, 7] have O (1) complexity only if coherent caches are provided), whereas our algorithm requires O (log N ) remote operations. <p> The results of this paper suggest some interesting questions regarding the inherent complexity of synchronization. The queue-based algorithms in [3, 7, 11] require O (1) remote operations, whether there is contention or not (actually the algorithms in <ref> [3, 7] </ref> have O (1) complexity only if coherent caches are provided), whereas our algorithm requires O (log N ) remote operations. <p> In one of our tests for the two-process case, one process executed 50,000 critical sections during a period of time in which the other process executed only 120 critical sections. Dependence on coherent caching for efficient synchronization <ref> [3, 7] </ref> is questionable, as many caching schemes do not cache shared writable data. Our solution neither requires a coherent cache for efficient implementation nor any strong primitives.
Reference: [8] <author> J. Kessels, </author> <title> "Arbitration Without Common Modifiable Variables", </title> <journal> Acta Informatica, </journal> <volume> Vol. 17, </volume> <year> 1982, </year> <pages> pp. 135-141. </pages>
Reference-contexts: Most such algorithms also require O (N ) remote operations in the absence of contention. Some exceptions to the latter include the algorithm given by Kessels in <ref> [8] </ref> and the previously mentioned one given by Lamport in [9]. Kessels' algorithm generates O (log N ) remote operations in the absence of contention, while Lamport's generates O (1). A variant of Lamport's algorithm was recently presented by Styer in [14]. <p> We also require that each process in its exit section eventually enters its noncritical section; this requirement is trivially satisfied by our solution (and most others), so we will not consider it further. As in <ref> [8] </ref>, we first solve the mutual exclusion problem for two processes, and then apply our two-process solution in a binary arbitration tree to get an N -process solution. Our algorithm is depicted in Figure 1. <p> However, in this algorithm, a process that reaches the top of a left subtree checks all leaves of the corresponding right subtree, resulting in O (N ) remote memory references outside of busy-waiting loops. The structure of our arbitration tree is inherited from Kessels's solution in <ref> [8] </ref>, which induces only O (log N ) memory references outside of busy-waiting loops. In Figure 1, our two-process mutual exclusion algorithm (from statement 4 to statement 19) is placed "on top" of two (N=2)-process versions of our algorithm.
Reference: [9] <author> L. Lamport, </author> <title> "A Fast Mutual Exclusion Algorithm", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 5, No. 1, </volume> <month> February, </month> <year> 1987, </year> <pages> pp. 1-11. </pages>
Reference-contexts: Second, even in the absence of contention, such algorithms require a process contending for its critical section to execute many operations. The second of these two problems has been subsequently addressed, specifically by Lamport in <ref> [9] </ref>, where a read/write algorithm is given that requires only a constant number of operations per critical section acquisition in the absence of contention. Following the title of Lamport's paper, such algorithms have come to be known simply as "fast mutual exclusion algorithms". <p> Most such algorithms also require O (N ) remote operations in the absence of contention. Some exceptions to the latter include the algorithm given by Kessels in [8] and the previously mentioned one given by Lamport in <ref> [9] </ref>. Kessels' algorithm generates O (log N ) remote operations in the absence of contention, while Lamport's generates O (1). A variant of Lamport's algorithm was recently presented by Styer in [14]. <p> We tested seven mutual exclusion algorithms on the TC2000: a simple test-and-set algorithm; the queue-based algorithm using compare-and-swap given by Mellor-Crummey and Scott in [11]; the queue-based algorithm using fetch-and-add given by T. Anderson in [3]; the fast mutual exclusion algorithm given by Lamport in <ref> [9] </ref>; the tree-based algorithm given by Styer in [14]; the tree-based algorithm given by Peterson and Fischer in [13]; and the mutual exclusion algorithm described in Section 3. Performance results obtained by running these seven algorithms on the TC2000 are summarized in Figure 5.
Reference: [10] <author> L. Lamport, </author> <title> "How to Write a Proof", </title> <type> Research Report 94, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <month> February, </month> <year> 1993. </year>
Reference-contexts: In the rest of this section, we focus on the proof that the mutual exclusion and starvation-freedom properties hold for the two-process program. Our assertions and proofs are stated in a hierarchical structure proposed by Lamport <ref> [10] </ref>. A sequence of conjunctions (disjunctions) is denoted by putting each conjunct (disjunct), preceded by a ^ (_), in a separate line. In proofs in Lamport's style, an assertion is proven by a series of high-level steps.
Reference: [11] <author> J. Mellor-Crummey and M. Scott, </author> <title> "Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 9, No. 1, </volume> <month> February, </month> <year> 1991, </year> <pages> pp. 21-65. </pages>
Reference-contexts: Recently, several queue-based mutual exclusion algorithms based on primitives that are stronger than reads and writes have been proposed in which this type of busy-waiting is avoided <ref> [3, 7, 11] </ref>. These algorithms are based on the idea of "local spinning". In particular, processes busy-wait only on locally accessible shared variables that do not require a traversal of the global interconnect when accessed. Performance studies presented in [3, 7, 11] have established the importance of local spinning in ensuring <p> have been proposed in which this type of busy-waiting is avoided <ref> [3, 7, 11] </ref>. These algorithms are based on the idea of "local spinning". In particular, processes busy-wait only on locally accessible shared variables that do not require a traversal of the global interconnect when accessed. Performance studies presented in [3, 7, 11] have established the importance of local spinning in ensuring good performance under heavy contention. Although the notion of a locally accessible shared variable may at first seem counterintuitive, there are two architectural paradigms that support it. <p> It is worth noting that our algorithm and its variation are starvation-free, whereas some of the aforementioned algorithms are not. The results of this paper suggest some interesting questions regarding the inherent complexity of synchronization. The queue-based algorithms in <ref> [3, 7, 11] </ref> require O (1) remote operations, whether there is contention or not (actually the algorithms in [3, 7] have O (1) complexity only if coherent caches are provided), whereas our algorithm requires O (log N ) remote operations. <p> The TC2000 has cache memory, but does not provide a cache coherence mechanism. We tested seven mutual exclusion algorithms on the TC2000: a simple test-and-set algorithm; the queue-based algorithm using compare-and-swap given by Mellor-Crummey and Scott in <ref> [11] </ref>; the queue-based algorithm using fetch-and-add given by T. Anderson in [3]; the fast mutual exclusion algorithm given by Lamport in [9]; the tree-based algorithm given by Styer in [14]; the tree-based algorithm given by Peterson and Fischer in [13]; and the mutual exclusion algorithm described in Section 3. <p> The graph depicted for the MCS algorithm is mostly flat, except at the point for two processors. This anomaly at two processors coincides with results reported by Mellor-Crummey and Scott on the Sequent Symmetry, and was attributed by them to the lack of a compare-and-swap instruction on the Symmetry <ref> [11] </ref>. As our implementation of their algorithm did employ compare-and-swap, we have not found a satisfying explanation for this behavior on the TC2000. T. Anderson's algorithm requires only local spinning when implemented on a machine with coherent caches. <p> Anderson's algorithm is far better than that of the simple test-and-set algorithm. Because the processes in Anderson's algorithm spin globally on the TC2000, this might be interpreted as a counterexample to our belief that minimizing remote operations is important for good scalability. However, Mellor-Crummey and Scott reported in <ref> [11] </ref> that Anderson's algorithm produced far fewer remote operations than the test-and-set algorithm. Sequent Symmetry Performance results of experiments on the Sequent Symmetry are summarized in Figure 5. The Sequent Symmetry is a shared memory multiprocessor whose processor and memory nodes are interconnected via a shared bus. <p> Cache coherence is maintained by a snoopy protocol. The Symmetry provides an atomic fetch-and-store instruction. Because other strong primitives are not provided, we used a version of Mellor-Crummey and Scott's algorithm that is implemented with fetch-and-store and that does not ensure starvation-freedom <ref> [11] </ref>. Fetch-and-add, which is used in T. Anderson's algorithm, was simulated by a test-and-set algorithm with randomized backoff, as Anderson did in [3]. The experiments on the Symmetry show similar results to that for the TC2000. However, on the Symmetry, T.
Reference: [12] <author> M. Michael and M. Scott, </author> <title> "Fast Mutual Exclusion, Even With Contention", </title> <type> Technical Report, </type> <institution> University of Rochester, </institution> <month> June, </month> <year> 1993. </year>
Reference-contexts: Because the processes in his algorithm busy-wait on remote variables, such complexity calculations do not give a true indication of scalability. Another recent algorithm of interest is one given by Michael and Scott in <ref> [12] </ref>. Although this algorithm generates O (N ) remote memory references in the presence of contention and O (1) in the absence of contention, it requires both full- and half-word reads and writes to memory, which is a level of hardware support more powerful than ordinary read/write atomicity.
Reference: [13] <author> G. Peterson and M. Fischer, </author> <title> "Economical Solutions for the Critical Section Problem in a Distributed System", </title> <booktitle> Proceedings of the 9th ACM Symposium on Theory of Computing , May, </booktitle> <year> 1977, </year> <pages> pp. 91-97. </pages>
Reference-contexts: Upon exiting its critical section, a process traverses this path in reverse, this time executing the exit section of each link. The first mutual exclusion algorithm that used a binary arbitration tree is that given by Peterson and Fischer in <ref> [13] </ref>. However, in this algorithm, a process that reaches the top of a left subtree checks all leaves of the corresponding right subtree, resulting in O (N ) remote memory references outside of busy-waiting loops. <p> Anderson in [3]; the fast mutual exclusion algorithm given by Lamport in [9]; the tree-based algorithm given by Styer in [14]; the tree-based algorithm given by Peterson and Fischer in <ref> [13] </ref>; and the mutual exclusion algorithm described in Section 3. Performance results obtained by running these seven algorithms on the TC2000 are summarized in Figure 5. Each point (x; y) in each graph represents the average time y for one critical section execution with x competing processors.
Reference: [14] <author> E. Styer, </author> <title> "Improving Fast Mutual Exclusion", </title> <booktitle> Proceedings of the Eleventh Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1992, </year> <pages> pp. 159-168. </pages>
Reference-contexts: Kessels' algorithm generates O (log N ) remote operations in the absence of contention, while Lamport's generates O (1). A variant of Lamport's algorithm was recently presented by Styer in <ref> [14] </ref>. Although Styer claims that his algorithm is more scalable than Lamport's, in terms of time complexity, they are actually very similar: both generate unbounded remote operations under heavy contention and O (1) operations in the absence of contention. <p> Anderson in [3]; the fast mutual exclusion algorithm given by Lamport in [9]; the tree-based algorithm given by Styer in <ref> [14] </ref>; the tree-based algorithm given by Peterson and Fischer in [13]; and the mutual exclusion algorithm described in Section 3. Performance results obtained by running these seven algorithms on the TC2000 are summarized in Figure 5.
Reference: [15] <author> J. Yang and J. Anderson, </author> <title> "Fast, Scalable Synchronization with Minimal Hardware Support (Extended Abstract)", </title> <booktitle> Proceedings of the 12th Annual ACM Symposium on Principles of Distributed Computing , August, </booktitle> <year> 1993, </year> <pages> pp. 171-182. </pages>
Reference: [16] <author> J. Yang and J. Anderson, </author> <title> "Time Bounds for Mutual Exclusion and Related Problems", </title> <booktitle> Proceedings of the 26th Annual ACM Symposium on Theory of Computing , May, </booktitle> <year> 1994, </year> <pages> pp. 224-233. 45 </pages>
Reference-contexts: A significant step towards answering this question was recently presented by us in <ref> [16] </ref>. This new result involves programs with limited "write-contention". The write-contention of a concurrent program is the number of processes that may be simultaneously enabled to write the same shared variable. It is shown in [16] that for any N -process mutual exclusion algorithm with write-contention K, there is an execution <p> A significant step towards answering this question was recently presented by us in <ref> [16] </ref>. This new result involves programs with limited "write-contention". The write-contention of a concurrent program is the number of processes that may be simultaneously enabled to write the same shared variable. It is shown in [16] that for any N -process mutual exclusion algorithm with write-contention K, there is an execution involving only one process in which that process executes at least (log K N ) remote memory references in its entry section. <p> Our mutual exclusion algorithm is contained within the class of algorithms based on such primitives that have constant write-contention. Hence, our algorithm is asymptotically optimal for this class. The execution that establishes the (log K N ) lower bound in <ref> [16] </ref> involves only one process, implying that fast mutual exclusion requires high write-contention (i.e., K must approach N ). All fast mutual exclusion algorithms for N processes presented to date (including the fast-path algorithm presented in this paper) have write-contention N . <p> All fast mutual exclusion algorithms for N processes presented to date (including the fast-path algorithm presented in this paper) have write-contention N . Despite the significance of the lower bound proved in <ref> [16] </ref>, we still do not know whether the apparent 2 gap between mutual exclusion using reads and writes and mutual exclusion using stronger primitives is fundamental.
References-found: 16

