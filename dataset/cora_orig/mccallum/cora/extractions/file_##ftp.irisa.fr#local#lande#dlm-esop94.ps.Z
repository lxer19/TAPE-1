URL: file://ftp.irisa.fr/local/lande/dlm-esop94.ps.Z
Refering-URL: http://www.irisa.fr/lande/LeMetayer.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: clh@doc.ic.ac.uk  e-mail: lemetayer@irisa.fr  
Title: Lazy type inference for the strictness analysis of lists  
Author: Chris Hankin Daniel Le Metayer INRIA/IRISA 
Address: LONDON SW7 2BZ, UK  35042 RENNES CEDEX, FRANCE  
Affiliation: Department of Computing, Imperial College,  Campus de Beaulieu  
Abstract: We present a type inference system for the strictness analysis of lists and we show that it can be used as the basis for an efficient algorithm. The algorithm is as accurate as the usual abstract interpretation technique. One distinctive advantage of this approach is that it is not necessary to impose an abstract domain of a particular depth prior to the analysis: the lazy type algorithm will instead explore the part of a potentially infinite domain required to prove the strictness property.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. van Bakel, </author> <title> Complete restrictions of the intersection type discipline, </title> <journal> Theoretical Computer Science, </journal> <volume> 102(1) </volume> <pages> 135-163, </pages> <year> 1992. </year>
Reference-contexts: t !t t ! t t 1 ^ 2 ! 1 ^ ! 2 ! ( 1 ^ 2 ) ! 0 ! 0 3 Lazy Types We introduce a slightly restricted language of strictness formulae T I (Fig. 3); this language is closely related to van Bakel's strict types <ref> [1] </ref>. <p> First we show that the weakening rule can be removed from ` T without changing the set of derivable types provided we add a form of weakening in the Var and Fix rules. A similar property has been proved for other type systems including a form of weakening <ref> [1, 22] </ref>. <p> x : 2 [x 7! ] ` G e : Taut ` G c : t App ` G e 1 : ((; e 2 ) ! ) Fix n ^ i ! 1 ) ^ . . . ^ ( i=1 ` G fix (g:e) : k (k 2 <ref> [1; n] </ref>) Cond-1 ` G e 1 : f ` G cond (e 1 ; e 2 ; e 3 ) : Cond-2 ` G e 2 : ` G e 3 : ` G cond (e 1 ; e 2 ; e 3 ) : Hd ` T hd (e)
Reference: [2] <author> P. N. Benton, </author> <title> Strictness logic and polymorphic invariance, </title> <booktitle> in Proceedings of the 2nd Int. Symposium on Logical Foundations of Computer Science, </booktitle> <publisher> LNCS 620, Springer Verlag, </publisher> <year> 1992. </year> <month> 18 </month>
Reference-contexts: Techniques striving for a better representation of the domains do not really solve the problem [12, 17]. This observation has motivated some researchers, <ref> [2, 18, 19, 20] </ref>, to develop non-standard type inference systems for strictness analysis. Kuo and Mishra, [20], proposed a type inference system for strictness information; they developed a sound and complete inference algorithm but did not show the correctness of the inference system (with respect to a standard semantics). <p> In [21] it is shown how their type inference system can be extended to a form of full strictness for lists and to the 4-point domain of Wadler [25]. The other authors, <ref> [2, 18, 19] </ref>, have developed sound and complete inference systems but have not given much attention to algorithms. In [13] we demonstrated a technique for deriving efficient static analysis algorithms from type inference systems.
Reference: [3] <author> P. N. Benton, </author> <title> Strictness Properties of Lazy Algebraic Datatypes, </title> <booktitle> in Proceedings WSA'93, </booktitle> <publisher> LNCS 724, Springer Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Wadler's domain construction does not readily generalise to other recursive data types. Recently Benton <ref> [3] </ref> has shown how to construct an abstract domain from any algebraic data type. It should be straightforward to extend our system (and algorithm) to incorporate such domains.
Reference: [4] <author> G. L. Burn, </author> <title> Evaluation Transformers a model for the parallel evaluation of functional languages (extended abstract), </title> <booktitle> in Proceedings of the 1987 Conference on Functional Programming Languages and Computer Architecture, </booktitle> <publisher> LNCS 274, Springer Verlag, </publisher> <year> 1987. </year>
Reference-contexts: There have been a number of proposals to extend strictness analysis to recursively defined data structures <ref> [4, 21, 25, 26] </ref>. These have led to sophisticated analyses but two aspects of the problem have received little attention until recently: 1. The integration of the results of the analysis into a real compiler. 2. The efficiency of the algorithm implementing the analysis.
Reference: [5] <author> G. Burn and D. Le Metayer, </author> <title> Proving the correctness of compiler op-timisations based on strictness analysis, </title> <booktitle> in Proceedings 5th int. Symp. on Programming Language Implementation and Logic Programming, </booktitle> <publisher> LNCS 714, Springer Verlag, </publisher> <year> 1993. </year>
Reference-contexts: The integration of the results of the analysis into a real compiler. 2. The efficiency of the algorithm implementing the analysis. The first issue has been tackled recently both from an experimental point of view [11, 16] and from a theoretical point of view <ref> [5, 8] </ref>. We are concerned with the second issue in this paper. The abstract interpretation and the projections approaches have led to the construction of analyses based on rich domains which make them intractable even for some simple examples.
Reference: [6] <author> T.-R. Chuang and B. Goldberg, </author> <title> A syntactic approach to fixed point computation on finite domains, </title> <booktitle> in Proceedings of the 1992 ACM Conference on Lisp and Functional Programming, </booktitle> <publisher> ACM Press, </publisher> <year> 1992. </year>
Reference-contexts: reader can easily verify (the structure of the proof is very similar to the previous one). 7 Conclusions The problem of designing efficient algorithms for strictness analysis has received much attention recently and one current trend seems to revert from the usual "extensional" approach to more "intensional" or syntactic techniques <ref> [20, 21, 18, 6, 10, 24] </ref>. The key observation underlying these works is that the choice of representing abstract functions by functions can be disastrous in terms of efficiency and is not always justified in terms of accuracy.
Reference: [7] <author> P. Cousot and R. Cousot, </author> <title> Comparing the Galois Connection and Widening/Narrowing Approaches to Abstract Interpretation, </title> <editor> in M. Bruynooghe and M. Wirsing (eds), PLILP'92, </editor> <publisher> LNCS 631, Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: In other words, we do not have to choose a particular domain before the analysis as is usually done for abstract interpretation (except when widening operators are used as in <ref> [7] </ref>). We first describe an extension of Jensen's strictness logic [18] to include an analogue of Wadler's 4-point domain [25] (Section 2). In Section 3, we introduce the notion of lazy types for lists and we present the corresponding system.
Reference: [8] <author> O. Danvy and J. Hatcliff, </author> <title> CPS transformation after strictness analysis, </title> <type> Technical Report, </type> <institution> Kansas State University, </institution> <note> to appear in ACM LOPLAS. </note>
Reference-contexts: The integration of the results of the analysis into a real compiler. 2. The efficiency of the algorithm implementing the analysis. The first issue has been tackled recently both from an experimental point of view [11, 16] and from a theoretical point of view <ref> [5, 8] </ref>. We are concerned with the second issue in this paper. The abstract interpretation and the projections approaches have led to the construction of analyses based on rich domains which make them intractable even for some simple examples.
Reference: [9] <author> M. van Eekelen, E. Goubault, C. Hankin and E. N tker, </author> <title> Abstract reduction: a theory via abstract interpretation, </title> <editor> in R. Sleep et al (eds), </editor> <title> Term graph rewriting: theory and practice, </title> <publisher> John Wiley & Sons Ltd, </publisher> <year> 1992. </year>
Reference-contexts: Because of this parametrisable termination condition, it is difficult to formally qualify the power of abstract graph reduction. Another advantage of the lazy types approach is the fact that its correctness proof is much easier to establish (see <ref> [9] </ref> for an introduction to the complications involved by a formalisation of abstract graph reduction).
Reference: [10] <author> A. Ferguson and R. J. M. Hughes, </author> <title> Fast abstract interpretation using sequential algorithms, </title> <booktitle> in Proceedings WSA'93, </booktitle> <publisher> LNCS 724, Springer Verlag, </publisher> <year> 1993. </year>
Reference-contexts: reader can easily verify (the structure of the proof is very similar to the previous one). 7 Conclusions The problem of designing efficient algorithms for strictness analysis has received much attention recently and one current trend seems to revert from the usual "extensional" approach to more "intensional" or syntactic techniques <ref> [20, 21, 18, 6, 10, 24] </ref>. The key observation underlying these works is that the choice of representing abstract functions by functions can be disastrous in terms of efficiency and is not always justified in terms of accuracy. <p> Some of these proposals trade a cheaper implementation against a loss of accuracy [20, 21]. The work presented here is more amenable to comparison with two techniques proposed recently <ref> [10, 24] </ref> which use extensional representations of functions to build very efficient algorithms without sacrificing accuracy. Here we will concentrate on the comparison with the [24]. <p> The work presented here is more amenable to comparison with two techniques proposed recently [10, 24] which use extensional representations of functions to build very efficient algorithms without sacrificing accuracy. Here we will concentrate on the comparison with the [24]. The analysis of <ref> [10] </ref> is expressed in a very different framework: concrete data structures are special kinds of Scott domains whose elements can be seen as syntax trees; a precise statement of the relationship with lazy types is still a matter for further research.
Reference: [11] <author> S. Finne and G. Burn, </author> <title> Assessing the evaluation transformer model of reduction on the spineless G-machine, </title> <booktitle> in Proceedings of the 6th ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <publisher> ACM Press, </publisher> <year> 1993, </year> <pages> pp. 331-341. </pages>
Reference-contexts: The integration of the results of the analysis into a real compiler. 2. The efficiency of the algorithm implementing the analysis. The first issue has been tackled recently both from an experimental point of view <ref> [11, 16] </ref> and from a theoretical point of view [5, 8]. We are concerned with the second issue in this paper. The abstract interpretation and the projections approaches have led to the construction of analyses based on rich domains which make them intractable even for some simple examples.
Reference: [12] <author> C. L. Hankin and L. S. Hunt, </author> <title> Approximate fixed points in abstract interpretation, </title> <editor> in B. Krieg-Bruckner (ed), </editor> <booktitle> Proceedings of the 4th Eu-ropean Symposium on Programming, </booktitle> <publisher> LNCS 582, Springer Verlag, </publisher> <year> 1992. </year> <month> 19 </month>
Reference-contexts: The abstract interpretation and the projections approaches have led to the construction of analyses based on rich domains which make them intractable even for some simple examples. Techniques striving for a better representation of the domains do not really solve the problem <ref> [12, 17] </ref>. This observation has motivated some researchers, [2, 18, 19, 20], to develop non-standard type inference systems for strictness analysis.
Reference: [13] <author> C. L. Hankin and D. Le Metayer, </author> <title> Deriving algorithms from type in-ference systems: Application to strictness analysis, </title> <note> to appear in Proceedings of POPL'94, ACM Press, </note> <year> 1994. </year>
Reference-contexts: The other authors, [2, 18, 19], have developed sound and complete inference systems but have not given much attention to algorithms. In <ref> [13] </ref> we demonstrated a technique for deriving efficient static analysis algorithms from type inference systems. The basis for this work was Jensen's conjunctive strictness logic [18]; we used techniques similar to [14, 15] to refine the logic into an algorithm. 2 In this paper, we follow the approach taken in [13] <p> <ref> [13] </ref> we demonstrated a technique for deriving efficient static analysis algorithms from type inference systems. The basis for this work was Jensen's conjunctive strictness logic [18]; we used techniques similar to [14, 15] to refine the logic into an algorithm. 2 In this paper, we follow the approach taken in [13] to construct an effi-cient algorithm for the analysis of lists. The algorithm is both correct and complete with respect to the usual abstract interpretation approach. So it does not incur the loss of accuracy of previous type inference systems for the analysis of lists [21]. <p> We state the correctness and completeness properties with respect to the original system and we proceed in Section 4 to define the lazy type inference algorithm. The algorithm can in fact be derived in the same way as in <ref> [13] </ref> and the correctness proof follows for the same reasons. Section 5 is an example of the functioning of the algorithm. <p> In the rule Cond-1, represents the standard type of e 2 (or e 3 ). This system is an extension of <ref> [13, 18] </ref> and the soundness and completeness proofs of the logic (with respect to traditional abstract interpretation) follow straightforwardly from [19]. <p> Definition 3.2 (Most General Types) M GT (; e) = CT ( f i 2 T S j ` T e : i g) We show in <ref> [13] </ref> that the most general type of an expression is precisely the information returned by the standard abstract interpretation-based analysis. <p> 3.8 and proceed by induction on e to prove completeness. nil 2 env [x 7! ] 2 env S S S (; e) 2 T G S . . . n 2 T 0 1 ^ . . . ^ n 2 T G 4 The lazy types algorithm In <ref> [13] </ref>, we show how to derive an abstract machine from the basic lazy types system.
Reference: [14] <author> J. J. Hannan, </author> <title> Investigating a proof-theoretic meta-language, </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <type> DIKU Technical Report Nr 91/1, </type> <year> 1991. </year>
Reference-contexts: In [13] we demonstrated a technique for deriving efficient static analysis algorithms from type inference systems. The basis for this work was Jensen's conjunctive strictness logic [18]; we used techniques similar to <ref> [14, 15] </ref> to refine the logic into an algorithm. 2 In this paper, we follow the approach taken in [13] to construct an effi-cient algorithm for the analysis of lists. The algorithm is both correct and complete with respect to the usual abstract interpretation approach.
Reference: [15] <author> J. Hannan and D. Miller, </author> <title> From Operational Semantics to Abstract Machines, </title> <booktitle> Mathematical Structures in Computer Science, </booktitle> <volume> 2(4), </volume> <year> 1992. </year>
Reference-contexts: In [13] we demonstrated a technique for deriving efficient static analysis algorithms from type inference systems. The basis for this work was Jensen's conjunctive strictness logic [18]; we used techniques similar to <ref> [14, 15] </ref> to refine the logic into an algorithm. 2 In this paper, we follow the approach taken in [13] to construct an effi-cient algorithm for the analysis of lists. The algorithm is both correct and complete with respect to the usual abstract interpretation approach.
Reference: [16] <author> P. H. Hartel and K. G. Langendoen, </author> <title> Benchmarking implementations of lazy functional languages, </title> <booktitle> in Proceedings of the 6th ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <publisher> ACM Press, </publisher> <year> 1993, </year> <pages> pp. 341-350. </pages>
Reference-contexts: The integration of the results of the analysis into a real compiler. 2. The efficiency of the algorithm implementing the analysis. The first issue has been tackled recently both from an experimental point of view <ref> [11, 16] </ref> and from a theoretical point of view [5, 8]. We are concerned with the second issue in this paper. The abstract interpretation and the projections approaches have led to the construction of analyses based on rich domains which make them intractable even for some simple examples.
Reference: [17] <author> L. S. Hunt and C. L. Hankin, </author> <title> Fixed Points and Frontiers: A New Perspective, </title> <journal> Journal of Functional Programming, </journal> <volume> 1(1), </volume> <year> 1991. </year>
Reference-contexts: The abstract interpretation and the projections approaches have led to the construction of analyses based on rich domains which make them intractable even for some simple examples. Techniques striving for a better representation of the domains do not really solve the problem <ref> [12, 17] </ref>. This observation has motivated some researchers, [2, 18, 19, 20], to develop non-standard type inference systems for strictness analysis. <p> easy to justify formally and improve the derivation considerably. 5 Example We consider the following functions: f oldr b g nil = b f oldr b g cons (x; xs) = g x (f oldr b g xs) cat l = f oldr nil append l which was introduced in <ref> [17] </ref> to demonstrate the inefficiency of traditional abstract interpretation.
Reference: [18] <author> T. P. Jensen, </author> <title> Strictness Analysis in Logical Form, </title> <editor> in J. Hughes (ed), </editor> <booktitle> Proceedings of the 5th ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <publisher> LNCS 523, Springer Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Techniques striving for a better representation of the domains do not really solve the problem [12, 17]. This observation has motivated some researchers, <ref> [2, 18, 19, 20] </ref>, to develop non-standard type inference systems for strictness analysis. Kuo and Mishra, [20], proposed a type inference system for strictness information; they developed a sound and complete inference algorithm but did not show the correctness of the inference system (with respect to a standard semantics). <p> In [21] it is shown how their type inference system can be extended to a form of full strictness for lists and to the 4-point domain of Wadler [25]. The other authors, <ref> [2, 18, 19] </ref>, have developed sound and complete inference systems but have not given much attention to algorithms. In [13] we demonstrated a technique for deriving efficient static analysis algorithms from type inference systems. <p> The other authors, [2, 18, 19], have developed sound and complete inference systems but have not given much attention to algorithms. In [13] we demonstrated a technique for deriving efficient static analysis algorithms from type inference systems. The basis for this work was Jensen's conjunctive strictness logic <ref> [18] </ref>; we used techniques similar to [14, 15] to refine the logic into an algorithm. 2 In this paper, we follow the approach taken in [13] to construct an effi-cient algorithm for the analysis of lists. <p> In other words, we do not have to choose a particular domain before the analysis as is usually done for abstract interpretation (except when widening operators are used as in [7]). We first describe an extension of Jensen's strictness logic <ref> [18] </ref> to include an analogue of Wadler's 4-point domain [25] (Section 2). In Section 3, we introduce the notion of lazy types for lists and we present the corresponding system. <p> In the rule Cond-1, represents the standard type of e 2 (or e 3 ). This system is an extension of <ref> [13, 18] </ref> and the soundness and completeness proofs of the logic (with respect to traditional abstract interpretation) follow straightforwardly from [19]. <p> reader can easily verify (the structure of the proof is very similar to the previous one). 7 Conclusions The problem of designing efficient algorithms for strictness analysis has received much attention recently and one current trend seems to revert from the usual "extensional" approach to more "intensional" or syntactic techniques <ref> [20, 21, 18, 6, 10, 24] </ref>. The key observation underlying these works is that the choice of representing abstract functions by functions can be disastrous in terms of efficiency and is not always justified in terms of accuracy.
Reference: [19] <author> T. P. Jensen, </author> <title> Abstract Interpretation in Logical Form, </title> <type> PhD thesis, </type> <institution> University of London, </institution> <year> 1992. </year> <note> Also available as DIKU Technical Report 93/11. </note>
Reference-contexts: Techniques striving for a better representation of the domains do not really solve the problem [12, 17]. This observation has motivated some researchers, <ref> [2, 18, 19, 20] </ref>, to develop non-standard type inference systems for strictness analysis. Kuo and Mishra, [20], proposed a type inference system for strictness information; they developed a sound and complete inference algorithm but did not show the correctness of the inference system (with respect to a standard semantics). <p> In [21] it is shown how their type inference system can be extended to a form of full strictness for lists and to the 4-point domain of Wadler [25]. The other authors, <ref> [2, 18, 19] </ref>, have developed sound and complete inference systems but have not given much attention to algorithms. In [13] we demonstrated a technique for deriving efficient static analysis algorithms from type inference systems. <p> In the rule Cond-1, represents the standard type of e 2 (or e 3 ). This system is an extension of [13, 18] and the soundness and completeness proofs of the logic (with respect to traditional abstract interpretation) follow straightforwardly from <ref> [19] </ref>. <p> It should be straightforward to extend our system (and algorithm) to incorporate such domains. Benton's construction leads to quite large domains; the size of the domains would make conventional abstract interpretation intractable and highlights the benefit of our approach which lazily explores the domain. In his thesis Jensen, <ref> [19] </ref>, has developed a more general logical treatment of recursive types. His approach involves two extensions to the logic; the first is to add disjunctions and the second extension involves adding modal operators for describing uniform properties of elements of recursive types.
Reference: [20] <author> T.-M. Kuo and P. Mishra, </author> <title> Strictness analysis: a new perspective based on type inference, </title> <booktitle> in Proceedings of the 4th ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: Techniques striving for a better representation of the domains do not really solve the problem [12, 17]. This observation has motivated some researchers, <ref> [2, 18, 19, 20] </ref>, to develop non-standard type inference systems for strictness analysis. Kuo and Mishra, [20], proposed a type inference system for strictness information; they developed a sound and complete inference algorithm but did not show the correctness of the inference system (with respect to a standard semantics). <p> Techniques striving for a better representation of the domains do not really solve the problem [12, 17]. This observation has motivated some researchers, [2, 18, 19, 20], to develop non-standard type inference systems for strictness analysis. Kuo and Mishra, <ref> [20] </ref>, proposed a type inference system for strictness information; they developed a sound and complete inference algorithm but did not show the correctness of the inference system (with respect to a standard semantics). <p> reader can easily verify (the structure of the proof is very similar to the previous one). 7 Conclusions The problem of designing efficient algorithms for strictness analysis has received much attention recently and one current trend seems to revert from the usual "extensional" approach to more "intensional" or syntactic techniques <ref> [20, 21, 18, 6, 10, 24] </ref>. The key observation underlying these works is that the choice of representing abstract functions by functions can be disastrous in terms of efficiency and is not always justified in terms of accuracy. <p> The key observation underlying these works is that the choice of representing abstract functions by functions can be disastrous in terms of efficiency and is not always justified in terms of accuracy. Some of these proposals trade a cheaper implementation against a loss of accuracy <ref> [20, 21] </ref>. The work presented here is more amenable to comparison with two techniques proposed recently [10, 24] which use extensional representations of functions to build very efficient algorithms without sacrificing accuracy. Here we will concentrate on the comparison with the [24].
Reference: [21] <author> A. Leung and P. Mishra, </author> <title> Reasoning about simple and exhaustive demand in higher-order lazy languages, </title> <booktitle> in Proceedings of the 5th ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <publisher> LNCS 523, Springer Verlag, </publisher> <year> 1991. </year>
Reference-contexts: There have been a number of proposals to extend strictness analysis to recursively defined data structures <ref> [4, 21, 25, 26] </ref>. These have led to sophisticated analyses but two aspects of the problem have received little attention until recently: 1. The integration of the results of the analysis into a real compiler. 2. The efficiency of the algorithm implementing the analysis. <p> Kuo and Mishra, [20], proposed a type inference system for strictness information; they developed a sound and complete inference algorithm but did not show the correctness of the inference system (with respect to a standard semantics). In <ref> [21] </ref> it is shown how their type inference system can be extended to a form of full strictness for lists and to the 4-point domain of Wadler [25]. The other authors, [2, 18, 19], have developed sound and complete inference systems but have not given much attention to algorithms. <p> The algorithm is both correct and complete with respect to the usual abstract interpretation approach. So it does not incur the loss of accuracy of previous type inference systems for the analysis of lists <ref> [21] </ref>. The core of the algorithm is the notion of lazy types (or lazily evaluated types) which allows us to compute only the information required to answer a particular question about the strictness of a function. <p> reader can easily verify (the structure of the proof is very similar to the previous one). 7 Conclusions The problem of designing efficient algorithms for strictness analysis has received much attention recently and one current trend seems to revert from the usual "extensional" approach to more "intensional" or syntactic techniques <ref> [20, 21, 18, 6, 10, 24] </ref>. The key observation underlying these works is that the choice of representing abstract functions by functions can be disastrous in terms of efficiency and is not always justified in terms of accuracy. <p> The key observation underlying these works is that the choice of representing abstract functions by functions can be disastrous in terms of efficiency and is not always justified in terms of accuracy. Some of these proposals trade a cheaper implementation against a loss of accuracy <ref> [20, 21] </ref>. The work presented here is more amenable to comparison with two techniques proposed recently [10, 24] which use extensional representations of functions to build very efficient algorithms without sacrificing accuracy. Here we will concentrate on the comparison with the [24].
Reference: [22] <author> J. C. Mitchell, </author> <title> Type inference with simple subtypes, </title> <journal> Journal of Functional Programming, </journal> <volume> 1(3), </volume> <year> 1991. </year>
Reference-contexts: First we show that the weakening rule can be removed from ` T without changing the set of derivable types provided we add a form of weakening in the Var and Fix rules. A similar property has been proved for other type systems including a form of weakening <ref> [1, 22] </ref>.
Reference: [23] <author> A. Mycroft, </author> <title> Abstract Interpretation and Optimising Transformations for Applicative Programs, </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <month> De-cember </month> <year> 1981. </year> <month> 20 </month>
Reference-contexts: Abstract interpretation represents the strictness properties of a function by an abstract function defined on boolean domains <ref> [23] </ref>. For instance g abs t f = f means that g is undefined if its second argument is undefined. In terms of types, this property is represented by g : t ! f ! f . Notice that t and f are now (non-standard) types.
Reference: [24] <author> E. Nocker, </author> <title> Strictness analysis using abstract reduction, </title> <booktitle> in Proceedings of the 6th ACM Conference on Functional Programming Languages and Computer Architecture, </booktitle> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: reader can easily verify (the structure of the proof is very similar to the previous one). 7 Conclusions The problem of designing efficient algorithms for strictness analysis has received much attention recently and one current trend seems to revert from the usual "extensional" approach to more "intensional" or syntactic techniques <ref> [20, 21, 18, 6, 10, 24] </ref>. The key observation underlying these works is that the choice of representing abstract functions by functions can be disastrous in terms of efficiency and is not always justified in terms of accuracy. <p> Some of these proposals trade a cheaper implementation against a loss of accuracy [20, 21]. The work presented here is more amenable to comparison with two techniques proposed recently <ref> [10, 24] </ref> which use extensional representations of functions to build very efficient algorithms without sacrificing accuracy. Here we will concentrate on the comparison with the [24]. <p> The work presented here is more amenable to comparison with two techniques proposed recently [10, 24] which use extensional representations of functions to build very efficient algorithms without sacrificing accuracy. Here we will concentrate on the comparison with the <ref> [24] </ref>. The analysis of [10] is expressed in a very different framework: concrete data structures are special kinds of Scott domains whose elements can be seen as syntax trees; a precise statement of the relationship with lazy types is still a matter for further research. In [24] the analysis is expressed <p> the comparison with the <ref> [24] </ref>. The analysis of [10] is expressed in a very different framework: concrete data structures are special kinds of Scott domains whose elements can be seen as syntax trees; a precise statement of the relationship with lazy types is still a matter for further research. In [24] the analysis is expressed as a form of reduction of abstract graphs. As in our work, the abstract domain is infinite and computation is done lazily. There are important differences however. Their derivation strategy is even more lazy than ours in the following sense. <p> These extra measures can take the form of arbitrary cuts in the derivation (using empirical resource consumption criteria) incurring a loss of accuracy. A neededness analysis called reduction path analysis is also proposed in <ref> [24] </ref> to allow termination of the computation without throwing away too much information. Because of this parametrisable termination condition, it is difficult to formally qualify the power of abstract graph reduction.
Reference: [25] <author> P. Wadler, </author> <title> Strictness Analysis on Non-flat Domains, </title> <editor> in S. Abramsky and C. L. Hankin (eds), </editor> <title> Abstract Interpretation of Declarative Languages, </title> <publisher> Ellis Horwood, </publisher> <year> 1987. </year>
Reference-contexts: There have been a number of proposals to extend strictness analysis to recursively defined data structures <ref> [4, 21, 25, 26] </ref>. These have led to sophisticated analyses but two aspects of the problem have received little attention until recently: 1. The integration of the results of the analysis into a real compiler. 2. The efficiency of the algorithm implementing the analysis. <p> In [21] it is shown how their type inference system can be extended to a form of full strictness for lists and to the 4-point domain of Wadler <ref> [25] </ref>. The other authors, [2, 18, 19], have developed sound and complete inference systems but have not given much attention to algorithms. In [13] we demonstrated a technique for deriving efficient static analysis algorithms from type inference systems. <p> In other words, we do not have to choose a particular domain before the analysis as is usually done for abstract interpretation (except when widening operators are used as in [7]). We first describe an extension of Jensen's strictness logic [18] to include an analogue of Wadler's 4-point domain <ref> [25] </ref> (Section 2). In Section 3, we introduce the notion of lazy types for lists and we present the corresponding system. We state the correctness and completeness properties with respect to the original system and we proceed in Section 4 to define the lazy type inference algorithm. <p> For example, the sum function from the 3 previous section is translated as: sum (l) = case (0; f; l) where f x xs = x + (sum xs) The loss af accuracy that occurs without the case operator is discussed in <ref> [25] </ref>. Abstract interpretation represents the strictness properties of a function by an abstract function defined on boolean domains [23]. For instance g abs t f = f means that g is undefined if its second argument is undefined. <p> Let us now turn to the types used for the representation of properties of lists. As a first stage, we consider the extension of the boolean domain to Wadler's 4-point domain <ref> [25] </ref>. We show that this extension can be generalised to domains of unbounded depth in Section 6. <p> For example, it is not adequate for describing a property such as "this is a list containing lists whose one element is undefined". Following Wadler <ref> [25] </ref>, we can in fact generalise the definition of 4-point domain from the 2-point domain to domains of any depth.
Reference: [26] <author> P. Wadler and J. Hughes, </author> <title> Projections for Strictness Analysis, </title> <booktitle> in Proceedings of the 1987 Conference on Functional Programming Languages and Computer Architecture, </booktitle> <publisher> LNCS 274, Springer Verlag, </publisher> <year> 1987. </year> <month> 21 </month>
Reference-contexts: There have been a number of proposals to extend strictness analysis to recursively defined data structures <ref> [4, 21, 25, 26] </ref>. These have led to sophisticated analyses but two aspects of the problem have received little attention until recently: 1. The integration of the results of the analysis into a real compiler. 2. The efficiency of the algorithm implementing the analysis.
References-found: 26

