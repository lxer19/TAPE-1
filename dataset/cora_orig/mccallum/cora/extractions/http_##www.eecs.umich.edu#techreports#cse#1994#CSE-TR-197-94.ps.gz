URL: http://www.eecs.umich.edu/techreports/cse/1994/CSE-TR-197-94.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse94.html
Root-URL: http://www.eecs.umich.edu
Title: Architectural Support for Managing Communication in Point-to-Point Distributed Systems  
Author: Wu-chang Feng, Jennifer Rexford, Ashish Mehra, Stuart Daniel, James Dolter, and Kang Shin 
Address: Ann Arbor, MI 48109-2122  
Affiliation: Real-Time Computing Laboratory Department of Electrical Engineering and Computer Science The University of Michigan  
Abstract: Point-to-point networks provide a natural platform for distributed systems due to their high bandwidth, scalability, and the potential for exploiting communication locality. Managing these networks, however, is complicated by the disparate quality-of-service requirements of distributed applications. Since the various routing and switching schemes are best-suited for different classes of traffic, the network adapter should be able to dynamically tailor them according to the current need. In this paper, we present and evaluate SPIDER (Scalable Point-to-point Interface DrivER), a network adapter that supports a variety of routing and switching schemes, and includes means for dynamically selecting between them. By exercising low-level control over each network link, SPIDER exploits concurrency amongst the links to reduce both packet latency and intrusion on the protocol software. We evaluate a mesh of SPIDERs through cycle-level simulations over a range of routing and switching schemes. We also demonstrate how this architecture can dynamically partition network bandwidth to meet the performance requirements of disparate traffic classes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Li and P. Hudak, </author> <title> "Memory coherence in shared virtual memory systems," </title> <journal> ACM Trans. Computer Systems, </journal> <volume> vol. 7, no. 4, </volume> <pages> pp. 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Distributed systems have emerged as scalable, cost-effective platforms for applications with widely-varying characteristics and resource requirements. The advent of faster networks has enabled distributed systems to employ mechanisms previously applied only to tightly-coupled parallel machines, including system-wide shared memory <ref> [1] </ref> and a finer grain of computation [2]. Scalable application performance in such environments depends largely on the provision of concurrent low-latency and high-bandwidth communication.
Reference: [2] <author> H. Kung, R. Sansom, S. Schlick, P. Steenkiste, M. Arnould, F. J. Bitz, F. Christianson, E. C. Cooper, O. Menzilcioglu, D. Ombres, and B. Zill, </author> <title> "Network-based multicomputers: An emerging parallel architecture," </title> <booktitle> in Supercomputing 91, </booktitle> <pages> pp. 664-673. </pages> <publisher> IEEE, ACM, </publisher> <address> New York, NY, USA, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Distributed systems have emerged as scalable, cost-effective platforms for applications with widely-varying characteristics and resource requirements. The advent of faster networks has enabled distributed systems to employ mechanisms previously applied only to tightly-coupled parallel machines, including system-wide shared memory [1] and a finer grain of computation <ref> [2] </ref>. Scalable application performance in such environments depends largely on the provision of concurrent low-latency and high-bandwidth communication. Network designs employing shared buses or token rings, for example, can effectively interconnect a small number of computing nodes, but the serialization of medium access limits performance in larger configurations.
Reference: [3] <author> E. A. Arnould, F. J. Bitz, E. C. Cooper, H. T. Kung, R. D. Sansom, and P. A. Steenkiste, </author> <title> "The design of Nectar: A network backplane for heterogeneous multicomputers," </title> <booktitle> in Proc. Int'l Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 205-216. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1989. </year>
Reference: [4] <author> Y. Oie, T. Suda, M. Murata, D. Kolson, and H. Miyahara, </author> <title> "Survey of switching techniques in high-speed networks and their performance," </title> <booktitle> in IEEE INFOCOM, </booktitle> <pages> pp. 1242-1251, </pages> <month> June </month> <year> 1990. </year>
Reference: [5] <author> D. Cohen, G. G. Finn, R. Felderman, and A. DeSchon, </author> <title> "The use of message-based multi-computer components to construct gigabit networks," </title> <journal> Computer Communication Review, </journal> <volume> vol. 23, no. 3, </volume> <pages> pp. 32-44, </pages> <month> July </month> <year> 1993. </year>
Reference: [6] <author> W. Athas and C. Seitz, </author> <title> "Multicomputers: Message-passing concurrent computers," </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 9-24, </pages> <month> August </month> <year> 1988. </year> <month> 14 </month>
Reference: [7] <author> X. Zhang, </author> <title> "System effects of interprocessor communication latency in multicomputers," </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. </pages> <address> 12-15,52-55, </address> <month> April </month> <year> 1991. </year>
Reference: [8] <author> D. Talia, </author> <title> "Message-routing systems for transputer-based multicomputers," </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. 62-72, </pages> <month> June </month> <year> 1993. </year>
Reference: [9] <author> W. J. Dally and C. L. Seitz, </author> <title> "The torus routing chip," </title> <journal> Journal of Distributed Computing, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 187-196, </pages> <year> 1986. </year>
Reference-contexts: Traditional packet switching requires an arriving packet to buffer completely before transmission to a subsequent node can begin. This consumes processing and memory resources at each intermediate node. In contrast, cut-through switching schemes, such as virtual cut-through [24] and wormhole <ref> [9] </ref>, attempt to directly forward the incoming packet to an idle output link. If the packet encounters a busy outgoing link, virtual cut-through switching stores the packet, consuming memory and processing resources at the intermediate node. <p> Most of the experiments employ dimension-ordered routing, which requires a packet to travel along a minimal path completely in the x-direction before proceeding in the y-direction to reach the destination node <ref> [9, 28] </ref>. For the simulation results below, each node independently generates packets with exponentially-distributed inter-arrival times and uniform random selection of destination nodes, unless otherwise stated. 5.1 Switching In defining how packets flow through the network, the various switching schemes stress different resources at intermediate nodes.
Reference: [10] <author> S. Konstantinidou and L. Snyder, </author> <title> "Chaos router: Architecture and performance," </title> <booktitle> in Proc. Int'l Symposium on Computer Architecture, </booktitle> <pages> pp. 212-221, </pages> <month> May </month> <year> 1991. </year>
Reference: [11] <author> W. J. Dally, J. A. S. Fiske, J. S. Keen, R. A. Lethin, M. D. Noakes, P. R. Nuth, R. E. Davison, and G. A. Fyler, </author> <title> "The Message-Driven Processor: A multicomputer processing node with efficient mechanisms," </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. 23-39, </pages> <month> April </month> <year> 1992. </year>
Reference: [12] <author> A. L. Davis, "Mayfly: </author> <title> A general-purpose, scalable, </title> <booktitle> parallel processing architecture," Lisp and Symbolic Computation, </booktitle> <volume> vol. 5, no. 1/2, </volume> <pages> pp. 7-47, </pages> <month> May </month> <year> 1992. </year>
Reference: [13] <author> C. L. Seitz and W. Su, </author> <title> "A family of routing and communication chips based on the Mosaic," </title> <booktitle> in Symp. on Integrated Systems: Proc. of the Washington Conf., </booktitle> <year> 1993. </year>
Reference: [14] <author> K. Ramakrishnan, </author> <title> "Performance considerations in designing network interfaces," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 203-219, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: In contrast, distributed systems typically support a wide range of communication protocols. Since the network adapter defines the communication primitives available to the protocol software, flexible support for network I/O necessitates a careful division of functionality between the adapter and the controlling processor (network host) <ref> [14] </ref>. The overhead of host-adapter interaction can limit the amount of useful concurrency between the software and hardware portions of the protocol stack.
Reference: [15] <author> V. Jacobson, </author> <title> "Efficient TCP implementation," </title> <booktitle> in ACM SIGCOMM'90 Tutorial, </booktitle> <month> Septem-ber </month> <year> 1990. </year>
Reference: [16] <author> O. Menzilcioglu and S. Schlick, "Nectar CAB: </author> <title> A high-speed network processor," </title> <booktitle> in Proc. Int. Conf. on Distributed Computer Systems, </booktitle> <pages> pp. 508-515, </pages> <month> May </month> <year> 1991. </year>
Reference: [17] <author> A. Krishnakumar and K. Sabnani, </author> <title> "VLSI implementations of communication protocols a survey," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 7, no. 7, </volume> <pages> pp. 1082-1090, </pages> <month> September </month> <year> 1989. </year>
Reference: [18] <author> C. Dalton, G. Watson, D. Banks, C. Calamvokis, A. Edwards, and J. Lumley, </author> <title> "Afterburner," </title> <journal> IEEE Network Magazine, </journal> <pages> pp. 36-43, </pages> <month> July </month> <year> 1993. </year>
Reference: [19] <author> H. Kanakia and D. R. Cheriton, </author> <title> "The VMP network adapter board (NAB): high-performance network communication for multiprocessors," </title> <booktitle> Proceedings of the SIGCOMM Symposium, </booktitle> <pages> pp. 175-187, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The overhead of host-adapter interaction can limit the amount of useful concurrency between the software and hardware portions of the protocol stack. Single-port network adapters either facilitate flexibility through simple designs [15-18], or restrict flexibility, and hence improve performance, by supporting specific communication protocols and resource management strategies <ref> [19, 20] </ref>. This paper proposes architectural support for managing communication in point-to-point distributed systems. In particular, we present flexible, integrated hardware for routing and switching which supports, but does not dictate, higher-level host policies.
Reference: [20] <author> G. Chesson, </author> <title> "XTP/PE overview," </title> <booktitle> in Conference on Local Computer Networks, </booktitle> <month> October </month> <year> 1988. </year>
Reference-contexts: The overhead of host-adapter interaction can limit the amount of useful concurrency between the software and hardware portions of the protocol stack. Single-port network adapters either facilitate flexibility through simple designs [15-18], or restrict flexibility, and hence improve performance, by supporting specific communication protocols and resource management strategies <ref> [19, 20] </ref>. This paper proposes architectural support for managing communication in point-to-point distributed systems. In particular, we present flexible, integrated hardware for routing and switching which supports, but does not dictate, higher-level host policies.
Reference: [21] <author> J. Dolter, S. Daniel, A. Mehra, J. Rexford, W. Feng, and K. G. Shin, "SPIDER: </author> <title> Flexible and efficient communication support for point-to-point distributed systems," </title> <type> Technical Report CSE-TR-180-93, </type> <institution> University of Michigan, </institution> <month> October </month> <year> 1993. </year> <note> To appear in Proc. Int. Conf. on Distributed Computing Systems, </note> <month> June </month> <year> 1994. </year>
Reference-contexts: Section 2 discusses the influence of routing and switching techniques on both host resource consumption and packet latency. Section 3 describes the architecture and basic operation of SPIDER, the Scalable Point-to-point Interface DrivER, that provides flexible hardware support for routing and switching in point-to-point distributed systems <ref> [21] </ref>. Section 4 addresses how SPIDER insulates the software from low-level protocol processing without precluding host control over network policies. By simulating a mesh of SPIDERs at the cycle level, Section 5 evaluates how different routing and switching schemes affect packet latency and consumption of host resources.
Reference: [22] <author> D. Ferrari, </author> <title> "Client requirements for real-time communication services," </title> <journal> IEEE Communications Magazine, </journal> <pages> pp. 65-72, </pages> <month> November </month> <year> 1990. </year> <month> 15 </month>
Reference-contexts: In addition, emerging distributed applications require communication services with strict quality-of-service requirements, such as latency or bandwidth guarantees <ref> [22, 23] </ref>; this necessitates the coexistence of guaranteed and best-effort traffic. For point-to-point networks, these traffic patterns and classes affect the suitability of particular routing and switching schemes.
Reference: [23] <author> M. Zitterbart, B. Stiller, and A. N. Tantawy, </author> <title> "A model for flexible high-performance communication systems," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 11, no. 4, </volume> <pages> pp. 507-518, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In addition, emerging distributed applications require communication services with strict quality-of-service requirements, such as latency or bandwidth guarantees <ref> [22, 23] </ref>; this necessitates the coexistence of guaranteed and best-effort traffic. For point-to-point networks, these traffic patterns and classes affect the suitability of particular routing and switching schemes.
Reference: [24] <author> P. Kermani and L. Kleinrock, </author> <title> "Virtual cut-through: A new computer communication switching technique," </title> <journal> Computer Networks, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 267-286, </pages> <month> September </month> <year> 1979. </year>
Reference-contexts: Traditional packet switching requires an arriving packet to buffer completely before transmission to a subsequent node can begin. This consumes processing and memory resources at each intermediate node. In contrast, cut-through switching schemes, such as virtual cut-through <ref> [24] </ref> and wormhole [9], attempt to directly forward the incoming packet to an idle output link. If the packet encounters a busy outgoing link, virtual cut-through switching stores the packet, consuming memory and processing resources at the intermediate node. <p> The host can exercise fine-grain control over guaranteed traffic, while pipelining packet transmissions to support high-throughput best-effort packets. While SPIDER supports low-level cut-through switching schemes, the host at intermediate nodes can also implement partial cut-through <ref> [24, 33] </ref> for large packets which may be buffered because of busy outgoing links. This technique improves performance by overlapping the forwarding of buffered pages with the arrival of subsequent pages of a packet.
Reference: [25] <author> D. D. Kandlur, K. G. Shin, and D. Ferrari, </author> <title> "Real-time communication in multi-hop networks," </title> <booktitle> in Proc. Int. Conf. on Distributed Computer Systems, </booktitle> <pages> pp. 300-307, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Although cut-through switching techniques can improve average packet latency, they limit the ability of intermediate nodes to influence the allocation of buffer and network resources. By buffering packets at each intermediate node, packet switching facilitates resource scheduling to provide delay or bandwidth guarantees <ref> [25] </ref>. Likewise, static routing ensures that a packet utilizes buffer and link resources at predetermined nodes and links along its route. Adaptive routing algorithms, on the other hand, select intermediate nodes and links dynamically, complicating reservation of buffer and link bandwidth.
Reference: [26] <author> W. Dally, </author> <title> "Virtual-channel flow control," </title> <journal> IEEE Trans. Parallel and Distributed Systems, </journal> <volume> vol. 3, no. 2, </volume> <pages> pp. 194-205, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Designed to reside on the host processor's private memory bus, SPIDER has direct access to the host memory and provides the host with a memory-mapped control interface. The adapter coordinates bidirectional communication with up to six neighboring nodes, with two virtual channels <ref> [26] </ref> on each unidirectional link. Using SPIDER, one can construct point-to-point distributed systems with a variety of topologies, including rings, meshes, and irregular configurations. 3.1 Architecture Virtual channels are the unit of resource allocation and scheduling throughout SPIDER. <p> When the traffic load increases, however, channel contention causes wormhole latencies to become worse than those with packet switching, as seen in Figure 3 (b). This contention also results in a dramatically lower peak throughput <ref> [26, 34] </ref>, as seen in Figure 3 (c). By removing blocked packets from the network, virtual cut-through offers lower latencies under heavy loads than wormhole switching. <p> Depending on the relative importance of the traffic classes, the host uses virtual channels to limit interference between different traffic classes or to reduce channel contention within each class. Increasing the number of virtual channels on each link allows the host more flexibility in reducing contention <ref> [26] </ref> and partitioning traffic. Figure 6 evaluates a configuration where each physical link has three virtual channels, two allocated to best-effort packets for deadlock-free wormhole routing [27] and one dedicated to guaranteed traffic using packet switching.
Reference: [27] <author> W. J. Dally and C. L. Seitz, </author> <title> "Deadlock-free message routing in multiprocessor interconnection networks," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. C-36, no. 5, </volume> <pages> pp. 547-553, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Figure 3 (a) shows the average rate of in-transit packet arrivals at a node as a function of the switching scheme and the traffic load. These experiments employ dimension-ordered routing, with wormhole packets utilizing two virtual 9 channels to guarantee deadlock-avoidance <ref> [27] </ref>. As expected, packet switching imposes the highest in-transit load on the host, regardless of the traffic load. Wormhole switching, on the other hand, offers complete insulation of the host from in-transit packets by using channel resources to store blocked packets. <p> Increasing the number of virtual channels on each link allows the host more flexibility in reducing contention [26] and partitioning traffic. Figure 6 evaluates a configuration where each physical link has three virtual channels, two allocated to best-effort packets for deadlock-free wormhole routing <ref> [27] </ref> and one dedicated to guaranteed traffic using packet switching.
Reference: [28] <author> L. Ni and P. McKinley, </author> <title> "A survey of wormhole routing techniques in direct networks," </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 62-76, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Most of the experiments employ dimension-ordered routing, which requires a packet to travel along a minimal path completely in the x-direction before proceeding in the y-direction to reach the destination node <ref> [9, 28] </ref>. For the simulation results below, each node independently generates packets with exponentially-distributed inter-arrival times and uniform random selection of destination nodes, unless otherwise stated. 5.1 Switching In defining how packets flow through the network, the various switching schemes stress different resources at intermediate nodes.
Reference: [29] <author> J. Dolter, </author> <title> A Programmable Routing Controller Supporting Multi-mode Routing and Switching in Distributed Real-Time Systems, </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <month> Septem-ber </month> <year> 1993. </year>
Reference-contexts: By exporting this abstraction to the host, virtual channels can also facilitate separate management of traffic classes on distinct virtual networks. The programmable routing controller (PRC), a custom integrated circuit, 1 exploits concurrency amongst the virtual channels and provides fair, fine-grain arbitration at the memory and network interfaces <ref> [29] </ref>. The twelve PRC TXs provide low-level control of packet transmission while the twelve microprogrammable PRC RXs coordinate packet reception, as well as low-level routing and switching for in-transit packets. The PRC TXs and PRC RXs implement the low-level drivers controlling the actual transmitter and receiver devices. <p> Using the notification FIFOs, the host can direct a PRC RX's response to the prevailing network conditions. 5 Evaluation To capture the interaction between routing, switching, and host policies, we have developed pp-mess-sim (Point-to-Point MESS SIMulator) <ref> [29] </ref>. Implemented in C++, pp-mess-sim is an object-oriented discrete-event simulation environment for evaluating point-to-point network adapters. Using a high-level specification language, the user can select the interconnection topology and the communication patterns generated by each node in the network.
Reference: [30] <institution> Am79168/Am79169 TAXI tm -275 Technical Manual, Advanced Micro Devices, </institution> <address> ban-0.1m-1/93/0 17490a edition. </address>
Reference-contexts: The chip has a die size of 511 by 529 mils, and operates at a clock speed of 27:8 MHz on the network interface. The control interface operates off the host's bus clock, while the memory interface is asynchronous. 4 control on six pairs of AMD TAXI chips <ref> [30] </ref>, insulating the PRC from dependence on a par-ticular communication medium. The NI TX and NI RX control units perform the necessary interleaving of virtual channels to and from the physical links, on a byte-by-byte basis.
Reference: [31] <author> D. D. Kandlur and K. G. Shin, </author> <title> "Reliable broadcast algorithms for HARTS," </title> <journal> ACM Trans. Computer Systems, </journal> <volume> vol. 9, no. 4, </volume> <pages> pp. 374-398, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: A PRC RX can respond to network congestion by basing its routing decision on the reservation status of the outgoing virtual channels. By reserving multiple NI TXs, a PRC RX can also direct an incoming packet to several output links simultaneously, allowing SPIDER to support efficient broadcast algorithms <ref> [31] </ref>. The host can influence operation in the PRC RX through notification FIFOs, addressable as part of SPIDER's control interface. These FIFOs provide bidirectional information exchange between a PRC RX and the host.
Reference: [32] <author> S. J. Le*er, M. K. McKusick, M. J. Karels, and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD Unix Operating System, </title> <publisher> Addison Wesley, </publisher> <month> May </month> <year> 1989. </year>
Reference-contexts: Because SPIDER views a packet as a collection of one or more pages, it places few restrictions on packet format or size. These pages could be partially-filled and non-contiguous in memory (similar to MBUFs and MBUF clusters <ref> [32] </ref>). This allows a sending host to generate the packet header on a separate page while leaving the data pages untouched, minimizing data-copying overhead and host memory fragmentation. SPIDER coordinates memory transfer for packet transmission and reception, insulating the host from direct involvement with data movement.
Reference: [33] <author> S. Abraham and K. Padmanabhan, </author> <title> "Constraint based evaluation of multicomputer networks," </title> <booktitle> in International Conference on Parallel Processing, </booktitle> <pages> pp. </pages> <address> I-521-I-525, </address> <year> 1990. </year>
Reference-contexts: The host can exercise fine-grain control over guaranteed traffic, while pipelining packet transmissions to support high-throughput best-effort packets. While SPIDER supports low-level cut-through switching schemes, the host at intermediate nodes can also implement partial cut-through <ref> [24, 33] </ref> for large packets which may be buffered because of busy outgoing links. This technique improves performance by overlapping the forwarding of buffered pages with the arrival of subsequent pages of a packet.
Reference: [34] <author> J. Ngai and C. Seitz, </author> <title> "A framework for adaptive routing in multicomputer networks," </title> <booktitle> in Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 1-9, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: When the traffic load increases, however, channel contention causes wormhole latencies to become worse than those with packet switching, as seen in Figure 3 (b). This contention also results in a dramatically lower peak throughput <ref> [26, 34] </ref>, as seen in Figure 3 (c). By removing blocked packets from the network, virtual cut-through offers lower latencies under heavy loads than wormhole switching.
Reference: [35] <institution> IV-3207 VMEbus Single Board Computer and Multiprocessing Engine User's Manual, Ironics Incorporated, </institution> <note> 1991 edition. 16 </note>
Reference-contexts: In the current design, SPIDER interfaces to the Ironics IV-3207 <ref> [35] </ref>, a VMEbus-based 68040 card, through a daughterboard interface to the processor memory bus. An IV-3207 card, coupled with the SPIDER daughterboard, can serve either as a network-based uniprocessor handling both application and communication tasks or as a dedicated network host for the node.
References-found: 35

