URL: http://www.cs.utexas.edu/users/vlr/papers/dimacs96.ps
Refering-URL: http://www.cs.utexas.edu/users/vlr/pub.html
Root-URL: 
Title: Experimental Evaluation of Algorithms for Incremental Graph Connectivity  
Author: and Biconnectivity Madhukar Korupolu Ramgopal Mettu Vijaya Ramachandran Yuke Zhao 
Address: Austin, Austin TX 78712  
Affiliation: Department of Computer Sciences University of Texas at  
Abstract: We consider an algorithm to maintain the connected components and the biconnected components of a graph where vertex and edge insertions are allowed. Algorithms for this problem can be applied to task decomposition in engineering design. Connected components are maintained using a disjoint set data structure and the biconnected components are maintained by a block forest. We develop a special disjoint set structure that allows selective deletion of elements, and enables us to create and use condensible nodes. The algorithm runs in O(nlogn + m) time, where n is the number of vertices and m is the number of operations. Finally, we present extensive timing information for our implementation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Westbrook and R. E. Tarjan. </author> <title> Maintaining Bridge-Connected and Biconnected Components OnLine. </title> <booktitle> Algorithmica (1992) 7: </booktitle> <pages> 433-464 </pages>
Reference-contexts: 1. Introduction We consider the problem of maintaining graph connectivity and biconnectivity information incrementally, i.e., where vertex and edge insertions are allowed. Algorithms for this problem can be applied to task decomposition in engineering design. Here we specify an implementation design that uses the algorithm presented in Westbrook and Tarjan <ref> [1] </ref> which runs in O (nlogn + m) time, where n is the number of vertices and m is the number of operations. We develop a variation of the standard disjoint set structure that allows the deletion of selected elements. <p> In order to maintain the biconnected components of a graph incrementally, we make use of a tree structure of the blocks and vertices of a connected graph called the block tree <ref> [1] </ref>. The collection of block trees given by the components of a graph G = (V, E) is called the block forest. The block tree has two types of nodes: vertex (square) nodes, which represent the vertices of G; and block (round) nodes, which represent the blocks. <p> By defining the size of a block tree to be the same as the size of its corresponding connected component, Westbrook and Tarjan <ref> [1] </ref> show that everting the smaller block tree ensures O (nlogn) performance. This and the lemma below justify the use of size instead of rank in our modified disjoint set data structure. LEMMA 2. The connected component with smaller rank does not necessarily have smaller size. PROOF. <p> add the children set of b2 to the children set of b1; remove b2 from the children set of its parent, lca; free (b2); end. block_condense - 14 Subroutine findlca takes O (P) pointer steps, where P is the length of the path between the two given vertices (see findpath, <ref> [1] </ref>), and condense_path is a sequence of pointer operations along the path, hence it runs in O (P) pointer steps as well. All other operations involved in block_condense are merely pointer manipulations, therefore block_condense also runs in O (P) pointer steps. 5. <p> THEOREM 1. The data structure above can maintain the graph connectivity and biconnectivity incrementally in O (nlogn + m) time and O (n) space. PROOF. Tarjan and Westbrook <ref> [1] </ref> show that the total number of pointer steps taken by block_evert and block_condense is O (nlogn). For a sequence of m insert_edge, find_block, and new_vertex operations where m is in W (n), Tarjan and Westbrook show that the total number of pointer steps required is O (m + nlogn). <p> However, this analysis does not take into account the "holes" that need to be created in the block tree data structure during block_evert and block_condense operations. By the analysis given in <ref> [1] </ref>, our data structures support a sequence of m operations in O (m + n'logn') time, where n' represents the total number of elements in the disjoint sets of the block tree including "holes". From Lemmas 3 and 4 it follows that n' 3n-1, hence n' is O (n). <p> Once the block tree become biconnected the performance of the algorithm speeds up substantially from q (nlogn + m) to q (m a (m, n)) as indicated by <ref> [1] </ref>.
Reference: [2] <author> R. E. Tarjan. </author> <title> Efficiency of a Good But Not Linear Set Union Algorithm. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 22 (1975), </volume> <pages> 215-225. </pages>
Reference-contexts: A Disjoint Set Data Structure Disjoint sets are used to maintain both connected components and the children of nodes in the block forest in our implementation. We first present the standard disjoint set structure which supports find and merge operations <ref> [2] </ref>. Then we present a variation of the disjoint set data structure that allows selective deletion of elements. <p> The size of the combined tree is obj1.size+obj2.size. Return the combined set/tree. Although the work done by find to relink elements to point to the root seems excessive, it has been proven that the work done reduces the cost of future find operations <ref> [2] </ref>. In addition, the use of size to merge trees bounds the height of the tree to logx, where x is the number of elements in the set. <p> Thus, the path compression performed by the find operation and the use of size for merging two disjoint set trees allows a running time of O (k a (k, x)) as described in <ref> [2] </ref>. 2.2 A Disjoint Set Structure with Selected Deletions node_ptr element_ptr ais the element in the disjoint set that represents a In our block tree data structure (see Section 4), each object in the set doubly links to the child node that it represents.
Reference: [3] <author> D. Alberts, G. Cattaneo, and G. F. </author> <title> Italiano. An Empirical Study of Dynamic Graph Algorithms. </title> <booktitle> ACM-SIAM SODA (1996): </booktitle> <pages> 192-201. </pages>
Reference-contexts: We used the test results from Alberts et al. <ref> [3] </ref> as reference, which to our knowledge is the only other experimental study of dynamic graph algorithms. Alberts et al. measured their implementation of four different fully dynamic algorithms that maintained graph connectivity. For random inputs they indicated that none of these four algorithms was dominant in all cases.
Reference: [4] <author> J. H. Spencer. </author> <title> Ten Lectures on the Probabilistic Method. </title> <publisher> Capital City Press, </publisher> <year> 1994, </year> <note> 2nd edition. </note>
Reference-contexts: The sizes of sequences are approximately n/10, n and 2 ((nlnn)/2 - n), respectively. The largest sequence size was chosen as 2 ((nlnn)/2 - n) since a random graph is very likely to become connected when the number of its edges reaches approximately nlogn <ref> [4] </ref>, after which every operation will be within one block tree. Once the block tree become biconnected the performance of the algorithm speeds up substantially from q (nlogn + m) to q (m a (m, n)) as indicated by [1].
Reference: [5] <author> J. Dimarco. </author> <title> SPEC list. </title> <address> http://hpwww.epfl.ch/bench/SPEC.html </address>
Reference-contexts: The SPECintrate92 value for their DEC 4000/720 machine was 5144, compared to a SPECintrate92 value of 1864 for our machine <ref> [5] </ref>. Based on this benchmark, their machine is approximately 2.76 times faster than the one we used. Since Alberts et al. measured times for graphs with at most 500 vertices, we can only make a few comparisons between their implementations and ours.

References-found: 5

