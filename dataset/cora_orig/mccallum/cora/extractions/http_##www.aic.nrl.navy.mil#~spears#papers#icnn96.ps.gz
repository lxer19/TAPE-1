URL: http://www.aic.nrl.navy.mil/~spears/papers/icnn96.ps.gz
Refering-URL: http://www.aic.nrl.navy.mil/~spears/pubs.html
Root-URL: 
Email: spears@aic.nrl.navy.mil  
Phone: 202-767-9006 (W) 202-767-3172 (Fax)  
Title: A NN Algorithm for Boolean Satisfiability Problems  
Author: William M. Spears 
Address: Code 5514  Washington, D.C. 20375-5320  
Affiliation: AI Center  Naval Research Laboratory  
Abstract: Satisfiability (SAT) refers to the task of finding a truth assignment that makes an arbitrary boolean expression true. This paper compares a neural network algorithm (NNSAT) with GSAT [4], a greedy algorithm for solving satisfiability problems. GSAT can solve problem instances that are difficult for traditional satisfiability algorithms. Results suggest that NNSAT scales better as the number of variables increase, solving at least as many hard SAT problems.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. De Jong and W. Spears, </author> <title> "Using Genetic Algorithms to Solve NP-Complete Problems", </title> <booktitle> International Conference on Genetic Algorithms, </booktitle> <pages> pp. 124-132, </pages> <month> June </month> <year> 1989. </year>
Reference: [2] <author> J. Gu, </author> <title> "Efficient Local Search for Very Large-Scale Satisfiability Problems", </title> <journal> SIGART Bulletin, </journal> <volume> 3(1), </volume> <month> January </month> <year> 1992. </year>
Reference-contexts: The advantage of GSAT is that it can often solve problems that are difficult for the traditional algorithms. Other recent work has also concentrated on incomplete algorithms for satisfiability ([1], [6], [8], <ref> [2] </ref>). However, comparisons between the algorithms have been difficult to perform, due to a lack of agreement on what constitutes a reasonable test set of problems. One nice feature of [4] is that a class of hard problems is very precisely defined.
Reference: [3] <author> J. </author> <title> Hopfield, "Neural Networks and Physical Systems with Emergent Collective Computational Abilities", </title> <journal> Proc. Natl. Acad. Sci, </journal> <volume> 79, </volume> <pages> pp. 2554-2558, </pages> <year> 1982. </year>
Reference-contexts: Furthermore, it can not make two backwards moves in a row, since the backwards move will guarantee that it is possible to increase the number of true clauses in the next move. Since SAT is a constraint satisfaction problem, it can be modeled as a Hopfield neural network <ref> [3] </ref>. This paper describes NNSAT, a Hopfield network algorithm for solving SAT problems. NNSAT is not restricted 1 Soundness means that any solution found must be correct.
Reference: [4] <author> B. Selman, H. Levesque, and M. Mitchell, </author> <title> "A New Method for Solving Hard Satisfiability Problems", </title> <booktitle> Proceedings of the 1992 AAAI Conference, </booktitle> <pages> pp. 440-446, </pages> <year> 1992. </year>
Reference-contexts: Satisfiability is of interest to the logic, operations research, and computational complexity communities. Due to the emphasis of the logic community, traditional satisfiability algorithms tend to be sound and complete 1 . However, <ref> [4] </ref> point out that there exist classes of satisfiability problems that are extremely hard for these algorithms and have created a greedy algorithm (GSAT) that is sound, yet incomplete (i.e., there is no guarantee that GSAT will find a satisfying assignment if one exists). <p> Other recent work has also concentrated on incomplete algorithms for satisfiability ([1], [6], [8], [2]). However, comparisons between the algorithms have been difficult to perform, due to a lack of agreement on what constitutes a reasonable test set of problems. One nice feature of <ref> [4] </ref> is that a class of hard problems is very precisely defined. This paper compares GSAT with a novel neural network approach on that class of hard problems. <p> Each clause is generated by selecting L of the V variables uniformly randomly, negating each variable with probability 50%. Let R denote the ratio of the number of clauses to the number of variables (C=V ). According to <ref> [4] </ref>, hard problems are those where R is roughly 4.25, when L is 3. Although we could not obtain the specific problems used in their experiments, we generated random problems using their random problem generator (with L = 3 and R = 4:25). <p> Since the problems are not all solvable, Table 1 also presents the number of problems solved (out of 30). "Cutoff" indicates the number of assignments tried before NNSAT decides a problem is unsolvable. The results for GSAT are taken from <ref> [4] </ref>. The percentage solved by GSAT is not reported, however Selman (personal communication) states that GSAT solves roughly 50% of the 100 and 200 variable problems, and roughly 20% - 33% of the 500 variable problems. Also, the cutoffs for GSAT are not fully described. <p> Computational time is also reported (the results for GSAT are from <ref> [4] </ref>). The results for NNSAT-CNF are encouraging. In terms of "flips" (and time) NNSAT-CNF appears to scale better than GSAT, since it solves a greater percentage of the larger problems with less computational effort. The reason for this performance difference is not clear. However, [4] report that GSAT performs worse when <p> (the results for GSAT are from <ref> [4] </ref>). The results for NNSAT-CNF are encouraging. In terms of "flips" (and time) NNSAT-CNF appears to scale better than GSAT, since it solves a greater percentage of the larger problems with less computational effort. The reason for this performance difference is not clear. However, [4] report that GSAT performs worse when sideways steps are not allowed.
Reference: [5] <author> A. Sohn, </author> <title> "Solving Hard Satisfiability Problem with Synchronous Simulated Annealing on the AP1000 Multiprocessor", </title> <booktitle> Proceedings of the Seventh IEEE Symposium on Parallel and Distributed Processing San Antonio, Texas, </booktitle> <pages> pp. 719-722, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: For example, it may be possible to add stochastic operators based on the Davis-Putnam satisfiability algorithm. Third, NNSAT is intrinsically parallel and is a good match for parallel architectures. Andrew Sohn of the New Jersey Institute of Technology has ported NNSAT-CNF to a AP1000 multiprocessor <ref> [5] </ref>. Future work will concentrate on porting the general NNSAT algorithm to a parallel architecture. Acknowledgements I thank Diana Gordon, Ken De Jong, David Johnson, Bart Selman, Ian Gent, Toby Walsh, Antje Beringer, Andrew Sohn, Mitch Potter, and John Grefenstette for provocative and insightful comments.
Reference: [6] <author> W. Spears, </author> <title> "Using Neural Networks and Genetic Algorithms as Heuristics for NP-Complete Problems", </title> <type> Masters Thesis, </type> <institution> Department of Computer Science, George Mason University, </institution> <year> 1990. </year>
Reference-contexts: The advantage of GSAT is that it can often solve problems that are difficult for the traditional algorithms. Other recent work has also concentrated on incomplete algorithms for satisfiability ([1], <ref> [6] </ref>, [8], [2]). However, comparisons between the algorithms have been difficult to perform, due to a lack of agreement on what constitutes a reasonable test set of problems. One nice feature of [4] is that a class of hard problems is very precisely defined. <p> Similar constraints occur when 3 For example, if a is true and b is false, then both children of the node a ^ b are true. 4 See <ref> [6] </ref> for motivational details.
Reference: [7] <author> W. Spears, </author> <title> "Simulated Annealing for Hard Satisfiability Problems", </title> <note> to appear in the DIMACS Series on Discrete Mathematics and Theoretical Computer Science, </note> <year> 1996. </year>
Reference-contexts: To address the first issue a specific version of NNSAT (called NNSAT-CNF) was written for CNF expressions, enormously increasing the efficiency of the algorithm. To address the second issue, focus was centered on flips rather than assignments. As described by <ref> [7] </ref>, a flip in GSAT and NNSAT-CNF have almost identical computational complexity, thus making this an ideal measure for comparison 6 . Table 2 presents the results for NNSAT-CNF. <p> A reasonable hypothesis is that GSAT would perform even better if it could occasionally take sequences of backward steps, as does NNSAT and NNSAT-CNF 7 . 5 A literal is a negated or non-negated boolean variable. 6 In <ref> [7] </ref> NNSAT-CNF is called SASAT, because with CNF the network is simple and the emphasis is on Simulated Annealing. <p> None of the details of NNSAT as described in Section 2, however, are in that paper. 7 GSAT has recently been modified to make heuristically-driven backwards moves, which do indeed improve performance. These special backwards moves also improve the performance of NNSAT-CNF. See <ref> [7] </ref> for details.
Reference: [8] <author> R. Young and A. </author> <title> Reel, "A Hybrid Genetic Algorithm for a Logic Problem", </title> <booktitle> Proceedings of the 9th European Conference on Artificial Intelligence, </booktitle> <pages> pp. 744-746, </pages> <year> 1990. </year>
Reference-contexts: The advantage of GSAT is that it can often solve problems that are difficult for the traditional algorithms. Other recent work has also concentrated on incomplete algorithms for satisfiability ([1], [6], <ref> [8] </ref>, [2]). However, comparisons between the algorithms have been difficult to perform, due to a lack of agreement on what constitutes a reasonable test set of problems. One nice feature of [4] is that a class of hard problems is very precisely defined.
References-found: 8

