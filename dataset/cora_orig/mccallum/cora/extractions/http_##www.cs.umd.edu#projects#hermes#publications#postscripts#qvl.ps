URL: http://www.cs.umd.edu/projects/hermes/publications/postscripts/qvl.ps
Refering-URL: http://www.cs.umd.edu/projects/hermes/publications/abstracts/qvl.html
Root-URL: 
Email: fhwang; vsg@cs.umd.edu  
Title: Querying Video Libraries  
Author: Eenjun Hwang, V.S. Subrahmanian 
Address: College Park, MD 20742.  
Affiliation: Department of Computer Science Institute for Advanced Computer Studies Institute for Systems Research University of Maryland  
Abstract: There is now growing interest in organizing and querying large bodies of video data. In this paper, we will develop a simple SQL-like video query language which can be used not only to identify videos in the library that are of interest to the user, but which can also be used to extract, from such a video in a video library, the relevant segments of the video that satisfy the specified query condition. We investigate various types of user requests and show how they are expressed using our query language. We also develop polynomial-time algorithms to process such queries. Furthermore, we show how video-presentations may be synthesized in response to a user query. We show how a standard relational database system can be extended in order to handle queries such as those expressed in our language. Based on these principles, we have built a prototype video retrieval system called VIQS. We describe the design and implementation of VIQS and show some sample interactions with VIQS.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Adali, K.S. Candan, S.-S. Chen, K. </author> <title> Erol and V.S. Subrahmanian. (1995) AVIS: Advanced Video Information Systems, </title> <note> accepted for publication in: ACM Multimedia Journal. Also available via the WWW at http://www.cs.umd.edu//projects/hermes /publications/abstracts/avisdsqp.html. </note>
Reference-contexts: To facilitate this, the query language contains various primitive operations that apply to sets of video-segments. The query engine executes these queries using a formal model of video data structures defined by Adal et. al. <ref> [1] </ref>. This paper builds on the data structures defined in [1], and adds two fundamentally new contributions: first, it presents a unified query language within which video data can be accessed this query language includes temporal modalities; second, this query language provides various algebraic operations to compose video-segments together. 3. <p> To facilitate this, the query language contains various primitive operations that apply to sets of video-segments. The query engine executes these queries using a formal model of video data structures defined by Adal et. al. <ref> [1] </ref>. This paper builds on the data structures defined in [1], and adds two fundamentally new contributions: first, it presents a unified query language within which video data can be accessed this query language includes temporal modalities; second, this query language provides various algebraic operations to compose video-segments together. 3. <p> This is particularly critical if expensive image processing algorithms are used to retrieve the content of video data. In such cases, the relational component of the query focuses the search, leading to significant efficiency gains. 2 Preliminaries In <ref> [1] </ref>, the authors develop a formal model of video data and devise a storage scheme using modified spatial data structures. In this section, we present a quick overview of the video model developed in [1]. <p> relational component of the query focuses the search, leading to significant efficiency gains. 2 Preliminaries In <ref> [1] </ref>, the authors develop a formal model of video data and devise a storage scheme using modified spatial data structures. In this section, we present a quick overview of the video model developed in [1]. As is well known, whenever a movie is played on a VCR, the particular point in the movie that is currently being displayed may be captured by a number (e.g. 1155) on the VCR monitor. This number may be viewed as a frame number of the video. <p> In any event, there are certain players in these roles for instance, in the event Wedding of John and Mary, the role groom is played by John, the role bride is played by Mary. Adal et. al. <ref> [1] </ref> develop a 3 formal model of the above informal description of video-information and develop specialised data structures to store such information. We assume that a movie is divided up into a sequence of frames. In our setting, a frame is a logical division of a movie. <p> In general, an object/event may occur in multiple frame sequences. For instance, the object John may occur in frame-sequences [1078; 1101); [1133; 1148) and [1198; 1225). Adal et. al. <ref> [1] </ref> use this intuition to argue that associated with each object/activity/event, is a set of frame-sequences. Each frame sequence can be viewed as a line-segment; hence, associated with any object/activity/event, is a set of line segments. They enhance an existing data structure, called the segment tree (cf. <p> This will facilitate queries about a certain activity type as opposed to a certain event of that type. Similarly, a ROLEARRAY simply lists the name of the roles. 3 Query Language In the preceding section, we described, albeit briefly, a data structure developed by Adal et. al. <ref> [1] </ref> to index video data. In this section, we will show how this data structure can be used to facilitate the execution of queries. We will enumerate examples of such queries and show how these queries can be answered using our data structure. <p> Output : An answer presentation f s1 N f s2 corresponding to the set of frames f (f 1 [ : : :[ f n ) " (f 0 m )g int st, fi, /* start and end of each frame in the result */ sp <ref> [1] </ref>, sp [2], /* variables pointing to array index */ dt [1], dt [2], /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to <p> N f s2 corresponding to the set of frames f (f 1 [ : : :[ f n ) " (f 0 m )g int st, fi, /* start and end of each frame in the result */ sp <ref> [1] </ref>, sp [2], /* variables pointing to array index */ dt [1], dt [2], /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 <p> fi, /* start and end of each frame in the result */ sp <ref> [1] </ref>, sp [2], /* variables pointing to array index */ dt [1], dt [2], /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt <p> the result */ sp <ref> [1] </ref>, sp [2], /* variables pointing to array index */ dt [1], dt [2], /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else <p> dt <ref> [1] </ref>, dt [2], /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = <p> segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp <ref> [1] </ref> and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase <p> in consideration */ initialize line_num to zero ; initialize sp <ref> [1] </ref> and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp <p> initialize sp <ref> [1] </ref> and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n and sp [2] &lt;= 2m) <p> and sp [2] to one ; initialize dt <ref> [1] </ref> and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n and sp [2] &lt;= 2m) if (line_num == <p> and sp [2] by one ; dt <ref> [1] </ref> = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt <p> = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp <ref> [1] </ref> &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = <p> increase sp [i] by one ; while (sp <ref> [1] </ref> &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] <p> while (sp <ref> [1] </ref> &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one <p> &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp <ref> [1] </ref>],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set <p> 2) 14 set fi to the min (ARR1 [sp <ref> [1] </ref>],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; <p> ; else set i to sp of min (ARR1 [sp <ref> [1] </ref>],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] <p> of min (ARR1 [sp <ref> [1] </ref>],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one <p> [sp <ref> [1] </ref>],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; To see <p> [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp <ref> [1] </ref>],ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; To see how the algorithm works, we show a figure where each <p> This query involves computing the intersection of the two presentations given above. In this case: ARR1 = [8; 24; 61; 75; 111; 132]: Note that we assume that ARR1 and ARR2 are sorted in ascending order. Initially, ARR1 [sp <ref> [1] </ref>] = 8 and ARR2 [sp [2]] = 11. The algorithm first compares 8 and 11. As 8 &lt; 11, t increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. <p> Initially, ARR1 [sp <ref> [1] </ref>] = 8 and ARR2 [sp [2]] = 11. The algorithm first compares 8 and 11. As 8 &lt; 11, t increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. It also stores 8 into st as a possible start point of a frame sequence in the output presentation. The next elements to be compared are 24 and 11. <p> Initially, ARR1 [sp <ref> [1] </ref>] = 8 and ARR2 [sp [2]] = 11. The algorithm first compares 8 and 11. As 8 &lt; 11, t increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. It also stores 8 into st as a possible start point of a frame sequence in the output presentation. The next elements to be compared are 24 and 11. <p> Initially, ARR1 [sp <ref> [1] </ref>] = 8 and ARR2 [sp [2]] = 11. The algorithm first compares 8 and 11. As 8 &lt; 11, t increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. It also stores 8 into st as a possible start point of a frame sequence in the output presentation. The next elements to be compared are 24 and 11. <p> However, as line num = 2, it sets fi to the minimum of these two numbers (in this case, 11) and outputs (st,fi) as one of the frame-sequences in the intersection. The role of the dt [i] variable is to indicate entering and exiting line segments. dt <ref> [1] </ref> indicates the status associated with the first presentation, while dt [2] indicates the status associated with the second presentation. <p> In this case, we need to apply the union composition algorithm to the two presentations described in the Intersection example. The union composition algorithm works as follows: Initially, ARR1 [sp <ref> [1] </ref>] = 8 and ARR2 [sp [2]] = 11. First, it compares 8 and 11. As 8 &lt; 11, it increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. <p> The union composition algorithm works as follows: Initially, ARR1 [sp <ref> [1] </ref>] = 8 and ARR2 [sp [2]] = 11. First, it compares 8 and 11. As 8 &lt; 11, it increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. It also stores 8 in st as a start point for a frame-sequence in the unioned-presentation. <p> The union composition algorithm works as follows: Initially, ARR1 [sp <ref> [1] </ref>] = 8 and ARR2 [sp [2]] = 11. First, it compares 8 and 11. As 8 &lt; 11, it increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. It also stores 8 in st as a start point for a frame-sequence in the unioned-presentation. Unlike the intersection algorithm, the union algorithm considers the next point encounted by the sweep line as a possible finish point. <p> The union composition algorithm works as follows: Initially, ARR1 [sp <ref> [1] </ref>] = 8 and ARR2 [sp [2]] = 11. First, it compares 8 and 11. As 8 &lt; 11, it increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. It also stores 8 in st as a start point for a frame-sequence in the unioned-presentation. Unlike the intersection algorithm, the union algorithm considers the next point encounted by the sweep line as a possible finish point. The next elements that should be compared are 24 and 11. <p> The data structures of Adal et. al. <ref> [1] </ref> are not adequate to express the information requested in the above queries. However, there is no need to reinvent the wheel data such as which actor appeared in which role in which movie is typically likely to be stored in a relational database management system.
Reference: [2] <author> F. Arman, A. Hsu and M. Chiu. </author> <title> (1993) Image Processing on Compressed Data for Large Video Databases, </title> <booktitle> First ACM Intl. Conf. on Multimedia, </booktitle> <address> Anaheim, CA, </address> <month> Aug. </month> <year> 1993, </year> <month> pps 267-272. </month>
Reference-contexts: Output : An answer presentation f s1 N f s2 corresponding to the set of frames f (f 1 [ : : :[ f n ) " (f 0 m )g int st, fi, /* start and end of each frame in the result */ sp [1], sp <ref> [2] </ref>, /* variables pointing to array index */ dt [1], dt [2], /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to one ; <p> s2 corresponding to the set of frames f (f 1 [ : : :[ f n ) " (f 0 m )g int st, fi, /* start and end of each frame in the result */ sp [1], sp <ref> [2] </ref>, /* variables pointing to array index */ dt [1], dt [2], /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) <p> and end of each frame in the result */ sp [1], sp <ref> [2] </ref>, /* variables pointing to array index */ dt [1], dt [2], /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt <p> sp [1], sp <ref> [2] </ref>, /* variables pointing to array index */ dt [1], dt [2], /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to <p> <ref> [2] </ref>, /* variables for entering and exiting segment */ line_num; /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp [2] to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; <p> /* number of lines in consideration */ initialize line_num to zero ; initialize sp [1] and sp <ref> [2] </ref> to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by <p> initialize line_num to zero ; initialize sp [1] and sp <ref> [2] </ref> to one ; initialize dt [1] and dt [2] to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n <p> to one ; initialize dt [1] and dt <ref> [2] </ref> to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set <p> initialize dt [1] and dt <ref> [2] </ref> to one ; set st to the min (ARR1 [sp [1]], ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set fi to the <p> min (ARR1 [sp [1]], ARR2 [sp <ref> [2] </ref>]) ; line_num = line_num + dt [1] + dt [2] ; increase sp [1] and sp [2] by one ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if <p> ; dt [1] = -dt [1] ; dt <ref> [2] </ref> = -dt [2] ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = <p> sp of min (ARR1 [sp [1]],ARR2 [sp <ref> [2] </ref>]) ; line_num = dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n and sp [2] &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp <p> dt [i] = -dt [i] ; increase sp [i] by one ; while (sp [1] &lt;= 2n and sp <ref> [2] </ref> &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] <p> by one ; while (sp [1] &lt;= 2n and sp <ref> [2] </ref> &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp <p> sp <ref> [2] </ref> &lt;= 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the <p> 2m) if (line_num == 2) 14 set fi to the min (ARR1 [sp [1]],ARR2 [sp <ref> [2] </ref>]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp <p> fi to the min (ARR1 [sp [1]],ARR2 [sp <ref> [2] </ref>]) ; output pair of (st, fi); if (ARR1 [sp [1]] == ARR2 [sp [2]]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num <p> if (ARR1 [sp [1]] == ARR2 [sp <ref> [2] </ref>]) line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] <p> sp [1] and sp <ref> [2] </ref> by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt <p> i to sp of min (ARR1 [sp [1]],ARR2 [sp <ref> [2] </ref>]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp <p> <ref> [2] </ref>]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; To see how the algorithm <p> = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp <ref> [2] </ref>]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; To see how the algorithm works, we show <p> [i] = -dt [i] ; increase sp [i] by one ; else set st to the min (ARR1 [sp [1]],ARR2 [sp <ref> [2] </ref>]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; To see how the algorithm works, we show a figure where each frame sequence is <p> the min (ARR1 [sp [1]],ARR2 [sp <ref> [2] </ref>]) ; line_num = line_num + dt [1] + dt [2] ; dt [1] = -dt [1] ; dt [2] = -dt [2] ; increase sp [1] and sp [2] by one ; else set i to sp of min (ARR1 [sp [1]],ARR2 [sp [2]]) ; line_num = line_num + dt [i] ; dt [i] = -dt [i] ; increase sp [i] by one ; To see how the algorithm works, we show a figure where each frame sequence is represented by a line segment and the whole movie is represented by a whole line. <p> This query involves computing the intersection of the two presentations given above. In this case: ARR1 = [8; 24; 61; 75; 111; 132]: Note that we assume that ARR1 and ARR2 are sorted in ascending order. Initially, ARR1 [sp [1]] = 8 and ARR2 [sp <ref> [2] </ref>] = 11. The algorithm first compares 8 and 11. As 8 &lt; 11, t increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. It also stores 8 into st as a possible start point of a frame sequence in the output presentation. <p> It also stores 8 into st as a possible start point of a frame sequence in the output presentation. The next elements to be compared are 24 and 11. As 24 &gt; 11, the algorithm increments sp <ref> [2] </ref>, adds dt [2] to line num and changes the sign of dt [2]. Also, as a new possible start point, it updates st to 11. Now, it is given 19 and 24. <p> It also stores 8 into st as a possible start point of a frame sequence in the output presentation. The next elements to be compared are 24 and 11. As 24 &gt; 11, the algorithm increments sp <ref> [2] </ref>, adds dt [2] to line num and changes the sign of dt [2]. Also, as a new possible start point, it updates st to 11. Now, it is given 19 and 24. <p> The next elements to be compared are 24 and 11. As 24 &gt; 11, the algorithm increments sp <ref> [2] </ref>, adds dt [2] to line num and changes the sign of dt [2]. Also, as a new possible start point, it updates st to 11. Now, it is given 19 and 24. <p> The role of the dt [i] variable is to indicate entering and exiting line segments. dt [1] indicates the status associated with the first presentation, while dt <ref> [2] </ref> indicates the status associated with the second presentation. <p> In this case, we need to apply the union composition algorithm to the two presentations described in the Intersection example. The union composition algorithm works as follows: Initially, ARR1 [sp [1]] = 8 and ARR2 [sp <ref> [2] </ref>] = 11. First, it compares 8 and 11. As 8 &lt; 11, it increments sp [1], adds dt [1] to line num and changes the sign of dt [1]. It also stores 8 in st as a start point for a frame-sequence in the unioned-presentation. <p> Unlike the intersection algorithm, the union algorithm considers the next point encounted by the sweep line as a possible finish point. The next elements that should be compared are 24 and 11. As 24 &gt; 11, it increments sp <ref> [2] </ref>, adds dt [2] to line num and changes the sign of dt [2]. Also, as a 17 possible finish point, it stores 11 in fi. It will repeat this process till line num = 0, when it can output one frame-sequence in the answer presentation. <p> Unlike the intersection algorithm, the union algorithm considers the next point encounted by the sweep line as a possible finish point. The next elements that should be compared are 24 and 11. As 24 &gt; 11, it increments sp <ref> [2] </ref>, adds dt [2] to line num and changes the sign of dt [2]. Also, as a 17 possible finish point, it stores 11 in fi. It will repeat this process till line num = 0, when it can output one frame-sequence in the answer presentation. <p> The next elements that should be compared are 24 and 11. As 24 &gt; 11, it increments sp <ref> [2] </ref>, adds dt [2] to line num and changes the sign of dt [2]. Also, as a 17 possible finish point, it stores 11 in fi. It will repeat this process till line num = 0, when it can output one frame-sequence in the answer presentation. In this example, [8,24) could be the first such frame-sequence in the answer presentation. <p> However, they have no way of composing video-presentations together, nor do they have any constructs similar to our iterative constructs. Additionally, one of the innovations in our approach is the use of well studied spatial (rather than temporal)' data structures, suitably modified, to query video data. Arman et. al. <ref> [2] </ref> develop algorithms that can operate on compressed video directly they can identify scene changes by performing certain computations on DCT coefficients in JPEG and MPEG encoded video.
Reference: [3] <author> A. Brink, S. Marcus and V.S. Subrahmanian. </author> <title> (1995) Heterogeneous Multimedia Reasoning, </title> <journal> IEEE Computer, </journal> <volume> Vol. 28, No. 9, </volume> <month> Sep. </month> <year> 1995, </year> <month> pps 33-39. </month>
Reference: [4] <author> G. Davenport, T.A. Smith and N. Pincever. </author> <title> (1991) Cinematic Primitives for Multimedia, </title> <journal> IEEE Comp. Graphics and Applications, </journal> <volume> Vol. 11, No. 4, </volume> <month> July </month> <year> 1991, </year> <month> pps 67-74. </month>
Reference-contexts: Other work on video includes work by Davenport et. al. <ref> [4] </ref> who argue that segmenting video should not be done at the frame level. This is consistent with our rendition segmenting video at the frame level corresponds to a well-known data structure called the unit segment tree (cf. <p> As such video data becomes more and more widely accessible, the need to efficiently index this data becomes more and more significant. In this paper, we have developed schemes that allow frame-segment based retrieval of large video databases. Davenport et. al. <ref> [4] </ref> have argued persuasively against the development of indexing schemes that index each and every frame of video; the reason for this is that many thousands of contiguous frames may often denote a single event of interest, and in such cases, repetitive representation of this data, once for each frame, is
Reference: [5] <author> S. Gibbs, C. Breiteneder and D. Tsichritzis. </author> <title> (1994) Data Modeling of Time-Based Media, </title> <booktitle> Proc. ACM SIGMOD Conf. on Management of Data, </booktitle> <address> Minneapolis, Minnesota, </address> <month> June </month> <year> 1994, </year> <month> pps 91-102. </month>
Reference-contexts: In contrast, Query 2 is somewhat more complex. It requires: * executing Query 1 (relational query) * identifying other movies in which this actor has appeared (relational query), and finally * executing a FIND frames <ref> [5] </ref> query that finds frames from each of the movies identified in the preceding step. In other words, this requires the ability to iteratively find 5 frames each from each movie identified in step 2 above and concatenating the segments thus identified. Query 3 is even more complex. <p> SET MOVIES TO ( (SELECT A.Movie FROM actor A, actor B WHERE A.Name = B.name AND B.Movie = 'Rope' AND B.Role = 'Rupert') MINUS (SELECT DISTINCT Movie FROM actor WHERE Movie = 'Rope') ) FOREACH X IN MOVIES FIND frames <ref> [5] </ref> FROM X 21 Example (Query 3): In a similar vein, Query 3 may be expressed as follows: SET ACTOR TO ( (SELECT A.Name FROM actor A, sex S WHERE S.Sex = 'male' AND S.Name = A.Name AND A.Movie = 'Rope') INTERSECT (SELECT A.Name FROM actor A, sex S WHERE S.Sex <p> FROM actor A, sex S WHERE S.Sex = 'female' AND S.Name = A.Name AND A.Movie = 'Rope') INTERSECT (SELECT A.NAME FROM actor A, sex S WHERE S.Sex = 'female' AND S.Name = A.Name AND A.Movie = 'Rear Window' ) ) FOREACH X IN ACTORS FOREACH Y IN ACTRESS FIND frames <ref> [5] </ref> FROM Rear Window WHERE obj has X AND obj has Y We now characterize the meaning of the FOREACH and FORALL constructs in much greater detail. <p> The primary aim of this paper is to develop techniques by which video may be organized and queried. Three works that are closely related are [10], <ref> [5] </ref> and [7], Oomoto and Tanaka [10] have defined a video-based object oriented data model, OVID. They take pieces of video, identify meaningful features in them and link these features. They also outline a language called VideoSQL for querying such data. <p> In addition, the operations FORALL and FOREACH are new and allow the user to synthesize meaningful presentations. Finally, our methods of composing presentations are novel. Gibbs et. al. <ref> [5] </ref> study how stream-based temporal multimedia data may be modeled using object based methods. However, concepts such as roles and players, the distinction between activities and events, and the integration of such video systems with other traditional database systems are not addressed.
Reference: [6] <author> S. Gibbs and D. Tsichritzis. </author> <title> (1994) Multimedia Programming: Objects, Environments and Frameworks, </title> <publisher> ACM Press/Addison Wesley. </publisher>
Reference: [7] <author> R. Hjelsvold and R. Midtstraum. </author> <title> (1994) Modeling and Querying Video Data, </title> <booktitle> Proc. Intl. Conf. on Very Large Databases, </booktitle> <address> Santigo, Chile, </address> <month> Sep. </month> <year> 1994, </year> <month> pps 686-694. </month>
Reference-contexts: The primary aim of this paper is to develop techniques by which video may be organized and queried. Three works that are closely related are [10], [5] and <ref> [7] </ref>, Oomoto and Tanaka [10] have defined a video-based object oriented data model, OVID. They take pieces of video, identify meaningful features in them and link these features. They also outline a language called VideoSQL for querying such data. <p> Gibbs et. al. [5] study how stream-based temporal multimedia data may be modeled using object based methods. However, concepts such as roles and players, the distinction between activities and events, and the integration of such video systems with other traditional database systems are not addressed. Hjelsvold and Midtstraum <ref> [7] </ref> develop a "generic" data model for capturing video content and structure. Their idea is that video should be included as a data type in relational databases, i.e. systems such as PARADOX, INGRES, etc. should be augmented to handle video data. In particular, they study temporal queries.
Reference: [8] <author> M. Iino, Y.F. Day and A. Ghafoor. </author> <title> (1994) An Object-Oriented Model for Spatio-Temporal Synchronization of Multimedia Information, </title> <booktitle> Proc. 1994 Intl. Conf. on Multimedia Computing and Systems, </booktitle> <address> Boston, Massachusetts, </address> <month> May </month> <year> 1994, </year> <pages> pps 110-120, </pages> <publisher> IEEE Press. </publisher>
Reference-contexts: Consider now the intersection query where we wish to find all frames in which both Rupert and David appear. This query involves computing the intersection of the two presentations given above. In this case: ARR1 = <ref> [8; 24; 61; 75; 111; 132] </ref>: Note that we assume that ARR1 and ARR2 are sorted in ascending order. Initially, ARR1 [sp [1]] = 8 and ARR2 [sp [2]] = 11. The algorithm first compares 8 and 11.
Reference: [9] <author> S. Marcus and V.S. Subrahmanian. </author> <title> (1994) Multimedia Database Systems, to appear in: "Multimedia Databases: Research Issues and Directions" (eds. S. Jajodia and V.S. </title> <type> Subrahmanian), </type> <note> Springer-Verlag, to appear. </note>
Reference-contexts: The has construct specified above can be easily generalized to handle fuzzy matches by making has a fuzzy membership function instead of a two-valued membership function. This possibility was first introduced by Marcus and Subrahmanian <ref> [9] </ref> and is discussed in detail in section 3.5.7. 7 3.3 Frame-Request Queries A special case of the query format occurs when the result object type is frame, i.e. the user is interested in finding frames.
Reference: [10] <author> E. Oomoto and K. Tanaka. </author> <year> (1993) </year> <month> OVID: </month> <title> Design and Implementation of a Video-Object Database System, </title> <journal> IEEE Trans. on Knowledge and Data Engineering, Aug. 1993, </journal> <volume> 5, 4, </volume> <pages> pps 629-643. </pages>
Reference-contexts: The primary aim of this paper is to develop techniques by which video may be organized and queried. Three works that are closely related are <ref> [10] </ref>, [5] and [7], Oomoto and Tanaka [10] have defined a video-based object oriented data model, OVID. They take pieces of video, identify meaningful features in them and link these features. They also outline a language called VideoSQL for querying such data. <p> The primary aim of this paper is to develop techniques by which video may be organized and queried. Three works that are closely related are <ref> [10] </ref>, [5] and [7], Oomoto and Tanaka [10] have defined a video-based object oriented data model, OVID. They take pieces of video, identify meaningful features in them and link these features. They also outline a language called VideoSQL for querying such data.
Reference: [11] <author> H. Samet. </author> <title> (1989) The Design and Analysis of Spatial Data Structures, </title> <publisher> Addison Wesley. </publisher> <pages> 31 </pages>
Reference-contexts: Each frame sequence can be viewed as a line-segment; hence, associated with any object/activity/event, is a set of line segments. They enhance an existing data structure, called the segment tree (cf. Samet <ref> [11] </ref>) and use that as a basis for querying. This data structure is described below. Each node in a segment tree represents an interval. The root represents the entire interval associated with the movie (e.g. [0; 1200)). <p> Other work on video includes work by Davenport et. al. [4] who argue that segmenting video should not be done at the frame level. This is consistent with our rendition segmenting video at the frame level corresponds to a well-known data structure called the unit segment tree (cf. Samet <ref> [11] </ref>) which is just like the segment tree described here except that leaves always must represent unit intervals, i.e. intervals of the form [i; i + 1).
Reference: [12] <author> R. Weiss, A. Duda and D.K. Gifford. </author> <title> (1994) Content-Based Access to Algebraic Video, </title> <booktitle> Proc. 1994 Intl. Conf. on Multimedia Computing and Systems, </booktitle> <address> Boston, Massachusetts, </address> <month> May </month> <year> 1994, </year> <pages> pps 140-151, </pages> <publisher> IEEE Press. </publisher> <pages> 32 </pages>
References-found: 12

