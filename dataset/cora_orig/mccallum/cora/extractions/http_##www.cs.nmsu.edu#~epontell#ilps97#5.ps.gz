URL: http://www.cs.nmsu.edu/~epontell/ilps97/5.ps.gz
Refering-URL: http://www.cs.nmsu.edu/lldap/ilps97/programme.html
Root-URL: http://www.cs.nmsu.edu
Title: An extension of the WAM for uninitialized variables  
Author: Dante Baldan Nicola Civran Gilberto File 
Keyword: Static Analysis, Abstract Interpretation, Logic Programming, WAM, BAM, GAIA.  
Abstract: An extension of the WAM for handling uninitialized variables is presented. Our modification of the WAM is based on a static analysis designed within the classical Cousot's abstract interpretation framework. The information inferred by our analysis supports the optimization of the WAM code produced for the analyzed programs. The optimization consists in modifying some instructions taking into account the possibility that their inputs can be uninitialized variables. For illustrating the usefulness of our method, we show that it allows to improve the WAM code of the append program. In general, analyses that infer very concrete properties of programs are important because such properties can support significant and easily implementable optimizations of the code generated by compilers. The main contributions of this work are the simplicity of the domain of the analysis, the WAM-like extension supporting the optimization and the fact that the analysis is provably correct according to the well-known proof-scheme of Cousot's framework. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Hassan Ait-Kaci. </author> <title> Warren's Abstract Machine. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year> <title> Prepared with L A T E X. </title>
Reference-contexts: 1. Introduction We present a static analysis of logic programs that supports the production of optimized WAM code <ref> [12, 1] </ref> for these programs. This analysis is designed within the classical Cousot's Abstract Interpretation framework [6, 7]. The information that is inferred by this static analysis is that certain program variables are not initialized as self-referencing pointers. <p> For reading this paper a good knowledge of the WAM is required. A crystal-clear introduction to the WAM is presented by Hassan <ref> [1] </ref>. We will consider logic programs in normalized form as illustrated in the following example. Example Let P be the following logic program. cl : p (f (f (X)),Y,Y) :- q (X,g (g (g (Y))),Z), q (Z,Z,Z). <p> The temporary variables are those that occur in at most one of the body goals of the clause, whereas the permanent ones are those that occur in at least two distinct body goals of the clause. Following the notation used in <ref> [1] </ref>, the argument variables are always indicated with the letter A, the temporary ones with X and the permanent ones with Y, eventually with appropriate superscripts and subscripts. * Given a normalized clause cl : p=n : i 1 ; : : : ; i n where i i can be <p> Uninitialized Variable Analysis This section introduces the concrete and the abstract semantics for the uninitialized variable analysis. Both semantics are characterized by a domain and operations (respectively, concrete and abstract). The concrete semantics is an abstraction of the operational semantics of the WAM so as it is presented in <ref> [1] </ref>, thus familiarity with this work is required for following our description. The concrete semantics is illustrated simply sketching the computation of the meaning of the append program according to this semantics. <p> The Concrete Semantics As uninitialized variable analysis is concerned only with the variables of the clauses of a program, the concrete semantics is obtained from the operational semantics of the WAM <ref> [1] </ref> focusing only on the heap, on the variables of the local stack, and on the argument and temporary variables and ignoring all the other data structures used in the WAM such as the trail, the choice points etc.. In the following we will follow [1] calling stack the memory part <p> operational semantics of the WAM <ref> [1] </ref> focusing only on the heap, on the variables of the local stack, and on the argument and temporary variables and ignoring all the other data structures used in the WAM such as the trail, the choice points etc.. In the following we will follow [1] calling stack the memory part of the WAM made of the heap, the local stack and the argument and temporary variables. <p> Finally unify uninit x variable (I) and unify uninit x value (I), if executed in write mode, simply make the variable I pointing to an uninitialized location, else, if executed in read mode, they perform the binding of I with the input value S (in the notation of <ref> [1] </ref>). The whole optimized code is shown in Fig. 6. 4.2. The BAM and the speed-up Now we compare the information computed by Aquarius and by our analysis. First we consider the input values for the predicate append.
Reference: [2] <author> J. Almgren, S. Andersson, L. Flood, C. Frisk, H. Nilsson, and J. Sundberg. </author> <title> SICStus Prolog Library Manual. </title> <institution> Swedish Institute of Computer Science, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Append For illustrating the concrete semantics we will apply it to the append program that is shown in Fig. 1. Fig. 2 shows the normalized version of the program and Fig. 3 illustrates the corresponding WAM code produced by the SICStus <ref> [2, 8] </ref> Compiler 2.1. 3.1.2. The concrete semantics of Append In what follows we will briefly describe the computation of the concrete values at some of the program points of append . The computation starts from the goal ?-main, following the style of the benchmarks in [10].
Reference: [3] <author> Joachim Beer. </author> <title> The Occur-Check Problem Revisited. </title> <journal> Journal of Logic Programming, </journal> <volume> 5(3) </volume> <pages> 243-261, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Thus, the specified instructions are more efficient then the normal ones because dereferencing is expensive <ref> [10, 11, 3] </ref>. Our analysis allows to discover variables that can be considered as uninitialized. This information supports the optimization consisting in specialized/simplified versions of existing WAM instructions manipulating terms. Van Roy [10] proposed an uninitialized variable analysis for the BAM implemented in the Aquarius Compiler.
Reference: [4] <author> Garrett Birkhoff. </author> <title> Lattice Theory, </title> <booktitle> volume 25 of American Mathematical Society Colloquium Publications. </booktitle> <publisher> American Mathematical Society, </publisher> <address> New York, N.Y., third edition edition, </address> <year> 1967. </year> <booktitle> Workshop on Parallelism and Implementation Technology 15 </booktitle>
Reference-contexts: The optimized version of append is outlined together with performance results. Workshop on Parallelism and Implementation Technology 3 A short conclusion closes the paper. 2. Preliminaries In this section we introduce some terminology used in the paper. A complete introduction to lattice theory is in <ref> [4] </ref> and the theory of Abstract Interpretation can be found in [7]. 2.1. Logic programming We introduce some notation about logic programming [9].
Reference: [5] <author> Baudouin Le Charlier and Pascal Van Hentenryck. </author> <title> Experimental evaluation of a generic abstract interpretation algorithm for PROLOG. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 16(1) </volume> <pages> 35-201, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: In the present work we outline the analysis by means of the append program. The analysis for the introduction of uninitialized variables is performed using GAIA <ref> [5] </ref>. The system where we implemented the extension is the Emulator of SICStus 2.1 extended with an instruction set that handles the uninitialized variables. As a first step of the integration of the analysis within the Emulator we did not take care of the garbage collecting phase.
Reference: [6] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints. </title> <booktitle> In Fourth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 238-252, </pages> <address> Los Ange-les, California, January 1977. </address> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: 1. Introduction We present a static analysis of logic programs that supports the production of optimized WAM code [12, 1] for these programs. This analysis is designed within the classical Cousot's Abstract Interpretation framework <ref> [6, 7] </ref>. The information that is inferred by this static analysis is that certain program variables are not initialized as self-referencing pointers. The goal of the optimization consists in postponing the initialization of the variables as much as possible.
Reference: [7] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation and application to logic programs. </title> <journal> Journal of Logic Programming, </journal> <volume> 13(2-3):103-279, </volume> <month> July </month> <year> 1992. </year>
Reference-contexts: 1. Introduction We present a static analysis of logic programs that supports the production of optimized WAM code [12, 1] for these programs. This analysis is designed within the classical Cousot's Abstract Interpretation framework <ref> [6, 7] </ref>. The information that is inferred by this static analysis is that certain program variables are not initialized as self-referencing pointers. The goal of the optimization consists in postponing the initialization of the variables as much as possible. <p> Workshop on Parallelism and Implementation Technology 3 A short conclusion closes the paper. 2. Preliminaries In this section we introduce some terminology used in the paper. A complete introduction to lattice theory is in [4] and the theory of Abstract Interpretation can be found in <ref> [7] </ref>. 2.1. Logic programming We introduce some notation about logic programming [9]. It is well-known that compilers for logic programs are, in most cases, based on an abstract machine that has been introduced by D.Warren [12] and that is called the Warren Abstract Machine (WAM).
Reference: [8] <author> Ralph Clarke Haygood. </author> <title> Native code compilation in SICStus Prolog. </title> <editor> In Pascal Van Hentenryck, editor, </editor> <booktitle> Logic Programming Proceedings of the Eleventh International Conference on Logic Programming, </booktitle> <pages> pages 190-204, </pages> <institution> Massachusetts Institute of Technology, </institution> <address> 1994. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: Append For illustrating the concrete semantics we will apply it to the append program that is shown in Fig. 1. Fig. 2 shows the normalized version of the program and Fig. 3 illustrates the corresponding WAM code produced by the SICStus <ref> [2, 8] </ref> Compiler 2.1. 3.1.2. The concrete semantics of Append In what follows we will briefly describe the computation of the concrete values at some of the program points of append . The computation starts from the goal ?-main, following the style of the benchmarks in [10].
Reference: [9] <author> R. Kowalski. </author> <title> Logic for Problem Solving. </title> <publisher> North-Holland, </publisher> <address> New York, 4 edition, </address> <year> 1983. </year>
Reference-contexts: Preliminaries In this section we introduce some terminology used in the paper. A complete introduction to lattice theory is in [4] and the theory of Abstract Interpretation can be found in [7]. 2.1. Logic programming We introduce some notation about logic programming <ref> [9] </ref>. It is well-known that compilers for logic programs are, in most cases, based on an abstract machine that has been introduced by D.Warren [12] and that is called the Warren Abstract Machine (WAM). For reading this paper a good knowledge of the WAM is required.
Reference: [10] <author> P. Van Roy. </author> <title> Can Logic Programming Execute as Fast as Imperative Programming. </title> <type> PhD thesis, </type> <institution> Computer Science Division, University of California Berkeley, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: The phenomenon that the analysis aims to avoid is the initialization of a variable as self-referencing memory cell followed by a binding of that variable with another value. This situation is very common as stated in <ref> [10] </ref>. We follow [10] considering the memory cell of an uninitialized variable as containing garbage. <p> The phenomenon that the analysis aims to avoid is the initialization of a variable as self-referencing memory cell followed by a binding of that variable with another value. This situation is very common as stated in <ref> [10] </ref>. We follow [10] considering the memory cell of an uninitialized variable as containing garbage. <p> Thus, the specified instructions are more efficient then the normal ones because dereferencing is expensive <ref> [10, 11, 3] </ref>. Our analysis allows to discover variables that can be considered as uninitialized. This information supports the optimization consisting in specialized/simplified versions of existing WAM instructions manipulating terms. Van Roy [10] proposed an uninitialized variable analysis for the BAM implemented in the Aquarius Compiler. <p> Thus, the specified instructions are more efficient then the normal ones because dereferencing is expensive [10, 11, 3]. Our analysis allows to discover variables that can be considered as uninitialized. This information supports the optimization consisting in specialized/simplified versions of existing WAM instructions manipulating terms. Van Roy <ref> [10] </ref> proposed an uninitialized variable analysis for the BAM implemented in the Aquarius Compiler. The analysis needs two abstract domains: one made of tuples of modes associated with the argument variables of the predicates and one made of 4-tuples of sets of program variables. <p> The concrete semantics of Append In what follows we will briefly describe the computation of the concrete values at some of the program points of append . The computation starts from the goal ?-main, following the style of the benchmarks in <ref> [10] </ref>. The changes from one point to another will be indicated with . <p> What <ref> [10] </ref> proposes is the uninitialization of such memory cells since they will be eventually assigned a 'real' value. 3.2. The Abstract Domain for Uninitialized Variable Analysis The analysis in [10] requires two abstract domains: one made of 4-tuples of sets of variables and one made of tuples of modes associated with <p> What <ref> [10] </ref> proposes is the uninitialization of such memory cells since they will be eventually assigned a 'real' value. 3.2. The Abstract Domain for Uninitialized Variable Analysis The analysis in [10] requires two abstract domains: one made of 4-tuples of sets of variables and one made of tuples of modes associated with the argument variables of the predicates. We adopted an abstract domain made of 3-tuples of sets of variables according to the Abstract Interpretation framework. <p> We adopted an abstract domain made of 3-tuples of sets of variables according to the Abstract Interpretation framework. Therefore our domain is simpler than the one in <ref> [10] </ref> and closer to the Cousot's framework. 3.3. The definition of the abstract domain Let, in what follows, cl be any clause in normalized form. Recall that vars (cl) is the set of the variables of cl. We will describe the values of the abstract domain for cl. <p> Moreover, we adopted a single-input/single-output granularity for the predicates since our goal was not the one of performing multiple specialization of the programs. In the second part we present a comparison with the analysis and with the speed-up obtained by <ref> [10] </ref>. 4.1. The Fixpoint We present the fixpoint computed by our implementation. <p> We ran the code and the optimized code of append on a SUN workstation. The timing results indicate a speed-up of about 7-8% which is comparable with the execution speed-ups 14 Workshop on Parallelism and Implementation Technology of the BAM enhanced with the global dataflow analysis described in <ref> [10] </ref> which contains the recursively dereferenced term analysis and a mode analysis. We ran our analyzer also on an ad hoc program and the optimization results are analogous as in append. The extension of the optimization to other benchmarks will be the next part of the work. 5.
Reference: [11] <author> A. Taylor. </author> <title> Removal of dereferencing and trailing in prolog compilation. </title> <editor> In Levi, Giorgio; Martelli, Maurizio, editor, </editor> <booktitle> Proceedings of the 6th International Conference on Logic Programming (ICLP '89), </booktitle> <pages> pages 48-62, </pages> <address> Lisbon, Portugal, June 1989. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: Thus, the specified instructions are more efficient then the normal ones because dereferencing is expensive <ref> [10, 11, 3] </ref>. Our analysis allows to discover variables that can be considered as uninitialized. This information supports the optimization consisting in specialized/simplified versions of existing WAM instructions manipulating terms. Van Roy [10] proposed an uninitialized variable analysis for the BAM implemented in the Aquarius Compiler.
Reference: [12] <author> David H. D. Warren. </author> <title> An Abstract PROLOG Instruction Set. </title> <type> Technical Report 309, </type> <institution> Artificial Intelligence Center, Computer Science and Technology Division, SRI International, </institution> <address> Menlo Park, CA, </address> <month> October </month> <year> 1983. </year>
Reference-contexts: 1. Introduction We present a static analysis of logic programs that supports the production of optimized WAM code <ref> [12, 1] </ref> for these programs. This analysis is designed within the classical Cousot's Abstract Interpretation framework [6, 7]. The information that is inferred by this static analysis is that certain program variables are not initialized as self-referencing pointers. <p> Logic programming We introduce some notation about logic programming [9]. It is well-known that compilers for logic programs are, in most cases, based on an abstract machine that has been introduced by D.Warren <ref> [12] </ref> and that is called the Warren Abstract Machine (WAM). For reading this paper a good knowledge of the WAM is required. A crystal-clear introduction to the WAM is presented by Hassan [1]. We will consider logic programs in normalized form as illustrated in the following example.
References-found: 12

