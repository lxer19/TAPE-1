URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/94-07.ps.Z
Refering-URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/README.html
Root-URL: 
Email: hexmoor@cs.buffalo.edu  
Title: What are routines good for?  
Author: Henry H. Hexmoor 
Date: February 20, 1994  
Address: NY 14260  
Affiliation: Department of Computer Science SUNY at Buffalo, Buffalo  
Abstract: Routines are patterns of interaction between an agent and its world. Getting in or out of a car, changing lane, and flipping pages of a book can be routines for an agent if the agent consistently engages in these activities in a similar way. I.e., a task for an agent is a routine if the agent that has choices about how to accomplish that task, nevertheless does it in the same way. Consistently putting on the left leg of pants before putting on the right leg would be a routine for an agent. A routine is either imposed upon the agent (a plan at the conscious level to be followed), in which case it need not be discovered, or performed by the agent automatically, i.e., unconsciously. The latter may or may not ever be discovered, i.e., noticed and made conscious. However, the existence of such a routine may guide the agents actions. If it remains unconscious, it aids in choosing among competing actions unconsciously as an unexplained tendency or a preference. If it is noticed and made conscious, it can also be used as a concept and used in reasoning about actions and planning. We show how agents with routines a) use them to guide their everyday activity, b) use them to enrich their abstract concepts about acts. 
Abstract-found: 1
Intro-found: 1
Reference: [AC87] <author> Philip E. Agre and David Chap-man. Pengi: </author> <title> An implementation of a theory of activity. In Pro 15 Naturally, since we want this learning to be done by Gerry the name for the routine will be anonymous (a "gensym" in Lisp terms). Semantics of the routine for Gerry will be in terms of PMA. </title> <booktitle> ceedings of AAAI-87, </booktitle> <address> Seattle, Wa., </address> <pages> pages 268-272, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: In our work we try to understand and find ways in which routines can be formalized as well as their impact on learning about act, actions, and skills. "Routines are patterns of interaction between an agent and its world" <ref> [AC87] </ref>. Getting in or out of a car, changing lanes, and flipping pages of a book can be routines for an agent if the agent consistently engages in these activities in a similar way. <p> On the other hand, a routine might be a plan, a set of policies, or a script to be followed. 3 Following the research in situated activity <ref> [Suc88, AC87, Nil92] </ref>, we would like an agent to operate with situated actions instead of planned actions.
Reference: [Agr88] <author> Philip Agre. </author> <title> The dynamic structure of everyday life. </title> <type> Technical Report 1085, </type> <institution> MIT Artificial Intelligence Laboratory, MIT, </institution> <year> 1988. </year>
Reference-contexts: Consistently putting on the left leg of pants before putting on the right leg would be a routine for an agent. 1 In <ref> [Agr88] </ref>, a routine is described as a frequently repeated pattern of activity between an agent and the world, e.g., picking up a fork, making a bowl of cereal, putting on a heavy backpack, selecting a toll booth at the San Francisco Bay Bridge, putting a watch on, breaking an egg into
Reference: [Dru89] <author> Mark Drummond. </author> <title> Situated control rules. </title> <booktitle> In Proceedings Of the first conference on principles of knowledge representation, </booktitle> <pages> pages 103-113. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1989. </year>
Reference-contexts: We can consider this process of learning as a form of caching a plan into reactive plans as was done in <ref> [Sch87, Dru89] </ref>. Another way that the agent's actions is guided by routines is by refining skills at the unconscious level. There are many routines that need not have a concept associated with them at the conscious level, but nevertheless are useful in guiding actions.
Reference: [HCBS93] <author> Henry Hexmoor, Guido Caicedo, Frank Bidwell, and Stuart Shapiro. </author> <title> Air battle simulation: An agent with conscious and unconscious layers. </title> <institution> In University of Buffalo Graduate Conference in Computer Science-93 (TR93-14). Dept. of Computer Science, SUNY at Buffalo, </institution> <address> New York, </address> <year> 1993. </year>
Reference-contexts: In the larger context of intelligent agency, we argue that situated activity is a particular form of interaction between an agent and its environment that is produced by an agent when it is involved in unconscious interaction <ref> [HLS92, HLCS93, HCBS93] </ref>. Elsewhere, in [HS93], we discuss that unconscious actions are part of an agent's skills as opposed to its knowledge. When routines are unconscious they can be considered to be skills. On the other hand, an agent may also engage in conscious, reasoned out routine. <p> On the other hand, an agent may also engage in conscious, reasoned out routine. We have developed an architecture that facilitates modeling conscious and unconscious interactions of an agent with the world. Our architecture is GLAIR&lt; (Grounded Layered Architecture with Integrated Reasoning) <ref> [HN92, HLS92, HCBS93, HLCS93, HLS93, LHS93, HS93] </ref>. GLAIR is an architecture for intelligent autonomous agents that endows 2 In computational terms this is like a macro. <p> dogfight simulation game we call Air Battle Simulation (ABS). "Gabby," is the agent in this game which stands for "GLAIR air battler." Initially, Gabby has not acquired a PMA for the game yet, and so uses conscious level reasoning (i.e., SNePS behavioral rules [SR87]) to decide what move to make <ref> [HCBS93] </ref>. This is the case of a routine activity leading to becoming automatic. The routine is not being learned through automaticity. This form of learning does not encode or discover a routine but makes use of it. What is developed with RBL is a connection between situations and actions.
Reference: [Hen69] <author> Derek P. Hendrey. </author> <title> Conditioned Reinforcement. </title> <publisher> The Dorsey Press, </publisher> <year> 1969. </year>
Reference-contexts: Reinforcement learning is a trial-and-error process where, upon executing an action, applicability of actions to situations are updated based on the reinforcement signal received in response to the action. An action elicited by a stimulus is known as a respondent <ref> [Hen69] </ref>. 6 This is in contrast to actions controlled by their consequences [Hen69]. 7 For an RBL application, a set of states, a number of actions, and a reward system that determines rewards for being in a state are given. <p> An action elicited by a stimulus is known as a respondent <ref> [Hen69] </ref>. 6 This is in contrast to actions controlled by their consequences [Hen69]. 7 For an RBL application, a set of states, a number of actions, and a reward system that determines rewards for being in a state are given. The connection between actions and states is not given or it is underspecified.
Reference: [HLCS93] <author> Henry Hexmoor, Johan Lammens, Guido Caicedo, and Stuart C. Shapiro. </author> <title> Behavior Based AI, Cognitive Processes, and Emergent Behaviors in Autonomous Agents. </title> <booktitle> In Proceedings of AI in Engineering, </booktitle> <year> 1993. </year>
Reference-contexts: In the larger context of intelligent agency, we argue that situated activity is a particular form of interaction between an agent and its environment that is produced by an agent when it is involved in unconscious interaction <ref> [HLS92, HLCS93, HCBS93] </ref>. Elsewhere, in [HS93], we discuss that unconscious actions are part of an agent's skills as opposed to its knowledge. When routines are unconscious they can be considered to be skills. On the other hand, an agent may also engage in conscious, reasoned out routine. <p> On the other hand, an agent may also engage in conscious, reasoned out routine. We have developed an architecture that facilitates modeling conscious and unconscious interactions of an agent with the world. Our architecture is GLAIR&lt; (Grounded Layered Architecture with Integrated Reasoning) <ref> [HN92, HLS92, HCBS93, HLCS93, HLS93, LHS93, HS93] </ref>. GLAIR is an architecture for intelligent autonomous agents that endows 2 In computational terms this is like a macro.
Reference: [HLS92] <author> Henry Hexmoor, Joe Lammens, and Stuart Shapiro. </author> <title> An autonomous agent architecture for integrating perception and acting with grounded, embodied symbolic reasoning. </title> <type> Technical Report CS-92-21, </type> <institution> Dept. of Computer Science, SUNY at Buffalo, </institution> <address> New York, </address> <year> 1992. </year>
Reference-contexts: In the larger context of intelligent agency, we argue that situated activity is a particular form of interaction between an agent and its environment that is produced by an agent when it is involved in unconscious interaction <ref> [HLS92, HLCS93, HCBS93] </ref>. Elsewhere, in [HS93], we discuss that unconscious actions are part of an agent's skills as opposed to its knowledge. When routines are unconscious they can be considered to be skills. On the other hand, an agent may also engage in conscious, reasoned out routine. <p> On the other hand, an agent may also engage in conscious, reasoned out routine. We have developed an architecture that facilitates modeling conscious and unconscious interactions of an agent with the world. Our architecture is GLAIR&lt; (Grounded Layered Architecture with Integrated Reasoning) <ref> [HN92, HLS92, HCBS93, HLCS93, HLS93, LHS93, HS93] </ref>. GLAIR is an architecture for intelligent autonomous agents that endows 2 In computational terms this is like a macro. <p> Reading a driver's manual we are told about passing another vehicle and although that may not be the only way to pass another vehicle we adopt it. Once our conscious knowledge of passing another vehicle is practiced it becomes part of our skills and in our framework of GLAIR <ref> [HLS92] </ref> we consider it to have become unconscious. We can consider this process of learning as a form of caching a plan into reactive plans as was done in [Sch87, Dru89]. Another way that the agent's actions is guided by routines is by refining skills at the unconscious level.
Reference: [HLS93] <author> Henry Hexmoor, Johan Lammens, and Stuart C. Shapiro. </author> <title> Embodiment in GLAIR: A Grounded Layered Architecture with Integrated Reasoning. </title> <booktitle> In Florida AI Research Symposium, </booktitle> <pages> pages 325-329, </pages> <year> 1993. </year> <note> also available as SUNYAB CS Dept. TR93-10. </note>
Reference-contexts: On the other hand, an agent may also engage in conscious, reasoned out routine. We have developed an architecture that facilitates modeling conscious and unconscious interactions of an agent with the world. Our architecture is GLAIR&lt; (Grounded Layered Architecture with Integrated Reasoning) <ref> [HN92, HLS92, HCBS93, HLCS93, HLS93, LHS93, HS93] </ref>. GLAIR is an architecture for intelligent autonomous agents that endows 2 In computational terms this is like a macro.
Reference: [HN92] <author> Henry Hexmoor and Donald Nute. </author> <title> Methods for deciding what to do next and learning. Technical Re--port AI-1992-01, AI Programs, </title> <institution> The University of Georgia, Athens, Georgia, </institution> <year> 1992. </year> <note> Also available from SUNY at Buffalo, CS Department TR-92-23. </note>
Reference-contexts: On the other hand, an agent may also engage in conscious, reasoned out routine. We have developed an architecture that facilitates modeling conscious and unconscious interactions of an agent with the world. Our architecture is GLAIR&lt; (Grounded Layered Architecture with Integrated Reasoning) <ref> [HN92, HLS92, HCBS93, HLCS93, HLS93, LHS93, HS93] </ref>. GLAIR is an architecture for intelligent autonomous agents that endows 2 In computational terms this is like a macro.
Reference: [HS93] <author> Henry Hexmoor and Stuart C. Shapiro. </author> <title> Examining the expert reveals expertise. </title> <booktitle> In 3rd International Workshop on Human and Machine Cognition: Expertise in Context, </booktitle> <year> 1993. </year> <note> to appear. </note>
Reference-contexts: In the larger context of intelligent agency, we argue that situated activity is a particular form of interaction between an agent and its environment that is produced by an agent when it is involved in unconscious interaction [HLS92, HLCS93, HCBS93]. Elsewhere, in <ref> [HS93] </ref>, we discuss that unconscious actions are part of an agent's skills as opposed to its knowledge. When routines are unconscious they can be considered to be skills. On the other hand, an agent may also engage in conscious, reasoned out routine. <p> On the other hand, an agent may also engage in conscious, reasoned out routine. We have developed an architecture that facilitates modeling conscious and unconscious interactions of an agent with the world. Our architecture is GLAIR&lt; (Grounded Layered Architecture with Integrated Reasoning) <ref> [HN92, HLS92, HCBS93, HLCS93, HLS93, LHS93, HS93] </ref>. GLAIR is an architecture for intelligent autonomous agents that endows 2 In computational terms this is like a macro.
Reference: [LHS93] <author> Johan Lammens, Henry Hexmoor, and Stuart C. Shapiro. </author> <title> Of elephants and men. </title> <booktitle> In Proceedings of NATO-ASI. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1993. </year> <note> to appear. </note>
Reference-contexts: On the other hand, an agent may also engage in conscious, reasoned out routine. We have developed an architecture that facilitates modeling conscious and unconscious interactions of an agent with the world. Our architecture is GLAIR&lt; (Grounded Layered Architecture with Integrated Reasoning) <ref> [HN92, HLS92, HCBS93, HLCS93, HLS93, LHS93, HS93] </ref>. GLAIR is an architecture for intelligent autonomous agents that endows 2 In computational terms this is like a macro.
Reference: [Neh92] <author> Ulrich Nehmzow. </author> <title> Experiments in Comptence Acquisition for Autonomous Mobile Robots. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1992. </year>
Reference-contexts: Many recent works in mobile robotics have addressed learning isolated actions, particularly through neural network approaches, e.g. <ref> [Neh92] </ref>. In our approach, we don't isolate actions for learning. Instead we focus on emeregnt sequences of actions that are parts of larger tasks and unspervised learning of these action sequences.
Reference: [Nil92] <author> Nils J. Nilsson. </author> <title> Toward agent programs with circuit semantics. </title> <type> Technical Report STAN-CS-92-1412, </type> <institution> Stanford University, Stanford, </institution> <address> CA., </address> <year> 1992. </year>
Reference-contexts: On the other hand, a routine might be a plan, a set of policies, or a script to be followed. 3 Following the research in situated activity <ref> [Suc88, AC87, Nil92] </ref>, we would like an agent to operate with situated actions instead of planned actions.
Reference: [Sch87] <author> Marcel J. Schoppers. </author> <title> Universal plans for unpredictable environments. </title> <booktitle> In Proceedings 10th IJCAI, </booktitle> <pages> pages 1039-1046, </pages> <year> 1987. </year>
Reference-contexts: We can consider this process of learning as a form of caching a plan into reactive plans as was done in <ref> [Sch87, Dru89] </ref>. Another way that the agent's actions is guided by routines is by refining skills at the unconscious level. There are many routines that need not have a concept associated with them at the conscious level, but nevertheless are useful in guiding actions.
Reference: [SR87] <author> S. C. Shapiro and W. J. Rapa-port. </author> <title> SNePS considered as a fully intensional propositional semantic network. </title> <editor> In N. Cercone and G. McGalla, editors, </editor> <booktitle> The knowledge frontier: essays in the representation of knowledge, </booktitle> <pages> pages 262-315. </pages> <publisher> Springer, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: implementation of a World War I style dogfight simulation game we call Air Battle Simulation (ABS). "Gabby," is the agent in this game which stands for "GLAIR air battler." Initially, Gabby has not acquired a PMA for the game yet, and so uses conscious level reasoning (i.e., SNePS behavioral rules <ref> [SR87] </ref>) to decide what move to make [HCBS93]. This is the case of a routine activity leading to becoming automatic. The routine is not being learned through automaticity. This form of learning does not encode or discover a routine but makes use of it.
Reference: [Suc88] <author> Lucy A. Suchman. </author> <title> Plans and Situated Actions: The Problem of Human Machine Communication. </title> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: On the one hand, such a course of action can be considered to be a skill. 2 Since routines as skills are not plans, there can be no guarantee for success of a routine. Since we are concerned with every day activities, we are considering situated actions <ref> [Suc88] </ref>, i.e., actions that an agent exhibits without reasoning or making conscious decisions, ergo unconscious behaviors. <p> On the other hand, a routine might be a plan, a set of policies, or a script to be followed. 3 Following the research in situated activity <ref> [Suc88, AC87, Nil92] </ref>, we would like an agent to operate with situated actions instead of planned actions.
References-found: 16

