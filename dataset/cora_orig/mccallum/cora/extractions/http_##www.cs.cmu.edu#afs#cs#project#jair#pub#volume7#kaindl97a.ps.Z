URL: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume7/kaindl97a.ps.Z
Refering-URL: http://www.cs.washington.edu/research/jair/abstracts/kaindl97a.html
Root-URL: 
Email: hermann.kaindl@siemens.at  gerhard.kainz@siemens.at  
Title: Bidirectional Heuristic Search Reconsidered  
Author: Hermann Kaindl Gerhard Kainz 
Address: Geusaugasse 17 A-1030 Vienna, Austria  
Affiliation: Siemens AG Osterreich, PSE  
Note: Journal of Artificial Intelligence Research 7 (1997) 283-317 Submitted 8/97; published 12/97  
Abstract: The assessment of bidirectional heuristic search has been incorrect since it was first published more than a quarter of a century ago. For quite a long time, this search strategy did not achieve the expected results, and there was a major misunderstanding about the reasons behind it. Although there is still wide-spread belief that bidirectional heuristic search is a*icted by the problem of search frontiers passing each other, we demonstrate that this conjecture is wrong. Based on this finding, we present both a new generic approach to bidirectional heuristic search and a new approach to dynamically improving heuristic values that is feasible in bidirectional search only. These approaches are put into perspective with both the traditional and more recently proposed approaches in order to facilitate a better overall understanding. Empirical results of experiments with our new approaches show that bidirectional heuristic search can be performed very efficiently and also with limited memory. These results suggest that bidirectional heuristic search appears to be better for solving certain difficult problems than corresponding unidirectional search. This provides some evidence for the usefulness of a search strategy that was long neglected. In summary, we show that bidirectional heuristic search is viable and consequently propose that it be reconsidered.
Abstract-found: 1
Intro-found: 1
Reference: <author> Chakrabarti, P., Ghose, S., Acharya, A., & DeSarkar, S. </author> <year> (1989). </year> <title> Heuristic search in restricted memory. </title> <journal> Artificial Intelligence, </journal> <volume> 41 (2), </volume> <pages> 197-221. </pages>
Reference-contexts: When such a cached node is re-searched, an improved value can often be used instead of the value assigned directly by the static evaluation function. Apart from its use in Trans, this back-up idea is actually widely applied in many algorithms like MA* <ref> (Chakrabarti, Ghose, Acharya, & DeSarkar, 1989) </ref>, MREC (Sen & Bagchi, 1989), RTA* (Korf, 1990), SMA* (Russell, 1992) and ITS (Ghosh, Mahanti, & Nau, 1994). 287 Kaindl & Kainz Its advantages are very little overhead and steady (though often modest) improvement with increasing memory size.
Reference: <author> Culberson, J., & Schaeffer, J. </author> <year> (1996). </year> <title> Searching with pattern databases. </title> <editor> In McCalla, G. (Ed.), </editor> <booktitle> Advances in Artificial Intelligence, </booktitle> <pages> pp. 402-416. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: Since IDA*-Probing has no overhead in running time, it is even faster than Max-IDA*. In order to see how well probing via three iterations already indicates the better search direction, we compared its result with that 12. With much improved heuristic functions, much more efficient searches result <ref> (Culberson & Schaeffer, 1996) </ref> and even solving Twenty-Four Puzzle instances has become feasible (Korf & Taylor, 1996). 308 Bidirectional Heuristic Search Reconsidered of a perfect oracle.
Reference: <author> Davis, H., Pollack, R., & Sudkamp, T. </author> <year> (1984). </year> <title> Towards a better understanding of bidirectional search. </title> <booktitle> In Proc. Fourth National Conference on Artificial Intelligence (AAAI-84), </booktitle> <pages> pp. 68-72. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press / The MIT Press. de Champeaux, </publisher> <address> D. </address> <year> (1983). </year> <title> Bidirectional heuristic search again. </title> <journal> J. ACM, </journal> <volume> 30 (1), </volume> <pages> 22-32. </pages> <editor> de Champeaux, D., & Sint, L. </editor> <year> (1977). </year> <title> An improved bidirectional heuristic search algorithm. </title>
Reference-contexts: consensus about the belief that the search frontiers would pass each other, research focused on algorithms that would force the "wavefronts" to meet through "wave-shaping" techniques: BHFFA (de Champeaux & Sint, 1977), BHFFA2 (de Champeaux, 1983), d-node retargeting (Politowski & Pohl, 1984) and a generalized algorithm (encompassing BHPA and BHFFA2) <ref> (Davis, Pollack, & Sudkamp, 1984) </ref>. These 289 Kaindl & Kainz algorithms perform front-to-front evaluations and they show that bidirectional heuristic search can be efficient in terms of the number of nodes generated.
Reference: <author> J. </author> <booktitle> ACM, </booktitle> <volume> 24 (2), </volume> <pages> 177-191. </pages>
Reference: <author> Dechter, R., & Pearl, J. </author> <year> (1985). </year> <title> Generalized best-first strategies and the optimality of A fl </title> . 
Reference-contexts: Under certain conditions, A* is optimal over admissible unidirectional heuristic search algorithms using the same information, in the sense that it never expands more nodes than any of these <ref> (Dechter & Pearl, 1985) </ref>. We emphasize here that this optimality result of A* only compares it with unidirectional competitors, so a bidirectional approach may well improve on the performance of A*. <p> After all, A* is under certain conditions and in a certain sense optimal with respect to node expansions <ref> (Dechter & Pearl, 1985) </ref>. 4.1 Instantiating for Limited Memory First we show how our generic approach can be instantiated when only limited memory is available. Of course, any such instantiation should make use of any available domain-specific information. <p> Under this condition, it is reasonable to select IDA* as a linear-space search algorithm, since difficult problem instances of the Fifteen Puzzle require too much memory using A*, when only the Manhattan distance heuristic is used. Since A* makes good use of consistent heuristics like this one <ref> (Dechter & Pearl, 1985) </ref>, we select it for the part of the best-first search. 300 Bidirectional Heuristic Search Reconsidered Based on the key idea of bidirectional search, we let A* and IDA* search in opposite directions in steps 2 and 3 of our generic approach, respectively. <p> This is particularly interesting, since the optimality result of A* over unidirectional algorithms is stated in the sense that A* never expands a node that could be skipped by some other (unidirectional) algorithm <ref> (Dechter & Pearl, 1985) </ref>. Since the relative results on the 1000 fi 1000 mazes are very similar, we do not show them explicitly here (see, however, Kainz, 1996). They provide some empirical evidence that the performance of these algorithms is not just peculiar for a certain size of mazes. 7.
Reference: <author> J. </author> <booktitle> ACM, </booktitle> <volume> 32 (3), </volume> <pages> 505-536. </pages>
Reference: <author> Dijkstra, E. </author> <year> (1959). </year> <title> A note on two problems in connexion with graphs. </title> <booktitle> In Numerische Mathematik 1, </booktitle> <pages> pp. 269-271. </pages>
Reference: <author> Dillenburg, J., & Nelson, P. </author> <year> (1994). </year> <title> Perimeter search. </title> <journal> Artificial Intelligence, </journal> <volume> 65 (1), </volume> <pages> 165-178. </pages>
Reference-contexts: After this search is finished and the nodes are stored, a forward search starts from s, targeting all of the perimeter nodes. Depending on the given problem and the available storage, this forward search can be performed in an A* or IDA* fashion. The former is implemented in PS* <ref> (Dillenburg & Nelson, 1994) </ref>, and the latter both in IDPS* (Dillenburg & Nelson, 1994) and in BIDA* (Manzini, 1995). For the same perimeter depth, IDPS* and BIDA* search exactly the same nodes. <p> Depending on the given problem and the available storage, this forward search can be performed in an A* or IDA* fashion. The former is implemented in PS* <ref> (Dillenburg & Nelson, 1994) </ref>, and the latter both in IDPS* (Dillenburg & Nelson, 1994) and in BIDA* (Manzini, 1995). For the same perimeter depth, IDPS* and BIDA* search exactly the same nodes. <p> We made experiments of finding optimal solutions to a set of maze problems. 6 For these problems, BIDA* based on IDA* is inefficient due to the high number of iterations. So, we used here PS* <ref> (Dillenburg & Nelson, 1994) </ref> which implements the common underlying idea | perimeter search | based on A*. <p> While it may seem that the implementation of BS* could be further optimized, it is clear that there is some overhead as compared to A*. So, BS* can certainly not improve on A* here. PS* <ref> (Dillenburg & Nelson, 1994) </ref> | using perimeter search, i.e., the front-to-front method | generates 99.3 percent of the number of nodes of A*, but it needs 119.8 percent of the time used by A*.
Reference: <author> Ghosh, S., Mahanti, A., & Nau, D. </author> <year> (1994). </year> <title> ITS: an efficient limited-memory heuristic tree search algorithm. </title> <booktitle> In Proc. Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pp. 1353-1358. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press / The MIT Press. </publisher>
Reference-contexts: Apart from its use in Trans, this back-up idea is actually widely applied in many algorithms like MA* (Chakrabarti, Ghose, Acharya, & DeSarkar, 1989), MREC (Sen & Bagchi, 1989), RTA* (Korf, 1990), SMA* (Russell, 1992) and ITS <ref> (Ghosh, Mahanti, & Nau, 1994) </ref>. 287 Kaindl & Kainz Its advantages are very little overhead and steady (though often modest) improvement with increasing memory size.
Reference: <author> Hart, P., Nilsson, N., & Raphael, B. </author> <year> (1968). </year> <title> A formal basis for the heuristic determination of minimum cost paths. </title> <journal> IEEE Transactions on Systems Science and Cybernetics (SSC), </journal> <volume> SSC-4 (2), </volume> <pages> 100-107. </pages> <note> 315 Kaindl & Kainz Kaindl, </note> <author> H. </author> <year> (1990). </year> <title> Tree searching algorithms. </title> <editor> In Marsland, T., & Schaeffer, J. (Eds.), </editor> <title> Computers, Chess, </title> <journal> and Cognition, </journal> <pages> pp. 133-158. </pages> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: Rather, we focus on those unidirectional algorithms that form the basis of bidirectional search as discussed in this paper. First, we review the traditional best-first search algorithm A* <ref> (Hart, Nilsson, & Raphael, 1968) </ref>. Then, we shortly explain the linear-space algorithm IDA* (iterative-deepening-A*) proposed by Korf (1985). Finally, we review an algorithm called Trans (Reinefeld & Marsland, 1994) that implements a form of enhanced iterative-deepening search.
Reference: <author> Kaindl, H., Kainz, G., Leeb, A., & Smetana, H. </author> <year> (1995). </year> <title> How to use limited memory in heuristic search. </title> <booktitle> In Proc. Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), </booktitle> <pages> pp. 236-242. </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: It would not be too difficult to perceive an even more general approach that subsumes perimeter search. Because of the expensive front-to-front evaluations, however, we wanted 10. This approach is different from the one that we proposed earlier <ref> (Kaindl, Kainz, Leeb, & Smetana, 1995) </ref>. 299 Kaindl & Kainz to devise an approach that avoids the need to find a balance between the cost of such evaluations and their beneficial effect.
Reference: <author> Kaindl, H., & Khorsand, A. </author> <year> (1994). </year> <title> Memory-bounded bidirectional search. </title> <booktitle> In Proc. Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pp. 1359-1364. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press / The MIT Press. </publisher>
Reference: <author> Kaindl, H., Leeb, A., & Smetana, H. </author> <year> (1994). </year> <title> Improvements on linear-space search algorithms. </title> <booktitle> In Proc. Eleventh European Conference on Artificial Intelligence (ECAI-94), </booktitle> <pages> pp. 155-159. </pages> <address> Chichester, England: </address> <publisher> Wiley. </publisher>
Reference: <author> Kaindl, H., & Scheucher, A. </author> <year> (1992). </year> <title> Reasons for the effects of bounded look-ahead search. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics (SMC), </journal> <volume> 22 (5), </volume> <pages> 992-1007. </pages>
Reference: <author> Kaindl, H., & Smetana, H. </author> <year> (1994). </year> <title> Experimental comparison of heuristic search algorithms. </title> <booktitle> In AAAI-94 Workshop on Experimental Evaluation of Reasoning and Search Methods, </booktitle> <pages> pp. 11-14. </pages>
Reference: <author> Kainz, G. </author> <year> (1994). </year> <institution> Heuristische Suche in Graphen mit der Differenz-Methode. Diplomarbeit, Technische Universitat Wien, Vienna, Austria. </institution>
Reference-contexts: For more details on this method and its theoretical properties we refer the interested reader to <ref> (Kainz, 1994) </ref>. 5.2 The Max Method The second method computes its own estimate based on such differences and uses the maximum of this and the static estimate. Therefore, we call it the Max method. See Fig. 8 for the key idea of this method.
Reference: <author> Kainz, G. </author> <year> (1996). </year> <institution> Neue Algorithmen fur die bidirektionale heuristische Suche. Doctoral dissertation, Technische Universitat Wien, Vienna, Austria. </institution>
Reference-contexts: Actually, application is also possible in the context of traditional bidirec 302 Bidirectional Heuristic Search Reconsidered tional search like BS*. This involves, however, intricacies that are beyond the scope of this paper. So, the interested reader is referred to <ref> (Kainz, 1996) </ref>. 5.1 The Add Method The first method instantiates this approach by adding a constant derived from such differences to the heuristic values of the static evaluation function. Therefore, we call it the Add method. <p> The difference is Diff 2 (A) = g 1 (A) h 2 (A). We use this difference for the construction of an admissible estimate F 1 (A) of the cost of an 11. Earlier we called it Add-A* <ref> (Kainz & Kaindl, 1996) </ref>. 305 Kaindl & Kainz optimal path from s to t that is constrained to go through A. Note, that g 1 (A) = g fl 1 (A) is not necessary, so we call the difference used here Diff 2 (A) instead of Diff fl 2 (A). <p> We call the resulting algorithm that is based on this idea Max-IDA*. For more details on this method and its theoretical properties we refer the interested reader to <ref> (Kainz, 1996) </ref>. 307 Kaindl & Kainz 6. <p> However, we prefer to compare the algorithms using the most efficient implementation that we have available. For more details on these results see <ref> (Kainz, 1996) </ref>. 6.2 Mazes In order to get a better understanding of the usefulness of our new approach, we made also experiments in a second domain | finding shortest paths in a maze. These are the same maze problems as described above in Subsection 3.2. <p> Since the relative results on the 1000 fi 1000 mazes are very similar, we do not show them explicitly here <ref> (see, however, Kainz, 1996) </ref>. They provide some empirical evidence that the performance of these algorithms is not just peculiar for a certain size of mazes. 7. Discussion After this presentation of our new approach to bidirectional heuristic search and its experimental results, let us put it into perspective. <p> So, in the context of a traditional bidirectional search it is initially small. * Applying the Max idea becomes much more complex, e.g., in BS* where both search frontiers change <ref> (Kainz, 1996) </ref>. In general, one of the major problems of heuristic search is how to use available but limited memory effectively.
Reference: <author> Kainz, G., & Kaindl, H. </author> <year> (1996). </year> <title> Dynamic improvements of heuristic evaluations during search. </title> <booktitle> In Proc. Thirteenth National Conference on Artificial Intelligence (AAAI-96), </booktitle> <pages> pp. 311-317. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press / The MIT Press. </publisher>
Reference-contexts: Actually, application is also possible in the context of traditional bidirec 302 Bidirectional Heuristic Search Reconsidered tional search like BS*. This involves, however, intricacies that are beyond the scope of this paper. So, the interested reader is referred to <ref> (Kainz, 1996) </ref>. 5.1 The Add Method The first method instantiates this approach by adding a constant derived from such differences to the heuristic values of the static evaluation function. Therefore, we call it the Add method. <p> The difference is Diff 2 (A) = g 1 (A) h 2 (A). We use this difference for the construction of an admissible estimate F 1 (A) of the cost of an 11. Earlier we called it Add-A* <ref> (Kainz & Kaindl, 1996) </ref>. 305 Kaindl & Kainz optimal path from s to t that is constrained to go through A. Note, that g 1 (A) = g fl 1 (A) is not necessary, so we call the difference used here Diff 2 (A) instead of Diff fl 2 (A). <p> We call the resulting algorithm that is based on this idea Max-IDA*. For more details on this method and its theoretical properties we refer the interested reader to <ref> (Kainz, 1996) </ref>. 307 Kaindl & Kainz 6. <p> However, we prefer to compare the algorithms using the most efficient implementation that we have available. For more details on these results see <ref> (Kainz, 1996) </ref>. 6.2 Mazes In order to get a better understanding of the usefulness of our new approach, we made also experiments in a second domain | finding shortest paths in a maze. These are the same maze problems as described above in Subsection 3.2. <p> Since the relative results on the 1000 fi 1000 mazes are very similar, we do not show them explicitly here <ref> (see, however, Kainz, 1996) </ref>. They provide some empirical evidence that the performance of these algorithms is not just peculiar for a certain size of mazes. 7. Discussion After this presentation of our new approach to bidirectional heuristic search and its experimental results, let us put it into perspective. <p> So, in the context of a traditional bidirectional search it is initially small. * Applying the Max idea becomes much more complex, e.g., in BS* where both search frontiers change <ref> (Kainz, 1996) </ref>. In general, one of the major problems of heuristic search is how to use available but limited memory effectively.
Reference: <author> Koll, A., & Kaindl, H. </author> <year> (1993). </year> <title> Bidirectional best-first search with bounded error: Summary of results. </title> <booktitle> In Proc. Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pp. 217-223. </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference: <author> Korf, R. </author> <year> (1985). </year> <title> Depth-first iterative deepening: An optimal admissible tree search. </title> <journal> Artificial Intelligence, </journal> <volume> 27 (1), </volume> <pages> 97-109. </pages>
Reference: <author> Korf, R. </author> <year> (1990). </year> <title> Real-time heuristic search. </title> <journal> Artificial Intelligence, </journal> <volume> 42 (2-3), </volume> <pages> 189-212. </pages>
Reference-contexts: Apart from its use in Trans, this back-up idea is actually widely applied in many algorithms like MA* (Chakrabarti, Ghose, Acharya, & DeSarkar, 1989), MREC (Sen & Bagchi, 1989), RTA* <ref> (Korf, 1990) </ref>, SMA* (Russell, 1992) and ITS (Ghosh, Mahanti, & Nau, 1994). 287 Kaindl & Kainz Its advantages are very little overhead and steady (though often modest) improvement with increasing memory size.
Reference: <author> Korf, R., & Taylor, L. </author> <year> (1996). </year> <title> Finding optimal solutions to the Twenty-Four Puzzle. </title> <booktitle> In Proc. Thirteenth National Conference on Artificial Intelligence (AAAI-96), </booktitle> <pages> pp. 1202-1207. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press / The MIT Press. </publisher>
Reference-contexts: In order to see how well probing via three iterations already indicates the better search direction, we compared its result with that 12. With much improved heuristic functions, much more efficient searches result (Culberson & Schaeffer, 1996) and even solving Twenty-Four Puzzle instances has become feasible <ref> (Korf & Taylor, 1996) </ref>. 308 Bidirectional Heuristic Search Reconsidered of a perfect oracle.
Reference: <author> Kwa, J. </author> <year> (1989). </year> <title> BS fl : An Admissible Bidirectional Staged Heuristic Search Algorithm. </title> <journal> Artificial Intelligence, </journal> <volume> 38 (2), </volume> <pages> 95-109. </pages>
Reference-contexts: Since understanding this condition is important for this paper, we elaborate it in more depth below. Implicitly this is also the condition for successful termination of the improved algorithm BS* <ref> (Kwa, 1989) </ref>, which removes all nodes n whose f d -values are L min and terminates when Open 1 or Open 2 is empty.
Reference: <author> Lawler, E., & Wood, D. </author> <year> (1966). </year> <title> Branch-and-bound methods: a survey. </title> <journal> Operations Research, </journal> <volume> 14 (4), </volume> <month> 699-719. </month> <title> Bidirectional Heuristic Search Reconsidered Manzini, </title> <editor> G. </editor> <year> (1995). </year> <title> BIDA*: an improved perimeter search algorithm. </title> <journal> Artificial Intelligence, </journal> <volume> 75 (2), </volume> <pages> 347-360. </pages>
Reference-contexts: In particular, it should combine those unidirectional search algorithms that best suit the properties of the domain (see, e.g., Rao et al., 1991; Zhang & Korf, 1993). For example, in some domains IDA* is the choice, while in others depth-first branch-and-bound <ref> (Lawler & Wood, 1966) </ref> is much better. In the case of limited memory, either of them is to be preferred over A*. Below we will present experimental results on the Fifteen Puzzle, a domain that is characterized by having only few distinct cost values.
Reference: <author> Nilsson, N. </author> <year> (1980). </year> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga, </publisher> <address> Palo Alto, CA. </address>
Reference-contexts: When there is one goal node t explicitly given and the search operators are reversible, bidirectional search is possible, which proceeds both in the forward direction from s to t and in the backward direction from t to s <ref> (see, e.g., Nilsson, 1980) </ref>. Strictly speaking, it is not even required that operators have inverses. It is just necessary that for a given node n the set of parent nodes p i can be determined for which there exist operators that lead from p i to n.
Reference: <author> Pearl, J. </author> <year> (1984). </year> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: Finding such a solution can be attempted by searching this graph. If the search is guided by heuristic information, it is called a heuristic search. Most of the work on heuristic search for problem solving deals with unidirectional approaches, that start from s heading towards some node t <ref> (see, e.g., Pearl, 1984) </ref>. When there is one goal node t explicitly given and the search operators are reversible, bidirectional search is possible, which proceeds both in the forward direction from s to t and in the backward direction from t to s (see, e.g., Nilsson, 1980). <p> So, only the evaluator H 1 is actually used, which is consistent, and therefore A* does not have to re-open nodes <ref> (Pearl, 1984) </ref>. The search terminates when it selects some node n for expansion with f 1 (n) = g 1 (n) + H 1 (n) not being smaller than the cost of the best solution found so far, which is proven this way to be an optimal one.
Reference: <author> Pohl, I. </author> <year> (1970). </year> <title> First results on the effect of error in heuristic search. </title> <editor> In Meltzer, B., & Michie, D. (Eds.), </editor> <booktitle> Machine Intelligence 5, </booktitle> <pages> pp. 219-236. </pages> <publisher> Edinburgh University Press, Edinburgh. </publisher>
Reference-contexts: Therefore, such an algorithm requires a special termination condition for guaranteeing optimal solutions. The termination condition of 2. More precisely, BHPA can be viewed to consist of two HPA searches <ref> (Pohl, 1970) </ref> in opposing directions. As long as the heuristic function used is consistent and its values are weighted equally as the g d -values, the only relevant difference is a check whether Open has become empty.
Reference: <author> Pohl, I. </author> <year> (1971). </year> <title> Bi-directional search. </title> <booktitle> In Machine Intelligence 6, </booktitle> <pages> pp. </pages> <address> 127-140 Edinburgh. </address> <publisher> Edinburgh University Press. </publisher>
Reference-contexts: We call this the traditional approach. It encompasses both algorithms performing front-to-end and others performing front-to-front evaluations. 2.2.1 Front-to-end Evaluations Since the first proposed algorithm on bidirectional heuristic search called BHPA <ref> (Pohl, 1971) </ref> performed front-to-end evaluations, let us begin with this approach. It employs heuristic evaluation functions h d (n) that estimate the cost of an optimal path from the evaluated node n to t or s, respectively, depending on the search direction d. <p> The decision for searching in the forward or backward direction is made anew for each node expansion according to the cardinality criterion <ref> (Pohl, 1971) </ref>: if jOpen 1 j jOpen 2 j then d 1 else d 2 Whenever the search frontiers meet at some node n, a solution is found.
Reference: <author> Politowski, G., & Pohl, I. </author> <year> (1984). </year> <title> D-node retargeting in bidirectional heuristic search. </title> <booktitle> In Proc. Fourth National Conference on Artificial Intelligence (AAAI-84), </booktitle> <pages> pp. 274-277. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press / The MIT Press. </publisher>
Reference-contexts: was insufficient. 2.2.2 Front-to-front Evaluations Since for a long time there was consensus about the belief that the search frontiers would pass each other, research focused on algorithms that would force the "wavefronts" to meet through "wave-shaping" techniques: BHFFA (de Champeaux & Sint, 1977), BHFFA2 (de Champeaux, 1983), d-node retargeting <ref> (Politowski & Pohl, 1984) </ref> and a generalized algorithm (encompassing BHPA and BHFFA2) (Davis, Pollack, & Sudkamp, 1984). These 289 Kaindl & Kainz algorithms perform front-to-front evaluations and they show that bidirectional heuristic search can be efficient in terms of the number of nodes generated.
Reference: <author> Rao, V., Kumar, V., & Korf, R. </author> <year> (1991). </year> <title> Depth-first vs best-first search. </title> <booktitle> In Proc. Ninth National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> pp. 434-440. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press / The MIT Press. </publisher>
Reference: <author> Reinefeld, A., & Marsland, T. </author> <year> (1994). </year> <title> Enhanced iterative-deepening search. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), </journal> <volume> 16 (12), </volume> <pages> 701-709. </pages>
Reference-contexts: First, we review the traditional best-first search algorithm A* (Hart, Nilsson, & Raphael, 1968). Then, we shortly explain the linear-space algorithm IDA* (iterative-deepening-A*) proposed by Korf (1985). Finally, we review an algorithm called Trans <ref> (Reinefeld & Marsland, 1994) </ref> that implements a form of enhanced iterative-deepening search. A* maintains the set Open of so-called open nodes that have been generated but not yet expanded, i.e., the frontier nodes. <p> Fortunately, most computers have more memory available than needed for IDA*. This memory can be utilized for recognizing duplicate nodes in two ways, using a finite state machine (Taylor & Korf, 1993), or a transposition table implemented as a hash table <ref> (Reinefeld & Marsland, 1994) </ref>. Due to its more general applicability in a wider variety of domains, and since our bidirectional algorithms partly make use of it, we focus on the latter technique. The algorithm Trans proposed by Reinefeld and Marsland (1994) uses a transposition table for IDA*. <p> The traditional best-first search uses its assigned memory as usual, e.g., in A*, and the linear-space search uses as much memory as still available in a transposition table <ref> (Reinefeld & Marsland, 1994) </ref>. The former first of all orders the sequence of node generations and finds transpositions. The latter uses its memory for finding transpositions in another part of the search space, and for caching more accurate heuristic evaluations closer to t. <p> In the latter case a new solution is found. We call the resulting algorithm Max-BAI. When a transposition table <ref> (Reinefeld & Marsland, 1994) </ref> is used in addition as in BAI-Trans, we call it Max-BAI-Trans. Most interestingly, IDA* can also utilize the Max method without additional storage requirements. Let us sketch the basic approach for such a linear-space application of this method here.
Reference: <author> Russell, S. </author> <year> (1992). </year> <title> Efficient memory-bounded search methods. </title> <booktitle> In Proc. Tenth European Conference on Artificial Intelligence (ECAI-92), </booktitle> <pages> pp. 1-5. </pages> <address> Chichester, England: </address> <publisher> Wiley. </publisher>
Reference-contexts: Apart from its use in Trans, this back-up idea is actually widely applied in many algorithms like MA* (Chakrabarti, Ghose, Acharya, & DeSarkar, 1989), MREC (Sen & Bagchi, 1989), RTA* (Korf, 1990), SMA* <ref> (Russell, 1992) </ref> and ITS (Ghosh, Mahanti, & Nau, 1994). 287 Kaindl & Kainz Its advantages are very little overhead and steady (though often modest) improvement with increasing memory size. <p> Based on the same approach, Kaindl and Khorsand (1994) showed that bidirectional heuristic search using limited memory is possible through using a unidirectional search algorithm that can cope with limited memory | SMA* <ref> (Russell, 1992) </ref>.
Reference: <author> Russell, S., & Norvig, P. </author> <year> (1995). </year> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference-contexts: It is just necessary that for a given node n the set of parent nodes p i can be determined for which there exist operators that lead from p i to n. Searching backwards means generating parent nodes successively from the goal node t <ref> (see, e.g., Russell & Norvig, 1995) </ref>. In other words, backward search implements reasoning about the operators in the backward direction.
Reference: <author> Sen, A., & Bagchi, A. </author> <year> (1989). </year> <title> Fast recursive formulations for best-first search that allow controlled use of memory. </title> <booktitle> In Proc. Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pp. 297-302. </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: Apart from its use in Trans, this back-up idea is actually widely applied in many algorithms like MA* (Chakrabarti, Ghose, Acharya, & DeSarkar, 1989), MREC <ref> (Sen & Bagchi, 1989) </ref>, RTA* (Korf, 1990), SMA* (Russell, 1992) and ITS (Ghosh, Mahanti, & Nau, 1994). 287 Kaindl & Kainz Its advantages are very little overhead and steady (though often modest) improvement with increasing memory size.
Reference: <author> Taylor, L., & Korf, R. </author> <year> (1993). </year> <title> Pruning duplicate nodes in depth-first search. </title> <booktitle> In Proc. Eleventh National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> pp. 756-761. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press / The MIT Press. </publisher>
Reference-contexts: This disadvantage of IDA* relates to its advantage of requiring only linear space. Fortunately, most computers have more memory available than needed for IDA*. This memory can be utilized for recognizing duplicate nodes in two ways, using a finite state machine <ref> (Taylor & Korf, 1993) </ref>, or a transposition table implemented as a hash table (Reinefeld & Marsland, 1994). Due to its more general applicability in a wider variety of domains, and since our bidirectional algorithms partly make use of it, we focus on the latter technique.
Reference: <author> Zhang, W., & Korf, R. </author> <year> (1993). </year> <title> Depth-first vs. best-first search: new results. </title> <booktitle> In Proc. Eleventh National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> pp. 769-775. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press / The MIT Press. </publisher> <pages> 317 </pages>
References-found: 36

