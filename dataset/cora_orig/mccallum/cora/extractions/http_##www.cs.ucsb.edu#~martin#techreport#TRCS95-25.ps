URL: http://www.cs.ucsb.edu/~martin/techreport/TRCS95-25.ps
Refering-URL: http://www.cs.ucsb.edu/~martin/techreport/index.html
Root-URL: http://www.cs.ucsb.edu
Email: martin@cs.ucsb.edu  
Title: An Integrated Synchronization and Consistency Protocol for the Implementation of a High-Level Parallel Programming Language  
Author: Martin C. Rinard 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California, Santa Barbara  
Abstract: This paper presents the integrated synchronization and consistency protocol used in the implementation of Jade, an implicitly parallel language for coarse-grain parallel computation. The consistency protocol tags each replica of shared data with a version number. The synchronization algorithm computes the correct version numbers of the replicas of shared data that the computation will access. Because the integrated protocol piggybacks the version number information on the synchronization messages, it eliminates the excess message traffic characteristic of standard update and invalidate protocols. This paper characterizes the performance impact of the consistency protocol by presenting experimental results for several Jade applications running on the iPSC/860 under several different Jade implementations. We believe that implementors of other parallel software systems will be able to improve the efficiency of their systems by using similar integrated protocols.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Berrendorf and J. Helin. </author> <title> Evaluating the basic performance of the intel iPSC/860 parallel computer. </title> <journal> Concurrency: Practice & Experience, </journal> <volume> 4(3) </volume> <pages> 223-240, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Stable implementations of Jade for shared memory machines, message passing machines and heterogeneous networks of workstations have existed for over two years. Jade programs port without modification between all platforms. In this paper we present experimental results for several Jade applications running on the iPSC/860 <ref> [1] </ref>. These experimental results characterize the performance impact of the Jade version number protocol relative to an invalidate or update protocol. These experiments reveal that there is a wide variance in the performance impact of the update protocol relative to the other two protocols. <p> We first describe how each application accesses data, then relate the data access behavior to the observed communication and execution time differences. All experiments are run on the iPSC/860 <ref> [1] </ref>, a message passing machine consisting of i860 processing nodes interconnected by a hypercube network. The Jade implementation uses the NX/2 message passing library as its communication layer. 7.1 Ocean The computationally intensive section of Ocean uses an iterative method to solve a set of discretized spatial partial differential equations.
Reference: [2] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the Thirteenth Symposium on Operating Systems Principles, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: The standard way to solve the consistency problem is to use an invalidate or update consistency protocol. These protocols send messages that eliminate or overwrite any out of date replicas whenever a task writes shared data. The end result <ref> [2, 8] </ref> is usually a system that contains two distinct protocols: a synchronization protocol to implement the synchronization abstractions, and a consistency protocol to manage the replication.
Reference: [3] <author> R. Chandra, A. Gupta, and J. Hennessy. </author> <title> Data locality and load balancing in COOL. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: We also expect future parallel languages to become increasingly based on a data-oriented paradigm in which programmers participate in the parallelization process by providing information about how parts of the program access data. Locality hints in COOL <ref> [3] </ref> and shared regions [14] are two examples of this trend. The implementations of these languages will be able to exploit their knowledge of how the program accesses data to employ efficient integrated synchronization and consistency protocols similar to the one presented in this paper.
Reference: [4] <author> I. Duff, R. Grimes, and J. Lewis. </author> <title> Sparse matrix problems. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 15(1) </volume> <pages> 1-14, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: The performance numbers are for the entire computation, including initial and final I/O. 8 The data set for Ocean is a square 192 by 192 grid. For Panel Cholesky the timing runs factor the BCSSTK15 matrix from the Harwell-Boeing sparse matrix benchmark set <ref> [4] </ref>. The performance numbers only measure the actual numerical factorization, omitting initial I/O and a symbolic factorization phase.
Reference: [5] <author> M. Feeley and H. Levy. </author> <title> Distributed shared memory with versioned objects. </title> <booktitle> In Proceedings of the ACM Conference on Object-Oriented Programming Systems, Languages and Applications, </booktitle> <pages> pages 247-262, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: 119.30 91.75 Table 6: Execution Times for Water with Adaptive Broadcast (seconds) 1 2 4 8 16 24 32 Update 18904.08 9484.33 4786.00 2421.24 1256.29 868.11 677.41 Adaptive Broadcast 17398.11 9483.71 4765.06 2413.20 1248.43 864.99 676.82 Table 7: Execution Times for String with Adaptive Broadcast (seconds) SAM [15] and VDOM <ref> [5] </ref>, two more recent systems in the field of parallel computation, expose the concept of version numbers directly in the programming model. When a SAM or VDOM task writes an object it provides a number for the newly generated version of the object.
Reference: [6] <author> J. Harris, S. Lazaratos, and R. Michelena. </author> <title> Tomographic string inversion. </title> <booktitle> In 60th Annual International Meeting, Society of Exploration and Geophysics, Extended Abstracts, </booktitle> <pages> pages 82-85, </pages> <year> 1990. </year>
Reference-contexts: The final application set consists of three complete applications and one computational kernel. The complete applications are Water, which evaluates forces and potentials in a system of water molecules in the liquid state, String <ref> [6] </ref>, which computes a velocity model of the geology between two oil wells, and Ocean, which simulates the role of eddy and boundary currents in influencing large-scale ocean movements. The computational kernel is Panel Cholesky, which factors a sparse positive-definite matrix. <p> of an Update protocol substantially improves the overall performance. 1 2 4 8 16 24 32 Update 2439.95 1224.17 618.98 315.13 165.08 117.22 91.17 Invalidate 2458.70 1234.65 625.89 323.74 180.86 141.65 123.40 Version 2462.82 1236.85 626.98 323.94 180.72 141.47 123.14 Table 4: Execution Times for Water (seconds) 7.4 String String <ref> [6] </ref> computes a velocity model of the geology between two oil wells. Like Water, String performs a sequence of interleaved parallel and sequential phases. The parallel phases trace rays through a discretized velocity model, computing the difference between the simulated and experimentally observed travel times of the rays.
Reference: [7] <author> P. Keleher, S. Dwarkadas, A. Cox, and W. Zwaenepoel. TreadMarks: </author> <title> Distributed Shared Memory on Standard Workstations and Operating Systems. </title> <institution> Technical Report Rice COMP TR93-214, Rice University, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: SAM addresses this problem by allowing the program to access the latest version of an object (at the cost of extra communication to find the number of the latest version) and by providing libraries that encapsulate the version number calculation for common data structures with common access patterns. TreadMarks <ref> [7] </ref> is a page-based software distributed shared memory system that exploits the flexibility of release consistency to combine synchronization and invalidation messages. Whenever a processor acquires a lock it sends a lock acquire request message to the last processor to hold the lock. <p> The requestor invalidates these pages before proceeding beyond the lock acquire operation. An evaluation of an alternate protocol that piggybacks update messages on the lock acquire response message instead of invalidate messages found that the invalidate version exhibited superior performance <ref> [7] </ref>. We conjecture that part of the reason for this performance difference is that TreadMarks does not explicitly associate data with synchronization objects.
Reference: [8] <author> D. Lenoski, J. Laudon, T. Joe, D. Nakahira, L. Stevens, A. Gupta, and J. Hennessy. </author> <title> The DASH prototype: Implementation and performance. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: The standard way to solve the consistency problem is to use an invalidate or update consistency protocol. These protocols send messages that eliminate or overwrite any out of date replicas whenever a task writes shared data. The end result <ref> [2, 8] </ref> is usually a system that contains two distinct protocols: a synchronization protocol to implement the synchronization abstractions, and a consistency protocol to manage the replication.
Reference: [9] <author> M. Nelson, B. Welch, and J. Ousterhout. </author> <title> Caching in the sprite network file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 134-154, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The NAMOS system used a version-based scheme for concurrency control and consistency in a distributed database [10]. The Sprite file system also used a consistency scheme based on version numbers <ref> [9] </ref>.
Reference: [10] <author> D. Reed. </author> <title> Naming and Synchronization in a Decentralized Computer System. </title> <type> PhD thesis, </type> <institution> Dept. of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1978. </year>
Reference-contexts: Pointers to shared objects are identified in a Jade program using the shared type qualifier. For example: double shared A <ref> [10] </ref>; double shared *B; The first declaration defines a statically allocated shared vector of doubles, while the second declaration defines a reference (pointer) to a dynamically allocated shared vector of doubles. <p> The NAMOS system used a version-based scheme for concurrency control and consistency in a distributed database <ref> [10] </ref>. The Sprite file system also used a consistency scheme based on version numbers [9].
Reference: [11] <author> M. Rinard. </author> <title> The Design, Implementation and Evaluation of Jade, a Portable, Implicitly Parallel Programming Language. </title> <type> PhD thesis, </type> <institution> Stanford, </institution> <address> CA, </address> <year> 1994. </year> <note> http://www.cs.ucsb.edu/ martin. 15 </note>
Reference-contexts: A more efficient system would combine the messages and generate fewer interactions. In this paper we present the integrated synchronization and consistency protocol used in the implementation of Jade, a portable, implicitly parallel programming language designed for exploiting task-level concurrency <ref> [11, 13] </ref>. Jade programmers start with a program written in a standard serial, imperative language, then use Jade constructs to declaratively specify how parts of the program access data. The Jade implementation analyzes this data usage information to automatically execute the program in parallel. <p> In this case the queue would migrate to the processor performing most of the insertions and most of the insertions would not incur the overhead of a remote message send. In practice almost all insertions are performed on object queues that are available locally. See <ref> [11] </ref> for more details. At any given time each task resides completely on one processor; this processor is called the owner of the task. When an entry becomes enabled the implementation sends an enable message to the task's owner informing it that the entry is enabled.
Reference: [12] <author> M. Rinard and M. Lam. </author> <booktitle> Semantic foundations of Jade. In Proceedings of the Nineteenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 105-118, </pages> <address> Albuquerque, NM, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: We present an argument for the write before read case; a similar argument holds for the read before write case. See <ref> [12] </ref> for a more formal treatment of this argument. Consider a write that happens before a read in a sequential execution.
Reference: [13] <author> M. Rinard, D. Scales, and M. Lam. </author> <title> Jade: a high-level, machine-independent language for parallel programming. </title> <journal> Computer, </journal> <volume> 26(6) </volume> <pages> 28-38, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: A more efficient system would combine the messages and generate fewer interactions. In this paper we present the integrated synchronization and consistency protocol used in the implementation of Jade, a portable, implicitly parallel programming language designed for exploiting task-level concurrency <ref> [11, 13] </ref>. Jade programmers start with a program written in a standard serial, imperative language, then use Jade constructs to declaratively specify how parts of the program access data. The Jade implementation analyzes this data usage information to automatically execute the program in parallel.
Reference: [14] <author> H. Sandu, B. Gamsa, and S. Zhou. </author> <title> The shared regions approach to software cache coherence on multiprocessors. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 229-238, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: We also expect future parallel languages to become increasingly based on a data-oriented paradigm in which programmers participate in the parallelization process by providing information about how parts of the program access data. Locality hints in COOL [3] and shared regions <ref> [14] </ref> are two examples of this trend. The implementations of these languages will be able to exploit their knowledge of how the program accesses data to employ efficient integrated synchronization and consistency protocols similar to the one presented in this paper.
Reference: [15] <author> D. Scales and M. S. Lam. </author> <title> An efficient shared memory system for distributed memory machines. </title> <type> Technical Report CSL-TR-94-627, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: 623.50 318.63 166.69 119.30 91.75 Table 6: Execution Times for Water with Adaptive Broadcast (seconds) 1 2 4 8 16 24 32 Update 18904.08 9484.33 4786.00 2421.24 1256.29 868.11 677.41 Adaptive Broadcast 17398.11 9483.71 4765.06 2413.20 1248.43 864.99 676.82 Table 7: Execution Times for String with Adaptive Broadcast (seconds) SAM <ref> [15] </ref> and VDOM [5], two more recent systems in the field of parallel computation, expose the concept of version numbers directly in the programming model. When a SAM or VDOM task writes an object it provides a number for the newly generated version of the object.
Reference: [16] <author> J. Singh, W. Weber, and A. Gupta. </author> <title> SPLASH: Stanford parallel applications for shared memory. </title> <journal> Computer Architecture News, </journal> <volume> 20(1) </volume> <pages> 5-44, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The computational kernel is Panel Cholesky, which factors a sparse positive-definite matrix. The SPLASH benchmark set <ref> [16] </ref> contains variants of the Water, Ocean and Panel Cholesky applications. Figure 1 contains some basic application characteristics.
Reference: [17] <author> M. Zekauskas, W. Sawdon, and B. Bershad. </author> <title> Software write detection for a distributed shared memory. </title> <booktitle> In Proceedings of the First USENIX Symposium on Operating Systems Design and Implementation, </booktitle> <address> Monterey, CA, </address> <month> November </month> <year> 1994. </year> <month> 16 </month>
Reference-contexts: The TreadMarks implementation may therefore be unable to calculate a reasonably precise approximation to the data that the requestor will access, and the update version will communicate an excessive amount of data. Midway <ref> [17] </ref> is a software distributed shared memory system that allows programmers to associate data objects with synchronization objects such as locks. The Midway implementation further divides each object into software cache lines and tracks cache line modifications.
References-found: 17

