URL: ftp://ftp.cs.berkeley.edu/ucb/sprite/papers/vm-vs-fs.ps
Refering-URL: http://www.cs.berkeley.edu/projects/sprite/sprite.papers.html
Root-URL: 
Title: Virtual Memory vs. The File System  
Author: Michael N. Nelson 
Note: The work described here was supported in part by the Defense Advanced Research Projects Agency (DoD) under Contract No. N00039-84-C-0107  
Address: Palo Alto, CA 94301  
Affiliation: Digital Equipment Corporation Western Research Laboratory  
Abstract: This paper examines the behavior of mechanisms for providing variable-size file data caches. It presents the results of running virtual-memory- and file-intensive benchmarks on the Sprite operating system [OCD88]; the benchmarks are designed to simulate real-life applications that represent the worst case for variable-size cache mechanisms. The results indicate that variable-size cache mechanisms work well when virtual-memory-and file-intensive programs are run in sequence; the cache is able to change in size in order to provide overall performance no worse than that provided by a small fixed-size cache. However, when interactive programs are run concurrently with file-intensive programs, variable-size cache mechanisms perform very poorly if file pages and virtual-memory pages are treated equally. In order to guarantee good interactive response, virtual memory pages must be given preference over file pages. hhhhhhhhhhhhhhhhhhhhhhhhhhhhh
Abstract-found: 1
Intro-found: 1
Reference: [BCD72] <author> A. Bensoussan, C. T. Clingen and R. C. Daley, </author> <title> ``The MULTICS Virtual Memory: Concepts and Design'', </title> <journal> Comm. of the ACM 15, </journal> <month> 5 (May </month> <year> 1972). </year>
Reference-contexts: This approach eliminates the file cache entirely; the standard page replacement mechanisms automatically balance physical memory usage between file and program information. Mapped files were first used in Multics <ref> [BCD72, DaD68] </ref> and TENEX [BBM72, Mur72]. More recently they have been implemented in Pilot [Red80], Accent [RaR81, RaF86], Apollo [LLH85, Lea83] and Mach [Ras87]. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate.
Reference: [BBM72] <author> D. G. Bobrow, J. D. Burchfiel, D. L. Murphy and R. S. Tomlinson, ``TENEX, </author> <title> a Paged Time Sharing System for the PDP-10'', </title> <journal> Comm. of the ACM 15, </journal> <month> 3 (Mar. </month> <year> 1972), </year> <pages> 1135-143. </pages>
Reference-contexts: Thus, if a cache is allowed to become too large, the improvement in file system performance may be more than offset by a degradation in virtual memory performance. In order to provide both good file system performance and good virtual memory performance, several operating systems <ref> [BBM72, DaD68, Lea83, RaF86, Ras87] </ref> have implemented variable-size cache mechanisms. In these operating systems the portion of memory used for file data and virtual memory varies in response to the file and virtual-memory needs of the application programs being executed. <p> This approach eliminates the file cache entirely; the standard page replacement mechanisms automatically balance physical memory usage between file and program information. Mapped files were first used in Multics [BCD72, DaD68] and TENEX <ref> [BBM72, Mur72] </ref>. More recently they have been implemented in Pilot [Red80], Accent [RaR81, RaF86], Apollo [LLH85, Lea83] and Mach [Ras87]. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate.
Reference: [DaD68] <author> R. C. Daley and J. B. Dennis, </author> <title> ``Virtual Memory, Processes and Sharing in MULTICS'', </title> <journal> Comm. of the ACM 11, </journal> <month> 5 (May </month> <year> 1968), </year> <pages> 306-312. </pages>
Reference-contexts: Thus, if a cache is allowed to become too large, the improvement in file system performance may be more than offset by a degradation in virtual memory performance. In order to provide both good file system performance and good virtual memory performance, several operating systems <ref> [BBM72, DaD68, Lea83, RaF86, Ras87] </ref> have implemented variable-size cache mechanisms. In these operating systems the portion of memory used for file data and virtual memory varies in response to the file and virtual-memory needs of the application programs being executed. <p> This approach eliminates the file cache entirely; the standard page replacement mechanisms automatically balance physical memory usage between file and program information. Mapped files were first used in Multics <ref> [BCD72, DaD68] </ref> and TENEX [BBM72, Mur72]. More recently they have been implemented in Pilot [Red80], Accent [RaR81, RaF86], Apollo [LLH85, Lea83] and Mach [Ras87]. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate.
Reference: [LLH85] <author> P. Leach, P. Levine, J. Hamilton and B. Stumpf, </author> <title> ``The File System of an Integrated Local Network'', </title> <booktitle> Proc. of the 1985 ACM Computer Science Conference, </booktitle> <month> Mar. </month> <year> 1985, </year> <pages> 309-324. </pages>
Reference-contexts: This approach eliminates the file cache entirely; the standard page replacement mechanisms automatically balance physical memory usage between file and program information. Mapped files were first used in Multics [BCD72, DaD68] and TENEX [BBM72, Mur72]. More recently they have been implemented in Pilot [Red80], Accent [RaR81, RaF86], Apollo <ref> [LLH85, Lea83] </ref> and Mach [Ras87]. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate. Users invoke system calls such as read and write to access file data.
Reference: [Lea83] <author> P. J. Leach, et al., </author> <title> ``The Architecture of an Integrated Local Network'', </title> <journal> IEEE Journal on Selected Areas in Communications SAC-1, </journal> <volume> 5 (Nov. </volume> <year> 1983), </year> <pages> 842-857. </pages>
Reference-contexts: Thus, if a cache is allowed to become too large, the improvement in file system performance may be more than offset by a degradation in virtual memory performance. In order to provide both good file system performance and good virtual memory performance, several operating systems <ref> [BBM72, DaD68, Lea83, RaF86, Ras87] </ref> have implemented variable-size cache mechanisms. In these operating systems the portion of memory used for file data and virtual memory varies in response to the file and virtual-memory needs of the application programs being executed. <p> This approach eliminates the file cache entirely; the standard page replacement mechanisms automatically balance physical memory usage between file and program information. Mapped files were first used in Multics [BCD72, DaD68] and TENEX [BBM72, Mur72]. More recently they have been implemented in Pilot [Red80], Accent [RaR81, RaF86], Apollo <ref> [LLH85, Lea83] </ref> and Mach [Ras87]. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate. Users invoke system calls such as read and write to access file data.
Reference: [Mur72] <author> D. L. Murphy, </author> <title> ``Storage organization and management in TENEX'', </title> <booktitle> Proceedings AFIPS Fall Joint Computer Conference 15, 3 (1972), </booktitle> <pages> 23-32. </pages>
Reference-contexts: This approach eliminates the file cache entirely; the standard page replacement mechanisms automatically balance physical memory usage between file and program information. Mapped files were first used in Multics [BCD72, DaD68] and TENEX <ref> [BBM72, Mur72] </ref>. More recently they have been implemented in Pilot [Red80], Accent [RaR81, RaF86], Apollo [LLH85, Lea83] and Mach [Ras87]. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate.
Reference: [Nel86] <author> M. N. Nelson, </author> <title> ``The Sprite Virtual Memory System'', </title> <note> Technical Report UCB/Computer Science Dpt. 86/301, </note> <institution> University of California, Berkeley, </institution> <month> June </month> <year> 1986. </year>
Reference-contexts: In the Sprite mechanism, the file system module and the virtual memory module each manage a separate pool of physical memory pages. Virtual memory keeps its pages in approximate LRU order through a version of the clock algorithm <ref> [Nel86] </ref>. The file system keeps its cache blocks in perfect LRU order since all block accesses are made through the read and write system calls. Each module keeps a time-of-last-access for each page or block.
Reference: [Nel88] <author> M. N. Nelson, </author> <title> Physical Memory Management in a Network Operating System, </title> <type> Phd Thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1988. </year>
Reference-contexts: Variable-size caches are provided by having the virtual memory system and file system modules negotiate over physical memory usage. In this paper I will only give an overview of the Sprite mechanism; see [NWO88] or <ref> [Nel88] </ref> for more details. In the Sprite mechanism, the file system module and the virtual memory module each manage a separate pool of physical memory pages. Virtual memory keeps its pages in approximate LRU order through a version of the clock algorithm [Nel86]. <p> This makes Sprite a good vehicle for running experiments in variable-size cache behavior. Of course, Sprite has the disadvantage that it requires more copies than mapped-file schemes. However, measurements presented in <ref> [Nel88] </ref> demonstrate that the extra copies have an insignificant impact on performance. 3. Benchmarks In order to measure the performance of variable-size cache mechanisms, I developed two benchmarks and ran them on the Sprite operating system.
Reference: [NWO88] <author> M. N. Nelson, B. B. Welch and J. K. Ousterhout, </author> <title> ``Caching in the Sprite Network File System'', </title> <journal> Trans. Computer Systems 6, </journal> <month> 1 (Feb. </month> <year> 1988), </year> <pages> 134-154. </pages>
Reference-contexts: 1. Introduction File data caches have been used in many operating systems to improve file system performance. In a distributed system the use of caches can reduce both network and disk traffic. A study of the use of caches on diskless workstations <ref> [NWO88] </ref> showed that the use of large caches can reduce the execution time of application programs by up to 1/3. Unfortunately, if file data caches are allowed to become too large, then they will conflict with the needs of the virtual memory system. <p> Variable-size caches are provided by having the virtual memory system and file system modules negotiate over physical memory usage. In this paper I will only give an overview of the Sprite mechanism; see <ref> [NWO88] </ref> or [Nel88] for more details. In the Sprite mechanism, the file system module and the virtual memory module each manage a separate pool of physical memory pages. Virtual memory keeps its pages in approximate LRU order through a version of the clock algorithm [Nel86]. <p> This is small enough that sort will contend with the virtual memory system for memory. 4. Why Not Just Use Fixed-Size Caches? The results from previous measurements of file data caches <ref> [NWO88] </ref> suggest that a large fixed-size cache will provide the best performance for file-intensive programs. However, for the two benchmarks used here, a small fixed-size cache is best. <p> A small fixed-size cache is also best for the IFS benchmark. This benchmark was designed so that interactive performance would degrade if more than 1 Mbyte were used for the file system cache. In addition, measurements in <ref> [NWO88] </ref> show that even with a small cache the sort benchmark will only execute at most 25 percent more slowly than with a large cache. Thus a small fixed-size cache will give instantaneous interactive response (no page faults required) while only slightly degrading file system performance. <p> Thus a small fixed-size cache will give instantaneous interactive response (no page faults required) while only slightly degrading file system performance. The results with fixed-size caches demonstrate that different cache sizes are needed for different types of programs. The results in <ref> [NWO88] </ref> show that when purely file-intensive programs are run, a large cache is best. However, when a mix of file- and virtual-memory-intensive programs are run, then a small cache is best. 5. <p> Surprisingly, the file system penalty actually improves the execution time of the sort benchmark relative to without the penalty (see Tables 3 and 4). When the file system is penalized, sort takes only 25% longer than the best case. This degradation is nearly identical to the degradation shown in <ref> [NWO88] </ref> when sort was run using only a small cache. - 10 - Virtual Memory vs.
Reference: [OCD88] <author> J. K. Ousterhout, A. R. Cherenson, F. Douglis, M. N. Nelson and B. B. Welch, </author> <title> ``The Sprite Network Operating System'', </title> <booktitle> IEEE Computer 21, </booktitle> <month> 2 (Feb. </month> <year> 1988), </year> <pages> 23-36. </pages>
Reference: [RaR81] <author> R. F. Rashid and G. G. Robertson, </author> <title> ``Accent: A communication oriented network operating system kernel'', </title> <booktitle> Proceedings of the 8th Symposium on Operating Systems Principles, </booktitle> <year> 1981, </year> <pages> 164-175. </pages>
Reference-contexts: This approach eliminates the file cache entirely; the standard page replacement mechanisms automatically balance physical memory usage between file and program information. Mapped files were first used in Multics [BCD72, DaD68] and TENEX [BBM72, Mur72]. More recently they have been implemented in Pilot [Red80], Accent <ref> [RaR81, RaF86] </ref>, Apollo [LLH85, Lea83] and Mach [Ras87]. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate. Users invoke system calls such as read and write to access file data.
Reference: [RaF86] <author> R. F. Rashid and R. Fitzgerald, </author> <title> ``The Integration of Virtual Memory Management and Interprocess Communication in Accent'', </title> <journal> Trans. Computer Systems 4, </journal> <month> 2 (May </month> <year> 1986), </year> <pages> 147-177. </pages>
Reference-contexts: Thus, if a cache is allowed to become too large, the improvement in file system performance may be more than offset by a degradation in virtual memory performance. In order to provide both good file system performance and good virtual memory performance, several operating systems <ref> [BBM72, DaD68, Lea83, RaF86, Ras87] </ref> have implemented variable-size cache mechanisms. In these operating systems the portion of memory used for file data and virtual memory varies in response to the file and virtual-memory needs of the application programs being executed. <p> This approach eliminates the file cache entirely; the standard page replacement mechanisms automatically balance physical memory usage between file and program information. Mapped files were first used in Multics [BCD72, DaD68] and TENEX [BBM72, Mur72]. More recently they have been implemented in Pilot [Red80], Accent <ref> [RaR81, RaF86] </ref>, Apollo [LLH85, Lea83] and Mach [Ras87]. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate. Users invoke system calls such as read and write to access file data.
Reference: [Ras87] <author> R. Rashid, et al., </author> <title> ``Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures'', Conference on - 14 - Virtual Memory vs. </title> <booktitle> The File System Architectural Support for Programming Languages and Operating Systems (ASPLOS II), </booktitle> <month> Oct. </month> <year> 1987, </year> <pages> 31-39. </pages>
Reference-contexts: Thus, if a cache is allowed to become too large, the improvement in file system performance may be more than offset by a degradation in virtual memory performance. In order to provide both good file system performance and good virtual memory performance, several operating systems <ref> [BBM72, DaD68, Lea83, RaF86, Ras87] </ref> have implemented variable-size cache mechanisms. In these operating systems the portion of memory used for file data and virtual memory varies in response to the file and virtual-memory needs of the application programs being executed. <p> Mapped files were first used in Multics [BCD72, DaD68] and TENEX [BBM72, Mur72]. More recently they have been implemented in Pilot [Red80], Accent [RaR81, RaF86], Apollo [LLH85, Lea83] and Mach <ref> [Ras87] </ref>. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate. Users invoke system calls such as read and write to access file data.
Reference: [Red80] <author> D. D. Redell, et al., </author> <title> ``Pilot: An Operating System for a Personal Computer'', </title> <journal> Communications of the ACM 23, </journal> <month> 2 (Feb. </month> <year> 1980), </year> <pages> 81-92. - 15 </pages> - 
Reference-contexts: This approach eliminates the file cache entirely; the standard page replacement mechanisms automatically balance physical memory usage between file and program information. Mapped files were first used in Multics [BCD72, DaD68] and TENEX [BBM72, Mur72]. More recently they have been implemented in Pilot <ref> [Red80] </ref>, Accent [RaR81, RaF86], Apollo [LLH85, Lea83] and Mach [Ras87]. The Sprite approach to providing variable-size caches is quite different from the mapped-file approach. In Sprite, the file system and virtual memory system are separate. Users invoke system calls such as read and write to access file data.
References-found: 14

