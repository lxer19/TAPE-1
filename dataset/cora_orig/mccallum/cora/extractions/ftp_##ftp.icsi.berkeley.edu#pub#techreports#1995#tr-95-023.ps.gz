URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1995/tr-95-023.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1995.html
Root-URL: http://www.icsi.berkeley.edu
Title: Properties of Stochastic Perceptual Auditory-event-based Models for Automatic Speech Recognition  
Phone: (510) 643-9153 FAX (510) 643-7684  
Author: Su-Lin Wu 
Date: May 1995  
Address: 1947 Center St. Suite 600 Berkeley, California 94704-1198  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  
Abstract: Recently, physiological and psychoacoustic studies have uncovered new evidence supporting the idea that human auditory processes focus on the transitions between spoken sounds rather than on the steady-state portions of spoken sounds for speech recognition. Stochastic Perceptual Auditory-event-based Models (SPAMs) were developed by Morgan, Bour-lard, Hermansky and Greenberg to take this new evidence into account for word models in speech recognition by machines. This paper details our efforts to build a speech recognition system based on some of the properties of SPAMs. Although not all aspects of the complete SPAM theory have been implemented, we did find that fairly good recognition is possible with a system that concentrates almost exclusively on the transitions between speech sounds. Additionally, we found that such a system enhanced the more conventional phoneme-based system, which emphasized recognition of steady-state sounds. This blended system performed better than either system alone, especially in the case of noise-obscured speech. 
Abstract-found: 1
Intro-found: 1
Reference: [BM] <author> H. Bourlard, and N. Morgan, </author> <title> Connectionist Speech Recognition: A Hybrid Approach, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: recognition systems while still large and complex enough to allow general conclusions to be drawn from the results. 2.2 Hybrid Hidden Markov Model - Multilayer Perceptron System The speech recognition system developed for this work is based on the hybrid Hidden Markov Model, Multilayer Perceptron system in use at ICSI <ref> [BM] </ref>, illustrated below in is used as input to a neural network. A simple three-layer fully connected neural network is used to classify frames of features into speech sound units (Figure 2). The neural network produces a probability for each output for every time frame of speech. <p> For each of the four cuts, one-fourth was reserved for testing and the remaining three-fourths composed the training set. In this way, all of the available data is eventually used as part of a test set <ref> [BM] </ref>. 2.3.2 Training Experiments showed that a 200-hidden unit multilayer perceptron neural network was the right size for the training data available. The neural network was trained on 1,950 of the 2,600 total number of words, where approximately a tenth of the training data was reserved as a cross-validation set. <p> For each frame, the neural network produced a probability for each phoneme the frame could represent. This probability is divided by priors (the frequencies of each output unit as calculated from the training set) to produce likelihoods <ref> [BM] </ref>. Using the HMM models for words, dynamic programming determined which word contained the highest likelihood path for each utterance in the test set. <p> Non-transitioning states do have self-loops, however. Traditionally, priors are used to compensate for the neural networks tendency to favor the labels of frames it has seen more often, or, equivalently, to convert from posterior probabilities to data likelihoods (via Bayes Rule <ref> [BM] </ref>). Division by priors was not fully implemented for the avent-based recognition system; that is, while avents-versus-nts training was done with an equilibrated training set (which should be equivalent to division by priors), we did not divide by priors for the avent classification categories.
Reference: [BKM] <author> H. Bourlard, Y. Konig, and N. Morgan, </author> <title> REMAP: Recursive Estimation and Maximization of A posteriori Probabilities, </title> <type> ICSI Technical Report TR-94 064, </type> <year> 1994. </year>
Reference-contexts: REMAP is a new approach <ref> [BKM] </ref> that could potentially provide soft (probabilistic) targets for the tran sition over a region around the estimated onset time. <p> This is a gross simplification. Hard targets such as these were necessary for practical considerations in pilot systems. More accurate would be the soft targets under development as part of the REMAP theory by Konig, Bourlard and Morgan <ref> [BKM] </ref>. Because these targets will more accurately portray transitions, we hope that they may improve the avent-based system. Diphthongs are an open question with regards to this work.
Reference: [DPH] <author> J. Deller, J. Proakis, and J. Hansen, </author> <title> Discrete-Time Processing of Speech Sig nals, </title> <publisher> Macmillan Publishing Company, </publisher> <address> New York 1993. </address>
Reference: [DFP] <author> R. Drullman, J. Festen, and R. Plomp, </author> <title> Effect of temporal smearing on speech reception, </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 95 (2), </volume> <month> Feb ruary </month> <year> 1994. </year>
Reference: [Edwards] <author> H. Edwards, </author> <title> Applied Phonetics: The Sounds of American English, Singular Publishing Group, </title> <address> San Diego 1992. </address>
Reference-contexts: Diphthongs are an open question with regards to this work. Diphthongs, in which a speaker glides from one vowel to another in a single syllable, are technically two distinct regions with a transition in the middle <ref> [Edwards] </ref>. For example, the diphthong ay in nine is composed of the sounds aa and iy. The issue is not so clear cut, however, in real speech. Linguists disagree on which sounds are diphthongs and which are not.
Reference: [Furui] <author> S. Furui, </author> <title> On the Role of Spectral Transition for Speech Perception, </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 80, (4), </volume> <pages> pages 1016-1025, </pages> <year> 1986. </year>
Reference: [Greenberg] <author> S. Greenberg, </author> <title> Auditory Processing of Speech, Principles of Experimental Phonetics, Chapter 10, </title> <editor> N. Lass (editor), </editor> <address> St. Louis: Mosby. </address>
Reference-contexts: Avents are elementary auditory decisions, presumably made in response to rapid change in the speech spectrum and amplitude. Avents were designed to more closely represent the cues of human perception as researchers understand them <ref> [Greenberg] </ref>. In this study, avents are assumed to occur at the boundary between two phones and can be viewed as responses to leftcontext-dependent phonetic onsets. We built a recognition system based on avents to validate the SPAM idea of recognizing speech by focussing on transitions [MBGHW].
Reference: [KMHHT] <author> J. Koehler, N. Morgan, H. Hermansky, H. G. Hirsch, G. Tong, </author> <title> Integrating RASTA-PLP into Speech Recognition, </title> <booktitle> IEEE Proceedings of the International Conference on Acoustics, Speech and Signal Processing, 1994, </booktitle> <address> Ade laide, South Australia, </address> <publisher> pages I421-I424. </publisher> <editor> [Hermansky]Hermansky, H., </editor> <title> Perceptual Linear Predictive (PLP) Analysis of Speech, </title> <journal> Journal of the Acoustical Society of America, </journal> <month> April </month> <year> 1990, </year> <month> Pages 1738-1752. </month> <title> 15 ay-n 38 r-iy 17 h#-ey 40 h#-t 19 tcl-h# 42 uw-h# 21 s-eh 44 w-ah TABLE 14. Avent Label Set for Digits+ Index Label Index Label Properties of Stochastic Perceptual Auditory-event-based Models for Automatic Speech RecognitionJune 8, </title> <year> 1995 </year> <month> 23 </month>
Reference: [Kohn] <author> Phil Kohn at ICSI. </author> <title> Private communication. </title>
Reference-contexts: We used the neural network simulator BoB, written by Phil Kohn <ref> [Kohn] </ref>, to train the various neural networks. Approximately 10% of each training set was reserved as a crossval-idation set, so that the network would not overtrain and be unable to generalize for new inputs.
Reference: [LV] <author> P. Le Cerf and D. Van Compernolle, </author> <title> A New Variable Frame Rate Analysis Method for Speech Recognition, </title> <journal> IEEE Signal Processing Letters, </journal> <month> December </month> <year> 1994, </year> <pages> pages 185-187. </pages>
Reference: [LM] <author> T. Lander and S. T. Metzler, </author> <title> The CSLU Labeling Guide, Center for Spoken Language Understanding, </title> <institution> Oregon Graduate Institute, For Labeled Data Release 2.0, </institution> <month> February 2, </month> <year> 1994. </year>
Reference-contexts: Adapted from material from CSLUs Labelling Guide <ref> [LM] </ref> and work by Gary Tajchman. 37 ih unrfr fit high front unrounded short or lax 38 eh unrfr pet mid front unrounded short or lax 39 ey diph fate eh -&gt; iy 40 ae unrfr fat low front unrounded 41 aa unrbk father low back unrounded 42 aw diph how
Reference: [Ma] <author> K. Ma, </author> <title> Applying Large Vocabulary Hybrid HMM-MLP Methods to Telephone Recognition of Digits and Natural Numbers, </title> <type> Masters Thesis, </type> <institution> UC Berkeley, </institution> <note> Forthcoming in Spring 1995. </note>
Reference-contexts: Because each word is isolated, no grammar or natural language model is necessary. A recognition system based on conventional phone units had already been developed and optimized for performance by Kristine Ma <ref> [Ma] </ref>; this helped us make a realistic evaluation of the avent-based recognizers performance. <p> These data and models were used to perform training and recognition. In early experiments we tried to bootstrap the neural network with the much larger speech corpus NTIMIT before refining the training with the Digits+ data <ref> [Ma] </ref>. This improved the recognition performance of the system a modest amount; but not enough to warrant the additional time and computing resources necessary, so this technique was not pursued.
Reference: [MB] <author> H. Murveit and R. Brodersen, </author> <title> An Integrated-Circuit-Based Speech Recognition System, </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Pro cessing, </journal> <month> December </month> <year> 1986, </year> <pages> pages 1465-1472. </pages>
Reference: [MBGH] <author> N. Morgan, H. Bourlard, S. Greenberg, H. Hermansky, </author> <title> Stochastic Perceptual Auditory-Event-Based Models for Speech Recognition, </title> <booktitle> Pro ceedings ICSLP, </booktitle> <pages> pages 1943-46, </pages> <address> Yokohama, Japan, </address> <year> 1994. </year>
Reference-contexts: The frame just prior to the beginning of a new phone was automatically labelled as the transition. All other frames were labeled as nts for non-transitioning state, and mapped onto the non-perceiving state mentioned in SPAM literature <ref> [MBGH] </ref>. An example, the word six is shown in Figure 4. The waveform in the figure is labeled with phones, on the bottom row, and with the corresponding avent labels, on the upper row.
Reference: [MBGHW] <author> N. Morgan, H. Bourlard, S. Greenberg, H. Hermansky, and S.-L. Wu, </author> <title> Stochastic Perceptual Models of Speech, </title> <booktitle> IEEE Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Detroit, Michigan, 1995.. </address>
Reference-contexts: In this study, avents are assumed to occur at the boundary between two phones and can be viewed as responses to leftcontext-dependent phonetic onsets. We built a recognition system based on avents to validate the SPAM idea of recognizing speech by focussing on transitions <ref> [MBGHW] </ref>. We have not implemented several parts of the complete SPAM theory, most notably the dependency of an avent on previous avents or on the elapsed time between avents.
Reference: [TD] <author> C. C. Tappert and S. K. Das, </author> <title> Memory and Time Improvements in a Dynamic Programming Algorithm for Matching Speech Patterns, </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <month> December </month> <year> 1978, </year> <pages> pages 583-586. </pages>
Reference-contexts: It may also facilitate our training of the avent-detecting neural network by reducing the imbalance between the avent-detected and nts classes more meaningfully then by simple random subsampling. This an idea has been mentioned in published literature at least since 1978 <ref> [TD] </ref>. In several more recent papers, variable frame rate analysis techniques are able to eliminate 50% of the total number of frames without significant loss in performance [MB][LV]. Some of these papers mention that when low percentages of frames were eliminated, the performance of the recognizer increased.
Reference: [Tong] <author> G. Tong, </author> <title> Combating Additive Noise and Spectral Distortion in Speech Recognition Systems with JAH-RASTA, </title> <type> Masters Thesis, </type> <institution> UC Berkeley, </institution> <month> Spring </month> <year> 1994. </year>
Reference-contexts: Each word was recorded in isolation over a clean telephone line at Bellcore. For the additive noise in these experiments, we used automotive sound that was recorded over a cellular telephone. Noise was randomly selected from this source and then added to the clean speech waveforms <ref> [Tong] </ref>. We chose this task over others available because of its small size and simplicity and because the speech group at ICSI has already had considerable experience with this corpus.
References-found: 17

