URL: ftp://rtcl.eecs.umich.edu/outgoing/sjhan/doctor.ps.Z
Refering-URL: http://www.eecs.umich.edu/RTCL/harts/
Root-URL: http://www.cs.umich.edu
Email: email: fsjhan, kgshin, roseng@eecs.umich.edu  
Title: DOCTOR: An IntegrateD ftware Fault InjeC T iO n EnviR onment for Distributed Real-time Systems  
Author: Seungjae Han, Kang G. Shin, and Harold A. Rosenberg 
Note: is implemented on a distributed real-time system called HARTS [1], and its capability has been tested through numerous experiments.  
Address: Ann Arbor, Michigan 48109-2122.  
Affiliation: Real-Time Computing Laboratory Department of Elec. Engr. and Computer Science The University of Michigan  
Abstract: This paper presents an integrateD ftware fault injeC n enviR onment (DOCTOR) which is capable of generating synthetic workloads under which system dependability is evaluated, injecting various types of faults with different options, and collecting performance and dependability data. A comprehensive graphical user interface is also provided. The software-implemented fault-injection tool supports three types of faults: memory faults, CPU faults, and communication faults. Each injected fault may be permanent, transient or intermittent. A fault-injection plan can be formulated probabilistically, or based on the past event history. The modular organization of tools is particu larly designed for distributed architectures. DOCTOR
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Shin, </author> <title> "HARTS: A distributed real-time architecture," </title> <journal> IEEE Computer, </journal> <volume> vol. 24, no. 5, </volume> <pages> pp. 25-35, </pages> <month> May </month> <year> 1991. </year>
Reference: [2] <author> J. Stankovic, </author> <title> "Misconceptions about real-time computing," </title> <journal> IEEE Computer, </journal> <volume> vol. 21, no. 10, </volume> <pages> pp. 10-19, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: 1 Introduction In real-time systems the correctness of a computation depends not only on the logical correctness of the result but also on the time at which the result is produced <ref> [2] </ref>. There are a wide range of real-time applications, including continuous-media, transaction processing, and life- and mission-critical controls. Dis tributed architectures have proved to be well suited for meeting the timing and reliability requirements of these real-time applications.
Reference: [3] <author> G. Finelli, </author> <title> "Characterization of fault recovery through fault injection on ftmp," </title> <journal> IEEE Trans. Reliability, </journal> <volume> vol. 36, no. 2, </volume> <pages> pp. 164-170, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: With a common goal to accelerate the occurrence of faults or errors in the system to be tested during operation, numerous fault-injection tools have been developed using both software and hardware techniques <ref> [3, 4, 5, 6, 7, 8, 9] </ref>. Although hardware-implemented fault injectors closely mimic the real world by producing actual hardware faults, they require additional hardware which is often very expensive. <p> Increasing the sampling frequency also shortens the mean of error latency. Figure 2 shows the histogram of error latency for case 4 (screen dump of GUI). The latency of fault recovery is often assumed to be distributed exponentially. However, the authors of <ref> [3, 5] </ref> observed that this was not true. In [3], Finelli showed that error latency did not fit an exponential distribution, but it rather followed the Gamma or Weibull distribution. On the other hand, in [5], Barton showed that error latency followed the normal distribution. <p> Figure 2 shows the histogram of error latency for case 4 (screen dump of GUI). The latency of fault recovery is often assumed to be distributed exponentially. However, the authors of [3, 5] observed that this was not true. In <ref> [3] </ref>, Finelli showed that error latency did not fit an exponential distribution, but it rather followed the Gamma or Weibull distribution. On the other hand, in [5], Barton showed that error latency followed the normal distribution.
Reference: [4] <author> J. Arlat, Y. Crouzet, and J. Laprie, </author> <title> "Fault injection for dependability validation of fault-tolerant computing systems.," </title> <booktitle> in Proc. FTCS, </booktitle> <pages> pp. 348-355, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: With a common goal to accelerate the occurrence of faults or errors in the system to be tested during operation, numerous fault-injection tools have been developed using both software and hardware techniques <ref> [3, 4, 5, 6, 7, 8, 9] </ref>. Although hardware-implemented fault injectors closely mimic the real world by producing actual hardware faults, they require additional hardware which is often very expensive. <p> We have been developing an automated test case selection tool [11] for systematic fault generation on a formal basis. All these tools are controlled through a unified graphic user interface. In contrast to others <ref> [4, 5, 9] </ref>, we integrate tools in distributed environment. In real-time systems where time is the most precious resource, especially, fault injection and relevant data collection must be performed with minimum overhead to the target system. Otherwise, the correctness of the validation itself becomes doubtful. <p> 2 Fault-Injection Requirements There are four major attributes of fault injection: a set of faults F, a set of activations A which specify the workload used to exercise the system, a set of readouts R, and a set of derived measures M which correspond to dependability measures such as MTTF <ref> [4] </ref>. The FARM sets for fault injection in distributed real-time systems are more complex than those for single processor systems, because the fault-tolerance mechanisms of distributed real-time systems utilize multiple processors connected by communication networks.
Reference: [5] <author> J. Barton, E. Czeck, Z. Segall, and D. Siewiorek, </author> <title> "Fault injection experiments using fiat," </title> <journal> IEEE Trans. Computers, </journal> <volume> vol. 39, no. 4, </volume> <pages> pp. 575-581, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: With a common goal to accelerate the occurrence of faults or errors in the system to be tested during operation, numerous fault-injection tools have been developed using both software and hardware techniques <ref> [3, 4, 5, 6, 7, 8, 9] </ref>. Although hardware-implemented fault injectors closely mimic the real world by producing actual hardware faults, they require additional hardware which is often very expensive. <p> We have been developing an automated test case selection tool [11] for systematic fault generation on a formal basis. All these tools are controlled through a unified graphic user interface. In contrast to others <ref> [4, 5, 9] </ref>, we integrate tools in distributed environment. In real-time systems where time is the most precious resource, especially, fault injection and relevant data collection must be performed with minimum overhead to the target system. Otherwise, the correctness of the validation itself becomes doubtful. <p> Increasing the sampling frequency also shortens the mean of error latency. Figure 2 shows the histogram of error latency for case 4 (screen dump of GUI). The latency of fault recovery is often assumed to be distributed exponentially. However, the authors of <ref> [3, 5] </ref> observed that this was not true. In [3], Finelli showed that error latency did not fit an exponential distribution, but it rather followed the Gamma or Weibull distribution. On the other hand, in [5], Barton showed that error latency followed the normal distribution. <p> However, the authors of [3, 5] observed that this was not true. In [3], Finelli showed that error latency did not fit an exponential distribution, but it rather followed the Gamma or Weibull distribution. On the other hand, in <ref> [5] </ref>, Barton showed that error latency followed the normal distribution. To compare our experimental results with the others mentioned above, we performed the least-squares fit of our data to three types of distribution: normal, Weibull, and exponential distributions.
Reference: [6] <author> G. Kanawati, N. Kanawati, and J. Abraham, "FER-RARI: </author> <title> A tool for the validation of system dependability properties," </title> <booktitle> in Proc. FTCS, </booktitle> <pages> pp. 336-344. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: With a common goal to accelerate the occurrence of faults or errors in the system to be tested during operation, numerous fault-injection tools have been developed using both software and hardware techniques <ref> [3, 4, 5, 6, 7, 8, 9] </ref>. Although hardware-implemented fault injectors closely mimic the real world by producing actual hardware faults, they require additional hardware which is often very expensive. <p> pSOS +m provides system support within a node, an extended version of the x -kernel [14] operating system coordinates communication between nodes. 4 Like most other real-time systems, HARTS does not employ virtual memory or memory protection to reduce the unpredictability in memory access caused by page faults. similar to <ref> [6, 9] </ref>. In HARTOS, some of the CPU register contents are saved in the task control block and others are saved in the run-time stack, when a context switch occurs.
Reference: [7] <author> K. Echtle and M. Leu, </author> <title> "The EFA fault injector for fault-tolerant distributed system testing," </title> <booktitle> in Workshop on Fault-Tolerant Parallel and Distributed Systems, </booktitle> <pages> pp. 28-35. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: With a common goal to accelerate the occurrence of faults or errors in the system to be tested during operation, numerous fault-injection tools have been developed using both software and hardware techniques <ref> [3, 4, 5, 6, 7, 8, 9] </ref>. Although hardware-implemented fault injectors closely mimic the real world by producing actual hardware faults, they require additional hardware which is often very expensive.
Reference: [8] <author> H. Rosenberg and K. Shin, </author> <title> "Software fault injection and its application in distributed systems," </title> <booktitle> in Proc. FTCS, </booktitle> <pages> pp. 208-217. </pages> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: With a common goal to accelerate the occurrence of faults or errors in the system to be tested during operation, numerous fault-injection tools have been developed using both software and hardware techniques <ref> [3, 4, 5, 6, 7, 8, 9] </ref>. Although hardware-implemented fault injectors closely mimic the real world by producing actual hardware faults, they require additional hardware which is often very expensive.
Reference: [9] <author> W. Kao, R. Iyer, and D. Tang, </author> <title> "FINE: A fault injection and monitoring environment for tracing the UNIX system behavior under faults," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 19, no. 11, </volume> <pages> pp. 1105-1118, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: With a common goal to accelerate the occurrence of faults or errors in the system to be tested during operation, numerous fault-injection tools have been developed using both software and hardware techniques <ref> [3, 4, 5, 6, 7, 8, 9] </ref>. Although hardware-implemented fault injectors closely mimic the real world by producing actual hardware faults, they require additional hardware which is often very expensive. <p> We have been developing an automated test case selection tool [11] for systematic fault generation on a formal basis. All these tools are controlled through a unified graphic user interface. In contrast to others <ref> [4, 5, 9] </ref>, we integrate tools in distributed environment. In real-time systems where time is the most precious resource, especially, fault injection and relevant data collection must be performed with minimum overhead to the target system. Otherwise, the correctness of the validation itself becomes doubtful. <p> pSOS +m provides system support within a node, an extended version of the x -kernel [14] operating system coordinates communication between nodes. 4 Like most other real-time systems, HARTS does not employ virtual memory or memory protection to reduce the unpredictability in memory access caused by page faults. similar to <ref> [6, 9] </ref>. In HARTOS, some of the CPU register contents are saved in the task control block and others are saved in the run-time stack, when a context switch occurs.
Reference: [10] <author> D. Kiskis, </author> <title> Generation of Synthetic Workloads for Distributed Real-Time Computing Systems, </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: The dependence of experimental results on the executing workloads has to be dealt with in a systematic manner. For ease in generating workloads of various operational characteristics under which system dependability may be evaluated, we have developed a synthetic workload generation tool <ref> [10] </ref>. Also, to facilitate the collection of both performance and reliability data, an efficient data-collection tool is developed. We have been developing an automated test case selection tool [11] for systematic fault generation on a formal basis. All these tools are controlled through a unified graphic user interface. <p> Data Collection Module (DCM) collects experimental data during each experiment, and they are analyzed off-line after completing the experiment by Data Analysis Module (DAM). To obtain more accurate timing data with smaller performance overhead, Hardware MONitor (HMON) can be used in the place of DCM. Synthetic Workload Generator (SWG) <ref> [10] </ref> is provided to generate various artificial workloads. A tool for systematic fault selection [11] is currently under development. In addition, a comprehensive Graphic User Interface (GUI) and an automated multi-run experiment facility are provided to facilitate and automate the design and execution of fault-injection experiments.
Reference: [11] <author> H. Rosenberg and K. Shin, </author> <title> "Specification and generation of fault-injection experiments," </title> <booktitle> in Proc. FTCS. IEEE, </booktitle> <year> 1995. </year> <note> Submitted for publication. </note>
Reference-contexts: Also, to facilitate the collection of both performance and reliability data, an efficient data-collection tool is developed. We have been developing an automated test case selection tool <ref> [11] </ref> for systematic fault generation on a formal basis. All these tools are controlled through a unified graphic user interface. In contrast to others [4, 5, 9], we integrate tools in distributed environment. <p> To obtain more accurate timing data with smaller performance overhead, Hardware MONitor (HMON) can be used in the place of DCM. Synthetic Workload Generator (SWG) [10] is provided to generate various artificial workloads. A tool for systematic fault selection <ref> [11] </ref> is currently under development. In addition, a comprehensive Graphic User Interface (GUI) and an automated multi-run experiment facility are provided to facilitate and automate the design and execution of fault-injection experiments. Fault-injection experiments are completely transparent to the workloads. Each fault-injection experiment with specific work-loads is called a run.
Reference: [12] <author> K. Shin, D. Kandlur, D. Kiskis, P. Dodd, H. Rosen-berg, and A. Indiresan, </author> <title> "A distributed real-time operating system," </title> <journal> IEEE Software, </journal> <pages> pp. 58-68, </pages> <month> September </month> <year> 1992. </year> <note> [13] pSOS+/68K User's Manual, </note> <institution> Integrated Systems Inc., </institution> <year> 1992. </year>
Reference-contexts: In the current configuration, the nodes of HARTS are VMEbus-based Motorola 68040 systems. Each HARTS node has 1-3 AP cards, an NP card, and a communication network interface board. Each node of HARTS runs an operating system called HAR-TOS <ref> [12] </ref>. 3 A Sun Sparcstation serves as a console. Applications and system software are downloaded from this workstation through a dedicated local Ethernet. In implementing the fault injector on HARTS, we use three techniques to inject faults concurrently with the execution of workloads.
Reference: [14] <author> N. Hutchinson and L. Peterson, </author> <title> "The x-Kernel: An architecture for implementing network protocols," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 17, no. 1, </volume> <pages> pp. 1-13, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: While pSOS +m provides system support within a node, an extended version of the x -kernel <ref> [14] </ref> operating system coordinates communication between nodes. 4 Like most other real-time systems, HARTS does not employ virtual memory or memory protection to reduce the unpredictability in memory access caused by page faults. similar to [6, 9].
Reference: [15] <author> D. Fussell and S. Rangarajan, </author> <title> "Probabilistic diagnosis of multiprocessor systems with arbitrary connectivity," </title> <booktitle> Proc. FTCS, </booktitle> <pages> pp. 560-565, </pages> <year> 1989. </year>
Reference-contexts: This data can then be used both to validate the predicted performance of the algorithm, and to assist in the selection of various parameters used during the execution of the algorithm. The algorithm we chose to test is the probabilistic distributed diagnosis algorithm given in <ref> [15] </ref>. This algorithm is intended for the diagnosis of distributed systems of arbitrary connectivity. A run of the diagnosis algorithm consists of a number of rounds of testing. <p> There are a number of observations to be drawn from this data. The first thing to notice is that in almost all cases, the measured diagnostic accuracy of the algorithm exceeded that predicted by the probabilistic model in <ref> [15] </ref>, in many cases by a significant percentage. This is because the model makes a number of pessimistic assumptions, and therefore predicts only the worst-case performance of the algorithm. <p> As we see in interprocessor test coverage as low as 50%, the algorithm achieves nearly 100% correct diagnosis within 7 rounds of testing. When the test coverage is 95%, only 3 rounds are required to reach 100%. As predicted by the asymptotic analysis of the algorithm in <ref> [15] </ref>, both the measured and predicted diagnostic accuracy converge to 100% as the number of tests increase, but the measured accuracy starts much higher, and converges more quickly than predicted.
References-found: 14

