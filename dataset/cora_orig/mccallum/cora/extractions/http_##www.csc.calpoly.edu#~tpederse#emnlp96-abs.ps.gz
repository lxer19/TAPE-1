URL: http://www.csc.calpoly.edu/~tpederse/emnlp96-abs.ps.gz
Refering-URL: http://www.csc.calpoly.edu/~tpederse/pubs.html
Root-URL: http://www.csc.calpoly.edu
Email: fpedersen,rbruceg@seas.smu.edu  
Title: What to Infer from a Description  
Author: Ted Pedersen Rebecca Bruce 
Date: February 20, 1996  
Address: Dallas, TX 75275  
Affiliation: Department of Computer Science Engineering Southern Methodist University  
Abstract: Recent work in identifying dependent collocations among consecutive words (i.e., dependent bigrams) has applied inferential statistical methods where descriptive ones may have been more appropriate and easier to use. In this paper we make the distinction between inferential and descriptive methods and discuss how and when each should be applied. Inferential methods are useful in that they allow one to generalize the results obtained from the analysis of a random data sample to a larger population. However, implicit in these methodologies are stringent requirements regarding the nature of the data sample. We show experimentally the effect of not complying with these requirements in the context of dependent bigram identification. We suggest that Fisher's exact test is the most appropriate test for making inferences from a random sample of bigram data since this test makes the fewest requirements regarding the nature of the data. When it is possible to exhaustively study a population then a descriptive approach is most appropriate. There is no need to infer the characteristics of a population when that population can be studied in its entirety. We introduce a new descriptive measure, minimum sensitivity, that can be used to identify dependent collocations in a population. Experimental results show that this descriptive measure compares favorably to previous approaches. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. </author> <title> Agresti. Categorical Data Analysis. </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: Therefore Fisher's exact test can be used to determine the exact probability of drawing the observed data sample from a population described by the hypothesized model. The details of how Fisher's exact test is performed can be found in any number of sources, among them <ref> [1] </ref>, [7], or [10]. The significance values obtained using Fisher's exact test are reliable regardless of the distributional characteristics of the data sample; the test defines the exact distribution of comparable data samples not an approximation to that distribution.
Reference: [2] <editor> G. Altmann and M. Schibbe. Das Menzerathsche Gesetz in Informationsverarbeitenden Systemen. </editor> <address> Hildesheim, Zurich, </address> <year> 1989. </year>
Reference-contexts: Others have since found that analogues of Zipf's law apply at all levels of language <ref> [2] </ref>. The implications of Zipf's law are two-sided for statistical NLP. It can be viewed as fortuitous because it implies that a significant proportion of a corpus is made up of the most frequent words; these occur frequently enough to collect reliable statistics on them.
Reference: [3] <author> J. Badsberg. </author> <title> An Environment for Graphical Models. </title> <type> PhD thesis, </type> <institution> Aalborg University, </institution> <year> 1995. </year>
Reference-contexts: In particular, for bigram data we recommend Fisher's exact test. This test is available in the freely distributed software package CoCo <ref> [3] </ref> and in numerous commercially available statistical packages (e.g. SAS, SPSS, BMDP and IMSL). On an intuitive level, an exact test defines the exact distribution of comparable data samples that would result if you repeatedly randomly sampled from the hypothetical population model.
Reference: [4] <author> Y. Bishop, S. Fienberg, and P. Holland. </author> <title> Discrete Multivariate Analysis. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1975. </year>
Reference-contexts: We suggest a simple and effective measure for identifying dependent bigrams: the minimum sensitivity (S min ). Sensitivity is classically defined as the proportion of true results that agree with the true state <ref> [4] </ref>. We define sensitivity to be the ratio of how often a word occurs in a specific bigram to how often it occurs overall. Equations 9 and 10 show how sensitivity values are computed from bigram data in a 2 fi 2 contingency table.
Reference: [5] <author> K. Church, W. Gale, P. Hanks, and D. Hindle. </author> <title> Using statistics in lexical analysis. </title> <editor> In U. Zernik, editor, </editor> <title> Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1991. </year>
Reference-contexts: In this paper, we make clear the distinction between inferential and descriptive methods via an examination of recent work (e.g. <ref> [5] </ref>, [6], [11]) in identifying dependent collocations among consecutive words (i.e., dependent bigrams). In much of the previous work concerning bigram analysis, an inferential method is applied to the analysis of an entire population rather than to make inferences about some larger population. <p> There are a number of statistical tests that can be used to identify these bigrams which we refer to generally as tests for association. In this paper we examine the empirical methods developed by Church et. al. <ref> [5] </ref>, Dunning [6], and Smadja [11] for the study of dependent bigrams. These methods are useful because the unaided human mind simply cannot notice all the important lexical patterns, let alone rank them in order of importance, when dealing with large amounts of text. <p> When the variance of the population is unknown and the sample size is large, standard statistical techniques allow that the population variance can be estimated by the sample variance (s 2 ) which is in turn scaled by the sample size (n). t = q n Church et. al. <ref> [5] </ref> show how the t-test can be used to identify dependent bigrams. The data sample is produced through a series of Bernoulli trials that record the presence or absence of a single bigram.
Reference: [6] <author> T. Dunning. </author> <title> Accurate methods for the statistics of surprise and coincidence. </title> <journal> Computational Linguistics, </journal> <volume> 19(1) </volume> <pages> 61-74, </pages> <year> 1993. </year>
Reference-contexts: In this paper, we make clear the distinction between inferential and descriptive methods via an examination of recent work (e.g. [5], <ref> [6] </ref>, [11]) in identifying dependent collocations among consecutive words (i.e., dependent bigrams). In much of the previous work concerning bigram analysis, an inferential method is applied to the analysis of an entire population rather than to make inferences about some larger population. The particular method used is a significance test. <p> There are a number of statistical tests that can be used to identify these bigrams which we refer to generally as tests for association. In this paper we examine the empirical methods developed by Church et. al. [5], Dunning <ref> [6] </ref>, and Smadja [11] for the study of dependent bigrams. These methods are useful because the unaided human mind simply cannot notice all the important lexical patterns, let alone rank them in order of importance, when dealing with large amounts of text. <p> Dunning <ref> [6] </ref> shows that G 2 holds more closely to the 2 distribution than does X 2 when dealing with bigram data. <p> This approach to assigning significance is based on the assumption that the sample means are normally distributed. This assumption is shown to be inappropriate for bigram data in <ref> [6] </ref>. Smadja [11] performs a similar type of analysis using a z-score. <p> However, there is some variation between the significance computed for Fisher's test and G 2 among the more independent bigrams. This confirms the observation made by <ref> [6] </ref> that G 2 tends to overstate independence. This indicates that the asymptotic approximation of G 2 by the 2 distribution is breaking down for those bigrams. In this case Fisher's test provides a more reliable significance value.
Reference: [7] <author> R. Fisher. </author> <title> The Design of Experiments. </title> <publisher> Oliver and Boyd, </publisher> <address> London, </address> <year> 1935. </year>
Reference-contexts: Therefore Fisher's exact test can be used to determine the exact probability of drawing the observed data sample from a population described by the hypothesized model. The details of how Fisher's exact test is performed can be found in any number of sources, among them [1], <ref> [7] </ref>, or [10]. The significance values obtained using Fisher's exact test are reliable regardless of the distributional characteristics of the data sample; the test defines the exact distribution of comparable data samples not an approximation to that distribution.
Reference: [8] <author> M. Marcus, B. Santorini, and M. A. Marcinkiewicz. </author> <title> Building a large annotated corpus of English: The Penn Treebank. </title> <journal> Computational Linguistics, </journal> <volume> 19(2) </volume> <pages> 313-330, </pages> <year> 1993. </year>
Reference-contexts: But it also implies that there will always be a large tail of words that appear only a few times. As an example, in a 133,000 word subset of the ACL/DCI Wall Street Journal corpus <ref> [8] </ref> there are 14,319 distinct words and 73,779 distinct bigrams. Of the distinct words, 48 percent of them occur only once and 80 percent of them occur five times or less. Of the distinct bigrams, 81 percent occur once and 97 percent of them occur five times or less.
Reference: [9] <author> T. Pedersen, M. Kayaalp, and R. Bruce. </author> <title> Significant lexical relationships. </title> <type> Technical Report 96-CSE-3, </type> <institution> Southern Methodist University, </institution> <month> February </month> <year> 1996. </year>
Reference-contexts: Such a table is called an I fi J contingency table. Contingency tables can extend to beyond 2 dimensions when an object is cross-classified with respect to more than 2 variables. However, in this paper only 2 dimensional tables are considered. See <ref> [9] </ref> for an example of how larger tables are used in NLP. The joint frequency distribution of X and Y in the data sample is described by the counts fn ij g in the contingency table. <p> However, when the number of comparable data samples is large, the exhaustive enumeration performed in Fisher's test becomes infeasible. In <ref> [9] </ref> an alternative exact test is discussed. 5 Experimental Results for Inferential Methods As discussed in the previous section, there are two fundamental assumptions that underly inferential testing: (1) the data must be collected via a random sampling of the population under study, and (2) for many tests, the sample must
Reference: [10] <author> T. Read and N. Cressie. </author> <title> Goodness-of-fit Statistics for Discrete Multivariate Data. </title> <publisher> Springer-Verlag Inc., </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: More precisely, X 2 and G 2 are approximately 2 distributed when the following conditions regarding the random data sample hold <ref> [10] </ref>: 1. the sample size is large, 6 2. the number of cells in the contingency table representation of the data is fixed and small relative to the sample size, and 3. the expected count (under the hypothetical population model) for each cell is large. <p> Dunning [6] shows that G 2 holds more closely to the 2 distribution than does X 2 when dealing with bigram data. However, as pointed out in <ref> [10] </ref>, it is uncertain whether G 2 holds to the 2 distribution when the minimum of the expected values in a table is less than 1.0. <p> Therefore Fisher's exact test can be used to determine the exact probability of drawing the observed data sample from a population described by the hypothesized model. The details of how Fisher's exact test is performed can be found in any number of sources, among them [1], [7], or <ref> [10] </ref>. The significance values obtained using Fisher's exact test are reliable regardless of the distributional characteristics of the data sample; the test defines the exact distribution of comparable data samples not an approximation to that distribution.
Reference: [11] <author> F. Smadja. </author> <title> Retrieving collocations from text: </title> <journal> Xtract. Computational Linguistics, </journal> <volume> 19(1) </volume> <pages> 143-177, </pages> <year> 1993. </year>
Reference-contexts: In this paper, we make clear the distinction between inferential and descriptive methods via an examination of recent work (e.g. [5], [6], <ref> [11] </ref>) in identifying dependent collocations among consecutive words (i.e., dependent bigrams). In much of the previous work concerning bigram analysis, an inferential method is applied to the analysis of an entire population rather than to make inferences about some larger population. The particular method used is a significance test. <p> There are a number of statistical tests that can be used to identify these bigrams which we refer to generally as tests for association. In this paper we examine the empirical methods developed by Church et. al. [5], Dunning [6], and Smadja <ref> [11] </ref> for the study of dependent bigrams. These methods are useful because the unaided human mind simply cannot notice all the important lexical patterns, let alone rank them in order of importance, when dealing with large amounts of text. <p> This approach to assigning significance is based on the assumption that the sample means are normally distributed. This assumption is shown to be inappropriate for bigram data in [6]. Smadja <ref> [11] </ref> performs a similar type of analysis using a z-score.
Reference: [12] <author> G. Zipf. </author> <title> The Psycho-Biology of Language. </title> <publisher> Houghton Mi*in Company, </publisher> <address> Boston, MA, </address> <year> 1935. </year>
Reference-contexts: The challenge in identifying dependent bigrams is that most bigrams are relatively rare regardless of the size of the text. This follows from the the distributional tendencies of individual words and bigrams as described in Zipf's Law <ref> [12] </ref>. Zipf found that if the frequencies of the words in a large English text are ordered from most to least frequent, (f 1 ; f 2 ; : : : ; f m ), these frequencies roughly obey: f i / 1 i .
References-found: 12

