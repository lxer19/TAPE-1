URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/94.ferguson-allen.aips94.arguing-about-plans.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/ferguson/papers.html
Root-URL: 
Email: fferguson,jamesg@cs.rochester.edu  
Title: Arguing About Plans: Plan Representation and Reasoning for Mixed-Initiative Planning  
Author: George Ferguson James F. Allen 
Address: Rochester, Rochester, NY  
Affiliation: Department of Computer Science University of  
Date: 13-15 June 1994  
Note: Proceedings, Second Intl. Conf. on AI Planning Systems, Chicago, IL,  
Abstract: We consider the problem of representing plans for mixed-initiative planning, where several participants cooperate to develop plans. We claim that in such an environment, a crucial task is plan communication: the ability to suggest aspects of a plan, accept such suggestions from other agents, criticize plans, revise them, etc., in addition to building plans. The complexity of this interaction imposes significant new requirements on the representation of plans. We describe a formal model of plans based on defeasible argument systems that allows us to perform these types of reasoning. The arguments that are produced are explicit objects that can be used to provide a semantics for statements about plans. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. F., and Ferguson, G. </author> <year> 1994. </year> <title> Actions and events in interval temporal logic. </title> <journal> J. Logic and Computation, </journal> <note> Special Issue on Actions and Processes. To appear. </note>
Reference-contexts: In this paper we are concerned with the formal representational underpinnings. The representation proposed involves applying techniques for representing arguments to a logic of time, events and action, which supports reasoning about attempting actions and their effects. We have explored the logic of time and action in depth elsewhere <ref> (Allen & Ferguson 1994) </ref> and have applied it to plan reasoning (Allen 1991). <p> The representation can easily be generalized to either a situation calculus representation or the more expressive interval temporal logic <ref> (Allen & Ferguson 1994) </ref> that we actually use. An important point is that action attempts must be distinguished from their effects.
Reference: <author> Allen, J. F., and Schubert, L. K. </author> <year> 1991. </year> <title> The TRAINS project. </title> <type> TRAINS Technical Note 91-1, </type> <institution> Dept. of Computer Science, U. of Rochester, Rochester, NY. </institution>
Reference-contexts: The representation proposed involves applying techniques for representing arguments to a logic of time, events and action, which supports reasoning about attempting actions and their effects. We have explored the logic of time and action in depth elsewhere (Allen & Ferguson 1994) and have applied it to plan reasoning <ref> (Allen 1991) </ref>. Here we explore the use of explicit argument structures in a direct inference system, and show how, with a suitable logic of time and action, they provide a very rich representation both for talking about plans and for doing plan reasoning itself.
Reference: <author> Allen, J. F. </author> <year> 1991. </year> <title> Temporal reasoning and planning. In Reasoning about Plans. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher> <pages> 1-68. </pages>
Reference-contexts: The representation proposed involves applying techniques for representing arguments to a logic of time, events and action, which supports reasoning about attempting actions and their effects. We have explored the logic of time and action in depth elsewhere (Allen & Ferguson 1994) and have applied it to plan reasoning <ref> (Allen 1991) </ref>. Here we explore the use of explicit argument structures in a direct inference system, and show how, with a suitable logic of time and action, they provide a very rich representation both for talking about plans and for doing plan reasoning itself.
Reference: <author> Chapman, D. </author> <year> 1987. </year> <title> Planning for conjunctive goals. </title> <booktitle> Artificial Intelligence 32 </booktitle> <pages> 333-377. </pages>
Reference: <author> Drummond, M. </author> <year> 1989. </year> <title> Situated control rules. </title> <booktitle> In Proceedings of KR-89, </booktitle> <pages> 103-113. </pages>
Reference: <author> Ferguson, G. </author> <year> 1994. </year> <title> Domain plan reasoning in trains-93. </title> <type> TRAINS Technical Note 93-2, </type> <institution> Dept. of Computer Science, U. of Rochester, Rochester, NY. </institution> <note> To appear. </note>
Reference-contexts: In this paper we are concerned with the formal representational underpinnings. The representation proposed involves applying techniques for representing arguments to a logic of time, events and action, which supports reasoning about attempting actions and their effects. We have explored the logic of time and action in depth elsewhere <ref> (Allen & Ferguson 1994) </ref> and have applied it to plan reasoning (Allen 1991). <p> The representation can easily be generalized to either a situation calculus representation or the more expressive interval temporal logic <ref> (Allen & Ferguson 1994) </ref> that we actually use. An important point is that action attempts must be distinguished from their effects.
Reference: <author> Gross, D.; Allen, J. F.; and Traum, D. R. </author> <year> 1993. </year> <title> The TRAINS-91 dialogues. </title> <type> TRAINS Technical Note 92-1, </type> <institution> Dept. of Computer Science, U. of Rochester, Rochester, NY. </institution>
Reference-contexts: F30602-91-C-0010. designed an experiment that involves two people collaborating on forming plans in a transportation planning domain involving train scheduling. The subjects could not see each other, and could only communicate by speaking into a microphone. Over thirteen hours of interaction have been collected and transcribed (see <ref> (Gross, Allen, & Traum 1993) </ref>). In no case did one agent simply describe the plan by describing a sequence of actions.
Reference: <author> Hayes, P. J. </author> <year> 1975. </year> <title> A representation for robot plans. </title> <booktitle> In Proceedings of IJCAI-75, </booktitle> <pages> 181-188. </pages>
Reference: <author> Kambhampati, S., and Hendler, J. A. </author> <year> 1992. </year> <title> A validation-structure-based theory of plan modification and reuse. </title> <booktitle> Artificial Intelligence 55 </booktitle> <pages> 193-258. </pages>
Reference: <author> Kambhampati, S. </author> <year> 1992. </year> <title> Characterizing multi-contributor causal structure for planning. </title> <booktitle> In Proceedings of AIPS-92, </booktitle> <pages> 116-125. </pages>
Reference: <author> Konolige, K., and Pollack, M. E. </author> <year> 1989. </year> <title> Ascribing plans to agents, preliminary report. </title> <booktitle> In Proceedings of IJCAI-89, </booktitle> <pages> 924-930. </pages>
Reference-contexts: He notes the ability to include knowledge about applicability of defeasible rules directly within the framework and the incremental nature of argumentation that we have also noted. Konolige and Pollack <ref> (Konolige & Pollack 1989) </ref> directly apply the defeasible reasoning paradigm to plan recognition in the context of plans-as-intentions.
Reference: <author> Konolige, K. </author> <year> 1988. </year> <title> Defeasible argumentation in reasoning about events. </title> <editor> In Ras, Z. W., and Saitta, L., eds., </editor> <booktitle> Methodologies for Intelligent Systems 3, Proc. of the Third Intl. Symposium, </booktitle> <pages> 380-390. </pages> <publisher> North-Holland. </publisher>
Reference-contexts: Thus, our work can be seen as a generalization and formalization of that work which can be applied to other problems involved in plan communication. Our approach also abstracts away from the underlying representation of action (i.e., STRIPS). Konolige <ref> (Konolige 1988) </ref> applies defeasible reasoning to reasoning about events, in particular to the Yale Shooting problem. The emphasis is on what types of defeasible arguments are important in reasoning about events as well as what information is necessary for adjudicating between these arguments.
Reference: <author> Loui, R. </author> <year> 1987. </year> <title> Defeat among arguments: A system of defeasible inference. </title> <booktitle> Computational Intelligence 3(2) </booktitle> <pages> 100-106. </pages>
Reference-contexts: The preceding example is used to illustrate the approach. Finally we discuss some of the issues raised by this work. Argument Systems In this section we present a formal description of an argument system based on those of Loui <ref> (Loui 1987) </ref> and of Pollock (Pollock 1987; 1992). Basic Definitions We assume a logical language with an entailment relation j=, and allow a set KB of propositions that specify domain constraints against which arguments can be evaluated. <p> Pollock (Pollock 1992), for example, considers such phenomena as collective defeat and self-defeat. The details are not necessary to an appreciation of the formalism as regards planning. Also, there might be other grounds for preferring one argument over another besides specificity. Loui <ref> (Loui 1987) </ref> considers evidence, directness, and preferred premise, for example. As well, there might be domain-specific criteria, such as resource use or time limits in a planning context. The specificity principle is generally accepted as appropriate and is sufficient for what follows.
Reference: <author> McCarthy, J., and Hayes, P. J. </author> <year> 1969. </year> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <booktitle> In Machine Intelligence 4. </booktitle> <publisher> American Elsevier Publishing Co., Inc. </publisher> <pages> 463-502. </pages>
Reference-contexts: The traditional representations of plans are inadequate for supporting communication about plans. Formal models of plans (e.g., <ref> (McCarthy & Hayes 1969) </ref>,(Chapman 1987)) typically define a plan as a sequence of actions. If agents communicated plans by simply listing the sequence of actions to be performed, then this might be adequate. But this is not what happens.
Reference: <author> Pollock, J. L. </author> <year> 1987. </year> <title> Defeasible reasoning. </title> <booktitle> Cognitive Science 11 </booktitle> <pages> 481-518. </pages>
Reference: <author> Pollock, J. L. </author> <year> 1992. </year> <title> How to reason defeasibly. </title> <booktitle> Artificial Intelligence 57 </booktitle> <pages> 1-42. </pages>
Reference-contexts: Definition 7 An argument A is undefeated if there is no argument B that conflicts with A that is not itself defeated. There are complications in applying this somewhat circular definition to determine which arguments are undefeated. Pollock <ref> (Pollock 1992) </ref>, for example, considers such phenomena as collective defeat and self-defeat. The details are not necessary to an appreciation of the formalism as regards planning. Also, there might be other grounds for preferring one argument over another besides specificity.
References-found: 16

