URL: http://www.media.mit.edu/~vmb/papers/ootv.ps
Refering-URL: http://www.media.mit.edu/~vmb/
Root-URL: http://www.media.mit.edu
Title: Object-Oriented Television  
Author: By V. Michael Bove, Jr. 
Address: Room E15-324, 20 Ames Street Cambridge MA 02139 USA  
Affiliation: Media Laboratory, Massachusetts Institute of Technology  
Note: To appear in SMPTE Journal,  
Email: Internet: vmb@mit.edu  
Phone: (617) 253-0334, Fax (617) 258-6264  
Date: Dec. 1995  
Abstract: In search of more compression, researchers have recently sought to describe digital video of real scenes not as sequences of frames but rather as collections of objects that are rendered and combined according to scripting information. Depending upon the application and the scene analysis tools available, representations may range from two-dimensional layers to full three-dimensional computer-graphics-style data bases. The significance of these more meaningful representations goes beyond compression, however, enabling new forms of interactivity and personalization, as well as new degrees of freedom in post-production. This paper proposes a computational framework for a television receiver that can handle digital video in forms from "traditional" motion-compensated transform coders to sets of three-dimensional objects and discusses the requirements for a scripting language to control such a receiver. It is also noted that the concept of scalability can be expanded to include "intelligently resizable video," where the originator of a video sequence can specify how the scene is to be composed and cut for displays of differing sizes and aspect ratios. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. M. Bove, Jr. and A. B. Lippman, </author> <title> "Scalable Open Architecture Television," </title> <journal> SMPTE J., </journal> <volume> 101, </volume> <pages> 2-5, </pages> <month> Jan. </month> <year> 1992. </year>
Reference: [2] <author> G. Reitmeyer, et al., </author> <title> "The Digital Hierarchy | A Blueprint for Television in the 21st Century," </title> <journal> SMPTE J., </journal> <volume> 101, </volume> <pages> 466-470, </pages> <month> July </month> <year> 1992. </year>
Reference: [3] <author> A. B. Watson, </author> <title> "Perceptual-Components Architecture for Digital Video," </title> <journal> J. Optical Soc. America A, </journal> <volume> 7, </volume> <pages> 1943-1954, </pages> <month> Oct. </month> <year> 1990. </year>
Reference: [4] <author> W. Stackhouse, </author> <title> "Report of the Task Force on Digital Image Architecture," </title> <journal> SMPTE J., </journal> <volume> 101, </volume> <pages> 855-891, </pages> <month> Dec. </month> <year> 1992. </year>
Reference: [5] <author> K. A. Parulski, et al., </author> <title> "Source-Adaptive Encoding Options for HDTV and NTSC," </title> <journal> SMPTE J., </journal> <volume> 101, </volume> <pages> 674-683, </pages> <month> Oct. </month> <year> 1992. </year>
Reference: [6] <author> E. A. Adelson and J. Y. A. Wang, </author> <title> "Representing Moving Images with Layers," </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> 3, </volume> <pages> 625-638, </pages> <month> Sept. </month> <year> 1994. </year>
Reference: [7] <author> H. G. Mussmann, et al., </author> <title> "Object-Oriented Analysis-Synthesis Coding of Moving Objects," Signal Processing: </title> <journal> Image Communication, </journal> <volume> 1, </volume> <pages> 117-138, </pages> <year> 1989. </year> <month> 11 </month>
Reference: [8] <author> R. G. Kermode, </author> <title> "Coding for Content: Enhanced Resolution from Coding," </title> <booktitle> Proc. IEEE ICIP '95, </booktitle> <publisher> (in press). </publisher>
Reference: [9] <author> J. K. Aggarwal and N. Nandhakumar, </author> <title> "On the Computation of Motion from Sequences of Images | A Review," </title> <journal> Proc. IEEE, </journal> <volume> 76, </volume> <pages> 917-935, </pages> <month> Aug. </month> <year> 1988. </year>
Reference: [10] <author> S. C. Higgins, </author> <title> "The Moviemaker's Workspace: Towards a 3D Environment for Pre-Visualization," </title> <type> SM thesis, </type> <institution> MIT, </institution> <year> 1994. </year>
Reference: [11] <author> K. Fukui, et al., </author> <title> "A Virtual Studio for TV Program Production", </title> <journal> SMPTE J., </journal> <volume> 103, </volume> <pages> 386-390, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Many video editing systems now permit effects such as compositing. And increasingly, video content is created on computer-graphics systems. Even if the structured scene representation is used only within the studio, new production and post-production possibilities emerge (see, for instance, Reference <ref> [11] </ref>).
Reference: [12] <author> V. M. Bove, Jr., et al., </author> <title> "Real-Time Decoding and Display of Structured Video," </title> <booktitle> Proc. IEEE ICMCS '94, </booktitle> <pages> pp. 456-462. </pages>
Reference-contexts: It is then up to the display implementation to determine how best to produce images (repetition or interpolation of 2-D objects, re-rendering of 3-D objects) at an appropriate rate for the screen. The illustrated processing model should not be taken as a literal hardware architecture. Reference <ref> [12] </ref> describes a software implementation of this receiver on Cheops, a high-speed data-flow platform developed by the MIT Media Laboratory for use in digital video processing, but other implementations such as specialized hardware, parallel processors, or software on general-purpose processors are equally possible.
Reference: [13] <author> S. Becker and V. M. Bove, Jr., </author> <title> "Semiautomatic 3-D Model Extraction from Uncalibrated 2-D Camera Views," </title> <booktitle> Proc. SPIE Image Synthesis, </booktitle> <volume> 2410, </volume> <year> 1995, </year> <pages> pp. 447-461. </pages>
Reference: [14] <author> W. G. Gardner, </author> <title> "The Virtual Acoustic Room," </title> <type> SM Thesis, </type> <institution> MIT, </institution> <year> 1992. </year>
Reference-contexts: As directed by the script, perhaps in conjunction with user interaction, the audio would be "rendered" for the speakers associated with the video display. Also analogously with the visual case, the auditory synthesis methods <ref> [14] </ref> are much better understood at this time than are the analysis methods.[15] Until the analysis is better developed, changes in production methods and linkage with the video analysis can assist the process.
Reference: [15] <author> E. A. Macpherson, </author> <title> "A Computer Model of Binaural Localization for Stereo Imaging Measurement," </title> <journal> J. Audio Eng. Soc., </journal> <volume> 39, </volume> <pages> 604-622, </pages> <month> Sept. </month> <year> 1991. </year> <month> 12 </month>
References-found: 15

