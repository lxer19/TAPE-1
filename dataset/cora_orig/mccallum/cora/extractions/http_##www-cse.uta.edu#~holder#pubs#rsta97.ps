URL: http://www-cse.uta.edu/~holder/pubs/rsta97.ps
Refering-URL: http://www-cse.uta.edu/~holder/pubs.html
Root-URL: 
Email: Email: fcook, piotr, holderg@cse.uta.edu  
Title: Decision-Theoretic Multi-Agent Sensor Planning  
Author: Diane J. Cook, Piotr Gmytrasiewicz and Lawrence B. Holder 
Keyword: DARPA's Unmanned Ground Vehicle program.  
Address: Arlington  
Affiliation: Department of Computer Science Engineering University of Texas at  
Abstract: This paper describes a decision-theoretic approach to cooperative sensor planning between multiple autonomous vehicles executing a military mission. For this autonomous vehicle application, intelligent cooperative reasoning must be used to select optimal vehicle viewing locations and select optimal camera pan and tilt angles throughout the mission. Decisions are made in such a way as to maximize the value of information gained by the sensors while maintaining vehicle stealth. Because the mission involves multiple vehicles, cooperation can be used to balance the work load and to increase information gain. This paper presents the theoretical foundations of our cooperative sensor planning research and describes the application of these techniques to 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Aloimonos, I. Weiss, and A. Bandyopadhyay. </author> <title> Active vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 333-356, </pages> <year> 1988. </year>
Reference-contexts: Active vision research has also made use of decision-theoretic techniques to measure the utility of gathering information <ref> [1, 2, 13] </ref>, but has not been applied to this type of military application where both static and dynamic decision making is necessary to achieve the overall mission objectives.
Reference: [2] <author> R. </author> <title> Bajcsy. Active perception. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 76(8) </volume> <pages> 996-1005, </pages> <year> 1988. </year>
Reference-contexts: Work on active vision has been well established in the field. Bajcsy <ref> [2] </ref> introduced the idea of active perception as applied to controlling a sensor at any level of abstraction, from controlling the focus of the physical device (as we are doing) to controlling the semantic interpretation of information returned from the sensor. <p> Active vision research has also made use of decision-theoretic techniques to measure the utility of gathering information <ref> [1, 2, 13] </ref>, but has not been applied to this type of military application where both static and dynamic decision making is necessary to achieve the overall mission objectives.
Reference: [3] <author> R. Bajcsy and M. Campos. </author> <title> Active and exploratory perception. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 56(1) </volume> <pages> 31-40, </pages> <year> 1992. </year>
Reference-contexts: Although the work to date has demonstrated effective cooperative decision-guided sensor planning, there are a number of avenues we plan to pursue in the future. Ballard and Brown [4] and Bajcsy and Campos <ref> [3] </ref> both emphasize that learning is an important part of active perception. To date, the probabilities associated with each aspect of terrain reasoning, security, and stealth have been hard-coded. Future extensions of this project will learn the value of information and probabilities of each aspect of the mission from experience.
Reference: [4] <author> D. H. Ballard and C. M. Brown. </author> <booktitle> Principles of animate vision. CVGIP: Image Understanding, </booktitle> <volume> 56(1) </volume> <pages> 3-21, </pages> <year> 1992. </year>
Reference-contexts: Although the work to date has demonstrated effective cooperative decision-guided sensor planning, there are a number of avenues we plan to pursue in the future. Ballard and Brown <ref> [4] </ref> and Bajcsy and Campos [3] both emphasize that learning is an important part of active perception. To date, the probabilities associated with each aspect of terrain reasoning, security, and stealth have been hard-coded.
Reference: [5] <author> K. R. Boff, L. Kaufman, and J. P. Thomas. </author> <title> Handbook of Perception and Human Performance, Volume 1. </title> <publisher> John Wiley and Sons, </publisher> <year> 1986. </year>
Reference-contexts: Literature in the cognitive science community shows that this decision-theoretic approach to sensor planning is also demonstrated in human perception and information-gathering <ref> [5, 19] </ref>. Although active vision techniques have been used to make centralized decisions about sensor movements, there is very little work that allows decentralized sensor planning decisions. Multi 19 agent planning and negotiation techniques are common in the AI literature, but have not been integrated into computer vision work.
Reference: [6] <author> W. Briggs and D. J. Cook. </author> <title> Flexible social laws. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (to appear), </booktitle> <year> 1995. </year>
Reference-contexts: The use of multiple vehicles increases the chance of a successful mission because of the increased robustness, increased security, and increased number of observation points for scouting an area. Multi-agent planning and coordination is a focus of much attention in AI reasoning <ref> [6, 8, 9, 14, 15, 17, 21] </ref>. As automation of intelligent tasks increases, the need arises for heterogeneous agents to work in a common environment.
Reference: [7] <author> D. Cook. </author> <title> Reconfiguration of multi-agent planning systems. </title> <booktitle> In Proceedings of Artificial Intelligence Planning Systems, </booktitle> <pages> pages 225-230. </pages> <address> AIPS, </address> <year> 1994. </year>
Reference-contexts: While the need for multi-agent planning algorithms is apparent, 13 the development of algorithms which meet each agent's goals in a timely fashion, avoid deadlock, and do not incur heavy communication costs provides a challenging task. Cook <ref> [7] </ref> describes three types of multi-agent control schemes: central control, distributed control, and local control (no communication). Central control is shown to be effective when communication is reliable, and local control is effective if no communication is needed; otherwise, distributed control is necessary.
Reference: [8] <author> E. H. Durfee and T. A. Montgomery. </author> <title> Coordination as distributed search in a hierarchical behavior space. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 21(6) </volume> <pages> 1363-1378, </pages> <month> Nov/Dec </month> <year> 1991. </year>
Reference-contexts: The use of multiple vehicles increases the chance of a successful mission because of the increased robustness, increased security, and increased number of observation points for scouting an area. Multi-agent planning and coordination is a focus of much attention in AI reasoning <ref> [6, 8, 9, 14, 15, 17, 21] </ref>. As automation of intelligent tasks increases, the need arises for heterogeneous agents to work in a common environment.
Reference: [9] <author> E. Ephrati, M. E. Pollack, and S. </author> <title> Ur. Deriving multi-agent coordination through filtering strategies. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (to appear), </booktitle> <year> 1995. </year>
Reference-contexts: The use of multiple vehicles increases the chance of a successful mission because of the increased robustness, increased security, and increased number of observation points for scouting an area. Multi-agent planning and coordination is a focus of much attention in AI reasoning <ref> [6, 8, 9, 14, 15, 17, 21] </ref>. As automation of intelligent tasks increases, the need arises for heterogeneous agents to work in a common environment.
Reference: [10] <author> J. A. Feldman and R. F. Sproull. </author> <booktitle> Decision theory and artificial intelligence ii: the hungry monkey. Cognitive Science, </booktitle> <volume> 1(2) </volume> <pages> 158-192, </pages> <month> April </month> <year> 1977. </year>
Reference-contexts: The calculation of the expected value of a sensing action has to include the likelihood that the interesting object is located within the area scanned, and that the sensor can successfully recognize the object at that location. Following Feldmann and 5 Sproull <ref> [10] </ref>, we propose that the general expression for the value of scanning the area A, using sensor S, from the position P , be: U Scan (A; S; P ) = Z X P 1 c (x; y)P 2 k (x; y)V I k dxdy; (2) where P 1 c (x;
Reference: [11] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year> <month> 21 </month>
Reference-contexts: When a new field of view is requested, a biased roulette wheel is spun. Roulette wheel methods have proven to be effective in a variety of adaptive algorithm applications <ref> [11] </ref>. Using this selection method, potential fields of view are assigned a portion of the wheel corresponding to their fraction 12 of the total possible weight. The probability of selecting a given FOV is proportional to the FOV's share of the roulette wheel.
Reference: [12] <author> R. L. Keeney and H. Raiffa. </author> <title> Decisions with multiple objectives: preferences and value tradeoffs. </title> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference-contexts: One of the basic results in the multiattribute utility theory states that if the attributes are utility-independent then the global utility function is a multiplicative function over the attributes considered <ref> [12] </ref>.
Reference: [13] <author> E. Krotkov. </author> <title> Active Computer Vision by Cooperative Focus and Stereio. </title> <address> Springer-Verlay, </address> <year> 1989. </year>
Reference-contexts: Active vision research has also made use of decision-theoretic techniques to measure the utility of gathering information <ref> [1, 2, 13] </ref>, but has not been applied to this type of military application where both static and dynamic decision making is necessary to achieve the overall mission objectives.
Reference: [14] <author> Y. Moses and M. Tennenholtz. </author> <title> Artificial social systems part i: basic principles. </title> <type> Technical Report CS90-12, </type> <institution> Weizmann Institute, </institution> <year> 1990. </year>
Reference-contexts: The use of multiple vehicles increases the chance of a successful mission because of the increased robustness, increased security, and increased number of observation points for scouting an area. Multi-agent planning and coordination is a focus of much attention in AI reasoning <ref> [6, 8, 9, 14, 15, 17, 21] </ref>. As automation of intelligent tasks increases, the need arises for heterogeneous agents to work in a common environment.
Reference: [15] <author> Y. Moses and M. Tennenholtz. </author> <title> On formal aspects of artificial social systems. </title> <type> Technical Report CS91-01, </type> <institution> Weizmann Institute, </institution> <year> 1991. </year>
Reference-contexts: The use of multiple vehicles increases the chance of a successful mission because of the increased robustness, increased security, and increased number of observation points for scouting an area. Multi-agent planning and coordination is a focus of much attention in AI reasoning <ref> [6, 8, 9, 14, 15, 17, 21] </ref>. As automation of intelligent tasks increases, the need arises for heterogeneous agents to work in a common environment.
Reference: [16] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: One method of learning probability values is through the use of adaptive probabilistic networks, a subset of belief nets that can learn individual probability values and distributions using gradient descent <ref> [16, 18, 20] </ref>. Another important extension of this project is to add temporal reasoning to the sensor planning algorithm.
Reference: [17] <author> J. S. Rosenschein and G. Zlotkin. </author> <title> Designing conventions for automated negotiation. </title> <journal> AI Magazine, </journal> <volume> 15(3) </volume> <pages> 29-46, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: The use of multiple vehicles increases the chance of a successful mission because of the increased robustness, increased security, and increased number of observation points for scouting an area. Multi-agent planning and coordination is a focus of much attention in AI reasoning <ref> [6, 8, 9, 14, 15, 17, 21] </ref>. As automation of intelligent tasks increases, the need arises for heterogeneous agents to work in a common environment.
Reference: [18] <author> S. Russell and P. Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: One method of learning probability values is through the use of adaptive probabilistic networks, a subset of belief nets that can learn individual probability values and distributions using gradient descent <ref> [16, 18, 20] </ref>. Another important extension of this project is to add temporal reasoning to the sensor planning algorithm.
Reference: [19] <author> M. L. Shaw and P. Shaw. </author> <title> Optimal allocation of cognitive resources to spatial locations. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 3(2) </volume> <pages> 201-211, </pages> <year> 1977. </year>
Reference-contexts: Literature in the cognitive science community shows that this decision-theoretic approach to sensor planning is also demonstrated in human perception and information-gathering <ref> [5, 19] </ref>. Although active vision techniques have been used to make centralized decisions about sensor movements, there is very little work that allows decentralized sensor planning decisions. Multi 19 agent planning and negotiation techniques are common in the AI literature, but have not been integrated into computer vision work.
Reference: [20] <author> D. Spiegelhalter, P. Dawid, S. Lauritzen, and R. Cowell. </author> <title> Bayesian analysis in expert systems. </title> <journal> Statistical Science, </journal> <volume> 8 </volume> <pages> 219-282, </pages> <year> 1993. </year>
Reference-contexts: One method of learning probability values is through the use of adaptive probabilistic networks, a subset of belief nets that can learn individual probability values and distributions using gradient descent <ref> [16, 18, 20] </ref>. Another important extension of this project is to add temporal reasoning to the sensor planning algorithm.
Reference: [21] <author> F. von Martial. </author> <title> Coordinating Plans of Autonomous Agents. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: The use of multiple vehicles increases the chance of a successful mission because of the increased robustness, increased security, and increased number of observation points for scouting an area. Multi-agent planning and coordination is a focus of much attention in AI reasoning <ref> [6, 8, 9, 14, 15, 17, 21] </ref>. As automation of intelligent tasks increases, the need arises for heterogeneous agents to work in a common environment.
Reference: [22] <author> S. M. Weiss and C. A. </author> <title> Kulikowski. Computer Systems That Learn. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year> <month> 22 </month>
Reference-contexts: These regions are selected to maximize visibility of the region by the vehicles while also trying to balance the work load between vehicles. To date, the objective area is split into separate regions along lines parallel to the x or y axis. In the future, piecewise linear regression algorithms <ref> [22] </ref> can be used to yield a more effective split. All of these operations can be computationally expensive because of the large number of rays that must be traced.
References-found: 22

