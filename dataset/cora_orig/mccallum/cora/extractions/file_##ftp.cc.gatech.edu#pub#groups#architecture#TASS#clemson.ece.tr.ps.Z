URL: file://ftp.cc.gatech.edu/pub/groups/architecture/TASS/clemson.ece.tr.ps.Z
Refering-URL: http://www.cs.gatech.edu/computing/Architecture/TASS/tass.html
Root-URL: 
Title: Evaluating Multigauge Architectures for Computer Vision  
Author: by W. B. Ligon III and U. Ramachandran 
Address: Clemson, SC 29634-0915  
Affiliation: Electrical and Computer Engineering Department Clemson University  
Pubnum: TR-111392-0915P  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Agarwal. </author> <title> Limits on interconnection network performance. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 398-412, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: This quantity depends on the parameters of the ICN. The relationship between these parameters is beyond the scope of this paper, and the reader is referred to texts such as <ref> [2, 1, 9] </ref>. <p> The experiments described in this paper utilize an ICN model for a "k-ary n-cube" class of networks configured as a binary hypercube with serial links. The model is presented in [8] and is based on those used in Scott [9], Agarwal <ref> [1] </ref> and Dally [2]. The specifics of this model are beyond the scope of this paper. 18 4.2 Experimental Method In [7] we outline an experimental methodology for utilizing RAW in the design of parallel architectures. In these experiments we utilize the same methodology.
Reference: [2] <author> W. Dally. </author> <title> Performance Analysis of k-ary n-cube Interconnection Networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(6) </volume> <pages> 775-785, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: This quantity depends on the parameters of the ICN. The relationship between these parameters is beyond the scope of this paper, and the reader is referred to texts such as <ref> [2, 1, 9] </ref>. <p> The experiments described in this paper utilize an ICN model for a "k-ary n-cube" class of networks configured as a binary hypercube with serial links. The model is presented in [8] and is based on those used in Scott [9], Agarwal [1] and Dally <ref> [2] </ref>. The specifics of this model are beyond the scope of this paper. 18 4.2 Experimental Method In [7] we outline an experimental methodology for utilizing RAW in the design of parallel architectures. In these experiments we utilize the same methodology.
Reference: [3] <author> W. D. Hillis. </author> <title> The Connection Machine. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, </address> <year> 1985. </year>
Reference-contexts: Control reconfigurable machines can be configured as MIMD, SIMD, and Multiple-SIMD systems. Examples of systems which perform control reconfiguration are the Connection Machine 2 <ref> [3] </ref> which provides 64K PEs and 4 CUs, TRAC [10],and PASM [11], each of which provide N PEs and CUs. Processor reconfigurability (also known as multi-gauge capability) is the ability of the architecture to trade off faster and/or higher precision PEs for more numerous PEs. <p> This feature is called capability reconfiguration and is introduced in [6]. Capability reconfiguration is radically different from precision reconfiguration in terms of its implementation requirements. Capability reconfigurable PEs begin with a very simple computation circuit such as that described in <ref> [3] </ref>, but with a full word of precision. In such systems the CU utilizes a microsequencer to decode complex arithmetic operations such as multiplication and floating point arithmetic into a sequence of microinstructions. <p> PE model 1 is a bit-serial processing element whose design is taken from the Connection Machine 1 <ref> [3] </ref>, and is also used in the Connection Machine 2 and Connection Machine 200 (see Figure 5). This PE uses 1-bit data paths, has a small collection of 1-bit registers and a pair ControlData R15C A B R0 R1 . . . <p> All transfers from memory are stored in register A or B, and all transfers to memory are from register C. The PE can perform both a memory transfer and a computation in a single cycle. In Hillis <ref> [3] </ref>, a prototype chip in 2 micron CMOS packaged 16 PEs of very similar design onto a single die with a network router.
Reference: [4] <author> S. I. Kartashev and S. P. Kartashev. </author> <title> A multicomputer system with dynamic architecture. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(10):704-721, </volume> <month> October </month> <year> 1979. </year>
Reference-contexts: This capability can take two forms. First, low-precision PEs can be logically joined to form higher-precision PEs. This type of processor reconfiguration is called precision reconfiguration and has been provided in TRAC and DCG <ref> [4] </ref>. Second, simple boolean logic units can be combined to form more complex arithmetic units such as fast multipliers and floating point units. This feature is called capability reconfiguration and is introduced in [6]. Capability reconfiguration is radically different from precision reconfiguration in terms of its implementation requirements.
Reference: [5] <author> W. B. Ligon. </author> <title> An Empirical Analysis of Reconfigurable Architectures. </title> <type> Doctoral Thesis, </type> <institution> Georgia Institute of Technology, Atlanta, </institution> <year> 1992. </year>
Reference-contexts: In [7] we discuss the design details of RAW and provide an example experiment using it. In this paper we focus on the PCI model and present the results of experiments utilizing a coordinated set of tasks from computer vision applications. In [8] and <ref> [5] </ref> we demonstrate the PCI model's ability to handle control and interconnection aspects of the architecture. The experiments in this paper focus on processor granularity as the experimental variable, thus this paper emphasizes a breadth of application tasks rather than a breadth of architectural issues. <p> Each of these components can be further divided into three components which represent the processor, control, and interconnection dimensions. Details of RAW's design and construction are presented in [7] with additional details given in <ref> [5] </ref>. 13 4 A Study of Multigauge Architectures In this section we utilize the PCI model to study the potential for performance gains to be found in using multigauge heterogeneous architectures for computer vision systems by experimenting with the RAW simulation environment. <p> The benchmark programs presented in this study are shown in Table 2.1. Implementation details of these programs is beyond the scope of this paper. See Weems [13] for a functional description of the benchmark and <ref> [5] </ref> for a detailed description of the parallel implementation used in this study. 4.1 Architectures Studied The models and techniques presented in section 2 can be used to study heterogeneous systems regardless of the approach used to realize these systems.
Reference: [6] <author> W. B. Ligon and U. Ramachandran. </author> <title> A Reconfigurable Supercomputer Architecture. </title> <type> Technical Report GIT-ICS-89/13, </type> <institution> Georgia institute of Technology, </institution> <month> February </month> <year> 1989. </year> <month> 28 </month>
Reference-contexts: Second, simple boolean logic units can be combined to form more complex arithmetic units such as fast multipliers and floating point units. This feature is called capability reconfiguration and is introduced in <ref> [6] </ref>. Capability reconfiguration is radically different from precision reconfiguration in terms of its implementation requirements. Capability reconfigurable PEs begin with a very simple computation circuit such as that described in [3], but with a full word of precision. <p> Warp mode processing is a technique for simulating the presense of special-purpose hardware (such as support for trigonometric functions). The simulator separately accounts for the time to execute such functions. The three remaining PE models are based on the processor reconfigurable architecture described in <ref> [6] </ref>. 15 Program / Phase Description Filter Communicate 1 trade border values with neighbors Median median filter on image partition Fix Corners handle image borders Communicate 2 trade border values with neighbors Sobel Sobel transform on image partition Label Initialize Build Borders determine pixels on region borders Redistribute load balance border <p> Integer addition and logical operations perform no faster on model 3 PEs than model 2 PEs, but multiplication and floating point arithmetic do. As an example, model 3 PEs require 280 cycles to perform floating point addition, model 2 PEs require 370 cycles (see <ref> [6] </ref> for details). PE models 1, 2, and 3 are specifically designed to be reconfigured from one into another. The reconfigurable systems we simulate utilize a constant amount of hardware, and simply reconfigure the logical view of the PEs.
Reference: [7] <author> W. B. Ligon and U. Ramachandran. </author> <title> An Empirical Methodology for Exploring Reconfigurable Architectures. </title> <note> to appear in Journal of Parallel and Distributed Computing, </note> <year> 1992. </year>
Reference-contexts: We further discuss the performance relationship of programs and architectures within the context of this framework. These concepts have been embodied in a set of tools, the Reconfigurable Architecture Workbench (RAW), which allow us to simulate the execution of parallel programs on models of various parallel architectures. In <ref> [7] </ref> we discuss the design details of RAW and provide an example experiment using it. In this paper we focus on the PCI model and present the results of experiments utilizing a coordinated set of tasks from computer vision applications. <p> Each of these components can be further divided into three components which represent the processor, control, and interconnection dimensions. Details of RAW's design and construction are presented in <ref> [7] </ref> with additional details given in [5]. 13 4 A Study of Multigauge Architectures In this section we utilize the PCI model to study the potential for performance gains to be found in using multigauge heterogeneous architectures for computer vision systems by experimenting with the RAW simulation environment. <p> The model is presented in [8] and is based on those used in Scott [9], Agarwal [1] and Dally [2]. The specifics of this model are beyond the scope of this paper. 18 4.2 Experimental Method In <ref> [7] </ref> we outline an experimental methodology for utilizing RAW in the design of parallel architectures. In these experiments we utilize the same methodology. Briefly, we first study the performance of each of the four programs on an increasing number of unit model PEs, noting any change in the performance characteristic.
Reference: [8] <author> W. B. Ligon and U. Ramachandran. </author> <title> Simulating Interconnection Networks in RAW. </title> <type> Technical Report ECE-102692-0915P, </type> <institution> Clemson University, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: In [7] we discuss the design details of RAW and provide an example experiment using it. In this paper we focus on the PCI model and present the results of experiments utilizing a coordinated set of tasks from computer vision applications. In <ref> [8] </ref> and [5] we demonstrate the PCI model's ability to handle control and interconnection aspects of the architecture. The experiments in this paper focus on processor granularity as the experimental variable, thus this paper emphasizes a breadth of application tasks rather than a breadth of architectural issues. <p> The experiments described in this paper utilize an ICN model for a "k-ary n-cube" class of networks configured as a binary hypercube with serial links. The model is presented in <ref> [8] </ref> and is based on those used in Scott [9], Agarwal [1] and Dally [2]. The specifics of this model are beyond the scope of this paper. 18 4.2 Experimental Method In [7] we outline an experimental methodology for utilizing RAW in the design of parallel architectures.
Reference: [9] <author> S. Scott and J. Goodman. </author> <title> Performance of pipelined-channel k-ary n-cube networks. </title> <type> Technical Report CS-1010, </type> <institution> University of Wisconsin - Madison, </institution> <year> 1991. </year>
Reference-contexts: This quantity depends on the parameters of the ICN. The relationship between these parameters is beyond the scope of this paper, and the reader is referred to texts such as <ref> [2, 1, 9] </ref>. <p> The experiments described in this paper utilize an ICN model for a "k-ary n-cube" class of networks configured as a binary hypercube with serial links. The model is presented in [8] and is based on those used in Scott <ref> [9] </ref>, Agarwal [1] and Dally [2]. The specifics of this model are beyond the scope of this paper. 18 4.2 Experimental Method In [7] we outline an experimental methodology for utilizing RAW in the design of parallel architectures. In these experiments we utilize the same methodology.
Reference: [10] <author> M. C. Sejnowski, E. T. Upchurch, R. N. Kapur, D. P. S. Charlu, and G. J. Lipovski. </author> <title> An overview of the Texas Reconfigurable Array Computer. </title> <booktitle> In Proc. 1980 AFIPS Nat. Comput. Conf., </booktitle> <pages> pages 631-641, </pages> <address> Arlington, May 1980. </address> <publisher> AFIPS Press. </publisher>
Reference: [11] <author> H. J. Siegel, L. J. Siegel, F. C. Kemmerer, P. T. Mueller Jr., H. E. Smalley Jr., and S. D. Smith. PASM: </author> <title> A partitionable SIMD/MIMD system for image processing and pattern recognition. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(12):934-947, </volume> <month> December </month> <year> 1981. </year>
Reference-contexts: Control reconfigurable machines can be configured as MIMD, SIMD, and Multiple-SIMD systems. Examples of systems which perform control reconfiguration are the Connection Machine 2 [3] which provides 64K PEs and 4 CUs, TRAC [10],and PASM <ref> [11] </ref>, each of which provide N PEs and CUs. Processor reconfigurability (also known as multi-gauge capability) is the ability of the architecture to trade off faster and/or higher precision PEs for more numerous PEs. This capability can take two forms.
Reference: [12] <author> L. Snyder. </author> <title> Introduction to the Configurable, Highly Parallel Computer. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 47-56, </pages> <month> January </month> <year> 1982. </year>
Reference-contexts: Essentially, reconfigurability is a means of providing a high degree of service for short periods of time over a subset of the system with fewer total resources. An example of an interconnection reconfigurable architecture is the CHiP architecture <ref> [12] </ref>. Control reconfigurability (also known as multi-mode capability) describes the ability of an architecture to partition the PEs in the system among the CUs in various ways. Control reconfigurable machines can be configured as MIMD, SIMD, and Multiple-SIMD systems.
Reference: [13] <author> C. Weems, A. Hanson, E. Riseman, and A. Rosenfeld. </author> <title> An integrated image understanding benchmark. </title> <type> Technical report, </type> <institution> University of Massachusetts, </institution> <note> in preparation. 29 </note>
Reference-contexts: The number of data objects at this level is relatively small. 14 In order to capture the multi-level aspects of computer vision systems, we have utilized the 2nd DARPA image understanding benchmark in this study <ref> [13] </ref>. The benchmark uses two input images: an intensity image and a depth image, and is designed to require the use of both bottom-up and top-down strategies to resolve ambiguities in these images. The overall task of the benchmark programs is to recognize objects in a simplified blocks world. <p> The benchmark programs presented in this study are shown in Table 2.1. Implementation details of these programs is beyond the scope of this paper. See Weems <ref> [13] </ref> for a functional description of the benchmark and [5] for a detailed description of the parallel implementation used in this study. 4.1 Architectures Studied The models and techniques presented in section 2 can be used to study heterogeneous systems regardless of the approach used to realize these systems.
References-found: 13

