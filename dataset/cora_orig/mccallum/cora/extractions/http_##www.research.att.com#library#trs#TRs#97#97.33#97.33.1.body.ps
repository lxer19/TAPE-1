URL: http://www.research.att.com/library/trs/TRs/97/97.33/97.33.1.body.ps
Refering-URL: http://www.research.att.com/library/trs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: User Modeling For Spoken Dialogue System Evaluation  
Author: Wieland Eckert, Esther Levin, Roberto Pieraccini 
Address: Park Avenue Florham Park, NJ, 07932  
Affiliation: 180  
Abstract: Automatic speech dialogue systems are becoming common. In order to assess their performance, a large sample of real dialogues has to be collected and evaluated. This process is expensive, labor intensive, and prone to errors. To alleviate this situation we propose a user simulation to conduct dialogues with the system under investigation. Using stochastic modeling of real users we can both debug and evaluate a speech dialogue system while it is still in the lab, thus substantially reducing the amount of field testing with real users. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Norman M. Fraser and Paul Dalsgaard. </author> <title> Spoken dialogue systems: A European perspective. </title> <booktitle> In ISSD 96 [14], </booktitle> <pages> pages 25-36. </pages>
Reference-contexts: 1 Introduction Recent literature shows an increasing number of speech dialogue systems being implemented and used in the field <ref> [1, 2, 3, 4, 5, 6] </ref>. However, the development of such dialogue systems (especially the dialogue manager) is still considered art rather than an engineering task.
Reference: [2] <author> A. L. Gorin, B. A. Parker, R. M. Sachs, and J. G. Wilpon. </author> <title> How may I help you? In IVTTA 96 [15], </title> <address> pages 57-60. </address>
Reference-contexts: 1 Introduction Recent literature shows an increasing number of speech dialogue systems being implemented and used in the field <ref> [1, 2, 3, 4, 5, 6] </ref>. However, the development of such dialogue systems (especially the dialogue manager) is still considered art rather than an engineering task.
Reference: [3] <author> L. F. Lamel, J. L. Gauvain, S. K. Bennacef, L. Devillers, S. Foukia, J. J. Gan--golf, and S. Rosset. </author> <title> Field trials of a telephone service for rail travel information. </title> <booktitle> In IVTTA 96 [15], </booktitle> <pages> pages 111-116. </pages>
Reference-contexts: 1 Introduction Recent literature shows an increasing number of speech dialogue systems being implemented and used in the field <ref> [1, 2, 3, 4, 5, 6] </ref>. However, the development of such dialogue systems (especially the dialogue manager) is still considered art rather than an engineering task.
Reference: [4] <author> A. Kellner, B. Rueber, and F. Seide. </author> <title> A voice-controlled automatic telephone switchboard and directory information system. </title> <booktitle> In IVTTA 96 [15], </booktitle> <pages> pages 117-120. </pages>
Reference-contexts: 1 Introduction Recent literature shows an increasing number of speech dialogue systems being implemented and used in the field <ref> [1, 2, 3, 4, 5, 6] </ref>. However, the development of such dialogue systems (especially the dialogue manager) is still considered art rather than an engineering task.
Reference: [5] <author> Roberto Pieraccini, Esther Levin, and Wieland Eckert. AMICA: </author> <title> The AT&T Mixed Initiative Conversational Architecture. </title> <booktitle> In Proc. European Conf. on Speech Communication and Technology, </booktitle> <pages> pages 1875-1878, </pages> <address> Rhodes, Greece, </address> <month> September </month> <year> 1997. </year>
Reference-contexts: 1 Introduction Recent literature shows an increasing number of speech dialogue systems being implemented and used in the field <ref> [1, 2, 3, 4, 5, 6] </ref>. However, the development of such dialogue systems (especially the dialogue manager) is still considered art rather than an engineering task. <p> It seems reasonable to explore the system's capabilities in different specialized situations in order to obtain more detailed analyses of different cases. 4 Experiments & Results We have implemented a user model for the airline traffic information task (ATIS). This simulated user was connected to our AMICA system <ref> [5] </ref>. In order to get a feeling for different user interactions we implemented several parameter sets which resemble different populations of users. An outline of their characteristics is shown in Table 1. We ran simulations of 10,000 dialogues for each model and compared the evaluation results.
Reference: [6] <author> M. D. Sadek, A. Ferrieux, A. Cozannet, P. Bretier, F. Panaget, and J. Simonin. </author> <title> Effective human-computer cooperative spoken dialogue: </title> <booktitle> The AGS demonstrator. In ISSD 96 [14], </booktitle> <pages> pages 169-172. </pages>
Reference-contexts: 1 Introduction Recent literature shows an increasing number of speech dialogue systems being implemented and used in the field <ref> [1, 2, 3, 4, 5, 6] </ref>. However, the development of such dialogue systems (especially the dialogue manager) is still considered art rather than an engineering task.
Reference: [7] <author> Andrew Simpson and Norman Fraser. </author> <title> Black Box and Glass Box Evaluation of the SUNDIAL System. </title> <booktitle> In Proc. European Conf. on Speech Communication and Technology, </booktitle> <pages> pages 1423-1426, </pages> <address> Berlin, Germany, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Any evaluation and optimization on the dialogue level would greatly profit from a standardized automatic evaluation methodology where the adverse effects of subjective judgment could be minimized <ref> [7, 8, 9, 10] </ref>. In this paper we propose using a simulated user for an automatic assessment of a spoken dialogue system.
Reference: [8] <author> Morena Danieli and Elisabetta Gerbino. </author> <title> Metrics for Evaluating Dialogue Strategies in a Spoken Language System. </title> <booktitle> In Proceedings of the 1995 AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, </booktitle> <pages> pages 34-39, </pages> <year> 1995. </year>
Reference-contexts: Any evaluation and optimization on the dialogue level would greatly profit from a standardized automatic evaluation methodology where the adverse effects of subjective judgment could be minimized <ref> [7, 8, 9, 10] </ref>. In this paper we propose using a simulated user for an automatic assessment of a spoken dialogue system.
Reference: [9] <author> L. Hirschman and H. Thompson. </author> <title> Overview of evaluation in speech and natural language processing. </title> <editor> In R. Cole, editor, </editor> <booktitle> Survey of the State of the Art in Human Language Technology. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1996. </year> <note> to appear. </note>
Reference-contexts: Any evaluation and optimization on the dialogue level would greatly profit from a standardized automatic evaluation methodology where the adverse effects of subjective judgment could be minimized <ref> [7, 8, 9, 10] </ref>. In this paper we propose using a simulated user for an automatic assessment of a spoken dialogue system.
Reference: [10] <author> Marilyn A. Walker, Diane J. Litman, Candace A. Kamm, and Alicia Abella. </author> <title> PARADISE: A Framework for Evaluating Spoken Dialogue Agents. </title> <booktitle> In Proc. Conf. of the Association for Computational Linguistics, </booktitle> <pages> pages 271-280, </pages> <address> Madrid, Spain, </address> <year> 1997. </year>
Reference-contexts: Any evaluation and optimization on the dialogue level would greatly profit from a standardized automatic evaluation methodology where the adverse effects of subjective judgment could be minimized <ref> [7, 8, 9, 10] </ref>. In this paper we propose using a simulated user for an automatic assessment of a spoken dialogue system. <p> Simulation of user interaction is indispensable for this endeavor [11]. Furthermore, we will be engaged in the development and application of automatic evaluation criteria <ref> [10] </ref>. We want to provide quantitative measures for the "quality" of dialogues with as few manual operations as possible. 6 Summary Automatic evaluation of speech dialogue systems is accomplished by conducting dialogues with a simulated user.
Reference: [11] <author> Esther Levin, Roberto Pieraccini, and Wieland Eckert. </author> <title> A Stochastic Model of Computer-Human Interaction for Learning Dialogue Strategies. </title> <booktitle> In IEEE ASRU Workshop, </booktitle> <address> Santa Barbara, </address> <year> 1997. </year> <note> (this issue). </note>
Reference-contexts: different user populations can be modeled easily, * the same user model can be used for comparative evaluation of different (competing) dialogue systems, and * the simulations provide a mechanism for employing automatic optimization techniques for dialogue strategies, such as reinforcement learning (described in a companion paper in these proceedings <ref> [11] </ref>). A substantial amount of guesswork can be eliminated by employing standard procedures. In the following sections we describe our approach toward automatic evaluation of dialogue systems. <p> Clearly, it is necessary to run a large number of dialogues for a learning system and for practical reasons these dialogues can not be collected with human users. Simulation of user interaction is indispensable for this endeavor <ref> [11] </ref>. Furthermore, we will be engaged in the development and application of automatic evaluation criteria [10].
Reference: [12] <author> J. R. Searle. </author> <title> Speech acts. An essay in the philospphy of language. </title> <publisher> University Press, </publisher> <address> Cambridge, </address> <year> 1969. </year>
Reference-contexts: Speech is carried by acoustic signals that can be transported, for instance, via telephone lines. Word sequences represent the next level reducing the variability of speech production to clean text, e.g. written sentences. Intentions can not be observed directly but can be described in terms of speech acts <ref> [12] </ref> or dialogue acts [13]. In a simplified view they represent the actual information whereas the other two levels can be seen as transport mechanisms only. We have implemented an automatic agent that simulates the customer of level of interaction.
Reference: [13] <author> H. C. Bunt. </author> <title> Rules for the interpretation, evaluation and generation of dialogue acts. </title> <booktitle> In IPO annual progress report 16, </booktitle> <pages> pages 99-107. </pages> <institution> Technische Universiteit, Eindhoven, </institution> <year> 1981. </year>
Reference-contexts: Word sequences represent the next level reducing the variability of speech production to clean text, e.g. written sentences. Intentions can not be observed directly but can be described in terms of speech acts [12] or dialogue acts <ref> [13] </ref>. In a simplified view they represent the actual information whereas the other two levels can be seen as transport mechanisms only. We have implemented an automatic agent that simulates the customer of level of interaction.
Reference: [14] <editor> Acoustical Scociety of Japan. </editor> <booktitle> Proceedings International Symposium on Spoken Dialogues, </booktitle> <address> Philadelphia, </address> <month> October </month> <year> 1996. </year>
Reference: [15] <editor> IEEE Communication Scociety. </editor> <booktitle> Proceedings of the IEEE Third Workshop on Interactive Voice Technology for Telecommunications Applications, </booktitle> <address> Basking Ridge, </address> <month> September </month> <year> 1996. </year>
References-found: 15

