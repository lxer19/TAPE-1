URL: http://www.cs.tamu.edu/faculty/rwerger/pubs/ics99_tr1557.ps.gz
Refering-URL: http://www.cs.tamu.edu/faculty/rwerger/pubs/
Root-URL: http://www.cs.tamu.edu
Title: Hardware for Speculative Reduction Parallelization and Optimization in DSM Multiprocessors 1  
Author: Ye Zhang Lawrence Rauchwerger and Josep Torrellas 
Keyword: scalable shared-memory multiprocessors, cache coherence protocols, run-time paralleliza-tion, speculative execution, reduction parallelization.  
Web: http://www.cs.tamu.edu/faculty/rwerger/  
Note: http://iacoma.cs.uiuc.edu Texas A&M University,  
Affiliation: University of Illinois at Urbana-Champaign,  
Abstract: In previous work, we have presented a scheme for the speculative parallel execution of loops that have a modest number of cross-iteration dependences. In case a dependence violation is detected, we locally repair the state. Then, we restart parallel execution from that point on. We call the general algorithm the Sliding Commit algorithm. It is capable of validating independent and privatizable memory acces patterns. In this paper we extend its capabilities to validate the parallelization of reductions, a special and quite frequent type of access pattern. Furthermore, we present a techniques for the optimization of parallel reductions which is especially useful in the case of sparse, irregular applications. Simulations indicate significant speedups relative to sequential execution of reductions. Their optimization achieves an almost 50% improvement over 'classic' reduction parallelization. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Asenjo, E. Gutierrez, Y. Lin, D. Padua, B. Pottenger, and E. Zapata. </author> <title> On the automatic parallelization of sparse and irregular fortran codes. </title> <type> Technical Report 1512, </type> <institution> Center for Supercomputing Research and Development, </institution> <month> February </month> <year> 1997. </year>
Reference-contexts: Because the access pattern of the tested array is sparse, the case can be handled as a regular reduction array or as a shared array. When handled as a regular reduction array, reduction optimization (PCLR) has been applied. For the loop move3 goto100 in Dsmc3d privatization removes all dependences <ref> [1] </ref> but, due to its sparse nature, causes high initialization and final merging overhead. Spark98 is a sparse matrix and dense vector multiplication C kernel.
Reference: [2] <author> M. Berry et al. </author> <title> The Perfect Club Benchmarks: Effective Performance Evaluation of Supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(3):540, </volume> <month> Fall </month> <year> 1989. </year>
Reference-contexts: Private arrays are allocated locally. 5.2 Workloads Due to the impractically long running simulation times of full-length applications we have extracted and measured only the performance of representative (in terms of relative execution time) loops from well-known codes. Spice is a Perfect Club <ref> [2] </ref> code, Euler and Dsmc3d are HPF-2 applications [4], and Rmv is a Spark98 kernel [14]. The loops in subroutines Load and BJT from Spice have a highly irregular access pattern (they follow a linked list) but, after applying ANPA and reduction parallelization, they become fully parallel.
Reference: [3] <author> W. Blume, R. Doallo, R. Eigenmann, J. Grout, J. Hoeflinger, T. Lawrence, J. Lee, D. Padua, Y. Paek, B. Pottenger, L. Rauchwerger, and P. Tu. </author> <title> Advanced Program Restructuring for High-Performance Computers with Polaris. </title> <journal> IEEE Computer, </journal> <volume> 29(12):7882, </volume> <month> December </month> <year> 1996. </year>
Reference-contexts: The modeled multiprocessor has the hardware support of the basic design [20] and the enhancement proposed in this paper. The simulated applications have been pre-processed with the Polaris <ref> [3] </ref> parallelizing compiler that has been specifically enhanced to transform selected loops for speculative run-time parallelization. The compiler has inserted all necessary instructions to perform the marking and analysis phases. The modeled architecture has 200-MHz RISC processors, each with a 32-Kbyte on-chip primary cache and a 512-Kbyte off-chip secondary cache.
Reference: [4] <author> I. Duff, R. Schreiber, and P. Havlak. </author> <title> Hpf-2 scope of activities and motivating applications. </title> <type> Technical Report CRPC-TR94492, </type> <institution> Rice University, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: Spice is a Perfect Club [2] code, Euler and Dsmc3d are HPF-2 applications <ref> [4] </ref>, and Rmv is a Spark98 kernel [14]. The loops in subroutines Load and BJT from Spice have a highly irregular access pattern (they follow a linked list) but, after applying ANPA and reduction parallelization, they become fully parallel.
Reference: [5] <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the Automatic Parallelization of Four Perfect-Benchmark Programs. </title> <booktitle> Lecture Notes in Computer Science 589. Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <pages> pages 6583, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: One method is to transform the do loop into a doall and enclose the access to the reduction variable in an unordered critical section <ref> [5, 24] </ref>. The drawbacks of this method are that it is not scalable and that it requires potentially expensive synchronizations. A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm [10, 12].
Reference: [6] <author> S. Goldschmidt. </author> <title> Simulation of Multiprocessors: Accuracy and Performance. </title> <type> Ph.D. Thesis, </type> <institution> Stanford University, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: In this section, we present our simulation environment, the workloads, and conclude with the obtained experimental performance measurements. 5.1 Simulation Environment Our evaluation is based on execution-driven simulations of a CC-NUMA shared-memory multiprocessor using Tangolite <ref> [6] </ref>. The modeled multiprocessor has the hardware support of the basic design [20] and the enhancement proposed in this paper. The simulated applications have been pre-processed with the Polaris [3] parallelizing compiler that has been specifically enhanced to transform selected loops for speculative run-time parallelization.
Reference: [7] <author> S. Gopal, T. N. Vijaykumar, J. E. Smith, and G. S. Sohi. </author> <title> Speculative Versioning Cache. </title> <booktitle> In Proceedings of the 4th International Symposium on High-Performance Computer Architecture, </booktitle> <month> February </month> <year> 1998. </year>
Reference-contexts: Moreover, the hardware support improves the performance of any reduction parallelization by at least 50% over the software implemented solution. The overall scheme presented in [22] is somewhat related to speculative parallelization inside a multiprocessor chip <ref> [7, 8, 9, 16] </ref>, which also relies on extending the cache coherence protocol to detect dependence violations. Our scheme, however, is targeted to large-scale DSM parallelism. In addition, it does not have some of the limitations of the proposed chip-multiprocessor schemes. <p> Such limitations include the need to bound the size of the speculative state to fit in a buffer or L1 cache, and a strict in-order task commit policy that may result in load-imbalance among processors <ref> [7, 8, 9, 16] </ref>. The specific support for reduction validation is, to the best of our knowledge, original while the reduction optimization method is related to [11]. <p> As mentioned in Section 5.1 the compiler can evaluate the size of the private structures needed for the partial results and chose the appropriate technique: with or without PCLR. 7 Related Work Some work related to ours is four schemes that support speculative parallelization inside a multiprocessor chip <ref> [7, 9, 8, 16] </ref>. These schemes are relatively similar to each other. The cache coherence protocol inside a chip is extended with versions or time stamps similar to ours. Parallelism is exploited by running one task (for example one loop iteration) on each of the processors on chip.
Reference: [8] <author> Lance Hammond, Mark Willey, and Kunle Olukotun. </author> <title> Data speculation support for a chip multiprocessor. </title> <booktitle> In ASPLOS8, </booktitle> <year> 1998. </year>
Reference-contexts: Moreover, the hardware support improves the performance of any reduction parallelization by at least 50% over the software implemented solution. The overall scheme presented in [22] is somewhat related to speculative parallelization inside a multiprocessor chip <ref> [7, 8, 9, 16] </ref>, which also relies on extending the cache coherence protocol to detect dependence violations. Our scheme, however, is targeted to large-scale DSM parallelism. In addition, it does not have some of the limitations of the proposed chip-multiprocessor schemes. <p> Such limitations include the need to bound the size of the speculative state to fit in a buffer or L1 cache, and a strict in-order task commit policy that may result in load-imbalance among processors <ref> [7, 8, 9, 16] </ref>. The specific support for reduction validation is, to the best of our knowledge, original while the reduction optimization method is related to [11]. <p> As mentioned in Section 5.1 the compiler can evaluate the size of the private structures needed for the partial results and chose the appropriate technique: with or without PCLR. 7 Related Work Some work related to ours is four schemes that support speculative parallelization inside a multiprocessor chip <ref> [7, 9, 8, 16] </ref>. These schemes are relatively similar to each other. The cache coherence protocol inside a chip is extended with versions or time stamps similar to ours. Parallelism is exploited by running one task (for example one loop iteration) on each of the processors on chip.
Reference: [9] <author> V. Krishnan and J. Torrellas. </author> <title> Hardware and Software Support for Speculative Execution of Sequential Binaries on a Chip-Multiprocessor. </title> <booktitle> In Proceedings of the 1998 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1998. </year>
Reference-contexts: Moreover, the hardware support improves the performance of any reduction parallelization by at least 50% over the software implemented solution. The overall scheme presented in [22] is somewhat related to speculative parallelization inside a multiprocessor chip <ref> [7, 8, 9, 16] </ref>, which also relies on extending the cache coherence protocol to detect dependence violations. Our scheme, however, is targeted to large-scale DSM parallelism. In addition, it does not have some of the limitations of the proposed chip-multiprocessor schemes. <p> Such limitations include the need to bound the size of the speculative state to fit in a buffer or L1 cache, and a strict in-order task commit policy that may result in load-imbalance among processors <ref> [7, 8, 9, 16] </ref>. The specific support for reduction validation is, to the best of our knowledge, original while the reduction optimization method is related to [11]. <p> As mentioned in Section 5.1 the compiler can evaluate the size of the private structures needed for the partial results and chose the appropriate technique: with or without PCLR. 7 Related Work Some work related to ours is four schemes that support speculative parallelization inside a multiprocessor chip <ref> [7, 9, 8, 16] </ref>. These schemes are relatively similar to each other. The cache coherence protocol inside a chip is extended with versions or time stamps similar to ours. Parallelism is exploited by running one task (for example one loop iteration) on each of the processors on chip.
Reference: [10] <author> C. Kruskal. </author> <title> Efficient parallel algorithms for graph problems. </title> <booktitle> In Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 869876, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: The drawbacks of this method are that it is not scalable and that it requires potentially expensive synchronizations. A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [10, 12] </ref>. In this case, the reduction variable is privatized in the transformed doall. A scalar is then produced using the partial results computed in each processor as operands for a reduction operation (with the same operator) across the processors (Figure 4-(c)).
Reference: [11] <author> James R. Larus, Brad Richards, and Guhan Viswanathan. </author> <title> LCM: Memory system support for parallel language implementation. </title> <booktitle> In ASPLOS6, </booktitle> <pages> pages 208218, </pages> <year> 1994. </year>
Reference-contexts: The specific support for reduction validation is, to the best of our knowledge, original while the reduction optimization method is related to <ref> [11] </ref>. <p> Optimization of reductions is accomplsihed by allowing asynchronous, on-the-fly, merging of private data into shared data. This greatly reduces the cost of the final merge when compared to software merge schemes. Our cache line reduction optimization scheme is similar to the one proposed in <ref> [11] </ref>, though without presenting experimental data. 8 Summary Speculative parallel execution of statically non-analyzable codes on Distributed Shared-Memory (DSM) multiprocessors is challenging because of the long latency and distribution present.
Reference: [12] <author> F. Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hyper-cubes. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: The drawbacks of this method are that it is not scalable and that it requires potentially expensive synchronizations. A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm <ref> [10, 12] </ref>. In this case, the reduction variable is privatized in the transformed doall. A scalar is then produced using the partial results computed in each processor as operands for a reduction operation (with the same operator) across the processors (Figure 4-(c)).
Reference: [13] <author> D. Lenoski, J. Laudon, K. Gharachorloo, A. Gupta, and J. Hennessy. </author> <title> The Directory-Based Cache Coherence Protocol for the DASH Multiprocessor. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 148159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The cache sizes have been purposely selected so small in order to scale with the reduced working sets of the chosen applications. Real-life working sets could not be used because they would have required impracti-cally long simulation times. The caches are kept coherent with a DASH-like cache coherence protocol <ref> [13] </ref>. Each node has part of the global memory and the corresponding section of the directory. We have modeled the contention in the whole system with the exception of the global network, which is abstracted away as 11 a constant latency.
Reference: [14] <author> D. O'Hallaron, J. Shewchuk, and T. Gross. </author> <title> Architectural implications of a family of irregular applications. </title> <type> Technical Report CMU-CS-97-189, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> November </month> <year> 1997. </year> <month> 15 </month>
Reference-contexts: Spice is a Perfect Club [2] code, Euler and Dsmc3d are HPF-2 applications [4], and Rmv is a Spark98 kernel <ref> [14] </ref>. The loops in subroutines Load and BJT from Spice have a highly irregular access pattern (they follow a linked list) but, after applying ANPA and reduction parallelization, they become fully parallel. The dflux loop in Euler performs only some simple computation and a compile time verifiable reduction.
Reference: [15] <author> L. Rauchwerger and D. Padua. </author> <title> The LRPD Test: Speculative Run-Time Parallelization of Loops with Privatization and Reduction Parallelization. </title> <booktitle> In Proceedings of the SIGPLAN 1995 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 218232, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: In general, however, the inspector may be computationally expensive and have side-effects. Recently, we have introduced a new framework for speculative parallelization in hardware [22]. The scheme is based on a software-based run-time parallelization scheme that we proposed earlier <ref> [15] </ref>. The idea is to execute the code (loops) speculatively in parallel. As parallel execution proceeds, the extended directory-based cache coherence hardware of the DSM machine detects if there is a dependence violation.
Reference: [16] <author> J. G. Steffan and T. C. Mowry. </author> <title> The Potential for Using Thread-Level Data Speculation to Facilitate Automatic Parallelization. </title> <booktitle> In Proceedings of the 4th International Symposium on High-Performance Computer Architecture, </booktitle> <month> February </month> <year> 1998. </year>
Reference-contexts: Moreover, the hardware support improves the performance of any reduction parallelization by at least 50% over the software implemented solution. The overall scheme presented in [22] is somewhat related to speculative parallelization inside a multiprocessor chip <ref> [7, 8, 9, 16] </ref>, which also relies on extending the cache coherence protocol to detect dependence violations. Our scheme, however, is targeted to large-scale DSM parallelism. In addition, it does not have some of the limitations of the proposed chip-multiprocessor schemes. <p> Such limitations include the need to bound the size of the speculative state to fit in a buffer or L1 cache, and a strict in-order task commit policy that may result in load-imbalance among processors <ref> [7, 8, 9, 16] </ref>. The specific support for reduction validation is, to the best of our knowledge, original while the reduction optimization method is related to [11]. <p> As mentioned in Section 5.1 the compiler can evaluate the size of the private structures needed for the partial results and chose the appropriate technique: with or without PCLR. 7 Related Work Some work related to ours is four schemes that support speculative parallelization inside a multiprocessor chip <ref> [7, 9, 8, 16] </ref>. These schemes are relatively similar to each other. The cache coherence protocol inside a chip is extended with versions or time stamps similar to ours. Parallelism is exploited by running one task (for example one loop iteration) on each of the processors on chip.
Reference: [17] <author> J. Wu, J. Saltz, S. Hiranandani, and H. Berryman. </author> <title> Runtime compilation methods for multicomput-ers. In Dr. </title> <editor> H.D. Schwetman, editor, </editor> <booktitle> Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages 2630. </pages> <publisher> CRC Press, Inc., </publisher> <year> 1991. </year> <title> Vol. </title> <booktitle> II Software. </booktitle>
Reference: [18] <author> Y. Zhang, L. Rauchwerger, and J. Torrellas. </author> <title> Speculative Parallel Execution of Loops with Cross-Iteration Dependences in DSM Multiprocessors. </title> <type> Technical Report 1536, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> July </month> <year> 1997. </year>
Reference-contexts: The choice between the strategies is based on compiler analysis and heuristics. In the interest of brevity we will focus here only the reduction parallelization based on the ANPA. The basics of the privatization algorithm and its associated reduction validation are explained in more detail in <ref> [22, 23, 20, 18] </ref>. We assume the general case of a dynamically-scheduled loop.
Reference: [19] <author> Y. Zhang, L. Rauchwerger, and J. Torrellas. </author> <title> Hardware for Speculative Run-Time Parallelization in Distributed Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of teh 4th International Symposium on High Performance Computer Architecture 1998, (HPCA-4), </booktitle> <pages> pages 162173, </pages> <month> February </month> <year> 1998. </year>
Reference-contexts: In this paper we propose to extend the hardware scheme presented in <ref> [19] </ref> to: * speculatively apply the reduction parallelization transformation and validate it during parallel exe 2 cution for statically un-analyzable reductions (that cannot be legally transformed at compile time) and * to optimize the final cross-processor update of the shared memory such that most of the time associ ated with this
Reference: [20] <author> Y. Zhang, L. Rauchwerger, and J. Torrellas. </author> <title> Hardware for Speculative Run-Time Parallelization in Distributed Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of the 4th International Symposium on High-Performance Computer Architecture, </booktitle> <month> February </month> <year> 1998. </year>
Reference-contexts: briefly describe the speculative parallelization scheme that was introduced in [22], then present the new extensions for loops with reductions, and finally evaluate the new scheme. 2 DSM Hardware for Speculative Parallelization In previous work, we proposed a scheme to speculatively execute non-analyzable loops in parallel in a DSM machine <ref> [20] </ref>. The idea is to extend the directory-based cache-coherence protocol of the machine to detect, in hardware, any violation of a cross-iteration dependence. The loop is executed in parallel speculatively. <p> The scheme can be fleshed out into different hardware algorithms with different cost and performance. We envision the DSM machine to support a few such algorithms mapped to the same hardware, and the compiler to select the algorithm on an array-by-array basis <ref> [20] </ref>. We have developed the advanced privatization algorithm (APA) and the advanced non-privatization algorithms (ANPA). <p> The choice between the strategies is based on compiler analysis and heuristics. In the interest of brevity we will focus here only the reduction parallelization based on the ANPA. The basics of the privatization algorithm and its associated reduction validation are explained in more detail in <ref> [22, 23, 20, 18] </ref>. We assume the general case of a dynamically-scheduled loop. <p> In this section, we present our simulation environment, the workloads, and conclude with the obtained experimental performance measurements. 5.1 Simulation Environment Our evaluation is based on execution-driven simulations of a CC-NUMA shared-memory multiprocessor using Tangolite [6]. The modeled multiprocessor has the hardware support of the basic design <ref> [20] </ref> and the enhancement proposed in this paper. The simulated applications have been pre-processed with the Polaris [3] parallelizing compiler that has been specifically enhanced to transform selected loops for speculative run-time parallelization. The compiler has inserted all necessary instructions to perform the marking and analysis phases.
Reference: [21] <author> Y. Zhang, L. Rauchwerger, and J. Torrellas. </author> <title> Speculative Parallel Execution of Loops with with Cross-Iteration Dependences in DSM Multiprocessors. </title> <type> Technical report, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> July </month> <year> 1998. </year>
Reference-contexts: We will now only present ANPAR, which is the combination of ANPA and the reduction 8 verification algorithm. The combination of APA and the reduction verification algorithm, which we call APAR, is similar. It can be found in <ref> [21] </ref>. To enhance ANPA with reduction verification, we add the reduction bit RED to both cache tag and directory entry of the shared data under test. <p> After a failure recovery, the type of an element (reduction or shared), is decided by the type of the next reference to it. More details of these algorithms can be found in <ref> [21] </ref>. 5 Hardware Support for Reduction Optimization In the most common reduction algorithms, the final cross-processor merge of the per-processor partial reduction results often introduces a very significant overhead. Consequently, we propose a new hardware scheme to reduce its impact.
Reference: [22] <author> Y. Zhang, L. Rauchwerger, and J. Torrellas. </author> <title> Speculative Parallel Execution of Loops with Cross-Iteration Dependences in DSM Multiprocessors. </title> <booktitle> In Proceedings of the 5th International Symposium on High-Performance Computer Architecture(HPCA-5), </booktitle> <month> January </month> <year> 1999. </year>
Reference-contexts: Each wavefront is then executed in parallel by the executor, with synchronization separating the wavefronts. In general, however, the inspector may be computationally expensive and have side-effects. Recently, we have introduced a new framework for speculative parallelization in hardware <ref> [22] </ref>. The scheme is based on a software-based run-time parallelization scheme that we proposed earlier [15]. The idea is to execute the code (loops) speculatively in parallel. As parallel execution proceeds, the extended directory-based cache coherence hardware of the DSM machine detects if there is a dependence violation. <p> Simulation results suggest that the proposed hardware can efficiently parallelize loops with reductions which would otherwise have to be run serially. Moreover, the hardware support improves the performance of any reduction parallelization by at least 50% over the software implemented solution. The overall scheme presented in <ref> [22] </ref> is somewhat related to speculative parallelization inside a multiprocessor chip [7, 8, 9, 16], which also relies on extending the cache coherence protocol to detect dependence violations. Our scheme, however, is targeted to large-scale DSM parallelism. <p> The specific support for reduction validation is, to the best of our knowledge, original while the reduction optimization method is related to [11]. In the following, we briefly describe the speculative parallelization scheme that was introduced in <ref> [22] </ref>, then present the new extensions for loops with reductions, and finally evaluate the new scheme. 2 DSM Hardware for Speculative Parallelization In previous work, we proposed a scheme to speculatively execute non-analyzable loops in parallel in a DSM machine [20]. <p> The choice between the strategies is based on compiler analysis and heuristics. In the interest of brevity we will focus here only the reduction parallelization based on the ANPA. The basics of the privatization algorithm and its associated reduction validation are explained in more detail in <ref> [22, 23, 20, 18] </ref>. We assume the general case of a dynamically-scheduled loop.
Reference: [23] <author> Ye Zhang. </author> <title> DSM Hardware for Speculative Parallelization. </title> <type> PhD thesis, </type> <institution> Department of ECE, University of Illinois, Urbana, Illinois, </institution> <month> January </month> <year> 1999. </year>
Reference-contexts: The choice between the strategies is based on compiler analysis and heuristics. In the interest of brevity we will focus here only the reduction parallelization based on the ANPA. The basics of the privatization algorithm and its associated reduction validation are explained in more detail in <ref> [22, 23, 20, 18] </ref>. We assume the general case of a dynamically-scheduled loop. <p> The Read and Write bits of all the lines in the cache are cleared in hardware at the beginning of every iteration. The bits for a cache line are lost if the line is displaced from the cache. These algorithms, plus further possible optimizations, are described in detail in <ref> [23] </ref>. We note that the races in these transactions are handled as in the original cache coherence protocol transactions. For a given memory block, its corresponding directory acts as a serialization point of transactions. Consequently, no data inconsistency occurs. <p> The space can now be reused. In our experiments, we optimize this operation to reduce the number of messages sent to directory controllers and to handle the possible deallocation of overflowed Undo Buffers in software. The details are presented in <ref> [23] </ref>. 2.3 Undo Log The undo log records the data overwritten during speculative execution to assure a safe, consistent state in case a violation is detected and a previous state has to be reconstructed.
Reference: [24] <author> H. Zima. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press, </publisher> <address> New York, New York, </address> <year> 1991. </year> <month> 16 </month>
Reference-contexts: One method is to transform the do loop into a doall and enclose the access to the reduction variable in an unordered critical section <ref> [5, 24] </ref>. The drawbacks of this method are that it is not scalable and that it requires potentially expensive synchronizations. A scalable method can be obtained by noting that a reduction operation is an associative and commutative recurrence and can thus be parallelized using a recursive doubling algorithm [10, 12]. <p> this problem has been handled at compiletime by syntactically pattern matching the loop statements with a template of a generic reduction, and then performing a data dependence analysis of the variable under scrutiny to guarantee that it is not used anywhere else in the loop except in the reduction statement <ref> [24] </ref>. In the cases where data dependence analysis cannot be performed at compile time, reductions have to be validated at run-time. by extending the capabilities of the previously presented hardware for loops with dependences.
References-found: 24

