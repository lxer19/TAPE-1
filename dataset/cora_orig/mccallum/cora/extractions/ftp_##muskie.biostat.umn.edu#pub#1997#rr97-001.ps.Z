URL: ftp://muskie.biostat.umn.edu/pub/1997/rr97-001.ps.Z
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Markov Chain Monte Carlo in Practice: A Roundtable Discussion  
Author: Moderator: Robert E. Kass Panelists: Bradley P. Carlin, Andrew Gelman, and Radford M. Neal 
Date: August 4, 1997  
Abstract: Markov chain Monte Carlo (MCMC) methods make possible the use of flexible Bayesian models that would otherwise be computationally infeasible. In recent years, a great variety of such applications have been described in the literature. Applied statisticians who are new to these methods may have several questions and concerns, however: How much effort and expertise are needed to design and use a Markov chain sampler? How much confidence can one have in the answers that MCMC produces? How does the use of MCMC affect the rest of the model-building process? At the Joint Statistical Meetings in August, 1996, a panel of experienced MCMC users discussed these and other issues, as well as various "tricks of the trade". This paper is an edited recreation of that discussion. Its purpose is to offer advice and guidance to novice users of MCMC - and to not-so-novice users as well. Topics include building confidence in simulation results, methods for speeding and assessing convergence, estimating standard errors, identification of models for which good MCMC algorithms exist, and the current state of software development. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Besag, J. and Green, P.J. </author> <year> (1993), </year> <title> "Spatial Statistics and Bayesian Computation" (with discussion), </title> <journal> J. Roy. Statist. Soc., Ser. B, </journal> <volume> 55, </volume> <pages> 25-37. </pages>
Reference: <author> Besag, J., Green, P., Higdon, D. and Mengersen, K. </author> <year> (1995), </year> <title> "Bayesian Computation and Stochastic Systems" (with discussion), </title> <journal> Statistical Science, </journal> <volume> 10, </volume> <pages> 3-66. </pages>
Reference-contexts: Seems like a lot of work but maybe much of it could be automated. 15 Carlin: It's important to remember that improper posteriors are sometimes created deliberately to make the sampling process easier <ref> (see e.g. Besag et al., 1995, for several examples) </ref>. The unidentified parameters will of course never converge, but the identifiable ones (say, contrasts in an ANOVA-type model) may be very well behaved.
Reference: <author> Best, N.G., Cowles, M.K. and Vines, K. </author> <year> (1995), </year> <title> "CODA: Convergence Diagnosis and Output Analysis Software for Gibbs Sampling Output, Version 0.30," </title> <type> Technical report, </type> <institution> Medical Research Council Biostatistics Unit, Institute of Public Health, Cambridge University. </institution>
Reference-contexts: While BUGS itself contains only crude convergence diagnosis abilities, the accompanying post-sampling menu-driven S-plus function for this purpose, CODA (a musical analogy, and also an anagram of Convergence Diagnosis and Output Analysis), provides a wealth of diagnostic and summarization tools that are 18 fully equipped to handle parallel chains <ref> (Best, Cowles and Vines, 1995) </ref>. BUGS Version 0.5 features no Metropolis-Hastings updating capability, so all full conditional distributions that are not log-concave must be discretized onto a grid and sampled by brute force, a somewhat inelegant (though often adequate) solution.
Reference: <author> Boscardin, W.J. </author> <year> (1996), </year> <title> "Bayesian Analysis for some Hierarchical Linear Models," </title> <type> unpublished Ph.D. thesis, </type> <institution> Department of Statistics, University of California - Berkeley. </institution>
Reference: <author> Carlin, B.P. and Louis, T.A. </author> <year> (1996), </year> <title> Bayes and Empirical Bayes Methods for Data Analysis, </title> <address> 22 London: </address> <publisher> Chapman and Hall. </publisher>
Reference-contexts: However, this isn't very satisfying to the novice user. Let me go on to my next question and return later to this more difficult issue. 5 Assessing convergence Kass: Together with Kate Cowles, Brad has written a nice review of convergence diagnostics <ref> (Cowles and Carlin, 1996) </ref>. But it left me thinking that knowledge about this topic is not as great as the number of papers that have been written about it might lead one to believe. Indeed, some experienced users simply examine the trace plots (for some collection of parameters) informally. <p> If we put proper priors on 1 and 2 , these parameters become identified, but if these priors have large variances the parameters are "just barely" identified. <ref> (See the exercise on p.203 of Carlin and Louis, 1996.) </ref> The resulting slow convergence for 1 and 2 causes a correspondingly slow convergence for , but the problem is apparent only from the output; no plot or diagnostic for suggests any convergence failure.
Reference: <author> Casella, G., and George, E. </author> <year> (1992), </year> <title> "Explaining the Gibbs Sampler," </title> <journal> The American Statistician, </journal> <volume> 46, </volume> <pages> 167-174. </pages>
Reference: <author> Chib, S. and Greenberg, E. </author> <year> (1995), </year> <title> "Understanding the Metropolis-Hastings Algorithm," </title> <journal> The American Statistician, </journal> <volume> 49, </volume> <pages> 327-335. </pages>
Reference: <editor> Cowles, M.K. and Carlin, B.P. </editor> <year> (1996), </year> <title> "Markov Chain Monte Carlo Convergence Diagnostics: A Comparative Review," </title> <journal> J. Amer. Statist. Assoc., </journal> <volume> 91, </volume> <pages> 883-904. </pages>
Reference-contexts: However, this isn't very satisfying to the novice user. Let me go on to my next question and return later to this more difficult issue. 5 Assessing convergence Kass: Together with Kate Cowles, Brad has written a nice review of convergence diagnostics <ref> (Cowles and Carlin, 1996) </ref>. But it left me thinking that knowledge about this topic is not as great as the number of papers that have been written about it might lead one to believe. Indeed, some experienced users simply examine the trace plots (for some collection of parameters) informally.
Reference: <author> Evans, M. and Swartz, T. </author> <year> (1995), </year> <title> "Methods for Approximating Integrals in Statistics with Special Emphasis on Bayesian Integration Problems," </title> <journal> Statistical Science, 10, 254-272 (discussion and rejoinder: </journal> <volume> 11, </volume> <pages> 54-64). </pages>
Reference: <author> Fienberg, S.E. </author> <year> (1996), </year> <title> Comment on "Computation on Bayesian Graphical Models," by D.J. </title>
Reference: <author> Spiegelhalter, A. Thomas, and N.G. </author> <title> Best, in Bayesian Statistics 5, </title> <editor> eds. J.M. Bernardo, </editor> <publisher> J.O. </publisher>
Reference: <author> Berger, A.P. Dawid and A.F.M. </author> <title> Smith, </title> <publisher> Oxford: Oxford University Press, p.422. </publisher>
Reference: <author> Gelfand, A.E. and Carlin, B.P. </author> <year> (1995), </year> <title> Comment on "Bayesian Computation and Stochastic Systems," </title> <note> by J. </note> <author> Besag, P. Green, D. Higdon, and K. </author> <title> Mengersen, </title> <journal> Statistical Science, </journal> <volume> 10, </volume> <pages> 43-46. </pages>
Reference-contexts: Carlin: Even simple transformations, such as taking the log of a parameter with a heavily right-skewed marginal distribution, can be surprisingly helpful. Also, hierarchical centering <ref> (Gelfand, Sahu and Carlin, 1995, 1996) </ref>, which involves centering random effects around their means in hierarchical models, can be very effective. These transformations don't even involve a Jacobian, and can lead to surprising reductions in parameter correlation, hence accelerating convergence. Neal: Transformations can be very beneficial.
Reference: <author> Gelfand, A.E. and Sahu, S.K. </author> <year> (1996), </year> <title> "Identifiability, Propriety, and Parametrization with regard to Simulation-Based Fitting of Generalized Linear Mixed Models," </title> <type> Technical Report 96-36, </type> <institution> Department of Statistics, University of Connecticut. </institution>
Reference: <author> Gelfand, A.E., Sahu, S.K. and Carlin, B.P. </author> <year> (1995), </year> <title> "Efficient Parametrizations for Normal Linear Mixed Models," </title> <journal> Biometrika, </journal> <volume> 82, </volume> <pages> 479-488. </pages>
Reference-contexts: Carlin: Even simple transformations, such as taking the log of a parameter with a heavily right-skewed marginal distribution, can be surprisingly helpful. Also, hierarchical centering <ref> (Gelfand, Sahu and Carlin, 1995, 1996) </ref>, which involves centering random effects around their means in hierarchical models, can be very effective. These transformations don't even involve a Jacobian, and can lead to surprising reductions in parameter correlation, hence accelerating convergence. Neal: Transformations can be very beneficial.
Reference: <author> Gelfand, A.E., Sahu, S.K. and Carlin, B.P. </author> <year> (1996), </year> <title> "Efficient Parametrizations for Generalized 23 Linear Mixed Models" (with discussion), in Bayesian Statistics 5, </title> <editor> eds. J.M. Bernardo, </editor> <publisher> J.O. </publisher>
Reference: <author> Berger, A.P. Dawid, and A.F.M. </author> <title> Smith. </title> <publisher> Oxford: Oxford University Press, </publisher> <pages> pp. 165-180. </pages>
Reference: <author> Gelfand, A.E. and Smith, A.F.M. </author> <year> (1990), </year> <title> "Sampling-Based Approaches to Calculating Marginal Densities," </title> <journal> J. Amer. Statist. Assoc., </journal> <volume> 85, </volume> <pages> 398-409. </pages>
Reference: <author> Gelman, A. </author> <year> (1996), </year> <title> "Inference and Monitoring Convergence," in Markov Chain Monte Carlo in Practice, </title> <editor> eds. W.R. Gilks, S. Richardson, and D.J. Spiegelhalter, </editor> <publisher> London: Chapman and Hall, </publisher> <pages> pp. 131-143. </pages>
Reference-contexts: Even more commonly, this crude initialization procedure allows me to detect convergence failure. Gelman: Let me echo Brad here. I've encountered slow convergence in distributions that are essentially unimodal but are full of ridges in high dimensions. I've also found obvious programming and modeling bugs using multiple starting points <ref> (see, e.g., p. 134 of Gelman, 1996) </ref>. Neal: The problems I usually work with (e.g., neural network models, mixture models) may be a bit different from those that Andrew and Brad work with. The maximum likelihood estimates for these models are often ridiculous. <p> What can be done to check for or avoid these situations? Gelman: A basic way to check is to play around with informative prior distributions. For example, in a toxicokinetic modeling problem <ref> (Gelman, Bois, and Jiang, 1996) </ref>, we had prior distributions cut off at 3, where was the prior standard deviation.
Reference: <author> Gelman, A., Carlin, J.B., Stern, H.S., and Rubin, D.B. </author> <year> (1995), </year> <title> Bayesian Data Analysis, </title> <publisher> London: Chapman and Hall. </publisher>
Reference: <author> Gelman, A., Meng, X.-L. and Stern, H.S. </author> <year> (1996), </year> <title> "Posterior Predictive Assessment of Model Fitness via Realized Discrepancies" (with discussion), </title> <journal> Statistica Sinica, </journal> <volume> 6, </volume> <pages> 733-807. </pages>
Reference-contexts: Even more commonly, this crude initialization procedure allows me to detect convergence failure. Gelman: Let me echo Brad here. I've encountered slow convergence in distributions that are essentially unimodal but are full of ridges in high dimensions. I've also found obvious programming and modeling bugs using multiple starting points <ref> (see, e.g., p. 134 of Gelman, 1996) </ref>. Neal: The problems I usually work with (e.g., neural network models, mixture models) may be a bit different from those that Andrew and Brad work with. The maximum likelihood estimates for these models are often ridiculous. <p> What can be done to check for or avoid these situations? Gelman: A basic way to check is to play around with informative prior distributions. For example, in a toxicokinetic modeling problem <ref> (Gelman, Bois, and Jiang, 1996) </ref>, we had prior distributions cut off at 3, where was the prior standard deviation.
Reference: <author> Gelman, A., Bois, F.Y., and Jiang, J. </author> <year> (1996), </year> <title> "Physiological Pharmacokinetic Analysis using Population Modeling and Informative Prior Distributions," </title> <journal> Journal of the American Statistical Association 91, </journal> <pages> 1400-1412. </pages>
Reference-contexts: Even more commonly, this crude initialization procedure allows me to detect convergence failure. Gelman: Let me echo Brad here. I've encountered slow convergence in distributions that are essentially unimodal but are full of ridges in high dimensions. I've also found obvious programming and modeling bugs using multiple starting points <ref> (see, e.g., p. 134 of Gelman, 1996) </ref>. Neal: The problems I usually work with (e.g., neural network models, mixture models) may be a bit different from those that Andrew and Brad work with. The maximum likelihood estimates for these models are often ridiculous. <p> What can be done to check for or avoid these situations? Gelman: A basic way to check is to play around with informative prior distributions. For example, in a toxicokinetic modeling problem <ref> (Gelman, Bois, and Jiang, 1996) </ref>, we had prior distributions cut off at 3, where was the prior standard deviation.
Reference: <author> Gelman, A. and Rubin, D.B. </author> <year> (1992), </year> <title> "Inference from Iterative Simulation using Multiple Sequences" (with discussion), </title> <journal> Statistical Science, </journal> <volume> 7, </volume> <pages> 457-511. </pages>
Reference-contexts: Indeed, some experienced users simply examine the trace plots (for some collection of parameters) informally. So, what do each of you do to assess convergence? Gelman: I automatically monitor b R <ref> (Gelman and Rubin, 1992) </ref> for all parameters in the model and anything else that might be of interest.
Reference: <author> Geman, S., and Geman, D. </author> <year> (1984), </year> <title> "Stochastic Relaxation, Gibbs Distributions and the Bayesian Restoration of Images," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6, </volume> <pages> 721-741. </pages>
Reference: <author> Genz, A. and Kass, R.E. </author> <year> (1997), </year> <title> "Subregion Adaptive Integration of Functions Having a Dominant Peak," </title> <journal> J. Comp. Graph. Statist., </journal> <volume> 6, </volume> <pages> 92-111. </pages> <address> 24 Geyer, C.J. </address> <year> (1992), </year> <title> "Practical Markov Chain Monte Carlo" (with discussion), </title> <journal> Statistical Science, </journal> <volume> 7, </volume> <pages> 473-511. </pages>
Reference: <author> Geyer, C.J. and Thompson, E.A. </author> <year> (1995), </year> <title> "Annealing Markov Chain Monte Carlo with Applications to Ancestral Inference," </title> <journal> Journal of the American Statistical Association, </journal> <volume> 90, </volume> <pages> 909-920. </pages>
Reference: <author> Gilks, W.R., Richardson, S. and Spiegelhalter, </author> <title> D.J., </title> <editor> eds. </editor> <year> (1996), </year> <title> Markov Chain Monte Carlo in Practice, </title> <publisher> London: Chapman and Hall. </publisher>
Reference-contexts: Introduction The 1990's have witnessed a burst of activity in applying Bayesian methods. Most of these applications have used Markov chain Monte Carlo (MCMC) methods to simulate posterior distributions. The simulation algorithm is, in its basic form, quite simple and is becoming standard in many Bayesian applications <ref> (see e.g. Gilks, Richardson, and Spiegelhalter, 1996) </ref>. Furthermore, it has been around for a long time (dating at least to Metropolis et al., 1953), and the essential theory is in place (see Tierney, 1994, for a review). Nonetheless, newcomers often run into substantial difficulties.
Reference: <author> Gilks, W.R., Thomas, A. and Spiegelhalter, D.J. </author> <year> (1994), </year> <title> "A Language and Program for Complex Bayesian Modelling," </title> <journal> The Statistician, </journal> <volume> 43, </volume> <pages> 169-177. </pages>
Reference-contexts: In many situations it's either hard to get them working well or, worse yet, it may be hard to know how well they're working. Can we begin by identifying some classes of models where MCMC is easy to use - e.g., via standard software such as BUGS <ref> (Gilks et al., 1994) </ref> and is very likely to give reliable answers? Gelman: Hierarchical linear regression models and GLM's work pretty well.
Reference: <author> Hastings, W.K. </author> <year> (1970), </year> <title> "Monte Carlo Sampling Methods using Markov Chains and Their Applications," </title> <journal> Biometrika, </journal> <volume> 57, </volume> <pages> 97-109. </pages>
Reference: <author> MacEachern, S.N. and Berliner, L.M. </author> <year> (1994), </year> <title> "Subsampling the Gibbs Sampler," </title> <journal> The American Statistician, </journal> <volume> 48, </volume> <pages> 188-190. </pages>
Reference: <author> Meng, X.L. and Van Dyk, D. </author> <year> (1997), </year> <title> "The EM Algorithm An Old Folk-Song Sung to a Fast New Tune" (with discussion), </title> <journal> to appear Journal of the Royal Statistical Society, Ser. B. </journal>
Reference-contexts: This can be rewritten as y ~ glm (Xfi + W ff); ff ~ N (0; 2 I), where t = . Using the new parameterization, Gibbs can go a lot faster <ref> (see the discussions of Meng and Van Dyk, 1997) </ref>, even if both and have improper posterior distributions. Checking results Kass: How can you check results? I presume you think it wise to compare with maximum likelihood when possible, for example. 16 Gelman: Yes. Compare with anything and everything.
Reference: <author> Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H., and Teller, E. </author> <year> (1953), </year> <title> "Equations of State Calculations by Fast Computing Machines," </title> <journal> J. Chemical Physics, </journal> <volume> 21, </volume> <pages> 1087-1091. </pages>
Reference-contexts: The simulation algorithm is, in its basic form, quite simple and is becoming standard in many Bayesian applications (see e.g. Gilks, Richardson, and Spiegelhalter, 1996). Furthermore, it has been around for a long time <ref> (dating at least to Metropolis et al., 1953) </ref>, and the essential theory is in place (see Tierney, 1994, for a review). Nonetheless, newcomers often run into substantial difficulties.
Reference: <author> Neal, R.M. </author> <year> (1993), </year> <title> "Probabilistic Inference Using Markov Chain Monte Carlo Methods," </title> <type> Technical Report CRG-TR-93-1, </type> <institution> Department of Computer Science, University of Toronto. </institution> <note> (Available from the author's home page, at http://www.cs.toronto.edu/~radford/) Neal, R.M. </note> <year> (1995), </year> <title> "Suppressing Random Walks in Markov Chain Monte Carlo Using Ordered 25 Overrelaxation," </title> <type> Technical Report No. 9508, </type> <institution> Dept. of Statistics, University of Toronto. </institution> <note> (Available from the author's home page, at http://www.cs.toronto.edu/~radford/) Neal, R.M. </note> <year> (1996a), </year> <title> Bayesian Learning for Neural Networks, </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: There are several methods that are not well known in the statistics community that can speed up convergence by huge factors 13 in some problems, by suppressing the random walk that Gibbs sampling and simple forms of the Metropolis algorithm take; see my review <ref> (Neal, 1993) </ref>, a recent technical report of mine (Neal, 1995), and for an example involving neural network models, my book (Neal, 1996a). In addition to Andrew's suggestions for detecting implementation mistakes, I would add another: Compare with a completely different implementation, preferably a simpler one.
Reference: <author> Neal, R.M. </author> <year> (1996b), </year> <title> "Sampling from Multimodal Distributions Using Tempered Transitions," </title> <journal> Statistics and Computing, </journal> <volume> 6, </volume> <pages> 353-366. </pages>
Reference: <author> Ripley, B.D. </author> <year> (1987), </year> <title> Stochastic Simulation, </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Ritter, C. and Tanner, M.A. </author> <year> (1992), </year> <title> "Facilitating the Gibbs Sampler: The Gibbs Stopper and the Griddy Gibbs Sampler," </title> <journal> J. Amer. Statist. Assoc., </journal> <volume> 87, </volume> <pages> 861-868. </pages>
Reference-contexts: BUGS Version 0.5 features no Metropolis-Hastings updating capability, so all full conditional distributions that are not log-concave must be discretized onto a grid and sampled by brute force, a somewhat inelegant (though often adequate) solution. However, the next release (Version 0.6) allows current-point Metropolis updating using a grid-based <ref> (Ritter and Tanner, 1992) </ref> proposal density.
Reference: <author> Spiegelhalter, D.J., Thomas, A., Best, N. and Gilks, W.R. </author> <year> (1995a), </year> <title> "BUGS: Bayesian Inference Using Gibbs Sampling, Version 0.50," </title> <type> technical report, </type> <institution> Medical Research Council Biostatistics Unit, Institute of Public Health, Cambridge University. </institution>
Reference-contexts: Mixture models (including Student t's) are tougher because the posterior distributions typically have multiple modes. Carlin: Certainly the simpler the model is, the better. I like the approach taken by the BUGS people to offer not just a manual <ref> (Spiegelhalter et al., 1995a) </ref>, but also a book of examples (Spiegelhalter et al., 1995b) that can serve as prototypes for users.
Reference: <author> Spiegelhalter, D.J., Thomas, A., Best, N. and Gilks, W.R. </author> <year> (1995b), </year> <title> "BUGS Examples, Version 0.50," </title> <type> technical report, </type> <institution> Medical Research Council Biostatistics Unit, Institute of Public Health, Cambridge University. </institution>
Reference-contexts: Mixture models (including Student t's) are tougher because the posterior distributions typically have multiple modes. Carlin: Certainly the simpler the model is, the better. I like the approach taken by the BUGS people to offer not just a manual (Spiegelhalter et al., 1995a), but also a book of examples <ref> (Spiegelhalter et al., 1995b) </ref> that can serve as prototypes for users. This book currently covers the usual range of GLM's, as well as a surprising number of nonstandard models and special cases of interest (spatial models for disease mapping, conditional inference in case-control studies, etc.).
Reference: <author> Swendsen, R.H. and Wang, J.-S. </author> <year> (1987), </year> <title> "Nonuniversal Critical Dynamics in Monte Carlo Simulations," </title> <journal> Phys. Rev. Letters, </journal> <volume> 58, </volume> <pages> 86-88. </pages>
Reference: <author> Tierney, L. </author> <year> (1994), </year> <title> "Markov Chains for Exploring Posterior Distributions" (with discussion), </title> <journal> Ann. Statist., </journal> <volume> 22, </volume> <pages> 1701-1762. 26 </pages>
Reference-contexts: The simulation algorithm is, in its basic form, quite simple and is becoming standard in many Bayesian applications (see e.g. Gilks, Richardson, and Spiegelhalter, 1996). Furthermore, it has been around for a long time (dating at least to Metropolis et al., 1953), and the essential theory is in place <ref> (see Tierney, 1994, for a review) </ref>. Nonetheless, newcomers often run into substantial difficulties. For this reason we felt it would be worthwhile to discuss some of the most pressing issues at the 1996 Joint Statistical Meetings in Chicago. Here we offer a recreation of that discussion.
References-found: 40

