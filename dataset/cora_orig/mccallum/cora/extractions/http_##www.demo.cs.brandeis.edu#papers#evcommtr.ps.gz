URL: http://www.demo.cs.brandeis.edu/papers/evcommtr.ps.gz
Refering-URL: http://www.demo.cs.brandeis.edu/papers/long.html
Root-URL: http://www.cs.brandeis.edu
Email: saunders@cis.ohio-state.edu pollack@cis.ohio-state.edu  
Title: The Evolution of Communication in Adaptive Agents  
Author: Gregory M. Saunders and Jordan B. Pollack 
Address: Columbus, Ohio 43210 USA  
Affiliation: Laboratory for Artificial Intelligence Research Department of Computer and Information Science The Ohio State University  
Pubnum: Technical Report GS-94-EVCOMM  
Abstract-found: 0
Intro-found: 1
Reference: <author> Angeline, P. J., Saunders, G. M., and Pollack, J. B. </author> <year> (1994). </year> <title> An evolutionary algorithm that constructs recurrent neural networks. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(1) </volume> <pages> 54-65. </pages>
Reference-contexts: It provides a mechanism for the simultaneous acquisition of network structure and weight values. GNARL employs a population of networks and uses a fitness functions unsupervised feedback to guide search through network space. The algorithm is described in detail elsewhere <ref> (Angeline, Saunders, and Pollack, 1994) </ref>. Briey, it begins with a population of n random individuals; a sample network N is shown in task; the number of hidden nodes as well as the connections among them are free to vary from 0 to a user-supplied maximum h max . <p> When a node is added, it is initialized without connections; when a node is deleted, all its incident links are removed. All new links are initialized to 0. GNARL has been applied to several different problems <ref> (Angeline, Saunders, and Pollack, 1994) </ref>. <p> Note however that the networks behavior is not precisely captured by the FSA. Kolen (1994a, 1994b) shows that, in general, FSAs approximate networks only poorly. Another network induced by GNARL makes this point empirically. <ref> (See Saunders, Angeline, and Pollack, 1994) </ref>. Start more difficult to follow. The underlying 2-d grid is toroidal; (b) The semantics of the I/O units for the ant network.
Reference: <author> Arbib, M. A., Schweighofer, N., and Thach, W. T. </author> <year> (1994). </year> <title> Modelling the role of the cerebellum in prism adaptation. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <title> From 48 Saunders and Pollack The Evolution of Communication Animals to Animats 3: </title> <booktitle> Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 36-44, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> Arkin, R. C. </author> <year> (1992). </year> <title> Cooperation without communication: Multiagent schema-based robot navigation. </title> <journal> Journal of Robotic Systems, </journal> <volume> 9(3) </volume> <pages> 331-364. </pages>
Reference: <author> Arkin, R. C. and Hobbs, J. D. </author> <year> (1993). </year> <title> Dimensions of communication and social organization in multi-agent robotic systems. </title> <editor> In Meyer, J. A., Roitblat, H. L., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 2: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 486-493, </pages> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Barto, A. G. </author> <year> (1990). </year> <title> Connectionist learning for control. </title> <editor> In Miller-III, W. T., Sutton, R. S., and Werbos, P. J., editors, </editor> <booktitle> Neural Networks for Control, chapter 1, </booktitle> <pages> pages 5-58. </pages> <publisher> MIT Press, </publisher> <address> Cambridge. </address>
Reference-contexts: First, the temperature T (N) is calculated: (1) where f max (provided by the user) is the maximum possible fitness for a given task. This measure of Ns performance is used to anneal the structural and parametric <ref> (Barto, 1990) </ref> similarity between parent and offspring, so that networks with a high temperature are mutated severely, and those with a low temperature are mutated only slightly. This allows a coarse-grained search initially, and a finer-grained search as a network approaches a solution (cf. Kirkpatrick, Gelatt, and Vec-chi, 1983).
Reference: <author> Beer, R. D. </author> <year> (1990). </year> <title> Intelligence as Adaptive Behavior: An Experiment in Computational Neuroethology, </title> <booktitle> volume 6 of Perspectives in Artificial Intelligence. </booktitle> <publisher> Academic Press, Inc. </publisher>
Reference-contexts: 1 Introduction The field of adaptive behavior holds that higher-level cognitive skills arise from the more primitive ability of an agent to adapt to its environment <ref> (Beer, 1990) </ref>. <p> What justifies the unequal treatment of the two? Beer (1992) suggests dynamical systems theory as a unifying metaphor in which to understand the behavior of adaptive agents. Certainly, this language applies to all the results above: in each case, the agents evolved a structural congruence <ref> (Beer, 1990) </ref> between their internal dynam 44 Saunders and Pollack The Evolution of Communication ics and the dynamics of their environment. It is congruence that permitted the interlocking patterns of behavior (Winograd and Flores, 1986) which we termed either pseudo-random search (Section 3) or communication (Section 5).
Reference: <author> Beer, R. D. </author> <year> (1992). </year> <title> A dynamical systems perspective on autonomous agents. </title> <type> Technical Report CES-92-11, </type> <institution> Case Western Reserve University, Cleveland, Ohio. </institution>
Reference: <author> Beer, R. D. and Gallagher, J. C. </author> <year> (1992). </year> <title> Evolving dynamical neural networks for adaptive behavior. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 1(1) </volume> <pages> 91-122. </pages>
Reference: <author> Brooks, R. A. </author> <year> (1986). </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2(1) </volume> <pages> 14-23. </pages>
Reference-contexts: Although many behaviors have been studied in this bottom-up fashion perception (e.g., Arkin, Schweighofer, and Thach, 1994; Har-vey, Husbands, and Cliff, 1994), action selection (e.g., Maes, 1991, 1992; Tyrell, 1993), navigation <ref> (e.g., Brooks, 1986, 1991a) </ref>, food collection (Arkin, 1992; Deneubourg, et al., 1991), planning (e.g., Agre & Chapman, 1986; Donnart and Meyer, 1994), predator avoidance (Grefenstette, 1992; Schmajuk, 1994), locomotion (Beer, 1990; Beer and Gallagher, 1992), social activity (Mataric, 1993, 1994), etc. 1 relatively few people have studied communication as adaptive behavior.
Reference: <author> Brooks, R. A. </author> <year> (1991a). </year> <title> Intelligence without representations. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 139-159. </pages>
Reference: <author> Brooks, R. A. </author> <year> (1991b). </year> <title> Challenges for complete creature architectures. </title> <editor> In Meyer, J. A. and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 434-443. </pages> <publisher> MIT Press. </publisher>
Reference: <author> Chandrasekaran, B. </author> <year> (1990). </year> <title> What kind of information processing is intelligence: A perspective on ai paradigms and a proposal. </title> <editor> In Partridge, D. and Wilks, Y., editors, </editor> <booktitle> The foundations of artificial intelligence: A sourcebook, </booktitle> <pages> pages 14-46. </pages> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Now we adopt that perspective. As languages, the constant and oscillatory systems of communication in Section 5 appear quite impoverished. They possess no syntax by which different signals can combine into higher-level signals, and thus they lack both compositionality <ref> (Chandrasekaran, 1990) </ref> and generative capacity (Fodor and Pylyshyn, 1988; Pollack, 1990). But, interestingly, these systems of communication do possess a semantics. Consider the agents in experiment 3 (Section 5.1). They learned to generate signals of varying magnitude to indicate the presence of food.
Reference: <author> Collins, R. J. and Jefferson, D. R. </author> <year> (1991). </year> <title> Representations for artificial organisms. </title> <editor> In Meyer, J. A. and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 382-390, </pages> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Collins, R. J. and Jefferson, D. R. </author> <year> (1992). </year> <title> Antfarm: Towards simulated evolution. </title> <editor> In Langton, </editor> <address> C. </address>
Reference: <editor> G., Taylor, C., Farmer, J. D., and Rasmussen, S., editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 579-601. </pages> <publisher> Addison-Wesley. </publisher> <editor> de Bourcier, P. and Wheeler, M. </editor> <year> (1994). </year> <title> Signalling and territorial aggression: An investigation by means of synthetic behavioral ecology. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. </editor> <title> 49 Saunders and Pollack The Evolution of Communication W., </title> <editor> editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 463-472, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> Deneubourg, J. L., Goss, S., Franks, N., Sendova-Franks, A., Detrain, C., and Chrtien, L. </author> <year> (1991). </year> <title> The dynamics of collective sorting: Robot-like ants and ant-like robots. </title> <editor> In Meyer, J. A. and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 356-363. </pages> <publisher> MIT Press. </publisher>
Reference: <author> Dennett, D. C. </author> <year> (1987). </year> <title> Intentional systems in cognitive ethology: The Panglossian paradigm defended. </title> <booktitle> In The Intentional Stance, </booktitle> <pages> pages 237-286. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: out that a much lower-order explanation suffices: dead bees secrete oleic acid; the smell of oleic acid turns on the remove it subroutine in the other bees; put a dab of oleic acid on a live, healthy bee, and it will be dragged, kicking and screaming, out of the hive <ref> (Dennett, 1987, p. 256) </ref>. He goes on to justify the bee romantic level of explanation by the fact that it may lead to a better description of a system, where better is realized in terms of predictive power or generality (Dennett, 1987, p. 139). <p> He goes on to justify the bee romantic level of explanation by the fact that it may lead to a better description of a system, where better is realized in terms of predictive power or generality <ref> (Dennett, 1987, p. 139) </ref>. He labels this description in terms of beliefs, desires, and the like as the intentional stance. Similarly, saying that the agents of Section 5 are communicating is a stance we adopt towards the agents, one which leads to certain predictions and generalizations about the agents behaviors.
Reference: <author> Donnart, J. Y. and Meyer, J. A. </author> <year> (1994). </year> <title> An hierarchical classifier system implementing a motivationally autonomous animat. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 144-153, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> Fodor, J. A. and Pylyshyn, Z. W. </author> <year> (1988). </year> <title> Connectionism and cognitive architecture: A critical analysis. </title> <journal> Cognition, </journal> <volume> 28 </volume> <pages> 3-71. </pages>
Reference: <author> Fogel, D. B. </author> <year> (1992). </year> <title> Evolving Artificial Intelligence. </title> <type> Ph.D. thesis, </type> <institution> University of California, </institution> <address> San Diego. </address>
Reference-contexts: Next, we describe the method of communication our agents employ. Experimental results will be discussed in Section 3. 7 Saunders and Pollack The Evolution of Communication 2.1 GNARL GNARL (Saunders, Angeline, and Pollack, 1994; Angeline, Saunders, and Pollack, 1994) is an algorithm based on evolutionary programming <ref> (Fogel, 1992) </ref> that induces recurrent neural networks. It provides a mechanism for the simultaneous acquisition of network structure and weight values. GNARL employs a population of networks and uses a fitness functions unsupervised feedback to guide search through network space.
Reference: <author> Grefenstette, J. J. </author> <year> (1992). </year> <title> The evolution of strategies for multiagent environments. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 1(1) </volume> <pages> 65-90. </pages>
Reference: <author> Harvey, I., Husbands, P., and Cliff, D. </author> <year> (1994). </year> <title> Seeing the light: Artificial evolution, real vision. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 392-401, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> Huberman, B. A. and Hogg, T. </author> <year> (1987). </year> <title> Phase transitions in artificial intelligence systems. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 155-171. </pages> <publisher> North-Holland Publishers. </publisher>
Reference: <author> Jefferson, D., Collins, R., Cooper, C., Dyer, M., Flowers, M., Korf, R., Taylor, C., and Wang, A. </author> <year> (1992). </year> <title> Evolution as a theme in artificial life: The Genesys/Tracker system. </title> <editor> In Langton, C. G., Taylor, C., Farmer, J. D., and Rasmussen, S., editors, </editor> <booktitle> Artificial Life II: Proceedings of the Workshop on Artificial Life, </booktitle> <pages> pages 549-577. </pages> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Under an evolutionary program, the agents coevolve a communication scheme over continuous channels which in order to be successful conveys task-specific information. This section describes our experiments. First we briey describe GNARL, the algorithm we use to evolve our agents. Then we introduce an extension of the Tracker task <ref> (Jefferson et al., 1992) </ref>, which will serve as a substrate for our experiments. Next, we describe the method of communication our agents employ. <p> All new links are initialized to 0. GNARL has been applied to several different problems (Angeline, Saunders, and Pollack, 1994). In particular, we have applied GNARL to the Tracker task <ref> (Jefferson et al., 1992) </ref> in which T N ( ) 1 f max w w Normal 0 T N ( );( )+ w N", 9 Saunders and Pollack The Evolution of Communication a simulated ant must learn to follow a broken trail of food (Figure 2a).
Reference: <author> Kirkpatrick, S., Gelatt, C. D., and Vecchi, M. P. </author> <year> (1983). </year> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220 </volume> <pages> 671-680. </pages>
Reference-contexts: This allows a coarse-grained search initially, and a finer-grained search as a network approaches a solution <ref> (cf. Kirkpatrick, Gelatt, and Vec-chi, 1983) </ref>.
Reference: <author> Kolen, J. F. </author> <year> (1994a). </year> <title> Explorations of Back-Propagation and the Computational Capabilities of Recurrent Neural Networks. </title> <type> Ph.D. thesis, </type> <institution> Ohio State University. </institution>
Reference: <author> Kolen, J. F. </author> <year> (1994b). </year> <title> Fools gold: Extracting finite state machines from recurrent neural networks. </title> <editor> In Cowan, J. D., Tesauro, G., and Alspector, J., editors, </editor> <booktitle> Advances in Neural Information Processing 6. </booktitle> <publisher> Morgan Kaufmann. 50 Saunders and Pollack The Evolution of Communication MacLennan, B. </publisher> <year> (1992). </year> <title> Synthetic ecology: An approach to the study of communication. </title> <editor> In Langton, C. G., Taylor, C., Farmer, J. D., and Rasmussen, S., editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 631-658. </pages> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Our agents perform differently at no time is the input stream partitioned, normalized, or recognized; it simply modulates the behavior of the agent <ref> (as in Kolen, 1994b) </ref>. Yet it does so in a way which admits a meaningful explanation at the information processing level, one which points to a integration of the continuous substrate of sound with the discrete system of words.
Reference: <author> MacLennan, B. and Burghardt, G. M. </author> <year> (1993). </year> <title> Synthetic ethology and the evolution of cooperative communication. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 2(2) </volume> <pages> 161-188. </pages>
Reference: <author> Maes, P. </author> <year> (1991). </year> <title> Adaptive action selection. </title> <booktitle> In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society. </booktitle>
Reference: <author> Maes, P. </author> <year> (1992). </year> <title> Learning behavior networks from experience. </title> <editor> In Varela, F. J. and Bourgine, P., editors, </editor> <booktitle> Toward a Practice of Autonomous Systems: Proceedings of the First European Conference on Artificial Life, </booktitle> <pages> pages 48-57, </pages> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Mataric, M. J. </author> <year> (1993). </year> <title> Designing emergent behaviors: From local interactions to collective intelligence. </title> <editor> In Meyer, J. A., Roitblat, H. L., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 2: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 432-441, </pages> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Husbands, and Cliff, 1994), action selection (e.g., Maes, 1991, 1992; Tyrell, 1993), navigation (e.g., Brooks, 1986, 1991a), food collection (Arkin, 1992; Deneubourg, et al., 1991), planning (e.g., Agre & Chapman, 1986; Donnart and Meyer, 1994), predator avoidance (Grefenstette, 1992; Schmajuk, 1994), locomotion (Beer, 1990; Beer and Gallagher, 1992), social activity <ref> (Mataric, 1993, 1994) </ref>, etc. 1 relatively few people have studied communication as adaptive behavior. In this paper, we explore how communication can be understood as an adaptation by agents to their environment.
Reference: <author> Mataric, M. J. </author> <year> (1994). </year> <note> Learning to behave socially. </note> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 453-462, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> McDermott, D. </author> <year> (1981). </year> <title> Artificial intelligence meets natural stupidity. </title> <editor> In Haugeland, J., editor, </editor> <title> Mind Design: </title> <journal> Philosophy, Psychology, Artificial Intelligence, </journal> <volume> chapter 5, </volume> <pages> pages 143-160. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <note> reproduced from SIGART Newsletter, No. 57, </note> <month> April </month> <year> 1976. </year>
Reference: <author> McFarland, D. </author> <year> (1994). </year> <title> Towards robot cooperation. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 440-444, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> Meyer, J. A. and Guillot, A. </author> <year> (1991). </year> <title> Simulation of adaptive behavior in animats: Review and prospect. </title> <editor> In Meyer, J. A. and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 2-14, </pages> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Meyer, J. A. and Guillot, A. </author> <year> (1994). </year> <title> From SAB90 to SAB94: Four years of Animat research. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 2-11, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> Pollack, J. B. </author> <year> (1990). </year> <title> Recursive distributed representations. </title> <journal> Artificial Intelligence, </journal> <volume> 46 </volume> <pages> 77-105. </pages>
Reference: <author> Pollack, J. B. </author> <year> (1991). </year> <title> The induction of dynamical recognizers. </title> <journal> Machine Learning, </journal> <volume> 7 </volume> <month> 227-252. </month> <title> 51 Saunders and Pollack The Evolution of Communication Robbins, </title> <editor> P. </editor> <year> (1994). </year> <title> The effect of parasitism on the evolution of a communication protocol in an artificial life simulation. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 431-439, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> Saunders, G. M., Kolen, J. F., and Pollack, J. B. </author> <year> (1994). </year> <title> The importance of leaky levels to behavior-based AI. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 275-281, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference-contexts: It provides a mechanism for the simultaneous acquisition of network structure and weight values. GNARL employs a population of networks and uses a fitness functions unsupervised feedback to guide search through network space. The algorithm is described in detail elsewhere <ref> (Angeline, Saunders, and Pollack, 1994) </ref>. Briey, it begins with a population of n random individuals; a sample network N is shown in task; the number of hidden nodes as well as the connections among them are free to vary from 0 to a user-supplied maximum h max . <p> When a node is added, it is initialized without connections; when a node is deleted, all its incident links are removed. All new links are initialized to 0. GNARL has been applied to several different problems <ref> (Angeline, Saunders, and Pollack, 1994) </ref>. <p> Note however that the networks behavior is not precisely captured by the FSA. Kolen (1994a, 1994b) shows that, in general, FSAs approximate networks only poorly. Another network induced by GNARL makes this point empirically. <ref> (See Saunders, Angeline, and Pollack, 1994) </ref>. Start more difficult to follow. The underlying 2-d grid is toroidal; (b) The semantics of the I/O units for the ant network.
Reference: <author> Saunders, G. M., Angeline, P. J., and Pollack, J. B. </author> <year> (1994). </year> <title> Structural and behavioral evolution of recurrent networks. </title> <editor> In Cowan, J. D., Tesauro, G., and Alspector, J., editors, </editor> <booktitle> Advances in Neural Information Processing 7, </booktitle> <pages> pages 88-95. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: It provides a mechanism for the simultaneous acquisition of network structure and weight values. GNARL employs a population of networks and uses a fitness functions unsupervised feedback to guide search through network space. The algorithm is described in detail elsewhere <ref> (Angeline, Saunders, and Pollack, 1994) </ref>. Briey, it begins with a population of n random individuals; a sample network N is shown in task; the number of hidden nodes as well as the connections among them are free to vary from 0 to a user-supplied maximum h max . <p> When a node is added, it is initialized without connections; when a node is deleted, all its incident links are removed. All new links are initialized to 0. GNARL has been applied to several different problems <ref> (Angeline, Saunders, and Pollack, 1994) </ref>. <p> Note however that the networks behavior is not precisely captured by the FSA. Kolen (1994a, 1994b) shows that, in general, FSAs approximate networks only poorly. Another network induced by GNARL makes this point empirically. <ref> (See Saunders, Angeline, and Pollack, 1994) </ref>. Start more difficult to follow. The underlying 2-d grid is toroidal; (b) The semantics of the I/O units for the ant network.
Reference: <author> Schmajuk, N. A. </author> <year> (1994). </year> <title> Behavioral dynamics of escape and avoidance: A neural network approach. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 118-127, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> Shannon, C. E. and Weaver, W. </author> <year> (1949). </year> <title> The Mathematical Theory of Communication. </title> <institution> The University of Illinois Press, Urbana, Illinois. </institution>
Reference: <author> Steels, L. </author> <year> (1994). </year> <title> A case study in the behavior-oriented design of autonomous agents. </title> <editor> In Cliff, D., Husbands, P., Meyer, J. A., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 445-452, </pages> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher>
Reference: <author> Werner, G. M. and Dyer, M. G. </author> <year> (1992). </year> <title> Evolution of communication in artificial organisms. </title> <editor> In Langton, C. G., Taylor, C., Farmer, J. D., and Rasmussen, S., editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 659-687. </pages> <publisher> Addison-Wesley. </publisher>
Reference: <author> Werner, G. M. and Dyer, M. G. </author> <year> (1993). </year> <title> Evolution of herding behavior in artificial animals. </title> <editor> In Meyer, J. A., Roitblat, H. L., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 2: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 393-399, </pages> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Winograd, T. and Flores, F. </author> <year> (1986). </year> <title> Understanding Computers and Cognition. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: Certainly, this language applies to all the results above: in each case, the agents evolved a structural congruence (Beer, 1990) between their internal dynam 44 Saunders and Pollack The Evolution of Communication ics and the dynamics of their environment. It is congruence that permitted the interlocking patterns of behavior <ref> (Winograd and Flores, 1986) </ref> which we termed either pseudo-random search (Section 3) or communication (Section 5). McDermott (1981) warns against creative naming, which in our case means thinking that a set of agents is communicating simply because we adopt the label communication to describe their actions.
Reference: <author> Yanco, H. and Stein, L. A. </author> <year> (1993). </year> <title> An adaptive communication protocol for cooperating mobile robots. </title> <editor> In Meyer, J. A., Roitblat, H. L., and Wilson, S. W., editors, </editor> <booktitle> From Animals to Animats 2: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 478-485, </pages> <address> Cambridge, MA. </address> <publisher> MIT Press. </publisher>
References-found: 47

