URL: http://www.cs.toronto.edu/~greiner/PAPERS/impure-journal.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: greiner@scr.siemens.com  
Title: The Complexity of Revising Logic Programs  
Author: Russell Greiner 
Keyword: Theory Revision, Inductive Logic Programming, Computational Complexity Approximatability, PAC-Learning  
Date: August 25, 1996  
Address: 755 College Road East Princeton, NJ 08540-6632  
Affiliation: Siemens Corporate Research  
Abstract: A rule-based program will return a set of answers to each query. An impure program, which includes the Prolog cut "!" and "not()" operators, can return different answers if its rules are re-ordered. There are also many reasoning systems that return only the first answer found for each query; these first answers, too, depend on the rule order, even in pure rule-based systems. A theory revision algorithm, seeking a revised rule-base whose expected accuracy, over the distribution of queries, is optimal, should therefore consider modifying the order of the rules. This paper first shows that a polynomial number of training "labeled queries" (each a query paired with its correct answer) provides the distribution information necessary to identify the optimal ordering. It then proves, however, that the task of determining which ordering is optimal, once given this distributional information, is intractable even in trivial situations; e.g., even if each query is an atomic literal, we are seeking only a "perfect" theory, and the rule base is propositional. We also prove that this task is not even approximable: Unless P = N P , no polynomial time algorithm can produce an ordering of an n-rule theory whose accuracy is within n fl of optimal, for some fl &gt; 0. We next prove similar hardness, and non-approximatability, results for the related tasks of determining, in these impure contexts, (1) the optimal ordering of the antecedents; (2) the optimal set of new rules to add; and (3) the optimal set of existing rules to delete. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Carlos E. Alchourron, Peter Gardenfors, and David Makinson. </author> <title> On the logic of theory change: Partial meet contraction and revision functions. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-30, </pages> <year> 1985. </year>
Reference-contexts: More significantly, we present situations where the computational task is not just intractable, but is not even approximatable. Like theory revision systems, belief revision systems <ref> [1, 13, 23, 30] </ref> also modify a given theory to incorporate some new observations about the world. <p> This a (T; ) function measures T's accuracy for a single query. In general, our theories must deal with a range of queries. We model this using a stationary probability function P r : Q 7! <ref> [0; 1] </ref>, where P r () is the probability that the query will be posed. 4 Given this distribution, we can compute the "expected accuracy" of a theory T: A ( T ) = E [ a (T; ) ] = 2Q We will consider various sets of possible theories, (T) <p> Given such a training sample, we define the "empirical accuracy" of a theory T, written A S ( T ), as A S ( T ) = jSj i 2S Notice A S ( T ) 2 <ref> [0; 1] </ref>; moreover, the Law of Large Numbers guarantees that this quantity will approach T's true accuracy A ( T ) as the sample size grows large (with probability 1). <p> (a variant of) this "ln (jj) = poly (jTj)" claim is true for essentially every class of theories considered in this paper. 2.4 Extensions All of the theorems in this paper will hold even if we use a stochastic real-world oracle, encoded as O 0 : Q fi A 7! <ref> [0; 1] </ref>, where the correct answer to the query q is a with probability O 0 (q; a). (Notice here that a (T; q) = O 0 (q; T (q)).) Our deterministic oracle is a special case of this, where O 0 (q; a q ) = 1 for a single <p> To state our task formally: For any theory-to-set-of-theories mapping , Definition 1 (DP ( ) Decision Problem) INSTANCE: Initial theory T; Labeled training sample S = fhq i ; O ( q i )ig containing a set of labeled queries; and Accuracy value p 2 <ref> [0; 1] </ref>.
Reference: [2] <author> Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy. </author> <title> Proof verification and hardness of approximation problems. </title> <booktitle> In FOCS, </booktitle> <year> 1992. </year>
Reference-contexts: Following [12, 29], we define Definition 2 A maximization problem Max is PolyApprox iff 8fl 2 &lt; + ; 9B fl 2 Poly ( Max ); 8x 2 Max; MaxPerf Max ( B fl ; x ) &lt; jxj fl : Arora et al. <ref> [2] </ref> prove that, unless P = N P , the "Maximum Independent Set maximization problem" is not PolyApprox | i.e., there is some fl 2 &lt; + such that no polynomial-time algorithm can always find a solution within jxj fl of optimal. <p> Theorem 9 (from <ref> [2] </ref>) Unless P = N P , there is a ffi 2 &lt; + such that no poly time algorithm can produce a solution to arbitrary MaxIndSet problems to within K ffi , where K is the number of nodes in the graph.
Reference: [3] <author> Francesco Bergadano, Daniele Gunetti, and Umberto Trinchero. </author> <title> The difficulties of learning logic programs with cut. </title> <journal> Journal of AI Research, </journal> <volume> 1 </volume> <pages> 91-107, </pages> <year> 1993. </year> <title> The Complexity of Revising Logic Programs 23 </title>
Reference-contexts: Note also that we focus on Horn theories that are syntactically close to an initial theory; by contrast, ILP systems can return any Horn theory. (Although by construction, they tend to return theories which are syntactically close to the empty theory | i.e., small programs.) Bergadano et al. <ref> [3] </ref> also considers the challenges of learning impure logic programs (which can include the Prolog cut "!" and "not ()" operators), noting that it can be more difficult than learning pure programs.
Reference: [4] <author> Mark Boddy and Thomas Dean. </author> <title> Solving time dependent planning problems. </title> <type> Technical report, </type> <institution> Brown University, </institution> <year> 1988. </year>
Reference-contexts: Most such programs assume access to a sufficient number of correct training examples to determine the appropriate logic program. In some situations, however, one may need to produce a program before obtaining such resources. Here, one may want an "anytime" algorithm <ref> [4] </ref> that can, at any time, return an adequate program. (Of course, later programs, based on more samples, will usually be superior.) A nave implementation for such a system would start from scratch each time a program is requested; Given m samples, it would run an ILP system to produce the
Reference: [5] <author> C. Boutilier. </author> <title> Revision sequences and nested conditionals. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 519-525, </pages> <year> 1993. </year>
Reference-contexts: Section 2.3 discusses the sample complexity of the theory revision process. Finally, Section 2.4 presents several generalizations of our framework. 3 While the work on "iterated revision" <ref> [5, 25, 21, 14] </ref> also considers more than a single assertion, it usually deals with a sequence of assertions, where each new assertion must be incorporated, as it arrives. Afterwards, it is no longer distinguished from any other information in the present theory (but see [22]).
Reference: [6] <author> Gerhard Brewka. </author> <title> Preferred subtheories: An extended logical framework for default reasoning. </title> <booktitle> In Proceedings of IJCAI-89, </booktitle> <pages> pages 1043-48, </pages> <address> Detroit, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: can effectively modify the performance of any knowledge-based system written in a shell that uses operators corresponding to Prolog's cut "!" or "not ()", as well as any system that returns only the first answer found; this class of shells includes TestBench 1 and other fault-hierarchy systems, prioritized default theories <ref> [6, 28] </ref>, most production systems [32, 20], as well as Prolog [8]. The goal of a theory revision process is to improve the accuracy of the reasoning system on its performance task of answering queries.
Reference: [7] <author> Herman Chernoff. </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sums of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 </volume> <pages> 493-507, </pages> <year> 1952. </year>
Reference-contexts: We can also use standard statistical tools to bound the probability that A S ( T ) will be far from A ( T ), as a function of sample size; see <ref> [7] </ref>.
Reference: [8] <author> William F. Clocksin and Christopher S. Mellish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: a shell that uses operators corresponding to Prolog's cut "!" or "not ()", as well as any system that returns only the first answer found; this class of shells includes TestBench 1 and other fault-hierarchy systems, prioritized default theories [6, 28], most production systems [32, 20], as well as Prolog <ref> [8] </ref>. The goal of a theory revision process is to improve the accuracy of the reasoning system on its performance task of answering queries. <p> Such a theory is "m-Horn" if each of its clauses contain at most m literals. A theory is considered "impure" if it includes any rule whose antecedents use either the Prolog cut "!" or negation-as-failure "not ()" operator. See Clocksin&Mellish <ref> [8] </ref> for a description of how Prolog answers queries in general, and in particular, how it uses these operators.
Reference: [9] <author> William W. Cohen. </author> <title> PAC-learning recursive logic programs: Efficient algorithms. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 500-539, </pages> <year> 1995. </year>
Reference-contexts: not just intractable, but is in fact, non-approximatable, even in the propositional case, when all rules have unit weight and a single successful rule is sufficient to establish a conclusion. (4) There are a number of results on the complexity of (PAC-)learning logic programs from scratch (i.e., of ILP); cf., <ref> [10, 9, 11, 18] </ref>. We outlined above how our framework is different.
Reference: [10] <author> William W. Cohen. </author> <title> PAC-learning recursive logic programs: Negative results. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 541-573, </pages> <year> 1995. </year>
Reference-contexts: by proving that no theory reviser (be it a computer program, or a human programmer) can efficiently find even a near-optimal revision in such situations. (Indeed, here it may seem better to simply throw out the original program and start afresh; but see the negative results from Inductive Logic Programming <ref> [10, 11] </ref>.) As specific evidence that people who write logic programs often use such debugging techniques, please note that this is an essential step in building rule-based systems, where it has been shown to work effectively; cf., any text on Knowledge Acquisition [40]. <p> not just intractable, but is in fact, non-approximatable, even in the propositional case, when all rules have unit weight and a single successful rule is sufficient to establish a conclusion. (4) There are a number of results on the complexity of (PAC-)learning logic programs from scratch (i.e., of ILP); cf., <ref> [10, 9, 11, 18] </ref>. We outlined above how our framework is different.
Reference: [11] <author> William W. Cohen. </author> <title> PAC-learning non-recursive prolog clauses. </title> <journal> Artificial Intelligence, </journal> <volume> 79(1) </volume> <pages> 1-38, </pages> <year> 1996. </year>
Reference-contexts: by proving that no theory reviser (be it a computer program, or a human programmer) can efficiently find even a near-optimal revision in such situations. (Indeed, here it may seem better to simply throw out the original program and start afresh; but see the negative results from Inductive Logic Programming <ref> [10, 11] </ref>.) As specific evidence that people who write logic programs often use such debugging techniques, please note that this is an essential step in building rule-based systems, where it has been shown to work effectively; cf., any text on Knowledge Acquisition [40]. <p> not just intractable, but is in fact, non-approximatable, even in the propositional case, when all rules have unit weight and a single successful rule is sufficient to establish a conclusion. (4) There are a number of results on the complexity of (PAC-)learning logic programs from scratch (i.e., of ILP); cf., <ref> [10, 9, 11, 18] </ref>. We outlined above how our framework is different.
Reference: [12] <author> P. Crescenzi and A. Panconesi. </author> <title> Completeness in approximation classes. </title> <journal> Information and Computation, </journal> <volume> 93(2) </volume> <pages> 241-62, </pages> <year> 1991. </year>
Reference-contexts: Or if this bound was some constant c (x) = c 2 &lt; + , then we could efficiently obtain a solution within a factor of c of optimal, which may be good enough for some applications. 6 However, not all problems can be approximated. Following <ref> [12, 29] </ref>, we define Definition 2 A maximization problem Max is PolyApprox iff 8fl 2 &lt; + ; 9B fl 2 Poly ( Max ); 8x 2 Max; MaxPerf Max ( B fl ; x ) &lt; jxj fl : Arora et al. [2] prove that, unless P = N P
Reference: [13] <author> Mukesh Dalal. </author> <title> Investigations into a theory of knowledge base revision: Preliminary report. </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <pages> pages 475-479, </pages> <year> 1988. </year>
Reference-contexts: More significantly, we present situations where the computational task is not just intractable, but is not even approximatable. Like theory revision systems, belief revision systems <ref> [1, 13, 23, 30] </ref> also modify a given theory to incorporate some new observations about the world. <p> Such formalisms take as input an initial theory T 0 and a new assertion hq; +i, (resp., new retraction hr; i) and return a new (consistent) theory T 0 that entails q (resp., does not entail r) but otherwise is "close" to T 0 <ref> [13] </ref>. Most belief revision frameworks provide an axiomatic description of the preferred revision, which explicitly prefers a theory that is "semantically close" to the initial theory, which does/does-not entail a single new proposition [13]. <p> T 0 that entails q (resp., does not entail r) but otherwise is "close" to T 0 <ref> [13] </ref>. Most belief revision frameworks provide an axiomatic description of the preferred revision, which explicitly prefers a theory that is "semantically close" to the initial theory, which does/does-not entail a single new proposition [13].
Reference: [14] <author> A. Darwiche and J. Pearl. </author> <title> On the logic of iterated belief revision. </title> <booktitle> In TARK-94, </booktitle> <pages> pages 5-23, </pages> <year> 1994. </year>
Reference-contexts: Section 2.3 discusses the sample complexity of the theory revision process. Finally, Section 2.4 presents several generalizations of our framework. 3 While the work on "iterated revision" <ref> [5, 25, 21, 14] </ref> also considers more than a single assertion, it usually deals with a sequence of assertions, where each new assertion must be incorporated, as it arrives. Afterwards, it is no longer distinguished from any other information in the present theory (but see [22]).
Reference: [15] <author> Thomas G. Dietterich. </author> <title> Machine learning. </title> <booktitle> Annual Review of Computer Science, </booktitle> <volume> 4, </volume> <year> 1990. </year>
Reference-contexts: The Complexity of Revising Logic Programs 4 1.2 Related Research A theory revision process "learns from examples", as it uses "labeled samples" (here, correctly-labeled queries) to produce an accurate theory <ref> [15] </ref>. As the resulting "concept" is a logic program, such processes fits within the sub-topic of "Inductive Logic Programming (ILP)" [38].
Reference: [16] <author> William F. Dowling and Jean H. Gallier. </author> <title> Linear time algorithms for testing the satisfi-ability of propositional horn formula. </title> <journal> Journal of Logic Programming, </journal> <volume> 3 </volume> <pages> 267-84, </pages> <year> 1984. </year>
Reference-contexts: However, in the results that follow, we will assume that there is an efficient way to compute a (T 0 ; q i ). This is always true when T 0 is a propositional Horn theory and q i is atomic <ref> [16] </ref>, which is our main focus. Otherwise, we can assume another oracle that in constant time returns this a (T 0 ; q i ) value.) 3.1 Ordering of Rules This subsection considers the challenge of re-ordering the rules, using the OR transformations.
Reference: [17] <author> Jon Doyle and Ramesh Patil. </author> <title> Two theses of knowledge representation: Language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3), </volume> <year> 1991. </year>
Reference-contexts: Borrowing from <ref> [34, 17] </ref>, we also view a theory T as a function that maps each query to its proposed answer; hence, T: Q 7! A, where Q is a (possibly infinite) set of queries, and A = f Yes; No g is the set of possible answers.
Reference: [18] <author> S. Dzeroski, S. Muggleton, and S. Russell. </author> <title> PAC-learnability of determiniate logic programs. </title> <booktitle> In Proceedings of the Fifth Workshop on Computational Learning Theory, </booktitle> <address> Pitts-burgh, </address> <year> 1992. </year>
Reference-contexts: not just intractable, but is in fact, non-approximatable, even in the propositional case, when all rules have unit weight and a single successful rule is sufficient to establish a conclusion. (4) There are a number of results on the complexity of (PAC-)learning logic programs from scratch (i.e., of ILP); cf., <ref> [10, 9, 11, 18] </ref>. We outlined above how our framework is different.
Reference: [19] <author> T. Eiter and G. Gottlob. </author> <title> On the complexity of propositional knowledge base revison, updates and counterfactuals. </title> <journal> Artificial Intelligence, </journal> <volume> 57 </volume> <pages> 227-270, </pages> <year> 1992. </year> <title> The Complexity of Revising Logic Programs 24 </title>
Reference-contexts: difficult even if both initial and final theories (as well as the queries) are propositional and Horn; by contrast, many belief revision frameworks deal with arbitrary predicate-calculus CNF formulae. (Of course, the standard belief revision tasks | e.g., the "counterfactual problem" | are complete for higher levels in polynomial-time hierarchy <ref> [19] </ref>.) 2 Framework Section 2.1 first describes our task within the context of propositional Prolog programs; Section 2.2 then extends this description to predicate calculus. Section 2.3 discusses the sample complexity of the theory revision process.
Reference: [20] <author> Rick Evertsz. </author> <title> The automated analysis of rule-based systems, based on their procedural semantics. </title> <booktitle> In Proceedings of IJCAI-91, </booktitle> <pages> pages 22-27, </pages> <year> 1991. </year>
Reference-contexts: of any knowledge-based system written in a shell that uses operators corresponding to Prolog's cut "!" or "not ()", as well as any system that returns only the first answer found; this class of shells includes TestBench 1 and other fault-hierarchy systems, prioritized default theories [6, 28], most production systems <ref> [32, 20] </ref>, as well as Prolog [8]. The goal of a theory revision process is to improve the accuracy of the reasoning system on its performance task of answering queries.
Reference: [21] <author> M. Freund and D. Lehmann. </author> <title> Belief revision and rational inference. </title> <type> Technical Report TR-94-16, </type> <institution> Hebrew University, </institution> <year> 1994. </year>
Reference-contexts: Section 2.3 discusses the sample complexity of the theory revision process. Finally, Section 2.4 presents several generalizations of our framework. 3 While the work on "iterated revision" <ref> [5, 25, 21, 14] </ref> also considers more than a single assertion, it usually deals with a sequence of assertions, where each new assertion must be incorporated, as it arrives. Afterwards, it is no longer distinguished from any other information in the present theory (but see [22]).
Reference: [22] <author> N. Friedman and J. Halpern. </author> <title> Belief revision: A critique. </title> <booktitle> In KR-96 (submit), </booktitle> <year> 1996. </year>
Reference-contexts: Afterwards, it is no longer distinguished from any other information in the present theory (but see <ref> [22] </ref>). We, however, consider the assertions as a set, which is seen at once, and whose elements need not all be incorporated.
Reference: [23] <author> Peter Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of the Epistemic States. </title> <publisher> Bradford Book, MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: More significantly, we present situations where the computational task is not just intractable, but is not even approximatable. Like theory revision systems, belief revision systems <ref> [1, 13, 23, 30] </ref> also modify a given theory to incorporate some new observations about the world.
Reference: [24] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: This section also proves similar hardness, and non-approximatability, results for the 1 TestBench is a trademark of Carnegie Group, Inc. 2 Throughout, we will assume that P 6= N P <ref> [24] </ref>, which implies that any NP-hard problem is intractable. This also implies certain approximation claims, presented below. Also, we will define below the terms used in this section, including "syntactically close" and k-Horn. <p> Approximatability: Many decision problems correspond immediately to optimization problems; for example, the IndependentSet decision problem Given a graph G = hN; Ei and a positive integer K, is there a subset M N of at least jM j K nodes that are not connected to one another <ref> [24, p194] </ref>? corresponds to the obvious maximization problem: Given a graph G = hN; Ei, find the largest independent subset of N . <p> For example, there is a polynomial-time algorithm that computes a solution whose cost is (essentially) within a factor of 11=9 for any MaxBinPacking maximization problem; see <ref> [24, Theorem 6.2] </ref>. <p> Theorem 2 Each of DP P erf;Imp;P rop ( OR ) and DP P erf;P ur;P C1 ( OR ) is NP-complete. Proof: We reduce the canonical NP-complete task 3sat to our problems: Definition 3 (3sat Decision Problem, from <ref> [24, p259] </ref>:) Given a set U = fu 1 ; : : : ; u n g of variables and formula ' = fc 1 ; : : : ; c m g (a conjunction of clauses over U ) such that each clause c 2 ' is a disjunction of <p> each u i in T (P rop) ' with u i (1), and each u i with u i (0): Here, to simplify the description, we use the Monotone3sat problem, which is the NP-complete specialization of 3sat in which each clause includes either only positive literals, or only negative literals <ref> [24, p259] </ref>.
Reference: [25] <author> G. Gogic, C. H. Papadimitriou, and M. Sideri. </author> <title> Incremental recompilation of knowledge. </title> <booktitle> In Proceedings of AAAI-94, </booktitle> <pages> pages 922-927, </pages> <year> 1994. </year>
Reference-contexts: Section 2.3 discusses the sample complexity of the theory revision process. Finally, Section 2.4 presents several generalizations of our framework. 3 While the work on "iterated revision" <ref> [5, 25, 21, 14] </ref> also considers more than a single assertion, it usually deals with a sequence of assertions, where each new assertion must be incorporated, as it arrives. Afterwards, it is no longer distinguished from any other information in the present theory (but see [22]).
Reference: [26] <author> Russell Greiner. </author> <title> Finding the optimal derivation strategy in a redundant knowledge base. </title> <journal> Artificial Intelligence, </journal> <volume> 50(1) </volume> <pages> 95-116, </pages> <year> 1991. </year>
Reference-contexts: This paper has some superficial similarities with <ref> [26] </ref>, as both articles consider the complexity of (in essence) finding the best ordering of a set of rules. However, while [26] deals with the efficiency of finding any answer to a given query, this paper deals with the accuracy of the particular answer returned. <p> This paper has some superficial similarities with <ref> [26] </ref>, as both articles consider the complexity of (in essence) finding the best ordering of a set of rules. However, while [26] deals with the efficiency of finding any answer to a given query, this paper deals with the accuracy of the particular answer returned.
Reference: [27] <author> Russell Greiner. </author> <title> The complexity of theory revision. </title> <booktitle> In Proceedings of IJCAI-95, </booktitle> <year> 1995. </year>
Reference-contexts: The system is an exception, as it does reorder the rules. The empirical results discussed in [33] show that such transformations can be used effectively. There are a variety of related complexity results. (1) The companion paper <ref> [27] </ref> analyses the classes of transformations used by those other systems: adding or deleting either a rule or an antecedent within a rule, in the standard pure context. <p> We first state the results known about the standard pure context: Theorem 7 (from <ref> [27] </ref>) In the pure context, for each 2 f AR ; DR g * DP P erf;P ur;P rop ( ) can be solved in polynomial time * Each of DP Opt;P ur;P rop ( ) and DP Opt;P ur;P C ( ) is NP-hard, but is trivial to approximate: 9B
Reference: [28] <author> Benjamin Grosof. </author> <title> Generalizing prioritization. </title> <booktitle> In Proceedings of KR-91, </booktitle> <pages> pages 289-300, </pages> <address> Boston, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: can effectively modify the performance of any knowledge-based system written in a shell that uses operators corresponding to Prolog's cut "!" or "not ()", as well as any system that returns only the first answer found; this class of shells includes TestBench 1 and other fault-hierarchy systems, prioritized default theories <ref> [6, 28] </ref>, most production systems [32, 20], as well as Prolog [8]. The goal of a theory revision process is to improve the accuracy of the reasoning system on its performance task of answering queries.
Reference: [29] <author> Viggo Kann. </author> <title> On the Approximability of NP-Complete Optimization Problems. </title> <type> PhD thesis, </type> <institution> Royal Institute of Technology, Stockholm, </institution> <year> 1992. </year>
Reference-contexts: Or if this bound was some constant c (x) = c 2 &lt; + , then we could efficiently obtain a solution within a factor of c of optimal, which may be good enough for some applications. 6 However, not all problems can be approximated. Following <ref> [12, 29] </ref>, we define Definition 2 A maximization problem Max is PolyApprox iff 8fl 2 &lt; + ; 9B fl 2 Poly ( Max ); 8x 2 Max; MaxPerf Max ( B fl ; x ) &lt; jxj fl : Arora et al. [2] prove that, unless P = N P
Reference: [30] <author> Hirofumi Katsuno and Alberto Mendelzon. </author> <title> On the difference between updating a knowledge base and revising it. </title> <booktitle> In Proceedings of KR-91, </booktitle> <pages> pages 387-94, </pages> <address> Boston, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: More significantly, we present situations where the computational task is not just intractable, but is not even approximatable. Like theory revision systems, belief revision systems <ref> [1, 13, 23, 30] </ref> also modify a given theory to incorporate some new observations about the world.
Reference: [31] <author> M. J. Kearns, R. E. Schapire, and L. M. Sellie. </author> <title> Toward efficient agnostic leaning. </title> <booktitle> In Proceedings COLT-92, </booktitle> <pages> pages 341-352. </pages> <publisher> ACM Press, </publisher> <year> 1992. </year>
Reference-contexts: This also demonstrates the intractability of finding the smallest number of "individual re-orderings" required to produce a perfect ordering. We next deal with the "agnostic" version of this task <ref> [31] </ref>: asking for the most accurate reordering, in cases where no reordering produces a perfect theory. <p> Here, we seek the "optimal arrangement" (i.e., with the highest accuracy); this corresponds exactly to the "agnostic learning" model. Kearns, Schapire and Sellie <ref> [31] </ref> have also proved that the agnostic learning task can be intractable. Our results differ by dealing with a different class of "samples" (arbitrary queries, not bit vectors), and by having a different class of hypotheses (predicate calculus Horn theories, rather than propositional conjunctions).
Reference: [32] <author> John E. Laird, Paul S. Rosenbloom, and Allan Newell. </author> <title> Universal Subgoaling and Chunking: The Automatic Generation and Learning of Goal Hierarchies. </title> <publisher> Kluwer Academic Press, </publisher> <address> Hingham, MA, </address> <year> 1986. </year>
Reference-contexts: of any knowledge-based system written in a shell that uses operators corresponding to Prolog's cut "!" or "not ()", as well as any system that returns only the first answer found; this class of shells includes TestBench 1 and other fault-hierarchy systems, prioritized default theories [6, 28], most production systems <ref> [32, 20] </ref>, as well as Prolog [8]. The goal of a theory revision process is to improve the accuracy of the reasoning system on its performance task of answering queries.
Reference: [33] <author> Pat Langley, George Drastal, R. Bharat Rao, and Russell Greiner. </author> <title> Theory revision in fault hierarchies. </title> <booktitle> In Proceedings of The Fifth International Workshop on Principles of Diagnosis (DX-94), </booktitle> <address> New Paltz, NY, </address> <year> 1994. </year>
Reference-contexts: There are many implemented theory revision systems, including Audrey [43], Fonte [37], Either [39] and <ref> [33] </ref>. Most of these system deal (in essence) with the "pure" Horn clause framework, seeking all answers to each query, and so they therefore do not consider the particular class of transformations described in this paper. The system is an exception, as it does reorder the rules. <p> The system is an exception, as it does reorder the rules. The empirical results discussed in <ref> [33] </ref> show that such transformations can be used effectively. There are a variety of related complexity results. (1) The companion paper [27] analyses the classes of transformations used by those other systems: adding or deleting either a rule or an antecedent within a rule, in the standard pure context.
Reference: [34] <author> Hector J. Levesque. </author> <title> Foundations of a functional approach to knowledge representation. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 155-212, </pages> <year> 1984. </year>
Reference-contexts: Borrowing from <ref> [34, 17] </ref>, we also view a theory T as a function that maps each query to its proposed answer; hence, T: Q 7! A, where Q is a (possibly infinite) set of queries, and A = f Yes; No g is the set of possible answers.
Reference: [35] <author> Charles X.F. Ling and Marco Valtorta. </author> <title> Some results on the computational complexity of refining certainty factors. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 5 </volume> <pages> 121-148, </pages> <year> 1991. </year> <title> The Complexity of Revising Logic Programs 25 </title>
Reference-contexts: Among other results, it proves that the task of finding the optimal set of new rules to add (resp., existing rules to delete) is intractable, but can be approximated to within a factor of 2, in the pure context. (2) Valtorta and Ling <ref> [35, 36] </ref> also considers the computational complexity of modifying a theory.
Reference: [36] <author> Charles X.F. Ling and Marco Valtorta. </author> <title> Refinement of uncertain rule bases via reduction. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 13 </volume> <pages> 95-126, </pages> <year> 1995. </year>
Reference-contexts: Among other results, it proves that the task of finding the optimal set of new rules to add (resp., existing rules to delete) is intractable, but can be approximated to within a factor of 2, in the pure context. (2) Valtorta and Ling <ref> [35, 36] </ref> also considers the computational complexity of modifying a theory.
Reference: [37] <author> S. Muggleton and W. Buntine. </author> <title> Machine invention of first order predicates by inverting resolution. </title> <booktitle> In Proceedings of IML-88, </booktitle> <pages> pages 339-51. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Most ILP systems, however, consider only adding new information to an initial (often empty) starting theory; by contrast, theory revision systems consider other ways of modifying an existing, not-necessarily-empty initial theory, including (usually) deleting rules or antecedents. There are many implemented theory revision systems, including Audrey [43], Fonte <ref> [37] </ref>, Either [39] and [33]. Most of these system deal (in essence) with the "pure" Horn clause framework, seeking all answers to each query, and so they therefore do not consider the particular class of transformations described in this paper. <p> contexts. (These proofs are isomorphic to the ones appearing in the appendix.) 4 Contributions Most theory revision systems deal with a particular set of theory-modification techniques (adding or deleting either a rule or an antecedent) that implicitly assume the underlying theory is pure and the user is seeking all answers <ref> [43, 37, 39] </ref>. Many reasoning contexts, however, violate these assumptions: theories are often impure, and many users seek only a subset of the answers.
Reference: [38] <author> S.H. Muggleton. </author> <title> Inductive Logic Programming. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: As the resulting "concept" is a logic program, such processes fits within the sub-topic of "Inductive Logic Programming (ILP)" <ref> [38] </ref>. Most ILP systems, however, consider only adding new information to an initial (often empty) starting theory; by contrast, theory revision systems consider other ways of modifying an existing, not-necessarily-empty initial theory, including (usually) deleting rules or antecedents.
Reference: [39] <author> Dirk Ourston and Raymond J. Mooney. </author> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66(2) </volume> <pages> 273-310, </pages> <year> 1994. </year>
Reference-contexts: There are many implemented theory revision systems, including Audrey [43], Fonte [37], Either <ref> [39] </ref> and [33]. Most of these system deal (in essence) with the "pure" Horn clause framework, seeking all answers to each query, and so they therefore do not consider the particular class of transformations described in this paper. The system is an exception, as it does reorder the rules. <p> contexts. (These proofs are isomorphic to the ones appearing in the appendix.) 4 Contributions Most theory revision systems deal with a particular set of theory-modification techniques (adding or deleting either a rule or an antecedent) that implicitly assume the underlying theory is pure and the user is seeking all answers <ref> [43, 37, 39] </ref>. Many reasoning contexts, however, violate these assumptions: theories are often impure, and many users seek only a subset of the answers.
Reference: [40] <author> A. Carlisle Scott, Jan E. Clayton, and Elizabeth L. Gibson. </author> <title> A Practical guide to knowledge acquisition. </title> <publisher> Addison-Wesley Pub Co., </publisher> <address> Reading, MA, </address> <year> 1991. </year>
Reference-contexts: see the negative results from Inductive Logic Programming [10, 11].) As specific evidence that people who write logic programs often use such debugging techniques, please note that this is an essential step in building rule-based systems, where it has been shown to work effectively; cf., any text on Knowledge Acquisition <ref> [40] </ref>. The Complexity of Revising Logic Programs 4 1.2 Related Research A theory revision process "learns from examples", as it uses "labeled samples" (here, correctly-labeled queries) to produce an accurate theory [15].
Reference: [41] <author> V.N. Vapnik. </author> <title> Estimation of Dependencies Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: We can also use standard statistical tools to bound the probability that A S ( T ) will be far from A ( T ), as a function of sample size; see [7]. We can use such a tool to derive: Theorem 1 (from <ref> [41, Theorem 6.2] </ref>) Given a class of theories = (T) and constants *; ffi &gt; 0, let T fl 2 be the theory with the largest empirical accuracy after M upper (; *; ffi) = & * 2 ln jj !' samples (each a labeled query), drawn from the stationary distribution,
Reference: [42] <author> David C. Wilkins and Yong Ma. </author> <title> The refinement of probabilistic rule sets: sociopathic interactions. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 1-32, </pages> <year> 1994. </year>
Reference-contexts: Those papers, however, deal with a different type of modifications: viz., adjusting the numeric "weights" within a given network (e.g., altering the certainty factors associated with the rules), but not changing the structure by arranging rules or antecedents. (3) Wilkins and Ma <ref> [42] </ref> show the intractability of determining the best set of rules to delete in the context of such weighted rules, where a conclusion is believed if a specified function of the weights of the supporting rules exceeds a threshold.
Reference: [43] <author> James Wogulis and Michael J. Pazzani. </author> <title> A methodology for evaluating theory revision systems: Results with Audrey II. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 1128-1134, </pages> <year> 1993. </year>
Reference-contexts: Most ILP systems, however, consider only adding new information to an initial (often empty) starting theory; by contrast, theory revision systems consider other ways of modifying an existing, not-necessarily-empty initial theory, including (usually) deleting rules or antecedents. There are many implemented theory revision systems, including Audrey <ref> [43] </ref>, Fonte [37], Either [39] and [33]. Most of these system deal (in essence) with the "pure" Horn clause framework, seeking all answers to each query, and so they therefore do not consider the particular class of transformations described in this paper. <p> contexts. (These proofs are isomorphic to the ones appearing in the appendix.) 4 Contributions Most theory revision systems deal with a particular set of theory-modification techniques (adding or deleting either a rule or an antecedent) that implicitly assume the underlying theory is pure and the user is seeking all answers <ref> [43, 37, 39] </ref>. Many reasoning contexts, however, violate these assumptions: theories are often impure, and many users seek only a subset of the answers.
References-found: 43

