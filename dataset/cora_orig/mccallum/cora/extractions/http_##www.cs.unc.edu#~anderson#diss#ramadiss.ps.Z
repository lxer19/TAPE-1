URL: http://www.cs.unc.edu/~anderson/diss/ramadiss.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/
Root-URL: http://www.cs.unc.edu
Title: A Lock-Free Approach to Object Sharing in Real-Time Systems  
Author: by Srikanth Ramamurthy Prof. James Anderson, Adviser Prof. Prasun Dewan, Reader Prof. Kevin Jeffay, Reader 
Degree: A dissertation submitted to the faculty of the  in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the  Approved by:  
Date: 1997  
Address: Chapel Hill  Chapel Hill  
Affiliation: University of North Carolina at  Department of Computer Science.  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Y. Afek, H. Attiya, D.Dolev, E. Gafni, M. Merritt, and N. Shavit. </author> <title> Atomic snapshots of shared memory. </title> <booktitle> In Proceedings of the Ninth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 1-14. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization. <p> Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers [23, 24, 49, 50, 54, 59, 66, 67, 68, 75]; atomic snapshots that allow multiple variables to be read atomically; <ref> [1, 3, 17] </ref>, algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported by any real machine. 50 ations satisfy certain algebraic requirements [5, 16]. <p> The shared variable V is used by tasks to communicate return values of Read operations invoked by lower-priority tasks. The following informal definition states that the current "value" CV of the shared object is determined by the task identifier that is stored in a majority of the locations Buf <ref> [1] </ref> through Buf [2N 1]. (A formal definition of CV is given later.) CV (Val [p] :: p is a majority in Buf ) 4 For simplicity, the shared object is not explicitly passed as a parameter to the Read and CAS procedures shown in this figure. 102 shared var Val <p> If the Read procedure is invoked with the address of word w as input, then it 144 val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val count valid tid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Save [3; 1]: 22 Status [3]: 1 Status [4]: 2 (c) val count <p> 22 z: 8 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val count valid tid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Save [3; 1]: 22 Status [3]: 1 Status [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: <p> 0 true 4 Val (z) = 17 Save <ref> [3; 1] </ref>: 22 Status [3]: 1 Status [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) <p> Status [3]: 1 Status [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save <ref> [4; 1] </ref>: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 0 Status [4]: <p> [3]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 Status [4]: 1 (d) values 12/5, 22/10, and 8/17, respectively. <p> These routines are called within the programmer's transaction code in order to read or write a word of the MEM array. Thus, instead of writing "MEM <ref> [1] </ref> := MEM [10]", the programmer would write "Tr Write (1; Tr Read (10))". Figure 5.1 shows a simple example transaction, which enqueues an item onto a shared queue.
Reference: [2] <author> Y. Afek, D. Dauber, and D. Touitou. </author> <title> Wait-free made fast (extended abstract). </title> <booktitle> In Proceedings of the 27th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 538-547. </pages> <publisher> ACM, </publisher> <year> 1995. </year>
Reference-contexts: To rectify this situation, many researchers have developed universal constructions that allow easy implementation of lock-free objects. A universal construction is used to automatically generate lock-free implementations of arbitrary objects from their sequential implementations. Universal constructions 9 were proposed first by Herlihy [36], and improved later by others <ref> [2, 7, 20, 37, 42] </ref>. To implement a lock-free object using a universal construction, a programmer first writes code for a sequential implementation of that object. This code is then embedded within a retry loop that is automatically generated by the universal construction. <p> T 2 successfully changes CV by writing its new value (65) into Val <ref> [2] </ref> and by writing its task identifier (2) into all components of Buf . Before returning, T 2 writes true into all components of Pm to inform lower-priority tasks that their operations have been interfered with. Inset (d) shows the relevant variables at the termination of m 0 . <p> [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save <ref> [4; 2] </ref>: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 0 Status [4]: 1 (d) values 12/5,
Reference: [3] <author> J. Anderson. </author> <title> Composite registers. </title> <booktitle> In Proceedings of the Ninth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 15-30. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization. <p> Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers [23, 24, 49, 50, 54, 59, 66, 67, 68, 75]; atomic snapshots that allow multiple variables to be read atomically; <ref> [1, 3, 17] </ref>, algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported by any real machine. 50 ations satisfy certain algebraic requirements [5, 16]. <p> Task T 1 then assigns zero to all components of Buf (lines 18 and 19). However, before T 1 can establish a new majority identifier in Buf (lines 21 and 22), it is preempted by T 2 . (T 1 is enabled to write into Buf <ref> [3] </ref> at the preemption point.) Insets (b) and (c) show the relevant variables at the beginning and at the end of operation m 2 , respectively. <p> Inset (d) shows the relevant variables at the termination of m 0 . Observe that CV does not change when the enabled late writes of T 0 and T 1 modify Buf [4] and Buf <ref> [3] </ref>, respectively. <p> The current value of each word is now the desired new value, and all valid fields are true (so the value of Status [4] is no longer relevant). Before returning, task T 4 updates Status <ref> [3] </ref> (line 19 of Figure 4.13) to indicate that task T 3 (which must be of lower priority) has been interfered with. <p> Inset (d) shows relevant variables at the termination of m, assuming an interference on word z by task T 9 (which must be of higher-priority) with new value 56. Status [4] is now 1, indicating the failure of task T 4 's operation. Status <ref> [3] </ref> is left unchanged in this case. Observe that task T 4 has successfully restored the original values of words x and y. Insets (e) and (f) show the operation interleavings corresponding to insets (c) and (d), respectively. <p> If the Read procedure is invoked with the address of word w as input, then it 144 val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val count valid tid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Save [3; 1]: 22 Status [3]: 1 Status [4]: 2 (c) val count <p> procedure is invoked with the address of word w as input, then it 144 val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Save [3; 1]: 22 Status <ref> [3] </ref>: 0 (a) val count valid tid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Save [3; 1]: 22 Status [3]: 1 Status [4]: 2 (c) val count valid tid x: 5 <p> 22 z: 8 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val count valid tid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Save [3; 1]: 22 Status [3]: 1 Status [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: <p> true 4 Val (z) = 8 Save [3; 1]: 22 Status <ref> [3] </ref>: 0 (a) val count valid tid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Save [3; 1]: 22 Status [3]: 1 Status [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save [4; 1]: <p> 0 true 4 Val (z) = 17 Save <ref> [3; 1] </ref>: 22 Status [3]: 1 Status [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) <p> (z) = 17 Save [3; 1]: 22 Status <ref> [3] </ref>: 1 Status [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; <p> [3]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 Status [4]: 1 (d) values 12/5, 22/10, and 8/17, respectively. <p> 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status <ref> [3] </ref>: 0 Status [4]: 1 (d) values 12/5, 22/10, and 8/17, respectively.
Reference: [4] <author> J. Anderson and B. Groselj. </author> <title> Beyond atomic registers: Bounded wait-free implementations of nontrivial objects. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 19(3) </volume> <pages> 197-237, </pages> <month> Decem-ber </month> <year> 1992. </year>
Reference-contexts: p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization. <p> The value of CV equals 53 when m 0 begins execution. Inset (a) shows the contents of the various variables just before m 1 begins. At this time, CV equals 12 and T 0 is enabled to write zero into Buf <ref> [4] </ref>. (Note that m 0 has established a majority in Buf by this point.) During m 1 , task T 1 detects zero as the majority task identifier in Buf (lines 11 and 12 in Figure 4.6). <p> Inset (d) shows the relevant variables at the termination of m 0 . Observe that CV does not change when the enabled late writes of T 0 and T 1 modify Buf <ref> [4] </ref> and Buf [3], respectively. <p> Note that the current value of each word matches the desired old value. Inset (b) shows relevant variables after the first phase of m has completed, assuming no interferences by higher-priority tasks. The current value of each word is unchanged. Note that changing the value of Status <ref> [4] </ref> from 0 to 2 in inset (b) would have the effect of atomically changing the current value of each of x, y, and z to the desired new value. Inset (c) shows relevant variables at the termination of m, assuming no interferences by higher-priority tasks. <p> Inset (c) shows relevant variables at the termination of m, assuming no interferences by higher-priority tasks. The current value of each word is now the desired new value, and all valid fields are true (so the value of Status <ref> [4] </ref> is no longer relevant). Before returning, task T 4 updates Status [3] (line 19 of Figure 4.13) to indicate that task T 3 (which must be of lower priority) has been interfered with. <p> Inset (d) shows relevant variables at the termination of m, assuming an interference on word z by task T 9 (which must be of higher-priority) with new value 56. Status <ref> [4] </ref> is now 1, indicating the failure of task T 4 's operation. Status [3] is left unchanged in this case. Observe that task T 4 has successfully restored the original values of words x and y. <p> (z) = 8 Save [3; 1]: 22 Status [3]: 0 (a) val count valid tid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Save [3; 1]: 22 Status [3]: 1 Status <ref> [4] </ref>: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; <p> Save [3; 1]: 22 Status [3]: 1 Status [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save <ref> [4; 0] </ref>: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status <p> Status [3]: 1 Status [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save <ref> [4; 1] </ref>: 22 Save [4; 2]: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 0 Status [4]: <p> [4]: 2 (c) val count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save <ref> [4; 2] </ref>: 8 Status [4]: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 0 Status [4]: 1 (d) values 12/5, <p> count valid tid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Save [3; 1]: 22 Status [3]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 Status <ref> [4] </ref>: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 0 Status [4]: 1 (d) values 12/5, 22/10, and 8/17, respectively. <p> [4; 1]: 22 Save [4; 2]: 8 Status <ref> [4] </ref>: 0 (b) val count valid tid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Save [3; 1]: 22 Status [3]: 0 Status [4]: 1 (d) values 12/5, 22/10, and 8/17, respectively.
Reference: [5] <author> J. Anderson and M. Moir. </author> <title> Towards a necessary and sufficient condition for wait-free synchronization. </title> <booktitle> In Proceedings of the Seventh International Workshop on Distributed Algorithms, </booktitle> <pages> pages 39-53, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported by any real machine. 50 ations satisfy certain algebraic requirements <ref> [5, 16] </ref>. <p> For example, a construction is given in <ref> [5] </ref> that implements any object such that, for each pair of operations on the object, either the two operations commute with each other, or one overwrites the other (i.e., the effects of executing both operations is the same as executing just one of them). <p> Also, task T 2 's unfulfilled demand decreases by one unit at every instant in the interval [11; 14] because it executes on the processor. The demand placed by T 2 on the processor in the interval <ref> [5; 37] </ref> is 16 units; 7 units due to T 2 's unfulfilled demand at time 5, 2 units due to an interference in J 2;1 at time 14, and 7 units due the release of J 2;2 at time 36.
Reference: [6] <author> J. H. Anderson, R. Jain, and S. Ramamurthy. </author> <title> Wait-free object-sharing schemes for real-time uniprocessors and multiprocessors. </title> <booktitle> In Proceedings of the Eighteenth IEEE Real-Time Systems Symposium (to appear), </booktitle> <year> 1997. </year>
Reference-contexts: Lock-based schemes also perform very poorly in multiprocessor systems because the blocking factors entailed by a task can be significant [69]. As demonstrated in <ref> [6] </ref>, wait-free object implementations that use the cyclic helping technique, in conjunction with incremental helping, can significantly reduce helping overhead on a multiprocessor real-time system. Under the cyclic-helping scheme, processors in a system are thought of as if they were part of a logical ring.
Reference: [7] <author> J. H. Anderson and M. Moir. </author> <title> Universal constructions for large objects. </title> <booktitle> In Proceedings of the Ninth International Workshop on Distributed Algorithms, </booktitle> <pages> pages 168-182. </pages> <publisher> Springer Verlag, </publisher> <month> September </month> <year> 1995. </year>
Reference-contexts: To rectify this situation, many researchers have developed universal constructions that allow easy implementation of lock-free objects. A universal construction is used to automatically generate lock-free implementations of arbitrary objects from their sequential implementations. Universal constructions 9 were proposed first by Herlihy [36], and improved later by others <ref> [2, 7, 20, 37, 42] </ref>. To implement a lock-free object using a universal construction, a programmer first writes code for a sequential implementation of that object. This code is then embedded within a retry loop that is automatically generated by the universal construction. <p> For example, in order to transfer the contents of one shared queue to another, a task acquires locks for these two objects in a specific order, performs the transfer, and then releases the locks. In contrast, universal lock-free constructions that allow updates to multiple objects <ref> [7, 73] </ref> | the lock-free counterpart to nested critical sections | are not competitive with nested critical sections in real-time systems. Another advantage of using lock-based schemes is that, with little effort, any sequential object implementation can be converted to its concurrent version. <p> In particular, we explain the relevance of consensus numbers and Herlihy's consensus hierarchy to lock-free implementations, and then provide a description of the correctness requirements of lock-free objects. We also present descriptions of universal constructions by Herlihy [36, 37] and by Anderson and Moir <ref> [7, 8] </ref> because they are relevant to this dissertation. <p> As described below, these drawbacks are addressed in Anderson and Moir's universal construction for large objects. Large-Object Construction Anderson and Moir's large-object construction <ref> [7] </ref> fragments a large object into blocks; this is similar to Herlihy's approach for large object constructions. The construction in [7] differs from Herlihy's in two aspects: it is array-based rather than pointer-based, and it uses long-LL and long-SC primitives 6 instead of single-word LL/SC primitives. long-LL and long-SC primitives are <p> As described below, these drawbacks are addressed in Anderson and Moir's universal construction for large objects. Large-Object Construction Anderson and Moir's large-object construction <ref> [7] </ref> fragments a large object into blocks; this is similar to Herlihy's approach for large object constructions. The construction in [7] differs from Herlihy's in two aspects: it is array-based rather than pointer-based, and it uses long-LL and long-SC primitives 6 instead of single-word LL/SC primitives. long-LL and long-SC primitives are not provided by any machine; they are implemented using single-word LL/SC primitives. <p> the following observations: (i) any shared object can be implemented in a lock-free manner by using a constant number of LL and SC instructions [37]; (ii) an object that supports LL and SC operations can be implemented using only CAS, load, and store instructions with worst-case time complexity O (1) <ref> [7] </ref>; and, (iii) by Theorem 4.2, in any uniprocessor hard real-time system consisting of N tasks, an object that supports CAS and Read operations can be implemented using only load and store instructions with O (N ) worst-case time complexity. 4.5 Implementing CAS using Move, Load, and Store Instruc tions We <p> The framework that we present is based on universal lock-free constructions by Anderson and Moir for implementing large objects and for implementing multi-object operations in asynchronous systems <ref> [7, 8] </ref>. The behavior of transactions implemented under our transactional framework is very similar to the behavior of transactions implemented under conventional optimistic concurrency control (OCC) schemes [51].
Reference: [8] <author> J. H. Anderson and M. Moir. </author> <title> Universal constructions for multi-object operations. </title> <booktitle> In Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 184-193. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: For example, using nested critical sections, a task can atomically dequeue an element from one shared queue and enqueue that element in another shared queue. To achieve similar functionality in a lock-free system, universal constructions have been proposed that allow a task to perform operations on multiple objects simultaneously <ref> [8, 73] </ref>. Unfortunately, these implementations entail high algorithmic overhead, and are therefore too expensive to be competitive with nested critical sections in real-time systems. <p> In particular, we explain the relevance of consensus numbers and Herlihy's consensus hierarchy to lock-free implementations, and then provide a description of the correctness requirements of lock-free objects. We also present descriptions of universal constructions by Herlihy [36, 37] and by Anderson and Moir <ref> [7, 8] </ref> because they are relevant to this dissertation. <p> We now outline two universal constructions that are relevant to the work in this dissertation: one by Herlihy [37], and another by Anderson and Moir <ref> [8] </ref>. 44 Herlihy's Construction In [37], Herlihy presents two universal constructions for "small" and "large" objects. Herlihy's lock-free construction for small objects maintains N + 1 copies of the implemented object | a "current" copy, and a "working" copy for each task. <p> Hence, their construction is unsuitable for multi-object operations because it severely restricts concurrency. To rectify this problem, Anderson and Moir developed a multi-object construction that enables a high degree of concurrency <ref> [8] </ref>. Multi-Object Constructions The multi-object construction presented by Anderson and Moir in [8] is a generalization of Herlihy's lock-free construction described previously. As in Herlihy's construction, a task T i loads the pointer to each object that it accesses and then makes a local copy of that object. <p> Hence, their construction is unsuitable for multi-object operations because it severely restricts concurrency. To rectify this problem, Anderson and Moir developed a multi-object construction that enables a high degree of concurrency <ref> [8] </ref>. Multi-Object Constructions The multi-object construction presented by Anderson and Moir in [8] is a generalization of Herlihy's lock-free construction described previously. As in Herlihy's construction, a task T i loads the pointer to each object that it accesses and then makes a local copy of that object. Then, task T i applies its multi-object operation on its local object copies. <p> First, because their construction is based on Herlihy's lock-free construction, copying overhead can be excessive if large objects are accessed. Second, implementing the MWSC primitive 8 used in their construction entails high algorithmic overhead. In particular, the worst-case running-time of the MWSC implementation presented in <ref> [8] </ref> is O (N 3 M ), where N is the number of tasks in the system and M is the number of implemented shared words. <p> To enable the use of such practical implementations in real-time uniprocessor systems, we present two implementations of a shared object that supports Read and CAS operations. 3 (LL/SC can be implemented using Read and CAS in constant time <ref> [8] </ref>.) These implementations use load/store and move instructions, respectively. The key problem to be faced in our implementations is the problem of enabled late writes described in Section 4.3. Each of our implementations employ a different technique to solve this problem. <p> The framework that we present is based on universal lock-free constructions by Anderson and Moir for implementing large objects and for implementing multi-object operations in asynchronous systems <ref> [7, 8] </ref>. The behavior of transactions implemented under our transactional framework is very similar to the behavior of transactions implemented under conventional optimistic concurrency control (OCC) schemes [51].
Reference: [9] <author> J. H. Anderson and S. Ramamurthy. </author> <title> A framework for implementing objects and scheduling tasks in lock-free real-time systems. </title> <booktitle> In Proceedings of the 17th IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 92-105. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1996. </year>
Reference-contexts: Experimental results that compare and contrast the behavior of lock-free and lock-based schemes are presented in Chapter 6. Finally, conclusions and a discussion of future directions for this research appear in Chapter 7. (This dissertation includes work that is based on previously published work <ref> [9, 11, 12, 13, 14, 70] </ref>.) Chapter 2 Background and Related Work In this chapter, we provide background material on real-time systems and lock-free objects. First, we present scheduling conditions for various real-time scheduling schemes. Then, we describe various lock-based object-sharing schemes used in conventional real-time systems.
Reference: [10] <author> J. H. Anderson, S. Ramamurthy, and R. Jain. </author> <title> Implementing wait-free objects in priority-based systems. </title> <booktitle> In Proceedings of the 16th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 229-238. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1997. </year> <month> 223 </month>
Reference-contexts: These routines are called within the programmer's transaction code in order to read or write a word of the MEM array. Thus, instead of writing "MEM [1] := MEM <ref> [10] </ref>", the programmer would write "Tr Write (1; Tr Read (10))". Figure 5.1 shows a simple example transaction, which enqueues an item onto a shared queue. <p> In fact, Anderson, Ramamurthy, and Jain have shown recently that it is possible to dramatically reduce helping overhead in wait-free implementations for priority-based real-time systems <ref> [10] </ref>. <p> In order to be more competitive with lock-free schemes, the helping overhead has to be significantly reduced. In fact, on uniprocessor systems, it is possible to implement wait-free objects that are competitive with lock-based and lock-free schemes using a technique called incremental helping <ref> [10] </ref>. This technique exploits the real-time task model to ensure that a task helps at most one lower-priority task complete its operation before it performs its own operation. The scheduling conditions for task sets that employ this technique is very similar to the conditions for conventional lock-based schemes.
Reference: [11] <author> J. H. Anderson, S. Ramamurthy, and K. Jeffay. </author> <title> Real-time computing with lock-free objects. </title> <type> Technical Report TR95-021, </type> <institution> Department of Computer Science, University of North Carolina, Chapel Hill, North Carolina, </institution> <year> 1995. </year>
Reference-contexts: Experimental results that compare and contrast the behavior of lock-free and lock-based schemes are presented in Chapter 6. Finally, conclusions and a discussion of future directions for this research appear in Chapter 7. (This dissertation includes work that is based on previously published work <ref> [9, 11, 12, 13, 14, 70] </ref>.) Chapter 2 Background and Related Work In this chapter, we provide background material on real-time systems and lock-free objects. First, we present scheduling conditions for various real-time scheduling schemes. Then, we describe various lock-based object-sharing schemes used in conventional real-time systems. <p> Also, task T 2 's unfulfilled demand decreases by one unit at every instant in the interval <ref> [11; 14] </ref> because it executes on the processor.
Reference: [12] <author> J. H. Anderson, S. Ramamurthy, and K. Jeffay. </author> <title> Real-time computing with lock-free objects. </title> <journal> ACM Transactions on Comp. Sys., </journal> <volume> 15(6) </volume> <pages> 388-395, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: Experimental results that compare and contrast the behavior of lock-free and lock-based schemes are presented in Chapter 6. Finally, conclusions and a discussion of future directions for this research appear in Chapter 7. (This dissertation includes work that is based on previously published work <ref> [9, 11, 12, 13, 14, 70] </ref>.) Chapter 2 Background and Related Work In this chapter, we provide background material on real-time systems and lock-free objects. First, we present scheduling conditions for various real-time scheduling schemes. Then, we describe various lock-based object-sharing schemes used in conventional real-time systems.
Reference: [13] <author> J. H. Anderson, S. Ramamurthy, M. Moir, and K. Jeffay. </author> <title> Lock-free transactions for real-time systems. </title> <booktitle> In Proceedings of the First International Workshop on Real-Time Databases, </booktitle> <pages> pages 107-114, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Experimental results that compare and contrast the behavior of lock-free and lock-based schemes are presented in Chapter 6. Finally, conclusions and a discussion of future directions for this research appear in Chapter 7. (This dissertation includes work that is based on previously published work <ref> [9, 11, 12, 13, 14, 70] </ref>.) Chapter 2 Background and Related Work In this chapter, we provide background material on real-time systems and lock-free objects. First, we present scheduling conditions for various real-time scheduling schemes. Then, we describe various lock-based object-sharing schemes used in conventional real-time systems.
Reference: [14] <author> J. H. Anderson, S. Ramamurthy, M. Moir, and K. Jeffay. </author> <title> Lock-free transactions for real-time systems. In Real-Time Databases: Issues and Applications. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Amsterdam, </address> <year> 1997. </year>
Reference-contexts: Experimental results that compare and contrast the behavior of lock-free and lock-based schemes are presented in Chapter 6. Finally, conclusions and a discussion of future directions for this research appear in Chapter 7. (This dissertation includes work that is based on previously published work <ref> [9, 11, 12, 13, 14, 70] </ref>.) Chapter 2 Background and Related Work In this chapter, we provide background material on real-time systems and lock-free objects. First, we present scheduling conditions for various real-time scheduling schemes. Then, we describe various lock-based object-sharing schemes used in conventional real-time systems. <p> Thus, J 2;1 's operation on S 2 that begins at time 13 fails. This operation is retried at time 23, when it is successfully completed. Observe that J 2;1 experiences only one interference in the interval <ref> [14; 22] </ref>, even though two jobs (J 0;2 and J 1;2 ) are released in that interval that can potentially interfere with J 2;1 's object access. <p> Also, task T 2 's unfulfilled demand decreases by one unit at every instant in the interval <ref> [11; 14] </ref> because it executes on the processor.
Reference: [15] <author> R. Anderson and H. Woll. </author> <title> Wait-free parallel algorithms for the union-find problem. </title> <booktitle> In Proceedings of the 23rd Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 370-380. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: Implementations of various types of queues have been presented by Lamport [53], by Herlihy and Wing [38], by Israeli and Rappoport [41], by Wing and Gong [81, 82], and by Michael and Scott [64]. Anderson and Woll <ref> [15] </ref> and Lanin and Shasha [56] present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries [78, 79, 80]. Finally, Massalin and Pu have implemented an entire operating system using lock-free data structures such as lists, queues, and stacks [63].
Reference: [16] <author> J. Aspnes and M. Herlihy. </author> <title> Wait-free data structures in the asynchronous pram model. </title> <booktitle> In Proceedings of the Second Annual ACM Symposium on Parallel Architectures and Algorithms, </booktitle> <pages> pages 340-349, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported by any real machine. 50 ations satisfy certain algebraic requirements <ref> [5, 16] </ref>.
Reference: [17] <author> H. Attiya and O. Rachman. </author> <title> Atomic snapshots in o(n log n) operations. </title> <booktitle> In Proceedings of the Twelveth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 29-40. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers [23, 24, 49, 50, 54, 59, 66, 67, 68, 75]; atomic snapshots that allow multiple variables to be read atomically; <ref> [1, 3, 17] </ref>, algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported by any real machine. 50 ations satisfy certain algebraic requirements [5, 16].
Reference: [18] <author> N. C. Audsley, A. Burns, M. F. Richardson, and A. J. Wellings. </author> <title> Hard real-time scheduling: The deadline monotonic approach. </title> <booktitle> In Proceedings of the Eighth Workshop on Real-Time Operating Systems and Software, </booktitle> <pages> pages 133-138, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Leung and Whitehead [58] showed that the DM scheme is an optimal static priority scheme when each task's relative deadline is at most the length of its period. However, they did not provide scheduling conditions for the DM scheme. Later, in <ref> [18] </ref>, Audsley et al. developed a necessary and sufficient scheduling condition for periodic and synchronous task sets scheduled under the DM scheme. The scheduling condition in [18] is similar to (2.1) with one difference: t ranges from 0 to l i instead of p i , where l i is the <p> However, they did not provide scheduling conditions for the DM scheme. Later, in <ref> [18] </ref>, Audsley et al. developed a necessary and sufficient scheduling condition for periodic and synchronous task sets scheduled under the DM scheme. The scheduling condition in [18] is similar to (2.1) with one difference: t ranges from 0 to l i instead of p i , where l i is the relative deadline of task T i .
Reference: [19] <author> T. P. Baker. </author> <title> Stack-based scheduling of real-time processes. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 3(1) </volume> <pages> 67-99, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: For this reason, substantial effort has been devoted to the problem of bounding the duration of priority inversions in real-time systems either by using kernel support <ref> [19, 26, 44, 69, 71] </ref> or by using scheduling techniques [29, 65, 83]. <p> If context switches are expensive, the PCP can result in loss of predictability because the currently-known scheduling analysis [71] for the PCP ignores the effect of these extra context switches. Furthermore, these additional context switches can significantly increase blocking factors. The stack resource policy (SRP) <ref> [19] </ref> eliminates additional context switches by delaying the execution of a task until all required resources become available. Unlike the PIP/PCP, the SRP differentiates between priority levels and preemption levels. The notion of preemption levels is based on the relative deadlines of tasks; it is independent of priority levels. <p> The DPCP suffers from a major shortcoming: maintaining dynamic priority ceilings entail significant overhead at run-time. Furthermore, the large blocking factors in Condition 2.5 result in poor predicted schedulability. These problems were later addressed and solved in the SRP developed by Baker <ref> [19] </ref> and the EDF/DDM protocol developed by Jeffay [43, 44]. These schemes perform much better than DPCP because they result in optimal blocking factors. Although the implementation of the SRP and EDF/DDM are identical, the scheduling conditions developed for them are different. <p> Although the implementation of the SRP and EDF/DDM are identical, the scheduling conditions developed for them are different. Baker developed the following sufficient condition for determining the schedula-bility of a task set under the EDF scheme, when tasks' relative deadlines are not equal to their periods <ref> [19] </ref>. (8k : 0 k N 1 : l k k X c j 1) (2.6) The term B k =l k is akin to the blocking factor in (2.4). <p> It denotes the fraction of processor utilization wasted due a task at a lower-preemption level executing at the level of task T k . In <ref> [19] </ref>, Baker also developed a scheduling condition for a set of tasks that have relative deadlines equal to their periods. This condition is similar to (2.6), with one difference: the l k and l j terms are replaced by p k and p j , respectively. <p> The cost of a lock-based operation includes the cost of acquiring and releasing a lock; for lock-based objects, an implementation based on the stack resource policy was assumed <ref> [19] </ref>. If the conflicts parameter is k, then at least one object is accessed by k tasks, and no object is accessed by more than k 186 tasks. In our experiments, tasks were modeled as a sequence of three phases, of which only the second is an object-access phase.
Reference: [20] <author> G. Barnes. </author> <title> A method for implementing lock-free shared data structures. </title> <booktitle> In Proceedings of the Fifth Annual ACM Symposium on Parallel Architectures and Algorithms, </booktitle> <pages> pages 261-270. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: To rectify this situation, many researchers have developed universal constructions that allow easy implementation of lock-free objects. A universal construction is used to automatically generate lock-free implementations of arbitrary objects from their sequential implementations. Universal constructions 9 were proposed first by Herlihy [36], and improved later by others <ref> [2, 7, 20, 37, 42] </ref>. To implement a lock-free object using a universal construction, a programmer first writes code for a sequential implementation of that object. This code is then embedded within a retry loop that is automatically generated by the universal construction. <p> The semantics of SC are undefined if task T p has not previously executed a LL instruction. 2.4.3 Universal Constructions of Lock-Free Objects In recent years, several groups of researchers have presented methods for automat ically "transforming" sequential object implementations into lock-free ones <ref> [20, 35, 36, 37, 73] </ref>. These methods are called universal constructions. A universal construction relieves the object designer of the need to reason about concurrency, thereby greatly simplifying the task of providing a correct lock-free implementation for a particular shared object.
Reference: [21] <author> S. K. Baruah, R. R. Howell, and L. E. Rosier. </author> <title> Feasibility problems for recurring tasks on one processor. </title> <journal> Theoretical Computer Science, </journal> <volume> 118 </volume> <pages> 3-20, </pages> <year> 1993. </year>
Reference-contexts: When task sets are asynchronous, the conditions for RM and DM scheduling are no longer both necessary and sufficient. This is because conditions that are necessary and sufficient for synchronous task sets to be schedulable are only sufficient for asynchronous task sets <ref> [21, 58] </ref>. 2.1.2 Dynamic-Priority Scheduling Conditions Under dynamic-priority schemes, a task's priority can change over time. Such schemes allow higher achievable processor utilization than static-priority scheme, but they entail higher run-time overhead compared to static-priority schemes. <p> [27], the problem of determining the schedulability of a task set under the EDF scheme is equivalent to the problem of determining the feasibility of that task set. (Recall that an optimal scheduling scheme can schedule any feasible task set.) The feasibility problem was studied by Baruah, Howell, and Rosier <ref> [21] </ref>, who developed necessary and sufficient conditions for determining the feasibility 25 of an asynchronous set of periodic, independent tasks. They proved that (2.2) is a necessary (but not sufficient) condition for scheduling tasks under the EDF scheme, when task periods are different from their deadlines. <p> They proved that (2.2) is a necessary (but not sufficient) condition for scheduling tasks under the EDF scheme, when task periods are different from their deadlines. We now state the sufficient condition developed in <ref> [21] </ref> for determining the feasibility of a set of N periodic tasks. <p> As stated above, the expression cannot be evaluated because t is unbounded. Fortunately, it is shown in <ref> [21] </ref> that the above expression only needs to be checked for values of t that are less than or equal to 2 L + max 1iN (s i ) + max 1iN (l i ), where L is the least common multiple (LCM) of the task periods. <p> In <ref> [21] </ref>, Baruah, Howell, and Rosier t showed that the range of t can be further reduced if these exists an upper bound on processor utilization.
Reference: [22] <author> B. Bershad. </author> <title> Practical considerations for non-blocking concurrent objects. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Distributed Computing Systems, </booktitle> <pages> pages 264-274, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Furthermore, in some lock-based schemes, certain operating system tables must be modified when mode changes occur [72]. 1.2 Lock-Free Objects In this dissertation, we consider an alternative approach to interprocess communication in real-time systems. In particular, we show that lock-free shared objects <ref> [22, 37, 52, 62] </ref> | i.e., objects that are not critical-section-based | are a viable alternative to lock-based schemes in such systems. Such objects are typically implemented using retry loops that are potentially unbounded. <p> Thus, J 2;1 's operation on S 2 that begins at time 13 fails. This operation is retried at time 23, when it is successfully completed. Observe that J 2;1 experiences only one interference in the interval <ref> [14; 22] </ref>, even though two jobs (J 0;2 and J 1;2 ) are released in that interval that can potentially interfere with J 2;1 's object access.
Reference: [23] <author> B. Bloom. </author> <title> Constructing two-writer atomic registers. </title> <journal> IEEE Trans. on Computer Systems, </journal> <volume> 37(12) </volume> <pages> 1506-1514, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [24] <author> J. Burns and G. Peterson. </author> <title> Constructing multi-reader atomic values from non-atomic values. </title> <booktitle> In Proceedings of the Eighth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 222-231, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [25] <author> C.Dwork and O. Waarts. </author> <booktitle> Simple and efficient bounded and concurrent timestamping or bounded concurrent timestamp systems are comprehensible! In Proceedings of the 24th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 655-666. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1992. </year> <month> 224 </month>
Reference-contexts: These implementations include constructions of complex registers from simpler registers [23, 24, 49, 50, 54, 59, 66, 67, 68, 75]; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps <ref> [25, 28] </ref>; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported by any real machine. 50 ations satisfy certain algebraic requirements [5, 16]. <p> Observe that J 1;1 also experiences an interference at time 4 while accessing object S 2 due to the release of J 0;1 . The total demand placed in the interval <ref> [0; 25] </ref> by jobs with deadlines at or before 25 is 10 units; 4 and 6 units due to tasks T 0 and T 1 , respectively. Of the 6 units of T 1 's demand, 2 units are due to an interference in T 1 at time 4.
Reference: [26] <author> M. I. Chen and K. J. Lin. </author> <title> Dynamic priority ceiling: A concurrency control protocol for real time systems. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 2(1) </volume> <pages> 325-346, </pages> <year> 1990. </year>
Reference-contexts: For this reason, substantial effort has been devoted to the problem of bounding the duration of priority inversions in real-time systems either by using kernel support <ref> [19, 26, 44, 69, 71] </ref> or by using scheduling techniques [29, 65, 83]. <p> under the DM scheme is similar to (2.4) with one difference: t ranges up to l i rather than p i . 2.2.2 Dynamic-Priority Conditions The least predictable and least efficient mechanism for object sharing under dynamic-priority schemes is the dynamic priority ceiling protocol (DPCP) developed by Chen and Lin <ref> [26] </ref>. The DPCP is a straightforward adaptation of the PCP for dynamic-priority scheduling. One major difference between these schemes is that the DPCP modifies priority ceilings of objects at run-time. Chen and Lin developed the following scheduling condition for the DPCP [26]. <p> priority ceiling protocol (DPCP) developed by Chen and Lin <ref> [26] </ref>. The DPCP is a straightforward adaptation of the PCP for dynamic-priority scheduling. One major difference between these schemes is that the DPCP modifies priority ceilings of objects at run-time. Chen and Lin developed the following scheduling condition for the DPCP [26]. N1 X c j + B j 1 (2.5) In the above equation, B j represents the maximum amount of blocking that can 34 experienced by a job of task T j . The DPCP suffers from a major shortcoming: maintaining dynamic priority ceilings entail significant overhead at run-time. <p> This condition is similar to (2.6), with one difference: the l k and l j terms are replaced by p k and p j , respectively. Baker's condition is also applicable to the DPCP, and is a significant improvement over Chen and Lin's condition <ref> [26] </ref>.
Reference: [27] <author> M. Dertouzos. </author> <title> Control robotics: The procedural control of physical processors. </title> <booktitle> In Proceedings of the IFIP Congress, </booktitle> <pages> pages 807-813, </pages> <year> 1974. </year>
Reference-contexts: We now consider conditions that determine the schedulability of an asynchronous task set under the EDF scheme, when tasks' relative deadlines do not equal their periods. Because EDF is an optimal scheduling scheme <ref> [27] </ref>, the problem of determining the schedulability of a task set under the EDF scheme is equivalent to the problem of determining the feasibility of that task set. (Recall that an optimal scheduling scheme can schedule any feasible task set.) The feasibility problem was studied by Baruah, Howell, and Rosier [21],
Reference: [28] <author> D. Dolev and N.Shavit. </author> <booktitle> Bounded concurrent timestamp systems are constructible! In Proceedings of the 21st Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 78-92. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1989. </year>
Reference-contexts: These implementations include constructions of complex registers from simpler registers [23, 24, 49, 50, 54, 59, 66, 67, 68, 75]; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps <ref> [25, 28] </ref>; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported by any real machine. 50 ations satisfy certain algebraic requirements [5, 16].
Reference: [29] <author> S. R. Faulk and D. L. Parnas. </author> <title> On synchronization in hard real-time systems. </title> <journal> Comm. of the ACM, </journal> <volume> 31(3) </volume> <pages> 275-287, </pages> <year> 1988. </year>
Reference-contexts: For this reason, substantial effort has been devoted to the problem of bounding the duration of priority inversions in real-time systems either by using kernel support [19, 26, 44, 69, 71] or by using scheduling techniques <ref> [29, 65, 83] </ref>.
Reference: [30] <author> B. O. Gallmeister and C. Lanier. </author> <title> Early experience with posix 1003.4 and posix 1003.4a. </title> <booktitle> In Proceedings of the Twelveth IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 190-198. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1991. </year>
Reference-contexts: Massalin's conclusions are based on experiments run on a 25 MHz, one-wait-state memory, cold-cache 68030 CPU. In contrast, lock-based implementations fared much worse in a recent performance comparison of commercial real-time operating systems run on a 25 MHz, zero-wait-state memory 80386 CPU <ref> [30] </ref>. In this comparison, the implementation of semaphores on LynxOS took 154.4 microseconds to lock and unlock a semaphore in the worst case. The corresponding figure for POSIX mutex-style semaphores was 243.6 microseconds.
Reference: [31] <author> M. H. Graham. </author> <title> How to get serializability for real-time transactions without having to pay for it. </title> <booktitle> In Proceedings of the Fourteenth IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 56-65, </pages> <year> 1993. </year>
Reference-contexts: In addition, the larger conflicts parameter values considered (which resulted in less accurate predications for lock-free) may not be reflective of what one would find in practice. In fact, as explained in the following section, in many practical real-time systems, write-write conflicts cannot occur between concurrently executing tasks <ref> [31] </ref>, implying that the conflicts parameter is likely to be small. <p> Second, for a given task set, the choice of one object sharing scheme over another depends entirely on the schedulability of the task set under these schemes. For example, in many practical real-time systems, write-write conflicts cannot occur between concurrently executing tasks <ref> [31] </ref>. In such systems, most shared objects are single-writer multi-reader read/write buffers, and most of the operations in such a system are likely to be read-only.
Reference: [32] <author> M. Greenwald and D. Cheriton. </author> <title> The synergy between non-blocking synchronization and operating system structure. </title> <booktitle> In Proceedings of the USENIX Association Second Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 123-136, </pages> <year> 1996. </year>
Reference-contexts: The lock-based versions of these data structures were implemented under the EDF/DDM scheme. For objects other than skew heaps, 1 the object-specific lock-free implementations were based on implementations presented elsewhere. In particular, the read/write buffer, stack, and queue implementations are from [62], and the linked list implementations are from <ref> [32] </ref>. Transaction-based lock-free object implementations are based on the transactional framework described in Chapter 5. However, unlike the implementation described in Chapter 5, the implementation used in our experiments did not employ the MWCAS implementation described in Section 4.6.
Reference: [33] <author> M. G. Harbour, M. H. Klein, and J. P. Lehoczky. </author> <title> Fixed priority scheduling of periodic tasks with varying execution priority. </title> <booktitle> In Proceedings of the Twelveth IEEE Symposium on Real-Time Systems, </booktitle> <pages> pages 116-128. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1991. </year>
Reference-contexts: Requirement (ii) holds for most common scheduling policies, including RM, DM, and EDF scheduling and variations of these in which tasks are broken into phases that are allowed to have distinct priorities <ref> [33] </ref>. The only common scheduling policy that we know of that violates requirement (ii) is LLF scheduling [65]. Under LLF scheduling, the priority of a task invocation can change during its execution. Observe that requirements (i) and (ii) expressly preclude the use of locking within a processor.
Reference: [34] <author> J. Haritsa, M. Carey, and M. Livny. </author> <title> On being optimistic about real-time constraints. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 331-343, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, by adapting our transactional framework to use information about transaction priorities, the amount of wasted computation due to retries can be reduced, potentially | such techniques are likely to result in a significant reduction of missed transaction deadlines <ref> [34] </ref>. * Although we have developed some simple rules for choosing an object sharing scheme, the right choice of a scheme for implementing an object in an application is entirely 221 dependent on the task set of the application.
Reference: [35] <author> M. Herlihy. </author> <title> Impossibility and universality results for wait-free synchronization. </title> <booktitle> In Proceedings of the Seventh Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 276-290. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: Loui and Abu-Amara [61] showed that the N -task consensus problem cannot be solved in a wait-free manner for N &gt; 1 in an asynchronous system using load and store instructions. Herlihy later extended these results to other primitives by classifying each primitive according to its consensus number <ref> [35, 36] </ref>. The consensus number of a primitive is the maximum number of tasks for which a wait-free (or lock-free) consensus algorithm exists that relies only on that primitive, and load/store instructions. <p> The semantics of SC are undefined if task T p has not previously executed a LL instruction. 2.4.3 Universal Constructions of Lock-Free Objects In recent years, several groups of researchers have presented methods for automat ically "transforming" sequential object implementations into lock-free ones <ref> [20, 35, 36, 37, 73] </ref>. These methods are called universal constructions. A universal construction relieves the object designer of the need to reason about concurrency, thereby greatly simplifying the task of providing a correct lock-free implementation for a particular shared object.
Reference: [36] <author> M. Herlihy. </author> <title> Wait-free synchronization. </title> <journal> ACM Trans. on Programm. Lang. Syst., </journal> <volume> 13(1) </volume> <pages> 124-149, </pages> <year> 1991. </year>
Reference-contexts: To rectify this situation, many researchers have developed universal constructions that allow easy implementation of lock-free objects. A universal construction is used to automatically generate lock-free implementations of arbitrary objects from their sequential implementations. Universal constructions 9 were proposed first by Herlihy <ref> [36] </ref>, and improved later by others [2, 7, 20, 37, 42]. To implement a lock-free object using a universal construction, a programmer first writes code for a sequential implementation of that object. This code is then embedded within a retry loop that is automatically generated by the universal construction. <p> The fact that lock-free objects are typically implemented using strong synchronization primitives is no accident. In his seminal work <ref> [36] </ref>, Herlihy showed that strong primitives are, in general, necessary for implementing lock-free objects. Herlihy's results are based upon a categorization of objects by "consensus number". <p> Finally, we present background material on lock-free objects. In particular, we explain the relevance of consensus numbers and Herlihy's consensus hierarchy to lock-free implementations, and then provide a description of the correctness requirements of lock-free objects. We also present descriptions of universal constructions by Herlihy <ref> [36, 37] </ref> and by Anderson and Moir [7, 8] because they are relevant to this dissertation. <p> p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization. <p> For example, there exists an important special class of lock-free implementations known as wait-free implementations <ref> [36, 37, 67, 54] </ref> in which operations must satisfy a strong form of lock-freedom that precludes all waiting dependencies among tasks, including potentially unbounded retry loops. <p> Loui and Abu-Amara [61] showed that the N -task consensus problem cannot be solved in a wait-free manner for N &gt; 1 in an asynchronous system using load and store instructions. Herlihy later extended these results to other primitives by classifying each primitive according to its consensus number <ref> [35, 36] </ref>. The consensus number of a primitive is the maximum number of tasks for which a wait-free (or lock-free) consensus algorithm exists that relies only on that primitive, and load/store instructions. <p> The semantics of SC are undefined if task T p has not previously executed a LL instruction. 2.4.3 Universal Constructions of Lock-Free Objects In recent years, several groups of researchers have presented methods for automat ically "transforming" sequential object implementations into lock-free ones <ref> [20, 35, 36, 37, 73] </ref>. These methods are called universal constructions. A universal construction relieves the object designer of the need to reason about concurrency, thereby greatly simplifying the task of providing a correct lock-free implementation for a particular shared object. <p> Our results imply that Herlihy's hierarchy collapses in uniprocessor real-time systems, and that sophisticated hardware support is not required to implement lock-free objects in such systems. In fact, using the universal constructions described in <ref> [36, 42] </ref>, it is possible to implement any lock-free object using only consensus protocols. However, we eschew such an approach to implementing lock-free objects because practical implementations of such objects are usually based on 1 Primitives with unbounded consensus number. 91 strong primitives such as CAS. <p> Proof: By Lemma 4.1, exactly one value is written into Final and all tasks decide on the value in Final . Hence, it follows that all tasks decide on the same value. Using consensus objects, any shared object can be implemented in a wait-free 100 (and hence lock-free) manner <ref> [36, 42] </ref>. However, such implementations usually entail high overhead; practical wait-free and lock-free implementations are typically based on primitives such as CAS and LL/SC. <p> Most wait-free universal constructions ensure termination by requiring each task to "help" every other task to complete any pending object access <ref> [36, 37] </ref>. To see how this works, consider the lock-free universal construction of Herlihy [37], which is described in Subsection 2.4.3. This construction does not guarantee termination because the store-conditional operation of each retry loop iteration may fail.
Reference: [37] <author> M. Herlihy. </author> <title> A methodology for implementing highly concurrent data objects. </title> <journal> ACM Trans. on Programm. Lang. Syst., </journal> <volume> 15(5) </volume> <pages> 745-770, </pages> <year> 1993. </year>
Reference-contexts: Furthermore, in some lock-based schemes, certain operating system tables must be modified when mode changes occur [72]. 1.2 Lock-Free Objects In this dissertation, we consider an alternative approach to interprocess communication in real-time systems. In particular, we show that lock-free shared objects <ref> [22, 37, 52, 62] </ref> | i.e., objects that are not critical-section-based | are a viable alternative to lock-based schemes in such systems. Such objects are typically implemented using retry loops that are potentially unbounded. <p> To rectify this situation, many researchers have developed universal constructions that allow easy implementation of lock-free objects. A universal construction is used to automatically generate lock-free implementations of arbitrary objects from their sequential implementations. Universal constructions 9 were proposed first by Herlihy [36], and improved later by others <ref> [2, 7, 20, 37, 42] </ref>. To implement a lock-free object using a universal construction, a programmer first writes code for a sequential implementation of that object. This code is then embedded within a retry loop that is automatically generated by the universal construction. <p> Finally, we present background material on lock-free objects. In particular, we explain the relevance of consensus numbers and Herlihy's consensus hierarchy to lock-free implementations, and then provide a description of the correctness requirements of lock-free objects. We also present descriptions of universal constructions by Herlihy <ref> [36, 37] </ref> and by Anderson and Moir [7, 8] because they are relevant to this dissertation. <p> p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization. <p> For example, there exists an important special class of lock-free implementations known as wait-free implementations <ref> [36, 37, 67, 54] </ref> in which operations must satisfy a strong form of lock-freedom that precludes all waiting dependencies among tasks, including potentially unbounded retry loops. <p> The semantics of SC are undefined if task T p has not previously executed a LL instruction. 2.4.3 Universal Constructions of Lock-Free Objects In recent years, several groups of researchers have presented methods for automat ically "transforming" sequential object implementations into lock-free ones <ref> [20, 35, 36, 37, 73] </ref>. These methods are called universal constructions. A universal construction relieves the object designer of the need to reason about concurrency, thereby greatly simplifying the task of providing a correct lock-free implementation for a particular shared object. <p> A universal construction relieves the object designer of the need to reason about concurrency, thereby greatly simplifying the task of providing a correct lock-free implementation for a particular shared object. We now outline two universal constructions that are relevant to the work in this dissertation: one by Herlihy <ref> [37] </ref>, and another by Anderson and Moir [8]. 44 Herlihy's Construction In [37], Herlihy presents two universal constructions for "small" and "large" objects. Herlihy's lock-free construction for small objects maintains N + 1 copies of the implemented object | a "current" copy, and a "working" copy for each task. <p> We now outline two universal constructions that are relevant to the work in this dissertation: one by Herlihy <ref> [37] </ref>, and another by Anderson and Moir [8]. 44 Herlihy's Construction In [37], Herlihy presents two universal constructions for "small" and "large" objects. Herlihy's lock-free construction for small objects maintains N + 1 copies of the implemented object | a "current" copy, and a "working" copy for each task. <p> Also, task T 2 's unfulfilled demand decreases by one unit at every instant in the interval [11; 14] because it executes on the processor. The demand placed by T 2 on the processor in the interval <ref> [5; 37] </ref> is 16 units; 7 units due to T 2 's unfulfilled demand at time 5, 2 units due to an interference in J 2;1 at time 14, and 7 units due the release of J 2;2 at time 36. <p> Proof: The proof follows directly from the following observations: (i) any shared object can be implemented in a lock-free manner by using a constant number of LL and SC instructions <ref> [37] </ref>; (ii) an object that supports LL and SC operations can be implemented using only CAS, load, and store instructions with worst-case time complexity O (1) [7]; and, (iii) by Theorem 4.2, in any uniprocessor hard real-time system consisting of N tasks, an object that supports CAS and Read operations can <p> Most wait-free universal constructions ensure termination by requiring each task to "help" every other task to complete any pending object access <ref> [36, 37] </ref>. To see how this works, consider the lock-free universal construction of Herlihy [37], which is described in Subsection 2.4.3. This construction does not guarantee termination because the store-conditional operation of each retry loop iteration may fail. <p> Most wait-free universal constructions ensure termination by requiring each task to "help" every other task to complete any pending object access [36, 37]. To see how this works, consider the lock-free universal construction of Herlihy <ref> [37] </ref>, which is described in Subsection 2.4.3. This construction does not guarantee termination because the store-conditional operation of each retry loop iteration may fail. Herlihy extends this construction to be wait-free by requiring each task to "announce" any pending operation by recording it in a shared array. <p> We implemented lock-free queues by using the shared queue implementation given in [62] (modified to support the get length operation), and wait-free queues by using the wait-free universal construction given in <ref> [37] </ref>. Massalin's queue implementation requires CAS (needed for the dequeue operation) and CAS2 (needed for the enqueue operation), and Herlihy's 208 construction requires load-linked and store-conditional . We implemented these primitives by short kernel calls; interrupts were disabled for the duration of these calls.
Reference: [38] <author> M. Herlihy and J. Wing. </author> <title> Axioms for concurrent objects. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 13-26. </pages> <publisher> ACM, </publisher> <year> 1987. </year>
Reference-contexts: Other researchers have considered wait-free and lock-free implementations using instructions that are stronger than simple reads and writes. Implementations of various types of queues have been presented by Lamport [53], by Herlihy and Wing <ref> [38] </ref>, by Israeli and Rappoport [41], by Wing and Gong [81, 82], and by Michael and Scott [64]. Anderson and Woll [15] and Lanin and Shasha [56] present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries [78, 79, 80].
Reference: [39] <author> M. Herlihy and Jeanette Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <journal> ACM Trans. on Programm. Lang. Syst., </journal> <volume> 12(3) </volume> <pages> 463-492, </pages> <year> 1990. </year>
Reference-contexts: In order for a shared object implementation to be useful, each operation should "appear" to the invoking tasks to take effect instantaneously at some point during its execution. The formal correctness condition used to ensure this is linearizability <ref> [39] </ref>. Linearizability requires that the partial order that arises from any series of invocations on an object can be extended to a total order in such a way that the values returned by the invocations in the total order are consistent with the sequential semantics of the implemented object. <p> We say that an operation executes within the interval [t; u] iff the first statement execution of that operation occurs after state t and the last statement execution of that 94 operation occurs before state u. The correctness condition we use for our lock-free and wait-free implementations is linearizability <ref> [39] </ref>. An implementation of an object is linearizable if, in every history h, the partial order over the operation invocations in h can be extended to a total order such that the sequence of operations in the total order is consistent with the sequential semantics of the implemented operations.
Reference: [40] <author> J. Huang, J. Stankovic, K. Ramamritham, and D. Towsley. </author> <title> Experimental evaluation of real-time optimistic concurrency control schemes. </title> <booktitle> In Proceedings of the Seventeenth International Conference on Very Large Databases, </booktitle> <pages> pages 35-46, </pages> <year> 1991. </year>
Reference-contexts: In contrast, transactions in conventional OCC schemes cannot be preempted dur 162 ing their validate and commit phases <ref> [40] </ref> | such transactions entail a blocking factor due to the validate and commit phases of lower-priority transactions. Our transactional framework differs from conventional real-time database systems in another aspect.
Reference: [41] <author> A. Israeli and L. Rappaport. </author> <title> Efficient wait-free implementation of a concurrent priority queue. </title> <booktitle> In Proceedings of the Seventh International Workshop on Distributed Algorithms, </booktitle> <pages> pages 1-16, </pages> <month> October </month> <year> 1993. </year> <month> 225 </month>
Reference-contexts: Other researchers have considered wait-free and lock-free implementations using instructions that are stronger than simple reads and writes. Implementations of various types of queues have been presented by Lamport [53], by Herlihy and Wing [38], by Israeli and Rappoport <ref> [41] </ref>, by Wing and Gong [81, 82], and by Michael and Scott [64]. Anderson and Woll [15] and Lanin and Shasha [56] present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries [78, 79, 80].
Reference: [42] <author> P. Jayanti and S. Toueg. </author> <title> Some results on the impossibility, universality, and decidabil-ity of consensus. </title> <booktitle> In Proceedings of the Sixth International Workshop on Distributed Algorithms, </booktitle> <pages> pages 69-84. </pages> <publisher> Springer Verlag, </publisher> <month> November </month> <year> 1992. </year>
Reference-contexts: To rectify this situation, many researchers have developed universal constructions that allow easy implementation of lock-free objects. A universal construction is used to automatically generate lock-free implementations of arbitrary objects from their sequential implementations. Universal constructions 9 were proposed first by Herlihy [36], and improved later by others <ref> [2, 7, 20, 37, 42] </ref>. To implement a lock-free object using a universal construction, a programmer first writes code for a sequential implementation of that object. This code is then embedded within a retry loop that is automatically generated by the universal construction. <p> Our results imply that Herlihy's hierarchy collapses in uniprocessor real-time systems, and that sophisticated hardware support is not required to implement lock-free objects in such systems. In fact, using the universal constructions described in <ref> [36, 42] </ref>, it is possible to implement any lock-free object using only consensus protocols. However, we eschew such an approach to implementing lock-free objects because practical implementations of such objects are usually based on 1 Primitives with unbounded consensus number. 91 strong primitives such as CAS. <p> Proof: By Lemma 4.1, exactly one value is written into Final and all tasks decide on the value in Final . Hence, it follows that all tasks decide on the same value. Using consensus objects, any shared object can be implemented in a wait-free 100 (and hence lock-free) manner <ref> [36, 42] </ref>. However, such implementations usually entail high overhead; practical wait-free and lock-free implementations are typically based on primitives such as CAS and LL/SC.
Reference: [43] <author> K. Jeffay. </author> <title> The Real-Time Producer/Consumer Paradigm: Towards Verifiable Real-Time Computations. </title> <type> PhD thesis, </type> <institution> University of Washington, </institution> <address> Seattle, WA, </address> <year> 1989. </year>
Reference-contexts: Furthermore, the large blocking factors in Condition 2.5 result in poor predicted schedulability. These problems were later addressed and solved in the SRP developed by Baker [19] and the EDF/DDM protocol developed by Jeffay <ref> [43, 44] </ref>. These schemes perform much better than DPCP because they result in optimal blocking factors. Although the implementation of the SRP and EDF/DDM are identical, the scheduling conditions developed for them are different.
Reference: [44] <author> K. Jeffay. </author> <title> Scheduling sporadic tasks with shared resources in hard real-time systems. </title> <booktitle> In Proceedings of the Thirteenth IEEE Symposium on Real-Time Systems, </booktitle> <pages> pages 89-98. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1992. </year>
Reference-contexts: For this reason, substantial effort has been devoted to the problem of bounding the duration of priority inversions in real-time systems either by using kernel support <ref> [19, 26, 44, 69, 71] </ref> or by using scheduling techniques [29, 65, 83]. <p> By delaying a job's execution, the SRP ensures that the job never blocks during its execution. The SRP successfully addresses many of the problems associated with the PCP: first, it minimizes additional context switching overhead; second, it supports general semaphores. In <ref> [44] </ref>, Jeffay developed another protocol for lock-based object sharing under the EDF scheme, namely the earliest-deadline-first with dynamic-deadline-modification (EDF/DDM) protocol. The working of the EDF/DDM scheme is not illustrated here because it imitates the behavior of the SRP under EDF scheduling. <p> Furthermore, the large blocking factors in Condition 2.5 result in poor predicted schedulability. These problems were later addressed and solved in the SRP developed by Baker [19] and the EDF/DDM protocol developed by Jeffay <ref> [43, 44] </ref>. These schemes perform much better than DPCP because they result in optimal blocking factors. Although the implementation of the SRP and EDF/DDM are identical, the scheduling conditions developed for them are different. <p> This condition is similar to (2.6), with one difference: the l k and l j terms are replaced by p k and p j , respectively. Baker's condition is also applicable to the DPCP, and is a significant improvement over Chen and Lin's condition [26]. In <ref> [44] </ref>, Jeffay developed an exact schedulability test for asynchronous, sporadic tasks scheduled under the EDF/NPD scheme and that access objects using the EDF/DDM scheme. (As explained earlier, if tasks are periodic, then the condition in [44] is sufficient but not necessary.) According to this test, such a task set is schedulable <p> In <ref> [44] </ref>, Jeffay developed an exact schedulability test for asynchronous, sporadic tasks scheduled under the EDF/NPD scheme and that access objects using the EDF/DDM scheme. (As explained earlier, if tasks are periodic, then the condition in [44] is sufficient but not necessary.) According to this test, such a task set is schedulable iff the following 35 conditions hold. <p> the performance of the different object sharing schemes in an actual application | a desktop videoconferencing system. 179 6.1 Formal Comparison The formal comparison presented in this section is based upon the scheduling conditions presented in Sections 3.3 and 3.4, and scheduling conditions for lock-based schemes found in the literature <ref> [44, 69] </ref>. In deriving the scheduling conditions in Sections 3.3 and 3.4, we assume that the execution of the retry-loops of the different objects in the system are identical. We also assume that tasks do not invoke multi-object operations. <p> In reality, a preempted task need not be accessing a shared object, and hence may not necessarily have an interference as we have assumed. 6.1.2 Dynamic-Priority Scheduling We now compare the overhead of lock-free objects with the dynamic deadline modification (DDM) scheme under EDF scheduling (EDF/DDM) <ref> [44] </ref>, which is a lock-based protocol for dynamic-priority schemes. Under this scheme, tasks are divided into one or more phases. During each phase, a task accesses at most one shared resource. <p> Under the EDF/DDM scheme, r includes the cost of a system call to modify the task deadline before accessing an object, the cost of performing the shared-object operation, and the cost of a system call to restore the task deadline after an access. Based on the analysis of <ref> [44] </ref>, a sufficient condition for the schedulability of a set of periodic tasks under the EDF/DDM scheme, sched DDM , can be defined as follows. 182 sched DDM ( P N u j +m j r h8i; t : P i &lt; t &lt; p i : r + j=1 t1
Reference: [45] <author> K. Jeffay, D. F. Stanat, and C. U. Martel. </author> <title> On non-preemptive scheduling of periodic and sporadic tasks. </title> <booktitle> In Proceedings of the Twelveth IEEE Symposium on Real-Time Systems, </booktitle> <pages> pages 129-139. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1991. </year>
Reference-contexts: The demand placed by a task T i on the processor in an interval [t; t 0 ] is the amount of processing time required by jobs of T i in that interval <ref> [45] </ref>.
Reference: [46] <author> K. Jeffay and D. Stone. </author> <title> Accounting for interrupt handling costs in dynamic priority task systems. </title> <booktitle> In Proceedings of the Fourteenth IEEE Symposium on Real-Time Systems, </booktitle> <pages> pages 212-221. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1993. </year>
Reference-contexts: The expressions in [48] were derived only for the RM scheme, but they also hold for the DM and EDF schemes. Interrupt Handling Overhead Costs: The problem of accounting for interrupt handling overhead costs was first addressed by Jeffay and Stone in <ref> [46] </ref>. In their work, Jeffay and Stone focus on a system in which interrupts arrive periodically and in which a set of periodic tasks are scheduled under the EDF scheme. <p> The reasoning behind (2.10) is as follows: in any interval of length t, there are at most dt=v j e interrupts of type I j , each of which requires e j units of computation. Although, the work in <ref> [46] </ref> considers only the EDF scheme, it is also applicable to static-priority schemes. <p> (t) in the left-hand side of the inequality in Condition (2.4). (A similar condition for the DM scheme looks identical that for the RM scheme with one small difference: t ranges from 0 to l i instead of 0 to p i .) In [77], Stone adapted the conditions in <ref> [46] </ref> for EDF/NPD scheduling to account for context switching and interrupt handling costs, when tasks access tasks under the EDF/DDM scheme; these conditions are stated below. <p> I i I 1 I 2 I 3 I 45 I 67 I 89 I 1012 v i 54925 16666 10493 15492 45666 42603 47666 cost of handling interrupts, and hence cannot be used directly. Fortunately, this problem can be overcome by using techniques derived in <ref> [46] </ref>. The idea is to derive an expression that bounds the demand due to interrupt handlers in any given interval, and to then account for this demand in the scheduling conditions of Theorem 3.2 and [57]. Informally, we account for the cost of interrupt handlers as follows (see [46] for a <p> derived in <ref> [46] </ref>. The idea is to derive an expression that bounds the demand due to interrupt handlers in any given interval, and to then account for this demand in the scheduling conditions of Theorem 3.2 and [57]. Informally, we account for the cost of interrupt handlers as follows (see [46] for a more formal version of this argument). First, we define the term F (t) to be the cost of handling interrupts over an interval of length t. <p> Our analysis of the system when lock-free objects are used is based upon the scheduling condition below. This condition is based upon the conditions given in Theorems 3.5 and 3.4 and the techniques given in <ref> [46] </ref> for accounting for the overhead of interrupt handlers. ( j=1 (c j + s)=p j + j=1 e j =v j 1) ^ P N j p j c j + t1l j +p j k P Q l v j e j ti In this expression, B LF ( <p> The first conjunct above is the condition of Theorem 3.5 augmented to include utilization due to interrupt handlers. The second conjunct follows from Theorem 3.4 and results of <ref> [46] </ref>. The three summation terms in this conjunct give the maximum demand due to the tasks, interferences, and interrupt handlers, respectively, in an interval of length t. The right-hand side of the stated inequality gives the available processor time in that interval.
Reference: [47] <author> K. Jeffay, D. Stone, and F. D. Smith. </author> <title> Kernel support for live digital audio and video. </title> <journal> Computer Communications, </journal> <volume> 15(6) </volume> <pages> 388-395, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The objects were implemented under the YARTOS kernel developed at UNC <ref> [47, 77] </ref>, on a 66-MHz, 80486-based IBM PC. <p> This evidence comes from a set of experimental comparisons performed using a real-time desktop videoconferencing system implemented at UNC <ref> [47] </ref>. We modified this system to support lock-free shared objects implemented under both DM and EDF scheduling, semaphores implemented using the PCP under DM scheduling, and semaphores implemented under EDF/DDM scheduling. We also considered wait-free shared objects implemented under both DM and EDF scheduling.
Reference: [48] <author> Dan I. Katcher, H. Arakawa, and J. K. Strosnider. </author> <title> Engineering and analysis of fixed-priority schedulers. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 19(9) </volume> <pages> 920-934, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: We now discuss previous work on incorporating system overhead costs into scheduling conditions for periodic task sets. 36 Context Switching Overhead Costs: In <ref> [48] </ref>, Katcher, Arakawa, and Strosnider developed a RM scheduling condition that accounted for context-switching overhead costs. They enhanced Condition 2.4 by including an additional term to account for context switching overhead costs. In [48], Katcher et al. derived the following expression for CS i (t) the total additional demand due to <p> incorporating system overhead costs into scheduling conditions for periodic task sets. 36 Context Switching Overhead Costs: In <ref> [48] </ref>, Katcher, Arakawa, and Strosnider developed a RM scheduling condition that accounted for context-switching overhead costs. They enhanced Condition 2.4 by including an additional term to account for context switching overhead costs. In [48], Katcher et al. derived the following expression for CS i (t) the total additional demand due to context switches in T i or higher-priority in an interval of length t. i X l p j (C save + C rest ) (2.9) In (2.9), the worst-case time to save the <p> Note that this expression is pessimistic because a lower-priority job need not be executing when a job of task T j is released; the processor may be idle or a higher-priority job may be executing. The expressions in <ref> [48] </ref> were derived only for the RM scheme, but they also hold for the DM and EDF schemes. Interrupt Handling Overhead Costs: The problem of accounting for interrupt handling overhead costs was first addressed by Jeffay and Stone in [46].
Reference: [49] <author> L. Kirousis, E. Kranakis, and P. Vitanyi. </author> <title> Atomic multireader register. </title> <booktitle> In Proceedings of the Second International Workshop on Distributed Algorithms, </booktitle> <pages> pages 278-296, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization. <p> Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [50] <author> L. Kirousis, P. Spirakis, and P. Tsigas. </author> <title> Reading many variables in one atomic operation: Solutions with linear or sublinear complexity. </title> <booktitle> In Proceedings of the Fifth International Workshop on Distributed Algorithms, </booktitle> <pages> pages 229-241, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [51] <author> H. Kung and J. Robinson. </author> <title> On optimistic methods for concurrency control. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 6(2) </volume> <pages> 213-226, </pages> <month> December </month> <year> 1981. </year>
Reference-contexts: The behavior of transactions implemented under our transactional framework is very similar to the behavior of transactions implemented under conventional optimistic concurrency control (OCC) schemes <ref> [51] </ref>. One aspect in which our implementation differs from conventional OCC implementations is that we use a strong synchronization primitive at the user level to validate and commit transactions | transactions can be preempted during their validate and commit phases.
Reference: [52] <author> L. Lamport. </author> <title> Concurrent reading and writing. </title> <journal> Commun. ACM, </journal> 20(11) 806-811, Novem-ber 1977. 
Reference-contexts: Furthermore, in some lock-based schemes, certain operating system tables must be modified when mode changes occur [72]. 1.2 Lock-Free Objects In this dissertation, we consider an alternative approach to interprocess communication in real-time systems. In particular, we show that lock-free shared objects <ref> [22, 37, 52, 62] </ref> | i.e., objects that are not critical-section-based | are a viable alternative to lock-based schemes in such systems. Such objects are typically implemented using retry loops that are potentially unbounded.
Reference: [53] <author> L. Lamport. </author> <title> Specifying concurrent program modules. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(2) </volume> <pages> 190-222, </pages> <year> 1983. </year>
Reference-contexts: Other researchers have considered wait-free and lock-free implementations using instructions that are stronger than simple reads and writes. Implementations of various types of queues have been presented by Lamport <ref> [53] </ref>, by Herlihy and Wing [38], by Israeli and Rappoport [41], by Wing and Gong [81, 82], and by Michael and Scott [64]. Anderson and Woll [15] and Lanin and Shasha [56] present implementations for various set operations.
Reference: [54] <author> L. Lamport. </author> <title> On interprocess communication, parts 1 and 2. </title> <journal> Distributed Computing, </journal> <volume> 1 </volume> <pages> 77-101, </pages> <year> 1986. </year>
Reference-contexts: p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization. <p> For example, there exists an important special class of lock-free implementations known as wait-free implementations <ref> [36, 37, 67, 54] </ref> in which operations must satisfy a strong form of lock-freedom that precludes all waiting dependencies among tasks, including potentially unbounded retry loops. <p> Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [55] <author> B. W. Lampson and D. D. Redell. </author> <title> Experiences with processes and monitors in mesa. </title> <journal> Communications of the ACM, </journal> <volume> 23(2) </volume> <pages> 105-117, </pages> <year> 1980. </year>
Reference-contexts: The main shortcoming of these techniques is that they lack the flexibility to provide a general framework for object sharing in real-time systems. Lampson and Redell were the first to recognize priority inversion as a problem associated with using lock-based objects in priority-based systems <ref> [55] </ref>. A priority inversion occurs when a task is delayed by a lower-priority task that is inside a critical section. This problem is illustrated in Figure 2.2 (a). In Figure 2.2, up-arrows and down-arrows indicate task invocations and task completions, respectively. <p> The rest of this section deals with mechanisms for reducing blocking factors in lock-based schemes. Lampson and Redell were the first to solve the priority inversion problem using kernel support by associating with each resource R the priority of the highest-priority task that may lock that resource <ref> [55] </ref>. The priority of any task that accesses resource R is elevated to the priority associated with that resource. However, Lampson and Redell's work was targeted for the Mesa programming language; they did not provide a general solution to the priority inversion problem. <p> Later, Sha, Rajkumar, and Lehoczky considered this problem from a broader perspective of accessing lock-based objects in general priority-based systems [71]. Based on ideas presented in <ref> [55] </ref>, they developed several mechanisms for reducing priority inversion. Two such mechanisms were developed by them: the priority inheritance protocol (PIP) and the priority-ceiling-protocol (PCP) [71, 69].
Reference: [56] <author> V. Lanin and D. Shasha. </author> <title> Concurrent set manipulation without locking. </title> <booktitle> In Proceedings of the Seventh Annual ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 211-220. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: Implementations of various types of queues have been presented by Lamport [53], by Herlihy and Wing [38], by Israeli and Rappoport [41], by Wing and Gong [81, 82], and by Michael and Scott [64]. Anderson and Woll [15] and Lanin and Shasha <ref> [56] </ref> present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries [78, 79, 80]. Finally, Massalin and Pu have implemented an entire operating system using lock-free data structures such as lists, queues, and stacks [63].
Reference: [57] <author> J. P. Lehoczky, L. Sha, and Y. Ding. </author> <title> The rate monotonic scheduling algorithm: Exact characterization and average case behavior. </title> <booktitle> In Proceedings of the Tenth IEEE Symposium on Real-Time Systems, </booktitle> <pages> pages 166-171. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1989. </year> <month> 226 </month>
Reference-contexts: Although Liu and Layland's scheduling condition is appealing because of its simplicity, it is not very accurate and can lead to under-utilization of the processor. Later, Lehoczky, Sha, and Ding showed that the maximum achievable utilization under the RM scheme is close to 88% in practice <ref> [57] </ref>, thereby showing that the condition developed in [60] is not sufficiently accurate. Based on a critical instant argument, Lehoczky et al. also developed an exact schedulability test for synchronous, independent, periodic task sets [57]. <p> showed that the maximum achievable utilization under the RM scheme is close to 88% in practice <ref> [57] </ref>, thereby showing that the condition developed in [60] is not sufficiently accurate. Based on a critical instant argument, Lehoczky et al. also developed an exact schedulability test for synchronous, independent, periodic task sets [57]. <p> The resulting necessary condition for the 66 RM scheme differs slightly from that in <ref> [57] </ref> because we allow tasks to release their first jobs at arbitrary times. In particular, the floor functions within the summation expression in Theorem 3.1 are replaced by ceiling functions. The next theorem gives a sufficient scheduling condition for the DM scheme. <p> In order to more formally compare lock-free and wait-free objects, let us assume that objects are implemented using Herlihy's universal constructions. First, note that tasks that share wait-free objects can be viewed as independent tasks, i.e., the scheduling conditions derived in <ref> [57] </ref> and [60] apply. These conditions are the same as those given in Theorems 3.2 and 3.5, respectively, when s = 0. <p> Also, the new condition results in better predictions when there are fewer conflicts and when most operations are read-only. (Refer to the graphs in Figures 6.7 through 6.9.) BU (BCU) values for wait-free objects are given by "waitfree"; these values were obtained by using the RM scheduling condition in <ref> [57] </ref>. Experimental BCU values are not tabulated for this case because the RM condition in [57] is necessary and sufficient. Our simulations indicate that only the cost ratio parameter significantly affects relative performance. In examining the effects of various cost ratios, it is best to focus on BCU values. <p> when most operations are read-only. (Refer to the graphs in Figures 6.7 through 6.9.) BU (BCU) values for wait-free objects are given by "waitfree"; these values were obtained by using the RM scheduling condition in <ref> [57] </ref>. Experimental BCU values are not tabulated for this case because the RM condition in [57] is necessary and sufficient. Our simulations indicate that only the cost ratio parameter significantly affects relative performance. In examining the effects of various cost ratios, it is best to focus on BCU values. <p> The periods and execution times of the interrupt handlers are shown in Table 6.4. The formal model of the experimental system can be analyzed by using the schedul ing condition given in Theorem 3.2 when lock-free objects are used, and that given in <ref> [57] </ref> when lock-based objects are used. Note, however, that these conditions do not consider the 210 Table 6.4: Interrupt handler execution times and periods. Times are given in seconds. <p> Fortunately, this problem can be overcome by using techniques derived in [46]. The idea is to derive an expression that bounds the demand due to interrupt handlers in any given interval, and to then account for this demand in the scheduling conditions of Theorem 3.2 and <ref> [57] </ref>. Informally, we account for the cost of interrupt handlers as follows (see [46] for a more formal version of this argument). First, we define the term F (t) to be the cost of handling interrupts over an interval of length t. <p> F (t) j=1 t m Using (6.5), we can obtain a schedulability condition when the tasks synchronize using lock-based objects and the PCP. This involves modifying the condition presented in <ref> [57] </ref> to account for the demand placed by interrupt handlers, as given by (6.5).
Reference: [58] <author> J. Y. T. Leung and J. Whitehead. </author> <title> On the complexity of fixed-priority scheduling of periodic, real-time tasks. Performance Evaluation, </title> <booktitle> 2(4) </booktitle> <pages> 237-250, </pages> <year> 1982. </year>
Reference-contexts: Priority-based, preemptive scheduling schemes can be classified into static-priority and dynamic-priority schemes. Under static-priority scheduling, each task is assigned a distinct priority that does not change over time. Examples of such schemes include rate monotonic (RM) scheduling [60] and deadline monotonic (DM) scheduling <ref> [58] </ref>. Under dynamic-priority schemes, the priority of a task can vary over time. Examples of such schemes include earliest-deadline-first (EDF) scheduling [60] and least-laxity-first (LLF) scheduling [65]. In this dissertation, we only consider RM, DM, and EDF scheduling; these scheduling schemes are described using illustrated examples. <p> The period of a task scheduled under this scheme is assumed to be at least as large as that task's relative deadline. When a set of tasks is synchronous and independent, the DM scheme is an optimal static-priority scheduling scheme <ref> [58] </ref>, i.e., any task set that is schedulable under any other static-priority scheme is schedulable under the 13 DM scheme. The following example illustrates the working of the DM scheme. <p> For example, in order to ensure that sensor values are propagated to other tasks as soon as possible, a tracking task in a radar system may execute every 100 milliseconds but have a relative deadline of 30 milliseconds. Leung and Whitehead <ref> [58] </ref> showed that the DM scheme is an optimal static priority scheme when each task's relative deadline is at most the length of its period. However, they did not provide scheduling conditions for the DM scheme. <p> When task sets are asynchronous, the conditions for RM and DM scheduling are no longer both necessary and sufficient. This is because conditions that are necessary and sufficient for synchronous task sets to be schedulable are only sufficient for asynchronous task sets <ref> [21, 58] </ref>. 2.1.2 Dynamic-Priority Scheduling Conditions Under dynamic-priority schemes, a task's priority can change over time. Such schemes allow higher achievable processor utilization than static-priority scheme, but they entail higher run-time overhead compared to static-priority schemes. <p> These conditions assume that priority is assigned by the DM scheme <ref> [58] </ref>, in which tasks with 64 smaller relative deadlines have higher priorities. We also briefly consider the RM scheme, which is special case of DM scheduling. The following theorem gives a necessary scheduling condition for the DM scheme. <p> In both cases scheduling was performed using the DM scheduling algorithm <ref> [58] </ref>. Qualitatively, when queue synchronization was achieved using semaphores, approximately seven media samples were lost in the pipeline every second due to buffer overflow. In contrast, no media samples were lost when lock-free objects were used.
Reference: [59] <author> M. Li, J. Tromp, and P. Vitanyi. </author> <title> How to construct wait-free variables. </title> <booktitle> In Proceedings of International Colloquium on Automata, Languages, and Programming, </booktitle> <pages> pages 288-505, </pages> <year> 1989. </year>
Reference-contexts: Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [60] <author> C. Liu and J. Layland. </author> <title> Scheduling algorithms for multiprogramming in a hard real-time environment. </title> <journal> Journal of the ACM, </journal> <volume> 30 </volume> <pages> 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: Priority-based, preemptive scheduling schemes can be classified into static-priority and dynamic-priority schemes. Under static-priority scheduling, each task is assigned a distinct priority that does not change over time. Examples of such schemes include rate monotonic (RM) scheduling <ref> [60] </ref> and deadline monotonic (DM) scheduling [58]. Under dynamic-priority schemes, the priority of a task can vary over time. Examples of such schemes include earliest-deadline-first (EDF) scheduling [60] and least-laxity-first (LLF) scheduling [65]. <p> Examples of such schemes include rate monotonic (RM) scheduling <ref> [60] </ref> and deadline monotonic (DM) scheduling [58]. Under dynamic-priority schemes, the priority of a task can vary over time. Examples of such schemes include earliest-deadline-first (EDF) scheduling [60] and least-laxity-first (LLF) scheduling [65]. In this dissertation, we only consider RM, DM, and EDF scheduling; these scheduling schemes are described using illustrated examples. DM scheduling: Under the DM scheme, tasks with smaller relative deadlines are assigned higher priorities. <p> Under this scheme task periods need not be related to task deadlines, i.e., a task's period may be larger, smaller, or equal to its relative deadline. When tasks are independent, the EDF scheme is an optimal scheduling scheme <ref> [60] </ref> because it can successfully schedule any task set as long as the processor is not overloaded. The following example illustrate the working of the EDF scheme. Example 1.2: Consider a set of asynchronous periodic tasks fT 0 ; T 1 ; T 2 g scheduled under the EDF scheme. <p> As mentioned earlier, scheduling conditions provide a priori guarantees on the schedulability of real-time task sets | hard real-time systems require such a priori guarantees. The rest of this subsection deals with scheduling conditions for the RM, DM, and EDF scheduling schemes. 2.1.1 Static-Priority Scheduling Conditions In <ref> [60] </ref>, Liu and Layland developed a sufficiency condition for determining the schedulability of a synchronous, periodic, and independent task set scheduled under the RM scheme. They showed that, under the RM scheme, schedulability is related to the achievable worst-case processor utilization. <p> Later, Lehoczky, Sha, and Ding showed that the maximum achievable utilization under the RM scheme is close to 88% in practice [57], thereby showing that the condition developed in <ref> [60] </ref> is not sufficiently accurate. Based on a critical instant argument, Lehoczky et al. also developed an exact schedulability test for synchronous, independent, periodic task sets [57]. <p> Such schemes allow higher achievable processor utilization than static-priority scheme, but they entail higher run-time overhead compared to static-priority schemes. Of the existing dynamic-priority schemes, EDF and least-laxity-first (LLF) scheduling are the most well known <ref> [60, 65] </ref>. Under the LLF scheme, at every instant, the job with the smallest laxity is given highest priority. The laxity of a job J at time t is given by t d c, where d and 24 c denote J 's deadline and its unfulfilled computation requirement, respectively. <p> Hence, EDF scheduling is preferred to LLF scheduling in practical uniprocessor real-time systems. For this reason, EDF scheduling is the only dynamic-priority scheme considered in this dissertation. Liu and Layland were also the first to derive scheduling conditions for independent, periodic, synchronous task sets scheduled under the EDF scheme <ref> [60] </ref>. They showed that a set of N periodic tasks is schedulable iff the cumulative processor utilization of all tasks in the system is at most one. Formally, their scheduling conditions is as follows. <p> Note that we do not include the demand due to jobs J 0;2 , J 1;2 and J 2;1 because their deadlines are after time 25. 3.2 Preliminary Lemmas Before we present our scheduling conditions, we prove several lemmas used in the proofs of these conditions. In <ref> [60] </ref>, it is shown that for independent tasks (i.e., tasks that do not share objects), the longest response time of a task occurs at a critical instant of time, at which jobs of that task and all higher-priority tasks are released. <p> The following theorem gives a necessary scheduling condition for the EDF/NPD scheme. According to this theorem, a task set is schedulable only if processor utilization is at most one. This condition also holds when tasks periods are equal to their relative deadlines, and is identical to the condition in <ref> [60] </ref>. Theorem 3.3: (Necessity under EDF/NPD ) If set of periodic tasks that share lock-free objects is schedulable under the EDF/NPD scheme, then N1 X c i 1: Proof: Consider a set of tasks that is schedulable under the EDF/NPD scheme. <p> In order to more formally compare lock-free and wait-free objects, let us assume that objects are implemented using Herlihy's universal constructions. First, note that tasks that share wait-free objects can be viewed as independent tasks, i.e., the scheduling conditions derived in [57] and <ref> [60] </ref> apply. These conditions are the same as those given in Theorems 3.2 and 3.5, respectively, when s = 0.
Reference: [61] <author> M. Loui and H. Abu-Amara. </author> <title> Memory requirements for agreement among unreliable asynchronous processes. </title> <booktitle> Advances in Computing Research, </booktitle> <volume> 4 </volume> <pages> 163-183, </pages> <year> 1987. </year>
Reference-contexts: Loui and Abu-Amara <ref> [61] </ref> showed that the N -task consensus problem cannot be solved in a wait-free manner for N &gt; 1 in an asynchronous system using load and store instructions. Herlihy later extended these results to other primitives by classifying each primitive according to its consensus number [35, 36].
Reference: [62] <author> H. Massalin. </author> <title> Synthesis: An Efficient Implementation of Fundamental Operating System Services. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <address> New York, New York, </address> <year> 1992. </year>
Reference-contexts: Furthermore, in some lock-based schemes, certain operating system tables must be modified when mode changes occur [72]. 1.2 Lock-Free Objects In this dissertation, we consider an alternative approach to interprocess communication in real-time systems. In particular, we show that lock-free shared objects <ref> [22, 37, 52, 62] </ref> | i.e., objects that are not critical-section-based | are a viable alternative to lock-based schemes in such systems. Such objects are typically implemented using retry loops that are potentially unbounded. <p> What are typical values of s and r? A performance comparison of various lock-free objects is given by Massalin in <ref> [62] </ref>. Massalin reports that, given hardware support for primitives like compare-and-swap, s varies from 1.3 microseconds for a counter to 3.3 microseconds for a circular queue. In the absence of hardware support, such primitives can be simulated by a trap, adding an additional 4.2 microseconds. <p> The lock-based versions of these data structures were implemented under the EDF/DDM scheme. For objects other than skew heaps, 1 the object-specific lock-free implementations were based on implementations presented elsewhere. In particular, the read/write buffer, stack, and queue implementations are from <ref> [62] </ref>, and the linked list implementations are from [32]. Transaction-based lock-free object implementations are based on the transactional framework described in Chapter 5. However, unlike the implementation described in Chapter 5, the implementation used in our experiments did not employ the MWCAS implementation described in Section 4.6. <p> For a more detailed description of this system, we refer the interested reader to [77]. We evaluated the performance of the system when the shared queues were implemented using lock-free algorithms, wait-free algorithms, and lock-based techniques. We implemented lock-free queues by using the shared queue implementation given in <ref> [62] </ref> (modified to support the get length operation), and wait-free queues by using the wait-free universal construction given in [37]. Massalin's queue implementation requires CAS (needed for the dequeue operation) and CAS2 (needed for the enqueue operation), and Herlihy's 208 construction requires load-linked and store-conditional .
Reference: [63] <author> H. Massalin and C. Pu. </author> <title> A lock-free multiprocessor os kernel. </title> <type> Technical Report CUCS-005-91, </type> <institution> Columbia University, </institution> <address> New York, New York, </address> <year> 1991. </year>
Reference-contexts: Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries [78, 79, 80]. Finally, Massalin and Pu have implemented an entire operating system using lock-free data structures such as lists, queues, and stacks <ref> [63] </ref>. Chapter 3 Scheduling Conditions In this chapter, we derive conditions to predict the schedulability of task sets that access lock-free objects. The scheduling conditions we derive are essential for enabling the use of lock-free objects in hard real-time systems.
Reference: [64] <author> M. Michael and M. Scott. </author> <title> Simple, fast, and practical non-blocking and blocking concurrent queue algorithms. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 267-276. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1996. </year>
Reference-contexts: Implementations of various types of queues have been presented by Lamport [53], by Herlihy and Wing [38], by Israeli and Rappoport [41], by Wing and Gong [81, 82], and by Michael and Scott <ref> [64] </ref>. Anderson and Woll [15] and Lanin and Shasha [56] present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries [78, 79, 80].
Reference: [65] <author> A. K. Mok. </author> <title> Fundamental Design Problems of Distributed Systems for Hard Real-Time Environments. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, Mass., </address> <year> 1983. </year>
Reference-contexts: For this reason, substantial effort has been devoted to the problem of bounding the duration of priority inversions in real-time systems either by using kernel support [19, 26, 44, 69, 71] or by using scheduling techniques <ref> [29, 65, 83] </ref>. <p> Examples of such schemes include rate monotonic (RM) scheduling [60] and deadline monotonic (DM) scheduling [58]. Under dynamic-priority schemes, the priority of a task can vary over time. Examples of such schemes include earliest-deadline-first (EDF) scheduling [60] and least-laxity-first (LLF) scheduling <ref> [65] </ref>. In this dissertation, we only consider RM, DM, and EDF scheduling; these scheduling schemes are described using illustrated examples. DM scheduling: Under the DM scheme, tasks with smaller relative deadlines are assigned higher priorities. <p> Such schemes allow higher achievable processor utilization than static-priority scheme, but they entail higher run-time overhead compared to static-priority schemes. Of the existing dynamic-priority schemes, EDF and least-laxity-first (LLF) scheduling are the most well known <ref> [60, 65] </ref>. Under the LLF scheme, at every instant, the job with the smallest laxity is given highest priority. The laxity of a job J at time t is given by t d c, where d and 24 c denote J 's deadline and its unfulfilled computation requirement, respectively. <p> In his dissertation <ref> [65] </ref>, Mok proved a number of fundamental results that highlighted the complexity of lock-based real-time object sharing. In particular, he proved that the problem of deciding whether a schedule exists for a set of periodic tasks that only use semaphores to enforce mutual exclusion is NP-hard in the strong sense. <p> Requirement (ii) holds for most common scheduling policies, including RM, DM, and EDF scheduling and variations of these in which tasks are broken into phases that are allowed to have distinct priorities [33]. The only common scheduling policy that we know of that violates requirement (ii) is LLF scheduling <ref> [65] </ref>. Under LLF scheduling, the priority of a task invocation can change during its execution. Observe that requirements (i) and (ii) expressly preclude the use of locking within a processor.
Reference: [66] <author> R. Newman-Wolfe. </author> <title> A protocol for wait-free, atomic, multi-reader shared variables. </title> <booktitle> In Proceedings of the Sixth Annual Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 232-248, </pages> <year> 1987. </year>
Reference-contexts: Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [67] <author> G. L. Peterson. </author> <title> Concurrent reading while writing. </title> <journal> ACM Trans. on Programm. Lang. Syst., </journal> <volume> 5(1) </volume> <pages> 46-55, </pages> <year> 1983. </year>
Reference-contexts: p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization. <p> For example, there exists an important special class of lock-free implementations known as wait-free implementations <ref> [36, 37, 67, 54] </ref> in which operations must satisfy a strong form of lock-freedom that precludes all waiting dependencies among tasks, including potentially unbounded retry loops. <p> Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [68] <author> G. L. Peterson and J. Burns. </author> <title> Concurrent reading while writing ii: The multi-writer case. </title> <booktitle> In Proceedings of the 28th Annual ACM Symposium on Foundation of Computer Science. ACM, </booktitle> <year> 1987. </year>
Reference-contexts: p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization. <p> Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [69] <author> R. Rajkumar. </author> <title> Synchronization In Real-Time Systems APriority Inheritance Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: For this reason, substantial effort has been devoted to the problem of bounding the duration of priority inversions in real-time systems either by using kernel support <ref> [19, 26, 44, 69, 71] </ref> or by using scheduling techniques [29, 65, 83]. <p> An example of a mechanism that uses kernel support to bound the duration of priority inversion is the priority inheritance protocol (PIP) <ref> [69, 71] </ref>. Figure 1.1 (b) illustrates the working of the PIP on the task set depicted in Figure 1.1 (a). <p> Based on ideas presented in [55], they developed several mechanisms for reducing priority inversion. Two such mechanisms were developed by them: the priority inheritance protocol (PIP) and the priority-ceiling-protocol (PCP) <ref> [71, 69] </ref>. Under the PIP, if a task T is blocked by a lower-priority task T 0 that is accessing some object, then T 0 executes at T 's priority level for the remainder of its object access, i.e., T 0 inherits T 's priority. <p> the performance of the different object sharing schemes in an actual application | a desktop videoconferencing system. 179 6.1 Formal Comparison The formal comparison presented in this section is based upon the scheduling conditions presented in Sections 3.3 and 3.4, and scheduling conditions for lock-based schemes found in the literature <ref> [44, 69] </ref>. In deriving the scheduling conditions in Sections 3.3 and 3.4, we assume that the execution of the retry-loops of the different objects in the system are identical. We also assume that tasks do not invoke multi-object operations. <p> the processor, i.e., it does not including blocking terms associated with priority inversions in the lock-based case or interference costs in the lock-free case.) 6.1.1 Static-Priority Scheduling We begin by comparing the overhead of lock-free object sharing under RM scheduling with the overhead of the lock-based priority ceiling protocol (PCP) <ref> [69] </ref>. When tasks synchronize by locking, a higher-priority job can be blocked by a lower-priority job that accesses a common object; the maximum blocking time is called the blocking factor . Under the PCP, the worst-case blocking time equals the time required to execute the longest crit 180 ical section. <p> Since we do not consider nested critical sections, the blocking factor equals r, the time to execute a single critical section. We denote the schedulability condition for periodic tasks using the PCP by the predicate sched PCP , which on the basis of the analysis in <ref> [69] </ref>, is defined as follows. sched PCP h8i 9t : 0 &lt; t p i : r + P i l p j (u j + m j r) ti In the above equation, the first term on the left-hand side represents the blocking factor. <p> Predicted BU (BCU) values for lock-based objects are given by "blocking predicted". Values for this case were obtained by using the scheduling condition given in <ref> [69] </ref>. BU (BCU) values predicted by the scheduling conditions presented in Section 3.5 and in Section 3.3 are given by "lockfree predicted new" and "lock-free predicted old", respectively. Observe that the RM scheduling condition presented in Section 3.5 is much tighter than the one presented in Section 3.3. <p> Lock-based schemes also perform very poorly in multiprocessor systems because the blocking factors entailed by a task can be significant <ref> [69] </ref>. As demonstrated in [6], wait-free object implementations that use the cyclic helping technique, in conjunction with incremental helping, can significantly reduce helping overhead on a multiprocessor real-time system. Under the cyclic-helping scheme, processors in a system are thought of as if they were part of a logical ring.
Reference: [70] <author> S. Ramamurthy, M. Moir, and J. H. Anderson. </author> <title> Real-time object sharing with minimal support. </title> <booktitle> In Proceedings of the Fifteenth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 233-242. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1996. </year>
Reference-contexts: Experimental results that compare and contrast the behavior of lock-free and lock-based schemes are presented in Chapter 6. Finally, conclusions and a discussion of future directions for this research appear in Chapter 7. (This dissertation includes work that is based on previously published work <ref> [9, 11, 12, 13, 14, 70] </ref>.) Chapter 2 Background and Related Work In this chapter, we provide background material on real-time systems and lock-free objects. First, we present scheduling conditions for various real-time scheduling schemes. Then, we describe various lock-based object-sharing schemes used in conventional real-time systems.
Reference: [71] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky. </author> <title> Priority inheritance protocols: An approach to real-time system synchronization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(9) </volume> <pages> 1175-1185, </pages> <year> 1990. </year>
Reference-contexts: For this reason, substantial effort has been devoted to the problem of bounding the duration of priority inversions in real-time systems either by using kernel support <ref> [19, 26, 44, 69, 71] </ref> or by using scheduling techniques [29, 65, 83]. <p> An example of a mechanism that uses kernel support to bound the duration of priority inversion is the priority inheritance protocol (PIP) <ref> [69, 71] </ref>. Figure 1.1 (b) illustrates the working of the PIP on the task set depicted in Figure 1.1 (a). <p> However, Lampson and Redell's work was targeted for the Mesa programming language; they did not provide a general solution to the priority inversion problem. Later, Sha, Rajkumar, and Lehoczky considered this problem from a broader perspective of accessing lock-based objects in general priority-based systems <ref> [71] </ref>. Based on ideas presented in [55], they developed several mechanisms for reducing priority inversion. Two such mechanisms were developed by them: the priority inheritance protocol (PIP) and the priority-ceiling-protocol (PCP) [71, 69]. <p> Based on ideas presented in [55], they developed several mechanisms for reducing priority inversion. Two such mechanisms were developed by them: the priority inheritance protocol (PIP) and the priority-ceiling-protocol (PCP) <ref> [71, 69] </ref>. Under the PIP, if a task T is blocked by a lower-priority task T 0 that is accessing some object, then T 0 executes at T 's priority level for the remainder of its object access, i.e., T 0 inherits T 's priority. <p> In Figure 2.2 (c), extra context switches occur at times t 0 , t 1 , t 2 , and t 3 . If context switches are expensive, the PCP can result in loss of predictability because the currently-known scheduling analysis <ref> [71] </ref> for the PCP ignores the effect of these extra context switches. Furthermore, these additional context switches can significantly increase blocking factors. The stack resource policy (SRP) [19] eliminates additional context switches by delaying the execution of a task until all required resources become available. <p> Sha, Rajkumar, and Lehoczky <ref> [71] </ref> developed a sufficient condition for determining the schedulability of a 33 set of periodic tasks that access lock-based objects and that are scheduled under the RM scheme.
Reference: [72] <author> L. Sha, R. Rajkumar, J. P. Lehoczky, and K. Ramamritham. </author> <title> Mode change protocols for priority-driven preemptive scheduling. </title> <journal> Real-Time Systems Journal, </journal> <volume> 1(1) </volume> <pages> 243-264, </pages> <year> 1989. </year>
Reference-contexts: This is because, in order to guarantee bounded priority inversion and freedom from deadlock during mode changes, these mode-change protocols must determine a specific order in which tasks can be added or removed from the system <ref> [72] </ref>. Furthermore, in some lock-based schemes, certain operating system tables must be modified when mode changes occur [72]. 1.2 Lock-Free Objects In this dissertation, we consider an alternative approach to interprocess communication in real-time systems. <p> in order to guarantee bounded priority inversion and freedom from deadlock during mode changes, these mode-change protocols must determine a specific order in which tasks can be added or removed from the system <ref> [72] </ref>. Furthermore, in some lock-based schemes, certain operating system tables must be modified when mode changes occur [72]. 1.2 Lock-Free Objects In this dissertation, we consider an alternative approach to interprocess communication in real-time systems. In particular, we show that lock-free shared objects [22, 37, 52, 62] | i.e., objects that are not critical-section-based | are a viable alternative to lock-based schemes in such systems.
Reference: [73] <author> N. Shavit and D. Touitou. </author> <title> Software transactional memory. </title> <booktitle> In Proceedings of the Fourteenth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 204-213. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1995. </year> <month> 227 </month>
Reference-contexts: For example, using nested critical sections, a task can atomically dequeue an element from one shared queue and enqueue that element in another shared queue. To achieve similar functionality in a lock-free system, universal constructions have been proposed that allow a task to perform operations on multiple objects simultaneously <ref> [8, 73] </ref>. Unfortunately, these implementations entail high algorithmic overhead, and are therefore too expensive to be competitive with nested critical sections in real-time systems. <p> For example, in order to transfer the contents of one shared queue to another, a task acquires locks for these two objects in a specific order, performs the transfer, and then releases the locks. In contrast, universal lock-free constructions that allow updates to multiple objects <ref> [7, 73] </ref> | the lock-free counterpart to nested critical sections | are not competitive with nested critical sections in real-time systems. Another advantage of using lock-based schemes is that, with little effort, any sequential object implementation can be converted to its concurrent version. <p> The semantics of SC are undefined if task T p has not previously executed a LL instruction. 2.4.3 Universal Constructions of Lock-Free Objects In recent years, several groups of researchers have presented methods for automat ically "transforming" sequential object implementations into lock-free ones <ref> [20, 35, 36, 37, 73] </ref>. These methods are called universal constructions. A universal construction relieves the object designer of the need to reason about concurrency, thereby greatly simplifying the task of providing a correct lock-free implementation for a particular shared object.
Reference: [74] <author> A. Singh, J. Anderson, and M. Gouda. </author> <title> The elusive atomic register, revisited. </title> <booktitle> In Proceedings of the Sixth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 206-221. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1987. </year>
Reference-contexts: p x i &lt; t &lt; p i : CS i (t) + IH (t) + c i + j=0 t1+p j l j k (2.12) 38 2.4 Lock-Free Object Implementations Lock-free shared objects have been proposed as viable alternatives to lock-based objects in general asynchronous systems by various researchers <ref> [1, 3, 4, 36, 37, 49, 54, 67, 68, 74] </ref>. In this dissertation, we use the term "lock-free" to refer to object implementations based on an unbounded retry loop structure like that depicted in Figure 1.2. 3 Some lock-free implementations do not adhere to this characterization.
Reference: [75] <author> A. Singh, J. Anderson, and M. Gouda. </author> <title> The elusive atomic register. </title> <journal> Journal of the ACM, </journal> <volume> 41(2) </volume> <pages> 311-339, </pages> <year> 1994. </year>
Reference-contexts: Some specific object implementations are listed below. Many researchers have studied implementations of various kinds of wait-free shared objects using only read/write registers. These implementations include constructions of complex registers from simpler registers <ref> [23, 24, 49, 50, 54, 59, 66, 67, 68, 75] </ref>; atomic snapshots that allow multiple variables to be read atomically; [1, 3, 17], algorithms for maintaining timestamps [25, 28]; and mechanisms for implementing any object whose oper 8 The MWSC primitive must be implemented in software because it is not supported
Reference: [76] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Self adjusting binary trees. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Theory of Computing, </booktitle> <pages> pages 52-59, </pages> <year> 1983. </year>
Reference-contexts: For most simple data structures like read/write buffers, queues, linked lists, and stacks, s is often simply the cost of a simple, straight-line code sequence. For more complex data structures like skew heaps <ref> [76] </ref> | a data structure similar to a balanced heap | and balanced trees, a lock-free implementation would be more complicated, and corresponding s values might be relatively high.
Reference: [77] <author> D. L. Stone. </author> <title> Managing the Effect of Delay Jitter on the Display of Live Continuous Media. </title> <type> PhD thesis, </type> <institution> University of North Carolina, Chapel Hill, North Carolina, </institution> <year> 1995. </year>
Reference-contexts: terms IH (t) and CS i (t) in the left-hand side of the inequality in Condition (2.4). (A similar condition for the DM scheme looks identical that for the RM scheme with one small difference: t ranges from 0 to l i instead of 0 to p i .) In <ref> [77] </ref>, Stone adapted the conditions in [46] for EDF/NPD scheduling to account for context switching and interrupt handling costs, when tasks access tasks under the EDF/DDM scheme; these conditions are stated below. <p> The objects were implemented under the YARTOS kernel developed at UNC <ref> [47, 77] </ref>, on a 66-MHz, 80486-based IBM PC. <p> For a more detailed description of this system, we refer the interested reader to <ref> [77] </ref>. We evaluated the performance of the system when the shared queues were implemented using lock-free algorithms, wait-free algorithms, and lock-based techniques. <p> This is result is predicted by the formal analysis of the system, which we now present. Our analysis of the EDF/DDM scheme is based upon the following scheduling condition, which is proved in <ref> [77] </ref>. ( j=1 c j =p j + j=1 e j =v j 1) ^ P N j p j c j + j=1 t m h8i; t : p 1 &lt; t &lt; p i : r + j=1 t1l j +p j k P Q l v j e
Reference: [78] <author> J. Valois. </author> <title> Implementing lock-free queues. </title> <booktitle> In Proceedings of the Seventh International Conference on Parallel and Distributed Systems, </booktitle> <pages> pages 64-69, </pages> <year> 1994. </year>
Reference-contexts: Anderson and Woll [15] and Lanin and Shasha [56] present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries <ref> [78, 79, 80] </ref>. Finally, Massalin and Pu have implemented an entire operating system using lock-free data structures such as lists, queues, and stacks [63]. Chapter 3 Scheduling Conditions In this chapter, we derive conditions to predict the schedulability of task sets that access lock-free objects.
Reference: [79] <author> J. Valois. </author> <title> Lock-Free Data Structures. </title> <type> PhD thesis, </type> <institution> Renesselaer Polytechnic Institute, </institution> <address> Troy, New York, </address> <year> 1995. </year>
Reference-contexts: Anderson and Woll [15] and Lanin and Shasha [56] present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries <ref> [78, 79, 80] </ref>. Finally, Massalin and Pu have implemented an entire operating system using lock-free data structures such as lists, queues, and stacks [63]. Chapter 3 Scheduling Conditions In this chapter, we derive conditions to predict the schedulability of task sets that access lock-free objects.
Reference: [80] <author> J. Valois. </author> <title> Lock-free linked lists using compare-and-swap. </title> <booktitle> In Proceedings of the Fourteenth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 214-222. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Anderson and Woll [15] and Lanin and Shasha [56] present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries <ref> [78, 79, 80] </ref>. Finally, Massalin and Pu have implemented an entire operating system using lock-free data structures such as lists, queues, and stacks [63]. Chapter 3 Scheduling Conditions In this chapter, we derive conditions to predict the schedulability of task sets that access lock-free objects.
Reference: [81] <author> J. Wing and C. Gong. </author> <title> A library of concurrent objects and their proofs of correctness. </title> <type> Technical Report CMU-CS-90-151, </type> <institution> Carnegie Mellon University, Pittsburg, </institution> <address> PA, </address> <year> 1990. </year>
Reference-contexts: Other researchers have considered wait-free and lock-free implementations using instructions that are stronger than simple reads and writes. Implementations of various types of queues have been presented by Lamport [53], by Herlihy and Wing [38], by Israeli and Rappoport [41], by Wing and Gong <ref> [81, 82] </ref>, and by Michael and Scott [64]. Anderson and Woll [15] and Lanin and Shasha [56] present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries [78, 79, 80].
Reference: [82] <author> J. Wing and C. Gong. </author> <title> Testing and verifying concurrent objects. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 17(2) </volume> <pages> 164-182, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Other researchers have considered wait-free and lock-free implementations using instructions that are stronger than simple reads and writes. Implementations of various types of queues have been presented by Lamport [53], by Herlihy and Wing [38], by Israeli and Rappoport [41], by Wing and Gong <ref> [81, 82] </ref>, and by Michael and Scott [64]. Anderson and Woll [15] and Lanin and Shasha [56] present implementations for various set operations. Valois presents lock-free implementations for various data structures, including queues, lists, trees, and dictionaries [78, 79, 80].
Reference: [83] <author> J. Xu and D. L. Parnas. </author> <title> Scheduling processes with release times, deadlines, precedence, and exclusion relations. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 16(3) </volume> <pages> 360-369, </pages> <year> 1990. </year>
Reference-contexts: For this reason, substantial effort has been devoted to the problem of bounding the duration of priority inversions in real-time systems either by using kernel support [19, 26, 44, 69, 71] or by using scheduling techniques <ref> [29, 65, 83] </ref>.
References-found: 83

