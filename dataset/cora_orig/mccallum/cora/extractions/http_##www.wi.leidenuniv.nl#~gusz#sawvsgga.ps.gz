URL: http://www.wi.leidenuniv.nl/~gusz/sawvsgga.ps.gz
Refering-URL: http://www.wi.leidenuniv.nl/~jvhemert/csp-ea/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: jvhemert@wi.leidenuniv.nl  gusz@wi.leidenuniv.nl  
Title: Comparison of the SAW-ing Evolutionary Algorithm and the Grouping Genetic Algorithm for Graph Coloring 1  
Author: J.I. van Hemert A.E. Eiben 
Date: November 1997  
Affiliation: Leiden University  
Abstract: 1 This report is also available through http://www.wi.leidenuniv.nl/~gusz/ sawvsgga.ps.gz 
Abstract-found: 1
Intro-found: 1
Reference: [BHA92] <author> J.C. Bean and A.B. Hadj-Alouane. </author> <title> A dual genetic algorithm for bounded integer programs. </title> <type> Tr 92-53, </type> <institution> Department of Industrial and Operations Engineering, The University of Michigan, </institution> <year> 1992. </year>
Reference-contexts: An area related to solving CSPs is that of solving constrained optimization problems by evolutionary algorithms. Michalewicz and Schoenauer give an extensive overview of this field in [ZM96]. In this survey a technical report from 1992 forms the earliest example <ref> [BHA92] </ref>, where penalties are adapted. In [MA95] and [JH94] mechanisms for varying penalties according to a predefined schedule are reported. 2.2 The Grouping Genetic Algorithm The implementation of the GGA will look like the pseudo-code as shown in Figure 2.3.
Reference: [DBB94] <author> G. Dozier, J. Bowen, and D. Bahler. </author> <title> Solving small and large constraint satisfaction problems using a heuristic-based microgenetic algorithms. </title> <booktitle> In IEEE [IEE94], </booktitle> <pages> pages 306-311. </pages>
Reference-contexts: A conceptual difference between breakout methods and SAW-ing is that SAW-ing periodically modifies weights, while the breakout method is called if the search gets stuck in a local optimum. The micro-genetic algorithm of Dozier et al. for solving random CSPs uses breakout in this sense <ref> [DBB94, DBB95] </ref>. The idea to modify weights of constraints in CSPs is also used for solving satisfiability problems in a traditional AI approach [Fra96] and in an evolutionary algorithm [EvdH97b]. An area related to solving CSPs is that of solving constrained optimization problems by evolutionary algorithms.
Reference: [DBB95] <author> G. Dozier, J. Bowen, and D. Bahler. </author> <title> Solving randomly generated constraint satisfaction problems using a micro-evolutionary hybrid that evolves a population of hill-climbers. </title> <booktitle> In Proceedings of the 2nd IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 614-619. </pages> <publisher> IEEE Press, </publisher> <year> 1995. </year>
Reference-contexts: A conceptual difference between breakout methods and SAW-ing is that SAW-ing periodically modifies weights, while the breakout method is called if the search gets stuck in a local optimum. The micro-genetic algorithm of Dozier et al. for solving random CSPs uses breakout in this sense <ref> [DBB94, DBB95] </ref>. The idea to modify weights of constraints in CSPs is also used for solving satisfiability problems in a traditional AI approach [Fra96] and in an evolutionary algorithm [EvdH97b]. An area related to solving CSPs is that of solving constrained optimization problems by evolutionary algorithms.
Reference: [ERR94] <author> A.E. Eiben, P.-E. Raue, and Zs. Ruttkay. </author> <title> Repairing, adding constraints and learning as a means of improving GA performance on CSPs. </title> <editor> In J.C. Bioch and S.H. Nienhuiys-Cheng, editors, </editor> <booktitle> Proceedings of the 4th Belgian-Dutch Conference on Machine Learning, number 94-05 in EUR-CS, </booktitle> <pages> pages 112-123. </pages> <publisher> Erasmus University Press, </publisher> <year> 1994. </year>
Reference-contexts: Our first attempts to modify weights in a constraint satisfaction problem (CSP) depending on the progress of a genetic algorithm solving the problem were reported in <ref> [ERR94, ERR95] </ref>. Technically speaking, the idea is very similar to the breakout method as introduced by Morris [Mor93], but has been developed independently.
Reference: [ERR95] <author> A.E. Eiben, P.-E. Raue, and Zs. Ruttkay. </author> <title> Constrained problems. </title> <editor> In L. Chambers, editor, </editor> <booktitle> Practical Handbook of Genetic Algorithms, </booktitle> <pages> pages 307-365. </pages> <publisher> CRC Press, </publisher> <year> 1995. </year>
Reference-contexts: Our first attempts to modify weights in a constraint satisfaction problem (CSP) depending on the progress of a genetic algorithm solving the problem were reported in <ref> [ERR94, ERR95] </ref>. Technically speaking, the idea is very similar to the breakout method as introduced by Morris [Mor93], but has been developed independently.
Reference: [EVdH96] <author> A.E. Eiben and J.K. Van der Hauw. </author> <title> Graph coloring with adaptive evolutionary algorithms. </title> <type> Technical Report TR-96-11, </type> <institution> Leiden University, </institution> <month> August </month> <year> 1996. </year> <note> Also available as http:// www.wi.leidenuniv.nl/~gusz/graphcol.ps.gz. </note>
Reference-contexts: Introduction The purpose of this investigation is to extend a study by Eiben and van der Hauw on applying evolutionary algorithms to graph coloring, <ref> [vdH96, EVdH96, EvdH97a] </ref>. In particular, the EA based on Stepwise Adaptation of Weights (SAW) used by Eiben and van der Hauw are compared to the Grouping Genetic Algorithm (GGA) of Falkenauer [Fal94a]. <p> This report starts with a brief description of the SAW-ing EA and the grouping genetic algorithm in Chapter 2. The experimental setup, including the problem instances and the algorithm parameters, is presented in Chapter 3. Following the line of research in <ref> [vdH96, EVdH96, EvdH97a] </ref>, we perform a big comparison on three different graph topologies (arbitrary, equi-partite, and flat graphs), three different graph sizes (200, 500, and 1000 nodes), and graph instances for different edge connectivity values around the phase transition for each combination of topology and size. <p> Let us note that quite a lot of technical terms and notations are adopted from the literature, most of which are not explained in this document. Therefore, it is advised to read <ref> [EVdH96] </ref> and [Fal94a]. <p> Therefore, it is advised to read [EVdH96] and [Fal94a]. Furthermore, general knowledge on graph coloring and evolutionary algorithms is assumed. 1 Available from ftp://ftp.cs.ualberta.ca/pub/joe/GraphGenerator/generate.tar.gz 2 Chapter 2 The SAW-ing EA and the Grouping Genetic Algorithm 2.1 The SAW-ing evolutionary algorithm The evolutionary algorithm used in the experiments in <ref> [vdH96, EVdH96, EvdH97a] </ref> is based on a steady-state GA using order-based representation, 2-tournament selection and worst-fitness replacement strategy. The general outlines of a steady state evolutionary algorithm are shown in Figure 2.1. Using order-based representation the individuals are permutations and special operators are used to recombine and mutate permutations. <p> The experimental study reported in <ref> [EVdH96] </ref> disclosed that an algorithm variant using population size 1 and only mutation performs best. By the lack of crossover and the minimal population size, this hardly can be called a genetic algorithm, therefore we use the more general term evolutionary algorithm. <p> The experiment is labeled with the number 9 (the number of the corresponding table containing results for the SAW-ing EA in <ref> [EVdH96] </ref>); Table 3.3 gives an of overview of details. 8 Variable Value Population size 50 Allele mutation probability 0:1 Crossover N c = 8 Mutation N m = 12 Inversion N i = 12 Table 3.2: The Grouping Genetic Algorithm parameters. reference G type nodes edge prob runs T max seed <p> gives an of overview of details. 8 Variable Value Population size 50 Allele mutation probability 0:1 Crossover N c = 8 Mutation N m = 12 Inversion N i = 12 Table 3.2: The Grouping Genetic Algorithm parameters. reference G type nodes edge prob runs T max seed table 9 <ref> [EVdH96] </ref> equi 1000 0:01 25 300000 f0; 1; 2; 3g Table 3.3: First experiment: initial comparison of the SAW-ing EA and the GGA. The second comparison consists of nine subexperiments. <p> The edge probability is varied within a subexperiment with a stepsize, the exact values can be found in Table 3.4. Every subexperiment is labeled with a figure number between 25 and 33, these are the same figure numbers of the results from <ref> [EVdH96] </ref>. reference [EVdH96] G type nodes edge prob step size runs T max fi10 5 seed fig 25 arbit 200 0:005 ! 0:1 0.005 100 3 5 fig 26 arbit 500 0:002 ! 0:05 0.004 50 3 5 fig 27 arbit 1000 0:002 ! 0:03 0.002 25 3 5 fig 28 <p> The edge probability is varied within a subexperiment with a stepsize, the exact values can be found in Table 3.4. Every subexperiment is labeled with a figure number between 25 and 33, these are the same figure numbers of the results from <ref> [EVdH96] </ref>. reference [EVdH96] G type nodes edge prob step size runs T max fi10 5 seed fig 25 arbit 200 0:005 ! 0:1 0.005 100 3 5 fig 26 arbit 500 0:002 ! 0:05 0.004 50 3 5 fig 27 arbit 1000 0:002 ! 0:03 0.002 25 3 5 fig 28 equi 200 <p> Two constants, 8 and 10, are chosen for the experiment. Table 3.5 sums up all the exact experiment information. Just as in the previous experiment the experiment is labeled with the figure numbers from <ref> [EVdH96] </ref> for easy references. reference [EVdH96] G type nodes edge prob runs T max fi10 5 seed fig 34, 36 equi f50; 250; 500; : : : ; 1500g 8:0=n 25 10 5 fig 34, 35 equi f50; 250; 500; : : : ; 1500g 10:0=n 50 5 5 Table 3.5: <p> Two constants, 8 and 10, are chosen for the experiment. Table 3.5 sums up all the exact experiment information. Just as in the previous experiment the experiment is labeled with the figure numbers from <ref> [EVdH96] </ref> for easy references. reference [EVdH96] G type nodes edge prob runs T max fi10 5 seed fig 34, 36 equi f50; 250; 500; : : : ; 1500g 8:0=n 25 10 5 fig 34, 35 equi f50; 250; 500; : : : ; 1500g 10:0=n 50 5 5 Table 3.5: Third experiment: comparing computational complexity.
Reference: [EvdH97a] <author> A.E. Eiben and J.K. van der Hauw. </author> <title> Adaptive penalties for evolutionary graph-coloring. </title> <editor> In J.K. Hao et al., editor, </editor> <booktitle> Proceedings of Evolution Artificielle'97, </booktitle> <publisher> LNCS. Springer, </publisher> <address> Berlin, </address> <year> 1997. </year> <note> in press. </note>
Reference-contexts: Introduction The purpose of this investigation is to extend a study by Eiben and van der Hauw on applying evolutionary algorithms to graph coloring, <ref> [vdH96, EVdH96, EvdH97a] </ref>. In particular, the EA based on Stepwise Adaptation of Weights (SAW) used by Eiben and van der Hauw are compared to the Grouping Genetic Algorithm (GGA) of Falkenauer [Fal94a]. <p> This report starts with a brief description of the SAW-ing EA and the grouping genetic algorithm in Chapter 2. The experimental setup, including the problem instances and the algorithm parameters, is presented in Chapter 3. Following the line of research in <ref> [vdH96, EVdH96, EvdH97a] </ref>, we perform a big comparison on three different graph topologies (arbitrary, equi-partite, and flat graphs), three different graph sizes (200, 500, and 1000 nodes), and graph instances for different edge connectivity values around the phase transition for each combination of topology and size. <p> Therefore, it is advised to read [EVdH96] and [Fal94a]. Furthermore, general knowledge on graph coloring and evolutionary algorithms is assumed. 1 Available from ftp://ftp.cs.ualberta.ca/pub/joe/GraphGenerator/generate.tar.gz 2 Chapter 2 The SAW-ing EA and the Grouping Genetic Algorithm 2.1 The SAW-ing evolutionary algorithm The evolutionary algorithm used in the experiments in <ref> [vdH96, EVdH96, EvdH97a] </ref> is based on a steady-state GA using order-based representation, 2-tournament selection and worst-fitness replacement strategy. The general outlines of a steady state evolutionary algorithm are shown in Figure 2.1. Using order-based representation the individuals are permutations and special operators are used to recombine and mutate permutations.
Reference: [EvdH97b] <author> A.E. Eiben and J.K. van der Hauw. </author> <title> Solving 3-SAT with adaptive Genetic Algorithms. </title> <booktitle> In Proceedings of the 4th IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 81-86. </pages> <publisher> IEEE Press, </publisher> <year> 1997. </year>
Reference-contexts: The micro-genetic algorithm of Dozier et al. for solving random CSPs uses breakout in this sense [DBB94, DBB95]. The idea to modify weights of constraints in CSPs is also used for solving satisfiability problems in a traditional AI approach [Fra96] and in an evolutionary algorithm <ref> [EvdH97b] </ref>. An area related to solving CSPs is that of solving constrained optimization problems by evolutionary algorithms. Michalewicz and Schoenauer give an extensive overview of this field in [ZM96]. In this survey a technical report from 1992 forms the earliest example [BHA92], where penalties are adapted.
Reference: [Fal94a] <author> E. Falkenauer. </author> <title> A new representation and operators for genetic algorithms applied to grouping problems. </title> <journal> Evolutionary Computation, </journal> <volume> 2(2) </volume> <pages> 123-144, </pages> <year> 1994. </year>
Reference-contexts: In particular, the EA based on Stepwise Adaptation of Weights (SAW) used by Eiben and van der Hauw are compared to the Grouping Genetic Algorithm (GGA) of Falkenauer <ref> [Fal94a] </ref>. Applying the GGA for graph coloring is motivated by the fact that graph coloring can be seen as a specific kind of grouping problem and the GGA is specifically designed to handle grouping problems. <p> Experimental results with the GGA, however, are limited to the bin-packing and piling problems, where it proves to be superior to other methods <ref> [FD92, Fal94a, Fal95, Fal96] </ref>. The results of the SAW-ing EA will be retrieved from the experiments done earlier, while the GGA will be implemented from scratch. The GGA reuses the part from the implementation of the SAW-ing algorithm that reads in the problem instances. <p> Let us note that quite a lot of technical terms and notations are adopted from the literature, most of which are not explained in this document. Therefore, it is advised to read [EVdH96] and <ref> [Fal94a] </ref>. <p> The reason for this is to keep the genetic algorithm used in the experiments as close as possible to the ones used in the experiments done in <ref> [Fal94a] </ref>. To initialize the population the same first-fit heuristic is used on every individual, as will be explained in Section 2.4. The graph that has to be colored can be seen as a list of nodes. First, at random a node is selected from this list to color. <p> individuals deleted Stop-criterion T max fitness evaluations or optimum solution found Insertion heuristic first-fit Table 2.1: The Grouping Genetic Algorithm parameters. 2.3 Representation of the problem The representation used in the GGA to represent the Graph Coloring problem is analogous to the representation used in the bin packing problem in <ref> [Fal94a] </ref>. If we see the bins as the colors and the various sized objects as the nodes in our Graph Coloring problem, we than have a way to represent the Graph Coloring problem. One chromosome will consist of two parts. <p> It then continues coloring the next uncolored node, an so on until all the nodes are colored. 2.4.2 Crossover The crossover operator used is the general crossover method for GGAs from <ref> [Fal94a] </ref> combined with some simple heuristic functions. Here follows an explanation of this method with an accompanied example. 1: Copy parent 1 to child 1 and copy parent 2 to child 2. Select at random two crossing sites, delimiting the crossing section, in each of the two parents' group part. <p> Therefore, the parameters for our GGA are almost the same as in <ref> [Fal94a] </ref>. At some points, however, we deviate from Falke-nauers setup, e.g. here a population size of 50 is used, while in [Fal94a] population sizes 47 and 49 are applied. <p> Therefore, the parameters for our GGA are almost the same as in <ref> [Fal94a] </ref>. At some points, however, we deviate from Falke-nauers setup, e.g. here a population size of 50 is used, while in [Fal94a] population sizes 47 and 49 are applied. Furthermore, to determine the best parameters for the GGA a number of parameter settings are created where the number of crossovers and the number of mutations and inversions vary. <p> In a number of articles Falkenauer defines the notion of grouping problems, characterized by the property that a set of objects has to be partitioned (i.e. divided into disjoint groups) in such a way that certain constraints hold and a cost function is minimized, <ref> [Fal94a, Fal94b, Fal95] </ref>. Graph coloring is explicitly mentioned as an example where the constraints forbid having connected nodes in different groups and the cost function is the number of groups. Then general arguments are given to show that context sensitive genetic operators 1 should perform better than standard `blind' operators. <p> Some small testing has been done with a partial implementation of these heuristics, which confirmed these expectations. Another alteration to the GGA could be different mutation methods. Some methods are suggested by Falkenhauer <ref> [Fal94a] </ref>, like randomly removing objects from groups (uncoloring nodes in the case of graph coloring), and reinserting them afterwards. The probably most promising idea is to combine the GGA with the SAW-ing method. <p> This can than be used to form the fitness function as shown in Function 6.1. f k (x) = l k + j=k+1 18 Appendix A The program GC-GGA A.1 A short word This program, called Graph Coloring Grouping Genetic Algorithm (GC-GGA), implements the evolutionary algorithm proposed by Falkenhauer in <ref> [Fal94a] </ref> to color graphs called the Grouping Genetic Algorithm. It uses a graph generator made by J. Culberson, which can be found in the subdirectory tools. The program has been compiled and tested on various machines running Linux 2.0.30 (gcc 2.7.2.1), IRIX 5.3. (gcc 2.6.3), and SunOS 4.1.4 (gcc 2.7.2).
Reference: [Fal94b] <author> E. Falkenauer. </author> <title> Setting new limits in bin packing with a grouping ga using reduction. </title> <type> Technical report, </type> <institution> CRIF Research Centre for Bel-gian Metalworking Industry, </institution> <address> Brussels, </address> <year> 1994. </year> <note> also available as http:// www.dai.ed.ac.uk/groups/evalg/eag local copies of papers.body.html. 26 </note>
Reference-contexts: In a number of articles Falkenauer defines the notion of grouping problems, characterized by the property that a set of objects has to be partitioned (i.e. divided into disjoint groups) in such a way that certain constraints hold and a cost function is minimized, <ref> [Fal94a, Fal94b, Fal95] </ref>. Graph coloring is explicitly mentioned as an example where the constraints forbid having connected nodes in different groups and the cost function is the number of groups. Then general arguments are given to show that context sensitive genetic operators 1 should perform better than standard `blind' operators.
Reference: [Fal95] <author> E. Falkenauer. </author> <title> Solving equal piles with the grouping genetic algorithm. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the 6th International Conference on Genetic Algorithms, </booktitle> <pages> pages 492-497. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1995. </year>
Reference-contexts: Experimental results with the GGA, however, are limited to the bin-packing and piling problems, where it proves to be superior to other methods <ref> [FD92, Fal94a, Fal95, Fal96] </ref>. The results of the SAW-ing EA will be retrieved from the experiments done earlier, while the GGA will be implemented from scratch. The GGA reuses the part from the implementation of the SAW-ing algorithm that reads in the problem instances. <p> In a number of articles Falkenauer defines the notion of grouping problems, characterized by the property that a set of objects has to be partitioned (i.e. divided into disjoint groups) in such a way that certain constraints hold and a cost function is minimized, <ref> [Fal94a, Fal94b, Fal95] </ref>. Graph coloring is explicitly mentioned as an example where the constraints forbid having connected nodes in different groups and the cost function is the number of groups. Then general arguments are given to show that context sensitive genetic operators 1 should perform better than standard `blind' operators.
Reference: [Fal96] <author> E. Falkenauer. </author> <title> A hybrid grouping genetic algorithm for bin packing. </title> <journal> Journal of Heuristics, </journal> <volume> 2 </volume> <pages> 5-30, </pages> <year> 1996. </year>
Reference-contexts: Experimental results with the GGA, however, are limited to the bin-packing and piling problems, where it proves to be superior to other methods <ref> [FD92, Fal94a, Fal95, Fal96] </ref>. The results of the SAW-ing EA will be retrieved from the experiments done earlier, while the GGA will be implemented from scratch. The GGA reuses the part from the implementation of the SAW-ing algorithm that reads in the problem instances.
Reference: [FD92] <author> E. Falkenauer and A. Delchambre. </author> <title> A genetic algorithm for bin packing and line balancing. </title> <booktitle> In Proceedings of the IEEE 1992 Int. Conference on Robotics and Automation, </booktitle> <pages> pages 1186-1192. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: Experimental results with the GGA, however, are limited to the bin-packing and piling problems, where it proves to be superior to other methods <ref> [FD92, Fal94a, Fal95, Fal96] </ref>. The results of the SAW-ing EA will be retrieved from the experiments done earlier, while the GGA will be implemented from scratch. The GGA reuses the part from the implementation of the SAW-ing algorithm that reads in the problem instances.
Reference: [Fra96] <author> J. Frank. </author> <title> Weighting for godot: Learning heuristics for GSAT. </title> <booktitle> In Proceedings of the AAAI, </booktitle> <pages> pages 338-343, </pages> <year> 1996. </year>
Reference-contexts: The micro-genetic algorithm of Dozier et al. for solving random CSPs uses breakout in this sense [DBB94, DBB95]. The idea to modify weights of constraints in CSPs is also used for solving satisfiability problems in a traditional AI approach <ref> [Fra96] </ref> and in an evolutionary algorithm [EvdH97b]. An area related to solving CSPs is that of solving constrained optimization problems by evolutionary algorithms. Michalewicz and Schoenauer give an extensive overview of this field in [ZM96].
Reference: [IEE94] <institution> Proceedings of the 1st IEEE Conference on Evolutionary Computation. IEEE Press, </institution> <year> 1994. </year>
Reference: [JH94] <author> J. Joines and C. Houck. </author> <title> On the use of non-stationary penalty functions to solve non-linear constrained optimization problems with GAs. </title> <booktitle> In IEEE [IEE94], </booktitle> <pages> pages 579-584. </pages>
Reference-contexts: An area related to solving CSPs is that of solving constrained optimization problems by evolutionary algorithms. Michalewicz and Schoenauer give an extensive overview of this field in [ZM96]. In this survey a technical report from 1992 forms the earliest example [BHA92], where penalties are adapted. In [MA95] and <ref> [JH94] </ref> mechanisms for varying penalties according to a predefined schedule are reported. 2.2 The Grouping Genetic Algorithm The implementation of the GGA will look like the pseudo-code as shown in Figure 2.3.
Reference: [MA95] <author> Z. Michalewicz and N. Attia. </author> <title> Evolutionary optimization of constrained problems. In A.V. </title> <editor> Sebald and L.J. Fogel, editors, </editor> <booktitle> Proceedings of the 3rd Annual Conference on Evolutionary Programming, </booktitle> <pages> pages 98-108. </pages> <publisher> World Scientific, </publisher> <year> 1995. </year>
Reference-contexts: An area related to solving CSPs is that of solving constrained optimization problems by evolutionary algorithms. Michalewicz and Schoenauer give an extensive overview of this field in [ZM96]. In this survey a technical report from 1992 forms the earliest example [BHA92], where penalties are adapted. In <ref> [MA95] </ref> and [JH94] mechanisms for varying penalties according to a predefined schedule are reported. 2.2 The Grouping Genetic Algorithm The implementation of the GGA will look like the pseudo-code as shown in Figure 2.3.
Reference: [Mor93] <author> P. Morris. </author> <title> The breakout method for escaping from local minima. </title> <booktitle> In Proceedings of the 11th National Conference on Artificial Intelligence, AAAI-93, </booktitle> <pages> pages 40-45. </pages> <publisher> AAAI Press/The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Our first attempts to modify weights in a constraint satisfaction problem (CSP) depending on the progress of a genetic algorithm solving the problem were reported in [ERR94, ERR95]. Technically speaking, the idea is very similar to the breakout method as introduced by Morris <ref> [Mor93] </ref>, but has been developed independently. A conceptual difference between breakout methods and SAW-ing is that SAW-ing periodically modifies weights, while the breakout method is called if the search gets stuck in a local optimum.
Reference: [vdH96] <author> J.K. van der Hauw. </author> <title> Evaluating and improving steady state evolutionary algorithms on constraint satisfaction problems. </title> <type> Master's thesis, </type> <institution> Leiden University, </institution> <year> 1996. </year>
Reference-contexts: Introduction The purpose of this investigation is to extend a study by Eiben and van der Hauw on applying evolutionary algorithms to graph coloring, <ref> [vdH96, EVdH96, EvdH97a] </ref>. In particular, the EA based on Stepwise Adaptation of Weights (SAW) used by Eiben and van der Hauw are compared to the Grouping Genetic Algorithm (GGA) of Falkenauer [Fal94a]. <p> This report starts with a brief description of the SAW-ing EA and the grouping genetic algorithm in Chapter 2. The experimental setup, including the problem instances and the algorithm parameters, is presented in Chapter 3. Following the line of research in <ref> [vdH96, EVdH96, EvdH97a] </ref>, we perform a big comparison on three different graph topologies (arbitrary, equi-partite, and flat graphs), three different graph sizes (200, 500, and 1000 nodes), and graph instances for different edge connectivity values around the phase transition for each combination of topology and size. <p> Therefore, it is advised to read [EVdH96] and [Fal94a]. Furthermore, general knowledge on graph coloring and evolutionary algorithms is assumed. 1 Available from ftp://ftp.cs.ualberta.ca/pub/joe/GraphGenerator/generate.tar.gz 2 Chapter 2 The SAW-ing EA and the Grouping Genetic Algorithm 2.1 The SAW-ing evolutionary algorithm The evolutionary algorithm used in the experiments in <ref> [vdH96, EVdH96, EvdH97a] </ref> is based on a steady-state GA using order-based representation, 2-tournament selection and worst-fitness replacement strategy. The general outlines of a steady state evolutionary algorithm are shown in Figure 2.1. Using order-based representation the individuals are permutations and special operators are used to recombine and mutate permutations. <p> A shell-script called checkrunning.sh for checking which experiments are still running from the list of running experiments. Numerous shell-scripts starting with the string unplot- can be used to convert the postscript files that present the figures in <ref> [vdH96] </ref> back to ready to plot data. An rmquotes.sh script to remove the ugly doublequotes (") that Gnuplot puts around key values in the graphs it produces. <p> There are two archives; the first is Genea.tar.gz, which is the program made by van der Hauw for doing experiments for his Master's Thesis <ref> [vdH96] </ref> called Genea. The second archive called Generator.tar.gz contains the graph generator made by J. Culberson to generate instances of graph coloring problems. A.4 Configuration file parameters A.4.1 Evolutionary Algorithm parameters * populationsize This determines the number of individual genomes used by the evolutionary algorithm.
Reference: [ZM96] <author> Michalewicz Z. and Schoenauer M. </author> <title> Evolutionary algorithms for constrained parameter optimization problems. </title> <journal> Evolutionary Computation, </journal> <volume> 4(1) </volume> <pages> 1-32, </pages> <year> 1996. </year>
Reference-contexts: An area related to solving CSPs is that of solving constrained optimization problems by evolutionary algorithms. Michalewicz and Schoenauer give an extensive overview of this field in <ref> [ZM96] </ref>. In this survey a technical report from 1992 forms the earliest example [BHA92], where penalties are adapted.
References-found: 20

