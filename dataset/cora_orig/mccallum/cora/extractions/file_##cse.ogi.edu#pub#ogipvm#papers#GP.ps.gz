URL: file://cse.ogi.edu/pub/ogipvm/papers/GP.ps.gz
Refering-URL: http://www.cse.ogi.edu/DISC/projects/mist/papers.html
Root-URL: http://www.cse.ogi.edu
Email: o@ipncls.in2p3.fr  otto@cse.ogi.edu  
Title: Partitioning of Unstructured Meshes for Load Balancing  
Author: Olivier C. Martin martin and Steve W. Otto 
Date: August 28, 1994  
Address: Orsay CEDEX 91406 France  20000 NW Walker Rd, PO Box 91000 Portland, Oregon, USA 97291-1000  
Affiliation: Division de Physique Theorique Institut de Physique Nucleaire,  Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: Many large-scale engineering and scientific calculations involve repeated updating of variables on an unstructured mesh. To do these types of computations on distributed memory parallel computers, it is necessary to partition the mesh among the processors so that the load balance is maximized and inter-processor communication time is minimized. This can be approximated by the problem of partitioning a graph so as to obtain a minimum cut, a well-studied combinatorial optimization problem. Graph partitioning is NP complete, so for real world applications, one resorts to heuristics, i.e., algorithms that give good but not necessarily optimum solutions. These algorithms include recursive spectral bisection, local search methods such as Kernighan-Lin, and more general purpose methods such as simulated annealing. We show that a general procedure enables us to combine simulating annealing with Kernighan-Lin. The resulting algorithm is both very fast and extremely effective. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B.W. Kernighan. </author> <title> Some graph partitioning problems related to program segmentation, 1969. </title> <type> Ph.D. Thesis. </type>
Reference-contexts: An edge E i;j is cut if V i and V j belong to different subsets. The GPP has many practical applications. It occurs in program text segmentation <ref> [1] </ref>, and is a major ingredient in the problem of cell placement for VLSI [2, 3]. The application of interest for this paper is the partitioning of unstructured meshes used in scientific and engineering problems.
Reference: [2] <author> K. Shahookar and P. Mazumder. </author> <title> VLSI cell placement techniques. </title> <journal> ACM Computing Surveys, </journal> <volume> 23(2) </volume> <pages> 143-220, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: An edge E i;j is cut if V i and V j belong to different subsets. The GPP has many practical applications. It occurs in program text segmentation [1], and is a major ingredient in the problem of cell placement for VLSI <ref> [2, 3] </ref>. The application of interest for this paper is the partitioning of unstructured meshes used in scientific and engineering problems.
Reference: [3] <author> M. Hanan and J.M. Kertzberg. </author> <title> A review of the placement and quadratic assignment problems. </title> <journal> SIAM Review, </journal> <volume> 14, No. 2:324, </volume> <year> 1972. </year>
Reference-contexts: An edge E i;j is cut if V i and V j belong to different subsets. The GPP has many practical applications. It occurs in program text segmentation [1], and is a major ingredient in the problem of cell placement for VLSI <ref> [2, 3] </ref>. The application of interest for this paper is the partitioning of unstructured meshes used in scientific and engineering problems.
Reference: [4] <author> C. Farhat. </author> <title> On the mapping of massively parallel processors onto finite element graphs. </title> <journal> Computers and Structures, </journal> <volume> 32(2) </volume> <pages> 347-53, </pages> <year> 1989. </year>
Reference-contexts: Parallel implementations on distributed-memory computers require the distribution of the mesh amongst the processors. This leads to a graph partitioning problem where G=(V,E) is the graph associated with a differential operator defined on the mesh <ref> [4, 5, 6, 7, 8, 9] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G.
Reference: [5] <author> J. Flower, S. Otto, and M. Salama. </author> <title> A preprocessor for finite element problems. </title> <booktitle> In Symposium on Parallel Computations and Their Impact on Mechanics. American Society of Mechanical Engineers, 1987. ASME Winter Meeting, </booktitle> <month> Dec. </month> <pages> 14-16, </pages> <address> 1987, Boston, Mass. </address>
Reference-contexts: Parallel implementations on distributed-memory computers require the distribution of the mesh amongst the processors. This leads to a graph partitioning problem where G=(V,E) is the graph associated with a differential operator defined on the mesh <ref> [4, 5, 6, 7, 8, 9] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G.
Reference: [6] <author> A. Pothen, H. Simon, and K.P. Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM J. Mat. Anal. Appl., </journal> <volume> 11(3) </volume> <pages> 430-52, </pages> <year> 1990. </year> <month> 11 </month>
Reference-contexts: Parallel implementations on distributed-memory computers require the distribution of the mesh amongst the processors. This leads to a graph partitioning problem where G=(V,E) is the graph associated with a differential operator defined on the mesh <ref> [4, 5, 6, 7, 8, 9] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G. <p> Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods [18], and recursive spectral bisection <ref> [6, 8] </ref>. Leland and Hendrickson [9], and also Williams [19], compare these methods, and Mansour, Savage, and Wloka give parallel implementations [20, 21]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L.
Reference: [7] <author> V. Venkatakrishnan, H. Simon, and T. Barth. </author> <title> A MIMD implementation of a parallel Euler solver for unstructured grids. </title> <journal> The Journal of Supercomputing, </journal> <volume> 6(2) </volume> <pages> 117-27, </pages> <year> 1992. </year>
Reference-contexts: Parallel implementations on distributed-memory computers require the distribution of the mesh amongst the processors. This leads to a graph partitioning problem where G=(V,E) is the graph associated with a differential operator defined on the mesh <ref> [4, 5, 6, 7, 8, 9] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G.
Reference: [8] <author> S. Barnard and H. Simon. </author> <title> A fast multilevel implementation of recursive spectral bisection for partitioning unstructured problems. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 6(2) </volume> <pages> 101-17, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Parallel implementations on distributed-memory computers require the distribution of the mesh amongst the processors. This leads to a graph partitioning problem where G=(V,E) is the graph associated with a differential operator defined on the mesh <ref> [4, 5, 6, 7, 8, 9] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G. <p> This methodology, which we call chained local optimization (C-L-O), is a very general one. It can be applied to many optimization problems and is quite effective. The paper goes on to compare C-L-O against other effective heuristics <ref> [12, 8] </ref>, for both synthetically generated graphs and for graphs from real-world unstructured meshes. <p> Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods [18], and recursive spectral bisection <ref> [6, 8] </ref>. Leland and Hendrickson [9], and also Williams [19], compare these methods, and Mansour, Savage, and Wloka give parallel implementations [20, 21]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. <p> The line initialization is not possible for such graphs, nor is compaction of much use. 5 Performance on unstructured meshes Barnard and Simon <ref> [8] </ref> studied recursive spectral bisection on several unstructured meshes that arise in mesh-mapping problems. This section benchmarks L-K-L and C-L-O on some of these same problems, as well as a three-dimensional graph studied in [9]. <p> The best cut ever was 139: L-K-L found it with probability 0:016, and C-L-O found it in 15 of the 20 runs. For this instance, spectral bisection gave a cut size of 176 <ref> [8] </ref>. For Mpart [9], the best C-L-O runs found a partition with cut size 731. For comparison, Chaco [25] gets partitions of size 729 ("Multilevel-KL") and 724 ("Spectral-KL") on this graph [26]. <p> The key is to use K-L as a post-processor. Then, almost any method will become competitive. We illustrated this for coordinate bisection when transformed into L-K-L. Similarly, Barnard and Simon, as well as Leland and Hendrickson, have reported improvements to spectral bisection when K-L is used as a post-processor <ref> [8, 9] </ref>. However, such methods are limited by their deterministic behavior, and could almost certainly benefit from some randomization. 6 Parallel C-L-O Most local search methods for the GPP do not parallelize well, mainly because the constraint of maintaining a feasible solution is not readily implemented in parallel.
Reference: [9] <author> R. Leland and B. Hendrickson. </author> <title> An empirical study of static load balancing algorithms. </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <pages> pages 682-5. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: Parallel implementations on distributed-memory computers require the distribution of the mesh amongst the processors. This leads to a graph partitioning problem where G=(V,E) is the graph associated with a differential operator defined on the mesh <ref> [4, 5, 6, 7, 8, 9] </ref>. Model the parallel computation as consisting of updates to variables located at the vertices of G, with data dependences between the variables given by the edges, E, of G. <p> Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods [18], and recursive spectral bisection [6, 8]. Leland and Hendrickson <ref> [9] </ref>, and also Williams [19], compare these methods, and Mansour, Savage, and Wloka give parallel implementations [20, 21]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. However, for unstructured meshes, K-L is substantially better than simulating annealing, and is also much faster [12]. <p> This section benchmarks L-K-L and C-L-O on some of these same problems, as well as a three-dimensional graph studied in <ref> [9] </ref>. The main differences with the ensemble of geometric graphs used in the previous section are that, except for the "Mpart" mesh, the graphs are planar and have an average degree close to 6. <p> The best cut ever was 139: L-K-L found it with probability 0:016, and C-L-O found it in 15 of the 20 runs. For this instance, spectral bisection gave a cut size of 176 [8]. For Mpart <ref> [9] </ref>, the best C-L-O runs found a partition with cut size 731. For comparison, Chaco [25] gets partitions of size 729 ("Multilevel-KL") and 724 ("Spectral-KL") on this graph [26]. <p> The key is to use K-L as a post-processor. Then, almost any method will become competitive. We illustrated this for coordinate bisection when transformed into L-K-L. Similarly, Barnard and Simon, as well as Leland and Hendrickson, have reported improvements to spectral bisection when K-L is used as a post-processor <ref> [8, 9] </ref>. However, such methods are limited by their deterministic behavior, and could almost certainly benefit from some randomization. 6 Parallel C-L-O Most local search methods for the GPP do not parallelize well, mainly because the constraint of maintaining a feasible solution is not readily implemented in parallel.
Reference: [10] <author> B. Kernighan and S. Lin. </author> <title> An effective heuristic procedure for partitioning graphs. </title> <institution> Bell Syst. Tech. J., 49:291, </institution> <year> 1970. </year>
Reference-contexts: In what follows, we quickly summarize a number of solution methods for the GPP, and stress particularly the the Kernighan-Lin local search heuristic <ref> [10, 11] </ref>. After this, we explain our method of combining local search methods, such as Kernighan-Lin, with simulated annealing. This methodology, which we call chained local optimization (C-L-O), is a very general one. It can be applied to many optimization problems and is quite effective. <p> Since real applications have very large meshes, in practice it is necessary to take a heuristic approach. Two important, general-purpose heuristics are simulated annealing [16], and a variable depth, local search originally due to Kernighan and Lin <ref> [10, 11] </ref>, which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods [18], and recursive spectral bisection [6, 8]. <p> To deal with k-way partitions, one successively applies the algorithm described below to each pair of subsets chosen among the k subsets, until no improvement is found. The method can also be readily extended to the case of unequal sized partitions <ref> [10] </ref>. Let A be a subset of V, of size N=2, and B its complement. Define a 1-exchange to be an exchange of one element of A with an element of B. Suppose one repeatedly applies 1-exchanges that decrease the cut size until no more such 1-exchanges can be found.
Reference: [11] <author> C.M. Fiduccia and R.M. Mattheyses. </author> <title> A linear-time heuristic for improving network partitions. </title> <booktitle> In Proceedings 19'th Design Automation Workshop, </booktitle> <pages> page 175, </pages> <year> 1982. </year>
Reference-contexts: In what follows, we quickly summarize a number of solution methods for the GPP, and stress particularly the the Kernighan-Lin local search heuristic <ref> [10, 11] </ref>. After this, we explain our method of combining local search methods, such as Kernighan-Lin, with simulated annealing. This methodology, which we call chained local optimization (C-L-O), is a very general one. It can be applied to many optimization problems and is quite effective. <p> Since real applications have very large meshes, in practice it is necessary to take a heuristic approach. Two important, general-purpose heuristics are simulated annealing [16], and a variable depth, local search originally due to Kernighan and Lin <ref> [10, 11] </ref>, which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods [18], and recursive spectral bisection [6, 8].
Reference: [12] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation, part I (graph partitioning). </title> <journal> Oper. Res., </journal> <volume> 37 </volume> <pages> 865-92, </pages> <year> 1989. </year>
Reference-contexts: This methodology, which we call chained local optimization (C-L-O), is a very general one. It can be applied to many optimization problems and is quite effective. The paper goes on to compare C-L-O against other effective heuristics <ref> [12, 8] </ref>, for both synthetically generated graphs and for graphs from real-world unstructured meshes. <p> For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. However, for unstructured meshes, K-L is substantially better than simulating annealing, and is also much faster <ref> [12] </ref>. Nevertheless, it is necessary to enhance K-L for it to be competitive with special purpose methods such as recursive spectral bisection. <p> For sparse graphs, K-L is fast, requiring O (N ln (N )) operations per sweep. As shown by Johnson et al., it is much faster than simulated annealing, and also gives smaller cut sizes <ref> [12] </ref>. However, K-L gives erratic results from run to run. In particular, for unstructured meshes, it is beaten by the recursive spectral bisection and coordinate bisection methods. Thus, for such graphs, it is necessary to run K-L many times from different random starts or to find ways to enhance K-L. <p> Since the coordinate-bisection of two-dimensional meshes uses a dividing line with a random orientation, the algorithm is named L-K-L for "Line K-L." L-K-L gives as good results as a hierarchical compaction approach but is simpler and is more effective than simulated annealing or K-L from random starts <ref> [12] </ref>. In view of this, we restrict ourselves to presenting comparisons of our algorithm, C-L-O, to L-K-L only. 3 3 Chained Local Optimization Martin, Otto, and Felten [22] introduced a new meta-heuristic for optimization by combining local search methods with simulated annealing. <p> Neglecting edge effects, one has, on average, d = R 2 N : (1) Johnson et al. did a thorough comparison of several algorithms and concluded that for such geometric graphs, K-L from random starts was better than simulated annealing, but that L-K-L was better still <ref> [12] </ref>. We first qualitatively compare the performance of C-L-O with K-L from random starts. d = 6. The histogram gives the distribution of cut sizes encountered for 1000 K-L's from random start and those for one run of C-L-O for 1020 steps, the first 20 being omitted from the histogram. <p> For each instance, we ran L-K-L 2000 times, and we ran C-L-O 20 times, each run consisting of 100 kick/K-L steps. From the 2000 L-K-L data points, we followed the method described in <ref> [12] </ref> to derive the distribution of the best cut found in 100 independent trials. The mean was then compared with the corresponding mean of the best found in each of the 20 C-L-O runs. <p> The first four are two-dimensional meshes, the last a three-dimensional mesh. In comparing various algorithms, we need not consider simulated annealing since it has been shown that K-L performs better than S-A on such sparse graphs <ref> [12] </ref>. We consider the five graphs in turn. Spiral has the geometry of a spiral, so the use of the line algorithm (i.e., coordinate bisection) leads to a fragmented partition.
Reference: [13] <author> A. L. Beguelin, J. J. Dongarra, A. Geist, R. J. Manchek, and V. S. Sunderam. </author> <title> Heterogeneous network computing. </title> <booktitle> In Sixth SIAM Conference on Parallel Processing, </booktitle> <year> 1993. </year>
Reference-contexts: The paper goes on to compare C-L-O against other effective heuristics [12, 8], for both synthetically generated graphs and for graphs from real-world unstructured meshes. Finally, we describe the implementation of the C-L-O algorithm on a parallel network of workstations running PVM <ref> [13, 14] </ref>. 2 Graph Partitioning Heuristics Since the GPP is NP-complete, it comes as no surprise that exact methods are slow. An integer linear programming formulation of the GPP has recently been given by Barahona and Casari [15]. <p> Thus, we only consider implementations where a given processor has a complete configuration in local memory. We work in the framework of a distributed-memory architecture and have implemented the codes on a network of workstations under PVM <ref> [13, 14] </ref>. The simplest way to parallelize chained local optimization is to have each processor run independent C-L-O chains. This is equivalent to running multiple random starts on a single processor. If we have P processors, at any given time we have a population of at least P configurations.
Reference: [14] <author> J. J. Dongarra, A. Geist, R. J. Manchek, and V. S. Sunderam. </author> <title> Integrated PVM framework supports heterogeneous network computing. </title> <booktitle> Computers in Physics, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: The paper goes on to compare C-L-O against other effective heuristics [12, 8], for both synthetically generated graphs and for graphs from real-world unstructured meshes. Finally, we describe the implementation of the C-L-O algorithm on a parallel network of workstations running PVM <ref> [13, 14] </ref>. 2 Graph Partitioning Heuristics Since the GPP is NP-complete, it comes as no surprise that exact methods are slow. An integer linear programming formulation of the GPP has recently been given by Barahona and Casari [15]. <p> Thus, we only consider implementations where a given processor has a complete configuration in local memory. We work in the framework of a distributed-memory architecture and have implemented the codes on a network of workstations under PVM <ref> [13, 14] </ref>. The simplest way to parallelize chained local optimization is to have each processor run independent C-L-O chains. This is equivalent to running multiple random starts on a single processor. If we have P processors, at any given time we have a population of at least P configurations.
Reference: [15] <author> F. Barahona and A. Casari. </author> <title> On the magnetisation of the ground states in two dimensional Ising spin glasses. </title> <journal> Comp. Phys. Communications, </journal> <volume> 49:417, </volume> <year> 1988. </year>
Reference-contexts: An integer linear programming formulation of the GPP has recently been given by Barahona and Casari <ref> [15] </ref>. Since real applications have very large meshes, in practice it is necessary to take a heuristic approach. Two important, general-purpose heuristics are simulated annealing [16], and a variable depth, local search originally due to Kernighan and Lin [10, 11], which we will call Kernighan-Lin (K-L).
Reference: [16] <author> S. Kirkpatrick, C. Gelatt, and M. Vecchi. </author> <title> Optimization by simulated annealing. </title> <booktitle> Science, </booktitle> <address> 220:671, </address> <year> 1983. </year>
Reference-contexts: An integer linear programming formulation of the GPP has recently been given by Barahona and Casari [15]. Since real applications have very large meshes, in practice it is necessary to take a heuristic approach. Two important, general-purpose heuristics are simulated annealing <ref> [16] </ref>, and a variable depth, local search originally due to Kernighan and Lin [10, 11], which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods [18], and recursive spectral bisection [6, 8].
Reference: [17] <author> M. Berger and S. Bokhari. </author> <title> A partitioning strategy for non-uniform problems on multiprocessors. </title> <journal> IEEE Trans. Computers, </journal> <volume> C-36(5):570, </volume> <year> 1987. </year>
Reference-contexts: Two important, general-purpose heuristics are simulated annealing [16], and a variable depth, local search originally due to Kernighan and Lin [10, 11], which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection <ref> [17] </ref>, compaction or contraction methods [18], and recursive spectral bisection [6, 8]. Leland and Hendrickson [9], and also Williams [19], compare these methods, and Mansour, Savage, and Wloka give parallel implementations [20, 21]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. <p> This approach, if used on multiple levels in a hierarchical manner, is well suited to unstructured meshes. The second approach consists of using something besides a random starting partition for the K-L. A simple, yet effective, starting partition can be obtained by coordinate bisection <ref> [17] </ref>. Since the coordinate-bisection of two-dimensional meshes uses a dividing line with a random orientation, the algorithm is named L-K-L for "Line K-L." L-K-L gives as good results as a hierarchical compaction approach but is simpler and is more effective than simulated annealing or K-L from random starts [12]. <p> The reason for the poor results of K-L can be understood by looking at typical partitions: they are almost always fragmented as mentioned in section 3. Better results would be obtained by simply partitioning the vertices according to their coordinates, i.e., by using coordinate bisection <ref> [17] </ref>. For geometric graphs, this bisection can be obtained by choosing a random direction in space and partitioning the graph by a line parallel to this direction; this corresponds to the line algorithm discussed in section 2.
Reference: [18] <author> T. Bui, C. Heigham, C. Jones, and T. Leighton. </author> <title> Improving the performance of the Kernighan-Lin and simulated annealing graph bisection algorithms. </title> <booktitle> In 26'th ACM/IEEE Design Automation Conference, </booktitle> <pages> page 775, </pages> <year> 1989. </year>
Reference-contexts: Two important, general-purpose heuristics are simulated annealing [16], and a variable depth, local search originally due to Kernighan and Lin [10, 11], which we will call Kernighan-Lin (K-L). Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods <ref> [18] </ref>, and recursive spectral bisection [6, 8]. Leland and Hendrickson [9], and also Williams [19], compare these methods, and Mansour, Savage, and Wloka give parallel implementations [20, 21]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. <p> Thus, for such graphs, it is necessary to run K-L many times from different random starts or to find ways to enhance K-L. Enhancements to Kernighan-Lin for Unstructured Meshes There are two commonly used approaches for improving K-L. The first, called compaction or contraction <ref> [18] </ref>, consists of contracting the graph by merging nearby vertices, partitioning the smaller graph via K-L, undoing the merging procedure, and reapplying K-L. This approach, if used on multiple levels in a hierarchical manner, is well suited to unstructured meshes.
Reference: [19] <author> R. Williams. </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3(5) </volume> <pages> 457-81, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods [18], and recursive spectral bisection [6, 8]. Leland and Hendrickson [9], and also Williams <ref> [19] </ref>, compare these methods, and Mansour, Savage, and Wloka give parallel implementations [20, 21]. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. However, for unstructured meshes, K-L is substantially better than simulating annealing, and is also much faster [12].
Reference: [20] <author> N. Mansour. </author> <title> Physical Optimization Algorithms for Mapping Data to Distributed-Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Syracuse University, </institution> <year> 1992. </year>
Reference-contexts: Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods [18], and recursive spectral bisection [6, 8]. Leland and Hendrickson [9], and also Williams [19], compare these methods, and Mansour, Savage, and Wloka give parallel implementations <ref> [20, 21] </ref>. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. However, for unstructured meshes, K-L is substantially better than simulating annealing, and is also much faster [12].
Reference: [21] <author> J.E. Savage and M.G. Wloka. </author> <title> On parallelizing graph-partitioning heuristics. </title> <booktitle> In Proceedings of the ICALP'90, </booktitle> <pages> page 476, </pages> <year> 1990. </year>
Reference-contexts: Methods specific to the mapping of unstructured meshes include recursive coordinate bisection [17], compaction or contraction methods [18], and recursive spectral bisection [6, 8]. Leland and Hendrickson [9], and also Williams [19], compare these methods, and Mansour, Savage, and Wloka give parallel implementations <ref> [20, 21] </ref>. For the partitioning of generic (random) graphs, the "best" heuristics are simulated annealing and K-L. However, for unstructured meshes, K-L is substantially better than simulating annealing, and is also much faster [12].
Reference: [22] <author> O. Martin, S.W. Otto, </author> <title> and E.W. Felten. Large-step Markov chains for the traveling salesman problem. </title> <journal> J. Complex Syst., </journal> <volume> 5:3:299, </volume> <year> 1991. </year> <month> 12 </month>
Reference-contexts: In view of this, we restrict ourselves to presenting comparisons of our algorithm, C-L-O, to L-K-L only. 3 3 Chained Local Optimization Martin, Otto, and Felten <ref> [22] </ref> introduced a new meta-heuristic for optimization by combining local search methods with simulated annealing. The important realization is that simulated annealing needlessly explores all configurations. For most optimization problems, there are local search methods that quickly give good approximate solutions. <p> The resulting algorithm is termed "Chained Local Optimization" (C-L-O). It is a general purpose algorithm that improves upon both simulated annealing and local search methods (it necessarily beats local search, since it incorporates local search in the inner-most loop of the algorithm). We did <ref> [22, 23] </ref> an in depth study of C-L-O for the traveling salesperson problem, and found that it surpassed by a wide margin Lin-Kernighan, the best heuristic for that combinatorial optimization problem since 1973. <p> A symmetry property known as detailed balance is violated by C-L-O and this means that it does not correspond to the true "annealing" of some "physical" system <ref> [22] </ref>. 4 procedure used in chained local optimization. To implement C-L-O for an arbitrary combinatorial optimization problem, one requires two things: a good local search heuristic, and a choice for the kick adapted to the optimization problem.
Reference: [23] <author> O. Martin, S.W. Otto, </author> <title> and E.W. Felten. Large-step Markov chains for the TSP incorpo-rating local search heuristics. </title> <journal> Oper. Res. Lett., </journal> <volume> 11 </volume> <pages> 219-24, </pages> <year> 1992. </year>
Reference-contexts: The resulting algorithm is termed "Chained Local Optimization" (C-L-O). It is a general purpose algorithm that improves upon both simulated annealing and local search methods (it necessarily beats local search, since it incorporates local search in the inner-most loop of the algorithm). We did <ref> [22, 23] </ref> an in depth study of C-L-O for the traveling salesperson problem, and found that it surpassed by a wide margin Lin-Kernighan, the best heuristic for that combinatorial optimization problem since 1973.
Reference: [24] <author> O.C. Martin and S.W. Otto. </author> <title> Combining simulated annealing with local search heuristics. </title> <editor> In G. Laporte and I. Osman, editors, </editor> <booktitle> Metaheuristics in Combinatorial Optimization. </booktitle> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: We did [22, 23] an in depth study of C-L-O for the traveling salesperson problem, and found that it surpassed by a wide margin Lin-Kernighan, the best heuristic for that combinatorial optimization problem since 1973. More generally, as discussed by Martin and Otto <ref> [24] </ref>, C-L-O should perform well on a wide class of problems which includes the GPP. For the purpose of this paper, important features of C-L-O include the following. * It is general purpose, so it can be applied to general graphs.
Reference: [25] <author> B. Hendrickson and R. Leland. </author> <title> The Chaco user's guide, version 1.0. </title> <type> Technical Report SAND 93-2339, </type> <institution> Sandia National Laboratories, </institution> <address> Albuquerque, NM, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: For this instance, spectral bisection gave a cut size of 176 [8]. For Mpart [9], the best C-L-O runs found a partition with cut size 731. For comparison, Chaco <ref> [25] </ref> gets partitions of size 729 ("Multilevel-KL") and 724 ("Spectral-KL") on this graph [26]. It is fair to conclude that these types of meshes are solved rather easily, either by L-K-L using multiple tries, or by C-L-O. Not surprisingly, the larger meshes become more difficult.
Reference: [26] <author> B. Hendrickson, </author> <title> private communication. </title> <type> 13 </type>
Reference-contexts: For this instance, spectral bisection gave a cut size of 176 [8]. For Mpart [9], the best C-L-O runs found a partition with cut size 731. For comparison, Chaco [25] gets partitions of size 729 ("Multilevel-KL") and 724 ("Spectral-KL") on this graph <ref> [26] </ref>. It is fair to conclude that these types of meshes are solved rather easily, either by L-K-L using multiple tries, or by C-L-O. Not surprisingly, the larger meshes become more difficult. Note that both algorithms incorporate K-L, a general-purpose graph partitioning method.
References-found: 26

