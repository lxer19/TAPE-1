URL: http://www.win.tue.nl/cs/pa/rikvdw/papers/Benes98.ps.gz
Refering-URL: http://www.win.tue.nl/cs/pa/rikvdw/bibl.html
Root-URL: http://www.win.tue.nl
Title: A Fast Asynchronous Huffman Decoder for Compressed-Code Embedded Processors iterative self-timed ring. It achieves a
Author: Martin Benes Steven M. Nowick Andrew Wolfe 
Note: The circuit is non-pipelined, and is implemented as an  (or 163 MBytes/sec, or 1303 Mbit/sec), corresponding to  is also 83%  
Address: Santa Clara, CA Berkeley, CA New York, NY  
Affiliation: Department of EECS Dept. of Computer Science S3 Inc. U.C. Berkeley Columbia University  
Abstract: This paper presents the architecture and design of a high-performance asynchronous Huffman decoder for compressed-code embedded processors. In such processors, embedded programs are stored in compressed form in instruction ROM, then are decompressed on demand during instruction cache refill. The Huffman decoder is used as a code decompression engine. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Benes, A. Wolfe, and S.M. Nowick. </author> <title> A high-speed asynchronous decompression circuit for embedded processors. </title> <booktitle> In Proceedings of the 17th Conference on Advanced Research in VLSI. </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1997. </year>
Reference-contexts: Very recently, we introduced the first prototype design for such an asynchronous decompression circuit <ref> [1] </ref>. Instructions are compressed in memory, using a Huffman encoding scheme [10]. Huffman codes are variable-length, where the shortest codes are assigned to the most frequent symbols. <p> Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder. The design uses an entirely new organization, and is 83% faster than our earlier design <ref> [1] </ref>, using the same 0.8 CMOS technology, with no increase in area. The circuit is non-pipelined, and is implemented as an iterative self-timed ring. It is largely implemented using dynamic domino dual rail logic. It achieves a high-speed decode rate with very low area overhead. <p> Details of the management of the input and output buffers and their interaction with the overall system, such as requesting the next input word, signaling a completed output word, and indicating decode completion, have been described in <ref> [1] </ref>, and will not be discussed further here. 4 Huffman Decoder: Architecture and Implementation This section presents an overview of the new decoder architecture, as well as details on the implementation of its components. 4.1 Overview A structural diagram of the new decoder architecture is shown in Figure 4. <p> The remainder of this section gives details on the implementation of the stages. Note that some of the stages are the same as in the previous prototype <ref> [1] </ref>; others are new. However, the overall architecture, scheduling, and inter-stage synchronization schemes are new. We will present both new and old stages (old in less detail) for coherence. <p> Also, we include a global enable signal. When de-asserted, this signal resets all dynamic stages to the precharge state (e.g., between decoder requests). In Figure 4, inter-stage synchronization is indicated by dotted arrows. scheme 4.3 Huffman Encoding and Match We use a variant of Huffman encoding, introduced in <ref> [1] </ref>, to optimize the decoder implementation. On the one hand, the length of each Huffman code is precisely determined by the frequency distribution of the original input alphabet. <p> In our implementation, the maximum shift amount is 21 bits: given a maximum-length 14-bit Huffman code and a 7-bit current Offset. used only for an initial load, at the start of a new decode request (see <ref> [1] </ref>). As an optimization, a Pre-Shift stage is used to implement an early byte-shift. <p> Align. The Align stage effectively implements 3 stages of 2-1 multiplexers in hazard-free precharged domino logic. The stage has been described in <ref> [1] </ref>. The 3 select bits, from the Sum stage, indicate the desired shift amount (0-7 bits). An important new feature of the Align stage, in the self-timed ring, is that it is the unique synchronization point. <p> Thus, we obtain a considerable savings in hardware by not optimizing for worst-case codes. Admittedly, some of the area benefits of our design are due to a number of low-level optimizations, which would not appear in some commercial designs which use off-the-shelf parts. In fact, our earlier design <ref> [1] </ref> can be directly modified to handle a global synchronous clock, instead of an asynchronous clocking signal. That is, our architecture might be usable as a synchronous implementation, with comparable area (under 1 mm 2 ). <p> Second, the current overheads of shifting still dominate. Therefore, while our architecture achieved a significant improvement, there are still bottlenecks that merit further attention. 6 Comparison with a Previous Asyn chronous Design We now compare our new design with an earlier asynchronous decoder design presented in <ref> [1] </ref>. Both circuits were designed using the same design tools and technology (0.8); the earlier design also was fabricated. Both designs have the same area (0:75 mm 2 ) and the same number of transistors (6100). However, the new design is 83% faster than the old design. Architectural Comparison.
Reference: [2] <author> L. Benini, E. Macii, and M. Poncino. </author> <title> Telescopic units: Increasing the average throughput of pipelined designs by adaptive latency control. </title> <booktitle> In ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 22-27, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: However, a synchronous version would have significantly worse performance (approximately 14 ns per cycle), since a worst-case clock would be required, so no advantage could be obtained from data-dependent variations (see Figure 12). 5 5 A recent approach has been proposed, called telescopic units <ref> [2] </ref>, which allows variable-speed synchronous operation.
Reference: [3] <author> G. Birtwistle and A.L. Davis. </author> <title> Asynchronous Digital Circuit Design. </title> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Input data is fetched from memory using a simple 4-phase asynchronous handshaking protocol <ref> [3] </ref>. This data consists of a single compressed cache line, loaded 32-bits at a time. The compressed line itself contains a sequence of variable-length input symbols, each of which is a Huffman code for 1 byte of an instruction.
Reference: [4] <author> S. Choi and M. Lee. </author> <title> High speed pattern matching for a fast huffman decoder. </title> <journal> IEEE Trans. on Consumer Electronics, </journal> <volume> 41(1) </volume> <pages> 97-103, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: However, while significant compression can be obtained for small programs, the ROM table itself may be over 270 KBytes for large examples, rendering the approach impractical. 2.2 Related Work: Huffman Decoders Our design is estimated to have better performance and area than existing synchronous Huffman decoders <ref> [18, 9, 4, 17] </ref>. Most of these decoders are targeted for digital video applications, and focus on the MPEG-2 VLD decoder for the DCT coefficient table.
Reference: [5] <author> M. Matsui et al. </author> <title> 200 mhz video compression macrocells using low-swing differential logic. </title> <booktitle> In ISSCC, </booktitle> <pages> pages 76-77, </pages> <year> 1994. </year>
Reference-contexts: One of the fastest designs is a recent Toshiba chip <ref> [5] </ref>, using 0.5 nFets, which was clocked at 200 MHz output rate. The design uses aggressive but area-expensive cricuit techniques like differential amplifying logic, which we have not used.
Reference: [6] <author> S.B. Furber, P. Day, J.D. Garside, N.C. Paver, S. Temple, and J.V. Woods. </author> <title> The design and evaluation of an asynchronous microprocessor. </title> <booktitle> In Proceedings of the IEEE International Conference on Computer Design, </booktitle> <pages> pages 217-220. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Octo-ber </month> <year> 1994. </year>
Reference-contexts: Recently, a number of asynchronous chips have been successfully designed and/or fabricated, both for microprocessors and DSPs [21, 11, 14, 15, 16, 26], including embedded processors <ref> [6, 7, 8] </ref>. Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder.
Reference: [7] <author> S.B. Furber, J.D. Garside, S. Temple, J. Liu, P. Day, </author> <title> and N.C. Paver. Amulet2e: An asynchronous embedded controller. </title> <booktitle> In Async97 Symposium. ACM, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: Recently, a number of asynchronous chips have been successfully designed and/or fabricated, both for microprocessors and DSPs [21, 11, 14, 15, 16, 26], including embedded processors <ref> [6, 7, 8] </ref>. Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder.
Reference: [8] <author> J.D. Garside, S. Temple, and R. Mehra. </author> <title> The amulet2e cache system. </title> <booktitle> In Async96 Symposium. ACM, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: Recently, a number of asynchronous chips have been successfully designed and/or fabricated, both for microprocessors and DSPs [21, 11, 14, 15, 16, 26], including embedded processors <ref> [6, 7, 8] </ref>. Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder.
Reference: [9] <author> R. Hashemian. </author> <title> Design and implementation of a memory efficient huffman decoding. </title> <journal> IEEE Trans. on Consumer Electronics, </journal> <volume> 40(3) </volume> <pages> 345-51, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: However, while significant compression can be obtained for small programs, the ROM table itself may be over 270 KBytes for large examples, rendering the approach impractical. 2.2 Related Work: Huffman Decoders Our design is estimated to have better performance and area than existing synchronous Huffman decoders <ref> [18, 9, 4, 17] </ref>. Most of these decoders are targeted for digital video applications, and focus on the MPEG-2 VLD decoder for the DCT coefficient table.
Reference: [10] <author> D.A. Huffman. </author> <title> A method for the construction of min imum redundancy codes. </title> <journal> Proc. IEEE, </journal> <volume> 40(10) </volume> <pages> 1098-1101, </pages> <month> September </month> <year> 1952. </year>
Reference-contexts: Very recently, we introduced the first prototype design for such an asynchronous decompression circuit [1]. Instructions are compressed in memory, using a Huffman encoding scheme <ref> [10] </ref>. Huffman codes are variable-length, where the shortest codes are assigned to the most frequent symbols. In principle, a Huffman decoder is an excellent match for asynchronous design: an asynchronous decoder can be highly-optimized for common, rather than rare, codes, and thus obtain improved average-case performance. <p> In the worst case, all symbols have the same frequency, therefore all codes are 7 bits: the weighted mean code length (dynamic average) is 7 bits and the maximum code length is 7 bits. For details on Huffman codes, see <ref> [10] </ref>. ates at 3.3 V. In contrast, our design uses 6100 transistors in a total area of 0.75 mm 2 .
Reference: [11] <author> J. Kessels and P. Marston. </author> <title> Design asynchronous standby circuits for a low-power pager. </title> <booktitle> In Async97 Symposium. ACM, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: In contrast, performance of a synchronous design may be limited, due to a worst-case fixed clock rate, or the design may have a large area overhead to handle worst-case computation efficiently. Recently, a number of asynchronous chips have been successfully designed and/or fabricated, both for microprocessors and DSPs <ref> [21, 11, 14, 15, 16, 26] </ref>, including embedded processors [6, 7, 8]. Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder.
Reference: [12] <author> M. Kozuch and A. Wolfe. </author> <title> Compression of embedded system programs. </title> <booktitle> In IEEE International Conference on Computer Design, </booktitle> <pages> pages 270-277, </pages> <month> October </month> <year> 1994. </year> <title> 6 Note that an iterative ring structure effectively has pipelined precharges, i.e., they are overlapped with evaluations. Here, though, we refer to true pipelining of several simultaneous evaluations. </title>
Reference-contexts: Sloan Research Fellowship. y This work was funded in part from NSF under award MIP-9408462 and by an AT&T foundation gift. A novel approach to designing compact embedded systems has been proposed, called a compressed code architecture <ref> [24, 12] </ref>. In this approach, instructions are stored in compressed form in memory, then are decompressed when brought into the cache. As a result, a significant reduction in instruction memory size may be obtained. <p> Section 6 compares our new design with our previous asynchronous decoder design, and Section 7 presents conclusions. 2 Background 2.1 Compressed-Code Embedded Processors An embedded system is loosely defined as one which incorporates microprocessors, or microcontrollers, yet is not itself a general-purpose computer <ref> [24, 12, 13] </ref>. Embedded systems are extremely widespread, including: controllers for automobiles, airplanes, portable consumer electronics, etc. These systems typically include a microprocessor, or microcontroller, which executes a stored program determined by the system designer. The instruction memory is either integrated on-chip, or is external [13, 25]. <p> Therefore, techniques to reduce the size of the instruction ROM are of critical importance. Recently, Wolfe et al. introduced a useful approach to designing compact embedded systems, called a compressed-code architecture <ref> [24, 12] </ref>. In this approach, embedded programs are stored in memory in compressed format, then are decompressed in the instruction cache, and executed in standard format. This solution results in reduced memory size, with only a minimal impact on processor performance. <p> The CLB (cache lookaside buffer) serves as a form of TLB for the line address table; it caches the most recently accessed LAT entries, to speed up cache line refill. The overheads of LAT and CLB are very small (see <ref> [12] </ref> for details). This compression scheme allows a substantial reduction in the size of instruction memory. Using a Huff-man encoding scheme for instructions, experiments indicate that a compression ratio of 76% (i.e., compressed program size/uncompressed program size) can be obtained for MIPS processors on typical applications [12]. <p> are very small (see <ref> [12] </ref> for details). This compression scheme allows a substantial reduction in the size of instruction memory. Using a Huff-man encoding scheme for instructions, experiments indicate that a compression ratio of 76% (i.e., compressed program size/uncompressed program size) can be obtained for MIPS processors on typical applications [12]. This ratio includes the small overheads required to detect and align variable-length compressed cache lines in instruction memory. This reduction in program size can translate into lower cost, weight and power consumption for the entire embedded system.
Reference: [13] <author> S.Y. Liao, S. Devadas, and K. Keutzer. </author> <title> Code density optimization for embedded DSP processors using data compression techniques. </title> <editor> In W.J. Dally, J.W. Poul-ton, and A.T. Ishii, editors, </editor> <booktitle> Proceedings of the 16th Conference on Advanced Research in VLSI, </booktitle> <pages> pages 272-285. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1995. </year>
Reference-contexts: Section 6 compares our new design with our previous asynchronous decoder design, and Section 7 presents conclusions. 2 Background 2.1 Compressed-Code Embedded Processors An embedded system is loosely defined as one which incorporates microprocessors, or microcontrollers, yet is not itself a general-purpose computer <ref> [24, 12, 13] </ref>. Embedded systems are extremely widespread, including: controllers for automobiles, airplanes, portable consumer electronics, etc. These systems typically include a microprocessor, or microcontroller, which executes a stored program determined by the system designer. The instruction memory is either integrated on-chip, or is external [13, 25]. <p> Embedded systems are extremely widespread, including: controllers for automobiles, airplanes, portable consumer electronics, etc. These systems typically include a microprocessor, or microcontroller, which executes a stored program determined by the system designer. The instruction memory is either integrated on-chip, or is external <ref> [13, 25] </ref>. Practical embedded systems are often limited by constraints on size, weight, power consumption and price. In particular, for low-cost and high-volume systems, the cost of the entire system is often closely tied to the total area of the chip (s). <p> In particular, for low-cost and high-volume systems, the cost of the entire system is often closely tied to the total area of the chip (s). In such systems, a significant percentage of the area may be devoted to the instruction ROM, storing the program code <ref> [13] </ref>. Therefore, techniques to reduce the size of the instruction ROM are of critical importance. Recently, Wolfe et al. introduced a useful approach to designing compact embedded systems, called a compressed-code architecture [24, 12]. <p> In contrast, Wolfe's decompres sion approach is quite general: it can be used to compress instructions in any existing instruction set, without modification. Liao, Devadas and Keutzer <ref> [13] </ref> propose software and hardware approaches to code compression, using dictionary lookup with "mini-subroutines". However, while this method is promising, it is orthogonal to Wolfe's approach: hardware compression can be used in addition to their approach. <p> Furthermore, their optimization is limited to finding exact matches of entire instructions (i.e., same op-code and operands); in contrast, Wolfe's method looks for matches at a finer granularity (byte-level). Finally, their method may adversely interact with existing code optimization techniques (see <ref> [13] </ref>), while Wolfe's method can be used with any existing code optimizer. Finally, a method by Yoshida et al. [25] compacts instruction memory using a logarithmic-based compression scheme, along with a ROM-based decompression table.
Reference: [14] <author> A.J. Martin, S.M. Burns, T.K. Lee, D. Borkovic, and P.J. Hazewindus. </author> <title> The design of an asynchronous microprocessor. </title> <booktitle> In 1989 Caltech Conference on Very Large Scale Integration, </booktitle> <year> 1989. </year>
Reference-contexts: In contrast, performance of a synchronous design may be limited, due to a worst-case fixed clock rate, or the design may have a large area overhead to handle worst-case computation efficiently. Recently, a number of asynchronous chips have been successfully designed and/or fabricated, both for microprocessors and DSPs <ref> [21, 11, 14, 15, 16, 26] </ref>, including embedded processors [6, 7, 8]. Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder.
Reference: [15] <author> T. Nanya, Y. Ueno, H. Kagotani, M. Kuwako, and A. Takamura. TITAC: </author> <title> design of a quasi-delay-insensitive microprocessor. </title> <journal> IEEE Design and Test, </journal> <volume> 11(2) </volume> <pages> 50-63, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: In contrast, performance of a synchronous design may be limited, due to a worst-case fixed clock rate, or the design may have a large area overhead to handle worst-case computation efficiently. Recently, a number of asynchronous chips have been successfully designed and/or fabricated, both for microprocessors and DSPs <ref> [21, 11, 14, 15, 16, 26] </ref>, including embedded processors [6, 7, 8]. Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder.
Reference: [16] <author> L.S. Nielsen and J. Sparso. </author> <title> A low-power asynchronous data path for a fir filter bank. </title> <booktitle> In Proceedings of the International Symposium on Advanced Research in Asynchronous Circuits and Systems (Async96), </booktitle> <pages> pages 197-207. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> November </month> <year> 1996. </year>
Reference-contexts: In contrast, performance of a synchronous design may be limited, due to a worst-case fixed clock rate, or the design may have a large area overhead to handle worst-case computation efficiently. Recently, a number of asynchronous chips have been successfully designed and/or fabricated, both for microprocessors and DSPs <ref> [21, 11, 14, 15, 16, 26] </ref>, including embedded processors [6, 7, 8]. Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder.
Reference: [17] <author> H. Park, J. Son, and S. Cho. </author> <title> Area efficient fast huff-man encoder for multimedia applications. </title> <booktitle> In ICASSP, </booktitle> <pages> pages 3279-3281, </pages> <year> 1995. </year>
Reference-contexts: However, while significant compression can be obtained for small programs, the ROM table itself may be over 270 KBytes for large examples, rendering the approach impractical. 2.2 Related Work: Huffman Decoders Our design is estimated to have better performance and area than existing synchronous Huffman decoders <ref> [18, 9, 4, 17] </ref>. Most of these decoders are targeted for digital video applications, and focus on the MPEG-2 VLD decoder for the DCT coefficient table. <p> The structure of the code is quite simple, and the code length can be easily derived from the number of leading zeros. The complexity of this code is therefore simpler than our MIPS-based code which has 256 code words. For example, the decoder by Park et al. <ref> [17] </ref> has an area is 3.5 mm 2 in a 0.65 CMOS process, compared with only 0.75 mm 2 for our design in a 0.8 process. While the authors claim a peak performance of 680 Mbit/sec, this is based on the decoding of 17-bit codewords at 40 MHz.
Reference: [18] <editor> M.K. Rudberg and L. Wanhammar. </editor> <title> New approaches to high speed huffman decoding. </title> <booktitle> In ISCAS, </booktitle> <pages> pages 149-152, </pages> <year> 1996. </year>
Reference-contexts: However, while significant compression can be obtained for small programs, the ROM table itself may be over 270 KBytes for large examples, rendering the approach impractical. 2.2 Related Work: Huffman Decoders Our design is estimated to have better performance and area than existing synchronous Huffman decoders <ref> [18, 9, 4, 17] </ref>. Most of these decoders are targeted for digital video applications, and focus on the MPEG-2 VLD decoder for the DCT coefficient table.
Reference: [19] <author> S. Segars, K. Clarke, and L. Goudge. </author> <title> Embedded control problems, </title> <journal> thumb and the ARM7TDMI. IEEE Micro, </journal> <volume> 15(5) </volume> <pages> 22-30, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Finally, compression can result in lower system power, since fewer bus cycles are required to fetch compressed instructions. Related Work. Several alternative approaches have been proposed for code compression in embedded processors, each with some limitations. A modified instruction set, called Thumb <ref> [19] </ref>, was recently introduced for the ARM processor core, which includes new 16-bit instructions taken from the standard 32-bit ARM instruction set. The goal is to reduce instruction bandwidth for embedded applications.
Reference: [20] <author> J. Sparso and J. Staunstrup. </author> <title> Design and performance analysis of delay insensitive multi-ring structures. </title> <booktitle> In Proceedings of the Twenty-Sixth Annual Hawaii International Conference on System Sciences, </booktitle> <volume> volume I, </volume> <pages> pages 349-358. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Jan-uary </month> <year> 1993. </year>
Reference-contexts: Therefore, a token can effectively propagate through each logic stage with no control overhead. Such structures have been extended to multi-rings as well <ref> [20] </ref>. Zero-overhead rings have been highly effective for the implementation of iterative computations, where latency is paramount. Therefore, the core of our new architecture is a self-timed ring, generalized to allow parallel computation threads.
Reference: [21] <author> K. van Berkel, R. Burgess, J. Kessels, M. Roncken, F. Schalij, and A. Peeters. </author> <title> Asynchronous circuits for low power: A DCC error corrector. </title> <journal> IEEE Design and Test of Computers, </journal> <volume> 11(2) </volume> <pages> 22-32, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: In contrast, performance of a synchronous design may be limited, due to a worst-case fixed clock rate, or the design may have a large area overhead to handle worst-case computation efficiently. Recently, a number of asynchronous chips have been successfully designed and/or fabricated, both for microprocessors and DSPs <ref> [21, 11, 14, 15, 16, 26] </ref>, including embedded processors [6, 7, 8]. Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder.
Reference: [22] <author> T.E. Williams. </author> <title> Self-timed rings and their application to division. </title> <type> Technical Report CSL-TR-91-482, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <year> 1991. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: The decoder is organized in the form of ring architecture a self-timed ring. These rings have been studied in depth, and applied to a number of designs such as a high-speed self-timed divider chip <ref> [22, 23] </ref>. In particular, Williams introduced a novel zero-overhead design style for self-timed rings, where control operations (e.g., precharging in a dynamic implementation) are done in background mode while other stages are computing. Therefore, a token can effectively propagate through each logic stage with no control overhead. <p> A final comparison of the new architecture with the earlier prototype appears in Section 5. 4.2 Inter-Stage Synchronization To synchronize between stages in the ring, we use an adaptation of a scheme called PS0 by Williams <ref> [22] </ref>, as shown in Figure 5. In PS0, precharged dual-rail function blocks are organized into a ring. Each function block has a completion detector, which controls the previous stage. As an example, once F 2 has evaluated, completion of evaluation is detected, which then enables F 1 to precharge.
Reference: [23] <author> T.E. Williams and M.A. Horowitz. </author> <title> A zero-overhead self-timed 54b 160ns CMOS divider. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> 26(11) </volume> <pages> 1651-1661, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: The decoder is organized in the form of ring architecture a self-timed ring. These rings have been studied in depth, and applied to a number of designs such as a high-speed self-timed divider chip <ref> [22, 23] </ref>. In particular, Williams introduced a novel zero-overhead design style for self-timed rings, where control operations (e.g., precharging in a dynamic implementation) are done in background mode while other stages are computing. Therefore, a token can effectively propagate through each logic stage with no control overhead.
Reference: [24] <author> A. Wolfe and A. Chanin. </author> <title> Executing compressed programs on an embedded RISC processor. </title> <booktitle> In 25th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 81-91, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Sloan Research Fellowship. y This work was funded in part from NSF under award MIP-9408462 and by an AT&T foundation gift. A novel approach to designing compact embedded systems has been proposed, called a compressed code architecture <ref> [24, 12] </ref>. In this approach, instructions are stored in compressed form in memory, then are decompressed when brought into the cache. As a result, a significant reduction in instruction memory size may be obtained. <p> Section 6 compares our new design with our previous asynchronous decoder design, and Section 7 presents conclusions. 2 Background 2.1 Compressed-Code Embedded Processors An embedded system is loosely defined as one which incorporates microprocessors, or microcontrollers, yet is not itself a general-purpose computer <ref> [24, 12, 13] </ref>. Embedded systems are extremely widespread, including: controllers for automobiles, airplanes, portable consumer electronics, etc. These systems typically include a microprocessor, or microcontroller, which executes a stored program determined by the system designer. The instruction memory is either integrated on-chip, or is external [13, 25]. <p> Therefore, techniques to reduce the size of the instruction ROM are of critical importance. Recently, Wolfe et al. introduced a useful approach to designing compact embedded systems, called a compressed-code architecture <ref> [24, 12] </ref>. In this approach, embedded programs are stored in memory in compressed format, then are decompressed in the instruction cache, and executed in standard format. This solution results in reduced memory size, with only a minimal impact on processor performance.
Reference: [25] <author> Y. Yoshida, B.-Y. Song, H. Okuhata, T. Onoye, and I. Shirakawa. </author> <title> An object code compression approach to embedded processors. </title> <booktitle> In International Symposium on Low Power Electronics and Design (ISLPED), </booktitle> <pages> pages 265-268. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1997. </year>
Reference-contexts: Embedded systems are extremely widespread, including: controllers for automobiles, airplanes, portable consumer electronics, etc. These systems typically include a microprocessor, or microcontroller, which executes a stored program determined by the system designer. The instruction memory is either integrated on-chip, or is external <ref> [13, 25] </ref>. Practical embedded systems are often limited by constraints on size, weight, power consumption and price. In particular, for low-cost and high-volume systems, the cost of the entire system is often closely tied to the total area of the chip (s). <p> Finally, their method may adversely interact with existing code optimization techniques (see [13]), while Wolfe's method can be used with any existing code optimizer. Finally, a method by Yoshida et al. <ref> [25] </ref> compacts instruction memory using a logarithmic-based compression scheme, along with a ROM-based decompression table.
Reference: [26] <author> K.Y. Yun, P.A. Beerel, A.E. Dooply, J. Arceo, and V. Vakilotojar. </author> <title> The design and verification of a high-performance low-control-overhead asynchronous differential equation solver. </title> <booktitle> In Async97 Symposium. ACM, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: In contrast, performance of a synchronous design may be limited, due to a worst-case fixed clock rate, or the design may have a large area overhead to handle worst-case computation efficiently. Recently, a number of asynchronous chips have been successfully designed and/or fabricated, both for microprocessors and DSPs <ref> [21, 11, 14, 15, 16, 26] </ref>, including embedded processors [6, 7, 8]. Several of these designs have demonstrated the benefits of asynchronous design for average-case operation. In this paper, we propose a new architecture an implementation of an asynchronous Huffman decoder.
References-found: 26

