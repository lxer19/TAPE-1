URL: http://www.cs.berkeley.edu/~carson/papers/eccv96.ps.gz
Refering-URL: http://www.cs.berkeley.edu/projects/vision/publications.html
Root-URL: 
Phone: 2  3  
Title: Finding Pictures of Objects in Large Collections of Images  
Author: David A. Forsyth Jitendra Malik Margaret M. Fleck Hayit Greenspan ; Thomas Leung Serge Belongie Chad Carson Chris Bregler 
Address: Berkeley, Berkeley CA 94720  Iowa, Iowa City, IA 52240  Pasadena CA 91125  
Affiliation: 1 Computer Science Division, University of California at  Dept. of Computer Science, University of  Dept. of Electrical Engineering, Caltech,  
Abstract: Retrieving images from very large collections, using image content as a key, is becoming an important problem. Users prefer to ask for pictures using notions of content that are strongly oriented to the presence of abstractly defined objects. Computer programs that implement these queries automatically are desirable, but are hard to build because conventional object recognition techniques from computer vision cannot recognize very general objects in very general contexts. This paper describes our approach to object recognition, which is structured around a sequence of increasingly specialized grouping activities that assemble coherent regions of image that can be shown to satisfy increasingly stringent constraints. The constraints that are satisfied provide a form of object classification in quite general contexts. This view of recognition is distinguished by: far richer involvement of early visual primitives, including color and texture; hierarchical grouping and learning strategies in the classification process; the ability to deal with rather general objects in uncontrolled configurations and contexts. We illustrate these properties with four case-studies: one demonstrating the use of color and texture descriptors; one showing how trees can be described by fusing texture and geometric properties; one learning scenery concepts using grouped features; and one showing how this view of recognition yields a program that can tell, quite accurately, whether a picture contains naked people or not.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Ashley, J., Barber, R., Flickner, M.D., Hafner, J.L., Lee, D., Niblack, W. and Petkovich, D. </author> <title> (1995) "Automatic and semiautomatic methods for image annotation and retrieval in QBIC," </title> <booktitle> SPIE Proc. Storage and Retrieval for Image and Video Databases III, </booktitle> <pages> 24-35. </pages>
Reference-contexts: Another example is the collection of images available on the Internet, which is notoriously large and disorderly. This lack of structure makes it hard to rely on textual annotations in indexing computer programs that could automatically assess image content are a more practical alternative <ref> (Sclaroff, 1995) </ref>. Another reason that manual indexing is difficult is that it can be hard to pre-dict future content queries; for example, local political figures may reach national importance long after an image has been indexed. In a very large collection, the subsequent reindexing process becomes onerous. <p> Sirovich and Kirby, 1987; Turk and Pentland, 1991; Murase and Nayar, 1995). All of the approaches described rely heavily on specific, detailed geometry, known (or easily determined) correspondences, and either the existence of a single object on a uniform, known background <ref> (in the case of Murase and Na-yar, 1995) </ref> or the prospect of relatively clear segmentation. None is competent to perform abstract classification; this emphasis appears to be related to the underlying notion of model, rather than to the relative difficulty of the classification vs. identification. <p> Object-oriented queries search for images that contain particular objects; such queries can be seen either as constructs on material queries <ref> (Picard and Minka, 1995) </ref> as essentially textual matters (Price et al., 1992), or as the proper domain of object recognition. The best-known image database system is QBIC (Niblack et al., 1993) which allows an operator to specify various properties of a desired image. <p> The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match. The operator can adjust the scoring function. Region segmentation is largely manual, but the most recent versions of QBIC <ref> (Ashley et al., 1995) </ref> contain simple automated segmentation facilities. The representations constructed are a hierarchy of oriented rectangles of fixed internal color and a set of tiles on a fixed grid, which are described by internal color and texture properties. <p> Further examples of systems that identify materials using low-level image properties include Virage (home page at http://www.virage.com/), Candid (home page at http://www.c3.lanl.gov/ kelly/CANDID/main.shtml and Kelly et al., 1995) and Chabot <ref> (Ogle and Stonebraker, 1995) </ref>. None of these systems code spatial organization in a way that supports object queries. <p> To achieve an object-oriented query system there is a need to go to higher levels of the representation hierarchy and to encode spatial relationships using higher-level grouping features. Finally, there is a query mode that looks for images that are near iconic matches of a given image <ref> (for example, Jacobs et al., 1995) </ref>. <p> It is often possible to tell from region properties alone whether the region is likely to have come from a constrained class of shapes <ref> (eg Zisserman et al., 1995) </ref>; knowing the class of shape from which a region came allows other inferences. <p> Texture is a well-researched property of image regions, and many texture descriptors have been proposed, including multi-orientation filter banks (e.g. Malik and Perona, 1990; Greenspan et al.,1994), the second-moment matrix (Forstner, 1993; G-arding and Lindeberg, 1995), and orientation histograms <ref> (Freeman and Roth, 1995) </ref>. We will not elaborate here on some of the more classical approaches to texture segmentation and classification- both of which are challenging and well-studied tasks. <p> Because of the viewing conditions, the image of a tree corresponding to this model will have a bilateral symmetry about a vertical axis, a special case of the planar harmonic homology of <ref> (Mukherjee et al., 1995) </ref>. This axis provides part of a coordinate system in which the representation can be computed. The other is provided by the outline of the tree, which establishes scale and translation along the axis and scale perpendicular to the axis.
Reference: 2. <author> Belongie, S., Blasi, R., and Murphy, K. </author> <title> (1996) "Grouping of Color and Texture Features for Automated Image Annotation," </title> <type> Technical Report for CS280, </type> <institution> University of California Berkeley. </institution>
Reference: 3. <author> Brady, J.M. and Asada, H. </author> <title> (1984) "Smoothed Local Symmetries and Their Implementation," </title> <journal> Int. J. Robotics Res. </journal> <volume> 3/3, </volume> <pages> 36-61. </pages>
Reference: 4. <author> Brooks, R.A. </author> <title> (1981) "Symbolic Reasoning among 3-D Models and 2-D Images," </title> <booktitle> Artificial Intelligence 17, </booktitle> <pages> pp. 285-348. </pages>
Reference: 5. <author> Burel, G., and Carel, D. </author> <title> (1994) "Detecting and localization of face on digital images" Pattern Recognition Letters 15 pp 963-967. </title>
Reference: 6. <author> Burt, P.J., and Adelson, </author> <title> E.H., (1983) "The Laplacian Pyramid as a Compact Image Code," </title> <journal> IEEE Trans. on Communications, </journal> <volume> vol. com-31, no. </volume> <pages> 4. </pages>
Reference: 7. <author> Canny, J.F. </author> <title> (1986) "A Computational Approach to Edge Detection," </title> <journal> IEEE Patt. Anal. Mach. Int. </journal> <volume> 8/6, </volume> <pages> pp. 679-698. </pages>
Reference: 8. <author> Connell, J.H., and Brady, J.M. </author> <title> (1987) "Generating and Generalizing Models of Visual Objects," </title> <journal> Artificial Intelligence, </journal> <volume> 31, 2, </volume> <pages> 159-183. </pages>
Reference: 9. <author> Fleck, Margaret M. </author> <title> (1996) "The Topology of Boundaries," in press, </title> <journal> Artificial Intelligence. </journal>
Reference-contexts: The combination of these features provide us with feature-vectors from which the desired categorization is enabled. Figs. 1 and 2 display preliminary results of the textured-region analysis. A second problem of interest is the detection of periodic repetition of a basic tile, as a means for region grouping <ref> (Leung and Malik, 1996) </ref>. Such regions can be described by a representation which characterizes the individual basic element, and then represents the spatial relationships between these elements. Spatial relationships are represented by a graph where nodes correspond to individual elements and arcs join spatially neighboring elements. <p> An example of repetitive tile grouping is presented in Fig. 3. A more elaborate description of this work can be found in <ref> (Leung and Malik, 1996) </ref>. Of-course, texture need not be studied purely as a gray-scale phenomenon. Many interesting textures, such as fields of flowers, consist of a representative spatial distribution of colored elements. Color is yet another important cue in extracting information from images. <p> Attempting to classify images based on whether they contain naked people or not provides a useful special case that emphasizes the structural representation over segmentation, because naked people display a very limited range of colors and are untextured. Our system <ref> (Fleck et al., 1996) </ref> for telling whether an image contains naked people: first locates images containing large areas of skin-colored region; then, within these areas, finds elongated regions and groups them into pos sible human limbs and connected groups of limbs.
Reference: 10. <author> Fleck, M.M., Forsyth, D.A., and Bregler, C. </author> <booktitle> (1996) "Finding Naked People,"Fourth European Conference on Computer Vision, Cambridge, UK, </booktitle> <volume> Vol 2, </volume> <pages> pp. 593-602. </pages>
Reference: 11. <author> Forstner, W. </author> <note> (1993) Chapter 16, in Haralick, </note> <author> R. and Shapiro, L. </author> <title> Computer and Robot Vision, </title> <publisher> Addison-Wesley. </publisher>
Reference: 12. <author> Forsyth, D.A., Mundy, J.L., Zisserman, A.P., Heller, A., Coehlo, C., and Rothwell, </author> <title> C.A. (1991) "Invariant Descriptors for 3D Recognition and Pose," </title> <journal> IEEE Trans. Patt. Anal. and Mach. Intelligence, </journal> <volume> 13, </volume> <pages> 10. </pages>
Reference: 13. <author> Freeman, W., and Roth, M. </author> <title> (1995) Orientation histograms for hand gesture recognition. </title> <booktitle> International Workshop on Automatic Face- and Gesture-Recognition. </booktitle>
Reference: 14. <author> Garding, J., and Lindeberg, T. </author> <title> (1996) Direct computation of shape cues using scale-adapted spatial derivative operators. </title> <journal> Int. J. of Computer Vision, </journal> <volume> 17, </volume> <month> Febru-ary </month> <year> 1996. </year>
Reference: 15. <author> Greenspan, H., Goodman R., Chellappa, R., and Anderson, S. </author> <title> (1994) "Learning Texture Discrimination Rules in a Multiresolution System," </title> <journal> in the special issue on "Learning in Computer Vision" of the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), </journal> <volume> Vol. 16, No. 9, </volume> <pages> 894-901. </pages>
Reference: 16. <author> Greenspan, H., Belongie, S., Perona, P., and Goodman, R. </author> <title> (1994) "Rotation In--variant Texture Recognition Using a Steerable Pyramid," </title> <booktitle> 12th International Conference on Pattern Recognition (ICPR), </booktitle> <address> Jerusalem, Israel. </address>
Reference: 17. <author> Grimson, W.E.L. and Lozano-Perez, T. </author> <title> (1987) "Localising overlapping parts by searching the interpretation tree", </title> <journal> PAMI, </journal> <volume> 9, </volume> <pages> 469-482. </pages>
Reference: 18. <author> Huttenlocher, D.P. and Ullman, S. </author> <title> (1986) "Object recognition using alignment," </title> <booktitle> Proc. ICCV-1, </booktitle> <pages> 102-111. </pages>
Reference: 19. <author> Jacobs, C.E., Finkelstein, A., and Salesin, D.H. </author> <title> (1995) "Fast Multiresolution Image Querying," </title> <booktitle> Proc SIGGRAPH-95, </booktitle> <pages> 277-285. </pages>
Reference-contexts: Another example is the collection of images available on the Internet, which is notoriously large and disorderly. This lack of structure makes it hard to rely on textual annotations in indexing computer programs that could automatically assess image content are a more practical alternative <ref> (Sclaroff, 1995) </ref>. Another reason that manual indexing is difficult is that it can be hard to pre-dict future content queries; for example, local political figures may reach national importance long after an image has been indexed. In a very large collection, the subsequent reindexing process becomes onerous. <p> Sirovich and Kirby, 1987; Turk and Pentland, 1991; Murase and Nayar, 1995). All of the approaches described rely heavily on specific, detailed geometry, known (or easily determined) correspondences, and either the existence of a single object on a uniform, known background <ref> (in the case of Murase and Na-yar, 1995) </ref> or the prospect of relatively clear segmentation. None is competent to perform abstract classification; this emphasis appears to be related to the underlying notion of model, rather than to the relative difficulty of the classification vs. identification. <p> Object-oriented queries search for images that contain particular objects; such queries can be seen either as constructs on material queries <ref> (Picard and Minka, 1995) </ref> as essentially textual matters (Price et al., 1992), or as the proper domain of object recognition. The best-known image database system is QBIC (Niblack et al., 1993) which allows an operator to specify various properties of a desired image. <p> The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match. The operator can adjust the scoring function. Region segmentation is largely manual, but the most recent versions of QBIC <ref> (Ashley et al., 1995) </ref> contain simple automated segmentation facilities. The representations constructed are a hierarchy of oriented rectangles of fixed internal color and a set of tiles on a fixed grid, which are described by internal color and texture properties. <p> Further examples of systems that identify materials using low-level image properties include Virage (home page at http://www.virage.com/), Candid (home page at http://www.c3.lanl.gov/ kelly/CANDID/main.shtml and Kelly et al., 1995) and Chabot <ref> (Ogle and Stonebraker, 1995) </ref>. None of these systems code spatial organization in a way that supports object queries. <p> To achieve an object-oriented query system there is a need to go to higher levels of the representation hierarchy and to encode spatial relationships using higher-level grouping features. Finally, there is a query mode that looks for images that are near iconic matches of a given image <ref> (for example, Jacobs et al., 1995) </ref>. <p> It is often possible to tell from region properties alone whether the region is likely to have come from a constrained class of shapes <ref> (eg Zisserman et al., 1995) </ref>; knowing the class of shape from which a region came allows other inferences. <p> Texture is a well-researched property of image regions, and many texture descriptors have been proposed, including multi-orientation filter banks (e.g. Malik and Perona, 1990; Greenspan et al.,1994), the second-moment matrix (Forstner, 1993; G-arding and Lindeberg, 1995), and orientation histograms <ref> (Freeman and Roth, 1995) </ref>. We will not elaborate here on some of the more classical approaches to texture segmentation and classification- both of which are challenging and well-studied tasks. <p> Because of the viewing conditions, the image of a tree corresponding to this model will have a bilateral symmetry about a vertical axis, a special case of the planar harmonic homology of <ref> (Mukherjee et al., 1995) </ref>. This axis provides part of a coordinate system in which the representation can be computed. The other is provided by the outline of the tree, which establishes scale and translation along the axis and scale perpendicular to the axis.
Reference: 20. <author> Kelly, P.M., Cannon, M., Hush, </author> <title> D.R. (1995) "Query by image example: the comparison algorithm for navigating digital image databases (CANDID) approach," </title> <booktitle> SPIE Proc. Storage and Retrieval for Image and Video Databases III, </booktitle> <pages> 238-249. </pages>
Reference: 21. <author> Kriegman, D. and Ponce, J. </author> <title> (1994) "Representations for recognising complex curved 3D objects," </title> <booktitle> Proc. International NSF-ARPA workshop on object representation in computer vision, LNCS-994, </booktitle> <pages> 89-100. </pages>
Reference: 22. <author> Lamdan, Y., Schwartz, J.T. and Wolfson, H.J. </author> <title> (1988) "Object Recognition by Affine Invariant Matching," </title> <booktitle> Proceedings CVPR, </booktitle> <address> p.335-344. </address>
Reference: 23. <author> Layne, S.S. </author> <title> (1994) "Some issues in the indexing of images," </title> <journal> J. Am. Soc. Information Science, </journal> <volume> 45, 8, </volume> <pages> 583-588. </pages>
Reference: 24. <author> Leung, T.K., Burl, M.C., Perona, P. </author> <title> (1995) "Finding faces in cluttered scenes using random labelled graph matching, </title> " <booktitle> International Conference on Computer Vision pp 637-644. </booktitle>
Reference: 25. <author> Leung, T.K., and Malik, J., </author> <title> "Detecting, localizing and grouping repeated scene elements from an image," </title> <booktitle> (1996) Fourth European Conference on Computer Vision, Cambridge, UK, </booktitle> <volume> Vol 1, </volume> <pages> pp. 546-555. </pages>
Reference: 26. <author> Liu, J., Mundy, J.L., Forsyth, D.A., Zisserman, </author> <title> A.P., and Rothwell, C.A. (1993) "Efficient Recognition of rotationally symmetric surfaces and straight homogenous generalized cylinders," </title> <booktitle> IEEE Conference on Computer Vision and Pattern Recognition '93. </booktitle>
Reference: 27. <author> Lowe, David G. </author> <title> (1987) "The Viewpoint Consistency Constraint," </title> <journal> Intern. J. of Comp. Vis, </journal> <volume> 1/1, </volume> <pages> pp. 57-72. </pages>
Reference: 28. <author> Malik, J., and Perona, P. </author> <title> (1990) "Preattentive texture discrimination with early vision mechanisms," </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 7(5) </volume> <pages> 923-932. </pages>
Reference: 29. <author> Malik, J., and Rosenholtz, R. </author> <title> (1994) "Recovering surface curvature and orientation from texture distortion: a least squares algorithm and sensitivity analysis," </title> <booktitle> Proc. of Third European Conf. on Computer Vision, </booktitle> <address> Stockholm, </address> <note> published as J.O. </note> <editor> Eklundh (ed.) </editor> <publisher> LNCS 800, Springer Verlag, </publisher> <pages> pp. 353-364. </pages>
Reference: 30. <author> Minka, T. </author> <title> (1995) "An image database browser that learns from user interaction," </title> <type> MIT media lab TR 365. </type>
Reference: 31. <author> Mukherjee, D.P., Zisserman, A., and Brady, J.M. </author> <title> (1995) "Shape from symmetry - detecting and exploiting symmetry in affine images," </title> <journal> Proc. Roy. Soc., </journal> <volume> 351, </volume> <pages> 77-106. </pages>
Reference: 32. <author> Murase, H. and Nayar, </author> <title> S.K. (1995) "Visual learning and recognition of 3D objects from appearance," </title> <journal> Int. J. Computer Vision, </journal> <volume> 14, 1, </volume> <pages> 5-24. </pages>
Reference: 33. <author> Nevatia, R. and Binford, </author> <title> T.O. (1977) "Description and recognition of curved objects," </title> <journal> Artificial Intelligence, </journal> <volume> 8, </volume> <pages> 77-98, </pages> <year> 1977 </year>
Reference: 34. <author> Niblack, W., Barber, R, Equitz, W., Flickner, M., Glasman, E., Petkovic, D., and Yanker, P. </author> <title> (1993) "The QBIC project: querying images by content using colour, texture and shape," </title> <booktitle> IS and T/SPIE 1993 Intern. Symp. Electr. Imaging: Science and Technology, Conference 1908, Storage and Retrieval for Image and Video Databases. </booktitle>
Reference: 35. <author> Ogle, Virginia E. and Michael Stonebraker (1995) "Chabot: </author> <title> Retrieval from a Re--lational Database of Images," </title> <booktitle> Computer 28/9, </booktitle> <pages> pp. 40-48. </pages>
Reference: 36. <author> Pentland A., Moghaddam, B., Starner T., </author> <title> (1994) "View-based and modular eigenspaces for face recognition," </title> <journal> Computer Vision and Pattern Recognition, </journal> <pages> pp 84-91. </pages>
Reference: 37. <author> Pentland, A., Picard, R.W., and Sclaroff, S. </author> <year> (1993) </year> <month> "Photobook: </month> <title> content-based manipulation of image databases," MIT Media Lab Perceptual Computing TR No. </title> <type> 255. </type>
Reference: 38. <author> Picard, R.W. and Minka, T. </author> <title> (1995) "Vision texture for annotation," </title> <journal> J. Multimedia systems, </journal> <volume> 3, </volume> <pages> 3-14. </pages>
Reference: 39. <author> Polana, R., Nelon, R. </author> <title> (1993) "Detecting Activities" Computer Vision and Pattern Recognition pp 2-13. </title>
Reference: 40. <author> Price, R., Chua, T.-S., Al-Hawamdeh, S. </author> <title> (1992) "Applying relevance feedback to a photo-archival system," </title> <journal> J. Information Sci., </journal> <volume> 18, </volume> <pages> 203-215. </pages>
Reference: 41. <author> J. R. Quinlan, </author> <title> C4.5 Programs for Machine Learning, </title> <publisher> Morgan Kauffman, </publisher> <year> 1993. </year>
Reference: 42. <author> Rothwell, C.A., Zisserman, A., Mundy, J.L., and Forsyth, D.A. </author> <title> (1992) "Efficient Model Library Access by Projectively Invariant Indexing Functions," </title> <booktitle> Computer Vision and Pattern Recognition 92, </booktitle> <pages> 109-114. </pages>
Reference: 43. <author> Rowley, H., Baluja, S., Kanade, T. </author> <title> (1996) "Human Face Detection in Visual Scenes" NIPS, </title> <booktitle> volume 8, </booktitle> <year> 1996. </year>
Reference: 44. <author> Sclaroff, S. </author> <title> (1995) "World wide web image search engines," </title> <institution> Boston University Computer Science Dept TR95-016. </institution>
Reference: 45. <author> Sirovitch, L. and Kirby, M., </author> <title> "Low-dimensional procedure for the characterization of human faces," </title> <journal> J. Opt. Soc. America A, </journal> <volume> 2, </volume> <pages> 519-524, </pages> <year> 1987. </year>
Reference: 46. <author> Stein, F. and Medioni, G. </author> <title> (1992) "Structural indexing: efficient 3D object recognition," </title> <booktitle> PAMI-14, </booktitle> <pages> 125-145. </pages>
Reference: 47. <author> Sung, K.K, Poggio, T., </author> <title> (1994) "Example-based Learning from View-based Human Face Detection" MIT A.I. Lab Memo No. </title> <type> 1521. </type>
Reference: 48. <author> Taubin, G. and Cooper, </author> <title> D.B. (1992) "Object recognition based on moment (or algebraic) invariants," in J.L. Mundy and A.P. Zisserman (ed.s) Geometric Invari-ance in Computer Vision, </title> <publisher> MIT Press. </publisher>
Reference: 49. <author> Taylor, B., </author> <note> (1977) "Tense and Continuity" Linguistics and Philosophy 1 199-220. </note>
Reference: 50. <author> Tenny, C.L. </author> <title> (1987) "Grammaticalizing Aspect and Affectedness," </title> <type> Ph.D. thesis, </type> <institution> Linguistics and Philosophy, Massachusetts Inst. of Techn. </institution>
Reference: 51. <author> Turk, M. and Pentland, A., </author> <title> "Eigenfaces for recognition," </title> <journal> J. Cognitive Neuroscience, </journal> <volume> 3, 1, </volume> <year> 1991. </year>
Reference: 52. <author> Ullman, S. and Basri, R. </author> <title> (1991) "Recognition by linear combination of models," </title> <journal> IEEE PAMI, </journal> <volume> 13, 10, </volume> <pages> 992-1007. </pages>
Reference: 53. <author> Weiss, I. </author> <title> (1988) "Projective Invariants of Shapes," </title> <booktitle> Proceeding DARPA Image Understanding Workshop, </booktitle> <address> p.1125-1134. </address>
Reference: 54. <author> Whorf, B.L. </author> <title> (1941) "The Relation of Habitual Thought and Behavior to Language," in Leslie Spier, ed., Language, culture, and personality, essays in memory of Edward Sapir, </title> <note> Sapir Memorial Publication Fund, Menasha, WI. </note>
Reference: 55. <author> Zerroug, M. and Nevatia, R. </author> <title> (1994) "From an intensity image to 3D segmented descriptions," </title> <booktitle> Proc 12'th ICPR, </booktitle> <pages> 108-113. </pages>
Reference: 56. <author> Zisserman, A., Mundy, J.L., Forsyth, D.A., Liu, J.S., Pillow, N., Rothwell, C.A. and Utcke, S. </author> <title> (1995) "Class-based grouping in perspective images", Intern. Conf. on Comp. Vis. This article was processed using the L a T E X macro package with LLNCS style </title>
References-found: 56

