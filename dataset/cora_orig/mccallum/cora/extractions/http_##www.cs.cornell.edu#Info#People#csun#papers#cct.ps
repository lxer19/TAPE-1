URL: http://www.cs.cornell.edu/Info/People/csun/papers/cct.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/csun/sun.html
Root-URL: 
Title: Compact Clique Tree Data Structures in Sparse Matrix Factorizations  
Author: Alex Pothen and Chunguang Sun 
Keyword: chordal graph, clique tree, compact clique tree, skeleton matrix, skeleton clique tree, sparse Cholesky factorization, sparse matrix.  
Web: 65F50, 65F25, 68R10.  
Note: AMS(MOS) subject classifications:  
Abstract: This paper appears in Large-Scale Numerical Optimization, T. F. Coleman and Y. Li, eds., SIAM, Philadelphia, 1990, pp. 180-204. Abstract The design of compact data structures for representing the structure of the Cholesky factor L of a sparse, symmetric positive definite matrix A is considered. The clique tree data structure described in [16] provides a compact representation when the structure of L must be stored explicitly. Two more compact data structures, the compact clique tree and the skeleton clique tree, which represent the structure of L implicitly, i.e., when some computation on the data structure is permitted to obtain the structure of L, are described. Matrix interpretations of these data structures are provided. The situations when these data structures differ are characterized, and it is proved that the compact clique tree is the smaller of the two in size. There exist filled graphs on n vertices where the compact clique tree has size fi(n) while the skeleton clique tree has size fi(n 2 ), though experimentally the two are almost identical for filled graphs obtained from common ordering algorithms. A partial justification is provided for this phenomenon. Computational results on some Boeing-Harwell test problems show that these data structures require substantially less space than either the clique tree or the matrix A. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Ashcraft, </author> <title> A vector implementation of the multifrontal method for large, sparse, symmetric, positive definite linear systems, </title> <type> Tech. Report ETA-TR-51, </type> <institution> Engineering Technology Applications Division, Boeing Computer Services, </institution> <address> Seattle, WA, </address> <year> 1987. </year> <month> 26 </month>
Reference-contexts: Their idea is to discard most nonzero values in the columns of L, and recompute them as necessary within the framework of a divide and conquer approach. The algorithm is organized around a data structure called the element merge tree, which is similar to the elimination tree. Ashcraft <ref> [1] </ref> has reported results from a vectorized implementation of a multifrontal sparse Cholesky factorization. He computes a supernodal elimination tree which is defined on the supernodes.
Reference: [2] <author> C. Ashcraft, R. Grimes, J. Lewis, B. Peyton, and H. Simon, </author> <title> Progress in sparse matrix methods for large linear systems on vector supercomputers, </title> <journal> Int. J. Supercomputer Appl., </journal> <volume> 1 (1987), </volume> <pages> pp. 10-30. </pages>
Reference-contexts: Our restrictive definition corresponds to choosing the root clique of this subtree as the parent of K. Supernodes and clique trees. Supernodes have been used in the ordering and symbolic factorization steps [12] and more recently, in the numeric factorization step of sparse factorizations <ref> [2] </ref> to increase the efficiency of the computations. <p> Finally, a partial supernode partition is a supernode partition if every supernode in the partition is a maximal supernode. 8 Partial supernode partitions have been used by Ashcraft et al. <ref> [2] </ref> for vectorized numerical factorization. The paper [21] includes an O (n) algorithm for computing the supernode partition from the etree. It is not difficult to verify that the new sets of the maximal cliques in a clique tree form a supernode partition. <p> We consider one-pass algorithms in which once data is 23 moved out of core, it is not required again. This feature of the algorithm reduces input--output operations which are typically expensive. A description of out-of-core algorithms for sparse Cholesky factorization may be found in Ashcraft et al. <ref> [2] </ref>. Initially consider using the clique tree to organize the algorithm. In the numerical factorization step, the columns of L corresponding to the new vertices of a maximal clique K can be computed together. <p> Thus the use of the cct or sct makes more space available to perform the factorization, reducing the number of garbage collection steps required in the course of the algorithm. Ashcraft et al. <ref> [2] </ref> report that garbage collection on the integer subscripts together with the numerical values of the nonzeros provides an order of magnitude reduction in the integer storage required for an out-of-core sparse Cholesky factorization algorithm. They recommend that this feature be included in software for out-of-core factorizations.
Reference: [3] <author> R. E. Bank and D. J. Rose, </author> <title> On the complexity of sparse Gaussian elimination via bordering, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 11 (1990), </volume> <pages> pp. 145-160. </pages>
Reference-contexts: But the structure of such a row j is not necessarily a subset of the structure of row k. Hence it is not known how to compute these intersections in time proportional to the number of nonzeros involved in the computations at this step. Bank and Rose <ref> [3] </ref> have recently described a solution of this problem for grid graphs. Eisenstat, Schultz, and Sherman [8] have proposed a variant of Cholesky factorization for finite element problems on machines with limited core storage without making use of auxiliary storage.
Reference: [4] <author> R. E. Bank and R. K. Smith, </author> <title> General sparse elimination requires no permanent integer storage, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 8 (1987), </volume> <pages> pp. 574-584. </pages>
Reference-contexts: George and Liu [13] have extended this work to static storage implementations of Gaussian elimination and orthogonal factorization. Bank and Smith <ref> [4] </ref> have described a row-oriented data structure for the factorization of a sparse matrix with a symmetric nonzero structure in which overhead storage is required only for the nonzeros of A. The structure of the rows of L are computed as necessary from the corresponding rows of A.
Reference: [5] <author> J. R. S. Blair, R. E. England, and M. G. Thomason, </author> <title> Cliques and their separators in triangulated graphs, </title> <type> Tech. Report CS73-88, </type> <institution> Computer Science, University of Tennessee, Knoxville, </institution> <month> Aug </month> <year> 1988. </year>
Reference-contexts: A general approach uses the clique graph, which is the edge-weighted intersection graph of the maximal cliques. The weight of an edge joining two maximal cliques K i and K j is the 3 number of vertices common to both cliques. Blair, English, and Thomason <ref> [5] </ref> then show that a clique tree may be characterized as any maximum-weight spanning tree of the clique graph. Earlier approaches for computing clique trees include Gavril [10], Walter [25], and Tarjan and Yannakakis [24] (see also Golumbic [14]).
Reference: [6] <author> I. S. Duff, A. M. Erisman, and J. K. Reid, </author> <title> Direct Methods for Sparse Matrices, </title> <publisher> Clarendon Press, Oxford, </publisher> <address> England, </address> <year> 1986. </year>
Reference-contexts: Hence it will be advantageous in parallel algorithms to communicate the cct or sct between processors and then let each processor compute the clique tree. Related work. The compressed column storage scheme of Sherman [23] is used in modern sparse matrix software <ref> [6, 12] </ref>. This is a column oriented storage scheme for the Cholesky factor in which overlaps between the row subscripts of consecutively numbered columns are exploited to compress the subscripts.
Reference: [7] <author> I. S. Duff, R. Grimes, and J. Lewis, </author> <title> Sparse matrix test problems, </title> <journal> ACM Trans. on Math. Software, </journal> <volume> 15 (1989), </volume> <pages> pp. 1-14. </pages>
Reference-contexts: Computational results. In this section, we report results pertaining to the computation of the various clique tree data structures for a set of large problems from the Boeing-Harwell collection <ref> [7] </ref>. The results we report were obtained by ordering the matrices using Liu's Multiple Minimum Degree (MMD) ordering [17]. All programs were written in C, and the computations were performed on one processor of a Cray-2 running Unicos 5.1, using version 5:0:2 of the C compiler.
Reference: [8] <author> S. Eisenstat, M. Schultz, and A. Sherman, </author> <title> Software for sparse Gaussian elimination with limited core storage, in Sparse Matrix Proceedings, </title> <editor> I. Duff and G. Stewart, eds., </editor> <booktitle> Society for Industrial and Applied Mathematics, </booktitle> <address> Philadelphia, </address> <year> 1978, </year> <pages> pp. 135-153. </pages>
Reference-contexts: Hence it is not known how to compute these intersections in time proportional to the number of nonzeros involved in the computations at this step. Bank and Rose [3] have recently described a solution of this problem for grid graphs. Eisenstat, Schultz, and Sherman <ref> [8] </ref> have proposed a variant of Cholesky factorization for finite element problems on machines with limited core storage without making use of auxiliary storage.
Reference: [9] <author> D. R. Fulkerson and O. A. Gross, </author> <title> Incidence matrices and interval graphs, </title> <journal> Pacific J. Math., </journal> <volume> 15 (1965), </volume> <pages> pp. 835-855. </pages>
Reference-contexts: We will not distinguish between a clique and its set of vertices. A clique K is a maximal clique if there exists no other vertex v of G such that K [ fvg is a clique. A result of Fulkerson and Gross <ref> [9] </ref> in the next section shows that the maximal cliques of a chordal graph are unique. <p> The vertices of a clique tree are the maximal cliques of the chordal graph G, and therefore, the first step in computing a clique tree is to identify the maximal cliques of the filled graph. They are easily identified by the following characterization due to Fulkerson and Gross <ref> [9] </ref>. Proposition 2.1. Let K be a maximal clique in a chordal graph G whose vertices are numbered in a PEO.
Reference: [10] <author> F. Gavril, </author> <title> The intersection graphs of subtrees are exactly the chordal graphs, </title> <journal> J. Comb. Theory, Ser. B, </journal> <volume> 16 (1974), </volume> <pages> pp. 47-56. </pages>
Reference-contexts: Blair, English, and Thomason [5] then show that a clique tree may be characterized as any maximum-weight spanning tree of the clique graph. Earlier approaches for computing clique trees include Gavril <ref> [10] </ref>, Walter [25], and Tarjan and Yannakakis [24] (see also Golumbic [14]). In his thesis, Peyton [20] describes an O (e) algorithm to compute clique trees from the adjacency lists of the chordal graph using maximum cardinality search.
Reference: [11] <author> J. A. George, </author> <title> Nested dissection of a regular finite element mesh, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 15 (1978), </volume> <pages> pp. 1053-1069. </pages>
Reference-contexts: Grid graphs. Liu [18] shows that the skeleton graph of a k fi k regular nine-point grid graph ordered by the nested dissection ordering described by George <ref> [11] </ref> has no more than 2k 2 edges. It is of interest to characterize ccts and scts for this model problem. <p> Let k = 2 m 1, where m is a positive integer. Consider a k fi k nine-point regular grid graph ordered by nested dissection ordering using the separators described by George <ref> [11] </ref>. This graph has a clique tree whose cct has size 2k 2 + ((k + 1) 2 =4) 2k;. the compact cliques corresponding to interior cliques are empty; further, the sct is identical to the cct. <p> For instance, when the regular nine-point grid graph is ordered with the separators described by George <ref> [11] </ref>, all cliques except the root clique satisfy this property. The reason why filled graphs from the commonly used ordering algorithms have this property is not well understood yet.
Reference: [12] <author> J. A. George and J. W. Liu, </author> <title> Computer Solution of Large Sparse Positive Definite Systems, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year> <title> [13] , Compact structural representation of sparse Cholesky, QR and LU factors, </title> <booktitle> in Computer Methods in Applied Sciences and Engineering VII, </booktitle> <editor> R. Glowinski and J.-L. Lions, eds., </editor> <publisher> Elsevier Publishers B. V. (North Holland), </publisher> <year> 1986, </year> <pages> pp. 93-106. </pages>
Reference-contexts: Our restrictive definition corresponds to choosing the root clique of this subtree as the parent of K. Supernodes and clique trees. Supernodes have been used in the ordering and symbolic factorization steps <ref> [12] </ref> and more recently, in the numeric factorization step of sparse factorizations [2] to increase the efficiency of the computations. <p> Hence it will be advantageous in parallel algorithms to communicate the cct or sct between processors and then let each processor compute the clique tree. Related work. The compressed column storage scheme of Sherman [23] is used in modern sparse matrix software <ref> [6, 12] </ref>. This is a column oriented storage scheme for the Cholesky factor in which overlaps between the row subscripts of consecutively numbered columns are exploited to compress the subscripts. <p> In practice, the success of this scheme relies on an ordering algorithm for first identifying, and then numbering consecutively, sets of nodes which are indistinguishable with respect to elimination. The minimum degree ordering algorithms <ref> [12] </ref> identify such indistinguishable nodes by a heuristic method. The spectacular compression observed is primarily due to the underlying clique tree structure of the filled graph. A set of indistinguishable nodes corresponds roughly to a set of new nodes in a 24 maximal clique of a clique tree.
Reference: [14] <author> M. Golumbic, </author> <title> Algorithmic Graph Theory and Perfect Graphs, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: We will assume some knowledge of terminology associated with sparse matrix factorizations and chordal graphs; the reader may find discussions of these in Liu [19] and Golumbic <ref> [14] </ref>. The vertices of a chordal graph can be ordered such that they can be eliminated in this order without causing any fill, and such an ordering is called a perfect elimination ordering (PEO). <p> Blair, English, and Thomason [5] then show that a clique tree may be characterized as any maximum-weight spanning tree of the clique graph. Earlier approaches for computing clique trees include Gavril [10], Walter [25], and Tarjan and Yannakakis [24] (see also Golumbic <ref> [14] </ref>). In his thesis, Peyton [20] describes an O (e) algorithm to compute clique trees from the adjacency lists of the chordal graph using maximum cardinality search.
Reference: [15] <author> J. Lewis, B. W. Peyton, and A. Pothen, </author> <title> Supernodes and clique trees in sparse matrix factorizations. work in preparation, </title> <year> 1989. </year>
Reference-contexts: It is not difficult to verify that the new sets of the maximal cliques in a clique tree form a supernode partition. The connections between supernodes and clique trees are explored in greater detail in <ref> [15] </ref>, where in particular it is shown that an algorithm for computing a supernode partition can be modified to compute a clique tree. 3. Compact and skeleton clique trees.
Reference: [16] <author> J. G. Lewis, B. W. Peyton, and A. Pothen, </author> <title> A fast algorithm for reordering sparse matrices for parallel factorization, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 6 (1989), </volume> <pages> pp. 1146-1173. </pages>
Reference-contexts: In this case, it is possible to store the structure of L in space much smaller than the number of nonzeros in L by using the clique tree data structure described in <ref> [16] </ref>. The existence of this data structure is the primary fl Presented at the Workshop on Large-Scale Numerical Optimization, Mathematical Sciences Institute, Cornell University, Oct 18-20, 1989. Written December 1989; revised April 1990. y Departments of Computer Science and Mathematics, The University of Wisconsin-Madison, 1210 W. <p> In the context of sparse matrix factorizations, it is more efficient to work with the the higher adjacency lists of the vertices stored in a compressed format, since these lists are available as the output of a symbolic factorization algorithm. The paper <ref> [16] </ref> describes an O (n) algorithm for computing a clique tree from these lists. <p> Let P denote the parent clique of a maximal clique K in a clique tree T . As a consequence of our definition of a clique tree, it can be proved (Proposition 6 and Theorem 7, <ref> [16] </ref>) that * anc (K ) P , new (K ) " P = ;; * a vertex w 2 new (K ) can belong to the anc set of another clique D only if D is a descendant of K; * a vertex w 2 anc (K ) belongs to <p> Then ladj (v) = [ D2D new (D ) [ fw : w 2 new (K ) and w &lt; v g: Proof. From Theorem 7 in <ref> [16] </ref> (see the properties of clique trees described in x 2), since v 2 new (K ), v can belong to another clique D only if D is a descendant of K. <p> Further, since w 0 is a new vertex in K, it may belong to other cliques only if they are descendants of K in T . From Theorem 7 in <ref> [16] </ref> (see the discussion about the properties of clique trees in x 2), if w 0 belongs to some proper descendant D of K, it also belongs to the child C which lies on the clique path from D to K in T . <p> The computation of the cct involves three additional steps: first, a symbolic factorization step to compute L; next, the computation of the clique tree from L using the clique tree algorithm described in <ref> [16] </ref>; and finally, the computation of the cct from the clique tree. Note that the symbolic factorization step dominates the other two steps.
Reference: [17] <author> J. W. Liu, </author> <title> Modification of the minimum-degree algorithm by multiple elimination, </title> <journal> ACM Trans. on Math. Software, </journal> <volume> 11 (1985), </volume> <pages> pp. </pages> <month> 141-153. </month> <title> [18] , A compact row storage scheme for Cholesky factors using elimination trees, </title> <journal> ACM Trans. on Math. Software, </journal> <volume> 12 (1986), </volume> <pages> pp. </pages> <month> 127-148. </month> <title> [19] , The role of elimination trees in sparse factorization, </title> <type> Tech. Report 87-12, </type> <institution> Computer Science, York University, </institution> <address> North York, Ontario, Canada, </address> <year> 1987. </year>
Reference-contexts: Computational results. In this section, we report results pertaining to the computation of the various clique tree data structures for a set of large problems from the Boeing-Harwell collection [7]. The results we report were obtained by ordering the matrices using Liu's Multiple Minimum Degree (MMD) ordering <ref> [17] </ref>. All programs were written in C, and the computations were performed on one processor of a Cray-2 running Unicos 5.1, using version 5:0:2 of the C compiler. The sizes of eight problems and the various data structures associated with them are shown in Table 1.
Reference: [20] <author> B. W. Peyton, </author> <title> Some Applications of Clique Trees to the Solution of Sparse Linear Systems, </title> <type> PhD thesis, </type> <institution> Clemson University, Clemson, </institution> <address> SC, </address> <year> 1986. </year>
Reference-contexts: Blair, English, and Thomason [5] then show that a clique tree may be characterized as any maximum-weight spanning tree of the clique graph. Earlier approaches for computing clique trees include Gavril [10], Walter [25], and Tarjan and Yannakakis [24] (see also Golumbic [14]). In his thesis, Peyton <ref> [20] </ref> describes an O (e) algorithm to compute clique trees from the adjacency lists of the chordal graph using maximum cardinality search.
Reference: [21] <author> A. Pothen, </author> <title> Simplicial cliques, shortest elimination trees, and supernodes in sparse Cholesky factorization, </title> <type> Tech. Report CS-88-13, </type> <institution> Computer Science, The Pennsylvania State University, University Park, </institution> <address> PA, </address> <month> April </month> <year> 1988. </year>
Reference-contexts: Finally, a partial supernode partition is a supernode partition if every supernode in the partition is a maximal supernode. 8 Partial supernode partitions have been used by Ashcraft et al. [2] for vectorized numerical factorization. The paper <ref> [21] </ref> includes an O (n) algorithm for computing the supernode partition from the etree. It is not difficult to verify that the new sets of the maximal cliques in a clique tree form a supernode partition.
Reference: [22] <author> R. Schreiber, </author> <title> A new implementation of sparse Gaussian elimination, </title> <journal> ACM Trans. on Math. Software, </journal> <volume> 8 (1982), </volume> <pages> pp. 256-276. </pages>
Reference-contexts: We denote the size of the skeleton matrix by jA S j. The skeleton graph of the chordal graph in Fig. 1 is shown in Fig. 4. The reader can verify that under the given ordering, all omitted edges are generated as fill edges. A result of Schreiber <ref> [22] </ref> (see also Liu [18]) characterizes the structure of the v-th row of L as a subtree F (v) of the etree rooted at v from which vertices have been pruned. <p> Vertices in new (K ) numbered lower than v also belong to ladj (v). Since no other cliques contain v, these are the only vertices in ladj (v). A result of Schreiber <ref> [22] </ref> characterizes the structure of the v-th row of L as a pruned subtree F (v) of the etree rooted at v. This result now follows easily from the previous Theorem since the cliques in D together with K form a subtree of the clique tree rooted at K. <p> The spectacular compression observed is primarily due to the underlying clique tree structure of the filled graph. A set of indistinguishable nodes corresponds roughly to a set of new nodes in a 24 maximal clique of a clique tree. Schreiber <ref> [22] </ref> has proposed an implementation of sparse Cholesky factorization where relative (rather than absolute) row subscripts are stored. This storage scheme makes use of the observation that the structure of a column j (except the diagonal element) is contained in the structure of its parent p in the elimination tree.
Reference: [23] <author> A. H. Sherman, </author> <title> On the efficient solution of sparse linear and nonlinear equations, </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Yale University, </institution> <year> 1975. </year>
Reference-contexts: Electronic address: csun@shire.cs.psu.edu. The research of this author was supported by U.S. Air Force Office of Scientific Research grant AFOSR-88-0161. 1 reason for the spectacular success of the compressed column storage scheme proposed by Sherman <ref> [23] </ref> and used in modern sparse matrix software. The size of the clique tree data structure is the number of compressed row subscripts in a scheme which stores L by columns, when `accidental compression' is ignored. <p> Hence it will be advantageous in parallel algorithms to communicate the cct or sct between processors and then let each processor compute the clique tree. Related work. The compressed column storage scheme of Sherman <ref> [23] </ref> is used in modern sparse matrix software [6, 12]. This is a column oriented storage scheme for the Cholesky factor in which overlaps between the row subscripts of consecutively numbered columns are exploited to compress the subscripts.
Reference: [24] <author> R. E. Tarjan and M. Yannakakis, </author> <title> Simple linear-time algorithms to test chordality of graphs, test acyclicity of hypergraphs, and selectively reduce acyclic hypergraphs, </title> <journal> SIAM J. Comput., </journal> <volume> 13 (1984), </volume> <pages> pp. 566-579. </pages>
Reference-contexts: Blair, English, and Thomason [5] then show that a clique tree may be characterized as any maximum-weight spanning tree of the clique graph. Earlier approaches for computing clique trees include Gavril [10], Walter [25], and Tarjan and Yannakakis <ref> [24] </ref> (see also Golumbic [14]). In his thesis, Peyton [20] describes an O (e) algorithm to compute clique trees from the adjacency lists of the chordal graph using maximum cardinality search.
Reference: [25] <author> J. R. Walter, </author> <title> Representations of chordal graphs as subtrees of a tree, </title> <journal> J. Graph Theory, </journal> <volume> 2 (1978), </volume> <pages> pp. 265-267. </pages>
Reference-contexts: Blair, English, and Thomason [5] then show that a clique tree may be characterized as any maximum-weight spanning tree of the clique graph. Earlier approaches for computing clique trees include Gavril [10], Walter <ref> [25] </ref>, and Tarjan and Yannakakis [24] (see also Golumbic [14]). In his thesis, Peyton [20] describes an O (e) algorithm to compute clique trees from the adjacency lists of the chordal graph using maximum cardinality search.
Reference: [26] <author> E. Zmijewski and J. R. Gilbert, </author> <title> A parallel algorithm for sparse symbolic Cholesky factorization on a multiprocessor, </title> <booktitle> Parallel Computing, 7 (1988), </booktitle> <pages> pp. 199-210. 27 </pages>
Reference-contexts: Liu [19] provides an excellent survey of this role. The etree can be computed in O (jAjff (jAj; n)) time from the matrix A by an algorithm of Zmijewski and Gilbert <ref> [26] </ref>, where ff (fl; fl) is the functional inverse of Ackermann's function. It is well-known (e.g., see [19]) that the higher degrees of the vertices can then be computed from A and the etree in O (jAj) space and O (jLj) time.
References-found: 23

