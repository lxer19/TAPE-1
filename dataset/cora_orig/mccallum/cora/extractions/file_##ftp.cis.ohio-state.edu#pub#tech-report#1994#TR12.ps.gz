URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1994/TR12.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: e-mail: fprakash, singhalg@cis.ohio-state.edu  
Title: Maximal Global Snapshot with Concurrent  
Author: Initiators Ravi Prakash and Mukesh Singhal 
Keyword: concurrent snapshot, consistent snapshot, recovery.  
Address: Columbus, OH 43210.  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: In a distributed system multiple nodes may initiate snapshot collection concurrently. In this paper we present a global snapshot collection algorithm that combines the information collected by each initiator. This generates a maximal, consistent global snapshot that is more recent than the snapshot collected by any initiator. Global snapshots are used to establish checkpoints for recovery from node failures. A maximal snapshot implies that the amount of computation lost during roll-back, after node failures, is minimized. We also present an efficient information dissemination strategy that nodes can employ to exchange snapshot information with each other.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. M. Chandy and L. Lamport. </author> <title> Distributed Snapshots : Determining Global States of Distributed Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(1) </volume> <pages> 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes. <p> Even though their tentative local snapshots put together would have constituted a consistent global snapshot, indicated by C, the effort is wasted. Spezialetti and Kearns' algorithm [13] is based on the Chandy-Lamport snapshot collection strategy <ref> [1] </ref> and requires every node in the system to take its local snapshot. Mutually disjoint sets of nodes take their local snapshots in response to requests from different initia 3 tors. Then the local snapshots are patched together to construct a global snapshot.
Reference: [2] <author> J.-M. Helary. </author> <title> Observing Global States of Asynchronous Distributed Applications. </title> <editor> In J-C Bermond and M. Raynal, editors, </editor> <booktitle> Proc. of the 3 rd International Workshop on Distributed Algorithms. </booktitle> <publisher> Springer-Verlag LNCS 392, </publisher> <year> 1989. </year>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes.
Reference: [3] <author> S. T. Huang. </author> <title> Detecting Termination of Distributed Computations by External Agents. </title> <booktitle> In Proceedings of the 9 th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 79-84, </pages> <year> 1989. </year>
Reference-contexts: In the second phase the initiators exchange information with each and make one tentative local snapshot permanent at each node. Lamport's clock [8] is maintained by each node. Huang's termination detection algorithm <ref> [3] </ref>, of associating weights with nodes and messages, is employed to detect the termination of snapshot collection.
Reference: [4] <author> D. Johnson and W. Zwaenepoel. </author> <title> Recovery in distributed systems using optimistic message logging and checkpointing. </title> <journal> Journal of Algorithms, </journal> <volume> 3(11) </volume> <pages> 462-491, </pages> <year> 1990. </year>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes.
Reference: [5] <author> R. Koo and S. Toueg. </author> <title> Checkpointing and Rollback-Recovery for Distributed Systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(1):23-31, </volume> <month> January </month> <year> 1987. </year>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes. <p> The global snapshot is used to establish consistent checkpoints at the nodes. Recovery from a node failure is performed by rolling back the computation to a consistent checkpoint and then allowing it to proceed from there <ref> [5, 12, 14, 16, 17] </ref>. The more recent the checkpoint, the less the amount of computation that is lost during failure recovery. Hence, it is important to develop algorithms that collect a maximal global snapshot of the system (i.e., as latest as possible). <p> The more recent the checkpoint, the less the amount of computation that is lost during failure recovery. Hence, it is important to develop algorithms that collect a maximal global snapshot of the system (i.e., as latest as possible). Koo and Toueg <ref> [5] </ref> have shown that if the nodes take their local snapshots in an uncoordinated manner, it may not be possible to construct a consistent global state from such snapshots. The rollback may lead to a domino effect. <p> Then it sends request messages to other nodes to take their snapshots. If the nodes maintain information about causal dependencies, a minimal number of nodes have to take their local snapshots in response to such requests. Such minimal snapshot collection algorithms have been presented in <ref> [5, 11] </ref>. Koo and Toueg's algorithm [5] involves suspending the underlying computation during snapshot collection. Once a node has taken its local snapshot for a snapshot initiator, it neither sends nor accepts any messages other than control messages corresponding to that snapshot initiation. <p> If the nodes maintain information about causal dependencies, a minimal number of nodes have to take their local snapshots in response to such requests. Such minimal snapshot collection algorithms have been presented in [5, 11]. Koo and Toueg's algorithm <ref> [5] </ref> involves suspending the underlying computation during snapshot collection. Once a node has taken its local snapshot for a snapshot initiator, it neither sends nor accepts any messages other than control messages corresponding to that snapshot initiation. The nodes resume the underlying computation when the snapshot collection terminates. <p> Most of the snapshot collection algorithms presented in the past have assumed that at any given time only one snapshot collection is active. Koo and Toueg <ref> [5] </ref> and Spezialetti and Kearns [13] have proposed methods to handle concurrent initiations of snapshot collection. Koo and Toueg [5] handle concurrent snapshot collections in the following manner: Once a node takes a local snapshot, it is unwilling to take a snapshot in response to another initiator's request. <p> Most of the snapshot collection algorithms presented in the past have assumed that at any given time only one snapshot collection is active. Koo and Toueg <ref> [5] </ref> and Spezialetti and Kearns [13] have proposed methods to handle concurrent initiations of snapshot collection. Koo and Toueg [5] handle concurrent snapshot collections in the following manner: Once a node takes a local snapshot, it is unwilling to take a snapshot in response to another initiator's request. <p> Therefore, some snapshot collection algorithms that require the computation to be temporarily suspended are not desirable. In a distributed computation, multiple nodes may concurrently initiate snapshot collection. Most previous snapshot collection algorithms have assumed that only one node initiates snapshot collection at a time. Koo and Toueg <ref> [5] </ref> consider concurrent snapshot initiations. But in their algorithm, all the initiations may end up aborting, in some situations, leading to a wastage of effort. Spezialetti and Kearns' algorithm [13] imposes restrictions on the propagation of snapshot requests.
Reference: [6] <author> A. D. Kshemkalyani, M. Raynal, and M. Singhal. </author> <title> Global Snapshots of a Distributed System. </title> <type> Technical Report OSU-CISRC-1/94-TR2, </type> <institution> The Ohio State University, </institution> <year> 1994. </year>
Reference-contexts: Fewer messages will therefore lead to an earlier completion of the information dissemination phase. 6 Conclusion Global snapshot collection of a distributed computation is a very important problem <ref> [6] </ref>. One of its primary applications is in establishing consistent checkpoints for recovery from node failures. On node failures, the computation can be restored to the most recent checkpoint. The snapshot collection process should not interfere with the underlying computation.
Reference: [7] <author> T.-H. Lai and T.-H. Yang. </author> <title> On Distributed Snapshots. </title> <journal> Information Processing Letters, </journal> <volume> 25 </volume> <pages> 153-158, </pages> <year> 1987. </year>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes.
Reference: [8] <author> L. Lamport. </author> <title> Time, Clocks and the Ordering of Events in a Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year> <month> 19 </month>
Reference-contexts: In the first phase, each node in the system takes one or more tentative local snapshots (depending on the number of initiators). In the second phase the initiators exchange information with each and make one tentative local snapshot permanent at each node. Lamport's clock <ref> [8] </ref> is maintained by each node. Huang's termination detection algorithm [3], of associating weights with nodes and messages, is employed to detect the termination of snapshot collection.
Reference: [9] <author> F. Mattern. </author> <title> Virtual Time and Global States of Distributed Systems. </title> <editor> In M.Cosnard et. al., editor, </editor> <booktitle> Proceedings of the Workshop on Parallel and Distributed Algorithm, </booktitle> <pages> pages 215-226. </pages> <publisher> Elsevier Science Publishers B.V.(North-Holland), </publisher> <year> 1989. </year>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes. <p> This approach has been employed by Spezialetti and Kearns [13]. Let m nodes initiate snapshot collection independently and concurrently, and the snapshots collected by them be denoted as C 1 ; : : : ; C m . Mattern <ref> [9] </ref> has shown that if C 1 and C 2 are consistent snapshots of a distributed computation, then C 1 " C 2 is also a consistent snapshot. <p> After all the nodes have finished taking their local snapshots, the latest local snapshot of each node is combined to produce a global consistent snapshot. This approach corresponds to taking the union of all the concurrent snapshots. Mattern <ref> [9] </ref> has shown that if C 1 and C 2 are consistent snapshots of a distributed computation, then C 1 [ C 2 is also a consistent snapshot. The snapshot thus obtained is the maximal of the snapshots collected by the individual initiators. <p> So, the snapshot collected by each initiation is consistent. The information sharing phase of the algorithm (subsection 3.2.2) has the effect of taking the union of the consistent snapshots collected by the initiators. According to <ref> [9] </ref>, the union of consistent snapshots is itself a consistent snapshot. 3.3 Optimizations The following optimizations can be made in the algorithm described in subsection 3.2. Firstly, a node does not need to maintain multiple tentative snapshots.
Reference: [10] <author> F. Mattern. </author> <title> Efficient Distributed Snapshots and Global Virtual Time Algorithms for Non-FIFO Systems. </title> <type> Technical Report SFB124-24/90, </type> <institution> University of Kaiserslautern, </institution> <year> 1990. </year>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes.
Reference: [11] <author> R. Prakash and M. Singhal. </author> <title> Minimal Global Snapshot and Failure Recovery using Infection. </title> <type> Technical Report OSU-CISRC-12/93-TR42, </type> <institution> The Ohio State University, </institution> <year> 1993. </year>
Reference-contexts: Then it sends request messages to other nodes to take their snapshots. If the nodes maintain information about causal dependencies, a minimal number of nodes have to take their local snapshots in response to such requests. Such minimal snapshot collection algorithms have been presented in <ref> [5, 11] </ref>. Koo and Toueg's algorithm [5] involves suspending the underlying computation during snapshot collection. Once a node has taken its local snapshot for a snapshot initiator, it neither sends nor accepts any messages other than control messages corresponding to that snapshot initiation. <p> Once a node has taken its local snapshot for a snapshot initiator, it neither sends nor accepts any messages other than control messages corresponding to that snapshot initiation. The nodes resume the underlying computation when the snapshot collection terminates. In <ref> [11] </ref>, Prakash and Singhal present a snapshot collection algorithm that allows the underlying computation to proceed while the snapshot is being collected. In addition, it does not force every node to take its local snapshot. 2 In a distributed system, multiple nodes may concurrently and independently initiate global snapshot collection. <p> During a snapshot collection, it is not mandatory for all the nodes to take their local snapshots. A snapshot initiator can maintain a list of nodes on which it is causally dependent, and send snapshot requests only to those nodes <ref> [11] </ref>. On receiving a snapshot request, a node propagates the request (if required) only to those nodes on which it is causally dependent. Thus, the minimal set of nodes, required to maintain consistency, are made to take their local snapshots. This saves the effort involved in global snapshot collection.
Reference: [12] <author> A. P. Sistla and J. L. Welch. </author> <title> Efficient Distributed Recovery Using Message Logging. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 223-238, </pages> <year> 1989. </year>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes. <p> The global snapshot is used to establish consistent checkpoints at the nodes. Recovery from a node failure is performed by rolling back the computation to a consistent checkpoint and then allowing it to proceed from there <ref> [5, 12, 14, 16, 17] </ref>. The more recent the checkpoint, the less the amount of computation that is lost during failure recovery. Hence, it is important to develop algorithms that collect a maximal global snapshot of the system (i.e., as latest as possible).
Reference: [13] <author> M. Spezialetti and P. Kearns. </author> <title> Efficient Distributed Snapshots. </title> <booktitle> In Proceedings of the 6 th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 382-388, </pages> <year> 1986. </year>
Reference-contexts: Most of the snapshot collection algorithms presented in the past have assumed that at any given time only one snapshot collection is active. Koo and Toueg [5] and Spezialetti and Kearns <ref> [13] </ref> have proposed methods to handle concurrent initiations of snapshot collection. Koo and Toueg [5] handle concurrent snapshot collections in the following manner: Once a node takes a local snapshot, it is unwilling to take a snapshot in response to another initiator's request. <p> As a result both P 1 and P 2 receive a negative response and do not make their tentative snapshots permanent. Even though their tentative local snapshots put together would have constituted a consistent global snapshot, indicated by C, the effort is wasted. Spezialetti and Kearns' algorithm <ref> [13] </ref> is based on the Chandy-Lamport snapshot collection strategy [1] and requires every node in the system to take its local snapshot. Mutually disjoint sets of nodes take their local snapshots in response to requests from different initia 3 tors. <p> Different nodes may take local snapshots in response to requests from different initiators. Once all the nodes have taken their snapshots, the local snapshots are combined to produce a global consistent snapshot. This approach has been employed by Spezialetti and Kearns <ref> [13] </ref>. Let m nodes initiate snapshot collection independently and concurrently, and the snapshots collected by them be denoted as C 1 ; : : : ; C m . <p> Most previous snapshot collection algorithms have assumed that only one node initiates snapshot collection at a time. Koo and Toueg [5] consider concurrent snapshot initiations. But in their algorithm, all the initiations may end up aborting, in some situations, leading to a wastage of effort. Spezialetti and Kearns' algorithm <ref> [13] </ref> imposes restrictions on the propagation of snapshot requests. As a result the global snapshot collected is the minimal of the snapshots collected by all the initiators. We have presented a global snapshot collection algorithm that handles concurrent initiation of snapshot collection by multiple nodes. <p> We have also presented a new strategy for information dissemination that the concurrent initiators can use to share their recorded information and construct a global state. Its average 18 case performance is better than that of the strategy of Spezialetti and Kearns in <ref> [13] </ref>. Both the strategies have the same worst case performance. During snapshot collection, it is not mandatory that all the nodes take their local snapshots. Information about causal dependency can be used to make a minimal set of nodes take their local snapshots.
Reference: [14] <author> R. E. Strom and S. Yemini. </author> <title> Optimistic Recovery in Distributed Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(3) </volume> <pages> 204-226, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: The global snapshot is used to establish consistent checkpoints at the nodes. Recovery from a node failure is performed by rolling back the computation to a consistent checkpoint and then allowing it to proceed from there <ref> [5, 12, 14, 16, 17] </ref>. The more recent the checkpoint, the less the amount of computation that is lost during failure recovery. Hence, it is important to develop algorithms that collect a maximal global snapshot of the system (i.e., as latest as possible).
Reference: [15] <author> K. Taylor. </author> <title> The Role of Inhibition in Asynchronous Consistent-cut Protocols. </title> <booktitle> In Proceedings of the third International Workshop on Distributed Algorithms, </booktitle> <pages> pages 280-291. </pages> <publisher> Springer-Verlag LNCS 392, </publisher> <year> 1989. </year>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes.
Reference: [16] <author> S. Venkatesan. </author> <title> Optimistic Crash Recovery Without Rolling Back Non-Faulty Processors. </title> <year> 1992. </year>
Reference-contexts: The global snapshot is used to establish consistent checkpoints at the nodes. Recovery from a node failure is performed by rolling back the computation to a consistent checkpoint and then allowing it to proceed from there <ref> [5, 12, 14, 16, 17] </ref>. The more recent the checkpoint, the less the amount of computation that is lost during failure recovery. Hence, it is important to develop algorithms that collect a maximal global snapshot of the system (i.e., as latest as possible).
Reference: [17] <author> S. Venkatesan and Tony T.-Y. Juang. </author> <title> Low Overhead Optimistic Crash Recovery. </title> <booktitle> Preliminary version appears in Proceedings of 11 th International Conference on Distributed Computing Systems, </booktitle> <year> 1991. </year>
Reference-contexts: The global snapshot is used to establish consistent checkpoints at the nodes. Recovery from a node failure is performed by rolling back the computation to a consistent checkpoint and then allowing it to proceed from there <ref> [5, 12, 14, 16, 17] </ref>. The more recent the checkpoint, the less the amount of computation that is lost during failure recovery. Hence, it is important to develop algorithms that collect a maximal global snapshot of the system (i.e., as latest as possible).
Reference: [18] <author> K. Venkatesh, T. Radhakrishnan, and H.F. Li. </author> <title> Global state detection in non-FIFO networks. </title> <booktitle> In Proceedings of the 7 th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 364-370, </pages> <year> 1987. </year> <month> 20 </month>
Reference-contexts: Thus, the reception of the message will be recorded by P j , while its transmission will not be recorded at P i . In order to handle failures, algorithms have been proposed to collect consistent global snapshots of the system <ref> [1, 2, 4, 5, 7, 9, 10, 12, 15, 18] </ref>. The global snapshot is used to establish consistent checkpoints at the nodes.
References-found: 18

