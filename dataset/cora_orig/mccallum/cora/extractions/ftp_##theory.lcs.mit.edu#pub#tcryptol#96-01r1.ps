URL: ftp://theory.lcs.mit.edu/pub/tcryptol/96-01r1.ps
Refering-URL: http://theory.lcs.mit.edu/~tcryptol/1996/96-01.html
Root-URL: 
Email: canetti,rosario@theory.lcs.mit.edu  
Title: Incoercible Multiparty Computation (Extended Abstract)  
Author: Ran Canetti Rosario Gennaro 
Address: 545 Technology Square, Cambridge MA 02139, U.S.A.  
Affiliation: Laboratory for Computer Science, Massachusetts Institute of Technology,  
Note: An extended Abstract of this work appears in the proceedings of 37th FOCS, 1996.  
Date: August 7, 1996  
Abstract: In this work we present the first general treatment of the coercion problem in secure computation. First we present a general definition of protocols that provide resilience to coercion. Our definition constitutes a natural extension of the general paradigm used for defining secure multiparty protocols. Next we show that if trapdoor permutations exist then any function can be incoercibly computed (i.e., computed by a protocol that provides resilience to coercion) in the presence of computationally bounded adversaries and only public communication channels. This holds as long as less than half the parties are coerced (or corrupted). In particular, ours are the first incoercible protocols without physical security assumptions. Also, our protocols constitute an alternative solution to the recently solved adaptive security problem. Our techniques are quite surprising and include non-standard use of deniable encryptions. 
Abstract-found: 1
Intro-found: 1
Reference: [Be] <author> D. Beaver, </author> <title> "Foundations of Secure Interactive Computing", </title> <booktitle> CRYPTO, </booktitle> <year> 1991. </year>
Reference-contexts: Coming up with a definition that captures this new type of attack turned out to be a non-trivial task. Moreover, our definition manages to incorporate this concern within the existing framework used for defining multiparty secure computation <ref> [MR, Be, CFGN, C] </ref>. In particular, it is immediate from our definition that any incoercible protocol is also (adaptively) secure in the standard sense. <p> This requirement is crucial: it will force the faking algorithm to generate fake inputs that indeed `look like' real random inputs. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>. <p> Let us shortly review the definition of secure multiparty computation (without coercion) <ref> [MR, Be, CFGN, C] </ref>. Adaptively secure protocols are defined using a similar framework as the one used here. That is, the real-life computation is compared, as here, with a computation in an ideal model.
Reference: [BT] <editor> J. Benaloh and D. Tunistra, "Receipt-Free Secret-Ballot Elections", </editor> <booktitle> 26th STOC, </booktitle> <year> 1994, </year> <pages> pp. 544-552. </pages>
Reference-contexts: As long as enough parties remain uncorrupted, the parties can correctly compute any function of their inputs, while making sure that the adversary learns nothing from the computation other than the inputs and outputs of the corrupted parties. However, these protocols suffer from the following deficiency, pointed out in <ref> [He, BT] </ref>. Using any of these protocols, the public transcript of the communication can be used as an (involuntary) commitment of the parties to their inputs and outputs. <p> Coercion in the context of secret voting has been studied in the past <ref> [BT, SK, NR] </ref>. These studies, however, were limited. First, they consider only a simplified version of secret voting, where there are voting centers that cannot be coerced. Next, their constructions require physically secure communication channels during crucial parts of the computation.
Reference: [BCG] <author> M. Ben-Or, R. Canetti and O. Goldreich, </author> <title> "Asynchronous Secure Computations", </title> <booktitle> 25th STOC, </booktitle> <year> 1993, </year> <pages> pp. 52-61. </pages>
Reference-contexts: This requirement is crucial: it will force the faking algorithm to generate fake inputs that indeed `look like' real random inputs. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>.
Reference: [BGW] <author> M. Ben-Or, S. Goldwasser and A. Wigderson, </author> " <title> Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation", </title> <booktitle> 20th STOC, </booktitle> <year> 1988, </year> <pages> pp. 1-10. </pages>
Reference-contexts: Having formalized the notion of incoercible protocols, a simple argument now shows that incoercible secure computation is impossible when the adversary is computationally unbounded. Interestingly, this holds even if the communication channels are private (as in <ref> [BGW, CCD] </ref>). Thus, our protocols are another demonstration of the interesting fact that constructions based on the computational limitations of the adversary achieve qualitatively stronger results than constructions based on physical assumptions (such as private channels). On the construction. <p> Nevertheless, our solution achieves both incoercibility and adaptive security. For convenience, we use the [CFGN] protocol in our construction. However, we can do with protocols that achieve only a weaker type of security, described in the sequel (the [GMW2] protocols, as well as the <ref> [BGW] </ref> protocols augmented with encrypting each message using standard encryption, have this type of security). <p> The same argument demonstrates that known constructions for secure multiparty computation (e.g., <ref> [GMW2, BGW, CCD, CFGN] </ref>) are coercible (i.e., not incoercible) even if the adversary is limited to probabilistic polynomial time. Moreover, the natural strategy of simply using deniable encryption (see Section 4 below) on top of previously known solutions is susceptible to the same difficulties. Computationally unbounded adversaries, private channels. <p> Thus, if the adversary corrupts or coerces t randomly chosen parties, it will `catch' P with probability O ( t n ). Consider for illustration the <ref> [BGW] </ref> construction for computing a function that whose output depends on P 's input. <p> We remark that the [GMW2] construction, as well as the <ref> [BGW, CCD, RB] </ref> constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. This means that in our construction any of these methods can be used. instead of [CFGN]. <p> Let be the secure protocol for the computation of the function f that results from the construction of <ref> [BGW, CFGN] </ref>. Let 0 be the incoercible protocol for the computation of the same function that results from our construction above. We analyze the round and computational complexity of the two protocols. <p> We remark that a single invocation of protocol 1 (i.e., a single set of keys) suffices for incoercibly performing many different computational tasks, even where each task has different inputs. Notice that this analysis holds even if we replace the <ref> [BGW, CFGN] </ref> construction with any other protocol having the following property: the input of each party is first shared within a constant number of rounds, and only the shares are accessed in subsequent rounds.
Reference: [C] <author> R. Canetti, </author> <title> "Studies in Secure Multiparty Computation and Applications", </title> <type> Ph.D. Thesis, </type> <institution> Weizmann Institute of Science, </institution> <year> 1995. </year> <note> Available on-line at http://theory.lcs.mit.edu/~canetti </note>
Reference-contexts: Coming up with a definition that captures this new type of attack turned out to be a non-trivial task. Moreover, our definition manages to incorporate this concern within the existing framework used for defining multiparty secure computation <ref> [MR, Be, CFGN, C] </ref>. In particular, it is immediate from our definition that any incoercible protocol is also (adaptively) secure in the standard sense. <p> Next we define an ideal model of computation, which represents the `most we can hope for' from incoercible computation. This ideal model is an extension of the ideal model used in <ref> [C, CFGN] </ref> to define adaptive security. Finally we say that a (real-life) computation is incoercible if it is equivalent | in a standard sense described in the sequel | to a computation in the ideal model. <p> This requirement is crucial: it will force the faking algorithm to generate fake inputs that indeed `look like' real random inputs. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>. <p> Let us shortly review the definition of secure multiparty computation (without coercion) <ref> [MR, Be, CFGN, C] </ref>. Adaptively secure protocols are defined using a similar framework as the one used here. That is, the real-life computation is compared, as here, with a computation in an ideal model.
Reference: [CDNO] <author> R. Canetti, C. Dwork, M. Naor and R. Ostrovsky, "Deniable Encryptions", </author> <title> manuscript. Available at the Theory of Cryptography Library, </title> <address> http://theory.lcs.mit.edu/ ~ tcryptol/ </address>
Reference-contexts: On the construction. We construct incoercible protocols for computing any function in the computational setting, as long as less than half of the parties are coerced or corrupted. A main tool in our construction is a new type of encryption schemes, called deniable encryptions <ref> [CDNO] </ref>. These schemes address the same problem of resilience to coercion, in the limited context of encryption. <p> In fact, if our construction uses any of these weaker protocols instead of [CFGN] then it constitutes an alternative to [CFGN] for obtaining adaptive security. (A third alternative is proposed in <ref> [CDNO] </ref>.) We remark that [CFGN] construct yet another type of encryption functions, called non-committing encryption. Non-committing encryptions have similar flavor to deniable ones, in that there exist ciphertexts that can be "opened" as encryptions of, say, both 1 and 0. However, non-committing encryptions are weaker than deniable ones. <p> In the next two sections we describe how we overcome this problem. 4 Tools We describe two tools used in our construction: deniable encryption and standard (i.e. coercible) secure multiparty computation. 4.1 Deniable encryptions Deniable encryption schemes, recently introduced in <ref> [CDNO] </ref>, are two-party (public key) encryption protocols with the additional property that later, upon coercion, the sender can convincingly `lie' about the encrypted value. (That is, the sender can present `fake random input' that is consistent with the original ciphertext and an encrypted value different than the original one.) For self-containment, <p> key) encryption protocols with the additional property that later, upon coercion, the sender can convincingly `lie' about the encrypted value. (That is, the sender can present `fake random input' that is consistent with the original ciphertext and an encrypted value different than the original one.) For self-containment, and since the <ref> [CDNO] </ref> work is not yet widely accessible, we present here a sketch of the definition and constructions relevant to this work. (The construction appears in Appendix A.) We remark that our construction of incoercible protocols uses deniable encryption protocols as a general tool and does not rely on particular implementations. <p> We now present a more precise definition. (The definition here is slightly more limited than the one in <ref> [CDNO] </ref>; this suffices for our needs.) With c = E e (m; r) we denote the encryption of m using random coins r. With E (m) we denote the random variable describing E (m; r) where the probability is over the choices of r and the random input of G. <p> We remark that schemes resilient against coercion of the receiver, or simultaneous coercion of both the sender and the receiver, are defined in a similar way. (For this work we only need schemes resilient against coercing the sender.) In Appendix A we sketch the <ref> [CDNO] </ref> encryption scheme. Appropriately choosing the security parameter, this scheme is 1 n k -sender deniable, for any constant k. 4.2 Standard secure computation Our construction makes use of protocols for securely computing any function among many parties in a non-coercive scenario.
Reference: [CFGN] <author> R. Canetti, U. Feige, O. Goldreich and M. Naor, </author> <title> "Adaptively Secure Computation", </title> <booktitle> 28th STOC, </booktitle> <year> 1996. </year> <note> Also in MIT LCS TR No. 682, </note> <year> 1996. </year>
Reference-contexts: Coming up with a definition that captures this new type of attack turned out to be a non-trivial task. Moreover, our definition manages to incorporate this concern within the existing framework used for defining multiparty secure computation <ref> [MR, Be, CFGN, C] </ref>. In particular, it is immediate from our definition that any incoercible protocol is also (adaptively) secure in the standard sense. <p> Consequently, coercion does not help in finding the transmitted value. A natural first attempt at constructing incoercible protocols may be to start with any standard secure protocol (say, <ref> [GMW2, CFGN] </ref>) and have the parties encrypt each message using deniable encryption. However, this simple solution does not work. Essentially, the reason is that each encrypted message (i.e., each ciphertext) has a unique receiver who can correctly decrypt it. <p> On incoercibility and adaptive security. Recently it was shown how to compute any function in the computational setting when the adversary is adaptive (i.e., when it can corrupt parties during the course of the computation based on the information gathered so far) <ref> [CFGN] </ref>. In principle, adaptive security (i.e., security against adaptive adversaries) is unrelated to incoercibility. In particular, the coercion problem remains even if the set of coerced parties is known in advance. Nevertheless, our solution achieves both incoercibility and adaptive security. For convenience, we use the [CFGN] protocol in our construction. <p> the information gathered so far) <ref> [CFGN] </ref>. In principle, adaptive security (i.e., security against adaptive adversaries) is unrelated to incoercibility. In particular, the coercion problem remains even if the set of coerced parties is known in advance. Nevertheless, our solution achieves both incoercibility and adaptive security. For convenience, we use the [CFGN] protocol in our construction. However, we can do with protocols that achieve only a weaker type of security, described in the sequel (the [GMW2] protocols, as well as the [BGW] protocols augmented with encrypting each message using standard encryption, have this type of security). <p> In fact, if our construction uses any of these weaker protocols instead of <ref> [CFGN] </ref> then it constitutes an alternative to [CFGN] for obtaining adaptive security. (A third alternative is proposed in [CDNO].) We remark that [CFGN] construct yet another type of encryption functions, called non-committing encryption. <p> In fact, if our construction uses any of these weaker protocols instead of <ref> [CFGN] </ref> then it constitutes an alternative to [CFGN] for obtaining adaptive security. (A third alternative is proposed in [CDNO].) We remark that [CFGN] construct yet another type of encryption functions, called non-committing encryption. <p> In fact, if our construction uses any of these weaker protocols instead of <ref> [CFGN] </ref> then it constitutes an alternative to [CFGN] for obtaining adaptive security. (A third alternative is proposed in [CDNO].) We remark that [CFGN] construct yet another type of encryption functions, called non-committing encryption. Non-committing encryptions have similar flavor to deniable ones, in that there exist ciphertexts that can be "opened" as encryptions of, say, both 1 and 0. However, non-committing encryptions are weaker than deniable ones. <p> Such ciphertexts can only be generated in a simulated execution of the protocol (such as the one needed there). In deniable encryption each ciphertext generated by parties has unique decryption, and at the same time can be "opened" both ways for a coercer. Finally, this work differs from <ref> [CFGN] </ref> in the following aspect. Both works acknowledge the fact that in the physical world parties are often able to locally deviate from their program (say, by failing to erase, or by rewriting local data) in an undetectable way. For the task of designing adaptively secure protocols [CFGN], this phenomenon plays <p> work differs from <ref> [CFGN] </ref> in the following aspect. Both works acknowledge the fact that in the physical world parties are often able to locally deviate from their program (say, by failing to erase, or by rewriting local data) in an undetectable way. For the task of designing adaptively secure protocols [CFGN], this phenomenon plays an adversarial role: a protocol should be secure even if all parties locally deviate from their programs in certain ways. Here, however, we use this phenomenon to our benefit: we obtain an extra security property (namely, resilience to coercion) that would otherwise be impossible. Organization. <p> Next we define an ideal model of computation, which represents the `most we can hope for' from incoercible computation. This ideal model is an extension of the ideal model used in <ref> [C, CFGN] </ref> to define adaptive security. Finally we say that a (real-life) computation is incoercible if it is equivalent | in a standard sense described in the sequel | to a computation in the ideal model. <p> Alternatively, they are polynomial in the complexity of the function. 2 We assume that protocol does not instruct the parties to erase any data during the computation. Alternatively one may assume that the parties copy all data to a safe, non-erasable memory. See <ref> [CFGN] </ref> for a discussion on parties that avoid erasing data, and about semi-honest parties in general. 5 All the other internal data can be computed from the input, random input, and the messages received by the party so far.) From this round on, the corrupted party follows the instructions of the <p> This black-box represents the input-output relations of the real-life adversary described above. For concreteness, we present the following description of the "mechanics" of this black-box, representing a real-life adversary. (This description differs from the one in <ref> [CFGN] </ref> only in that coercion requests are added.) The black-box has a random tape, where it expects to find its random input, and an input-output tape. Once a special start input is given on the input-output tape, the interaction on 7 this tape proceeds in iterations, as follows. <p> This requirement is crucial: it will force the faking algorithm to generate fake inputs that indeed `look like' real random inputs. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>. <p> The same argument demonstrates that known constructions for secure multiparty computation (e.g., <ref> [GMW2, BGW, CCD, CFGN] </ref>) are coercible (i.e., not incoercible) even if the adversary is limited to probabilistic polynomial time. Moreover, the natural strategy of simply using deniable encryption (see Section 4 below) on top of previously known solutions is susceptible to the same difficulties. Computationally unbounded adversaries, private channels. <p> Consequently, P does not have to `lie' about any of its past messages. Instead P can present a different interpretation (i.e., a different random input) that will make the same transcript `look' like it resulted from a different input. However, known constructions (e.g., <ref> [GMW2, CFGN] </ref>) do not take advantage of this leeway, and are thus coercible. That is, these constructions do not allow a party to claim that his input was different than what was really used in the computation without `lying' about at least one of its outgoing or incoming messages. <p> Let us shortly review the definition of secure multiparty computation (without coercion) <ref> [MR, Be, CFGN, C] </ref>. Adaptively secure protocols are defined using a similar framework as the one used here. That is, the real-life computation is compared, as here, with a computation in an ideal model. <p> The real-life adversary is modified accordingly. (Of course, adaptively secure protocols are not required to specify a faking algorithm for coerced parties.) Since we are facing a dynamic (coercive) adversary in our new model, it is natural to use the <ref> [CFGN] </ref> construction as a stepping stone. Indeed, in this version of the paper we do just that (for reasons described below). We remark, however, that in fact we do not need the full power of their method. <p> We remark that the [GMW2] construction, as well as the [BGW, CCD, RB] constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. This means that in our construction any of these methods can be used. instead of <ref> [CFGN] </ref>. An immediate consequence of this is that our construction, combined with, say [GMW2], is an alternative construction to [CFGN] for obtaining full-fledged adaptively secure protocols. Still, for convenience we use the [CFGN] construction in this version of the paper. <p> This means that in our construction any of these methods can be used. instead of <ref> [CFGN] </ref>. An immediate consequence of this is that our construction, combined with, say [GMW2], is an alternative construction to [CFGN] for obtaining full-fledged adaptively secure protocols. Still, for convenience we use the [CFGN] construction in this version of the paper. This will allow for a much simpler and easier to understand proof of our construction, and will highlight the main point, namely incoercibility. <p> This means that in our construction any of these methods can be used. instead of <ref> [CFGN] </ref>. An immediate consequence of this is that our construction, combined with, say [GMW2], is an alternative construction to [CFGN] for obtaining full-fledged adaptively secure protocols. Still, for convenience we use the [CFGN] construction in this version of the paper. This will allow for a much simpler and easier to understand proof of our construction, and will highlight the main point, namely incoercibility. The important (for us) feature of the [CFGN] construction is that its security can be proven via black-box simulation, similar <p> Still, for convenience we use the <ref> [CFGN] </ref> construction in this version of the paper. This will allow for a much simpler and easier to understand proof of our construction, and will highlight the main point, namely incoercibility. The important (for us) feature of the [CFGN] construction is that its security can be proven via black-box simulation, similar to the one described in Section 2. That is, for any protocol constructed via [CFGN] there exists a simulator (that is, an ideal-model adversary) that carries out, with any real-life adversary, a simulated interaction that is indistinguishable from <p> The important (for us) feature of the <ref> [CFGN] </ref> construction is that its security can be proven via black-box simulation, similar to the one described in Section 2. That is, for any protocol constructed via [CFGN] there exists a simulator (that is, an ideal-model adversary) that carries out, with any real-life adversary, a simulated interaction that is indistinguishable from a real one. 5 Protocols In this section we show how to incoercibly compute any function in the computational setting in the presence of a (c; t)-limited <p> An extension that deals with the case of different, private outputs for different parties is described in Section 5.2. An analysis appears in Section 5.3. 5.1 Computing functions with a common output A naive attempt at constructing incoercible protocols may be to start with a known secure-but-coercible construction (say, <ref> [CFGN] </ref>), and encrypt each message using deniable encryption. However, the impossibility argument of Section 3 applies to this solution as well: in order to `lie' about its input, a coerced party has to `lie' about the plaintext of at least one ciphertext sent in the past. <p> Let 1 be the secure protocol computing the function F 1 (constructed e.g. using <ref> [CFGN] </ref>.) The players will perform 1 over the secret inputs i in a such a way that the i th output e ffi d (i) is privately known only to player P i . In Phase 1 the players will invoke protocol 1 n times, on the following n inputs. <p> Let be the secure protocol for the computation of the function f that results from the construction of <ref> [BGW, CFGN] </ref>. Let 0 be the incoercible protocol for the computation of the same function that results from our construction above. We analyze the round and computational complexity of the two protocols. <p> We remark that a single invocation of protocol 1 (i.e., a single set of keys) suffices for incoercibly performing many different computational tasks, even where each task has different inputs. Notice that this analysis holds even if we replace the <ref> [BGW, CFGN] </ref> construction with any other protocol having the following property: the input of each party is first shared within a constant number of rounds, and only the shares are accessed in subsequent rounds. <p> How can we modify our protocol to achieve that? Noticing that the function F 3 in Phase 3 could be defined to be n-valued too, one would think that 11 In fact, the zero-knowledge proof is not necessary if either of <ref> [GMW2, CFGN] </ref> is used in phases 1 and 3. This is so since the protocols 1 and 3 can be combined, in a natural way, into one protocol where each party P i has "intermediate output" ~ d (i) , and subsequently an additional input ~z.
Reference: [CCD] <author> D. Chaum, C. Crepeau and I Damgard, </author> <title> "Multiparty unconditionally secure protocols", </title> <booktitle> 20th STOC, </booktitle> <year> 1988, </year> <pages> pp. 11-19. </pages>
Reference-contexts: Having formalized the notion of incoercible protocols, a simple argument now shows that incoercible secure computation is impossible when the adversary is computationally unbounded. Interestingly, this holds even if the communication channels are private (as in <ref> [BGW, CCD] </ref>). Thus, our protocols are another demonstration of the interesting fact that constructions based on the computational limitations of the adversary achieve qualitatively stronger results than constructions based on physical assumptions (such as private channels). On the construction. <p> The same argument demonstrates that known constructions for secure multiparty computation (e.g., <ref> [GMW2, BGW, CCD, CFGN] </ref>) are coercible (i.e., not incoercible) even if the adversary is limited to probabilistic polynomial time. Moreover, the natural strategy of simply using deniable encryption (see Section 4 below) on top of previously known solutions is susceptible to the same difficulties. Computationally unbounded adversaries, private channels. <p> We remark that the [GMW2] construction, as well as the <ref> [BGW, CCD, RB] </ref> constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. This means that in our construction any of these methods can be used. instead of [CFGN].
Reference: [DDN] <author> D. Dolev, C. Dwork, M. Naor, </author> <title> "Non-malleable Encryption", </title> <booktitle> 23th STOC, </booktitle> <year> 1991, </year> <pages> pp. 542-552. </pages>
Reference-contexts: Thus the protocol would cease to be secure even in the standard sense. This is the malleability problem of encryptions functions <ref> [DDN] </ref>. In our case the problem is solved by using a different encryption key for each party. 14 proof by each player P i that the input contributed during this phase is actually the share ~ d (i) it received in Phase 1.
Reference: [GL] <author> O. Goldreich and L. Levin, </author> <title> "A Hard-Core Predicate to any One-Way Function", </title> <booktitle> 21st STOC, </booktitle> <year> 1989, </year> <pages> pp. 25-32. </pages>
Reference: [GMW1] <author> O. Goldreich, S. Micali and A. Wigderson, </author> <title> "Proofs that yield nothing but their validity and a methodology of cryptographic protocol design", </title> <booktitle> 27th FOCS, </booktitle> <year> 1986, </year> <pages> pp. 174-187. </pages> <note> Journal version in JACM, vol.38, no.1, pp.691-729, 1991. 18 </note>
Reference-contexts: This is an NP-statement, so it can be proven in zero-knowledge (say, using <ref> [GMW1] </ref>). 11 The faking algorithm. We specify the actions of player P i upon coercion. First P i hands his fake input x 0 i to the adversary. If x i = x 0 i then P i also hands his real random input r i .
Reference: [GMW2] <author> O. Goldreich, S. Micali and A. Wigderson, </author> <title> "How to Play any Mental Game", </title> <booktitle> 19th STOC, </booktitle> <year> 1987, </year> <pages> pp. 218-229. </pages>
Reference-contexts: Still, the parties want to compute some common function of their inputs in a secure way. Security here means maintaining correctness of the outputs while keeping the parties' internal data as private as possible. This is the well-known secure multiparty computation problem (e.g., <ref> [Y, GMW2] </ref>). The parties' distrust in each other is modeled via an adversary that corrupts parties, learns their inputs, and controls their behavior. <p> Consequently, coercion does not help in finding the transmitted value. A natural first attempt at constructing incoercible protocols may be to start with any standard secure protocol (say, <ref> [GMW2, CFGN] </ref>) and have the parties encrypt each message using deniable encryption. However, this simple solution does not work. Essentially, the reason is that each encrypted message (i.e., each ciphertext) has a unique receiver who can correctly decrypt it. <p> Nevertheless, our solution achieves both incoercibility and adaptive security. For convenience, we use the [CFGN] protocol in our construction. However, we can do with protocols that achieve only a weaker type of security, described in the sequel (the <ref> [GMW2] </ref> protocols, as well as the [BGW] protocols augmented with encrypting each message using standard encryption, have this type of security). <p> We have tried to point these issues out in the presentation below and in Section 2.3. Mechanics of the real-life computation. We first review the standard computational setting for secure multiparty computation <ref> [GMW2] </ref>. Next we incorporate coercion in this setting. <p> The same argument demonstrates that known constructions for secure multiparty computation (e.g., <ref> [GMW2, BGW, CCD, CFGN] </ref>) are coercible (i.e., not incoercible) even if the adversary is limited to probabilistic polynomial time. Moreover, the natural strategy of simply using deniable encryption (see Section 4 below) on top of previously known solutions is susceptible to the same difficulties. Computationally unbounded adversaries, private channels. <p> Consequently, P does not have to `lie' about any of its past messages. Instead P can present a different interpretation (i.e., a different random input) that will make the same transcript `look' like it resulted from a different input. However, known constructions (e.g., <ref> [GMW2, CFGN] </ref>) do not take advantage of this leeway, and are thus coercible. That is, these constructions do not allow a party to claim that his input was different than what was really used in the computation without `lying' about at least one of its outgoing or incoming messages. <p> We remark that the <ref> [GMW2] </ref> construction, as well as the [BGW, CCD, RB] constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. This means that in our construction any of these methods can be used. instead of [CFGN]. <p> This means that in our construction any of these methods can be used. instead of [CFGN]. An immediate consequence of this is that our construction, combined with, say <ref> [GMW2] </ref>, is an alternative construction to [CFGN] for obtaining full-fledged adaptively secure protocols. Still, for convenience we use the [CFGN] construction in this version of the paper. This will allow for a much simpler and easier to understand proof of our construction, and will highlight the main point, namely incoercibility. <p> How can we modify our protocol to achieve that? Noticing that the function F 3 in Phase 3 could be defined to be n-valued too, one would think that 11 In fact, the zero-knowledge proof is not necessary if either of <ref> [GMW2, CFGN] </ref> is used in phases 1 and 3. This is so since the protocols 1 and 3 can be combined, in a natural way, into one protocol where each party P i has "intermediate output" ~ d (i) , and subsequently an additional input ~z.
Reference: [GM] <author> S. Goldwasser and S. Micali, </author> <title> "Probabilistic encryption", </title> <journal> JCSS, </journal> <volume> Vol. 28, No 2, </volume> <month> April </month> <year> 1984, </year> <pages> pp. 270-299. </pages>
Reference-contexts: A definition. We concentrate on encryption functions that are deniable with respect to coercing the sender. A deniable encryption scheme contains a key-generation algorithm G, an encryption algorithm E and a decryption algorithm D that constitute a standard semantically secure encryption scheme as defined in <ref> [GM] </ref>, with the exception that there may be a negligible probability of decryption error. Furthermore, the sender should have a `faking algorithm' E with the following property.
Reference: [He] <author> A. Herzberg, </author> <note> Rump session presentations at CRYPTO'91. </note>
Reference-contexts: As long as enough parties remain uncorrupted, the parties can correctly compute any function of their inputs, while making sure that the adversary learns nothing from the computation other than the inputs and outputs of the corrupted parties. However, these protocols suffer from the following deficiency, pointed out in <ref> [He, BT] </ref>. Using any of these protocols, the public transcript of the communication can be used as an (involuntary) commitment of the parties to their inputs and outputs.
Reference: [MR] <author> S. Micali and P. Rogaway, </author> <title> "Secure Computation", </title> <note> in preparation. Preliminary version in CRYPTO 91. </note>
Reference-contexts: Coming up with a definition that captures this new type of attack turned out to be a non-trivial task. Moreover, our definition manages to incorporate this concern within the existing framework used for defining multiparty secure computation <ref> [MR, Be, CFGN, C] </ref>. In particular, it is immediate from our definition that any incoercible protocol is also (adaptively) secure in the standard sense. <p> This requirement is crucial: it will force the faking algorithm to generate fake inputs that indeed `look like' real random inputs. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>. <p> Let us shortly review the definition of secure multiparty computation (without coercion) <ref> [MR, Be, CFGN, C] </ref>. Adaptively secure protocols are defined using a similar framework as the one used here. That is, the real-life computation is compared, as here, with a computation in an ideal model.
Reference: [NR] <author> V. Niemi and A. Renvall, </author> <title> "How to prevent buying of votes in computer elections", </title> <booktitle> ASYACRYPT 1994, </booktitle> <pages> pp. 141-148. </pages>
Reference-contexts: Coercion in the context of secret voting has been studied in the past <ref> [BT, SK, NR] </ref>. These studies, however, were limited. First, they consider only a simplified version of secret voting, where there are voting centers that cannot be coerced. Next, their constructions require physically secure communication channels during crucial parts of the computation.
Reference: [RB] <author> T. Rabin and M. Ben-Or, </author> <title> "Verifiable Secret Sharing and Secure Computation with Honest Majority", </title> <booktitle> 21th STOC, </booktitle> <year> 1989, </year> <pages> pp. 73-85. </pages>
Reference-contexts: We remark that the [GMW2] construction, as well as the <ref> [BGW, CCD, RB] </ref> constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. This means that in our construction any of these methods can be used. instead of [CFGN].
Reference: [SK] <author> K. Sako and J. Kilian, </author> <title> "Receipt-Free Mix-Type Voting Scheme", </title> <booktitle> Eurocrypt 1995, </booktitle> <pages> pp. 393-403. </pages>
Reference-contexts: Coercion in the context of secret voting has been studied in the past <ref> [BT, SK, NR] </ref>. These studies, however, were limited. First, they consider only a simplified version of secret voting, where there are voting centers that cannot be coerced. Next, their constructions require physically secure communication channels during crucial parts of the computation.
Reference: [Sh] <author> A. Shamir, </author> <title> "How to share a secret", </title> <journal> CACM, </journal> <volume> vol.22, </volume> <month> Nov. </month> <year> 1979, </year> <pages> pp. 612-613. </pages>
Reference-contexts: Shamir's <ref> [Sh] </ref>.) Consider the following n-input, n-output function F 1 ( 1 ; : : : ; n ) = (e ffi d (1) ; : : : ; e ffi d (n) ) where (e; d (1) ; : : : ; d (n) ) = ~ G ( L i
Reference: [Y] <author> A. Yao, </author> <title> "Protocols for Secure Computation", </title> <booktitle> 23th FOCS, </booktitle> <year> 1982, </year> <month> pp.160-164. </month>
Reference-contexts: Still, the parties want to compute some common function of their inputs in a secure way. Security here means maintaining correctness of the outputs while keeping the parties' internal data as private as possible. This is the well-known secure multiparty computation problem (e.g., <ref> [Y, GMW2] </ref>). The parties' distrust in each other is modeled via an adversary that corrupts parties, learns their inputs, and controls their behavior.
References-found: 20

