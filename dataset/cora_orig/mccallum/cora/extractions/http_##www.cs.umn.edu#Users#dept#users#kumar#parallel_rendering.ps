URL: http://www.cs.umn.edu/Users/dept/users/kumar/parallel_rendering.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: Fast Volume Rendering Using an Efficient, Scalable Parallel Formulation of the Shear-Warp Algorithm  
Author: Minesh B. Amin Ananth Grama Vineet Singh 
Keyword: volume rendering, raytracing, algorithms, shear-warp algorithm, performance modeling and analysis, scalability, adaptive load-balancing  
Address: Palo Alto  
Affiliation: Hewlett Packard Labs,  
Abstract: This paper presents a fast and scalable parallel algorithm for volume rendering and its implementation on distributed-memory parallel computers. This parallel algorithm is based on the shear-warp algorithm of Lacroute and Levoy. Coupled with optimizations that exploit coherence in the volume and image space, the shear-warp algorithm is currently acknowledged to be the fastest sequential volume rendering algorithm. We have designed a memory efficient parallel formulation of this algorithm that (1) drastically reduces communication requirements by using a novel data partitioning scheme and (2) improves multi-frame performance with an adaptive load-balancing technique. All the optimizations of the Lacroute-Levoy algorithm are preserved in the parallel formulation. The paper also provides an analytical model of performance for the parallel formulation that shows that it is possible to sustain excellent performance across a wide range of practical problem sizes and number of processors. Our implementation, running on a 128 processor TMC CM-5 distributed-memory parallel computer, renders a 256 3 voxel medical data set at 12 frames/sec. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> HANSEN, C. D., KROGH, M., AND WHITE, W. </author> <title> Massively Parallel Visualization: Parallel Rendering. </title> <booktitle> In Proceedings of the Seventh SIAM Conference on Parallel Processing for Scientific Computing (Feb. </booktitle> <year> 1995), </year> <pages> pp. 790-795. </pages>
Reference-contexts: To further illustrate the reduction of communication overhead in using sheared volume space partitioning compared to volume space partitioning, we note that the algorithm described in <ref> [6, 1] </ref> uses volume partitioning. They have a phase they call image composition. This is identical to what we have to do for compositing of the overlap areas of the image if we use volume space partitioning (as described in Section 3.1.1). <p> For a 128 3 voxel dataset and 256 2 pixel image using 128 processors on a CM-5, this phase takes 128.7 msecs in <ref> [6, 1] </ref>. <p> In fact, performance on shared bus multicomputers is rarely known to scale to a large number of processors. There have been other attempts at parallelizing volume rendering. The best rendering times reported in these papers range from a few hundred milliseconds [7] to a few seconds <ref> [1, 6] </ref>. Our results are over an order of magnitude better than most of these results and more than two orders of magnitude better than some of them [1, 6]. 6 Conclusions and Future Work In this paper, we have presented a parallel formulation of the shear-warp rendering algorithm and demonstrated <p> The best rendering times reported in these papers range from a few hundred milliseconds [7] to a few seconds <ref> [1, 6] </ref>. Our results are over an order of magnitude better than most of these results and more than two orders of magnitude better than some of them [1, 6]. 6 Conclusions and Future Work In this paper, we have presented a parallel formulation of the shear-warp rendering algorithm and demonstrated scalable performance up to 128 processors of a CM-5.
Reference: [2] <author> KUMAR, V., GRAMA, A., GUPTA, A., AND KARYPIS, G. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <address> Benjamin/Cummings, </address> <year> 1994. </year>
Reference-contexts: At the end of the all-to-all broadcast, each processor contains all the data from all the processors. This can be done in a tree of communicationmessages with message sizes doubling at each level of the tree. See <ref> [2] </ref> for more details. clear that the communication overhead of our parallel formulation is minimal. Our performance results later support this observation. Compositing Slices to form Intermediate Images As pointed out in Section 3 the compositing phase in sheared volume space partitioning can proceed independently at various processors. <p> The lookup table is a table of approximately 8K entries which are computed independently. Each processor computes an equal number of entries. These are then made available to everyone else through a single all-to-all broadcast operation <ref> [2] </ref>. Shearing the volume results in communication between processors. This communication is integrated with the communication resulting from load balance. Compositing and warp are completely local operations. Each processor is now left with segments of the final image.
Reference: [3] <author> LACROUTE, P., AND LEVOY, M. </author> <title> Fast Volume Rendering Using a Shear-Warp Factorization of the Viewing Transformation. </title> <booktitle> In Proceedings of the SIGGRAPH 94 Conference (July 1994), </booktitle> <pages> pp. 451-457. </pages>
Reference-contexts: A number of approaches have been adopted towards achieving this goal. These include advances in algorithms, using dedicated hardware, and general purpose parallel processors. A number of algorithms have been proposed for volume rendering. They can be broadly classified as raytracing [5], splatting [4], cell-projection [8], or shear-warp algorithms <ref> [3] </ref>. Raytracing algorithms, specifically those based on object space methods, trace rays through each point in the image plane as they pass through volume elements. The contribution of each volume element to an image pixel is computed by trilinearly interpolating neighboring voxels. <p> The shear-warp algorithm can be viewed as an image space technique capable of utilizing both image and object space coherence. This approach has shown particular promise. Lacroute and Levoy <ref> [3] </ref> combine this technique with optimizations such as early termination and run-length encoding to obtain single processor performance that exceeds that of most parallel formulations of volume rendering thus far. Improvements in rendering speed come at the expense of a second resampling step. <p> Improvements in rendering speed come at the expense of a second resampling step. Its implications on image quality are discussed by Lacroute and Levoy <ref> [3] </ref>. The fastest sequential time for rendering a typical volume of size 256 fi 256 fi 256 using the shear-warp algorithm is approximately one second on a R4000 Indigo. The desired goal of achieving real time rendering requires a further thirty-fold speedup over this time. <p> Fortunately, it has been shown that this does not lead to a significant deterioration in the quality of rendering <ref> [3] </ref>. Our parallel algorithm maintains the image quality of this sequential algorithm. The operation count can be further reduced by using a variety of optimizations. <p> Using this, runs of transparent voxels are skipped. In this way, the algorithm follows two pointer chains computing interpolations only for non-transparent voxels and unsaturated intermediate image pixels. This is illustrated in Figure 2. For the implementation in <ref> [3] </ref>, three run-length encodings are pre-computed, one for each possible principal viewing direction. The encoding used for a particular frame is the one with slices most perpendicular to the viewing rays. For the medical datasets used in [3], total memory required for the volume representation is lower than an uncompressed 3D <p> This is illustrated in Figure 2. For the implementation in <ref> [3] </ref>, three run-length encodings are pre-computed, one for each possible principal viewing direction. The encoding used for a particular frame is the one with slices most perpendicular to the viewing rays. For the medical datasets used in [3], total memory required for the volume representation is lower than an uncompressed 3D array representation despite the need for three run-length encodings. Our parallel algorithm uses the same run-length encoded data-structure used in this sequential algorithm. <p> Table 1 shows the breakdown of the time taken for the sequential algorithm on a single SGI Indigo R4000 workstation for a 256x256x167 voxel brain data set (from a MRI scan of a human brain) and image size 256x256 pixels <ref> [3] </ref>. This implies that each one of these functional units must be effectively parallelized. Although Lacroute and Levoy [3] discuss versions of their algorithm to deal with perspective projections and run-time change in the opacity transfer function, we do not discuss them in our paper. <p> taken for the sequential algorithm on a single SGI Indigo R4000 workstation for a 256x256x167 voxel brain data set (from a MRI scan of a human brain) and image size 256x256 pixels <ref> [3] </ref>. This implies that each one of these functional units must be effectively parallelized. Although Lacroute and Levoy [3] discuss versions of their algorithm to deal with perspective projections and run-time change in the opacity transfer function, we do not discuss them in our paper. <p> Cutting across scanlines reduces coherence in the image and volume space. As the number of processors increases, scanlines might be cut into a large number of segments and eventually, all benefit of spatial coherence in volume and image may be lost. As pointed out in <ref> [3] </ref>, coherence in volume and image space is responsible for reducing the computational complexity of this problem from O (n 3 ) to O (n 2 ) and exploiting this coherence leads to significant performance gains in practice. 3.1.3 Sheared Volume Space Partitioning A principal drawback of volume space partitioning is <p> Note that for neighboring processors that share a boundary in the sheared volume space partitioning, one scanline per slice is replicated on both sides of the boundary. No additional compositing computation is required with this scheme. The entire volume is traversed only once exactly like the original sequential algorithm <ref> [3] </ref>, except for the replicated scanlines. When processor boundaries change (due to relative shear between subsequent frames or due to load balancing) additional communication is required for replication of volume scanlines on processor boundaries. <p> We assume that each processor has equal computational load. Although there are a total of O (n 3 ) voxels in the dataset, a significant fraction of them are transparent. Furthermore, a large number of them are never visited due to early termination of rays. Lacroute and Levoy <ref> [3] </ref> estimate that the computational complexity of this phase of the algorithm is O (n 2 ). Assuming ideal load balance, the parallel runtime of this phase is given by O ( n 2 p ). <p> We report on the rendering time of two datasets here: the brain dataset of dimensions 256 fi 256 fi 167 and the smaller 1:2 subsampled version of this brain dataset of dimensions 128 fi 128 fi 84. The brain dataset is the same as the one used in <ref> [3] </ref>. In each case, the final image size was 256 fi 256. Since the communication overhead changes as the dataset is rotated, the per-frame times are computed as an average of 89 frames displaced from each other by a rotation of one degree.
Reference: [4] <author> LAUR, D., AND HANRAHAN, P. </author> <title> Hierarchical Splatting: A Progressive Refinement Algorithm for Volume Rendering. </title> <booktitle> Computer Graphics 25, </booktitle> <month> 4 (July </month> <year> 1991), </year> <pages> 285-288. </pages>
Reference-contexts: A number of approaches have been adopted towards achieving this goal. These include advances in algorithms, using dedicated hardware, and general purpose parallel processors. A number of algorithms have been proposed for volume rendering. They can be broadly classified as raytracing [5], splatting <ref> [4] </ref>, cell-projection [8], or shear-warp algorithms [3]. Raytracing algorithms, specifically those based on object space methods, trace rays through each point in the image plane as they pass through volume elements. The contribution of each volume element to an image pixel is computed by trilinearly interpolating neighboring voxels.
Reference: [5] <author> LEVOY, M. </author> <title> Display of Surfaces from Volume Data. </title> <journal> IEEE Computer Graphics and Applications 8, </journal> <month> 3 (May </month> <year> 1988), </year> <pages> 29-37. </pages>
Reference-contexts: A number of approaches have been adopted towards achieving this goal. These include advances in algorithms, using dedicated hardware, and general purpose parallel processors. A number of algorithms have been proposed for volume rendering. They can be broadly classified as raytracing <ref> [5] </ref>, splatting [4], cell-projection [8], or shear-warp algorithms [3]. Raytracing algorithms, specifically those based on object space methods, trace rays through each point in the image plane as they pass through volume elements. The contribution of each volume element to an image pixel is computed by trilinearly interpolating neighboring voxels. <p> Before describing the shear-warp algorithm, let us consider raytracing algorithms based on object space methods <ref> [5] </ref>. For each pixel in the viewing plane, a ray is driven through the volume slices and their color and opacity accrued in a front to back order.
Reference: [6] <author> MA, K.-L., PAINTER, J. S., HANSEN, C. D., AND KROGH, M. </author> <title> F. </title>
Reference-contexts: To further illustrate the reduction of communication overhead in using sheared volume space partitioning compared to volume space partitioning, we note that the algorithm described in <ref> [6, 1] </ref> uses volume partitioning. They have a phase they call image composition. This is identical to what we have to do for compositing of the overlap areas of the image if we use volume space partitioning (as described in Section 3.1.1). <p> For a 128 3 voxel dataset and 256 2 pixel image using 128 processors on a CM-5, this phase takes 128.7 msecs in <ref> [6, 1] </ref>. <p> In fact, performance on shared bus multicomputers is rarely known to scale to a large number of processors. There have been other attempts at parallelizing volume rendering. The best rendering times reported in these papers range from a few hundred milliseconds [7] to a few seconds <ref> [1, 6] </ref>. Our results are over an order of magnitude better than most of these results and more than two orders of magnitude better than some of them [1, 6]. 6 Conclusions and Future Work In this paper, we have presented a parallel formulation of the shear-warp rendering algorithm and demonstrated <p> The best rendering times reported in these papers range from a few hundred milliseconds [7] to a few seconds <ref> [1, 6] </ref>. Our results are over an order of magnitude better than most of these results and more than two orders of magnitude better than some of them [1, 6]. 6 Conclusions and Future Work In this paper, we have presented a parallel formulation of the shear-warp rendering algorithm and demonstrated scalable performance up to 128 processors of a CM-5.
References-found: 6

