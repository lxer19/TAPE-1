URL: http://www-cad.eecs.berkeley.edu/HomePages/aml/publications/erl95-12.ps.gz
Refering-URL: http://www-cad.eecs.berkeley.edu/HomePages/aml/publications/index.html
Root-URL: http://www.cs.berkeley.edu
Title: Inference of State Machines from Examples of Behavior  
Author: Arlindo Oliveira Stephen Edwards 
Note: 1 aml@eecs.berkeley.edu This work was developed while this author was supported by the Joint Services Electronics Program under contract number F49620-94-C-0038. 2 sedwards@eecs.berkeley.edu This work was developed while the author was supported, in part, by a National Science Foundation Graduate Research Fellowship. Additional support was provided by the Semiconductor Research Corporation under grant number 94-DC-008.  
Date: February 18, 1995  
Abstract-found: 0
Intro-found: 1
Reference: [Ang78] <author> D. Angluin. </author> <title> On the complexity of minimum inference of regular sets. </title> <journal> Inform. Control, </journal> <volume> 39(3) </volume> <pages> 337-350, </pages> <year> 1978. </year>
Reference-contexts: If all strings of length n or less are given (a uniform-complete sample), the problem can be solved in polynomial time [GH66, TB73, PF88]. However, Angluin has shown <ref> [Ang78] </ref> that even if an arbitrarily small fixed fraction (j (n) j) * , * &gt; 0 is missing, the problem remains NP-complete. The problem becomes easier if the algorithm is allowed to make queries or experiment with the unknown machine.
Reference: [Ang87] <author> D. Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Inform. Comput., </journal> <volume> 75(2) </volume> <pages> 87-106, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: However, Angluin has shown [Ang78] that even if an arbitrarily small fixed fraction (j (n) j) * , * &gt; 0 is missing, the problem remains NP-complete. The problem becomes easier if the algorithm is allowed to make queries or experiment with the unknown machine. Angluin <ref> [Ang87] </ref> proposes an algorithm based on the approach described by Gold [Gol72] that solves the problem in polynomial time by allowing the algorithm to ask membership queries.
Reference: [BK76] <author> A. W. Biermann and R. Krishnaswamy. </author> <title> Constructing programs from example computations. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> SE-2:141-153, </volume> <year> 1976. </year>
Reference-contexts: Our algorithms take a set of labeled strings and do not make queries or experiment with the machine. The best algorithms known for the problem addressed here, where the learner has no control over the training set, remain those proposed by Bierman et al. <ref> [BK76, BP75] </ref>. Based on an explicit search algorithm guaranteed to obtain the exact solution, they require, in general, exponential time. Section 3.2 details an explicit enumeration method similar to Bierman's, and uses a data structure that makes the implementation very efficient. <p> Presented first is an explicit algorithm that builds a machine by traversing the transitions in the specification, fitting them into the machine so the output and transitions requirements are satisfied. This is very similar to Bierman et al.'s work <ref> [BK76, BP75] </ref>. Presented second is an implicit algorithm that simultaneously considers all possible mapping functions F , and eliminates those not satisfying the output and transition requirements. Both algorithms look for a minimum machine in stages.
Reference: [BP75] <author> A. W. B. R. I. Biermann and F. E. Petry. </author> <title> Speeding up the synthesis of programs from traces. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-24:122-136, </volume> <year> 1975. </year>
Reference-contexts: Our algorithms take a set of labeled strings and do not make queries or experiment with the machine. The best algorithms known for the problem addressed here, where the learner has no control over the training set, remain those proposed by Bierman et al. <ref> [BK76, BP75] </ref>. Based on an explicit search algorithm guaranteed to obtain the exact solution, they require, in general, exponential time. Section 3.2 details an explicit enumeration method similar to Bierman's, and uses a data structure that makes the implementation very efficient. <p> Presented first is an explicit algorithm that builds a machine by traversing the transitions in the specification, fitting them into the machine so the output and transitions requirements are satisfied. This is very similar to Bierman et al.'s work <ref> [BK76, BP75] </ref>. Presented second is an implicit algorithm that simultaneously considers all possible mapping functions F , and eliminates those not satisfying the output and transition requirements. Both algorithms look for a minimum machine in stages.
Reference: [BRB89] <author> K. Brace, R. Rudell, and R. Bryant. </author> <title> Efficient implementation of a BDD package. </title> <booktitle> In Proceedings of the 26th Design Automation Conference, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: The implicit algorithm is implemented in C++ and makes use of the MDD package described by Kam and Brayton [KB90]. This package uses the CMU Boolean Decision Diagram package described by Brace <ref> [BRB89] </ref>. 19 MainLoop () F := 1 R := ; Stores the processed transitions C := LargeClique () ComputeAllowed (C) foreach t i := (a i ; n s i ; n d i ; b i ) 2 T R := R [ t i Add this transitions to the
Reference: [CP90] <author> R. Carraghan and P. M. Pardalos. </author> <title> An exact algorithm for the maximum clique problem. </title> <journal> Operations Research Letters, </journal> <volume> 9 </volume> <pages> 375-382, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: We locate a large clique in the incompatibility graph using a slightly modified version of an exact algorithm by Carraghan and Pardalos <ref> [CP90] </ref>, shown in Figure 3.2. The algorithm takes a set of nodes, forms subsets incompatible with another node from the set, and calls itself on these subsets.
Reference: [DM93] <author> S. Das and M. Mozer. </author> <title> A unified gradient-descent/clustering algorithm architecture for finite state machine induction. </title> <booktitle> In Advances in Neural Information Processing Systems 6, </booktitle> <address> Denver, CO, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Recently, connectionist approaches to learning from a given set of strings have been proposed. These have had limited success. Polack [Pol91], Giles et al. [GMC + 92] and Das and Mozer <ref> [DM93] </ref> propose different approaches based on gradient descent algorithms for neural network training, but their results show this strategy does not have any important advantages over search-based methods (e.g., those described in this report). Being heuristic algorithms, they are not guaranteed to find the exact solution.
Reference: [GH66] <author> James N. Gray and Michael A. Harrison. </author> <title> The theory of sequential relations. </title> <journal> Information and Control, </journal> <volume> 9, </volume> <year> 1966. </year>
Reference-contexts: If all strings of length n or less are given (a uniform-complete sample), the problem can be solved in polynomial time <ref> [GH66, TB73, PF88] </ref>. However, Angluin has shown [Ang78] that even if an arbitrarily small fixed fraction (j (n) j) * , * &gt; 0 is missing, the problem remains NP-complete. The problem becomes easier if the algorithm is allowed to make queries or experiment with the unknown machine.
Reference: [GL65] <author> A. Grasselli and F. Luccio. </author> <title> A method for minimizing the number of internal states in incompletely specified sequential networks. </title> <journal> IRE Transactions on Electronic Computers, </journal> <volume> EC-14(3):350-359, </volume> <month> June </month> <year> 1965. </year>
Reference-contexts: A compatible is a set of states equivalent in the sense that they can be merged without affecting the behavior of the machine. The minimum machine can be found by selecting a minimum set of compatibles that satisfies two simple requirements. This method was improved by Grasselli and Luccio <ref> [GL65] </ref>, who showed that only a subset of the compatibles, the prime compatibles, need be considered. Hachtel et al.'s [HRSJ91] stamina program provides an efficient implementation of this algorithm. This algorithm is still the state-of-the-art in finite state machine reduction for the majority of cases.
Reference: [GMC + 92] <author> C. L. Giles, C. B. Miller, D. Chen, H. H. Chen, G. Z. Sun, and Y. C. Lee. </author> <title> Learning and extracting finite state automata with second-order recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 393-405, </pages> <year> 1992. </year>
Reference-contexts: Section 3.2 details an explicit enumeration method similar to Bierman's, and uses a data structure that makes the implementation very efficient. Recently, connectionist approaches to learning from a given set of strings have been proposed. These have had limited success. Polack [Pol91], Giles et al. <ref> [GMC + 92] </ref> and Das and Mozer [DM93] propose different approaches based on gradient descent algorithms for neural network training, but their results show this strategy does not have any important advantages over search-based methods (e.g., those described in this report).
Reference: [Gol72] <author> E. M. Gold. </author> <title> System identification via state characterization. </title> <journal> Automatica, </journal> <volume> 8 </volume> <pages> 621-636, </pages> <year> 1972. </year>
Reference-contexts: The problem becomes easier if the algorithm is allowed to make queries or experiment with the unknown machine. Angluin [Ang87] proposes an algorithm based on the approach described by Gold <ref> [Gol72] </ref> that solves the problem in polynomial time by allowing the algorithm to ask membership queries. Schapire [Sch92] proposes an interesting approach that does not require the availability of a reset signal to take the machine to a known state.
Reference: [Gol78] <author> E. M. Gold. </author> <title> Complexity of automaton identification from given data. </title> <journal> Inform. Control, </journal> <volume> 37 </volume> <pages> 302-320, </pages> <year> 1978. </year>
Reference-contexts: Given an algorithm that computes the minimum DFA accepting a set of strings and rejecting another, it is easy to select the minimum Moore machine consistent with the observed data. The problem of selecting the minimum DFA consistent with a set of labeled strings is NP-complete. Gold <ref> [Gol78] </ref> proved that given a finite alphabet , two finite subsets S; T fl and an integer k, determining if there is a k-state DFA that recognizes L such that S L and T fl L is NP-complete.
Reference: [HRSJ91] <author> G. Hachtel, J.-K. Rho, F. Somenzi, and R. </author> <title> Jacoby. Exact and heuristic algorithms for the minimization of incompletely specified state machines. </title> <booktitle> In Proceedings of the European Design Automation Conference, </booktitle> <year> 1991. </year>
Reference-contexts: The minimum machine can be found by selecting a minimum set of compatibles that satisfies two simple requirements. This method was improved by Grasselli and Luccio [GL65], who showed that only a subset of the compatibles, the prime compatibles, need be considered. Hachtel et al.'s <ref> [HRSJ91] </ref> stamina program provides an efficient implementation of this algorithm. This algorithm is still the state-of-the-art in finite state machine reduction for the majority of cases. Some problems, however, exhibit exponentially large numbers of compatibles, rendering an explicit enumeration approach such as stamina's ineffective. <p> In this section, we compare the performance of the explicit algorithm, mmm, described in Section 3.2 and the implicit version, iasmin, described in Section 3.3 with two algorithms that solve the problem using the FSM reduction paradigm: stamina <ref> [HRSJ91] </ref> and ism [KVBSV94]. We first selected three target machines, shown in Figure 4.1. For each generating machine, we generated a number of specifications. Each specification consisted of one string. The specifications used had strings with lengths between 10 and 65 input/output pairs. <p> Another possibility is that the generating machine is itself non-minimal. To obtain a tighter bound on the number of states in the minimal satisfying machine for a given specification, all states and transitions not visited are discarded. The resulting machine is sent through the traditional state minimizer stamina <ref> [HRSJ91] </ref> and the number of states in this minimized machine is used as an estimate. In two of 394 specifications generated this way, this bound was off by one (i.e., the minimum satisfying machine had one fewer states). 29
Reference: [KB90] <author> T. Kam and R.K. Brayton. </author> <title> Multi-valued decision diagrams. </title> <type> Tech. Report No. </type> <institution> UCB/ERL M90/125, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: behavior specification. 15 3.3.1 Multi-valued Decision Diagrams Any Boolean function of k discrete variables, x 1 ; x 2 ; : : : ; x k : F : P 1 fi P 2 fi fi P k ! f0; 1g (3:2) can be represented by a Multi-valued Decision Diagram <ref> [KB90] </ref> (MDD). An MDD is a rooted, directed, acyclic graph where each non-terminal node is labeled with the name of one variable. An MDD for F has two terminal nodes f z and f o that correspond to the leaves of the graph. <p> For a given variable ordering, reduced, ordered MDDs are canonical representations for functions defined over that domain, thus implying that two functions can easily be checked for equivalence. Our implicit algorithm uses the MDD package described by Kam and Brayton <ref> [KB90] </ref>. This MDD package provides an array of primitives for function manipulation. The reader is referred to that reference for a more detailed description of these primitives. We use the following MDD package primitives: 1. <p> The call to the implicit simulation algorithm only takes place if the memory requirements of the MDD package are exceeding some prespecified limit. The implicit algorithm is implemented in C++ and makes use of the MDD package described by Kam and Brayton <ref> [KB90] </ref>.
Reference: [KVBSV94] <author> T. Kam, T. Villa, R. K. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> A fully implicit algorithm for exact state minimization. </title> <booktitle> Proceedings of the Design Automation Conference, </booktitle> <year> 1994. </year> <month> 30 </month>
Reference-contexts: In this case, a version of the Grasseli and Luccio algorithm based on the implicit enumeration of the compatibles is more efficient. Kam et al. describe such a scheme <ref> [KVBSV94] </ref>. <p> In this section, we compare the performance of the explicit algorithm, mmm, described in Section 3.2 and the implicit version, iasmin, described in Section 3.3 with two algorithms that solve the problem using the FSM reduction paradigm: stamina [HRSJ91] and ism <ref> [KVBSV94] </ref>. We first selected three target machines, shown in Figure 4.1. For each generating machine, we generated a number of specifications. Each specification consisted of one string. The specifications used had strings with lengths between 10 and 65 input/output pairs.
Reference: [Lan92] <author> K. J. Lang. </author> <title> Random DFA's can be approximately learned from sparse uniform examples. </title> <booktitle> In Proc. 5th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 45-52. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: The main purpose of the connectionist work, however, was not to beat discrete search algorithms, but to evaluate the feasibility of such an approach to problems of this kind. Lang <ref> [Lan92] </ref> describes a much more promising heuristic approach. Although it fails to find the smallest 2 DFA in many cases, it is a very efficient algorithm and and can find approximate solutions for machines with several hundred states.
Reference: [PF88] <author> S. Porat and J. A. Feldman. </author> <title> Learning automata from ordered examples. </title> <booktitle> In Proc. 1st Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 386-396, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: If all strings of length n or less are given (a uniform-complete sample), the problem can be solved in polynomial time <ref> [GH66, TB73, PF88] </ref>. However, Angluin has shown [Ang78] that even if an arbitrarily small fixed fraction (j (n) j) * , * &gt; 0 is missing, the problem remains NP-complete. The problem becomes easier if the algorithm is allowed to make queries or experiment with the unknown machine.
Reference: [Pfl73] <author> C. F. Pfleeger. </author> <title> State reduction in incompletely specified finite state machines. </title> <journal> IEEE Trans. Computers, </journal> <volume> C-22:1099-1102, </volume> <year> 1973. </year>
Reference-contexts: The problem of selecting the minimum automaton consistent with a set of strings can be transformed into the problem of minimizing an incompletely-specified finite state machine 1 . Pfleeger <ref> [Pfl73] </ref> showed minimizing these is NP-complete. However, since this problems is of great practical importance, many different algorithms have been developed for its solution. Paull and Unger [PU59] were the first to propose a method based on the selection of compatibility classes, or compatibles.
Reference: [Pol91] <author> Jordan B. Pollack. </author> <title> The induction of dynamical recognizers. </title> <journal> Machine Learning, </journal> <volume> 7 </volume> <pages> 123-148, </pages> <year> 1991. </year>
Reference-contexts: Section 3.2 details an explicit enumeration method similar to Bierman's, and uses a data structure that makes the implementation very efficient. Recently, connectionist approaches to learning from a given set of strings have been proposed. These have had limited success. Polack <ref> [Pol91] </ref>, Giles et al. [GMC + 92] and Das and Mozer [DM93] propose different approaches based on gradient descent algorithms for neural network training, but their results show this strategy does not have any important advantages over search-based methods (e.g., those described in this report).
Reference: [PU59] <author> M. Paull and S. Unger. </author> <title> Minimizing the number of states in incompletely specified state machines. </title> <journal> IRE Transactions on Electronic Computers, </journal> <month> September </month> <year> 1959. </year>
Reference-contexts: Pfleeger [Pfl73] showed minimizing these is NP-complete. However, since this problems is of great practical importance, many different algorithms have been developed for its solution. Paull and Unger <ref> [PU59] </ref> were the first to propose a method based on the selection of compatibility classes, or compatibles. A compatible is a set of states equivalent in the sense that they can be merged without affecting the behavior of the machine.
Reference: [Sch92] <author> R. E. Schapire. </author> <title> The Design and Analysis of Efficient Learning Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1992. </year>
Reference-contexts: The problem becomes easier if the algorithm is allowed to make queries or experiment with the unknown machine. Angluin [Ang87] proposes an algorithm based on the approach described by Gold [Gol72] that solves the problem in polynomial time by allowing the algorithm to ask membership queries. Schapire <ref> [Sch92] </ref> proposes an interesting approach that does not require the availability of a reset signal to take the machine to a known state. All these algorithms, however, solve easier versions of the problem addressed here.
Reference: [TB73] <author> B. A. Trakhtenbrot and Y. M. Barzdin. </author> <title> Finite Automata. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1973. </year>
Reference-contexts: If all strings of length n or less are given (a uniform-complete sample), the problem can be solved in polynomial time <ref> [GH66, TB73, PF88] </ref>. However, Angluin has shown [Ang78] that even if an arbitrarily small fixed fraction (j (n) j) * , * &gt; 0 is missing, the problem remains NP-complete. The problem becomes easier if the algorithm is allowed to make queries or experiment with the unknown machine.
Reference: [Tom82] <author> M. Tomita. </author> <title> Dynamic construction of finite-state automata from examples using hill-climbing. </title> <booktitle> In Proc. Fourth Annual Cognitive Science Conference, </booktitle> <pages> page 105, </pages> <year> 1982. </year> <month> 31 </month>
Reference-contexts: Being heuristic algorithms, they are not guaranteed to find the exact solution. Moreover, the size of problems they can handle is very limited. For example, they are not able to solve some of the Tomita grammars <ref> [Tom82] </ref>, none of which require larger than five-state DFAs. The main purpose of the connectionist work, however, was not to beat discrete search algorithms, but to evaluate the feasibility of such an approach to problems of this kind. Lang [Lan92] describes a much more promising heuristic approach. <p> Considerations like this lead us to a lower bound on the number of states in the minimum machine. 4 accept reject 1 0 111 01 11111 011 1111111 11111110 those in the "reject" column produce a 0. From Tomita <ref> [Tom82] </ref>. n 0 n 1 n 2 n 18 n 19 n 20 machine.
References-found: 23

