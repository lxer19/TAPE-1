URL: http://theory.lcs.mit.edu/~fftw/fftw-paper.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~fftw/
Root-URL: 
Email: athena@theory.lcs.mit.edu  stevenj@mit.edu  
Phone: 2  02139.  
Title: The Fastest Fourier Transform in the West (MIT-LCS-TR-728)  
Author: Matteo Frigo Steven G. Johnson 
Address: 77 Massachusetts Avenue, 12-104, Cambridge, MA  
Note: 02139.  
Date: September 11, 1997  
Affiliation: Massachusetts Institute of Technology  Massachusetts Institute of Technology,  
Abstract: Matteo Frigo was supported in part by the Defense Advanced Research Projects Agency (DARPA) under Grant N00014-94-1-0985. Steven G. Johnson was supported in part by a DoD NDSEG Fellowship, an MIT Karl Taylor Compton Fellowship, and by the Materials Research Science and Engineering Center program of the National Science Foundation under award DMR-9400334. This paper is a technical report of the MIT Labroratory for Computer Science MIT-LCS-TR-728 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. N. Swarztrauber, </author> <title> Vectorizing the FFTs, </title> <booktitle> Parallel Computations, </booktitle> <pages> pp. 51-83, </pages> <year> 1982. </year> <editor> G. </editor> <publisher> Rodrigue ed. </publisher>
Reference-contexts: 1 Introduction This paper describes FFTW, a portable C package for computing the one- and multidimensional complex discrete Fourier transform (DFT). Extensive benchmarking demonstrates that FFTW is typically faster than all other publicly available DFT software, including the well-known FFTPACK <ref> [1] </ref> and the code from Numerical Recipes [2]. More interestingly, FFTW is competitive with or better than proprietary, highly-tuned codes such as Sun's Performance Library and IBM's ESSL library. <p> This metric is imprecise because it refers only to radix-2 Cooley-Tukey algorithms. Nonetheless, it allows 3 our numbers to be compared with other results in the literature <ref> [1] </ref>. Except where otherwise noted, all benchmarks were performed in double precision. A complete listing of the FFT implementations included in the benchmark is given in Table 1. Performance Library for large transforms in double precision, although Sun's software is faster for sizes between 128 and 2048. <p> Hale in a C numerical library from the Colorado School of Mines. Krukar 1D C FFT by R. H. Krukar. Nielson Mixed-radix, C FFT by J. J. Nielson. Singleton Mixed-radix, multidimensional, Fortran FFT by R. C. Singleton [20]. FFTPACK Fortran 1D FFT library by P. N. Swarztrauber <ref> [1] </ref>. PDA 3D FFT from the Public Domain Algorithms library. Uses FFTPACK for its 1D FFTs. NR C FFTs in one or more dimensions from Numerical Recipes in C [2]. Temperton Fortran FFT in one and three dimensions by C. Temperton [21]. NAPACK Fortran FFT from the free NAPACK library.
Reference: [2] <author> W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling, </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <address> New York, NY: </address> <publisher> Cambridge University Press, </publisher> <editor> 2nd ed., </editor> <year> 1992. </year>
Reference-contexts: 1 Introduction This paper describes FFTW, a portable C package for computing the one- and multidimensional complex discrete Fourier transform (DFT). Extensive benchmarking demonstrates that FFTW is typically faster than all other publicly available DFT software, including the well-known FFTPACK [1] and the code from Numerical Recipes <ref> [2] </ref>. More interestingly, FFTW is competitive with or better than proprietary, highly-tuned codes such as Sun's Performance Library and IBM's ESSL library. FFTW is an implementation of the Cooley-Tukey [3] fast Fourier transform (FFT), and is freely available on the World Wide Web at the URL http://theory.lcs.mit.edu/fftw. <p> Nielson. Singleton Mixed-radix, multidimensional, Fortran FFT by R. C. Singleton [20]. FFTPACK Fortran 1D FFT library by P. N. Swarztrauber [1]. PDA 3D FFT from the Public Domain Algorithms library. Uses FFTPACK for its 1D FFTs. NR C FFTs in one or more dimensions from Numerical Recipes in C <ref> [2] </ref>. Temperton Fortran FFT in one and three dimensions by C. Temperton [21]. NAPACK Fortran FFT from the free NAPACK library. Mayer 1D C FFT by R. Mayer. Edelblute 1D C FFT by D. Edelblute and R. Mayer. Beauregard 1D C FFT by G. Beauregard.
Reference: [3] <author> J. W. Cooley and J. W. Tukey, </author> <title> An algorithm for the machine computation of the complex Fourier series, </title> <journal> Mathematics of Computation, </journal> <volume> vol. 19, </volume> <pages> pp. 297-301, </pages> <month> Apr. </month> <year> 1965. </year>
Reference-contexts: More interestingly, FFTW is competitive with or better than proprietary, highly-tuned codes such as Sun's Performance Library and IBM's ESSL library. FFTW is an implementation of the Cooley-Tukey <ref> [3] </ref> fast Fourier transform (FFT), and is freely available on the World Wide Web at the URL http://theory.lcs.mit.edu/fftw. Three main ideas are the keys to FFTW's performance. First, the computation of the transform is performed by an executor consisting of highly-optimized, composable blocks of C code called codelets. <p> Once the user has created a plan, she can use the plan as many times as needed. FFTW is not restricted to transforms whose size is a power of 2. A parallel version of the executor, written in Cilk [5], also exists. The executor implements the well-known Cooley-Tukey algorithm <ref> [3] </ref>, which works by factoring the size N of the transform into N = N 1 N 2 . The algorithm then recursively computes N 1 transforms of size N 2 and N 2 transforms of size N 1 . <p> The AST generation phase creates a crude AST for the desired codelet. This AST contains a lot of useless code, such as multiplications by 0 and 1, but the code is polished by the following optimization phase. The AST generator uses the Cooley-Tukey algorithm <ref> [3] </ref> in the form presented by [6, page 611]. We assume that the reader is familiar with this well-known algorithm. The actual implementation of the AST generator consists of about 60 lines of code.
Reference: [4] <author> X. Leroy, </author> <title> The Caml Light system release 0.71. </title> <institution> Institut National de Recherche en In-formatique at Automatique (INRIA), </institution> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: In this way, FFTW is a single program that performs efficiently on a variety of architectures. Third, the codelets are automatically generated by a codelet generator written in the Caml Light dialect of ML <ref> [4] </ref>. The codelet generator produces long, optimized, unreadable code, which is nevertheless easy to modify via simple changes to the generator. <p> The Fortran code was never faster than FFTW. We will give more results for native Fortran software in the final paper. 3 The codelet generator In this section we describe the codelet generator, that produces optimized C codelets. It is written in Caml Light <ref> [4] </ref> because it is easy to express symbolic manipulations in that language. Because of this automatic generation process, it is easy to produce and experiment with long straight-line code. The generator performs many optimizations such as constant folding and minus-sign propagation. <p> Depending on the options with which the generator is invoked, the codelet computes either the forward or the backward transform, and can optionally multiply its input by a precomputed set of twiddle factors. The codelet generator is written in the Caml Light dialect of ML <ref> [4] </ref>. Caml is an applicative, polymorphic, and strongly-typed functional language with first-class functions, algebraic data types, and pattern matching. The codelet generator operates on a subset of C's abstract syntax tree (AST).
Reference: [5] <author> R. D. Blumofe, C. F. Joerg, B. C. Kuszmaul, C. E. Leiserson, K. H. Randall, and Y. Zhou, Cilk: </author> <title> An efficient multithreaded runtime system, </title> <booktitle> in Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP), </booktitle> <address> (Santa Barbara, California), </address> <pages> pp. 207-216, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Once the user has created a plan, she can use the plan as many times as needed. FFTW is not restricted to transforms whose size is a power of 2. A parallel version of the executor, written in Cilk <ref> [5] </ref>, also exists. The executor implements the well-known Cooley-Tukey algorithm [3], which works by factoring the size N of the transform into N = N 1 N 2 . The algorithm then recursively computes N 1 transforms of size N 2 and N 2 transforms of size N 1 . <p> The current version of FFTW extends the program described in this paper in several directions. We have written three parallel versions, using Cilk <ref> [5] </ref>, Posix threads [25] and MPI [26]. We also support multidimensional real-complex transforms.
Reference: [6] <author> A. V. Oppenheim and R. W. Schafer, </author> <title> Discrete-time Signal Processing. </title> <address> Englewood Cliffs, NJ 07632: </address> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: The base case of the recursion is handled by the codelets, which are hard-coded transforms for various small sizes. We emphasize that the executor works by explicit recursion, in sharp contrast with the traditional loop-based implementations <ref> [6, page 608] </ref>. The recursive divide-and-conquer approach is superior on modern machines, because it exploits all levels of the memory hierarchy: as soon as a subproblem fits into cache, no further cache misses are needed in order to solve that subproblem. <p> Second, we can easily experiment with diverse optimizations and algorithmic variations. For example, it was easy to add support for prime factor FFT algorithms (see [8] and <ref> [6, page 619] </ref>) within the codelets. 2 A huge body of previous work on the Fourier transform exists, which we do not have space to reference properly. We limit ourselves to mention some references that are important to the present paper. <p> We limit ourselves to mention some references that are important to the present paper. A good tutorial on the FFT can be found in [9] or in classical textbooks such as <ref> [6] </ref>. Previous work exists on automatic generation of FFT programs: [10] describes the generation of FFT programs for prime sizes, and [11] presents a generator of Pascal programs implementing a Prime Factor algorithm. Johnson and Burrus [12] first applied dynamic programming to the design of optimal DFT modules. <p> This AST contains a lot of useless code, such as multiplications by 0 and 1, but the code is polished by the following optimization phase. The AST generator uses the Cooley-Tukey algorithm [3] in the form presented by <ref> [6, page 611] </ref>. We assume that the reader is familiar with this well-known algorithm. The actual implementation of the AST generator consists of about 60 lines of code. <p> We assume that the reader is familiar with this well-known algorithm. The actual implementation of the AST generator consists of about 60 lines of code. With 20 additional lines of code our generator can also produce an AST for the Prime Factor algorithm [8] as described in <ref> [6, page 619] </ref>. Recall that the Cooley-Tukey algorithm reduces a transform of size N = N 1 N 2 to N 1 transforms of size N 2 , followed by some multiplications by certain complex constants called twiddle factors, followed by N 2 transforms of size N 1 .
Reference: [7] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms. </title> <address> Cam-bridge, Massachusetts: </address> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: In order to prune the search, we assume that the optimal solution for a problem of size N is still optimal when used as a subroutine of a larger problem. With this assumption, the planner can use a dynamic-programming <ref> [7, chapter 16] </ref> algorithm to find a solution that, while not optimal, is sufficiently good for practical purposes. The solution is expressed in the form of byte-code that can be interpreted by the executor with negligible overhead. Our results contradict the folk theorem that byte-code is slow.
Reference: [8] <author> I. J. </author> <title> Good, The interaction algorithm and practical Fourier analysis, </title> <journal> J. Roy. Statist. Soc., </journal> <volume> vol. B 20, </volume> <pages> pp. 361-372, </pages> <year> 1958. </year>
Reference-contexts: Second, we can easily experiment with diverse optimizations and algorithmic variations. For example, it was easy to add support for prime factor FFT algorithms (see <ref> [8] </ref> and [6, page 619]) within the codelets. 2 A huge body of previous work on the Fourier transform exists, which we do not have space to reference properly. We limit ourselves to mention some references that are important to the present paper. <p> We assume that the reader is familiar with this well-known algorithm. The actual implementation of the AST generator consists of about 60 lines of code. With 20 additional lines of code our generator can also produce an AST for the Prime Factor algorithm <ref> [8] </ref> as described in [6, page 619].
Reference: [9] <author> P. Duhamel and M. Vetterli, </author> <title> Fast Fourier transforms: a tutorial review and a state of the art, </title> <booktitle> Signal Processing, </booktitle> <volume> vol. 19, </volume> <pages> pp. 259-299, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: We limit ourselves to mention some references that are important to the present paper. A good tutorial on the FFT can be found in <ref> [9] </ref> or in classical textbooks such as [6]. Previous work exists on automatic generation of FFT programs: [10] describes the generation of FFT programs for prime sizes, and [11] presents a generator of Pascal programs implementing a Prime Factor algorithm.
Reference: [10] <author> I. Selesnick and C. S. Burrus, </author> <title> Automatic generation of prime length FFT programs, </title> <journal> IEEE Transactions on Signal Processing, </journal> <pages> pp. 14-24, </pages> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: We limit ourselves to mention some references that are important to the present paper. A good tutorial on the FFT can be found in [9] or in classical textbooks such as [6]. Previous work exists on automatic generation of FFT programs: <ref> [10] </ref> describes the generation of FFT programs for prime sizes, and [11] presents a generator of Pascal programs implementing a Prime Factor algorithm. Johnson and Burrus [12] first applied dynamic programming to the design of optimal DFT modules.
Reference: [11] <author> F. Perez and T. Takaoka, </author> <title> A prime factor FFT algorithm implementation using a program generation technique, </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> vol. 35, </volume> <pages> pp. 1221-1223, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: A good tutorial on the FFT can be found in [9] or in classical textbooks such as [6]. Previous work exists on automatic generation of FFT programs: [10] describes the generation of FFT programs for prime sizes, and <ref> [11] </ref> presents a generator of Pascal programs implementing a Prime Factor algorithm. Johnson and Burrus [12] first applied dynamic programming to the design of optimal DFT modules.
Reference: [12] <author> H. W. Johnson and C. S. Burrus, </author> <title> The design of optimal DFT algorithms using dynamic programming, </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> vol. 31, </volume> <pages> pp. 378-387, </pages> <month> Apr. </month> <year> 1983. </year> <month> 16 </month>
Reference-contexts: Previous work exists on automatic generation of FFT programs: [10] describes the generation of FFT programs for prime sizes, and [11] presents a generator of Pascal programs implementing a Prime Factor algorithm. Johnson and Burrus <ref> [12] </ref> first applied dynamic programming to the design of optimal DFT modules. Although these papers all deal with the arithmetic complexity of the FFT, we are not aware of previous work where these techniques are used to maximize the actual performance of a program.
Reference: [13] <author> J.-W. Hong and H. T. Kung, </author> <title> I/O complexity: </title> <booktitle> the red-blue pebbling game, in Pro--ceedings of the Thirteenth Annual ACM Symposium on Theory of Computing, (Mil-waukee), </booktitle> <pages> pp. 326-333, </pages> <year> 1981. </year>
Reference-contexts: Although these papers all deal with the arithmetic complexity of the FFT, we are not aware of previous work where these techniques are used to maximize the actual performance of a program. The behavior of the FFT in the presence of nonuniform memory was first studied by <ref> [13] </ref>. Savage [14] gives an asymptotically optimal strategy for minimizing the memory traffic of the FFT under very general conditions. Our divide-and-conquer strategy is similiar in spirit to Savage's approach. The details of our implementation are asymptotically suboptimal but faster in practice.
Reference: [14] <author> J. E. Savage, </author> <title> Space-time tradeoffs in memory hierarchies, </title> <type> Tech. Rep. CS 93-08, </type> <institution> Brown University, CS Dept., </institution> <address> Providence, RI 02912, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: Although these papers all deal with the arithmetic complexity of the FFT, we are not aware of previous work where these techniques are used to maximize the actual performance of a program. The behavior of the FFT in the presence of nonuniform memory was first studied by [13]. Savage <ref> [14] </ref> gives an asymptotically optimal strategy for minimizing the memory traffic of the FFT under very general conditions. Our divide-and-conquer strategy is similiar in spirit to Savage's approach. The details of our implementation are asymptotically suboptimal but faster in practice.
Reference: [15] <author> R. D. Blumofe, M. Frigo, C. F. Joerg, C. E. Leiserson, and K. H. Randall, </author> <title> An analysis of dag-consistent distributed shared-memory algorithms, </title> <booktitle> in Proceedings of the Eighth Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA), (Padua, Italy), </booktitle> <pages> pp. 297-308, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Our divide-and-conquer strategy is similiar in spirit to Savage's approach. The details of our implementation are asymptotically suboptimal but faster in practice. Some other theoretical evidence in support of recursive divide-and-conquer algorithms for improving locality can be found in <ref> [15] </ref>. In this short paper we do not have space to give more details about the planner and the executor. Instead, in Section 2 we present performance comparisons between FFTW and various other programs. In Section 3, we discuss the codelet generator and its optimization strategy.
Reference: [16] <author> J. W. Cooley, P. A. W. Lewis, and P. D. Welch, </author> <title> The Fast Fourier Transform algorithm and its applications, </title> <institution> IBM Research, </institution> <year> 1967. </year>
Reference-contexts: The MFLOPS count is computed by postulating the number of floating point operations to be 5N log 2 N , where N is the number of complex values being transformed (see <ref> [16, page 23] </ref> and [17, page 45]). This metric is imprecise because it refers only to radix-2 Cooley-Tukey algorithms. Nonetheless, it allows 3 our numbers to be compared with other results in the literature [1]. Except where otherwise noted, all benchmarks were performed in double precision.
Reference: [17] <author> C. V. Loan, </author> <title> Computational Frameworks for the Fast Fourier Transform. </title> <address> Philadelphia: </address> <publisher> SIAM, </publisher> <year> 1992. </year>
Reference-contexts: The MFLOPS count is computed by postulating the number of floating point operations to be 5N log 2 N , where N is the number of complex values being transformed (see [16, page 23] and <ref> [17, page 45] </ref>). This metric is imprecise because it refers only to radix-2 Cooley-Tukey algorithms. Nonetheless, it allows 3 our numbers to be compared with other results in the literature [1]. Except where otherwise noted, all benchmarks were performed in double precision.
Reference: [18] <author> C. Temperton, </author> <title> Implementation of a self-sorting in-place prime factor FFT algorithm, </title> <journal> Journal of Computational Physics, </journal> <volume> vol. 58, </volume> <pages> pp. 283-299, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: This trend also appeared on most of the other hardware that we benchmarked. A notable program is the one labelled `CWP' in the graphs, which sometimes surpasses the speed of FFTW for large transforms. Unlike all other programs we tried, CWP uses a prime-factor algorithm <ref> [18, 19] </ref> instead of the Cooley-Tukey FFT. CWP works only on a restricted set of transform sizes. Consequently, the benchmark actually times it for a transform whose size (chosen by CWP) is slightly larger than that used by the rest of the codes.
Reference: [19] <author> C. Temperton, </author> <title> A new set of minimum-add small-n rotated DFT modules, </title> <journal> Journal of Computational Physics, </journal> <volume> vol. 75, </volume> <pages> pp. 190-198, </pages> <year> 1988. </year>
Reference-contexts: This trend also appeared on most of the other hardware that we benchmarked. A notable program is the one labelled `CWP' in the graphs, which sometimes surpasses the speed of FFTW for large transforms. Unlike all other programs we tried, CWP uses a prime-factor algorithm <ref> [18, 19] </ref> instead of the Cooley-Tukey FFT. CWP works only on a restricted set of transform sizes. Consequently, the benchmark actually times it for a transform whose size (chosen by CWP) is slightly larger than that used by the rest of the codes.
Reference: [20] <author> R. C. </author> <title> Singleton, An algorithm for computing the mixed radix fast Fourier transform., </title> <journal> IEEE Transactions on Audio and Electroacoustics, </journal> <volume> vol. AU-17, </volume> <pages> pp. 93-103, </pages> <month> June </month> <year> 1969. </year>
Reference-contexts: CWP A prime-factor FFT implementation by D. Hale in a C numerical library from the Colorado School of Mines. Krukar 1D C FFT by R. H. Krukar. Nielson Mixed-radix, C FFT by J. J. Nielson. Singleton Mixed-radix, multidimensional, Fortran FFT by R. C. Singleton <ref> [20] </ref>. FFTPACK Fortran 1D FFT library by P. N. Swarztrauber [1]. PDA 3D FFT from the Public Domain Algorithms library. Uses FFTPACK for its 1D FFTs. NR C FFTs in one or more dimensions from Numerical Recipes in C [2]. Temperton Fortran FFT in one and three dimensions by C.
Reference: [21] <author> C. Temperton, </author> <title> A generalized prime factor FFT algorithm for any n = 2 p 3 q 5 r , SIAM Journal on Scientific and Statistical Computing, </title> <journal> vol. </journal> <volume> 13, </volume> <pages> pp. 676-686, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: N. Swarztrauber [1]. PDA 3D FFT from the Public Domain Algorithms library. Uses FFTPACK for its 1D FFTs. NR C FFTs in one or more dimensions from Numerical Recipes in C [2]. Temperton Fortran FFT in one and three dimensions by C. Temperton <ref> [21] </ref>. NAPACK Fortran FFT from the free NAPACK library. Mayer 1D C FFT by R. Mayer. Edelblute 1D C FFT by D. Edelblute and R. Mayer. Beauregard 1D C FFT by G. Beauregard. HARMD 3D Fortran FFT, author unknown. Table 1: Description of the programs benchmarked.
Reference: [22] <author> S. I. Feldman, D. M. Gay, M. W. Maimone, and N. L. Schryer, </author> <title> A Fortran to C converter, </title> <type> Tech. Rep. 149, </type> <institution> AT&T Bell Laboratories, </institution> <year> 1995. </year>
Reference-contexts: It was our intention to benchmark C FFTs, but much of the public-domain software was written in Fortran. These codes were converted to C via the free f2c software <ref> [22] </ref>. This raises some legitimate concerns about the quality of the automatic translation performed by f2c, as well as the relative quality of Fortran and C compilers. Accordingly, we compared the original Fortran FFTPACK with the f2c version.
Reference: [23] <author> H. Abelson and G. J. Sussman, </author> <title> Structure and Interpretation of Computer Programs. </title> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: We now give an example of how the rules are implemented in the actual codelet generator, and then we discuss some of the more subtle rules that we found useful. looking at the example, the reader can convince herself that a sufficiently powerful optimizer can be implemented quite easily <ref> [23, page 108] </ref>. By playing with the optimizer we found some interesting rules to make the codelets faster. Consider for example the two fragments of code in Figure 9. At first glance, it appears that the two fragments should perform comparably.
Reference: [24] <author> J. L. Bentley, </author> <title> Writing Efficient Programs. </title> <address> Englewood Cliffs, NJ 07632: </address> <publisher> Prentice-Hall Software Series, </publisher> <year> 1982. </year>
Reference-contexts: As a rule, the optimizer makes all constants positive and propagates the minus sign to the rest of the AST. We found that this rule typically yielded a speed improvement of about 10-15%. Another interesting result that arose from our investigations is shown in Figure 10. Conventional wisdom <ref> [24, page 84] </ref> dictates that the common subexpression c + d be pre-computed and stored into a temporary variable, as shown in the right part of the figure.
Reference: [25] <author> D. R. Butenhof, </author> <title> Programming with POSIX threads. </title> <publisher> Addison-Wesley, </publisher> <year> 1997. </year> <month> 17 </month>
Reference-contexts: The current version of FFTW extends the program described in this paper in several directions. We have written three parallel versions, using Cilk [5], Posix threads <ref> [25] </ref> and MPI [26]. We also support multidimensional real-complex transforms.
Reference: [26] <author> M. Snir, S. Otto, S. Huss-Lederman, D. Walker, and J. Dongarra, </author> <title> MPI: The Complete Reference. </title> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: The current version of FFTW extends the program described in this paper in several directions. We have written three parallel versions, using Cilk [5], Posix threads [25] and MPI <ref> [26] </ref>. We also support multidimensional real-complex transforms.
Reference: [27] <author> J. T. Buck, S. Ha, E. A. Lee, and D. G. Messerschmitt, Ptolemy: </author> <title> A framework for simulating and prototyping heterogeneous systems, </title> <journal> Int. Journal of Computer Simulation, </journal> <volume> vol. 4, </volume> <pages> pp. 155-182, </pages> <month> Apr. </month> <year> 1994. </year> <month> 18 </month>
Reference-contexts: It has continued to gain users, and is now part of the netlib repository of scientific software. FFTW has been adopted in the FFT component of the Ptolemy project <ref> [27] </ref>, a software environment for signal processing and simulation. In addition, the VSIP (Vector/Signal/Image Processing Forum) committee is discussing the possibility of incorporating FFTW into the VSIP reference implementation as an example of how to use FFTs that have an optimize/initialization phase before first use.
References-found: 27

