URL: http://ptolemy.eecs.berkeley.edu/~pino/papers/branchPrediction/unpublished.ps.gz
Refering-URL: http://ptolemy.eecs.berkeley.edu/~pino/papers/branchPrediction/index.html
Root-URL: http://www.cs.berkeley.edu
Email: pino@EECS.Berkeley.EDU, raj@lsil.COM, and culler@CS.Berkeley.EDU  
Title: Performance Evaluation of One and Two-Level Dynamic Branch Prediction Schemes over Comparable Hardware Costs Branch
Author: Jos Luis Pino Balraj Singh and David E. Culler tak en, th e pipe line lea ds 
Note: bytes  1.0 INTRODUCTION  opcode information in the instruction is known as static branch prediction. This can be as simple as predicting all branches taken which can achieve up to  
Date: ABSTRACT  68 percent  
Address: Berkeley, CA  
Affiliation: EECS Department, University of California, Berkeley, CA LSI Logic Corporation, Milpitas, CA CS Division, University of California,  
Abstract: processors. Various methods have been proposed to speculate the path of an instruction stream after a branch. In this paper, the performance of prediction schemes are evaluated by both the accuracy of prediction and the amount of hardware the technique requires to reach that level of accuracy. We model the configurations which were proposed by the authors of these schemes by allocating equal number of memory. The total number of bytes per scheme was varied from 1 byte to 128 kilobytes for each of the different runs. The inputs to the various schemes were traces obtained by running the SPEC-92 benchmarks. We also compare the performance of finite state machines proposed in [1] to update history bits in the 2 bit schemes. We find that simpler schemes for branch prediction consistently give accurate results and outperform more complex schemes in low cost hardware implementations. the branch target as early in the pipeline as possible. Another technique used to reduce the cost of branch is to speculate on the direction and the target of the branch and move the execution in that direction. If the speculation is incorrect then the processor must nullify the instructions it partially executed in the wrong direction. Speculation that is done at compile time and based on accuracy [6] or a more sophisticated strategy of always predicting forward branches not taken and backward branches as taken [7]. When speculation is done at runtime it is known as dynamic branch prediction. This is discussed in further detail in section 2.0 of this paper. For purposes of our study, we define the hardware cost as the size of the tables for address tags and prediction bits. The hardware cost model does not account for the complexity of looking up an entry in a branch prediction table. This introduces a comparably small error in the same direction as the lookup costs are proportional to the table size and complexity and do not effect our results. Our paper compares the performance of proposed dynamic branch prediction schemes over a broad range of hardware costs on the same input datasets. To our knowledge this is the first time a study of this nature has been conducted. In the following sections we describe the various dynamic prediction schemes we use for the study. For each scheme, the hardware cost model is given. Each hardware cost function given has as one of its arguments the order of the number of bytes of memory available. We also discuss our UCB/ERL M94/45, June 20, 1994 This document was created with FrameMaker 4.0.4 
Abstract-found: 1
Intro-found: 0
Reference: [4] <author> D.R. Kaeli, P.G. Emma, J.W. Knight, and T.R. Puzak, </author> <title> Contrasting instruction-fetch time and instruction-decode time branch prediction mechanisms: achieving synergy through their cooperative operation, </title> <booktitle> Eighteenth EUROMICRO Symposium on Micropro-cessing and Microprogramming (EUROMICRO 92), </booktitle> <volume> vol. </volume> <pages> 35, </pages> <address> Paris, France, 1992, p. </address> <pages> 401-8. </pages>
Reference: [5] <author> T.-Y. Yeh and Y.N. Patt, </author> <title> Two-level adaptive training branch prediction, </title> <booktitle> Proceedings of the 24th International Symposium on Microarchitecture. MICRO 24, </booktitle> <address> Albuquerque, NM, USA, </address> <publisher> ACM, </publisher> <year> 1991, </year> <pages> p. 51-61. </pages>
Reference-contexts: When a branch instruction is tak en, th e pipe line lea ds to fe tch es of se quentia l instructions after the branch. These instructions must be nullified since they are invalid. Since on an average 20 percent of the instructions are branches <ref> [5] </ref>, nullifying instr uctions impose s a substa ntia l penalty on the performance of the processor. This effect is more significant in superscalar architectures which may issue more than one instruction per cycle.
Reference: [6] <author> S.-T. Pan, K. So, and J.T. Rahmeh, </author> <title> Improving the accuracy of dynamic branch prediction using branch correlation, </title> <booktitle> Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <volume> vol. </volume> <pages> 27, </pages> <address> Bos-ton, MA, USA, 1992, p. </address> <pages> 76-84 </pages>
Reference-contexts: Speculation that is done at compile time and based on opcode information in the instruction is known as static branch prediction. This can be as simple as predicting all branches taken which can achieve up to 68 percent accuracy <ref> [6] </ref> or a more sophisticated strategy of always predicting forward branches not taken and backward branches as taken [7]. When speculation is done at runtime it is known as dynamic branch prediction. This is discussed in further detail in section 2.0 of this paper.
Reference: [7] <author> T.-Y. Yeh and Y.N. Patt, </author> <title> A comparison of dynamic branch predictors that use two levels of branch history, </title> <booktitle> 20th Annual International Symposium on Computer Architecture ISCA 20, </booktitle> <volume> vol. </volume> <pages> 21, </pages> <address> San Diego, CA, USA, 1993, p. </address> <pages> 257-66. </pages>
Reference-contexts: This can be as simple as predicting all branches taken which can achieve up to 68 percent accuracy [6] or a more sophisticated strategy of always predicting forward branches not taken and backward branches as taken <ref> [7] </ref>. When speculation is done at runtime it is known as dynamic branch prediction. This is discussed in further detail in section 2.0 of this paper. For purposes of our study, we define the hardware cost as the size of the tables for address tags and prediction bits.
Reference: [8] <author> D.A. Patterson and J. L. Hennessy, </author> <title> Computer Architecture a Quantitative Approach, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA., </address> <year> 1990. </year>
Reference: [9] <author> J. Lee and A. J. Smith, </author> <title> Branch Prediction Strategies and Branch Target Buffer Design, </title> <booktitle> IEEE Computer, </booktitle> <month> (January </month> <year> 1984), </year> <pages> pp. 6-22. </pages>
Reference: [10] <author> J. E. Smith, </author> <title> A Study of Branch Prediction Strategies, </title> <booktitle> Proceedings of the 8th International Symposium on Computer Architecture, </booktitle> <month> (May. </month> <year> 1981), </year> <pages> pp. 443-458. </pages>
References-found: 7

