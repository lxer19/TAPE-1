URL: ftp://www.cs.rutgers.edu/pub/technical-reports/hpcd-tr-28.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: 
Email: richterg@cs.rutgers.edu  
Title: Learning When Reformulation is Appropriate for Iterative Design  
Author: Mark Schwabacher Thomas Ellman Haym Hirsh Gerard Richter fschwabac, ellman, hirsh, 
Keyword: mechanical engineering, design, decision tree induction, reformulation, numerical optimization.  
Address: New Jersey Piscataway, New Jersey 08855  
Affiliation: Department of Computer Science Hill Center for the Mathematical Sciences Busch Campus Rutgers, The State University of  
Abstract: It is well known that search-space reformulation can improve the speed and reliability of numerical optimization in engineering design. We argue that the best choice of reformulation depends on the design goal, and present a technique for automatically constructing rules that map the design goal into a reformulation chosen from a space of possible reformulations. We tested our technique in the domain of racing-yacht-hull design, where each reformulation corresponds to incorporating constraints into the search space. We applied a standard inductive-learning algorithm, C4.5, to a set of training data describing which constraints are active in the optimal design for each goal encountered in a previous design session. We then used these rules to choose an appropriate reformulation for each of a set of test cases. Our experimental results show that using these reformulations improves both the speed and the reliability of design optimization, outperforming competing methods and approaching the best performance possible. 
Abstract-found: 1
Intro-found: 1
Reference: [ Cerbone, 1992 ] <author> G. Cerbone. </author> <title> Machine learning in engineering: Techniques to speed up numerical optimization. </title> <type> Technical Report 92-30-09, </type> <institution> Oregon State University Department of Computer Science, </institution> <year> 1992. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: Cerbone <ref> [ Cerbone, 1992 ] </ref> has reported work which applied machine-learning techniques to a problem similar to our prototype-selection problem. His design space, in the domain of truss design, has an exponential number of disconnected search spaces.
Reference: [ Char et al., 1992 ] <author> B.W. Char, K.O. Geddes, G.H. Gonnet, B.L. Leong, M.B. Monagan, and S.M. Watt. </author> <title> First Leaves: A Tutorial Introduction to Maple V. </title> <publisher> Springer-Verlag and Waterloo Maple Publishing, </publisher> <year> 1992. </year>
Reference-contexts: Displacement is not a design parameter; rather, it is a quantity computed from all of the design parameters. In order to incorporate the displacement constraint, we used Maple <ref> [ Char et al., 1992 ] </ref> , a symbolic algebra package, to invert the displacement formula, and created a new set of operators that vary certain parameters while maintaining displacement at the minimum displacement allowed by the constraint.
Reference: [ Choy and Agogino, 1986 ] <author> J. Choy and A. Agogino. Symon: </author> <title> Automated symbolic monotonicity analysis system for qualitative design optimization. </title> <booktitle> In Proceedings ASME International Computers in Engineering Conference, </booktitle> <year> 1986. </year>
Reference-contexts: [ Orelup et al., 1988, Tong, 1988, Powell, 1990, Hoeltzel and Chieng, 1987 ] have developed alternative artificial-intelligence techniques for controlling iterative parameter-design optimization. [ Gelsey and Smith, 1995 ] describe a Search Space Toolkit which assists in determining properties of the search space that can be used for reformulation. <ref> [ Choy and Agogino, 1986 ] </ref> describe a system that automates [ Papalambros and Wilde, 1988 ] 's method of using monotonicity analysis to detect constraint activity.
Reference: [ Craig et al., 1994 ] <author> L. Craig, J. Zhou, and A. </author> <title> Tits. User's guide for cfsqp version 2.1: A c code for solving (large scale) constrained nonlinear (minimax) optimization problems, generating iterates satisfying all inequality constraints. </title> <type> Technical Report TR-94-16r1, </type> <institution> Institute for Systems Research, University of Maryland, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: A search space is thus specified by providing the parameters that define an initial prototype, and a set of operators for modifying that prototype. To find a yacht for a given design goal our system uses CFSQP, a state-of-the-art implementation of the Sequential Quadratic Programming method <ref> [ Craig et al., 1994 ] </ref> . Sequential Quadratic Programming is a quasi-Newton method that solves a nonlinear constrained optimization problem by fitting a sequence of quadratic programs 2 to it, and then solving each of these problems using a quadratic programming method.
Reference: [ Ellman et al., 1992 ] <author> T. Ellman, J. Keane, and M. Schwabacher. </author> <title> The rutgers cap project design associate. </title> <type> Technical Report CAP-TR-7, </type> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ, </address> <year> 1992. </year>
Reference: [ Gelsey and Smith, 1995 ] <author> A. Gelsey and D. Smith. </author> <title> A search space toolkit. </title> <booktitle> In Proceedings of the Eleventh Conference on Artificial Intelligence for Applications, </booktitle> <year> 1995. </year>
Reference-contexts: He uses inductive learning techniques to learn rules for selecting a subset of these search spaces for further exploration. Several investigators [ Orelup et al., 1988, Tong, 1988, Powell, 1990, Hoeltzel and Chieng, 1987 ] have developed alternative artificial-intelligence techniques for controlling iterative parameter-design optimization. <ref> [ Gelsey and Smith, 1995 ] </ref> describe a Search Space Toolkit which assists in determining properties of the search space that can be used for reformulation. [ Choy and Agogino, 1986 ] describe a system that automates [ Papalambros and Wilde, 1988 ] 's method of using monotonicity analysis to detect
Reference: [ Hoeltzel and Chieng, 1987 ] <author> D. Hoeltzel and W. Chieng. </author> <title> Statistical machine learning for the cognitive selection of nonlinear programming algorithms in engineering design optimization. </title> <booktitle> In Advances in Design Automation, </booktitle> <address> Boston, MA, </address> <year> 1987. </year>
Reference: [ IYRU, 1985 ] <institution> The Rating Rule and Measurement Instructions of the International Twelve Metre Class. International Yacht Racing Union, </institution> <year> 1985. </year>
Reference-contexts: There is also noise in the search space caused by the constraints of the 12-Meter Rule, which is discussed further in the next section. 4 The reformulations Yachts entered in the 1987 America's Cup race had to satisfy what is know as the 12-Meter Rule <ref> [ IYRU, 1985 ] </ref> . The basic formula in the rule is: length f reeboard + p sailarea 2:37 In addition to the basic formula, the rule contains several other constraints, along with associated penalties for violating these constraints.
Reference: [ Letcher et al., 1987 ] <author> J. Letcher, J. Marshall, J. Oliver, and N. Salvesen. </author> <title> Stars and stripes. </title> <journal> Scientific American, </journal> <volume> 257(2), </volume> <month> August </month> <year> 1987. </year>
Reference-contexts: represents a yacht geometry by a set of design parameters, and evaluates course time 1 This is the boat that won the 1987 America's Cup competition, returning the trophy to the United States after an Australian win in 1983 (which represented the only non-US win in more than 100 years <ref> [ Letcher et al., 1987 ] </ref> .) using a Velocity-Prediction Program called RUVPP, [ Schwabacher et al., 1994 ] a somewhat simplified version of AHVPP from AeroHydro, Inc., which is a marketed product used in yacht design [ Letcher, 1991 ] .
Reference: [ Letcher, 1991 ] <author> J. Letcher. </author> <title> The Aero/Hydro VPP Manual. </title> <institution> Aero/Hydro, Inc., Southwest Harbor, ME, </institution> <year> 1991. </year>
Reference-contexts: in 1983 (which represented the only non-US win in more than 100 years [ Letcher et al., 1987 ] .) using a Velocity-Prediction Program called RUVPP, [ Schwabacher et al., 1994 ] a somewhat simplified version of AHVPP from AeroHydro, Inc., which is a marketed product used in yacht design <ref> [ Letcher, 1991 ] </ref> . Yacht designs are modified by operators that manipulate design parameters. A search space is thus specified by providing the parameters that define an initial prototype, and a set of operators for modifying that prototype.
Reference: [ Murthy et al., 1993 ] <author> S. Murthy, S. Kasif, S. Salzberg, and R. Beigel. </author> <title> Oc1: Randomized induction of oblique decision trees. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <address> Washington, D.C., </address> <year> 1993. </year>
Reference-contexts: The border between these regions does not appear to be axis parallel, and appears to be nonlinear. This suggests that better performance might be achieved using an oblique decision tree learner, such as OC1 <ref> [ Murthy et al., 1993 ] </ref> , or by attempting to learn nonlinear region boundaries. As would be expected, even though our yacht-domain results with C4.5 were nearly optimal for 100 examples, results degrade when given less training data.
Reference: [ Orelup et al., 1988 ] <author> M. F. Orelup, J. R. Dixon, P. R. Cohen, and M. K. Simmons. Dominic ii: </author> <title> Meta-level control in iterative redesign. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 25-30, </pages> <address> St. Paul, MN, </address> <year> 1988. </year>
Reference: [ Papalambros and Wilde, 1988 ] <author> P. Papalambros and J. Wilde. </author> <title> Principles of Optimal Design. </title> <publisher> Cam-bridge University Press, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: In either case, if it is known that the constraint will be active at the optimal design point, and the constraint function f is invertible, then the constraint can be incorporated into the search space by using the inverse of f to eliminate one of the design parameters. <ref> [ Papalambros and Wilde, 1988 ] </ref> describe how monotonicity knowledge can be used to determine that certain constraints will be active at the optimum. <p> Chieng, 1987 ] have developed alternative artificial-intelligence techniques for controlling iterative parameter-design optimization. [ Gelsey and Smith, 1995 ] describe a Search Space Toolkit which assists in determining properties of the search space that can be used for reformulation. [ Choy and Agogino, 1986 ] describe a system that automates <ref> [ Papalambros and Wilde, 1988 ] </ref> 's method of using monotonicity analysis to detect constraint activity.
Reference: [ Powell, 1990 ] <author> D. Powell. Inter-gen: </author> <title> A hybrid approach to engineering design optimization. </title> <type> Technical report, </type> <institution> Rensselaer Polytechnic Institute Department of Computer Science, </institution> <month> December </month> <year> 1990. </year> <type> Ph.D. Thesis. </type>
Reference: [ Quinlan, 1993 ] <author> John Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: If learning is successful, these mappings extrapolate from the training data and can be used successfully in future design sessions to map a new goal into an appropriate reformulation. The specific inductive-learning system used in this work is C4.5 <ref> [ Quinlan, 1993 ] </ref> (release 6.0). The approach taken by C4.5 is to find a small decision tree that correctly classifies the training data, and to then remove lower portions of the tree that appear to fit noise in the data.
Reference: [ Schwabacher et al., 1994 ] <author> M. Schwabacher, H. Hirsh, and T. </author> <title> Ellman. Learning prototype-selection rules for case-based iterative design. </title> <booktitle> In Proceedings of the Tenth IEEE Conference on Artificial Intelligence for Applications, </booktitle> <address> San Antonio, Texas, </address> <year> 1994. </year>
Reference-contexts: time 1 This is the boat that won the 1987 America's Cup competition, returning the trophy to the United States after an Australian win in 1983 (which represented the only non-US win in more than 100 years [ Letcher et al., 1987 ] .) using a Velocity-Prediction Program called RUVPP, <ref> [ Schwabacher et al., 1994 ] </ref> a somewhat simplified version of AHVPP from AeroHydro, Inc., which is a marketed product used in yacht design [ Letcher, 1991 ] . Yacht designs are modified by operators that manipulate design parameters. <p> C4.5 outperformed MFC for every training-set size, but C4.5's error rate on smaller training sets was significantly larger than C4.5's error rate for larger training sets (with performance reaching an asymptote for training sets of about 60 cases or more). 6 Related work Previously, we published results <ref> [ Schwabacher et al., 1994 ] </ref> showing that machine learning can improve optimization performance by learning how to select an initial prototype from which to start the optimizer. Cerbone [ Cerbone, 1992 ] has reported work which applied machine-learning techniques to a problem similar to our prototype-selection problem.
Reference: [ Tong, 1988 ] <author> S. S. Tong. </author> <title> Coupling symbolic manipulation and numerical simulation for complex engineering designs. </title> <booktitle> In International Association of Mathematics and Computers in Simulation Conference on Expert Systems for Numerical Computing, </booktitle> <institution> Purdue University, </institution> <year> 1988. </year>
Reference: [ Weiss and Kulikowski, 1991 ] <author> Sholom M. Weiss and Casimir A. </author> <title> Kulikowski. Computer Systems That Learn. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: One of the constraints was violated at the optimum in 10 of these optimizations. Figure 3 gives an example of a decision tree output by C4.5. We used C4.5 to perform tenfold cross-validation <ref> [ Weiss and Kulikowski, 1991 ] </ref> , and obtained the error rates shown in Table 1.
References-found: 18

