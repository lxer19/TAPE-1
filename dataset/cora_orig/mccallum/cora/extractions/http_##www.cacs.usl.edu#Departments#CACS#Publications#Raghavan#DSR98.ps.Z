URL: http://www.cacs.usl.edu/Departments/CACS/Publications/Raghavan/DSR98.ps.Z
Refering-URL: http://www.cacs.usl.edu/~raghavan/raghavan-1.html
Root-URL: http://www.cacs.usl.edu/~raghavan/raghavan-1.html
Title: Structural Abstractions of Hypertext Documents for Web-based Retrieval  
Author: Jitender S. Deogun Hayri Sever Vijay V. Raghavan 
Address: Lincoln, NE 68588, USA  06532 Beytepe, Ankara, Turkey.  Lafayette, LA 70504, USA  
Affiliation: The Department of Computer Science Engineering University of Nebraska  Department of Computer Science Engineering Hacettepe University  The Center for Advanced Computer Studies University of Southwestern Louisiana  
Abstract: There have been conflicting views in the literature on the capability of tools and mechanisms for storing and accessing information over Internet. On one hand it has been claimed for a long time that World Wide Web offers a chaotic environment for Web agents to extract information because the description of a document by HTML is easily comprehensible by humans, but is not so by machines. On the other hand, it has been hypothesized that information is sufficiently structured to facilitate effective Web mining, especially for electronic catalogs. In this article we do not intend to take position on this matter, but rather investigate the performance of a search engine while indexing more logical elements of HTML documents and while increasing the scope of indexing process. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Bollmann and V. S. Cherniavsky. </author> <title> Measurement-theoretical investigation of the mz-metric. </title> <editor> In R. N. Oddy, S. E. Robertson, C. J. van Rusbergen, and R. W. Williams, editors, </editor> <booktitle> Information Retrieval Research, </booktitle> <pages> pages 256-267. </pages> <publisher> Butterworths, </publisher> <address> Boston, </address> <year> 1981. </year>
Reference-contexts: To identify the types of nodes, we use a subjective classifier based on words in URLs as well as patterns in Web pages. We measure the quality of retrieval output by MZ metric <ref> [1] </ref>.
Reference: [2] <author> R. B. Doorenbos, O. Etzioni, and D. S. Weld. </author> <title> A scalable comparison-shopping agent for the world-wide web. </title> <type> Technical Report UW-CSE-96-01-03, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <year> 1996. </year>
Reference-contexts: Information extraction involves in dynamically extracting specific information from newly discovered Web resources, such that the need for hand-coded "wrappers" to access the resource and parse its response can be eliminated or reduced. Generalization discovers regular patterns at (or inductively learns) individual Web sites and across multiple sites. ShopBot <ref> [2] </ref>, a Web mining agent specialized on electronic catalogs, uses descriptions of domains and vendors as prior knowledge to compare vendors by an attribute (say, price) for given a characterization of the desired product. <p> A case study on electronic commerce sites such as "Internet Shopping Network (http://www/internet.net)" and "NECX Direct (http://necxdirect.necx.com)" reveals that &lt;br&gt;<a>text</a>text and &lt;li&gt;<a>text</a>&lt;/li&gt;text&lt;br&gt; are common line descriptions in which product information is encoded <ref> [2] </ref>. Similarly, WebSeek, image and video search engine located at http://www.ctr.columbia.edu/webseek, also utilizes structural regularities to index the images and videos [5].
Reference: [3] <author> O. Etzioni. </author> <title> The world-wide web: </title> <journal> Quagmire or gold mine? Communications of the ACM, </journal> <volume> 39(11) </volume> <pages> 65-68, </pages> <month> Nov. </month> <year> 1996. </year>
Reference-contexts: 1. Introduction The exploration of structures is not a new approach. Etzioni in <ref> [3] </ref> argued the structured Web hypothesis: Information on the Web is sufficiently structured to facilitate effective Web mining. He suggested following three subtasks for Web mining, namely resource discovery, information extraction, and generalization. The resource discovery focuses on the automatic in dexing and (furthermore classifying) Web documents.
Reference: [4] <author> B. P. McCune, R. M. Tong, J. S. Dean, and D. G. Shapiro. RUBRIC: </author> <title> A system for rule-based information retrieval. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 11(9) </volume> <pages> 939-944, </pages> <year> 1985. </year>
Reference-contexts: A set of rules for a query topic constitutes a goal tree involving AND/OR arcs. Furthermore, to interpret weights it is satisfactory to use the functions minimum, maximum, and product to propagate the weights across AND or OR arcs and implication nodes, respectively <ref> [4] </ref>. Finally the evaluation of a goal tree yields the extension of the query topic; that is, a set of ranked documents is returned by the concept-level retrieval engine in response to the selected query topic. The concept-level module is implemented on top of the descriptor-level retrieval.
Reference: [5] <author> J. R. Smith and S.-F. Chang. </author> <title> Visually searching the web for content. </title> <booktitle> IEEE Multimedia, </booktitle> <pages> pages 12-20, </pages> <month> July </month> <year> 1997. </year>
Reference-contexts: Similarly, WebSeek, image and video search engine located at http://www.ctr.columbia.edu/webseek, also utilizes structural regularities to index the images and videos <ref> [5] </ref>. It uses key terms contained in &lt;img src=URL alt=[alt text]&gt; and &lt;a href=URL&gt;[hyperlink text]&lt;/a&gt; as well as terms in directory names to classify the subjects of hyper objects through a key-term dictionary. This dictionary provides a set of mappings from key terms to subject classes.
References-found: 5

