URL: http://www.cam.sri.com/people/milward/ddgc92.ps.gz
Refering-URL: http://www.cam.sri.com/people/milward/
Root-URL: 
Email: davidm@cogsci.ed.ac.uk  
Title: DYNAMICS, DEPENDENCY GRAMMAR AND INCREMENTAL INTERPRETATION  
Author: DAVID MILWARD 
Address: 2, Buccleuch Place, Edinburgh, EH8 9LW, Scotland  
Affiliation: Centre for Cognitive Science, University of Edinburgh  
Note: In Proceedings of the 14th International Conference on Computational Linguistics, Coling 92, Nantes, pages 1095-1099.  
Abstract: The paper describes two equivalent grammatical formalisms. The first is a lexicalised version of dependency grammar, and this can be used to provide tree-structured analyses of sentences (though somewhat flatter than those usually provided by phrase structure grammars). The second is a new formalism, `Dynamic Dependency Grammar', which uses axioms and deduction rules to provide analyses of sentences in terms of transitions between states. A reformulation of dependency grammar using state transitions is of interest on several grounds. Firstly, it can be used to show that incremental interpretation is possible without requiring notions of overlapping, or flexible constituency (as in some versions of categorial grammar), and without destroying a transparent link between syntax and semantics. Secondly, the reformulation provides a level of description which can act as an intermediate stage between the original grammar and a parsing algorithm. Thirdly, it is possible to extend the reformulated grammars with further axioms and deduction rules to provide coverage of syntactic constructions such as coordination which are difficult to encode lexically. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ades, A. and Steedman, M. </author> <title> (1972) On the Order of Words. </title> <booktitle> Linguistics and Philosophy 4, </booktitle> <pages> 517-558. </pages>
Reference: <author> Aho, A. and Ullman, J. </author> <title> (1972) The Theory of Parsing, Translation and Compiling, Volume 1:Parsing. </title> <publisher> Prentice-Hall Inc, </publisher> <address> New Jersey. </address>
Reference: <author> Barry, G. and Pickering, M. </author> <title> (1990) Dependency and Constituency in Categorial Grammar. </title> <editor> In Barry, G. and Morrill, G. (eds), </editor> <title> Studies in Categorial Grammar. </title> <institution> Centre for Cognitive Science, </institution> <note> University of Edinburgh. </note> <editor> van Benthem, J. </editor> <title> (1990) General Dynamics. </title> <note> ITLI report, Amsterdam (to appear in Theoretical Linguistics). </note>
Reference-contexts: Dependency grammars adopting these assumptions were formali-sed by Gaifman (Hays, 1964). Lexicalisation is relatively trivial given this formalisation, and the work on embedded dependency grammar within categorial grammar <ref> (Barry and Pickering, 1990) </ref>. Lexicalised Dependency Grammar (LDG) treats each head as a function. For example, the head thought is treated as a function with two arguments, a noun phrase and a sentence. Constituents are formed by combining functions with all their argu ments.
Reference: <author> Dowty, D.R., Wall, R.F. and Peters, S. </author> <title> (1981) Introduction to Montague Semantics. </title> <publisher> D.Reidel, Dord-recht. </publisher>
Reference-contexts: Adopting a `standard' - calculus semantics <ref> (c.f. Dowty et al, 1981) </ref> we obtain the following transitions for the string "Sue saw": 12 For this purpose, it is convenient to treat an analysis in a DDG as the transitions performed by each word.
Reference: <author> Hays, D.G. </author> <title> (1964) Dependency Theory: A Formalism and Some Observations. </title> <booktitle> Language 40, </booktitle> <pages> 511-525. </pages>
Reference-contexts: In this paper we will assume adjacency, and, for simplicity, that dependents are fixed in their order relative to the head and to each other. Dependency grammars adopting these assumptions were formali-sed by Gaifman <ref> (Hays, 1964) </ref>. Lexicalisation is relatively trivial given this formalisation, and the work on embedded dependency grammar within categorial grammar (Barry and Pickering, 1990). Lexicalised Dependency Grammar (LDG) treats each head as a function.
Reference: <author> Hudson, R. </author> <title> (1988) Coordination and Grammatical Relations. </title> <journal> Journal of Linguistics 24, </journal> <pages> 303-342. </pages>
Reference: <author> Milward, D. </author> <title> (1990) Coordination in an Axiomatic Grammar. In Coling-90, </title> <journal> Helsinki, </journal> <volume> vol 3, </volume> <pages> 207-212. </pages>
Reference-contexts: The final state is just of type sentence. DDG is specified using a logic consisting of a set of axioms and a deduction rule. The logic is similar, but more general, than that used in Axiomatic Grammar <ref> (Milward, 1990) </ref>. 6 The deduction rule is again called Sequencing. The rule is identical in form to the Sequencing Rule used in the reformulation of the FSM, though here it puts together strings of words rather than strings of letters.
Reference: <author> Milward, D. </author> <title> (1991) Axiomatic Grammar, Non-Constituent Coordination, and Incremental Interpretation. </title> <type> PhD thesis, </type> <institution> University of Cambridge. </institution>
Reference-contexts: For example, the following deduction rule (again restricted to non-empty strings), C 0 String a C 1 , C 0 String b C 1 C 0 String a *"and"*String b C 1 provides an account of the syntax of non-constituent coordination <ref> (Milward, 1991) </ref>.
Reference: <author> Milward, D. </author> <title> (1992) Dynamic Grammars. </title> <type> Technical Report, </type> <institution> Centre for Cognitive Science, University of Edinburgh. </institution> <note> In preparation. </note>
Reference-contexts: The rule is as follows, 7 C 0 String a C 1 , C 1 String b C 2 C 0 String a *String b C 2 and is restricted to non-empty strings. 8 ments has been developed, and this also can be reformulated as a dynamic grammar <ref> (Milward, 1992) </ref>. 6 Axiomatic Grammar is a particular dynamic grammar designed for English, which takes relationships between states as a primary phenomenon, to be justified solely by linguistic data (rather than by an existing formalism such as dependency grammar). 7 Here `*' concatenates strings of words e.g. "John"*"sleeps" = "John sleeps".
Reference: <author> Pulman, S. </author> <title> (1985) A Parser That Doesn't. </title> <booktitle> In 2nd European ACL, </booktitle> <address> Geneva. </address>
Reference: <author> Woods, W. </author> <title> (1973) An Experimental Parsing System for Transition Network Grammars. </title> <editor> In Rustin, R. (ed.), </editor> <booktitle> Natural Language Processing, </booktitle> <publisher> Algorithmics Press, </publisher> <address> New York. </address> <month> 5 </month>
Reference-contexts: It is worth noting at this early stage that dynamic grammars are not lexicalised rehashes of Augmented Transition Networks <ref> (Woods, 1973) </ref>. ATNs use a finite number of states combined with a recursion mechanism, and act essentially in the same way as a top down parser. They are not particularly suited to incremental interpretation.
References-found: 11

