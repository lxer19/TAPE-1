URL: http://simon.cs.cornell.edu/home/selman/papers-ftp/96.jacm.knowlcomp.ps
Refering-URL: http://simon.cs.cornell.edu/home/selman/papers-ftp/papers.html
Root-URL: 
Email: fselman, kautzg@research.att.com  
Title: Knowledge Compilation and Theory Approximation  
Author: Bart Selman and Henry Kautz 
Address: Murray Hill, NJ 07974  
Affiliation: AI Principles Research Department AT&T Bell Laboratories  
Abstract: Computational efficiency is a central concern in the design of knowledge representation systems. In order to obtain efficient systems, it has been suggested that one should limit the form of the statements in the knowledge base or use an incomplete inference mechanism. The former approach is often too restrictive for practical applications, whereas the latter leads to uncertainty about exactly what can and cannot be inferred from the knowledge base. We present a third alternative, in which knowledge given in a general representation language is translated (compiled) into a tractable form allowing for efficient subsequent query answering. We show how propositional logical theories can be compiled into Horn theories that approximate the original information. The approximations bound the original theory from below and above in terms of logical strength. The procedures are extended to other tractable languages (for example, binary clauses) and to the first-order case. Finally, we demonstrate the generality of our approach by compiling concept descriptions in a general frame-based language into a tractable form. 
Abstract-found: 1
Intro-found: 1
Reference: [ Agre and Chapman, 1987 ] <author> P.E. Agre and D. Chapman. Pengi: </author> <title> An implementation of a theory of activity. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <pages> pages 268-272, </pages> <address> Seattle, Wa, </address> <year> 1987. </year>
Reference-contexts: The motivation behind our knowledge compilation approach is similar to that behind the work on universal plans [ Schoppers, 1987 ] , a form of reactive planning <ref> [ Agre and Chapman, 1987 ] </ref> .
Reference: [ Amarel, 1968 ] <author> Saul Amarel. </author> <title> On representations of problems of reasoning about actions. </title> <editor> In Michie, editor, </editor> <booktitle> Machine Intelligence 3, </booktitle> <pages> pages 131-171. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1968. </year> <month> 39 </month>
Reference-contexts: We maintain the computational advantage because inference is still efficient using the Horn bound. In work in artificial intelligence on planning and theorem-proving with abstraction <ref> [ Amarel, 1968; Plaisted, 1981 ] </ref> , one maps a theory to a smaller, simpler theory, generates proofs in the smaller theory, and then uses the proofs to guide generation of proofs in the original theory.
Reference: [ Aspvall et al., 1979 ] <author> B. Aspvall, M. F. Plass, and R. E. Tarjan. </author> <title> A linear-time al-gorithm for testing the truth of certain quantified boolean formulae. </title> <journal> Information Processing Letters, </journal> <volume> 8(121), </volume> <year> 1979. </year>
Reference-contexts: Satisfiability and entail-ment can be determined in linear time for this class <ref> [ Aspvall et al., 1979 ] </ref> . (Note that unit clauses and the empty clause are included in this class.) * Unit clauses; that is, bounds that consist of conjunctions of literals.
Reference: [ Boddy and Dean, 1988 ] <author> Mark Boddy and Thomas Dean. </author> <title> Solving time dependent planning problems. </title> <type> Technical report, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1988. </year>
Reference-contexts: So, instead of waiting for the best Horn bounds, it would be desirable to employ procedures that could output lower- and upper-bounds as intermediate results, generating better and better bounds over time. That is, the approximation algorithms should be anytime procedures <ref> [ Boddy and Dean, 1988 ] </ref> . The algorithms presented in this paper have this property. We discuss a method for generating the GLB first.
Reference: [ Boppana and Sipser, 1990 ] <author> R. B. Boppana and M. Sipser. </author> <title> The complexity of finite functions. </title> <editor> In J. an Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Volume A: Algorithms and Compexity, </booktitle> <pages> pages 757-804. </pages> <publisher> Elsevier, Am-sterdam (and MIT Press, </publisher> <address> Cambridge), </address> <year> 1990. </year>
Reference: [ Borgida and Etherington, 1989 ] <author> Alex Borgida and David W. Etherington. </author> <title> Hierarchical knowledge bases and efficient disjunctive reasoning. </title> <booktitle> In Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 33-43, </pages> <address> Toronto, Ontario, 1989. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference: [ Buro and Buning, 1992 ] <author> M. Buro and H. Kleine Buning. </author> <title> Report on a sat competition. </title> <type> Technical Memorandum 110, </type> <institution> Mathematik/Informatik Universitat Pader-born, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: We see that knowledge compilation reduced the overall time by over two orders of magnitude on the largest theories. This 6 The Davis-Putnam procedure is currently the fastest known complete procedure for propositional satisfiability testing and theorem-proving on the class of formulas considered here <ref> [ Buro and Buning, 1992; Dubois et al., 1995 ] </ref> . Tableau [ Crawford and Auton, 1993 ] is one of the fastest implementations of the algorithm. 18 eliminates the remote possibility that the bounds are only answering the easy queries.
Reference: [ Bylander, 1991 ] <author> T. Bylander. </author> <title> Complexity results for planning. </title> <booktitle> In Proceedings of IJCAI-91, </booktitle> <pages> pages 274-279, </pages> <address> Sidney, Australia, </address> <year> 1991. </year>
Reference: [ Cadoli and Schaerf, 1992 ] <author> Marco Cadoli and Marco Schaerf. </author> <title> Approximation in concept description languages. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning (KR-92), </booktitle> <pages> pages 330-341, </pages> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference: [ Cadoli, 1993 ] <author> Marco Cadoli. </author> <title> Semantical and computational aspects of horn approximations. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 39-44, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference: [ Cook, 1971 ] <author> S. A. Cook. </author> <title> The complexity of theorem-proving procedures. </title> <booktitle> In Proceedings of the 3rd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 151-158, </pages> <year> 1971. </year> <month> 40 </month>
Reference-contexts: Models are represented by dots. Each of the bounds can be represented by a set of Horn clauses. In general, determining whether a given CNF formula (the query) follows from a set of formulas in a knowledge base is intractable <ref> [ Cook, 1971 ] </ref> . However, when the knowledge base contains only Horn clauses the problem can be solved in time linear in the length of the knowledge base combined with the query [ Dowling and Gallier, 1984 ] .
Reference: [ Crawford and Auton, 1993 ] <author> J. Crawford and L. Auton. </author> <title> Experimental results on the crossover point in satisfiability problems. </title> <booktitle> In Proceedings of AAAI-93, </booktitle> <pages> pages 21-27, </pages> <address> Washington, DC, </address> <year> 1993. </year>
Reference-contexts: This 6 The Davis-Putnam procedure is currently the fastest known complete procedure for propositional satisfiability testing and theorem-proving on the class of formulas considered here [ Buro and Buning, 1992; Dubois et al., 1995 ] . Tableau <ref> [ Crawford and Auton, 1993 ] </ref> is one of the fastest implementations of the algorithm. 18 eliminates the remote possibility that the bounds are only answering the easy queries.
Reference: [ Dalal and Etherington, 1992 ] <author> Mukesh Dalal and David W. Etherington. </author> <title> Tractable approximate deduction using limited vocabularies. </title> <booktitle> In Proceedings of the Ninth Canadian Conference on Artificial Intelligence (AI '92), </booktitle> <pages> pages 206-212, </pages> <address> Van-couver, British Columbia, </address> <year> 1992. </year>
Reference: [ Davis and Putnam, 1960 ] <author> M. Davis and H. Putnam. </author> <title> A computing procedure for quantification theory. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 7 </volume> <pages> 201-215, </pages> <year> 1960. </year>
Reference-contexts: Mitchell, Selman and Levesque [1992] show that most randomly-generated theories are easy to reason with. Such theories tend to be either very over-constrained or very under-constrained; in either case, experiments show that answering queries is easy using the standard Davis-Putnam procedure <ref> [ Davis and Putnam, 1960 ] </ref> . 5 However, Mitchell et al. also described how to randomly generate computationally challenging theories. The key is to generate formulas with a particular ratio of clauses to variables. For random 3CNF formulas, the ratio is about 4.3.
Reference: [ de Kleer, 1990 ] <author> Johan de Kleer. </author> <title> Exploiting locality in the tms. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <pages> pages 264-271, </pages> <address> Anaheim, CA, </address> <year> 1990. </year>
Reference: [ Dean, 1985 ] <author> Tom Dean. </author> <booktitle> Artificial Intelligence, Theory and Practice. </booktitle> <address> Ben-jamin/Cummings, Redwood City, CA, </address> <year> 1985. </year>
Reference-contexts: Applications of propositional inference arise in many areas of artificial intelligence and computer science in general. Examples include qualitative reasoning about physical systems [ Reiter and de Kleer, 1987 ] , circuit diagnosis [ Larrabee, 1992 ] , expert systems <ref> [ Dean, 1985 ] </ref> , and learning theory [ Valiant, 1983 ] . In addition, many reasoning tasks can be directly mapped into propositional inference problems, such as finite-domain constraint satisfaction problems (CSP) [ Dechter, 1992 ] and certain classes of planning problems [ Kautz and Selman, 1992b ] .
Reference: [ Dechter and Pearl, 1992 ] <author> Rina Dechter and Judea Pearl. </author> <title> Structure identification in relational data. </title> <journal> Artificial Intelligence, </journal> <volume> 58(1-3):237-270, </volume> <year> 1992. </year>
Reference-contexts: One way to do this would be to simply stop generating the bounds at some point; this is straightforward, given the anytime nature of our compilation algorithms. Another alternative would be to generate so-called k-Horn approximations, which are Horn theories with at most k literals per clause <ref> [ Dechter and Pearl, 1992 ] </ref> .
Reference: [ Dechter, 1992 ] <author> Rina Dechter. </author> <title> Constraint networks. </title> <booktitle> In Encyclopedia of Artificial Intelligence, </booktitle> <pages> pages 276-285. </pages> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: In addition, many reasoning tasks can be directly mapped into propositional inference problems, such as finite-domain constraint satisfaction problems (CSP) <ref> [ Dechter, 1992 ] </ref> and certain classes of planning problems [ Kautz and Selman, 1992b ] . Finally, note that first-order domain theories in artificial intelligence often involve only finite domains.
Reference: [ del Val, 1985 ] <author> A. del Val. </author> <title> An analysis of approximate knowledge compilation. </title> <booktitle> In Proceedings of IJCAI-95, </booktitle> <address> Montreal, Canada, </address> <year> 1985. </year>
Reference: [ Donini et al., 1991 ] <author> Francesco M. Donini, Maurizio Lenzerini, Daniele Nardi, and Werner Nutt. </author> <title> The complexity of concept languages. </title> <booktitle> In Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning (KR-91), </booktitle> <pages> pages 151-162, </pages> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: In particular, we are investigating decidable (and possibly tractable) approximations to theories in undecidable languages. 10 3.1.3 Description Logics In this section, we consider description logics, a family of frame-based knowledge representation languages as studied by Levesque and Brachman [1985]. (See also <ref> [ Donini et al., 1991 ] </ref> .) Levesque and Brachman consider a language F L in which one can describe structured concepts in terms of other concepts, either complex or primitive.
Reference: [ Dowling and Gallier, 1984 ] <author> William F. Dowling and Jean H. Gallier. </author> <title> Linear time algorithms for testing the satisfiability of propositional horn formula. </title> <journal> Journal of Logic Programming, </journal> <volume> 3 </volume> <pages> 267-284, </pages> <year> 1984. </year>
Reference-contexts: However, when the knowledge base contains only Horn clauses the problem can be solved in time linear in the length of the knowledge base combined with the query <ref> [ Dowling and Gallier, 1984 ] </ref> . So, a useful kind of knowledge compilation would be the following: Given a set of arbitrary clauses, compute a logically equivalent set of Horn clauses, and base subsequent inference on that set. Unfortunately, there does not always exist a logically equivalent Horn theory.
Reference: [ Doyle and Patil, 1991 ] <author> J. Doyle and R. Patil. </author> <title> Two theses of knowledge representation: Language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3) </volume> <pages> 261-298, </pages> <year> 1991. </year> <month> 41 </month>
Reference-contexts: In general, in order to obtain a computationally efficient representation system one either restricts the expressive power of the knowledge representation language or one uses an incomplete inference mechanism. In the first approach, the representation language is often too limited for practical applications <ref> [ Doyle and Patil, 1991 ] </ref> . The second approach involves either resource-bounded reasoning or the introduction of a non-traditional semantics. In resource-bounded reasoning, inference is limited by bounding the number of inference steps performed by the inference procedure.
Reference: [ Dubois et al., 1995 ] <author> O. Dubois, P. Andre, Y. Boufkhad, and J. Carlier. </author> <title> Sat versus unsat. </title> <editor> In David S. Johnson and Michael A. Trick, editors, </editor> <title> Cliques, Coloring, and Satisfiability: Second DIMACS Implementation Challenge, </title> <booktitle> DIMACS Series in Discrete Mathematics and Theoretical Computer Science. </booktitle> <publisher> AMS Press, </publisher> <address> Providence, RI, </address> <year> 1995. </year>
Reference-contexts: We see that knowledge compilation reduced the overall time by over two orders of magnitude on the largest theories. This 6 The Davis-Putnam procedure is currently the fastest known complete procedure for propositional satisfiability testing and theorem-proving on the class of formulas considered here <ref> [ Buro and Buning, 1992; Dubois et al., 1995 ] </ref> . Tableau [ Crawford and Auton, 1993 ] is one of the fastest implementations of the algorithm. 18 eliminates the remote possibility that the bounds are only answering the easy queries.
Reference: [ Ellman, 1993 ] <author> Thomas Ellman. </author> <title> Abstraction via approximate symmetry. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <volume> volume 2, </volume> <pages> pages 916-921, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: Various mechanisms have been suggested for creating the abstractions, such as eliminating operator preconditions [ Sacerdoti, 1974 ] , finding symmetries in the search space <ref> [ Ellman, 1993 ] </ref> , and employing explanation-based learning on previously-generated plans [ Knoblock et al., 1991a ] . These abstractions are similar to our notion of an upper-bound. (Some of the approaches differ in that they can introduce abstract solution that do not correspond to any concrete solution.
Reference: [ Erol et al., 1992 ] <author> K. Erol, </author> <title> D.S. Nau, and V.S. Subrahmanian. On the complexity of domain-independent planning. </title> <booktitle> In Proceedings AAAI-92, </booktitle> <pages> pages 381-386, </pages> <address> San Jose, CA, </address> <year> 1992. </year>
Reference: [ Etherington et al., 1989 ] <author> David W. Etherington, Alex Borgida, Ronald J. Brach-man, and Henry Kautz. </author> <title> Vivid knowledge and tractable reasoning: Preliminary report. </title> <booktitle> In Proceedings of IJCAI-89, </booktitle> <pages> pages 1146-1152, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: In particular, one may avoid some of the accidental truths that often hold in a single model or diagram. Horn lower-bounds are also a generalization of Levesque's notion of vivid representations <ref> [ Levesque, 1986; Etherington et al., 1989 ] </ref> . To allow for fast inference, a vivid representation contains only complete information (no reasoning by cases). Levesque proposes to replace a knowledge base containing incomplete information by a complete, vivid representation of the information.
Reference: [ Frisch, 1985 ] <author> Alan M. Frisch. </author> <title> Using model theory to specify AI programs. </title> <booktitle> In Proceedings of IJCAI-85, </booktitle> <pages> pages 148-154, </pages> <address> Los Angeles, CA, </address> <year> 1985. </year>
Reference-contexts: Moreover, no information is provided if a proof cannot be found within the time bound. (But see [ Horvitz et al., 1989 ] for an example of probabilistic inference, where confidence in the results increases with the amount of computation.) Accounts of limited inference based on non-traditional semantics <ref> [ Levesque, 1984; Frisch, 1985; Patel-Schneider, 1986 ] </ref> often provide only a very weak kind of inference. For example, in the four-valued semantics approach of Levesque, given the statements p and p q, one cannot infer q.
Reference: [ Garey and Johnson, 1979 ] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: a Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference: [ Gelernter, 1959 ] <author> H. Gelernter. </author> <title> Realization of a geometry theorem-proving machine. </title> <booktitle> In Proceedings of the International Conference on Information Processing, </booktitle> <pages> pages 273-282, </pages> <address> Paris, </address> <year> 1959. </year> <note> UNESCO House. (Reprinted in Computers and Thought, </note> <editor> E. Feigenbaum and J. Feldman (Eds.), </editor> <publisher> McGraw-Hill, NY, </publisher> <pages> pages 134-152, </pages> <year> 1963.). </year>
Reference: [ Greiner and Schuurmans, 1992 ] <author> Russ Greiner and Dale Schuurmans. </author> <title> Learning useful horn approximations. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning (KR-92), </booktitle> <pages> pages 383-392, </pages> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference: [ Greiner, 1992 ] <author> Russell Greiner. </author> <title> Learning near-optimal horn approximations. </title> <booktitle> In Preprints of the AAAI Spring Symposium on Knowledge Assimilation. </booktitle> <institution> Stanford University, Stanford, </institution> <address> CA, </address> <month> March </month> <year> 1992. </year> <month> 42 </month>
Reference: [ Gupta and Nau, 1991 ] <author> Naresh Gupta and Dana S. Nau. </author> <title> Complexity results for blocks-world planning. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <pages> pages 629-635, </pages> <address> Anaheim, CA, </address> <year> 1991. </year>
Reference: [ Heintze and Jaffar, 1990 ] <author> Nevin Heintze and Joxan Jaffar. </author> <title> A finite presentation theorem for approximating logic programs. </title> <booktitle> In Proceedings of POPL-90, </booktitle> <pages> pages 197-201, </pages> <year> 1990. </year>
Reference-contexts: Levesque and Brachman consider the complexity of determining whether one 10 Interesting connections may be drawn with some recent research on the analysis of Prolog programs (for use in, for example, optimization and program specification). For example, <ref> [ Heintze and Jaffar, 1990 ] </ref> describes how to construct a recursive (i.e., decidable) approximation to a potentially non-recursive logic program. Their method computes a lower-bound of the logic program viewed as a logical theory (but not in general the greatest lower-bound). 30 concept subsumes another.
Reference: [ Henschen and Wos, 1974 ] <author> L. Henschen and L. Wos. </author> <title> Unit refutations and horn sets. </title> <journal> Journal of the ACM, </journal> <volume> 21(4) </volume> <pages> 590-605, </pages> <year> 1974. </year>
Reference-contexts: This class is of particular interest because (linear-time) unit propagation (BCP) is complete for it <ref> [ Henschen and Wos, 1974; Lewis, 1978 ] </ref> . In additional to the clausal target languages we have concentrated on in this paper, one could consider tractable non-clausal target languages.
Reference: [ Horvitz et al., 1989 ] <author> Eric J. Horvitz, Gregory F. Cooper, and David E. Hecker-man. </author> <title> Reflection and action under scarce resources: Theoretical principles and empirical study. </title> <booktitle> In Proceedings of IJCAI-89, </booktitle> <pages> pages 1121-1126, </pages> <address> Detroit, MI, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: It therefore becomes difficult to characterize exactly what can and cannot be inferred, that is, the approach lacks a real semantics (one that does not simply mimic the proof theory). Moreover, no information is provided if a proof cannot be found within the time bound. (But see <ref> [ Horvitz et al., 1989 ] </ref> for an example of probabilistic inference, where confidence in the results increases with the amount of computation.) Accounts of limited inference based on non-traditional semantics [ Levesque, 1984; Frisch, 1985; Patel-Schneider, 1986 ] often provide only a very weak kind of inference.
Reference: [ Imielinski, 1987 ] <author> Thomsz Imielinski. </author> <title> Domain abstraction and limited reasoning. </title> <booktitle> In Proceedings of IJCAI-87, </booktitle> <volume> volume 2, </volume> <pages> pages 997-1002, </pages> <year> 1987. </year>
Reference: [ Johnson, 1990 ] <author> D. S. Johnson. </author> <title> A catalog of complexity classes. </title> <editor> In J. Van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume A, chapter 2. </booktitle> <publisher> Elsevier Science Publishers B. V., North Holland, </publisher> <year> 1990. </year>
Reference: [ Johnson, 1993 ] <author> D. S. Johnson, </author> <year> 1993. </year> <type> personal communication. </type>
Reference-contexts: For example, by reasoning by cases, one can prove that a computer scientist who reads Dennett and Kosslyn is also cognitive scientist. In general, for such non-Horn form theories, is only slightly harder than answering a single query, since the best known algorithms for both problems are singly-exponential <ref> [ Johnson, 1993 ] </ref> .
Reference: [ Karp and Lipton, 1982 ] <author> R. M. Karp and R. Lipton. </author> <title> Turing machines that take advice. </title> <journal> Enseign. Math., </journal> <volume> 28 </volume> <pages> 191-209, </pages> <year> 1982. </year>
Reference-contexts: For any n the circuit is simply fixed to return 1 or 0.) Although it is possible that P 6= NP and yet NP non-uniform P, this is considered unlikely. One consequence would be that the polynomial-time hierarchy would collapse to S 2 <ref> [ Karp and Lipton, 1982 ] </ref> . As shown in the appendix, the theorem can be strengthened to say that the claim that there always exists an efficient form of the LUB for answering Horn clausal queries is equivalent to the claim that NP non-uniform P.
Reference: [ Kautz and Selman, 1991 ] <author> Henry Kautz and Bart Selman. </author> <title> A general framework for knowledge compilation. </title> <booktitle> In Proceedings of the International Workshop on Processing Declarative Knowledge (PDK), </booktitle> <address> Kaiserslautern, Germany, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: The paper concludes with a discussion of extensions to first-order theories and various generalizations of Horn approximations, as well as to description logics. A preliminary discussion of these ideas appeared in [ Selman and Kautz, 1991 ] and <ref> [ Kautz and Selman, 1991 ] </ref> . 2 Propositional Horn Approximations In this section, we introduce the idea of knowledge compilation using a concrete example.
Reference: [ Kautz and Selman, 1992a ] <author> Henry Kautz and Bart Selman. </author> <title> Forming concepts for fast inference. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <pages> pages 786-793, </pages> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: Thus, by teaching the system new concept definitions, the size of the new source theory grows only slightly, and the LUB shrinks to approximately the size of the source theory itself. In <ref> [ Kautz and Selman, 1992a ] </ref> we discuss a strategy for automatically deriving (learning) new concept letters that shrink the original bound. We call this theory compaction.
Reference: [ Kautz and Selman, 1992b ] <author> Henry Kautz and Bart Selman. </author> <note> Planning as satisfia-bility. </note> <editor> In Bernd Neumann, editor, </editor> <booktitle> Proceedings of the 10th European Conference on Artificial Intelligence (ECAI-92), </booktitle> <pages> pages 359-364, </pages> <address> Vienna, Austria, </address> <year> 1992. </year> <month> 43 </month>
Reference-contexts: In addition, many reasoning tasks can be directly mapped into propositional inference problems, such as finite-domain constraint satisfaction problems (CSP) [ Dechter, 1992 ] and certain classes of planning problems <ref> [ Kautz and Selman, 1992b ] </ref> . Finally, note that first-order domain theories in artificial intelligence often involve only finite domains. Such theories are therefore essentially propositional. 2 For example, Reiter and Mackworth [1989] discuss how their first-order domain theory for visual interpretation can be restated in propositional form.
Reference: [ Kautz and Selman, forthcoming ] <author> Henry Kautz and Bart Selman. </author> <title> Efficient ap-proximations of quantified formulas. (In Preparation), </title> <publisher> forthcoming. </publisher>
Reference-contexts: Here will we only give a brief description of how to extend knowledge compilation techniques to languages with quantification; more details will appear in a future paper <ref> [ Kautz and Selman, forthcoming ] </ref> . In the propositional case, GLBs and LUBs for any pair of a source and target language always exist, since only a finite number of logically distinct theories can be constructed. In the general first-order case, however, such best approximations may not be well-defined.
Reference: [ Kautz et al., 1994 ] <author> Henry A. Kautz, Michael J. Kearns, and Bart Selman. </author> <title> Horn approximations of empirical data. </title> <journal> Artificial Intelligence, </journal> <volume> 74 </volume> <pages> 129-145, </pages> <year> 1994. </year>
Reference-contexts: They consider the case where the original theory S is given directly by its set of models (satisfying truth assignments). They introduce a weaker notion of Horn approximations, called k-Horn approximations, in which each Horn clause contains at most k literals. See <ref> [ Kautz et al., 1994 ] </ref> , for a discussion of this work. Finally, Greiner and Schuurmans [1992; Greiner 1992] have adapted our compilation algorithms to ones that search for bounds that are optimal with respect 34 to a given query distribution.
Reference: [ Knoblock et al., 1991a ] <author> Craig A. Knoblock, Steven Minton, and Oren Etzioni. </author> <title> Integrating abstraction and explanation-based learning in prodigy. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <pages> pages 541-546, </pages> <address> Anaheim, CA, </address> <year> 1991. </year>
Reference-contexts: Various mechanisms have been suggested for creating the abstractions, such as eliminating operator preconditions [ Sacerdoti, 1974 ] , finding symmetries in the search space [ Ellman, 1993 ] , and employing explanation-based learning on previously-generated plans <ref> [ Knoblock et al., 1991a ] </ref> . These abstractions are similar to our notion of an upper-bound. (Some of the approaches differ in that they can introduce abstract solution that do not correspond to any concrete solution.
Reference: [ Knoblock et al., 1991b ] <author> Craig A. Knoblock, Josh D. Tenenberg, and Qiang Yang. </author> <title> Characterizing abstraction hierarchies for planning. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <pages> pages 692-697, </pages> <address> Anaheim, CA, </address> <year> 1991. </year>
Reference: [ Larrabee, 1992 ] <author> T. Larrabee. </author> <title> Test pattern generation using boolean satisfiability. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <month> January </month> <year> 1992. </year>
Reference-contexts: We illustrate our method by studying the approximation of propositional logic theories by Horn theories. Applications of propositional inference arise in many areas of artificial intelligence and computer science in general. Examples include qualitative reasoning about physical systems [ Reiter and de Kleer, 1987 ] , circuit diagnosis <ref> [ Larrabee, 1992 ] </ref> , expert systems [ Dean, 1985 ] , and learning theory [ Valiant, 1983 ] .
Reference: [ Lee, 1967 ] <author> R. C. T. Lee. </author> <title> A Completeness Theorem and a Computer Program for Finding Theorems Derivable From Given Axioms. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <year> 1967. </year>
Reference-contexts: More generally, if a Horn theory entails a set of clauses, then it entails a Horn-strengthening of the set. Proof: By the subsumption theorem <ref> [ Lee, 1967 ] </ref> , there is a clause C 0 that follows from S H by resolution such that C 0 subsumes C. Because the resolvent of Horn clauses is Horn, C 0 is Horn.
Reference: [ Levesque and Brachman, 1985 ] <author> H.J. Levesque and R.J. Brachman. </author> <title> A fundamental tradeoff in knowledge representation and reasoning (revised version). </title> <editor> In R.J. Brachman and H.J. Levesque, editors, </editor> <booktitle> Readings in Knowledge Representation, </booktitle> <pages> pages 41-70. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1985. </year>
Reference: [ Levesque, 1984 ] <author> Hector J. Levesque. </author> <title> A logic of implicit and explicit belief. </title> <booktitle> In Proceedings of AAAI-84, </booktitle> <pages> pages 198-202, </pages> <address> Austin, TX, </address> <year> 1984. </year>
Reference-contexts: Moreover, no information is provided if a proof cannot be found within the time bound. (But see [ Horvitz et al., 1989 ] for an example of probabilistic inference, where confidence in the results increases with the amount of computation.) Accounts of limited inference based on non-traditional semantics <ref> [ Levesque, 1984; Frisch, 1985; Patel-Schneider, 1986 ] </ref> often provide only a very weak kind of inference. For example, in the four-valued semantics approach of Levesque, given the statements p and p q, one cannot infer q. <p> Cadoli and Schaerf [1992] generalize Levesque's work on implicit and explicit belief <ref> [ Levesque, 1984 ] </ref> . They approximate the inference process by allowing a sequence of more and more powerful inference relations. The more time the system has to evaluate a query, the more powerful an inference relation it can use.
Reference: [ Levesque, 1986 ] <author> Hector Levesque. </author> <title> Making believers out of computers. </title> <journal> Artificial Intelligence, </journal> <volume> 30(1) </volume> <pages> 81-108, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: In particular, one may avoid some of the accidental truths that often hold in a single model or diagram. Horn lower-bounds are also a generalization of Levesque's notion of vivid representations <ref> [ Levesque, 1986; Etherington et al., 1989 ] </ref> . To allow for fast inference, a vivid representation contains only complete information (no reasoning by cases). Levesque proposes to replace a knowledge base containing incomplete information by a complete, vivid representation of the information.
Reference: [ Lewis, 1978 ] <author> H.R. Lewis. </author> <title> Renaming a set of clauses as a horn set. </title> <journal> JACM, </journal> <volume> 25(1) </volume> <pages> 134-135, </pages> <year> 1978. </year>
Reference-contexts: This class is of particular interest because (linear-time) unit propagation (BCP) is complete for it <ref> [ Henschen and Wos, 1974; Lewis, 1978 ] </ref> . In additional to the clausal target languages we have concentrated on in this paper, one could consider tractable non-clausal target languages.
Reference: [ McAllester and Givan, 1992 ] <author> David A. McAllester and Robert Givan. </author> <title> Natural language syntax and first-order inference. </title> <journal> Artificial Intelligence, </journal> <volume> 56 </volume> <pages> 1-20, </pages> <year> 1992. </year>
Reference: [ Mitchell et al., 1992 ] <author> D. Mitchell, B. Selman, and H.J. Levesque. </author> <title> Hard and easy distribution of sat problems. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <address> San Jose, CA, </address> <year> 1992. </year> <month> 44 </month>
Reference-contexts: Note that the queries handled by the bounds can be answered in linear time. However, the Davis-Putnam procedure scales exponentially on the queries considered in the table (this follows from the experiments in <ref> [ Mitchell et al., 1992 ] </ref> ). Thus, this suggests that knowledge compilation on such randomly-generated theories should have a clear payoff.
Reference: [ Muggleton and Buntine, 1988 ] <author> Stephen Muggleton and Wray Buntine. </author> <title> Machine invention of first-order predicates by inverting resolution. </title> <editor> In J. Laird, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 339-344, </pages> <year> 1988. </year>
Reference-contexts: We call this theory compaction. The flavor of our approach is very similar to that of the use of additional letters in extended resolution [ Tseitin, 1968 ] . See <ref> [ Muggleton and Buntine, 1988 ] </ref> for a related approach to learning new generalizations, based on inverting resolution proofs. 2.5.3 Does a Compact Representation of the LUB Always Exist? So far, we have shown that a naive representation of a theory's LUB can sometimes require an exponential amount of space, and
Reference: [ Patel-Schneider, 1986 ] <author> Peter F. Patel-Schneider. </author> <title> A four-valued semantics for frame-based description languages. </title> <booktitle> In Proceedings of AAAI-86, </booktitle> <pages> pages 344-348, </pages> <address> Philadelphia, PA, </address> <year> 1986. </year>
Reference-contexts: Moreover, no information is provided if a proof cannot be found within the time bound. (But see [ Horvitz et al., 1989 ] for an example of probabilistic inference, where confidence in the results increases with the amount of computation.) Accounts of limited inference based on non-traditional semantics <ref> [ Levesque, 1984; Frisch, 1985; Patel-Schneider, 1986 ] </ref> often provide only a very weak kind of inference. For example, in the four-valued semantics approach of Levesque, given the statements p and p q, one cannot infer q.
Reference: [ Plaisted, 1981 ] <author> D. Plaisted. </author> <title> Theorem proving with abstraction. </title> <journal> Artificial Intelligence, </journal> <volume> 16 </volume> <pages> 47-65, </pages> <year> 1981. </year>
Reference-contexts: We maintain the computational advantage because inference is still efficient using the Horn bound. In work in artificial intelligence on planning and theorem-proving with abstraction <ref> [ Amarel, 1968; Plaisted, 1981 ] </ref> , one maps a theory to a smaller, simpler theory, generates proofs in the smaller theory, and then uses the proofs to guide generation of proofs in the original theory.
Reference: [ Reiter and de Kleer, 1987 ] <author> Raymond Reiter and Johan de Kleer. </author> <title> Foundations of assumption based truth maintance systems: Preliminary report. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <pages> pages 183-187, </pages> <address> Seattle, WA, </address> <year> 1987. </year>
Reference-contexts: We refer to this approach as knowledge compilation. We illustrate our method by studying the approximation of propositional logic theories by Horn theories. Applications of propositional inference arise in many areas of artificial intelligence and computer science in general. Examples include qualitative reasoning about physical systems <ref> [ Reiter and de Kleer, 1987 ] </ref> , circuit diagnosis [ Larrabee, 1992 ] , expert systems [ Dean, 1985 ] , and learning theory [ Valiant, 1983 ] . <p> Then we computed the unit LUB and a unit 4 De Kleer also discusses the possibility of replacing the entire theory by its set of prime implicates. Though this may be useful for abductive reasoning <ref> [ Reiter and de Kleer, 1987; Selman and Levesque, 1990 ] </ref> , it is not necessary for deductive reasoning because Horn clauses themselves already allow for efficient inference.
Reference: [ Reiter and Mackworth, 1989 ] <author> R. Reiter and A. Mackworth. </author> <title> A logical framework for depiction and image interpretation. </title> <journal> Artificial Intelligence, </journal> <volume> 41(2) </volume> <pages> 125-155, </pages> <year> 1989. </year>
Reference: [ Sacerdoti, 1974 ] <author> Earl D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2) </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: Various mechanisms have been suggested for creating the abstractions, such as eliminating operator preconditions <ref> [ Sacerdoti, 1974 ] </ref> , finding symmetries in the search space [ Ellman, 1993 ] , and employing explanation-based learning on previously-generated plans [ Knoblock et al., 1991a ] .
Reference: [ Schoppers, 1987 ] <author> M. J. Schoppers. </author> <title> Universal plans for reactive robots in unpredictable environments. </title> <booktitle> In Proceedings of AAAI-87, </booktitle> <volume> volume 2, </volume> <pages> pages 1039-1046, </pages> <year> 1987. </year>
Reference-contexts: By contrast, the aim in the knowledge compilation framework is to pre-process (compile) a theory in such a manner that queries (problem instances) can be solved in polynomial time. The motivation behind our knowledge compilation approach is similar to that behind the work on universal plans <ref> [ Schoppers, 1987 ] </ref> , a form of reactive planning [ Agre and Chapman, 1987 ] .
Reference: [ Selman and Kautz, 1991 ] <author> Bart Selman and Henry Kautz. </author> <title> Knowledge compilation using horn approximations. </title> <booktitle> In Proceedings of AAAI-91, </booktitle> <pages> pages 904-909, </pages> <address> Anaheim, CA, </address> <year> 1991. </year>
Reference-contexts: The paper concludes with a discussion of extensions to first-order theories and various generalizations of Horn approximations, as well as to description logics. A preliminary discussion of these ideas appeared in <ref> [ Selman and Kautz, 1991 ] </ref> and [ Kautz and Selman, 1991 ] . 2 Propositional Horn Approximations In this section, we introduce the idea of knowledge compilation using a concrete example. <p> From the Generate GLB algorithm it follows immediately that the size of the generated bound is less than or equal to that of the original theory. 7 The system 7 Recently, Cadoli [1993], building on our original paper on knowledge compilation <ref> [Selman and Kautz, 1991] </ref>, has shown that computing the GLB is in the complexity class P NP . (Problems in P NP can be solved in polynomial time by a deterministic Turing machine with access to an NP oracle.
Reference: [ Selman and Levesque, 1990 ] <author> Bart Selman and Hector J. Levesque. </author> <title> Abductive and default reasoning: a computational core. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <pages> pages 343-348, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: Then we computed the unit LUB and a unit 4 De Kleer also discusses the possibility of replacing the entire theory by its set of prime implicates. Though this may be useful for abductive reasoning <ref> [ Reiter and de Kleer, 1987; Selman and Levesque, 1990 ] </ref> , it is not necessary for deductive reasoning because Horn clauses themselves already allow for efficient inference.
Reference: [ Selman et al., 1992 ] <author> B. Selman, Levesque H.J., and D. Mitchell. </author> <title> A new method for solving hard satisfiability problems. </title> <booktitle> In Proceedings of AAAI-92, </booktitle> <pages> pages 440-446, </pages> <address> San Jose, CA, </address> <year> 1992. </year> <month> 45 </month>
Reference-contexts: Generate GLB was similar adapted for unit bounds; in particular, the first strengthening of the theory was taken to be a satisfying model of the theory found using a fast randomized satisfiability procedure <ref> [ Selman et al., 1992 ] </ref> . Computation time for the unit LUBs ranged from 5 minutes for the 75 variable theories, to one hour for the 200 variable theories, on a 100Mhz SGI Challenge. Computation of the unit GLBs ranged from 1 minute to 5 minutes each.
Reference: [ Selman, 1990 ] <author> Bart Selman. </author> <title> Tractable default reasoning. </title> <type> Ph.D. Thesis, </type> <institution> Depart--ment of Computer Science, University of Toronto, Toronto, </institution> <address> Ontario, </address> <year> 1990. </year>
Reference: [ Subramanian and Genesereth, 1987 ] <author> Devika Subramanian and Michael R. Gene-sereth. </author> <title> The relevance of irrelevance. </title> <booktitle> In Proceedings of IJCAI-87, </booktitle> <volume> volume 1, </volume> <pages> pages 416-422, </pages> <address> Milan, Italy, </address> <year> 1987. </year>
Reference: [ Tseitin, 1968 ] <author> G. S. Tseitin. </author> <title> On the complexity of derivation in propositional calculus. </title> <editor> In A. O. Slisenko, editor, </editor> <booktitle> Studies in Constructive Mathematics and Mathematical Logic, Part II. </booktitle> <year> 1968. </year>
Reference-contexts: In [ Kautz and Selman, 1992a ] we discuss a strategy for automatically deriving (learning) new concept letters that shrink the original bound. We call this theory compaction. The flavor of our approach is very similar to that of the use of additional letters in extended resolution <ref> [ Tseitin, 1968 ] </ref> .
Reference: [ Valiant and V.V., 1986 ] <author> R.G. Valiant and Vazirani V.V. </author> <title> Np is as easy as detecting unique solutions. </title> <journal> Theoretical Computer Science, </journal> <volume> 47 </volume> <pages> 85-93, </pages> <year> 1986. </year>
Reference: [ Valiant, 1983 ] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1983. </year> <month> 46 </month>
Reference-contexts: Applications of propositional inference arise in many areas of artificial intelligence and computer science in general. Examples include qualitative reasoning about physical systems [ Reiter and de Kleer, 1987 ] , circuit diagnosis [ Larrabee, 1992 ] , expert systems [ Dean, 1985 ] , and learning theory <ref> [ Valiant, 1983 ] </ref> . In addition, many reasoning tasks can be directly mapped into propositional inference problems, such as finite-domain constraint satisfaction problems (CSP) [ Dechter, 1992 ] and certain classes of planning problems [ Kautz and Selman, 1992b ] .
References-found: 69

