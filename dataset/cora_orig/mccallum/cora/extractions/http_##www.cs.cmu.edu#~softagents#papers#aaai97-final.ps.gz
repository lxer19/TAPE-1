URL: http://www.cs.cmu.edu/~softagents/papers/aaai97-final.ps.gz
Refering-URL: http://www.cs.cmu.edu/~softagents/publications_old.html
Root-URL: 
Email: Dajun.Zeng@cs.cmu.edu katia@cs.cmu.edu  
Phone: Voice: (412) 268-8815 Fax: (412) 268-5569  
Title: Benefits of Learning in Negotiation  
Author: Dajun Zeng Katia Sycara 
Address: Pittsburgh, PA 15213  
Affiliation: The Robotics Institute Carnegie Mellon University,  
Abstract: Negotiation has been extensively discussed in game-theoretic, economic, and management science literatures for decades. Recent growing interest in electronic commerce has given increased importance to automated negotiation. Evidence both from theoretical analysis and from observations of human interactions suggests that if decision makers can somehow take into consideration what other agents are thinking and furthermore learn during their interactions how other agents behave, their payoff might increase. In this paper, we propose a sequential decision making model of negotiation, called Bazaar. Within the proposed negotiation framework, we model learning as a Bayesian belief update process. In this paper, we explore the hypothesis that learning is beneficial in sequential negotiation and present initial experimental results. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bertsekas, D. P. </author> <year> 1995. </year> <title> Dynamic Programming and Optimal Control. </title> <address> Belmont, MA: </address> <publisher> Athena Scientific. </publisher>
Reference: <author> Cyert, R. M., and DeGroot, M. H. </author> <year> 1987. </year> <title> Bayesian Analysis and Uncertainty in Economic Theory. </title> <publisher> Row-man & Littlefield. </publisher>
Reference: <author> Harsanyi, J. C., and Selten, R. </author> <year> 1972. </year> <title> A generalized nash solution for two-person bargaining games with incomplete information. </title> <booktitle> Management Science 18 </booktitle> <pages> 80-106. </pages>
Reference: <author> Jordan, J. S. </author> <year> 1992. </year> <title> The exponential covergence of bayesian learning in normal form games. </title> <booktitle> Games and Economic Behavior 4 </booktitle> <pages> 202-217. </pages>
Reference-contexts: Learning in Negotiation The importance of learning in negotiation has been recently recognized in the game research community as fundamental for understanding human behavior as well as for developing new solution concepts (Osborne & Rubinstein 1994; Harsanyi & Selten 1972). In <ref> (Jordan 1992) </ref> the author studied the impact of Bayesian learning processes for finite-strategy normal form games. Kalai and Lehrer (Kalai & Lehrer 1993) analyzed infinitely repeated games in which players as subjective utility maximizers learn to predict opponents' future strategies.
Reference: <author> Kalai, E., and Lehrer, E. </author> <year> 1993. </year> <title> Rational learning leads to nash equilibrium. </title> <type> Econometrica 61(5) </type> <pages> 1019-1045. </pages>
Reference-contexts: In (Jordan 1992) the author studied the impact of Bayesian learning processes for finite-strategy normal form games. Kalai and Lehrer <ref> (Kalai & Lehrer 1993) </ref> analyzed infinitely repeated games in which players as subjective utility maximizers learn to predict opponents' future strategies.
Reference: <author> Kraus, S., and Subrahmanian, V. S. </author> <year> 1995. </year> <title> Multiagent reasoning with probability, time, and beliefs. </title> <journal> International Journal of Intelligent Systems 10(5) </journal> <pages> 459-499. </pages>
Reference: <author> Luce, R. D., and Raiffa, H. </author> <year> 1957. </year> <title> Games and Decisions: Introduction and Critical Survey. </title> <address> New York, </address> <publisher> Wiley. </publisher>
Reference-contexts: In this way, we ensured that the zone of agreement always exists. Note that learning takes place within each run of the experiment rather than between runs. We measured the quality of a particular bargaining process using the normalized joint utility fashioned after the Nash solution <ref> (Luce & Raiffa 1957) </ref>.
Reference: <author> Mor, Y.; Goldman, C. V.; and Rosenschein, J. S. </author> <year> 1995. </year> <title> Learn your opponent's strategy (in polynomial time). </title> <booktitle> In Proceedings of IJCAI-95 Workshop on Adaptation and Learning in Multiagent Systems. </booktitle>
Reference-contexts: These theoretical results, however, are available only for the simplest game settings and valid only under very restrictive assumptions such as only a subset of possible negotiation strategies are allowed. Multi-agent learning has also increasingly drawn research efforts from Distributed AI community. Mor et. al. <ref> (Mor, Goldman, & Rosenschein 1995) </ref> discussed multi-agent learning as a means to reach equilibrium. They modeled agents as finite automata and analyzed the computational complexity of certain classes of learning strategies based on this automaton model.
Reference: <author> Osborne, M. J., and Rubinstein, A. </author> <year> 1994. </year> <title> A Course in Game Theory. </title> <publisher> The MIT Press. </publisher>
Reference: <author> Rosenschein, J., and Zlotkin, G. </author> <year> 1994. </year> <title> Rules of Encounter. </title> <address> Cambridge, Mass.: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Standard game-theoretic models (Osborne & Rubinstein 1 Copyright c fl1997, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. 2 This paper appears in Proceedings of AAAI-97. 1994) tend to focus on outcomes of negotiation in contrast to the negotiation process itself. DAI research <ref> (Rosenschein & Zlotkin 1994) </ref> emphasizes special protocols articulating compromises while trying to minimize the potential interactions or communications of the involved agents.
Reference: <author> Sandholm, T. W., and Lesser, V. R. </author> <year> 1995. </year> <title> Coalition fromation among bounded rational agents. </title> <booktitle> In Proceedings of 14th International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: Introduction Recent growing interest in autonomous interacting software agents and their potential application in areas such as electronic commerce (e.g., <ref> (Sandholm & Lesser 1995) </ref>) has given increased importance to automated negotiation. Much DAI and game theoretic research (Rosenschein & Zlotkin 1994; Osborne & Rubinstein 1994; Kraus & Subrahmanian 1995) deals with coordination and negotiation issues by giving pre-computed solutions to specific problems.
Reference: <author> Sen, S., and Sekaran, M. </author> <year> 1995. </year> <title> Multiagent coordination with learning classifier systems. </title> <booktitle> In Proceedings of IJCAI-95 Workshop on Adaptation and Learning in Multiagent Systems. </booktitle> <pages> 6 </pages>
Reference-contexts: These theoretical results, however, are available only for the simplest game settings and valid only under very restrictive assumptions such as only a subset of possible negotiation strategies are allowed. Multi-agent learning has also increasingly drawn research efforts from Distributed AI community. Mor et. al. <ref> (Mor, Goldman, & Rosenschein 1995) </ref> discussed multi-agent learning as a means to reach equilibrium. They modeled agents as finite automata and analyzed the computational complexity of certain classes of learning strategies based on this automaton model. <p> Mor et. al. (Mor, Goldman, & Rosenschein 1995) discussed multi-agent learning as a means to reach equilibrium. They modeled agents as finite automata and analyzed the computational complexity of certain classes of learning strategies based on this automaton model. In <ref> (Sen & Sekaran 1995) </ref> the authors demonstrated that some simple agent adaptive behaviors based on reciprocity allow agents to produce satisfactory global performance. In the context of Bazaar, we are using the Bayesian framework to update the knowledge and belief that each agent has about the environment and other agents.
References-found: 12

